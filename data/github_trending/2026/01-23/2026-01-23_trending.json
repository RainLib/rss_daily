{
  "date": "2026-01-23",
  "name": "trending",
  "repositories": [
    {
      "id": 815634288,
      "name": "tambo",
      "full_name": "tambo-ai/tambo",
      "description": "Generative UI SDK for React",
      "html_url": "https://github.com/tambo-ai/tambo",
      "stars": 3667,
      "forks": 220,
      "language": "TypeScript",
      "topics": [
        "agent",
        "agents",
        "ai",
        "assistant",
        "assistant-chat-bots",
        "generative-ui",
        "js",
        "react",
        "reactjs",
        "ui",
        "ui-components"
      ],
      "created_at": "2024-06-15T17:11:37Z",
      "updated_at": "2026-01-23T01:57:41Z",
      "pushed_at": "2026-01-23T02:11:00Z",
      "open_issues": 68,
      "owner": {
        "login": "tambo-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/187570293?v=4"
      },
      "readme": "<div align=\"center\">\n  <img src=\"assets/octo-white-background-rounded.png\" width=\"150\">\n  <h1>Tambo AI</h1>\n  <h3>Generative UI for React</h3>\n  <p>Build apps that adapt to your users.</p>\n</div>\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/@tambo-ai/react\"><img src=\"https://img.shields.io/npm/v/%40tambo-ai%2Freact?logo=npm\" alt=\"npm version\" /></a>\n  <a href=\"https://github.com/tambo-ai/tambo/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/tambo-ai/tambo\" alt=\"License\" /></a>\n  <a href=\"https://github.com/tambo-ai/tambo/commits/main\"><img src=\"https://img.shields.io/github/last-commit/tambo-ai/tambo\" alt=\"Last Commit\" /></a>\n  <a href=\"https://discord.gg/dJNvPEHth6\"><img src=\"https://img.shields.io/discord/1251581895414911016?color=7289da&label=discord\" alt=\"Discord\"></a>\n  <a href=\"https://github.com/tambo-ai/tambo\"><img src=\"https://img.shields.io/github/stars/tambo-ai/tambo\" alt=\"GitHub stars\" /></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/15734\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://trendshift.io/api/badge/repositories/15734\" alt=\"tambo-ai/tambo | Trendshift\" width=\"250\" height=\"55\" /></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://docs.tambo.co\">Documentation</a> ‚Ä¢\n  <a href=\"https://discord.gg/dJNvPEHth6\">Discord</a>\n</p>\n\n---\n\n## What is Tambo?\n\nTambo is a generative UI SDK for React. Register your components, and the AI decides which ones to render based on natural language conversations.\n\nhttps://github.com/user-attachments/assets/8381d607-b878-4823-8b24-ecb8053bef23\n\n## Why We Built This\n\nMost software is built around a one-size-fits-all mental model that doesn't fit every user.\n\n**Users shouldn't have to learn your app.** Generative UI shows the right components based on what someone is trying to do. First-time users and power users see different things.\n\n**Users shouldn't have to click through your workflows.** \"Show me sales from last quarter grouped by region\" should just work. The AI translates what users want into the right interface.\n\n```tsx\nconst components: TamboComponent[] = [{\n  name: \"Graph\",\n  description: \"Displays data as charts\",\n  component: Graph,\n  propsSchema: z.object({ data: z.array(...), type: z.enum([\"line\", \"bar\", \"pie\"]) })\n}];\n```\n\n## Get Started\n\n```bash\nnpx tambo create-app my-tambo-app\ncd my-tambo-app\nnpx tambo init      # choose cloud or self-hosted\nnpm run dev\n```\n\n**Tambo Cloud** is a free hosted backend. **Self-hosted** runs on your own infrastructure.\n\nCheck out the [pre-built component library](https://ui.tambo.co) for ready-made primitives, or fork a template:\n\n| Template                                                                 | Description                                       |\n| ------------------------------------------------------------------------ | ------------------------------------------------- |\n| [AI Chat with Generative UI](https://github.com/tambo-ai/tambo-template) | Chat interface with dynamic component generation  |\n| [AI Analytics Dashboard](https://github.com/tambo-ai/analytics-template) | Analytics dashboard with AI-powered visualization |\n\nhttps://github.com/user-attachments/assets/6cbc103b-9cc7-40f5-9746-12e04c976dff\n\n## How It Works\n\nTambo supports two kinds of components.\n\n**Generative components** render once in response to a message. Charts, summaries, data visualizations.\n\nhttps://github.com/user-attachments/assets/3bd340e7-e226-4151-ae40-aab9b3660d8b\n\n**Interactable components** persist and update as users refine requests. Shopping carts, spreadsheets, task boards.\n\nhttps://github.com/user-attachments/assets/12d957cd-97f1-488e-911f-0ff900ef4062\n\n### Registering Components\n\nTell the AI which components it can use. Zod schemas define the props.\n\n```tsx\n// Generative: AI creates on-demand\nconst components: TamboComponent[] = [\n  {\n    name: \"Graph\",\n    description: \"Displays data as charts using Recharts library\",\n    component: Graph,\n    propsSchema: z.object({\n      data: z.array(z.object({ name: z.string(), value: z.number() })),\n      type: z.enum([\"line\", \"bar\", \"pie\"]),\n    }),\n  },\n];\n\n// Interactable: persists and updates by ID\nconst InteractableNote = withInteractable(Note, {\n  componentName: \"Note\",\n  description: \"A note supporting title, content, and color modifications\",\n  propsSchema: z.object({\n    title: z.string(),\n    content: z.string(),\n    color: z.enum([\"white\", \"yellow\", \"blue\", \"green\"]).optional(),\n  }),\n});\n```\n\nDocs: [generative components](https://docs.tambo.co/concepts/components/defining-tambo-components), [interactable components](https://docs.tambo.co/concepts/components/interactable-components)\n\n### The Provider\n\nWrap your app with `TamboProvider`.\n\n```tsx\n<TamboProvider\n  apiKey={process.env.NEXT_PUBLIC_TAMBO_API_KEY!}\n  components={components}\n>\n  <Chat />\n  <InteractableNote id=\"note-1\" title=\"My Note\" content=\"Start writing...\" />\n</TamboProvider>\n```\n\nFor apps with signed-in users, pass a per-user `userToken` (OAuth access token) to `TamboProvider` to enable per-user auth and connect Tambo to your app's end-user identity. See [User Authentication](https://docs.tambo.co/concepts/user-authentication) for details.\n\nDocs: [provider options](https://docs.tambo.co/api-reference/tambo-provider)\n\n### Hooks\n\nSend messages with `useTamboThreadInput`. `useTamboThread` handles streaming, including props for generated components and tool calls.\n\n```tsx\nconst { value, setValue, submit, isPending } = useTamboThreadInput();\n\n<input value={value} onChange={(e) => setValue(e.target.value)} />\n<button onClick={() => submit()} disabled={isPending}>Send</button>\n```\n\n```tsx\nconst { thread } = useTamboThread();\n\n{\n  thread.messages.map((message) => (\n    <div key={message.id}>\n      {Array.isArray(message.content) ? (\n        message.content.map((part, i) =>\n          part.type === \"text\" ? <p key={i}>{part.text}</p> : null,\n        )\n      ) : (\n        <p>{String(message.content)}</p>\n      )}\n      {message.renderedComponent}\n    </div>\n  ));\n}\n```\n\nTrack streaming status if you want progressive loading:\n\n```tsx\nconst { streamStatus, propStatus } = useTamboStreamStatus();\n\nif (!streamStatus.isSuccess) return <Spinner />;\n{\n  propStatus[\"title\"]?.isSuccess && <h3>{title}</h3>;\n}\n```\n\nDocs: [threads and messages](https://docs.tambo.co/concepts/message-threads), [streaming status](https://docs.tambo.co/concepts/streaming/component-streaming-status)\n\n<p align=\"center\">\n  <a href=\"https://docs.tambo.co/getting-started/quickstart\">Full tutorial</a>\n</p>\n\n## Features\n\n### MCP Integrations\n\nConnect to Linear, Slack, databases, or your own MCP servers. Tambo supports the full MCP protocol: tools, prompts, elicitations, and sampling.\n\n```tsx\nimport { MCPTransport } from \"@tambo-ai/react/mcp\";\n\nconst mcpServers = [\n  {\n    name: \"filesystem\",\n    url: \"http://localhost:8261/mcp\",\n    transport: MCPTransport.HTTP,\n  },\n];\n\n<TamboProvider components={components} mcpServers={mcpServers}>\n  <App />\n</TamboProvider>;\n```\n\nhttps://github.com/user-attachments/assets/c7a13915-8fed-4758-be1b-30a60fad0cda\n\nSupports the full MCP protocol: tools, prompts, elicitations, and sampling.\n\nDocs: [MCP integration](https://docs.tambo.co/concepts/model-context-protocol)\n\n### Local Tools\n\nSometimes you need functions that run in the browser. DOM manipulation, authenticated fetches, accessing React state. Define them as tools and the AI can call them.\n\n```tsx\nconst tools: TamboTool[] = [\n  {\n    name: \"getWeather\",\n    description: \"Fetches weather for a location\",\n    tool: async (location: string) =>\n      fetch(`/api/weather?q=${encodeURIComponent(location)}`).then((r) =>\n        r.json(),\n      ),\n    toolSchema: z\n      .function()\n      .args(z.string())\n      .returns(\n        z.object({\n          temperature: z.number(),\n          condition: z.string(),\n          location: z.string(),\n        }),\n      ),\n  },\n];\n\n<TamboProvider tools={tools} components={components}>\n  <App />\n</TamboProvider>;\n```\n\nDocs: [local tools](https://docs.tambo.co/concepts/tools/adding-tools)\n\n### Context, Auth, and Suggestions\n\n**Additional context** lets you pass metadata to give the AI better responses. User state, app settings, current page. **User authentication** passes tokens from your auth provider. **Suggestions** generates prompts users can click based on what they're doing.\n\n```tsx\n<TamboProvider\n  userToken={userToken}\n  contextHelpers={{\n    selectedItems: () => ({\n      key: \"selectedItems\",\n      value: selectedItems.map((i) => i.name).join(\", \"),\n    }),\n    currentPage: () => ({ key: \"page\", value: window.location.pathname }),\n  }}\n/>\n```\n\n```tsx\nconst { suggestions, accept } = useTamboSuggestions({ maxSuggestions: 3 });\n\nsuggestions.map((s) => (\n  <button key={s.id} onClick={() => accept(s)}>\n    {s.title}\n  </button>\n));\n```\n\nDocs: [additional context](https://docs.tambo.co/concepts/additional-context), [user authentication](https://docs.tambo.co/concepts/user-authentication), [suggestions](https://docs.tambo.co/concepts/suggestions)\n\n### Supported LLM Providers\n\nOpenAI, Anthropic, Cerebras, Google Gemini, Mistral, and any OpenAI-compatible provider. [Full list](https://docs.tambo.co/models). Missing one? [Let us know](https://github.com/tambo-ai/tambo/issues).\n\n## How Tambo Compares\n\n| Feature                            | Tambo                                 | Vercel AI SDK                    | CopilotKit                       | Assistant UI         |\n| ---------------------------------- | ------------------------------------- | -------------------------------- | -------------------------------- | -------------------- |\n| **Component selection**            | AI decides which components to render | Manual tool-to-component mapping | Via agent frameworks (LangGraph) | Chat-focused tool UI |\n| **MCP integration**                | Built-in                              | Experimental (v4.2+)             | Recently added                   | Requires AI SDK v5   |\n| **Persistent stateful components** | Yes                                   | No                               | Shared state patterns            | No                   |\n| **Client-side tool execution**     | Declarative, automatic                | Manual via onToolCall            | Agent-side only                  | No                   |\n| **Self-hostable**                  | MIT (SDK + backend)                   | Apache 2.0 (SDK only)            | MIT                              | MIT                  |\n| **Hosted option**                  | Tambo Cloud                           | No                               | CopilotKit Cloud                 | Assistant Cloud      |\n| **Best for**                       | Full app UI control                   | Streaming and tool abstractions  | Multi-agent workflows            | Chat interfaces      |\n\n<p align=\"center\">\n  <a href=\"https://docs.tambo.co\">Full documentation</a>\n</p>\n\n---\n\n## Pricing\n\n### Self-Hosted\n\nFree forever. MIT licensed. 5-minute Docker setup.\n\n```bash\nnpx tambo init\n# Select \"Self-hosted\"\n```\n\n### Tambo Cloud\n\nFree tier, then pay as you grow.\n\n- **Free**: 10,000 messages/month\n- **Growth**: $25/mo for 200k messages + email support\n- **Enterprise**: Custom volume, SLA, SOC 2, HIPAA\n\n[Pricing details](https://tambo.co/pricing)\n\n## Repository Structure\n\nThis Turborepo hosts the React SDK ecosystem and Tambo Cloud platform.\n\n`apps/` has the web dashboard (Next.js), the API (NestJS), and MCP services.\n\n`packages/` has shared code. Database schema (Drizzle), LLM helpers, pure utilities, and tooling configs.\n\nThe root holds framework packages: `react-sdk/`, `cli/`, `showcase/`, `docs/`, `create-tambo-app/`.\n\n## Development\n\nYou'll need Node.js 22+, npm 11+, and optionally Docker.\n\n```bash\ngit clone https://github.com/tambo-ai/tambo.git\ncd tambo\nnpm install\nnpm run dev        # apps/web + apps/api\n```\n\nUseful commands:\n\n```bash\nnpm run build        # Build everything\nnpm run lint         # Lint (lint:fix to autofix)\nnpm run check-types  # Type check\nnpm test             # Run tests\n```\n\nDatabase (requires Docker):\n\n```bash\nnpm run db:generate  # Generate migrations\nnpm run db:migrate   # Apply migrations\nnpm run db:studio    # Open Drizzle Studio\n```\n\nDocker workflow lives in `scripts/cloud/`. See [README.DOCKER.md](./README.DOCKER.md) for details.\n\n[Contributing Guide](./CONTRIBUTING.md)\n\n## Community\n\n[Discord](https://discord.gg/dJNvPEHth6) for help and discussion. [GitHub](https://github.com/tambo-ai/tambo) to contribute. [@tambo_ai](https://twitter.com/tambo_ai) for updates.\n\n### Built with Tambo\n\n| Project                                                                                           | Preview                                                           | Description                                                                                             | Links                                                                                      |\n| ------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ |\n| **[db-thing](https://db-thing.vercel.app)** by [@akinloluwami](https://github.com/akinloluwami)   | <img src=\"community/db-thing.png\" alt=\"db-thing\" width=\"300\">     | Database design through conversation. Create schemas, generate ERDs, get optimization tips, export SQL. | [GitHub](https://github.com/akinloluwami/db-thing) ‚Ä¢ [Demo](https://db-thing.vercel.app)   |\n| **[CheatSheet](https://cheatsheet.tambo.co)** by [@michaelmagan](https://github.com/michaelmagan) | <img src=\"community/cheatsheet.png\" alt=\"CheatSheet\" width=\"300\"> | Spreadsheet editor with natural language. Edit cells, create charts, connect external data via MCP.     | [GitHub](https://github.com/michaelmagan/cheatsheet) ‚Ä¢ [Demo](https://cheatsheet.tambo.co) |\n\nBuilt something? [Open a PR](https://github.com/tambo-ai/tambo/pulls) or [share it in Discord](https://discord.gg/dJNvPEHth6).\n\n---\n\n## License\n\nUnless otherwise noted in a workspace (app or package), code in this repo is\nlicensed under MIT (see the root [LICENSE](LICENSE)).\n\nSome workspaces are licensed under Apache-2.0; see the accompanying `LICENSE`\nand `NOTICE` files in those workspaces.\n\n---\n\n<p align=\"center\">\n  <img src=\"assets/tambo-animation.gif\" alt=\"Tambo AI Animation\" width=\"800\">\n</p>\n\n---\n\n**For AI/LLM agents:** [docs.tambo.co/llms.txt](https://docs.tambo.co/llms.txt)\n",
      "stars_today": 558
    },
    {
      "id": 1033778670,
      "name": "AionUi",
      "full_name": "iOfficeAI/AionUi",
      "description": "Free, local, open-source Cowork for Gemini CLI, Claude Code, Codex, Opencode, Qwen Code, Goose Cli, Auggie, and more | üåü Star if you like it!",
      "html_url": "https://github.com/iOfficeAI/AionUi",
      "stars": 9283,
      "forks": 720,
      "language": "TypeScript",
      "topics": [
        "acp",
        "ai",
        "ai-agent",
        "banana",
        "chat",
        "chatbot",
        "claude-code",
        "codex",
        "cowork",
        "gemini",
        "gemini-cli",
        "gemini-pro",
        "llm",
        "multi-agent",
        "nano-banana",
        "office",
        "opencode",
        "qwen-code",
        "skills",
        "webui"
      ],
      "created_at": "2025-08-07T10:29:51Z",
      "updated_at": "2026-01-23T02:11:39Z",
      "pushed_at": "2026-01-22T14:30:06Z",
      "open_issues": 39,
      "owner": {
        "login": "iOfficeAI",
        "avatar_url": "https://avatars.githubusercontent.com/u/145246968?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"./resources/aionui-banner-1 copy.png\" alt=\"AionUi - Cowork with Your CLI AI Agent\" width=\"100%\">\n</p>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/github/v/release/iOfficeAI/AionUi?style=flat-square&color=32CD32\" alt=\"Version\">\n  &nbsp;\n  <img src=\"https://img.shields.io/badge/license-Apache--2.0-32CD32?style=flat-square&logo=apache&logoColor=white\" alt=\"License\">\n  &nbsp;\n  <img src=\"https://img.shields.io/badge/platform-macOS%20%7C%20Windows%20%7C%20Linux-6C757D?style=flat-square&logo=linux&logoColor=white\" alt=\"Platform\">\n</p>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/15423\" target=\"_blank\">\n    <img src=\"https://trendshift.io/api/badge/repositories/15423\" alt=\"GitHub Trending\" height=\"80\">\n  </a>\n</p>\n\n---\n\n<p align=\"center\">\n  <strong>üöÄ Cowork with Your AI, Gemini CLI, Claude Code, Codex, Qwen Code, Goose CLI, Auggie, and more</strong><br>\n  <em>User-friendly | Visual graphical interface | Multi-model support | Local data security</em>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/iOfficeAI/AionUi/releases\">\n    <img src=\"https://img.shields.io/badge/‚¨áÔ∏è%20Download%20Now-Latest%20Release-32CD32?style=for-the-badge&logo=github&logoColor=white\" alt=\"Download Latest Release\" height=\"50\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <strong>English</strong> | <a href=\"./readme_ch.md\">ÁÆÄ‰Ωì‰∏≠Êñá</a> | <a href=\"./readme_tw.md\">ÁπÅÈ´î‰∏≠Êñá</a> | <a href=\"./readme_jp.md\">Êó•Êú¨Ë™û</a> | <a href=\"./readme_ko.md\">ÌïúÍµ≠Ïñ¥</a> | <a href=\"./readme_es.md\">Espa√±ol</a> | <a href=\"./readme_pt.md\">Portugu√™s</a> | <a href=\"https://www.aionui.com\" target=\"_blank\">Official Website</a> | <a href=\"https://twitter.com/AionUI\" target=\"_blank\">Twitter</a>\n</p>\n\n<p align=\"center\">\n  <strong>üí¨ Community:</strong> <a href=\"https://discord.gg/g6u66vV9\" target=\"_blank\">Discord (English)</a> | <a href=\"./resources/wechat_group.png\" target=\"_blank\">ÂæÆ‰ø° (‰∏≠ÊñáÁæ§)</a>\n</p>\n\n---\n\n## üìã Quick Navigation\n\n<p align=\"center\">\n\n[‚ú® What Can AionUi Do?](#-what-can-aionui-do) ¬∑\n[ü§î Why Choose AionUi?](#-why-choose-aionui) ¬∑\n[‚ú® Core Features](#-core-features) ¬∑\n[üöÄ Quick Start](#-quick-start) ¬∑\n[üìñ Detailed Usage Guide](#-detailed-usage-guide) ¬∑\n[üí¨ Community](#-community--support)\n\n</p>\n\n---\n\n## ‚ú® What Can AionUi Do?\n\n<p align=\"center\">\n  <img src=\"./resources/offica-ai BANNER-function copy.png\" alt=\"AionUi - Cowork with Your CLI AI Agent\" width=\"800\">\n</p>\n\n### ü§ñ **Multi-Agent Mode - Cowork for Your Command-Line AI Tools, Unified Graphical Interface**\n\n_AionUi includes Gemini CLI built-in, ready to use out of the box with no extra installation. If you already have command-line tools like Gemini CLI, Claude Code, CodeX, Qwen Code, Goose AI, Augment Code installed, AionUi will auto-detect them and provide a unified graphical interface for a richer experience_\n\n- ‚úÖ **Auto Detection + Unified Interface** - Automatically recognizes local CLI tools, provides a unified graphical interface, say goodbye to command line\n- ‚úÖ **Local Storage + Multi-Session** - Conversations saved locally, supports multiple parallel sessions, each session with independent context\n\n<p align=\"center\">\n  <img src=\"./resources/acp home page.gif\" alt=\"Multi-Agent Mode Demo\" width=\"800\">\n</p>\n\n---\n\n### üìÅ **Smart File Management (AI Cowork)**\n\n_Batch renaming, automatic organization, smart classification, file merging_\n\n- **Auto Organize**: Intelligently identify content and auto-classify, keeping folders tidy.\n- **Efficient Batch**: One-click rename, merge files, say goodbye to tedious manual tasks.\n\n<p align=\"center\">\n  <img src=\"./resources/aionui sort file.gif\" alt=\"Smart File Management Demo\" width=\"800\">\n</p>\n\n---\n\n### üìÑ **Preview Panel - Quickly View AI-Generated Results**\n\n_Supports 9+ formats of visual preview (PDF, Word, Excel, PPT, code, Markdown, images, HTML, Diff, etc.)_\n\n- ‚úÖ **View Results Instantly** - After AI generates files, view preview immediately without switching apps\n- ‚úÖ **Real-time Tracking + Editable** - Automatically tracks file changes, editor and preview sync intelligently; supports real-time editing of Markdown, code, HTML, WYSIWYG\n\n<p align=\"center\">\n  <img src=\"./resources/preview.gif\" alt=\"Preview Panel Demo\" width=\"800\">\n</p>\n\n---\n\n### üé® **AI Image Generation & Editing**\n\n_Intelligent image generation, editing, and recognition, powered by Gemini_\n\n<p align=\"center\">\n  <img src=\"./resources/Image_Generation.gif\" alt=\"AI Image Generation Demo\" width=\"800\">\n</p>\n\n---\n\n### üí¨ **Multi-Task Parallel Processing**\n\n_Open multiple conversations, tasks don't get mixed up, independent memory, double efficiency_\n\n<p align=\"center\">\n  <img src=\"./resources/multichat-side-by-side.gif\" alt=\"Conversation Management Demo\" width=\"800\">\n</p>\n\n---\n\n### üåê **Access Anywhere - WebUI Mode**\n\n_Remotely control your AI tools - Access AionUi from any device on the network! Securely control local Gemini CLI, Claude Code, Codex, and other tools, data never leaves your device_\n\n```bash\n# Basic startup\nAionUi --webui\n\n# Remote access (accessible from other devices on the local network)\nAionUi --webui --remote\n```\n\n> üí° **Need detailed configuration guide?** Check out the [WebUI Configuration Tutorial](https://github.com/iOfficeAI/AionUi/wiki/WebUI-Configuration-Guide) - includes complete startup commands for all platforms\n\n<p align=\"center\">\n  <img src=\"./resources/webui banner.png\" alt=\"WebUI Remote Access Demo\" width=\"800\">\n</p>\n\n---\n\n## ü§î Why Choose AionUi?\n\n**Just like Claude Cowork makes Claude Code easier to use, AionUi is the Cowork platform for all your command-line AI tools**\n\nGemini CLI, Claude Code, Codex, Qwen Code are powerful, but share common pain points: conversations can't be saved, single-session limitations, cumbersome file operations, and only support a single model.\n\nAionUi provides unified **Cowork capabilities** for these command-line tools:\n\n- üéØ **Unified Platform** - One interface to manage all command-line AI tools, no switching needed; includes Gemini CLI, ready to use out of the box and completely free\n- üöÄ **Multi-Tool Support** - Not only supports Claude Code, but also Gemini CLI, Codex, Qwen Code, and more\n- üåê **Cross-Platform** - Full platform support for macOS, Windows, Linux (Claude Cowork currently only macOS)\n- üîÑ **Multi-Model Switching** - Flexibly switch between different models in the same interface, meeting different task requirements\n- üìÑ **Real-time Preview** - Visual preview for 9+ formats, immediately view the effects of AI-generated files\n- üíæ **Local Data Security** - All conversations and files saved locally, data never leaves your device\n\n---\n\n### ‚ùì Quick Q&A\n\n<details>\n<summary><strong>Q: Why is AionUi a great replacement for Claude Cowork?</strong></summary>\nA: AionUi is a **free and open-source** **Multi-AI Agent Desktop**. Compared to the official Cowork which only runs on macOS and is locked to Claude, AionUi is its **full-model, cross-platform enhanced version**, deeply covering **AI Office Automation** scenarios.\n\n| Dimension     | Claude Cowork        | AionUi (This Project)                       |\n| :------------ | :------------------- | :------------------------------------------ |\n| OS            | macOS Only           | üçè macOS / ü™ü Windows / üêß Linux            |\n| Model Support | Claude Only          | ü§ñ Gemini, Claude, DeepSeek, OpenAI, Ollama |\n| Interaction   | GUI                  | üñ•Ô∏è Full GUI + WebUI Remote Access           |\n| Cost          | Subscription $100/mo | üÜì Completely Free & Open Source            |\n\n**Deep AI Office Scenario Support:**\n\n- **File Management**: Intelligently organize messy local folders and batch rename with one click.\n- **Data Processing**: Deeply analyze and automatically beautify Excel reports.\n- **Document Generation**: Automatically write and format PPT, Word, and Markdown documents.\n- **Instant Preview**: Built-in 9+ format preview panels, making AI office collaboration results instantly visible.\n</details>\n\n<details>\n<summary><strong>Q: What can I do with AionUi?</strong></summary>\nA: It can be your **private Cowork workspace**. You can let it help you batch organize folders, deeply beautify Excel, and preview web code in real-time. It's your best graphical choice for exploring office automation workflows and enhancing your experience with Claude Code or Gemini CLI.\n</details>\n\n<details>\n<summary><strong>Q: Is AionUi ready to use out of the box?</strong></summary>\nA: Yes! AionUi is ready right after installation with a built-in Gemini CLI‚Äîno extra installation needed. If you already have Gemini CLI or other command-line tools installed, AionUi will auto-detect them for a richer experience.\n</details>\n\n<details>\n<summary><strong>Q: Is it free?</strong></summary>\nA: AionUi is completely free and open source, but using AI models requires corresponding API Keys.\n</details>\n\n<details>\n<summary><strong>Q: Which AI models are supported?</strong></summary>\nA: Supports mainstream models like Gemini, OpenAI, Claude, Qwen, as well as local models like Ollama, LM Studio.\n\nYou can also run multiple AI Agents simultaneously (such as Gemini CLI, Claude Code, Qwen Code, etc.), see the configuration guide for details.\n\n</details>\n\n<details>\n<summary><strong>Q: Is my data secure?</strong></summary>\nA: All conversation data is stored in a local SQLite database and will not be uploaded to any server.\n</details>\n\n---\n\n## ‚ú® Core Features\n\n### üí¨ **Multi-Session Chat**\n\n- **Multi-Session + Independent Context** - Open multiple chats simultaneously, each session has independent context memory, no confusion\n- **Local Storage** - All conversations are saved locally and will not be lost\n\n### ü§ñ **Multi-Model Support**\n\n- **Multi-Platform Support** - Supports mainstream models like Gemini, OpenAI, Claude, Qwen, flexible switching\n- **Local Model Support** - Supports local model deployment like Ollama, LM Studio, select Custom platform and set local API address (e.g., `http://localhost:11434/v1`) to connect\n- **Gemini 3 Subscription Optimization** - Automatically identifies subscribed users, recommends advanced models\n\n### üóÇÔ∏è **File Management**\n\n- **File Tree Browsing + Drag & Drop Upload** - Browse files like folders, support drag and drop files or folders for one-click import\n- **Smart Organization** - You can let AI help organize folders, automatic classification\n\n### üìÑ **Preview Panel - Give AI Agent a Display**\n\n- **9+ Format Preview** - Supports PDF, Word, Excel, PPT, code, Markdown, images, etc., view results immediately after AI generation\n- **Real-time Tracking + Editable** - Automatically tracks file changes, supports real-time editing and debugging of Markdown, code, HTML\n\n### üé® **AI Image Generation & Editing**\n\n- **Intelligent Image Generation** - Supports multiple image generation models like Gemini 2.5 Flash Image Preview, Nano, Banana\n- **Image Recognition & Editing** - AI-driven image analysis and editing features\n\n### üåê **WebUI Remote Access**\n\n- **Cross-Device Access** - Access from any device on the network via browser, supports mobile devices\n- **Local Data Security** - All data stored locally in SQLite database, suitable for server deployment\n\n### üé® **Personalized Interface Customization**\n\n_Customize with your own CSS code, make your interface match your preferences_\n\n<p align=\"center\">\n  <img src=\"./resources/css with skin.gif\" alt=\"CSS Custom Interface Demo\" width=\"800\">\n</p>\n\n- **Fully Customizable** - Freely customize interface colors, styles, layout through CSS code, create your exclusive experience\n\n---\n\n## üìñ Detailed Usage Guide\n\n<details>\n<summary><strong>üìñ Expand to View Complete Usage Guide</strong></summary>\n\n### üöÄ Quick Start\n\n- [üìñ Complete Installation Guide](https://github.com/iOfficeAI/AionUi/wiki/Getting-Started) - Detailed steps from download to configuration\n- [‚öôÔ∏è LLM Configuration Guide](https://github.com/iOfficeAI/AionUi/wiki/LLM-Configuration) - Multi-platform AI model configuration\n- [ü§ñ Multi-Agent Mode Setup](https://github.com/iOfficeAI/AionUi/wiki/ACP-Setup) - Integrate terminal AI agents\n- [üîå MCP Tool Configuration](https://github.com/iOfficeAI/AionUi/wiki/MCP-Configuration-Guide) - Model Context Protocol server setup\n- [üé® Image Generation Configuration](https://github.com/iOfficeAI/AionUi/wiki/AionUi-Image-Generation-Tool-Model-Configuration-Guide) - AI image generation setup tutorial\n- [üåê WebUI Configuration Guide](https://github.com/iOfficeAI/AionUi/wiki/WebUI-Configuration-Guide) - Complete WebUI setup and configuration tutorial\n\n### üéØ Use Cases\n\n- [üìÅ File Management](https://github.com/iOfficeAI/AionUi/wiki/file-management) - Smart file organization\n- [üìä Excel Processing](https://github.com/iOfficeAI/AionUi/wiki/excel-processing) - AI-driven data processing\n- [üé® Image Generation](https://github.com/iOfficeAI/AionUi/wiki/AionUi-Image-Generation-Tool-Model-Configuration-Guide) - AI image creation\n- [üìö More Use Cases](https://github.com/iOfficeAI/AionUi/wiki/Use-Cases-Overview)\n  - [üé¨ WorldofAI](https://www.youtube.com/watch?v=yUU5E-U5B3M) - YouTube Video Review\n  - [üé¨ Julian Goldie SEO](https://www.youtube.com/watch?v=enQnkKfth10) - YouTube Video Review\n\n### ‚ùì Support & Help\n\n- [‚ùì FAQ](https://github.com/iOfficeAI/AionUi/wiki/FAQ) - Questions and troubleshooting\n- [üîß Configuration & Usage Tutorials](https://github.com/iOfficeAI/AionUi/wiki/Configuration-Guides) - Complete configuration documentation\n\n</details>\n\n---\n\n## üöÄ Quick Start\n\n### üíª System Requirements\n\n- **macOS**: 10.15 or higher\n- **Windows**: Windows 10 or higher\n- **Linux**: Ubuntu 18.04+ / Debian 10+ / Fedora 32+\n- **Memory**: Recommended 4GB or more\n- **Storage**: At least 500MB available space\n\n### üì• Download\n\n<p>\n  <a href=\"https://github.com/iOfficeAI/AionUi/releases\">\n    <img src=\"https://img.shields.io/badge/Download-Latest%20Release-32CD32?style=for-the-badge&logo=github&logoColor=white\" alt=\"Download Latest Release\" height=\"50\">\n  </a>\n</p>\n\n### üç∫ Install via Homebrew (macOS)\n\n```bash\nbrew install aionui\n```\n\n### üîß Simple Installation\n\n1. **Download and install** AionUi application\n2. **Configure AI service** - Support Google account login or API Key authentication\n3. **Start using** - Immediately experience modern AI chat interface\n\n> üí° **Need detailed configuration guide?** Check out our [Complete Installation Tutorial](https://github.com/iOfficeAI/AionUi/wiki/Getting-Started)\n\n---\n\n## ü§ù Community & Support\n\n### üí¨ Community\n\n**üí° Your ideas matter!** We highly value every user's suggestions and feedback. Whether it's feature ideas, user experience, or issues you encounter, feel free to contact us anytime!\n\n<p align=\"center\">\n  <a href=\"https://x.com/AionUi\" target=\"_blank\">\n    <img src=\"./resources/contactus-x.png\" alt=\"Contact Us on X\" width=\"600\">\n  </a>\n</p>\n\n- [üí¨ GitHub Discussions](https://github.com/iOfficeAI/AionUi/discussions) - **Share ideas, make suggestions, exchange usage tips**\n- [üêõ Report Issues](https://github.com/iOfficeAI/AionUi/issues) - Report bugs or feature requests\n- [üì¶ Release Updates](https://github.com/iOfficeAI/AionUi/releases) - Get the latest version\n- [üí¨ Discord Community](https://discord.gg/g6u66vV9) - **Join our English community on Discord**\n- [üí¨ ÂæÆ‰ø° (‰∏≠ÊñáÁæ§)](./resources/wechat_group.png) - **Click to view QR code**\n\n### ü§ù Contributing\n\nWelcome to submit Issues and Pull Requests!\n\n1. Fork this project\n2. Create a feature branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n---\n\n## üìÑ License\n\nThis project is licensed under [Apache-2.0](LICENSE).\n\n---\n\n## üë• Contributors\n\nThanks to all developers who have contributed to AionUi!\n\n<p align=\"center\">\n  <a href=\"https://github.com/iOfficeAI/AionUi/graphs/contributors\">\n    <img src=\"https://contrib.rocks/image?repo=iOfficeAI/AionUi&max=50\" alt=\"Contributors\" />\n  </a>\n</p>\n\n## üìä Star History\n\n<p align=\"center\">\n  <a href=\"https://www.star-history.com/#iOfficeAI/aionui&Date\" target=\"_blank\">\n    <img src=\"https://api.star-history.com/svg?repos=iOfficeAI/aionui&type=Date\" alt=\"GitHub Star Trends\" width=\"600\">\n  </a>\n</p>\n\n<div align=\"center\">\n\n**‚≠ê If you like it, give us a star**\n\n[Report Bug](https://github.com/iOfficeAI/AionUi/issues) ¬∑ [Request Feature](https://github.com/iOfficeAI/AionUi/issues)\n\n</div>\n",
      "stars_today": 554
    },
    {
      "id": 274495425,
      "name": "remotion",
      "full_name": "remotion-dev/remotion",
      "description": "üé•      Make videos programmatically with React",
      "html_url": "https://github.com/remotion-dev/remotion",
      "stars": 27110,
      "forks": 1589,
      "language": "TypeScript",
      "topics": [
        "javascript",
        "react",
        "video"
      ],
      "created_at": "2020-06-23T19:49:10Z",
      "updated_at": "2026-01-23T02:11:51Z",
      "pushed_at": "2026-01-22T14:07:49Z",
      "open_issues": 94,
      "owner": {
        "login": "remotion-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/85344006?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://github.com/remotion-dev/logo\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-dark.apng\">\n      <img alt=\"Animated Remotion Logo\" src=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-light.gif\">\n    </picture>\n  </a>\n</p>\n\n[![Discord Shield](https://img.shields.io/discord/809501355504959528?color=000000&label=Discord&logo=fdgssdf)](https://remotion.dev/discord)\n[![NPM Version](https://img.shields.io/npm/v/remotion.svg?style=flat&color=black)](https://www.npmjs.org/package/remotion)\n[![NPM Downloads](https://img.shields.io/npm/dm/remotion.svg?style=flat&color=black&label=Downloads)](https://npmcharts.com/compare/remotion?minimal=true)\n[![Open Bounties](https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2Fremotion%2Fbounties%3Fstatus%3Dopen&style=flat&color=black&labelColor=grey&label=Open+Bounties)](https://github.com/remotion-dev/remotion/issues?q=is%3Aopen+label%3A%22%F0%9F%92%8E+Bounty%22+sort%3Aupdated-desc)\n<a href=\"https://twitter.com/remotion\"><img src=\"https://img.shields.io/twitter/follow/remotion?label=Twitter&color=black\" alt=\"Twitter\"></a>\n\nRemotion is a framework for **creating videos programmatically using React.**\n\n## Why create videos in React?\n\n- **Leverage web technologies**: Use all of CSS, Canvas, SVG, WebGL, etc.\n- **Leverage programming**: Use variables, functions, APIs, math and algorithms to create new effects\n- **Leverage React**: Reusable components, Powerful composition, Fast Refresh, Package ecosystem\n\n## Created with Remotion\n\n<table>\n<tr>\n<td align=\"center\">\n<img style=\"width: 290px\" src=\"https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/fireship-quick.gif\" />\n<p>\"This video was made with code\" <em>- Fireship</em> <a href=\"https://youtu.be/deg8bOoziaE\">Watch</a> ‚Ä¢ <a href=\"https://github.com/wcandillon/remotion-fireship\">Source</a></p>\n</td>\n<td align=\"center\">\n<img style=\"width: 240px\" src=\"https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/unwrapped-2023.gif\" />\n<p>GitHub Unwrapped - Personalized Year in Review <a href=\"https://www.githubunwrapped.com\">Try</a> ‚Ä¢ <a href=\"https://github.com/remotion-dev/github-unwrapped\">Source</a></p>\n</td>\n<td align=\"center\">\n<em>View more in the <a href=\"https://remotion.dev/showcase\">Remotion Showcase</a>!</em>\n</td>\n</tr>\n</table>\n\n## Get started\n\nIf you already have Node.JS installed, type\n\n```console\nnpx create-video@latest\n```\n\nto get started. Otherwise, read the [installation page](https://www.remotion.dev/docs/) in the documentation.\n\n## Documentation\n\nDocumentation: [**remotion.dev/docs**](https://www.remotion.dev/docs)  \nAPI Reference: [**remotion.dev/api**](https://www.remotion.dev/api)\n\n## License\n\nBe aware of that Remotion has a special license and requires obtaining a company license in some cases. Read the [LICENSE](LICENSE.md) page for more information.\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) to learn about contributing to this project.\n",
      "stars_today": 537
    },
    {
      "id": 846698999,
      "name": "goose",
      "full_name": "block/goose",
      "description": "an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM",
      "html_url": "https://github.com/block/goose",
      "stars": 27180,
      "forks": 2469,
      "language": "Rust",
      "topics": [
        "mcp"
      ],
      "created_at": "2024-08-23T19:03:36Z",
      "updated_at": "2026-01-23T02:10:08Z",
      "pushed_at": "2026-01-23T00:10:43Z",
      "open_issues": 298,
      "owner": {
        "login": "block",
        "avatar_url": "https://avatars.githubusercontent.com/u/185116535?v=4"
      },
      "readme": "<div align=\"center\">\n\n# goose\n\n_a local, extensible, open source AI agent that automates engineering tasks_\n\n<p align=\"center\">\n  <a href=\"https://opensource.org/licenses/Apache-2.0\">\n    <img src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg\">\n  </a>\n  <a href=\"https://discord.gg/goose-oss\">\n    <img src=\"https://img.shields.io/discord/1287729918100246654?logo=discord&logoColor=white&label=Join+Us&color=blueviolet\" alt=\"Discord\">\n  </a>\n  <a href=\"https://github.com/block/goose/actions/workflows/ci.yml\">\n     <img src=\"https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main\" alt=\"CI\">\n  </a>\n</p>\n</div>\n\ngoose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.\n\nWhether you're prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.\n\nDesigned for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.\n\n[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)\n\n# Quick Links\n- [Quickstart](https://block.github.io/goose/docs/quickstart)\n- [Installation](https://block.github.io/goose/docs/getting-started/installation)\n- [Tutorials](https://block.github.io/goose/docs/category/tutorials)\n- [Documentation](https://block.github.io/goose/docs/category/getting-started)\n- [Responsible AI-Assisted Coding Guide](https://github.com/block/goose/blob/main/HOWTOAI.md)\n- [Governance](https://github.com/block/goose/blob/main/GOVERNANCE.md)\n\n## Need Help?\n- [Diagnostics & Reporting](https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting)\n- [Known Issues](https://block.github.io/goose/docs/troubleshooting/known-issues)\n\n# a little goose humor ü¶¢\n\n> Why did the developer choose goose as their AI agent?\n> \n> Because it always helps them \"migrate\" their code to production! üöÄ\n\n# goose around with us  \n- [Discord](https://discord.gg/goose-oss)\n- [YouTube](https://www.youtube.com/@goose-oss)\n- [LinkedIn](https://www.linkedin.com/company/goose-oss)\n- [Twitter/X](https://x.com/goose_oss)\n- [Bluesky](https://bsky.app/profile/opensource.block.xyz)\n- [Nostr](https://njump.me/opensource@block.xyz)\n",
      "stars_today": 347
    },
    {
      "id": 1031912724,
      "name": "cc-switch",
      "full_name": "farion1231/cc-switch",
      "description": "A cross-platform desktop All-in-One assistant tool for Claude Code, Codex & Gemini CLI.",
      "html_url": "https://github.com/farion1231/cc-switch",
      "stars": 13058,
      "forks": 836,
      "language": "Rust",
      "topics": [
        "ai-tools",
        "claude-code",
        "codex",
        "deepseek-v3",
        "desktop-app",
        "kimi-k2-thiking",
        "mcp",
        "minimax",
        "open-source",
        "provider-management",
        "qwen-coder",
        "rust",
        "tauri",
        "typescript",
        "wsl-support"
      ],
      "created_at": "2025-08-04T14:16:16Z",
      "updated_at": "2026-01-23T02:10:36Z",
      "pushed_at": "2026-01-23T01:07:48Z",
      "open_issues": 127,
      "owner": {
        "login": "farion1231",
        "avatar_url": "https://avatars.githubusercontent.com/u/44939412?v=4"
      },
      "readme": "<div align=\"center\">\n\n# All-in-One Assistant for Claude Code, Codex & Gemini CLI\n\n[![Version](https://img.shields.io/badge/version-3.10.0-blue.svg)](https://github.com/farion1231/cc-switch/releases)\n[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/farion1231/cc-switch/releases)\n[![Built with Tauri](https://img.shields.io/badge/built%20with-Tauri%202-orange.svg)](https://tauri.app/)\n[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total)](https://github.com/farion1231/cc-switch/releases/latest)\n\n<a href=\"https://trendshift.io/repositories/15372\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/15372\" alt=\"farion1231%2Fcc-switch | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\nEnglish | [‰∏≠Êñá](README_ZH.md) | [Êó•Êú¨Ë™û](README_JA.md) | [Changelog](CHANGELOG.md)\n\n</div>\n\n## ‚ù§Ô∏èSponsor\n\n[![Zhipu GLM](assets/partners/banners/glm-en.jpg)](https://z.ai/subscribe?ic=8JVLJQFSKB)\n\nThis project is sponsored by Z.ai, supporting us with their GLM CODING PLAN.GLM CODING PLAN is a subscription service designed for AI coding, starting at just $3/month. It provides access to their flagship GLM-4.6 model across 10+ popular AI coding tools (Claude Code, Cline, Roo Code, etc.), offering developers top-tier, fast, and stable coding experiences.Get 10% OFF the GLM CODING PLAN with [this link](https://z.ai/subscribe?ic=8JVLJQFSKB)!\n\n---\n\n<table>\n<tr>\n<td width=\"180\"><a href=\"https://www.packyapi.com/register?aff=cc-switch\"><img src=\"assets/partners/logos/packycode.png\" alt=\"PackyCode\" width=\"150\"></a></td>\n<td>Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using <a href=\"https://www.packyapi.com/register?aff=cc-switch\">this link</a> and enter the \"cc-switch\" promo code during recharge to get 10% off.</td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://aigocode.com/invite/CC-SWITCH\"><img src=\"assets/partners/logos/aigocode.png\" alt=\"AIGoCode\" width=\"150\"></a></td>\n<td>Thanks to AIGoCode for sponsoring this project! AIGoCode is an all-in-one platform that integrates Claude Code, Codex, and the latest Gemini models, providing you with stable, efficient, and highly cost-effective AI coding services. The platform offers flexible subscription plans, zero risk of account suspension, direct access with no VPN required, and lightning-fast responses. AIGoCode has prepared a special benefit for CC Switch users: if you register via <a href=\"https://aigocode.com/invite/CC-SWITCH\">this link</a>, you'll receive an extra 10% bonus credit on your first top-up!</td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://www.dmxapi.cn/register?aff=bUHu\"><img src=\"assets/partners/logos/dmx-en.jpg\" alt=\"DMXAPI\" width=\"150\"></a></td>\n<td>Thanks to DMXAPI for sponsoring this project! DMXAPI provides global large model API services to 200+ enterprise users. One API key for all global models. Features include: instant invoicing, unlimited concurrency, starting from $0.15, 24/7 technical support. GPT/Claude/Gemini all at 32% off, domestic models 20-50% off, Claude Code exclusive models at 66% off! <a href=\"https://www.dmxapi.cn/register?aff=bUHu\">Register here</a></td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://cubence.com/signup?code=CCSWITCH&source=ccs\"><img src=\"assets/partners/logos/cubence.png\" alt=\"Cubence\" width=\"150\"></a></td>\n<td>Thanks to Cubence for sponsoring this project! Cubence is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more with flexible billing options including pay-as-you-go and monthly plans. Cubence provides special discounts for CC Switch users: register using <a href=\"https://cubence.com/signup?code=CCSWITCH&source=ccs\">this link</a> and enter the \"CCSWITCH\" promo code during recharge to get 10% off every top-up!</td>\n</tr>\n\n</table>\n\n## Screenshots\n\n|                  Main Interface                   |                  Add Provider                  |\n| :-----------------------------------------------: | :--------------------------------------------: |\n| ![Main Interface](assets/screenshots/main-en.png) | ![Add Provider](assets/screenshots/add-en.png) |\n\n## Features\n\n### Current Version: v3.10.0 | [Full Changelog](CHANGELOG.md) | [Release Notes](docs/release-note-v3.9.0-en.md)\n\n**v3.8.0 Major Update (2025-11-28)**\n\n**Persistence Architecture Upgrade & Brand New UI**\n\n- **SQLite + JSON Dual-layer Architecture**\n  - Migrated from JSON file storage to SQLite + JSON dual-layer structure\n  - Syncable data (providers, MCP, Prompts, Skills) stored in SQLite\n  - Device-level data (window state, local paths) stored in JSON\n  - Lays the foundation for future cloud sync functionality\n  - Schema version management for database migrations\n\n- **Brand New User Interface**\n  - Completely redesigned interface layout\n  - Unified component styles and smoother animations\n  - Optimized visual hierarchy\n  - Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility\n\n- **Japanese Language Support**\n  - Added Japanese interface support (now supports Chinese/English/Japanese)\n\n- **Auto Launch on Startup**\n  - One-click enable/disable in settings\n  - Platform-native APIs (Registry/LaunchAgent/XDG autostart)\n\n- **Skills Recursive Scanning**\n  - Support for multi-level directory structures\n  - Allow same-named skills from different repositories\n\n- **Critical Bug Fixes**\n  - Fixed custom endpoints lost when updating providers\n  - Fixed Gemini configuration write issues\n  - Fixed Linux WebKitGTK rendering issues\n\n**v3.7.0 Highlights**\n\n**Six Core Features, 18,000+ Lines of New Code**\n\n- **Gemini CLI Integration**\n  - Third supported AI CLI (Claude Code / Codex / Gemini)\n  - Dual-file configuration support (`.env` + `settings.json`)\n  - Complete MCP server management\n  - Presets: Google Official (OAuth) / PackyCode / Custom\n\n- **Claude Skills Management System**\n  - Auto-scan skills from GitHub repositories (3 pre-configured curated repos)\n  - One-click install/uninstall to `~/.claude/skills/`\n  - Custom repository support + subdirectory scanning\n  - Complete lifecycle management (discover/install/update)\n\n- **Prompts Management System**\n  - Multi-preset system prompt management (unlimited presets, quick switching)\n  - Cross-app support (Claude: `CLAUDE.md` / Codex: `AGENTS.md` / Gemini: `GEMINI.md`)\n  - Markdown editor (CodeMirror 6 + real-time preview)\n  - Smart backfill protection, preserves manual modifications\n\n- **MCP v3.7.0 Unified Architecture**\n  - Single panel manages MCP servers across three applications\n  - New SSE (Server-Sent Events) transport type\n  - Smart JSON parser + Codex TOML format auto-correction\n  - Unified import/export + bidirectional sync\n\n- **Deep Link Protocol**\n  - `ccswitch://` protocol registration (all platforms)\n  - One-click import provider configs via shared links\n  - Security validation + lifecycle integration\n\n- **Environment Variable Conflict Detection**\n  - Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)\n  - Visual conflict indicators + resolution suggestions\n  - Override warnings + backup before changes\n\n**Core Capabilities**\n\n- **Provider Management**: One-click switching between Claude Code, Codex, and Gemini API configurations\n- **Speed Testing**: Measure API endpoint latency with visual quality indicators\n- **Import/Export**: Backup and restore configs with auto-rotation (keep 10 most recent)\n- **i18n Support**: Complete Chinese/English localization (UI, errors, tray)\n- **Claude Plugin Sync**: One-click apply/restore Claude plugin configurations\n\n**v3.6 Highlights**\n\n- Provider duplication & drag-and-drop sorting\n- Multi-endpoint management & custom config directory (cloud sync ready)\n- Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)\n- WSL environment support with auto-sync on directory change\n- 100% hooks test coverage & complete architecture refactoring\n\n**System Features**\n\n- System tray with quick switching\n- Single instance daemon\n- Built-in auto-updater\n- Atomic writes with rollback protection\n\n## Download & Installation\n\n### System Requirements\n\n- **Windows**: Windows 10 and above\n- **macOS**: macOS 10.15 (Catalina) and above\n- **Linux**: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions\n\n### Windows Users\n\nDownload the latest `CC-Switch-v{version}-Windows.msi` installer or `CC-Switch-v{version}-Windows-Portable.zip` portable version from the [Releases](../../releases) page.\n\n### macOS Users\n\n**Method 1: Install via Homebrew (Recommended)**\n\n```bash\nbrew tap farion1231/ccswitch\nbrew install --cask cc-switch\n```\n\nUpdate:\n\n```bash\nbrew upgrade --cask cc-switch\n```\n\n**Method 2: Manual Download**\n\nDownload `CC-Switch-v{version}-macOS.zip` from the [Releases](../../releases) page and extract to use.\n\n> **Note**: Since the author doesn't have an Apple Developer account, you may see an \"unidentified developer\" warning on first launch. Please close it first, then go to \"System Settings\" ‚Üí \"Privacy & Security\" ‚Üí click \"Open Anyway\", and you'll be able to open it normally afterwards.\n\n### Arch Linux Users\n\n**Install via paru (Recommended)**\n\n```bash\nparu -S cc-switch-bin\n```\n\n### Linux Users\n\nDownload the latest Linux build from the [Releases](../../releases) page:\n\n- `CC-Switch-v{version}-Linux.deb` (Debian/Ubuntu)\n- `CC-Switch-v{version}-Linux.rpm` (Fedora/RHEL/openSUSE)\n- `CC-Switch-v{version}-Linux.AppImage` (Universal)\n- `CC-Switch-v{version}-Linux.flatpak` (Flatpak)\n\nFlatpak install & run:\n\n```bash\nflatpak install --user ./CC-Switch-v{version}-Linux.flatpak\nflatpak run com.ccswitch.desktop\n```\n\n## Quick Start\n\n### Basic Usage\n\n1. **Add Provider**: Click \"Add Provider\" ‚Üí Choose preset or create custom configuration\n2. **Switch Provider**:\n   - Main UI: Select provider ‚Üí Click \"Enable\"\n   - System Tray: Click provider name directly (instant effect)\n3. **Takes Effect**: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes\n4. **Back to Official**: Select the \"Official Login\" preset (Claude/Codex) or \"Google Official\" preset (Gemini), restart the corresponding client, then follow its login/OAuth flow\n\n### MCP Management\n\n- **Location**: Click \"MCP\" button in top-right corner\n- **Add Server**:\n  - Use built-in templates (mcp-fetch, mcp-filesystem, etc.)\n  - Support stdio / http / sse transport types\n  - Configure independent MCP servers for different apps\n- **Enable/Disable**: Toggle switches to control which servers sync to live config\n- **Sync**: Enabled servers auto-sync to each app's live files\n- **Import/Export**: Import existing MCP servers from Claude/Codex/Gemini config files\n\n### Skills Management (v3.7.0 New)\n\n- **Location**: Click \"Skills\" button in top-right corner\n- **Discover Skills**:\n  - Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)\n  - Add custom repositories (supports subdirectory scanning)\n- **Install Skills**: Click \"Install\" to one-click install to `~/.claude/skills/`\n- **Uninstall Skills**: Click \"Uninstall\" to safely remove and clean up state\n- **Manage Repositories**: Add/remove custom GitHub repositories\n\n### Prompts Management (v3.7.0 New)\n\n- **Location**: Click \"Prompts\" button in top-right corner\n- **Create Presets**:\n  - Create unlimited system prompt presets\n  - Use Markdown editor to write prompts (syntax highlighting + real-time preview)\n- **Switch Presets**: Select preset ‚Üí Click \"Activate\" to apply immediately\n- **Sync Mechanism**:\n  - Claude: `~/.claude/CLAUDE.md`\n  - Codex: `~/.codex/AGENTS.md`\n  - Gemini: `~/.gemini/GEMINI.md`\n- **Protection Mechanism**: Auto-save current prompt content before switching, preserves manual modifications\n\n### Configuration Files\n\n**Claude Code**\n\n- Live config: `~/.claude/settings.json` (or `claude.json`)\n- API key field: `env.ANTHROPIC_AUTH_TOKEN` or `env.ANTHROPIC_API_KEY`\n- MCP servers: `~/.claude.json` ‚Üí `mcpServers`\n\n**Codex**\n\n- Live config: `~/.codex/auth.json` (required) + `config.toml` (optional)\n- API key field: `OPENAI_API_KEY` in `auth.json`\n- MCP servers: `~/.codex/config.toml` ‚Üí `[mcp_servers]` tables\n\n**Gemini**\n\n- Live config: `~/.gemini/.env` (API key) + `~/.gemini/settings.json` (auth mode)\n- API key field: `GEMINI_API_KEY` or `GOOGLE_GEMINI_API_KEY` in `.env`\n- Environment variables: Support `GOOGLE_GEMINI_BASE_URL`, `GEMINI_MODEL`, etc.\n- MCP servers: `~/.gemini/settings.json` ‚Üí `mcpServers`\n- Tray quick switch: Each provider switch rewrites `~/.gemini/.env`, no need to restart Gemini CLI\n\n**CC Switch Storage (v3.8.0 New Architecture)**\n\n- Database (SSOT): `~/.cc-switch/cc-switch.db` (SQLite, stores providers, MCP, Prompts, Skills)\n- Local settings: `~/.cc-switch/settings.json` (device-level settings)\n- Backups: `~/.cc-switch/backups/` (auto-rotate, keep 10)\n\n### Cloud Sync Setup\n\n1. Go to Settings ‚Üí \"Custom Configuration Directory\"\n2. Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)\n3. Restart app to apply\n4. Repeat on other devices to enable cross-device sync\n\n> **Note**: First launch auto-imports existing Claude/Codex configs as default provider.\n\n## Architecture Overview\n\n### Design Principles\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                    Frontend (React + TS)                    ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ  ‚îÇ Components  ‚îÇ  ‚îÇ    Hooks     ‚îÇ  ‚îÇ  TanStack Query  ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ   (UI)      ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Logic) ‚îÇ‚îÄ‚îÄ‚îÇ   (Cache/Sync)   ‚îÇ    ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                         ‚îÇ Tauri IPC\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                  Backend (Tauri + Rust)                     ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ  ‚îÇ  Commands   ‚îÇ  ‚îÇ   Services   ‚îÇ  ‚îÇ  Models/Config   ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ (API Layer) ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Layer) ‚îÇ‚îÄ‚îÄ‚îÇ     (Data)       ‚îÇ    ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**Core Design Patterns**\n\n- **SSOT** (Single Source of Truth): All data stored in `~/.cc-switch/cc-switch.db` (SQLite)\n- **Dual-layer Storage**: SQLite for syncable data, JSON for device-level settings\n- **Dual-way Sync**: Write to live files on switch, backfill from live when editing active provider\n- **Atomic Writes**: Temp file + rename pattern prevents config corruption\n- **Concurrency Safe**: Mutex-protected database connection avoids race conditions\n- **Layered Architecture**: Clear separation (Commands ‚Üí Services ‚Üí DAO ‚Üí Database)\n\n**Key Components**\n\n- **ProviderService**: Provider CRUD, switching, backfill, sorting\n- **McpService**: MCP server management, import/export, live file sync\n- **ConfigService**: Config import/export, backup rotation\n- **SpeedtestService**: API endpoint latency measurement\n\n**v3.6 Refactoring**\n\n- Backend: 5-phase refactoring (error handling ‚Üí command split ‚Üí tests ‚Üí services ‚Üí concurrency)\n- Frontend: 4-stage refactoring (test infra ‚Üí hooks ‚Üí components ‚Üí cleanup)\n- Testing: 100% hooks coverage + integration tests (vitest + MSW)\n\n## Development\n\n### Environment Requirements\n\n- Node.js 18+\n- pnpm 8+\n- Rust 1.85+\n- Tauri CLI 2.8+\n\n### Development Commands\n\n```bash\n# Install dependencies\npnpm install\n\n# Dev mode (hot reload)\npnpm dev\n\n# Type check\npnpm typecheck\n\n# Format code\npnpm format\n\n# Check code format\npnpm format:check\n\n# Run frontend unit tests\npnpm test:unit\n\n# Run tests in watch mode (recommended for development)\npnpm test:unit:watch\n\n# Build application\npnpm build\n\n# Build debug version\npnpm tauri build --debug\n```\n\n### Rust Backend Development\n\n```bash\ncd src-tauri\n\n# Format Rust code\ncargo fmt\n\n# Run clippy checks\ncargo clippy\n\n# Run backend tests\ncargo test\n\n# Run specific tests\ncargo test test_name\n\n# Run tests with test-hooks feature\ncargo test --features test-hooks\n```\n\n### Testing Guide (v3.6 New)\n\n**Frontend Testing**:\n\n- Uses **vitest** as test framework\n- Uses **MSW (Mock Service Worker)** to mock Tauri API calls\n- Uses **@testing-library/react** for component testing\n\n**Test Coverage**:\n\n- Hooks unit tests (100% coverage)\n  - `useProviderActions` - Provider operations\n  - `useMcpActions` - MCP management\n  - `useSettings` series - Settings management\n  - `useImportExport` - Import/export\n- Integration tests\n  - App main application flow\n  - SettingsDialog complete interaction\n  - MCP panel functionality\n\n**Running Tests**:\n\n```bash\n# Run all tests\npnpm test:unit\n\n# Watch mode (auto re-run)\npnpm test:unit:watch\n\n# With coverage report\npnpm test:unit --coverage\n```\n\n## Tech Stack\n\n**Frontend**: React 18 ¬∑ TypeScript ¬∑ Vite ¬∑ TailwindCSS 4 ¬∑ TanStack Query v5 ¬∑ react-i18next ¬∑ react-hook-form ¬∑ zod ¬∑ shadcn/ui ¬∑ @dnd-kit\n\n**Backend**: Tauri 2.8 ¬∑ Rust ¬∑ serde ¬∑ tokio ¬∑ thiserror ¬∑ tauri-plugin-updater/process/dialog/store/log\n\n**Testing**: vitest ¬∑ MSW ¬∑ @testing-library/react\n\n## Project Structure\n\n```\n‚îú‚îÄ‚îÄ src/                      # Frontend (React + TypeScript)\n‚îÇ   ‚îú‚îÄ‚îÄ components/           # UI components (providers/settings/mcp/ui)\n‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Custom hooks (business logic)\n‚îÇ   ‚îú‚îÄ‚îÄ lib/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/              # Tauri API wrapper (type-safe)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query/            # TanStack Query config\n‚îÇ   ‚îú‚îÄ‚îÄ i18n/locales/         # Translations (zh/en)\n‚îÇ   ‚îú‚îÄ‚îÄ config/               # Presets (providers/mcp)\n‚îÇ   ‚îî‚îÄ‚îÄ types/                # TypeScript definitions\n‚îú‚îÄ‚îÄ src-tauri/                # Backend (Rust)\n‚îÇ   ‚îî‚îÄ‚îÄ src/\n‚îÇ       ‚îú‚îÄ‚îÄ commands/         # Tauri command layer (by domain)\n‚îÇ       ‚îú‚îÄ‚îÄ services/         # Business logic layer\n‚îÇ       ‚îú‚îÄ‚îÄ app_config.rs     # Config data models\n‚îÇ       ‚îú‚îÄ‚îÄ provider.rs       # Provider domain models\n‚îÇ       ‚îú‚îÄ‚îÄ mcp.rs            # MCP sync & validation\n‚îÇ       ‚îî‚îÄ‚îÄ lib.rs            # App entry & tray menu\n‚îú‚îÄ‚îÄ tests/                    # Frontend tests\n‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Unit tests\n‚îÇ   ‚îî‚îÄ‚îÄ components/           # Integration tests\n‚îî‚îÄ‚îÄ assets/                   # Screenshots & partner resources\n```\n\n## Changelog\n\nSee [CHANGELOG.md](CHANGELOG.md) for version update details.\n\n## Legacy Electron Version\n\n[Releases](../../releases) retains v2.0.3 legacy Electron version\n\nIf you need legacy Electron code, you can pull the electron-legacy branch\n\n## Contributing\n\nIssues and suggestions are welcome!\n\nBefore submitting PRs, please ensure:\n\n- Pass type check: `pnpm typecheck`\n- Pass format check: `pnpm format:check`\n- Pass unit tests: `pnpm test:unit`\n- üí° For new features, please open an issue for discussion before submitting a PR\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=farion1231/cc-switch&type=Date)](https://www.star-history.com/#farion1231/cc-switch&Date)\n\n## License\n\nMIT ¬© Jason Young\n",
      "stars_today": 269
    },
    {
      "id": 1081230042,
      "name": "VidBee",
      "full_name": "nexmoe/VidBee",
      "description": "Download videos from almost any website worldwide",
      "html_url": "https://github.com/nexmoe/VidBee",
      "stars": 4684,
      "forks": 333,
      "language": "TypeScript",
      "topics": [
        "downloader",
        "facebook",
        "tiktok",
        "twitter",
        "youtube"
      ],
      "created_at": "2025-10-22T13:43:42Z",
      "updated_at": "2026-01-23T02:09:44Z",
      "pushed_at": "2026-01-21T14:06:59Z",
      "open_issues": 30,
      "owner": {
        "login": "nexmoe",
        "avatar_url": "https://avatars.githubusercontent.com/u/16796652?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://github.com/nexmoe/VidBee\">\n    <img src=\"build/icon.png\" alt=\"Logo\" width=\"80\" height=\"80\">\n  </a>\n\n  <h3>VidBee</h3>\n  <p>\n    <a href=\"https://github.com/nexmoe/VidBee/stargazers\"><img src=\"https://img.shields.io/github/stars/nexmoe/VidBee?color=ffcb47&labelColor=black&logo=github&label=Stars\" /></a>\n    <a href=\"https://github.com/nexmoe/VidBee/graphs/contributors\"><img src=\"https://img.shields.io/github/contributors/nexmoe/VidBee?ogo=github&label=Contributors&labelColor=black\" /></a>\n    <a href=\"https://github.com/nexmoe/VidBee/releases\"><img src=\"https://img.shields.io/github/downloads/nexmoe/VidBee/total?color=369eff&labelColor=black&logo=github&label=Downloads\" /></a>\n    <a href=\"https://github.com/nexmoe/VidBee/releases/latest\"><img src=\"https://img.shields.io/github/v/release/nexmoe/VidBee?color=369eff&labelColor=black&logo=github&label=Latest%20Release\" /></a>\n    <a href=\"https://x.com/intent/follow?screen_name=nexmoex\"><img src=\"https://img.shields.io/badge/Follow-blue?color=1d9bf0&logo=x&labelColor=black\" /></a>\n    <a href=\"https://deepwiki.com/nexmoe/VidBee\"><img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\"></a>\n    <br />\n    <br />\n    <a href=\"https://github.com/nexmoe/VidBee/releases/latest\" target=\"_blank\"><img src=\"screenshots/main-interface.png\" alt=\"VidBee Desktop\" width=\"46%\"/></a>\n    <a href=\"https://github.com/nexmoe/VidBee/releases/latest\" target=\"_blank\"><img src=\"screenshots/download-queue.png\" alt=\"VidBee Download Queue\" width=\"46%\"/></a>\n    <br />\n    <br />\n  </p>\n</div>\n\nVidBee is a modern, open-source video downloader that lets you download videos and audios from 1000+ websites worldwide. Built with Electron and powered by yt-dlp, VidBee offers a clean, intuitive interface with powerful features for all your downloading needs, including RSS auto-download automation that automatically subscribes to feeds and downloads new videos from your favorite creators in the background.\n\n## üëãüèª Getting Started\n\nVidBee is currently under active development, and feedback is welcome for any [issue](https://github.com/nexmoe/VidBee/issues) encountered.\n\n[üì• Download VidBee](https://vidbee.org/download/) | [üìö Documentation](https://docs.vidbee.org)\n\n> [!IMPORTANT]\n>\n> **Star Us**, You will receive all release notifications from GitHub without any delay ~\n\n<a href=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats?repo_id=1081230042\" target=\"_blank\" style=\"display: block\" align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=1081230042&image_size=auto&color_scheme=dark\" width=\"655\" height=\"auto\">\n    <img alt=\"Performance Stats of nexmoe/VidBee - Last 28 days\" src=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=1081230042&image_size=auto&color_scheme=light\" width=\"655\" height=\"auto\">\n  </picture>\n</a>\n\n<!-- Made with [OSS Insight](https://ossinsight.io/) -->\n\n## ‚ú® Features\n\n### üåç Global Video Download Support\n\nDownload videos from almost any website worldwide through the powerful yt-dlp engine. Support for 1000+ sites including YouTube, TikTok, Instagram, Twitter, and many more.\n\n![VidBee Main Interface](screenshots/main-interface.png)\n\n### üé® Best-in-class UI Experience\n\nModern, clean interface with intuitive operations. One-click pause/resume/retry, real-time progress tracking, and comprehensive download queue management.\n\n![VidBee Download Queue](screenshots/download-queue.png)\n\n### üì° RSS Auto Download\n\nAutomatically subscribe to RSS feeds and auto-download new videos in the background from your favorite creators across YouTube, TikTok, and more. Set up RSS subscriptions once, and VidBee will automatically download new uploads without manual intervention, perfect for keeping up with your favorite channels and creators.\n\n## üåê Supported Sites\n\nVidBee supports 1000+ video and audio platforms through yt-dlp. For the complete list of supported sites, visit [https://vidbee.org/supported-sites/](https://vidbee.org/supported-sites/)\n\n## ü§ù Contributing\n\nYou are welcome to join the open source community to build together. For more details, check out:\n\n- [Contributing Guide](./CONTRIBUTING.md)\n- [DeepWiki Documentation](https://deepwiki.com/nexmoe/VidBee)\n\n## üìÑ License\n\nThis project is distributed under the MIT License. See [`LICENSE`](LICENSE) for details.\n\n## üôè Thanks\n\n- [yt-dlp](https://github.com/yt-dlp/yt-dlp) - The powerful video downloader engine\n- [FFmpeg](https://ffmpeg.org/) - The multimedia framework for video and audio processing\n- [Electron](https://www.electronjs.org/) - Build cross-platform desktop apps\n- [React](https://react.dev/) - The UI library\n- [Vite](https://vitejs.dev/) - Next generation frontend tooling\n- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework\n- [shadcn/ui](https://ui.shadcn.com/) - Beautifully designed components\n",
      "stars_today": 267
    },
    {
      "id": 1076426995,
      "name": "dexter",
      "full_name": "virattt/dexter",
      "description": "An autonomous agent for deep financial research",
      "html_url": "https://github.com/virattt/dexter",
      "stars": 8437,
      "forks": 1048,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-10-14T21:02:00Z",
      "updated_at": "2026-01-23T02:11:48Z",
      "pushed_at": "2026-01-22T21:53:54Z",
      "open_issues": 30,
      "owner": {
        "login": "virattt",
        "avatar_url": "https://avatars.githubusercontent.com/u/901795?v=4"
      },
      "readme": "# Dexter ü§ñ\n\nDexter is an autonomous financial research agent that thinks, plans, and learns as it works. It performs analysis using task planning, self-reflection, and real-time market data. Think Claude Code, but built specifically for financial research.\n\n\n<img width=\"1098\" height=\"659\" alt=\"Screenshot 2026-01-21 at 5 25 10‚ÄØPM\" src=\"https://github.com/user-attachments/assets/3bcc3a7f-b68a-4f5e-8735-9d22196ff76e\" />\n\n\n## Overview\n\nDexter takes complex financial questions and turns them into clear, step-by-step research plans. It runs those tasks using live market data, checks its own work, and refines the results until it has a confident, data-backed answer.  \n\n**Key Capabilities:**\n- **Intelligent Task Planning**: Automatically decomposes complex queries into structured research steps\n- **Autonomous Execution**: Selects and executes the right tools to gather financial data\n- **Self-Validation**: Checks its own work and iterates until tasks are complete\n- **Real-Time Financial Data**: Access to income statements, balance sheets, and cash flow statements\n- **Safety Features**: Built-in loop detection and step limits to prevent runaway execution\n\n[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)\n\n<img width=\"875\" height=\"558\" alt=\"Screenshot 2026-01-21 at 5 22 19‚ÄØPM\" src=\"https://github.com/user-attachments/assets/72d28363-69ea-4c74-a297-dfa60aa347f7\" />\n\n\n### Prerequisites\n\n- [Bun](https://bun.com) runtime (v1.0 or higher)\n- OpenAI API key (get [here](https://platform.openai.com/api-keys))\n- Financial Datasets API key (get [here](https://financialdatasets.ai))\n- Tavily API key (get [here](https://tavily.com)) - optional, for web search\n\n#### Installing Bun\n\nIf you don't have Bun installed, you can install it using curl:\n\n**macOS/Linux:**\n```bash\ncurl -fsSL https://bun.com/install | bash\n```\n\n**Windows:**\n```bash\npowershell -c \"irm bun.sh/install.ps1|iex\"\n```\n\nAfter installation, restart your terminal and verify Bun is installed:\n```bash\nbun --version\n```\n\n### Installing Dexter\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/virattt/dexter.git\ncd dexter\n```\n\n2. Install dependencies with Bun:\n```bash\nbun install\n```\n\n3. Set up your environment variables:\n```bash\n# Copy the example environment file (from parent directory)\ncp env.example .env\n\n# Edit .env and add your API keys (if using cloud providers)\n# OPENAI_API_KEY=your-openai-api-key\n# ANTHROPIC_API_KEY=your-anthropic-api-key\n# GOOGLE_API_KEY=your-google-api-key\n# XAI_API_KEY=your-xai-api-key\n\n# (Optional) If using Ollama locally\n# OLLAMA_BASE_URL=http://127.0.0.1:11434\n\n# Other required keys\n# FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key\n# TAVILY_API_KEY=your-tavily-api-key\n```\n\n### Usage\n\nRun Dexter in interactive mode:\n```bash\nbun start\n```\n\nOr with watch mode for development:\n```bash\nbun dev\n```\n\n## How to Contribute\n\n1. Fork the repository\n2. Create a feature branch\n3. Commit your changes\n4. Push to the branch\n5. Create a Pull Request\n\n**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.\n\n\n## License\n\nThis project is licensed under the MIT License.\n\n",
      "stars_today": 248
    },
    {
      "id": 839037098,
      "name": "mastra",
      "full_name": "mastra-ai/mastra",
      "description": "From the team behind Gatsby, Mastra is a framework for building AI-powered applications and agents with a modern TypeScript stack.",
      "html_url": "https://github.com/mastra-ai/mastra",
      "stars": 20181,
      "forks": 1449,
      "language": "TypeScript",
      "topics": [
        "agents",
        "ai",
        "chatbots",
        "evals",
        "javascript",
        "llm",
        "mcp",
        "nextjs",
        "nodejs",
        "reactjs",
        "tts",
        "typescript",
        "workflows"
      ],
      "created_at": "2024-08-06T20:44:31Z",
      "updated_at": "2026-01-23T02:05:07Z",
      "pushed_at": "2026-01-23T01:19:36Z",
      "open_issues": 328,
      "owner": {
        "login": "mastra-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/149120496?v=4"
      },
      "readme": "# Mastra\n\n[![npm version](https://badge.fury.io/js/@mastra%2Fcore.svg)](https://www.npmjs.com/package/@mastra/core)\n[![CodeQl](https://github.com/mastra-ai/mastra/actions/workflows/github-code-scanning/codeql/badge.svg)](https://github.com/mastra-ai/mastra/actions/workflows/github-code-scanning/codeql)\n[![GitHub Repo stars](https://img.shields.io/github/stars/mastra-ai/mastra)](https://github.com/mastra-ai/mastra/stargazers)\n[![Discord](https://img.shields.io/discord/1309558646228779139?logo=discord&label=Discord&labelColor=white&color=7289DA)](https://discord.gg/BTYqqHKUrf)\n[![Twitter Follow](https://img.shields.io/twitter/follow/mastra_ai?style=social)](https://x.com/mastra_ai)\n[![NPM Downloads](https://img.shields.io/npm/dm/%40mastra%252Fcore)](https://www.npmjs.com/package/@mastra/core)\n[![Static Badge](https://img.shields.io/badge/Y%20Combinator-W25-orange)](https://www.ycombinator.com/companies?batch=W25)\n\nMastra is a framework for building AI-powered applications and agents with a modern TypeScript stack.\n\nIt includes everything you need to go from early prototypes to production-ready applications. Mastra integrates with frontend and backend frameworks like React, Next.js, and Node, or you can deploy it anywhere as a standalone server. It's the easiest way to build, tune, and scale reliable AI products.\n\n## Why Mastra?\n\nPurpose-built for TypeScript and designed around established AI patterns, Mastra gives you everything you need to build great AI applications out-of-the-box.\n\nSome highlights include:\n\n- [**Model routing**](https://mastra.ai/models) - Connect to 40+ providers through one standard interface. Use models from OpenAI, Anthropic, Gemini, and more.\n\n- [**Agents**](https://mastra.ai/docs/agents/overview) - Build autonomous agents that use LLMs and tools to solve open-ended tasks. Agents reason about goals, decide which tools to use, and iterate internally until the model emits a final answer or an optional stopping condition is met.\n\n- [**Workflows**](https://mastra.ai/docs/workflows/overview) - When you need explicit control over execution, use Mastra's graph-based workflow engine to orchestrate complex multi-step processes. Mastra workflows use an intuitive syntax for control flow (`.then()`, `.branch()`, `.parallel()`).\n\n- [**Human-in-the-loop**](https://mastra.ai/docs/workflows/suspend-and-resume) - Suspend an agent or workflow and await user input or approval before resuming. Mastra uses [storage](https://mastra.ai/docs/server-db/storage) to remember execution state, so you can pause indefinitely and resume where you left off.\n\n- **Context management** - Give your agents the right context at the right time. Provide [conversation history](https://mastra.ai/docs/memory/conversation-history), [retrieve](https://mastra.ai/docs/rag/overview) data from your sources (APIs, databases, files), and add human-like [working](https://mastra.ai/docs/memory/working-memory) and [semantic](https://mastra.ai/docs/memory/semantic-recall) memory so your agents behave coherently.\n\n- **Integrations** - Bundle agents and workflows into existing React, Next.js, or Node.js apps, or ship them as standalone endpoints. When building UIs, integrate with agentic libraries like Vercel's AI SDK UI and CopilotKit to bring your AI assistant to life on the web.\n\n- [**MCP servers**](https://mastra.ai/docs/tools-mcp/mcp-overview) - Author Model Context Protocol servers, exposing agents, tools, and other structured resources via the MCP interface. These can then be accessed by any system or agent that supports the protocol.\n\n- **Production essentials** - Shipping reliable agents takes ongoing insight, evaluation, and iteration. With built-in [evals](https://mastra.ai/docs/evals/overview) and [observability](https://mastra.ai/docs/observability/overview), Mastra gives you the tools to observe, measure, and refine continuously.\n\n## Get started\n\nThe **recommended** way to get started with Mastra is by running the command below:\n\n```shell\nnpm create mastra@latest\n```\n\nFollow the [Installation guide](https://mastra.ai/docs/getting-started/installation) for step-by-step setup with the CLI or a manual install.\n\nIf you're new to AI agents, check out our [templates](https://mastra.ai/docs/getting-started/templates), [course](https://mastra.ai/course), and [YouTube videos](https://youtube.com/@mastra-ai) to start building with Mastra today.\n\n## Documentation\n\nVisit our [official documentation](https://mastra.ai/docs).\n\n## MCP Servers\n\nLearn how to make your IDE a Mastra expert by following the [`@mastra/mcp-docs-server` guide](https://mastra.ai/docs/getting-started/mcp-docs-server).\n\n## Contributing\n\nLooking to contribute? All types of help are appreciated, from coding to testing and feature specification.\n\nIf you are a developer and would like to contribute with code, please open an issue to discuss before opening a Pull Request.\n\nInformation about the project setup can be found in the [development documentation](./DEVELOPMENT.md)\n\n## Support\n\nWe have an [open community Discord](https://discord.gg/BTYqqHKUrf). Come and say hello and let us know if you have any questions or need any help getting things running.\n\nIt's also super helpful if you leave the project a star here at the [top of the page](https://github.com/mastra-ai/mastra)\n\n## Security\n\nWe are committed to maintaining the security of this repo and of Mastra as a whole. If you discover a security finding\nwe ask you to please responsibly disclose this to us at [security@mastra.ai](mailto:security@mastra.ai) and we will get\nback to you.\n",
      "stars_today": 227
    },
    {
      "id": 600886023,
      "name": "ratatui",
      "full_name": "ratatui/ratatui",
      "description": "A Rust crate for cooking up terminal user interfaces (TUIs) üë®‚Äçüç≥üêÄ https://ratatui.rs",
      "html_url": "https://github.com/ratatui/ratatui",
      "stars": 17670,
      "forks": 558,
      "language": "Rust",
      "topics": [
        "cli",
        "ratatui",
        "rust",
        "terminal",
        "terminal-user-interface",
        "tui",
        "widgets"
      ],
      "created_at": "2023-02-12T21:56:20Z",
      "updated_at": "2026-01-23T02:09:12Z",
      "pushed_at": "2026-01-20T03:39:16Z",
      "open_issues": 194,
      "owner": {
        "login": "ratatui",
        "avatar_url": "https://avatars.githubusercontent.com/u/125200832?v=4"
      },
      "readme": "<details>\n<summary>Table of Contents</summary>\n\n- [Quickstart](#quickstart)\n- [Documentation](#documentation)\n- [Templates](#templates)\n- [Built with Ratatui](#built-with-ratatui)\n- [Alternatives](#alternatives)\n- [Contributing](#contributing)\n- [Acknowledgements](#acknowledgements)\n- [License](#license)\n\n</details>\n\n![Release header](https://github.com/ratatui/ratatui/blob/b23480adfa9430697071c906c7ba4d4f9bd37a73/assets/release-header.png?raw=true)\n\n<div align=\"center\">\n\n[![Crate Badge]][Crate] [![Repo Badge]][Repo] [![Docs Badge]][Docs] [![License Badge]][License]  \\\n[![CI Badge]][CI] [![Deps Badge]][Deps] [![Codecov Badge]][Codecov] [![Sponsors Badge]][Sponsors]  \\\n[Ratatui Website] ¬∑ [Docs] ¬∑ [Widget Examples] ¬∑ [App Examples] ¬∑ [Changelog]  \\\n[Breaking Changes] ¬∑ [Contributing] ¬∑ [Report a bug] ¬∑ [Request a Feature]\n\n</div>\n\n[Ratatui][Ratatui Website] (_Àår√¶.t…ôÀàtu.i_) is a Rust crate for cooking up terminal user interfaces\n(TUIs). It provides a simple and flexible way to create text-based user interfaces in the terminal,\nwhich can be used for command-line applications, dashboards, and other interactive console programs.\n\n## Quickstart\n\nRatatui has [templates] available to help you get started quickly. You can use the\n[`cargo-generate`] command to create a new project with Ratatui:\n\n```shell\ncargo install --locked cargo-generate\ncargo generate ratatui/templates\n```\n\nSelecting the Hello World template produces the following application:\n\n```rust\nuse color_eyre::Result;\nuse crossterm::event::{self, Event};\nuse ratatui::{DefaultTerminal, Frame};\n\nfn main() -> Result<()> {\n    color_eyre::install()?;\n    let terminal = ratatui::init();\n    let result = run(terminal);\n    ratatui::restore();\n    result\n}\n\nfn run(mut terminal: DefaultTerminal) -> Result<()> {\n    loop {\n        terminal.draw(render)?;\n        if matches!(event::read()?, Event::Key(_)) {\n            break Ok(());\n        }\n    }\n}\n\nfn render(frame: &mut Frame) {\n    frame.render_widget(\"hello world\", frame.area());\n}\n```\n\n## Documentation\n\n- [Docs] - the full API documentation for the library on docs.rs.\n- [Ratatui Website] - explains the library's concepts and provides step-by-step tutorials.\n- [Ratatui Forum] - a place to ask questions and discuss the library.\n- [Widget Examples] - a collection of examples that demonstrate how to use the library.\n- [App Examples] - a collection of more complex examples that demonstrate how to build apps.\n- [ARCHITECTURE.md] - explains the crate organization and modular workspace structure.\n- [Changelog] - generated by [git-cliff] utilizing [Conventional Commits].\n- [Breaking Changes] - a list of breaking changes in the library.\n\nYou can also watch the [EuroRust 2024 talk] to learn about common concepts in Ratatui and what's\npossible to build with it.\n\n## Templates\n\nIf you're looking to get started quickly, you can use one of the available templates from the\n[templates] repository using [`cargo-generate`]:\n\n```shell\ncargo generate ratatui/templates\n```\n\n## Built with Ratatui\n\n[![Awesome](https://awesome.re/badge-flat2.svg)][awesome-ratatui]\n\nCheck out the [showcase] section of the website, or the [awesome-ratatui] repository for a curated\nlist of awesome apps and libraries built with Ratatui!\n\n## Alternatives\n\n- [Cursive](https://crates.io/crates/cursive) - a ncurses-based TUI library.\n- [iocraft](https://crates.io/crates/iocraft) - a declarative TUI library.\n\n## Contributing\n\n[![Discord Badge]][Discord Server] [![Matrix Badge]][Matrix] [![Forum Badge]][Ratatui Forum]\n\nFeel free to join our [Discord server](https://discord.gg/pMCEU9hNEj) for discussions and questions!\nThere is also a [Matrix](https://matrix.org/) bridge available at\n[#ratatui:matrix.org](https://matrix.to/#/#ratatui:matrix.org). We have also recently launched the\n[Ratatui Forum].\n\nWe rely on GitHub for [bugs][Report a bug] and [feature requests][Request a Feature].\n\nPlease make sure you read the [contributing](./CONTRIBUTING.md) guidelines before [creating a pull\nrequest][Create a Pull Request]. We accept AI generated code, but please read the [AI Contributions]\nguidelines to ensure compliance.\n\nIf you'd like to show your support, you can add the Ratatui badge to your project's README:\n\n```md\n[![Built With Ratatui](https://img.shields.io/badge/Built_With_Ratatui-000?logo=ratatui&logoColor=fff)](https://ratatui.rs/)\n```\n\n[![Built With Ratatui](https://img.shields.io/badge/Built_With_Ratatui-000?logo=ratatui&logoColor=fff)](https://ratatui.rs/)\n\n## Acknowledgements\n\nRatatui was forked from the [tui-rs] crate in 2023 in order to continue its development. None of\nthis could be possible without [Florian Dehau] who originally created [tui-rs] which inspired many\nRust TUIs.\n\nSpecial thanks to [Pavel Fomchenkov] for his work in designing an awesome logo for the Ratatui\nproject and organization.\n\n## License\n\nThis project is licensed under the [MIT License][License].\n\n[Repo]: https://github.com/ratatui/ratatui\n[Ratatui Website]: https://ratatui.rs/\n[Ratatui Forum]: https://forum.ratatui.rs\n[Docs]: https://docs.rs/ratatui\n[Widget Examples]: https://github.com/ratatui/ratatui/tree/main/ratatui-widgets/examples\n[App Examples]: https://github.com/ratatui/ratatui/tree/main/examples\n[ARCHITECTURE.md]: https://github.com/ratatui/ratatui/blob/main/ARCHITECTURE.md\n[Changelog]: https://github.com/ratatui/ratatui/blob/main/CHANGELOG.md\n[git-cliff]: https://git-cliff.org\n[Conventional Commits]: https://www.conventionalcommits.org\n[Breaking Changes]: https://github.com/ratatui/ratatui/blob/main/BREAKING-CHANGES.md\n[EuroRust 2024 talk]: https://www.youtube.com/watch?v=hWG51Mc1DlM\n[Report a bug]: https://github.com/ratatui/ratatui/issues/new?labels=bug&projects=&template=bug_report.md\n[Request a Feature]: https://github.com/ratatui/ratatui/issues/new?labels=enhancement&projects=&template=feature_request.md\n[Create a Pull Request]: https://github.com/ratatui/ratatui/compare\n[Contributing]: https://github.com/ratatui/ratatui/blob/main/CONTRIBUTING.md\n[AI Contributions]: https://github.com/ratatui/ratatui/blob/main/CONTRIBUTING.md#ai-generated-content\n[Crate]: https://crates.io/crates/ratatui\n[tui-rs]: https://crates.io/crates/tui\n[Sponsors]: https://github.com/sponsors/ratatui\n[Crate Badge]: https://img.shields.io/crates/v/ratatui?logo=rust&style=flat-square&color=E05D44\n[Repo Badge]: https://img.shields.io/badge/repo-ratatui/ratatui-1370D3?style=flat-square&logo=github\n[License Badge]: https://img.shields.io/crates/l/ratatui?style=flat-square&color=1370D3\n[CI Badge]: https://img.shields.io/github/actions/workflow/status/ratatui/ratatui/ci.yml?style=flat-square&logo=github\n[CI]: https://github.com/ratatui/ratatui/actions/workflows/ci.yml\n[Codecov Badge]: https://img.shields.io/codecov/c/github/ratatui/ratatui?logo=codecov&style=flat-square&token=BAQ8SOKEST&color=C43AC3\n[Codecov]: https://app.codecov.io/gh/ratatui/ratatui\n[Deps Badge]: https://deps.rs/repo/github/ratatui/ratatui/status.svg?path=ratatui&style=flat-square\n[Deps]: https://deps.rs/repo/github/ratatui/ratatui?path=ratatui\n[Discord Badge]: https://img.shields.io/discord/1070692720437383208?label=discord&logo=discord&style=flat-square&color=1370D3&logoColor=1370D3\n[Discord Server]: https://discord.gg/pMCEU9hNEj\n[Docs Badge]: https://img.shields.io/badge/docs-ratatui-1370D3?style=flat-square&logo=rust\n[Matrix Badge]: https://img.shields.io/matrix/ratatui-general%3Amatrix.org?style=flat-square&logo=matrix&label=Matrix&color=C43AC3\n[Matrix]: https://matrix.to/#/#ratatui:matrix.org\n[Forum Badge]: https://img.shields.io/discourse/likes?server=https%3A%2F%2Fforum.ratatui.rs&style=flat-square&logo=discourse&label=forum&color=C43AC3\n[Sponsors Badge]: https://img.shields.io/github/sponsors/ratatui?logo=github&style=flat-square&color=1370D3\n[templates]: https://github.com/ratatui/templates/\n[showcase]: https://ratatui.rs/showcase/\n[awesome-ratatui]: https://github.com/ratatui/awesome-ratatui\n[Pavel Fomchenkov]: https://github.com/nawok\n[Florian Dehau]: https://github.com/fdehau\n[`cargo-generate`]: https://crates.io/crates/cargo-generate\n[License]: ./LICENSE\n",
      "stars_today": 163
    },
    {
      "id": 1000362065,
      "name": "awesome-copilot",
      "full_name": "github/awesome-copilot",
      "description": "Community-contributed instructions, prompts, and configurations to help you make the most of GitHub Copilot.",
      "html_url": "https://github.com/github/awesome-copilot",
      "stars": 18562,
      "forks": 2123,
      "language": "JavaScript",
      "topics": [
        "ai",
        "github-copilot",
        "hacktoberfest",
        "prompt-engineering"
      ],
      "created_at": "2025-06-11T16:57:39Z",
      "updated_at": "2026-01-23T01:55:57Z",
      "pushed_at": "2026-01-23T00:07:45Z",
      "open_issues": 10,
      "owner": {
        "login": "github",
        "avatar_url": "https://avatars.githubusercontent.com/u/9919?v=4"
      },
      "readme": "# ü§ñ Awesome GitHub Copilot Customizations\n[![Powered by Awesome Copilot](https://img.shields.io/badge/Powered_by-Awesome_Copilot-blue?logo=githubcopilot)](https://aka.ms/awesome-github-copilot) [![GitHub contributors from allcontributors.org](https://img.shields.io/github/all-contributors/github/awesome-copilot?color=ee8449)](#contributors-)\n\n\nA community created collection of custom agents, prompts, and instructions to supercharge your GitHub Copilot experience across different domains, languages, and use cases.\n\n## üöÄ What is Awesome GitHub Copilot?\n\nThis repository provides a comprehensive toolkit for enhancing GitHub Copilot with specialized:\n\n- **üëâ [Awesome Agents](docs/README.agents.md)** - Specialized GitHub Copilot agents that integrate with MCP servers to provide enhanced capabilities for specific workflows and tools\n- **üëâ [Awesome Prompts](docs/README.prompts.md)** - Focused, task-specific prompts for generating code, documentation, and solving specific problems\n- **üëâ [Awesome Instructions](docs/README.instructions.md)** - Comprehensive coding standards and best practices that apply to specific file patterns or entire projects\n- **üëâ [Awesome Skills](docs/README.skills.md)** - Self-contained folders with instructions and bundled resources that enhance AI capabilities for specialized tasks\n- **üëâ [Awesome Collections](docs/README.collections.md)** - Curated collections of related prompts, instructions, agents, and skills organized around specific themes and workflows\n\n## üåü Featured Collections\n\nDiscover our curated collections of prompts, instructions, and agents organized around specific themes and workflows.\n\n| Name | Description | Items | Tags |\n| ---- | ----------- | ----- | ---- |\n| [Awesome Copilot](collections/awesome-copilot.md) | Meta prompts that help you discover and generate curated GitHub Copilot agents, collections, instructions, prompts, and skills. | 5 items | github-copilot, discovery, meta, prompt-engineering, agents |\n| [Copilot SDK](collections/copilot-sdk.md) | Build applications with the GitHub Copilot SDK across multiple programming languages. Includes comprehensive instructions for C#, Go, Node.js/TypeScript, and Python to help you create AI-powered applications. | 4 items | copilot-sdk, sdk, csharp, go, nodejs, typescript, python, ai, github-copilot |\n| [Partners](collections/partners.md) | Custom agents that have been created by GitHub partners | 20 items | devops, security, database, cloud, infrastructure, observability, feature-flags, cicd, migration, performance |\n\n\n## MCP Server\n\nTo make it easy to add these customizations to your editor, we have created a [MCP Server](https://developer.microsoft.com/blog/announcing-awesome-copilot-mcp-server) that provides a prompt for searching and installing prompts, instructions, agents, and skills directly from this repository. You'll need to have Docker installed and running to run the server.\n\n[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install-0098FF?logo=visualstudiocode&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vscode) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install-24bfa5?logo=visualstudiocode&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vscode-insiders) [![Install in Visual Studio](https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vs)\n\n<details>\n<summary>Show MCP Server JSON configuration</summary>\n\n```json\n{\n  \"servers\": {\n    \"awesome-copilot\": {\n      \"type\": \"stdio\",\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"ghcr.io/microsoft/mcp-dotnet-samples/awesome-copilot:latest\"\n      ]\n    }\n  }\n}\n```\n\n</details>\n\n## üîß How to Use\n\n### ü§ñ Custom Agents\n\nCustom agents can be used in Copilot coding agent (CCA), VS Code, and Copilot CLI (coming soon). For CCA, when assigning an issue to Copilot, select the custom agent from the provided list. In VS Code, you can activate the custom agent in the agents session, alongside built-in agents like Plan and Agent.\n\n### üéØ Prompts\n\nUse the `/` command in GitHub Copilot Chat to access prompts:\n\n```plaintext\n/awesome-copilot create-readme\n```\n\n### üìã Instructions\n\nInstructions automatically apply to files based on their patterns and provide contextual guidance for coding standards, frameworks, and best practices.\n\n## üéØ Why Use Awesome GitHub Copilot?\n\n- **Productivity**: Pre-built agents, prompts and instructions save time and provide consistent results.\n- **Best Practices**: Benefit from community-curated coding standards and patterns.\n- **Specialized Assistance**: Access expert-level guidance through specialized custom agents.\n- **Continuous Learning**: Stay updated with the latest patterns and practices across technologies.\n\n## ü§ù Contributing\n\nWe welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details on how to:\n\n- Add new prompts, instructions, agents, or skills\n- Improve existing content\n- Report issues or suggest enhancements\n\nFor AI coding agents working with this project, refer to [AGENTS.md](AGENTS.md) for detailed technical guidance on development workflows, setup commands, and contribution standards.\n\n### Quick Contribution Guide\n\n1. Follow our file naming conventions and frontmatter requirements\n2. Test your contributions thoroughly\n3. Update the appropriate README tables\n4. Submit a pull request with a clear description\n\n## üìñ Repository Structure\n\n```plaintext\n‚îú‚îÄ‚îÄ prompts/          # Task-specific prompts (.prompt.md)\n‚îú‚îÄ‚îÄ instructions/     # Coding standards and best practices (.instructions.md)\n‚îú‚îÄ‚îÄ agents/           # AI personas and specialized modes (.agent.md)\n‚îú‚îÄ‚îÄ collections/      # Curated collections of related items (.collection.yml)\n‚îú‚îÄ‚îÄ scripts/          # Utility scripts for maintenance\n‚îî‚îÄ‚îÄ skills/           # AI capabilities for specialized tasks\n```\n\n## üìÑ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## üõ°Ô∏è Security & Support\n\n- **Security Issues**: Please see our [Security Policy](SECURITY.md)\n- **Support**: Check our [Support Guide](SUPPORT.md) for getting help\n- **Code of Conduct**: We follow the [Contributor Covenant](CODE_OF_CONDUCT.md)\n\n## ‚ÑπÔ∏è Disclaimer\n\nThe customizations in this repository are sourced from and created by third-party developers. GitHub does not verify, endorse, or guarantee the functionality or security of these agents. Please carefully inspect any agent and its documentation before installing to understand permissions it may require and actions it may perform.\n\n---\n\n**Ready to supercharge your coding experience?** Start exploring our [prompts](docs/README.prompts.md), [instructions](docs/README.instructions.md), and [custom agents](docs/README.agents.md)!\n\n## Contributors ‚ú®\n\nThanks goes to these wonderful people ([emoji key](./CONTRIBUTING.md#contributors-recognition)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.aaron-powell.com/\"><img src=\"https://avatars.githubusercontent.com/u/434140?v=4?s=100\" width=\"100px;\" alt=\"Aaron Powell\"/><br /><sub><b>Aaron Powell</b></sub></a><br /><a href=\"#agents-aaronpowell\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=aaronpowell\" title=\"Code\">üíª</a> <a href=\"#collections-aaronpowell\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=aaronpowell\" title=\"Documentation\">üìñ</a> <a href=\"#infra-aaronpowell\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a> <a href=\"#instructions-aaronpowell\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#maintenance-aaronpowell\" title=\"Maintenance\">üöß</a> <a href=\"#prompts-aaronpowell\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://codemilltech.com/\"><img src=\"https://avatars.githubusercontent.com/u/2053639?v=4?s=100\" width=\"100px;\" alt=\"Matt Soucoup\"/><br /><sub><b>Matt Soucoup</b></sub></a><br /><a href=\"#infra-codemillmatt\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.buymeacoffee.com/troystaylor\"><img src=\"https://avatars.githubusercontent.com/u/44444967?v=4?s=100\" width=\"100px;\" alt=\"Troy Simeon Taylor\"/><br /><sub><b>Troy Simeon Taylor</b></sub></a><br /><a href=\"#agents-troystaylor\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-troystaylor\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#instructions-troystaylor\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-troystaylor\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/abbas133\"><img src=\"https://avatars.githubusercontent.com/u/7757139?v=4?s=100\" width=\"100px;\" alt=\"Abbas\"/><br /><sub><b>Abbas</b></sub></a><br /><a href=\"#agents-abbas133\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-abbas133\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://calva.io/\"><img src=\"https://avatars.githubusercontent.com/u/30010?v=4?s=100\" width=\"100px;\" alt=\"Peter Str√∂mberg\"/><br /><sub><b>Peter Str√∂mberg</b></sub></a><br /><a href=\"#agents-PEZ\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-PEZ\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#instructions-PEZ\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-PEZ\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://danielscottraynsford.com/\"><img src=\"https://avatars.githubusercontent.com/u/7589164?v=4?s=100\" width=\"100px;\" alt=\"Daniel Scott-Raynsford\"/><br /><sub><b>Daniel Scott-Raynsford</b></sub></a><br /><a href=\"#agents-PlagueHO\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-PlagueHO\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#instructions-PlagueHO\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-PlagueHO\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jhauga\"><img src=\"https://avatars.githubusercontent.com/u/10998676?v=4?s=100\" width=\"100px;\" alt=\"John Haugabook\"/><br /><sub><b>John Haugabook</b></sub></a><br /><a href=\"#instructions-jhauga\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-jhauga\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://witter.cz/@pavel\"><img src=\"https://avatars.githubusercontent.com/u/7853836?v=4?s=100\" width=\"100px;\" alt=\"Pavel Simsa\"/><br /><sub><b>Pavel Simsa</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=psimsa\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://digitarald.de/\"><img src=\"https://avatars.githubusercontent.com/u/8599?v=4?s=100\" width=\"100px;\" alt=\"Harald Kirschner\"/><br /><sub><b>Harald Kirschner</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=digitarald\" title=\"Code\">üíª</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=digitarald\" title=\"Documentation\">üìñ</a> <a href=\"#maintenance-digitarald\" title=\"Maintenance\">üöß</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mubaidr.js.org/\"><img src=\"https://avatars.githubusercontent.com/u/2222702?v=4?s=100\" width=\"100px;\" alt=\"Muhammad Ubaid Raza\"/><br /><sub><b>Muhammad Ubaid Raza</b></sub></a><br /><a href=\"#agents-mubaidr\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-mubaidr\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tmeschter\"><img src=\"https://avatars.githubusercontent.com/u/10506730?v=4?s=100\" width=\"100px;\" alt=\"Tom Meschter\"/><br /><sub><b>Tom Meschter</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=tmeschter\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.aungmyokyaw.com/\"><img src=\"https://avatars.githubusercontent.com/u/9404824?v=4?s=100\" width=\"100px;\" alt=\"Aung Myo Kyaw\"/><br /><sub><b>Aung Myo Kyaw</b></sub></a><br /><a href=\"#agents-AungMyoKyaw\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-AungMyoKyaw\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/JasonYeMSFT\"><img src=\"https://avatars.githubusercontent.com/u/39359541?v=4?s=100\" width=\"100px;\" alt=\"JasonYeMSFT\"/><br /><sub><b>JasonYeMSFT</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=JasonYeMSFT\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/jrc356/\"><img src=\"https://avatars.githubusercontent.com/u/37387479?v=4?s=100\" width=\"100px;\" alt=\"Jon Corbin\"/><br /><sub><b>Jon Corbin</b></sub></a><br /><a href=\"#agents-Jrc356\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-Jrc356\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/troytaylor-msft\"><img src=\"https://avatars.githubusercontent.com/u/248058374?v=4?s=100\" width=\"100px;\" alt=\"troytaylor-msft\"/><br /><sub><b>troytaylor-msft</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=troytaylor-msft\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://delatorre.dev/\"><img src=\"https://avatars.githubusercontent.com/u/38289677?v=4?s=100\" width=\"100px;\" alt=\"Emerson Delatorre\"/><br /><sub><b>Emerson Delatorre</b></sub></a><br /><a href=\"#instructions-fazedordecodigo\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/burkeholland\"><img src=\"https://avatars.githubusercontent.com/u/686963?v=4?s=100\" width=\"100px;\" alt=\"Burke Holland\"/><br /><sub><b>Burke Holland</b></sub></a><br /><a href=\"#agents-burkeholland\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#infra-burkeholland\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a> <a href=\"#instructions-burkeholland\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-burkeholland\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://yaooqinn.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/8326978?v=4?s=100\" width=\"100px;\" alt=\"Kent Yao\"/><br /><sub><b>Kent Yao</b></sub></a><br /><a href=\"#instructions-yaooqinn\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-yaooqinn\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.devprodlogs.com/\"><img src=\"https://avatars.githubusercontent.com/u/51440732?v=4?s=100\" width=\"100px;\" alt=\"Daniel Meppiel\"/><br /><sub><b>Daniel Meppiel</b></sub></a><br /><a href=\"#prompts-danielmeppiel\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yeelam-gordon\"><img src=\"https://avatars.githubusercontent.com/u/73506701?v=4?s=100\" width=\"100px;\" alt=\"Gordon Lam\"/><br /><sub><b>Gordon Lam</b></sub></a><br /><a href=\"#instructions-yeelam-gordon\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.madskristensen.net/\"><img src=\"https://avatars.githubusercontent.com/u/1258877?v=4?s=100\" width=\"100px;\" alt=\"Mads Kristensen\"/><br /><sub><b>Mads Kristensen</b></sub></a><br /><a href=\"#instructions-madskristensen\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://ks6088ts.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/1254960?v=4?s=100\" width=\"100px;\" alt=\"Shinji Takenaka\"/><br /><sub><b>Shinji Takenaka</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=ks6088ts\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/spectatora\"><img src=\"https://avatars.githubusercontent.com/u/1385755?v=4?s=100\" width=\"100px;\" alt=\"spectatora\"/><br /><sub><b>spectatora</b></sub></a><br /><a href=\"#agents-spectatora\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=spectatora\" title=\"Code\">üíª</a> <a href=\"#maintenance-spectatora\" title=\"Maintenance\">üöß</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sinedied\"><img src=\"https://avatars.githubusercontent.com/u/593151?v=4?s=100\" width=\"100px;\" alt=\"Yohan Lasorsa\"/><br /><sub><b>Yohan Lasorsa</b></sub></a><br /><a href=\"#instructions-sinedied\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-sinedied\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/VamshiVerma\"><img src=\"https://avatars.githubusercontent.com/u/21999324?v=4?s=100\" width=\"100px;\" alt=\"Vamshi Verma\"/><br /><sub><b>Vamshi Verma</b></sub></a><br /><a href=\"#instructions-VamshiVerma\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-VamshiVerma\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://montemagno.com/\"><img src=\"https://avatars.githubusercontent.com/u/1676321?v=4?s=100\" width=\"100px;\" alt=\"James Montemagno\"/><br /><sub><b>James Montemagno</b></sub></a><br /><a href=\"#agents-jamesmontemagno\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=jamesmontemagno\" title=\"Documentation\">üìñ</a> <a href=\"#instructions-jamesmontemagno\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-jamesmontemagno\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/alefragnani\"><img src=\"https://avatars.githubusercontent.com/u/3781424?v=4?s=100\" width=\"100px;\" alt=\"Alessandro Fragnani\"/><br /><sub><b>Alessandro Fragnani</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=alefragnani\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/ambilykk/\"><img src=\"https://avatars.githubusercontent.com/u/10282550?v=4?s=100\" width=\"100px;\" alt=\"Ambily\"/><br /><sub><b>Ambily</b></sub></a><br /><a href=\"#agents-ambilykk\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-ambilykk\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/krushideep\"><img src=\"https://avatars.githubusercontent.com/u/174652083?v=4?s=100\" width=\"100px;\" alt=\"krushideep\"/><br /><sub><b>krushideep</b></sub></a><br /><a href=\"#prompts-krushideep\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mihsoft\"><img src=\"https://avatars.githubusercontent.com/u/53946345?v=4?s=100\" width=\"100px;\" alt=\"devopsfan\"/><br /><sub><b>devopsfan</b></sub></a><br /><a href=\"#agents-mihsoft\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://tgrall.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/541250?v=4?s=100\" width=\"100px;\" alt=\"Tugdual Grall\"/><br /><sub><b>Tugdual Grall</b></sub></a><br /><a href=\"#instructions-tgrall\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-tgrall\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.promptboost.dev/\"><img src=\"https://avatars.githubusercontent.com/u/5461862?v=4?s=100\" width=\"100px;\" alt=\"Oren Me\"/><br /><sub><b>Oren Me</b></sub></a><br /><a href=\"#agents-OrenMe\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-OrenMe\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mjrousos\"><img src=\"https://avatars.githubusercontent.com/u/10077254?v=4?s=100\" width=\"100px;\" alt=\"Mike Rousos\"/><br /><sub><b>Mike Rousos</b></sub></a><br /><a href=\"#instructions-mjrousos\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-mjrousos\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://devkimchi.com/\"><img src=\"https://avatars.githubusercontent.com/u/1538528?v=4?s=100\" width=\"100px;\" alt=\"Justin Yoo\"/><br /><sub><b>Justin Yoo</b></sub></a><br /><a href=\"#instructions-justinyoo\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/guiopen\"><img src=\"https://avatars.githubusercontent.com/u/94094527?v=4?s=100\" width=\"100px;\" alt=\"Guilherme do Amaral Alves \"/><br /><sub><b>Guilherme do Amaral Alves </b></sub></a><br /><a href=\"#instructions-guiopen\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/griffinashe/\"><img src=\"https://avatars.githubusercontent.com/u/6391612?v=4?s=100\" width=\"100px;\" alt=\"Griffin Ashe\"/><br /><sub><b>Griffin Ashe</b></sub></a><br /><a href=\"#agents-griffinashe\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-griffinashe\" title=\"Curated collections of related content\">üéÅ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anchildress1\"><img src=\"https://avatars.githubusercontent.com/u/6563688?v=4?s=100\" width=\"100px;\" alt=\"Ashley Childress\"/><br /><sub><b>Ashley Childress</b></sub></a><br /><a href=\"#agents-anchildress1\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=anchildress1\" title=\"Documentation\">üìñ</a> <a href=\"#instructions-anchildress1\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#infra-anchildress1\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=anchildress1\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.senseof.tech/\"><img src=\"https://avatars.githubusercontent.com/u/50712277?v=4?s=100\" width=\"100px;\" alt=\"Adrien Clerbois\"/><br /><sub><b>Adrien Clerbois</b></sub></a><br /><a href=\"#agents-AClerbois\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=AClerbois\" title=\"Documentation\">üìñ</a> <a href=\"#prompts-AClerbois\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Vhivi\"><img src=\"https://avatars.githubusercontent.com/u/38220028?v=4?s=100\" width=\"100px;\" alt=\"ANGELELLI David\"/><br /><sub><b>ANGELELLI David</b></sub></a><br /><a href=\"#agents-Vhivi\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://markdav.is/\"><img src=\"https://avatars.githubusercontent.com/u/311063?v=4?s=100\" width=\"100px;\" alt=\"Mark Davis\"/><br /><sub><b>Mark Davis</b></sub></a><br /><a href=\"#instructions-markdav-is\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MattVevang\"><img src=\"https://avatars.githubusercontent.com/u/20714898?v=4?s=100\" width=\"100px;\" alt=\"Matt Vevang\"/><br /><sub><b>Matt Vevang</b></sub></a><br /><a href=\"#instructions-MattVevang\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://max.irro.at/\"><img src=\"https://avatars.githubusercontent.com/u/589073?v=4?s=100\" width=\"100px;\" alt=\"Maximilian Irro\"/><br /><sub><b>Maximilian Irro</b></sub></a><br /><a href=\"#instructions-mpgirro\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nullchimp\"><img src=\"https://avatars.githubusercontent.com/u/58362593?v=4?s=100\" width=\"100px;\" alt=\"NULLchimp\"/><br /><sub><b>NULLchimp</b></sub></a><br /><a href=\"#agents-nullchimp\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pkarda\"><img src=\"https://avatars.githubusercontent.com/u/12649718?v=4?s=100\" width=\"100px;\" alt=\"Peter Karda\"/><br /><sub><b>Peter Karda</b></sub></a><br /><a href=\"#prompts-pkarda\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sdolgin\"><img src=\"https://avatars.githubusercontent.com/u/576449?v=4?s=100\" width=\"100px;\" alt=\"Saul Dolgin\"/><br /><sub><b>Saul Dolgin</b></sub></a><br /><a href=\"#agents-sdolgin\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-sdolgin\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-sdolgin\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shubham070\"><img src=\"https://avatars.githubusercontent.com/u/5480589?v=4?s=100\" width=\"100px;\" alt=\"Shubham Gaikwad\"/><br /><sub><b>Shubham Gaikwad</b></sub></a><br /><a href=\"#agents-shubham070\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-shubham070\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-shubham070\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TheovanKraay\"><img src=\"https://avatars.githubusercontent.com/u/24420698?v=4?s=100\" width=\"100px;\" alt=\"Theo van Kraay\"/><br /><sub><b>Theo van Kraay</b></sub></a><br /><a href=\"#instructions-TheovanKraay\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TianqiZhang\"><img src=\"https://avatars.githubusercontent.com/u/5326582?v=4?s=100\" width=\"100px;\" alt=\"Tianqi Zhang\"/><br /><sub><b>Tianqi Zhang</b></sub></a><br /><a href=\"#agents-TianqiZhang\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.miniasp.com/\"><img src=\"https://avatars.githubusercontent.com/u/88981?v=4?s=100\" width=\"100px;\" alt=\"Will ‰øùÂì•\"/><br /><sub><b>Will ‰øùÂì•</b></sub></a><br /><a href=\"#agents-doggy8088\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-doggy8088\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tsubalog.hatenablog.com/\"><img src=\"https://avatars.githubusercontent.com/u/1592808?v=4?s=100\" width=\"100px;\" alt=\"Yuta Matsumura\"/><br /><sub><b>Yuta Matsumura</b></sub></a><br /><a href=\"#instructions-tsubakimoto\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anschnapp\"><img src=\"https://avatars.githubusercontent.com/u/17565996?v=4?s=100\" width=\"100px;\" alt=\"anschnapp\"/><br /><sub><b>anschnapp</b></sub></a><br /><a href=\"#agents-anschnapp\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hizahizi-hizumi\"><img src=\"https://avatars.githubusercontent.com/u/163728895?v=4?s=100\" width=\"100px;\" alt=\"hizahizi-hizumi\"/><br /><sub><b>hizahizi-hizumi</b></sub></a><br /><a href=\"#instructions-hizahizi-hizumi\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jianminhuang.cc/\"><img src=\"https://avatars.githubusercontent.com/u/6296280?v=4?s=100\" width=\"100px;\" alt=\"ÈªÉÂÅ•Êóª Vincent Huang\"/><br /><sub><b>ÈªÉÂÅ•Êóª Vincent Huang</b></sub></a><br /><a href=\"#prompts-Jian-Min-Huang\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://brunoborges.io/\"><img src=\"https://avatars.githubusercontent.com/u/129743?v=4?s=100\" width=\"100px;\" alt=\"Bruno Borges\"/><br /><sub><b>Bruno Borges</b></sub></a><br /><a href=\"#collections-brunoborges\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#instructions-brunoborges\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.movinglive.ca/\"><img src=\"https://avatars.githubusercontent.com/u/14792628?v=4?s=100\" width=\"100px;\" alt=\"Steve Magne\"/><br /><sub><b>Steve Magne</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=MovingLive\" title=\"Documentation\">üìñ</a> <a href=\"#instructions-MovingLive\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://shaneneuville.com/\"><img src=\"https://avatars.githubusercontent.com/u/5375137?v=4?s=100\" width=\"100px;\" alt=\"Shane Neuville\"/><br /><sub><b>Shane Neuville</b></sub></a><br /><a href=\"#agents-PureWeen\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-PureWeen\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://asilva.dev/\"><img src=\"https://avatars.githubusercontent.com/u/2493377?v=4?s=100\" width=\"100px;\" alt=\"Andr√© Silva\"/><br /><sub><b>Andr√© Silva</b></sub></a><br /><a href=\"#agents-askpt\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-askpt\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/agreaves-ms\"><img src=\"https://avatars.githubusercontent.com/u/111466195?v=4?s=100\" width=\"100px;\" alt=\"Allen Greaves\"/><br /><sub><b>Allen Greaves</b></sub></a><br /><a href=\"#agents-agreaves-ms\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-agreaves-ms\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AmeliaRose802\"><img src=\"https://avatars.githubusercontent.com/u/26167931?v=4?s=100\" width=\"100px;\" alt=\"Amelia Payne\"/><br /><sub><b>Amelia Payne</b></sub></a><br /><a href=\"#agents-AmeliaRose802\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/BBoyBen\"><img src=\"https://avatars.githubusercontent.com/u/34445365?v=4?s=100\" width=\"100px;\" alt=\"BBoyBen\"/><br /><sub><b>BBoyBen</b></sub></a><br /><a href=\"#instructions-BBoyBen\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://azureincubations.io/\"><img src=\"https://avatars.githubusercontent.com/u/45323234?v=4?s=100\" width=\"100px;\" alt=\"Brooke Hamilton\"/><br /><sub><b>Brooke Hamilton</b></sub></a><br /><a href=\"#instructions-brooke-hamilton\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/GeekTrainer\"><img src=\"https://avatars.githubusercontent.com/u/6109729?v=4?s=100\" width=\"100px;\" alt=\"Christopher Harrison\"/><br /><sub><b>Christopher Harrison</b></sub></a><br /><a href=\"#instructions-GeekTrainer\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/breakid\"><img src=\"https://avatars.githubusercontent.com/u/1446918?v=4?s=100\" width=\"100px;\" alt=\"Dan\"/><br /><sub><b>Dan</b></sub></a><br /><a href=\"#instructions-breakid\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.codewithdan.com/\"><img src=\"https://avatars.githubusercontent.com/u/1767249?v=4?s=100\" width=\"100px;\" alt=\"Dan Wahlin\"/><br /><sub><b>Dan Wahlin</b></sub></a><br /><a href=\"#agents-DanWahlin\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://debbie.codes/\"><img src=\"https://avatars.githubusercontent.com/u/13063165?v=4?s=100\" width=\"100px;\" alt=\"Debbie O'Brien\"/><br /><sub><b>Debbie O'Brien</b></sub></a><br /><a href=\"#agents-debs-obrien\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-debs-obrien\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-debs-obrien\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/echarrod\"><img src=\"https://avatars.githubusercontent.com/u/1381991?v=4?s=100\" width=\"100px;\" alt=\"Ed Harrod\"/><br /><sub><b>Ed Harrod</b></sub></a><br /><a href=\"#prompts-echarrod\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://learn.microsoft.com/dotnet\"><img src=\"https://avatars.githubusercontent.com/u/24882762?v=4?s=100\" width=\"100px;\" alt=\"Genevieve Warren\"/><br /><sub><b>Genevieve Warren</b></sub></a><br /><a href=\"#prompts-gewarren\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/guigui42\"><img src=\"https://avatars.githubusercontent.com/u/2376010?v=4?s=100\" width=\"100px;\" alt=\"Guillaume\"/><br /><sub><b>Guillaume</b></sub></a><br /><a href=\"#agents-guigui42\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-guigui42\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/riqueufmg\"><img src=\"https://avatars.githubusercontent.com/u/108551585?v=4?s=100\" width=\"100px;\" alt=\"Henrique Nunes\"/><br /><sub><b>Henrique Nunes</b></sub></a><br /><a href=\"#prompts-riqueufmg\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jeremiah-snee-openx\"><img src=\"https://avatars.githubusercontent.com/u/113928685?v=4?s=100\" width=\"100px;\" alt=\"Jeremiah Snee\"/><br /><sub><b>Jeremiah Snee</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=jeremiah-snee-openx\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kartikdhiman\"><img src=\"https://avatars.githubusercontent.com/u/59189590?v=4?s=100\" width=\"100px;\" alt=\"Kartik Dhiman\"/><br /><sub><b>Kartik Dhiman</b></sub></a><br /><a href=\"#instructions-kartikdhiman\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://kristiyanvelkov.com/\"><img src=\"https://avatars.githubusercontent.com/u/40764277?v=4?s=100\" width=\"100px;\" alt=\"Kristiyan Velkov\"/><br /><sub><b>Kristiyan Velkov</b></sub></a><br /><a href=\"#agents-kristiyan-velkov\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/msalaman\"><img src=\"https://avatars.githubusercontent.com/u/28122166?v=4?s=100\" width=\"100px;\" alt=\"msalaman\"/><br /><sub><b>msalaman</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=msalaman\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://soderlind.no/\"><img src=\"https://avatars.githubusercontent.com/u/1649452?v=4?s=100\" width=\"100px;\" alt=\"Per S√∏derlind\"/><br /><sub><b>Per S√∏derlind</b></sub></a><br /><a href=\"#instructions-soderlind\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dotneteers.net/\"><img src=\"https://avatars.githubusercontent.com/u/28162552?v=4?s=100\" width=\"100px;\" alt=\"Peter Smulovics\"/><br /><sub><b>Peter Smulovics</b></sub></a><br /><a href=\"#instructions-psmulovics\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/madvimer\"><img src=\"https://avatars.githubusercontent.com/u/3188898?v=4?s=100\" width=\"100px;\" alt=\"Ravish Rathod\"/><br /><sub><b>Ravish Rathod</b></sub></a><br /><a href=\"#instructions-madvimer\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://ricksm.it/\"><img src=\"https://avatars.githubusercontent.com/u/7207783?v=4?s=100\" width=\"100px;\" alt=\"Rick Smit\"/><br /><sub><b>Rick Smit</b></sub></a><br /><a href=\"#agents-ricksmit3000\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pertrai1\"><img src=\"https://avatars.githubusercontent.com/u/442374?v=4?s=100\" width=\"100px;\" alt=\"Rob Simpson\"/><br /><sub><b>Rob Simpson</b></sub></a><br /><a href=\"#instructions-pertrai1\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/inquinity\"><img src=\"https://avatars.githubusercontent.com/u/406234?v=4?s=100\" width=\"100px;\" alt=\"Robert Altman\"/><br /><sub><b>Robert Altman</b></sub></a><br /><a href=\"#instructions-inquinity\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://salih.guru/\"><img src=\"https://avatars.githubusercontent.com/u/76786120?v=4?s=100\" width=\"100px;\" alt=\"Salih\"/><br /><sub><b>Salih</b></sub></a><br /><a href=\"#instructions-salihguru\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://graef.io/\"><img src=\"https://avatars.githubusercontent.com/u/19261257?v=4?s=100\" width=\"100px;\" alt=\"Sebastian Gr√§f\"/><br /><sub><b>Sebastian Gr√§f</b></sub></a><br /><a href=\"#agents-segraef\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-segraef\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/SebastienDegodez\"><img src=\"https://avatars.githubusercontent.com/u/2349146?v=4?s=100\" width=\"100px;\" alt=\"Sebastien DEGODEZ\"/><br /><sub><b>Sebastien DEGODEZ</b></sub></a><br /><a href=\"#instructions-SebastienDegodez\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sesmyrnov\"><img src=\"https://avatars.githubusercontent.com/u/59627981?v=4?s=100\" width=\"100px;\" alt=\"Sergiy Smyrnov\"/><br /><sub><b>Sergiy Smyrnov</b></sub></a><br /><a href=\"#prompts-sesmyrnov\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/SomeSolutionsArchitect\"><img src=\"https://avatars.githubusercontent.com/u/139817767?v=4?s=100\" width=\"100px;\" alt=\"SomeSolutionsArchitect\"/><br /><sub><b>SomeSolutionsArchitect</b></sub></a><br /><a href=\"#agents-SomeSolutionsArchitect\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kewalaka\"><img src=\"https://avatars.githubusercontent.com/u/3146590?v=4?s=100\" width=\"100px;\" alt=\"Stu Mace\"/><br /><sub><b>Stu Mace</b></sub></a><br /><a href=\"#agents-kewalaka\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-kewalaka\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#instructions-kewalaka\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/STRUDSO\"><img src=\"https://avatars.githubusercontent.com/u/1543732?v=4?s=100\" width=\"100px;\" alt=\"S√∏ren Truds√∏ Mahon\"/><br /><sub><b>S√∏ren Truds√∏ Mahon</b></sub></a><br /><a href=\"#instructions-STRUDSO\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://enakdesign.com/\"><img src=\"https://avatars.githubusercontent.com/u/14024037?v=4?s=100\" width=\"100px;\" alt=\"Tj Vita\"/><br /><sub><b>Tj Vita</b></sub></a><br /><a href=\"#agents-semperteneo\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pelikhan\"><img src=\"https://avatars.githubusercontent.com/u/4175913?v=4?s=100\" width=\"100px;\" alt=\"Peli de Halleux\"/><br /><sub><b>Peli de Halleux</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=pelikhan\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.paulomorgado.net/\"><img src=\"https://avatars.githubusercontent.com/u/470455?v=4?s=100\" width=\"100px;\" alt=\"Paulo Morgado\"/><br /><sub><b>Paulo Morgado</b></sub></a><br /><a href=\"#prompts-paulomorgado\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://paul.crane.net.nz/\"><img src=\"https://avatars.githubusercontent.com/u/808676?v=4?s=100\" width=\"100px;\" alt=\"Paul Crane\"/><br /><sub><b>Paul Crane</b></sub></a><br /><a href=\"#agents-pcrane\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.pamelafox.org/\"><img src=\"https://avatars.githubusercontent.com/u/297042?v=4?s=100\" width=\"100px;\" alt=\"Pamela Fox\"/><br /><sub><b>Pamela Fox</b></sub></a><br /><a href=\"#prompts-pamelafox\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://oskarthornblad.se/\"><img src=\"https://avatars.githubusercontent.com/u/640102?v=4?s=100\" width=\"100px;\" alt=\"Oskar Thornblad\"/><br /><sub><b>Oskar Thornblad</b></sub></a><br /><a href=\"#instructions-prewk\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nischays\"><img src=\"https://avatars.githubusercontent.com/u/54121853?v=4?s=100\" width=\"100px;\" alt=\"Nischay Sharma\"/><br /><sub><b>Nischay Sharma</b></sub></a><br /><a href=\"#agents-nischays\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Naikabg\"><img src=\"https://avatars.githubusercontent.com/u/19915620?v=4?s=100\" width=\"100px;\" alt=\"Nikolay Marinov\"/><br /><sub><b>Nikolay Marinov</b></sub></a><br /><a href=\"#agents-Naikabg\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/niksac\"><img src=\"https://avatars.githubusercontent.com/u/20246918?v=4?s=100\" width=\"100px;\" alt=\"Nik Sachdeva\"/><br /><sub><b>Nik Sachdeva</b></sub></a><br /><a href=\"#agents-niksacdev\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#collections-niksacdev\" title=\"Curated collections of related content\">üéÅ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://onetipaweek.com/\"><img src=\"https://avatars.githubusercontent.com/u/833231?v=4?s=100\" width=\"100px;\" alt=\"Nick Taylor\"/><br /><sub><b>Nick Taylor</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=nickytonline\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://nicholasdbrady.github.io/cookbook/\"><img src=\"https://avatars.githubusercontent.com/u/18353756?v=4?s=100\" width=\"100px;\" alt=\"Nick Brady\"/><br /><sub><b>Nick Brady</b></sub></a><br /><a href=\"#agents-nicholasdbrady\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nastanford\"><img src=\"https://avatars.githubusercontent.com/u/1755947?v=4?s=100\" width=\"100px;\" alt=\"Nathan Stanford Sr\"/><br /><sub><b>Nathan Stanford Sr</b></sub></a><br /><a href=\"#instructions-nastanford\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/matebarabas\"><img src=\"https://avatars.githubusercontent.com/u/22733424?v=4?s=100\" width=\"100px;\" alt=\"M√°t√© Barab√°s\"/><br /><sub><b>M√°t√© Barab√°s</b></sub></a><br /><a href=\"#instructions-matebarabas\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikeparker104\"><img src=\"https://avatars.githubusercontent.com/u/12763221?v=4?s=100\" width=\"100px;\" alt=\"Mike Parker\"/><br /><sub><b>Mike Parker</b></sub></a><br /><a href=\"#instructions-mikeparker104\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikekistler\"><img src=\"https://avatars.githubusercontent.com/u/85643503?v=4?s=100\" width=\"100px;\" alt=\"Mike Kistler\"/><br /><sub><b>Mike Kistler</b></sub></a><br /><a href=\"#prompts-mikekistler\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/giomartinsdev\"><img src=\"https://avatars.githubusercontent.com/u/125399281?v=4?s=100\" width=\"100px;\" alt=\"Giovanni de Almeida Martins\"/><br /><sub><b>Giovanni de Almeida Martins</b></sub></a><br /><a href=\"#instructions-giomartinsdev\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dgh06175\"><img src=\"https://avatars.githubusercontent.com/u/77305722?v=4?s=100\" width=\"100px;\" alt=\"Ïù¥ÏÉÅÌòÑ\"/><br /><sub><b>Ïù¥ÏÉÅÌòÑ</b></sub></a><br /><a href=\"#instructions-dgh06175\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zooav\"><img src=\"https://avatars.githubusercontent.com/u/12625412?v=4?s=100\" width=\"100px;\" alt=\"Ankur Sharma\"/><br /><sub><b>Ankur Sharma</b></sub></a><br /><a href=\"#prompts-zooav\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/webreidi\"><img src=\"https://avatars.githubusercontent.com/u/55603905?v=4?s=100\" width=\"100px;\" alt=\"Wendy Breiding\"/><br /><sub><b>Wendy Breiding</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=webreidi\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/voidfnc\"><img src=\"https://avatars.githubusercontent.com/u/194750710?v=4?s=100\" width=\"100px;\" alt=\"voidfnc\"/><br /><sub><b>voidfnc</b></sub></a><br /><a href=\"#agents-voidfnc\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://about.me/shane-lee\"><img src=\"https://avatars.githubusercontent.com/u/5466825?v=4?s=100\" width=\"100px;\" alt=\"shane lee\"/><br /><sub><b>shane lee</b></sub></a><br /><a href=\"#instructions-shavo007\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sdanzo-hrb\"><img src=\"https://avatars.githubusercontent.com/u/136493100?v=4?s=100\" width=\"100px;\" alt=\"sdanzo-hrb\"/><br /><sub><b>sdanzo-hrb</b></sub></a><br /><a href=\"#agents-sdanzo-hrb\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nativebpm\"><img src=\"https://avatars.githubusercontent.com/u/33398121?v=4?s=100\" width=\"100px;\" alt=\"sauran\"/><br /><sub><b>sauran</b></sub></a><br /><a href=\"#instructions-isauran\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/samqbush\"><img src=\"https://avatars.githubusercontent.com/u/74389839?v=4?s=100\" width=\"100px;\" alt=\"samqbush\"/><br /><sub><b>samqbush</b></sub></a><br /><a href=\"#prompts-samqbush\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pareenaverma\"><img src=\"https://avatars.githubusercontent.com/u/59843121?v=4?s=100\" width=\"100px;\" alt=\"pareenaverma\"/><br /><sub><b>pareenaverma</b></sub></a><br /><a href=\"#agents-pareenaverma\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/oleksiyyurchyna\"><img src=\"https://avatars.githubusercontent.com/u/10256765?v=4?s=100\" width=\"100px;\" alt=\"oleksiyyurchyna\"/><br /><sub><b>oleksiyyurchyna</b></sub></a><br /><a href=\"#collections-oleksiyyurchyna\" title=\"Curated collections of related content\">üéÅ</a> <a href=\"#prompts-oleksiyyurchyna\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/time-by-waves\"><img src=\"https://avatars.githubusercontent.com/u/34587654?v=4?s=100\" width=\"100px;\" alt=\"oceans-of-time\"/><br /><sub><b>oceans-of-time</b></sub></a><br /><a href=\"#instructions-time-by-waves\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kshashank57\"><img src=\"https://avatars.githubusercontent.com/u/57212456?v=4?s=100\" width=\"100px;\" alt=\"kshashank57\"/><br /><sub><b>kshashank57</b></sub></a><br /><a href=\"#agents-kshashank57\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-kshashank57\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hueanmy\"><img src=\"https://avatars.githubusercontent.com/u/20430626?v=4?s=100\" width=\"100px;\" alt=\"Meii\"/><br /><sub><b>Meii</b></sub></a><br /><a href=\"#agents-hueanmy\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/factory-davidgu\"><img src=\"https://avatars.githubusercontent.com/u/229352262?v=4?s=100\" width=\"100px;\" alt=\"factory-davidgu\"/><br /><sub><b>factory-davidgu</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=factory-davidgu\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dangelov-qa\"><img src=\"https://avatars.githubusercontent.com/u/92313553?v=4?s=100\" width=\"100px;\" alt=\"dangelov-qa\"/><br /><sub><b>dangelov-qa</b></sub></a><br /><a href=\"#agents-dangelov-qa\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/BenoitMaucotel\"><img src=\"https://avatars.githubusercontent.com/u/54392431?v=4?s=100\" width=\"100px;\" alt=\"BenoitMaucotel\"/><br /><sub><b>BenoitMaucotel</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=BenoitMaucotel\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/benjisho-aidome\"><img src=\"https://avatars.githubusercontent.com/u/218995725?v=4?s=100\" width=\"100px;\" alt=\"benjisho-aidome\"/><br /><sub><b>benjisho-aidome</b></sub></a><br /><a href=\"#agents-benjisho-aidome\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#instructions-benjisho-aidome\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-benjisho-aidome\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yukiomoto\"><img src=\"https://avatars.githubusercontent.com/u/38450410?v=4?s=100\" width=\"100px;\" alt=\"Yuki Omoto\"/><br /><sub><b>Yuki Omoto</b></sub></a><br /><a href=\"#instructions-yukiomoto\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wschultz-boxboat\"><img src=\"https://avatars.githubusercontent.com/u/110492948?v=4?s=100\" width=\"100px;\" alt=\"Will Schultz\"/><br /><sub><b>Will Schultz</b></sub></a><br /><a href=\"#agents-wschultz-boxboat\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://bio.warengonzaga.com/\"><img src=\"https://avatars.githubusercontent.com/u/15052701?v=4?s=100\" width=\"100px;\" alt=\"Waren Gonzaga\"/><br /><sub><b>Waren Gonzaga</b></sub></a><br /><a href=\"#agents-warengonzaga\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://linktr.ee/vincentkoc\"><img src=\"https://avatars.githubusercontent.com/u/25068?v=4?s=100\" width=\"100px;\" alt=\"Vincent Koc\"/><br /><sub><b>Vincent Koc</b></sub></a><br /><a href=\"#agents-vincentkoc\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Vaporjawn\"><img src=\"https://avatars.githubusercontent.com/u/15694665?v=4?s=100\" width=\"100px;\" alt=\"Victor Williams\"/><br /><sub><b>Victor Williams</b></sub></a><br /><a href=\"#agents-Vaporjawn\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://vesharma.dev/\"><img src=\"https://avatars.githubusercontent.com/u/62218708?v=4?s=100\" width=\"100px;\" alt=\"Ve Sharma\"/><br /><sub><b>Ve Sharma</b></sub></a><br /><a href=\"#agents-VeVarunSharma\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.ferryhopper.com/\"><img src=\"https://avatars.githubusercontent.com/u/19361558?v=4?s=100\" width=\"100px;\" alt=\"Vasileios Lahanas\"/><br /><sub><b>Vasileios Lahanas</b></sub></a><br /><a href=\"#instructions-vlahanas\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tinyurl.com/3p5j9mwe\"><img src=\"https://avatars.githubusercontent.com/u/9591887?v=4?s=100\" width=\"100px;\" alt=\"Udaya Veeramreddygari\"/><br /><sub><b>Udaya Veeramreddygari</b></sub></a><br /><a href=\"#instructions-udayakumarreddyv\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/iletai\"><img src=\"https://avatars.githubusercontent.com/u/26614687?v=4?s=100\" width=\"100px;\" alt=\"T√†i L√™\"/><br /><sub><b>T√†i L√™</b></sub></a><br /><a href=\"#prompts-iletai\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tsubasaogawa.me/\"><img src=\"https://avatars.githubusercontent.com/u/7788821?v=4?s=100\" width=\"100px;\" alt=\"Tsubasa Ogawa\"/><br /><sub><b>Tsubasa Ogawa</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=tsubasaogawa\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://glsauto.com/\"><img src=\"https://avatars.githubusercontent.com/u/132710946?v=4?s=100\" width=\"100px;\" alt=\"Troy Witthoeft (glsauto)\"/><br /><sub><b>Troy Witthoeft (glsauto)</b></sub></a><br /><a href=\"#instructions-twitthoeft-gls\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jfversluis.dev/\"><img src=\"https://avatars.githubusercontent.com/u/939291?v=4?s=100\" width=\"100px;\" alt=\"Gerald Versluis\"/><br /><sub><b>Gerald Versluis</b></sub></a><br /><a href=\"#instructions-jfversluis\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/geoder101\"><img src=\"https://avatars.githubusercontent.com/u/145904?v=4?s=100\" width=\"100px;\" alt=\"George Dernikos\"/><br /><sub><b>George Dernikos</b></sub></a><br /><a href=\"#prompts-geoder101\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gautambaghel\"><img src=\"https://avatars.githubusercontent.com/u/22324290?v=4?s=100\" width=\"100px;\" alt=\"Gautam\"/><br /><sub><b>Gautam</b></sub></a><br /><a href=\"#agents-gautambaghel\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/feapaydin\"><img src=\"https://avatars.githubusercontent.com/u/19946639?v=4?s=100\" width=\"100px;\" alt=\"Furkan Enes\"/><br /><sub><b>Furkan Enes</b></sub></a><br /><a href=\"#instructions-feapaydin\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/fmuecke\"><img src=\"https://avatars.githubusercontent.com/u/7921024?v=4?s=100\" width=\"100px;\" alt=\"Florian M√ºcke\"/><br /><sub><b>Florian M√ºcke</b></sub></a><br /><a href=\"#agents-fmuecke\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.felixarjuna.dev/\"><img src=\"https://avatars.githubusercontent.com/u/79026094?v=4?s=100\" width=\"100px;\" alt=\"Felix Arjuna\"/><br /><sub><b>Felix Arjuna</b></sub></a><br /><a href=\"#instructions-felixarjuna\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ewega\"><img src=\"https://avatars.githubusercontent.com/u/26189114?v=4?s=100\" width=\"100px;\" alt=\"Eldrick Wega\"/><br /><sub><b>Eldrick Wega</b></sub></a><br /><a href=\"#prompts-ewega\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danchev\"><img src=\"https://avatars.githubusercontent.com/u/12420863?v=4?s=100\" width=\"100px;\" alt=\"Dobri Danchev\"/><br /><sub><b>Dobri Danchev</b></sub></a><br /><a href=\"#prompts-danchev\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dgamboa.com/\"><img src=\"https://avatars.githubusercontent.com/u/7052267?v=4?s=100\" width=\"100px;\" alt=\"Diego Gamboa\"/><br /><sub><b>Diego Gamboa</b></sub></a><br /><a href=\"#prompts-difegam\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/derekclair\"><img src=\"https://avatars.githubusercontent.com/u/5247629?v=4?s=100\" width=\"100px;\" alt=\"Derek Clair\"/><br /><sub><b>Derek Clair</b></sub></a><br /><a href=\"#agents-derekclair\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-derekclair\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dev.to/davidortinau\"><img src=\"https://avatars.githubusercontent.com/u/41873?v=4?s=100\" width=\"100px;\" alt=\"David Ortinau\"/><br /><sub><b>David Ortinau</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=davidortinau\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danielabbatt\"><img src=\"https://avatars.githubusercontent.com/u/8926756?v=4?s=100\" width=\"100px;\" alt=\"Daniel Abbatt\"/><br /><sub><b>Daniel Abbatt</b></sub></a><br /><a href=\"#instructions-danielabbatt\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/CypherHK\"><img src=\"https://avatars.githubusercontent.com/u/230935834?v=4?s=100\" width=\"100px;\" alt=\"CypherHK\"/><br /><sub><b>CypherHK</b></sub></a><br /><a href=\"#agents-CypherHK\" title=\"Specialized agents for GitHub Copilot\">üé≠</a> <a href=\"#prompts-CypherHK\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/craigbekker\"><img src=\"https://avatars.githubusercontent.com/u/1115912?v=4?s=100\" width=\"100px;\" alt=\"Craig Bekker\"/><br /><sub><b>Craig Bekker</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=craigbekker\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.peug.net/\"><img src=\"https://avatars.githubusercontent.com/u/3845786?v=4?s=100\" width=\"100px;\" alt=\"Christophe Peugnet\"/><br /><sub><b>Christophe Peugnet</b></sub></a><br /><a href=\"#instructions-tossnet\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lechnerc77\"><img src=\"https://avatars.githubusercontent.com/u/22294087?v=4?s=100\" width=\"100px;\" alt=\"Christian Lechner\"/><br /><sub><b>Christian Lechner</b></sub></a><br /><a href=\"#instructions-lechnerc77\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/charris-msft\"><img src=\"https://avatars.githubusercontent.com/u/74415662?v=4?s=100\" width=\"100px;\" alt=\"Chris Harris\"/><br /><sub><b>Chris Harris</b></sub></a><br /><a href=\"#agents-charris-msft\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/artemsaveliev\"><img src=\"https://avatars.githubusercontent.com/u/15679218?v=4?s=100\" width=\"100px;\" alt=\"Artem Saveliev\"/><br /><sub><b>Artem Saveliev</b></sub></a><br /><a href=\"#instructions-artemsaveliev\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://javaetmoi.com/\"><img src=\"https://avatars.githubusercontent.com/u/838318?v=4?s=100\" width=\"100px;\" alt=\"Antoine Rey\"/><br /><sub><b>Antoine Rey</b></sub></a><br /><a href=\"#prompts-arey\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PiKa919\"><img src=\"https://avatars.githubusercontent.com/u/96786190?v=4?s=100\" width=\"100px;\" alt=\"Ankit Das\"/><br /><sub><b>Ankit Das</b></sub></a><br /><a href=\"#instructions-PiKa919\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alineavila\"><img src=\"https://avatars.githubusercontent.com/u/24813256?v=4?s=100\" width=\"100px;\" alt=\"Aline √Åvila\"/><br /><sub><b>Aline √Åvila</b></sub></a><br /><a href=\"#instructions-alineavila\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/martin-cod\"><img src=\"https://avatars.githubusercontent.com/u/33550246?v=4?s=100\" width=\"100px;\" alt=\"Alexander Martinkevich\"/><br /><sub><b>Alexander Martinkevich</b></sub></a><br /><a href=\"#agents-martin-cod\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aldunchev\"><img src=\"https://avatars.githubusercontent.com/u/4631021?v=4?s=100\" width=\"100px;\" alt=\"Aleksandar Dunchev\"/><br /><sub><b>Aleksandar Dunchev</b></sub></a><br /><a href=\"#agents-aldunchev\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.qreate.it/\"><img src=\"https://avatars.githubusercontent.com/u/1868590?v=4?s=100\" width=\"100px;\" alt=\"Alan Sprecacenere\"/><br /><sub><b>Alan Sprecacenere</b></sub></a><br /><a href=\"#instructions-tegola\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/akashxlr8\"><img src=\"https://avatars.githubusercontent.com/u/58072860?v=4?s=100\" width=\"100px;\" alt=\"Akash Kumar Shaw\"/><br /><sub><b>Akash Kumar Shaw</b></sub></a><br /><a href=\"#instructions-akashxlr8\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/abdidaudpropel\"><img src=\"https://avatars.githubusercontent.com/u/51310019?v=4?s=100\" width=\"100px;\" alt=\"Abdi Daud\"/><br /><sub><b>Abdi Daud</b></sub></a><br /><a href=\"#agents-abdidaudpropel\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AIAlchemyForge\"><img src=\"https://avatars.githubusercontent.com/u/253636689?v=4?s=100\" width=\"100px;\" alt=\"AIAlchemyForge\"/><br /><sub><b>AIAlchemyForge</b></sub></a><br /><a href=\"#instructions-AIAlchemyForge\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/4regab\"><img src=\"https://avatars.githubusercontent.com/u/178603515?v=4?s=100\" width=\"100px;\" alt=\"4regab\"/><br /><sub><b>4regab</b></sub></a><br /><a href=\"#instructions-4regab\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MiguelElGallo\"><img src=\"https://avatars.githubusercontent.com/u/60221874?v=4?s=100\" width=\"100px;\" alt=\"Miguel P Z\"/><br /><sub><b>Miguel P Z</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=MiguelElGallo\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://a11ysupport.io/\"><img src=\"https://avatars.githubusercontent.com/u/498678?v=4?s=100\" width=\"100px;\" alt=\"Michael Fairchild\"/><br /><sub><b>Michael Fairchild</b></sub></a><br /><a href=\"#instructions-mfairchild365\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/michael-volz/\"><img src=\"https://avatars.githubusercontent.com/u/129928?v=4?s=100\" width=\"100px;\" alt=\"Michael A. Volz (Flynn)\"/><br /><sub><b>Michael A. Volz (Flynn)</b></sub></a><br /><a href=\"#prompts-michaelvolz\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Mike-Hanna\"><img src=\"https://avatars.githubusercontent.com/u/50142889?v=4?s=100\" width=\"100px;\" alt=\"Michael\"/><br /><sub><b>Michael</b></sub></a><br /><a href=\"#instructions-Mike-Hanna\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.mehmetalierol.com/\"><img src=\"https://avatars.githubusercontent.com/u/16721723?v=4?s=100\" width=\"100px;\" alt=\"Mehmet Ali EROL\"/><br /><sub><b>Mehmet Ali EROL</b></sub></a><br /><a href=\"#agents-mehmetalierol\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://maxprilutskiy.com/\"><img src=\"https://avatars.githubusercontent.com/u/5614659?v=4?s=100\" width=\"100px;\" alt=\"Max Prilutskiy\"/><br /><sub><b>Max Prilutskiy</b></sub></a><br /><a href=\"#agents-maxprilutskiy\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mbianchidev\"><img src=\"https://avatars.githubusercontent.com/u/37507190?v=4?s=100\" width=\"100px;\" alt=\"Matteo Bianchi\"/><br /><sub><b>Matteo Bianchi</b></sub></a><br /><a href=\"#agents-mbianchidev\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://marknoble.com/\"><img src=\"https://avatars.githubusercontent.com/u/3819700?v=4?s=100\" width=\"100px;\" alt=\"Mark Noble\"/><br /><sub><b>Mark Noble</b></sub></a><br /><a href=\"#agents-marknoble\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ManishJayaswal\"><img src=\"https://avatars.githubusercontent.com/u/9527491?v=4?s=100\" width=\"100px;\" alt=\"Manish Jayaswal\"/><br /><sub><b>Manish Jayaswal</b></sub></a><br /><a href=\"#agents-ManishJayaswal\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://linktr.ee/lukemurray\"><img src=\"https://avatars.githubusercontent.com/u/24467442?v=4?s=100\" width=\"100px;\" alt=\"Luke Murray\"/><br /><sub><b>Luke Murray</b></sub></a><br /><a href=\"#agents-lukemurraynz\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/LouellaCreemers\"><img src=\"https://avatars.githubusercontent.com/u/46204894?v=4?s=100\" width=\"100px;\" alt=\"Louella Creemers\"/><br /><sub><b>Louella Creemers</b></sub></a><br /><a href=\"#instructions-LouellaCreemers\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/saikoumudi\"><img src=\"https://avatars.githubusercontent.com/u/22682497?v=4?s=100\" width=\"100px;\" alt=\"Sai Koumudi Kaluvakolanu\"/><br /><sub><b>Sai Koumudi Kaluvakolanu</b></sub></a><br /><a href=\"#agents-saikoumudi\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/whiteken\"><img src=\"https://avatars.githubusercontent.com/u/20211937?v=4?s=100\" width=\"100px;\" alt=\"Kenny White\"/><br /><sub><b>Kenny White</b></sub></a><br /><a href=\"#instructions-whiteken\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/KaloyanGenev\"><img src=\"https://avatars.githubusercontent.com/u/42644424?v=4?s=100\" width=\"100px;\" alt=\"KaloyanGenev\"/><br /><sub><b>KaloyanGenev</b></sub></a><br /><a href=\"#agents-KaloyanGenev\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ranrar\"><img src=\"https://avatars.githubusercontent.com/u/95967772?v=4?s=100\" width=\"100px;\" alt=\"Kim Skov Rasmussen\"/><br /><sub><b>Kim Skov Rasmussen</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=Ranrar\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.julien-dubois.com/\"><img src=\"https://avatars.githubusercontent.com/u/316835?v=4?s=100\" width=\"100px;\" alt=\"Julien Dubois\"/><br /><sub><b>Julien Dubois</b></sub></a><br /><a href=\"#prompts-jdubois\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://digio.es/\"><img src=\"https://avatars.githubusercontent.com/u/173672918?v=4?s=100\" width=\"100px;\" alt=\"Jos√© Antonio Garrido\"/><br /><sub><b>Jos√© Antonio Garrido</b></sub></a><br /><a href=\"#instructions-josegarridodigio\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.sugbo4j.co.nz/\"><img src=\"https://avatars.githubusercontent.com/u/15100839?v=4?s=100\" width=\"100px;\" alt=\"Joseph Gonzales\"/><br /><sub><b>Joseph Gonzales</b></sub></a><br /><a href=\"#instructions-josephgonzales01\" title=\"Custom instructions for GitHub Copilot\">üß≠</a> <a href=\"#prompts-josephgonzales01\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yortch\"><img src=\"https://avatars.githubusercontent.com/u/4576246?v=4?s=100\" width=\"100px;\" alt=\"Jorge Balderas\"/><br /><sub><b>Jorge Balderas</b></sub></a><br /><a href=\"#instructions-yortch\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://johnpapa.net/\"><img src=\"https://avatars.githubusercontent.com/u/1202528?v=4?s=100\" width=\"100px;\" alt=\"John Papa\"/><br /><sub><b>John Papa</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=johnpapa\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.johnlokerse.dev/\"><img src=\"https://avatars.githubusercontent.com/u/3514513?v=4?s=100\" width=\"100px;\" alt=\"John\"/><br /><sub><b>John</b></sub></a><br /><a href=\"#agents-johnlokerse\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://joe-watkins.io/\"><img src=\"https://avatars.githubusercontent.com/u/3695795?v=4?s=100\" width=\"100px;\" alt=\"Joe Watkins\"/><br /><sub><b>Joe Watkins</b></sub></a><br /><a href=\"#instructions-joe-watkins\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jan-v.nl/\"><img src=\"https://avatars.githubusercontent.com/u/462356?v=4?s=100\" width=\"100px;\" alt=\"Jan de Vries\"/><br /><sub><b>Jan de Vries</b></sub></a><br /><a href=\"#agents-Jandev\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nohwnd\"><img src=\"https://avatars.githubusercontent.com/u/5735905?v=4?s=100\" width=\"100px;\" alt=\"Jakub Jare≈°\"/><br /><sub><b>Jakub Jare≈°</b></sub></a><br /><a href=\"#prompts-nohwnd\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jaxn\"><img src=\"https://avatars.githubusercontent.com/u/29095?v=4?s=100\" width=\"100px;\" alt=\"Jackson Miller\"/><br /><sub><b>Jackson Miller</b></sub></a><br /><a href=\"#instructions-jaxn\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ioana37\"><img src=\"https://avatars.githubusercontent.com/u/69301842?v=4?s=100\" width=\"100px;\" alt=\"Ioana A\"/><br /><sub><b>Ioana A</b></sub></a><br /><a href=\"#instructions-Ioana37\" title=\"Custom instructions for GitHub Copilot\">üß≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hunterhogan\"><img src=\"https://avatars.githubusercontent.com/u/2958419?v=4?s=100\" width=\"100px;\" alt=\"Hunter Hogan\"/><br /><sub><b>Hunter Hogan</b></sub></a><br /><a href=\"#agents-hunterhogan\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hashimwarren\"><img src=\"https://avatars.githubusercontent.com/u/6027587?v=4?s=100\" width=\"100px;\" alt=\"Hashim Warren\"/><br /><sub><b>Hashim Warren</b></sub></a><br /><a href=\"#agents-hashimwarren\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Arggon\"><img src=\"https://avatars.githubusercontent.com/u/20962238?v=4?s=100\" width=\"100px;\" alt=\"Gonzalo\"/><br /><sub><b>Gonzalo</b></sub></a><br /><a href=\"#prompts-Arggon\" title=\"Reusable prompts for GitHub Copilot\">‚å®Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://hachyderm.io/@0gis0\"><img src=\"https://avatars.githubusercontent.com/u/175379?v=4?s=100\" width=\"100px;\" alt=\"Gisela Torres\"/><br /><sub><b>Gisela Torres</b></sub></a><br /><a href=\"#agents-0GiS0\" title=\"Specialized agents for GitHub Copilot\">üé≠</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shibicr93\"><img src=\"https://avatars.githubusercontent.com/u/6803434?v=4?s=100\" width=\"100px;\" alt=\"Shibi Ramachandran\"/><br /><sub><b>Shibi Ramachandran</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=shibicr93\" title=\"Code\">üíª</a></td>\n    </tr>\n  </tbody>\n  <tfoot>\n    <tr>\n      <td align=\"center\" size=\"13px\" colspan=\"7\">\n        <img src=\"https://raw.githubusercontent.com/all-contributors/all-contributors-cli/1b8533af435da9854653492b1327a23a4dbd0a10/assets/logo-small.svg\">\n          <a href=\"https://all-contributors.js.org/docs/en/bot/usage\">Add your contributions</a>\n        </img>\n      </td>\n    </tr>\n  </tfoot>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!\n\n## üìö Additional Resources\n\n- [VS Code Copilot Customization Documentation](https://code.visualstudio.com/docs/copilot/copilot-customization) - Official Microsoft documentation\n- [GitHub Copilot Chat Documentation](https://code.visualstudio.com/docs/copilot/chat/copilot-chat) - Complete chat feature guide\n- [VS Code Settings](https://code.visualstudio.com/docs/getstarted/settings) - General VS Code configuration guide\n\n## ‚Ñ¢Ô∏è Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n",
      "stars_today": 159
    },
    {
      "id": 685877018,
      "name": "res-downloader",
      "full_name": "putyy/res-downloader",
      "description": "ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÁõ¥Êí≠ÊµÅ„ÄÅm3u8„ÄÅÈÖ∑Áãó„ÄÅQQÈü≥‰πêÁ≠âÂ∏∏ËßÅÁΩëÁªúËµÑÊ∫ê‰∏ãËΩΩ!",
      "html_url": "https://github.com/putyy/res-downloader",
      "stars": 13846,
      "forks": 1735,
      "language": "Go",
      "topics": [
        "douyin",
        "kuaishou",
        "res-downloader",
        "wechat",
        "wechat-video",
        "xiaohongshu"
      ],
      "created_at": "2023-09-01T08:03:47Z",
      "updated_at": "2026-01-23T02:10:59Z",
      "pushed_at": "2025-12-31T02:24:50Z",
      "open_issues": 38,
      "owner": {
        "login": "putyy",
        "avatar_url": "https://avatars.githubusercontent.com/u/31536789?v=4"
      },
      "readme": "<div align=\"center\">\n\n<a href=\"https://github.com/putyy/res-downloader\"><img src=\"build/appicon.png\" width=\"120\"/></a>\n<h1>res-downloader</h1>\n<h4>üìñ ‰∏≠Êñá | <a href=\"https://github.com/putyy/res-downloader/blob/master/README-EN.md\">English</a></h4>\n\n[![GitHub stars](https://img.shields.io/github/stars/putyy/res-downloader)](https://github.com/putyy/res-downloader/stargazers)\n[![GitHub forks](https://img.shields.io/github/forks/putyy/res-downloader)](https://github.com/putyy/res-downloader/fork)\n[![GitHub release](https://img.shields.io/github/release/putyy/res-downloader)](https://github.com/putyy/res-downloader/releases)\n![GitHub All Releases](https://img.shields.io/github/downloads/putyy/res-downloader/total)\n[![License](https://img.shields.io/github/license/putyy/res-downloader)](https://github.com/putyy/res-downloader/blob/master/LICENSE)\n\n</div>\n\n---\n\n### üéâ Áà±‰∫´Á¥†Êùê‰∏ãËΩΩÂô®\n\n> ‰∏ÄÊ¨æÂü∫‰∫é Go + [Wails](https://github.com/wailsapp/wails) ÁöÑË∑®Âπ≥Âè∞ËµÑÊ∫ê‰∏ãËΩΩÂ∑•ÂÖ∑ÔºåÁÆÄÊ¥ÅÊòìÁî®ÔºåÊîØÊåÅÂ§öÁßçËµÑÊ∫êÂóÖÊé¢‰∏é‰∏ãËΩΩ„ÄÇ\n\n## ‚ú® ÂäüËÉΩÁâπËâ≤\n\n- üöÄ **ÁÆÄÂçïÊòìÁî®**ÔºöÊìç‰ΩúÁÆÄÂçïÔºåÁïåÈù¢Ê∏ÖÊô∞ÁæéËßÇ\n- üñ•Ô∏è **Â§öÂπ≥Âè∞ÊîØÊåÅ**ÔºöWindows / macOS / Linux\n- üåê **Â§öËµÑÊ∫êÁ±ªÂûãÊîØÊåÅ**ÔºöËßÜÈ¢ë / Èü≥È¢ë / ÂõæÁâá / m3u8 / Áõ¥Êí≠ÊµÅÁ≠â\n- üì± **Âπ≥Âè∞ÂÖºÂÆπÂπøÊ≥õ**ÔºöÊîØÊåÅÂæÆ‰ø°ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÈÖ∑ÁãóÈü≥‰πê„ÄÅQQÈü≥‰πêÁ≠â\n- üåç **‰ª£ÁêÜÊäìÂåÖ**ÔºöÊîØÊåÅËÆæÁΩÆ‰ª£ÁêÜËé∑ÂèñÂèóÈôêÁΩëÁªú‰∏ãÁöÑËµÑÊ∫ê\n\n## üìö ÊñáÊ°£ & ÁâàÊú¨\n\n- üìò [Âú®Á∫øÊñáÊ°£](https://res.putyy.com/)\n- üí¨ [Âä†ÂÖ•‰∫§ÊµÅÁæ§](https://www.putyy.com/app/admin/upload/img/20250418/6801d9554dc7.webp)\n- üß© [ÊúÄÊñ∞Áâà](https://github.com/putyy/res-downloader/releases) ÔΩú [MiniÁâà ‰ΩøÁî®ÈªòËÆ§ÊµèËßàÂô®Â±ïÁ§∫UI](https://github.com/putyy/resd-mini) ÔΩú [ElectronÊóßÁâà ÊîØÊåÅWin7](https://github.com/putyy/res-downloader/tree/old)\n  > *Áæ§Êª°Êó∂ÂèØÂä†ÂæÆ‰ø° `AmorousWorld`ÔºåËØ∑Â§áÊ≥®‚Äúgithub‚Äù*\n\n## üß© ‰∏ãËΩΩÂú∞ÂùÄ\n\n- üÜï [GitHub ‰∏ãËΩΩ](https://github.com/putyy/res-downloader/releases)\n- üÜï [ËìùÂ•è‰∫ë‰∏ãËΩΩÔºàÂØÜÁ†ÅÔºö9vs5Ôºâ](https://wwjv.lanzoum.com/b04wgtfyb)\n- ‚ö†Ô∏è *Win7 Áî®Êà∑ËØ∑‰∏ãËΩΩ `2.3.0` ÁâàÊú¨*\n\n\n## üñºÔ∏è È¢ÑËßà\n\n![È¢ÑËßà](docs/images/show.webp)\n--- \n\n## üöÄ ‰ΩøÁî®ÊñπÊ≥ï\n\n> ËØ∑Êåâ‰ª•‰∏ãÊ≠•È™§Êìç‰Ωú‰ª•Ê≠£Á°Æ‰ΩøÁî®ËΩØ‰ª∂Ôºö\n\n1. ÂÆâË£ÖÊó∂Âä°ÂøÖ **ÂÖÅËÆ∏ÂÆâË£ÖËØÅ‰π¶Êñá‰ª∂** Âπ∂ **ÂÖÅËÆ∏ÁΩëÁªúËÆøÈóÆ**\n2. ÊâìÂºÄËΩØ‰ª∂ ‚Üí È¶ñÈ°µÂ∑¶‰∏äËßíÁÇπÂáª **‚ÄúÂêØÂä®‰ª£ÁêÜ‚Äù**\n3. ÈÄâÊã©Ë¶ÅËé∑ÂèñÁöÑËµÑÊ∫êÁ±ªÂûãÔºàÈªòËÆ§ÂÖ®ÈÉ®Ôºâ\n4. Âú®Â§ñÈÉ®ÊâìÂºÄËµÑÊ∫êÈ°µÈù¢ÔºàÂ¶ÇËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÁΩëÈ°µÁ≠âÔºâ\n5. ËøîÂõûËΩØ‰ª∂È¶ñÈ°µÔºåÂç≥ÂèØÁúãÂà∞ËµÑÊ∫êÂàóË°®\n\n## ‚ùì Â∏∏ËßÅÈóÆÈ¢ò\n\n### üì∫ m3u8 ËßÜÈ¢ëËµÑÊ∫ê\n\n- Âú®Á∫øÈ¢ÑËßàÔºö[m3u8play](https://m3u8play.com/)\n- ËßÜÈ¢ë‰∏ãËΩΩÔºö[m3u8-down](https://m3u8-down.gowas.cn/)\n\n### üì° Áõ¥Êí≠ÊµÅËµÑÊ∫ê\n\n- Êé®Ëçê‰ΩøÁî® [OBS](https://obsproject.com/) ËøõË°åÂΩïÂà∂ÔºàÊïôÁ®ãËØ∑ÁôæÂ∫¶Ôºâ\n\n### üê¢ ‰∏ãËΩΩÊÖ¢„ÄÅÂ§ßÊñá‰ª∂Â§±Ë¥•Ôºü\n\n- Êé®ËçêÂ∑•ÂÖ∑Ôºö\n  - [Neat Download Manager](https://www.neatdownloadmanager.com/index.php/en/)\n  - [Motrix](https://motrix.app/download)\n- ËßÜÈ¢ëÂè∑ËµÑÊ∫ê‰∏ãËΩΩÂêéÂèØÂú®Êìç‰ΩúÈ°πÁÇπÂáª `ËßÜÈ¢ëËß£ÂØÜÔºàËßÜÈ¢ëÂè∑Ôºâ`\n\n### üß© ËΩØ‰ª∂Êó†Ê≥ïÊã¶Êà™ËµÑÊ∫êÔºü\n\n- Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°ÆËÆæÁΩÆÁ≥ªÁªü‰ª£ÁêÜÔºö  \n  Âú∞ÂùÄÔºö127.0.0.1\n  Á´ØÂè£Ôºö8899\n\n### üåê ÂÖ≥Èó≠ËΩØ‰ª∂ÂêéÊó†Ê≥ï‰∏äÁΩëÔºü\n\n- ÊâãÂä®ÂÖ≥Èó≠Á≥ªÁªü‰ª£ÁêÜËÆæÁΩÆ\n\n### üß† Êõ¥Â§öÈóÆÈ¢ò\n\n- [GitHub Issues](https://github.com/putyy/res-downloader/issues)\n- [Áà±‰∫´ËÆ∫ÂùõËÆ®ËÆ∫Â∏ñ](https://s.gowas.cn/d/4089)\n\n## üí° ÂÆûÁé∞ÂéüÁêÜ & ÂàùË°∑\n\nÊú¨Â∑•ÂÖ∑ÈÄöËøá‰ª£ÁêÜÊñπÂºèÂÆûÁé∞ÁΩëÁªúÊäìÂåÖÔºåÂπ∂Á≠õÈÄâÂèØÁî®ËµÑÊ∫ê„ÄÇ‰∏é Fiddler„ÄÅCharles„ÄÅÊµèËßàÂô® DevTools ÂéüÁêÜÁ±ª‰ººÔºå‰ΩÜÂØπËµÑÊ∫êËøõË°å‰∫ÜÊõ¥ÂèãÂ•ΩÁöÑÁ≠õÈÄâ„ÄÅÂ±ïÁ§∫ÂíåÂ§ÑÁêÜÔºåÂ§ßÂπÖÂ∫¶Èôç‰Ωé‰∫Ü‰ΩøÁî®Èó®ÊßõÔºåÊõ¥ÈÄÇÂêàÂ§ß‰ºóÁî®Êà∑‰ΩøÁî®„ÄÇ\n\n---\n\n## ‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé\n\n> Êú¨ËΩØ‰ª∂‰ªÖ‰æõÂ≠¶‰π†‰∏éÁ†îÁ©∂Áî®ÈÄîÔºåÁ¶ÅÊ≠¢Áî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÊàñËøùÊ≥ïÁî®ÈÄî„ÄÇ  \nÂ¶ÇÂõ†Ê≠§‰∫ßÁîüÁöÑ‰ªª‰ΩïÊ≥ïÂæãË¥£‰ªªÔºåÊ¶Ç‰∏é‰ΩúËÄÖÊó†ÂÖ≥ÔºÅ\n",
      "stars_today": 144
    },
    {
      "id": 658928958,
      "name": "ollama",
      "full_name": "ollama/ollama",
      "description": "Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.",
      "html_url": "https://github.com/ollama/ollama",
      "stars": 160261,
      "forks": 14246,
      "language": "Go",
      "topics": [
        "deepseek",
        "gemma",
        "gemma3",
        "gemma3n",
        "go",
        "golang",
        "gpt-oss",
        "llama",
        "llama2",
        "llama3",
        "llava",
        "llm",
        "llms",
        "mistral",
        "ollama",
        "phi4",
        "qwen"
      ],
      "created_at": "2023-06-26T19:39:32Z",
      "updated_at": "2026-01-23T02:09:28Z",
      "pushed_at": "2026-01-23T01:35:50Z",
      "open_issues": 2373,
      "owner": {
        "login": "ollama",
        "avatar_url": "https://avatars.githubusercontent.com/u/151674099?v=4"
      },
      "readme": "<div align=\"center\">\n¬† <a href=\"https://ollama.com\">\n    <img alt=\"ollama\" width=\"240\" src=\"https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7\">\n  </a>\n</div>\n\n# Ollama\n\nGet up and running with large language models.\n\n### macOS\n\n[Download](https://ollama.com/download/Ollama.dmg)\n\n### Windows\n\n[Download](https://ollama.com/download/OllamaSetup.exe)\n\n### Linux\n\n```shell\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n[Manual install instructions](https://docs.ollama.com/linux#manual-install)\n\n### Docker\n\nThe official [Ollama Docker image](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` is available on Docker Hub.\n\n### Libraries\n\n- [ollama-python](https://github.com/ollama/ollama-python)\n- [ollama-js](https://github.com/ollama/ollama-js)\n\n### Community\n\n- [Discord](https://discord.gg/ollama)\n- [Reddit](https://reddit.com/r/ollama)\n\n## Quickstart\n\nTo run and chat with [Gemma 3](https://ollama.com/library/gemma3):\n\n```shell\nollama run gemma3\n```\n\n## Model library\n\nOllama supports a list of models available on [ollama.com/library](https://ollama.com/library \"ollama model library\")\n\nHere are some example models that can be downloaded:\n\n| Model              | Parameters | Size  | Download                         |\n| ------------------ | ---------- | ----- | -------------------------------- |\n| Gemma 3            | 1B         | 815MB | `ollama run gemma3:1b`           |\n| Gemma 3            | 4B         | 3.3GB | `ollama run gemma3`              |\n| Gemma 3            | 12B        | 8.1GB | `ollama run gemma3:12b`          |\n| Gemma 3            | 27B        | 17GB  | `ollama run gemma3:27b`          |\n| QwQ                | 32B        | 20GB  | `ollama run qwq`                 |\n| DeepSeek-R1        | 7B         | 4.7GB | `ollama run deepseek-r1`         |\n| DeepSeek-R1        | 671B       | 404GB | `ollama run deepseek-r1:671b`    |\n| Llama 4            | 109B       | 67GB  | `ollama run llama4:scout`        |\n| Llama 4            | 400B       | 245GB | `ollama run llama4:maverick`     |\n| Llama 3.3          | 70B        | 43GB  | `ollama run llama3.3`            |\n| Llama 3.2          | 3B         | 2.0GB | `ollama run llama3.2`            |\n| Llama 3.2          | 1B         | 1.3GB | `ollama run llama3.2:1b`         |\n| Llama 3.2 Vision   | 11B        | 7.9GB | `ollama run llama3.2-vision`     |\n| Llama 3.2 Vision   | 90B        | 55GB  | `ollama run llama3.2-vision:90b` |\n| Llama 3.1          | 8B         | 4.7GB | `ollama run llama3.1`            |\n| Llama 3.1          | 405B       | 231GB | `ollama run llama3.1:405b`       |\n| Phi 4              | 14B        | 9.1GB | `ollama run phi4`                |\n| Phi 4 Mini         | 3.8B       | 2.5GB | `ollama run phi4-mini`           |\n| Mistral            | 7B         | 4.1GB | `ollama run mistral`             |\n| Moondream 2        | 1.4B       | 829MB | `ollama run moondream`           |\n| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`         |\n| Starling           | 7B         | 4.1GB | `ollama run starling-lm`         |\n| Code Llama         | 7B         | 3.8GB | `ollama run codellama`           |\n| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored`   |\n| LLaVA              | 7B         | 4.5GB | `ollama run llava`               |\n| Granite-3.3        | 8B         | 4.9GB | `ollama run granite3.3`          |\n\n> [!NOTE]\n> You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.\n\n## Customize a model\n\n### Import from GGUF\n\nOllama supports importing GGUF models in the Modelfile:\n\n1. Create a file named `Modelfile`, with a `FROM` instruction with the local filepath to the model you want to import.\n\n   ```\n   FROM ./vicuna-33b.Q4_0.gguf\n   ```\n\n2. Create the model in Ollama\n\n   ```shell\n   ollama create example -f Modelfile\n   ```\n\n3. Run the model\n\n   ```shell\n   ollama run example\n   ```\n\n### Import from Safetensors\n\nSee the [guide](https://docs.ollama.com/import) on importing models for more information.\n\n### Customize a prompt\n\nModels from the Ollama library can be customized with a prompt. For example, to customize the `llama3.2` model:\n\n```shell\nollama pull llama3.2\n```\n\nCreate a `Modelfile`:\n\n```\nFROM llama3.2\n\n# set the temperature to 1 [higher is more creative, lower is more coherent]\nPARAMETER temperature 1\n\n# set the system message\nSYSTEM \"\"\"\nYou are Mario from Super Mario Bros. Answer as Mario, the assistant, only.\n\"\"\"\n```\n\nNext, create and run the model:\n\n```\nollama create mario -f ./Modelfile\nollama run mario\n>>> hi\nHello! It's your friend Mario.\n```\n\nFor more information on working with a Modelfile, see the [Modelfile](https://docs.ollama.com/modelfile) documentation.\n\n## CLI Reference\n\n### Create a model\n\n`ollama create` is used to create a model from a Modelfile.\n\n```shell\nollama create mymodel -f ./Modelfile\n```\n\n### Pull a model\n\n```shell\nollama pull llama3.2\n```\n\n> This command can also be used to update a local model. Only the diff will be pulled.\n\n### Remove a model\n\n```shell\nollama rm llama3.2\n```\n\n### Copy a model\n\n```shell\nollama cp llama3.2 my-model\n```\n\n### Multiline input\n\nFor multiline input, you can wrap text with `\"\"\"`:\n\n```\n>>> \"\"\"Hello,\n... world!\n... \"\"\"\nI'm a basic program that prints the famous \"Hello, world!\" message to the console.\n```\n\n### Multimodal models\n\n```\nollama run llava \"What's in this image? /Users/jmorgan/Desktop/smile.png\"\n```\n\n> **Output**: The image features a yellow smiley face, which is likely the central focus of the picture.\n\n### Pass the prompt as an argument\n\n```shell\nollama run llama3.2 \"Summarize this file: $(cat README.md)\"\n```\n\n> **Output**: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.\n\n### Show model information\n\n```shell\nollama show llama3.2\n```\n\n### List models on your computer\n\n```shell\nollama list\n```\n\n### List which models are currently loaded\n\n```shell\nollama ps\n```\n\n### Stop a model which is currently running\n\n```shell\nollama stop llama3.2\n```\n\n### Generate embeddings from the CLI\n\n```shell\nollama run embeddinggemma \"Your text to embed\"\n```\n\nYou can also pipe text for scripted workflows:\n\n```shell\necho \"Your text to embed\" | ollama run embeddinggemma\n```\n\n### Start Ollama\n\n`ollama serve` is used when you want to start ollama without running the desktop application.\n\n## Building\n\nSee the [developer guide](https://github.com/ollama/ollama/blob/main/docs/development.md)\n\n### Running local builds\n\nNext, start the server:\n\n```shell\n./ollama serve\n```\n\nFinally, in a separate shell, run a model:\n\n```shell\n./ollama run llama3.2\n```\n\n## Building with MLX (experimental)\n\nFirst build the MLX libraries:\n\n```shell\ncmake --preset MLX\ncmake --build --preset MLX --parallel\ncmake --install build --component MLX\n```\n\nWhen building with the `-tags mlx` flag, the main `ollama` binary includes MLX support for experimental features like image generation:\n\n```shell\ngo build -tags mlx .\n```\n\nFinally, start the server:\n\n```\n./ollama serve\n```\n\n### Building MLX with CUDA\n\nWhen building with CUDA, use the preset \"MLX CUDA 13\" or \"MLX CUDA 12\" to enable CUDA with default architectures:\n\n```shell\ncmake --preset 'MLX CUDA 13'\ncmake --build --preset 'MLX CUDA 13' --parallel\ncmake --install build --component MLX\n```\n\n## REST API\n\nOllama has a REST API for running and managing models.\n\n### Generate a response\n\n```shell\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3.2\",\n  \"prompt\":\"Why is the sky blue?\"\n}'\n```\n\n### Chat with a model\n\n```shell\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama3.2\",\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n  ]\n}'\n```\n\nSee the [API documentation](./docs/api.md) for all endpoints.\n\n## Community Integrations\n\n### Web & Desktop\n\n- [Onyx](https://github.com/onyx-dot-app/onyx)\n- [Open WebUI](https://github.com/open-webui/open-webui)\n- [SwiftChat (macOS with ReactNative)](https://github.com/aws-samples/swift-chat)\n- [Enchanted (macOS native)](https://github.com/AugustDev/enchanted)\n- [Hollama](https://github.com/fmaclen/hollama)\n- [Lollms WebUI (Single user)](https://github.com/ParisNeo/lollms-webui)\n- [Lollms (Multi users)](https://github.com/ParisNeo/lollms)\n- [LibreChat](https://github.com/danny-avila/LibreChat)\n- [Bionic GPT](https://github.com/bionic-gpt/bionic-gpt)\n- [HTML UI](https://github.com/rtcfirefly/ollama-ui)\n- [AI-UI](https://github.com/bajahaw/ai-ui)\n- [Saddle](https://github.com/jikkuatwork/saddle)\n- [TagSpaces](https://www.tagspaces.org) (A platform for file-based apps, [utilizing Ollama](https://docs.tagspaces.org/ai/) for the generation of tags and descriptions)\n- [Chatbot UI](https://github.com/ivanfioravanti/chatbot-ollama)\n- [Chatbot UI v2](https://github.com/mckaywrigley/chatbot-ui)\n- [Typescript UI](https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file)\n- [Minimalistic React UI for Ollama Models](https://github.com/richawo/minimal-llm-ui)\n- [Ollamac](https://github.com/kevinhermawan/Ollamac)\n- [big-AGI](https://github.com/enricoros/big-AGI)\n- [Cheshire Cat assistant framework](https://github.com/cheshire-cat-ai/core)\n- [Amica](https://github.com/semperai/amica)\n- [chatd](https://github.com/BruceMacD/chatd)\n- [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI)\n- [Dify.AI](https://github.com/langgenius/dify)\n- [MindMac](https://mindmac.app)\n- [NextJS Web Interface for Ollama](https://github.com/jakobhoeg/nextjs-ollama-llm-ui)\n- [Msty](https://msty.app)\n- [Chatbox](https://github.com/Bin-Huang/Chatbox)\n- [WinForm Ollama Copilot](https://github.com/tgraupmann/WinForm_Ollama_Copilot)\n- [NextChat](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) with [Get Started Doc](https://docs.nextchat.dev/models/ollama)\n- [Alpaca WebUI](https://github.com/mmo80/alpaca-webui)\n- [OllamaGUI](https://github.com/enoch1118/ollamaGUI)\n- [OpenAOE](https://github.com/InternLM/OpenAOE)\n- [Odin Runes](https://github.com/leonid20000/OdinRunes)\n- [LLM-X](https://github.com/mrdjohnson/llm-x) (Progressive Web App)\n- [AnythingLLM (Docker + MacOs/Windows/Linux native app)](https://github.com/Mintplex-Labs/anything-llm)\n- [Ollama Basic Chat: Uses HyperDiv Reactive UI](https://github.com/rapidarchitect/ollama_basic_chat)\n- [Ollama-chats RPG](https://github.com/drazdra/ollama-chats)\n- [IntelliBar](https://intellibar.app/) (AI-powered assistant for macOS)\n- [Jirapt](https://github.com/AliAhmedNada/jirapt) (Jira Integration to generate issues, tasks, epics)\n- [ojira](https://github.com/AliAhmedNada/ojira) (Jira chrome plugin to easily generate descriptions for tasks)\n- [QA-Pilot](https://github.com/reid41/QA-Pilot) (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)\n- [ChatOllama](https://github.com/sugarforever/chat-ollama) (Open Source Chatbot based on Ollama with Knowledge Bases)\n- [CRAG Ollama Chat](https://github.com/Nagi-ovo/CRAG-Ollama-Chat) (Simple Web Search with Corrective RAG)\n- [RAGFlow](https://github.com/infiniflow/ragflow) (Open-source Retrieval-Augmented Generation engine based on deep document understanding)\n- [StreamDeploy](https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold) (LLM Application Scaffold)\n- [chat](https://github.com/swuecho/chat) (chat web app for teams)\n- [Lobe Chat](https://github.com/lobehub/lobe-chat) with [Integrating Doc](https://lobehub.com/docs/self-hosting/examples/ollama)\n- [Ollama RAG Chatbot](https://github.com/datvodinh/rag-chatbot.git) (Local Chat with multiple PDFs using Ollama and RAG)\n- [BrainSoup](https://www.nurgo-software.com/products/brainsoup) (Flexible native client with RAG & multi-agent automation)\n- [macai](https://github.com/Renset/macai) (macOS client for Ollama, ChatGPT, and other compatible API back-ends)\n- [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)\n- [Ollama Grid Search](https://github.com/dezoito/ollama-grid-search) (app to evaluate and compare models)\n- [Olpaka](https://github.com/Otacon/olpaka) (User-friendly Flutter Web App for Ollama)\n- [Casibase](https://casibase.org) (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)\n- [OllamaSpring](https://github.com/CrazyNeil/OllamaSpring) (Ollama Client for macOS)\n- [LLocal.in](https://github.com/kartikm7/llocal) (Easy to use Electron Desktop Client for Ollama)\n- [Shinkai Desktop](https://github.com/dcSpark/shinkai-apps) (Two click install Local AI using Ollama + Files + RAG)\n- [AiLama](https://github.com/zeyoyt/ailama) (A Discord User App that allows you to interact with Ollama anywhere in Discord)\n- [Ollama with Google Mesop](https://github.com/rapidarchitect/ollama_mesop/) (Mesop Chat Client implementation with Ollama)\n- [R2R](https://github.com/SciPhi-AI/R2R) (Open-source RAG engine)\n- [Ollama-Kis](https://github.com/elearningshow/ollama-kis) (A simple easy-to-use GUI with sample custom LLM for Drivers Education)\n- [OpenGPA](https://opengpa.org) (Open-source offline-first Enterprise Agentic Application)\n- [Painting Droid](https://github.com/mateuszmigas/painting-droid) (Painting app with AI integrations)\n- [Kerlig AI](https://www.kerlig.com/) (AI writing assistant for macOS)\n- [AI Studio](https://github.com/MindWorkAI/AI-Studio)\n- [Sidellama](https://github.com/gyopak/sidellama) (browser-based LLM client)\n- [LLMStack](https://github.com/trypromptly/LLMStack) (No-code multi-agent framework to build LLM agents and workflows)\n- [BoltAI for Mac](https://boltai.com) (AI Chat Client for Mac)\n- [Harbor](https://github.com/av/harbor) (Containerized LLM Toolkit with Ollama as default backend)\n- [PyGPT](https://github.com/szczyglis-dev/py-gpt) (AI desktop assistant for Linux, Windows, and Mac)\n- [Alpaca](https://github.com/Jeffser/Alpaca) (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)\n- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md) (AutoGPT Ollama integration)\n- [Go-CREW](https://www.jonathanhecl.com/go-crew/) (Powerful Offline RAG in Golang)\n- [PartCAD](https://github.com/openvmp/partcad/) (CAD model generation with OpenSCAD and CadQuery)\n- [Ollama4j Web UI](https://github.com/ollama4j/ollama4j-web-ui) - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j\n- [PyOllaMx](https://github.com/kspviswa/pyOllaMx) - macOS application capable of chatting with both Ollama and Apple MLX models.\n- [Cline](https://github.com/cline/cline) - Formerly known as Claude Dev is a VS Code extension for multi-file/whole-repo coding\n- [Void](https://github.com/voideditor/void) (Open source AI code editor and Cursor alternative)\n- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) (Desktop client with Ollama support)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)\n- [Archyve](https://github.com/nickthecook/archyve) (RAG-enabling document library)\n- [crewAI with Mesop](https://github.com/rapidarchitect/ollama-crew-mesop) (Mesop Web Interface to run crewAI with Ollama)\n- [Tkinter-based client](https://github.com/chyok/ollama-gui) (Python tkinter-based Client for Ollama)\n- [LLMChat](https://github.com/trendy-design/llmchat) (Privacy focused, 100% local, intuitive all-in-one chat interface)\n- [Local Multimodal AI Chat](https://github.com/Leon-Sander/Local-Multimodal-AI-Chat) (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)\n- [ARGO](https://github.com/xark-argo/argo) (Locally download and run Ollama and Huggingface models with RAG and deep research on Mac/Windows/Linux)\n- [OrionChat](https://github.com/EliasPereirah/OrionChat) - OrionChat is a web interface for chatting with different AI providers\n- [G1](https://github.com/bklieger-groq/g1) (Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)\n- [Web management](https://github.com/lemonit-eric-mao/ollama-web-management) (Web management page)\n- [Promptery](https://github.com/promptery/promptery) (desktop client for Ollama.)\n- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)\n- [chat-ollama](https://github.com/annilq/chat-ollama) (a React Native client for Ollama)\n- [SpaceLlama](https://github.com/tcsenpai/spacellama) (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)\n- [YouLama](https://github.com/tcsenpai/youlama) (Webapp to quickly summarize any YouTube video, supporting Invidious as well)\n- [DualMind](https://github.com/tcsenpai/dualmind) (Experimental app allowing two models to talk to each other in the terminal or in a web interface)\n- [ollamarama-matrix](https://github.com/h1ddenpr0cess20/ollamarama-matrix) (Ollama chatbot for the Matrix chat protocol)\n- [ollama-chat-app](https://github.com/anan1213095357/ollama-chat-app) (Flutter-based chat app)\n- [Perfect Memory AI](https://www.perfectmemory.ai/) (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)\n- [Hexabot](https://github.com/hexastack/hexabot) (A conversational AI builder)\n- [Reddit Rate](https://github.com/rapidarchitect/reddit_analyzer) (Search and Rate Reddit topics with a weighted summation)\n- [OpenTalkGpt](https://github.com/adarshM84/OpenTalkGpt) (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)\n- [VT](https://github.com/vinhnx/vt.ai) (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)\n- [Nosia](https://github.com/nosia-ai/nosia) (Easy to install and use RAG platform based on Ollama)\n- [Witsy](https://github.com/nbonamy/witsy) (An AI Desktop application available for Mac/Windows/Linux)\n- [Abbey](https://github.com/US-Artificial-Intelligence/abbey) (A configurable AI interface server with notebooks, document storage, and YouTube support)\n- [Minima](https://github.com/dmayboroda/minima) (RAG with on-premises or fully local workflow)\n- [aidful-ollama-model-delete](https://github.com/AidfulAI/aidful-ollama-model-delete) (User interface for simplified model cleanup)\n- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) (An AI-powered search engine & an open-source alternative to Perplexity AI)\n- [Ollama Chat WebUI for Docker ](https://github.com/oslook/ollama-webui) (Support for local docker deployment, lightweight ollama webui)\n- [AI Toolkit for Visual Studio Code](https://aka.ms/ai-tooklit/ollama-docs) (Microsoft-official VS Code extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)\n- [MinimalNextOllamaChat](https://github.com/anilkay/MinimalNextOllamaChat) (Minimal Web UI for Chat and Model Control)\n- [Chipper](https://github.com/TilmanGriesel/chipper) AI interface for tinkerers (Ollama, Haystack RAG, Python)\n- [ChibiChat](https://github.com/CosmicEventHorizon/ChibiChat) (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)\n- [LocalLLM](https://github.com/qusaismael/localllm) (Minimal Web-App to run ollama models on it with a GUI)\n- [Ollamazing](https://github.com/buiducnhat/ollamazing) (Web extension to run Ollama models)\n- [OpenDeepResearcher-via-searxng](https://github.com/benhaotang/OpenDeepResearcher-via-searxng) (A Deep Research equivalent endpoint with Ollama support for running locally)\n- [AntSK](https://github.com/AIDotNet/AntSK) (Out-of-the-box & Adaptable RAG Chatbot)\n- [MaxKB](https://github.com/1Panel-dev/MaxKB/) (Ready-to-use & flexible RAG Chatbot)\n- [yla](https://github.com/danielekp/yla) (Web interface to freely interact with your customized models)\n- [LangBot](https://github.com/RockChinQ/LangBot) (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)\n- [1Panel](https://github.com/1Panel-dev/1Panel/) (Web-based Linux Server Management Tool)\n- [AstrBot](https://github.com/Soulter/AstrBot/) (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)\n- [Reins](https://github.com/ibrahimcetin/reins) (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)\n- [Flufy](https://github.com/Aharon-Bensadoun/Flufy) (A beautiful chat interface for interacting with Ollama's API. Built with React, TypeScript, and Material-UI.)\n- [Ellama](https://github.com/zeozeozeo/ellama) (Friendly native app to chat with an Ollama instance)\n- [screenpipe](https://github.com/mediar-ai/screenpipe) Build agents powered by your screen history\n- [Ollamb](https://github.com/hengkysteen/ollamb) (Simple yet rich in features, cross-platform built with Flutter and designed for Ollama. Try the [web demo](https://hengkysteen.github.io/demo/ollamb/).)\n- [Writeopia](https://github.com/Writeopia/Writeopia) (Text editor with integration with Ollama)\n- [AppFlowy](https://github.com/AppFlowy-IO/AppFlowy) (AI collaborative workspace with Ollama, cross-platform and self-hostable)\n- [Lumina](https://github.com/cushydigit/lumina.git) (A lightweight, minimal React.js frontend for interacting with Ollama servers)\n- [Tiny Notepad](https://pypi.org/project/tiny-notepad) (A lightweight, notepad-like interface to chat with ollama available on PyPI)\n- [macLlama (macOS native)](https://github.com/hellotunamayo/macLlama) (A native macOS GUI application for interacting with Ollama models, featuring a chat interface.)\n- [GPTranslate](https://github.com/philberndt/GPTranslate) (A fast and lightweight, AI powered desktop translation application written with Rust and Tauri. Features real-time translation with OpenAI/Azure/Ollama.)\n- [ollama launcher](https://github.com/NGC13009/ollama-launcher) (A launcher for Ollama, aiming to provide users with convenient functions such as ollama server launching, management, or configuration.)\n- [ai-hub](https://github.com/Aj-Seven/ai-hub) (AI Hub supports multiple models via API keys and Chat support via Ollama API.)\n- [Mayan EDMS](https://gitlab.com/mayan-edms/mayan-edms) (Open source document management system to organize, tag, search, and automate your files with powerful Ollama driven workflows.)\n- [Serene Pub](https://github.com/doolijb/serene-pub) (Beginner friendly, open source AI Roleplaying App for Windows, Mac OS and Linux. Search, download and use models with Ollama all inside the app.)\n- [Andes](https://github.com/aqerd/andes) (A Visual Studio Code extension that provides a local UI interface for Ollama models)\n- [KDeps](https://github.com/kdeps/kdeps) (Kdeps is an offline-first AI framework for building Dockerized full-stack AI applications declaratively using Apple PKL and integrates APIs with Ollama on the backend.)\n- [Clueless](https://github.com/KashyapTan/clueless) (Open Source & Local Cluely: A desktop application LLM assistant to help you talk to anything on your screen using locally served Ollama models. Also undetectable to screenshare)\n- [ollama-co2](https://github.com/carbonatedWaterOrg/ollama-co2) (FastAPI web interface for monitoring and managing local and remote Ollama servers with real-time model monitoring and concurrent downloads)\n- [Hillnote](https://hillnote.com) (A Markdown-first workspace designed to supercharge your AI workflow. Create documents ready to integrate with Claude, ChatGPT, Gemini, Cursor, and more - all while keeping your work on your device.)\n\n### Cloud\n\n- [Google Cloud](https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama)\n- [Fly.io](https://fly.io/docs/python/do-more/add-ollama/)\n- [Koyeb](https://www.koyeb.com/deploy/ollama)\n\n### Tutorial\n\n- [handy-ollama](https://github.com/datawhalechina/handy-ollama) (Chinese Tutorial for Ollama by [Datawhale ](https://github.com/datawhalechina) - China's Largest Open Source AI Learning Community)\n\n### Terminal\n\n- [oterm](https://github.com/ggozad/oterm)\n- [Ellama Emacs client](https://github.com/s-kostyaev/ellama)\n- [Emacs client](https://github.com/zweifisch/ollama)\n- [neollama](https://github.com/paradoxical-dev/neollama) UI client for interacting with models from within Neovim\n- [gen.nvim](https://github.com/David-Kunz/gen.nvim)\n- [ollama.nvim](https://github.com/nomnivore/ollama.nvim)\n- [ollero.nvim](https://github.com/marco-souza/ollero.nvim)\n- [ollama-chat.nvim](https://github.com/gerazov/ollama-chat.nvim)\n- [ogpt.nvim](https://github.com/huynle/ogpt.nvim)\n- [gptel Emacs client](https://github.com/karthink/gptel)\n- [Oatmeal](https://github.com/dustinblackman/oatmeal)\n- [cmdh](https://github.com/pgibler/cmdh)\n- [ooo](https://github.com/npahlfer/ooo)\n- [shell-pilot](https://github.com/reid41/shell-pilot)(Interact with models via pure shell scripts on Linux or macOS)\n- [tenere](https://github.com/pythops/tenere)\n- [llm-ollama](https://github.com/taketwo/llm-ollama) for [Datasette's LLM CLI](https://llm.datasette.io/en/stable/).\n- [typechat-cli](https://github.com/anaisbetts/typechat-cli)\n- [ShellOracle](https://github.com/djcopley/ShellOracle)\n- [tlm](https://github.com/yusufcanb/tlm)\n- [podman-ollama](https://github.com/ericcurtin/podman-ollama)\n- [gollama](https://github.com/sammcj/gollama)\n- [ParLlama](https://github.com/paulrobello/parllama)\n- [Ollama eBook Summary](https://github.com/cognitivetech/ollama-ebook-summary/)\n- [Ollama Mixture of Experts (MOE) in 50 lines of code](https://github.com/rapidarchitect/ollama_moe)\n- [vim-intelligence-bridge](https://github.com/pepo-ec/vim-intelligence-bridge) Simple interaction of \"Ollama\" with the Vim editor\n- [x-cmd ollama](https://x-cmd.com/mod/ollama)\n- [bb7](https://github.com/drunkwcodes/bb7)\n- [SwollamaCLI](https://github.com/marcusziade/Swollama) bundled with the Swollama Swift package. [Demo](https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage)\n- [aichat](https://github.com/sigoden/aichat) All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools & agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.\n- [PowershAI](https://github.com/rrg92/powershai) PowerShell module that brings AI to terminal on Windows, including support for Ollama\n- [DeepShell](https://github.com/Abyss-c0re/deepshell) Your self-hosted AI assistant. Interactive Shell, Files and Folders analysis.\n- [orbiton](https://github.com/xyproto/orbiton) Configuration-free text editor and IDE with support for tab completion with Ollama.\n- [orca-cli](https://github.com/molbal/orca-cli) Ollama Registry CLI Application - Browse, pull, and download models from Ollama Registry in your terminal.\n- [GGUF-to-Ollama](https://github.com/jonathanhecl/gguf-to-ollama) - Importing GGUF to Ollama made easy (multiplatform)\n- [AWS-Strands-With-Ollama](https://github.com/rapidarchitect/ollama_strands) - AWS Strands Agents with Ollama Examples\n- [ollama-multirun](https://github.com/attogram/ollama-multirun) - A bash shell script to run a single prompt against any or all of your locally installed ollama models, saving the output and performance statistics as easily navigable web pages. ([Demo](https://attogram.github.io/ai_test_zone/))\n- [ollama-bash-toolshed](https://github.com/attogram/ollama-bash-toolshed) - Bash scripts to chat with tool using models. Add new tools to your shed with ease. Runs on Ollama.\n- [hle-eval-ollama](https://github.com/mags0ft/hle-eval-ollama) - Runs benchmarks like \"Humanity's Last Exam\" (HLE) on your favorite local Ollama models and evaluates the quality of their responses\n- [VT Code](https://github.com/vinhnx/vtcode) - VT Code is a Rust-based terminal coding agent with semantic code intelligence via Tree-sitter. Ollama integration for running local/cloud models with configurable endpoints.\n\n### Apple Vision Pro\n\n- [SwiftChat](https://github.com/aws-samples/swift-chat) (Cross-platform AI chat app supporting Apple Vision Pro via \"Designed for iPad\")\n- [Enchanted](https://github.com/AugustDev/enchanted)\n\n### Database\n\n- [pgai](https://github.com/timescale/pgai) - PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector)\n  - [Get started guide](https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md)\n- [MindsDB](https://github.com/mindsdb/mindsdb/blob/staging/mindsdb/integrations/handlers/ollama_handler/README.md) (Connects Ollama models with nearly 200 data platforms and apps)\n- [chromem-go](https://github.com/philippgille/chromem-go/blob/v0.5.0/embed_ollama.go) with [example](https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama)\n- [Kangaroo](https://github.com/dbkangaroo/kangaroo) (AI-powered SQL client and admin tool for popular databases)\n\n### Package managers\n\n- [Pacman](https://archlinux.org/packages/extra/x86_64/ollama/)\n- [Gentoo](https://github.com/gentoo/guru/tree/master/app-misc/ollama)\n- [Homebrew](https://formulae.brew.sh/formula/ollama)\n- [Helm Chart](https://artifacthub.io/packages/helm/ollama-helm/ollama)\n- [Guix channel](https://codeberg.org/tusharhero/ollama-guix)\n- [Nix package](https://search.nixos.org/packages?show=ollama&from=0&size=50&sort=relevance&type=packages&query=ollama)\n- [Flox](https://flox.dev/blog/ollama-part-one)\n\n### Libraries\n\n- [LangChain](https://python.langchain.com/docs/integrations/chat/ollama/) and [LangChain.js](https://js.langchain.com/docs/integrations/chat/ollama/) with [example](https://js.langchain.com/docs/tutorials/local_rag/)\n- [Firebase Genkit](https://firebase.google.com/docs/genkit/plugins/ollama)\n- [crewAI](https://github.com/crewAIInc/crewAI)\n- [Yacana](https://remembersoftwares.github.io/yacana/) (User-friendly multi-agent framework for brainstorming and executing predetermined flows with built-in tool integration)\n- [Strands Agents](https://github.com/strands-agents/sdk-python) (A model-driven approach to building AI agents in just a few lines of code)\n- [Spring AI](https://github.com/spring-projects/spring-ai) with [reference](https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html) and [example](https://github.com/tzolov/ollama-tools)\n- [LangChainGo](https://github.com/tmc/langchaingo/) with [example](https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example)\n- [LangChain4j](https://github.com/langchain4j/langchain4j) with [example](https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java)\n- [LangChainRust](https://github.com/Abraxas-365/langchain-rust) with [example](https://github.com/Abraxas-365/langchain-rust/blob/main/examples/llm_ollama.rs)\n- [LangChain for .NET](https://github.com/tryAGI/LangChain) with [example](https://github.com/tryAGI/LangChain/blob/main/examples/LangChain.Samples.OpenAI/Program.cs)\n- [LLPhant](https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama)\n- [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/llm/ollama/) and [LlamaIndexTS](https://ts.llamaindex.ai/modules/llms/available_llms/ollama)\n- [LiteLLM](https://github.com/BerriAI/litellm)\n- [OllamaFarm for Go](https://github.com/presbrey/ollamafarm)\n- [OllamaSharp for .NET](https://github.com/awaescher/OllamaSharp)\n- [Ollama for Ruby](https://github.com/gbaptista/ollama-ai)\n- [Ollama-rs for Rust](https://github.com/pepperoni21/ollama-rs)\n- [Ollama-hpp for C++](https://github.com/jmont-dev/ollama-hpp)\n- [Ollama4j for Java](https://github.com/ollama4j/ollama4j)\n- [ModelFusion Typescript Library](https://modelfusion.dev/integration/model-provider/ollama)\n- [OllamaKit for Swift](https://github.com/kevinhermawan/OllamaKit)\n- [Ollama for Dart](https://github.com/breitburg/dart-ollama)\n- [Ollama for Laravel](https://github.com/cloudstudio/ollama-laravel)\n- [LangChainDart](https://github.com/davidmigloz/langchain_dart)\n- [Semantic Kernel - Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama)\n- [Haystack](https://github.com/deepset-ai/haystack-integrations/blob/main/integrations/ollama.md)\n- [Elixir LangChain](https://github.com/brainlid/langchain)\n- [Ollama for R - rollama](https://github.com/JBGruber/rollama)\n- [Ollama for R - ollama-r](https://github.com/hauselin/ollama-r)\n- [Ollama-ex for Elixir](https://github.com/lebrunel/ollama-ex)\n- [Ollama Connector for SAP ABAP](https://github.com/b-tocs/abap_btocs_ollama)\n- [Testcontainers](https://testcontainers.com/modules/ollama/)\n- [Portkey](https://portkey.ai/docs/welcome/integration-guides/ollama)\n- [PromptingTools.jl](https://github.com/svilupp/PromptingTools.jl) with an [example](https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama)\n- [LlamaScript](https://github.com/Project-Llama/llamascript)\n- [llm-axe](https://github.com/emirsahin1/llm-axe) (Python Toolkit for Building LLM Powered Apps)\n- [Gollm](https://docs.gollm.co/examples/ollama-example)\n- [Gollama for Golang](https://github.com/jonathanhecl/gollama)\n- [Ollamaclient for Golang](https://github.com/xyproto/ollamaclient)\n- [High-level function abstraction in Go](https://gitlab.com/tozd/go/fun)\n- [Ollama PHP](https://github.com/ArdaGnsrn/ollama-php)\n- [Agents-Flex for Java](https://github.com/agents-flex/agents-flex) with [example](https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama)\n- [Parakeet](https://github.com/parakeet-nest/parakeet) is a GoLang library, made to simplify the development of small generative AI applications with Ollama.\n- [Haverscript](https://github.com/andygill/haverscript) with [examples](https://github.com/andygill/haverscript/tree/main/examples)\n- [Ollama for Swift](https://github.com/mattt/ollama-swift)\n- [Swollama for Swift](https://github.com/guitaripod/Swollama) with [DocC](https://guitaripod.github.io/Swollama/documentation/swollama)\n- [GoLamify](https://github.com/prasad89/golamify)\n- [Ollama for Haskell](https://github.com/tusharad/ollama-haskell)\n- [multi-llm-ts](https://github.com/nbonamy/multi-llm-ts) (A Typescript/JavaScript library allowing access to different LLM in a unified API)\n- [LlmTornado](https://github.com/lofcz/llmtornado) (C# library providing a unified interface for major FOSS & Commercial inference APIs)\n- [Ollama for Zig](https://github.com/dravenk/ollama-zig)\n- [Abso](https://github.com/lunary-ai/abso) (OpenAI-compatible TypeScript SDK for any LLM provider)\n- [Nichey](https://github.com/goodreasonai/nichey) is a Python package for generating custom wikis for your research topic\n- [Ollama for D](https://github.com/kassane/ollama-d)\n- [OllamaPlusPlus](https://github.com/HardCodeDev777/OllamaPlusPlus) (Very simple C++ library for Ollama)\n- [any-llm](https://github.com/mozilla-ai/any-llm) (A single interface to use different llm providers by [mozilla.ai](https://www.mozilla.ai/))\n- [any-agent](https://github.com/mozilla-ai/any-agent) (A single interface to use and evaluate different agent frameworks by [mozilla.ai](https://www.mozilla.ai/))\n- [Neuro SAN](https://github.com/cognizant-ai-lab/neuro-san-studio) (Data-driven multi-agent orchestration framework) with [example](https://github.com/cognizant-ai-lab/neuro-san-studio/blob/main/docs/user_guide.md#ollama)\n- [achatbot-go](https://github.com/ai-bot-pro/achatbot-go) a multimodal(text/audio/image) chatbot.\n- [Ollama Bash Lib](https://github.com/attogram/ollama-bash-lib) - A Bash Library for Ollama. Run LLM prompts straight from your shell, and more\n\n### Mobile\n\n- [SwiftChat](https://github.com/aws-samples/swift-chat) (Lightning-fast Cross-platform AI chat app with native UI for Android, iOS, and iPad)\n- [Enchanted](https://github.com/AugustDev/enchanted)\n- [Maid](https://github.com/Mobile-Artificial-Intelligence/maid)\n- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)\n- [Ollama Android Chat](https://github.com/sunshine0523/OllamaServer) (No need for Termux, start the Ollama service with one click on an Android device)\n- [Reins](https://github.com/ibrahimcetin/reins) (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)\n\n### Extensions & Plugins\n\n- [Raycast extension](https://github.com/MassimilianoPasquini97/raycast_ollama)\n- [Discollama](https://github.com/mxyng/discollama) (Discord bot inside the Ollama discord channel)\n- [Continue](https://github.com/continuedev/continue)\n- [Vibe](https://github.com/thewh1teagle/vibe) (Transcribe and analyze meetings with Ollama)\n- [Obsidian Ollama plugin](https://github.com/hinterdupfinger/obsidian-ollama)\n- [Logseq Ollama plugin](https://github.com/omagdy7/ollama-logseq)\n- [NotesOllama](https://github.com/andersrex/notesollama) (Apple Notes Ollama plugin)\n- [Dagger Chatbot](https://github.com/samalba/dagger-chatbot)\n- [Discord AI Bot](https://github.com/mekb-turtle/discord-ai-bot)\n- [Ollama Telegram Bot](https://github.com/ruecat/ollama-telegram)\n- [Hass Ollama Conversation](https://github.com/ej52/hass-ollama-conversation)\n- [Rivet plugin](https://github.com/abrenneke/rivet-plugin-ollama)\n- [Obsidian BMO Chatbot plugin](https://github.com/longy2k/obsidian-bmo-chatbot)\n- [Cliobot](https://github.com/herval/cliobot) (Telegram bot with Ollama support)\n- [Copilot for Obsidian plugin](https://github.com/logancyang/obsidian-copilot)\n- [Obsidian Local GPT plugin](https://github.com/pfrankov/obsidian-local-gpt)\n- [Open Interpreter](https://docs.openinterpreter.com/language-model-setup/local-models/ollama)\n- [Llama Coder](https://github.com/ex3ndr/llama-coder) (Copilot alternative using Ollama)\n- [Ollama Copilot](https://github.com/bernardo-bruning/ollama-copilot) (Proxy that allows you to use Ollama as a copilot like GitHub Copilot)\n- [twinny](https://github.com/rjmacarthy/twinny) (Copilot and Copilot chat alternative using Ollama)\n- [Wingman-AI](https://github.com/RussellCanfield/wingman-ai) (Copilot code and chat alternative using Ollama and Hugging Face)\n- [Page Assist](https://github.com/n4ze3m/page-assist) (Chrome Extension)\n- [Plasmoid Ollama Control](https://github.com/imoize/plasmoid-ollamacontrol) (KDE Plasma extension that allows you to quickly manage/control Ollama model)\n- [AI Telegram Bot](https://github.com/tusharhero/aitelegrambot) (Telegram bot using Ollama in backend)\n- [AI ST Completion](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) (Sublime Text 4 AI assistant plugin with Ollama support)\n- [Discord-Ollama Chat Bot](https://github.com/kevinthedang/discord-ollama) (Generalized TypeScript Discord Bot w/ Tuning Documentation)\n- [ChatGPTBox: All in one browser extension](https://github.com/josStorer/chatGPTBox) with [Integrating Tutorial](https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467)\n- [Discord AI chat/moderation bot](https://github.com/rapmd73/Companion) Chat/moderation bot written in python. Uses Ollama to create personalities.\n- [Headless Ollama](https://github.com/nischalj10/headless-ollama) (Scripts to automatically install ollama client & models on any OS for apps that depend on ollama server)\n- [Terraform AWS Ollama & Open WebUI](https://github.com/xuyangbocn/terraform-aws-self-host-llm) (A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front-end Open WebUI service.)\n- [node-red-contrib-ollama](https://github.com/jakubburkiewicz/node-red-contrib-ollama)\n- [Local AI Helper](https://github.com/ivostoykov/localAI) (Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)\n- [LSP-AI](https://github.com/SilasMarvin/lsp-ai) (Open-source language server for AI-powered functionality)\n- [QodeAssist](https://github.com/Palm1r/QodeAssist) (AI-powered coding assistant plugin for Qt Creator)\n- [Obsidian Quiz Generator plugin](https://github.com/ECuiDev/obsidian-quiz-generator)\n- [AI Summary Helper plugin](https://github.com/philffm/ai-summary-helper)\n- [TextCraft](https://github.com/suncloudsmoon/TextCraft) (Copilot in Word alternative using Ollama)\n- [Alfred Ollama](https://github.com/zeitlings/alfred-ollama) (Alfred Workflow)\n- [TextLLaMA](https://github.com/adarshM84/TextLLaMA) A Chrome Extension that helps you write emails, correct grammar, and translate into any language\n- [Simple-Discord-AI](https://github.com/zyphixor/simple-discord-ai)\n- [LLM Telegram Bot](https://github.com/innightwolfsleep/llm_telegram_bot) (telegram bot, primary for RP. Oobabooga-like buttons, [A1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui) API integration e.t.c)\n- [mcp-llm](https://github.com/sammcj/mcp-llm) (MCP Server to allow LLMs to call other LLMs)\n- [SimpleOllamaUnity](https://github.com/HardCodeDev777/SimpleOllamaUnity) (Unity Engine extension for communicating with Ollama in a few lines of code. Also works at runtime)\n- [UnityCodeLama](https://github.com/HardCodeDev777/UnityCodeLama) (Unity Editor tool to analyze scripts via Ollama)\n- [NativeMind](https://github.com/NativeMindBrowser/NativeMindExtension) (Private, on-device AI Assistant, no cloud dependencies)\n- [GMAI - Gradle Managed AI](https://gmai.premex.se/) (Gradle plugin for automated Ollama lifecycle management during build phases)\n- [NOMYO Router](https://github.com/nomyo-ai/nomyo-router) (A transparent Ollama proxy with model deployment aware routing which auto-manages multiple Ollama instances in a given network)\n\n### Supported backends\n\n- [llama.cpp](https://github.com/ggml-org/llama.cpp) project founded by Georgi Gerganov.\n\n### Observability\n\n- [Opik](https://www.comet.com/docs/opik/cookbook/ollama) is an open-source platform to debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards. Opik supports native integration to Ollama.\n- [Lunary](https://lunary.ai/docs/integrations/ollama) is the leading open-source LLM observability platform. It provides a variety of enterprise-grade features such as real-time analytics, prompt templates management, PII masking, and comprehensive agent tracing.\n- [OpenLIT](https://github.com/openlit/openlit) is an OpenTelemetry-native tool for monitoring Ollama Applications & GPUs using traces and metrics.\n- [HoneyHive](https://docs.honeyhive.ai/integrations/ollama) is an AI observability and evaluation platform for AI agents. Use HoneyHive to evaluate agent performance, interrogate failures, and monitor quality in production.\n- [Langfuse](https://langfuse.com/docs/integrations/ollama) is an open source LLM observability platform that enables teams to collaboratively monitor, evaluate and debug AI applications.\n- [MLflow Tracing](https://mlflow.org/docs/latest/llms/tracing/index.html#automatic-tracing) is an open source LLM observability tool with a convenient API to log and visualize traces, making it easy to debug and evaluate GenAI applications.\n\n### Security\n\n- [Ollama Fortress](https://github.com/ParisNeo/ollama_proxy_server)\n",
      "stars_today": 128
    },
    {
      "id": 965415649,
      "name": "codex",
      "full_name": "openai/codex",
      "description": "Lightweight coding agent that runs in your terminal",
      "html_url": "https://github.com/openai/codex",
      "stars": 56868,
      "forks": 7368,
      "language": "Rust",
      "topics": [],
      "created_at": "2025-04-13T05:37:54Z",
      "updated_at": "2026-01-23T02:03:28Z",
      "pushed_at": "2026-01-23T02:10:09Z",
      "open_issues": 875,
      "owner": {
        "login": "openai",
        "avatar_url": "https://avatars.githubusercontent.com/u/14957082?v=4"
      },
      "readme": "<p align=\"center\"><code>npm i -g @openai/codex</code><br />or <code>brew install --cask codex</code></p>\n<p align=\"center\"><strong>Codex CLI</strong> is a coding agent from OpenAI that runs locally on your computer.\n<p align=\"center\">\n  <img src=\"./.github/codex-cli-splash.png\" alt=\"Codex CLI splash\" width=\"80%\" />\n</p>\n</br>\nIf you want Codex in your code editor (VS Code, Cursor, Windsurf), <a href=\"https://developers.openai.com/codex/ide\">install in your IDE.</a>\n</br>If you are looking for the <em>cloud-based agent</em> from OpenAI, <strong>Codex Web</strong>, go to <a href=\"https://chatgpt.com/codex\">chatgpt.com/codex</a>.</p>\n\n---\n\n## Quickstart\n\n### Installing and running Codex CLI\n\nInstall globally with your preferred package manager:\n\n```shell\n# Install using npm\nnpm install -g @openai/codex\n```\n\n```shell\n# Install using Homebrew\nbrew install --cask codex\n```\n\nThen simply run `codex` to get started.\n\n<details>\n<summary>You can also go to the <a href=\"https://github.com/openai/codex/releases/latest\">latest GitHub Release</a> and download the appropriate binary for your platform.</summary>\n\nEach GitHub Release contains many executables, but in practice, you likely want one of these:\n\n- macOS\n  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`\n  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`\n- Linux\n  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`\n  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`\n\nEach archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.\n\n</details>\n\n### Using Codex with your ChatGPT plan\n\nRun `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what's included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).\n\nYou can also use Codex with an API key, but this requires [additional setup](https://developers.openai.com/codex/auth#sign-in-with-an-api-key).\n\n## Docs\n\n- [**Codex Documentation**](https://developers.openai.com/codex)\n- [**Contributing**](./docs/contributing.md)\n- [**Installing & building**](./docs/install.md)\n- [**Open source fund**](./docs/open-source-fund.md)\n\nThis repository is licensed under the [Apache-2.0 License](LICENSE).\n",
      "stars_today": 121
    },
    {
      "id": 1052259802,
      "name": "ralph-orchestrator",
      "full_name": "mikeyobrien/ralph-orchestrator",
      "description": "An improved implementation of the Ralph Wiggum technique for autonomous AI agent orchestration",
      "html_url": "https://github.com/mikeyobrien/ralph-orchestrator",
      "stars": 1230,
      "forks": 137,
      "language": "Rust",
      "topics": [
        "ai",
        "ai-agents",
        "ai-agents-framework",
        "ai-developer-tools",
        "claude-code",
        "claude-code-cli",
        "codex-cli",
        "development-tools",
        "development-workflow",
        "gemini-cli",
        "kiro",
        "kiro-cli",
        "opencode",
        "ralph-loop",
        "ralph-wiggum"
      ],
      "created_at": "2025-09-07T18:17:13Z",
      "updated_at": "2026-01-23T01:30:23Z",
      "pushed_at": "2026-01-22T22:49:37Z",
      "open_issues": 5,
      "owner": {
        "login": "mikeyobrien",
        "avatar_url": "https://avatars.githubusercontent.com/u/11792047?v=4"
      },
      "readme": "# Ralph Orchestrator\n\n[![License](https://img.shields.io/badge/license-MIT-blue)](LICENSE)\n[![Rust](https://img.shields.io/badge/rust-1.75+-orange)](https://www.rust-lang.org/)\n[![Build](https://img.shields.io/github/actions/workflow/status/mikeyobrien/ralph-orchestrator/ci.yml?branch=main&label=CI)](https://github.com/mikeyobrien/ralph-orchestrator/actions)\n[![Coverage](https://img.shields.io/badge/coverage-65%25-yellowgreen)](coverage/index.html)\n[![Mentioned in Awesome Claude Code](https://awesome.re/mentioned-badge.svg)](https://github.com/hesreallyhim/awesome-claude-code)\n[![Docs](https://img.shields.io/badge/docs-mkdocs-blue)](https://mikeyobrien.github.io/ralph-orchestrator/)\n\n\nA hat-based orchestration framework that keeps Ralph in a loop until the task is done.\n\n> \"Me fail English? That's unpossible!\" - Ralph Wiggum\n\n**Notice:** Ralph Orchestrator is under active development. It works today, but expect rough edges and breaking changes between releases.\n\nv1.0.0 was ralphed into existence with little oversight and guidance. v2.0.0 is a simpler, more-structured implementation. Looking for the old version? See [v1.2.3](https://github.com/mikeyobrien/ralph-orchestrator/tree/v1.2.3). \n\n<img width=\"912\" height=\"712\" alt=\"Screenshot 2026-01-20 at 10 27 57‚ÄØAM\" src=\"https://github.com/user-attachments/assets/91b08b47-8b0a-4e2c-b66e-88551c2c5cc6\" />\n\n## Table of Contents\n\n- [What is Ralph?](#what-is-ralph)\n- [Features](#features)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Configuration](#configuration)\n- [Custom Backends and Per-Hat Configuration](#custom-backends-and-per-hat-configuration)\n- [Presets](#presets)\n- [Key Concepts](#key-concepts)\n- [Orchestration and Coordination Patterns](#orchestration-and-coordination-patterns)\n- [CLI Reference](#cli-reference)\n- [Architecture](#architecture)\n- [Building & Testing](#building--testing)\n- [Contributing](#contributing)\n- [License](#license)\n- [Acknowledgments](#acknowledgments)\n\n## What is Ralph?\n\nRalph implements the [Ralph Wiggum technique](https://ghuntley.com/ralph/) ‚Äî autonomous task completion through continuous iteration.\n\n> \"The orchestrator is a thin coordination layer, not a platform. Ralph is smart; let Ralph do the work.\"\n\n### Two Modes of Operation\n\nRalph supports two orchestration styles:\n\n| Mode | Description | Best For |\n|------|-------------|----------|\n| **Traditional** | Simple loop ‚Äî Ralph iterates until done | Quick tasks, simple automation, minimal config |\n| **Hat-Based** | Ralph can wear many hats ‚Äî specialized personas coordinate through events | Complex workflows, multi-step processes, role separation |\n\n**Traditional mode** is the original Ralph Wiggum approach: start a loop, let it run until it outputs the completion promise. No roles, no events, just iteration.\n\n**Hat-based mode** adds structure: specialized personas coordinate through events. You define the roles that fit your workflow ‚Äî reviewers, testers, documenters, whatever makes sense. Presets provide ready-made patterns like TDD or spec-driven development.\n\n### The Ralph Tenets\n\n1. **Fresh Context Is Reliability** ‚Äî Each iteration clears context. Re-read specs, plan, code every cycle.\n2. **Backpressure Over Prescription** ‚Äî Don't prescribe how; create gates that reject bad work.\n3. **The Plan Is Disposable** ‚Äî Regeneration costs one planning loop. Cheap.\n4. **Disk Is State, Git Is Memory** ‚Äî Files are the handoff mechanism.\n5. **Steer With Signals, Not Scripts** ‚Äî Add signs, not scripts.\n6. **Let Ralph Ralph** ‚Äî Sit *on* the loop, not *in* it.\n\nSee [AGENTS.md](AGENTS.md) for the full philosophy.\n\n## Features\n\n- **Multi-Backend Support** ‚Äî Works with Claude Code, Kiro, Gemini CLI, Codex, Amp, Copilot CLI, and OpenCode\n- **Hat System** ‚Äî Specialized Ralph personas with distinct behaviors\n- **Event-Driven Coordination** ‚Äî Hats communicate through typed events with glob pattern matching\n- **Backpressure Enforcement** ‚Äî Gates that reject incomplete work (tests, lint, typecheck)\n- **Presets Library** ‚Äî 20+ pre-configured workflows for common development patterns\n- **Interactive TUI** ‚Äî Real-time terminal UI for monitoring Ralph's activity (enabled by default)\n- **Memories** ‚Äî Persistent learning across sessions stored in `.agent/memories.md`\n- **Tasks** ‚Äî Runtime work tracking stored in `.agent/tasks.jsonl`\n- **Session Recording** ‚Äî Record and replay sessions for debugging and testing (experimental)\n\n## Installation\n\n### Prerequisites\n\n- [Rust](https://rustup.rs/) 1.75+\n- At least one AI CLI:\n  - [Claude Code](https://github.com/anthropics/claude-code) (recommended)\n  - [Kiro](https://kiro.dev/)\n  - [Gemini CLI](https://github.com/google-gemini/gemini-cli)\n  - [Codex](https://github.com/openai/codex)\n  - [Amp](https://github.com/sourcegraph/amp)\n  - [Copilot CLI](https://docs.github.com/copilot) (`npm install -g @github/copilot`)\n  - [OpenCode](https://opencode.ai/) (`curl -fsSL https://opencode.ai/install | bash`)\n\n### Via npm (Recommended)\n\n```bash\n# Install globally\nnpm install -g @ralph-orchestrator/ralph-cli\n\n# Or run directly with npx\nnpx @ralph-orchestrator/ralph-cli --version\n```\n\n### Via Homebrew (macOS)\n\n```bash\nbrew install ralph-orchestrator\n```\n\n### Via Cargo\n\n```bash\ncargo install ralph-cli\n```\n\n### From Source\n\n```bash\ngit clone https://github.com/mikeyobrien/ralph-orchestrator.git\ncd ralph-orchestrator\ncargo build --release\n\n# Add to PATH\nexport PATH=\"$PATH:$(pwd)/target/release\"\n\n# Or create symlink\nsudo ln -s $(pwd)/target/release/ralph /usr/local/bin/ralph\n```\n\n### Verify Installation\n\n```bash\nralph --version\nralph --help\n```\n\n### Migrating from v1 (Python)\n\nIf you have the old Python-based Ralph v1 installed, uninstall it first to avoid conflicts:\n\n```bash\n# If installed via pip\npip uninstall ralph-orchestrator\n\n# If installed via pipx\npipx uninstall ralph-orchestrator\n\n# If installed via uv\nuv tool uninstall ralph-orchestrator\n\n# Verify removal\nwhich ralph  # Should return nothing or point to new Rust version\n```\n\nThe v1 Python version is no longer maintained. See [v1.2.3](https://github.com/mikeyobrien/ralph-orchestrator/tree/v1.2.3) for historical reference.\n\n## Quick Start\n\n### 1. Initialize a Project\n\n```bash\n# Traditional mode ‚Äî simple loop, no hats (recommended for getting started)\nralph init --backend claude\n\n# Hat-based mode ‚Äî use a preset workflow with specialized personas\nralph init --preset tdd-red-green\n\n# Combine preset with different backend\nralph init --preset spec-driven --backend kiro\n\n# See all available presets\nralph init --list-presets\n```\n\nThis creates `ralph.yml` in your current directory. Without a preset, you get traditional mode (no hats). With a preset, you get hat-based orchestration.\n\n### 2. Define Your Task\n\n**Option A:** Create a `PROMPT.md` file:\n\n```bash\ncat > PROMPT.md << 'EOF'\nBuild a REST API with the following endpoints:\n- POST /users - Create a new user\n- GET /users/:id - Get user by ID\n- PUT /users/:id - Update user\n- DELETE /users/:id - Delete user\n\nUse Express.js with TypeScript. Include input validation\nand proper error handling.\nEOF\n```\n\n**Option B:** Pass inline prompt when running:\n\n```bash\nralph run -p \"Add input validation to the user API endpoints\"\n```\n\n### 3. Run Ralph\n\n```bash\n# TUI mode (default) ‚Äî real-time terminal UI for monitoring\nralph run\n\n# With inline prompt\nralph run -p \"Implement the login endpoint with JWT authentication\"\n\n# Headless mode (no TUI)\nralph run --no-tui\n\n# Resume interrupted session\nralph run --continue\n\n# Dry run (show what would execute)\nralph run --dry-run\n```\n\n### Alternative: SOP-Driven Sessions\n\nFor standalone planning and task generation (without Ralph's event loop), use these commands:\n\n```bash\n# Start an interactive PDD planning session\nralph plan                           # SOP prompts for input\nralph plan \"build a REST API\"        # Provide idea inline\nralph plan --backend kiro \"my idea\"  # Use specific backend\n\n# Generate code task files from descriptions\nralph task                           # SOP prompts for input\nralph task \"add authentication\"      # From description\nralph task specs/feature/plan.md     # From PDD plan file\n```\n\nThese commands spawn an interactive AI session with bundled SOPs ‚Äî perfect for one-off planning without configuring a full workflow.\n\n## Configuration\n\nRalph uses a YAML configuration file (`ralph.yml` by default).\n\n### Traditional Mode (No Hats)\n\nThe simplest configuration ‚Äî just a loop that runs until completion:\n\n```yaml\n# ralph.yml ‚Äî Traditional mode\ncli:\n  backend: \"claude\"\n\nevent_loop:\n  completion_promise: \"LOOP_COMPLETE\"\n  max_iterations: 100\n```\n\nThis runs Ralph in a loop. No hats, no events, no role switching. Ralph iterates until it outputs `LOOP_COMPLETE` or hits the iteration limit.\n\n### Hat-Based Mode (Specialized Personas)\n\n> Ralph can wear many hats.\n\nAdd a `hats` section to enable role-based orchestration. Hats subscribe to events (triggers) and publish events when done:\n\n```yaml\n# ralph.yml ‚Äî Hat-based mode (example structure)\ncli:\n  backend: \"claude\"\n\nevent_loop:\n  completion_promise: \"LOOP_COMPLETE\"\n  max_iterations: 100\n  starting_event: \"task.start\"\n\nhats:\n  my_hat:\n    name: \"üéØ My Hat\"\n    triggers: [\"task.start\"]        # Events that activate this hat\n    publishes: [\"work.done\"]        # Events this hat can emit\n    instructions: |\n      Your instructions here...\n```\n\nWith hats, Ralph publishes a starting event, which triggers the matching hat. That hat does its work and publishes an event, potentially triggering other hats. This event-driven handoff continues until completion.\n\n> **Tip:** Use `ralph init --preset <name>` to get pre-configured hat workflows. See [Presets](#presets) for ready-made patterns like TDD, spec-driven development, and more.\n\n### Full Configuration Reference\n\n```yaml\n# Event loop settings\nevent_loop:\n  completion_promise: \"LOOP_COMPLETE\"  # Output that signals completion\n  max_iterations: 100                   # Maximum orchestration loops\n  max_runtime_seconds: 14400            # 4 hours max runtime\n  idle_timeout_secs: 1800               # 30 min idle timeout\n  starting_event: \"task.start\"          # First event published\n\n# CLI backend settings\ncli:\n  backend: \"claude\"                     # claude, kiro, gemini, codex, amp, copilot, opencode, custom\n  prompt_mode: \"arg\"                    # arg (CLI argument) or stdin\n\n# Core behaviors (always injected into prompts)\ncore:\n  scratchpad: \".agent/scratchpad.md\"    # Shared memory across iterations\n  specs_dir: \"./specs/\"                 # Directory for specifications\n  guardrails:                           # Rules injected into every prompt\n    - \"Fresh context each iteration - scratchpad is memory\"\n    - \"Don't assume 'not implemented' - search first\"\n    - \"Backpressure is law - tests/typecheck/lint must pass\"\n\n# Memories ‚Äî persistent learning across sessions (enabled by default)\nmemories:\n  enabled: true                         # Set false to disable\n  inject: auto                          # auto, manual, or none\n\n# Tasks ‚Äî runtime work tracking (enabled by default)\ntasks:\n  enabled: true                         # Set false to use scratchpad-only mode\n\n# Custom hats (omit to use default planner/builder)\nhats:\n  my_hat:\n    name: \"My Hat Name\"                 # Display name\n    triggers: [\"some.event\"]            # Events that activate this hat\n    publishes: [\"other.event\"]          # Events this hat can emit\n    instructions: |                     # Prompt instructions\n      What this hat should do...\n```\n\n\n## Custom Backends and Per-Hat Configuration\n\n### Custom Backends\n\nBeyond the built-in backends (Claude, Kiro, Gemini, Codex, Amp, Copilot, OpenCode), you can define custom backends to integrate any CLI-based AI agent:\n\n```yaml\ncli:\n  backend: \"custom\"\n  command: \"my-agent\"\n  args: [\"--headless\", \"--auto-approve\"]\n  prompt_mode: \"arg\"        # \"arg\" or \"stdin\"\n  prompt_flag: \"-p\"         # Optional: flag for prompt argument\n```\n\n| Field | Description |\n|-------|-------------|\n| `command` | The CLI command to execute |\n| `args` | Arguments inserted before the prompt |\n| `prompt_mode` | How to pass the prompt: `arg` (command-line argument) or `stdin` |\n| `prompt_flag` | Flag preceding the prompt (e.g., `-p`, `--prompt`). If omitted, prompt is positional. |\n\n### Per-Hat Backend Configuration\n\nDifferent hats can use different backends, enabling specialized tools for specialized tasks:\n\n```yaml\ncli:\n  backend: \"claude\"  # Default for Ralph and hats without explicit backend\n\nhats:\n  builder:\n    name: \"üî® Builder\"\n    description: \"Implements code\"\n    triggers: [\"build.task\"]\n    publishes: [\"build.done\"]\n    backend: \"claude\"        # Explicit: Claude for coding\n\n  researcher:\n    name: \"üîç Researcher\"\n    description: \"Researches technical questions\"\n    triggers: [\"research.task\"]\n    publishes: [\"research.done\"]\n    backend:                 # Kiro with custom agent (has MCP tools)\n      type: \"kiro\"\n      agent: \"researcher\"\n\n  reviewer:\n    name: \"üëÄ Reviewer\"\n    description: \"Reviews code changes\"\n    triggers: [\"review.task\"]\n    publishes: [\"review.done\"]\n    backend: \"gemini\"        # Different model for fresh perspective\n```\n\n**Backend Types:**\n\n| Type | Syntax | Invocation |\n|------|--------|------------|\n| Named | `backend: \"claude\"` | Uses standard backend configuration |\n| Kiro Agent | `backend: { type: \"kiro\", agent: \"builder\" }` | `kiro-cli --agent builder ...` |\n| Custom | `backend: { command: \"...\", args: [...] }` | Your custom command |\n\n**When to mix backends:**\n\n| Scenario | Recommended Backend |\n|----------|---------------------|\n| Complex coding | Claude (best reasoning) |\n| AWS/cloud tasks | Kiro with agent (MCP tools) |\n| Code review | Different model (fresh perspective) |\n| Internal tools | Custom backend |\n| Cost optimization | Faster/cheaper model for simple tasks |\n\nHats without explicit `backend` inherit from `cli.backend`.\n\n## Presets\n\nPresets are pre-configured workflows for common development patterns.\n\n### Development Workflows\n\n| Preset | Pattern | Description |\n|--------|---------|-------------|\n| `feature` | Planner-Builder | Standard feature development |\n| `feature-minimal` | Single hat | Minimal feature development |\n| `tdd-red-green` | Test-Implement-Refactor | TDD with red-green-refactor cycle |\n| `spec-driven` | Spec-Build-Verify | Specification-first development |\n| `refactor` | Analyze-Plan-Execute | Code refactoring workflow |\n\n### Debugging & Investigation\n\n| Preset | Pattern | Description |\n|--------|---------|-------------|\n| `debug` | Investigate-Fix-Verify | Bug investigation and fixing |\n| `incident-response` | Triage-Fix-Postmortem | Production incident handling |\n| `code-archaeology` | Explore-Document-Present | Legacy code understanding |\n\n### Review & Quality\n\n| Preset | Pattern | Description |\n|--------|---------|-------------|\n| `review` | Analyze-Critique-Suggest | Code review workflow |\n| `pr-review` | Multi-Perspective | PR review with specialized reviewers |\n| `adversarial-review` | Critic-Defender | Devil's advocate review style |\n\n### Documentation\n\n| Preset | Pattern | Description |\n|--------|---------|-------------|\n| `docs` | Write-Review-Publish | Documentation writing |\n| `documentation-first` | Doc-Implement-Sync | Doc-first development |\n\n### Specialized\n\n| Preset | Pattern | Description |\n|--------|---------|-------------|\n| `api-design` | Design-Implement-Document | API-first development |\n| `migration-safety` | Analyze-Migrate-Verify | Safe code migrations |\n| `performance-optimization` | Profile-Optimize-Benchmark | Performance tuning |\n| `scientific-method` | Hypothesis-Experiment-Conclude | Experimental approach |\n| `mob-programming` | Rotate roles | Simulated mob programming |\n| `socratic-learning` | Question-Answer-Synthesize | Learning through dialogue |\n| `research` | Gather-Analyze-Synthesize | Research and analysis |\n| `gap-analysis` | Current-Target-Plan | Gap identification |\n\n### Using Presets\n\n```bash\n# List all available presets\nralph init --list-presets\n\n# Initialize with a preset\nralph init --preset tdd-red-green\n\n# Use preset with different backend\nralph init --preset spec-driven --backend gemini\n\n# Override existing config\nralph init --preset debug --force\n```\n\n## Key Concepts\n\n### Hats\n\nHats are specialized Ralph personas. Each hat has:\n\n- **Triggers**: Events that activate this hat\n- **Publishes**: Events this hat can emit\n- **Instructions**: Prompt injected when hat is active\n\nView event history:\n\n```bash\nralph events\n```\n\n## Orchestration and Coordination Patterns\n\nRalph's hat system enables sophisticated multi-agent workflows through event-driven coordination. This section covers the architectural patterns, event routing mechanics, and built-in workflow templates.\n\n### How Hat-Based Orchestration Works\n\n#### The Event-Driven Model\n\nHats communicate through a **pub/sub event system**:\n\n1. **Ralph publishes a starting event** (e.g., `task.start`)\n2. **The matching hat activates** ‚Äî the hat subscribed to that event takes over\n3. **The hat does its work** and publishes an event when done\n4. **The next hat activates** ‚Äî triggered by the new event\n5. **The cycle continues** until a termination event or `LOOP_COMPLETE`\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  task.start ‚Üí [Test Writer] ‚Üí test.written ‚Üí [Implementer] ‚Üí   ‚îÇ\n‚îÇ  test.passing ‚Üí [Refactorer] ‚Üí refactor.done ‚îÄ‚îÄ‚îê                ‚îÇ\n‚îÇ                                                ‚îÇ                ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚Üí (loops back to Test Writer for next test)                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n#### Ralph as the Constant Coordinator\n\nIn hat-based mode, **Ralph is always present**:\n\n- Ralph cannot be removed or replaced\n- Custom hats define the **topology** (who triggers whom)\n- Ralph executes with **topology awareness** ‚Äî knowing which hats exist and their relationships\n- Ralph serves as the **universal fallback** ‚Äî orphaned events automatically route to Ralph\n\nThis means custom hats don't execute directly. Instead, Ralph reads all pending events across all hats and decides what to do based on the defined topology. Ralph then either:\n- Delegates to the appropriate hat by publishing an event\n- Handles the work directly if no hat is suited\n\n#### Event Routing and Topic Matching\n\nEvents route to hats using **glob-style pattern matching**:\n\n| Pattern | Matches |\n|---------|---------|\n| `task.start` | Exactly `task.start` |\n| `build.*` | `build.done`, `build.blocked`, `build.task`, etc. |\n| `*.done` | `build.done`, `review.done`, `test.done`, etc. |\n| `*` | Everything (global wildcard ‚Äî used by Ralph as fallback) |\n\n**Priority Rules:**\n- Specific patterns take precedence over wildcards\n- If multiple hats have specific subscriptions, that's an error (ambiguous routing)\n- Global wildcard (`*`) only triggers if no specific handler exists\n\n### Coordination Patterns\n\nRalph presets implement several proven coordination patterns:\n\n#### 1. Linear Pipeline\n\nThe simplest pattern ‚Äî work flows through a sequence of specialists.\n\n```\nInput ‚Üí Hat A ‚Üí Event ‚Üí Hat B ‚Üí Event ‚Üí Hat C ‚Üí Output\n```\n\n**Example: TDD Red-Green-Refactor** (`tdd-red-green.yml`)\n\n```yaml\nhats:\n  test_writer:\n    triggers: [\"tdd.start\", \"refactor.done\"]\n    publishes: [\"test.written\"]\n\n  implementer:\n    triggers: [\"test.written\"]\n    publishes: [\"test.passing\"]\n\n  refactorer:\n    triggers: [\"test.passing\"]\n    publishes: [\"refactor.done\", \"cycle.complete\"]\n```\n\n```\ntdd.start ‚Üí üî¥ Test Writer ‚Üí test.written ‚Üí üü¢ Implementer ‚Üí\ntest.passing ‚Üí üîµ Refactorer ‚Üí refactor.done ‚îÄ‚îê\n                                              ‚îÇ\n              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚îî‚îÄ‚îÄ‚Üí (back to Test Writer)\n```\n\n**When to use:** Workflows with clear sequential phases where each step builds on the previous.\n\n#### 2. Contract-First Pipeline\n\nA variant where work must pass validation gates before proceeding.\n\n**Example: Spec-Driven Development** (`spec-driven.yml`)\n\n```yaml\nhats:\n  spec_writer:\n    triggers: [\"spec.start\", \"spec.rejected\"]\n    publishes: [\"spec.ready\"]\n\n  spec_reviewer:\n    triggers: [\"spec.ready\"]\n    publishes: [\"spec.approved\", \"spec.rejected\"]\n\n  implementer:\n    triggers: [\"spec.approved\", \"spec.violated\"]\n    publishes: [\"implementation.done\"]\n\n  verifier:\n    triggers: [\"implementation.done\"]\n    publishes: [\"task.complete\", \"spec.violated\"]\n```\n\n```\nspec.start ‚Üí üìã Spec Writer ‚îÄ‚îÄ‚Üí spec.ready ‚îÄ‚îÄ‚Üí üîé Spec Critic\n                 ‚Üë                                   ‚îÇ\n                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ spec.rejected ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n                                                     ‚Üì\n                                               spec.approved\n                                                     ‚îÇ\n                                                     ‚Üì\ntask.complete ‚Üê‚îÄ‚îÄ ‚úÖ Verifier ‚Üê‚îÄ‚îÄ impl.done ‚Üê‚îÄ‚îÄ ‚öôÔ∏è Implementer\n                       ‚îÇ                              ‚Üë\n                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ spec.violated ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**When to use:** High-stakes changes where the spec must be rock-solid before implementation begins.\n\n#### 3. Cyclic Rotation\n\nMultiple roles take turns, each bringing a different perspective.\n\n**Example: Mob Programming** (`mob-programming.yml`)\n\n```yaml\nhats:\n  navigator:\n    triggers: [\"mob.start\", \"observation.noted\"]\n    publishes: [\"direction.set\", \"mob.complete\"]\n\n  driver:\n    triggers: [\"direction.set\"]\n    publishes: [\"code.written\"]\n\n  observer:\n    triggers: [\"code.written\"]\n    publishes: [\"observation.noted\"]\n```\n\n```\nmob.start ‚Üí üß≠ Navigator ‚Üí direction.set ‚Üí ‚å®Ô∏è Driver ‚Üí\ncode.written ‚Üí üëÅÔ∏è Observer ‚Üí observation.noted ‚îÄ‚îê\n                                                ‚îÇ\n              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚îî‚îÄ‚îÄ‚Üí (back to Navigator)\n```\n\n**When to use:** Complex features that benefit from multiple perspectives and continuous feedback.\n\n#### 4. Adversarial Review\n\nTwo roles with opposing objectives ensure robustness.\n\n**Example: Red Team / Blue Team** (`adversarial-review.yml`)\n\n```yaml\nhats:\n  builder:\n    name: \"üîµ Blue Team (Builder)\"\n    triggers: [\"security.review\", \"fix.applied\"]\n    publishes: [\"build.ready\"]\n\n  red_team:\n    name: \"üî¥ Red Team (Attacker)\"\n    triggers: [\"build.ready\"]\n    publishes: [\"vulnerability.found\", \"security.approved\"]\n\n  fixer:\n    triggers: [\"vulnerability.found\"]\n    publishes: [\"fix.applied\"]\n```\n\n```\nsecurity.review ‚Üí üîµ Blue Team ‚Üí build.ready ‚Üí üî¥ Red Team\n                      ‚Üë                            ‚îÇ\n                      ‚îÇ                            ‚îú‚îÄ‚Üí security.approved ‚úì\n                      ‚îÇ                            ‚îÇ\n                      ‚îÇ                            ‚îî‚îÄ‚Üí vulnerability.found\n                      ‚îÇ                                        ‚îÇ\n                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ fix.applied ‚Üê‚îÄ‚îÄ üõ°Ô∏è Fixer ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**When to use:** Security-sensitive code, authentication systems, or any code where adversarial thinking improves quality.\n\n#### 5. Hypothesis-Driven Investigation\n\nThe scientific method applied to debugging.\n\n**Example: Scientific Method** (`scientific-method.yml`)\n\n```yaml\nhats:\n  observer:\n    triggers: [\"science.start\", \"hypothesis.rejected\"]\n    publishes: [\"observation.made\"]\n\n  theorist:\n    triggers: [\"observation.made\"]\n    publishes: [\"hypothesis.formed\"]\n\n  experimenter:\n    triggers: [\"hypothesis.formed\"]\n    publishes: [\"hypothesis.confirmed\", \"hypothesis.rejected\"]\n\n  fixer:\n    triggers: [\"hypothesis.confirmed\"]\n    publishes: [\"fix.applied\"]\n```\n\n```\nscience.start ‚Üí üî¨ Observer ‚Üí observation.made ‚Üí üß† Theorist ‚Üí\nhypothesis.formed ‚Üí üß™ Experimenter ‚îÄ‚îÄ‚î¨‚îÄ‚Üí hypothesis.confirmed ‚Üí üîß Fixer\n                                      ‚îÇ\n                                      ‚îî‚îÄ‚Üí hypothesis.rejected ‚îÄ‚îê\n                                                               ‚îÇ\n              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚îî‚îÄ‚îÄ‚Üí (back to Observer with new data)\n```\n\n**When to use:** Complex bugs where the root cause isn't obvious. Forces systematic investigation over random fixes.\n\n#### 6. Coordinator-Specialist (Fan-Out)\n\nA coordinator delegates to specialists based on the work type.\n\n**Example: Gap Analysis** (`gap-analysis.yml`)\n\n```yaml\nhats:\n  analyzer:\n    triggers: [\"gap.start\", \"verify.complete\", \"report.complete\"]\n    publishes: [\"analyze.spec\", \"verify.request\", \"report.request\"]\n\n  verifier:\n    triggers: [\"analyze.spec\", \"verify.request\"]\n    publishes: [\"verify.complete\"]\n\n  reporter:\n    triggers: [\"report.request\"]\n    publishes: [\"report.complete\"]\n```\n\n```\n                    ‚îå‚îÄ‚Üí analyze.spec ‚îÄ‚îÄ‚Üí üîç Verifier ‚îÄ‚îÄ‚îê\n                    ‚îÇ                                  ‚îÇ\ngap.start ‚Üí üìä Analyzer ‚Üê‚îÄ‚îÄ verify.complete ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                    ‚îÇ\n                    ‚îî‚îÄ‚Üí report.request ‚îÄ‚îÄ‚Üí üìù Reporter ‚îÄ‚îÄ‚Üí report.complete\n```\n\n**When to use:** Work that naturally decomposes into independent specialist tasks (analysis, verification, reporting).\n\n#### 7. Adaptive Entry Point\n\nA bootstrapping hat detects input type and routes to the appropriate workflow.\n\n**Example: Code-Assist** (`code-assist.yml`)\n\n```yaml\nhats:\n  planner:\n    triggers: [\"build.start\"]\n    publishes: [\"tasks.ready\"]\n    # Detects: PDD directory vs. code task file vs. description\n\n  builder:\n    triggers: [\"tasks.ready\", \"validation.failed\", \"task.complete\"]\n    publishes: [\"implementation.ready\", \"task.complete\"]\n\n  validator:\n    triggers: [\"implementation.ready\"]\n    publishes: [\"validation.passed\", \"validation.failed\"]\n\n  committer:\n    triggers: [\"validation.passed\"]\n    publishes: [\"commit.complete\"]\n```\n\n```\nbuild.start ‚Üí üìã Planner ‚îÄ‚îÄ‚îÄ (detects input type) ‚îÄ‚îÄ‚îÄ‚Üí tasks.ready\n                                                            ‚îÇ\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n    ‚îÇ\n    ‚Üì\n‚öôÔ∏è Builder ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ validation.failed ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ                                               ‚îÇ\n    ‚îú‚îÄ‚îÄ task.complete ‚îÄ‚îÄ‚Üí (loop for PDD mode) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n    ‚îÇ                                               ‚îÇ\n    ‚îî‚îÄ‚îÄ implementation.ready ‚îÄ‚îÄ‚Üí ‚úÖ Validator ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n                                      ‚îÇ             ‚îÇ\n                                      ‚îî‚îÄ‚Üí validation.passed\n                                              ‚îÇ\n                                              ‚Üì\n                                        üì¶ Committer ‚Üí commit.complete\n```\n\n**When to use:** Workflows that need to handle multiple input formats or adapt their behavior based on context.\n\n### Designing Custom Hat Collections\n\n#### Hat Configuration Schema\n\n```yaml\nhats:\n  my_hat:\n    name: \"üéØ Display Name\"      # Shown in TUI and logs\n    description: \"What this hat does\"  # REQUIRED ‚Äî Ralph uses this for delegation\n    triggers: [\"event.a\", \"event.b\"]   # Events that activate this hat\n    publishes: [\"event.c\", \"event.d\"]  # Events this hat can emit\n    default_publishes: \"event.c\"       # Fallback if hat forgets to emit\n    max_activations: 10                # Optional cap on activations\n    backend: \"claude\"                  # Optional backend override\n    instructions: |\n      Prompt injected when this hat is active.\n      Tell the hat what to do, not how to do it.\n```\n\n#### Design Principles\n\n1. **Description is critical** ‚Äî Ralph uses hat descriptions to decide when to delegate. Make them clear and specific.\n\n2. **One hat, one responsibility** ‚Äî Each hat should have a clear, focused purpose. If you're writing \"and\" in the description, consider splitting.\n\n3. **Events are routing signals, not data** ‚Äî Keep payloads brief. Store detailed output in files and reference them in events.\n\n4. **Design for recovery** ‚Äî If a hat fails or forgets to publish, Ralph catches the orphaned event. Your topology should handle unexpected states gracefully.\n\n5. **Test with simple prompts first** ‚Äî Complex topologies can have emergent behavior. Start simple, validate the flow, then add complexity.\n\n#### Validation Rules\n\nRalph validates hat configurations:\n\n- **Required description**: Every hat must have a description (Ralph needs it for delegation context)\n- **Reserved triggers**: `task.start` and `task.resume` are reserved for Ralph\n- **No ambiguous routing**: Each trigger pattern must map to exactly one hat\n\n```\nERROR: Ambiguous routing for trigger 'build.done'.\nBoth 'planner' and 'reviewer' trigger on 'build.done'.\n```\n\n### Event Emission\n\nHats emit events to signal completion or hand off work:\n\n```bash\n# Simple event with payload\nralph emit \"build.done\" \"tests: pass, lint: pass\"\n\n# Event with JSON payload\nralph emit \"review.done\" --json '{\"status\": \"approved\", \"issues\": 0}'\n\n# Direct handoff to specific hat (bypasses routing)\nralph emit \"handoff\" --target reviewer \"Please review the changes\"\n```\n\n**In agent output**, events are embedded as XML tags:\n\n```xml\n<event topic=\"impl.done\">Implementation complete</event>\n<event topic=\"handoff\" target=\"reviewer\">Please review</event>\n```\n\n### Choosing a Pattern\n\n| Scenario | Recommended Pattern | Preset |\n|----------|---------------------|--------|\n| Sequential workflow with clear phases | Linear Pipeline | `tdd-red-green` |\n| Spec must be approved before coding | Contract-First | `spec-driven` |\n| Need multiple perspectives | Cyclic Rotation | `mob-programming` |\n| Security review required | Adversarial | `adversarial-review` |\n| Debugging complex issues | Hypothesis-Driven | `scientific-method` |\n| Work decomposes into specialist tasks | Coordinator-Specialist | `gap-analysis` |\n| Multiple input formats | Adaptive Entry | `code-assist` |\n| Standard feature development | Basic delegation | `feature` |\n\n### When Not to Use Hats\n\nHat-based orchestration adds complexity. Use **traditional mode** (no hats) when:\n\n- The task is straightforward and single-focused\n- You don't need role separation or handoffs\n- You're prototyping and want minimal configuration\n- The work doesn't naturally decompose into distinct phases\n\nTraditional mode is just Ralph in a loop until completion ‚Äî simpler, faster to set up, and often sufficient.\n\n### Memories and Tasks\n\nRalph uses two complementary systems for persistent state (both enabled by default):\n\n**Memories** (`.agent/memories.md`) ‚Äî Accumulated wisdom across sessions:\n- Codebase patterns and conventions discovered\n- Architectural decisions and rationale\n- Recurring problem solutions (fixes)\n- Project-specific context\n\n**Tasks** (`.agent/tasks.jsonl`) ‚Äî Runtime work tracking:\n- Create, list, and close tasks during orchestration\n- Track dependencies between tasks\n- Used for loop completion verification\n\nWhen memories and tasks are enabled, they replace the scratchpad for state management. Set `memories.enabled: false` and `tasks.enabled: false` to use the legacy scratchpad-only mode.\n\n### Scratchpad (Legacy Mode)\n\nWhen memories/tasks are disabled, all hats share `.agent/scratchpad.md` ‚Äî persistent memory across iterations. This enables hats to build on previous work rather than starting fresh.\n\nThe scratchpad is the primary mechanism for:\n- Task tracking (with `[ ]`, `[x]`, `[~]` markers)\n- Context preservation between iterations\n- Handoff between hats\n\n### Backpressure\n\nRalph enforces quality gates through backpressure. When a builder publishes `build.done`, it must include evidence:\n\n```\ntests: pass, lint: pass, typecheck: pass\n```\n\n## CLI Reference\n\n### Commands\n\n| Command | Description |\n|---------|-------------|\n| `ralph run` | Run the orchestration loop (default) |\n| `ralph resume` | Resume from existing scratchpad |\n| `ralph plan` | Start an interactive PDD planning session |\n| `ralph task` | Start an interactive code-task-generator session |\n| `ralph events` | View event history |\n| `ralph init` | Initialize configuration file |\n| `ralph clean` | Clean up `.agent/` directory |\n| `ralph emit` | Emit an event to the event log |\n| `ralph tools` | Runtime tools for memories and tasks (agent-facing) |\n\n### Global Options\n\n| Option | Description |\n|--------|-------------|\n| `-c, --config <FILE>` | Config file path (default: `ralph.yml`) |\n| `-v, --verbose` | Verbose output |\n| `--color <MODE>` | Color output: `auto`, `always`, `never` |\n\n### `ralph run` Options\n\n| Option | Description |\n|--------|-------------|\n| `-p, --prompt <TEXT>` | Inline prompt text |\n| `-P, --prompt-file <FILE>` | Prompt file path |\n| `--max-iterations <N>` | Override max iterations |\n| `--completion-promise <TEXT>` | Override completion trigger |\n| `--dry-run` | Show what would execute |\n| `--no-tui` | Disable TUI mode (TUI is enabled by default) |\n| `-a, --autonomous` | Force headless mode |\n| `--idle-timeout <SECS>` | TUI idle timeout (default: 30) |\n| `--record-session <FILE>` | Record session to JSONL |\n| `-q, --quiet` | Suppress output (for CI) |\n| `--continue` | Resume from existing scratchpad |\n\n### `ralph init` Options\n\n| Option | Description |\n|--------|-------------|\n| `--backend <NAME>` | Backend: `claude`, `kiro`, `gemini`, `codex`, `amp`, `copilot`, `opencode` |\n| `--preset <NAME>` | Use preset configuration |\n| `--list-presets` | List available presets |\n| `--force` | Overwrite existing config |\n\n### `ralph plan` Options\n\n| Option | Description |\n|--------|-------------|\n| `<IDEA>` | Optional rough idea to develop (SOP prompts if not provided) |\n| `-b, --backend <BACKEND>` | Backend to use (overrides config and auto-detection) |\n\n### `ralph task` Options\n\n| Option | Description |\n|--------|-------------|\n| `<INPUT>` | Optional description text or path to PDD plan file |\n| `-b, --backend <BACKEND>` | Backend to use (overrides config and auto-detection) |\n\n### `ralph tools` Subcommands\n\nThe `tools` command provides agent-facing utilities for runtime state management:\n\n```bash\n# Memory management (persistent learning)\nralph tools memory add \"content\" -t pattern --tags tag1,tag2\nralph tools memory search \"query\"\nralph tools memory list\nralph tools memory show <id>\nralph tools memory delete <id>\n\n# Task management (runtime tracking)\nralph tools task add \"Title\" -p 2              # Create task (priority 1-5)\nralph tools task add \"X\" --blocked-by Y        # With dependency\nralph tools task list                           # All tasks\nralph tools task ready                          # Unblocked tasks only\nralph tools task close <id>                     # Mark complete\n```\n\n## Architecture\n\nRalph is organized as a Cargo workspace with seven crates:\n\n| Crate | Purpose |\n|-------|---------|\n| `ralph-proto` | Protocol types: Event, Hat, Topic, Error |\n| `ralph-core` | Business logic: EventLoop, HatRegistry, Config |\n| `ralph-adapters` | CLI backend integrations (Claude, Kiro, Gemini, etc.) |\n| `ralph-tui` | Terminal UI with ratatui |\n| `ralph-cli` | Binary entry point and CLI parsing |\n| `ralph-e2e` | End-to-end test harness for backend validation |\n| `ralph-bench` | Benchmarking harness (dev-only) |\n\n## Building & Testing\n\n### Build\n\n```bash\ncargo build           # Debug build\ncargo build --release # Release build\n```\n\n### Test\n\n```bash\n# Run all tests (includes smoke tests with JSONL replay)\ncargo test\n\n# Run smoke tests specifically\ncargo test -p ralph-core smoke_runner\n\n# Run Kiro-specific smoke tests\ncargo test -p ralph-core kiro\n```\n\n### Smoke Tests\n\nSmoke tests use recorded JSONL fixtures instead of live API calls ‚Äî fast, free, and deterministic.\n\n**Fixture locations:**\n- `crates/ralph-core/tests/fixtures/basic_session.jsonl` ‚Äî Claude CLI session\n- `crates/ralph-core/tests/fixtures/kiro/` ‚Äî Kiro CLI sessions\n\n**Recording new fixtures:**\n\n```bash\n# Record a session\nralph run -c ralph.yml --record-session session.jsonl -p \"your prompt\"\n\n# Or capture raw CLI output\nclaude -p \"your prompt\" 2>&1 | tee output.txt\n```\n\n### Linting\n\n```bash\ncargo clippy --all-targets --all-features\ncargo fmt --check\n```\n\n## Contributing\n\nContributions are welcome! Please:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Write tests for new functionality\n4. Ensure `cargo test` passes\n5. Run `cargo clippy` and `cargo fmt`\n6. Commit your changes (`git commit -m 'Add amazing feature'`)\n7. Push to the branch (`git push origin feature/amazing-feature`)\n8. Open a Pull Request\n\nSee [AGENTS.md](AGENTS.md) for development philosophy and conventions.\n\n## License\n\nMIT License ‚Äî See [LICENSE](LICENSE) for details.\n\n## Acknowledgments\n\n- **[Geoffrey Huntley](https://ghuntley.com/ralph/)** ‚Äî Creator of the Ralph Wiggum technique\n- **[Harper Reed](https://harper.blog/)** ‚Äî Spec-driven development methodology\n- **[Strands Agent SOPs](https://github.com/strands-agents/agent-sop)** ‚Äî Natural language workflows that enable AI agents to perform complex, multi-step tasks with consistency and reliability. \n- **[ratatui](https://ratatui.rs/)** ‚Äî Terminal UI framework\n- **[portable-pty](https://crates.io/crates/portable-pty)** ‚Äî Cross-platform PTY support\n\n---\n\n*\"I'm learnding!\" - Ralph Wiggum*\n\n---\n\n[![Star History Chart](https://api.star-history.com/svg?repos=mikeyobrien/ralph-orchestrator&type=date&legend=top-left)](https://www.star-history.com/#mikeyobrien/ralph-orchestrator&type=date&legend=top-left)\n",
      "stars_today": 99
    },
    {
      "id": 340547520,
      "name": "zed",
      "full_name": "zed-industries/zed",
      "description": "Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.",
      "html_url": "https://github.com/zed-industries/zed",
      "stars": 73851,
      "forks": 6688,
      "language": "Rust",
      "topics": [
        "gpui",
        "rust-lang",
        "text-editor",
        "zed"
      ],
      "created_at": "2021-02-20T03:01:06Z",
      "updated_at": "2026-01-23T01:53:29Z",
      "pushed_at": "2026-01-23T01:53:26Z",
      "open_issues": 3390,
      "owner": {
        "login": "zed-industries",
        "avatar_url": "https://avatars.githubusercontent.com/u/79345384?v=4"
      },
      "readme": "# Zed\n\n[![Zed](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/zed-industries/zed/main/assets/badge/v0.json)](https://zed.dev)\n[![CI](https://github.com/zed-industries/zed/actions/workflows/run_tests.yml/badge.svg)](https://github.com/zed-industries/zed/actions/workflows/run_tests.yml)\n\nWelcome to Zed, a high-performance, multiplayer code editor from the creators of [Atom](https://github.com/atom/atom) and [Tree-sitter](https://github.com/tree-sitter/tree-sitter).\n\n---\n\n### Installation\n\nOn macOS, Linux, and Windows you can [download Zed directly](https://zed.dev/download) or install Zed via your local package manager ([macOS](https://zed.dev/docs/installation#macos)/[Linux](https://zed.dev/docs/linux#installing-via-a-package-manager)/[Windows](https://zed.dev/docs/windows#package-managers)).\n\nOther platforms are not yet available:\n\n- Web ([tracking issue](https://github.com/zed-industries/zed/issues/5396))\n\n### Developing Zed\n\n- [Building Zed for macOS](./docs/src/development/macos.md)\n- [Building Zed for Linux](./docs/src/development/linux.md)\n- [Building Zed for Windows](./docs/src/development/windows.md)\n\n### Contributing\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for ways you can contribute to Zed.\n\nAlso... we're hiring! Check out our [jobs](https://zed.dev/jobs) page for open roles.\n\n### Licensing\n\nLicense information for third party dependencies must be correctly provided for CI to pass.\n\nWe use [`cargo-about`](https://github.com/EmbarkStudios/cargo-about) to automatically comply with open source licenses. If CI is failing, check the following:\n\n- Is it showing a `no license specified` error for a crate you've created? If so, add `publish = false` under `[package]` in your crate's Cargo.toml.\n- Is the error `failed to satisfy license requirements` for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license's requirements. If you're unsure, ask a lawyer. Once you've verified that this system is acceptable add the license's SPDX identifier to the `accepted` array in `script/licenses/zed-licenses.toml`.\n- Is `cargo-about` unable to find the license for a dependency? If so, add a clarification field at the end of `script/licenses/zed-licenses.toml`, as specified in the [cargo-about book](https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration).\n\n## Sponsorship\n\nZed is developed by **Zed Industries, Inc.**, a for-profit company.\n\nIf you‚Äôd like to financially support the project, you can do so via GitHub Sponsors.\nSponsorships go directly to Zed Industries and are used as general company revenue.\nThere are no perks or entitlements associated with sponsorship.\n",
      "stars_today": 88
    },
    {
      "id": 612354784,
      "name": "llama.cpp",
      "full_name": "ggml-org/llama.cpp",
      "description": "LLM inference in C/C++",
      "html_url": "https://github.com/ggml-org/llama.cpp",
      "stars": 93542,
      "forks": 14577,
      "language": "C++",
      "topics": [
        "ggml"
      ],
      "created_at": "2023-03-10T18:58:00Z",
      "updated_at": "2026-01-23T01:44:01Z",
      "pushed_at": "2026-01-22T23:00:37Z",
      "open_issues": 1031,
      "owner": {
        "login": "ggml-org",
        "avatar_url": "https://avatars.githubusercontent.com/u/134263123?v=4"
      },
      "readme": "# llama.cpp\n\n![llama](https://user-images.githubusercontent.com/1991296/230134379-7181e485-c521-4d23-a0d6-f7b3b61ba524.png)\n\n[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![Release](https://img.shields.io/github/v/release/ggml-org/llama.cpp)](https://github.com/ggml-org/llama.cpp/releases)\n[![Server](https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml/badge.svg)](https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml)\n\n[Manifesto](https://github.com/ggml-org/llama.cpp/discussions/205) / [ggml](https://github.com/ggml-org/ggml) / [ops](https://github.com/ggml-org/llama.cpp/blob/master/docs/ops.md)\n\nLLM inference in C/C++\n\n## Recent API changes\n\n- [Changelog for `libllama` API](https://github.com/ggml-org/llama.cpp/issues/9289)\n- [Changelog for `llama-server` REST API](https://github.com/ggml-org/llama.cpp/issues/9291)\n\n## Hot topics\n\n- **[guide : using the new WebUI of llama.cpp](https://github.com/ggml-org/llama.cpp/discussions/16938)**\n- [guide : running gpt-oss with llama.cpp](https://github.com/ggml-org/llama.cpp/discussions/15396)\n- [[FEEDBACK] Better packaging for llama.cpp to support downstream consumers ü§ó](https://github.com/ggml-org/llama.cpp/discussions/15313)\n- Support for the `gpt-oss` model with native MXFP4 format has been added | [PR](https://github.com/ggml-org/llama.cpp/pull/15091) | [Collaboration with NVIDIA](https://blogs.nvidia.com/blog/rtx-ai-garage-openai-oss) | [Comment](https://github.com/ggml-org/llama.cpp/discussions/15095)\n- Multimodal support arrived in `llama-server`: [#12898](https://github.com/ggml-org/llama.cpp/pull/12898) | [documentation](./docs/multimodal.md)\n- VS Code extension for FIM completions: https://github.com/ggml-org/llama.vscode\n- Vim/Neovim plugin for FIM completions: https://github.com/ggml-org/llama.vim\n- Hugging Face Inference Endpoints now support GGUF out of the box! https://github.com/ggml-org/llama.cpp/discussions/9669\n- Hugging Face GGUF editor: [discussion](https://github.com/ggml-org/llama.cpp/discussions/9268) | [tool](https://huggingface.co/spaces/CISCai/gguf-editor)\n\n----\n\n## Quick start\n\nGetting started with llama.cpp is straightforward. Here are several ways to install it on your machine:\n\n- Install `llama.cpp` using [brew, nix or winget](docs/install.md)\n- Run with Docker - see our [Docker documentation](docs/docker.md)\n- Download pre-built binaries from the [releases page](https://github.com/ggml-org/llama.cpp/releases)\n- Build from source by cloning this repository - check out [our build guide](docs/build.md)\n\nOnce installed, you'll need a model to work with. Head to the [Obtaining and quantizing models](#obtaining-and-quantizing-models) section to learn more.\n\nExample command:\n\n```sh\n# Use a local model file\nllama-cli -m my_model.gguf\n\n# Or download and run a model directly from Hugging Face\nllama-cli -hf ggml-org/gemma-3-1b-it-GGUF\n\n# Launch OpenAI-compatible API server\nllama-server -hf ggml-org/gemma-3-1b-it-GGUF\n```\n\n## Description\n\nThe main goal of `llama.cpp` is to enable LLM inference with minimal setup and state-of-the-art performance on a wide\nrange of hardware - locally and in the cloud.\n\n- Plain C/C++ implementation without any dependencies\n- Apple silicon is a first-class citizen - optimized via ARM NEON, Accelerate and Metal frameworks\n- AVX, AVX2, AVX512 and AMX support for x86 architectures\n- RVV, ZVFH, ZFH, ZICBOP and ZIHINTPAUSE support for RISC-V architectures\n- 1.5-bit, 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit integer quantization for faster inference and reduced memory use\n- Custom CUDA kernels for running LLMs on NVIDIA GPUs (support for AMD GPUs via HIP and Moore Threads GPUs via MUSA)\n- Vulkan and SYCL backend support\n- CPU+GPU hybrid inference to partially accelerate models larger than the total VRAM capacity\n\nThe `llama.cpp` project is the main playground for developing new features for the [ggml](https://github.com/ggml-org/ggml) library.\n\n<details>\n<summary>Models</summary>\n\nTypically finetunes of the base models below are supported as well.\n\nInstructions for adding support for new models: [HOWTO-add-model.md](docs/development/HOWTO-add-model.md)\n\n#### Text-only\n\n- [X] LLaMA ü¶ô\n- [x] LLaMA 2 ü¶ôü¶ô\n- [x] LLaMA 3 ü¶ôü¶ôü¶ô\n- [X] [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.1)\n- [x] [Mixtral MoE](https://huggingface.co/models?search=mistral-ai/Mixtral)\n- [x] [DBRX](https://huggingface.co/databricks/dbrx-instruct)\n- [x] [Jamba](https://huggingface.co/ai21labs)\n- [X] [Falcon](https://huggingface.co/models?search=tiiuae/falcon)\n- [X] [Chinese LLaMA / Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) and [Chinese LLaMA-2 / Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)\n- [X] [Vigogne (French)](https://github.com/bofenghuang/vigogne)\n- [X] [BERT](https://github.com/ggml-org/llama.cpp/pull/5423)\n- [X] [Koala](https://bair.berkeley.edu/blog/2023/04/03/koala/)\n- [X] [Baichuan 1 & 2](https://huggingface.co/models?search=baichuan-inc/Baichuan) + [derivations](https://huggingface.co/hiyouga/baichuan-7b-sft)\n- [X] [Aquila 1 & 2](https://huggingface.co/models?search=BAAI/Aquila)\n- [X] [Starcoder models](https://github.com/ggml-org/llama.cpp/pull/3187)\n- [X] [Refact](https://huggingface.co/smallcloudai/Refact-1_6B-fim)\n- [X] [MPT](https://github.com/ggml-org/llama.cpp/pull/3417)\n- [X] [Bloom](https://github.com/ggml-org/llama.cpp/pull/3553)\n- [x] [Yi models](https://huggingface.co/models?search=01-ai/Yi)\n- [X] [StableLM models](https://huggingface.co/stabilityai)\n- [x] [Deepseek models](https://huggingface.co/models?search=deepseek-ai/deepseek)\n- [x] [Qwen models](https://huggingface.co/models?search=Qwen/Qwen)\n- [x] [PLaMo-13B](https://github.com/ggml-org/llama.cpp/pull/3557)\n- [x] [Phi models](https://huggingface.co/models?search=microsoft/phi)\n- [x] [PhiMoE](https://github.com/ggml-org/llama.cpp/pull/11003)\n- [x] [GPT-2](https://huggingface.co/gpt2)\n- [x] [Orion 14B](https://github.com/ggml-org/llama.cpp/pull/5118)\n- [x] [InternLM2](https://huggingface.co/models?search=internlm2)\n- [x] [CodeShell](https://github.com/WisdomShell/codeshell)\n- [x] [Gemma](https://ai.google.dev/gemma)\n- [x] [Mamba](https://github.com/state-spaces/mamba)\n- [x] [Grok-1](https://huggingface.co/keyfan/grok-1-hf)\n- [x] [Xverse](https://huggingface.co/models?search=xverse)\n- [x] [Command-R models](https://huggingface.co/models?search=CohereForAI/c4ai-command-r)\n- [x] [SEA-LION](https://huggingface.co/models?search=sea-lion)\n- [x] [GritLM-7B](https://huggingface.co/GritLM/GritLM-7B) + [GritLM-8x7B](https://huggingface.co/GritLM/GritLM-8x7B)\n- [x] [OLMo](https://allenai.org/olmo)\n- [x] [OLMo 2](https://allenai.org/olmo)\n- [x] [OLMoE](https://huggingface.co/allenai/OLMoE-1B-7B-0924)\n- [x] [Granite models](https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330)\n- [x] [GPT-NeoX](https://github.com/EleutherAI/gpt-neox) + [Pythia](https://github.com/EleutherAI/pythia)\n- [x] [Snowflake-Arctic MoE](https://huggingface.co/collections/Snowflake/arctic-66290090abe542894a5ac520)\n- [x] [Smaug](https://huggingface.co/models?search=Smaug)\n- [x] [Poro 34B](https://huggingface.co/LumiOpen/Poro-34B)\n- [x] [Bitnet b1.58 models](https://huggingface.co/1bitLLM)\n- [x] [Flan T5](https://huggingface.co/models?search=flan-t5)\n- [x] [Open Elm models](https://huggingface.co/collections/apple/openelm-instruct-models-6619ad295d7ae9f868b759ca)\n- [x] [ChatGLM3-6b](https://huggingface.co/THUDM/chatglm3-6b) + [ChatGLM4-9b](https://huggingface.co/THUDM/glm-4-9b) + [GLMEdge-1.5b](https://huggingface.co/THUDM/glm-edge-1.5b-chat) + [GLMEdge-4b](https://huggingface.co/THUDM/glm-edge-4b-chat)\n- [x] [GLM-4-0414](https://huggingface.co/collections/THUDM/glm-4-0414-67f3cbcb34dd9d252707cb2e)\n- [x] [SmolLM](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966)\n- [x] [EXAONE-3.0-7.8B-Instruct](https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct)\n- [x] [FalconMamba Models](https://huggingface.co/collections/tiiuae/falconmamba-7b-66b9a580324dd1598b0f6d4a)\n- [x] [Jais](https://huggingface.co/inceptionai/jais-13b-chat)\n- [x] [Bielik-11B-v2.3](https://huggingface.co/collections/speakleash/bielik-11b-v23-66ee813238d9b526a072408a)\n- [x] [RWKV-6](https://github.com/BlinkDL/RWKV-LM)\n- [x] [QRWKV-6](https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1)\n- [x] [GigaChat-20B-A3B](https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct)\n- [X] [Trillion-7B-preview](https://huggingface.co/trillionlabs/Trillion-7B-preview)\n- [x] [Ling models](https://huggingface.co/collections/inclusionAI/ling-67c51c85b34a7ea0aba94c32)\n- [x] [LFM2 models](https://huggingface.co/collections/LiquidAI/lfm2-686d721927015b2ad73eaa38)\n- [x] [Hunyuan models](https://huggingface.co/collections/tencent/hunyuan-dense-model-6890632cda26b19119c9c5e7)\n- [x] [BailingMoeV2 (Ring/Ling 2.0) models](https://huggingface.co/collections/inclusionAI/ling-v2-68bf1dd2fc34c306c1fa6f86)\n\n#### Multimodal\n\n- [x] [LLaVA 1.5 models](https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e), [LLaVA 1.6 models](https://huggingface.co/collections/liuhaotian/llava-16-65b9e40155f60fd046a5ccf2)\n- [x] [BakLLaVA](https://huggingface.co/models?search=SkunkworksAI/Bakllava)\n- [x] [Obsidian](https://huggingface.co/NousResearch/Obsidian-3B-V0.5)\n- [x] [ShareGPT4V](https://huggingface.co/models?search=Lin-Chen/ShareGPT4V)\n- [x] [MobileVLM 1.7B/3B models](https://huggingface.co/models?search=mobileVLM)\n- [x] [Yi-VL](https://huggingface.co/models?search=Yi-VL)\n- [x] [Mini CPM](https://huggingface.co/models?search=MiniCPM)\n- [x] [Moondream](https://huggingface.co/vikhyatk/moondream2)\n- [x] [Bunny](https://github.com/BAAI-DCAI/Bunny)\n- [x] [GLM-EDGE](https://huggingface.co/models?search=glm-edge)\n- [x] [Qwen2-VL](https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d)\n- [x] [LFM2-VL](https://huggingface.co/collections/LiquidAI/lfm2-vl-68963bbc84a610f7638d5ffa)\n\n</details>\n\n<details>\n<summary>Bindings</summary>\n\n- Python: [ddh0/easy-llama](https://github.com/ddh0/easy-llama)\n- Python: [abetlen/llama-cpp-python](https://github.com/abetlen/llama-cpp-python)\n- Go: [go-skynet/go-llama.cpp](https://github.com/go-skynet/go-llama.cpp)\n- Node.js: [withcatai/node-llama-cpp](https://github.com/withcatai/node-llama-cpp)\n- JS/TS (llama.cpp server client): [lgrammel/modelfusion](https://modelfusion.dev/integration/model-provider/llamacpp)\n- JS/TS (Programmable Prompt Engine CLI): [offline-ai/cli](https://github.com/offline-ai/cli)\n- JavaScript/Wasm (works in browser): [tangledgroup/llama-cpp-wasm](https://github.com/tangledgroup/llama-cpp-wasm)\n- Typescript/Wasm (nicer API, available on npm): [ngxson/wllama](https://github.com/ngxson/wllama)\n- Ruby: [yoshoku/llama_cpp.rb](https://github.com/yoshoku/llama_cpp.rb)\n- Rust (more features): [edgenai/llama_cpp-rs](https://github.com/edgenai/llama_cpp-rs)\n- Rust (nicer API): [mdrokz/rust-llama.cpp](https://github.com/mdrokz/rust-llama.cpp)\n- Rust (more direct bindings): [utilityai/llama-cpp-rs](https://github.com/utilityai/llama-cpp-rs)\n- Rust (automated build from crates.io): [ShelbyJenkins/llm_client](https://github.com/ShelbyJenkins/llm_client)\n- C#/.NET: [SciSharp/LLamaSharp](https://github.com/SciSharp/LLamaSharp)\n- C#/VB.NET (more features - community license): [LM-Kit.NET](https://docs.lm-kit.com/lm-kit-net/index.html)\n- Scala 3: [donderom/llm4s](https://github.com/donderom/llm4s)\n- Clojure: [phronmophobic/llama.clj](https://github.com/phronmophobic/llama.clj)\n- React Native: [mybigday/llama.rn](https://github.com/mybigday/llama.rn)\n- Java: [kherud/java-llama.cpp](https://github.com/kherud/java-llama.cpp)\n- Java: [QuasarByte/llama-cpp-jna](https://github.com/QuasarByte/llama-cpp-jna)\n- Zig: [deins/llama.cpp.zig](https://github.com/Deins/llama.cpp.zig)\n- Flutter/Dart: [netdur/llama_cpp_dart](https://github.com/netdur/llama_cpp_dart)\n- Flutter: [xuegao-tzx/Fllama](https://github.com/xuegao-tzx/Fllama)\n- PHP (API bindings and features built on top of llama.cpp): [distantmagic/resonance](https://github.com/distantmagic/resonance) [(more info)](https://github.com/ggml-org/llama.cpp/pull/6326)\n- Guile Scheme: [guile_llama_cpp](https://savannah.nongnu.org/projects/guile-llama-cpp)\n- Swift [srgtuszy/llama-cpp-swift](https://github.com/srgtuszy/llama-cpp-swift)\n- Swift [ShenghaiWang/SwiftLlama](https://github.com/ShenghaiWang/SwiftLlama)\n- Delphi [Embarcadero/llama-cpp-delphi](https://github.com/Embarcadero/llama-cpp-delphi)\n- Go (no CGo needed): [hybridgroup/yzma](https://github.com/hybridgroup/yzma)\n- Android: [llama.android](/examples/llama.android)\n\n</details>\n\n<details>\n<summary>UIs</summary>\n\n*(to have a project listed here, it should clearly state that it depends on `llama.cpp`)*\n\n- [AI Sublime Text plugin](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) (MIT)\n- [BonzAI App](https://apps.apple.com/us/app/bonzai-your-local-ai-agent/id6752847988) (proprietary)\n- [cztomsik/ava](https://github.com/cztomsik/ava) (MIT)\n- [Dot](https://github.com/alexpinel/Dot) (GPL)\n- [eva](https://github.com/ylsdamxssjxxdd/eva) (MIT)\n- [iohub/collama](https://github.com/iohub/coLLaMA) (Apache-2.0)\n- [janhq/jan](https://github.com/janhq/jan) (AGPL)\n- [johnbean393/Sidekick](https://github.com/johnbean393/Sidekick) (MIT)\n- [KanTV](https://github.com/zhouwg/kantv?tab=readme-ov-file) (Apache-2.0)\n- [KodiBot](https://github.com/firatkiral/kodibot) (GPL)\n- [llama.vim](https://github.com/ggml-org/llama.vim) (MIT)\n- [LARS](https://github.com/abgulati/LARS) (AGPL)\n- [Llama Assistant](https://github.com/vietanhdev/llama-assistant) (GPL)\n- [LLMFarm](https://github.com/guinmoon/LLMFarm?tab=readme-ov-file) (MIT)\n- [LLMUnity](https://github.com/undreamai/LLMUnity) (MIT)\n- [LMStudio](https://lmstudio.ai/) (proprietary)\n- [LocalAI](https://github.com/mudler/LocalAI) (MIT)\n- [LostRuins/koboldcpp](https://github.com/LostRuins/koboldcpp) (AGPL)\n- [MindMac](https://mindmac.app) (proprietary)\n- [MindWorkAI/AI-Studio](https://github.com/MindWorkAI/AI-Studio) (FSL-1.1-MIT)\n- [Mobile-Artificial-Intelligence/maid](https://github.com/Mobile-Artificial-Intelligence/maid) (MIT)\n- [Mozilla-Ocho/llamafile](https://github.com/Mozilla-Ocho/llamafile) (Apache-2.0)\n- [nat/openplayground](https://github.com/nat/openplayground) (MIT)\n- [nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all) (MIT)\n- [ollama/ollama](https://github.com/ollama/ollama) (MIT)\n- [oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) (AGPL)\n- [PocketPal AI](https://github.com/a-ghorbani/pocketpal-ai) (MIT)\n- [psugihara/FreeChat](https://github.com/psugihara/FreeChat) (MIT)\n- [ptsochantaris/emeltal](https://github.com/ptsochantaris/emeltal) (MIT)\n- [pythops/tenere](https://github.com/pythops/tenere) (AGPL)\n- [ramalama](https://github.com/containers/ramalama) (MIT)\n- [semperai/amica](https://github.com/semperai/amica) (MIT)\n- [withcatai/catai](https://github.com/withcatai/catai) (MIT)\n- [Autopen](https://github.com/blackhole89/autopen) (GPL)\n\n</details>\n\n<details>\n<summary>Tools</summary>\n\n- [akx/ggify](https://github.com/akx/ggify) ‚Äì download PyTorch models from HuggingFace Hub and convert them to GGML\n- [akx/ollama-dl](https://github.com/akx/ollama-dl) ‚Äì download models from the Ollama library to be used directly with llama.cpp\n- [crashr/gppm](https://github.com/crashr/gppm) ‚Äì launch llama.cpp instances utilizing NVIDIA Tesla P40 or P100 GPUs with reduced idle power consumption\n- [gpustack/gguf-parser](https://github.com/gpustack/gguf-parser-go/tree/main/cmd/gguf-parser) - review/check the GGUF file and estimate the memory usage\n- [Styled Lines](https://marketplace.unity.com/packages/tools/generative-ai/styled-lines-llama-cpp-model-292902) (proprietary licensed, async wrapper of inference part for game development in Unity3d with pre-built Mobile and Web platform wrappers and a model example)\n- [unslothai/unsloth](https://github.com/unslothai/unsloth) ‚Äì ü¶• exports/saves fine-tuned and trained models to GGUF (Apache-2.0)\n\n</details>\n\n<details>\n<summary>Infrastructure</summary>\n\n- [Paddler](https://github.com/intentee/paddler) - Open-source LLMOps platform for hosting and scaling AI in your own infrastructure\n- [GPUStack](https://github.com/gpustack/gpustack) - Manage GPU clusters for running LLMs\n- [llama_cpp_canister](https://github.com/onicai/llama_cpp_canister) - llama.cpp as a smart contract on the Internet Computer, using WebAssembly\n- [llama-swap](https://github.com/mostlygeek/llama-swap) - transparent proxy that adds automatic model switching with llama-server\n- [Kalavai](https://github.com/kalavai-net/kalavai-client) - Crowdsource end to end LLM deployment at any scale\n- [llmaz](https://github.com/InftyAI/llmaz) - ‚ò∏Ô∏è Easy, advanced inference platform for large language models on Kubernetes.\n</details>\n\n<details>\n<summary>Games</summary>\n\n- [Lucy's Labyrinth](https://github.com/MorganRO8/Lucys_Labyrinth) - A simple maze game where agents controlled by an AI model will try to trick you.\n\n</details>\n\n\n## Supported backends\n\n| Backend | Target devices |\n| --- | --- |\n| [Metal](docs/build.md#metal-build) | Apple Silicon |\n| [BLAS](docs/build.md#blas-build) | All |\n| [BLIS](docs/backend/BLIS.md) | All |\n| [SYCL](docs/backend/SYCL.md) | Intel and Nvidia GPU |\n| [MUSA](docs/build.md#musa) | Moore Threads GPU |\n| [CUDA](docs/build.md#cuda) | Nvidia GPU |\n| [HIP](docs/build.md#hip) | AMD GPU |\n| [ZenDNN](docs/build.md#zendnn) | AMD CPU |\n| [Vulkan](docs/build.md#vulkan) | GPU |\n| [CANN](docs/build.md#cann) | Ascend NPU |\n| [OpenCL](docs/backend/OPENCL.md) | Adreno GPU |\n| [IBM zDNN](docs/backend/zDNN.md) | IBM Z & LinuxONE |\n| [WebGPU [In Progress]](docs/build.md#webgpu) | All |\n| [RPC](https://github.com/ggml-org/llama.cpp/tree/master/tools/rpc) | All |\n| [Hexagon [In Progress]](docs/backend/hexagon/README.md) | Snapdragon |\n\n## Obtaining and quantizing models\n\nThe [Hugging Face](https://huggingface.co) platform hosts a [number of LLMs](https://huggingface.co/models?library=gguf&sort=trending) compatible with `llama.cpp`:\n\n- [Trending](https://huggingface.co/models?library=gguf&sort=trending)\n- [LLaMA](https://huggingface.co/models?sort=trending&search=llama+gguf)\n\nYou can either manually download the GGUF file or directly use any `llama.cpp`-compatible models from [Hugging Face](https://huggingface.co/) or other model hosting sites, such as [ModelScope](https://modelscope.cn/), by using this CLI argument: `-hf <user>/<model>[:quant]`. For example:\n\n```sh\nllama-cli -hf ggml-org/gemma-3-1b-it-GGUF\n```\n\nBy default, the CLI would download from Hugging Face, you can switch to other options with the environment variable `MODEL_ENDPOINT`. For example, you may opt to downloading model checkpoints from ModelScope or other model sharing communities by setting the environment variable, e.g. `MODEL_ENDPOINT=https://www.modelscope.cn/`.\n\nAfter downloading a model, use the CLI tools to run it locally - see below.\n\n`llama.cpp` requires the model to be stored in the [GGUF](https://github.com/ggml-org/ggml/blob/master/docs/gguf.md) file format. Models in other data formats can be converted to GGUF using the `convert_*.py` Python scripts in this repo.\n\nThe Hugging Face platform provides a variety of online tools for converting, quantizing and hosting models with `llama.cpp`:\n\n- Use the [GGUF-my-repo space](https://huggingface.co/spaces/ggml-org/gguf-my-repo) to convert to GGUF format and quantize model weights to smaller sizes\n- Use the [GGUF-my-LoRA space](https://huggingface.co/spaces/ggml-org/gguf-my-lora) to convert LoRA adapters to GGUF format (more info: https://github.com/ggml-org/llama.cpp/discussions/10123)\n- Use the [GGUF-editor space](https://huggingface.co/spaces/CISCai/gguf-editor) to edit GGUF meta data in the browser (more info: https://github.com/ggml-org/llama.cpp/discussions/9268)\n- Use the [Inference Endpoints](https://ui.endpoints.huggingface.co/) to directly host `llama.cpp` in the cloud (more info: https://github.com/ggml-org/llama.cpp/discussions/9669)\n\nTo learn more about model quantization, [read this documentation](tools/quantize/README.md)\n\n## [`llama-cli`](tools/cli)\n\n#### A CLI tool for accessing and experimenting with most of `llama.cpp`'s functionality.\n\n- <details open>\n    <summary>Run in conversation mode</summary>\n\n    Models with a built-in chat template will automatically activate conversation mode. If this doesn't occur, you can manually enable it by adding `-cnv` and specifying a suitable chat template with `--chat-template NAME`\n\n    ```bash\n    llama-cli -m model.gguf\n\n    # > hi, who are you?\n    # Hi there! I'm your helpful assistant! I'm an AI-powered chatbot designed to assist and provide information to users like you. I'm here to help answer your questions, provide guidance, and offer support on a wide range of topics. I'm a friendly and knowledgeable AI, and I'm always happy to help with anything you need. What's on your mind, and how can I assist you today?\n    #\n    # > what is 1+1?\n    # Easy peasy! The answer to 1+1 is... 2!\n    ```\n\n    </details>\n\n- <details>\n    <summary>Run in conversation mode with custom chat template</summary>\n\n    ```bash\n    # use the \"chatml\" template (use -h to see the list of supported templates)\n    llama-cli -m model.gguf -cnv --chat-template chatml\n\n    # use a custom template\n    llama-cli -m model.gguf -cnv --in-prefix 'User: ' --reverse-prompt 'User:'\n    ```\n\n    </details>\n\n- <details>\n    <summary>Constrain the output with a custom grammar</summary>\n\n    ```bash\n    llama-cli -m model.gguf -n 256 --grammar-file grammars/json.gbnf -p 'Request: schedule a call at 8pm; Command:'\n\n    # {\"appointmentTime\": \"8pm\", \"appointmentDetails\": \"schedule a a call\"}\n    ```\n\n    The [grammars/](grammars/) folder contains a handful of sample grammars. To write your own, check out the [GBNF Guide](grammars/README.md).\n\n    For authoring more complex JSON grammars, check out https://grammar.intrinsiclabs.ai/\n\n    </details>\n\n\n## [`llama-server`](tools/server)\n\n#### A lightweight, [OpenAI API](https://github.com/openai/openai-openapi) compatible, HTTP server for serving LLMs.\n\n- <details open>\n    <summary>Start a local HTTP server with default configuration on port 8080</summary>\n\n    ```bash\n    llama-server -m model.gguf --port 8080\n\n    # Basic web UI can be accessed via browser: http://localhost:8080\n    # Chat completion endpoint: http://localhost:8080/v1/chat/completions\n    ```\n\n    </details>\n\n- <details>\n    <summary>Support multiple-users and parallel decoding</summary>\n\n    ```bash\n    # up to 4 concurrent requests, each with 4096 max context\n    llama-server -m model.gguf -c 16384 -np 4\n    ```\n\n    </details>\n\n- <details>\n    <summary>Enable speculative decoding</summary>\n\n    ```bash\n    # the draft.gguf model should be a small variant of the target model.gguf\n    llama-server -m model.gguf -md draft.gguf\n    ```\n\n    </details>\n\n- <details>\n    <summary>Serve an embedding model</summary>\n\n    ```bash\n    # use the /embedding endpoint\n    llama-server -m model.gguf --embedding --pooling cls -ub 8192\n    ```\n\n    </details>\n\n- <details>\n    <summary>Serve a reranking model</summary>\n\n    ```bash\n    # use the /reranking endpoint\n    llama-server -m model.gguf --reranking\n    ```\n\n    </details>\n\n- <details>\n    <summary>Constrain all outputs with a grammar</summary>\n\n    ```bash\n    # custom grammar\n    llama-server -m model.gguf --grammar-file grammar.gbnf\n\n    # JSON\n    llama-server -m model.gguf --grammar-file grammars/json.gbnf\n    ```\n\n    </details>\n\n\n## [`llama-perplexity`](tools/perplexity)\n\n#### A tool for measuring the [perplexity](tools/perplexity/README.md) [^1] (and other quality metrics) of a model over a given text.\n\n- <details open>\n    <summary>Measure the perplexity over a text file</summary>\n\n    ```bash\n    llama-perplexity -m model.gguf -f file.txt\n\n    # [1]15.2701,[2]5.4007,[3]5.3073,[4]6.2965,[5]5.8940,[6]5.6096,[7]5.7942,[8]4.9297, ...\n    # Final estimate: PPL = 5.4007 +/- 0.67339\n    ```\n\n    </details>\n\n- <details>\n    <summary>Measure KL divergence</summary>\n\n    ```bash\n    # TODO\n    ```\n\n    </details>\n\n[^1]: [https://huggingface.co/docs/transformers/perplexity](https://huggingface.co/docs/transformers/perplexity)\n\n## [`llama-bench`](tools/llama-bench)\n\n#### Benchmark the performance of the inference for various parameters.\n\n- <details open>\n    <summary>Run default benchmark</summary>\n\n    ```bash\n    llama-bench -m model.gguf\n\n    # Output:\n    # | model               |       size |     params | backend    | threads |          test |                  t/s |\n    # | ------------------- | ---------: | ---------: | ---------- | ------: | ------------: | -------------------: |\n    # | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         pp512 |      5765.41 ¬± 20.55 |\n    # | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         tg128 |        197.71 ¬± 0.81 |\n    #\n    # build: 3e0ba0e60 (4229)\n    ```\n\n    </details>\n\n## [`llama-simple`](examples/simple)\n\n#### A minimal example for implementing apps with `llama.cpp`. Useful for developers.\n\n- <details>\n    <summary>Basic text completion</summary>\n\n    ```bash\n    llama-simple -m model.gguf\n\n    # Hello my name is Kaitlyn and I am a 16 year old girl. I am a junior in high school and I am currently taking a class called \"The Art of\n    ```\n\n    </details>\n\n\n## Contributing\n\n- Contributors can open PRs\n- Collaborators will be invited based on contributions\n- Maintainers can push to branches in the `llama.cpp` repo and merge PRs into the `master` branch\n- Any help with managing issues, PRs and projects is very appreciated!\n- See [good first issues](https://github.com/ggml-org/llama.cpp/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) for tasks suitable for first contributions\n- Read the [CONTRIBUTING.md](CONTRIBUTING.md) for more information\n- Make sure to read this: [Inference at the edge](https://github.com/ggml-org/llama.cpp/discussions/205)\n- A bit of backstory for those who are interested: [Changelog podcast](https://changelog.com/podcast/532)\n\n## Other documentation\n\n- [cli](tools/cli/README.md)\n- [completion](tools/completion/README.md)\n- [server](tools/server/README.md)\n- [GBNF grammars](grammars/README.md)\n\n#### Development documentation\n\n- [How to build](docs/build.md)\n- [Running on Docker](docs/docker.md)\n- [Build on Android](docs/android.md)\n- [Performance troubleshooting](docs/development/token_generation_performance_tips.md)\n- [GGML tips & tricks](https://github.com/ggml-org/llama.cpp/wiki/GGML-Tips-&-Tricks)\n\n#### Seminal papers and background on the models\n\nIf your issue is with model generation quality, then please at least scan the following links and papers to understand the limitations of LLaMA models. This is especially important when choosing an appropriate model size and appreciating both the significant and subtle differences between LLaMA models and ChatGPT:\n- LLaMA:\n    - [Introducing LLaMA: A foundational, 65-billion-parameter large language model](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)\n    - [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)\n- GPT-3\n    - [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)\n- GPT-3.5 / InstructGPT / ChatGPT:\n    - [Aligning language models to follow instructions](https://openai.com/research/instruction-following)\n    - [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)\n\n## XCFramework\nThe XCFramework is a precompiled version of the library for iOS, visionOS, tvOS,\nand macOS. It can be used in Swift projects without the need to compile the\nlibrary from source. For example:\n```swift\n// swift-tools-version: 5.10\n// The swift-tools-version declares the minimum version of Swift required to build this package.\n\nimport PackageDescription\n\nlet package = Package(\n    name: \"MyLlamaPackage\",\n    targets: [\n        .executableTarget(\n            name: \"MyLlamaPackage\",\n            dependencies: [\n                \"LlamaFramework\"\n            ]),\n        .binaryTarget(\n            name: \"LlamaFramework\",\n            url: \"https://github.com/ggml-org/llama.cpp/releases/download/b5046/llama-b5046-xcframework.zip\",\n            checksum: \"c19be78b5f00d8d29a25da41042cb7afa094cbf6280a225abe614b03b20029ab\"\n        )\n    ]\n)\n```\nThe above example is using an intermediate build `b5046` of the library. This can be modified\nto use a different version by changing the URL and checksum.\n\n## Completions\nCommand-line completion is available for some environments.\n\n#### Bash Completion\n```bash\n$ build/bin/llama-cli --completion-bash > ~/.llama-completion.bash\n$ source ~/.llama-completion.bash\n```\nOptionally this can be added to your `.bashrc` or `.bash_profile` to load it\nautomatically. For example:\n```console\n$ echo \"source ~/.llama-completion.bash\" >> ~/.bashrc\n```\n\n## Dependencies\n\n- [yhirose/cpp-httplib](https://github.com/yhirose/cpp-httplib) - Single-header HTTP server, used by `llama-server` - MIT license\n- [stb-image](https://github.com/nothings/stb) - Single-header image format decoder, used by multimodal subsystem - Public domain\n- [nlohmann/json](https://github.com/nlohmann/json) - Single-header JSON library, used by various tools/examples - MIT License\n- [miniaudio.h](https://github.com/mackron/miniaudio) - Single-header audio format decoder, used by multimodal subsystem - Public domain\n- [subprocess.h](https://github.com/sheredom/subprocess.h) - Single-header process launching solution for C and C++ - Public domain\n",
      "stars_today": 80
    },
    {
      "id": 1023959202,
      "name": "runanywhere-sdks",
      "full_name": "RunanywhereAI/runanywhere-sdks",
      "description": "Production ready toolkit to run AI locally",
      "html_url": "https://github.com/RunanywhereAI/runanywhere-sdks",
      "stars": 3983,
      "forks": 126,
      "language": "Kotlin",
      "topics": [
        "agent-framework",
        "android",
        "apple-intelligence",
        "edge",
        "edge-ai",
        "foundational-models",
        "inference",
        "ios",
        "kotlin",
        "llamacpp",
        "llm",
        "multimodal",
        "ollama",
        "on-device-ai",
        "privacy",
        "swift",
        "voice-ai",
        "voice-assistant"
      ],
      "created_at": "2025-07-22T01:23:34Z",
      "updated_at": "2026-01-22T23:29:43Z",
      "pushed_at": "2026-01-22T12:04:20Z",
      "open_issues": 24,
      "owner": {
        "login": "RunanywhereAI",
        "avatar_url": "https://avatars.githubusercontent.com/u/220821781?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"examples/logo.svg\" alt=\"RunAnywhere Logo\" width=\"140\"/>\n</p>\n\n<h1 align=\"center\">RunAnywhere</h1>\n\n<p align=\"center\">\n  <strong>On-device AI for mobile apps.</strong><br/>\n  Run LLMs, speech-to-text, and text-to-speech locally‚Äîprivate, offline, fast.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://apps.apple.com/us/app/runanywhere/id6756506307\">\n    <img src=\"https://img.shields.io/badge/App_Store-Download-0D96F6?style=for-the-badge&logo=apple&logoColor=white\" alt=\"Download on App Store\" />\n  </a>\n  &nbsp;\n  <a href=\"https://play.google.com/store/apps/details?id=com.runanywhere.runanywhereai\">\n    <img src=\"https://img.shields.io/badge/Google_Play-Download-34A853?style=for-the-badge&logo=google-play&logoColor=white\" alt=\"Get it on Google Play\" />\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/RunanywhereAI/runanywhere-sdks/stargazers\"><img src=\"https://img.shields.io/github/stars/RunanywhereAI/runanywhere-sdks?style=flat-square\" alt=\"GitHub Stars\" /></a>\n  <a href=\"LICENSE\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue?style=flat-square\" alt=\"License\" /></a>\n  <a href=\"https://discord.gg/N359FBbDVd\"><img src=\"https://img.shields.io/badge/Discord-Join-5865F2?style=flat-square&logo=discord&logoColor=white\" alt=\"Discord\" /></a>\n</p>\n\n<p align=\"center\">\n  <img src=\"docs/screenshots/main-screenshot.jpg\" alt=\"Chat\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/chat-interface.png\" alt=\"Analytics\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/quiz-flow.png\" alt=\"Structured Output\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/voice-ai.png\" alt=\"Voice AI\" width=\"180\"/>\n</p>\n\n---\n\n## What is RunAnywhere?\n\nRunAnywhere lets you add AI features to your mobile app that run entirely on-device:\n\n- **LLM Chat** ‚Äî Llama, Mistral, Qwen, SmolLM, and more\n- **Speech-to-Text** ‚Äî Whisper-powered transcription\n- **Text-to-Speech** ‚Äî Neural voice synthesis\n- **Voice Assistant** ‚Äî Full STT ‚Üí LLM ‚Üí TTS pipeline\n\nNo cloud. No latency. No data leaves the device.\n\n---\n\n## SDKs\n\n| Platform | Status | Installation | Documentation |\n|----------|--------|--------------|---------------|\n| **Swift** (iOS/macOS) | Stable | [Swift Package Manager](#swift-ios--macos) | [docs.runanywhere.ai/swift](https://docs.runanywhere.ai/swift/introduction) |\n| **Kotlin** (Android) | Stable | [Gradle](#kotlin-android) | [docs.runanywhere.ai/kotlin](https://docs.runanywhere.ai/kotlin/introduction) |\n| **React Native** | Beta | [npm](#react-native) | [docs.runanywhere.ai/react-native](https://docs.runanywhere.ai/react-native/introduction) |\n| **Flutter** | Beta | [pub.dev](#flutter) | [docs.runanywhere.ai/flutter](https://docs.runanywhere.ai/flutter/introduction) |\n\n---\n\n## Quick Start\n\n### Swift (iOS / macOS)\n\n```swift\nimport RunAnywhere\nimport LlamaCPPRuntime\n\n// 1. Initialize\nLlamaCPP.register()\ntry RunAnywhere.initialize()\n\n// 2. Load a model\ntry await RunAnywhere.downloadModel(\"smollm2-360m\")\ntry await RunAnywhere.loadModel(\"smollm2-360m\")\n\n// 3. Generate\nlet response = try await RunAnywhere.chat(\"What is the capital of France?\")\nprint(response) // \"Paris is the capital of France.\"\n```\n\n**Install via Swift Package Manager:**\n\n```\nhttps://github.com/RunanywhereAI/runanywhere-sdks\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/swift/introduction) ¬∑ [Source code](sdk/runanywhere-swift/)\n\n---\n\n### Kotlin (Android)\n\n```kotlin\nimport com.runanywhere.sdk.public.RunAnywhere\nimport com.runanywhere.sdk.public.extensions.*\n\n// 1. Initialize\nLlamaCPP.register()\nRunAnywhere.initialize(environment = SDKEnvironment.DEVELOPMENT)\n\n// 2. Load a model\nRunAnywhere.downloadModel(\"smollm2-360m\").collect { println(\"${it.progress * 100}%\") }\nRunAnywhere.loadLLMModel(\"smollm2-360m\")\n\n// 3. Generate\nval response = RunAnywhere.chat(\"What is the capital of France?\")\nprintln(response) // \"Paris is the capital of France.\"\n```\n\n**Install via Gradle:**\n\n```kotlin\ndependencies {\n    implementation(\"com.runanywhere.sdk:runanywhere-kotlin:0.1.4\")\n    implementation(\"com.runanywhere.sdk:runanywhere-core-llamacpp:0.1.4\")\n}\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/kotlin/introduction) ¬∑ [Source code](sdk/runanywhere-kotlin/)\n\n---\n\n### React Native\n\n```typescript\nimport { RunAnywhere, SDKEnvironment } from '@runanywhere/core';\nimport { LlamaCPP } from '@runanywhere/llamacpp';\n\n// 1. Initialize\nawait RunAnywhere.initialize({ environment: SDKEnvironment.Development });\nLlamaCPP.register();\n\n// 2. Load a model\nawait RunAnywhere.downloadModel('smollm2-360m');\nawait RunAnywhere.loadModel(modelPath);\n\n// 3. Generate\nconst response = await RunAnywhere.chat('What is the capital of France?');\nconsole.log(response); // \"Paris is the capital of France.\"\n```\n\n**Install via npm:**\n\n```bash\nnpm install @runanywhere/core @runanywhere/llamacpp\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/react-native/introduction) ¬∑ [Source code](sdk/runanywhere-react-native/)\n\n---\n\n### Flutter\n\n```dart\nimport 'package:runanywhere/runanywhere.dart';\nimport 'package:runanywhere_llamacpp/runanywhere_llamacpp.dart';\n\n// 1. Initialize\nawait RunAnywhere.initialize();\nawait LlamaCpp.register();\n\n// 2. Load a model\nawait RunAnywhere.downloadModel('smollm2-360m');\nawait RunAnywhere.loadModel('smollm2-360m');\n\n// 3. Generate\nfinal response = await RunAnywhere.chat('What is the capital of France?');\nprint(response); // \"Paris is the capital of France.\"\n```\n\n**Install via pub.dev:**\n\n```yaml\ndependencies:\n  runanywhere: ^0.15.11\n  runanywhere_llamacpp: ^0.15.11\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/flutter/introduction) ¬∑ [Source code](sdk/runanywhere-flutter/)\n\n---\n\n## Sample Apps\n\nFull-featured demo applications demonstrating SDK capabilities:\n\n| Platform | Source Code | Download |\n|----------|-------------|----------|\n| iOS | [examples/ios/RunAnywhereAI](examples/ios/RunAnywhereAI/) | [App Store](https://apps.apple.com/us/app/runanywhere/id6756506307) |\n| Android | [examples/android/RunAnywhereAI](examples/android/RunAnywhereAI/) | [Google Play](https://play.google.com/store/apps/details?id=com.runanywhere.runanywhereai) |\n| React Native | [examples/react-native/RunAnywhereAI](examples/react-native/RunAnywhereAI/) | Build from source |\n| Flutter | [examples/flutter/RunAnywhereAI](examples/flutter/RunAnywhereAI/) | Build from source |\n\n---\n\n## Features\n\n| Feature | iOS | Android | React Native | Flutter |\n|---------|-----|---------|--------------|---------|\n| LLM Text Generation | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Streaming | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Speech-to-Text | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Text-to-Speech | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Voice Assistant Pipeline | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Model Download + Progress | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Structured Output (JSON) | ‚úÖ | ‚úÖ | üîú | üîú |\n| Apple Foundation Models | ‚úÖ | ‚Äî | ‚Äî | ‚Äî |\n\n---\n\n## Supported Models\n\n### LLM (GGUF format via llama.cpp)\n\n| Model | Size | RAM Required | Use Case |\n|-------|------|--------------|----------|\n| SmolLM2 360M | ~400MB | 500MB | Fast, lightweight |\n| Qwen 2.5 0.5B | ~500MB | 600MB | Multilingual |\n| Llama 3.2 1B | ~1GB | 1.2GB | Balanced |\n| Mistral 7B Q4 | ~4GB | 5GB | High quality |\n\n### Speech-to-Text (Whisper via ONNX)\n\n| Model | Size | Languages |\n|-------|------|-----------|\n| Whisper Tiny | ~75MB | English |\n| Whisper Base | ~150MB | Multilingual |\n\n### Text-to-Speech (Piper via ONNX)\n\n| Voice | Size | Language |\n|-------|------|----------|\n| Piper US English | ~65MB | English (US) |\n| Piper British English | ~65MB | English (UK) |\n\n---\n\n## Repository Structure\n\n```\nrunanywhere-sdks/\n‚îú‚îÄ‚îÄ sdk/\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-swift/          # iOS/macOS SDK\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-kotlin/         # Android SDK\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-react-native/   # React Native SDK\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-flutter/        # Flutter SDK\n‚îÇ   ‚îî‚îÄ‚îÄ runanywhere-commons/        # Shared C++ core\n‚îÇ\n‚îú‚îÄ‚îÄ examples/\n‚îÇ   ‚îú‚îÄ‚îÄ ios/RunAnywhereAI/          # iOS sample app\n‚îÇ   ‚îú‚îÄ‚îÄ android/RunAnywhereAI/      # Android sample app\n‚îÇ   ‚îú‚îÄ‚îÄ react-native/RunAnywhereAI/ # React Native sample app\n‚îÇ   ‚îî‚îÄ‚îÄ flutter/RunAnywhereAI/      # Flutter sample app\n‚îÇ\n‚îî‚îÄ‚îÄ docs/                           # Documentation\n```\n\n---\n\n## Requirements\n\n| Platform | Minimum | Recommended |\n|----------|---------|-------------|\n| iOS | 17.0+ | 17.0+ |\n| macOS | 14.0+ | 14.0+ |\n| Android | API 24 (7.0) | API 28+ |\n| React Native | 0.74+ | 0.76+ |\n| Flutter | 3.10+ | 3.24+ |\n\n**Memory:** 2GB minimum, 4GB+ recommended for larger models\n\n---\n\n## Contributing\n\nWe welcome contributions. See our [Contributing Guide](CONTRIBUTING.md) for details.\n\n```bash\n# Clone the repo\ngit clone https://github.com/RunanywhereAI/runanywhere-sdks.git\n\n# Set up a specific SDK (example: Swift)\ncd runanywhere-sdks/sdk/runanywhere-swift\n./scripts/build-swift.sh --setup\n\n# Run the sample app\ncd ../../examples/ios/RunAnywhereAI\nopen RunAnywhereAI.xcodeproj\n```\n\n---\n\n## Support\n\n- **Discord:** [Join our community](https://discord.gg/N359FBbDVd)\n- **GitHub Issues:** [Report bugs or request features](https://github.com/RunanywhereAI/runanywhere-sdks/issues)\n- **Email:** founders@runanywhere.ai\n- **Twitter:** [@RunanywhereAI](https://twitter.com/RunanywhereAI)\n\n---\n\n## License\n\nApache 2.0 ‚Äî see [LICENSE](LICENSE) for details.\n",
      "stars_today": 77
    },
    {
      "id": 526081371,
      "name": "go2rtc",
      "full_name": "AlexxIT/go2rtc",
      "description": "Ultimate camera streaming application with support RTSP, RTMP, HTTP-FLV, WebRTC, MSE, HLS, MP4, MJPEG, HomeKit, FFmpeg, etc.",
      "html_url": "https://github.com/AlexxIT/go2rtc",
      "stars": 11865,
      "forks": 900,
      "language": "Go",
      "topics": [
        "ffmpeg",
        "h264",
        "h265",
        "hassio",
        "hls",
        "home-assistant",
        "homekit",
        "http-flv",
        "media-server",
        "mjpeg",
        "mp4",
        "rtmp",
        "rtp",
        "rtsp",
        "rtsp-server",
        "streaming",
        "webcam-streaming",
        "webrtc"
      ],
      "created_at": "2022-08-18T06:16:48Z",
      "updated_at": "2026-01-23T02:06:33Z",
      "pushed_at": "2026-01-21T19:26:29Z",
      "open_issues": 576,
      "owner": {
        "login": "AlexxIT",
        "avatar_url": "https://avatars.githubusercontent.com/u/511909?v=4"
      },
      "readme": "<h1 align=\"center\">\n\n  ![go2rtc](assets/logo.gif)\n  <br>\n  [![stars](https://img.shields.io/github/stars/AlexxIT/go2rtc?style=flat-square&logo=github)](https://github.com/AlexxIT/go2rtc/stargazers)\n  [![docker pulls](https://img.shields.io/docker/pulls/alexxit/go2rtc?style=flat-square&logo=docker&logoColor=white&label=pulls)](https://hub.docker.com/r/alexxit/go2rtc)\n  [![releases](https://img.shields.io/github/downloads/AlexxIT/go2rtc/total?color=blue&style=flat-square&logo=github)](https://github.com/AlexxIT/go2rtc/releases)\n  [![goreport](https://goreportcard.com/badge/github.com/AlexxIT/go2rtc)](https://goreportcard.com/report/github.com/AlexxIT/go2rtc)\n</h1>\n\nUltimate camera streaming application with support for RTSP, WebRTC, HomeKit, FFmpeg, RTMP, etc.\n\n![go2rtc overview](assets/go2rtc.png)\n\n- zero-dependency and zero-config [small app](#go2rtc-binary) for all OS (Windows, macOS, Linux, ARM)\n- zero-delay for many supported protocols (lowest possible streaming latency)\n- streaming from [RTSP](#source-rtsp), [RTMP](#source-rtmp), [DVRIP](#source-dvrip), [HTTP](#source-http) (FLV/MJPEG/JPEG/TS), [USB Cameras](#source-ffmpeg-device) and [other sources](#module-streams)\n- streaming from any sources, supported by [FFmpeg](#source-ffmpeg)\n- streaming to [RTSP](#module-rtsp), [WebRTC](#module-webrtc), [MSE/MP4](#module-mp4), [HomeKit](#module-homekit) [HLS](#module-hls) or [MJPEG](#module-mjpeg)\n- [publish](#publish-stream) any source to popular streaming services (YouTube, Telegram, etc.)\n- first project in the World with support streaming from [HomeKit Cameras](#source-homekit)\n- on-the-fly transcoding for unsupported codecs via [FFmpeg](#source-ffmpeg)\n- play audio files and live streams on some cameras with [speaker](#stream-to-camera)\n- multi-source two-way [codecs negotiation](#codecs-negotiation)\n  - mixing tracks from different sources to single stream\n  - auto-match client-supported codecs\n  - [two-way audio](#two-way-audio) for some cameras\n- can be [integrated to](#module-api) any smart home platform or be used as [standalone app](#go2rtc-binary)\n\n**Supported Formats** - describes the communication API: authorization, encryption, command set, structure of media packets\n\n- devices: `alsa` (Linux audio), `v4l2` (Linux video)\n- files: `adts`, `flv`, `h264`, `hevc`, `hls`, `mjpeg`, `mpegts`, `mp4`, `wav`\n- network (public and well known): `mpjpeg`, `onvif`, `rtmp`, `rtp`, `rtsp`, `webrtc`, `yuv4mpegpipe`\n- network (private and exclusive): `bubble`, `doorbird`, `dvrip`, `eseecloud`, `gopro`, `hass` (Home Assistant), `homekit` (Apple), `isapi` (Hikvision), `kasa` (TP-Link), `multitrans` (TP-Link), `nest` (Google), `ring`, `roborock`, `tapo` and `vigi` (TP-Link), `tuya`, `webtorrent`, `wyze`, `xiaomi` (Mi Home)\n- webrtc related: `creality`, `kinesis` (Amazon), `openipc`, `switchbot`, `whep`, `whip`, `wyze`\n- other: `ascii`, `echo`, `exec`, `expr`, `ffmpeg`\n\n**Supported Protocols** - describes the transport for data transmission\n\n- public: `http`, `pipe`, `rtmp`, `rtsp`, `tcp`, `udp`, `webrtc`, `ws` (WebSocket)\n- private: `cs2` (PPPP), `hap` and `hds` (HomeKit), `tutk` (P2P)\n\n**Inspired by:**\n\n- series of streaming projects from [@deepch](https://github.com/deepch)\n- [webrtc](https://github.com/pion/webrtc) go library and whole [@pion](https://github.com/pion) team\n- [rtsp-simple-server](https://github.com/aler9/rtsp-simple-server) idea from [@aler9](https://github.com/aler9)\n- [GStreamer](https://gstreamer.freedesktop.org/) framework pipeline idea\n- [MediaSoup](https://mediasoup.org/) framework routing idea\n- HomeKit Accessory Protocol from [@brutella](https://github.com/brutella/hap)\n- creator of the project's logo [@v_novoseltsev](https://www.instagram.com/v_novoseltsev)\n\n> [!CAUTION]\n> The official website of the project is this GitHub repository and go2rtc.org (hosted on GitHub Pages). The website go2rtc[.]com is in no way associated with the authors of this project.\n\n---\n\n- [Fast start](#fast-start)\n  - [go2rtc: Binary](#go2rtc-binary)\n  - [go2rtc: Docker](#go2rtc-docker)\n  - [go2rtc: Home Assistant add-on](#go2rtc-home-assistant-add-on)\n  - [go2rtc: Home Assistant integration](#go2rtc-home-assistant-integration)\n  - [go2rtc: Dev version](#go2rtc-dev-version)\n- [Configuration](#configuration)\n  - [Module: Streams](#module-streams)\n  - [Two-way audio](#two-way-audio)\n  - [Source: RTSP](#source-rtsp)\n  - [Source: RTMP](#source-rtmp)\n  - [Source: HTTP](#source-http)\n  - [Source: ONVIF](#source-onvif)\n  - [Source: FFmpeg](#source-ffmpeg)\n  - [Source: FFmpeg Device](#source-ffmpeg-device)\n  - [Source: Exec](#source-exec)\n  - [Source: Echo](#source-echo)\n  - [Source: Expr](#source-expr)\n  - [Source: HomeKit](#source-homekit)\n  - [Source: Bubble](#source-bubble)\n  - [Source: DVRIP](#source-dvrip)\n  - [Source: Tapo](#source-tapo)\n  - [Source: Kasa](#source-kasa)\n  - [Source: Multitrans](#source-multitrans)\n  - [Source: Tuya](#source-tuya)\n  - [Source: Xiaomi](#source-xiaomi)\n  - [Source: Wyze](#source-wyze)\n  - [Source: GoPro](#source-gopro)\n  - [Source: Ivideon](#source-ivideon)\n  - [Source: Hass](#source-hass)\n  - [Source: ISAPI](#source-isapi)\n  - [Source: Nest](#source-nest)\n  - [Source: Ring](#source-ring)\n  - [Source: Roborock](#source-roborock)\n  - [Source: Doorbird](#source-doorbird)\n  - [Source: WebRTC](#source-webrtc)\n  - [Source: WebTorrent](#source-webtorrent)\n  - [Incoming sources](#incoming-sources)\n  - [Stream to camera](#stream-to-camera)\n  - [Publish stream](#publish-stream)\n  - [Preload stream](#preload-stream)\n  - [Module: API](#module-api)\n  - [Module: RTSP](#module-rtsp)\n  - [Module: RTMP](#module-rtmp)\n  - [Module: WebRTC](#module-webrtc)\n  - [Module: HomeKit](#module-homekit)\n  - [Module: WebTorrent](#module-webtorrent)\n  - [Module: ngrok](#module-ngrok)\n  - [Module: Hass](#module-hass)\n  - [Module: MP4](#module-mp4)\n  - [Module: HLS](#module-hls)\n  - [Module: MJPEG](#module-mjpeg)\n  - [Module: Log](#module-log)\n- [Security](#security)\n- [Codecs filters](#codecs-filters)\n- [Codecs madness](#codecs-madness)\n- [Codecs negotiation](#codecs-negotiation)\n- [Projects using go2rtc](#projects-using-go2rtc)\n- [Camera experience](#camera-experience)\n- [Tips](#tips)\n\n# Fast start\n\n1. Download [binary](#go2rtc-binary) or use [Docker](#go2rtc-docker) or Home Assistant [add-on](#go2rtc-home-assistant-add-on) or [Integration](#go2rtc-home-assistant-integration)\n2. Open web interface: `http://localhost:1984/`\n\n**Optionally:**\n\n- add your [streams](#module-streams) to [config](#configuration) file\n- setup [external access](#module-webrtc) to webrtc\n\n**Developers:**\n\n- write your own [web interface](#module-api)\n- integrate [web api](#module-api) into your smart home platform\n\n## go2rtc: Binary\n\nDownload binary for your OS from [latest release](https://github.com/AlexxIT/go2rtc/releases/):\n\n- `go2rtc_win64.zip` - Windows 10+ 64-bit\n- `go2rtc_win32.zip` - Windows 10+ 32-bit\n- `go2rtc_win_arm64.zip` - Windows ARM 64-bit\n- `go2rtc_linux_amd64` - Linux 64-bit\n- `go2rtc_linux_i386` - Linux 32-bit\n- `go2rtc_linux_arm64` - Linux ARM 64-bit (ex. Raspberry 64-bit OS)\n- `go2rtc_linux_arm` - Linux ARM 32-bit (ex. Raspberry 32-bit OS)\n- `go2rtc_linux_armv6` - Linux ARMv6 (for old Raspberry 1 and Zero)\n- `go2rtc_linux_mipsel` - Linux MIPS (ex. [Xiaomi Gateway 3](https://github.com/AlexxIT/XiaomiGateway3), [Wyze cameras](https://github.com/gtxaspec/wz_mini_hacks))\n- `go2rtc_mac_amd64.zip` - macOS 11+ Intel 64-bit\n- `go2rtc_mac_arm64.zip` - macOS ARM 64-bit\n- `go2rtc_freebsd_amd64.zip` - FreeBSD 64-bit\n- `go2rtc_freebsd_arm64.zip` - FreeBSD ARM 64-bit\n\nDon't forget to fix the rights `chmod +x go2rtc_xxx_xxx` on Linux and Mac.\n\nPS. The application is compiled with the latest versions of the Go language for maximum speed and security. Therefore, the [minimum OS versions](https://go.dev/wiki/MinimumRequirements) depend on the Go language.\n\n## go2rtc: Docker\n\nThe Docker container [`alexxit/go2rtc`](https://hub.docker.com/r/alexxit/go2rtc) supports multiple architectures including `amd64`, `386`, `arm64`, and `arm`. This container offers the same functionality as the [Home Assistant add-on](#go2rtc-home-assistant-add-on) but is designed to operate independently of Home Assistant. It comes preinstalled with [FFmpeg](#source-ffmpeg) and [Python](#source-echo).\n\n## go2rtc: Home Assistant add-on\n\n[![Open your Home Assistant instance and show the add add-on repository dialog with a specific repository URL pre-filled.](https://my.home-assistant.io/badges/supervisor_add_addon_repository.svg)](https://my.home-assistant.io/redirect/supervisor_add_addon_repository/?repository_url=https%3A%2F%2Fgithub.com%2FAlexxIT%2Fhassio-addons)\n\n1. Install Add-On:\n    - Settings > Add-ons > Plus > Repositories > Add `https://github.com/AlexxIT/hassio-addons`\n    - go2rtc > Install > Start\n2. Setup [Integration](#module-hass)\n\n## go2rtc: Home Assistant Integration\n\n[WebRTC Camera](https://github.com/AlexxIT/WebRTC) custom component can be used on any [Home Assistant installation](https://www.home-assistant.io/installation/), including [HassWP](https://github.com/AlexxIT/HassWP) on Windows. It can automatically download and use the latest version of go2rtc. Or it can connect to an existing version of go2rtc. Addon installation in this case is optional.\n\n## go2rtc: Dev version\n\nLatest, but maybe unstable version:\n\n- Binary: [latest nightly release](https://nightly.link/AlexxIT/go2rtc/workflows/build/master)\n- Docker: `alexxit/go2rtc:master` or `alexxit/go2rtc:master-hardware` versions\n- Home Assistant add-on: `go2rtc master` or `go2rtc master hardware` versions\n\n# Configuration\n\n- by default go2rtc will search `go2rtc.yaml` in the current work directory\n- `api` server will start on default **1984 port** (TCP)\n- `rtsp` server will start on default **8554 port** (TCP)\n- `webrtc` will use port **8555** (TCP/UDP) for connections\n- `ffmpeg` will use default transcoding options\n\nConfiguration options and a complete list of settings can be found in [the wiki](https://github.com/AlexxIT/go2rtc/wiki/Configuration).\n\nAvailable modules:\n\n- [streams](#module-streams)\n- [api](#module-api) - HTTP API (important for WebRTC support)\n- [rtsp](#module-rtsp) - RTSP Server (important for FFmpeg support)\n- [webrtc](#module-webrtc) - WebRTC Server\n- [mp4](#module-mp4) - MSE, MP4 stream and MP4 snapshot Server\n- [hls](#module-hls) - HLS TS or fMP4 stream Server\n- [mjpeg](#module-mjpeg) - MJPEG Server\n- [ffmpeg](#source-ffmpeg) - FFmpeg integration\n- [ngrok](#module-ngrok) - ngrok integration (external access for private network)\n- [hass](#module-hass) - Home Assistant integration\n- [log](#module-log) - logs config\n\n## Module: Streams\n\n**go2rtc** supports different stream source types. You can config one or multiple links of any type as a stream source.\n\nAvailable source types:\n\n- [rtsp](#source-rtsp) - `RTSP` and `RTSPS` cameras with [two-way audio](#two-way-audio) support\n- [rtmp](#source-rtmp) - `RTMP` streams\n- [http](#source-http) - `HTTP-FLV`, `MPEG-TS`, `JPEG` (snapshots), `MJPEG` streams\n- [onvif](#source-onvif) - get camera `RTSP` link and snapshot link using `ONVIF` protocol\n- [ffmpeg](#source-ffmpeg) - FFmpeg integration (`HLS`, `files` and many others)\n- [ffmpeg:device](#source-ffmpeg-device) - local USB Camera or Webcam\n- [exec](#source-exec) - get media from external app output\n- [echo](#source-echo) - get stream link from bash or python\n- [expr](#source-expr) - get stream link via built-in expression language\n- [homekit](#source-homekit) - streaming from HomeKit Camera\n- [bubble](#source-bubble) - streaming from ESeeCloud/dvr163 NVR\n- [dvrip](#source-dvrip) - streaming from DVR-IP NVR\n- [eseecloud](#source-eseecloud) - streaming from ESeeCloud/dvr163 NVR\n- [tapo](#source-tapo) - TP-Link Tapo cameras with [two-way audio](#two-way-audio) support\n- [ring](#source-ring) - Ring cameras with [two-way audio](#two-way-audio) support\n- [tuya](#source-tuya) - Tuya cameras with [two-way audio](#two-way-audio) support\n- [xiaomi](#source-xiaomi) - Xiaomi cameras with [two-way audio](#two-way-audio) support\n- [kasa](#source-tapo) - TP-Link Kasa cameras\n- [gopro](#source-gopro) - GoPro cameras\n- [ivideon](#source-ivideon) - public cameras from [Ivideon](https://tv.ivideon.com/) service\n- [hass](#source-hass) - Home Assistant integration\n- [isapi](#source-isapi) - two-way audio for Hikvision (ISAPI) cameras\n- [roborock](#source-roborock) - Roborock vacuums with cameras\n- [doorbird](#source-doorbird) - Doorbird cameras with [two-way audio](#two-way-audio) support\n- [webrtc](#source-webrtc) - WebRTC/WHEP sources\n- [webtorrent](#source-webtorrent) - WebTorrent source from another go2rtc\n- [wyze](#source-wyze) - Wyze cameras with [two-way audio](#two-way-audio) support\n\nRead more about [incoming sources](#incoming-sources)\n\n## Two-way audio\n\nSupported sources:\n\n- [RTSP cameras](#source-rtsp) with [ONVIF Profile T](https://www.onvif.org/specs/stream/ONVIF-Streaming-Spec.pdf) (back channel connection)\n- [DVRIP](#source-dvrip) cameras\n- [TP-Link Tapo](#source-tapo) cameras\n- [Hikvision ISAPI](#source-isapi) cameras\n- [Roborock vacuums](#source-roborock) models with cameras\n- [Doorbird](#source-doorbird) cameras\n- [Exec](#source-exec) audio on server\n- [Ring](#source-ring) cameras\n- [Tuya](#source-tuya) cameras\n- [Wyze](#source-wyze) cameras\n- [Xiaomi](#source-xiaomi) cameras\n- [Any Browser](#incoming-browser) as IP-camera\n\nTwo-way audio can be used in browser with [WebRTC](#module-webrtc) technology. The browser will give access to the microphone only for HTTPS sites ([read more](https://stackoverflow.com/questions/52759992/how-to-access-camera-and-microphone-in-chrome-without-https)).\n\ngo2rtc also supports [play audio](#stream-to-camera) files and live streams on this cameras.\n\n## Source: RTSP\n\n```yaml\nstreams:\n  sonoff_camera: rtsp://rtsp:12345678@192.168.1.123/av_stream/ch0\n  dahua_camera:\n    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&subtype=0&unicast=true&proto=Onvif\n    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&subtype=1#backchannel=0\n  amcrest_doorbell:\n    - rtsp://username:password@192.168.1.123:554/cam/realmonitor?channel=1&subtype=0#backchannel=0\n  unifi_camera: rtspx://192.168.1.123:7441/fD6ouM72bWoFijxK\n  glichy_camera: ffmpeg:rtsp://username:password@192.168.1.123/live/ch00_1 \n```\n\n**Recommendations**\n\n- **Amcrest Doorbell** users may want to disable two-way audio, because with an active stream, you won't have a working call button. You need to add `#backchannel=0` to the end of your RTSP link in YAML config file\n- **Dahua Doorbell** users may want to change [audio codec](https://github.com/AlexxIT/go2rtc/issues/49#issuecomment-2127107379) for proper two-way audio. Make sure not to request backchannel multiple times by adding `#backchannel=0` to other stream sources of the same doorbell. The `unicast=true&proto=Onvif` is preferred for two-way audio as this makes the doorbell accept multiple codecs for the incoming audio\n- **Reolink** users may want NOT to use RTSP protocol at all, some camera models have a very awful, unusable stream implementation\n- **Ubiquiti UniFi** users may want to disable HTTPS verification. Use `rtspx://` prefix instead of `rtsps://`. And don't use `?enableSrtp` [suffix](https://github.com/AlexxIT/go2rtc/issues/81)\n- **TP-Link Tapo** users may skip login and password, because go2rtc support login [without them](https://drmnsamoliu.github.io/video.html)\n- If your camera has two RTSP links, you can add both as sources. This is useful when streams have different codecs, for example AAC audio with main stream and PCMU/PCMA audio with second stream\n- If the stream from your camera is glitchy, try using [ffmpeg source](#source-ffmpeg). It will not add CPU load if you don't use transcoding\n- If the stream from your camera is very glitchy, try to use transcoding with [ffmpeg source](#source-ffmpeg)\n\n**Other options**\n\nFormat: `rtsp...#{param1}#{param2}#{param3}`\n\n- Add custom timeout `#timeout=30` (in seconds)\n- Ignore audio - `#media=video` or ignore video - `#media=audio`\n- Ignore two-way audio API `#backchannel=0` - important for some glitchy cameras\n- Use WebSocket transport `#transport=ws...`\n\n**RTSP over WebSocket**\n\n```yaml\nstreams:\n  # WebSocket with authorization, RTSP - without\n  axis-rtsp-ws:  rtsp://192.168.1.123:4567/axis-media/media.amp?overview=0&camera=1&resolution=1280x720&videoframeskipmode=empty&Axis-Orig-Sw=true#transport=ws://user:pass@192.168.1.123:4567/rtsp-over-websocket\n  # WebSocket without authorization, RTSP - with\n  dahua-rtsp-ws: rtsp://user:pass@192.168.1.123/cam/realmonitor?channel=1&subtype=1&proto=Private3#transport=ws://192.168.1.123/rtspoverwebsocket\n```\n\n## Source: RTMP\n\nYou can get a stream from an RTMP server, for example [Nginx with nginx-rtmp-module](https://github.com/arut/nginx-rtmp-module).\n\n```yaml\nstreams:\n  rtmp_stream: rtmp://192.168.1.123/live/camera1\n```\n\n## Source: HTTP\n\nSupport Content-Type:\n\n- **HTTP-FLV** (`video/x-flv`) - same as RTMP, but over HTTP\n- **HTTP-JPEG** (`image/jpeg`) - camera snapshot link, can be converted by go2rtc to MJPEG stream\n- **HTTP-MJPEG** (`multipart/x`) - simple MJPEG stream over HTTP\n- **MPEG-TS** (`video/mpeg`) - legacy [streaming format](https://en.wikipedia.org/wiki/MPEG_transport_stream)\n\nSource also supports HTTP and TCP streams with autodetection for different formats: **MJPEG**, **H.264/H.265 bitstream**, **MPEG-TS**.\n\n```yaml\nstreams:\n  # [HTTP-FLV] stream in video/x-flv format\n  http_flv: http://192.168.1.123:20880/api/camera/stream/780900131155/657617\n  \n  # [JPEG] snapshots from Dahua camera, will be converted to MJPEG stream\n  dahua_snap: http://admin:password@192.168.1.123/cgi-bin/snapshot.cgi?channel=1\n\n  # [MJPEG] stream will be proxied without modification\n  http_mjpeg: https://mjpeg.sanford.io/count.mjpeg\n\n  # [MJPEG or H.264/H.265 bitstream or MPEG-TS]\n  tcp_magic: tcp://192.168.1.123:12345\n\n  # Add custom header\n  custom_header: \"https://mjpeg.sanford.io/count.mjpeg#header=Authorization: Bearer XXX\"\n```\n\n**PS.** Dahua camera has a bug: if you select MJPEG codec for RTSP second stream, snapshot won't work.\n\n## Source: ONVIF\n\n*[New in v1.5.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.5.0)*\n\nThe source is not very useful if you already know RTSP and snapshot links for your camera. But it can be useful if you don't.\n\n**WebUI > Add** webpage support ONVIF autodiscovery. Your server must be on the same subnet as the camera. If you use Docker, you must use \"network host\".\n\n```yaml\nstreams:\n  dahua1: onvif://admin:password@192.168.1.123\n  reolink1: onvif://admin:password@192.168.1.123:8000\n  tapo1: onvif://admin:password@192.168.1.123:2020\n```\n\n## Source: FFmpeg\n\nYou can get any stream, file or device via FFmpeg and push it to go2rtc. The app will automatically start FFmpeg with the proper arguments when someone starts watching the stream.\n\n- FFmpeg preinstalled for **Docker** and **Home Assistant add-on** users\n- **Home Assistant add-on** users can target files from [/media](https://www.home-assistant.io/more-info/local-media/setup-media/) folder\n\nFormat: `ffmpeg:{input}#{param1}#{param2}#{param3}`. Examples:\n\n```yaml\nstreams:\n  # [FILE] all tracks will be copied without transcoding codecs\n  file1: ffmpeg:/media/BigBuckBunny.mp4\n\n  # [FILE] video will be transcoded to H264, audio will be skipped\n  file2: ffmpeg:/media/BigBuckBunny.mp4#video=h264\n\n  # [FILE] video will be copied, audio will be transcoded to PCMU\n  file3: ffmpeg:/media/BigBuckBunny.mp4#video=copy#audio=pcmu\n\n  # [HLS] video will be copied, audio will be skipped\n  hls: ffmpeg:https://devstreaming-cdn.apple.com/videos/streaming/examples/bipbop_16x9/gear5/prog_index.m3u8#video=copy\n\n  # [MJPEG] video will be transcoded to H264\n  mjpeg: ffmpeg:http://185.97.122.128/cgi-bin/faststream.jpg#video=h264\n\n  # [RTSP] video with rotation, should be transcoded, so select H264\n  rotate: ffmpeg:rtsp://12345678@192.168.1.123/av_stream/ch0#video=h264#rotate=90\n```\n\nAll transcoding formats have [built-in templates](internal/ffmpeg/ffmpeg.go): `h264`, `h265`, `opus`, `pcmu`, `pcmu/16000`, `pcmu/48000`, `pcma`, `pcma/16000`, `pcma/48000`, `aac`, `aac/16000`.\n\nBut you can override them via YAML config. You can also add your own formats to the config and use them with source params.\n\n```yaml\nffmpeg:\n  bin: ffmpeg  # path to ffmpeg binary\n  global: \"-hide_banner\"\n  timeout: 5  # default timeout in seconds for rtsp inputs\n  h264: \"-codec:v libx264 -g:v 30 -preset:v superfast -tune:v zerolatency -profile:v main -level:v 4.1\"\n  mycodec: \"-any args that supported by ffmpeg...\"\n  myinput: \"-fflags nobuffer -flags low_delay -timeout {timeout} -i {input}\"\n  myraw: \"-ss 00:00:20\"\n```\n\n- You can use go2rtc stream name as ffmpeg input (ex. `ffmpeg:camera1#video=h264`)\n- You can use `video` and `audio` params multiple times (ex. `#video=copy#audio=copy#audio=pcmu`)\n- You can use `rotate` param with `90`, `180`, `270` or `-90` values, important with transcoding (ex. `#video=h264#rotate=90`)\n- You can use `width` and/or `height` params, important with transcoding (ex. `#video=h264#width=1280`)\n- You can use `drawtext` to add a timestamp (ex. `drawtext=x=2:y=2:fontsize=12:fontcolor=white:box=1:boxcolor=black`)\n  - This will greatly increase the CPU of the server, even with hardware acceleration\n- You can use `timeout` param to set RTSP input timeout in seconds (ex. `#timeout=10`)\n- You can use `raw` param for any additional FFmpeg arguments (ex. `#raw=-vf transpose=1`)\n- You can use `input` param to override default input template (ex. `#input=rtsp/udp` will change RTSP transport from TCP to UDP+TCP)\n  - You can use raw input value (ex. `#input=-timeout {timeout} -i {input}`)\n  - You can add your own input templates\n\nRead more about [hardware acceleration](https://github.com/AlexxIT/go2rtc/wiki/Hardware-acceleration).\n\n**PS.** It is recommended to check the available hardware in the WebUI add page.\n\n## Source: FFmpeg Device\n\nYou can get video from any USB camera or Webcam as RTSP or WebRTC stream. This is part of FFmpeg integration.\n\n- check available devices in web interface\n- `video_size` and `framerate` must be supported by your camera!\n- for Linux supported only video for now\n- for macOS you can stream FaceTime camera or whole desktop!\n- for macOS important to set right framerate\n\nFormat: `ffmpeg:device?{input-params}#{param1}#{param2}#{param3}`\n\n```yaml\nstreams:\n  linux_usbcam:   ffmpeg:device?video=0&video_size=1280x720#video=h264\n  windows_webcam: ffmpeg:device?video=0#video=h264\n  macos_facetime: ffmpeg:device?video=0&audio=1&video_size=1280x720&framerate=30#video=h264#audio=pcma\n```\n\n**PS.** It is recommended to check the available devices in the WebUI add page.\n\n## Source: Exec\n\nExec source can run any external application and expect data from it. Two transports are supported - **pipe** (*from [v1.5.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.5.0)*) and **RTSP**.\n\nIf you want to use **RTSP** transport, the command must contain the `{output}` argument in any place. On launch, it will be replaced by the local address of the RTSP server.\n\n**pipe** reads data from app stdout in different formats: **MJPEG**, **H.264/H.265 bitstream**, **MPEG-TS**. Also pipe can write data to app stdin in two formats: **PCMA** and **PCM/48000**.\n\nThe source can be used with:\n\n- [FFmpeg](https://ffmpeg.org/) - go2rtc ffmpeg source just a shortcut to exec source\n- [FFplay](https://ffmpeg.org/ffplay.html) - play audio on your server\n- [GStreamer](https://gstreamer.freedesktop.org/)\n- [Raspberry Pi Cameras](https://www.raspberrypi.com/documentation/computers/camera_software.html)\n- any of your own software\n\nPipe commands support parameters (format: `exec:{command}#{param1}#{param2}`):\n\n- `killsignal` - signal which will be sent to stop the process (numeric form)\n- `killtimeout` - time in seconds for forced termination with sigkill\n- `backchannel` - enable backchannel for two-way audio\n- `starttimeout` - time in seconds for waiting first byte from RTSP\n\n```yaml\nstreams:\n  stream: exec:ffmpeg -re -i /media/BigBuckBunny.mp4 -c copy -rtsp_transport tcp -f rtsp {output}\n  picam_h264: exec:libcamera-vid -t 0 --inline -o -\n  picam_mjpeg: exec:libcamera-vid -t 0 --codec mjpeg -o -\n  pi5cam_h264: exec:libcamera-vid -t 0 --libav-format h264 -o -\n  canon: exec:gphoto2 --capture-movie --stdout#killsignal=2#killtimeout=5\n  play_pcma: exec:ffplay -fflags nobuffer -f alaw -ar 8000 -i -#backchannel=1\n  play_pcm48k: exec:ffplay -fflags nobuffer -f s16be -ar 48000 -i -#backchannel=1\n```\n\n## Source: Echo\n\nSome sources may have a dynamic link. And you will need to get it using a Bash or Python script. Your script should echo a link to the source. RTSP, FFmpeg or any of the [supported sources](#module-streams).\n\n**Docker** and **Home Assistant add-on** users has preinstalled `python3`, `curl`, `jq`.\n\nCheck examples in [wiki](https://github.com/AlexxIT/go2rtc/wiki/Source-Echo-examples).\n\n```yaml\nstreams:\n  apple_hls: echo:python3 hls.py https://developer.apple.com/streaming/examples/basic-stream-osx-ios5.html\n```\n\n## Source: Expr\n\n*[New in v1.8.2](https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.2)*\n\nLike `echo` source, but uses the built-in [expr](https://github.com/antonmedv/expr) expression language.\n\n*[read more](internal/expr/README.md)*\n\n## Source: HomeKit\n\n**Important:**\n\n- You can use HomeKit Cameras **without Apple devices** (iPhone, iPad, etc.), it's just a yet another protocol\n- HomeKit device can be paired with only one ecosystem. So, if you have paired it to an iPhone (Apple Home), you can't pair it with Home Assistant or go2rtc. Or if you have paired it to go2rtc, you can't pair it with an iPhone\n- HomeKit device should be on the same network with working [mDNS](https://en.wikipedia.org/wiki/Multicast_DNS) between the device and go2rtc\n\ngo2rtc supports importing paired HomeKit devices from [Home Assistant](#source-hass). So you can use HomeKit camera with Home Assistant and go2rtc simultaneously. If you are using Home Assistant, I recommend pairing devices with it; it will give you more options.\n\nYou can pair device with go2rtc on the HomeKit page. If you can't see your devices, reload the page. Also, try rebooting your HomeKit device (power off). If you still can't see it, you have a problem with mDNS.\n\nIf you see a device but it does not have a pairing button, it is paired to some ecosystem (Apple Home, Home Assistant, HomeBridge etc). You need to delete the device from that ecosystem, and it will be available for pairing. If you cannot unpair the device, you will have to reset it.\n\n**Important:**\n\n- HomeKit audio uses very non-standard **AAC-ELD** codec with very non-standard params and specification violations\n- Audio can't be played in `VLC` and probably any other player\n- Audio should be transcoded for use with MSE, WebRTC, etc.\n\nRecommended settings for using HomeKit Camera with WebRTC, MSE, MP4, RTSP:\n\n```yaml\nstreams:\n  aqara_g3:\n    - hass:Camera-Hub-G3-AB12\n    - ffmpeg:aqara_g3#audio=aac#audio=opus\n```\n\nRTSP link with \"normal\" audio for any player: `rtsp://192.168.1.123:8554/aqara_g3?video&audio=aac`\n\n**This source is in active development!** Tested only with [Aqara Camera Hub G3](https://www.aqara.com/eu/product/camera-hub-g3) (both EU and CN versions).\n\n## Source: Bubble\n\n*[New in v1.6.1](https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.1)*\n\nOther names: [ESeeCloud](http://www.eseecloud.com/), [dvr163](http://help.dvr163.com/).\n\n- you can skip `username`, `password`, `port`, `ch` and `stream` if they are default\n- set up separate streams for different channels and streams\n\n```yaml\nstreams:\n  camera1: bubble://username:password@192.168.1.123:34567/bubble/live?ch=0&stream=0\n```\n\n## Source: DVRIP\n\n*[New in v1.2.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.2.0)*\n\nOther names: DVR-IP, NetSurveillance, Sofia protocol (NETsurveillance ActiveX plugin XMeye SDK).\n\n- you can skip `username`, `password`, `port`, `channel` and `subtype` if they are default\n- set up separate streams for different channels\n- use `subtype=0` for Main stream, and `subtype=1` for Extra1 stream\n- only the TCP protocol is supported\n\n```yaml\nstreams:\n  only_stream: dvrip://username:password@192.168.1.123:34567?channel=0&subtype=0\n  only_tts: dvrip://username:password@192.168.1.123:34567?backchannel=1\n  two_way_audio:\n    - dvrip://username:password@192.168.1.123:34567?channel=0&subtype=0\n    - dvrip://username:password@192.168.1.123:34567?backchannel=1\n```\n\n## Source: EseeCloud\n\n*[New in v1.9.10](https://github.com/AlexxIT/go2rtc/releases/tag/v1.9.10)*\n\n```yaml\nstreams:\n  camera1: eseecloud://user:pass@192.168.1.123:80/livestream/12\n```\n\n## Source: Tapo\n\n*[New in v1.2.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.2.0)*\n\n[TP-Link Tapo](https://www.tapo.com/) proprietary camera protocol with **two-way audio** support.\n\n- stream quality is the same as [RTSP protocol](https://www.tapo.com/en/faq/34/)\n- use the **cloud password**, this is not the RTSP password! you do not need to add a login!\n- you can also use **UPPERCASE** MD5 hash from your cloud password with `admin` username\n- some new camera firmwares require SHA256 instead of MD5\n\n```yaml\nstreams:\n  # cloud password without username\n  camera1: tapo://cloud-password@192.168.1.123\n  # admin username and UPPERCASE MD5 cloud-password hash\n  camera2: tapo://admin:UPPERCASE-MD5@192.168.1.123\n  # admin username and UPPERCASE SHA256 cloud-password hash\n  camera3: tapo://admin:UPPERCASE-SHA256@192.168.1.123\n  # VGA stream (the so called substream, the lower resolution one)\n  camera4: tapo://cloud-password@192.168.1.123?subtype=1 \n  # HD stream (default)\n  camera5: tapo://cloud-password@192.168.1.123?subtype=0 \n```\n\n```bash\necho -n \"cloud password\" | md5 | awk '{print toupper($0)}'\necho -n \"cloud password\" | shasum -a 256 | awk '{print toupper($0)}'\n```\n\n## Source: Kasa\n\n*[New in v1.7.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.7.0)*\n\n[TP-Link Kasa](https://www.kasasmart.com/) non-standard protocol [more info](https://medium.com/@hu3vjeen/reverse-engineering-tp-link-kc100-bac4641bf1cd).\n\n- `username` - urlsafe email, `alex@gmail.com` -> `alex%40gmail.com`\n- `password` - base64password, `secret1` -> `c2VjcmV0MQ==`\n\n```yaml\nstreams:\n  kc401: kasa://username:password@192.168.1.123:19443/https/stream/mixed\n```\n\nTested: KD110, KC200, KC401, KC420WS, EC71.\n\n## Source: Multitrans\n\nTwo-way audio support for Chinese version of [TP-Link cameras](https://www.tp-link.com.cn/list_2549.html).\n\n*[read more](internal/multitrans/README.md)*\n\n## Source: Tuya\n\n*[New in v1.9.13](https://github.com/AlexxIT/go2rtc/releases/tag/v1.9.13)*\n\n[Tuya](https://www.tuya.com/) proprietary camera protocol with **two-way audio** support. Go2rtc supports `Tuya Smart API` and `Tuya Cloud API`.\n\n*[read more](internal/tuya/README.md)*\n\n## Source: Xiaomi\n\n*[New in v1.9.13](https://github.com/AlexxIT/go2rtc/releases/tag/v1.9.13)*\n\nThis source allows you to view cameras from the [Xiaomi Mi Home](https://home.mi.com/) ecosystem.\n\n*[read more](internal/xiaomi/README.md)*\n\n## Source: Wyze\n\nThis source allows you to stream from [Wyze](https://wyze.com/) cameras using native P2P protocol - no `docker-wyze-bridge` required. Supports H.264/H.265 video, AAC/G.711 audio, and two-way audio.\n\n*[read more](internal/wyze/README.md)*\n\n## Source: GoPro\n\n*[New in v1.8.3](https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.3)*\n\nSupport streaming from [GoPro](https://gopro.com/) cameras, connected via USB or Wi-Fi to Linux, Mac, Windows.\n\n*[read more](internal/gopro/README.md)*\n\n## Source: Ivideon\n\nSupport public cameras from the service [Ivideon](https://tv.ivideon.com/).\n\n```yaml\nstreams:\n  quailcam: ivideon:100-tu5dkUPct39cTp9oNEN2B6/0\n```\n\n## Source: Hass\n\nSupport import camera links from [Home Assistant](https://www.home-assistant.io/) config files:\n\n- [Generic Camera](https://www.home-assistant.io/integrations/generic/), setup via GUI\n- [HomeKit Camera](https://www.home-assistant.io/integrations/homekit_controller/)\n- [ONVIF](https://www.home-assistant.io/integrations/onvif/)\n- [Roborock](https://github.com/humbertogontijo/homeassistant-roborock) vacuums with camera\n\n```yaml\nhass:\n  config: \"/config\"  # skip this setting if you are a Home Assistant add-on user\n\nstreams:\n  generic_camera: hass:Camera1  # Settings > Integrations > Integration Name\n  aqara_g3: hass:Camera-Hub-G3-AB12\n```\n\n**WebRTC Cameras** (*from [v1.6.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.0)*)\n\nAny cameras in WebRTC format are supported. But at the moment Home Assistant only supports some [Nest](https://www.home-assistant.io/integrations/nest/) cameras in this format.\n\n**Important.** The Nest API only allows you to get a link to a stream for 5 minutes. Do not use this with Frigate! If the stream expires, Frigate will consume all available RAM on your machine within seconds. It's recommended to use [Nest source](#source-nest) - it supports extending the stream.\n\n```yaml\nstreams:\n  # link to Home Assistant Supervised\n  hass-webrtc1: hass://supervisor?entity_id=camera.nest_doorbell\n  # link to external Home Assistant with Long-Lived Access Tokens\n  hass-webrtc2: hass://192.168.1.123:8123?entity_id=camera.nest_doorbell&token=eyXYZ...\n```\n\n**RTSP Cameras**\n\nBy default, the Home Assistant API does not allow you to get a dynamic RTSP link to a camera stream. [This method](https://github.com/felipecrs/hass-expose-camera-stream-source#importing-cameras-from-home-assistant-to-go2rtc-or-frigate) can work around it.\n\n## Source: ISAPI\n\n*[New in v1.3.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0)*\n\nThis source type supports only backchannel audio for the Hikvision ISAPI protocol. So it should be used as a second source in addition to the RTSP protocol.\n\n```yaml\nstreams:\n  hikvision1:\n    - rtsp://admin:password@192.168.1.123:554/Streaming/Channels/101\n    - isapi://admin:password@192.168.1.123:80/\n```\n\n## Source: Nest\n\n*[New in v1.6.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.0)*\n\nCurrently, only WebRTC cameras are supported.\n\nFor simplicity, it is recommended to connect the Nest/WebRTC camera to the [Home Assistant](#source-hass). But if you can somehow get the below parameters, Nest/WebRTC source will work without Home Assistant.\n\n```yaml\nstreams:\n  nest-doorbell: nest:?client_id=***&client_secret=***&refresh_token=***&project_id=***&device_id=***\n```\n\n## Source: Ring\n\nThis source type support Ring cameras with [two-way audio](#two-way-audio) support. If you have a `refresh_token` and `device_id` - you can use it in `go2rtc.yaml` config file. Otherwise, you can use the go2rtc interface and add your ring account (WebUI > Add > Ring). Once added, it will list all your Ring cameras.\n\n```yaml\nstreams:\n  ring: ring:?device_id=XXX&refresh_token=XXX\n  ring_snapshot: ring:?device_id=XXX&refresh_token=XXX&snapshot\n```\n\n## Source: Roborock\n\n*[New in v1.3.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0)*\n\nThis source type supports Roborock vacuums with cameras. Known working models:\n\n- Roborock S6 MaxV - only video (the vacuum has no microphone)\n- Roborock S7 MaxV - video and two-way audio\n- Roborock Qrevo MaxV - video and two-way audio\n\nSource supports loading Roborock credentials from Home Assistant [custom integration](https://github.com/humbertogontijo/homeassistant-roborock) or the [core integration](https://www.home-assistant.io/integrations/roborock). Otherwise, you need to log in to your Roborock account (MiHome account is not supported). Go to: go2rtc WebUI > Add webpage. Copy `roborock://...` source for your vacuum and paste it to `go2rtc.yaml` config.\n\nIf you have a graphic PIN for your vacuum, add it as a numeric PIN (lines: 123, 456, 789) to the end of the `roborock` link.\n\n## Source: Doorbird\n\nThis source type supports [Doorbird](https://www.doorbird.com/) devices including MJPEG stream, audio stream as well as two-way audio.\n\n*[read more](internal/doorbird/README.md)*\n\n## Source: WebRTC\n\n*[New in v1.3.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0)*\n\nThis source type supports four connection formats.\n\n**whep**\n\n[WebRTC/WHEP](https://datatracker.ietf.org/doc/draft-murillo-whep/) is replaced by [WebRTC/WISH](https://datatracker.ietf.org/doc/charter-ietf-wish/02/) standard for WebRTC video/audio viewers. But it may already be supported in some third-party software. It is supported in go2rtc.\n\n**go2rtc**\n\nThis format is only supported in go2rtc. Unlike WHEP, it supports asynchronous WebRTC connections and two-way audio.\n\n**openipc** (*from [v1.7.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.7.0)*)\n\nSupport connection to [OpenIPC](https://openipc.org/) cameras.\n\n**wyze (via docker-wyze-bridge)** (*from [v1.6.1](https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.1)*)\n\nLegacy method to connect to [Wyze](https://www.wyze.com/) cameras using WebRTC protocol via [docker-wyze-bridge](https://github.com/mrlt8/docker-wyze-bridge). For native P2P support without docker-wyze-bridge, see [Source: Wyze](#source-wyze).\n\n**kinesis** (*from [v1.6.1](https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.1)*)\n\nSupports [Amazon Kinesis Video Streams](https://aws.amazon.com/kinesis/video-streams/), using WebRTC protocol. You need to specify the signalling WebSocket URL with all credentials in query params, `client_id` and `ice_servers` list in [JSON format](https://developer.mozilla.org/en-US/docs/Web/API/RTCIceServer).\n\n**switchbot**\n\nSupport connection to [SwitchBot](https://us.switch-bot.com/) cameras that are based on Kinesis Video Streams. Specifically, this includes [Pan/Tilt Cam Plus 2K](https://us.switch-bot.com/pages/switchbot-pan-tilt-cam-plus-2k) and [Pan/Tilt Cam Plus 3K](https://us.switch-bot.com/pages/switchbot-pan-tilt-cam-plus-3k) and [Smart Video Doorbell](https://www.switchbot.jp/products/switchbot-smart-video-doorbell). `Outdoor Spotlight Cam 1080P`, `Outdoor Spotlight Cam 2K`, `Pan/Tilt Cam`, `Pan/Tilt Cam 2K`, `Indoor Cam` are based on Tuya, so this feature is not available.\n\n```yaml\nstreams:\n  webrtc-whep:      webrtc:http://192.168.1.123:1984/api/webrtc?src=camera1\n  webrtc-go2rtc:    webrtc:ws://192.168.1.123:1984/api/ws?src=camera1\n  webrtc-openipc:   webrtc:ws://192.168.1.123/webrtc_ws#format=openipc#ice_servers=[{\"urls\":\"stun:stun.kinesisvideo.eu-north-1.amazonaws.com:443\"}]\n  webrtc-wyze:      webrtc:http://192.168.1.123:5000/signaling/camera1?kvs#format=wyze\n  webrtc-kinesis:   webrtc:wss://...amazonaws.com/?...#format=kinesis#client_id=...#ice_servers=[{...},{...}]\n  webrtc-switchbot: webrtc:wss://...amazonaws.com/?...#format=switchbot#resolution=hd#play_type=0#client_id=...#ice_servers=[{...},{...}]\n```\n\n**PS.** For `kinesis` sources, you can use [echo](#source-echo) to get connection params using `bash`, `python` or any other script language.\n\n## Source: WebTorrent\n\n*[New in v1.3.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0)*\n\nThis source can get a stream from another go2rtc via [WebTorrent](#module-webtorrent) protocol.\n\n```yaml\nstreams:\n  webtorrent1: webtorrent:?share=huofssuxaty00izc&pwd=k3l2j9djeg8v8r7e\n```\n\n## Incoming sources\n\nBy default, go2rtc establishes a connection to the source when any client requests it. Go2rtc drops the connection to the source when it has no clients left.\n\n- Go2rtc also can accepts incoming sources in [RTSP](#module-rtsp), [RTMP](#module-rtmp), [HTTP](#source-http) and **WebRTC/WHIP** formats\n- Go2rtc won't stop such a source if it has no clients\n- You can push data only to an existing stream (create a stream with empty source in config)\n- You can push multiple incoming sources to the same stream\n- You can push data to a non-empty stream, so it will have additional codecs inside\n\n**Examples**\n\n- RTSP with any codec\n\n  ```yaml\n  ffmpeg -re -i BigBuckBunny.mp4 -c copy -rtsp_transport tcp -f rtsp rtsp://localhost:8554/camera1\n  ```\n\n- HTTP-MJPEG with MJPEG codec\n\n  ```yaml\n  ffmpeg -re -i BigBuckBunny.mp4 -c mjpeg -f mpjpeg http://localhost:1984/api/stream.mjpeg?dst=camera1\n  ```\n\n- HTTP-FLV with H264, AAC codecs\n\n  ```yaml\n  ffmpeg -re -i BigBuckBunny.mp4 -c copy -f flv http://localhost:1984/api/stream.flv?dst=camera1\n  ```\n\n- MPEG-TS with H264 codec\n\n  ```yaml\n  ffmpeg -re -i BigBuckBunny.mp4 -c copy -f mpegts http://localhost:1984/api/stream.ts?dst=camera1\n  ```\n\n### Incoming: Browser\n\n*[New in v1.3.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0)*\n\nYou can turn the browser of any PC or mobile into an IP camera with support for video and two-way audio. Or even broadcast your PC screen:\n\n1. Create empty stream in the `go2rtc.yaml`\n2. Go to go2rtc WebUI\n3. Open `links` page for your stream\n4. Select `camera+microphone` or `display+speaker` option\n5. Open `webrtc` local page (your go2rtc **should work over HTTPS!**) or `share link` via [WebTorrent](#module-webtorrent) technology (work over HTTPS by default)\n\n### Incoming: WebRTC/WHIP\n\n*[New in v1.3.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0)*\n\nYou can use **OBS Studio** or any other broadcast software with [WHIP](https://www.ietf.org/archive/id/draft-ietf-wish-whip-01.html) protocol support. This standard has not yet been approved. But you can download OBS Studio [dev version](https://github.com/obsproject/obs-studio/actions/runs/3969201209):\n\n- Settings > Stream > Service: WHIP > `http://192.168.1.123:1984/api/webrtc?dst=camera1`\n\n## Stream to camera\n\n*[New in v1.3.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0)*\n\ngo2rtc supports playing audio files (ex. music or [TTS](https://www.home-assistant.io/integrations/#text-to-speech)) and live streams (ex. radio) on cameras with [two-way audio](#two-way-audio) support (RTSP/ONVIF cameras, TP-Link Tapo, Hikvision ISAPI, Roborock vacuums, any Browser).\n\nAPI example:\n\n```text\nPOST http://localhost:1984/api/streams?dst=camera1&src=ffmpeg:http://example.com/song.mp3#audio=pcma#input=file\n```\n\n- you can stream: local files, web files, live streams or any format, supported by FFmpeg\n- you should use [ffmpeg source](#source-ffmpeg) for transcoding audio to codec, that your camera supports\n- you can check camera codecs on the go2rtc WebUI info page when the stream is active\n- some cameras support only low quality `PCMA/8000` codec (ex. [Tapo](#source-tapo))\n- it is recommended to choose higher quality formats if your camera supports them (ex. `PCMA/48000` for some Dahua cameras)\n- if you play files over `http` link, you need to add `#input=file` params for transcoding, so the file will be transcoded and played in real time\n- if you play live streams, you should skip `#input` param, because it is already in real time\n- you can stop active playback by calling the API with the empty `src` parameter\n- you will see one active producer and one active consumer in go2rtc WebUI info page during streaming\n\n## Publish stream\n\n*[New in v1.8.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.0)*\n\nYou can publish any stream to streaming services (YouTube, Telegram, etc.) via RTMP/RTMPS. Important:\n\n- Supported codecs: H264 for video and AAC for audio\n- AAC audio is required for YouTube; videos without audio will not work\n- You don't need to enable [RTMP module](#module-rtmp) listening for this task\n\nYou can use the API:\n\n```text\nPOST http://localhost:1984/api/streams?src=camera1&dst=rtmps://...\n```\n\nOr config file:\n\n```yaml\npublish:\n  # publish stream \"video_audio_transcode\" to Telegram\n  video_audio_transcode:\n    - rtmps://xxx-x.rtmp.t.me/s/xxxxxxxxxx:xxxxxxxxxxxxxxxxxxxxxx\n  # publish stream \"audio_transcode\" to Telegram and YouTube\n  audio_transcode:\n    - rtmps://xxx-x.rtmp.t.me/s/xxxxxxxxxx:xxxxxxxxxxxxxxxxxxxxxx\n    - rtmp://xxx.rtmp.youtube.com/live2/xxxx-xxxx-xxxx-xxxx-xxxx\n\nstreams:\n  video_audio_transcode:\n    - ffmpeg:rtsp://user:pass@192.168.1.123/stream1#video=h264#hardware#audio=aac\n  audio_transcode:\n    - ffmpeg:rtsp://user:pass@192.168.1.123/stream1#video=copy#audio=aac\n```\n\n- **Telegram Desktop App** > Any public or private channel or group (where you admin) > Live stream > Start with... > Start streaming.\n- **YouTube** > Create > Go live > Stream latency: Ultra low-latency > Copy: Stream URL + Stream key.\n\n## Preload stream\n\nYou can preload any stream on go2rtc start. This is useful for cameras that take a long time to start up.\n\n```yaml\npreload:\n  camera1:                                     # default: video&audio = ANY\n  camera2: \"video\"                             # preload only video track\n  camera3: \"video=h264&audio=opus\"             # preload H264 video and OPUS audio\n\nstreams:\n  camera1: \n    - rtsp://192.168.1.100/stream\n  camera2: \n    - rtsp://192.168.1.101/stream  \n  camera3: \n    - rtsp://192.168.1.102/h265stream\n    - ffmpeg:camera3#video=h264#audio=opus#hardware\n```\n\n## Module: API\n\nThe HTTP API is the main part for interacting with the application. Default address: `http://localhost:1984/`.\n\n**Important!** go2rtc passes requests from localhost and from Unix sockets without HTTP authorisation, even if you have it configured! It is your responsibility to set up secure external access to the API. If not properly configured, an attacker can gain access to your cameras and even your server.\n\n[API description](api/README.md).\n\n**Module config**\n\n- you can disable HTTP API with `listen: \"\"` and use, for example, only RTSP client/server protocol\n- you can enable HTTP API only on localhost with `listen: \"127.0.0.1:1984\"` setting\n- you can change the API `base_path` and host go2rtc on your main app webserver suburl\n- all files from `static_dir` hosted on root path: `/`\n- you can use raw TLS cert/key content or path to files\n\n```yaml\napi:\n  listen: \":1984\"    # default \":1984\", HTTP API port (\"\" - disabled)\n  username: \"admin\"  # default \"\", Basic auth for WebUI\n  password: \"pass\"   # default \"\", Basic auth for WebUI\n  local_auth: true   # default false, Enable auth check for localhost requests\n  base_path: \"/rtc\"  # default \"\", API prefix for serving on suburl (/api => /rtc/api)\n  static_dir: \"www\"  # default \"\", folder for static files (custom web interface)\n  origin: \"*\"        # default \"\", allow CORS requests (only * supported)\n  tls_listen: \":443\" # default \"\", enable HTTPS server\n  tls_cert: |        # default \"\", PEM-encoded fullchain certificate for HTTPS\n    -----BEGIN CERTIFICATE-----\n    ...\n    -----END CERTIFICATE-----\n  tls_key: |         # default \"\", PEM-encoded private key for HTTPS\n    -----BEGIN PRIVATE KEY-----\n    ...\n    -----END PRIVATE KEY-----\n  unix_listen: \"/tmp/go2rtc.sock\"  # default \"\", unix socket listener for API\n```\n\n**PS:**\n\n- MJPEG over WebSocket plays better than native MJPEG because Chrome [bug](https://bugs.chromium.org/p/chromium/issues/detail?id=527446)\n- MP4 over WebSocket was created only for Apple iOS because it doesn't support MSE and native MP4\n\n## Module: RTSP\n\nYou can get any stream as RTSP-stream: `rtsp://192.168.1.123:8554/{stream_name}`\n\nYou can enable external password protection for your RTSP streams. Password protection is always disabled for localhost calls (ex. FFmpeg or Home Assistant on the same server).\n\n```yaml\nrtsp:\n  listen: \":8554\"    # RTSP Server TCP port, default - 8554\n  username: \"admin\"  # optional, default - disabled\n  password: \"pass\"   # optional, default - disabled\n  default_query: \"video&audio\"  # optional, default codecs filters \n```\n\nBy default go2rtc provide RTSP-stream with only one first video and only one first audio. You can change it with the `default_query` setting:\n\n- `default_query: \"mp4\"` - MP4 compatible codecs (H264, H265, AAC)\n- `default_query: \"video=all&audio=all\"` - all tracks from all source (not all players can handle this)\n- `default_query: \"video=h264,h265\"` - only one video track (H264 or H265)\n- `default_query: \"video&audio=all\"` - only one first any video and all audio as separate tracks\n\nRead more about [codecs filters](#codecs-filters).\n\n## Module: RTMP\n\n*[New in v1.8.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.0)*\n\nYou can get any stream as RTMP-stream: `rtmp://192.168.1.123/{stream_name}`. Only H264/AAC codecs supported right now.\n\n[Incoming stream](#incoming-sources) in RTMP format tested only with [OBS Studio](https://obsproject.com/) and a Dahua camera. Different FFmpeg versions have different problems with this format.\n\n```yaml\nrtmp:\n  listen: \":1935\"  # by default - disabled!\n```\n\n## Module: WebRTC\n\nIn most cases, [WebRTC](https://en.wikipedia.org/wiki/WebRTC) uses a direct peer-to-peer connection from your browser to go2rtc and sends media data via UDP.\nIt **can't pass** media data through your Nginx or Cloudflare or [Nabu Casa](https://www.nabucasa.com/) HTTP TCP connection!\nIt can automatically detect your external IP via a public [STUN](https://en.wikipedia.org/wiki/STUN) server.\nIt can establish an external direct connection via [UDP hole punching](https://en.wikipedia.org/wiki/UDP_hole_punching) technology even if you do not open your server to the World.\n\nBut about 10-20% of users may need to configure additional settings for external access if **mobile phone** or **go2rtc server** is behind [Symmetric NAT](https://tomchen.github.io/symmetric-nat-test/).\n\n- by default, WebRTC uses both TCP and UDP on port 8555 for connections\n- you can use this port for external access\n- you can change the port in YAML config:\n\n```yaml\nwebrtc:\n  listen: \":8555\"  # address of your local server and port (TCP/UDP)\n```\n\n**Static public IP**\n\n- forward the port 8555 on your router (you can use the same 8555 port or any other as external port)\n- add your external IP address and external port to the YAML config\n\n```yaml\nwebrtc:\n  candidates:\n    - 216.58.210.174:8555  # if you have a static public IP address\n```\n\n**Dynamic public IP**\n\n- forward the port 8555 on your router (you can use the same 8555 port or any other as the external port)\n- add `stun` word and external port to YAML config\n  - go2rtc automatically detects your external address with STUN server\n\n```yaml\nwebrtc:\n  candidates:\n    - stun:8555  # if you have a dynamic public IP address\n```\n\n**Hard tech way 1. Own TCP-tunnel**\n\nIf you have a personal [VPS](https://en.wikipedia.org/wiki/Virtual_private_server), you can create a TCP tunnel and setup in the same way as \"Static public IP\". But use your VPS IP address in the YAML config.\n\n**Hard tech way 2. Using TURN-server**\n\nIf you have personal [VPS](https://en.wikipedia.org/wiki/Virtual_private_server), you can install TURN server (e.g. [coturn](https://github.com/coturn/coturn), config [example](https://github.com/AlexxIT/WebRTC/wiki/Coturn-Example)).\n\n```yaml\nwebrtc:\n  ice_servers:\n    - urls: [stun:stun.l.google.com:19302]\n    - urls: [turn:123.123.123.123:3478]\n      username: your_user\n      credential: your_pass\n```\n\n## Module: HomeKit\n\n*[New in v1.7.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.7.0)*\n\nHomeKit module can work in two modes:\n\n- export any H264 camera to Apple HomeKit\n- transparent proxy any Apple HomeKit camera (Aqara, Eve, Eufy, etc.) back to Apple HomeKit, so you will have all camera features in Apple Home and also will have RTSP/WebRTC/MP4/etc. from your HomeKit camera\n\n**Important**\n\n- HomeKit cameras support only H264 video and OPUS audio\n\n**Minimal config**\n\n```yaml\nstreams:\n  dahua1: rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&subtype=0\nhomekit:\n  dahua1:  # same stream ID from streams list, default PIN - 19550224\n```\n\n**Full config**\n\n```yaml\nstreams:\n  dahua1:\n    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&subtype=0\n    - ffmpeg:dahua1#video=h264#hardware  # if your camera doesn't support H264, important for HomeKit\n    - ffmpeg:dahua1#audio=opus           # only OPUS audio supported by HomeKit\n\nhomekit:\n  dahua1:                   # same stream ID from streams list\n    pin: 12345678           # custom PIN, default: 19550224\n    name: Dahua camera      # custom camera name, default: generated from stream ID\n    device_id: dahua1       # custom ID, default: generated from stream ID\n    device_private: dahua1  # custom key, default: generated from stream ID\n```\n\n**Proxy HomeKit camera**\n\n- Video stream from HomeKit camera to Apple device (iPhone, AppleTV) will be transmitted directly\n- Video stream from HomeKit camera to RTSP/WebRTC/MP4/etc. will be transmitted via go2rtc\n\n```yaml\nstreams:\n  aqara1:\n    - homekit://...\n    - ffmpeg:aqara1#audio=aac#audio=opus  # optional audio transcoding\n\nhomekit:\n  aqara1:  # same stream ID from streams list\n```\n\n## Module: WebTorrent\n\n*[New in v1.3.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0)*\n\nThis module supports:\n\n- Share any local stream via [WebTorrent](https://webtorrent.io/) technology\n- Get any [incoming stream](#incoming-browser) from PC or mobile via [WebTorrent](https://webtorrent.io/) technology\n- Get any remote [go2rtc source](#source-webtorrent) via [WebTorrent](https://webtorrent.io/) technology\n\nSecurely and freely. You do not need to open a public access to the go2rtc server. But in some cases (Symmetric NAT), you may need to set up external access to [WebRTC module](#module-webrtc).\n\nTo generate a sharing link or incoming link, go to the go2rtc WebUI (stream links page). This link is **temporary** and will stop working after go2rtc is restarted!\n\nYou can create permanent external links in the go2rtc config:\n\n```yaml\nwebtorrent:\n  shares:\n    super-secret-share:  # share name, should be unique among all go2rtc users!\n      pwd: super-secret-password\n      src: rtsp-dahua1   # stream name from streams section\n```\n\nLink example: `https://go2rtc.org/webtorrent/#share=02SNtgjKXY&pwd=wznEQqznxW&media=video+audio`\n\n## Module: ngrok\n\nWith [ngrok](https://ngrok.com/) integration, you can get external access to your streams in situations when you have internet with a private IP address.\n\n*[read more](internal/ngrok/README.md)*\n\n## Module: Hass\n\nWhile [go2rtc is used by default in Home Assistant](https://www.home-assistant.io/integrations/go2rtc/), the best and easiest way to have full control over it is to install the [WebRTC Camera](#go2rtc-home-assistant-integration) custom integration and card.\n\nYou have several options on how to add a camera to Home Assistant:\n\n1. Camera RTSP source => [Generic Camera](https://www.home-assistant.io/integrations/generic/)\n2. Camera [any source](#module-streams) => [go2rtc config](#configuration) => [Generic Camera](https://www.home-assistant.io/integrations/generic/)\n   - Install any [go2rtc](#fast-start)\n   - Add your stream to [go2rtc config](#configuration)\n   - Home Assistant > Settings > Integrations > Add Integration > [ONVIF](https://my.home-assistant.io/redirect/config_flow_start/?domain=onvif) > Host: `127.0.0.1`, Port: `1984`\n   - Home Assistant > Settings > Integrations > Add Integration > [Generic Camera](https://my.home-assistant.io/redirect/config_flow_start/?domain=generic) > Stream Source URL: `rtsp://127.0.0.1:8554/camera1` (change to your stream name, leave everything else as is)\n\nYou have several options on how to watch the stream from the cameras in Home Assistant:\n\n1. `Camera Entity` => `Picture Entity Card` => Technology `WebRTC` (through [built-in go2rtc](https://www.home-assistant.io/integrations/go2rtc/)), codecs `H264/H265/AAC/PCMU/PCMA/OPUS`, best latency. Fallbacks to: Technology `HLS`, codecs: `H264/H265/AAC`, poor latency.\n2. `Camera Entity` or `Camera URL` => [WebRTC Camera](https://github.com/AlexxIT/WebRTC) => Technology: `WebRTC/MSE/MP4/MJPEG`, codecs: `H264/H265/AAC/PCMU/PCMA/OPUS`, best latency, best compatibility.\n   - Install and add [WebRTC Camera](https://github.com/AlexxIT/WebRTC) custom integration\n   - Use WebRTC Camera custom card in your dashboard\n\nYou can add camera `entity_id` to [go2rtc config](#configuration) if you need transcoding:\n\n```yaml\nstreams:\n  \"camera.hall\": ffmpeg:{input}#video=copy#audio=opus\n```\n\n**PS.** Default Home Assistant cards don't support two-way audio. You can use two-way audio from the [add-on Web UI](https://my.home-assistant.io/redirect/supervisor_addon/?addon=a889bffc_go2rtc&repository_url=https%3A%2F%2Fgithub.com%2FAlexxIT%2Fhassio-addons), but you need to use HTTPS to access the microphone. This is a browser restriction and cannot be avoided.\n\n**PS.** There is also another nice card with two-way audio support through go2rtc - [Advanced Camera Card](https://github.com/dermotduffy/advanced-camera-card).\n\n## Module: MP4\n\nProvides several features:\n\n1. MSE stream (fMP4 over WebSocket)\n2. Camera snapshots in MP4 format (single frame), can be sent to [Telegram](https://github.com/AlexxIT/go2rtc/wiki/Snapshot-to-Telegram)\n3. HTTP progressive streaming (MP4 file stream) - bad format for streaming because of high start delay. This format doesn't work in all Safari browsers, but go2rtc will automatically redirect it to HLS/fMP4 in this case.\n\nAPI examples:\n\n- MP4 snapshot: `http://192.168.1.123:1984/api/frame.mp4?src=camera1` (H264, H265)\n- MP4 stream: `http://192.168.1.123:1984/api/stream.mp4?src=camera1` (H264, H265, AAC)\n- MP4 file: `http://192.168.1.123:1984/api/stream.mp4?src=camera1` (H264, H265*, AAC, OPUS, MP3, PCMA, PCMU, PCM)\n  - You can use `mp4`, `mp4=flac` and `mp4=all` param for codec filters\n  - You can use `duration` param in seconds (ex. `duration=15`)\n  - You can use `filename` param (ex. `filename=record.mp4`)\n  - You can use `rotate` param with `90`, `180` or `270` values\n  - You can use `scale` param with positive integer values (ex. `scale=4:3`)\n\nRead more about [codecs filters](#codecs-filters).\n\n**PS.** Rotate and scale params don't use transcoding and change video using metadata.\n\n## Module: HLS\n\n*[New in v1.1.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.1.0)*\n\n[HLS](https://en.wikipedia.org/wiki/HTTP_Live_Streaming) is the worst technology for real-time streaming. It can only be useful on devices that do not support more modern technology, like [WebRTC](#module-webrtc), [MSE/MP4](#module-mp4).\n\nThe go2rtc implementation differs from the standards and may not work with all players.\n\nAPI examples:\n\n- HLS/TS stream: `http://192.168.1.123:1984/api/stream.m3u8?src=camera1` (H264)\n- HLS/fMP4 stream: `http://192.168.1.123:1984/api/stream.m3u8?src=camera1&mp4` (H264, H265, AAC)\n\nRead more about [codecs filters](#codecs-filters).\n\n## Module: MJPEG\n\n- This module can provide and receive streams in MJPEG format.\n- This module is also responsible for receiving snapshots in JPEG format.\n- This module also supports streaming to the server console (terminal) in the **animated ASCII art** format.\n\n*[read more](internal/mjpeg/README.md)*\n\n## Module: Log\n\nYou can set different log levels for different modules.\n\n```yaml\nlog:\n  level: info  # default level\n  api: trace\n  exec: debug\n  rtsp: warn\n  streams: error\n  webrtc: fatal\n```\n\n# Security\n\n> [!IMPORTANT]\n> If an attacker gains access to the API, you are in danger. Through the API, an attacker can use insecure sources such as echo and exec. And get full access to your server.\n\nFor maximum (paranoid) security, go2rtc has special settings:\n\n```yaml\napp:\n  # use only allowed modules\n  modules: [api, rtsp, webrtc, exec, ffmpeg, mjpeg]\n\napi:\n  # use only allowed API paths\n  allow_paths: [/api, /api/streams, /api/webrtc, /api/frame.jpeg]\n  # enable auth for localhost (used together with username and password)\n  local_auth: true\n\nexec:\n  # use only allowed exec paths\n  allow_paths: [ffmpeg]\n```\n\nBy default, `go2rtc` starts the Web interface on port `1984` and RTSP on port `8554`, as well as uses port `8555` for WebRTC connections. The three ports are accessible from your local network. So anyone on your local network can watch video from your cameras without authorization. The same rule applies to the Home Assistant add-on.\n\nThis is not a problem if you trust your local network as much as I do. But you can change this behaviour with a `go2rtc.yaml` config:\n\n```yaml\napi:\n  listen: \"127.0.0.1:1984\" # localhost\n\nrtsp:\n  listen: \"127.0.0.1:8554\" # localhost\n\nwebrtc:\n  listen: \":8555\" # external TCP/UDP port\n```\n\n- local access to RTSP is not a problem for [FFmpeg](#source-ffmpeg) integration, because it runs locally on your server\n- local access to API is not a problem for the [Home Assistant add-on](#go2rtc-home-assistant-add-on), because Home Assistant runs locally on the same server, and the add-on web UI is protected with Home Assistant authorization ([Ingress feature](https://www.home-assistant.io/blog/2019/04/15/hassio-ingress/))\n- external access to WebRTC TCP port is not a problem, because it is used only for transmitting encrypted media data\n  - anyway you need to open this port to your local network and to the Internet for WebRTC to work\n\nIf you need web interface protection without the Home Assistant add-on, you need to use a reverse proxy, like [Nginx](https://nginx.org/), [Caddy](https://caddyserver.com/), etc.\n\nPS. Additionally, WebRTC will try to use the 8555 UDP port to transmit encrypted media. It works without problems on the local network, and sometimes also works for external access, even if you haven't opened this port on your router ([read more](https://en.wikipedia.org/wiki/UDP_hole_punching)). But for stable external WebRTC access, you need to open the 8555 port on your router for both TCP and UDP.\n\n# Codecs filters\n\ngo2rtc can automatically detect which codecs your device supports for [WebRTC](#module-webrtc) and [MSE](#module-mp4) technologies.\n\nBut it cannot be done for [RTSP](#module-rtsp), [HTTP progressive streaming](#module-mp4), [HLS](#module-hls) technologies. You can manually add a codec filter when you create a link to a stream. The filters work the same for all three technologies. Filters do not create a new codec. They only select the suitable codec from existing sources. You can add new codecs to the stream using the [FFmpeg transcoding](#source-ffmpeg).\n\nWithout filters:\n\n- RTSP will provide only the first video and only the first audio (any codec)\n- MP4 will include only compatible codecs (H264, H265, AAC)\n- HLS will output in the legacy TS format (H264 without audio)\n\nSome examples:\n\n- `rtsp://192.168.1.123:8554/camera1?mp4` - useful for recording as MP4 files (e.g. Home Assistant or Frigate)\n- `rtsp://192.168.1.123:8554/camera1?video=h264,h265&audio=aac` - full version of the filter above\n- `rtsp://192.168.1.123:8554/camera1?video=h264&audio=aac&audio=opus` - H264 video codec and two separate audio tracks\n- `rtsp://192.168.1.123:8554/camera1?video&audio=all` - any video codec and all audio codecs as separate tracks\n- `http://192.168.1.123:1984/api/stream.m3u8?src=camera1&mp4` - HLS stream with MP4 compatible codecs (HLS/fMP4)\n- `http://192.168.1.123:1984/api/stream.m3u8?src=camera1&mp4=flac` - HLS stream with PCMA/PCMU/PCM audio support (HLS/fMP4), won't work on old devices\n- `http://192.168.1.123:1984/api/stream.mp4?src=camera1&mp4=flac` - MP4 file with PCMA/PCMU/PCM audio support, won't work on old devices (ex. iOS 12)\n- `http://192.168.1.123:1984/api/stream.mp4?src=camera1&mp4=all` - MP4 file with non-standard audio codecs, won't work on some players\n\n# Codecs madness\n\n`AVC/H.264` video can be played almost anywhere. But `HEVC/H.265` has many limitations in supporting different devices and browsers.\n\n| Device                                                             | WebRTC                                  | MSE                                     | HTTP*                                        | HLS                         |\n|--------------------------------------------------------------------|-----------------------------------------|-----------------------------------------|----------------------------------------------|-----------------------------|\n| *latency*                                                          | best                                    | medium                                  | bad                                          | bad                         |\n| Desktop Chrome 136+ <br/> Desktop Edge <br/> Android Chrome 136+   | H264, H265* <br/> PCMU, PCMA <br/> OPUS | H264, H265* <br/> AAC, FLAC* <br/> OPUS | H264, H265* <br/> AAC, FLAC* <br/> OPUS, MP3 | no                          |\n| Desktop Firefox                                                    | H264 <br/> PCMU, PCMA <br/> OPUS        | H264 <br/> AAC, FLAC* <br/> OPUS        | H264 <br/> AAC, FLAC* <br/> OPUS             | no                          |\n| Desktop Safari 14+ <br/> iPad Safari 14+ <br/> iPhone Safari 17.1+ | H264, H265* <br/> PCMU, PCMA <br/> OPUS | H264, H265 <br/> AAC, FLAC*             | **no!**                                      | H264, H265 <br/> AAC, FLAC* |\n| iPhone Safari 14+                                                  | H264, H265* <br/> PCMU, PCMA <br/> OPUS | **no!**                                 | **no!**                                      | H264, H265 <br/> AAC, FLAC* |\n| macOS [Hass App][1]                                                | no                                      | no                                      | no                                           | H264, H265 <br/> AAC, FLAC* |\n\n[1]: https://apps.apple.com/app/home-assistant/id1099568401\n\n- `HTTP*` - HTTP Progressive Streaming, not related to [progressive download](https://en.wikipedia.org/wiki/Progressive_download), because the file has no size and no end\n- `WebRTC H265` - supported in [Chrome 136+](https://developer.chrome.com/release-notes/136), supported in [Safari 18+](https://developer.apple.com/documentation/safari-release-notes/safari-18-release-notes)\n- `MSE iPhone` - supported in [iOS 17.1+](https://webkit.org/blog/14735/webkit-features-in-safari-17-1/)\n\n**Audio**\n\n- Go2rtc support [automatic repack](#built-in-transcoding) `PCMA/PCMU/PCM` codecs to `FLAC` for MSE/MP4/HLS so they will work almost anywhere\n- **WebRTC** audio codecs: `PCMU/8000`, `PCMA/8000`, `OPUS/48000/2`\n- `OPUS` and `MP3` inside **MP4** are part of the standard, but some players do not support them anyway (especially Apple)\n\n**Apple devices**\n\n- all Apple devices don't support HTTP progressive streaming\n- old iPhone firmwares don't support MSE technology because it competes with the HTTP Live Streaming (HLS) technology, invented by Apple\n- HLS is the worst technology for **live** streaming, it still exists only because of iPhones\n\n**Codec names**\n\n- H264 = H.264 = AVC (Advanced Video Coding)\n- H265 = H.265 = HEVC (High Efficiency Video Coding)\n- PCMA = G.711 PCM (A-law) = PCM A-law (`alaw`)\n- PCMU = G.711 PCM (¬µ-law) = PCM mu-law (`mulaw`)\n- PCM = L16 = PCM signed 16-bit big-endian (`s16be`)\n- AAC = MPEG4-GENERIC\n- MP3 = MPEG-1 Audio Layer III or MPEG-2 Audio Layer III\n\n# Built-in transcoding\n\nThere are no plans to embed complex transcoding algorithms inside go2rtc. [FFmpeg source](#source-ffmpeg) does a great job with this. Including [hardware acceleration](https://github.com/AlexxIT/go2rtc/wiki/Hardware-acceleration) support.\n\nBut go2rtc has some simple algorithms. They are turned on automatically; you do not need to set them up additionally.\n\n**PCM for MSE/MP4/HLS**\n\nGo2rtc can pack `PCMA`, `PCMU` and `PCM` codecs into an MP4 container so that they work in all browsers and all built-in players on modern devices. Including Apple QuickTime:\n\n```text\nPCMA/PCMU => PCM => FLAC => MSE/MP4/HLS\n```\n\n**Resample PCMA/PCMU for WebRTC**\n\nBy default WebRTC supports only `PCMA/8000` and `PCMU/8000`. But go2rtc can automatically resample PCMA and PCMU codecs with a different sample rate. Also, go2rtc can transcode `PCM` codec to `PCMA/8000`, so WebRTC can play it:\n\n```text\nPCM/xxx => PCMA/8000 => WebRTC\nPCMA/xxx => PCMA/8000 => WebRTC\nPCMU/xxx => PCMU/8000 => WebRTC\n```\n\n**Important**\n\n- FLAC codec not supported in an RTSP stream. If you are using Frigate or Home Assistant for recording MP4 files with PCMA/PCMU/PCM audio, you should set up transcoding to the AAC codec.\n- PCMA and PCMU are VERY low-quality codecs. They support only 256! different sounds. Use them only when you have no other options.\n\n# Codecs negotiation\n\nFor example, you want to watch RTSP-stream from [Dahua IPC-K42](https://www.dahuasecurity.com/fr/products/All-Products/Network-Cameras/Wireless-Series/Wi-Fi-Series/4MP/IPC-K42) camera in your Chrome browser.\n\n- this camera supports two-way audio standard **ONVIF Profile T**\n- this camera supports codecs **H264, H265** for send video, and you select `H264` in camera settings\n- this camera supports codecs **AAC, PCMU, PCMA** for sending audio (from mic), and you select `AAC/16000` in camera settings\n- this camera supports codecs **AAC, PCMU, PCMA** for receiving audio (to speaker), you don't need to select them\n- your browser supports codecs **H264, VP8, VP9, AV1** for receiving video, you don't need to select them\n- your browser supports codecs **OPUS, PCMU, PCMA** for sending and receiving audio, you don't need to select them\n- you can't get camera audio directly, because its audio codecs don't match with your browser codecs\n  - so you decide to use transcoding via FFmpeg and add this setting to the config YAML file\n  - you have chosen `OPUS/48000/2` codec, because it is higher quality than the `PCMU/8000` or `PCMA/8000`\n\nNow you have a stream with two sources - **RTSP and FFmpeg**:\n\n```yaml\nstreams:\n  dahua:\n    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&subtype=0&unicast=true&proto=Onvif\n    - ffmpeg:rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&subtype=0#audio=opus\n```\n\n**go2rtc** automatically matches codecs for your browser and all your stream sources. This is called **multi-source two-way codec negotiation**. And this is one of the main features of this app.\n\n![Codec negotiation](assets/codecs.svg)\n\n**PS.** You can select `PCMU` or `PCMA` codec in camera settings and not use transcoding at all. Or you can select `AAC` codec for main stream and `PCMU` codec for second stream and add both RTSP to YAML config, this also will work fine.\n\n# Projects using go2rtc\n\n- [Home Assistant](https://www.home-assistant.io/) [2024.11+](https://www.home-assistant.io/integrations/go2rtc/) - top open-source smart home project\n- [Frigate](https://frigate.video/) [0.12+](https://docs.frigate.video/guides/configuring_go2rtc/) - open-source NVR built around real-time AI object detection\n- [Advanced Camera Card](https://github.com/dermotduffy/advanced-camera-card) - custom card for Home Assistant\n- [OpenIPC](https://github.com/OpenIPC/firmware/tree/master/general/package/go2rtc) - alternative IP camera firmware from an open community\n- [wz_mini_hacks](https://github.com/gtxaspec/wz_mini_hacks) - custom firmware for Wyze cameras\n- [EufyP2PStream](https://github.com/oischinger/eufyp2pstream) - a small project that provides a video/audio stream from Eufy cameras that don't directly support RTSP\n- [ioBroker.euSec](https://github.com/bropat/ioBroker.eusec) - [ioBroker](https://www.iobroker.net/) adapter for controlling Eufy security devices\n- [MMM-go2rtc](https://github.com/Anonym-tsk/MMM-go2rtc) - MagicMirror¬≤ module\n- [ring-mqtt](https://github.com/tsightler/ring-mqtt) - Ring-to-MQTT bridge\n- [lightNVR](https://github.com/opensensor/lightNVR)\n\n**Distributions**\n\n- [Alpine Linux](https://pkgs.alpinelinux.org/packages?name=go2rtc)\n- [Arch User Repository](https://linux-packages.com/aur/package/go2rtc)\n- [Gentoo](https://github.com/inode64/inode64-overlay/tree/main/media-video/go2rtc)\n- [NixOS](https://search.nixos.org/packages?query=go2rtc)\n- [Proxmox Helper Scripts](https://github.com/community-scripts/ProxmoxVE/)\n- [QNAP](https://www.myqnap.org/product/go2rtc/)\n- [Synology NAS](https://synocommunity.com/package/go2rtc)\n- [Unraid](https://unraid.net/community/apps?q=go2rtc)\n\n# Camera experience\n\n- [Dahua](https://www.dahuasecurity.com/) - reference implementation streaming protocols, a lot of settings, high stream quality, multiple streaming clients\n- [EZVIZ](https://www.ezviz.com/) - awful RTSP protocol implementation, many bugs in SDP\n- [Hikvision](https://www.hikvision.com/) - a lot of proprietary streaming technologies\n- [Reolink](https://reolink.com/) - some models have an awful, unusable RTSP implementation and not the best RTMP alternative (I recommend that you contact Reolink support for new firmware), few settings\n- [Sonoff](https://sonoff.tech/) - very low stream quality, no settings, not the best protocol implementation\n- [TP-Link](https://www.tp-link.com/) - few streaming clients, packet loss?\n- Chinese cheap noname cameras, Wyze Cams, Xiaomi cameras with hacks (usually have `/live/ch00_1` in RTSP URL) - awful but usable RTSP protocol implementation, low stream quality, few settings, packet loss?\n\n# Tips\n\n**Using apps for low RTSP delay**\n\n- `ffplay -fflags nobuffer -flags low_delay \"rtsp://192.168.1.123:8554/camera1\"`\n- VLC > Preferences > Input / Codecs > Default Caching Level: Lowest Latency\n\n**Snapshots to Telegram**\n\n[read more](https://github.com/AlexxIT/go2rtc/wiki/Snapshot-to-Telegram)\n",
      "stars_today": 72
    },
    {
      "id": 709588939,
      "name": "awesome-leetcode-resources",
      "full_name": "ashishps1/awesome-leetcode-resources",
      "description": "Awesome LeetCode resources to learn Data Structures and Algorithms and prepare for Coding Interviews.",
      "html_url": "https://github.com/ashishps1/awesome-leetcode-resources",
      "stars": 15357,
      "forks": 3338,
      "language": "Java",
      "topics": [
        "algorithms",
        "coding",
        "data-structures",
        "dsa",
        "leetcode",
        "leetcode-patterns"
      ],
      "created_at": "2023-10-25T01:48:19Z",
      "updated_at": "2026-01-23T01:38:08Z",
      "pushed_at": "2025-11-25T13:00:27Z",
      "open_issues": 12,
      "owner": {
        "login": "ashishps1",
        "avatar_url": "https://avatars.githubusercontent.com/u/8646889?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"images/leetcode-repo-logo.png\" width=\"350\" height=\"200\">\n</p>\n<p align=\"center\">\n  <a href=\"https://blog.algomaster.io/\">Join Free Newsletter</a>\n</p>\n\nThis repository contains awesome LeetCode resources to learn Data Structures and Algorithms (DSA) and prepare for Coding interviews.\n\nüëâ If you want to master DSA patterns, checkout [AlgoMaster.io](https://algomaster.io)\n\n## üí° Tips\n- [How I Mastered DSA](https://blog.algomaster.io/p/how-i-mastered-data-structures-and-algorithms)\n- [How to Start LeetCode](https://blog.algomaster.io/p/how-to-start-leetcode-in-2025)\n- [15 Leetcode Patterns](https://blog.algomaster.io/p/15-leetcode-patterns)\n\n## üìå Fundamental Concepts\n- [Algorithmic Complexity](https://blog.algomaster.io/p/57bd4963-462f-4294-a972-4012691fc729)\n- [Big-O Cheat Sheet](https://www.bigocheatsheet.com/)\n- [Arrays](https://www.youtube.com/watch?v=SlNq09scdWE&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Bit Manipulation Techniques](https://blog.algomaster.io/p/c650df76-f978-46ee-a572-eb13c354905d)\n- [Sorting Algorithms](https://medium.com/jl-codes/understanding-sorting-algorithms-af6222995c8)\n- [Linked List](https://www.youtube.com/watch?v=FbHf0ii0WDg&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Queues](https://medium.com/basecs/to-queue-or-not-to-queue-2653bcde5b04)\n- [Stacks](https://medium.com/basecs/stacks-and-overflows-dbcf7854dc67)\n- [Hash Tables](https://medium.com/basecs/taking-hash-tables-off-the-shelf-139cbf4752f0)\n- [Heaps](https://medium.com/basecs/learning-to-love-heaps-cef2b273a238)\n- [Recursion](https://leetcode.com/discuss/study-guide/1733447/become-master-in-recursion)\n- [Backtracking](https://medium.com/algorithms-and-leetcode/backtracking-e001561b9f28)\n- [Trees](https://leetcode.com/discuss/study-guide/1820334/Become-Master-in-Tree)\n- [Tries](https://medium.com/basecs/trying-to-understand-tries-3ec6bede0014)\n- [Binary Search](https://leetcode.com/discuss/study-guide/786126/Python-Powerful-Ultimate-Binary-Search-Template.-Solved-many-problems)\n- [Greedy Algorithm](https://www.freecodecamp.org/news/greedy-algorithms/)\n- [Dynamic Programming](https://medium.com/basecs/less-repetition-more-dynamic-programming-43d29830a630)\n- [Graph Theory](https://www.youtube.com/watch?v=xN5VGzK9_FQ&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Master Graph Algorithms](https://blog.algomaster.io/p/master-graph-algorithms-for-coding)\n- [DFS Traversal](https://medium.com/basecs/deep-dive-through-a-graph-dfs-traversal-8177df5d0f13)\n- [BFS Traversal](https://medium.com/basecs/going-broad-in-a-graph-bfs-traversal-959bd1a09255)\n- [Union-Find](https://leetcode.com/discuss/general-discussion/1072418/Disjoint-Set-Union-(DSU)Union-Find-A-Complete-Guide)\n- [Dijkstra Algorithm](https://leetcode.com/discuss/study-guide/1059477/A-guide-to-Dijkstra's-Algorithm)\n- [Minimum Spanning Tree](https://www.hackerearth.com/practice/algorithms/graphs/minimum-spanning-tree/tutorial/)\n\n## üöÄ Patterns\n- [15 Leetcode Patterns](https://blog.algomaster.io/p/15-leetcode-patterns)\n- [20 DP Patterns](https://blog.algomaster.io/p/20-patterns-to-master-dynamic-programming)\n- [Two Pointers Pattern](https://www.youtube.com/watch?v=QzZ7nmouLTI&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Sliding Window Pattern](https://www.youtube.com/watch?v=y2d0VHdvfdc&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Prefix Sum Pattern](https://www.youtube.com/watch?v=yuws7YK0Yng&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Fast and Slow Pointers Pattern](https://www.youtube.com/watch?v=b139yf7Ik-E&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Top 'K' Elements Pattern](https://www.youtube.com/watch?v=6_v6OoxvMOE&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Kadane's Algorithm](https://www.youtube.com/watch?v=NUWAXbSlsws&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Linked List In-place Reversal Pattern](https://www.youtube.com/watch?v=auoTGovuo9A&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Monotonic Stack Pattern](https://www.youtube.com/watch?v=DtJVwbbicjQ&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Overlapping Intervals Pattern](https://blog.algomaster.io/p/812e72f7-eced-4256-a4c1-00606ae50679)\n- [Backtracking Pattern](https://blog.algomaster.io/p/81d42ca2-600c-4252-aa33-a56462090048)\n- [Modified Binary Search Pattern](https://blog.algomaster.io/p/d0d81b04-4c2a-4b45-a101-5137c3146686)\n- [Tree Patterns](https://leetcode.com/discuss/study-guide/937307/Iterative-or-Recursive-or-DFS-and-BFS-Tree-Traversal-or-In-Pre-Post-and-LevelOrder-or-Views)\n  - [Tree Iterative Traversal](https://medium.com/leetcode-patterns/leetcode-pattern-0-iterative-traversals-on-trees-d373568eb0ec)\n  - [Tree Question Pattern](https://leetcode.com/discuss/study-guide/2879240/TREE-QUESTION-PATTERN-2023-oror-TREE-STUDY-GUIDE) \n- [Graph Patterns](https://leetcode.com/discuss/study-guide/655708/Graph-For-Beginners-Problems-or-Pattern-or-Sample-Solutions)\n- [DFS + BFS Patterns (1)](https://medium.com/leetcode-patterns/leetcode-pattern-1-bfs-dfs-25-of-the-problems-part-1-519450a84353)\n- [DFS + BFS Patterns (2)](https://medium.com/leetcode-patterns/leetcode-pattern-2-dfs-bfs-25-of-the-problems-part-2-a5b269597f52)\n\n## üìù Must-Read Leetcode Articles\n- [Sliding Window Template](https://leetcode.com/problems/frequency-of-the-most-frequent-element/solutions/1175088/C++-Maximum-Sliding-Window-Cheatsheet-Template/)\n- [Two Pointers Patterns](https://leetcode.com/discuss/study-guide/1688903/Solved-all-two-pointers-problems-in-100-days)\n- [Collections of Important String Questions](https://leetcode.com/discuss/study-guide/2001789/Collections-of-Important-String-questions-Pattern)\n- [Substring Problem Template](https://leetcode.com/problems/minimum-window-substring/solutions/26808/Here-is-a-10-line-template-that-can-solve-most-'substring'-problems/)\n- [Binary Search Template](https://leetcode.com/discuss/study-guide/786126/Python-Powerful-Ultimate-Binary-Search-Template.-Solved-many-problems)\n- [A General Approach to Backtracking Questions](https://leetcode.com/problems/permutations/solutions/18239/A-general-approach-to-backtracking-questions-in-Java-(Subsets-Permutations-Combination-Sum-Palindrome-Partioning)/)\n- [Monotonic Stack Template](https://leetcode.com/discuss/study-guide/2347639/A-comprehensive-guide-and-template-for-monotonic-stack-based-problems)\n- [Heap Patterns](https://leetcode.com/discuss/general-discussion/1127238/master-heap-by-solving-23-questions-in-4-patterns-category)\n- [Bit Manipulation Patterns](https://leetcode.com/discuss/study-guide/4282051/all-types-of-patterns-for-bits-manipulations-and-how-to-use-it)\n- [Dynamic Programming Patterns](https://leetcode.com/discuss/study-guide/458695/Dynamic-Programming-Patterns)\n- [Stock Series Patterns](https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/solutions/108870/most-consistent-ways-of-dealing-with-the-series-of-stock-problems/)\n\n## ‚úÖ Curated Problems\n- [AlgoMaster 300](https://algomaster.io/practice/dsa-patterns)\n- [Blind 75](https://leetcode.com/discuss/general-discussion/460599/blind-75-leetcode-questions)\n- [Leetcode Top 100 Liked](https://leetcode.com/studyplan/top-100-liked/)\n- [Leetcode Top Interview 150](https://leetcode.com/studyplan/top-interview-150/)\n\n## üì∫ YouTube Playlist\n- [AlgoMaster DSA Playlist](https://www.youtube.com/playlist?list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2&pp=gAQB)\n- [AlgoMaster LeetCode Pattern Playlist](https://www.youtube.com/playlist?list=PLK63NuByH5o-tqaMUHRA4r8ObRW7PWz45)\n- [Abdul Bari's Algorithms Playlist](https://www.youtube.com/playlist?list=PLDN4rrl48XKpZkf03iYFl-O29szjTrs_O)\n- [William Fiset's Data Structure Playlist](https://www.youtube.com/playlist?list=PLDV1Zeh2NRsB6SWUrDFW2RmDotAfPbeHu)\n- [William Fiset's Graphs Playlist](https://www.youtube.com/playlist?list=PLDV1Zeh2NRsDGO4--qE8yH72HFL1Km93P)\n- [Tushar Roy's Dynamic Programming Playlist](https://www.youtube.com/playlist?list=PLrmLmBdmIlpsHaNTPP_jHHDx_os9ItYXr)\n\n## üìá Courses\n- [Coursera - Algorithms, Part I](https://www.coursera.org/learn/algorithms-part1)\n- [Coursera - Algorithms, Part 2](https://www.coursera.org/learn/algorithms-part2)\n\n## üìö Books\n- [Data Structures And Algorithms Made Easy](https://www.amazon.in/dp/B08CMLS7LZ)\n- [Cracking the Coding Interview](https://www.amazon.in/dp/0984782850)\n\n## üì© Newsletter\n- [AlgoMaster Newsletter](https://blog.algomaster.io/)\n\n## üîé Visualization\n- [AlgoMaster DSA Animations](https://algomaster.io/animations/dsa)\n- [VisuAlgo](https://visualgo.net/en)\n\n## üìé LeetCode Extensions\n- [LeetCode Timer](https://chromewebstore.google.com/detail/leetcode-timer/gfkgelnlcnomnahkfmhemgpahgmibofd): Easily time your leetcode practise sessions with automatic time setting based on difficulty.\n- [LeetCode Video Solutions](https://chromewebstore.google.com/detail/leetcode-video-solutions/ilnmgkahgjdpkoliooildngldmilhelm): Watch free LeetCode video ‚ñ∂ solutions on the problem page itself.\n- [LeetCode Format](https://chromewebstore.google.com/detail/leetcode-format/imogghebhifnnlgogigikjecilkicfpp): Adds Format code button on leetcode to format the code using Prettier code formatter.\n- [LeetHub v2](https://chromewebstore.google.com/detail/leethub-v2/mhanfgfagplhgemhjfeolkkdidbakocm?hl=en): Automatically integrate your Leetcode & GeeksforGeeks submissions to GitHub.\n- [LeetCode VS Code Extension](https://marketplace.visualstudio.com/items?itemName=LeetCode.vscode-leetcode): Solve LeetCode problems in VS Code.\n\nYour contributions are most welcome!\n\n---\n\n<p align=\"center\">\n  <i>If you find this resource helpful, please give it a star ‚≠êÔ∏è and share it with others!</i>\n</p>\n",
      "stars_today": 62
    },
    {
      "id": 53809090,
      "name": "anime",
      "full_name": "juliangarnier/anime",
      "description": "JavaScript animation engine",
      "html_url": "https://github.com/juliangarnier/anime",
      "stars": 66131,
      "forks": 4425,
      "language": "JavaScript",
      "topics": [
        "animation",
        "anime",
        "canvas",
        "css",
        "javascript",
        "javascript-library",
        "svg"
      ],
      "created_at": "2016-03-13T21:37:45Z",
      "updated_at": "2026-01-23T02:12:13Z",
      "pushed_at": "2026-01-22T18:46:26Z",
      "open_issues": 92,
      "owner": {
        "login": "juliangarnier",
        "avatar_url": "https://avatars.githubusercontent.com/u/1268691?v=4"
      },
      "readme": "# Anime.js\n\n<p align=\"center\">\n  <picture align=\"center\">\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/images/animejs-v4-logo-animation-dark.gif\">\n    <img align=\"center\" alt=\"Anime.js V4 logo animation\" src=\"./assets/images/animejs-v4-logo-animation.gif\" width=\"560\">\n  </picture>\n</p>\n\n<p align=\"center\">\n  <strong>\n  <em>Anime.js</em> is a fast, multipurpose and lightweight JavaScript animation library with a simple, yet powerful API.<br>\n  It works with CSS properties, SVG, DOM attributes and JavaScript Objects.\n  </strong>\n</p>\n\n\n<p align=\"center\">\n  <img alt=\"NPM Downloads\" src=\"https://img.shields.io/npm/dm/animejs?style=flat-square&logo=npm\">\n  <img alt=\"jsDelivr hits (npm)\" src=\"https://img.shields.io/jsdelivr/npm/hm/animejs?style=flat-square&logo=jsdeliver\">\n  <img alt=\"GitHub Sponsors\" src=\"https://img.shields.io/github/sponsors/juliangarnier?style=flat-square&logo=github\">\n</p>\n\n## Sponsors\n\nAnime.js is 100% free and is only made possible with the help of our sponsors.\nHelp the project become sustainable by sponsoring us on <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">GitHub Sponsors</a>.\n\n### Platinum sponsors\n\n<table>\n  <tbody>\n    <tr>\n      <td>\n        <a target=\"_blank\" href=\"https://ice.io/?ref=animejs\">\n          <picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/sponsors/ice-open-network-logomark.png?v=200126\">\n            <img align=\"center\" src=\"./assets/sponsors/ice-open-network-logomark-dark.png?v=200126\" width=\"310\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://hyperswitch.io/?utm_source=julian&utm_medium=github&utm_campaign=animejs_sponsorship\">\n          <picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/sponsors/juspay-logomark.png?v=200126\">\n            <img align=\"center\" src=\"./assets/sponsors/juspay-logomark-dark.png?v=200126\" width=\"310\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">\n          <picture>\n            <img align=\"center\" src=\"./assets/sponsors/placeholder-large.png?v=200126\" width=\"310\">\n          </picture>\n        </a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### Silver sponsors\n\n<table>\n  <tbody>\n    <tr>\n      <td>\n        <a target=\"_blank\" href=\"https://www.testmu.ai?utm_source=animeJS&utm_medium=organic&utm_campaign=july_08&utm_term=sk&utm_content=opensource\">\n          <picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/sponsors/testmu-ai-logomark.png?v=200126\">\n            <img align=\"center\" src=\"./assets/sponsors/testmu-ai-logomark-dark.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://inspatialapp.com/?ref=animejs\">\n          <picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/sponsors/inspatial-logomark.png?v=200126\">\n            <img align=\"center\" src=\"./assets/sponsors/inspatial-logomark-dark.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">\n          <picture>\n            <img align=\"center\" src=\"./assets/sponsors/placeholder-small.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">\n          <picture>\n            <img align=\"center\" src=\"./assets/sponsors/placeholder-small.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">\n          <picture>\n            <img align=\"center\" src=\"./assets/sponsors/placeholder-small.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n      <td>\n        <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">\n          <picture>\n            <img align=\"center\" src=\"./assets/sponsors/placeholder-small.png?v=200126\" width=\"141\">\n          </picture>\n        </a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\nGet featured here by becoming a <a target=\"_blank\" href=\"https://github.com/sponsors/juliangarnier\">GitHub Sponsor</a>.\n\n\n## Usage\n\nAnime.js V4 works by importing ES modules like so:\n\n\n<table>\n<tr>\n  <td>\n\n```javascript\nimport {\n  animate,\n  stagger,\n} from 'animejs';\n\nanimate('.square', {\n  x: 320,\n  rotate: { from: -180 },\n  duration: 1250,\n  delay: stagger(65, { from: 'center' }),\n  ease: 'inOutQuint',\n  loop: true,\n  alternate: true\n});\n```\n\n  </td>\n  <td>\n    <img align=\"center\" alt=\"Anime.js code example\" src=\"./assets/images/usage-example-result.gif\">\n  </td>\n</tr>\n</table>\n\n## V4 Documentation\n\nThe full documentation is available [here](https://animejs.com/documentation).\n\n## V3 Migration guide\n\nYou can find the v3 to v4 migration guide [here](https://github.com/juliangarnier/anime/wiki/Migrating-from-v3-to-v4).\n\n## NPM development scripts\n\nFirst, run `npm i` to install all the necessary packages.\nThen, execute the following scripts with `npm run <script>`.\n\n| script | action |\n| ------ | ------ |\n| `dev` | Watches for changes in `src/**/*.js`, bundles the ESM version to `lib/` and creates type declarations in `types/` |\n| `dev:test` | Runs `dev` and `test:browser` concurrently |\n| `build` | Bundles ESM / UMD / CJS / IIFE versions to `lib/` and creates type declarations in `types/` |\n| `test:browser` | Starts a local server and runs all browser-related tests |\n| `test:node` | Starts Node-related tests |\n| `open:examples` | Starts a local server to browse the examples locally |\n\n¬© [Julian Garnier](http://juliangarnier.com) | [MIT License](LICENSE.md)\n",
      "stars_today": 58
    },
    {
      "id": 299354207,
      "name": "rustdesk",
      "full_name": "rustdesk/rustdesk",
      "description": "An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.",
      "html_url": "https://github.com/rustdesk/rustdesk",
      "stars": 106158,
      "forks": 15715,
      "language": "Rust",
      "topics": [
        "android",
        "anydesk",
        "dart",
        "flatpak",
        "flutter",
        "flutter-apps",
        "ios",
        "linux",
        "macos",
        "p2p",
        "rdp",
        "remote-control",
        "remote-desktop",
        "rust",
        "rust-lang",
        "teamviewer",
        "vnc",
        "wayland",
        "windows"
      ],
      "created_at": "2020-09-28T15:36:08Z",
      "updated_at": "2026-01-23T01:55:17Z",
      "pushed_at": "2026-01-22T06:15:14Z",
      "open_issues": 102,
      "owner": {
        "login": "rustdesk",
        "avatar_url": "https://avatars.githubusercontent.com/u/71636191?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"res/logo-header.svg\" alt=\"RustDesk - Your remote desktop\"><br>\n  <a href=\"#raw-steps-to-build\">Build</a> ‚Ä¢\n  <a href=\"#how-to-build-with-docker\">Docker</a> ‚Ä¢\n  <a href=\"#file-structure\">Structure</a> ‚Ä¢\n  <a href=\"#snapshot\">Snapshot</a><br>\n  [<a href=\"docs/README-UA.md\">–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</a>] | [<a href=\"docs/README-CS.md\">ƒçesky</a>] | [<a href=\"docs/README-ZH.md\">‰∏≠Êñá</a>] | [<a href=\"docs/README-HU.md\">Magyar</a>] | [<a href=\"docs/README-ES.md\">Espa√±ol</a>] | [<a href=\"docs/README-FA.md\">ŸÅÿßÿ±ÿ≥€å</a>] | [<a href=\"docs/README-FR.md\">Fran√ßais</a>] | [<a href=\"docs/README-DE.md\">Deutsch</a>] | [<a href=\"docs/README-PL.md\">Polski</a>] | [<a href=\"docs/README-ID.md\">Indonesian</a>] | [<a href=\"docs/README-FI.md\">Suomi</a>] | [<a href=\"docs/README-ML.md\">‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç</a>] | [<a href=\"docs/README-JP.md\">Êó•Êú¨Ë™û</a>] | [<a href=\"docs/README-NL.md\">Nederlands</a>] | [<a href=\"docs/README-IT.md\">Italiano</a>] | [<a href=\"docs/README-RU.md\">–†—É—Å—Å–∫–∏–π</a>] | [<a href=\"docs/README-PTBR.md\">Portugu√™s (Brasil)</a>] | [<a href=\"docs/README-EO.md\">Esperanto</a>] | [<a href=\"docs/README-KR.md\">ÌïúÍµ≠Ïñ¥</a>] | [<a href=\"docs/README-AR.md\">ÿßŸÑÿπÿ±ÿ®Ÿä</a>] | [<a href=\"docs/README-VN.md\">Ti·∫øng Vi·ªát</a>] | [<a href=\"docs/README-DA.md\">Dansk</a>] | [<a href=\"docs/README-GR.md\">ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨</a>] | [<a href=\"docs/README-TR.md\">T√ºrk√ße</a>] | [<a href=\"docs/README-NO.md\">Norsk</a>] | [<a href=\"docs/README-RO.md\">Rom√¢nƒÉ</a>]<br>\n  <b>We need your help to translate this README, <a href=\"https://github.com/rustdesk/rustdesk/tree/master/src/lang\">RustDesk UI</a> and <a href=\"https://github.com/rustdesk/doc.rustdesk.com\">RustDesk Doc</a> to your native language</b>\n</p>\n\n> [!Caution]\n> **Misuse Disclaimer:** <br>\n> The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.\n\n\nChat with us: [Discord](https://discord.gg/nDceKgxnkV) | [Twitter](https://twitter.com/rustdesk) | [Reddit](https://www.reddit.com/r/rustdesk) | [YouTube](https://www.youtube.com/@rustdesk)\n\n[![RustDesk Server Pro](https://img.shields.io/badge/RustDesk%20Server%20Pro-Advanced%20Features-blue)](https://rustdesk.com/pricing.html)\n\nYet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, [set up your own](https://rustdesk.com/server), or [write your own rendezvous/relay server](https://github.com/rustdesk/rustdesk-server-demo).\n\n![image](https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png)\n\nRustDesk welcomes contribution from everyone. See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for help getting started.\n\n[**FAQ**](https://github.com/rustdesk/rustdesk/wiki/FAQ)\n\n[**BINARY DOWNLOAD**](https://github.com/rustdesk/rustdesk/releases)\n\n[**NIGHTLY BUILD**](https://github.com/rustdesk/rustdesk/releases/tag/nightly)\n\n[<img src=\"https://f-droid.org/badge/get-it-on.png\"\n    alt=\"Get it on F-Droid\"\n    height=\"80\">](https://f-droid.org/en/packages/com.carriez.flutter_hbb)\n[<img src=\"https://flathub.org/api/badge?svg&locale=en\"\n    alt=\"Get it on Flathub\"\n    height=\"80\">](https://flathub.org/apps/com.rustdesk.RustDesk)\n\n## Dependencies\n\nDesktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our [CI](https://github.com/rustdesk/rustdesk/blob/master/.github/workflows/flutter-build.yml) for building Flutter version.\n\nPlease download Sciter dynamic library yourself.\n\n[Windows](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll) |\n[Linux](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so) |\n[macOS](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib)\n\n## Raw Steps to build\n\n- Prepare your Rust development env and C++ build env\n\n- Install [vcpkg](https://github.com/microsoft/vcpkg), and set `VCPKG_ROOT` env variable correctly\n\n  - Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static\n  - Linux/macOS: vcpkg install libvpx libyuv opus aom\n\n- run `cargo run`\n\n## [Build](https://rustdesk.com/docs/en/dev/build/)\n\n## How to Build on Linux\n\n### Ubuntu 18 (Debian 10)\n\n```sh\nsudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \\\n        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \\\n        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev\n```\n\n### openSUSE Tumbleweed\n\n```sh\nsudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel\n```\n\n### Fedora 28 (CentOS 8)\n\n```sh\nsudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel\n```\n\n### Arch (Manjaro)\n\n```sh\nsudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire\n```\n\n### Install vcpkg\n\n```sh\ngit clone https://github.com/microsoft/vcpkg\ncd vcpkg\ngit checkout 2023.04.15\ncd ..\nvcpkg/bootstrap-vcpkg.sh\nexport VCPKG_ROOT=$HOME/vcpkg\nvcpkg/vcpkg install libvpx libyuv opus aom\n```\n\n### Fix libvpx (For Fedora)\n\n```sh\ncd vcpkg/buildtrees/libvpx/src\ncd *\n./configure\nsed -i 's/CFLAGS+=-I/CFLAGS+=-fPIC -I/g' Makefile\nsed -i 's/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g' Makefile\nmake\ncp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/\ncd\n```\n\n### Build\n\n```sh\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource $HOME/.cargo/env\ngit clone --recurse-submodules https://github.com/rustdesk/rustdesk\ncd rustdesk\nmkdir -p target/debug\nwget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so\nmv libsciter-gtk.so target/debug\nVCPKG_ROOT=$HOME/vcpkg cargo run\n```\n\n## How to build with Docker\n\nBegin by cloning the repository and building the Docker container:\n\n```sh\ngit clone https://github.com/rustdesk/rustdesk\ncd rustdesk\ngit submodule update --init --recursive\ndocker build -t \"rustdesk-builder\" .\n```\n\nThen, each time you need to build the application, run the following command:\n\n```sh\ndocker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID=\"$(id -u)\" -e PGID=\"$(id -g)\" rustdesk-builder\n```\n\nNote that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the `<OPTIONAL-ARGS>` position. For instance, if you wanted to build an optimized release version, you would run the command above followed by `--release`. The resulting executable will be available in the target folder on your system, and can be run with:\n\n```sh\ntarget/debug/rustdesk\n```\n\nOr, if you're running a release executable:\n\n```sh\ntarget/release/rustdesk\n```\n\nPlease ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as `install` or `run` are not currently supported via this method as they would install or run the program inside the container instead of the host.\n\n## File Structure\n\n- **[libs/hbb_common](https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common)**: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions\n- **[libs/scrap](https://github.com/rustdesk/rustdesk/tree/master/libs/scrap)**: screen capture\n- **[libs/enigo](https://github.com/rustdesk/rustdesk/tree/master/libs/enigo)**: platform specific keyboard/mouse control\n- **[libs/clipboard](https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard)**: file copy and paste implementation for Windows, Linux, macOS.\n- **[src/ui](https://github.com/rustdesk/rustdesk/tree/master/src/ui)**: obsolete Sciter UI (deprecated)\n- **[src/server](https://github.com/rustdesk/rustdesk/tree/master/src/server)**: audio/clipboard/input/video services, and network connections\n- **[src/client.rs](https://github.com/rustdesk/rustdesk/tree/master/src/client.rs)**: start a peer connection\n- **[src/rendezvous_mediator.rs](https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs)**: Communicate with [rustdesk-server](https://github.com/rustdesk/rustdesk-server), wait for remote direct (TCP hole punching) or relayed connection\n- **[src/platform](https://github.com/rustdesk/rustdesk/tree/master/src/platform)**: platform specific code\n- **[flutter](https://github.com/rustdesk/rustdesk/tree/master/flutter)**: Flutter code for desktop and mobile\n- **[flutter/web/js](https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js)**: JavaScript for Flutter web client\n\n## Screenshots\n\n![Connection Manager](https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651)\n\n![Connected to a Windows PC](https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea)\n\n![File Transfer](https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad)\n\n![TCP Tunneling](https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5)\n\n",
      "stars_today": 56
    },
    {
      "id": 370467085,
      "name": "AndroidMic",
      "full_name": "teamclouday/AndroidMic",
      "description": "Use your Android phone as a microphone for your PC",
      "html_url": "https://github.com/teamclouday/AndroidMic",
      "stars": 857,
      "forks": 53,
      "language": "Rust",
      "topics": [
        "android-application",
        "audio-streaming",
        "microphone",
        "rnnoise",
        "tcp-socket",
        "udp-socket",
        "usb-serial"
      ],
      "created_at": "2021-05-24T19:44:17Z",
      "updated_at": "2026-01-22T23:10:01Z",
      "pushed_at": "2025-12-27T23:55:28Z",
      "open_issues": 47,
      "owner": {
        "login": "teamclouday",
        "avatar_url": "https://avatars.githubusercontent.com/u/22620163?v=4"
      },
      "readme": "<p align=\"center\">\n  <img align=\"center\" src=\"./Assets/app_icon.svg\" alt=\"app icon\" width=\"80px\" />\n  <h1 align=\"center\" style=\"display: inline-block; margin-left: 12px; vertical-align: middle;\">AndroidMic</h1>\n</p>\n\n<h3 align=\"center\">Use your Android phone as a microphone for your PC</h3>\n\n<!-- <a href=\"https://flathub.org/apps/io.github.teamclouday.AndroidMic\"><img align=center height=\"40\" src=\"https://flathub.org/assets/badges/flathub-badge-en.svg\"  alt=\"Download on Flathub\"/></a> -->\n[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/teamclouday/AndroidMic.svg?logo=github&label=GitHub&cacheSeconds=3600)](https://github.com/teamclouday/AndroidMic/releases/latest)\n[![F-Droid](https://img.shields.io/f-droid/v/io.github.teamclouday.AndroidMic?logo=f-droid&label=F-Droid&cacheSeconds=3600)](https://f-droid.org/packages/io.github.teamclouday.AndroidMic)\n\n---\n\n<p  style=\"text-align: center;\">\n  <img src=\"./Assets/pc_screenshot_main_dark.png\" width=\"65%\"  alt=\"main window pc\"/>\n  <img src=\"./Assets/android_screenshot_main_dark.png\" width=\"25%\"  alt=\"main window android\"/>\n</p>\n\n# Features\n\n- Multiplatform (Linux, Windows, MacOs)\n- Wifi and USB support\n- Noise Cancellation\n- Audio wave visualization\n- Advanced Audio Options\n\n# How to Use\n\n## PC Side\n\n- **1. Start the app**: Download and install the latest release. Then start the app.\n    <details>\n    <summary>\n    More about installation\n    </summary>\n\n  On macOS, you will need to run the following command to allow the app to run. For more details, refer to this [link](https://discussions.apple.com/thread/253714860?sortBy=best):\n\n  ```sh\n  xattr -c /Applications/AndroidMic.app\n  ```\n\n    </details>\n\n- **2. Pick an output audio device**: You will see a list of audio player devices from the dropdown list. Here you want to choose a device that is wired to the virtual mic device on your system that you will be using.\n\n    <details>\n    <summary>\n    More about output device\n    </summary>\n\n  The step is system independent.\n\n  On Windows you can use [Virtual Audio Cable](https://vac.muzychenko.net/en/download.htm) or [VB Cable](https://vb-audio.com/Cable/). Both software will install virtual input and output audio devices on your system. After that map the output player device to the input mic device so any audio our app played to the device is transferred to the virtual mic device.\n\n  On Linux you can use pulseaudio to create a virtual mic device.\n\n    </details>\n\n- **3. Choose a connection method**: This is how your phone will be connected to your PC and stream audio from the mic.\n\n  For TCP & UDP, connect your phone and PC to the same internet.\n\n  For USB serial, connect your phone to PC with a cable.\n\n    <details>\n    <summary>\n    More about USB serial\n    </summary>\n\n  This option also requires configurations that are system independent.\n\n  On Windows, make sure the adb process is shutdown and android studio is closed.\n\n  On MacOS, it should just work.\n\n  On Linux, you will need to configure [udev](https://github.com/libusb/libusb/wiki/FAQ#can-i-run-libusb-applications-on-linux-without-root-privilege) so that the app has permission to use USB.\n\n  Samsung phone users may need to use [zadig](https://zadig.akeo.ie/) to change the USB driver to WinUSB. This is because by default Samsung phones use its proprietary USB driver which is not compatible with the app.\n\n    </details>\n\n  For USB adb, make sure the system has installed [adb](https://developer.android.com/tools/adb). The connect your phone to PC.\n\n- **4. Configure advanced settings**: Click to open the advanced settings window, and pick an audio format the output audio device supports. Usually sample rate of 44.1k or 48k, mono channel, and i16 or i24 are supported.\n\n## Android Side\n\n- **1. Start the app**: Download and install the apk file from release page. Then open the app.\n\n- **2. Configure the app**: Open the side drawer menu, configure the connection method according to the option on PC app. Then pick the **same audio settings** as the ones in PC app advanced settings.\n\n- **3. Connect**: First start recording and give sufficient permissions. Recording permission for accessing your phone's mic. Notification permission so the app can let you know if it is still recording in the background. Then connect to the PC app.\n\n    <details>\n    <summary>More about connection configurations</summary>\n\n  For TCP/UDP, you will need to enter the PC address and port. You can find that information from the log area on PC app.\n\n  For USB adb, set your phone to developer mode and enable USB debugging.\n\n  For USB serial, make sure your phone's USB setting is charging only. With this option, the app will ask your permission to launch the app in accessory mode.\n\n    </details>\n\n---\n\nFor more question / feature request / bug report, please [submit an issues](https://github.com/teamclouday/AndroidMic/issues).\n\n---\n\n## Some Notes\n\nThe PC app started as a WPF app written in C# and was only supported on Windows. Now most of the features are recreated in Rust app thanks to @wiiznokes and it's cross platform supported. But here's the [link to the WPF app branch](https://github.com/teamclouday/AndroidMic/tree/wpf-app-backup) in case you are interested.\n\nBluetooth is no longer supported because USB serial is made possible.\n\nWindows defender will very often identify the app as a virus, with their ML algorithm. If that happens, please [report to Microsoft](https://www.microsoft.com/en-us/wdsi/filesubmission) to get it fixed.",
      "stars_today": 53
    },
    {
      "id": 892240018,
      "name": "social-media-agent",
      "full_name": "langchain-ai/social-media-agent",
      "description": "üì≤ An agent for sourcing, curating, and scheduling social media posts with human-in-the-loop.",
      "html_url": "https://github.com/langchain-ai/social-media-agent",
      "stars": 1985,
      "forks": 354,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2024-11-21T18:46:16Z",
      "updated_at": "2026-01-23T01:23:52Z",
      "pushed_at": "2026-01-22T18:12:16Z",
      "open_issues": 14,
      "owner": {
        "login": "langchain-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/126733545?v=4"
      },
      "readme": "# Social Media Agent\n\nThis repository contains an 'agent' which can take in a URL, and generate a Twitter & LinkedIn post based on the content of the URL. It uses a human-in-the-loop (HITL) flow to handle authentication with different social media platforms, and to allow the user to make changes, or accept/reject the generated post.\n\n![Screenshot of the social media agent flow](./static/agent_flow.png)\n\n## Table of contents\n\n- [Quickstart](#quickstart)\n  - [Environment variables](#set-environment-variables)\n  - [LangGraph Server](#start-the-langgraph-server)\n- [Full setup](#advanced-setup)\n  - [Environment variables](#set-environment-variables-1)\n  - [Authentication](#setup-authentication)\n  - [Supabase](#setup-supabase)\n  - [Slack](#setup-slack)\n  - [GitHub](#setup-github)\n- [Usage](#usage)\n  - [Generate Post](#generate-post)\n  - [Setup Crons](#setup-crons)\n  - [Prebuilt Scripts](#prebuilt-scripts)\n- [Setup Agent Inbox](#setup-agent-inbox)\n  - [Using the deployed inbox](#using-the-deployed-inbox)\n  - [Using the local inbox](#using-the-local-inbox)\n- [Customization](#customization)\n  - [Prompts](#prompts)\n  - [Post Style](#post-style)\n\n# Quickstart\n\n> [!TIP]\n> üé• For a visual guide, check out our [step-by-step video tutorial](https://youtu.be/TmTl5FMgkCQ) that walks you through the account setup process and project configuration.\n\nThis quickstart covers how to setup the Social Media Agent in a basic setup mode. This is the quickest way to get up and running, however it will lack some of the features of the full setup mode. See [here](#advanced-setup) for the full setup guide.\n\n<details>\n<summary>Running in basic setup mode will lack the following features:</summary>\n\n- Parsing content from GitHub, Twitter or YouTube URLs\n- Ingesting data from Slack, or sending updates to Slack\n- Image selection & uploads\n\n</details>\n\nTo get started, you'll need the following API keys/software:\n\n- [Anthropic API](https://console.anthropic.com/) - General LLM\n- [LangSmith](https://smith.langchain.com/) - LangSmith API key required to run the LangGraph server locally (free)\n- [FireCrawl API](https://www.firecrawl.dev/) - Web scraping. New users get 500 credits for free\n- [Arcade](https://www.arcade.dev/) - Easy authentication for reading & writing to social media platforms\n\n## Setup Instructions\n\n### Clone the repository:\n\n```bash\ngit clone https://github.com/langchain-ai/social-media-agent.git\n```\n\n```bash\ncd social-media-agent\n```\n\n### Install dependencies:\n\n```bash\nyarn install\n```\n\n### Set environment variables.\n\nCopy the values of the quickstart `.env.quickstart.example` to `.env`, then add the values:\n\n```bash\ncp .env.quickstart.example .env\n```\n\nOnce done, ensure you have the following environment variables set:\n\n```bash\n# For LangSmith tracing (optional)\nLANGSMITH_API_KEY=\nLANGSMITH_TRACING_V2=true\n\n# For LLM generations\nANTHROPIC_API_KEY=\n\n# For web scraping\nFIRECRAWL_API_KEY=\n\n# Arcade API key - used for fetching Tweets, and scheduling LinkedIn/Twitter posts\nARCADE_API_KEY=\n```\n\nIf you plan to post to LinkedIn as an organization (rather than as yourself), you'll also need to set:\n\n```bash\n# Get the organization ID from the URL of the company page when you're logged in as an admin.\n# For example, if the URL is `https://www.linkedin.com/company/12345678/admin/dashboard/`, the organization ID would be `12345678`.\nPOST_TO_LINKEDIN_ORGANIZATION=true\nLINKEDIN_ORGANIZATION_ID=\n```\n\n### Install LangGraph CLI\n\n```bash\npip install langgraph-cli\n```\n\nThen run the following command to check the CLI is installed:\n\n```bash\nlanggraph --version\n```\n\nClick [here](https://langchain-ai.github.io/langgraph/cloud/reference/cli/) to read the full download instructions for the LangGraph CLI.\n\n### Start the LangGraph server:\n\nTo start the LangGraph server, run this script:\n\n```bash\nyarn langgraph:in_mem:up\n```\n\nUnder the hood, this will execute the following command:\n\n```bash\nnpx @langchain/langgraph-cli dev --port 54367\n```\n\n> [!NOTE]\n> The first time running this command (or if a new version of `@langchain/langgraph-cli` has been released), it will ask you to accept an install for the CLI. Enter `y` to accept.\n\nOnce the server is ready, you can execute the following command to generate a post:\n\n```bash\nyarn generate_post\n```\n\nYou may also modify this script to pass different URLs to generate posts for other content.\n\nThis will kick off a new run to generate a post on a [LangChain blog post](https://blog.langchain.dev/customers-appfolio/).\n\nTo view the output, either inspect it in LangSmith, or use Agent Inbox.\n\n> [!TIP]\n> Follow these steps to setup & configure the Agent Inbox: [Setup Agent Inbox Guide](#setup-agent-inbox)\n\n# Advanced Setup\n\n![Screenshot of the social media agent graph](./static/graph_screenshot.png)\n\nTo use all of the features of the Social Media Agent, you'll need the following:\n\n- [Anthropic API](https://console.anthropic.com/) - General LLM\n- [Google Vertex AI](https://cloud.google.com/vertex-ai) - For dealing with YouTube video content\n- [LangSmith](https://smith.langchain.com/) - LangSmith API key required to run the LangGraph server locally (free)\n- [FireCrawl API](https://www.firecrawl.dev/) - Web scraping\n- [Arcade](https://www.arcade.dev) - Social media authentication and scheduling\n- [Twitter Developer Account](https://developer.twitter.com/en/portal/dashboard) - For uploading media to Twitter\n- [LinkedIn Developer Account](https://developer.linkedin.com/) - Posting to LinkedIn\n- [GitHub API](https://github.com/settings/personal-access-tokens) - Reading GitHub content\n- [Supabase](https://supabase.com/) - Storing images\n- [Slack Developer Account](https://api.slack.com/apps) (optional) - ingesting data from a Slack channel\n\n## Setup Instructions\n\n### Clone the repository:\n\n```bash\ngit clone https://github.com/langchain-ai/social-media-agent.git\n```\n\n```bash\ncd social-media-agent\n```\n\n### Install dependencies:\n\n```bash\nyarn install\n```\n\n### Set environment variables.\n\nCopy the values of the full env example file `.env.full.example` to `.env`, then update the values as needed.\n\n```bash\ncp .env.full.example .env\n```\n\n### Setup authentication\n\nThe agent needs your authorization to read and write to social media platforms. There are two ways to authorize the agent:\n\n1. Use Arcade (quickest to set up)\n2. Use your own Twitter and LinkedIn developer accounts\n\nYou can use either method, but not both.\n\n#### Arcade setup\n\nCreate an Arcade account [here](https://www.arcade.dev). After you register, [get an Arcade API key](https://docs.arcade.dev/home/quickstart?lang=typescript). Set this value as `ARCADE_API_KEY` in your `.env` file.\n\nThen, you will need to set these environment variables in your `.env` file:\n\n- `TWITTER_USER_ID` - The ID/email of the Twitter account you want to use to post to Twitter.\n- `LINKEDIN_USER_ID` - The ID/email of the LinkedIn account you want to use to post to LinkedIn.\n\nMake sure you have the `USE_ARCADE_AUTH` environment variable set to `true` to have the graph use Arcade authentication.\n\nIf you plan to post to LinkedIn as an organization (rather than as yourself), you'll also need to set:\n\n```bash\n# Get the organization ID from the URL of the company page when you're logged in as an admin.\n# For example, if the URL is `https://www.linkedin.com/company/12345678/admin/dashboard/`, the organization ID would be `12345678`.\nLINKEDIN_ORGANIZATION_ID=\nPOST_TO_LINKEDIN_ORGANIZATION=true\n```\n\n> [!NOTE]\n> If you want to upload media to Twitter, you will still need to set up your own Twitter developer account (below) in addition to using Arcade.\n>\n> If you are only planning to read/write text posts on Twitter, you can use Arcade without any additional setup.\n\n#### Twitter app setup\n\nYou'll need to follow these instructions if you plan on uploading media to Twitter, and/or you are not using Arcade for authorization.\n\n1. Create a Twitter developer account\n2. Create a new app and give it a name.\n3. Copy the `API Key`, `API Key Secret` and `Bearer Token` and set them as `TWITTER_API_KEY`, `TWITTER_API_KEY_SECRET`, and `TWITTER_BEARER_TOKEN` in your `.env` file.\n4. After saving, visit the App Dashboard. Find the `User authentication settings` section, and click the `Set up` button. This is how you will authorize users to use the Twitter API on their behalf.\n5. Set the following fields:\n\n- `App permissions`: `Read and write`\n- `Type of App`: `Web App, Automated App or Bot`\n- `App info`:\n  - `Callback URI/Redirect URL`: `http://localhost:3000/auth/twitter/callback`\n  - `Website URL`: Your website URL\n\n6. Save. You'll then be given a `Client ID` and `Client Secret`. Set these as `TWITTER_CLIENT_ID` and `TWITTER_CLIENT_SECRET` in your `.env` file.\n\nOnce done, run the `yarn start:auth` command to run the Twitter OAuth server. Open [http://localhost:3000](http://localhost:3000) in your browser, and click `Login with Twitter`.\n\nAfter authorizing your account with the app, navigate to your terminal where you'll see a JSON object logged. Copy the `token` and `tokenSecret` values and set them as `TWITTER_USER_TOKEN` and `TWITTER_USER_TOKEN_SECRET` in your `.env` file.\n\n#### LinkedIn app setup\n\nYou'll need to follow these instructions if you plan on posting to LinkedIn and are not using Arcade for authorization.\n\n1. Create a new LinkedIn developer account, and app [here](https://developer.linkedin.com/)\n2. After creating your app, navigate to the `Auth` tab, and add a new authorized redirect URL for OAuth 2.0. Set it to `http://localhost:3000/auth/linkedin/callback`\n3. Go to the `Products` tab and enable the `Share on LinkedIn` and `Sign In with LinkedIn using OpenID Connect` products.\n\n<details>\n<summary>If you plan on posting from company pages, you'll need to do the following:</summary>\n\n1. If you plan on posting from company pages, you'll also need to enable the `Advertising API` product. Furthermore, ensure your personal account has at least one one of the following roles with the company page:\n\n- `ADMINISTRATOR`\n- `DIRECT_SPONSORED_CONTENT_POSTER`\n- `RECRUITING_POSTER`\n\n2. Next, ensure your company page has verified the app. You can create a verification link on the `Settings` tab of your app, then click the `Verify` button on the company page card.\n3. Once requesting access, you'll need to fill out a form for verification. Once submitted, you should receive an email stating you've been granted developer access which will give you the proper permission to test out the API until it's been approved.\n4. Inside the [authorization server file (./src/clients/auth-server.ts)](./src/clients/auth-server.ts), ensure the `w_organization_social` scope is enabled inside the scopes string in the `/auth/linkedin` route. Once done, the scopes string should look like this: `openid profile email w_member_social w_organization_social`\n5. Get the organization ID from the URL of the company page when you're logged in as an admin and set it as the `LINKEDIN_ORGANIZATION_ID` environment variable. For example, if the URL is `https://www.linkedin.com/company/12345678/admin/dashboard/`, the organization ID would be `12345678`.\n\n> [!NOTE]\n> If you plan on only posting from the company account, you can set the `POST_TO_LINKEDIN_ORGANIZATION` to `\"true\"` in your `.env` file. If you want to choose dynamically, you can set this to `true`/`false` in the configurable fields (`postToLinkedInOrganization`) when invoking the `generate_post` graph.\n>\n> This value will take precedence over the `POST_TO_LINKEDIN_ORGANIZATION` environment variable.\n\n</details>\n\n4. Save the following environment variables in your `.env` file:\n\n- `LINKEDIN_CLIENT_ID`\n- `LINKEDIN_CLIENT_SECRET`\n\n5. Run the `yarn start:auth` command to run the LinkedIn OAuth server. Open [http://localhost:3000](http://localhost:3000) in your browser, and click `Login with LinkedIn`.\n6. After logging in, copy the `access_token` and `sub` values from the objects logged to the terminal. Set these values as `LINKEDIN_ACCESS_TOKEN` (`access_token`) and `LINKEDIN_PERSON_URN` (`sub`) in your `.env` file.\n\n</details>\n\n### Setup Supabase\n\nSupabase is required for storing images found/generated by the agent. This step is not required for running the agent in basic setup mode.\n\nTo setup Supabase, create an account and a new project.\n\nSet the `SUPABASE_URL` and `SUPABASE_SERVICE_ROLE_KEY` environment variables to the values provided by Supabase.\n\nCreate a new storage bucket called `images`. Make sure the bucket is set to public to the image URLs are accessible. Also ensure the max upload size is set to at least 5MB inside the global project settings, and the bucket specific settings.\n\n### Setup Slack\n\nSlack integration is optional, but recommended if you intend on using the `ingest_data` agent, or having updates sent to Slack.\n\nThis agent can be used in a cron job to fetch messages from a Slack channel, and call the `generate_post` graph for each message. We use this flow internally at LangChain to enable having a single Slack channel for submitting relevant URLs to the agent, which are then turned into posts once daily.\n\nTo configure the Slack integration, create a new Slack app and install it into your desired Slack workspace.\n\nOnce installed, ensure it has access to the channel you want to ingest messages from. Additionally, if you want it to send update messages to Slack, it will need write permissions to the workspace.\n\nFinally, make sure the `SLACK_BOT_TOKEN` environment variable is set in your `.env` file. Then, when you create a cron (see the [Setup Crons](#setup-crons) section), you'll only have to pass in the channel ID to ingest messages from.\n\nTo enable sending updates to Slack, add a `SLACK_CHANNEL_ID` environment variable to your `.env` file with the channel ID you want to send updates to (at LangChain, we have one channel for sending content links, and a separate one for sending update messages).\n\n### Setup GitHub\n\nThe GitHub API token is required to fetch details about GitHub repository URLs submitted to the agent. This is not required if you do not plan on sending GitHub URLs to the agent.\n\nTo get a GitHub API token, create a new fine grained token with the `Public Repositories (read-only)` scope at a minimum. If you intend on using this agent for private GitHub repositories, you'll need to give the token access to those repositories as well.\n\nEnsure this is set as `GITHUB_TOKEN` in your `.env` file.\n\n# Usage\n\n## Generate Post\n\nOnce all the setup steps have been completed, start your graph server by running:\n\n```bash\nyarn langgraph:in_mem:up\n```\n\n> [!NOTE]\n> The first time running this command (or if a new version of `@langchain/langgraph-cli` has been released), it will ask you to accept an install for the CLI. Enter `y` to accept.\n\nOnce the server is ready, you can execute the following command to generate a post:\n\n(before doing this, you should edit the file so that the text only mode is set to false: `[TEXT_ONLY_MODE]: false` if using advanced setup mode)\n\n```bash\nyarn generate_post\n```\n\nThis will kick off a new run to generate a post on a [LangChain blog post](https://blog.langchain.dev/customers-appfolio/).\n\nTo view the output, either inspect it in LangSmith, or use [the Agent Inbox](#setup-agent-inbox).\n\nYou may also modify this script to pass different URLs to generate posts for other content.\n\n## Setup Crons\n\nThe Agent Inbox is most powerful when used with cron jobs. Doing this allows you to send links to generate posts on to a Slack channel, and have the cron job check for these links asynchronously. With this setup, you can send links to Slack, and have the inbox handle the rest while you sleep.\n\nWe have a series of scripts to help with this, which you can find in the [`scripts/crons`](./scripts/crons) directory. In this section, we'll explain how to quickly create a cron for ingesting links to your graph from Slack.\n\n### Slack Setup\n\nBefore we get started, ensure you have the proper Slack integration setup, as described in the [Setup Slack](#setup-slack) section. Then, edit the [`create-cron.ts`](./scripts/crons/create-cron.ts) file, and set the `slackChannelId` field to the channel ID of the channel you want to ingest links from.\n\nAfter editing, run the following command to create the cron:\n\n```bash\nyarn cron:create\n```\n\nThis will create a new cron job that will ingest links from Slack into your graph, once daily.\n\n## Prebuilt Scripts\n\nFor more information on all of the prebuilt scripts, see the [`scripts/README.md`](./scripts/README.md) file.\n\n# Setup Agent Inbox\n\nThe Agent Inbox is the easiest way to view interrupted events, and manage accepting, responding, or other allowed actions. To view your events in the inbox, you can either add your graph to the deployed version of the Agent Inbox, or clone & run the Agent Inbox locally.\n\n## Using the deployed inbox\n\nThe Agent Inbox is setup in a way that allows for any graph --local or deployed-- to be added & accessed via the UI.\n\nTo add your local graph to the inbox, visit the deployed site here: [dev.agentinbox.ai](https://dev.agentinbox.ai/).\n\nIf it's your first time vising the site, you'll immediately be prompted to add a new graph. Fill out the form with the following values:\n\n- Graph ID: `generate_post`\n- Graph API URL: `http://localhost:54367`\n- Name: (optional) `Generate Post (local)`\n\nAfter saving, you should be able to view your graph in the inbox. If you do this after invoking your graph (and waiting for the thread to interrupt), it will automatically fetch the interrupted event.\n\n## Using the local inbox\n\nTo run the Agent Inbox locally, follow the setup instructions [here](https://github.com/langchain-ai/agent-inbox/blob/main/README.md).\n\nOnce the web server is running, open your browser and visit [http://localhost:3000](http://localhost:3000). This will then prompt you to add your graph to the inbox.\n\nFill out the form with the following values:\n\n- Graph ID: `generate_post`\n- Graph API URL: `http://localhost:54367`\n- Name: (optional) `Generate Post (local)`\n\n## Using the Agent Inbox with a graph deployed on LangGraph Platform\n\nThe Agent Inbox can also be used with graph's deployed in production on LangGraph Platform. To use these graphs, the setup steps are the exact same, with the only difference being the graph API URL should be the URL of the deployed graph, and you're required to set a LangSmith API key. This is required to fetch & invoke the deployed graph. LangSmith API keys are stored in your browser's local storage, and never stored on the server.\n\n# Customization\n\n## Prompts\n\nThis agent is setup to generate posts for LangChain, using LangChain products as context. To use the agent for your own use case, you should update the following prompts/prompt sections inside the [`prompts`](./src/agents/generate-post/prompts/index.ts) folder:\n\n- `BUSINESS_CONTEXT` - Context to be used when checking whether or not content is relevant to your business/use case.\n- `TWEET_EXAMPLES` ([`prompts/examples.ts`](./src/agents/generate-post/prompts/examples.ts)) - A list of examples of posts you'd like the agent to use as a guide when generating the final post.\n- `POST_STRUCTURE_INSTRUCTIONS` - A set of structure instructions for the agent to follow when generating the final post.\n- `POST_CONTENT_RULES` - A set of general writing style/content guidelines for the agent to follow when generating a post.\n\nThe prompt for the marketing report is located in the [`generate-post/nodes/generate-report/prompts.ts`](./src/agents/generate-post/nodes/generate-report/prompts.ts) file. You likely don't need to update this, as it's already structured to be general.\n\n## Post Style\n\nThere are two main prompts to modify to change the style of the posts.\n\n1. Post structure instructions (`POST_STRUCTURE_INSTRUCTIONS`). These are the instructions the LLM will follow for how to structure the post generations. This should _not_ be where you specify tone, or writing style. This prompt is used to set the structure each post should follow. By default, it's prompted to include three parts: `Header`, `Body`, `Call to action`. When experimenting with this prompt this, try removing it completely, instead relying on the few-shot examples (`TWEET_EXAMPLES`) and the content rules (`POST_CONTENT_RULES`).\n2. Few-shot examples (`TWEET_EXAMPLES`). These are the examples given to the LLM of which it's prompted to use as examples for style, content, tone and structure. This is arguably one of the most important parts of the prompt. Currently, these are set to a handful of Tweets by popular AI focused Twitter accounts. You should _definitely_ update these if you want to generate non-AI focused Tweets, instead with examples of Tweets/posts on your target content.\n3. \"Business context\" (`BUSINESS_CONTEXT`). This prompt is used widely throughout the agent to provide context into your main goal of the social media agent. For us at LangChain, this prompt is used to describe the different LangChain products and services. The default prompt is focused on AI content, but should be updated/edited to match your use case. This prompt is used in verifying content is relevant for you, generating marketing reports, and generating tweets.\n",
      "stars_today": 51
    },
    {
      "id": 189630195,
      "name": "TaskExplorer",
      "full_name": "DavidXanatos/TaskExplorer",
      "description": "Power full Task Manager",
      "html_url": "https://github.com/DavidXanatos/TaskExplorer",
      "stars": 2990,
      "forks": 236,
      "language": "C",
      "topics": [],
      "created_at": "2019-05-31T17:03:45Z",
      "updated_at": "2026-01-23T01:53:32Z",
      "pushed_at": "2026-01-17T09:26:06Z",
      "open_issues": 49,
      "owner": {
        "login": "DavidXanatos",
        "avatar_url": "https://avatars.githubusercontent.com/u/3890945?v=4"
      },
      "readme": "# TaskExplorer\n\nTask Explorer is a powerful task management tool designed not only to monitor running applications but to provide deep insight into what those applications are doing. Its user interface prioritizes speed and efficiency, delivering real-time data on processes with minimal interaction. Instead of requiring multiple windows or sub-windows, Task Explorer displays relevant information in accessible panels. When selecting a process, detailed information is displayed in the lower half of the screen, allowing you to navigate through the data seamlessly using the arrow keys. The dynamic data refresh allows users to observe changes in real-time, offering additional clarity and insight into system performance and behavior.\n\n## Features\n\nTask Explorer offers an array of advanced features to provide comprehensive visibility into the system. The **Thread Panel** displays a stack trace for the selected thread, offering immediate insights into the current actions of an application, which is particularly useful for diagnosing deadlocks or performance bottlenecks. The **Memory Panel** allows users to view and edit process memory, featuring an advanced memory editor with string search capabilities. In the **Handles Panel**, all open handles are displayed, including essential details such as file names, current file positions, and sizes, giving a clear view of the disk operations a program is performing. \n\nThe **Socket Panel** provides visibility into all open connections or sockets for each process, with additional data rate information. It also has the option to show pseudo UDP connections based on ETW data, allowing users to monitor network communications effectively. The **Modules Panel** lists all loaded DLLs and memory-mapped files, with the ability to unload or inject DLLs as needed. Additionally, the application includes a variety of other useful panels, including **Token**, **Environment**, **Windows**, **GDI**, and **.NET** panels.\n\nBy double-clicking a process, you can open the **Task Info Panels** in a separate window, enabling the simultaneous inspection of multiple processes. The system monitoring capabilities are robust as well, featuring toolbar graphs that show real-time usage of system resources such as CPU, handles, network traffic, and disk access. The **System Info Panels** display all open files and sockets and allow users to control system services, including drivers. Dedicated performance panels for CPU, Memory, Disk I/O, Network, and GPU resources offer detailed graphs, making it easy to monitor and optimize system performance.\n\nFor users who need more screen space, the **System Info Panel** can be fully collapsed or opened in a separate window, maximizing the available area for the task panels.\n\n## Screen Shots\n\n![image](./.github/images/thread_view.png)\n![image](./.github/images/handle_view.png)\n\n\n## System Requirements\n\nTask Explorer is compatible with Windows 7 or higher, on both 32-bit and 64-bit systems.\n\n## Additional Information\n\nTask Explorer is built using the Qt Framework, ensuring a cross-platform user interface with plans to eventually port the tool to Linux, which could make it one of the first advanced, GUI-based task managers for the platform. On Windows, Task Explorer leverages the Process Hacker library and uses a custom-compiled version of the systeminformer.sys driver from the [SystemInformer](https://github.com/winsiderss/systeminformer/) project, ensuring robust performance and system monitoring capabilities.\n\n## Support\n\nIf you find Task Explorer useful, please consider supporting the project on Patreon: [https://www.patreon.com/DavidXanatos](https://www.patreon.com/DavidXanatos)\n\nIcons provided by [Icons8](http://icons8.com/).\n",
      "stars_today": 49
    },
    {
      "id": 155297903,
      "name": "dozzle",
      "full_name": "amir20/dozzle",
      "description": "Realtime log viewer for containers.  Supports Docker, Swarm and K8s. ",
      "html_url": "https://github.com/amir20/dozzle",
      "stars": 11155,
      "forks": 481,
      "language": "Go",
      "topics": [
        "docker",
        "docker-container",
        "golang",
        "k8s",
        "log",
        "logging",
        "logging-server",
        "real-time",
        "sever-events",
        "swarm",
        "vuejs"
      ],
      "created_at": "2018-10-30T00:05:23Z",
      "updated_at": "2026-01-23T01:40:07Z",
      "pushed_at": "2026-01-23T00:54:55Z",
      "open_issues": 5,
      "owner": {
        "login": "amir20",
        "avatar_url": "https://avatars.githubusercontent.com/u/260667?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"assets/logo.svg\" alt=\"Dozzle Logo\" width=\"200\"/>\n</p>\n\n# Dozzle - [dozzle.dev](https://dozzle.dev/)\n\nDozzle is a small lightweight application with a web based interface to monitor Docker logs. It doesn‚Äôt store any log files. It is for live monitoring of your container logs only.\n\nhttps://github.com/user-attachments/assets/66a7b4b2-d6c9-4fca-ab04-aef6cd7c0c31\n\n[![Docker Image Size (latest by date)](https://img.shields.io/docker/image-size/amir20/dozzle)](https://hub.docker.com/r/amir20/dozzle/)\n[![Docker Pulls](https://img.shields.io/docker/pulls/amir20/dozzle.svg)](https://hub.docker.com/r/amir20/dozzle/)\n[![Docker Version](https://img.shields.io/docker/v/amir20/dozzle?sort=semver)](https://hub.docker.com/r/amir20/dozzle/)\n![Test](https://github.com/amir20/dozzle/workflows/Test/badge.svg)\n\n> [!NOTE]\n> If you like Dozzle, check out [`dtop`](https://github.com/amir20/dtop) which is a top like application for monitoring Docker containers. It integrates with Dozzle to allow for linking directly to container logs.\n\n## Features\n\n- Intelligent fuzzy search for container names ü§ñ\n- Search logs using regex üî¶\n- Search logs using [SQL queries](https://dozzle.dev/guide/sql-engine) üìä\n- Small memory footprint üèé\n- Split screen for viewing multiple logs\n- Live stats with memory and CPU usage\n- Multi-user [authentication](https://dozzle.dev/guide/authentication) with support for proxy forward authorization üö®\n- [Swarm](https://dozzle.dev/guide/swarm-mode) mode support üê≥\n- [Agent](https://dozzle.dev/guide/agent) mode for monitoring multiple Docker hosts üïµÔ∏è‚Äç‚ôÇÔ∏è\n- Dark mode üåô\n\nDozzle has been tested with hundreds of containers. However, it doesn't support offline searching. Products like [Loggly](https://www.loggly.com), [Papertrail](https://papertrailapp.com) or [Kibana](https://www.elastic.co/products/kibana) are more suited for full search capabilities.\n\n## Getting Started\n\nDozzle is a small container (7 MB compressed). Pull the latest release with:\n\n    $ docker pull amir20/dozzle:latest\n\n### Running Dozzle\n\nThe simplest way to use dozzle is to run the docker container. Also, mount the Docker Unix socket with `--volume` to `/var/run/docker.sock`:\n\n    $ docker run --name dozzle -d --volume=/var/run/docker.sock:/var/run/docker.sock -p 8080:8080 amir20/dozzle:latest\n\nDozzle will be available at [http://localhost:8080/](http://localhost:8080/).\n\nHere is the Docker Compose file:\n\n    services:\n      dozzle:\n        container_name: dozzle\n        image: amir20/dozzle:latest\n        volumes:\n          - /var/run/docker.sock:/var/run/docker.sock\n        ports:\n          - 8080:8080\n\nFor advanced options like [authentication](https://dozzle.dev/guide/authentication), [remote hosts](https://dozzle.dev/guide/remote-hosts) or common [questions](https://dozzle.dev/guide/faq) see documentation at [dozzle.dev](https://dozzle.dev/guide/getting-started).\n\n## Swarm Mode\n\nDozzle works with Docker Swarm mode. You can run Dozzle as a global service with:\n\n    $ docker service create --name dozzle --env DOZZLE_MODE=swarm --mode global --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock -p 8080:8080 amir20/dozzle:latest\n\nSee the [Swarm Mode](https://dozzle.dev/guide/swarm-mode) documentation for more details.\n\n## Agent Mode\n\nDozzle can be used to monitor multiple Docker hosts. You can run Dozzle in agent mode with:\n\n    $ docker run -v /var/run/docker.sock:/var/run/docker.sock -p 7007:7007 amir20/dozzle:latest agent\n\nSee the [Agent Mode](https://dozzle.dev/guide/agent) documentation for more details.\n\n## Technical Details\n\nDozzle users automatic API negotiation which works with most Docker configurations. Dozzle also works with [Colima](https://github.com/abiosoft/colima) and [Podman](https://podman.io/).\n\n### Installation on podman\n\nBy default Podman doesn't have a background process but you can enable this for Dozzle to work.\n\nVerify first if your podman installation has enabled remote socket:\n\n```\npodman info\n```\n\nWhen you get under the key remote socket output like this, its already enabled:\n\n```\n  remoteSocket:\n    exists: true\n    path: /run/user/1000/podman/podman.sock\n```\n\nIf it's not enabled please follow [this tutorial](https://github.com/containers/podman/blob/main/docs/tutorials/socket_activation.md) to enable it.\n\nOnce you have the podman remote socket you can run Dozzle on podman.\n\n```\npodman run --volume=/run/user/1000/podman/podman.sock:/var/run/docker.sock -d -p 8080:8080 docker.io/amir20/dozzle:latest\n```\n\nAdditionally you have to create a fake engine-id to prevent `host not found` errors. Podman doesn't generate an engine-id like Docker by itself due to its daemonless architecture.\n\nUnder `/var/lib/docker` create a file named `engine-id`. On a system with Podman you will have to create the folder path as well. Inside the file place the UUID, for instance using `uuidgen > engine-id`. After that the file should have an identifier that looks like this: `b9f1d7fc-b459-4b6e-9f7a-e3d1cd2e14a9`.\n\nFor more details check [Podman Infos](docs/guide/podman.md) or the [FAQ](docs/guide/faq.md#i-am-seeing-host-not-found-error-in-the-logs-how-do-i-fix-it)\n\n## Security\n\nDozzle supports file based authentication and forward proxy like [Authelia](https://www.authelia.com/). These are documented at https://dozzle.dev/guide/authentication.\n\n## Analytics collected\n\nDozzle collects anonymous user configurations using Google Analytics. Why? Dozzle is an open source project with no funding. As a result, there is no time to do user studies of Dozzle. Analytics is collected to prioritize features and fixes based on how people use Dozzle. This data is completely public and can be viewed live using [ Data Studio dashboard](https://datastudio.google.com/s/naeIu0MiWsY).\n\nIf you do not want to be tracked at all, see the `--no-analytics` flag below.\n\n## Environment variables and configuration\n\nDozzle follows the [12-factor](https://12factor.net/) model. Configurations can use the CLI flags or environment variables. See documentation at [https://dozzle.dev/guide/supported-env-vars](https://dozzle.dev/guide/supported-env-vars) for more details.\n\n## Support\n\nThere are many ways you can support Dozzle:\n\n- Use it! Write about it! Star it! If you love Dozzle, drop me a line and tell me what you love.\n- Blog about Dozzle to spread the word. If you are good at writing send PRs to improve the documentation at [dozzle.dev](https://dozzle.dev/)\n- Sponsor my work at https://www.buymeacoffee.com/amirraminfar\n\n<a href=\"https://www.buymeacoffee.com/amirraminfar\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png\" alt=\"Buy Me A Coffee\" style=\"height: 60px !important;width: 217px !important;\" ></a>\n\n## License\n\n[MIT](LICENSE)\n\n## Building\n\nTo build and test locally:\n\n1. Install [NodeJs](https://nodejs.org/en/download/) and [pnpm](https://pnpm.io/installation).\n2. Install [Go](https://go.dev/doc/install).\n3. Install tools with `make tools`.\n4. Install node modules `pnpm install`.\n5. Run `make dev` to start a development server with hot reload.\n",
      "stars_today": 45
    },
    {
      "id": 564499496,
      "name": "pixels",
      "full_name": "databricks-industry-solutions/pixels",
      "description": "Facilitates simple large scale processing of HLS Medical images, documents, zip files. OHIF Viewer, 2 segmentation models and interactive learning.",
      "html_url": "https://github.com/databricks-industry-solutions/pixels",
      "stars": 182,
      "forks": 58,
      "language": "JavaScript",
      "topics": [
        "dicom",
        "fair-data",
        "hls",
        "medical-imaging"
      ],
      "created_at": "2022-11-10T21:12:59Z",
      "updated_at": "2026-01-23T00:43:01Z",
      "pushed_at": "2026-01-22T16:58:52Z",
      "open_issues": 53,
      "owner": {
        "login": "databricks-industry-solutions",
        "avatar_url": "https://avatars.githubusercontent.com/u/106546034?v=4"
      },
      "readme": "<div bgcolor=\"white\">\n  <img src=https://hls-eng-data-public.s3.amazonaws.com/img/Databricks_HLS.png width=\"380px\" align=\"right\">\n</div>\n\n# `pixels` Solution Accelerator\n‚úÖ  Ingest and index DICOM image metadata (.dcm and from zip archives)\n</br> ‚úÖ  Analyze DICOM image metadata with SQL and Machine Learning.\n</br> ‚úÖ  View, segment, label DICOM Images with OHIF viewer integrated into Lakehouse Apps and Databricks security model. \n</br> ‚úÖ  One button push to launch model training from OHIF viewer.\n</br> ‚úÖ  NVIDIA's [MONAI](https://docs.nvidia.com/monai/index.html) Integration, AI to automatically segment medical images and train custom models.\n</br> ‚úÖ  Leverage Databricks' [Model Serving](https://docs.databricks.com/en/machine-learning/model-serving/index.html) with serverless GPU enabled clusters for real-time segmentation.\n\n---\n## Secure Lakehouse integrated DICOM Viewer powered by OHIF\n<img src=\"https://github.com/databricks-industry-solutions/pixels/blob/main/images/LHA_AUTOSEG.gif?raw=true\" alt=\"MONAI_AUTOSEG\"/></br>\n\n---\n## Run SQL queries over DICOM metadata\n![Analyze](https://github.com/databricks-industry-solutions/pixels/blob/main/images/DICOM-analyze-with-SQL.png?raw=true)\n\n---\n## Build Dashboards over DICOM metadata\nadd any features extracted too!\n![Dashboard](images/pixels-dashboard.png)\n\n---\n## DICOM data ingestion is easy\n\n```python\n# import Pixels Catalog (indexer) and DICOM transformers & utilities\nfrom dbx.pixels import Catalog                              # 01\nfrom dbx.pixels.dicom import *                              # 02\n\n# catalog all your files\ncatalog = Catalog(spark)                                    # 03\ncatalog_df = catalog.catalog(<path>)                        # 04\n\n# extract the DICOM metadata\nmeta_df = DicomMetaExtractor(catalog).transform(catalog_df) # 05\n\n# save your work for SQL access\ncatalog.save(meta_df)                                       # 06\n```\nYou'll find this example in [01-dcm-demo](https://github.com/databricks-industry-solutions/pixels/blob/main/01-dcm-demo.py) which does:\n\n---\n## Architecture\n![image](https://github.com/user-attachments/assets/75decf47-3a37-446a-a672-d497d155f464)\n\nThe image depicts the **Pixels Reference Solution Architecture**, which outlines a data processing and analytics framework designed for healthcare or imaging applications. Here's a breakdown of its components:\n\n### **Key Functional Areas**\n1. **AI/BI Analytics**: Supports cohort building and natural language-based analysis.\n   \n2. **Lakehouse Apps**: Includes an OHIF Viewer for labeling and customer-specific applications.\n\n3. **Deep Learning**: Facilitates active learning and customer model training.\n\n4. **Realtime Inferencing**: Implements MONAI (Medical Open Network for AI) for segmentation integration with the OHIF viewer. Customer provided proprietary models can be easily plugged in.\n\n### **Data Flow: Batch, Incremental, Streaming Lakeflow**\nThe architecture processes data in stages:\n1. **Acquire**: from data in ADLS, S3, GCS cloud storage as governed by Unity Catalog (UC) Volumes.  Based on customer demand, due to the composible nature of the solution accelerator, sources VNA, PACS, CIFS, AWS HealthImaging can be added as needed.\n   \n2. **Ingest**:  Ultimately all the DICOM files are ingested. Ingesting and producing Nifti file formats are currently on the roadmap.\n\n3. **Extract & Index**: Unzips files, storing the extracted DICOM files into a UC volume. All of the DICOM metadata tags are extracted and stored in Databricks Data Intelligence Platform tables.\n\n4. **Protect ‚Äì Metadata**: Applies PHI (Protected Health Information) redaction via format preserving encryption to all necessary tags.\n\n5. **Protect ‚Äì Image**: Ensures PHI redaction for pixel-level data. This is under active integration based on work Databricks has done in previous solution accelerators.\n\n6. **Inferencing**: Utilizes industry-standard models pre-trained MONAI open source models sponsored by NVIDIA. Similarly, customers can fine tune the MONAI models or bring their own segmentation or featurization models.\n\n### **Supporting Layers**\n- **Governance Layer**: Unity Catalog provides data access controls, automatic capture of data lineage (including models)\n  \n- **Customer‚Äôs Cloud Storage**: Stores object indexes, folders, and ML models in open formats in customer's account.\n  \n- **Open Access**: Provides APIs, SQL connections, Spark integration, and credential vending via Delta Sharing.\n\nThis architecture is designed to handle healthcare imaging data securely while enabling advanced analytics and AI-driven insights.\n\n\n---\n## Getting started\n\n1. To run this accelerator, [clone](https://docs.databricks.com/aws/en/repos/git-operations-with-repos) this repo into a Databricks workspace. \n\n2. Attach a notebook to Serverless Compute or a cluster (>=DBR 14.3 LTS)\n3. Run [`config/setup.py`]($./config/setup) from the notebook. This will install the pixels package onto your workspace\n\n\n## Run pipeline as a job\n1. Attach the [`RUNME`]($./RUNME) notebook to Serverless Compute or a cluster (>=DBR 14.3 LTS). 2. Execute the notebook via Run-All. You can configure the notebook tasks run by the job in `job_json`\nA multi-step-job describing the accelerator pipeline will be created, and the link will be provided. The cost associated with running the accelerator is the user's responsibility.\n\n## Incremental processing\nPixels allows you to ingest DICOM files in a streaming fashion using [autoloader](https://docs.databricks.com/en/ingestion/auto-loader/unity-catalog.html) capability.\nTo enable incremental processing you need to set `streaming` and `streamCheckpointBasePath` as follows:\n```python\ncatalog_df = catalog.catalog(path, streaming=True, streamCheckpointBasePath=<checkpointPath>)\n```\n\n## Built-in unzip\nAutomatically extracts zip files in the defined volume path.\nIf extractZip is not enabled then zip files will be ignored.\nTo enable unzip capability you need to set `extractZip`. The parameter `extractZipBasePath` is optional and the default path will be volume + /unzipped/\n```python\ncatalog_df = catalog.catalog(path, extractZip=True, extractZipBasePath=<unzipPath>)\n```\n\n## Metadata Anonymization\nPixels provides a feature to anonymize DICOM metadata to ensure patient privacy and compliance with regulations. This feature can be enabled during the cataloging process. An example can be explored in the [03-Metadata-DeIdentification](https://github.com/databricks-industry-solutions/pixels/blob/main/03-Metadata-DeIdentification.py) notebook.\n\nTo enable metadata anonymization, you can use the following extractor:\n```python\nmetadata_df = DicomMetaAnonymizerExtractor(\n   catalog,\n   anonym_mode=\"METADATA\",\n   fp_key=<fp_key>, #ONLY HEX STRING ALLOWED - 128, 192 or 256 bits\n   fp_tweak=<fp_tweak>,   #ONLY HEX STRING ALLOWED - 64 bits\n   anonymization_base_path=<anonym_path>\n).transform(catalog_df)\n```\n`fp_key` is the format preserving encryption key used to ensure that the anonymization process is consistent across different runs. This key is used to generate pseudonyms for sensitive data fields, ensuring that the same input value always maps to the same pseudonym. This is useful for maintaining the ability to link records across datasets without revealing the original sensitive information.\n\n`fp_tweak` is an optional parameter that can be used to add an additional layer of randomness to the pseudonymization process. This can be useful for further enhancing privacy.\n\nBy setting the `anonym_mode` parameter to `\"METADATA\"`, the DICOM metadata will be anonymized during the ingestion process. This ensures that sensitive patient information is not stored in the catalog.\nThe default configuration will save the anonymized DICOM files under `anonymization_base_path` property's path.\n\n---\n## OHIF Viewer\nInside `dbx.pixels` resources folder, a pre-built version of [OHIF Viewer](https://github.com/OHIF/Viewers) with Databricks and [Unity Catalog Volumes](https://docs.databricks.com/en/sql/language-manual/sql-ref-volumes.html) extension is provided. \n\nAll the catalog entries will be available in an easy to use study list.\n![Catalog](https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_catalog_view.png?raw=true)\nFast and multiple-layer visualization capability.\n![CT_View](https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_mr_view.png?raw=true)\n\nTo start the OHIF Viewer web app you need to:\n - Execute the [06-OHIF-Viewer](https://github.com/databricks-industry-solutions/pixels/blob/main/06-OHIF-Viewer.py) inside a Databricks workspace.\n - Set the `table` parameter to the full name of your Pixels catalog table. Ex: `main.pixels_solacc.object_catalog`\n - Set the `sqlWarehouseID`parameter to execute the queries required to collect the records. It's the final section of the `HTTP path` in the `Connection details` tab. Use [Serverless](https://docs.databricks.com/en/admin/sql/warehouse-types.html#sql-warehouse-types) for best performance.\n\n    <img src=\"https://github.com/databricks-industry-solutions/pixels/blob/main/images/sqlWarehouseID.png?raw=true\" alt=\"sqlWarehouseID\"/>\n\n - Use the link generated in the last notebook to access the OHIF viewer page.\n\n## Save measurements and segmentations\nThe OHIF Viewer allows you to save back to Databricks the measurements and the segmentations created in the viewer.\nThe metadata will be stored in the object_catalog, and the generated dicom files in the volume under the path `/ohif/exports/`.\n\n<img src=\"https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_save_segm.png?raw=true\" alt=\"OHIF_SAVE_SEG\" height=\"300\"/>\n<img src=\"https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_save_meas.png?raw=true\" alt=\"OHIF_SAVE_MEAS\" height=\"300\"/>\n<img src=\"https://github.com/databricks-industry-solutions/pixels/blob/main/images/ohif_save_result.png?raw=true\" alt=\"OHIF_SAVED\" height=\"300\"/>\n\n\n## MONAILabel Integration\n\n[MONAILabel](https://monai.io/label.html) is an open-source tool designed for interactive medical image labeling. It supports various annotation tasks such as segmentation and classification, providing a seamless experience when integrated with viewers like OHIF that is already available in this solution accelerator.\n\n![MONAI_BTN](https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_result.png?raw=true)\nOnce the server is running, you can use the OHIF Viewer to interact with your medical images. This integration allows you to leverage advanced annotation capabilities directly within your Databricks environment.\n\n### Key Features\n - Interactive Annotation: Use AI-assisted tools for efficient labeling.\n - Seamless Integration: Work directly within Databricks using a web-based viewer.\n - Customizable Workflows: Tailor the annotation process to fit specific research needs.\n\n### MONAILabel Setup Instructions\nTo execute the MONAILabel server it is mandatory to use a cluster with Databricks Runtime Version of `14.3 LTS ML`. For the best performance use a [GPU-Enabled compute](https://docs.databricks.com/en/compute/gpu.html#gpu-enabled-compute).\n#### Start the MONAILabel server\n - Execute the [05-MONAILabel](https://github.com/databricks-industry-solutions/pixels/blob/main/05-MONAILabel.py) inside a Databricks workspace.\n - Set the `table` parameter to the full name of your Pixels catalog table. Ex: `main.pixels_solacc.object_catalog`\n - Set the `sqlWarehouseID`parameter to the DBSQL Warehouse ID, needed to run queries required to collect the records. Use [Serverless](https://docs.databricks.com/en/admin/sql/warehouse-types.html#sql-warehouse-types) for best performance.\n    <img src=\"https://github.com/databricks-industry-solutions/pixels/blob/main/images/sqlWarehouseID.png?raw=true\" alt=\"sqlWarehouseID\">\n#### Open the OHIF Viewer\n - Execute the notebook [06-OHIF-Viewer](https://github.com/databricks-industry-solutions/pixels/blob/main/06-OHIF-Viewer.py) to start the OHIF Viewer with the MONAILabel extension and open the generated link.\n - Select the preferred CT scan study and press the `MONAI Label` button.\n\n    <img src=\"https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_btn.png?raw=true\" alt=\"MONAI_BTN\" height=\"250\"/></br>\n#### Connect, execute and save\n - Connect the MONAILabel server using the refresh button.\n\n    <img src=\"https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_server.png?raw=true\" alt=\"MONAI_SERVER\" height=\"200\"/></br>\n - Execute an auto-segmentation task using the Run button and wait for the results to be displayed.\n\n    <img src=\"https://github.com/databricks-industry-solutions/pixels/blob/main/images/monailabel_autosegm.png?raw=true\" alt=\"MONAI_AUTOSEG\" height=\"650\"/></br>\n - Save the final result metadata in the catalog and the generated dicom file in the volume under the path `/ohif/exports/` using the button `Export DICOM SEG`.\n\nThis setup enhances your medical image analysis workflow by combining Databricks' computing power with MONAILabel's sophisticated annotation tools.\n\n### Model Serving Instructions\n\nTo deploy the MONAILabel server in a Model Serving endpoint we prepared [ModelServing](https://github.com/databricks-industry-solutions/pixels/blob/main/monailabel_model/ModelServing.py), a Databricks notebook designed to initialize the Databricks customized version of the **MONAILabel server** that wraps the server in an **MLflow Python custom model** and registers it for use in a **serving endpoint**.\n\n#### Key Features\n\n- **Model Creation**: Utilizes the MONAILabel auto segmentation model on CT AXIAL images.\n- **Unity Catalog Integration**: Adds the model to the Unity Catalog for organized management.\n- **Serving Endpoint Deployment**: Deploys the model in a serving endpoint for real-time inference.\n\n#### Auto Segmentation with Lakehouse App and Serving Endpoint\n\nhttps://github.com/user-attachments/assets/8cf62378-ab39-4a89-86ad-c2f231b7a524\n\n#### Active Learning\n\nhttps://github.com/user-attachments/assets/17142752-d9b9-434b-b893-b6bc05080f54\n\n\n## Working with Unity Catalog\nUnity Catalog (UC) [volumes](https://docs.databricks.com/en/data-governance/unity-catalog/create-volumes.html) are the recommended approach for providing access to and governing non-tabular data assets in a cloud object storage locations, including DICOM files. Volumes are accessed by using the following format for the path that is passed to the pixels `Catalog` object - \n```\n/Volumes/<catalog>/<schema>/<volume>/<path-level-1>/...\n```\nwhere `<catalog>`, `<schema>` and `<volume>` reflect the three-level namespace of Unity Catalog. The path field returned by the `Catalog` object reflects the volume file path listed above and subsequent metadata and thumbnail extraction operations will use volumes for accessing files.\n\nDICOM file Ingestion works with Shared, Dedicated and Serverless Compute types.\n\n---\n## Contributors\n- Douglas Moore @ Databricks\n- Emanuele Rinaldi @ Databricks\n- Nicole Jingting Lu @ Databricks\n- Krishanu Nandy @ Databricks\n- May Merkle-Tan @ Databricks\n- Cal Reynolds @ Databricks\n- Guanyu Chen @ Databricks\n- Yen Low @ Databricks\n- Ben Russoniello @ Prominence Advisors\n\n\n## About `dbx.pixels`\nRelibly turn millions of image files into SQL accessible metadata, thumbnails; Enable Deep Learning, AI/BI Dashboarding, Genie Spaces.\n\n- tags: \ndicom, dcm, pre-processing, visualization, repos, sql, python, spark, pyspark, package, image catalog, mamograms, dcm file\n---\n\n## About DICOM\n![DICOM Image processing](https://dicom.offis.uni-oldenburg.de/images/dicomlogo.gif)\n[Per OFFIS computer science institute](https://dicom.offis.uni-oldenburg.de/en/general/dicom-introduction/) \n\nDICOM¬Æ ‚Äî Digital Imaging and Communications in Medicine ‚Äî is the international standard for medical images and related information. It defines the formats for medical images that can be exchanged with the data and quality necessary for clinical use.\n\nDICOM¬Æ is implemented in almost every radiology, cardiology imaging, and radiotherapy device (X-ray, CT, MRI, ultrasound, etc.), and increasingly in devices in other medical domains such as ophthalmology and dentistry. With hundreds of thousands of medical imaging devices in use, DICOM¬Æ is one of the most widely deployed healthcare messaging Standards in the world. There are literally billions of DICOM¬Æ images currently in use for clinical care.\n\nSince its first publication in 1993, DICOM¬Æ has revolutionized the practice of radiology, allowing the replacement of X-ray film with a fully digital workflow. Much as the Internet has become the platform for new consumer information applications, DICOM¬Æ has enabled advanced medical imaging applications that have ‚Äúchanged the face of clinical medicine‚Äù. From the emergency department, to cardiac stress testing, to breast cancer detection, DICOM¬Æ is the standard that makes medical imaging work ‚Äî for doctors and for patients.\n\nDICOM¬Æ is recognized by the International Organization for Standardization as the ISO 12052 standard.\n\n## Licensing\n\n&copy; 2024 Databricks, Inc. All rights reserved. The source in this notebook is provided subject to the Databricks License [https://databricks.com/db-license-source].  All included or referenced third party libraries are subject to the licenses set forth below.\n\n| library              | purpose                             | license                       | source                                                  |\n|----------------------|-------------------------------------|-------------------------------|---------------------------------------------------------|\n| dbx.pixels           | Scale out image processing library  | Databricks                    | https://github.com/databricks-industry-solutions/pixels |\n| pydicom              | Python api for DICOM files          | MIT                           | https://github.com/pydicom/pydicom                      |\n| python-gdcm          | Install gdcm C++ libraries          | Apache Software License (BSD) | https://github.com/tfmoraes/python-gdcm                 |\n| gdcm                 | Parse DICOM files                   | BSD                           | https://sourceforge.net/projects/gdcm                   |\n| s3fs                 | Resolve s3:// paths                 | BSD 3-Clause                  | https://github.com/fsspec/s3fs                          |\n| pandas               | Pandas UDFs                         | BSD License (BSD-3-Clause)    | https://github.com/pandas-dev/pandas                    |\n| OHIF Viewer          | Medical image viewer                | MIT                           | https://github.com/OHIF/Viewers                         |\n| MONAILabel           | Intelligent open source image labeling and learning tool | Apache-2.0 license  | https://github.com/Project-MONAI/MONAILabel |\n| DICOGNITO            | A library and command line tool for anonymizing DICOM files | MIT  | https://github.com/blairconrad/dicognito |\n| FF3                  | FPE - Format Preserving Encryption with FF3 in Python | Apache-2.0 license  | https://github.com/mysto/python-fpe |\n| Vista3D              | MONAI Versatile Imaging SegmenTation and Annotation model | Apache-2.0 license (code) - NCLS v1 (model weight) | https://github.com/Project-MONAI/VISTA/tree/main/vista3d |\n\n\n",
      "stars_today": 45
    },
    {
      "id": 626896474,
      "name": "SafeLine",
      "full_name": "chaitin/SafeLine",
      "description": "SafeLine is a self-hosted WAF(Web Application Firewall) / reverse proxy to protect your web apps from attacks and exploits.",
      "html_url": "https://github.com/chaitin/SafeLine",
      "stars": 20209,
      "forks": 1295,
      "language": "Go",
      "topics": [
        "api-gateway",
        "application-security",
        "appsec",
        "blueteam",
        "bruteforce",
        "captcha",
        "cve",
        "cybersecurity",
        "firewall",
        "hackers",
        "http-flood",
        "security",
        "self-hosted",
        "sql-injection",
        "vulnerability",
        "waf",
        "web-application-firewall",
        "web-security",
        "websecurity",
        "xss"
      ],
      "created_at": "2023-04-12T11:30:14Z",
      "updated_at": "2026-01-23T00:07:16Z",
      "pushed_at": "2025-11-05T08:13:12Z",
      "open_issues": 62,
      "owner": {
        "login": "chaitin",
        "avatar_url": "https://avatars.githubusercontent.com/u/7302766?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"/images/banner.png\" width=\"400\" />\n</p>\n\n<h4 align=\"center\">\n  SafeLine - Make your web apps secure\n</h4>\n\n<p align=\"center\">\n  <a target=\"_blank\" href=\"https://ly.safepoint.cloud/laA8asp\">üè† Website</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"https://ly.safepoint.cloud/w2AeHhb\">üìñ Docs</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"https://ly.safepoint.cloud/hSMd4SH\">üîç Live Demo</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"https://discord.gg/SVnZGzHFvn\">üôã‚Äç‚ôÇÔ∏è Discord</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"/README_CN.md\">‰∏≠ÊñáÁâà</a>\n</p>\n\n## üëã INTRODUCTION\n\nSafeLine is a self-hosted **`WAF(Web Application Firewall)`** to protect your web apps from attacks and exploits.\n\nA web application firewall helps protect web apps by filtering and monitoring HTTP traffic between a web application and the Internet. It typically protects web apps from attacks such as `SQL injection`, `XSS`, `code injection`, `os command injection`, `CRLF injection`, `ldap injection`, `xpath injection`, `RCE`, `XXE`, `SSRF`, `path traversal`, `backdoor`, `bruteforce`, `http-flood`, `bot abused`, among others.\n\n#### üí° How It Works\n\n<img src=\"/images/how-it-works.png\" width=\"800\" />\n\nBy deploying a WAF in front of a web application, a shield is placed between the web application and the Internet. While a proxy server protects a client machine‚Äôs identity by using an intermediary, a WAF is a type of reverse-proxy, protecting the server from exposure by having clients pass through the WAF before reaching the server.\n\nA WAF protects your web apps by filtering, monitoring, and blocking any malicious HTTP/S traffic traveling to the web application, and prevents any unauthorized data from leaving the app. It does this by adhering to a set of policies that help determine what traffic is malicious and what traffic is safe. Just as a proxy server acts as an intermediary to protect the identity of a client, a WAF operates in similar fashion but acting as a reverse proxy intermediary that protects the web app server from a potentially malicious client.\n\nits core capabilities include:\n\n- Defenses for web attacks\n- Proactive bot abused defense \n- HTML & JS code encryption\n- IP-based rate limiting\n- Web Access Control List\n\n#### ‚ö°Ô∏è Screenshots\n\n| <img src=\"./images/screenshot-1.png\" width=370 /> | <img src=\"./images/screenshot-2.png\" width=370 /> |\n| ------------------------------------------------- | ------------------------------------------------- | \n| <img src=\"./images/screenshot-3.png\" width=370 /> | <img src=\"./images/screenshot-4.png\" width=370 /> | \n\nGet [Live Demo](https://demo.waf.chaitin.com:9443/)\n\n## üî• FEATURES\n\nList of the main features as follows:\n\n- **`Block Web Attacks`**\n  - It defenses for all of web attacks, such as `SQL injection`, `XSS`, `code injection`, `os command injection`, `CRLF injection`, `XXE`, `SSRF`, `path traversal` and so on.\n- **`Rate Limiting`**\n  - Defend your web apps against `DoS attacks`, `bruteforce attempts`, `traffic surges`, and other types of abuse by throttling traffic that exceeds defined limits.\n- **`Anti-Bot Challenge`**\n  - Anti-Bot challenges to protect your website from `bot attacks`, humen users will be allowed, crawlers and bots will be blocked.\n- **`Authentication Challenge`**\n  - When authentication challenge turned on, visitors need to enter the password, otherwise they will be blocked.\n- **`Dynamic Protection`**\n  - When dynamic protection turned on, html and js codes in your web server will be dynamically encrypted by each time you visit.\n\n#### üß© Showcases\n\n|                               | Legitimate User                                     | Malicious User                                                   |\n| ----------------------------- | --------------------------------------------------- | ---------------------------------------------------------------- | \n| **`Block Web Attacks`**       | <img src=\"./images/skeleton.png\" width=270 />       | <img src=\"./images/blocked-for-attack-detected.png\" width=270 /> |\n| **`Rate Limiting`**           | <img src=\"./images/skeleton.png\" width=270 />       | <img src=\"./images/blocked-for-access-too-fast.png\" width=270 /> |\n| **`Anti-Bot Challenge`**       | <img src=\"./images/captcha-1.gif\" width=270 />      | <img src=\"./images/captcha-2.gif\" width=270 />                     |\n| **`Auth Challenge`**          | <img src=\"./images/auth-1.gif\" width=270 />         | <img src=\"./images/auth-2.gif\" width=270 />                        |\n| **`HTML Dynamic Protection`** | <img src=\"./images/dynamic-html-1.png\" width=270 /> | <img src=\"./images/dynamic-html-2.png\" width=270 />              |\n| **`JS Dynamic Protection`**   | <img src=\"./images/dynamic-js-1.png\" width=270 />   | <img src=\"./images/dynamic-js-2.png\" width=270 />                | \n\n## üöÄ Quickstart\n\n> [!WARNING]\n> ‰∏≠ÂõΩÂ§ßÈôÜÁî®Êà∑ÂÆâË£ÖÂõΩÈôÖÁâàÂèØËÉΩ‰ºöÂØºËá¥Êó†Ê≥ïËøûÊé•‰∫ëÊúçÂä°ÔºåËØ∑Êü•Áúã [‰∏≠ÊñáÁâàÂÆâË£ÖÊñáÊ°£](https://docs.waf-ce.chaitin.cn/zh/%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/%E5%AE%89%E8%A3%85%E9%9B%B7%E6%B1%A0)\n\n#### üì¶ Installing\n\nInformation on how to install SafeLine can be found in the [Install Guide](https://docs.waf.chaitin.com/en/GetStarted/Deploy)\n\n#### ‚öôÔ∏è Protecting Web Apps\n\nto see [Configuration](https://docs.waf.chaitin.com/en/GetStarted/AddApplication)\n\n## üìã More Informations\n\n#### Effect Evaluation\n\n| Metric            | ModSecurity, Level 1 | CloudFlare, Free     | SafeLine, Balance      | SafeLine, Strict      |\n| ----------------- | -------------------- | -------------------- | ---------------------- | --------------------- |\n| Total Samples     | 33669                | 33669                | 33669                  | 33669                 |\n| **Detection**     | 69.74%               | 10.70%               | 71.65%                 | **76.17%**            |\n| **False Positive**| 17.58%               | 0.07%                | **0.07%**              | 0.22%                 |\n| **Accuracy**      | 82.20%               | 98.40%               | **99.45%**             | 99.38%                |\n\n\n#### Is SafeLine Production-Ready?\n\nYes, SafeLine is production-ready.\n\n- Over 180,000 installations worldwide\n- Protecting over 1,000,000 Websites\n- Handling over 30,000,000,000 HTTP Requests Daily\n\n#### üôã‚Äç‚ôÇÔ∏è Community\n\nJoin our [Discord](https://discord.gg/SVnZGzHFvn) to get community support, the core team members are identified by the STAFF role in Discord.\n\n- channel [#feedback](https://discord.com/channels/1243085666485534830/1243120292822253598): for new features discussion.\n- channel [#FAQ](https://discord.com/channels/1243085666485534830/1263761679619981413): for FAQ.\n- channel [#general](https://discord.com/channels/1243085666485534830/1243115843919806486): for any other questions.\n\nSeveral contact options exist for our community, the primary one being Discord. These are in addition to GitHub issues for creating a new issue.\n\n<p align=\"left\">\n  <a target=\"_blank\" href=\"https://discord.gg/SVnZGzHFvn\"><img src=\"https://img.shields.io/badge/Discord-5865F2?style=flat&logo=discord&logoColor=white\"></a> &nbsp;\n  <a target=\"_blank\" href=\"https://x.com/safeline_waf\"><img src=\"https://img.shields.io/badge/X.com-000000?style=flat&logo=x&logoColor=white\"></a> &nbsp;\n  <a target=\"_blank\" href=\"/images/wechat.png\"><img src=\"https://img.shields.io/badge/WeChat-07C160?style=flat&logo=wechat&logoColor=white\"></a>\n</p>\n\n#### üí™ PRO Edition\n\nComing soon!\n\n#### üìù License\n\nSee [LICENSE](/LICENSE.md) for details.\n",
      "stars_today": 41
    },
    {
      "id": 542284380,
      "name": "bruno",
      "full_name": "usebruno/bruno",
      "description": "Opensource IDE For Exploring and Testing API's (lightweight alternative to Postman/Insomnia)",
      "html_url": "https://github.com/usebruno/bruno",
      "stars": 40177,
      "forks": 2072,
      "language": "JavaScript",
      "topics": [
        "api-client",
        "api-testing",
        "automation",
        "developer-tools",
        "git",
        "graphql-client",
        "http-client",
        "javascript",
        "openapi",
        "openapi3",
        "opensource",
        "rest-api",
        "testing",
        "testing-tools"
      ],
      "created_at": "2022-09-27T20:51:45Z",
      "updated_at": "2026-01-23T01:49:53Z",
      "pushed_at": "2026-01-22T14:46:33Z",
      "open_issues": 1662,
      "owner": {
        "login": "usebruno",
        "avatar_url": "https://avatars.githubusercontent.com/u/114530840?v=4"
      },
      "readme": "<br />\n<img src=\"assets/images/logo-transparent.png\" width=\"80\"/>\n\n### Bruno - Opensource IDE for exploring and testing APIs.\n\n[![GitHub version](https://badge.fury.io/gh/usebruno%2Fbruno.svg)](https://badge.fury.io/gh/usebruno%2Fbruno)\n[![CI](https://github.com/usebruno/bruno/actions/workflows/tests.yml/badge.svg?branch=main)](https://github.com/usebruno/bruno/actions/workflows/tests.yml)\n[![Commit Activity](https://img.shields.io/github/commit-activity/m/usebruno/bruno)](https://github.com/usebruno/bruno/pulse)\n[![X](https://img.shields.io/twitter/follow/use_bruno?style=social&logo=x)](https://twitter.com/use_bruno)\n[![Website](https://img.shields.io/badge/Website-Visit-blue)](https://www.usebruno.com)\n[![Download](https://img.shields.io/badge/Download-Latest-brightgreen)](https://www.usebruno.com/downloads)\n\n**English**\n| [–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](docs/readme/readme_ua.md)\n| [–†—É—Å—Å–∫–∏–π](docs/readme/readme_ru.md)\n| [T√ºrk√ße](docs/readme/readme_tr.md)\n| [Deutsch](docs/readme/readme_de.md)\n| [Fran√ßais](docs/readme/readme_fr.md)\n| [Portugu√™s (BR)](docs/readme/readme_pt_br.md)\n| [ÌïúÍµ≠Ïñ¥](docs/readme/readme_kr.md)\n| [‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](docs/readme/readme_bn.md)\n| [Espa√±ol](docs/readme/readme_es.md)\n| [Italiano](docs/readme/readme_it.md)\n| [Rom√¢nƒÉ](docs/readme/readme_ro.md)\n| [Polski](docs/readme/readme_pl.md)\n| [ÁÆÄ‰Ωì‰∏≠Êñá](docs/readme/readme_cn.md)\n| [Ê≠£È´î‰∏≠Êñá](docs/readme/readme_zhtw.md)\n| [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](docs/readme/readme_ar.md)\n| [Êó•Êú¨Ë™û](docs/readme/readme_ja.md)\n| [·É•·Éê·É†·Éó·É£·Éö·Éò](docs/readme/readme_ka.md)\n| [Nederlands](docs/readme/readme_nl.md)\n| [ŸÅÿßÿ±ÿ≥€å](docs/readme/readme_fa.md)\n\nBruno is a new and innovative API client, aimed at revolutionizing the status quo represented by Postman and similar tools out there.\n\nBruno stores your collections directly in a folder on your filesystem. We use a plain text markup language, Bru, to save information about API requests.\n\nYou can use Git or any version control of your choice to collaborate over your API collections.\n\nBruno is offline-only. There are no plans to add cloud-sync to Bruno, ever. We value your data privacy and believe it should stay on your device. Read our long-term vision [here](https://github.com/usebruno/bruno/discussions/269)\n\n[Download Bruno](https://www.usebruno.com/downloads)\n\nüì¢ Watch our recent talk at India FOSS 3.0 Conference [here](https://www.youtube.com/watch?v=7bSMFpbcPiY)\n\n![bruno](assets/images/landing-2-dark.png#gh-light-mode-only)\n![bruno](assets/images/landing-2-light.png#gh-dark-mode-only) <br /><br />\n\n## Commercial Versions ‚ú®\n\nMajority of our features are free and open source.\nWe strive to strike a harmonious balance between [open-source principles and sustainability](https://github.com/usebruno/bruno/discussions/269)\n\nYou can explore our [paid versions](https://www.usebruno.com/pricing) to see if there are additional features that you or your team may find useful! <br/>\n\n## Table of Contents\n\n- [Installation](#installation)\n- [Features](#features)\n  - [Run across multiple platforms üñ•Ô∏è](#run-across-multiple-platforms-%EF%B8%8F)\n  - [Collaborate via Git üë©‚Äçüíªüßë‚Äçüíª](#collaborate-via-git-%E2%80%8D%E2%80%8D)\n- [Important Links üìå](#important-links-)\n- [Showcase üé•](#showcase-)\n- [Share Testimonials üì£](#share-testimonials-)\n- [Publishing to New Package Managers](#publishing-to-new-package-managers)\n- [Stay in touch üåê](#stay-in-touch-)\n- [Trademark](#trademark)\n- [Contribute üë©‚Äçüíªüßë‚Äçüíª](#contribute-%E2%80%8D%E2%80%8D)\n- [Authors](#authors)\n- [License üìÑ](#license-)\n\n## Installation\n\nBruno is available as binary download [on our website](https://www.usebruno.com/downloads) for Mac, Windows and Linux.\n\nYou can also install Bruno via package managers like Homebrew, Chocolatey, Scoop, Snap, Flatpak and Apt.\n\n```sh\n# On Mac via Homebrew\nbrew install bruno\n\n# On Windows via Chocolatey\nchoco install bruno\n\n# On Windows via Scoop\nscoop bucket add extras\nscoop install bruno\n\n# On Windows via winget\nwinget install Bruno.Bruno\n\n# On Linux via Snap\nsnap install bruno\n\n# On Linux via Flatpak\nflatpak install com.usebruno.Bruno\n\n# On Arch Linux via AUR\nyay -S bruno\n\n# On Linux via Apt\nsudo mkdir -p /etc/apt/keyrings\nsudo apt update && sudo apt install gpg curl\ncurl -fsSL \"https://keyserver.ubuntu.com/pks/lookup?op=get&search=0x9FA6017ECABE0266\" \\\n  | gpg --dearmor \\\n  | sudo tee /etc/apt/keyrings/bruno.gpg > /dev/null\nsudo chmod 644 /etc/apt/keyrings/bruno.gpg\necho \"deb [arch=amd64 signed-by=/etc/apt/keyrings/bruno.gpg] http://debian.usebruno.com/ bruno stable\" \\\n  | sudo tee /etc/apt/sources.list.d/bruno.list\nsudo apt update && sudo apt install bruno\n```\n\n## Features\n\n### Run across multiple platforms üñ•Ô∏è\n\n![bruno](assets/images/run-anywhere.png) <br /><br />\n\n### Collaborate via Git üë©‚Äçüíªüßë‚Äçüíª\n\nOr any version control system of your choice\n\n![bruno](assets/images/version-control.png) <br /><br />\n\n## Important Links üìå\n\n- [Our Long Term Vision](https://github.com/usebruno/bruno/discussions/269)\n- [Roadmap](https://www.usebruno.com/roadmap)\n- [Documentation](https://docs.usebruno.com)\n- [Stack Overflow](https://stackoverflow.com/questions/tagged/bruno)\n- [Website](https://www.usebruno.com)\n- [Pricing](https://www.usebruno.com/pricing)\n- [Download](https://www.usebruno.com/downloads)\n\n## Showcase üé•\n\n- [Testimonials](https://github.com/usebruno/bruno/discussions/343)\n- [Knowledge Hub](https://github.com/usebruno/bruno/discussions/386)\n- [Scriptmania](https://github.com/usebruno/bruno/discussions/385)\n\n## Share Testimonials üì£\n\nIf Bruno has helped you at work and your teams, please don't forget to share your [testimonials on our GitHub discussion](https://github.com/usebruno/bruno/discussions/343)\n\n## Publishing to New Package Managers\n\nPlease see [here](publishing.md) for more information.\n\n## Stay in touch üåê\n\n[ùïè (Twitter)](https://twitter.com/use_bruno) <br />\n[Website](https://www.usebruno.com) <br />\n[Discord](https://discord.com/invite/KgcZUncpjq) <br />\n[LinkedIn](https://www.linkedin.com/company/usebruno)\n\n## Trademark\n\n**Name**\n\n`Bruno` is a trademark held by [Anoop M D](https://www.helloanoop.com/)\n\n**Logo**\n\nThe logo is sourced from [OpenMoji](https://openmoji.org/library/emoji-1F436/). License: CC [BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)\n\n## Contribute üë©‚Äçüíªüßë‚Äçüíª\n\nI am happy that you are looking to improve bruno. Please check out the [contributing guide](contributing.md)\n\nEven if you are not able to make contributions via code, please don't hesitate to file bugs and feature requests that needs to be implemented to solve your use case.\n\n## Authors\n\n<div align=\"center\">\n    <a href=\"https://github.com/usebruno/bruno/graphs/contributors\">\n        <img src=\"https://contrib.rocks/image?repo=usebruno/bruno\" />\n    </a>\n</div>\n\n## License üìÑ\n\n[MIT](license.md)\n",
      "stars_today": 39
    },
    {
      "id": 709589487,
      "name": "awesome-system-design-resources",
      "full_name": "ashishps1/awesome-system-design-resources",
      "description": "Learn System Design concepts and prepare for interviews using free resources.",
      "html_url": "https://github.com/ashishps1/awesome-system-design-resources",
      "stars": 29211,
      "forks": 6701,
      "language": "Java",
      "topics": [
        "awesome",
        "backend",
        "computer-science",
        "distributed-systems",
        "high-level-design",
        "hld",
        "interview",
        "interview-questions",
        "scalability",
        "system-design"
      ],
      "created_at": "2023-10-25T01:50:42Z",
      "updated_at": "2026-01-23T01:58:31Z",
      "pushed_at": "2026-01-11T14:54:34Z",
      "open_issues": 7,
      "owner": {
        "login": "ashishps1",
        "avatar_url": "https://avatars.githubusercontent.com/u/8646889?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"diagrams/system-design-github-logo.png\" width=\"350\" height=\"200\">\n</p>\n\nThis repository contains free resources to learn System Design concepts and prepare for interviews.\n\nüëâ Subscribe to my [AlgoMaster Newsletter](https://bit.ly/amghsd) and get a **FREE System Design Interview Handbook** in your inbox.\n\n‚úÖ If you are new to System Design, start here: [System Design was HARD until I Learned these 30 Concepts](https://blog.algomaster.io/p/30-system-design-concepts)\n\n## ‚öôÔ∏è Core Concepts\n- [Scalability](https://algomaster.io/learn/system-design/scalability)\n- [Availability](https://algomaster.io/learn/system-design/availability)\n- [Reliability](https://algomaster.io/learn/system-design/reliability)\n- [CAP Theorem](https://blog.algomaster.io/p/cap-theorem-explained)\n- [Consistent Hashing](https://blog.algomaster.io/p/consistent-hashing-explained)\n- [SPOF](https://blog.algomaster.io/p/system-design-how-to-avoid-single-point-of-failures)\n- [Failover](https://www.druva.com/glossary/what-is-a-failover-definition-and-related-faqs)\n- [Fault Tolerance](https://www.cockroachlabs.com/blog/what-is-fault-tolerance/)\n\n## üåê Networking Fundamentals\n- [OSI Model](https://algomaster.io/learn/system-design/osi)\n- [IP Addresses](https://algomaster.io/learn/system-design/ip-address)\n- [Domain Name System (DNS)](https://blog.algomaster.io/p/how-dns-actually-works)\n- [Proxy vs Reverse Proxy](https://blog.algomaster.io/p/proxy-vs-reverse-proxy-explained)\n- [HTTP/HTTPS](https://algomaster.io/learn/system-design/http-https)\n- [TCP vs UDP](https://algomaster.io/learn/system-design/tcp-vs-udp)\n- [Load Balancing](https://blog.algomaster.io/p/load-balancing-algorithms-explained-with-code)\n- [Checksums](https://algomaster.io/learn/system-design/checksums)\n\n## üîå API Fundamentals\n- [APIs](https://algomaster.io/learn/system-design/what-is-an-api)\n- [API Gateway](https://blog.algomaster.io/p/what-is-an-api-gateway)\n- [REST vs GraphQL](https://blog.algomaster.io/p/rest-vs-graphql)\n- [WebSockets](https://blog.algomaster.io/p/websockets)\n- [Webhooks](https://algomaster.io/learn/system-design/webhooks)\n- [Idempotency](https://algomaster.io/learn/system-design/idempotency)\n- [Rate limiting](https://blog.algomaster.io/p/rate-limiting-algorithms-explained-with-code)\n- [API Design](https://abdulrwahab.medium.com/api-architecture-best-practices-for-designing-rest-apis-bf907025f5f)\n\n## üóÑÔ∏è Database Fundamentals\n- [ACID Transactions](https://algomaster.io/learn/system-design/acid-transactions)\n- [SQL vs NoSQL](https://algomaster.io/learn/system-design/sql-vs-nosql)\n- [Database Indexes](https://algomaster.io/learn/system-design/indexing)\n- [Database Sharding](https://algomaster.io/learn/system-design/sharding)\n- [Data Replication](https://redis.com/blog/what-is-data-replication/)\n- [Database Scaling](https://blog.algomaster.io/p/system-design-how-to-scale-a-database)\n- [Databases Types](https://blog.algomaster.io/p/15-types-of-databases)\n- [Bloom Filters](https://algomaster.io/learn/system-design/bloom-filters)\n- [Database Architectures](https://www.mongodb.com/developer/products/mongodb/active-active-application-architectures/)\n\n## ‚ö° Caching Fundamentals\n- [Caching 101](https://algomaster.io/learn/system-design/what-is-caching)\n- [Caching Strategies](https://algomaster.io/learn/system-design/caching-strategies)\n- [Cache Eviction Policies](https://blog.algomaster.io/p/7-cache-eviction-strategies)\n- [Distributed Caching](https://blog.algomaster.io/p/distributed-caching)\n- [Content Delivery Network (CDN)](https://algomaster.io/learn/system-design/content-delivery-network-cdn)\n\n## üîÑ Asynchronous Communication\n- [Pub/Sub](https://algomaster.io/learn/system-design/pub-sub)\n- [Message Queues](https://algomaster.io/learn/system-design/message-queues)\n- [Change Data Capture (CDC)](https://algomaster.io/learn/system-design/change-data-capture-cdc)\n\n## üß© Distributed System and Microservices\n- [HeartBeats](https://blog.algomaster.io/p/heartbeats-in-distributed-systems)\n- [Service Discovery](https://blog.algomaster.io/p/service-discovery-in-distributed-systems)\n- [Consensus Algorithms](https://medium.com/@sourabhatta1819/consensus-in-distributed-system-ac79f8ba2b8c)\n- [Distributed Locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)\n- [Microservices Guidelines](https://newsletter.systemdesign.one/p/netflix-microservices) \n- [Gossip Protocol](http://highscalability.com/blog/2023/7/16/gossip-protocol-explained.html)\n- [Circuit Breaker](https://medium.com/geekculture/design-patterns-for-microservices-circuit-breaker-pattern-276249ffab33)\n- [Disaster Recovery](https://cloud.google.com/learn/what-is-disaster-recovery)\n- [Distributed Tracing](https://www.dynatrace.com/news/blog/what-is-distributed-tracing/)\n\n## üñáÔ∏è Architectural Patterns\n- [Client-Server Architecture](https://algomaster.io/learn/system-design/client-server-architecture)\n- [Microservices Architecture](https://medium.com/hashmapinc/the-what-why-and-how-of-a-microservices-architecture-4179579423a9)\n- [Serverless Architecture](https://blog.algomaster.io/p/2edeb23b-cfa5-4b24-845e-3f6f7a39d162)\n- [Event-Driven Architecture](https://www.confluent.io/learn/event-driven-architecture/)\n- [Peer-to-Peer (P2P) Architecture](https://www.spiceworks.com/tech/networking/articles/what-is-peer-to-peer/)\n\n## ‚öñÔ∏è System Design Tradeoffs\n- [Top 15 Tradeoffs](https://blog.algomaster.io/p/system-design-top-15-trade-offs)\n- [Vertical vs Horizontal Scaling](https://algomaster.io/learn/system-design/vertical-vs-horizontal-scaling)\n- [Concurrency vs Parallelism](https://blog.algomaster.io/p/concurrency-vs-parallelism)\n- [Long Polling vs WebSockets](https://blog.algomaster.io/p/long-polling-vs-websockets)\n- [Batch vs Stream Processing](https://blog.algomaster.io/p/batch-processing-vs-stream-processing)\n- [Stateful vs Stateless Design](https://blog.algomaster.io/p/stateful-vs-stateless-architecture)\n- [Strong vs Eventual Consistency](https://blog.algomaster.io/p/strong-vs-eventual-consistency)\n- [Read-Through vs Write-Through Cache](https://blog.algomaster.io/p/59cae60d-9717-4e20-a59e-759e370db4e5)\n- [Push vs Pull Architecture](https://blog.algomaster.io/p/af5fe2fe-9a4f-4708-af43-184945a243af)\n- [REST vs RPC](https://blog.algomaster.io/p/106604fb-b746-41de-88fb-60e932b2ff68)\n- [Synchronous vs. asynchronous communications](https://blog.algomaster.io/p/aec1cebf-6060-45a7-8e00-47364ca70761)\n- [Latency vs Throughput](https://aws.amazon.com/compare/the-difference-between-throughput-and-latency/)\n\n## ‚úÖ [How to Answer a System Design Interview Problem](https://algomaster.io/learn/system-design-interviews/answering-framework)\n\n## üíª System Design Interview Problems\n### Easy\n- [Design URL Shortener like TinyURL](https://algomaster.io/learn/system-design-interviews/design-url-shortener)\n- [Design Autocomplete for Search Engines](https://algomaster.io/learn/system-design-interviews/design-instagram)\n- [Design Load Balancer](https://algomaster.io/learn/system-design-interviews/design-load-balancer)\n- [Design Content Delivery Network (CDN)](https://www.youtube.com/watch?v=8zX0rue2Hic)\n- [Design Parking Garage](https://www.youtube.com/watch?v=NtMvNh0WFVM)\n- [Design Vending Machine](https://www.youtube.com/watch?v=D0kDMUgo27c)\n- [Design Distributed Key-Value Store](https://www.youtube.com/watch?v=rnZmdmlR-2M)\n- [Design Distributed Cache](https://www.youtube.com/watch?v=iuqZvajTOyA)\n- [Design Authentication System](https://www.youtube.com/watch?v=uj_4vxm9u90)\n- [Design Unified Payments Interface (UPI)](https://www.youtube.com/watch?v=QpLy0_c_RXk)\n### Medium\n- [Design WhatsApp](https://algomaster.io/learn/system-design-interviews/design-whatsapp)\n- [Design Spotify](https://algomaster.io/learn/system-design-interviews/design-spotify)\n- [Design Instagram](https://algomaster.io/learn/system-design-interviews/design-instagram)\n- [Design Notification Service](https://algomaster.io/learn/system-design-interviews/design-notification-service)\n- [Design Distributed Job Scheduler](https://blog.algomaster.io/p/design-a-distributed-job-scheduler)\n- [Design Tinder](https://www.youtube.com/watch?v=tndzLznxq40)\n- [Design Facebook](https://www.youtube.com/watch?v=9-hjBGxuiEs)\n- [Design Twitter](https://www.youtube.com/watch?v=wYk0xPP_P_8)\n- [Design Reddit](https://www.youtube.com/watch?v=KYExYE_9nIY)\n- [Design Netflix](https://www.youtube.com/watch?v=psQzyFfsUGU)\n- [Design Youtube](https://www.youtube.com/watch?v=jPKTo1iGQiE)\n- [Design Google Search](https://www.youtube.com/watch?v=CeGtqouT8eA)\n- [Design E-commerce Store like Amazon](https://www.youtube.com/watch?v=EpASu_1dUdE)\n- [Design TikTok](https://www.youtube.com/watch?v=Z-0g_aJL5Fw)\n- [Design Shopify](https://www.youtube.com/watch?v=lEL4F_0J3l8)\n- [Design Airbnb](https://www.youtube.com/watch?v=YyOXt2MEkv4)\n- [Design Rate Limiter](https://www.youtube.com/watch?v=mhUQe4BKZXs)\n- [Design Distributed Message Queue like Kafka](https://www.youtube.com/watch?v=iJLL-KPqBpM)\n- [Design Flight Booking System](https://www.youtube.com/watch?v=qsGcfVGvFSs)\n- [Design Online Code Editor](https://www.youtube.com/watch?v=07jkn4jUtso)\n- [Design an Analytics Platform (Metrics & Logging)](https://www.youtube.com/watch?v=kIcq1_pBQSY)\n- [Design Payment System](https://www.youtube.com/watch?v=olfaBgJrUBI)\n- [Design a Digital Wallet](https://www.youtube.com/watch?v=4ijjIUeq6hE)\n### Hard\n- [Design Location Based Service like Yelp](https://www.youtube.com/watch?v=M4lR_Va97cQ)\n- [Design Uber](https://www.youtube.com/watch?v=umWABit-wbk)\n- [Design Food Delivery App like Doordash](https://www.youtube.com/watch?v=iRhSAR3ldTw)\n- [Design Google Docs](https://www.youtube.com/watch?v=2auwirNBvGg)\n- [Design Google Maps](https://www.youtube.com/watch?v=jk3yvVfNvds)\n- [Design Zoom](https://www.youtube.com/watch?v=G32ThJakeHk)\n- [Design Distributed Counter](https://systemdesign.one/distributed-counter-system-design/)\n- [Design File Sharing System like Dropbox](https://www.youtube.com/watch?v=U0xTu6E2CT8)\n- [Design Ticket Booking System like BookMyShow](https://www.youtube.com/watch?v=lBAwJgoO3Ek)\n- [Design Distributed Web Crawler](https://www.youtube.com/watch?v=BKZxZwUgL3Y)\n- [Design Code Deployment System](https://www.youtube.com/watch?v=q0KGYwNbf-0)\n- [Design Distributed Cloud Storage like S3](https://www.youtube.com/watch?v=UmWtcgC96X8)\n- [Design Distributed Locking Service](https://www.youtube.com/watch?v=v7x75aN9liM)\n- [Design Slack](https://systemdesign.one/slack-architecture/)\n- [Design Live Comments](https://systemdesign.one/live-comment-system-design/)\n\n## üìá Courses\n- [System Design Fundamentals](https://algomaster.io/learn/system-design/course-introduction)\n- [System Design Interviews](https://algomaster.io/learn/system-design-interviews/introduction)\n\n## üì© Newsletters\n- [AlgoMaster Newsletter](https://blog.algomaster.io/)\n\n## üìö Books\n- [Designing Data-Intensive Applications](https://www.amazon.in/dp/9352135245)\n\n## üì∫ YouTube Channels\n- [Tech Dummies Narendra L](https://www.youtube.com/@TechDummiesNarendraL)\n- [Gaurav Sen](https://www.youtube.com/@gkcs)\n- [codeKarle](https://www.youtube.com/@codeKarle)\n- [ByteByteGo](https://www.youtube.com/@ByteByteGo)\n- [System Design Interview](https://www.youtube.com/@SystemDesignInterview)\n- [sudoCODE](https://www.youtube.com/@sudocode)\n- [Success in Tech](https://www.youtube.com/@SuccessinTech/videos)\n\n## üìú Must-Read Engineering Articles\n- [How Discord stores trillions of messages](https://discord.com/blog/how-discord-stores-trillions-of-messages)\n- [Building In-Video Search at Netflix](https://netflixtechblog.com/building-in-video-search-936766f0017c)\n- [How Canva scaled Media uploads from Zero to 50 Million per Day](https://www.canva.dev/blog/engineering/from-zero-to-50-million-uploads-per-day-scaling-media-at-canva/)\n- [How Airbnb avoids double payments in a Distributed Payments System](https://medium.com/airbnb-engineering/avoiding-double-payments-in-a-distributed-payments-system-2981f6b070bb)\n- [Stripe‚Äôs payments APIs - The first 10 years](https://stripe.com/blog/payment-api-design)\n- [Real time messaging at Slack](https://slack.engineering/real-time-messaging/)\n\n## üóûÔ∏è Must-Read Distributed Systems Papers\n- [Paxos: The Part-Time Parliament](https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf)\n- [MapReduce: Simplified Data Processing on Large Clusters](https://research.google.com/archive/mapreduce-osdi04.pdf)\n- [The Google File System](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf)\n- [Dynamo: Amazon‚Äôs Highly Available Key-value Store](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)\n- [Kafka: a Distributed Messaging System for Log Processing](https://notes.stephenholiday.com/Kafka.pdf)\n- [Spanner: Google‚Äôs Globally-Distributed Database](https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf)\n- [Bigtable: A Distributed Storage System for Structured Data](https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf)\n- [ZooKeeper: Wait-free coordination for Internet-scale systems](https://www.usenix.org/legacy/event/usenix10/tech/full_papers/Hunt.pdf)\n- [The Log-Structured Merge-Tree (LSM-Tree)](https://www.cs.umb.edu/~poneil/lsmtree.pdf)\n- [The Chubby lock service for loosely-coupled distributed systems](https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf)\n\n---\n\n<p align=\"center\">\n  <i>If you find this resource helpful, please give it a star ‚≠êÔ∏è and share it with others!</i>\n</p>\n",
      "stars_today": 38
    },
    {
      "id": 993475914,
      "name": "container",
      "full_name": "apple/container",
      "description": "A tool for creating and running Linux containers using lightweight virtual machines on a Mac. It is written in Swift, and optimized for Apple silicon. ",
      "html_url": "https://github.com/apple/container",
      "stars": 23497,
      "forks": 595,
      "language": "Swift",
      "topics": [],
      "created_at": "2025-05-30T21:26:05Z",
      "updated_at": "2026-01-22T23:03:28Z",
      "pushed_at": "2026-01-22T15:49:09Z",
      "open_issues": 238,
      "owner": {
        "login": "apple",
        "avatar_url": "https://avatars.githubusercontent.com/u/10639145?v=4"
      },
      "readme": "# `container`\n\n`container` is a tool that you can use to create and run Linux containers as lightweight virtual machines on your Mac. It's written in Swift, and optimized for Apple silicon.\n\nThe tool consumes and produces [OCI-compatible container images](https://github.com/opencontainers/image-spec), so you can pull and run images from any standard container registry. You can push images that you build to those registries as well, and run the images in any other OCI-compatible application.\n\n`container` uses the [Containerization](https://github.com/apple/containerization) Swift package for low level container, image, and process management.\n\n![introductory movie showing some basic commands](./docs/assets/landing-movie.gif)\n\n## Get started\n\n### Requirements\n\nYou need a Mac with Apple silicon to run `container`. To build it, see the [BUILDING](./BUILDING.md) document.\n\n`container` is supported on macOS 26, since it takes advantage of new features and enhancements to virtualization and networking in this release. We do not support older versions of macOS and the `container` maintainers typically will not address issues that cannot be reproduced on the macOS 26.\n\n### Install or upgrade\n\nIf you're upgrading, first stop and uninstall your existing `container` (the `-k` flag keeps your user data, while `-d` removes it):\n\n```bash\ncontainer system stop\n/usr/local/bin/uninstall-container.sh -k\n```\n\nDownload the latest signed installer package for `container` from the [GitHub release page](https://github.com/apple/container/releases).\n\nTo install the tool, double-click the package file and follow the instructions. Enter your administrator password when prompted, to give the installer permission to place the installed files under `/usr/local`.\n\nStart the system service with:\n\n```bash\ncontainer system start\n```\n\n### Uninstall\n\nUse the `uninstall-container.sh` script (installed to `/usr/local/bin`) to remove `container` from your system. To remove your user data along with the tool, run:\n\n```bash\n/usr/local/bin/uninstall-container.sh -d\n```\n\nTo retain your user data so that it is available should you reinstall later, run:\n\n```bash\n/usr/local/bin/uninstall-container.sh -k\n```\n\n## Next steps\n\n- Take [a guided tour of `container`](./docs/tutorial.md) by building, running, and publishing a simple web server image.\n- Learn how to [use various `container` features](./docs/how-to.md).\n- Read a brief description and [technical overview](./docs/technical-overview.md) of `container`.\n- Browse the [full command reference](./docs/command-reference.md).\n- [Build and run](./BUILDING.md) `container` on your own development system.\n- View the project [API documentation](https://apple.github.io/container/documentation/).\n\n## Contributing\n\nContributions to `container` are welcomed and encouraged. Please see our [main contributing guide](https://github.com/apple/containerization/blob/main/CONTRIBUTING.md) for more information.\n\n## Project Status\n\nThe container project is currently under active development. Its stability, both for consuming the project as a Swift package and the `container` tool, is only guaranteed within patch versions, such as between 0.1.1 and 0.1.2. Minor version number releases may include breaking changes until we achieve a 1.0.0 release.\n",
      "stars_today": 38
    },
    {
      "id": 628160489,
      "name": "SimpMusic",
      "full_name": "maxrave-dev/SimpMusic",
      "description": "A cross-platform music app using YouTube Music for backend",
      "html_url": "https://github.com/maxrave-dev/SimpMusic",
      "stars": 7250,
      "forks": 328,
      "language": "Kotlin",
      "topics": [
        "android",
        "android-16",
        "android-app",
        "android-application",
        "android-auto",
        "compose-multiplatform",
        "exoplayer",
        "kotlin",
        "linux",
        "macos",
        "media3",
        "mp3",
        "music",
        "spotify",
        "video-streaming",
        "windows",
        "youtube",
        "youtube-music"
      ],
      "created_at": "2023-04-15T04:53:33Z",
      "updated_at": "2026-01-23T01:38:45Z",
      "pushed_at": "2026-01-20T17:48:43Z",
      "open_issues": 356,
      "owner": {
        "login": "maxrave-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/113747128?v=4"
      },
      "readme": "<div align=\"center\"> <img src=\"https://raw.githubusercontent.com/maxrave-dev/SimpMusic/main/fastlane/metadata/android/en-US/images/featureGraphic.png\"> <h1>SimpMusic</h1>  \nA FOSS YouTube Music client for Android and Desktop with many features from<br>Spotify, SponsorBlock, ReturnYouTubeDislike using Compose Multiplatform to develop.\n<br> \n<br>\n<a href=\"https://github.com/maxrave-dev/SimpMusic/releases\"><img src=\"https://img.shields.io/github/v/release/maxrave-dev/SimpMusic\"></a> <a href=\"https://github.com/maxrave-dev/SimpMusic/releases\"><img src=\"https://img.shields.io/github/downloads/maxrave-dev/SimpMusic/total\"></a> <br> <br> <a href=\"https://trendshift.io/repositories/13482\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13482\" alt=\"maxrave-dev%2FSimpMusic | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n<br>\n<br>\n<a href=\"https://www.producthunt.com/products/simpmusic/reviews?utm_source=badge-product_rating&utm_medium=badge&utm_source=badge-simpmusic\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/product_rating.svg?product_id=903836&theme=dark\" alt=\"SimpMusic - A&#0032;FOSS&#0032;YouTube&#0032;Music&#0032;client&#0032;for&#0032;Android&#0032;with&#0032;many&#0032;features | Product Hunt\" style=\"width: 242px; height: 108px;\" width=\"242\" height=\"108\" /></a>\n<br> \n<h4>Download</h4>  \n<a href=\"https://apt.izzysoft.de/packages/com.maxrave.simpmusic/\"><img src=\"https://gitlab.com/IzzyOnDroid/repo/-/raw/master/assets/IzzyOnDroid.png\" width=\"200\"></a> \n<a href=\"https://f-droid.org/en/packages/com.maxrave.simpmusic/\"><img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" width=\"200\"></a> \n<a href=\"https://www.openapk.net/simpmusic/com.maxrave.simpmusic/\"><img src=\"https://www.openapk.net/images/openapk-badge.png\" width=\"200\"></a> \n<a href=\"https://github.com/maxrave-dev/SimpMusic/releases\"><img src=\"https://raw.githubusercontent.com/NeoApplications/Neo-Backup/034b226cea5c1b30eb4f6a6f313e4dadcbb0ece4/badge_github.png\" width=\"200\"></a> \n<h4>Nightly Build</h4>  \n<a href=\"https://simpmusic.org/nightly-download\"><img src=\"https://github.com/maxrave-dev/SimpMusic/actions/workflows/android.yml/badge.svg\"></a><br/> <a href=\"https://simpmusic.org/nightly-download\"><img src=\"https://raw.githubusercontent.com/NeoApplications/Neo-Backup/034b226cea5c1b30eb4f6a6f313e4dadcbb0ece4/badge_github.png\" width=\"200\"></a> \n</div>  \n\n> SimpMusic is available on Desktop now!\n  \n## Features ‚ú®Ô∏è    \n- Play music from YouTube Music or YouTube for free, without ads and in the background    \n- Browsing Home, Charts, Podcast, Moods & Genre with YouTube Music data at high speed    \n- Search everything on YouTube    \n- Analyze your playing data, create custom playlists, and sync with YouTube Music...    \n- Spotify Canvas supported    \n- Play 1080p video option with subtitle    \n- AI song suggestions    \n- Customize your playlist, synced with YouTube Music\n- Notifications from followed artists    \n- Caching and offline playback support    \n- Synced lyrics from SimpMusic Lyrics, LRCLIB, Spotify (require login) and YouTube Transcript - AI lyrics translation (BETA) (\\*)  \n- Personalize data (\\**) and multi-YouTube-account support    \n- Supports SponsorBlock and Return YouTube Dislike\n- Sleep Timer    \n- Android Auto with online content\n- Discord Rich Presence support\n- And many more!    \n  \n> (\\*) Use your OpenAI or Gemini API key    \n> (\\**) For users who chose \"Send back to Google\" feature    \n    \n> **Warning**    \n > This app is in the beta stage, so it may have many bugs and make it crash. If you find any bugs,      \n> please create an issue or contact me via email or Discord server.   \n> Because of depending on YouTube Music, the player error will happen and it's normally, please don't ask me about the stable state of this app.\n    \n## Screenshots    \n <p align=\"center\">          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/01.png?raw=true\" width=\"200\" />          \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/02.png?raw=true\" width=\"200\" />          \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/03.png?raw=true\" width=\"200\" />          \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/04.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/05.png?raw=true\" width=\"200\" />          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/17.png?raw=true\" width=\"200\" />  \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/07.png?raw=true\" width=\"200\" />          \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/08.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/09.png?raw=true\" width=\"200\" />          \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/10.png?raw=true\" width=\"200\" />         \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/11.png?raw=true\" width=\"200\" /> \n     <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/12.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">    \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/13.png?raw=true\" width=\"200\" />          \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/14.png?raw=true\" width=\"200\" />         \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/15.png?raw=true\" width=\"200\" /> \n     <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/16.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">  \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/06.png?raw=true\" width=\"800\" />  \n</p>\n\n #### More [screenshots](https://photos.app.goo.gl/AbieoXG5ctDrpwzp7) here.\n \n ## Data    \n- This app uses hidden API from YouTube Music with some tricks to get data from YouTube Music.    \n- Use Spotify Web API and some tricks to get Spotify Canvas and Lyrics    \n- Thanks to [InnerTune](https://github.com/z-huang/InnerTune/) for the idea to get data from YouTube Music. This repo is my inspiration to create this app.    \n- Special thanks to [SmartTube](https://github.com/yuliskov/SmartTube). This repo help me to extract the streaming URL of YouTube Music.    \n- My app is using [SponsorBlock](https://sponsor.ajay.app/) to skip sponsor in YouTube videos.    \n- ReturnYouTubeDislike for getting information on votes \n- Main lyrics data from SimpMusic Lyrics\n- Alternative lyrics data from LRCLIB. More information [LRCLIB](https://lrclib.net/)    \n \n ## Privacy    \n SimpMusic doesn't have any tracker or third-party server for collecting user data in FOSS version. If YouTube      \nlogged-in users enable \"Send back to Google\" feature, SimpMusic only uses YouTube Music Tracking API to send listening history and listening record of video to Google for better recommendations and      \nsupporting artist or YouTube Creator (For API reference,      \nsee [this](https://github.com/maxrave-dev/SimpMusic/blob/13f7ab6e5fa521b62a9fd31a1cefdc2787a1a8af/kotlinYtmusicScraper/src/main/java/com/maxrave/kotlinytmusicscraper/Ytmusic.kt#L639C4-L666C1)).\n\nWe collect crash data in the Full version to improve the app.\n   \n## Full or FOSS version\nI use [Sentry](http://sentry.io) crashlytics to catch all crashes in the Full version. [Sentry](https://github.com/getsentry/sentry) is the open-source project.\n If you don't want to be collected crash data, you must use FOSS version.\n \n## Desktop app\n\n### Before downloading the Desktop app, make sure your system installed 3 applications below:\n- [Gstreamer](https://gstreamer.freedesktop.org/download/): Required for playback audio.\n- [Yt-dlp](https://github.com/yt-dlp/yt-dlp): Required for getting streaming URL from YouTube (when using 256kps or higher quality).\n\n### Which file should I download?\n- For Windows: Download the file with extension `.msi`.\n- For macOS: Download the file with extension `.dmg`.\n- For Linux: Download the file with extension `.deb` (Debian based), `.rpm` (Red-hat based), `.AppImage` (all Linux distributions) .\n\n### Log in guide: https://www.simpmusic.org/blogs/en/how-to-log-in-on-desktop-app\n\n### Some limitations on Desktop app:\n- No offline playback support.\n- No video playback support.\n- Very buggy on some Linux distributions (because of Jetbrains not fix).\n\nPlease report issues on our Discord server if you find any bugs.\n \n## Translation    \n[![Crowdin](https://badges.crowdin.net/simpmusic/localized.svg)](https://crowdin.com/project/simpmusic)\n<br/>\nYou can help me translate this app into your language by using Crowdin [SimpMusic on Crowdin](https://crowdin.com/project/simpmusic)    \n #### Special thanks to all translators on Crowdin ‚ù§Ô∏è    \n ## FAQ    \n #### 1. Wrong Lyrics?    \n Lyrics are provided by LRCLIB and other sources. Sometimes lyrics may not match perfectly with YouTube\"      \nvideoId\" parameter. So I need to use some \"String Matcher\" and \"Duration\" for search lyrics. So      \nsometimes, some songs or videos get the wrong lyrics    \n    \n#### 2. Why the name or brand is \"SimpMusic\"?    \n Simply, because I love the name. It's a combination of 'Simple' and 'Music'. But SimpMusic is not a simple app, it's all you need for a powerful music streaming app.    \n  \n#### More FAQ, join [my Discord channel](https://discord.com/channels/1136988323819298856/1349800418745778196)  \n  ## Developer/Team    \n- [maxrave-dev](https://github.com/maxrave-dev/SimpMusic): Founder/Developer/Designer    \n- [Owen Connor](https://github.com/owencz1998): Discord Server Admin.    \n- [ilianoKokoro](https://github.com/ilianoKokoro): Discord Server Admin.\n- [CrazyWolf13](https://github.com/CrazyWolf13): Issues organizer/planner.\n\nWe're looking for more contributors, all contributions are welcome!\nSee our [CODE OF CONDUCT](https://github.com/maxrave-dev/SimpMusic/blob/main/CODE_OF_CONDUCT.md)\n\nThanks for all my contributors:\n\n<a href=\"https://github.com/maxrave-dev/SimpMusic/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=maxrave-dev/SimpMusic\" />\n</a>\n\n ## Showcase\nThis project is following clean architecture and MVVM pattern (in UI, app module).\n\n ### Dependencies graph\n  <p float=\"left\">        \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/dependencies_graph.svg?raw=true\" width=\"800\"> \n  </p>\n\n ## Support & Donations \n #### Special thanks to all supporter ‚ù§Ô∏è    \n <div align=\"left\"> \n <a href=\"https://simpmusic.org/\"><img alt=\"Visit the website\" height=\"50\" src=\"https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/documentation/website_vector.svg\"></a> &nbsp;        \n<a href=\"https://discord.gg/Rq5tWVM9Hg\"><img alt=\"Discord Server\" height=\"50\" src=\"https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/social/discord-plural_vector.svg\"></a> &nbsp;        \n<br> <a href=\"https://www.buymeacoffee.com/maxrave\"><img alt=\"Buy me a Coffee\" height=\"50\" src=\"https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/donate/buymeacoffee-singular_vector.svg\"></a> &nbsp;        \n<a href=\"https://liberapay.com/maxrave/\"><img alt=\"liberapay\" height=\"50\"        \nsrc=\"https://raw.githubusercontent.com/liberapay/liberapay.com/master/www/assets/liberapay/logo-v2_black-on-yellow.svg\"></a> \n</div>\n    \n ### MOMO or Vietnamese banking    \n <p float=\"left\">        \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/dev/asset/52770992.jpg?raw=true\" width=\"300\"> \n </p>\n\n## SimpMusic is sponsored by:\n<br />\n<a href=\"https://vercel.com/oss\">\n  <img alt=\"Vercel OSS Program\" src=\"https://vercel.com/oss/program-badge.svg\" />\n</a>\n<br />\n<br />\n<a href=\"https://www.digitalocean.com/?refcode=d7f6eedfb9a9&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=badge\"><img src=\"https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%201.svg\" width=\"300\" alt=\"DigitalOcean Referral Badge\" /></a>\n<br>\n<br>\n<a href=\"https://crowdin.com\">\n<img src=\"https://support.crowdin.com/assets/logos/plate/png/crowdin-logo-with-plate.png\" width=\"300\"/>\n</a>\n<br>\n<a href=\"https://sentry.io\">\n<img src=\"https://github.com/maxrave-dev/SimpMusic/blob/dev/asset/sentry.svg?raw=true\" width=\"300\"/>\n</a>\n<br>\n<br>\n\nGet a free $200 credit over 60 days on DigitalOcean: [GET NOW](https://www.digitalocean.com/?refcode=d7f6eedfb9a9&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=badge)\n\nCrowdin and Sentry both have a free enterprise plan for Open-source projects. Follow the URLs: \n- [Open Source License Request Form | Crowdin](https://crowdin.com/page/open-source-project-setup-request)\n- [Sentry for Open Source | Sentry](https://sentry.io/for/open-source/)\n\nCheck out the Vercel open-source program:\n- https://vercel.com/open-source-program\n\n*This project is a part of SimpMusic.org Open-source project by me [maxrave-dev](https://github.com/maxrave-dev)*\n",
      "stars_today": 36
    },
    {
      "id": 593867048,
      "name": "xpipe",
      "full_name": "xpipe-io/xpipe",
      "description": "Access your entire server infrastructure from your local desktop",
      "html_url": "https://github.com/xpipe-io/xpipe",
      "stars": 13565,
      "forks": 522,
      "language": "Java",
      "topics": [
        "bash",
        "docker",
        "filemanager",
        "files",
        "incus",
        "java",
        "javafx",
        "k8s",
        "kubernetes",
        "lxd",
        "networking",
        "podman",
        "sftp",
        "ssh",
        "tailscale",
        "wsl"
      ],
      "created_at": "2023-01-27T02:25:38Z",
      "updated_at": "2026-01-23T02:04:18Z",
      "pushed_at": "2026-01-22T15:33:27Z",
      "open_issues": 48,
      "owner": {
        "login": "xpipe-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/93734037?v=4"
      },
      "readme": "<p align=\"center\">\n    <a href=\"https://xpipe.io\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/img/banner.png\" alt=\"XPipe Banner\" />\n    </a>\n</p>\n\n<h1></h1>\n\n## About\n\nXPipe is a connection hub that allows you to access your entire server infrastructure from your local desktop. It works on top of your installed command-line programs like SSH, docker, or others, and does not require any setup on your remote systems. It integrates with your favourite text editors, terminals, shells, VNC/RDP clients, password managers, and command-line tools. The platform is designed to be extensible, allowing anyone to add easily support for more tools or to implement custom functionality through a modular extension system.\n\nIt currently supports:\n\n- [SSH](https://docs.xpipe.io/guide/ssh) connections, config files, and tunnels\n- [Docker](https://docs.xpipe.io/guide/docker) + compose, [Podman](https://docs.xpipe.io/guide/podman), [LXD](https://docs.xpipe.io/guide/lxc), and [incus](https://docs.xpipe.io/guide/lxc) containers\n- [Proxmox PVE](https://docs.xpipe.io/guide/proxmox), [Hyper-V](https://docs.xpipe.io/guide/hyperv), [KVM](https://docs.xpipe.io/guide/kvm), and [VMware Player/Workstation/Fusion](https://docs.xpipe.io/guide/vmware) virtual machines\n- [Tailscale](https://docs.xpipe.io/guide/tailscale), [Netbird](https://docs.xpipe.io/guide/netbird), and [Teleport](https://docs.xpipe.io/guide/teleport) connections\n- [AWS](https://docs.xpipe.io/guide/aws) and [Hetzner Cloud](https://docs.xpipe.io/guide/hcloud) servers\n- [RDP](https://docs.xpipe.io/guide/rdp) and [VNC](https://docs.xpipe.io/guide/vnc) connections\n- Windows Subsystem for Linux, Cygwin, and MSYS2 environments\n- [Kubernetes](https://docs.xpipe.io/guide/kubernetes) clusters, pods, and containers\n- [Powershell Remote Sessions](https://docs.xpipe.io/guide/pssession)\n\n---\n\n<div align=\"center\">\n    <a href=\"https://docs.xpipe.io/guide/ssh\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/ssh.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/docker\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/docker.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/docker#compose\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/compose.png\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/lxc\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/lxd.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/podman\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/podman.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/aws\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/aws.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/kubernetes\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/k8s.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/proxmox\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/proxmox.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/vmware\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/vmware.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/kvm\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/virsh.png\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/tailscale\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/tailscale.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/netbird\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/netbird.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/hcloud\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/hetzner.svg\" width=40 height=40 />\n    </a>\n    <a href=\"#\"><img width=10 /></a>\n    <a href=\"https://docs.xpipe.io/guide/teleport\" target=\"_blank\" rel=\"noopener\">\n        <img src=\"https://github.com/xpipe-io/.github/raw/main/icons/teleport.png\" width=40 height=40 />\n    </a>\n</div>\n\n## Connection hub\n\n- Easily establish and manage connections to remote systems from a central hub interface\n- Organize all your connections in hierarchical categories to maintain an overview over hundreds of connections.\n- Create custom shell login environments to instantly jump into a properly set up shell for every use case\n- Quickly perform various commonly used actions like starting/stopping systems, establishing tunnels, and more\n- Create desktop shortcuts and macros that automatically open remote connections in your terminal without having to open any GUI\n\n![Connection hub](https://github.com/xpipe-io/.github/raw/main/img/hub_shadow.png)\n\n## File browser\n\n- Interact with the file system of any remote system using a workflow optimized for professionals\n- Utilize your entire arsenal of locally installed programs to open and edit remote files\n- Dynamically elevate sessions with sudo when required without having to restart the session\n- Seamlessly transfer files from and to your system desktop environment\n- Work and perform transfers on multiple systems at the same time with the built-in tabbed multitasking\n- Quickly open a terminal session into any directory in your favourite terminal emulator\n- Customize every action through the scripting system\n\n![Browser](https://github.com/xpipe-io/.github/raw/main/img/browser_shadow.png)\n\n## Terminal launcher\n\n- Launches you into a shell session in your favourite terminal with one click. Automatically fills password prompts and more\n- Comes with support for all commonly used terminal emulators across all operating systems\n- Supports opening custom terminal emulators as well via a custom command-line spec\n- Works with all command shells such as bash, zsh, fish, cmd, PowerShell, and more, locally and remote\n- Integrates with multiplexers like tmux and zellij, plus prompts like starship and oh-my-zsh\n- Supports opening multiple sessions in split terminal pane views\n- Connects to a system while the terminal is still starting up, allowing for faster connections than otherwise possible\n\n![Terminal](https://github.com/xpipe-io/.github/raw/main/img/terminal_shadow.png)\n\n## Versatile scripting system\n\n- Create reusable simple shell scripts, templates, and groups to run on connected remote systems\n- Automatically make your scripts available in the PATH on any remote system without any setup\n- Setup shell init environments for connections to fully customize your work environment for every purpose\n- Open custom shells and custom remote connections by providing your own commands\n- Use custom scripts in the file browser \n\n![scripts](https://github.com/xpipe-io/.github/raw/main/img/scripts_shadow.png)\n\n## And much more\n\n- You can synchronize your vault across multiple systems and share it with other team members via your own self-hosted git repository\n- All data is stored exclusively on your systems in a cryptographically secure vault. You can also choose to increase security by using a custom master passphrase for further encryption\n- XPipe is able to retrieve secrets automatically from your installed password manager and doesn't have store secrets itself\n- There are no servers involved, all your information stays on your systems. The XPipe application does not send any personal or sensitive information to outside services\n- XPipe has an integrated MCP server that you can enable. This allows you to easily use all of XPipe's features from an AI agent\n- Run coherent desktop applications remotely via the uniform desktop application system in XPipe for RDP, VNC, and X11 forwards\n- Securely tunnel and automatically open remote services with one click with the services integration\n\n# Downloads\n\nNote that this is a desktop application that should be run on your local desktop workstation, not on any server or containers. It will be able to connect to your server infrastructure from there.\n\nFor a full reference and instructions, see the [installation docs](https://docs.xpipe.io/guide/installation) and [managed installation docs](https://docs.xpipe.io/guide/managed-installation).\n\n## Windows\n\nInstallers are the easiest way to get started and come with an optional automatic update functionality:\n\n- [Windows .msi Installer (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-windows-x86_64.msi)\n- [Windows .msi Installer (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-windows-arm64.msi)\n\nIf you don't like installers, you can also use a portable version that is packaged as an archive:\n\n- [Windows .zip Portable (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-windows-x86_64.zip)\n- [Windows .zip Portable (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-windows-arm64.zip)\n\nAlternatively, you can also use the following package managers:\n- [choco](https://community.chocolatey.org/packages/xpipe) to install it with `choco install xpipe`.\n- [winget](https://github.com/microsoft/winget-cli) to install it with `winget install xpipe-io.xpipe --source winget`.\n- [scoop](https://github.com/microsoft/winget-cli) to install it with `scoop install extras/xpipe`.\n\n## macOS\n\nInstallers are the easiest way to get started and come with an optional automatic update functionality:\n\n- [MacOS .pkg Installer (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-macos-x86_64.pkg)\n- [MacOS .pkg Installer (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-macos-arm64.pkg)\n\nIf you don't like installers, you can also use a portable version that is packaged as an archive:\n\n- [MacOS .dmg Portable (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-macos-x86_64.dmg)\n- [MacOS .dmg Portable (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-macos-arm64.dmg)\n\nAlternatively, you can also use [Homebrew](https://github.com/xpipe-io/homebrew-tap) to install XPipe with `brew install --cask xpipe-io/tap/xpipe`.\n\n## Linux\n\nYou can install XPipe the fastest by pasting the installation command into your terminal. This will perform the setup automatically.\nThe script supports installation via `apt`, `dnf`, `yum`, `zypper`, `rpm`, and `pacman` on Linux:\n\n```\nbash <(curl -sL https://github.com/xpipe-io/xpipe/raw/master/get-xpipe.sh)\n```\n\nOf course, there are also other installation methods available.\n\n### Debian-based distros\n\nThe following debian installers are available:\n\n- [Linux .deb Installer (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-x86_64.deb)\n- [Linux .deb Installer (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-arm64.deb)\n\nNote that you should use apt to install the package with `sudo apt install <file>` as other package managers, for example dpkg,\nare not able to resolve and install any dependency packages.\n\n### RHEL-based distros\n\nThe rpm releases are signed with the GPG key https://xpipe.io/signatures/crschnick.asc.\nYou can import it via `rpm --import https://xpipe.io/signatures/crschnick.asc` to allow your rpm-based package manager to verify the release signature. \n\nThe following rpm installers are available:\n\n- [Linux .rpm Installer (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-x86_64.rpm)\n- [Linux .rpm Installer (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-installer-linux-arm64.rpm)\n\n### Arch\n\nThere is an official [AUR package](https://aur.archlinux.org/packages/xpipe) available that you can either install manually or via an AUR helper such as with `yay -S xpipe`.\n\n### AppImages\n\nAlternatively, there are also AppImages available. These can be useful if you are using an immutable distro.\n\n- [Linux .AppImage Portable (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-x86_64.AppImage)\n- [Linux .AppImage Portable (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-arm64.AppImage)\n\n### NixOS\n\nThere's an official [xpipe nixpkg](https://search.nixos.org/packages?channel=unstable&show=xpipe&from=0&size=50&sort=relevance&type=packages&query=xpipe) available that you can install with `nix-env -iA nixos.xpipe` on x86_64 Linux systems. This package is however usually not up to date.\n\nThere is also a custom repository that contains the latest up-to-date release flakes for Linux and macOS systems: https://github.com/xpipe-io/nixpkg.\n\n### Tarball\n\nIn case you prefer to use an archive version that you can extract anywhere, you can use these:\n\n- [Linux .tar.gz Portable (x86-64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-x86_64.tar.gz)\n- [Linux .tar.gz Portable (ARM 64)](https://github.com/xpipe-io/xpipe/releases/latest/download/xpipe-portable-linux-arm64.tar.gz)\n\n### Docker container\n\nXPipe is a desktop application first and foremost. It requires a full desktop environment to function with various installed applications such as terminals, editors, shells, CLI tools, and more. So there is no true web-based interface for XPipe.\n\nSince it might make sense however to access your XPipe environment from the web, there is also a so-called webtop docker container image for XPipe. [XPipe Webtop](https://github.com/xpipe-io/xpipe-webtop) is a web-based desktop environment that can be run in a container and accessed from a browser via KasmVNC. The desktop environment comes with XPipe and various terminals and editors preinstalled and configured. This image is also available for Kasm Workspaces in the [XPipe Kasm Registry](https://github.com/xpipe-io/kasm-registry).\n\n# Further information\n\n## Contributing\n\nSee [CONTRIBUTING.md](/CONTRIBUTING.md) for details.\n\n<img src=\"https://contrib.rocks/image?repo=xpipe-io/xpipe\" alt=\"contrib.rocks image\" />\n\n## Open source model\n\nXPipe follows an open core model, which essentially means that the main application is open source while certain other components are not. This mainly concerns the features only available in the homelab/professional plan and the shell handling library implementation. Furthermore, some CI pipelines and tests that run on private servers are also not included in the open repository.\n\nThe distributed XPipe application consists out of two parts:\n- The open-source core that you can find this repository. It is licensed under the [Apache License 2.0](/LICENSE.md).\n- The closed-source extensions, mostly for homelab/professional plan features, which are not included in this repository\n\nAdditional features are available in the homelab/professional plan. For more details see https://xpipe.io/pricing.\nIf your enterprise puts great emphasis on having access to the full source code, there are also full source-available enterprise options available.\n\n## Documentation\n\nYou can find the documentation at https://docs.xpipe.io.\n\n## Discord\n\n[![Discord](https://discordapp.com/api/guilds/979695018782646285/widget.png?style=banner2)](https://discord.gg/8y89vS8cRb)\n",
      "stars_today": 34
    },
    {
      "id": 863717537,
      "name": "librepods",
      "full_name": "kavishdevar/librepods",
      "description": "AirPods liberated from Apple's ecosystem.",
      "html_url": "https://github.com/kavishdevar/librepods",
      "stars": 24689,
      "forks": 1300,
      "language": "Kotlin",
      "topics": [
        "accessiblity",
        "airpods",
        "android",
        "battery-monitor",
        "conversational-awareness",
        "ear-detection",
        "hearing-aid",
        "hearing-aids",
        "linux",
        "reverse-engineering"
      ],
      "created_at": "2024-09-26T19:31:11Z",
      "updated_at": "2026-01-23T01:02:33Z",
      "pushed_at": "2025-12-29T12:51:41Z",
      "open_issues": 118,
      "owner": {
        "login": "kavishdevar",
        "avatar_url": "https://avatars.githubusercontent.com/u/46088622?v=4"
      },
      "readme": ">[!IMPORTANT]\nDevelopment paused due to lack of time until 17th May 2026 (JEE Advanced). PRs and issues might not be responded to until then.\n\n![LibrePods Banner](./imgs/banner.png)\n\n## What is LibrePods?\n\nLibrePods unlocks Apple's exclusive AirPods features on non-Apple devices. Get access to noise control modes, adaptive transparency, ear detection, hearing aid, customized transparency mode, battery status, and more - all the premium features you paid for but Apple locked to their ecosystem.\n\n## Device Compatibility\n\n| Status | Device                | Features                                                   |\n| ------ | --------------------- | ---------------------------------------------------------- |\n| ‚úÖ      | AirPods Pro (2nd Gen) | Fully supported and tested                                 |\n| ‚úÖ      | AirPods Pro (3rd Gen) | Fully supported (except heartrate monitoring)              |\n| ‚úÖ      | AirPods Max           | Fully supported (client shows unsupported features)        |\n| ‚ö†Ô∏è      | Other AirPods models  | Basic features (battery status, ear detection) should work |\n\nMost features should work with any AirPods. Currently, I've only got AirPods Pro 2 to test with. But, I believe the protocol remains the same for all other AirPods (based on analysis of the bluetooth stack on macOS).\n\n## Key Features\n\n- **Noise Control Modes**: Easily switch between noise control modes without having to reach out to your AirPods to long press\n- **Ear Detection**: Controls your music automatically when you put your AirPods in or take them out, and switch to phone speaker when you take them out\n- **Battery Status**: Accurate battery levels\n- **Head Gestures**: Answer calls just by nodding your head\n- **Conversational Awareness**: Volume automatically lowers when you speak\n- **Hearing Aid\\***\n- **Customize Transparency Mode\\***\n- **Multi-device connectivity\\*** (upto 2 devices)\n- **Other customizations**:\n  - Rename your AirPods\n  - Customize long-press actions\n  - All accessibility settings\n  - And more!\n\n&ast; Features marked with an asterisk require the VendorID to be change to that of Apple.\n\n## Platform Support\n\n### Linux\nfor the old version see the [Linux README](./linux/README.md). (doesn't have many features, maintainer didn't have time to work on it)\n\nnew version in development ([#241](https://github.com/kavishdevar/librepods/pull/241))\n\n![new version](https://github.com/user-attachments/assets/86b3c871-89a8-4e49-861a-5119de1e1d28)\n\n### Android\n\n#### Screenshots\n\n|                                                                                         |                                                    |                                                                              |\n| --------------------------------------------------------------------------------------- | -------------------------------------------------- | ---------------------------------------------------------------------------- |\n| ![Settings 1](./android/imgs/settings-1.png)                                            | ![Settings 2](./android/imgs/settings-2.png)       | ![Debug Screen](./android/imgs/debug.png)                                    |\n| ![Battery Notification and QS Tile for NC Mode](./android/imgs/notification-and-qs.png) | ![Popup](./android/imgs/popup.png)                 | ![Head Tracking and Gestures](./android/imgs/head-tracking-and-gestures.png) |\n| ![Long Press Configuration](./android/imgs/long-press.png)                              | ![Widget](./android/imgs/widget.png)               | ![Customizations 1](./android/imgs/customizations-1.png)                     |\n| ![Customizations 2](./android/imgs/customizations-2.png)                                | ![accessibility](./android/imgs/accessibility.png) | ![transparency](./android/imgs/transparency.png)                             |\n| ![hearing-aid](./android/imgs/hearing-aid.png)                                          | ![hearing-test](./android/imgs/hearing-test.png)   | ![hearing-aid-adjustments](./android/imgs/hearing-aid-adjustments.png)       |\n\n\nhere's a very unprofessional demo video\n\nhttps://github.com/user-attachments/assets/43911243-0576-4093-8c55-89c1db5ea533\n\n#### Root Requirement\n\nIf you are using ColorOS/OxygenOS 16, you don't need root except for customizing transparency mode, setting up hearing aid, and use Bluetooth Multipoint. Changing ANC, conversational awareness, ear detection, and other customizations will work without root. For everyone else:\n\n> [!CAUTION]\n> **You must have a rooted device with Xposed to use LibrePods on Android.** This is due to a [bug in the Android Bluetooth stack](https://issuetracker.google.com/issues/371713238). Please upvote the issue by clicking the '+1' icon on the IssueTracker page. DO NOT leave a +1 comment - use the +1 button in the top right of the page next to the \"Hotlists\" field.  Leaving +1 comment spam makes it impossible for developers to engage in the necessary technical discussion to implement this fix, and will disincentivize the responsible Google developers from engaging.  I don't know a fix for Android versions <13 either. So, this needs a phone running A13+.\n> \n> There are **no exceptions** to the root requirement until Google/your OEM figures out a fix.\n\nUntil then, you must xposed. I used to provide a non-xposed method too, where the module used overlayfs to replace the bluetooth library with a locally patched one, but that was broken due to how various devices handled overlayfs and a patched library. With xposed, you can also enable the DID hook enabling a few extra features.\n\n## Changing VendorID in the DID profile to that of Apple\n\nTurns out, if you change the VendorID in DID Profile to that of Apple, you get access to several special features!\n\nYou can do this on Linux by editing the DeviceID in `/etc/bluetooth/main.conf`. Add this line to the config file `DeviceID = bluetooth:004C:0000:0000`. For android you can enable the `act as Apple device` setting in the app's settings.\n\n### Multi-device Connectivity\n\nUpto two devices can be simultaneously connected to AirPods, for audio and control both. Seamless connection switching. The same notification shows up on Apple device when Android takes over the AirPods as if it were an Apple device (\"Move to iPhone\"). Android also shows a popup when the other device takes over.\n\n### Accessibility Settings and Hearing Aid\n\nAccessibility settings like customizing transparency mode (amplification, balance, tone, conversation boost, and ambient noise reduction), and loud sound reduction can be configured.\n\nAll hearing aid customizations can be done from Android (linux soon), including setting the audiogram result. The app doesn't provide a way to take a hearing test because it requires much more precision. It is much better to use an already available audiogram result. \n\n#### A few notes\n\n- Due to recent AirPods' firmware upgrades, you must enable `Off listening mode` to switch to `Off`. This is because in this mode, loud sounds are not reduced.\n\n- If you have take both AirPods out, the app will automatically switch to the phone speaker. But, Android might keep on trying to connect to the AirPods because the phone is still connected to them, just the A2DP profile is not connected. The app tries to disconnect the A2DP profile as soon as it detects that Android has connected again if they're not in the ear.\n\n- When renaming your AirPods through the app, you'll need to re-pair them with your phone for the name change to take effect. This is a limitation of how Bluetooth device naming works on Android.\n\n- If you want the AirPods icon and battery status to show in Android Settings app, install the app as a system app by using the root module.\n\n## Supporters\n\nA huge thank you to everyone supporting the project!\n- @davdroman\n- @tedsalmon\n- @wiless\n- @SmartMsg\n- @lunaroyster\n- @ressiwage\n\n## Special thanks\n- @tyalie for making the first documentation on the protocol! ([tyalie/AAP-Protocol-Definition](https://github.com/tyalie/AAP-Protocol-Defintion))\n- @rithvikvibhu and folks over at lagrangepoint for helping with the hearing aid feature ([gist](https://gist.github.com/rithvikvibhu/45e24bbe5ade30125f152383daf07016))\n- @devnoname120 for helping with the first root patch\n- @timgromeyer for making the first version of the linux app\n- @hackclub for hosting [High Seas](https://highseas.hackclub.com) and [Low Skies](https://low-skies.hackclub.com)!\n\n## Star History\n\n<a href=\"https://www.star-history.com/#kavishdevar/librepods&type=date&legend=top-left\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=kavishdevar/librepods&type=date&theme=dark&legend=top-left\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=kavishdevar/librepods&type=date&legend=top-left\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=kavishdevar/librepods&type=date&legend=top-left\" />\n </picture>\n</a>\n\n# License\n\nLibrePods - AirPods liberated from Apple‚Äôs ecosystem\nCopyright (C) 2025 LibrePods contributors\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\nany later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nAll trademarks, logos, and brand names are the property of their respective owners. Use of them does not imply any affiliation with or endorsement by them. All AirPods images, symbols, and the SF Pro font are the property of Apple Inc.\n",
      "stars_today": 32
    },
    {
      "id": 120425779,
      "name": "lapce",
      "full_name": "lapce/lapce",
      "description": "Lightning-fast and Powerful Code Editor written in Rust",
      "html_url": "https://github.com/lapce/lapce",
      "stars": 37946,
      "forks": 1223,
      "language": "Rust",
      "topics": [
        "code-editor",
        "developer-tools",
        "rust",
        "text-editor",
        "vim"
      ],
      "created_at": "2018-02-06T08:41:06Z",
      "updated_at": "2026-01-23T01:49:17Z",
      "pushed_at": "2026-01-23T00:49:24Z",
      "open_issues": 870,
      "owner": {
        "login": "lapce",
        "avatar_url": "https://avatars.githubusercontent.com/u/43668847?v=4"
      },
      "readme": "<h1 align=\"center\">\n  <a href=\"https://lapce.dev\" target=\"_blank\">\n  <img src=\"extra/images/logo.png\" width=200 height=200/><br>\n  Lapce\n  </a>\n</h1>\n\n<h4 align=\"center\">Lightning-fast And Powerful Code Editor</h4>\n\n<div align=\"center\">\n  <a href=\"https://github.com/lapce/lapce/actions/workflows/ci.yml\" target=\"_blank\">\n    <img src=\"https://github.com/lapce/lapce/actions/workflows/ci.yml/badge.svg\" />\n  </a>\n  <a href=\"https://discord.gg/n8tGJ6Rn6D\" target=\"_blank\">\n    <img src=\"https://img.shields.io/discord/946858761413328946?logo=discord\" />\n  </a>\n  <a href=\"https://docs.lapce.dev\" target=\"_blank\">\n      <img src=\"https://img.shields.io/static/v1?label=Docs&message=docs.lapce.dev&color=blue\" alt=\"Lapce Docs\">\n  </a>\n</div>\n<br/>\n\n\nLapce (IPA: /l√¶ps/) is written in pure Rust, with a UI in [Floem](https://github.com/lapce/floem). It is designed with [Rope Science](https://xi-editor.io/docs/rope_science_00.html) from the [Xi-Editor](https://github.com/xi-editor/xi-editor), enabling lightning-fast computation, and leverages [wgpu](https://github.com/gfx-rs/wgpu) for rendering. More information about the features of Lapce can be found on the [main website](https://lapce.dev) and user documentation can be found on [GitBook](https://docs.lapce.dev/).\n\n![](https://github.com/lapce/lapce/blob/master/extra/images/screenshot.png?raw=true)\n\n## Features\n\n* Built-in LSP ([Language Server Protocol](https://microsoft.github.io/language-server-protocol/)) support to give you intelligent code features such as: completion, diagnostics and code actions\n* Modal editing support as first class citizen (Vim-like, and toggleable)\n* Built-in remote development support inspired by [VSCode Remote Development](https://code.visualstudio.com/docs/remote/remote-overview). Enjoy the benefits of a \"local\" experience, and seamlessly gain the full power of a remote system. We also have [Lapdev](https://lap.dev/) which can help manage your remote dev environments. \n* Plugins can be written in programming languages that can compile to the [WASI](https://wasi.dev/) format (C, Rust, [AssemblyScript](https://www.assemblyscript.org/))\n* Built-in terminal, so you can execute commands in your workspace, without leaving Lapce.\n\n## Installation\n\nYou can find pre-built releases for Windows, Linux and macOS [here](https://github.com/lapce/lapce/releases), or [installing with a package manager](docs/installing-with-package-manager.md).\nIf you'd like to compile from source, you can find the [guide](docs/building-from-source.md).\n\n## Contributing\n\n<a href=\"https://ws.lap.dev/#https://github.com/lapce/lapce\" target=\"_blank\">\n      <img src=\"https://lap.dev/images/open-in-lapdev.svg?version=8\" alt=\"Open in Lapdev\">\n</a>\n\n[Lapdev](https://lap.dev/), developed by the Lapce team, is a cloud dev env service similar to GitHub Codespaces. By clicking the button above, you'll be taken to a fully set up Lapce dev env where you can browse the code and start developing. All dependencies are pre-installed, so you can get straight to code.\n\nGuidelines for contributing to Lapce can be found in [`CONTRIBUTING.md`](CONTRIBUTING.md).\n\n## Feedback & Contact\n\nThe most popular place for Lapce developers and users is on the [Discord server](https://discord.gg/n8tGJ6Rn6D).\n\nOr, join the discussion on [Reddit](https://www.reddit.com/r/lapce/) where we are just getting started.\n\nThere is also a [Matrix Space](https://matrix.to/#/#lapce-editor:matrix.org), which is linked to the content from the Discord server.\n\n## License\n\nLapce is released under the Apache License Version 2, which is an open source license. You may contribute to this project, or use the code as you please as long as you adhere to its conditions. You can find a copy of the license text here: [`LICENSE`](LICENSE).\n",
      "stars_today": 31
    },
    {
      "id": 745612559,
      "name": "BPB-Worker-Panel",
      "full_name": "bia-pain-bache/BPB-Worker-Panel",
      "description": "A GUI Panel providing Worker subscriptions for VLESS, Trojan and Warp configs alongside chain proxies, offering full DNS, clean IP,  Fragment, Warp, Warp pro and routing settings for cross-platform clients using Amnezia, Wireguard, Sing-box, Clash/Mihomo and Xray cores.",
      "html_url": "https://github.com/bia-pain-bache/BPB-Worker-Panel",
      "stars": 9460,
      "forks": 31503,
      "language": "TypeScript",
      "topics": [
        "amnezia",
        "android",
        "chain",
        "clash-core",
        "fragment",
        "ios",
        "linux",
        "mihomo",
        "proxy-chain",
        "singbox-core",
        "trojan",
        "vless",
        "warp",
        "windows",
        "xray-core"
      ],
      "created_at": "2024-01-19T17:58:28Z",
      "updated_at": "2026-01-22T20:13:59Z",
      "pushed_at": "2026-01-08T11:33:28Z",
      "open_issues": 7,
      "owner": {
        "login": "bia-pain-bache",
        "avatar_url": "https://avatars.githubusercontent.com/u/155004885?v=4"
      },
      "readme": "<h1 align=\"center\">BPB Panel</h1>\n\n### üåè Readme in [Farsi](README_fa.md)\n\n<p align=\"center\">\n  <img src=\"docs/assets/images/panel-overview.jpg\">\n</p>\n<br>\n\n## Introduction\n\nThis project is aimed to provide a user panel to access FREE, SECURE and PRIVATE **VLESS**, **Trojan** and **Warp** configs, It ensures connectivity even when domains or Warp services are blocked by ISPs, offering two deployment options:\n\n- **Workers** deployment\n- **Pages** deployment\n\nüåü If you found **BPB Panel** valuable, Your donations make all the difference üåü\n\n### USDT (BEP20)\n\n```text\n0xbdf15d41C56f861f25b2b11C835bd45dfD5b792F\n```\n\n## Features\n\n1. **Free and Private**: No costs involved and the server is private.\n2. **Intuitive Panel:** Streamlined for effortless navigation, configuration and use.\n3. **Versatile Protocols:** Provides VLESS, Trojan and Wireguard (Warp) protocols.\n4. **Warp Pro configs:** Optimized Warp for crucial circumstances.\n5. **Fragment support:** Supports Fragment functionality for crucial network situations.\n6. **Comprehensive Routing Rules:** Bypassing Iran/China/Russia, Blocking QUIC, Porn, Ads, Malwares, Phishing and also bypassing sanctions.\n7. **Chain Proxy:** Capable of adding a chain proxy (VLESS, Trojan, Shadowsocks, socks and http) to fix IP.\n8. **Broad client compatibility:** Offers subscription links for Xray, Sing-box and Clash-Mihomo core clients.\n9. **Password-protected panel:** Provides secure and private panel with password protection.\n10. **Fully customizable:** Supports setting up clean IP-domains, Proxy IPs, DNS servers, choosing ports and protocols, Warp endpoints and more.\n\n## Limitations\n\n1. **UDP transport**: VLESS and Trojan protocols on workers do not handle **UDP** properly, so it is disabled by default (affecting features like Telegram video calls), UDP DNS is also unsupported. DoH is enabled by default for enhanced security.\n2. **Request limit**: each worker supports 100K requests per day for VLESS and Trojan, suitable for 2-3 users. You can use limitless Warp configs.\n\n## Getting started\n\n- [Installation methods](https://bia-pain-bache.github.io/BPB-Worker-Panel/installation/wizard/)\n- [Configuration](https://bia-pain-bache.github.io/BPB-Worker-Panel/configuration/)\n- [How to use](https://bia-pain-bache.github.io/BPB-Worker-Panel/usage/)\n- [FAQ](https://bia-pain-bache.github.io/BPB-Worker-Panel/faq/)\n\n## Supported Clients\n\n|       Client        |      Version      |  Fragment support  |  Warp Pro support  |\n| :-----------------: | :---------------: | :----------------: | :----------------: |\n|     **v2rayNG**     | 1.10.26 or higher | :heavy_check_mark: | :heavy_check_mark: |\n|     **MahsaNG**     |   14 or higher    | :heavy_check_mark: | :heavy_check_mark: |\n|     **v2rayN**      | 7.15.4 or higher  | :heavy_check_mark: | :heavy_check_mark: |\n|   **v2rayN-PRO**    |   1.9 or higher   | :heavy_check_mark: | :heavy_check_mark: |\n|    **Sing-box**     | 1.12.0 or higher  | :heavy_check_mark: |        :x:         |\n|    **Streisand**    | 1.6.64 or higher  | :heavy_check_mark: | :heavy_check_mark: |\n|   **Clash Meta**    |                   |        :x:         | :heavy_check_mark: |\n| **Clash Verge Rev** |                   |        :x:         | :heavy_check_mark: |\n|     **FLClash**     |                   |        :x:         | :heavy_check_mark: |\n|   **AmneziaVPN**    |                   |        :x:         | :heavy_check_mark: |\n|    **WG Tunnel**    |                   |        :x:         | :heavy_check_mark: |\n\n## Environment variables\n\n|   Variable   |               Usage                |     Mandatory      |\n| :----------: | :--------------------------------: | :----------------: |\n|   **UUID**   |             VLESS UUID             | :heavy_check_mark: |\n| **TR_PASS**  |          Trojan Password           | :heavy_check_mark: |\n| **PROXY_IP** | Proxy IP or domain (VLESS, Trojan) |        :x:         |\n|  **PREFIX**  |   NAT64 Prefixes (VLESS, Trojan)   |        :x:         |\n| **SUB_PATH** |         Subscriptions' URI         |        :x:         |\n| **FALLBACK** |  Fallback domain (VLESS, Trojan)   |        :x:         |\n| **DOH_URL**  |              Core DOH              |        :x:         |\n\n---\n\n## Stargazers Over Time\n\n[![Stargazers Over Time](https://starchart.cc/bia-pain-bache/BPB-Worker-Panel.svg?variant=adaptive)](https://starchart.cc/bia-pain-bache/BPB-Worker-Panel)\n\n---\n\n### Special Thanks\n\n- VLESS, Trojan [Cloudflare-workers/pages proxy script](https://github.com/yonggekkk/Cloudflare-workers-pages-vless) created by [yonggekkk](https://github.com/yonggekkk)\n- CF-vless code author [3Kmfi6HP](https://github.com/3Kmfi6HP/EDtunnel)\n- CF preferred IP program author [badafans](https://github.com/badafans/Cloudflare-IP-SpeedTest), [XIU2](https://github.com/XIU2/CloudflareSpeedTest)\n",
      "stars_today": 30
    },
    {
      "id": 936473202,
      "name": "FlashMLA",
      "full_name": "deepseek-ai/FlashMLA",
      "description": "FlashMLA: Efficient Multi-head Latent Attention Kernels",
      "html_url": "https://github.com/deepseek-ai/FlashMLA",
      "stars": 12161,
      "forks": 952,
      "language": "C++",
      "topics": [],
      "created_at": "2025-02-21T06:31:27Z",
      "updated_at": "2026-01-23T02:11:10Z",
      "pushed_at": "2026-01-20T16:05:02Z",
      "open_issues": 83,
      "owner": {
        "login": "deepseek-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/148330874?v=4"
      },
      "readme": "# FlashMLA\n\n## Introduction\n\nFlashMLA is DeepSeek's library of optimized attention kernels, powering the [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) and [DeepSeek-V3.2-Exp](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp) models. This repository contains the following implementations:\n\n**Sparse Attention Kernels**\n\n*These kernels power DeepSeek Sparse Attention (DSA), as introduced in [this paper](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp).*\n\n- Token-level sparse attention for the prefill stage\n- Token-level sparse attention for the decoding stage, with FP8 KV cache\n\n**Dense Attention Kernels**\n\n- Dense attention for the prefill stage\n- Dense attention for the decoding stage\n\n## News\n\n- **2025.09.29 Release of Sparse Attention Kernels**: With the launch of [DeepSeek-V3.2](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp), we are releasing the corresponding token-level sparse attention kernels. These kernels power the model's DeepSeek Sparse Attention (DSA) and achieve up to 640 TFlops during prefilling and 410 TFlops during decoding. We also release a deep-dive blog for our new FP8 sparse decoding kernel. Check it out [here](docs/20250929-hopper-fp8-sparse-deep-dive.md).\n- **2025.08.01 Kernels for MHA on SM100**: Thanks to [NVIDIA's PR](https://github.com/deepseek-ai/FlashMLA/pull/76) for MHA forward / backward kernels on SM100!\n- **2025.04.22 Deep-Dive Blog**: We'd love to share the technical details behind the new FlashMLA kernel! Check out our deep-dive write-up [here](docs/20250422-new-kernel-deep-dive.md).\n- **2025.04.22 Performance Update**: We're excited to announce the new release of Flash MLA, which delivers 5% ~ 15% performance improvement for compute-bound workloads, achieving up to 660 TFlops on NVIDIA H800 SXM5 GPUs. The interface of the new version is fully compatible with the old one. Simply upgrade to the new version for an immediate performance boost! üöÄüöÄüöÄ\n\n## Performance\n\n#### Test & benchmark MLA decoding (Sparse & Dense):\n\n```bash\npython tests/test_flash_mla_dense_decoding.py\npython tests/test_flash_mla_sparse_decoding.py\n```\n\nThe dense MLA decoding kernel achieves up to 3000 GB/s in memory-bound configuration and 660 TFLOPS in computation-bound configuration on H800 SXM5 with CUDA 12.8. The token-level sparse MLA decoding kernel (which uses an FP8 KV cache while performing the matrix multiplication in bfloat16) achieves 410 TFLOPS in compute-bound configuration on H800 SXM5 with CUDA 12.8, and achieves up to 350 TFlops on B200 (which is not really optimized yet).\n\n#### Test & benchmark MHA prefill (Dense):\n\n```bash\npython tests/test_fmha_sm100.py\n```\n\nIt achieves up to 1460 TFlops in forward and 1000 TFlops in backward computation on B200, as reported by NVIDIA.\n\n#### Test & benchmark MLA prefill (Sparse):\n\n```bash\npython tests/test_flash_mla_sparse_prefill.py\n```\n\nIt achieves up to 640 TFlops in forward computation on H800 SXM5 with CUDA 12.8, and achieves up to 1450 TFlops on B200, CUDA 12.9.\n\n## Requirements\n\n- SM90 / SM100 (See the support matrix below)\n- CUDA 12.8 and above (CUDA 12.9+ is required for SM100 kernels)\n- PyTorch 2.0 and above\n\nSupport matrix:\n\n| Kernel | GPU Architecture | MLA Mode [2] | KVCache Format |\n| :---: | :---: | :---: | :---: |\n| Dense Decoding | SM90 | MQA | BF16 |\n| Sparse Decoding | SM90 & SM100 | MQA | FP8 [1] |\n| Dense Prefill | SM100 | MHA |  |\n| Sparse Prefill | SM90 & SM100 | MQA |  |\n\n[1]: For more details on using FP8 KV cache, see documents below.\n\n[2]: Here \"MLA Mode\" refers to the mode used for MLA calculation. MQA stands for Multi-Query Attention mode (i.e. `head_dim_k` =  576 with `head_dim_v` = 512), while MHA stands for Multi-Head Attention mode (i.e. `head_dim_k` = 192 / 128 with `head_dim_v` = 128). For a detailed explanation of these modes, please refer to the appendix of [DeepSeek V3.2's Paper](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp).\n\n## Installation\n\n```bash\ngit clone https://github.com/deepseek-ai/FlashMLA.git flash-mla\ncd flash-mla\ngit submodule update --init --recursive\npip install -v .\n```\n\n## Usage\n\n### MLA Decoding\n\nTo use the MLA decoding kernels, call get_mla_metadata once before the decoding loop to get the tile scheduler metadata. Then, call flash_mla_with_kvcache in each decoding step. For example:\n\n```python\nfrom flash_mla import get_mla_metadata, flash_mla_with_kvcache\n\ntile_scheduler_metadata, num_splits = get_mla_metadata(\n    cache_seqlens,\n    s_q * h_q // h_kv,\n    h_kv,\n    h_q,\n    is_fp8,\n    topk,\n)\n\nfor i in range(num_layers):\n    ...\n    o_i, lse_i = flash_mla_with_kvcache(\n        q_i, kvcache_i, block_table, cache_seqlens, dv,\n        tile_scheduler_metadata, num_splits,\n        is_causal, is_fp8_kvcache, indices,\n    )\n    ...\n```\n\nWhere\n\n- `s_q` is the number of q tokens per q sequence. If MTP (speculative decoding) is disabled, it should be 1.\n- `h_kv` is the number of key-value heads.\n- `h_q` is the number of query heads.\n\n**FP8 KV Cache:**\nIf `is_fp8_kvcache` is set to `True`, the kernel reads the KV cache in the \"FP8 with scale\" format (described below). It dequantizes the cache to bfloat16 and performs attention computation in bfloat16. The output is also in bfloat16.\n\nIn the \"FP8 with scale\" format, each token's KV cache is 656 Bytes, structured as:\n-   **First 512 bytes:** The \"quantized NoPE\" part, containing 512 `float8_e4m3` values.\n-   **Next 16 bytes:** Scale factors, containing 4 `float32` values. The first `float32` is the scale for the first 128 `float8_e4m3` values, the second for the next 128, and so on.\n-   **Last 128 bytes:** The \"RoPE\" part, containing 64 `bfloat16` values. This part is not quantized for accuracy.\n\nSee `tests/quant.py` for quantization and dequantization details.\n\n**Sparse Attention (`indices` tensor):**\nThe `indices` tensor (if provided) enables token-level sparse attention by instructing the kernel to compute attention only for specified tokens.\n\n-   **Shape:** `indices` should be a 3D tensor of shape `(batch_size, seq_len_q, topk)`.\n-   **Format:** `indices_in_kvcache[i][j][k] = (the index of the page block where token t resides) * page_block_size + (the offset of token t within the page block)`, where `t` is the k-th token for the j-th query sequence in the i-th batch. Since the index of the page block has already been encoded into `indices_in_kvcache`, the kernel does not require the `block_table` parameter.\n-   **Invalid entries:** Set invalid indices to `-1`.\n\n**Return Values:**\nThe kernel returns `(out, lse)`, where:\n-   `out` is the attention result.\n-   `lse` is the log-sum-exp value of the attention scores for each query head.\n\nSee `tests/test_flash_mla_decoding.py` for a complete example.\n\n### Sparse MLA Prefill\n\nFor the sparse MLA prefill kernel, call `flash_mla_sparse_fwd` directly with the following parameters:\n-   `q`: Query tensor of shape `[s_q, h_q, d_qk]`\n-   `kv`: Key-Value tensor of shape `[s_kv, h_kv, d_qk]`\n-   `indices`: Indices tensor of shape `[s_q, h_kv, topk]`\n-   `sm_scale`: A scalar value\n\n**Note on batching:** This kernel does not support a batch dimension. For multi-batch inference, reshape the input tensors and adjust the `indices` parameter to simulate batch processing.\n\n**Invalid indices:** Set invalid entries in `indices` to `-1` or any number `>= s_kv`.\n\n**Return Values and Equivalent PyTorch Code:**\nThe kernel returns `(out, max_logits, lse)`. This is equivalent to the following PyTorch operations:\n\n```python\nQ: [s_q, h_q, d_qk], bfloat16\nkv: [s_kv, h_kv, d_qk], bfloat16\nindices: [s_q, h_kv, topk], int32\n\nkv = kv.squeeze(1)  # [s_kv, d_qk], h_kv must be 1\nindices = indices.squeeze(1)    # [s_q, topk]\nfocused_kv = kv[indices]    # For the i-th sequence (s_q), the corresponding KV tokens are selected from the KV cache based on indices[i, :]. This operation results in a tensor of shape [s_q, topk, d_qk].\n\nP = (Q @ focused_kv.transpose(-1, -2)) * sm_scale * math.log2(math.e)    # [s_q, h_q, topk]\nmax_logits = P.max(dim=-1) # [s_q, h_q]\nlse = log2sumexp2(P, dim=-1, base=2)   # [s_q, h_q]Ôºå\"log2sumexp2\" means that the exponentiation and logarithm are base-2\nS = exp2(P - lse)      # [s_q, h_q, topk]\nout = S @ focused_kv  # [s_q, h_q, d_qk]\n\nreturn (out, max_logits, lse)\n```\n\nSee `tests/test_flash_mla_prefill.py` for a complete example.\n\n### Dense MHA Prefill\n\nThis kernel implements the standard dense Multi-Head Attention (MHA) forward and backward operations. It can be called using:\n-   `flash_attn_varlen_func`\n-   `flash_attn_varlen_qkvpacked_func`\n-   `flash_attn_varlen_kvpacked_func`\n\nThe usage is similar to the `flash_attn` package. See `tests/test_fmha_sm100.py` for a complete example.\n\n## Acknowledgement\n\nFlashMLA is inspired by [FlashAttention 2&3](https://github.com/dao-AILab/flash-attention/) and [cutlass](https://github.com/nvidia/cutlass) projects.\n\n## Community Support\n\n### MetaX\nFor MetaX GPUs, visit the official website: [MetaX](https://www.metax-tech.com).\n\nThe corresponding FlashMLA version can be found at: [MetaX-MACA/FlashMLA](https://github.com/MetaX-MACA/FlashMLA)\n\n\n### Moore Threads\nFor the Moore Threads GPU, visit the official website: [Moore Threads](https://www.mthreads.com/).\n\nThe corresponding FlashMLA version is available on GitHub: [MooreThreads/MT-flashMLA](https://github.com/MooreThreads/MT-flashMLA).\n\n\n### Hygon DCU\nFor the Hygon DCU, visit the official website: [Hygon Developer](https://developer.sourcefind.cn/).\n\nThe corresponding FlashMLA version is available here: [OpenDAS/MLAttention](https://developer.sourcefind.cn/codes/OpenDAS/MLAttention).\n\n\n### Intellifusion\nFor the Intellifusion NNP, visit the official website: [Intellifusion](https://www.intellif.com).\n\nThe corresponding FlashMLA version is available on Gitee: [Intellifusion/tyllm](https://gitee.com/Intellifusion_2025/tyllm/blob/master/python/tylang/flash_mla.py).\n\n\n### Iluvatar Corex\nFor Iluvatar Corex GPUs, visit the official website: [Iluvatar Corex](https://www.iluvatar.com).\n\nThe corresponding FlashMLA version is available on GitHub: [Deep-Spark/FlashMLA](https://github.com/Deep-Spark/FlashMLA/tree/iluvatar_flashmla)\n\n\n### AMD Instinct\nFor AMD Instinct GPUs, visit the official website: [AMD Instinct](https://www.amd.com/en/products/accelerators/instinct.html).\n\nThe corresponding FlashMLA version can be found at: [AITER/MLA](https://github.com/ROCm/aiter/blob/main/aiter/mla.py)\n\n## Citation\n\n```bibtex\n@misc{flashmla2025,\n      title={FlashMLA: Efficient Multi-head Latent Attention Kernels},\n      author={Jiashi Li, Shengyu Liu},\n      year={2025},\n      publisher = {GitHub},\n      howpublished = {\\url{https://github.com/deepseek-ai/FlashMLA}},\n}\n```\n",
      "stars_today": 30
    },
    {
      "id": 631254164,
      "name": "one-api",
      "full_name": "songquanpeng/one-api",
      "description": "LLM API ÁÆ°ÁêÜ & ÂàÜÂèëÁ≥ªÁªüÔºåÊîØÊåÅ OpenAI„ÄÅAzure„ÄÅAnthropic Claude„ÄÅGoogle Gemini„ÄÅDeepSeek„ÄÅÂ≠óËäÇË±ÜÂåÖ„ÄÅChatGLM„ÄÅÊñáÂøÉ‰∏ÄË®Ä„ÄÅËÆØÈ£ûÊòüÁÅ´„ÄÅÈÄö‰πâÂçÉÈóÆ„ÄÅ360 Êô∫ËÑë„ÄÅËÖæËÆØÊ∑∑ÂÖÉÁ≠â‰∏ªÊµÅÊ®°ÂûãÔºåÁªü‰∏Ä API ÈÄÇÈÖçÔºåÂèØÁî®‰∫é key ÁÆ°ÁêÜ‰∏é‰∫åÊ¨°ÂàÜÂèë„ÄÇÂçïÂèØÊâßË°åÊñá‰ª∂ÔºåÊèê‰æõ Docker ÈïúÂÉèÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºåÂºÄÁÆ±Âç≥Áî®„ÄÇLLM API management & key redistribution system, unifying multiple providers under a single API. Single binary, Docker-ready, with an English UI.",
      "html_url": "https://github.com/songquanpeng/one-api",
      "stars": 29209,
      "forks": 5669,
      "language": "JavaScript",
      "topics": [
        "api",
        "api-gateway",
        "azure-openai-api",
        "chatgpt",
        "claude",
        "ernie-bot",
        "gemini",
        "gpt",
        "openai",
        "openai-api",
        "proxy"
      ],
      "created_at": "2023-04-22T12:39:24Z",
      "updated_at": "2026-01-23T02:07:11Z",
      "pushed_at": "2026-01-09T03:26:43Z",
      "open_issues": 979,
      "owner": {
        "login": "songquanpeng",
        "avatar_url": "https://avatars.githubusercontent.com/u/39998050?v=4"
      },
      "readme": "<p align=\"right\">\n   <strong>‰∏≠Êñá</strong> | <a href=\"./README.en.md\">English</a> | <a href=\"./README.ja.md\">Êó•Êú¨Ë™û</a>\n</p>\n\n\n<p align=\"center\">\n  <a href=\"https://github.com/songquanpeng/one-api\"><img src=\"https://raw.githubusercontent.com/songquanpeng/one-api/main/web/default/public/logo.png\" width=\"150\" height=\"150\" alt=\"one-api logo\"></a>\n</p>\n\n<div align=\"center\">\n\n# One API\n\n_‚ú® ÈÄöËøáÊ†áÂáÜÁöÑ OpenAI API Ê†ºÂºèËÆøÈóÆÊâÄÊúâÁöÑÂ§ßÊ®°ÂûãÔºåÂºÄÁÆ±Âç≥Áî® ‚ú®_\n\n</div>\n\n<p align=\"center\">\n  <a href=\"https://raw.githubusercontent.com/songquanpeng/one-api/main/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/songquanpeng/one-api?color=brightgreen\" alt=\"license\">\n  </a>\n  <a href=\"https://github.com/songquanpeng/one-api/releases/latest\">\n    <img src=\"https://img.shields.io/github/v/release/songquanpeng/one-api?color=brightgreen&include_prereleases\" alt=\"release\">\n  </a>\n  <a href=\"https://hub.docker.com/repository/docker/justsong/one-api\">\n    <img src=\"https://img.shields.io/docker/pulls/justsong/one-api?color=brightgreen\" alt=\"docker pull\">\n  </a>\n  <a href=\"https://github.com/songquanpeng/one-api/releases/latest\">\n    <img src=\"https://img.shields.io/github/downloads/songquanpeng/one-api/total?color=brightgreen&include_prereleases\" alt=\"release\">\n  </a>\n  <a href=\"https://goreportcard.com/report/github.com/songquanpeng/one-api\">\n    <img src=\"https://goreportcard.com/badge/github.com/songquanpeng/one-api\" alt=\"GoReportCard\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/songquanpeng/one-api#ÈÉ®ÁΩ≤\">ÈÉ®ÁΩ≤ÊïôÁ®ã</a>\n  ¬∑\n  <a href=\"https://github.com/songquanpeng/one-api#‰ΩøÁî®ÊñπÊ≥ï\">‰ΩøÁî®ÊñπÊ≥ï</a>\n  ¬∑\n  <a href=\"https://github.com/songquanpeng/one-api/issues\">ÊÑèËßÅÂèçÈ¶à</a>\n  ¬∑\n  <a href=\"https://github.com/songquanpeng/one-api#Êà™ÂõæÂ±ïÁ§∫\">Êà™ÂõæÂ±ïÁ§∫</a>\n  ¬∑\n  <a href=\"https://openai.justsong.cn/\">Âú®Á∫øÊºîÁ§∫</a>\n  ¬∑\n  <a href=\"https://github.com/songquanpeng/one-api#Â∏∏ËßÅÈóÆÈ¢ò\">Â∏∏ËßÅÈóÆÈ¢ò</a>\n  ¬∑\n  <a href=\"https://github.com/songquanpeng/one-api#Áõ∏ÂÖ≥È°πÁõÆ\">Áõ∏ÂÖ≥È°πÁõÆ</a>\n  ¬∑\n  <a href=\"https://iamazing.cn/page/reward\">ËµûËµèÊîØÊåÅ</a>\n</p>\n\n> [!NOTE]\n> Êú¨È°πÁõÆ‰∏∫ÂºÄÊ∫êÈ°πÁõÆÔºå‰ΩøÁî®ËÄÖÂøÖÈ°ªÂú®ÈÅµÂæ™ OpenAI ÁöÑ[‰ΩøÁî®Êù°Ê¨æ](https://openai.com/policies/terms-of-use)‰ª•Âèä**Ê≥ïÂæãÊ≥ïËßÑ**ÁöÑÊÉÖÂÜµ‰∏ã‰ΩøÁî®Ôºå‰∏çÂæóÁî®‰∫éÈùûÊ≥ïÁî®ÈÄî„ÄÇ\n>\n> Ê†πÊçÆ[„ÄäÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúçÂä°ÁÆ°ÁêÜÊöÇË°åÂäûÊ≥ï„Äã](http://www.cac.gov.cn/2023-07/13/c_1690898327029107.htm)ÁöÑË¶ÅÊ±ÇÔºåËØ∑ÂãøÂØπ‰∏≠ÂõΩÂú∞Âå∫ÂÖ¨‰ºóÊèê‰æõ‰∏ÄÂàáÊú™ÁªèÂ§áÊ°àÁöÑÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúçÂä°„ÄÇ\n\n> [!NOTE]\n> Á®≥ÂÆöÁâà / È¢ÑËßàÁâàÈïúÂÉèÂú∞ÂùÄÔºö[justsong/one-api](https://hub.docker.com/repository/docker/justsong/one-api)\n> ÊàñËÄÖ [ghcr.io/songquanpeng/one-api](https://github.com/songquanpeng/one-api/pkgs/container/one-api)\n>\n> alpha ÁâàÈïúÂÉèÂú∞ÂùÄÔºö[justsong/one-api-alpha](https://hub.docker.com/repository/docker/justsong/one-api-alpha)\n> ÊàñËÄÖ [ghcr.io/songquanpeng/one-api-alpha](https://github.com/songquanpeng/one-api/pkgs/container/one-api-alpha)\n\n> [!WARNING]\n> ‰ΩøÁî® root Áî®Êà∑ÂàùÊ¨°ÁôªÂΩïÁ≥ªÁªüÂêéÔºåÂä°ÂøÖ‰øÆÊîπÈªòËÆ§ÂØÜÁ†Å `123456`ÔºÅ\n\n## ÂäüËÉΩ\n1. ÊîØÊåÅÂ§öÁßçÂ§ßÊ®°ÂûãÔºö\n   + [x] [OpenAI ChatGPT Á≥ªÂàóÊ®°Âûã](https://platform.openai.com/docs/guides/gpt/chat-completions-api)ÔºàÊîØÊåÅ [Azure OpenAI API](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference)Ôºâ\n   + [x] [Anthropic Claude Á≥ªÂàóÊ®°Âûã](https://anthropic.com) (ÊîØÊåÅ AWS Claude)\n   + [x] [Google PaLM2/Gemini Á≥ªÂàóÊ®°Âûã](https://developers.generativeai.google)\n   + [x] [Mistral Á≥ªÂàóÊ®°Âûã](https://mistral.ai/)\n   + [x] [Â≠óËäÇË∑≥Âä®Ë±ÜÂåÖÂ§ßÊ®°ÂûãÔºàÁÅ´Â±±ÂºïÊìéÔºâ](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&ac=DSASUQY5&rc=2QXCA1VI)\n   + [x] [ÁôæÂ∫¶ÊñáÂøÉ‰∏ÄË®ÄÁ≥ªÂàóÊ®°Âûã](https://cloud.baidu.com/doc/WENXINWORKSHOP/index.html)\n   + [x] [ÈòøÈáåÈÄö‰πâÂçÉÈóÆÁ≥ªÂàóÊ®°Âûã](https://help.aliyun.com/document_detail/2400395.html)\n   + [x] [ËÆØÈ£ûÊòüÁÅ´ËÆ§Áü•Â§ßÊ®°Âûã](https://www.xfyun.cn/doc/spark/Web.html)\n   + [x] [Êô∫Ë∞± ChatGLM Á≥ªÂàóÊ®°Âûã](https://bigmodel.cn)\n   + [x] [360 Êô∫ËÑë](https://ai.360.cn)\n   + [x] [ËÖæËÆØÊ∑∑ÂÖÉÂ§ßÊ®°Âûã](https://cloud.tencent.com/document/product/1729)\n   + [x] [Moonshot AI](https://platform.moonshot.cn/)\n   + [x] [ÁôæÂ∑ùÂ§ßÊ®°Âûã](https://platform.baichuan-ai.com)\n   + [x] [MINIMAX](https://api.minimax.chat/)\n   + [x] [Groq](https://wow.groq.com/)\n   + [x] [Ollama](https://github.com/ollama/ollama)\n   + [x] [Èõ∂‰∏Ä‰∏áÁâ©](https://platform.lingyiwanwu.com/)\n   + [x] [Èò∂Ë∑ÉÊòüËæ∞](https://platform.stepfun.com/)\n   + [x] [Coze](https://www.coze.com/)\n   + [x] [Cohere](https://cohere.com/)\n   + [x] [DeepSeek](https://www.deepseek.com/)\n   + [x] [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/)\n   + [x] [DeepL](https://www.deepl.com/)\n   + [x] [together.ai](https://www.together.ai/)\n   + [x] [novita.ai](https://www.novita.ai/)\n   + [x] [Á°ÖÂü∫ÊµÅÂä® SiliconCloud](https://cloud.siliconflow.cn/i/rKXmRobW)\n   + [x] [xAI](https://x.ai/)\n2. ÊîØÊåÅÈÖçÁΩÆÈïúÂÉè‰ª•Âèä‰ºóÂ§ö[Á¨¨‰∏âÊñπ‰ª£ÁêÜÊúçÂä°](https://iamazing.cn/page/openai-api-third-party-services)„ÄÇ\n3. ÊîØÊåÅÈÄöËøá**Ë¥üËΩΩÂùáË°°**ÁöÑÊñπÂºèËÆøÈóÆÂ§ö‰∏™Ê∏†ÈÅì„ÄÇ\n4. ÊîØÊåÅ **stream Ê®°Âºè**ÔºåÂèØ‰ª•ÈÄöËøáÊµÅÂºè‰º†ËæìÂÆûÁé∞ÊâìÂ≠óÊú∫ÊïàÊûú„ÄÇ\n5. ÊîØÊåÅ**Â§öÊú∫ÈÉ®ÁΩ≤**Ôºå[ËØ¶ËßÅÊ≠§Â§Ñ](#Â§öÊú∫ÈÉ®ÁΩ≤)„ÄÇ\n6. ÊîØÊåÅ**‰ª§ÁâåÁÆ°ÁêÜ**ÔºåËÆæÁΩÆ‰ª§ÁâåÁöÑËøáÊúüÊó∂Èó¥„ÄÅÈ¢ùÂ∫¶„ÄÅÂÖÅËÆ∏ÁöÑ IP ËåÉÂõ¥‰ª•ÂèäÂÖÅËÆ∏ÁöÑÊ®°ÂûãËÆøÈóÆ„ÄÇ\n7. ÊîØÊåÅ**ÂÖëÊç¢Á†ÅÁÆ°ÁêÜ**ÔºåÊîØÊåÅÊâπÈáèÁîüÊàêÂíåÂØºÂá∫ÂÖëÊç¢Á†ÅÔºåÂèØ‰ΩøÁî®ÂÖëÊç¢Á†Å‰∏∫Ë¥¶Êà∑ËøõË°åÂÖÖÂÄº„ÄÇ\n8. ÊîØÊåÅ**Ê∏†ÈÅìÁÆ°ÁêÜ**ÔºåÊâπÈáèÂàõÂª∫Ê∏†ÈÅì„ÄÇ\n9. ÊîØÊåÅ**Áî®Êà∑ÂàÜÁªÑ**‰ª•Âèä**Ê∏†ÈÅìÂàÜÁªÑ**ÔºåÊîØÊåÅ‰∏∫‰∏çÂêåÂàÜÁªÑËÆæÁΩÆ‰∏çÂêåÁöÑÂÄçÁéá„ÄÇ\n10. ÊîØÊåÅÊ∏†ÈÅì**ËÆæÁΩÆÊ®°ÂûãÂàóË°®**„ÄÇ\n11. ÊîØÊåÅ**Êü•ÁúãÈ¢ùÂ∫¶ÊòéÁªÜ**„ÄÇ\n12. ÊîØÊåÅ**Áî®Êà∑ÈÇÄËØ∑Â•ñÂä±**„ÄÇ\n13. ÊîØÊåÅ‰ª•ÁæéÂÖÉ‰∏∫Âçï‰ΩçÊòæÁ§∫È¢ùÂ∫¶„ÄÇ\n14. ÊîØÊåÅÂèëÂ∏ÉÂÖ¨ÂëäÔºåËÆæÁΩÆÂÖÖÂÄºÈìæÊé•ÔºåËÆæÁΩÆÊñ∞Áî®Êà∑ÂàùÂßãÈ¢ùÂ∫¶„ÄÇ\n15. ÊîØÊåÅÊ®°ÂûãÊò†Â∞ÑÔºåÈáçÂÆöÂêëÁî®Êà∑ÁöÑËØ∑Ê±ÇÊ®°ÂûãÔºåÂ¶ÇÊó†ÂøÖË¶ÅËØ∑‰∏çË¶ÅËÆæÁΩÆÔºåËÆæÁΩÆ‰πãÂêé‰ºöÂØºËá¥ËØ∑Ê±Ç‰ΩìË¢´ÈáçÊñ∞ÊûÑÈÄ†ËÄåÈùûÁõ¥Êé•ÈÄè‰º†Ôºå‰ºöÂØºËá¥ÈÉ®ÂàÜËøòÊú™Ê≠£ÂºèÊîØÊåÅÁöÑÂ≠óÊÆµÊó†Ê≥ï‰º†ÈÄíÊàêÂäü„ÄÇ\n16. ÊîØÊåÅÂ§±Ë¥•Ëá™Âä®ÈáçËØï„ÄÇ\n17. ÊîØÊåÅÁªòÂõæÊé•Âè£„ÄÇ\n18. ÊîØÊåÅ [Cloudflare AI Gateway](https://developers.cloudflare.com/ai-gateway/providers/openai/)ÔºåÊ∏†ÈÅìËÆæÁΩÆÁöÑ‰ª£ÁêÜÈÉ®ÂàÜÂ°´ÂÜô `https://gateway.ai.cloudflare.com/v1/ACCOUNT_TAG/GATEWAY/openai` Âç≥ÂèØ„ÄÇ\n19. ÊîØÊåÅ‰∏∞ÂØåÁöÑ**Ëá™ÂÆö‰πâ**ËÆæÁΩÆÔºå\n    1. ÊîØÊåÅËá™ÂÆö‰πâÁ≥ªÁªüÂêçÁß∞Ôºålogo ‰ª•ÂèäÈ°µËÑö„ÄÇ\n    2. ÊîØÊåÅËá™ÂÆö‰πâÈ¶ñÈ°µÂíåÂÖ≥‰∫éÈ°µÈù¢ÔºåÂèØ‰ª•ÈÄâÊã©‰ΩøÁî® HTML & Markdown ‰ª£Á†ÅËøõË°åËá™ÂÆö‰πâÔºåÊàñËÄÖ‰ΩøÁî®‰∏Ä‰∏™ÂçïÁã¨ÁöÑÁΩëÈ°µÈÄöËøá iframe ÂµåÂÖ•„ÄÇ\n20. ÊîØÊåÅÈÄöËøáÁ≥ªÁªüËÆøÈóÆ‰ª§ÁâåË∞ÉÁî®ÁÆ°ÁêÜ APIÔºåËøõËÄå**Âú®Êó†ÈúÄ‰∫åÂºÄÁöÑÊÉÖÂÜµ‰∏ãÊâ©Â±ïÂíåËá™ÂÆö‰πâ** One API ÁöÑÂäüËÉΩÔºåËØ¶ÊÉÖËØ∑ÂèÇËÄÉÊ≠§Â§Ñ [API ÊñáÊ°£](./docs/API.md)„ÄÇ\n21. ÊîØÊåÅ Cloudflare Turnstile Áî®Êà∑Ê†°È™å„ÄÇ\n22. ÊîØÊåÅÁî®Êà∑ÁÆ°ÁêÜÔºåÊîØÊåÅ**Â§öÁßçÁî®Êà∑ÁôªÂΩïÊ≥®ÂÜåÊñπÂºè**Ôºö\n    + ÈÇÆÁÆ±ÁôªÂΩïÊ≥®ÂÜåÔºàÊîØÊåÅÊ≥®ÂÜåÈÇÆÁÆ±ÁôΩÂêçÂçïÔºâ‰ª•ÂèäÈÄöËøáÈÇÆÁÆ±ËøõË°åÂØÜÁ†ÅÈáçÁΩÆ„ÄÇ\n    + ÊîØÊåÅ[È£û‰π¶ÊéàÊùÉÁôªÂΩï](https://open.feishu.cn/document/uAjLw4CM/ukTMukTMukTM/reference/authen-v1/authorize/get)Ôºà[ËøôÈáåÊúâ One API ÁöÑÂÆûÁé∞ÁªÜËäÇÈòêËø∞‰æõÂèÇËÄÉ](https://iamazing.cn/page/feishu-oauth-login)Ôºâ„ÄÇ\n    + ÊîØÊåÅ [GitHub ÊéàÊùÉÁôªÂΩï](https://github.com/settings/applications/new)„ÄÇ\n    + ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÊéàÊùÉÔºàÈúÄË¶ÅÈ¢ùÂ§ñÈÉ®ÁΩ≤ [WeChat Server](https://github.com/songquanpeng/wechat-server)Ôºâ„ÄÇ\n23. ÊîØÊåÅ‰∏ªÈ¢òÂàáÊç¢ÔºåËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè `THEME` Âç≥ÂèØÔºåÈªòËÆ§‰∏∫ `default`ÔºåÊ¨¢Ëøé PR Êõ¥Â§ö‰∏ªÈ¢òÔºåÂÖ∑‰ΩìÂèÇËÄÉ[Ê≠§Â§Ñ](./web/README.md)„ÄÇ\n24. ÈÖçÂêà [Message Pusher](https://github.com/songquanpeng/message-pusher) ÂèØÂ∞ÜÊä•Ë≠¶‰ø°ÊÅØÊé®ÈÄÅÂà∞Â§öÁßç App ‰∏ä„ÄÇ\n\n## ÈÉ®ÁΩ≤\n### Âü∫‰∫é Docker ËøõË°åÈÉ®ÁΩ≤\n```shell\n# ‰ΩøÁî® SQLite ÁöÑÈÉ®ÁΩ≤ÂëΩ‰ª§Ôºö\ndocker run --name one-api -d --restart always -p 3000:3000 -e TZ=Asia/Shanghai -v /home/ubuntu/data/one-api:/data justsong/one-api\n# ‰ΩøÁî® MySQL ÁöÑÈÉ®ÁΩ≤ÂëΩ‰ª§ÔºåÂú®‰∏äÈù¢ÁöÑÂü∫Á°Ä‰∏äÊ∑ªÂä† `-e SQL_DSN=\"root:123456@tcp(localhost:3306)/oneapi\"`ÔºåËØ∑Ëá™Ë°å‰øÆÊîπÊï∞ÊçÆÂ∫ìËøûÊé•ÂèÇÊï∞Ôºå‰∏çÊ∏ÖÊ•öÂ¶Ç‰Ωï‰øÆÊîπËØ∑ÂèÇËßÅ‰∏ãÈù¢ÁéØÂ¢ÉÂèòÈáè‰∏ÄËäÇ„ÄÇ\n# ‰æãÂ¶ÇÔºö\ndocker run --name one-api -d --restart always -p 3000:3000 -e SQL_DSN=\"root:123456@tcp(localhost:3306)/oneapi\" -e TZ=Asia/Shanghai -v /home/ubuntu/data/one-api:/data justsong/one-api\n```\n\nÂÖ∂‰∏≠Ôºå`-p 3000:3000` ‰∏≠ÁöÑÁ¨¨‰∏Ä‰∏™ `3000` ÊòØÂÆø‰∏ªÊú∫ÁöÑÁ´ØÂè£ÔºåÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅËøõË°å‰øÆÊîπ„ÄÇ\n\nÊï∞ÊçÆÂíåÊó•ÂøóÂ∞Ü‰ºö‰øùÂ≠òÂú®ÂÆø‰∏ªÊú∫ÁöÑ `/home/ubuntu/data/one-api` ÁõÆÂΩïÔºåËØ∑Á°Æ‰øùËØ•ÁõÆÂΩïÂ≠òÂú®‰∏îÂÖ∑ÊúâÂÜôÂÖ•ÊùÉÈôêÔºåÊàñËÄÖÊõ¥Êîπ‰∏∫ÂêàÈÄÇÁöÑÁõÆÂΩï„ÄÇ\n\nÂ¶ÇÊûúÂêØÂä®Â§±Ë¥•ÔºåËØ∑Ê∑ªÂä† `--privileged=true`ÔºåÂÖ∑‰ΩìÂèÇËÄÉ https://github.com/songquanpeng/one-api/issues/482 „ÄÇ\n\nÂ¶ÇÊûú‰∏äÈù¢ÁöÑÈïúÂÉèÊó†Ê≥ïÊãâÂèñÔºåÂèØ‰ª•Â∞ùËØï‰ΩøÁî® GitHub ÁöÑ Docker ÈïúÂÉèÔºåÂ∞Ü‰∏äÈù¢ÁöÑ `justsong/one-api` ÊõøÊç¢‰∏∫ `ghcr.io/songquanpeng/one-api` Âç≥ÂèØ„ÄÇ\n\nÂ¶ÇÊûú‰Ω†ÁöÑÂπ∂ÂèëÈáèËæÉÂ§ßÔºå**Âä°ÂøÖ**ËÆæÁΩÆ `SQL_DSN`ÔºåËØ¶ËßÅ‰∏ãÈù¢[ÁéØÂ¢ÉÂèòÈáè](#ÁéØÂ¢ÉÂèòÈáè)‰∏ÄËäÇ„ÄÇ\n\nÊõ¥Êñ∞ÂëΩ‰ª§Ôºö`docker run --rm -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower -cR`\n\nNginx ÁöÑÂèÇËÄÉÈÖçÁΩÆÔºö\n```\nserver{\n   server_name openai.justsong.cn;  # ËØ∑Ê†πÊçÆÂÆûÈôÖÊÉÖÂÜµ‰øÆÊîπ‰Ω†ÁöÑÂüüÂêç\n\n   location / {\n          client_max_body_size  64m;\n          proxy_http_version 1.1;\n          proxy_pass http://localhost:3000;  # ËØ∑Ê†πÊçÆÂÆûÈôÖÊÉÖÂÜµ‰øÆÊîπ‰Ω†ÁöÑÁ´ØÂè£\n          proxy_set_header Host $host;\n          proxy_set_header X-Forwarded-For $remote_addr;\n          proxy_cache_bypass $http_upgrade;\n          proxy_set_header Accept-Encoding gzip;\n          proxy_read_timeout 300s;  # GPT-4 ÈúÄË¶ÅËæÉÈïøÁöÑË∂ÖÊó∂Êó∂Èó¥ÔºåËØ∑Ëá™Ë°åË∞ÉÊï¥\n   }\n}\n```\n\n‰πãÂêé‰ΩøÁî® Let's Encrypt ÁöÑ certbot ÈÖçÁΩÆ HTTPSÔºö\n```bash\n# Ubuntu ÂÆâË£Ö certbotÔºö\nsudo snap install --classic certbot\nsudo ln -s /snap/bin/certbot /usr/bin/certbot\n# ÁîüÊàêËØÅ‰π¶ & ‰øÆÊîπ Nginx ÈÖçÁΩÆ\nsudo certbot --nginx\n# Ê†πÊçÆÊåáÁ§∫ËøõË°åÊìç‰Ωú\n# ÈáçÂêØ Nginx\nsudo service nginx restart\n```\n\nÂàùÂßãË¥¶Âè∑Áî®Êà∑Âêç‰∏∫ `root`ÔºåÂØÜÁ†Å‰∏∫ `123456`„ÄÇ\n\n### ÈÄöËøáÂÆùÂ°îÈù¢ÊùøËøõË°å‰∏ÄÈîÆÈÉ®ÁΩ≤\n1. ÂÆâË£ÖÂÆùÂ°îÈù¢Êùø9.2.0Âèä‰ª•‰∏äÁâàÊú¨ÔºåÂâçÂæÄ [ÂÆùÂ°îÈù¢Êùø](https://www.bt.cn/new/download.html?r=dk_oneapi) ÂÆòÁΩëÔºåÈÄâÊã©Ê≠£ÂºèÁâàÁöÑËÑöÊú¨‰∏ãËΩΩÂÆâË£ÖÔºõ\n2. ÂÆâË£ÖÂêéÁôªÂΩïÂÆùÂ°îÈù¢ÊùøÔºåÂú®Â∑¶‰æßËèúÂçïÊ†è‰∏≠ÁÇπÂáª `Docker`ÔºåÈ¶ñÊ¨°ËøõÂÖ•‰ºöÊèêÁ§∫ÂÆâË£Ö `Docker` ÊúçÂä°ÔºåÁÇπÂáªÁ´ãÂç≥ÂÆâË£ÖÔºåÊåâÊèêÁ§∫ÂÆåÊàêÂÆâË£ÖÔºõ\n3. ÂÆâË£ÖÂÆåÊàêÂêéÂú®Â∫îÁî®ÂïÜÂ∫ó‰∏≠ÊêúÁ¥¢ `One-API`ÔºåÁÇπÂáªÂÆâË£ÖÔºåÈÖçÁΩÆÂüüÂêçÁ≠âÂü∫Êú¨‰ø°ÊÅØÂç≥ÂèØÂÆåÊàêÂÆâË£ÖÔºõ\n\n### Âü∫‰∫é Docker Compose ËøõË°åÈÉ®ÁΩ≤\n\n> ‰ªÖÂêØÂä®ÊñπÂºè‰∏çÂêåÔºåÂèÇÊï∞ËÆæÁΩÆ‰∏çÂèòÔºåËØ∑ÂèÇËÄÉÂü∫‰∫é Docker ÈÉ®ÁΩ≤ÈÉ®ÂàÜ\n\n```shell\n# ÁõÆÂâçÊîØÊåÅ MySQL ÂêØÂä®ÔºåÊï∞ÊçÆÂ≠òÂÇ®Âú® ./data/mysql Êñá‰ª∂Â§πÂÜÖ\ndocker-compose up -d\n\n# Êü•ÁúãÈÉ®ÁΩ≤Áä∂ÊÄÅ\ndocker-compose ps\n```\n\n### ÊâãÂä®ÈÉ®ÁΩ≤\n1. ‰ªé [GitHub Releases](https://github.com/songquanpeng/one-api/releases/latest) ‰∏ãËΩΩÂèØÊâßË°åÊñá‰ª∂ÊàñËÄÖ‰ªéÊ∫êÁ†ÅÁºñËØëÔºö\n   ```shell\n   git clone https://github.com/songquanpeng/one-api.git\n\n   # ÊûÑÂª∫ÂâçÁ´Ø\n   cd one-api/web/default\n   npm install\n   npm run build\n\n   # ÊûÑÂª∫ÂêéÁ´Ø\n   cd ../..\n   go mod download\n   go build -ldflags \"-s -w\" -o one-api\n   ````\n2. ËøêË°åÔºö\n   ```shell\n   chmod u+x one-api\n   ./one-api --port 3000 --log-dir ./logs\n   ```\n3. ËÆøÈóÆ [http://localhost:3000/](http://localhost:3000/) Âπ∂ÁôªÂΩï„ÄÇÂàùÂßãË¥¶Âè∑Áî®Êà∑Âêç‰∏∫ `root`ÔºåÂØÜÁ†Å‰∏∫ `123456`„ÄÇ\n\nÊõ¥Âä†ËØ¶ÁªÜÁöÑÈÉ®ÁΩ≤ÊïôÁ®ã[ÂèÇËßÅÊ≠§Â§Ñ](https://iamazing.cn/page/how-to-deploy-a-website)„ÄÇ\n\n### Â§öÊú∫ÈÉ®ÁΩ≤\n1. ÊâÄÊúâÊúçÂä°Âô® `SESSION_SECRET` ËÆæÁΩÆ‰∏ÄÊ†∑ÁöÑÂÄº„ÄÇ\n2. ÂøÖÈ°ªËÆæÁΩÆ `SQL_DSN`Ôºå‰ΩøÁî® MySQL Êï∞ÊçÆÂ∫ìËÄåÈùû SQLiteÔºåÊâÄÊúâÊúçÂä°Âô®ËøûÊé•Âêå‰∏Ä‰∏™Êï∞ÊçÆÂ∫ì„ÄÇ\n3. ÊâÄÊúâ‰ªéÊúçÂä°Âô®ÂøÖÈ°ªËÆæÁΩÆ `NODE_TYPE` ‰∏∫ `slave`Ôºå‰∏çËÆæÁΩÆÂàôÈªòËÆ§‰∏∫‰∏ªÊúçÂä°Âô®„ÄÇ\n4. ËÆæÁΩÆ `SYNC_FREQUENCY` ÂêéÊúçÂä°Âô®Â∞ÜÂÆöÊúü‰ªéÊï∞ÊçÆÂ∫ìÂêåÊ≠•ÈÖçÁΩÆÔºåÂú®‰ΩøÁî®ËøúÁ®ãÊï∞ÊçÆÂ∫ìÁöÑÊÉÖÂÜµ‰∏ãÔºåÊé®ËçêËÆæÁΩÆËØ•È°πÂπ∂ÂêØÁî® RedisÔºåÊó†ËÆ∫‰∏ª‰ªé„ÄÇ\n5. ‰ªéÊúçÂä°Âô®ÂèØ‰ª•ÈÄâÊã©ËÆæÁΩÆ `FRONTEND_BASE_URL`Ôºå‰ª•ÈáçÂÆöÂêëÈ°µÈù¢ËØ∑Ê±ÇÂà∞‰∏ªÊúçÂä°Âô®„ÄÇ\n6. ‰ªéÊúçÂä°Âô®‰∏ä**ÂàÜÂà´**Ë£ÖÂ•Ω RedisÔºåËÆæÁΩÆÂ•Ω `REDIS_CONN_STRING`ÔºåËøôÊ†∑ÂèØ‰ª•ÂÅöÂà∞Âú®ÁºìÂ≠òÊú™ËøáÊúüÁöÑÊÉÖÂÜµ‰∏ãÊï∞ÊçÆÂ∫ìÈõ∂ËÆøÈóÆÔºåÂèØ‰ª•ÂáèÂ∞ëÂª∂ËøüÔºàRedis ÈõÜÁæ§ÊàñËÄÖÂì®ÂÖµÊ®°ÂºèÁöÑÊîØÊåÅËØ∑ÂèÇËÄÉÁéØÂ¢ÉÂèòÈáèËØ¥ÊòéÔºâ„ÄÇ\n7. Â¶ÇÊûú‰∏ªÊúçÂä°Âô®ËÆøÈóÆÊï∞ÊçÆÂ∫ìÂª∂Ëøü‰πüÊØîËæÉÈ´òÔºåÂàô‰πüÈúÄË¶ÅÂêØÁî® RedisÔºåÂπ∂ËÆæÁΩÆ `SYNC_FREQUENCY`Ôºå‰ª•ÂÆöÊúü‰ªéÊï∞ÊçÆÂ∫ìÂêåÊ≠•ÈÖçÁΩÆ„ÄÇ\n\nÁéØÂ¢ÉÂèòÈáèÁöÑÂÖ∑‰Ωì‰ΩøÁî®ÊñπÊ≥ïËØ¶ËßÅ[Ê≠§Â§Ñ](#ÁéØÂ¢ÉÂèòÈáè)„ÄÇ\n\n### ÂÆùÂ°îÈÉ®ÁΩ≤ÊïôÁ®ã\n\nËØ¶ËßÅ [#175](https://github.com/songquanpeng/one-api/issues/175)„ÄÇ\n\nÂ¶ÇÊûúÈÉ®ÁΩ≤ÂêéËÆøÈóÆÂá∫Áé∞Á©∫ÁôΩÈ°µÈù¢ÔºåËØ¶ËßÅ [#97](https://github.com/songquanpeng/one-api/issues/97)„ÄÇ\n\n### ÈÉ®ÁΩ≤Á¨¨‰∏âÊñπÊúçÂä°ÈÖçÂêà One API ‰ΩøÁî®\n> Ê¨¢Ëøé PR Ê∑ªÂä†Êõ¥Â§öÁ§∫‰æã„ÄÇ\n\n#### ChatGPT Next Web\nÈ°πÁõÆ‰∏ªÈ°µÔºöhttps://github.com/Yidadaa/ChatGPT-Next-Web\n\n```bash\ndocker run --name chat-next-web -d -p 3001:3000 yidadaa/chatgpt-next-web\n```\n\nÊ≥®ÊÑè‰øÆÊîπÁ´ØÂè£Âè∑Ôºå‰πãÂêéÂú®È°µÈù¢‰∏äËÆæÁΩÆÊé•Âè£Âú∞ÂùÄÔºà‰æãÂ¶ÇÔºöhttps://openai.justsong.cn/ ÔºâÂíå API Key Âç≥ÂèØ„ÄÇ\n\n#### ChatGPT Web\nÈ°πÁõÆ‰∏ªÈ°µÔºöhttps://github.com/Chanzhaoyu/chatgpt-web\n\n```bash\ndocker run --name chatgpt-web -d -p 3002:3002 -e OPENAI_API_BASE_URL=https://openai.justsong.cn -e OPENAI_API_KEY=sk-xxx chenzhaoyu94/chatgpt-web\n```\n\nÊ≥®ÊÑè‰øÆÊîπÁ´ØÂè£Âè∑„ÄÅ`OPENAI_API_BASE_URL` Âíå `OPENAI_API_KEY`„ÄÇ\n\n#### QChatGPT - QQÊú∫Âô®‰∫∫\nÈ°πÁõÆ‰∏ªÈ°µÔºöhttps://github.com/RockChinQ/QChatGPT\n\nÊ†πÊçÆ[ÊñáÊ°£](https://qchatgpt.rockchin.top)ÂÆåÊàêÈÉ®ÁΩ≤ÂêéÔºåÂú® `data/provider.json`ËÆæÁΩÆ`requester.openai-chat-completions.base-url`‰∏∫ One API ÂÆû‰æãÂú∞ÂùÄÔºåÂπ∂Â°´ÂÜô API Key Âà∞ `keys.openai` ÁªÑ‰∏≠ÔºåËÆæÁΩÆ `model` ‰∏∫Ë¶Å‰ΩøÁî®ÁöÑÊ®°ÂûãÂêçÁß∞„ÄÇ\n\nËøêË°åÊúüÈó¥ÂèØ‰ª•ÈÄöËøá`!model`ÂëΩ‰ª§Êü•Áúã„ÄÅÂàáÊç¢ÂèØÁî®Ê®°Âûã„ÄÇ\n\n### ÈÉ®ÁΩ≤Âà∞Á¨¨‰∏âÊñπÂπ≥Âè∞\n<details>\n<summary><strong>ÈÉ®ÁΩ≤Âà∞ Sealos </strong></summary>\n<div>\n\n> Sealos ÁöÑÊúçÂä°Âô®Âú®ÂõΩÂ§ñÔºå‰∏çÈúÄË¶ÅÈ¢ùÂ§ñÂ§ÑÁêÜÁΩëÁªúÈóÆÈ¢òÔºåÊîØÊåÅÈ´òÂπ∂Âèë & Âä®ÊÄÅ‰º∏Áº©„ÄÇ\n\nÁÇπÂáª‰ª•‰∏ãÊåâÈíÆ‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºàÈÉ®ÁΩ≤ÂêéËÆøÈóÆÂá∫Áé∞ 404 ËØ∑Á≠âÂæÖ 3~5 ÂàÜÈíüÔºâÔºö\n\n[![Deploy-on-Sealos.svg](https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg)](https://cloud.sealos.io/?openapp=system-fastdeploy?templateName=one-api)\n\n</div>\n</details>\n\n<details>\n<summary><strong>ÈÉ®ÁΩ≤Âà∞ Zeabur</strong></summary>\n<div>\n\n> Zeabur ÁöÑÊúçÂä°Âô®Âú®ÂõΩÂ§ñÔºåËá™Âä®Ëß£ÂÜ≥‰∫ÜÁΩëÁªúÁöÑÈóÆÈ¢òÔºåÂêåÊó∂ÂÖçË¥πÁöÑÈ¢ùÂ∫¶‰πüË∂≥Â§ü‰∏™‰∫∫‰ΩøÁî®\n\n[![Deploy on Zeabur](https://zeabur.com/button.svg)](https://zeabur.com/templates/7Q0KO3)\n\n1. È¶ñÂÖà fork ‰∏Ä‰ªΩ‰ª£Á†Å„ÄÇ\n2. ËøõÂÖ• [Zeabur](https://zeabur.com?referralCode=songquanpeng)ÔºåÁôªÂΩïÔºåËøõÂÖ•ÊéßÂà∂Âè∞„ÄÇ\n3. Êñ∞Âª∫‰∏Ä‰∏™ ProjectÔºåÂú® Service -> Add Service ÈÄâÊã© MarketplaceÔºåÈÄâÊã© MySQLÔºåÂπ∂ËÆ∞‰∏ãËøûÊé•ÂèÇÊï∞ÔºàÁî®Êà∑Âêç„ÄÅÂØÜÁ†Å„ÄÅÂú∞ÂùÄ„ÄÅÁ´ØÂè£Ôºâ„ÄÇ\n4. Â§çÂà∂ÈìæÊé•ÂèÇÊï∞ÔºåËøêË°å ```create database `one-api` ``` ÂàõÂª∫Êï∞ÊçÆÂ∫ì„ÄÇ\n5. ÁÑ∂ÂêéÂú® Service -> Add ServiceÔºåÈÄâÊã© GitÔºàÁ¨¨‰∏ÄÊ¨°‰ΩøÁî®ÈúÄË¶ÅÂÖàÊéàÊùÉÔºâÔºåÈÄâÊã©‰Ω† fork ÁöÑ‰ªìÂ∫ì„ÄÇ\n6. Deploy ‰ºöËá™Âä®ÂºÄÂßãÔºåÂÖàÂèñÊ∂à„ÄÇËøõÂÖ•‰∏ãÊñπ VariableÔºåÊ∑ªÂä†‰∏Ä‰∏™ `PORT`ÔºåÂÄº‰∏∫ `3000`ÔºåÂÜçÊ∑ªÂä†‰∏Ä‰∏™ `SQL_DSN`ÔºåÂÄº‰∏∫ `<username>:<password>@tcp(<addr>:<port>)/one-api` ÔºåÁÑ∂Âêé‰øùÂ≠ò„ÄÇ Ê≥®ÊÑèÂ¶ÇÊûú‰∏çÂ°´ÂÜô `SQL_DSN`ÔºåÊï∞ÊçÆÂ∞ÜÊó†Ê≥ïÊåÅ‰πÖÂåñÔºåÈáçÊñ∞ÈÉ®ÁΩ≤ÂêéÊï∞ÊçÆ‰ºö‰∏¢Â§±„ÄÇ\n7. ÈÄâÊã© Redeploy„ÄÇ\n8. ËøõÂÖ•‰∏ãÊñπ DomainsÔºåÈÄâÊã©‰∏Ä‰∏™ÂêàÈÄÇÁöÑÂüüÂêçÂâçÁºÄÔºåÂ¶Ç \"my-one-api\"ÔºåÊúÄÁªàÂüüÂêç‰∏∫ \"my-one-api.zeabur.app\"Ôºå‰πüÂèØ‰ª• CNAME Ëá™Â∑±ÁöÑÂüüÂêç„ÄÇ\n9. Á≠âÂæÖÈÉ®ÁΩ≤ÂÆåÊàêÔºåÁÇπÂáªÁîüÊàêÁöÑÂüüÂêçËøõÂÖ• One API„ÄÇ\n\n</div>\n</details>\n\n<details>\n<summary><strong>ÈÉ®ÁΩ≤Âà∞ Render</strong></summary>\n<div>\n\n> Render Êèê‰æõÂÖçË¥πÈ¢ùÂ∫¶ÔºåÁªëÂç°ÂêéÂèØ‰ª•Ëøõ‰∏ÄÊ≠•ÊèêÂçáÈ¢ùÂ∫¶\n\nRender ÂèØ‰ª•Áõ¥Êé•ÈÉ®ÁΩ≤ docker ÈïúÂÉèÔºå‰∏çÈúÄË¶Å fork ‰ªìÂ∫ìÔºöhttps://dashboard.render.com\n\n</div>\n</details>\n\n## ÈÖçÁΩÆ\nÁ≥ªÁªüÊú¨Ë∫´ÂºÄÁÆ±Âç≥Áî®„ÄÇ\n\n‰Ω†ÂèØ‰ª•ÈÄöËøáËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÊàñËÄÖÂëΩ‰ª§Ë°åÂèÇÊï∞ËøõË°åÈÖçÁΩÆ„ÄÇ\n\nÁ≠âÂà∞Á≥ªÁªüÂêØÂä®ÂêéÔºå‰ΩøÁî® `root` Áî®Êà∑ÁôªÂΩïÁ≥ªÁªüÂπ∂ÂÅöËøõ‰∏ÄÊ≠•ÁöÑÈÖçÁΩÆ„ÄÇ\n\n**Note**ÔºöÂ¶ÇÊûú‰Ω†‰∏çÁü•ÈÅìÊüê‰∏™ÈÖçÁΩÆÈ°πÁöÑÂê´‰πâÔºåÂèØ‰ª•‰∏¥Êó∂Âà†ÊéâÂÄº‰ª•ÁúãÂà∞Ëøõ‰∏ÄÊ≠•ÁöÑÊèêÁ§∫ÊñáÂ≠ó„ÄÇ\n\n## ‰ΩøÁî®ÊñπÊ≥ï\nÂú®`Ê∏†ÈÅì`È°µÈù¢‰∏≠Ê∑ªÂä†‰Ω†ÁöÑ API KeyÔºå‰πãÂêéÂú®`‰ª§Áâå`È°µÈù¢‰∏≠Êñ∞Â¢ûËÆøÈóÆ‰ª§Áâå„ÄÇ\n\n‰πãÂêéÂ∞±ÂèØ‰ª•‰ΩøÁî®‰Ω†ÁöÑ‰ª§ÁâåËÆøÈóÆ One API ‰∫ÜÔºå‰ΩøÁî®ÊñπÂºè‰∏é [OpenAI API](https://platform.openai.com/docs/api-reference/introduction) ‰∏ÄËá¥„ÄÇ\n\n‰Ω†ÈúÄË¶ÅÂú®ÂêÑÁßçÁî®Âà∞ OpenAI API ÁöÑÂú∞ÊñπËÆæÁΩÆ API Base ‰∏∫‰Ω†ÁöÑ One API ÁöÑÈÉ®ÁΩ≤Âú∞ÂùÄÔºå‰æãÂ¶ÇÔºö`https://openai.justsong.cn`ÔºåAPI Key Âàô‰∏∫‰Ω†Âú® One API ‰∏≠ÁîüÊàêÁöÑ‰ª§Áâå„ÄÇ\n\nÊ≥®ÊÑèÔºåÂÖ∑‰ΩìÁöÑ API Base ÁöÑÊ†ºÂºèÂèñÂÜ≥‰∫é‰Ω†ÊâÄ‰ΩøÁî®ÁöÑÂÆ¢Êà∑Á´Ø„ÄÇ\n\n‰æãÂ¶ÇÂØπ‰∫é OpenAI ÁöÑÂÆòÊñπÂ∫ìÔºö\n```bash\nOPENAI_API_KEY=\"sk-xxxxxx\"\nOPENAI_API_BASE=\"https://<HOST>:<PORT>/v1\"\n```\n\n```mermaid\ngraph LR\n    A(Áî®Êà∑)\n    A --->|‰ΩøÁî® One API ÂàÜÂèëÁöÑ key ËøõË°åËØ∑Ê±Ç| B(One API)\n    B -->|‰∏≠ÁªßËØ∑Ê±Ç| C(OpenAI)\n    B -->|‰∏≠ÁªßËØ∑Ê±Ç| D(Azure)\n    B -->|‰∏≠ÁªßËØ∑Ê±Ç| E(ÂÖ∂‰ªñ OpenAI API Ê†ºÂºè‰∏ãÊ∏∏Ê∏†ÈÅì)\n    B -->|‰∏≠ÁªßÂπ∂‰øÆÊîπËØ∑Ê±Ç‰ΩìÂíåËøîÂõû‰Ωì| F(Èùû OpenAI API Ê†ºÂºè‰∏ãÊ∏∏Ê∏†ÈÅì)\n```\n\nÂèØ‰ª•ÈÄöËøáÂú®‰ª§ÁâåÂêéÈù¢Ê∑ªÂä†Ê∏†ÈÅì ID ÁöÑÊñπÂºèÊåáÂÆö‰ΩøÁî®Âì™‰∏Ä‰∏™Ê∏†ÈÅìÂ§ÑÁêÜÊú¨Ê¨°ËØ∑Ê±ÇÔºå‰æãÂ¶ÇÔºö`Authorization: Bearer ONE_API_KEY-CHANNEL_ID`„ÄÇ\nÊ≥®ÊÑèÔºåÈúÄË¶ÅÊòØÁÆ°ÁêÜÂëòÁî®Êà∑ÂàõÂª∫ÁöÑ‰ª§ÁâåÊâçËÉΩÊåáÂÆöÊ∏†ÈÅì ID„ÄÇ\n\n‰∏çÂä†ÁöÑËØùÂ∞Ü‰ºö‰ΩøÁî®Ë¥üËΩΩÂùáË°°ÁöÑÊñπÂºè‰ΩøÁî®Â§ö‰∏™Ê∏†ÈÅì„ÄÇ\n\n### ÁéØÂ¢ÉÂèòÈáè\n> One API ÊîØÊåÅ‰ªé `.env` Êñá‰ª∂‰∏≠ËØªÂèñÁéØÂ¢ÉÂèòÈáèÔºåËØ∑ÂèÇÁÖß `.env.example` Êñá‰ª∂Ôºå‰ΩøÁî®Êó∂ËØ∑Â∞ÜÂÖ∂ÈáçÂëΩÂêç‰∏∫ `.env`„ÄÇ\n1. `REDIS_CONN_STRING`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞Ü‰ΩøÁî® Redis ‰Ωú‰∏∫ÁºìÂ≠ò‰ΩøÁî®„ÄÇ\n   + ‰æãÂ≠êÔºö`REDIS_CONN_STRING=redis://default:redispw@localhost:49153`\n   + Â¶ÇÊûúÊï∞ÊçÆÂ∫ìËÆøÈóÆÂª∂ËøüÂæà‰ΩéÔºåÊ≤°ÊúâÂøÖË¶ÅÂêØÁî® RedisÔºåÂêØÁî®ÂêéÂèçËÄå‰ºöÂá∫Áé∞Êï∞ÊçÆÊªûÂêéÁöÑÈóÆÈ¢ò„ÄÇ\n   + Â¶ÇÊûúÈúÄË¶Å‰ΩøÁî®Âì®ÂÖµÊàñËÄÖÈõÜÁæ§Ê®°ÂºèÔºö\n     + ÂàôÈúÄË¶ÅÊääËØ•ÁéØÂ¢ÉÂèòÈáèËÆæÁΩÆ‰∏∫ËäÇÁÇπÂàóË°®Ôºå‰æãÂ¶ÇÔºö`localhost:49153,localhost:49154,localhost:49155`„ÄÇ\n     + Èô§Ê≠§‰πãÂ§ñËøòÈúÄË¶ÅËÆæÁΩÆ‰ª•‰∏ãÁéØÂ¢ÉÂèòÈáèÔºö\n       + `REDIS_PASSWORD`ÔºöRedis ÈõÜÁæ§ÊàñËÄÖÂì®ÂÖµÊ®°Âºè‰∏ãÁöÑÂØÜÁ†ÅËÆæÁΩÆ„ÄÇ\n       + `REDIS_MASTER_NAME`ÔºöRedis Âì®ÂÖµÊ®°Âºè‰∏ã‰∏ªËäÇÁÇπÁöÑÂêçÁß∞„ÄÇ\n2. `SESSION_SECRET`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞Ü‰ΩøÁî®Âõ∫ÂÆöÁöÑ‰ºöËØùÂØÜÈí•ÔºåËøôÊ†∑Á≥ªÁªüÈáçÊñ∞ÂêØÂä®ÂêéÂ∑≤ÁôªÂΩïÁî®Êà∑ÁöÑ cookie Â∞Ü‰æùÊóßÊúâÊïà„ÄÇ\n   + ‰æãÂ≠êÔºö`SESSION_SECRET=random_string`\n3. `SQL_DSN`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞Ü‰ΩøÁî®ÊåáÂÆöÊï∞ÊçÆÂ∫ìËÄåÈùû SQLiteÔºåËØ∑‰ΩøÁî® MySQL Êàñ PostgreSQL„ÄÇ\n   + ‰æãÂ≠êÔºö\n     + MySQLÔºö`SQL_DSN=root:123456@tcp(localhost:3306)/oneapi`\n     + PostgreSQLÔºö`SQL_DSN=postgres://postgres:123456@localhost:5432/oneapi`ÔºàÈÄÇÈÖç‰∏≠ÔºåÊ¨¢ËøéÂèçÈ¶àÔºâ\n   + Ê≥®ÊÑèÈúÄË¶ÅÊèêÂâçÂª∫Á´ãÊï∞ÊçÆÂ∫ì `oneapi`ÔºåÊó†ÈúÄÊâãÂä®Âª∫Ë°®ÔºåÁ®ãÂ∫èÂ∞ÜËá™Âä®Âª∫Ë°®„ÄÇ\n   + Â¶ÇÊûú‰ΩøÁî®Êú¨Âú∞Êï∞ÊçÆÂ∫ìÔºöÈÉ®ÁΩ≤ÂëΩ‰ª§ÂèØÊ∑ªÂä† `--network=\"host\"` ‰ª•‰ΩøÂæóÂÆπÂô®ÂÜÖÁöÑÁ®ãÂ∫èÂèØ‰ª•ËÆøÈóÆÂà∞ÂÆø‰∏ªÊú∫‰∏äÁöÑ MySQL„ÄÇ\n   + Â¶ÇÊûú‰ΩøÁî®‰∫ëÊï∞ÊçÆÂ∫ìÔºöÂ¶ÇÊûú‰∫ëÊúçÂä°Âô®ÈúÄË¶ÅÈ™åËØÅË∫´‰ªΩÔºåÈúÄË¶ÅÂú®ËøûÊé•ÂèÇÊï∞‰∏≠Ê∑ªÂä† `?tls=skip-verify`„ÄÇ\n   + ËØ∑Ê†πÊçÆ‰Ω†ÁöÑÊï∞ÊçÆÂ∫ìÈÖçÁΩÆ‰øÆÊîπ‰∏ãÂàóÂèÇÊï∞ÔºàÊàñËÄÖ‰øùÊåÅÈªòËÆ§ÂÄºÔºâÔºö\n     + `SQL_MAX_IDLE_CONNS`ÔºöÊúÄÂ§ßÁ©∫Èó≤ËøûÊé•Êï∞ÔºåÈªòËÆ§‰∏∫ `100`„ÄÇ\n     + `SQL_MAX_OPEN_CONNS`ÔºöÊúÄÂ§ßÊâìÂºÄËøûÊé•Êï∞ÔºåÈªòËÆ§‰∏∫ `1000`„ÄÇ\n       + Â¶ÇÊûúÊä•Èîô `Error 1040: Too many connections`ÔºåËØ∑ÈÄÇÂΩìÂáèÂ∞èËØ•ÂÄº„ÄÇ\n     + `SQL_CONN_MAX_LIFETIME`ÔºöËøûÊé•ÁöÑÊúÄÂ§ßÁîüÂëΩÂë®ÊúüÔºåÈªòËÆ§‰∏∫ `60`ÔºåÂçï‰ΩçÂàÜÈíü„ÄÇ\n4. `LOG_SQL_DSN`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞Ü‰∏∫ `logs` Ë°®‰ΩøÁî®Áã¨Á´ãÁöÑÊï∞ÊçÆÂ∫ìÔºåËØ∑‰ΩøÁî® MySQL Êàñ PostgreSQL„ÄÇ\n5. `FRONTEND_BASE_URL`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÈáçÂÆöÂêëÈ°µÈù¢ËØ∑Ê±ÇÂà∞ÊåáÂÆöÁöÑÂú∞ÂùÄÔºå‰ªÖÈôê‰ªéÊúçÂä°Âô®ËÆæÁΩÆ„ÄÇ\n   + ‰æãÂ≠êÔºö`FRONTEND_BASE_URL=https://openai.justsong.cn`\n6. `MEMORY_CACHE_ENABLED`ÔºöÂêØÁî®ÂÜÖÂ≠òÁºìÂ≠òÔºå‰ºöÂØºËá¥Áî®Êà∑È¢ùÂ∫¶ÁöÑÊõ¥Êñ∞Â≠òÂú®‰∏ÄÂÆöÁöÑÂª∂ËøüÔºåÂèØÈÄâÂÄº‰∏∫ `true` Âíå `false`ÔºåÊú™ËÆæÁΩÆÂàôÈªòËÆ§‰∏∫ `false`„ÄÇ\n   + ‰æãÂ≠êÔºö`MEMORY_CACHE_ENABLED=true`\n7. `SYNC_FREQUENCY`ÔºöÂú®ÂêØÁî®ÁºìÂ≠òÁöÑÊÉÖÂÜµ‰∏ã‰∏éÊï∞ÊçÆÂ∫ìÂêåÊ≠•ÈÖçÁΩÆÁöÑÈ¢ëÁéáÔºåÂçï‰Ωç‰∏∫ÁßíÔºåÈªòËÆ§‰∏∫ `600` Áßí„ÄÇ\n   + ‰æãÂ≠êÔºö`SYNC_FREQUENCY=60`\n8. `NODE_TYPE`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÊåáÂÆöËäÇÁÇπÁ±ªÂûãÔºåÂèØÈÄâÂÄº‰∏∫ `master` Âíå `slave`ÔºåÊú™ËÆæÁΩÆÂàôÈªòËÆ§‰∏∫ `master`„ÄÇ\n   + ‰æãÂ≠êÔºö`NODE_TYPE=slave`\n9. `CHANNEL_UPDATE_FREQUENCY`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÂÆöÊúüÊõ¥Êñ∞Ê∏†ÈÅì‰ΩôÈ¢ùÔºåÂçï‰Ωç‰∏∫ÂàÜÈíüÔºåÊú™ËÆæÁΩÆÂàô‰∏çËøõË°åÊõ¥Êñ∞„ÄÇ\n   + ‰æãÂ≠êÔºö`CHANNEL_UPDATE_FREQUENCY=1440`\n10. `CHANNEL_TEST_FREQUENCY`ÔºöËÆæÁΩÆ‰πãÂêéÂ∞ÜÂÆöÊúüÊ£ÄÊü•Ê∏†ÈÅìÔºåÂçï‰Ωç‰∏∫ÂàÜÈíüÔºåÊú™ËÆæÁΩÆÂàô‰∏çËøõË°åÊ£ÄÊü•„ÄÇ \n   +‰æãÂ≠êÔºö`CHANNEL_TEST_FREQUENCY=1440`\n11. `POLLING_INTERVAL`ÔºöÊâπÈáèÊõ¥Êñ∞Ê∏†ÈÅì‰ΩôÈ¢ù‰ª•ÂèäÊµãËØïÂèØÁî®ÊÄßÊó∂ÁöÑËØ∑Ê±ÇÈó¥ÈöîÔºåÂçï‰Ωç‰∏∫ÁßíÔºåÈªòËÆ§Êó†Èó¥Èöî„ÄÇ\n    + ‰æãÂ≠êÔºö`POLLING_INTERVAL=5`\n12. `BATCH_UPDATE_ENABLED`ÔºöÂêØÁî®Êï∞ÊçÆÂ∫ìÊâπÈáèÊõ¥Êñ∞ËÅöÂêàÔºå‰ºöÂØºËá¥Áî®Êà∑È¢ùÂ∫¶ÁöÑÊõ¥Êñ∞Â≠òÂú®‰∏ÄÂÆöÁöÑÂª∂ËøüÂèØÈÄâÂÄº‰∏∫ `true` Âíå `false`ÔºåÊú™ËÆæÁΩÆÂàôÈªòËÆ§‰∏∫ `false`„ÄÇ\n    + ‰æãÂ≠êÔºö`BATCH_UPDATE_ENABLED=true`\n    + Â¶ÇÊûú‰Ω†ÈÅáÂà∞‰∫ÜÊï∞ÊçÆÂ∫ìËøûÊé•Êï∞ËøáÂ§öÁöÑÈóÆÈ¢òÔºåÂèØ‰ª•Â∞ùËØïÂêØÁî®ËØ•ÈÄâÈ°π„ÄÇ\n13. `BATCH_UPDATE_INTERVAL=5`ÔºöÊâπÈáèÊõ¥Êñ∞ËÅöÂêàÁöÑÊó∂Èó¥Èó¥ÈöîÔºåÂçï‰Ωç‰∏∫ÁßíÔºåÈªòËÆ§‰∏∫ `5`„ÄÇ\n    + ‰æãÂ≠êÔºö`BATCH_UPDATE_INTERVAL=5`\n14. ËØ∑Ê±ÇÈ¢ëÁéáÈôêÂà∂Ôºö\n    + `GLOBAL_API_RATE_LIMIT`ÔºöÂÖ®Â±Ä API ÈÄüÁéáÈôêÂà∂ÔºàÈô§‰∏≠ÁªßËØ∑Ê±ÇÂ§ñÔºâÔºåÂçï ip ‰∏âÂàÜÈíüÂÜÖÁöÑÊúÄÂ§ßËØ∑Ê±ÇÊï∞ÔºåÈªòËÆ§‰∏∫ `180`„ÄÇ\n    + `GLOBAL_WEB_RATE_LIMIT`ÔºöÂÖ®Â±Ä Web ÈÄüÁéáÈôêÂà∂ÔºåÂçï ip ‰∏âÂàÜÈíüÂÜÖÁöÑÊúÄÂ§ßËØ∑Ê±ÇÊï∞ÔºåÈªòËÆ§‰∏∫ `60`„ÄÇ\n15. ÁºñÁ†ÅÂô®ÁºìÂ≠òËÆæÁΩÆÔºö\n    + `TIKTOKEN_CACHE_DIR`ÔºöÈªòËÆ§Á®ãÂ∫èÂêØÂä®Êó∂‰ºöËÅîÁΩë‰∏ãËΩΩ‰∏Ä‰∫õÈÄöÁî®ÁöÑËØçÂÖÉÁöÑÁºñÁ†ÅÔºåÂ¶ÇÔºö`gpt-3.5-turbo`ÔºåÂú®‰∏Ä‰∫õÁΩëÁªúÁéØÂ¢É‰∏çÁ®≥ÂÆöÔºåÊàñËÄÖÁ¶ªÁ∫øÊÉÖÂÜµÔºåÂèØËÉΩ‰ºöÂØºËá¥ÂêØÂä®ÊúâÈóÆÈ¢òÔºåÂèØ‰ª•ÈÖçÁΩÆÊ≠§ÁõÆÂΩïÁºìÂ≠òÊï∞ÊçÆÔºåÂèØËøÅÁßªÂà∞Á¶ªÁ∫øÁéØÂ¢É„ÄÇ\n    + `DATA_GYM_CACHE_DIR`ÔºöÁõÆÂâçËØ•ÈÖçÁΩÆ‰ΩúÁî®‰∏é `TIKTOKEN_CACHE_DIR` ‰∏ÄËá¥Ôºå‰ΩÜÊòØ‰ºòÂÖàÁ∫ßÊ≤°ÊúâÂÆÉÈ´ò„ÄÇ\n16. `RELAY_TIMEOUT`Ôºö‰∏≠ÁªßË∂ÖÊó∂ËÆæÁΩÆÔºåÂçï‰Ωç‰∏∫ÁßíÔºåÈªòËÆ§‰∏çËÆæÁΩÆË∂ÖÊó∂Êó∂Èó¥„ÄÇ\n17. `RELAY_PROXY`ÔºöËÆæÁΩÆÂêé‰ΩøÁî®ËØ•‰ª£ÁêÜÊù•ËØ∑Ê±Ç API„ÄÇ\n18. `USER_CONTENT_REQUEST_TIMEOUT`ÔºöÁî®Êà∑‰∏ä‰º†ÂÜÖÂÆπ‰∏ãËΩΩË∂ÖÊó∂Êó∂Èó¥ÔºåÂçï‰Ωç‰∏∫Áßí„ÄÇ\n19. `USER_CONTENT_REQUEST_PROXY`ÔºöËÆæÁΩÆÂêé‰ΩøÁî®ËØ•‰ª£ÁêÜÊù•ËØ∑Ê±ÇÁî®Êà∑‰∏ä‰º†ÁöÑÂÜÖÂÆπÔºå‰æãÂ¶ÇÂõæÁâá„ÄÇ\n20. `SQLITE_BUSY_TIMEOUT`ÔºöSQLite ÈîÅÁ≠âÂæÖË∂ÖÊó∂ËÆæÁΩÆÔºåÂçï‰Ωç‰∏∫ÊØ´ÁßíÔºåÈªòËÆ§ `3000`„ÄÇ\n21. `GEMINI_SAFETY_SETTING`ÔºöGemini ÁöÑÂÆâÂÖ®ËÆæÁΩÆÔºåÈªòËÆ§ `BLOCK_NONE`„ÄÇ\n22. `GEMINI_VERSION`ÔºöOne API ÊâÄ‰ΩøÁî®ÁöÑ Gemini ÁâàÊú¨ÔºåÈªòËÆ§‰∏∫ `v1`„ÄÇ\n23. `THEME`ÔºöÁ≥ªÁªüÁöÑ‰∏ªÈ¢òËÆæÁΩÆÔºåÈªòËÆ§‰∏∫ `default`ÔºåÂÖ∑‰ΩìÂèØÈÄâÂÄºÂèÇËÄÉ[Ê≠§Â§Ñ](./web/README.md)„ÄÇ\n24. `ENABLE_METRIC`ÔºöÊòØÂê¶Ê†πÊçÆËØ∑Ê±ÇÊàêÂäüÁéáÁ¶ÅÁî®Ê∏†ÈÅìÔºåÈªòËÆ§‰∏çÂºÄÂêØÔºåÂèØÈÄâÂÄº‰∏∫ `true` Âíå `false`„ÄÇ\n25. `METRIC_QUEUE_SIZE`ÔºöËØ∑Ê±ÇÊàêÂäüÁéáÁªüËÆ°ÈòüÂàóÂ§ßÂ∞èÔºåÈªòËÆ§‰∏∫ `10`„ÄÇ\n26. `METRIC_SUCCESS_RATE_THRESHOLD`ÔºöËØ∑Ê±ÇÊàêÂäüÁéáÈòàÂÄºÔºåÈªòËÆ§‰∏∫ `0.8`„ÄÇ\n27. `INITIAL_ROOT_TOKEN`ÔºöÂ¶ÇÊûúËÆæÁΩÆ‰∫ÜËØ•ÂÄºÔºåÂàôÂú®Á≥ªÁªüÈ¶ñÊ¨°ÂêØÂä®Êó∂‰ºöËá™Âä®ÂàõÂª∫‰∏Ä‰∏™ÂÄº‰∏∫ËØ•ÁéØÂ¢ÉÂèòÈáèÂÄºÁöÑ root Áî®Êà∑‰ª§Áâå„ÄÇ\n28. `INITIAL_ROOT_ACCESS_TOKEN`ÔºöÂ¶ÇÊûúËÆæÁΩÆ‰∫ÜËØ•ÂÄºÔºåÂàôÂú®Á≥ªÁªüÈ¶ñÊ¨°ÂêØÂä®Êó∂‰ºöËá™Âä®ÂàõÂª∫‰∏Ä‰∏™ÂÄº‰∏∫ËØ•ÁéØÂ¢ÉÂèòÈáèÁöÑ root Áî®Êà∑ÂàõÂª∫Á≥ªÁªüÁÆ°ÁêÜ‰ª§Áâå„ÄÇ\n29. `ENFORCE_INCLUDE_USAGE`ÔºöÊòØÂê¶Âº∫Âà∂Âú® stream Ê®°Âûã‰∏ãËøîÂõû usageÔºåÈªòËÆ§‰∏çÂºÄÂêØÔºåÂèØÈÄâÂÄº‰∏∫ `true` Âíå `false`„ÄÇ\n30. `TEST_PROMPT`ÔºöÊµãËØïÊ®°ÂûãÊó∂ÁöÑÁî®Êà∑ promptÔºåÈªòËÆ§‰∏∫ `Print your model name exactly and do not output without any other text.`„ÄÇ\n\n### ÂëΩ‰ª§Ë°åÂèÇÊï∞\n1. `--port <port_number>`: ÊåáÂÆöÊúçÂä°Âô®ÁõëÂê¨ÁöÑÁ´ØÂè£Âè∑ÔºåÈªòËÆ§‰∏∫ `3000`„ÄÇ\n   + ‰æãÂ≠êÔºö`--port 3000`\n2. `--log-dir <log_dir>`: ÊåáÂÆöÊó•ÂøóÊñá‰ª∂Â§πÔºåÂ¶ÇÊûúÊ≤°ÊúâËÆæÁΩÆÔºåÈªòËÆ§‰øùÂ≠òËá≥Â∑•‰ΩúÁõÆÂΩïÁöÑ `logs` Êñá‰ª∂Â§π‰∏ã„ÄÇ\n   + ‰æãÂ≠êÔºö`--log-dir ./logs`\n3. `--version`: ÊâìÂç∞Á≥ªÁªüÁâàÊú¨Âè∑Âπ∂ÈÄÄÂá∫„ÄÇ\n4. `--help`: Êü•ÁúãÂëΩ‰ª§ÁöÑ‰ΩøÁî®Â∏ÆÂä©ÂíåÂèÇÊï∞ËØ¥Êòé„ÄÇ\n\n## ÊºîÁ§∫\n### Âú®Á∫øÊºîÁ§∫\nÊ≥®ÊÑèÔºåËØ•ÊºîÁ§∫Á´ô‰∏çÊèê‰æõÂØπÂ§ñÊúçÂä°Ôºö\nhttps://openai.justsong.cn\n\n### Êà™ÂõæÂ±ïÁ§∫\n![channel](https://user-images.githubusercontent.com/39998050/233837954-ae6683aa-5c4f-429f-a949-6645a83c9490.png)\n![token](https://user-images.githubusercontent.com/39998050/233837971-dab488b7-6d96-43af-b640-a168e8d1c9bf.png)\n\n## Â∏∏ËßÅÈóÆÈ¢ò\n1. È¢ùÂ∫¶ÊòØ‰ªÄ‰πàÔºüÊÄé‰πàËÆ°ÁÆóÁöÑÔºüOne API ÁöÑÈ¢ùÂ∫¶ËÆ°ÁÆóÊúâÈóÆÈ¢òÔºü\n   + È¢ùÂ∫¶ = ÂàÜÁªÑÂÄçÁéá * Ê®°ÂûãÂÄçÁéá * ÔºàÊèêÁ§∫ token Êï∞ + Ë°•ÂÖ® token Êï∞ * Ë°•ÂÖ®ÂÄçÁéáÔºâ\n   + ÂÖ∂‰∏≠Ë°•ÂÖ®ÂÄçÁéáÂØπ‰∫é GPT3.5 Âõ∫ÂÆö‰∏∫ 1.33ÔºåGPT4 ‰∏∫ 2Ôºå‰∏éÂÆòÊñπ‰øùÊåÅ‰∏ÄËá¥„ÄÇ\n   + Â¶ÇÊûúÊòØÈùûÊµÅÊ®°ÂºèÔºåÂÆòÊñπÊé•Âè£‰ºöËøîÂõûÊ∂àËÄóÁöÑÊÄª tokenÔºå‰ΩÜÊòØ‰Ω†Ë¶ÅÊ≥®ÊÑèÊèêÁ§∫ÂíåË°•ÂÖ®ÁöÑÊ∂àËÄóÂÄçÁéá‰∏ç‰∏ÄÊ†∑„ÄÇ\n   + Ê≥®ÊÑèÔºåOne API ÁöÑÈªòËÆ§ÂÄçÁéáÂ∞±ÊòØÂÆòÊñπÂÄçÁéáÔºåÊòØÂ∑≤ÁªèË∞ÉÊï¥ËøáÁöÑ„ÄÇ\n2. Ë¥¶Êà∑È¢ùÂ∫¶Ë∂≥Â§ü‰∏∫‰ªÄ‰πàÊèêÁ§∫È¢ùÂ∫¶‰∏çË∂≥Ôºü\n   + ËØ∑Ê£ÄÊü•‰Ω†ÁöÑ‰ª§ÁâåÈ¢ùÂ∫¶ÊòØÂê¶Ë∂≥Â§üÔºåËøô‰∏™ÂíåË¥¶Êà∑È¢ùÂ∫¶ÊòØÂàÜÂºÄÁöÑ„ÄÇ\n   + ‰ª§ÁâåÈ¢ùÂ∫¶‰ªÖ‰æõÁî®Êà∑ËÆæÁΩÆÊúÄÂ§ß‰ΩøÁî®ÈáèÔºåÁî®Êà∑ÂèØËá™Áî±ËÆæÁΩÆ„ÄÇ\n3. ÊèêÁ§∫Êó†ÂèØÁî®Ê∏†ÈÅìÔºü\n   + ËØ∑Ê£ÄÊü•ÁöÑÁî®Êà∑ÂàÜÁªÑÂíåÊ∏†ÈÅìÂàÜÁªÑËÆæÁΩÆ„ÄÇ\n   + ‰ª•ÂèäÊ∏†ÈÅìÁöÑÊ®°ÂûãËÆæÁΩÆ„ÄÇ\n4. Ê∏†ÈÅìÊµãËØïÊä•ÈîôÔºö`invalid character '<' looking for beginning of value`\n   + ËøôÊòØÂõ†‰∏∫ËøîÂõûÂÄº‰∏çÊòØÂêàÊ≥ïÁöÑ JSONÔºåËÄåÊòØ‰∏Ä‰∏™ HTML È°µÈù¢„ÄÇ\n   + Â§ßÊ¶ÇÁéáÊòØ‰Ω†ÁöÑÈÉ®ÁΩ≤Á´ôÁöÑ IP Êàñ‰ª£ÁêÜÁöÑËäÇÁÇπË¢´ CloudFlare Â∞ÅÁ¶Å‰∫Ü„ÄÇ\n5. ChatGPT Next Web Êä•ÈîôÔºö`Failed to fetch`\n   + ÈÉ®ÁΩ≤ÁöÑÊó∂ÂÄô‰∏çË¶ÅËÆæÁΩÆ `BASE_URL`„ÄÇ\n   + Ê£ÄÊü•‰Ω†ÁöÑÊé•Âè£Âú∞ÂùÄÂíå API Key ÊúâÊ≤°ÊúâÂ°´ÂØπ„ÄÇ\n   + Ê£ÄÊü•ÊòØÂê¶ÂêØÁî®‰∫Ü HTTPSÔºåÊµèËßàÂô®‰ºöÊã¶Êà™ HTTPS ÂüüÂêç‰∏ãÁöÑ HTTP ËØ∑Ê±Ç„ÄÇ\n6. Êä•ÈîôÔºö`ÂΩìÂâçÂàÜÁªÑË¥üËΩΩÂ∑≤È•±ÂíåÔºåËØ∑Á®çÂêéÂÜçËØï`\n   + ‰∏äÊ∏∏Ê∏†ÈÅì 429 ‰∫Ü„ÄÇ\n7. ÂçáÁ∫ß‰πãÂêéÊàëÁöÑÊï∞ÊçÆ‰ºö‰∏¢Â§±ÂêóÔºü\n   + Â¶ÇÊûú‰ΩøÁî® MySQLÔºå‰∏ç‰ºö„ÄÇ\n   + Â¶ÇÊûú‰ΩøÁî® SQLiteÔºåÈúÄË¶ÅÊåâÁÖßÊàëÊâÄÁªôÁöÑÈÉ®ÁΩ≤ÂëΩ‰ª§ÊåÇËΩΩ volume ÊåÅ‰πÖÂåñ one-api.db Êï∞ÊçÆÂ∫ìÊñá‰ª∂ÔºåÂê¶ÂàôÂÆπÂô®ÈáçÂêØÂêéÊï∞ÊçÆ‰ºö‰∏¢Â§±„ÄÇ\n8. ÂçáÁ∫ß‰πãÂâçÊï∞ÊçÆÂ∫ìÈúÄË¶ÅÂÅöÂèòÊõ¥ÂêóÔºü\n   + ‰∏ÄËà¨ÊÉÖÂÜµ‰∏ã‰∏çÈúÄË¶ÅÔºåÁ≥ªÁªüÂ∞ÜÂú®ÂàùÂßãÂåñÁöÑÊó∂ÂÄôËá™Âä®Ë∞ÉÊï¥„ÄÇ\n   + Â¶ÇÊûúÈúÄË¶ÅÁöÑËØùÔºåÊàë‰ºöÂú®Êõ¥Êñ∞Êó•Âøó‰∏≠ËØ¥ÊòéÔºåÂπ∂ÁªôÂá∫ËÑöÊú¨„ÄÇ\n9. ÊâãÂä®‰øÆÊîπÊï∞ÊçÆÂ∫ìÂêéÊä•ÈîôÔºö`Êï∞ÊçÆÂ∫ì‰∏ÄËá¥ÊÄßÂ∑≤Ë¢´Á†¥ÂùèÔºåËØ∑ËÅîÁ≥ªÁÆ°ÁêÜÂëò`Ôºü\n   + ËøôÊòØÊ£ÄÊµãÂà∞ ability Ë°®ÈáåÊúâ‰∫õËÆ∞ÂΩïÁöÑÊ∏†ÈÅì id ÊòØ‰∏çÂ≠òÂú®ÁöÑÔºåËøôÂ§ßÊ¶ÇÁéáÊòØÂõ†‰∏∫‰Ω†Âà†‰∫Ü channel Ë°®ÈáåÁöÑËÆ∞ÂΩï‰ΩÜÊòØÊ≤°ÊúâÂêåÊ≠•Âú® ability Ë°®ÈáåÊ∏ÖÁêÜÊó†ÊïàÁöÑÊ∏†ÈÅì„ÄÇ\n   + ÂØπ‰∫éÊØè‰∏Ä‰∏™Ê∏†ÈÅìÔºåÂÖ∂ÊâÄÊîØÊåÅÁöÑÊ®°ÂûãÈÉΩÈúÄË¶ÅÊúâ‰∏Ä‰∏™‰∏ìÈó®ÁöÑ ability Ë°®ÁöÑËÆ∞ÂΩïÔºåË°®Á§∫ËØ•Ê∏†ÈÅìÊîØÊåÅËØ•Ê®°Âûã„ÄÇ\n\n## Áõ∏ÂÖ≥È°πÁõÆ\n* [FastGPT](https://github.com/labring/FastGPT): Âü∫‰∫é LLM Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÁü•ËØÜÂ∫ìÈóÆÁ≠îÁ≥ªÁªü\n* [ChatGPT Next Web](https://github.com/Yidadaa/ChatGPT-Next-Web):  ‰∏ÄÈîÆÊã•Êúâ‰Ω†Ëá™Â∑±ÁöÑË∑®Âπ≥Âè∞ ChatGPT Â∫îÁî®\n* [VChart](https://github.com/VisActor/VChart):  ‰∏çÂè™ÊòØÂºÄÁÆ±Âç≥Áî®ÁöÑÂ§öÁ´ØÂõæË°®Â∫ìÔºåÊõ¥ÊòØÁîüÂä®ÁÅµÊ¥ªÁöÑÊï∞ÊçÆÊïÖ‰∫ãËÆ≤Ëø∞ËÄÖ„ÄÇ\n* [VMind](https://github.com/VisActor/VMind):  ‰∏ç‰ªÖËá™Âä®ÔºåËøòÂæàÊô∫ËÉΩ„ÄÇÂºÄÊ∫êÊô∫ËÉΩÂèØËßÜÂåñËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n* [CherryStudio](https://github.com/CherryHQ/cherry-studio):  ÂÖ®Âπ≥Âè∞ÊîØÊåÅÁöÑAIÂÆ¢Êà∑Á´Ø, Â§öÊúçÂä°ÂïÜÈõÜÊàêÁÆ°ÁêÜ„ÄÅÊú¨Âú∞Áü•ËØÜÂ∫ìÊîØÊåÅ„ÄÇ\n\n## Ê≥®ÊÑè\n\nÊú¨È°πÁõÆ‰ΩøÁî® MIT ÂçèËÆÆËøõË°åÂºÄÊ∫êÔºå**Âú®Ê≠§Âü∫Á°Ä‰∏ä**ÔºåÂøÖÈ°ªÂú®È°µÈù¢Â∫ïÈÉ®‰øùÁïôÁΩ≤Âêç‰ª•ÂèäÊåáÂêëÊú¨È°πÁõÆÁöÑÈìæÊé•„ÄÇÂ¶ÇÊûú‰∏çÊÉ≥‰øùÁïôÁΩ≤ÂêçÔºåÂøÖÈ°ªÈ¶ñÂÖàËé∑ÂæóÊéàÊùÉ„ÄÇ\n\nÂêåÊ†∑ÈÄÇÁî®‰∫éÂü∫‰∫éÊú¨È°πÁõÆÁöÑ‰∫åÂºÄÈ°πÁõÆ„ÄÇ\n\n‰æùÊçÆ MIT ÂçèËÆÆÔºå‰ΩøÁî®ËÄÖÈúÄËá™Ë°åÊâøÊãÖ‰ΩøÁî®Êú¨È°πÁõÆÁöÑÈ£éÈô©‰∏éË¥£‰ªªÔºåÊú¨ÂºÄÊ∫êÈ°πÁõÆÂºÄÂèëËÄÖ‰∏éÊ≠§Êó†ÂÖ≥„ÄÇ\n",
      "stars_today": 29
    },
    {
      "id": 340181518,
      "name": "fastfetch",
      "full_name": "fastfetch-cli/fastfetch",
      "description": "A maintained, feature-rich and performance oriented, neofetch like system information tool.",
      "html_url": "https://github.com/fastfetch-cli/fastfetch",
      "stars": 19515,
      "forks": 664,
      "language": "C",
      "topics": [
        "bsdfetch",
        "command-line",
        "fastfetch",
        "fetch",
        "flashfetch",
        "hacktoberfest",
        "macfetch",
        "neofetch",
        "terminal",
        "winfetch"
      ],
      "created_at": "2021-02-18T21:25:19Z",
      "updated_at": "2026-01-23T00:49:41Z",
      "pushed_at": "2026-01-22T07:37:49Z",
      "open_issues": 44,
      "owner": {
        "login": "fastfetch-cli",
        "avatar_url": "https://avatars.githubusercontent.com/u/136235211?v=4"
      },
      "readme": "# Fastfetch\n\n[![GitHub Workflow Status (with event)](https://img.shields.io/github/actions/workflow/status/fastfetch-cli/fastfetch/ci.yml)](https://github.com/fastfetch-cli/fastfetch/actions)\n[![GitHub license](https://img.shields.io/github/license/fastfetch-cli/fastfetch)](https://github.com/fastfetch-cli/fastfetch/blob/dev/LICENSE)\n[![GitHub contributors](https://img.shields.io/github/contributors/fastfetch-cli/fastfetch)](https://github.com/fastfetch-cli/fastfetch/graphs/contributors)\n[![GitHub top language](https://img.shields.io/github/languages/top/fastfetch-cli/fastfetch?logo=c&label=)](https://github.com/fastfetch-cli/fastfetch/blob/dev/CMakeLists.txt#L5)\n[![GitHub commit activity (branch)](https://img.shields.io/github/commit-activity/m/fastfetch-cli/fastfetch)](https://github.com/fastfetch-cli/fastfetch/commits)  \n[![homebrew downloads](https://img.shields.io/homebrew/installs/dm/fastfetch?logo=homebrew)](https://formulae.brew.sh/formula/fastfetch#default)\n[![GitHub all releases](https://img.shields.io/github/downloads/fastfetch-cli/fastfetch/total?logo=github)](https://github.com/fastfetch-cli/fastfetch/releases)  \n[![GitHub release (with filter)](https://img.shields.io/github/v/release/fastfetch-cli/fastfetch?logo=github)](https://github.com/fastfetch-cli/fastfetch/releases)\n[![latest packaged version(s)](https://repology.org/badge/latest-versions/fastfetch.svg)](https://repology.org/project/fastfetch/versions)\n[![Packaging status](https://repology.org/badge/tiny-repos/fastfetch.svg)](https://repology.org/project/fastfetch/versions)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/fastfetch-cli/fastfetch)\n[![‰∏≠ÊñáREADME](https://img.shields.io/badge/%E4%B8%AD%E6%96%87-README-red)](README-cn.md)\n\nFastfetch is a [neofetch](https://github.com/dylanaraps/neofetch)-like tool for fetching system information and displaying it in a visually appealing way. It is written mainly in C, with a focus on performance and customizability. Currently, it supports Linux, macOS, Windows 7+, Android, FreeBSD, OpenBSD, NetBSD, DragonFly, Haiku, and illumos (SunOS).\n\n<img src=\"screenshots/example1.png\" width=\"49%\" align=\"left\" />\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/24/Transparent_Square_Tiles_Texture.png\" width=\"49%\" height=\"16px\" align=\"left\" />\n<img src=\"screenshots/example4.png\" width=\"49%\" align=\"left\" />\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/24/Transparent_Square_Tiles_Texture.png\" width=\"49%\" height=\"16px\" align=\"left\" />\n<img src=\"screenshots/example2.png\" width=\"48%\" align=\"top\" />\n<img src=\"screenshots/example3.png\" width=\"48%\" align=\"top\" />\n<img src=\"screenshots/example5.png\" height=\"15%\" align=\"top\" />\n\nAccording configuration files for examples are located [here](https://github.com/fastfetch-cli/fastfetch/tree/dev/presets/examples).\n\nThere are [screenshots on different platforms](https://github.com/fastfetch-cli/fastfetch/wiki).\n\n## Installation\n\n### Linux\n\nSome distributions package outdated versions of fastfetch. Older versions receive no support, so please always try to use the latest version.\n\n<a href=\"https://repology.org/project/fastfetch/versions\">\n    <img src=\"https://repology.org/badge/vertical-allrepos/fastfetch.svg?columns=2\" alt=\"Packaging status\" align=\"right\">\n</a>\n\n* Ubuntu: [`ppa:zhangsongcui3371/fastfetch`](https://launchpad.net/~zhangsongcui3371/+archive/ubuntu/fastfetch) (Ubuntu 22.04 or newer; latest version)\n* Debian / Ubuntu: `apt install fastfetch` (Debian 13 or newer; Ubuntu 25.04 or newer)\n* Debian / Ubuntu: Download `fastfetch-linux-<proper architecture>.deb` from [Github release page](https://github.com/fastfetch-cli/fastfetch/releases/latest) and double-click it (for Ubuntu 20.04 or newer and Debian 11 or newer).\n* Arch Linux: `pacman -S fastfetch`\n* Fedora: `dnf install fastfetch`\n* Gentoo: `emerge --ask app-misc/fastfetch`\n* Alpine: `apk add --upgrade fastfetch`\n* NixOS: `nix-shell -p fastfetch`\n* openSUSE: `zypper install fastfetch`\n* ALT Linux: `apt-get install fastfetch`\n* Exherbo: `cave resolve --execute app-misc/fastfetch`\n* Solus: `eopkg install fastfetch`\n* Slackware: `sbopkg -i fastfetch`\n* Void Linux: `xbps-install fastfetch`\n* Venom Linux: `scratch install fastfetch`\n\nYou may need `sudo`, `doas`, or `sup` to run these commands.\n\nIf fastfetch is not packaged for your distribution or an outdated version is packaged, [linuxbrew](https://brew.sh/) is a good alternative: `brew install fastfetch`\n\n### macOS\n\n* [Homebrew](https://formulae.brew.sh/formula/fastfetch#default): `brew install fastfetch`\n* [MacPorts](https://ports.macports.org/port/fastfetch/): `sudo port install fastfetch`\n\n### Windows\n\n* [scoop](https://scoop.sh/#/apps?q=fastfetch): `scoop install fastfetch`\n* [Chocolatey](https://community.chocolatey.org/packages/fastfetch): `choco install fastfetch`\n* [winget](https://github.com/microsoft/winget-pkgs/tree/master/manifests/f/Fastfetch-cli/Fastfetch): `winget install fastfetch`\n* [MSYS2 MinGW](https://packages.msys2.org/base/mingw-w64-fastfetch): `pacman -S mingw-w64-<subsystem>-<arch>-fastfetch`\n\nYou may also download the program directly from [the GitHub releases page](https://github.com/fastfetch-cli/fastfetch/releases/latest) in the form of an archive file.\n\n### BSD systems\n\n* FreeBSD: `pkg install fastfetch`\n* NetBSD: `pkgin in fastfetch`\n* OpenBSD: `pkg_add fastfetch` (Snapshots only)\n* DragonFly BSD: `pkg install fastfetch` (Snapshots only)\n\n### Android (Termux)\n\n* `pkg install fastfetch`\n\n### Nightly\n\n<https://nightly.link/fastfetch-cli/fastfetch/workflows/ci/dev?preview>\n\n## Build from source\n\nSee the Wiki: https://github.com/fastfetch-cli/fastfetch/wiki/Building\n\n## Usage\n\n* Run with default configuration: `fastfetch`\n* Run with [all supported modules](https://github.com/fastfetch-cli/fastfetch/wiki/Support+Status#available-modules) to find what interests you: `fastfetch -c all.jsonc`\n* View all data that fastfetch detects: `fastfetch -s <module1>[:<module2>][:<module3>] --format json`\n* Display help messages: `fastfetch --help`\n* Generate a minimal config file: `fastfetch [-s <module1>[:<module2>]] --gen-config [</path/to/config.jsonc>]`\n    * Use: `--gen-config-full` to generate a full config file with all optional options\n\n## Customization\n\nFastfetch uses JSONC (JSON with comments) for configuration. [See the Wiki for details](https://github.com/fastfetch-cli/fastfetch/wiki/Configuration). There are some premade config files in the [`presets`](presets) directory, including those used for the screenshots above. You can load them using `-c <filename>`. These files can serve as examples of the configuration syntax.\n\nLogos can also be heavily customized; see the [logo documentation](https://github.com/fastfetch-cli/fastfetch/wiki/Logo-options) for more information.\n\n### WARNING\n\nFastfetch supports a `Command` module that can run arbitrary shell commands. If you copy-paste a config file from an untrusted source, it may contain malicious commands that can harm your system or compromise your privacy. Please always review the config file before using it.\n\n## FAQ\n\n### Q: Neofetch is good enough. Why do I need fastfetch?\n\n1. Fastfetch is actively maintained.\n2. Fastfetch is faster, as the name suggests.\n3. Fastfetch has a greater number of features, though by default it only has a few modules enabled; use `fastfetch -c all` to discover what you want.\n4. Fastfetch is more configurable. You can find more information in the Wiki: <https://github.com/fastfetch-cli/fastfetch/wiki/Configuration>.\n5. Fastfetch is more polished. For example, neofetch prints `555 MiB` in the Memory module and `23 G` in the Disk module, whereas fastfetch prints `555.00 MiB` and `22.97 GiB` respectively.\n6. Fastfetch is more accurate. For example, [neofetch never actually supports the Wayland protocol](https://github.com/dylanaraps/neofetch/pull/2395).\n\n### Q: Fastfetch shows my local IP address. Does it leak my privacy?\n\nA local IP address (10.x.x.x, 172.x.x.x, 192.168.x.x) has nothing to do with privacy. It only has meaning if you are on the same network, for example, if you connect to the same Wi-Fi network.\n\nActually, the `Local IP` module is the most useful module for me personally. I (@CarterLi) have several VMs installed to test fastfetch and often need to SSH into them. With fastfetch running on shell startup, I never need to type `ip addr` manually.\n\nIf you really don't like it, you can disable the `Local IP` module in `config.jsonc`.\n\n### Q: Where is the config file? I can't find it.\n\nFastfetch does not generate a config file automatically. You can use `fastfetch --gen-config` to generate one. The config file will be saved in `~/.config/fastfetch/config.jsonc` by default. See the [Wiki for details](https://github.com/fastfetch-cli/fastfetch/wiki/Configuration).\n\n### Q: The configuration is so complex. Where is the documentation?\n\nFastfetch uses JSON (with comments) for configuration. I suggest using an IDE with JSON schema support (like VSCode) to edit it.\n\nAlternatively, you can refer to the presets in the [`presets` directory](https://github.com/fastfetch-cli/fastfetch/tree/dev/presets).\n\nThe **correct** way to edit the configuration:\n\nThis is an example that [changes size prefix from MiB / GiB to MB / GB](https://github.com/fastfetch-cli/fastfetch/discussions/1014). Editor used: [helix](https://github.com/helix-editor/helix)\n\n[![asciicast](https://asciinema.org/a/1uF6sTPGKrHKI1MVaFcikINSQ.svg)](https://asciinema.org/a/1uF6sTPGKrHKI1MVaFcikINSQ)\n\n### Q: I WANT THE DOCUMENTATION!\n\n[Here is the documentation](https://github.com/fastfetch-cli/fastfetch/wiki/Json-Schema). It is generated from the [JSON schema](https://github.com/fastfetch-cli/fastfetch/blob/dev/doc/json_schema.json), but you might not find it very user-friendly.\n\n### Q: How can I customize the module output?\n\nFastfetch uses `format` to generate output. For example, to make the `GPU` module show only the GPU name (leaving other information undisplayed), you can use:\n\n```jsonc\n{\n    \"modules\": [\n        {\n            \"type\": \"gpu\",\n            \"format\": \"{name}\" // See `fastfetch -h gpu-format` for details\n        }\n    ]\n}\n```\n\n...which is equivalent to `fastfetch -s gpu --gpu-format '{name}'`\n\nSee `fastfetch -h format` for information on basic usage. For module-specific formatting, see `fastfetch -h <module>-format`\n\n### Q: I have my own ASCII art / image file. How can I show it with fastfetch?\n\nTry `fastfetch -l /path/to/logo`. See the [logo documentation](https://github.com/fastfetch-cli/fastfetch/wiki/Logo-options) for details.\n\nIf you just want to display the distro name in [FIGlet text](https://github.com/pwaller/pyfiglet):\n\n```bash\n# install pyfiglet and jq first\npyfiglet -s -f small_slant $(fastfetch -s os --format json | jq -r '.[0].result.name') && fastfetch -l none\n```\n\n![image](https://github.com/fastfetch-cli/fastfetch/assets/6134068/6466524e-ab8c-484f-848d-eec7ddeb7df2)\n\n### Q: My image logo behaves strangely. How can I fix it?\n\nSee the troubleshooting section: <https://github.com/fastfetch-cli/fastfetch/wiki/Logo-options#troubleshooting>\n\n### Q: Fastfetch runs in black and white on shell startup. Why?\n\nThis issue usually occurs when using fastfetch with `p10k`. There are known incompatibilities between fastfetch and p10k instant prompt.\nThe p10k documentation clearly states that you should NOT print anything to stdout after `p10k-instant-prompt` is initialized. You should put `fastfetch` before the initialization of `p10k-instant-prompt` (recommended).\n\nYou can always use `fastfetch --pipe false` to force fastfetch to run in colorful mode.\n\n### Q: Why do fastfetch and neofetch show different memory usage results?\n\nSee [#1096](https://github.com/fastfetch-cli/fastfetch/issues/1096).\n\n### Q: Fastfetch shows fewer dpkg packages than neofetch. Is it a bug?\n\nNeofetch incorrectly counts `rc` packages (packages that have been removed but still have configuration files remaining). See bug: https://github.com/dylanaraps/neofetch/issues/2278\n\n### Q: I use Debian / Ubuntu / Debian-derived distro. My GPU is detected as `XXXX Device XXXX (VGA compatible)`. Is this a bug?\n\nTry upgrading `pci.ids`: Download <https://pci-ids.ucw.cz/v2.2/pci.ids> and overwrite the file `/usr/share/hwdata/pci.ids`. For AMD GPUs, you should also upgrade `amdgpu.ids`: Download <https://gitlab.freedesktop.org/mesa/drm/-/raw/main/data/amdgpu.ids> and overwrite the file `/usr/share/libdrm/amdgpu.ids`\n\nAlternatively, you may try using `fastfetch --gpu-driver-specific`, which will make fastfetch attempt to ask the driver for the GPU name if supported.\n\n### Q: I get the error `Authorization required, but no authorization protocol specified` when running fastfetch as root\n\nTry `export XAUTHORITY=$HOME/.Xauthority`\n\n### Q: Fastfetch cannot detect my awesome 3rd-party macOS window manager!\n\nTry `fastfetch --wm-detect-plugin`. See also [#984](https://github.com/fastfetch-cli/fastfetch/issues/984)\n\n### Q: How can I change the colors of my ASCII logo?\n\nTry `fastfetch --logo-color-[1-9] <color>`, where `[1-9]` is the index of color placeholders.\n\nFor example: `fastfetch --logo-color-1 red --logo-color-2 green`.\n\nIn JSONC, you can use:\n\n```jsonc\n{\n    \"logo\": {\n        \"color\": {\n            \"1\": \"red\",\n            \"2\": \"green\"\n        }\n    }\n}\n```\n\n### Q: How do I hide a key?\n\nSet the key to a white space.\n\n```jsonc\n{\n    \"key\": \" \"\n}\n```\n\n### Q: How can I display images on Windows?\n\nAs of April 2025:\n\n#### mintty and Wezterm\n\nmintty (used by Bash on Windows and MSYS2) and Wezterm (nightly build only) support the iTerm image protocol on Windows.\n\nIn `config.jsonc`:  \n```json\n{\n  \"logo\": {\n    \"type\": \"iterm\",\n    \"source\": \"C:/path/to/image.png\",\n    \"width\": <num-in-chars>\n  }\n}\n```\n\n#### Windows Terminal\n\nWindows Terminal supports the sixel image protocol only.\n\n* If you installed fastfetch through MSYS2:\n    1. Install imagemagick: `pacman -S mingw-w64-<subsystem>-x86_64-imagemagick`\n    2. In `config.jsonc`:  \n```jsonc\n{\n  \"logo\": {\n    \"type\": \"sixel\", // DO NOT USE \"auto\"\n    \"source\": \"C:/path/to/image.png\", // Do NOT use `~` as fastfetch is a native Windows program and doesn't apply cygwin path conversion\n    \"width\": <image-width-in-chars>, // Optional\n    \"height\": <image-height-in-chars> // Optional\n  }\n}\n```\n* If you installed fastfetch via scoop or downloaded the binary directly from the GitHub Releases page:\n    1. Convert your image manually to sixel format using [any online image conversion service](https://www.google.com/search?q=convert+image+to+sixel)\n    2. In `config.jsonc`:  \n```jsonc\n{\n  \"logo\": {\n    \"type\": \"raw\", // DO NOT USE \"auto\"\n    \"source\": \"C:/path/to/image.sixel\",\n    \"width\": <image-width-in-chars>, // Required\n    \"height\": <image-height-in-chars> // Required\n  }\n}\n```\n\n### Q: I want feature A / B / C. Will fastfetch support it?\n\nFastfetch is a system information tool. We only accept hardware or system-level software feature requests. For most personal uses, I recommend using the `Command` module to implement custom functionality, which can be used to grab output from a custom shell script:\n\n```jsonc\n// This module shows the default editor\n{\n    \"modules\": [\n        {\n            \"type\": \"command\",\n            \"text\": \"$EDITOR --version | head -1\",\n            \"key\": \"Editor\"\n        }\n    ]\n}\n```\n\nOtherwise, please open a feature request in [GitHub Issues](https://github.com/fastfetch-cli/fastfetch/issues).\n\n### Q: I have questions. Where can I get help?\n\n* For usage questions, please start a discussion in [GitHub Discussions](https://github.com/fastfetch-cli/fastfetch/discussions).\n* For possible bugs, please open an issue in [GitHub Issues](https://github.com/fastfetch-cli/fastfetch/issues). Be sure to fill out the bug report template carefully to help developers investigate.\n\n## Donate\n\nIf you find Fastfetch useful, please consider donating.\n\n* Current maintainer: [@CarterLi](https://paypal.me/zhangsongcui)\n* Original author: [@LinusDierheimer](https://github.com/sponsors/LinusDierheimer)\n\n## Code signing\n\n* Free code signing provided by [SignPath.io](https://about.signpath.io/), certificate by [SignPath Foundation](https://signpath.org/)\n* This program will not transfer any information to other networked systems unless specifically requested by the user or the person installing or operating it\n\n## Star History\n\nGive us a star to show your support!\n\n<a href=\"https://star-history.com/#fastfetch-cli/fastfetch&Date\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=fastfetch-cli/fastfetch&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=fastfetch-cli/fastfetch&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=fastfetch-cli/fastfetch&type=Date\" />\n  </picture>\n</a>\n",
      "stars_today": 29
    },
    {
      "id": 527600676,
      "name": "MusicFree",
      "full_name": "maotoumao/MusicFree",
      "description": "Êèí‰ª∂Âåñ„ÄÅÂÆöÂà∂Âåñ„ÄÅÊó†ÂπøÂëäÁöÑÂÖçË¥πÈü≥‰πêÊí≠ÊîæÂô®",
      "html_url": "https://github.com/maotoumao/MusicFree",
      "stars": 22965,
      "forks": 1594,
      "language": "TypeScript",
      "topics": [
        "free",
        "music-player",
        "musicfree",
        "plugin",
        "react",
        "react-native",
        "typescript"
      ],
      "created_at": "2022-08-22T14:29:32Z",
      "updated_at": "2026-01-23T02:07:28Z",
      "pushed_at": "2026-01-06T14:15:47Z",
      "open_issues": 223,
      "owner": {
        "login": "maotoumao",
        "avatar_url": "https://avatars.githubusercontent.com/u/31655147?v=4"
      },
      "readme": "# MusicFree\n\n**‰∏≠Êñá** | [English](./readme-en.md)\n\n![GitHub Repo stars](https://img.shields.io/github/stars/maotoumao/MusicFree) \n![GitHub forks](https://img.shields.io/github/forks/maotoumao/MusicFree)\n![star](https://gitcode.com/maotoumao/MusicFree/star/badge.svg)\n\n![GitHub License](https://img.shields.io/github/license/maotoumao/MusicFree)\n![GitHub Downloads (all assets, all releases)](https://img.shields.io/github/downloads/maotoumao/MusicFree/total)\n![GitHub Issues or Pull Requests](https://img.shields.io/github/issues/maotoumao/MusicFree)\n![GitHub package.json version](https://img.shields.io/github/package-json/v/maotoumao/MusicFree)\n\n<a href=\"https://trendshift.io/repositories/1028\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/1028\" alt=\"maotoumao%2FMusicFree | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n## ÁÆÄ‰ªã\n\n‰∏Ä‰∏™Êèí‰ª∂Âåñ„ÄÅÂÆöÂà∂Âåñ„ÄÅÊó†ÂπøÂëäÁöÑÂÖçË¥πÈü≥‰πêÊí≠ÊîæÂô®ÔºåÁõÆÂâçÂè™ÊîØÊåÅ Android Âíå Harmony OS„ÄÇ\n\n> **Ê°åÈù¢ÁâàÊù•Âï¶Ôºö<https://github.com/maotoumao/MusicFreeDesktop>**\n\nÂ¶ÇÊûúÈúÄË¶Å‰∫ÜËß£ÂêéÁª≠ËøõÂ±ïÂèØ‰ª•ÂÖ≥Ê≥®ÂÖ¨‰ºóÂè∑‚ÜìÔºõÂ¶ÇÊûúÊúâÈóÆÈ¢òÂèØ‰ª•Âú® issue Âå∫ÊàñËÄÖÂÖ¨‰ºóÂè∑Áõ¥Êé•ÁïôË®ÄÂèçÈ¶à„ÄÇ\n\n![ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑](./src/assets/imgs/wechat_channel.jpg)\n\nËΩØ‰ª∂‰∏ãËΩΩÊñπÂºè„ÄÅÊèí‰ª∂‰ΩøÁî®ËØ¥Êòé„ÄÅÊèí‰ª∂ÂºÄÂèëÊñáÊ°£ÂèØÂéªÁ´ôÁÇπ [https://musicfree.catcat.work](https://musicfree.catcat.work) Êü•Áúã„ÄÇ\n\n> [!NOTE]\n> - Â¶ÇÊûú‰Ω†Âú®ÂÖ∂‰ªñÁöÑÂπ≥Âè∞ÁúãÂà∞Êî∂Ë¥πÁâà/Êó†ÂπøÂëäÁâà/Á†¥Ëß£ÁâàÔºåÈÉΩÊòØÂÅáÁöÑÔºåÊú¨Êù•Â∞±ÊòØÂºÄÊ∫êÈ°πÁõÆÔºå**ÈÅáÂà∞Êî∂Ë¥πÁâàËØ∑Áõ¥Êé•‰∏æÊä•**Ôºõ\n> - ËΩØ‰ª∂È¶ñÂÖàÊòØËá™Áî®ÔºåÈ°∫Â∏¶ÂàÜ‰∫´Âá∫Êù•Â∏åÊúõÂèØ‰ª•Â∏ÆÂä©Âà∞ÊúâÈúÄË¶ÅÁöÑ‰∫∫ÔºõÊòØ‰∏ö‰Ωô‰ΩúÂìÅÔºå‰ºöÂ∞ΩÈáè‰øùÊåÅÁª¥Êä§Ôºå‰∏çËøáÊØèÂ§©ËÉΩÂÜôÁöÑÊó∂Èó¥ÊúâÈôêÔºàÂçäÂ∞èÊó∂Â∑¶Âè≥ÔºâÔºåÁõÆÊµã‰ºöÊúâÂæàÈïø‰∏ÄÊÆµÊó∂Èó¥Â§Ñ‰∫é‰∏çÁ®≥ÂÆöÊµãËØïÁâàÊú¨Ôºå‰∏îÊõ¥Êñ∞È¢ëÁéá‰∏çÂÆöÔºåËØ∑Ë∞®ÊÖé‰ΩøÁî®Ôºõ\n> - ËΩØ‰ª∂ÁöÑÁ¨¨‰∏âÊñπÊèí‰ª∂„ÄÅÂèäÂÖ∂ÊâÄ‰∫ßÁîüÁöÑÊï∞ÊçÆ‰∏éÊú¨ËΩØ‰ª∂Êó†ÂÖ≥ÔºåËØ∑ÂêàÁêÜÂêàÊ≥ï‰ΩøÁî®ÔºåÂèØËÉΩ‰∫ßÁîüÁöÑÁâàÊùÉÊï∞ÊçÆËØ∑ÂèäÊó∂Âà†Èô§„ÄÇ\n> - **ËØ∑‰∏çË¶Å‰ª• VIP/Á†¥Ëß£Áâà‰∏∫Âô±Â§¥ËøõË°åÂÆ£‰º†**ÔºåÁ§∫‰æã‰ªìÂ∫ìÂü∫‰∫é‰∫íËÅîÁΩëÂÖ¨ÂºÄÊé•Âè£Â∞ÅË£ÖÔºåÂπ∂**ËøáÊª§ÊéâÊâÄÊúâ VIP„ÄÅËØïÂê¨„ÄÅ‰ªòË¥πÊ≠åÊõ≤**Ôºå‰∏îÁ§∫‰æã‰ªìÂ∫ì‰ª•Âêé‰πü**‰∏ç‰ºöÊèê‰æõÂÖ∑Â§áÁ†¥Ëß£ÂäüËÉΩÁöÑÊèí‰ª∂**Ôºõ\n> - Êú¨ËΩØ‰ª∂ÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØ**Âè™‰ºö‰∏ªÂä®ÊäïÊîæÂú® Git ‰ªìÂ∫ì‰ª•ÂèäÂÖ¨‰ºóÂè∑‚Äú‰∏ÄÂè™Áå´Â§¥Áå´‚Äù‰∏≠**ÔºåÂ¶ÇÊûúÂ∏åÊúõÂÜôÊñáÁ´†‰ªãÁªçÊú¨ËΩØ‰ª∂ËØ∑Ëá™‰æøÔºå‰ΩÜËøòÁÉ¶ËØ∑**Â¶ÇÂÆûÈôàËø∞ÔºåÊ∂âÂèäÂà∞Á§∫‰æã‰ªìÂ∫ìËØ∑ÁªôÊèí‰ª∂Ê∫êÊâì‰∏™Á†Å**Ôºå‰∏çË¶ÅÁªôËΩØ‰ª∂Â¢ûÂä†‰∏Ä‰∫õ‰∏çÂÆûÁöÑÂäüËÉΩÔºàÂ∞ΩÁÆ°Êàë‰πüÊÉ≥ÊúâÔºâÔºõÊèèËø∞ÂÜ≤Á™ÅÁöÑÂú∞Êñπ‰ª•Êú¨‰ªìÂ∫ì‰∏∫ÂáÜ„ÄÇ\n\n\n## È°πÁõÆ‰ΩøÁî®Á∫¶ÂÆöÔºö\nÊú¨È°πÁõÆÂü∫‰∫é AGPL 3.0 ÂçèËÆÆÂºÄÊ∫êÔºå‰ΩøÁî®Ê≠§È°πÁõÆÊó∂ËØ∑ÈÅµÂÆàÂºÄÊ∫êÂçèËÆÆ„ÄÇ  \nÈô§Ê≠§Â§ñÔºåÂ∏åÊúõ‰Ω†Âú®‰ΩøÁî®‰ª£Á†ÅÊó∂Â∑≤Áªè‰∫ÜËß£‰ª•‰∏ãÈ¢ùÂ§ñËØ¥ÊòéÔºö\n\n1. ÊâìÂåÖ„ÄÅ‰∫åÊ¨°ÂàÜÂèë **ËØ∑‰øùÁïô‰ª£Á†ÅÂá∫Â§Ñ**Ôºöhttps://github.com/maotoumao/MusicFree\n2. ËØ∑‰∏çË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåÂêàÊ≥ïÂêàËßÑ‰ΩøÁî®‰ª£Á†ÅÔºõ\n3. Â¶ÇÊûúÂºÄÊ∫êÂçèËÆÆÂèòÊõ¥ÔºåÂ∞ÜÂú®Ê≠§ Github ‰ªìÂ∫ìÊõ¥Êñ∞Ôºå‰∏çÂè¶Ë°åÈÄöÁü•„ÄÇ\n\n> [!CAUTION]\n> ### üëé Hall of Shame\n> üëé Â∞èÁ±≥/Âçé‰∏∫/vivoÁ≠â<ins>Â∫îÁî®Â∏ÇÂú∫ÁöÑ MusicFree </ins>ÂíåÊú¨ËΩØ‰ª∂Êó†ÂÖ≥Ôºå**ÊòØÂ•óÁî®Êú¨ËΩØ‰ª∂ÂêçÁß∞Âíå Logo ÁöÑÂπøÂëäËΩØ‰ª∂**„ÄÇ\n>\n> üëé ÈÄüÊÇ¶Èü≥‰πêÂü∫‰∫éÊú¨ËΩØ‰ª∂‰∫åÊ¨°ÂºÄÂèëÔºåÊîπÂä®ÁÇπ‰ªÖ‰ªÖÊòØÂÜÖÁΩÆÊèí‰ª∂„ÄÅ‰øÆÊîπ‰∏Ä‰∫õ UI ‰ª•ÂèäÂºïÊµÅÔºå**Âπ∂Êú™ÈÅµÂÆàÊú¨È°πÁõÆÁöÑÂºÄÊ∫êÂçèËÆÆÔºå‰∏îÊãíÁªùÊ≤üÈÄö**„ÄÇ\n\n---\n\n## ÁâπÊÄß\n\n- Êèí‰ª∂ÂåñÔºöÊú¨ËΩØ‰ª∂‰ªÖ‰ªÖÊòØ‰∏Ä‰∏™Êí≠ÊîæÂô®ÔºåÊú¨Ë∫´**Âπ∂‰∏çÈõÜÊàê**‰ªª‰ΩïÂπ≥Âè∞ÁöÑ‰ªª‰ΩïÈü≥Ê∫êÔºåÊâÄÊúâÁöÑÊêúÁ¥¢„ÄÅÊí≠Êîæ„ÄÅÊ≠åÂçïÂØºÂÖ•Á≠âÂäüËÉΩÂÖ®ÈÉ®Âü∫‰∫é**Êèí‰ª∂**„ÄÇËøô‰πüÂ∞±ÊÑèÂë≥ÁùÄÔºå**Âè™Ë¶ÅÂèØ‰ª•Âú®‰∫íËÅîÁΩë‰∏äÊêúÁ¥¢Âà∞ÁöÑÈü≥Ê∫êÔºåÂè™Ë¶ÅÊúâÂØπÂ∫îÁöÑÊèí‰ª∂Ôºå‰Ω†ÈÉΩÂèØ‰ª•‰ΩøÁî®Êú¨ËΩØ‰ª∂ËøõË°åÊêúÁ¥¢„ÄÅÊí≠ÊîæÁ≠âÂäüËÉΩ**„ÄÇÂÖ≥‰∫éÊèí‰ª∂ÁöÑËØ¶ÁªÜËØ¥ÊòéËØ∑ÁúãÊèí‰ª∂‰∏ÄËäÇ„ÄÇ\n\n- Êèí‰ª∂ÊîØÊåÅÁöÑÂäüËÉΩÔºöÊêúÁ¥¢ÔºàÈü≥‰πê„ÄÅ‰∏ìËæë„ÄÅ‰ΩúËÄÖÔºâ„ÄÅÊí≠Êîæ„ÄÅÊü•Áúã‰∏ìËæë„ÄÅÊü•Áúã‰ΩúËÄÖËØ¶ÁªÜ‰ø°ÊÅØ„ÄÅÂØºÂÖ•ÂçïÊõ≤„ÄÅÂØºÂÖ•Ê≠åÂçï„ÄÅËé∑ÂèñÊ≠åËØçÁ≠â„ÄÇ\n\n- ÂÆöÂà∂Âåñ„ÄÅÊó†ÂπøÂëäÔºöÊú¨ËΩØ‰ª∂Êèê‰æõ‰∫ÜÊµÖËâ≤„ÄÅÊ∑±Ëâ≤Ê®°ÂºèÔºõÊîØÊåÅËá™ÂÆö‰πâËÉåÊôØÔºõÊú¨ËΩØ‰ª∂Âü∫‰∫é AGPL ÂçèËÆÆÂºÄÊ∫êÔºå~~‰∏Ä‰∏™ star ÂÅö‰∫§Êòì~~ Â∞Ü‰ºö‰øùÊåÅÂÖçË¥π„ÄÇ\n- ÈöêÁßÅÔºöÊâÄÊúâÁöÑÊï∞ÊçÆÈÉΩÂ≠òÂÇ®Âú®Êú¨Âú∞ÔºåÊú¨ËΩØ‰ª∂‰∏ç‰ºöÊî∂ÈõÜ‰Ω†ÁöÑ‰ªª‰Ωï‰∏™‰∫∫‰ø°ÊÅØ„ÄÇ\n- Ê≠åËØçÂÖ≥ËÅîÔºö‰Ω†ÂèØ‰ª•Êää‰∏§È¶ñÊ≠åÁöÑÊ≠åËØçÂÖ≥ËÅîËµ∑Êù•ÔºåÊØîÂ¶ÇÂ∞ÜÊ≠åÊõ≤ A ÁöÑÊ≠åËØçÂÖ≥ËÅîÂà∞Ê≠åÊõ≤ BÔºåÂÖ≥ËÅîÂêé A„ÄÅB ‰∏§È¶ñÊ≠åÈÉΩÂ∞ÜÊòæÁ§∫Ê≠åÊõ≤ B ÁöÑÊ≠åËØç„ÄÇ‰Ω†‰πüÂèØ‰ª•ÂÖ≥ËÅîÂ§öÈ¶ñÊ≠åÁöÑÊ≠åËØçÔºåÂ¶Ç A->B->CÔºåËøôÊ†∑ A„ÄÅB„ÄÅC ‰∏âÈ¶ñÊ≠åÈÉΩÂ∞ÜÊòæÁ§∫ C ÁöÑÊ≠åËØç„ÄÇ\n\n## Êèí‰ª∂\n\n### Êèí‰ª∂ÁÆÄ‰ªã\n\nÊèí‰ª∂Êú¨Ë¥®‰∏äÊòØ‰∏Ä‰∏™Êª°Ë∂≥Êèí‰ª∂ÂçèËÆÆÁöÑ commonjs Ê®°Âùó„ÄÇÊèí‰ª∂‰∏≠ÂÆö‰πâ‰∫ÜÊêúÁ¥¢ÔºàÈü≥‰πê„ÄÅ‰∏ìËæë„ÄÅ‰ΩúËÄÖÔºâ„ÄÅÊí≠Êîæ„ÄÅÊü•Áúã‰∏ìËæë„ÄÅ‰ΩúËÄÖËØ¶ÁªÜ‰ø°ÊÅØ„ÄÅÂØºÂÖ•Ê≠åÂçï„ÄÅËé∑ÂèñÊ≠åËØçÁ≠âÂü∫Êú¨ÂáΩÊï∞ÔºåÊèí‰ª∂ÁöÑÂºÄÂèëËÄÖÂè™ÈúÄË¶ÅÂÖ≥ÂøÉËæìÂÖ•ËæìÂá∫ÈÄªËæëÔºåËá≥‰∫éÂàÜÈ°µ„ÄÅÁºìÂ≠òÁ≠âÂÖ®ÈÉΩ‰∫§Áªô MusicFree ÊéßÂà∂Âç≥ÂèØ„ÄÇÊú¨ËΩØ‰ª∂ÈÄöËøáÊèí‰ª∂Êù•ÂÆåÊàêÊí≠ÊîæÂô®ÁöÑÊâÄÊúâÂäüËÉΩÔºåËøôÊ†∑Ëß£ËÄ¶ÁöÑËÆæËÆ°‰πüÂèØ‰ª•‰ΩøÂæóÊú¨ËΩØ‰ª∂ÂèØ‰ª•‰∏ìÊ≥®‰∫éÂÅö‰∏Ä‰∏™ÂäüËÉΩÂÆåÂñÑÁöÑÊí≠ÊîæÂô®ÔºåÊàëÁõ¥ÂëºÂ∞èËÄåÁæé„ÄÇ\n\nÊèí‰ª∂ÂºÄÂèëÊñáÊ°£ÂèØ‰ª•ÂèÇËÄÉ [ËøôÈáå](https://musicfree.catcat.work/plugin/introduction.html)\n\nÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºö\n\n- Â¶ÇÊûú‰Ω†ÊòØ‰ΩøÁî®Á¨¨‰∏âÊñπ‰∏ãËΩΩÁöÑÊèí‰ª∂ÔºåÈÇ£‰πàËØ∑Ëá™Ë°åÈâ¥Âà´Êèí‰ª∂ÁöÑÂÆâÂÖ®ÊÄßÔºàÂü∫Êú¨‰∏äÁúã‰∏ãÊ≤°ÊúâÂ•áÊÄ™ÁöÑÁΩëÁªúËØ∑Ê±Ç‰ªÄ‰πàÁöÑÂ∞±Â•Ω‰∫ÜÔºõËá™Â∑±ÂÜôÁöÑÊúÄÂÆâÂÖ®Ôºå*‰∏çË¶ÅÂÆâË£ÖÊù•Ë∑Ø‰∏çÊòéÁöÑ‰∏úË•ø*ÔºâÔºåÈò≤Ê≠¢ÊÅ∂ÊÑè‰ª£Á†ÅÁ†¥Âùè„ÄÇÂõ†‰∏∫Á¨¨‰∏âÊñπÊÅ∂ÊÑèÊèí‰ª∂ÂØºËá¥ÁöÑÂèØËÉΩÁöÑÊçüÂ§±‰∏éÊú¨ËΩØ‰ª∂Êó†ÂÖ≥„ÄÇ\n\n- Êèí‰ª∂‰ΩøÁî®ËøáÁ®ã‰∏≠ÂèØËÉΩ‰ºö‰∫ßÁîüÊüê‰∫õÂíåÊú¨ËΩØ‰ª∂Êó†ÂÖ≥ÁöÑÁâàÊùÉÊï∞ÊçÆÔºåÊèí‰ª∂„ÄÅ‰ª•ÂèäÊèí‰ª∂‰∫ßÁîüÁöÑ‰ªª‰ΩïÊï∞ÊçÆ‰∏éÊú¨ËΩØ‰ª∂Êó†ÂÖ≥ÔºåËØ∑‰ΩøÁî®ËÄÖËá™Ë°åÊñüÈÖåÔºåÂèäÊó∂Âà†Èô§Êï∞ÊçÆÔºåÊú¨ËΩØ‰ª∂‰∏çÊèêÂÄ°‰πü‰∏ç‰ºöÊèê‰æõ‰ªª‰ΩïÁ†¥Ëß£Ë°å‰∏∫Ôºå‰Ω†ÂèØ‰ª•Êê≠Âª∫Ëá™Â∑±ÁöÑÁ¶ªÁ∫øÈü≥‰πê‰ªìÂ∫ì‰ΩøÁî®„ÄÇ\n\n### Êèí‰ª∂‰ΩøÁî®\n\n‰∏ãËΩΩ app ‰πãÂêéÔºåÂè™ÈúÄË¶ÅÂú®‰æßËæπÊ†èËÆæÁΩÆ-Êèí‰ª∂ËÆæÁΩÆ‰∏≠ÂÆâË£ÖÊèí‰ª∂Âç≥ÂèØ„ÄÇÊîØÊåÅÂÆâË£ÖÊú¨Âú∞Êèí‰ª∂Âíå‰ªéÁΩëÁªúÂÆâË£ÖÊèí‰ª∂ÔºàÊîØÊåÅËß£Êûê.js Êñá‰ª∂Âíå.json ÊèèËø∞Êñá‰ª∂ÔºõÂ∑≤ÁªèÂÜô‰∫ÜÂá†‰∏™Á§∫ÊÑèÁöÑÊèí‰ª∂Ôºö[ÊåáË∑ØËøô‰∏™‰ªìÂ∫ì](https://github.com/maotoumao/MusicFreePlugins)Ôºå‰∏çËøáÂèØËÉΩÂäüËÉΩ‰∏çÊòØÂæàÂÆåÂñÑÔºâÔºõ\n\n\n‰Ω†ÂèØ‰ª•Áõ¥Êé•ÁÇπÂáª‰ªéÁΩëÁªúÂÆâË£ÖÊèí‰ª∂ÔºåÁÑ∂ÂêéËæìÂÖ•<https://raw.gitcode.com/maotoumao/MusicFreePlugins/raw/master/plugins.json> ÔºåÁÇπÂáªÁ°ÆËÆ§Âç≥ÂèØÂÆâË£Ö„ÄÇ\n\nÂõæÊñáÁâàËØ¶ÁªÜ‰ΩøÁî®ËØ¥ÊòéÂèØ‰ª•ÂèÇËÄÉÂÖ¨‰ºóÂè∑Ôºö[MusicFree Êèí‰ª∂‰ΩøÁî®ÊåáÂçó](https://mp.weixin.qq.com/s?__biz=MzkxOTM5MDI4MA==&mid=2247483875&idx=1&sn=aedf8bb909540634d927de7fd2b4b8b1&chksm=c1a390c4f6d419d233908bb781d418c6b9fd2ca82e9e93291e7c93b8ead3c50ca5ae39668212#rd)ÔºåÊàñËÄÖÁ´ôÁÇπÔºö https://musicfree.catcat.work/usage/mobile/install-plugin.html\n\n## ‰∏ãËΩΩÂú∞ÂùÄ\n\nËØ∑ËΩ¨Âà∞ÂèëÂ∏ÉÈ°µÊü•ÁúãÔºö[ÊåáË∑Ø](https://github.com/maotoumao/MusicFree/releases) (Â¶ÇÊûúÊâì‰∏çÂºÄÂèØ‰ª•Êää github Êç¢Êàê gitcode)ÔºåÂÖ¨‰ºóÂè∑ÂõûÂ§ç Musicfree ‰πüÂèØ‰ª•„ÄÇ\n\n## Q&A\n\n‰ΩøÁî®Êó∂ÈÅáÂà∞ÁöÑÂ∏∏ËßÅÈóÆÈ¢òÂèØ‰ª•ÁúãËøôÈáåÔºö[MusicFree ‰ΩøÁî® Q&A](https://musicfree.catcat.work/qa/common.html)\n\nÊäÄÊúØ‰∫§ÊµÅ/‰∏ÄËµ∑ÂÜôÁÇπÊúâÊÑèÊÄùÁöÑ‰∏úË•ø/ÊäÄÊúØÂêëÁöÑÈó≤ËÅäÊ¨¢ËøéÂä†Áæ§Ôºö[683467814](https://jq.qq.com/?_wv=1027&k=upVpi2k3)~ Ôºà‰∏çÊòØÁ≠îÁñëÁæ§Ôºâ\n\nÈó≤ËÅäÂèØ‰ª•Âà∞ [QQ È¢ëÈÅì](https://pd.qq.com/s/cyxnf0jj1)~\n\n## WIP\n\nÂ¶ÇÊûúÊúâÈúÄË¶ÅËÆ®ËÆ∫ÁöÑÊñ∞ÈúÄÊ±ÇÔºåÂèØ‰ª•Âú®ÂÖ¨‰ºóÂè∑ÂêéÂè∞ÁïôË®Ä/Êèêissue/ÊàñËÄÖÂéªdiscussionÂºÄ‰∏™ËØùÈ¢ò„ÄÇ\n\n## ÊîØÊåÅËøô‰∏™È°πÁõÆ\n\nÂ¶ÇÊûú‰Ω†ÂñúÊ¨¢Ëøô‰∏™È°πÁõÆÔºåÊàñËÄÖÂ∏åÊúõÊàëÂèØ‰ª•ÊåÅÁª≠Áª¥Êä§‰∏ãÂéªÔºå‰Ω†ÂèØ‰ª•ÈÄöËøá‰ª•‰∏ã‰ªª‰Ωï‰∏ÄÁßçÊñπÂºèÊîØÊåÅÊàë;)\n\n1. Star Ëøô‰∏™È°πÁõÆÔºåÂàÜ‰∫´Áªô‰Ω†Ë∫´ËæπÁöÑ‰∫∫Ôºõ\n2. ÂÖ≥Ê≥®ÂÖ¨‰ºóÂè∑üëáÊàñ b Á´ô [‰∏çÊÉ≥Áù°ËßâÁå´Â§¥Áå´](https://space.bilibili.com/12866223) Ëé∑ÂèñÊúÄÊñ∞‰ø°ÊÅØÔºõ\n3. ÂÖ≥Ê≥®Áå´Â§¥Áå´ÁöÑ [Â∞èÁ∫¢‰π¶](https://www.xiaohongshu.com/user/profile/5ce6085200000000050213a6?xhsshare=CopyLink&appuid=5ce6085200000000050213a6&apptime=1714394544)ÔºåËôΩÁÑ∂ÂèØËÉΩ‰∏ç‰ºöÂú®ËøôÈáåÊõ¥Êñ∞ËΩØ‰ª∂Áõ∏ÂÖ≥ÁöÑ‰ø°ÊÅØÔºå‰ΩÜ‰πüÁÆóÊîØÊåÅÂï¶~\n\n![ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑](./src/assets/imgs/wechat_channel.jpg)\n\nÊÑüË∞¢‰ª•‰∏ãÂ∞è‰ºô‰º¥ÁöÑÊé®ËçêÔºåÂæàÊÑèÂ§ñ‰πüÂæàÊÉäÂñú ~~~\n\nÊù•Ëá™**ÊûúÊ†∏Ââ•Â£≥**ÁöÑÂÆâÂà©~ <https://mp.weixin.qq.com/s/F6hMbLv_a-Ty0fPA_0P0Rg>\n\nÊù•Ëá™**Â∞èÊ£âË¢Ñ**ÁöÑÂÆâÂà©~ <https://mp.weixin.qq.com/s/Fqe3o7vcTw0KDKoB-gsQfg>\n\n## ChangeLog\n\n[ÁÇπÂáªËøôÈáå](./changelog.md)\n\n---\nÊú¨È°πÁõÆ‰ªÖ‰æõÂ≠¶‰π†ÂèÇËÄÉ‰ΩøÁî®ÔºåÂü∫‰∫é AGPL3.0 ÂçèËÆÆÂºÄÊ∫êÔºõËØ∑Âú®Á¨¶ÂêàÊ≥ïÂæãÊ≥ïËßÑÁöÑÊÉÖÂÜµ‰∏ãÂêàÁêÜ‰ΩøÁî®Êú¨È°πÁõÆÔºåÁ¶ÅÊ≠¢Áî®‰∫éÂïÜ‰∏öÁõÆÁöÑ‰ΩøÁî®„ÄÇ\n\n## Â∫îÁî®Êà™Âõæ\n\n**‰ª•‰∏ãÊà™Âõæ‰ªÖ‰∏∫ UI Ê†∑‰æãÔºåËΩØ‰ª∂ÂÜÖÈÉ®‰∏çÊèê‰æõ‰ªª‰ΩïÈü≥Ê∫êÔºå‰∏ç‰ª£Ë°®ÂÆûÈôÖ‰ΩøÁî®Êó∂Ë°®Áé∞Â¶Ç‰∏ãÂõæ„ÄÇ**\n#### ‰∏ªÁïåÈù¢\n\n<img src=\"./.imgs/main-v0.6.jpg\" width=\"320px\" alt=\"‰∏ªÁïåÈù¢\">\n\n#### ‰æßËæπÊ†è\n\n- ‰æßËæπÊ†è\n\n<img src=\"./.imgs/sidebar-v0.6.jpg\" width=\"320px\" alt=\"‰æßËæπÊ†è\">\n\n- Âü∫Á°ÄËÆæÁΩÆ\n\n<img src=\"./.imgs/basic-setting-v0.6.jpg\" width=\"320px\" alt=\"Âü∫Á°ÄËÆæÁΩÆ\">\n\n- ‰∏ªÈ¢òËÆæÁΩÆ\n\n<img src=\"./.imgs/theme-setting-v0.6.jpg\" width=\"320px\" alt=\"‰∏ªÈ¢òËÆæÁΩÆ\">\n\n#### Èü≥‰πêÁõ∏ÂÖ≥\n\n- Ê≠åÂçïÈ°µ\n\n<img src=\"./.imgs/song-sheet-v0.6.jpg\" width=\"320px\" alt=\"Ê≠åÂçïÈ°µ\">\n\n- Ê≠åÂçïÂÜÖÊ£ÄÁ¥¢\n\n<img src=\"./.imgs/search-in-sheet-v0.6.jpg\" width=\"320px\" alt=\"Ê≠åÂçïÂÜÖÊ£ÄÁ¥¢\">\n\n- Êí≠ÊîæÈ°µ\n\n<img src=\"./.imgs/song-cover-v0.6.jpg\" width=\"320px\" alt=\"Êí≠ÊîæÈ°µ\">\n\n- Ê≠åËØçÈ°µ\n\n<img src=\"./.imgs/song-lrc-v0.6.jpg\" width=\"320px\" alt=\"Ê≠åËØçÈ°µ\">\n\n#### ÊêúÁ¥¢Áõ∏ÂÖ≥\n\n- ‰ΩúËÄÖ‰ø°ÊÅØ\n\n<img src=\"./.imgs/artist-detail-v0.6.jpg\" width=\"320px\" alt=\"‰ΩúËÄÖ‰ø°ÊÅØ\">\n\n\n<details>\n\n\n<summary>‰ª•‰∏ãÊòØËΩØ‰ª∂Êó©ÊúüÁâàÊú¨ÁöÑ UI</summary>\n\n#### ‰∏ªÁïåÈù¢\n\n<img src=\"./.imgs/main.jpg\" width=\"320px\" alt=\"‰∏ªÁïåÈù¢\">\n\n#### ‰æßËæπÊ†è\n\n- Âü∫Á°ÄËÆæÁΩÆ\n\n<img src=\"./.imgs/basic-setting.jpg\" width=\"320px\" alt=\"Âü∫Á°ÄËÆæÁΩÆ\">\n\n- ‰∏ªÈ¢òËÆæÁΩÆ\n\n<img src=\"./.imgs/theme-setting.jpg\" width=\"320px\" alt=\"‰∏ªÈ¢òËÆæÁΩÆ\">\n\n#### Èü≥‰πêÁõ∏ÂÖ≥\n\n- Ê≠åÂçïÈ°µ\n\n<img src=\"./.imgs/song-sheet.jpg\" width=\"320px\" alt=\"Ê≠åÂçïÈ°µ\">\n\n- Ê≠åÂçïÂÜÖÊ£ÄÁ¥¢\n\n<img src=\"./.imgs/search-in-sheet.jpg\" width=\"320px\" alt=\"Ê≠åÂçïÂÜÖÊ£ÄÁ¥¢\">\n\n- Êí≠ÊîæÈ°µ\n\n<img src=\"./.imgs/song-cover.jpg\" width=\"320px\" alt=\"Êí≠ÊîæÈ°µ\">\n\n- Ê≠åËØçÈ°µ\n\n<img src=\"./.imgs/song-lrc.jpg\" width=\"320px\" alt=\"Ê≠åËØçÈ°µ\">\n\n#### ÊêúÁ¥¢Áõ∏ÂÖ≥\n\n- ‰ΩúËÄÖ‰ø°ÊÅØ\n\n<img src=\"./.imgs/artist-detail.jpg\" width=\"320px\" alt=\"‰ΩúËÄÖ‰ø°ÊÅØ\">\n\n\n</details>\n",
      "stars_today": 28
    },
    {
      "id": 717960955,
      "name": "Pearcleaner",
      "full_name": "alienator88/Pearcleaner",
      "description": "A free, source-available and fair-code licensed mac app cleaner",
      "html_url": "https://github.com/alienator88/Pearcleaner",
      "stars": 10900,
      "forks": 256,
      "language": "Swift",
      "topics": [],
      "created_at": "2023-11-13T03:55:50Z",
      "updated_at": "2026-01-23T02:05:13Z",
      "pushed_at": "2026-01-16T17:47:41Z",
      "open_issues": 42,
      "owner": {
        "login": "alienator88",
        "avatar_url": "https://avatars.githubusercontent.com/u/6263626?v=4"
      },
      "readme": "# Pearcleaner\n\n### Project Status: \n> As you may have noticed, there haven't been recent updates made to the app and I wanted to provide some details.\n> I have a full time job on the side, but most recently I took a break for the holidays and right after that I joined a friend who is starting a SaaS company. For now, I just legitimately don't have any spare time to work on my open-source apps. Once things slow down in the future and I have more free time, I'll get back to tackling the submitted issues/requests. If anybody has Swift/SwiftUI experience and wants to work on the existing issues meanwhile, feel free to submit PRs and I'll review/approve as I can. Thank you!\n\n<br>\n\n<p align=\"center\">\n<!--    <img src=\"https://github.com/alienator88/Pearcleaner/assets/91337119/165f6961-f4fc-4199-bc68-580bacff6eaf\" align=\"center\" width=\"128\" height=\"128\" /> -->\n   <img src=\"https://github.com/user-attachments/assets/62cd5fcb-92d3-4d3a-9664-161a7deabd46\" align=\"center\" width=\"160\" height=\"160\" />\n\n   <br />\n   <strong>Status: </strong>Maintained\n   <br />\n   <strong>Version: </strong>5.4.3\n   <br />\n   <a href=\"https://github.com/alienator88/Pearcleaner/releases\"><strong>Download</strong></a>\n    ¬∑ \n   <a href=\"https://github.com/alienator88/Pearcleaner/commits\">Commits</a>\n  </p>\n</p>\n</br>\n\n\nA free, source-available and fair-code licensed Mac app cleaner inspired by [Freemacsoft's AppCleaner](https://freemacsoft.net/appcleaner/) and [Sun Knudsen's Privacy Guides](https://github.com/sunknudsen/guides/tree/main/archive/how-to-clean-uninstall-macos-apps-using-appcleaner-open-source-alternative) post on his app-cleaner script.\nThis project was born out of wanting to learn more on how macOS deals with app installation/uninstallation and getting more Swift experience. If you have suggestions I'm open to hearing them, submit a feature request!\n\n\n### Table of Contents:\n[Features](#features) | [Screenshots](#screenshots) | [Issues](#issues) | [Requirements](#requirements) | [Download](#getting-pearcleaner) | [Translations](#translations) | [License](#license) | [Thanks](#thanks) | [Other Apps](#other-apps)\n\n<br>\n\n\n\n## Features\n### Core\n- **App Uninstall ‚Ä¢ Orphaned File Search ‚Ä¢ Development Environment Manager ‚Ä¢ File Search ‚Ä¢ Homebrew Manager ‚Ä¢ App Lipo ‚Ä¢ PKG Manager ‚Ä¢ Plugin Manager ‚Ä¢ Services Manager ‚Ä¢ Apps Updater** \n- Drag/drop apps, CLI support, and deep link automation [view](https://github.com/alienator88/Pearcleaner/wiki/Deep-Link-Guide)\n- List or Grid view with badges for web/iOS apps\n- Finder Extension for right-click uninstall\n- Pearcleaner self-uninstall and other options\n\n### Utilities\n- Prune unused app translations, keeping only preferred languages\n- Strip unneeded architectures from universal apps without requirement of lipo binary from xcode tools\n- **Sentinel Monitor**: Automatic cleanup when apps hit Trash (~2MB RAM)\n- Export app bundles and file lists\n- Basic Steam games support\n\n### Customization\n- Theme system with custom colors\n- Include/exclude directories for searching\n- Adjustable search sensitivity\n\n## Screenshots\n\n<img src=\"https://github.com/user-attachments/assets/5095d30c-3665-4b24-bf00-756baac59026\" align=\"left\" width=\"400\" />\n<img src=\"https://github.com/user-attachments/assets/e9841914-613e-4206-b0bd-07963bf27507\" align=\"center\" width=\"400\" />\n<p></p>\n<img src=\"https://github.com/user-attachments/assets/c35258c2-2886-412c-a4c4-3c5e343e7a2c\" align=\"left\" width=\"400\" />\n<img src=\"https://github.com/user-attachments/assets/e6253ce4-b1e4-4851-a2c2-46b1f1e128cb\" align=\"center\" width=\"400\" />\n\n\n## Issues\n> [!WARNING]\n> - When submitting issues, please use the appropriate issue template corresponding with your problem [HERE](https://github.com/alienator88/Pearcleaner/issues/new/choose)\n> - Issues with no template will be closed\n> - This is a personal/hobby app, therefore the project is fairly opinionated. Opinion-based requests (e.g., ‚Äúthe layout would look better this way‚Äù) will not be considered.\n\n## Requirements\n> [!NOTE]\n> - Full Disk permission to search for files\n> - Privileged Helper to perform actions on system folders\n\n| macOS Version | Codename | Supported |\n|---------------|----------|-----------|\n| 13.x          | Ventura  | ‚úÖ        |\n| 14.x          | Sonoma   | ‚úÖ        |\n| 15.x          | Sequoia  | ‚úÖ        |\n| 26.x          | Tahoe    | ‚úÖ        |\n| TBD           | Beta     | ‚ùå        |\n> Versions prior to macOS 13.0 are not supported due to missing Swift/SwiftUI APIs required by the app.\n\n## Getting Pearcleaner\n\n<details>\n  <summary>Releases</summary>\n\nPre-compiled, always up-to-date versions are available from my [releases](https://github.com/alienator88/Pearcleaner/releases) page.\n</details>\n\n<details>\n  <summary>Homebrew</summary>\n\nYou can add the app via Homebrew:\n```\nbrew install --cask pearcleaner\n```\n</details>\n\n## Translations\nIf you are able to contribute to translations for the app, please see this discussion: https://github.com/alienator88/Pearcleaner/discussions/137\n\n## License\n> [!IMPORTANT]\n> Pearcleaner is licensed under Apache 2.0 with [Commons Clause](https://commonsclause.com/). This means that you can do anything you'd like with the source, modify it, contribute to it, etc., but the license explicitly prohibits any form of monetization for Pearcleaner or any modified versions of it. See full license [HERE](https://github.com/alienator88/Pearcleaner/blob/main/LICENSE.md)\n\n## Thanks\n\n- Much appreciation to [Freemacsoft's AppCleaner](https://freemacsoft.net/appcleaner/) and [Sun Knudsen's app-cleaner script](https://github.com/sunknudsen/guides/tree/main/archive/how-to-clean-uninstall-macos-apps-using-appcleaner-open-source-alternative) for the inspiration\n- [DharsanB](https://github.com/dharsanb) for sponsoring my Apple Developer account\n\n## Some of my apps\n\n[Pearcleaner](https://github.com/alienator88/Pearcleaner) - An opensource app cleaner with privacy in mind\n\n[Sentinel](https://github.com/alienator88/Sentinel) - A GUI for controlling gatekeeper status on your Mac\n\n[Viz](https://github.com/alienator88/Viz) - Utility for extracting text from images, videos, qr/barcodes\n\n[PearHID](https://github.com/alienator88/PearHID) - Remap your macOS keyboard with a simple SwiftUI frontend\n",
      "stars_today": 28
    },
    {
      "id": 59929513,
      "name": "skim",
      "full_name": "skim-rs/skim",
      "description": "Fuzzy Finder in rust!",
      "html_url": "https://github.com/skim-rs/skim",
      "stars": 6395,
      "forks": 234,
      "language": "Rust",
      "topics": [
        "fuzzyfinder",
        "rust",
        "skim"
      ],
      "created_at": "2016-05-29T06:24:46Z",
      "updated_at": "2026-01-23T01:51:30Z",
      "pushed_at": "2026-01-22T20:54:52Z",
      "open_issues": 33,
      "owner": {
        "login": "skim-rs",
        "avatar_url": "https://avatars.githubusercontent.com/u/187454154?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://crates.io/crates/skim\">\n    <img src=\"https://img.shields.io/crates/v/skim.svg\" alt=\"Crates.io\" />\n  </a>\n  <a href=\"https://github.com/skim-rs/skim/actions?query=workflow%3A%22Build+%26+Test%22+event%3Apush\">\n    <img src=\"https://github.com/skim-rs/skim/actions/workflows/test.yml/badge.svg?event=push\" alt=\"Build & Test\" />\n  </a>\n  <a href=\"https://repology.org/project/skim-fuzzy-finder/versions\">\n    <img src=\"https://repology.org/badge/tiny-repos/skim-fuzzy-finder.svg\" alt=\"Packaging status\" />\n  </a>\n  <a href=\"https://discord.gg/23PuxttufP\">\n    <img alt=\"Skim Discord\" src=\"https://img.shields.io/discord/1031830957432504361?label=&color=7389d8&labelColor=6a7ec2&logoColor=ffffff&logo=discord\" />\n  </a>\n  <a href=\"https://ratatui.rs\">\n    <img alt=\"Built with Ratatui\" src=\"https://ratatui.rs/built-with-ratatui/badge.svg\" />\n  </a>\n</p>\n\n> Life is short, skim!\n\nWe spend so much of our time navigating through files, lines, and commands. That's where Skim comes in!\nIt's a powerful fuzzy finder designed to make your workflow faster and more efficient.\n\n[![skim demo](https://asciinema.org/a/pIfwazaM0mTHA8F7qRbjrqOnm.svg)](https://asciinema.org/a/pIfwazaM0mTHA8F7qRbjrqOnm)\n\nSkim provides a single executable called `sk`. Think of it as a smarter alternative to tools like\n`grep` - once you try it, you'll wonder how you ever lived without it!\n\n# Table of contents\n\n- [Installation](#installation)\n   * [Package Managers](#package-managers)\n   * [Manually](#manually)\n- [Usage](#usage)\n   * [As Vim plugin](#as-vim-plugin)\n   * [As filter](#as-filter)\n   * [As Interactive Interface](#as-interactive-interface)\n   * [Shell Bindings](#shell-bindings)\n   * [Key Bindings](#key-bindings)\n   * [Search Syntax](#search-syntax)\n   * [exit code](#exit-code)\n- [Tools compatible with `skim`](#tools-compatible-with-skim)\n   * [fzf-lua neovim plugin](#fzf-lua-neovim-plugin)\n   * [nu_plugin_skim](#nu_plugin_skim)\n- [Customization](#customization)\n   * [Keymap](#keymap)\n   * [Sort Criteria](#sort-criteria)\n   * [Color Scheme](#color-scheme)\n   * [Misc](#misc)\n- [Advanced Topics](#advanced-topics)\n   * [Interactive mode](#interactive-mode)\n      + [How does it work?](#how-does-it-work)\n   * [Executing external programs](#executing-external-programs)\n   * [Preview Window](#preview-window)\n      + [How does it work?](#how-does-it-work-1)\n   * [Fields support](#fields-support)\n   * [Use as a library](#use-as-a-library)\n- [FAQ](#faq)\n   * [How to ignore files?](#how-to-ignore-files)\n   * [Some files are not shown in Vim plugin](#some-files-are-not-shown-in-vim-plugin)\n- [Differences from fzf](#differences-from-fzf)\n- [How to contribute](#how-to-contribute)\n- [Troubleshooting](#troubleshooting)\n   * [No line feed issues with nix, FreeBSD, termux](#no-line-feed-issues-with-nix-freebsd-termux)\n\n# Installation\n\nThe skim project contains several components:\n\n1. `sk` executable - the core program\n2. Vim/Nvim plugin - to call `sk` inside Vim/Nvim. Check [skim.vim](https://github.com/skim-rs/skim/blob/master/plugin/skim.vim) for Vim support.\n\n## Package Managers\n\n| OS             | Package Manager   | Command                      |\n| -------------- | ----------------- | ---------------------------- |\n| macOS          | Homebrew          | `brew install sk`            |\n| macOS          | MacPorts          | `sudo port install skim`     |\n| Alpine         | apk               | `apk add skim`               |\n| Arch           | pacman            | `pacman -S skim`             |\n| Gentoo         | Portage           | `emerge --ask app-misc/skim` |\n| Guix           | guix              | `guix install skim`          |\n| Void           | XBPS              | `xbps-install -S skim`       |\n\n<a href=\"https://repology.org/project/skim-fuzzy-finder/versions\">\n    <img src=\"https://repology.org/badge/vertical-allrepos/skim-fuzzy-finder.svg?columns=4\" alt=\"Packaging status\">\n</a>\n\n## Manually\n\nAny of the following applies:\n\n- Using the install script:\n    ```sh\n    # Always check the content of the script before running it !\n    $ curl --proto '=https' --tlsv1.2 -LsSf https://github.com/skim-rs/skim/releases/latest/download/skim-installer.sh | sh\n    ```\n- Using Binary: Simply [download the sk executable](https://github.com/skim-rs/skim/releases) directly.\n- Install from [crates.io](https://crates.io/): Run `cargo +nightly install skim` (or `cargo install skim --no-default-features --features cli` if you don't like using nightly rust, which will make you lose the `frizbee` typo-resistant matcher)\n- Build Manually:\n    ```sh\n    $ git clone --depth 1 git@github.com:skim-rs/skim.git ~/.skim\n    $ cd ~/.skim\n    $ cargo +nightly install\n    $ cargo +nightly build --release\n    $ # Add the resulting `target/release/sk` executable to your PATH\n    ```\n\n# Usage\n\nSkim can be used either as a general filter (similar to `grep`) or as an interactive\ninterface for running commands.\n\n## As Vim plugin\n\nVia vim-plug (recommended):\n\nInstall skim, then :\n\n```vim\nPlug 'skim-rs/skim'\n```\n\n\n## As filter\n\nHere are some examples to get you started:\n\n```bash\n# directly invoke skim\nsk\n\n# Or pipe some input to it (press TAB key to select multiple items when -m is enabled)\nvim $(find . -name \"*.rs\" | sk -m)\n```\nThis last command lets you select files with the \".rs\" extension and opens\nyour selections in Vim - a great time-saver for developers!\n\n## As Interactive Interface\n\n`skim` can invoke other commands dynamically. Normally you would want to\nintegrate it with [grep](https://www.gnu.org/software/grep/),\n[ack](https://github.com/petdance/ack2),\n[ag](https://github.com/ggreer/the_silver_searcher), or\n[rg](https://github.com/BurntSushi/ripgrep) for searching contents in a\nproject directory:\n\n```sh\n# works with grep\nsk --ansi -i -c 'grep -rI --color=always --line-number \"{}\" .'\n# works with ack\nsk --ansi -i -c 'ack --color \"{}\"'\n# works with ag\nsk --ansi -i -c 'ag --color \"{}\"'\n# works with rg\nsk --ansi -i -c 'rg --color=always --line-number \"{}\"'\n```\n\n> **Note**: In these examples, `{}` will be literally expanded to the current input query.\n> This means these examples will search for the exact query string, not fuzzily.\n> For fuzzy searching, pipe the command output into `sk` without using interactive mode.\n\n![interactive mode demo](https://cloud.githubusercontent.com/assets/1527040/21603930/655d859a-d1db-11e6-9fec-c25099d30a12.gif)\n\n## Shell Bindings\n\nBindings for Fish, Bash and Zsh are available in the `shell` directory:\n- `completion.{shell}` contains the completion scripts for `sk` cli usage\n- `key-bindings.{shell}` contains key-binds and shell integrations:\n    - `ctrl-t` to select a file through `sk`\n    - `ctrl-r` to select an history entry through `sk`\n    - `alt-c`  to `cd` into a directory selected through `sk`\n    - (not available in `fish`) `**` to complete file paths, for example `ls **<tab>` will show a `sk` widget to select a folder\n\nTo enable these features, source the `key-bindings.{shell}` file and set up completions according to your shell's documentation or see below.\n\n### Shell Completions\n\nYou can generate shell completions for your preferred shell using the `--shell` flag with one of the supported shells: `bash`, `zsh`, `fish`, `powershell`, or `elvish`:\n\n> **Note:** While PowerShell completions are supported, Windows is not supported for now.\n\n#### Option 1: Source directly in your current shell session\n\n```sh\n# For bash\nsource <(sk --shell bash)\n\n# For zsh\nsource <(sk --shell zsh)\n\n# For fish\nsk --shell fish | source\n```\n\n#### Option 2: Save to a file to be loaded automatically on shell startup\n\n```sh\n# For bash, add to ~/.bashrc\necho 'source <(sk --shell bash)' >> ~/.bashrc  # Or save to ~/.bash_completion\n\n# For zsh, add to ~/.zshrc\nsk --shell zsh > ~/.zfunc/_sk  # Create ~/.zfunc directory and add to fpath in ~/.zshrc\n\n# For fish, add to ~/.config/fish/completions/\nsk --shell fish > ~/.config/fish/completions/sk.fish\n```\n\n## Key Bindings\n\nSome commonly used key bindings:\n\n| Key               | Action                                     |\n|------------------:|--------------------------------------------|\n| Enter             | Accept (select current one and quit)       |\n| ESC/Ctrl-G        | Abort                                      |\n| Ctrl-P/Up         | Move cursor up                             |\n| Ctrl-N/Down       | Move cursor Down                           |\n| TAB               | Toggle selection and move down (with `-m`) |\n| Shift-TAB         | Toggle selection and move up (with `-m`)   |\n\nFor a complete list of key bindings, refer to the [man\npage](https://github.com/skim-rs/skim/blob/master/man/man1/sk.1) (`man sk`).\n\n## Search Syntax\n\n`skim` borrows `fzf`'s syntax for matching items:\n\n| Token    | Match type                 | Description                       |\n|----------|----------------------------|-----------------------------------|\n| `text`   | fuzzy-match                | items that match `text`           |\n| `^music` | prefix-exact-match         | items that start with `music`     |\n| `.mp3$`  | suffix-exact-match         | items that end with `.mp3`        |\n| `'wild`  | exact-match (quoted)       | items that include `wild`         |\n| `!fire`  | inverse-exact-match        | items that do not include `fire`  |\n| `!.mp3$` | inverse-suffix-exact-match | items that do not end with `.mp3` |\n\n`skim` also supports the combination of tokens.\n\n- Whitespace has the meaning of `AND`. With the term `src main`, `skim` will search\n    for items that match **both** `src` and `main`.\n- ` | ` means `OR` (note the spaces around `|`). With the term `.md$ |\n    .markdown$`, `skim` will search for items ends with either `.md` or\n    `.markdown`.\n- `OR` has higher precedence. For example, `readme .md$ | .markdown$` is interpreted as\n    `readme AND (.md$ OR .markdown$)`.\n\n- When using the `--split-match` option, each part around spaces or `|` will be matched in a split way:\n    - If the option's value (defaulting to `:`) is absent from the query, do a normal match\n    - If it is present, match everything before to everything before it in the items, and everything after it (including potential other occurences of the delimiter) to the part after it in the items. This is particularly useful when piping in input from `rg` to match on both file name and content.\n\nIf you prefer using regular expressions, `skim` offers a `regex` mode:\n\n```sh\nsk --regex\n```\n\nYou can switch to `regex` mode dynamically by pressing `Ctrl-R` (Rotate Mode).\n\n## exit code\n\n| Exit Code | Meaning                             |\n|-----------|-------------------------------------|\n| 0         | Exited normally                     |\n| 1         | No Match found                      |\n| 130       | Aborted by Ctrl-C/Ctrl-G/ESC/etc... |\n\n# Tools compatible with `skim`\n\nThese tools are or aim to be compatible with `skim`:\n\n## [fzf-lua neovim plugin](https://github.com/ibhagwan/fzf-lua)\n\nA [neovim](https://neovim.io) plugin allowing fzf and skim to be used in a to navigate your code.\n\nInstall it with your package manager, following the README. For instance, with `lazy.nvim`:\n\n```lua\n{\n  \"ibhagwan/fzf-lua\",\n  -- enable `sk` support instead of the default `fzf`\n  opts = {'skim'}\n}\n```\n\n## [nu_plugin_skim](https://github.com/idanarye/nu_plugin_skim)\n\nA [nushell](https://www.nushell.sh/) plugin to allow for better interaction between skim and nushell.\n\nFollowing the instruction in the plugin's README, you can install it with cargo:\n```nu\ncargo install nu_plugin_skim\nplugin add ~/.cargo/bin/nu_plugin_skim\n```\n\n# Customization\n\nThe doc here is only a preview, please check the man page (`man sk`) for a full\nlist of options.\n\n## Keymap\n\nSpecify the bindings with comma separated pairs (no space allowed). For example:\n\n```sh\nsk --bind 'alt-a:select-all,alt-d:deselect-all'\n```\n\nAdditionally, use `+` to concatenate actions, such as `execute-silent(echo {} | pbcopy)+abort`.\n\nSee the _KEY BINDINGS_ section of the man page for details.\n\n## Sort Criteria\n\nThere are five sort keys for results: `score, index, begin, end, length`. You can\nspecify how the records are sorted by `sk --tiebreak score,index,-begin` or any\nother order you want.\n\n## Color Scheme\n\nYou probably have your own aesthetic preferences! Fortunately, you aren't\nlimited to the default appearance - Skim supports comprehensive customization of its color scheme.\n\n```sh\n--color=[BASE_SCHEME][,COLOR:ANSI]\n```\n\nSkim also respects the `NO_COLOR` environment variable. Set it to anything and `sk` (and many other terminal apps) will disable all colored output. See [no-color.org](https://no-color.org/) for more details.\n\n### Available Base Color Schemes\n\nSkim comes with several built-in color schemes that you can use as a starting point:\n\n```sh\nsk --color=dark      # Default dark theme (256 colors)\nsk --color=light     # Light theme (256 colors)\nsk --color=16        # Simple 16-color theme\nsk --color=bw        # Minimal black & white theme (no colors, just styles)\nsk --color=none      # Minimal black & white theme (no colors, no styles)\nsk --color=molokai   # Molokai-inspired theme (256 colors)\n```\n\n### Customizing Colors\n\nYou can customize individual UI elements by specifying color values after the base scheme:\n\n```sh\nsk --color=light,fg:232,bg:255,current_bg:116,info:27\n```\n\nColors can be specified in several ways:\n\n- ANSI colors (0-255): `sk --color=fg:232,bg:255`\n- RGB hex values: `sk --color=fg:#FF0000` (red text)\n\n### Available Color Customization Options\n\nThe following UI elements can be customized:\n\n| Element            | Description                                 | Example                        |\n|--------------------|---------------------------------------------|--------------------------------|\n| `fg`               | Normal text foreground color                | `--color=fg:232`               |\n| `bg`               | Normal text background color                | `--color=bg:255`               |\n| `matched`          | Matched text in search results              | `--color=matched:108`          |\n| `matched_bg`       | Background of matched text                  | `--color=matched_bg:0`         |\n| `current`          | Current line foreground color               | `--color=current:254`          |\n| `current_bg`       | Current line background color               | `--color=current_bg:236`       |\n| `current_match`    | Matched text in current line                | `--color=current_match:151`    |\n| `current_match_bg` | Background of matched text in current line  | `--color=current_match_bg:236` |\n| `spinner`          | Progress indicator color                    | `--color=spinner:148`          |\n| `info`             | Information line color                      | `--color=info:144`             |\n| `prompt`           | Prompt color                                | `--color=prompt:110`           |\n| `cursor`           | Cursor color                                | `--color=cursor:161`           |\n| `selected`         | Selected item marker color                  | `--color=selected:168`         |\n| `header`           | Header text color                           | `--color=header:109`           |\n| `border`           | Border color for preview/layout             | `--color=border:59`            |\n\n### Examples\n\n```sh\n# Use light theme but change the current line background\nsk --color=light,current_bg:24\n\n# Custom theme with multiple colors\nsk --color=dark,matched:#00FF00,current:#FFFFFF,current_bg:#000080\n\n# High contrast theme\nsk --color=fg:232,bg:255,matched:160,current:255,current_bg:20\n```\n\nFor more details, check the man page (`man sk`).\n\n## Misc\n\n- `--ansi`: to parse ANSI color codes (e.g., `\\e[32mABC`) of the data source\n- `--regex`: use the query as regular expression to match the data source\n\n# Advanced Topics\n\n## Interactive mode\n\nIn **interactive mode**, you can invoke a command dynamically. Try it out:\n\n```sh\nsk --ansi -i -c 'rg --color=always --line-number \"{}\"'\n```\n\n### How does it work?\n\n![How Skim's interactive mode works](https://user-images.githubusercontent.com/1527040/53381293-461ce380-39ab-11e9-8e86-7c3bbfd557bc.png)\n\n- Skim  accepts two kinds of sources: Command output or piped input\n- Skim has two kinds of prompts: A query prompt to specify the query pattern and a\n    command prompt to specify the \"arguments\" of the command\n- `-c` is used to specify the command to execute and defaults to `SKIM_DEFAULT_COMMAND`\n- `-i` tells skim to open command prompt on startup, which will show `c>` by default.\n\nTo further narrow down the results returned by the command, press\n`Ctrl-Q` to toggle interactive mode.\n\n## Executing external programs\n\nYou can configure key bindings to start external processes without leaving Skim (`execute`, `execute-silent`).\n\n```sh\n# Press F1 to open the file with less without leaving skim\n# Press CTRL-Y to copy the line to clipboard and aborts skim (requires pbcopy)\nsk --bind 'f1:execute(less -f {}),ctrl-y:execute-silent(echo {} | pbcopy)+abort'\n```\n\n## Preview Window\n\nThis is a great feature of fzf that skim borrows. For example, we use 'ag' to\nfind the matched lines, and once we narrow down to the target lines, we want to\nfinally decide which lines to pick by checking the context around the line.\n`grep` and `ag` have the option `--context`, and skim can make use of `--context` for\na better preview window. For example:\n\n```sh\nsk --ansi -i -c 'ag --color \"{}\"' --preview \"preview.sh {}\"\n```\n\n(Note that [preview.sh](https://github.com/junegunn/fzf.vim/blob/master/bin/preview.sh) is a script to print the context given filename:lines:columns)\n\nYou get things like this:\n\n![preview demo](https://user-images.githubusercontent.com/1527040/30677573-0cee622e-9ebf-11e7-8316-c741324ecb3a.png)\n\n### How does it work?\n\nIf the preview command is given by the `--preview` option, skim will replace the\n`{}` with the current highlighted line surrounded by single quotes, call the\ncommand to get the output, and print the output on the preview window.\n\nSometimes you don't need the whole line for invoking the command. In this case\nyou can use `{}`, `{1..}`, `{..3}` or `{1..5}` to select the fields. The\nsyntax is explained in the section [Fields Support](#filds-support).\n\nLastly, you might want to configure the position of preview window with `--preview-window`:\n- `--preview-window up:30%` to put the window in the up position with height\n    30% of the total height of skim.\n- `--preview-window left:10:wrap` to specify the `wrap` allows the preview\n    window to wrap the output of the preview command.\n- `--preview-window wrap:hidden` to hide the preview window at startup, later\n    it can be shown by the action `toggle-preview`.\n\n## Fields support\n\nNormally only plugin users need to understand this.\n\nFor example, you have the data source with the format:\n\n```sh\n<filename>:<line number>:<column number>\n```\n\nHowever, you want to search `<filename>` only when typing in queries. That\nmeans when you type `21`, you want to find a `<filename>` that contains `21`,\nbut not matching line number or column number.\n\nYou can use `sk --delimiter ':' --nth 1` to achieve this.\n\nYou can also use `--with-nth` to re-arrange the order of fields.\n\n**Range Syntax**\n\n- `<num>` -- to specify the `num`-th fields, starting with 1.\n- `start..` -- starting from the `start`-th fields and the rest.\n- `..end` -- starting from the `0`-th field, all the way to `end`-th field,\n    including `end`.\n- `start..end` -- starting from `start`-th field, all the way to `end`-th\n    field, including `end`.\n\n## Use as a library\n\nSkim can be used as a library in your Rust crates.\n\nFirst, add skim into your `Cargo.toml`:\n\n```toml\n[dependencies]\nskim = { version = \"<version>\", default-features = false, features = [..] }\n```\n\n_Note on features_:\n    - the `cli` feature is required to use skim as a cli, it *should* not be needed when using it as a library.\n    - the `nightly-frizbee` feature adds the frizbee algorithm, but requires cargo nigthly.\n\nThen try to run this simple example:\n\n```rust\nextern crate skim;\nuse skim::prelude::*;\nuse std::io::Cursor;\n\npub fn main() {\n    let options = SkimOptionsBuilder::default()\n        .height(String::from(\"50%\"))\n        .multi(true)\n        .build()\n        .unwrap();\n\n    let input = \"aaaaa\\nbbbb\\nccc\".to_string();\n\n    // `SkimItemReader` is a helper to turn any `BufRead` into a stream of `SkimItem`\n    // `SkimItem` was implemented for `AsRef<str>` by default\n    let item_reader = SkimItemReader::default();\n    let items = item_reader.of_bufread(Cursor::new(input));\n\n    // `run_with` would read and show items from the stream\n    let selected_items = Skim::run_with(&options, Some(items))\n        .map(|out| out.selected_items)\n        .unwrap_or_else(|| Vec::new());\n\n    for item in selected_items.iter() {\n        println!(\"{}\", item.output());\n    }\n}\n```\n\nGiven an `Option<SkimItemReceiver>`, skim will read items accordingly, do its\njob and bring us back the user selection including the selected items, the\nquery, etc. Note that:\n\n- `SkimItemReceiver` is `crossbeam::channel::Receiver<Arc<dyn SkimItem>>`\n- If it is none, it will invoke the given command and read items from command output\n- Otherwise, it will read the items from the (crossbeam) channel.\n\nTrait `SkimItem` is provided to customize how a line could be displayed,\ncompared and previewed. It is implemented by default for `AsRef<str>`\n\nPlus, `SkimItemReader` is a helper to convert a `BufRead` into\n`SkimItemReceiver` (we can easily turn a `File` or `String` into `BufRead`),\nso that you could deal with strings or files easily.\n\nCheck out more examples under the [examples/](https://github.com/skim-rs/skim/tree/master/skim/examples) directory.\n\n# FAQ\n\n## How to ignore files?\n\nSkim invokes `find .` to fetch a list of files for filtering. You can override\nthis by setting the environment variable `SKIM_DEFAULT_COMMAND`. For example:\n\n```sh\n$ SKIM_DEFAULT_COMMAND=\"fd --type f || git ls-tree -r --name-only HEAD || rg --files || find .\"\n$ sk\n```\n\nYou could put it in your `.bashrc` or `.zshrc` if you like it to be default.\n\n## Some files are not shown in Vim plugin\n\nIf you use the Vim plugin and execute the `:SK` command, you may find some\nof your files not shown.\n\nAs described in [#3](https://github.com/skim-rs/skim/issues/3), in the Vim\nplugin, `SKIM_DEFAULT_COMMAND` is set to the command by default:\n\n```vim\nlet $SKIM_DEFAULT_COMMAND = \"git ls-tree -r --name-only HEAD || rg --files || ag -l -g \\\"\\\" || find .\"\n```\n\nThis means files not recognized by git won't be shown. You can either override the\ndefault with `let $SKIM_DEFAULT_COMMAND = ''` or locate the missing files by\nyourself.\n\n# Differences from fzf\n\n[fzf](https://github.com/junegunn/fzf) is a command-line fuzzy finder written\nin Go and [skim](https://github.com/skim-rs/skim) tries to implement a new one\nin Rust!\n\nThis project is written from scratch. Some decisions of implementation are\ndifferent from fzf. For example:\n\n1. `skim` has an interactive mode.\n2. `skim` supports pre-selection.\n3. The fuzzy search algorithm is different.\n\nMore generally, `skim`'s maintainers allow themselves some freedom of implementation.\nThe goal is to keep `skim` as feature-full as `fzf` is, but the command flags might differ.\n\n# How to contribute\n\n[Create new issues](https://github.com/skim-rs/skim/issues/new) if you encounter any bugs\nor have any ideas. Pull requests are warmly welcomed.\n\n# Troubleshooting\n\nTo troubleshoot what's happening, you can set the environment variable `RUST_LOG` to either `debug` or even `trace`, and set `--log-file` to a path. You can then read those logs during or after the execution to better understand what's happening. Don't hesitate to add those logs to an issue if you need help.\n\n## No line feed issues with nix, FreeBSD, termux\n\nIf you encounter display issues like:\n\n```bash\n$ for n in {1..10}; do echo \"$n\"; done | sk\n  0/10 0/0.> 10/10  10  9  8  7  6  5  4  3  2> 1\n```\n\nFor example\n\n- https://github.com/skim-rs/skim/issues/412\n- https://github.com/skim-rs/skim/issues/455\n\nYou need to set TERMINFO or TERMINFO_DIRS to the path of a correct terminfo database path\n\nFor example, with termux, you can add this in your bashrc:\n\n```\nexport TERMINFO=/data/data/com.termux/files/usr/share/terminfo\n```\n\n# Benchmarks\n\nThe `bench.sh` script is available to benchmark the code.\n\nYou can use it directly using `./bench.sh <binary> -n <number of items> -r <number of runs>`, or generate the data using `./bench.sh -g <output file> -n <number of items>`, then `./bench.sh <binary> -f <file> -r <number of runs>`\n",
      "stars_today": 28
    },
    {
      "id": 1001684671,
      "name": "RapidRAW",
      "full_name": "CyberTimon/RapidRAW",
      "description": "A beautiful, non-destructive, and GPU-accelerated RAW image editor built with performance in mind.",
      "html_url": "https://github.com/CyberTimon/RapidRAW",
      "stars": 4307,
      "forks": 144,
      "language": "TypeScript",
      "topics": [
        "color-grading",
        "editing",
        "image-processing",
        "masks",
        "raw",
        "react",
        "rust",
        "tauri"
      ],
      "created_at": "2025-06-13T20:16:40Z",
      "updated_at": "2026-01-23T01:53:11Z",
      "pushed_at": "2026-01-22T20:05:56Z",
      "open_issues": 93,
      "owner": {
        "login": "CyberTimon",
        "avatar_url": "https://avatars.githubusercontent.com/u/78795905?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/editor.png\" alt=\"RapidRAW Editor\">\n</p>\n\n<div align=\"center\">\n\n[![Rust](https://img.shields.io/badge/rust-%23000000.svg?style=for-the-badge&logo=rust&logoColor=white)](https://www.rust-lang.org/)\n[![wgpu](https://img.shields.io/badge/wgpu-%23282C34.svg?style=for-the-badge&logo=webgpu&logoColor=white)](https://wgpu.rs/)\n[![React](https://img.shields.io/badge/react-%2320232a.svg?style=for-the-badge&logo=react&logoColor=%2361DAFB)](https://react.dev/)\n[![Tauri](https://img.shields.io/badge/Tauri-24C8DB?style=for-the-badge&logo=tauri&logoColor=white)](https://tauri.app/)\n[![AGPL-3.0](https://img.shields.io/badge/License-AGPL_v3-blue.svg?style=for-the-badge)](https://opensource.org/licenses/AGPL-3.0)\n[![GitHub stars](https://img.shields.io/github/stars/CyberTimon/RapidRAW?style=for-the-badge&logo=github&label=Stars)](https://github.com/CyberTimon/RapidRAW/stargazers)\n<br>\n[![www.getrapidraw.com](https://img.shields.io/badge/getrapidraw.com-%232ea44f?style=for-the-badge&logo=safari&logoColor=white)](https://www.getrapidraw.com)\n[![Instagram](https://img.shields.io/badge/Instagram-%23E4405F.svg?style=for-the-badge&logo=Instagram&logoColor=white)](https://www.instagram.com/getrapidraw/)\n[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/cvFugZ2Hw8)\n\n</div>\n\n# RapidRAW\n\n> A beautiful, non-destructive, and GPU-accelerated RAW image editor built with performance in mind.\n\nRapidRAW is a modern, high-performance alternative to Adobe Lightroom¬Æ. It delivers a simple, beautiful editing experience in a lightweight package (under 20MB) for Windows, macOS, and Linux.\n\nI started developing this project as a personal challenge when I was 18. My goal was to create a high-performance tool for my own photography workflow while deepening my understanding of React, WGSL and Rust, with the support from Google Gemini.\n\n<table width=\"100%\">\n  <tr>\n    <td width=\"50%\" valign=\"top\" align=\"center\">\n      <br>\n      <a href=\"https://github.com/CyberTimon/RapidRAW/releases/latest\">\n        <img src=\"https://raw.githubusercontent.com/CyberTimon/RapidRAW/main/src-tauri/icons/full_res_original.png\" alt=\"Download RapidRAW\" height=\"96\">\n      </a>\n      <h3>Download RapidRAW</h3>\n      <p>Get the latest release for Windows, macOS, and Linux. Packaged and ready to run.</p>\n      <strong><a href=\"https://github.com/CyberTimon/RapidRAW/releases/latest\">Download Latest Version ‚Üí</a></strong>\n      <br><br>\n    </td>\n    <td width=\"50%\" valign=\"top\" align=\"center\">\n      <br>\n      <a href=\"https://github.com/CyberTimon/RapidRAW-Docs\">\n        <img src=\"https://raw.githubusercontent.com/CyberTimon/RapidRAW/main/src-tauri/icons/docs.png\" alt=\"Read the Docs\" height=\"96\">\n      </a>\n      <h3>Read the Docs</h3>\n      <p>Learn how to use RapidRAW with step-by-step tutorials, from adjustments to masking.</p>\n      <strong><a href=\"https://github.com/CyberTimon/RapidRAW-Docs\">View Tutorials & Examples ‚Üí</a></strong>\n      <br><br>\n    </td>\n  </tr>\n</table>\n\nHave fun!\n\n<details>\n<summary><strong>For Who Is This?</strong></summary>\nRapidRAW is for photographers who love to edit their photos in a <strong>clean, fast, and simple workflow</strong>. It prioritizes speed, a beautiful user interface, and powerful tools that let you achieve your creative color vision quickly.\n<br><br>\nIt is <strong>not</strong> for users who seek absolute, perfect color accuracy. While the results are great for most purposes, the focus is on a fluid, creative process rather than perfect color precision.\n<br><br>\nRapidRAW is still in active development and isn't yet as polished as mature tools like Darktable, RawTherapee, or Adobe Lightroom¬Æ. Right now, the focus is on building a fast, enjoyable core editing experience. You may encounter bugs - if you do, please report them so I can fix them :) Your feedback really helps!\n<br><br>\n</details>\n<details>\n<summary><strong>Recent Changes</strong></summary>\n\n*   **2026-01-20:** Export preset management for saving export settings \n*   **2026-01-19:** Preload library for faster startup & automatic geometry transformation helper lines\n*   **2026-01-18:** Implement image geometry transformation utils\n*   **2026-01-17:** Refactor AI panel to correctly work with the new masking system\n*   **2026-01-16:** Major masking system overhaul with drag & drop, per-mask opacity/invert & UI improvements\n*   **2026-01-13:** New python middleware client for external generative AI integration (ComfyUI)\n*   **2026-01-12:** Created a RapidRAW community discord server\n*   **2026-01-11:** Separate preview worker, optional high-quality live previews & mask/ai patch caching\n*   **2026-01-10:** Enhanced EXIF UI, optimized color wheels/curves & rawler update\n*   **2026-01-09:** Live previews for all adjustments & masks with optimized GPU processing\n\n\n<details>\n<summary><strong>Expand further</strong></summary>\n\n*   **2026-01-05:** Collage maker upgrade (drag & drop, zoom, ratio options)\n*   **2026-01-05:** 'Prefer RAW' filter option added to library\n*   **2026-01-05:** Support for uppercase file extensions\n*   **2026-01-05:** Flush thumbnail cache on folder switch\n*   **2025-12-27:** Fix LUT banding issues with improved sampling\n*   **2025-12-26:** AI masking stability improvements under load\n*   **2025-12-23:** Metadata card in toolbar & context menu export\n*   **2025-12-23:** Monochromatic grain & white balance picker improvements\n*   **2025-12-22:** BM3D Denoising with comparison slider\n*   **2025-12-20:** Batch export stability improvements & RAM optimization\n*   **2025-12-14:** Exposure slider added to masking tools\n*   **2025-12-14:** Improved delete workflow\n*   **2025-12-08:** Improved mask eraser tool behavior & ORT v2 migration\n*   **2025-12-07:** Write EXIF metadata to file\n*   **2025-12-07:** Color picker for white balance\n*   **2025-11-30:** HSL luminance artifacts fix\n*   **2025-11-29:** Improved mask stacking & many bug fixes\n*   **2025-11-28:** QOI support\n*   **2025-11-25:** Update rawler\n*   **2025-11-23:** Recursive library view to display images from all subfolders\n*   **2025-11-22:** DNG loader improvements\n*   **2025-11-18:** Improved vibrancy adjustment\n*   **2025-11-15:** Virtual copies & library improvements\n*   **2025-11-14:** Open-with-file cross plattform compatibilty & single instance lock\n*   **2025-11-13:** Rewritten tagging system to support pill-like image tagging\n*   **2025-11-10:** Improved folder tree with search functionality\n*   **2025-11-08:** Added EXR file format support\n*   **2025-11-XX:** Improving AgX\n*   **2025-11-02:** Optimize image loading & add processing engine settings\n*   **2025-10-31:** Expose highlights compression point to user & improve keybinds detection\n*   **2025-10-28:** Copy paste settings & brightness adjustment\n*   **2025-10-XX:** Working on tonemapping - ongoing...\n*   **2025-10-24:** Getting AgX right isn't as easy as it seems :=)\n*   **2025-10-22:** AgX tone mapping\n*   **2025-10-19:** Whole image mask component & organize mask components better\n*   **2025-10-19:** You can now apply presets to masks & improved auto adjustments\n*   **2025-10-17:** New centr√© adjustment, rawler now as a submodule & improved logger\n*   **2025-10-15:** Ability to pin folders, improved session handling & smooth library thumbnail updating\n*   **2025-10-11:** Realistic, complex & non-dulling exposure & highlights slider\n*   **2025-10-11:** Smooth filmstrip thumbnail updates\n*   **2025-10-07:** New watermarking support\n*   **2025-10-06:** Improve crop quality by transforming before scaling\n*   **2025-10-XX:** Many small improvements - ongoing...\n*   **2025-09-27:** Sort library by exif metadata & release cleanup / bug fixes\n*   **2025-09-26:** Collage maker to create unique collages with many different layouts, spacing & border radius\n*   **2025-09-23:** Color calibration tool to adjust RGB primaries & adjustments visibility settings\n*   **2025-09-22:** Issue template & CI/CD improvements\n*   **2025-09-20:** Universal presets importer, prioritize dGPU & improved local contrast tools (sharpness, clarity etc.)\n*   **2025-09-17:** Automatic image culling (duplicate & blur detection)\n*   **2025-09-14:** Grid previews in community panel & improved ComfyUi workflow\n*   **2025-09-12:** New community presets panel to share & showcase presets\n*   **2025-09-10:** Extended generative AI roadmap & started building RapidRAW website\n*   **2025-09-09:** Many shader improvements & bug fixes, invert tint slider\n*   **2025-09-06:** New update notifier that alerts users when a new version becomes available\n*   **2025-09-04:** Added toggleable clipping warnings (blue = shadows, red = highlights)\n*   **2025-09-02:** Transition to Rust 2024 & Cache image on GPU\n*   **2025-08-31:** Cancel thumbnail generation on folder change & optimized ai patch saving  \n*   **2025-08-30:** Optimize ComfyUI image transfer & speed\n*   **2025-08-28:** Chromatic aberration correction & Shader improvements\n*   **2025-08-26:** User customisable ComfyUI workflow selection\n*   **2025-08-25:** Make LUTs parser more robust (support more advanced formats)\n*   **2025-08-24:** Improved keyboard shortcuts\n*   **2025-08-23:** Estimate file size before exporting\n*   **2025-08-21:** Added LUTs (.cube, .3dl, .png, .jpg, .jpeg, .tiff) support\n*   **2025-08-16:** Fast AI sky masks\n*   **2025-08-15:** Show full resolution image when zooming in\n*   **2025-08-15:** Implement Tauri's IPC as a replacement for the slow Base64 image transfer\n*   **2025-08-12:** Relative zoom indicator\n*   **2025-08-11:** TypeScript cleanup & many bug fixes\n*   **2025-08-09:** Local inpainting without the need for ComfyUI, ability to change thumbnail aspect ratio\n*   **2025-08-09:** Frontend refactored to TypeScript thanks to @varjolintu\n*   **2025-08-08:** New onnxruntime download strategy & the base for local inpainting\n*   **2025-08-05:** Improved HSL cascading, UI & animation improvements, ability to grow & shrink / feather AI masks\n*   **2025-08-03:** New high performance, seamless image panorama stitcher (without any dependencies on OpenCV)\n*   **2025-08-02:** Added an image straightening tool and improved crop & rotation functionality (especially on portrait images)\n*   **2025-08-02:** A new dedicated image importer, ability to rename and batch rename files, improved dark theme, and other fixes\n*   **2025-07-31:** Ability to tag & filter images by color labels, refactored image right clicking\n*   **2025-07-31:** Reimplemented the functionality of GPU processing (GPU cropping, etc.) -> No longer dependent on TEXTURE_BINDING_ARRAY\n*   **2025-07-29:** Refactored generative AI foundation, many small fixes\n*   **2025-07-27:** Automatic AI image tagging, overall mask transparency setting per mask\n*   **2025-07-25:** Fuji RAF X-Trans sensor support (new x-trans demosaicing algo)\n*   **2025-07-24:** Auto crop when cropping an image (to prevent black borders), added drag & drop sort abilty to presets panel\n*   **2025-07-22:** Significant improvements to the shader: More accurate exposure slider, better tone mapper (simplified ACES)\n*   **2025-07-21:** Remember scroll position when going into the editing section\n*   **2025-07-20:** Ability to add presets to folders, export preset folders etc, preset _animations_\n*   **2025-07-20:** Tutorials on how to use RapidRAW\n*   **2025-07-19:** Initial color negative conversion implementation, shader improvements\n*   **2025-07-19:** New color wheels, persistent collapsed / expanded state for UI elements\n*   **2025-07-19:** Fixed banding & purple artefacts on RAW images, better color noise reduction, show exposure in stops\n*   **2025-07-18:** Smooth zoom slider, new adaptive editor theme setting\n*   **2025-07-18:** New export functionality: Export with metadata, GPS metadata remover, batch export file naming scheme using tags\n*   **2025-07-18:** Ability to delete the associated RAW/JPEG in right click delete operations\n*   **2025-07-17:** Small bug fixes\n*   **2025-07-13:** Native looking titlebar and ability to input precise number into sliders\n*   **2025-07-13:** Huge update to masks: You can now add multiple masks to a mask containers, subtract / add / combine masks etc.\n*   **2025-07-12:** Improved curves tool, more shader improvements, improved handling of very large files\n*   **2025-07-11:** More accurate shader, reorganized main library preferences dropdown, smoother histogram, more realistic film grain\n*   **2025-07-11:** Added a HUD-like waveform overlay toggle to display specific channel waveforms (w-key)\n*   **2025-07-10:** Rewritten batch export system and async thumbnail generation (makes the loading of large folders a lot more fluid)\n*   **2025-07-10:** Window transparency can now be toggled in the settings, thanks to @andrewazores\n*   **2025-07-08:** Ability to toggle the visibility of individual adjustments sections\n*   **2025-07-08:** Fixed top-left zoom bug, corrected scale behavior in crop panel, keep default original aspect ratio\n*   **2025-07-08:** Added image rating filter and redesigned the metadata panel with improved layout, clearer sections, and an embedded GPS map\n*   **2025-07-07:** Improved generative AI features and updated [AI Roadmap](#ai-roadmap)\n*   **2025-07-06:** Initial generative AI integration with [ComfyUI](https://github.com/comfyanonymous/ComfyUI) - for more details, checkout the [AI Roadmap](#ai-roadmap)\n*   **2025-07-05:** Ability to overwrite preset with current settings\n*   **2025-07-04:** High speed and precise cache to significantly accelerate large image editing\n*   **2025-07-04:** Greatly improved shader with better dehaze, more accurate curves etc\n*   **2025-07-04:** Predefined 90¬∞ clockwise rotation and ability to flip images\n*   **2025-07-03:** Switched from [rawloader](https://github.com/pedrocr/rawloader) to [rawler](https://github.com/dnglab/dnglab/tree/main/rawler) to support a wider range of RAW formats\n*   **2025-07-02:** AI-powered foreground / background masking\n*   **2025-06-30:** AI-powered subject masking\n*   **2025-06-30:** Precompiled Linux builds\n*   **2025-06-29:** New 5:4 aspect ratio, new low contrast grey theme and more cameras support (DJI Mavic lineup)\n*   **2025-06-28:** Release cleanup, CI/CD improvements and minor fixes\n*   **2025-06-27:** Initial release. For more information about the earlier progress, look at the [Initial Development Log](#initial-development-log)\n\n</details>\n</details>\n<br>\n\n**Table of Contents**\n- [Key Features](#key-features)\n- [Demo & Screenshots](#demo--screenshots)\n- [The Idea](#the-idea)\n- [Current Priorities](#current-priorities)\n- [AI Roadmap](#ai-roadmap)\n- [Initial Development Log](#initial-development-log)\n- [Getting Started](#getting-started)\n- [System Requirements](#system-requirements)\n- [Contributing](#contributing)\n- [Special Thanks](#special-thanks)\n- [Support the Project](#support-the-project)\n- [License & Philosophy](#license--philosophy)\n\n---\n\n## Key Features\n\n<table width=\"100%\">\n  <tr>\n    <td valign=\"top\" width=\"50%\">\n      <h4>Core Editing Engine</h4>\n      <ul>\n        <li><strong>GPU-Accelerated Processing:</strong> All image adjustments are processed on the GPU using a custom WGSL shader for rapid feedback.</li>\n        <li><strong>Masking:</strong> Create masks with AI subject, sky and foreground detection. Combine with traditional Brush, Linear, and Radial masks for great control.</li>\n        <li><strong>Generative Edits:</strong> Remove objects or add new elements with text prompts. Each edit creates a non-destructive patch layer, powered by an optional ComfyUI backend.</li>\n        <li><strong>Full RAW Support:</strong> Supports a wide range of RAW camera formats thanks to rawler.</li>\n        <li><strong>Non-Destructive Workflow:</strong> All edits are stored in a <code>.rrdata</code> sidecar file, leaving your original images untouched.</li>\n        <li><strong>32-bit Precision:</strong> Ensures high-quality adjustments without banding or data loss.</li>\n      </ul>\n      <h4>Professional Grade Adjustments</h4>\n      <ul>\n        <li><strong>Tonal Controls:</strong> Exposure, Contrast, Highlights, Shadows, Whites, and Blacks.</li>\n        <li><strong>Tone Curves:</strong> Full control over Luma, Red, Green, and Blue channels.</li>\n        <li><strong>Color Grading:</strong> Temperature, Tint, Vibrance, Saturation, and a full HSL color mixer.</li>\n        <li><strong>Detail Enhancement:</strong> Sharpening, Clarity, Structure, and Noise Reduction.</li>\n        <li><strong>Effects:</strong> LUTs, Dehaze, Vignette, and Film Grain simulation.</li>\n        <li><strong>Transform Tools:</strong> Crop with aspect ratio locking, Rotate, and Flip.</li>\n      </ul>\n    </td>\n    <td valign=\"top\" width=\"50%\">\n      <h4>Library & Workflow</h4>\n      <ul>\n        <li><strong>Image Library:</strong> Effortlessly sort, rate, tag, and manage your entire photo collection for a streamlined and efficient workflow.</li>\n        <li><strong>Folder Management:</strong> Integrated folder tree, create, rename, and delete folders directly within the app.</li>\n        <li><strong>File Operations:</strong> Import, copy, move, rename, and duplicate images and their associated edits.</li>\n        <li><strong>Filmstrip View:</strong> Quickly navigate between all the images in your current folder while editing.</li>\n        <li><strong>Batch Operations:</strong> Save significant time by applying a consistent set of adjustments or exporting entire batches of images simultaneously.</li>\n        <li><strong>EXIF Data Viewer:</strong> Gain insights by inspecting the complete metadata from your camera, including shutter speed, aperture, ISO, and lens information.</li>\n      </ul>\n      <h4>Productivity & UI</h4>\n      <ul>\n        <li><strong>Preset System:</strong> Create, save, import, and export your favorite looks.</li>\n        <li><strong>Copy & Paste Settings:</strong> Quickly transfer adjustments between images.</li>\n        <li><strong>Undo/Redo History:</strong> A robust history system for every edit.</li>\n        <li><strong>Customizable UI:</strong> Resizable panels and multiple beautiful UI themes with smooth animations.</li>\n        <li><strong>Panorama Stitcher:</strong> Seamlessly combine multiple images into a wide panorama.</li>\n        <li><strong>Exporting:</strong> Control file format, quality, naming scheme, metadata, resizing options on export.</li>\n      </ul>\n    </td>\n  </tr>\n</table>\n\n## Demo & Screenshots\n\nHere's RapidRAW in action.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/editor.gif\" alt=\"The main editor interface in action\"></img><br>\n  <em>The main editor interface in action.</em>\n</p>\n<br>\n<table width=\"100%\">\n  <tr>\n    <td width=\"50%\" align=\"center\">\n      <img src=\"https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/batch.gif\" alt=\"Powerful batch operations and export\" style=\"max-width: 100%;\">\n      <br>\n      <em>Powerful batch operations and export.</em>\n    </td>\n    <td width=\"50%\" align=\"center\">\n      <img src=\"https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/customization.gif\" alt=\"Customizable editor layout and panels\" style=\"max-width: 100%;\">\n      <br>\n      <em>Customizable editor layout and panels.</em>\n    </td>\n  </tr>\n  <tr>\n    <td width=\"50%\" align=\"center\">\n      <img src=\"https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/masks.gif\" alt=\"Advanced masking to speedup workflow\" style=\"max-width: 100%;\">\n      <br>\n      <em>Advanced masking to speedup workflow.</em>\n    </td>\n    <td width=\"50%\" align=\"center\">\n      <img src=\"https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/ai.gif\" alt=\"Experimental generative AI features\" style=\"max-width: 100%;\">\n      <br>\n      <em>Experimental generative AI features.</em>\n    </td>\n  </tr>\n  <tr>\n    <td width=\"50%\" align=\"center\">\n      <img src=\"https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/library.gif\" alt=\"Library navigation and folder management\" style=\"max-width: 100%;\">\n      <br>\n      <em>Library navigation and folder management.</em>\n    </td>\n    <td width=\"50%\" align=\"center\">\n      <img src=\"https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/themes.gif\" alt=\"Beautiful themes and UI customization\" style=\"max-width: 100%;\">\n      <br>\n      <em>Beautiful themes and UI customization.</em>\n    </td>\n  </tr>\n</table>\n\n> If you like the theme images and want to see more of my own images, checkout my Instagram: [**@timonkaech.photography**](https://www.instagram.com/timonkaech.photography/)\n\n## The Idea\n\n#### The Motivation\nAs a photography enthusiast, I often found existing software to be sluggish and resource-heavy on my machine. Born from the desire for a more responsive and streamlined photo editing experience, I set out to build my own. The goal was to create a tool that was not only fast but also helped me learn the details of digital image processing and camera technology.\n\n#### The Challenge\nI set an ambitious goal to rapidly build a functional, feature-rich application from an empty folder. This personal challenge pushed me to learn quickly and focus intensely on the core architecture and user experience.\n\n#### The Process\nThe foundation is built on Rust for its safety and performance, and Tauri for its ability to create lightweight, cross-platform desktop apps with a web frontend. The entire image processing pipeline is offloaded to the GPU via WGPU and a custom WGSL shader, ensuring that even on complex edits with multiple masks, the UI remains fluid.\n\nI am **immensely grateful for Google's Gemini suite of AI models.** As an 18-year-old without a formal background in advanced mathematics or image science, the AI Studio's free tier was an invaluable assistant, helping me research and implement concepts like the Menon demosaicing algorithm.\n\n## Current Priorities\n\nWhile the core functionality is in place, I'm actively working on improving several key areas. Here's a transparent look at the current focus:\n\n| Task                                                                                         | Priority | Difficulty | Status |\n|----------------------------------------------------------------------------------------------|----------|------------|--------|\n| Find a better X-Trans demosaicing algorithm                                                  | Medium  | High     | [ ]    |\n| Refactoring the frontend (reduce prop drilling in React components)                         | Low  | Medium     | [ ]    |\n| Write a tutorial on how to connect ComfyUI with RapidRAW                                    | Medium | Medium       | [ ]    |\n| Centralize Coordinate Transformation Logic - See [#245](https://github.com/CyberTimon/RapidRAW/issues/245) | Medium      | High | [ ]    |\n| Improve speed on older systems (e.g. Pascal GPUs)                                            | Medium   | High       | [ ]    |\n| Implement warping tools                                                                     | Low  | High       | [ ]    |\n\n## AI Roadmap\n\nI've designed RapidRAW's AI features with flexibility in mind. You have three ways to use them, giving you the choice between fast local tools, powerful self-hosting, and simple cloud convenience.\n\n### 1. Built-in AI Tools (Local & Free)\n\nThese features are integrated directly into RapidRAW and run entirely on your computer. They are fast, free, and require no setup from you.\n\n*   **AI Masking:** Instantly detect and mask subjects, skies, and foregrounds.\n*   **Automatic Tagging:** The image library is automatically tagged with keywords using a local CLIP model, making your photos easy to search.\n*   **Simple Generative Replace:** A basic, CPU-based inpainting tool for removing small distractions.\n\n### 2. Self-Hosted Integration with ComfyUI (Local & Free)\n\nFor users with a capable GPU who want maximum control, RapidRAW can connect to your own local [ComfyUI](https://github.com/comfyanonymous/ComfyUI) server. This is managed by the [**RapidRAW-AI-Connector**](https://github.com/CyberTimon/RapidRAW-AI-Connector), a lightweight middleware that bridges RapidRAW and ComfyUI. Its purpose is to manage image caching, workflow injection, and AI coordination.\n\n**Why this approach?** This new architecture makes generative edits much more efficient. Instead of sending the entire high-resolution image for every single change, the AI Connector intelligently caches it. The full image is sent only once; for every subsequent edit, only the tiny mask and text are transferred. This makes the process significantly faster and more responsive.\n\nThis setup gives you the best of both worlds: a highly efficient workflow while retaining full control to use your own hardware and any custom Diffusion models or workflows you choose.\n\n*   **Full Control:** Use your own hardware and any custom Diffusion model or workflow you choose.\n*   **Cost-Free Power:** Utilise your existing hardware for advanced generative edits at no extra cost.\n*   **Custom Workflow Selection:** Import your own ComfyUI workflows and use your custom nodes.\n\n### 3. Optional Cloud Service (Subscription)\n\nTo be clear, **I won't lock features behind a paywall.** All of RapidRAW's functionality is available for free if you use the built-in tools or self-host.\n\nHowever, I realize that not everyone has the powerful hardware or technical desire to set up and maintain their own ComfyUI server. For those who want a simpler solution, I will be offering an optional **$5/month subscription** (pricing is not final).\n\nThis is purely a **convenience service**. It provides the **same high-quality results** as a self-hosted setup without any of the hassle - just log in, and it works. Subscribing is also the best way to support the project and help me dedicate more time to its development.\n\n| Feature                 | Built-in AI (Free)                               | Self-Hosted (ComfyUI)                               | Optional Cloud Service                           |\n| ----------------------- | ------------------------------------------------ | --------------------------------------------------- | ------------------------------------------------ |\n| **Cost**                | Free, included                                   | Free (requires your own hardware)                   | $TBD / month                                   |\n| **Setup**               | None                                             | Manual ComfyUI / AI Connector setup                         | None (Just log in)                           |\n| **Use Case**            | Everyday workflow acceleration                   | Full control for technical users                    | Maximum convenience                          |\n| **Status**              | **Available**                                    | **Available**                                       | Coming Soon                                 |\n\n<details>\n<summary><strong>Click to see the Generative AI features in action</strong></summary>\n<br>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/ai.gif\" alt=\"Experimental generative AI features\" style=\"max-width: 100%;\">\n  <br>\n  <em>Generative Replace, which can be powered by either a local ComfyUI backend or the upcoming optional cloud service.</em>\n</p>\n</details>\n\n## Initial Development Log\n\nThis project began as an intensive sprint to build the core functionality. Here's a summary of the initial progress and key milestones:\n\n<details>\n<summary><strong>Click to expand the day-by-day development log</strong></summary>\n\n*   **Day 1: June 13th, 2025** - Project inception, basic Tauri setup, and initial brightness/contrast shader implementation.\n*   **Day 2: June 14th** - Core architecture refactor, full library support (folder tree, image list), and optimized image loading. Implemented histogram and curve editor support. Added UI themes.\n*   **Day 3: June 15th** - Implemented a working crop tool, preset system, and context menus. Enabled auto-saving of edits to sidecar files and auto-thumbnail generation. Refined color adjustments.\n*   **Day 4: June 16th** - Initial prototype for local adjustments with masking. Added mask support to presets. Bug-free image preview switching.\n*   **Day 5: June 17th** - Major UI overhaul. Created the filmstrip and resizable panel layout. Fixed mask scaling issues and improved the library/welcome screen.\n*   **Day 6: June 18th** - Performance tuning. Reduced GPU calls for adjustments, leading to a much smoother cropping and editing experience. Implemented saving of panel UI state.\n*   **Day 7: June 19th** - Enhanced library functionality. Added multi-selection and the ability to copy/paste adjustments across multiple images.\n*   **Day 8: June 20th** - Implemented initial RAW file support and an EXIF metadata viewer.\n*   **Day 9: June 21st** - Added advanced detail adjustments (Clarity, Sharpening, Dehaze, etc.) and film grain. Developed a linear RAW processing pipeline.\n*   **Day 10: June 22nd** - Implemented layer stacking for smooth preview transitions. Built a robust export panel with batch export capabilities. Added import/export for presets.\n*   **Day 11: June 23rd** - Added full undo/redo functionality integrated with a custom history hook. Improved context menus and completed the settings panel.\n*   **Day 12: June 24th** - Implemented image rotation and fixed all mask scaling/alignment issues related to cropping and rotation.\n*   **Day 13: June 25th** - Rewrote the mask system to be bitmap-based. Implemented brush and linear gradient tools, with semi-transparent visualization.\n*   **Day 14: June 26th-27th** - Final polish. Added universal keyboard shortcuts, full adjustment support for masks, theme management, and final UI/UX improvements. This ReadMe.\n\n</details>\n\n## Getting Started\n\nYou have two options to run RapidRAW:\n\n**1. Download the Latest Release (Recommended)**\n\n**Windows & macOS:**\n- Grab the pre-built installer or application bundle for your operating system from the [**Releases**](https://github.com/CyberTimon/RapidRAW/releases) page.\n\n**Linux:**\n- The official Flatpak package supports all Linux distributions and is available on [Flathub](https://flathub.org/apps/io.github.CyberTimon.RapidRAW).\n- On Debian-based distributions, install the `.deb` package from the [**Releases**](https://github.com/CyberTimon/RapidRAW/releases) page.\n- On Arch-based distributions, use the [`rapidraw-bin`](https://aur.archlinux.org/packages/rapidraw-bin) package from the AUR.\n\n**2. Build from Source**\n\nIf you want to build the project yourself, you'll need to have [Rust](https://www.rust-lang.org/tools/install) and [Node.js](https://nodejs.org/) installed.\n\n```bash\n# 1. Clone the repository (including the rawler/dnglab submodule)\ngit clone https://github.com/CyberTimon/RapidRAW.git --recurse-submodules\ncd RapidRAW\n\n# 2. Install frontend dependencies\nnpm install\n\n# 3. Build and run the application\nnpm start\n```\n\n## System Requirements\n\nRapidRAW is built to be lightweight and cross-platform. The minimum (tested) requirements are:\n\n*   **Windows:** Windows 10 or newer\n*   **macOS:** macOS 13 (Ventura) or newer\n*   **Linux:** Ubuntu 22.04+ or a compatible modern distribution\n\n### Common Problems\n<details>\n<summary>Linux Wayland/WebKit Crash</summary>\n\nIf RapidRAW crashes on Wayland (e.g. GNOME + NVIDIA), try launching it with:\n\n```bash\nWEBKIT_DISABLE_DMABUF_RENDERER=1 RapidRAW\n```\nor\n```bash\nWEBKIT_DISABLE_COMPOSITING_MODE=1 RapidRAW\n```\n\nThis issue is related to **WebKit** and **NVIDIA drivers**, not RapidRAW directly. Switching to **X11** or using **AMD / Intel GPUs** may also help.\n\nSee [#306](https://github.com/CyberTimon/RapidRAW/issues/306) for more information.\n</details>\n\n## Contributing\n\nI‚Äôm really grateful for any contributions you make to RapidRAW! Whether you‚Äôre reporting a bug, suggesting a new feature, or submitting a pull request - your input helps shape the project and makes it better for everyone. Don‚Äôt hesitate to open an issue or start a discussion to share your ideas.  \n\n### Image format issues\nIf your camera‚Äôs RAW files aren‚Äôt supported, please open a issue here first: [rawler issues](https://github.com/dnglab/dnglab/issues). Once support is added in rawler, create a issue for RapidRAW so I can update the packages and keep everything in sync.  \n\n### Feature requests\nGot an idea? Add it in the discussion tab with the **\"idea\"** tag. This way, the community can vote on features they'd love to see, and I can focus on the most impactful ones.  \n\n### Stale issues\nTo keep things tidy and relevant, please update your issue if the issue still exists with the latest release. Issues with no updates after 4-6 weeks will be closed as stale.\n\nThank you for contributing your time and ideas - every bit of feedback makes RapidRAW a stronger and more useful project!  \n\n## Special Thanks\n\nA huge thank you to the following projects and tools that were very important in the development of RapidRAW:\n\n*   **[Google AI Studio](https://aistudio.google.com):** For providing amazing assistance in researching, implementing image processing algorithms and giving an overall speed boost.\n*   **[rawler](https://github.com/dnglab/dnglab/tree/main/rawler):** For the excellent Rust crate that provides the foundation for RAW file processing in this project.\n*   **[pixls.us](https://discuss.pixls.us/):** For being an incredible community full of knowledgeable people who offered inspiration, advice, and ideas.\n*   **[darktable & co.](https://github.com/darktable-org/darktable):** For some reference implementations that guided parts of this work.\n*   **You:** For using and supporting RapidRAW. Your interest keeps this project alive and evolving.\n\n## Support the Project\n\nAs an 18-year-old developer balancing this project with an apprenticeship, your support means the world. If you find RapidRAW useful or exciting, please consider donating to help me dedicate more time to its development and cover any associated costs.\n\n-   **Ko-fi:** [Donate on Ko-fi](https://ko-fi.com/cybertimon)\n-   **Crypto:**\n    -   BTC: `36yHjo2dkBwQ63p3YwtqoYAohoZhhUTkCJ` (min. 0.0001 because of broker)\n    -   ETH: `0x597e6bdb97f3d0f1602b5efc8f3b7beb21eaf74a` (min. 0.005 because of broker)\n    -   SOL: `CkXM3C777S8iJX9h3MGSfwGxb85Yx7GHmynQUFSbZXUL` (min. 0.01 because of broker)\n\n## License & Philosophy\n\nThis project is licensed under the **GNU Affero General Public License v3.0 (AGPL-3.0)**. I chose this license to ensure that RapidRAW and any of its derivatives will always remain open-source and free for the community. It protects the project from being used in closed-source commercial software, ensuring that improvements benefit everyone.\n\nSee the [LICENSE](LICENSE) file for more details.\n",
      "stars_today": 28
    },
    {
      "id": 643647588,
      "name": "AeroSpace",
      "full_name": "nikitabobko/AeroSpace",
      "description": "AeroSpace is an i3-like tiling window manager for macOS",
      "html_url": "https://github.com/nikitabobko/AeroSpace",
      "stars": 18339,
      "forks": 395,
      "language": "Swift",
      "topics": [
        "apple",
        "i3",
        "i3wm",
        "mac",
        "macos",
        "swift",
        "tiling",
        "tiling-window-manager",
        "window-manager"
      ],
      "created_at": "2023-05-21T20:20:17Z",
      "updated_at": "2026-01-23T01:47:31Z",
      "pushed_at": "2026-01-19T16:50:08Z",
      "open_issues": 179,
      "owner": {
        "login": "nikitabobko",
        "avatar_url": "https://avatars.githubusercontent.com/u/20517828?v=4"
      },
      "readme": "# AeroSpace Beta [![Build](https://github.com/nikitabobko/AeroSpace/actions/workflows/build.yml/badge.svg?branch=main)](https://github.com/nikitabobko/AeroSpace/actions/workflows/build.yml)\n\n<img src=\"./resources/Assets.xcassets/AppIcon.appiconset/icon.png\" width=\"40%\" align=\"right\">\n\nAeroSpace is an i3-like tiling window manager for macOS\n\nVideos:\n- [YouTube 91 sec Demo](https://www.youtube.com/watch?v=UOl7ErqWbrk)\n- [YouTube Guide by Josean Martinez](https://www.youtube.com/watch?v=-FoWClVHG5g)\n\nDocs:\n- [AeroSpace Guide](https://nikitabobko.github.io/AeroSpace/guide)\n- [AeroSpace Commands](https://nikitabobko.github.io/AeroSpace/commands)\n- [AeroSpace Goodies](https://nikitabobko.github.io/AeroSpace/goodies)\n\n## Key features\n\n- Tiling window manager based on a [tree paradigm](https://nikitabobko.github.io/AeroSpace/guide#tree)\n- [i3](https://i3wm.org/) inspired\n- Fast workspaces switching without animations and without the necessity to disable SIP\n- AeroSpace employs its [own emulation of virtual workspaces](https://nikitabobko.github.io/AeroSpace/guide#emulation-of-virtual-workspaces) instead of relying on native macOS Spaces due to [their considerable limitations](https://nikitabobko.github.io/AeroSpace/guide#emulation-of-virtual-workspaces)\n- Plain text configuration (dotfiles friendly). See: [default-config.toml](https://nikitabobko.github.io/AeroSpace/guide#default-config)\n- CLI first (manpages and shell completion included)\n- Doesn't require disabling SIP (System Integrity Protection)\n- [Proper multi-monitor support](https://nikitabobko.github.io/AeroSpace/guide#multiple-monitors) (i3-like paradigm)\n\n## Installation\n\nInstall via [Homebrew](https://brew.sh/) to get autoupdates (Preferred)\n\n```\nbrew install --cask nikitabobko/tap/aerospace\n```\n\nIn multi-monitor setup please make sure that monitors [are properly arranged](https://nikitabobko.github.io/AeroSpace/guide#proper-monitor-arrangement).\n\nOther installation options: https://nikitabobko.github.io/AeroSpace/guide#installation\n\n> [!NOTE]\n> By using AeroSpace, you acknowledge that it's not [notarized](https://developer.apple.com/documentation/security/notarizing_macos_software_before_distribution).\n>\n> Notarization is a \"security\" feature by Apple.\n> You send binaries to Apple, and they either approve them or not.\n> In reality, notarization is about building binaries the way Apple likes it.\n>\n> I don't have anything against notarization as a concept.\n> I specifically don't like the way Apple does notarization.\n> I don't have time to deal with Apple.\n>\n> [Homebrew installation script](https://github.com/nikitabobko/homebrew-tap/blob/main/Casks/aerospace.rb) is configured to\n> automatically delete `com.apple.quarantine` attribute, that's why the app should work out of the box, without any warnings that\n> \"Apple cannot check AeroSpace for malicious software\"\n\n## Community, discussions, issues\n\nAeroSpace project doesn't accept Issues directly - we ask you to create a [Discussion](https://github.com/nikitabobko/AeroSpace/discussions) first.\nPlease read [CONTRIBUTING.md](./CONTRIBUTING.md) for more details.\n\nCommunity discussions happen at GitHub Discussions.\nThere you can discuss bugs, propose new features, ask your questions, show off your setup, or just chat.\n\nThere are 7 channels:\n-   [#all](https://github.com/nikitabobko/AeroSpace/discussions).\n    [RSS](https://github.com/nikitabobko/AeroSpace/discussions.atom?discussions_q=sort%3Adate_created).\n    Feed with all discussions.\n-   [#announcements](https://github.com/nikitabobko/AeroSpace/discussions/categories/announcements).\n    [RSS](https://github.com/nikitabobko/AeroSpace/discussions/categories/announcements.atom?discussions_q=category%3Aannouncements+sort%3Adate_created).\n    Only maintainers can post here.\n    Highly moderated traffic.\n-   [#announcements-releases](https://github.com/nikitabobko/AeroSpace/discussions/categories/announcements-releases).\n    [RSS](https://github.com/nikitabobko/AeroSpace/discussions/categories/announcements-releases.atom?discussions_q=category%3Aannouncements-releases+sort%3Adate_created).\n    Announcements about non-patch releases.\n    Only maintainers can post here.\n-   [#feature-ideas](https://github.com/nikitabobko/AeroSpace/discussions/categories/feature-ideas).\n    [RSS](https://github.com/nikitabobko/AeroSpace/discussions/categories/feature-ideas.atom?discussions_q=category%3Afeature-ideas+sort%3Adate_created).\n-   [#general](https://github.com/nikitabobko/AeroSpace/discussions/categories/general).\n    [RSS](https://github.com/nikitabobko/AeroSpace/discussions/categories/general.atom?discussions_q=sort%3Adate_created+category%3Ageneral).\n-   [#potential-bugs](https://github.com/nikitabobko/AeroSpace/discussions/categories/potential-bugs).\n    [RSS](https://github.com/nikitabobko/AeroSpace/discussions/categories/potential-bugs.atom?discussions_q=category%3Apotential-bugs+sort%3Adate_created).\n    If you think that you have encountered a bug, you can discuss your bugs here.\n-   [#questions-and-answers](https://github.com/nikitabobko/AeroSpace/discussions/categories/questions-and-answers).\n    [RSS](https://github.com/nikitabobko/AeroSpace/discussions/categories/questions-and-answers.atom?discussions_q=category%3Aquestions-and-answers+sort%3Adate_created).\n    Everyone is welcome to ask questions.\n    Everyone is encouraged to answer other people's questions.\n\n## Project status\n\nPublic Beta. AeroSpace can be used as a daily driver, but expect breaking changes until 1.0 is reached.\n\nWhat stops us from 1.0 release:\n- [x] https://github.com/nikitabobko/AeroSpace/issues/131 Performance. Implement thread-per-application to circumvent macOS blocking AX API.\n- [ ] https://github.com/nikitabobko/AeroSpace/issues/1215 _Big refactoring_. Rewrite mutable double-linked core tree data structure to immutable single-linked persistent tree.\n  Important for: stability and potential performance\n  - [ ] https://github.com/nikitabobko/AeroSpace/issues/1216 The big refactoring will help us to fix stability issue that windows may randomly jump to the focused workspace\n  - [ ] https://github.com/nikitabobko/AeroSpace/issues/68 The big refactoring will help us to support macOS native tabs\n- [ ] https://github.com/nikitabobko/AeroSpace/issues/278 Implement shell-like combinators.\n  Ignore a lot of crazy fuss in the issue,\n  We are most probably going with the minimal approach to only introduce common shell-combinators: `||`, `&&`, `;` and `eval` command to send multiple commands in one go.\n- [ ] https://github.com/nikitabobko/AeroSpace/issues/1012 Investigate a possibility to use `CGEvent.tapCreate` API for global hotkeys\n  - [ ] https://github.com/nikitabobko/AeroSpace/issues/28 Maybe it will allow to distinguish left and right modifiers. Maybe not\n\nBig and important issues which will go after 1.0 release:\n- [ ] https://github.com/nikitabobko/AeroSpace/issues/2 sticky windows\n- [ ] https://github.com/nikitabobko/AeroSpace/issues/260 Dynamic TWM\n\n## Development\n\nA notes on how to setup the project, build it, how to run the tests, etc. can be found here: [dev-docs/development.md](./dev-docs/development.md)\n\n## Project values\n\n**Values**\n- AeroSpace is targeted at advanced users and developers\n- Keyboard centric\n- Breaking changes (configuration files, CLI, behavior) are avoided as much as possible, but it must not let the software stagnate.\n  Thus breaking changes can happen, but with careful considerations and helpful message.\n  [Semver](https://semver.org/) major version is bumped in case of a breaking change (It's all guaranteed once AeroSpace reaches 1.0 version, until then breaking changes just happen)\n- AeroSpace doesn't use GUI, unless necessarily\n  - AeroSpace will never provide a GUI for configuration.\n    For advanced users, it's easier to edit a configuration file in text editor rather than navigating through checkboxes in GUI.\n  - Status menu icon is ok, because visual feedback is needed\n- Provide _practical_ features. Fancy appearance features are not _practical_ (e.g. window borders, transparency, animations, etc.)\n- \"dark magic\" (aka \"private APIs\", \"code injections\", etc.) must be avoided as much as possible\n  - Right now, AeroSpace uses only a single private API to get window ID of accessibility object `_AXUIElementGetWindow`.\n    Everything else is [macOS public accessibility API](https://developer.apple.com/documentation/applicationservices/axuielement_h).\n  - AeroSpace will never require you to disable SIP (System Integrity Protection).\n  - The goal is to make AeroSpace easily maintainable, and resistant to macOS updates.\n\n**Non Values**\n- Play nicely with existing macOS features.\n  If limitations are imposed then AeroSpace won't play nicely with existing macOS features\n  (For example, AeroSpace doesn't acknowledge the existence of macOS Spaces, and it uses [emulation of its own workspaces](https://nikitabobko.github.io/AeroSpace/guide#emulation-of-virtual-workspaces))\n- Ricing.\n  AeroSpace provides only a very minimal support for ricing - gaps and a few callbacks for integrations with bars.\n  The current maintainer doesn't care about ricing.\n  Ricing issues are not a priority, and they are mostly ignored.\n  The ricing stance can change only with the appearance of more maintainers.\n\n## macOS compatibility table\n\n|                                                                                | macOS 13 (Ventura) | macOS 14 (Sonoma) | macOS 15 (Sequoia) | macOS 26 (Tahoe) |\n| ------------------------------------------------------------------------------ | ------------------ | ----------------- | ------------------ | ---------------- |\n| AeroSpace binary runs on ...                                                   | +                  | +                 | +                  | +                |\n| AeroSpace debug build from sources is supported on ...                         |                    | +                 | +                  | +                |\n| AeroSpace release build from sources is supported on ... (Requires Xcode 26+)  |                    |                   | +                  | +                |\n\n## Sponsorship\n\nAeroSpace is developed and maintained in my free time.\nIf you find it useful, [consider sponsoring](https://github.com/sponsors/nikitabobko#sponsors).\n\n## People who have write access\n\nIn alphabetical order:\n\n- [@mobile-ar](https://github.com/mobile-ar/)\n- [@nikitabobko](https://github.com/nikitabobko/)\n\n## Tip of the day\n\n```bash\ndefaults write -g NSWindowShouldDragOnGesture -bool true\n```\n\nNow, you can move windows by holding `ctrl`+`cmd` and dragging any part of the window (not necessarily the window title)\n\nSource: [reddit](https://www.reddit.com/r/MacOS/comments/k6hiwk/keyboard_modifier_to_simplify_click_drag_of/)\n\n## Related projects\n\n- [Amethyst](https://github.com/ianyh/Amethyst)\n- [yabai](https://github.com/koekeishiya/yabai)\n",
      "stars_today": 26
    },
    {
      "id": 100767968,
      "name": "voidImageViewer",
      "full_name": "voidtools/voidImageViewer",
      "description": "Lightweight image viewer for Windows with animated GIF/WEBP support",
      "html_url": "https://github.com/voidtools/voidImageViewer",
      "stars": 995,
      "forks": 60,
      "language": "C",
      "topics": [],
      "created_at": "2017-08-19T03:43:38Z",
      "updated_at": "2026-01-23T02:08:16Z",
      "pushed_at": "2026-01-22T11:18:40Z",
      "open_issues": 18,
      "owner": {
        "login": "voidtools",
        "avatar_url": "https://avatars.githubusercontent.com/u/31149593?v=4"
      },
      "readme": "# void Image Viewer\nA lightweight image viewer for Windows with animated GIF/WEBP support.  \nOpens and displays BMP, GIF, ICO, PNG, JPG, TIF and WEBP images as fast as possible.  \nAnimate GIF/WEBP files as accurately as possible.  \n\n[Download](#download)<br/>\n[See also](#See-also)<br/>\n<br/><br/><br/>\n\n\n\nDownload\n--------\nhttps://github.com/voidtools/voidImageViewer/releases\n\nhttps://www.voidtools.com/forum/viewtopic.php?t=5623\n<br/><br/><br/>\n\n\nvoid Image Viewer main window:\n\n![Void Image Viewer Image View](https://www.voidtools.com/voidImageViewer.Image.View10.gif)\n<br/><br/><br/>\n\n\n\nvoid Image Viewer General Options:\n\n![Void Image Viewer Options General](https://www.voidtools.com/voidImageViewer.Options.General10.png)\n<br/><br/><br/>\n\n\n\nvoid Image Viewer View Options:\n\n![Void Image Viewer Options View](https://www.voidtools.com/voidImageViewer.Options.View10.png)\n<br/><br/><br/>\n\n\n\nvoid Image Viewer Controls Options:\n\n![Void Image Viewer Image Controls](https://www.voidtools.com/voidImageViewer.Options.Controls10.png)\n<br/><br/><br/>\n\n\n\nSee also\n--------\nhttps://www.voidtools.com/forum/viewtopic.php?t=5623\n",
      "stars_today": 25
    },
    {
      "id": 107505869,
      "name": "firecracker",
      "full_name": "firecracker-microvm/firecracker",
      "description": "Secure and fast microVMs for serverless computing.",
      "html_url": "https://github.com/firecracker-microvm/firecracker",
      "stars": 31991,
      "forks": 2218,
      "language": "Rust",
      "topics": [
        "containers",
        "minimalist",
        "open-source",
        "oversubscription",
        "rust",
        "sandbox",
        "serverless",
        "virtual-machine",
        "virtualization"
      ],
      "created_at": "2017-10-19T06:18:47Z",
      "updated_at": "2026-01-23T01:48:43Z",
      "pushed_at": "2026-01-22T14:36:40Z",
      "open_issues": 73,
      "owner": {
        "login": "firecracker-microvm",
        "avatar_url": "https://avatars.githubusercontent.com/u/44477506?v=4"
      },
      "readme": "<picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/fc_logo_full_transparent-bg_white-fg.png\">\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"docs/images/fc_logo_full_transparent-bg.png\">\n   <img alt=\"Firecracker Logo Title\" width=\"750\" src=\"docs/images/fc_logo_full_transparent-bg.png\">\n</picture>\n\nOur mission is to enable secure, multi-tenant, minimal-overhead execution of\ncontainer and function workloads.\n\nRead more about the Firecracker Charter [here](CHARTER.md).\n\n## What is Firecracker?\n\nFirecracker is an open source virtualization technology that is purpose-built\nfor creating and managing secure, multi-tenant container and function-based\nservices that provide serverless operational models. Firecracker runs workloads\nin lightweight virtual machines, called microVMs, which combine the security and\nisolation properties provided by hardware virtualization technology with the\nspeed and flexibility of containers.\n\n## Overview\n\nThe main component of Firecracker is a virtual machine monitor (VMM) that uses\nthe Linux Kernel Virtual Machine (KVM) to create and run microVMs. Firecracker\nhas a minimalist design. It excludes unnecessary devices and guest-facing\nfunctionality to reduce the memory footprint and attack surface area of each\nmicroVM. This improves security, decreases the startup time, and increases\nhardware utilization. Firecracker has also been integrated in container\nruntimes, for example\n[Kata Containers](https://github.com/kata-containers/kata-containers) and\n[Flintlock](https://github.com/liquidmetal-dev/flintlock).\n\nFirecracker was developed at Amazon Web Services to accelerate the speed and\nefficiency of services like [AWS Lambda](https://aws.amazon.com/lambda/) and\n[AWS Fargate](https://aws.amazon.com/fargate/). Firecracker is open sourced\nunder [Apache version 2.0](LICENSE).\n\nTo read more about Firecracker, check out\n[firecracker-microvm.io](https://firecracker-microvm.github.io).\n\n## Getting Started\n\nTo get started with Firecracker, download the latest\n[release](https://github.com/firecracker-microvm/firecracker/releases) binaries\nor build it from source.\n\nYou can build Firecracker on any Unix/Linux system that has Docker running (we\nuse a development container) and `bash` installed, as follows:\n\n```bash\ngit clone https://github.com/firecracker-microvm/firecracker\ncd firecracker\ntools/devtool build\ntoolchain=\"$(uname -m)-unknown-linux-musl\"\n```\n\nThe Firecracker binary will be placed at\n`build/cargo_target/${toolchain}/debug/firecracker`. For more information on\nbuilding, testing, and running Firecracker, go to the\n[quickstart guide](docs/getting-started.md).\n\nThe overall security of Firecracker microVMs, including the ability to meet the\ncriteria for safe multi-tenant computing, depends on a well configured Linux\nhost operating system. A configuration that we believe meets this bar is\nincluded in [the production host setup document](docs/prod-host-setup.md).\n\n## Contributing\n\nFirecracker is already running production workloads within AWS, but it's still\nDay 1 on the journey guided by our [mission](CHARTER.md). There's a lot more to\nbuild and we welcome all contributions.\n\nTo contribute to Firecracker, check out the development setup section in the\n[getting started guide](docs/getting-started.md) and then the Firecracker\n[contribution guidelines](CONTRIBUTING.md).\n\n## Releases\n\nNew Firecracker versions are released via the GitHub repository\n[releases](https://github.com/firecracker-microvm/firecracker/releases) page,\ntypically every two or three months. A history of changes is recorded in our\n[changelog](CHANGELOG.md).\n\nThe Firecracker release policy is detailed [here](docs/RELEASE_POLICY.md).\n\n## Design\n\nFirecracker's overall architecture is described in\n[the design document](docs/design.md).\n\n## Features & Capabilities\n\nFirecracker consists of a single micro Virtual Machine Manager process that\nexposes an API endpoint to the host once started. The API is\n[specified in OpenAPI format](src/firecracker/swagger/firecracker.yaml). Read\nmore about it in the [API docs](docs/api_requests).\n\nThe **API endpoint** can be used to:\n\n- Configure the microvm by:\n  - Setting the number of vCPUs (the default is 1).\n  - Setting the memory size (the default is 128 MiB).\n  - Configuring a [CPU template](docs/cpu_templates/cpu-templates.md).\n- Add one or more network interfaces to the microVM.\n- Add one or more read-write or read-only disks to the microVM, each represented\n  by a file-backed block device.\n- Trigger a block device re-scan while the guest is running. This enables the\n  guest OS to pick up size changes to the block device's backing file.\n- Change the backing file for a block device, before or after the guest boots.\n- Configure rate limiters for virtio devices which can limit the bandwidth,\n  operations per second, or both.\n- Configure the logging and metric system.\n- `[BETA]` Configure the data tree of the guest-facing metadata service. The\n  service is only available to the guest if this resource is configured.\n- Add a [vsock socket](docs/vsock.md) to the microVM.\n- Add a [entropy device](docs/entropy.md) to the microVM.\n- Add a [pmem device](docs/pmem.md) to the microVM.\n- Configure and manage [memory hotplugging](docs/memory-hotplug.md).\n- Start the microVM using a given kernel image, root file system, and boot\n  arguments.\n- [x86_64 only] Stop the microVM.\n\n**Built-in Capabilities**:\n\n- Demand fault paging and CPU oversubscription enabled by default.\n- Advanced, thread-specific seccomp filters for enhanced security.\n- [Jailer](docs/jailer.md) process for starting Firecracker in production\n  scenarios; applies a cgroup/namespace isolation barrier and then drops\n  privileges.\n\n## Tested platforms\n\nWe test all combinations of:\n\n| Instance                               | Host OS & Kernel | Guest Rootfs | Guest Kernel |\n| :------------------------------------- | :--------------- | :----------- | :----------- |\n| m5n.metal (Intel Cascade Lake)         | al2 linux_5.10   | ubuntu 24.04 | linux_5.10   |\n| m6i.metal (Intel Ice Lake)             | al2023 linux_6.1 |              | linux_6.1    |\n| m7i.metal-24xl (Intel Sapphire Rapids) |                  |              |              |\n| m7i.metal-48xl (Intel Sapphire Rapids) |                  |              |              |\n| m6a.metal (AMD Milan)                  |                  |              |              |\n| m7a.metal-48xl (AMD Genoa)             |                  |              |              |\n| m6g.metal (Graviton 2)                 |                  |              |              |\n| m7g.metal (Graviton 3)                 |                  |              |              |\n| m8g.metal-24xl (Graviton 4)            |                  |              |              |\n| m8g.metal-48xl (Graviton 4)            |                  |              |              |\n\n## Known issues and Limitations\n\n- The `pl031` RTC device on aarch64 does not support interrupts, so guest\n  programs which use an RTC alarm (e.g. `hwclock`) will not work.\n\n## Performance\n\nFirecracker's performance characteristics are listed as part of the\n[specification documentation](SPECIFICATION.md). All specifications are a part\nof our commitment to supporting container and function workloads in serverless\noperational models, and are therefore enforced via continuous integration\ntesting.\n\n## Policy for Security Disclosures\n\nThe security of Firecracker is our top priority. If you suspect you have\nuncovered a vulnerability, contact us privately, as outlined in our\n[security policy document](SECURITY.md); we will immediately prioritize your\ndisclosure.\n\n## FAQ & Contact\n\nFrequently asked questions are collected in our [FAQ doc](FAQ.md).\n\nYou can get in touch with the Firecracker community in the following ways:\n\n- Security-related issues, see our [security policy document](SECURITY.md).\n- Chat with us on our\n  [Slack workspace](https://join.slack.com/t/firecracker-microvm/shared_invite/zt-2tc0mfxpc-tU~HYAYSzLDl5XGGJU3YIg)\n  _Note: most of the maintainers are on a European time zone._\n- Open a GitHub issue in this repository.\n- Email the maintainers at\n  [firecracker-maintainers@amazon.com](mailto:firecracker-maintainers@amazon.com).\n\nWhen communicating within the Firecracker community, please mind our\n[code of conduct](CODE_OF_CONDUCT.md).\n",
      "stars_today": 24
    },
    {
      "id": 27193779,
      "name": "node",
      "full_name": "nodejs/node",
      "description": "Node.js JavaScript runtime ‚ú®üê¢üöÄ‚ú®",
      "html_url": "https://github.com/nodejs/node",
      "stars": 115341,
      "forks": 34462,
      "language": "JavaScript",
      "topics": [
        "javascript",
        "js",
        "linux",
        "macos",
        "mit",
        "node",
        "nodejs",
        "runtime",
        "windows"
      ],
      "created_at": "2014-11-26T19:57:11Z",
      "updated_at": "2026-01-23T02:11:44Z",
      "pushed_at": "2026-01-22T22:34:42Z",
      "open_issues": 2419,
      "owner": {
        "login": "nodejs",
        "avatar_url": "https://avatars.githubusercontent.com/u/9950313?v=4"
      },
      "readme": "# Node.js\n\nNode.js is an open-source, cross-platform JavaScript runtime environment.\n\nFor information on using Node.js, see the [Node.js website][].\n\nThe Node.js project uses an [open governance model](./GOVERNANCE.md). The\n[OpenJS Foundation][] provides support for the project.\n\nContributors are expected to act in a collaborative manner to move\nthe project forward. We encourage the constructive exchange of contrary\nopinions and compromise. The [TSC](./GOVERNANCE.md#technical-steering-committee)\nreserves the right to limit or block contributors who repeatedly act in ways\nthat discourage, exhaust, or otherwise negatively affect other participants.\n\n**This project has a [Code of Conduct][].**\n\n## Table of contents\n\n* [Support](#support)\n* [Release types](#release-types)\n  * [Download](#download)\n    * [Current and LTS releases](#current-and-lts-releases)\n    * [Nightly releases](#nightly-releases)\n    * [API documentation](#api-documentation)\n  * [Verifying binaries](#verifying-binaries)\n* [Building Node.js](#building-nodejs)\n* [Security](#security)\n* [Contributing to Node.js](#contributing-to-nodejs)\n* [Current project team members](#current-project-team-members)\n  * [TSC (Technical Steering Committee)](#tsc-technical-steering-committee)\n  * [Collaborators](#collaborators)\n  * [Triagers](#triagers)\n  * [Release keys](#release-keys)\n* [License](#license)\n\n## Support\n\nLooking for help? Check out the\n[instructions for getting support](.github/SUPPORT.md).\n\n## Release types\n\n* **Current**: Under active development. Code for the Current release is in the\n  branch for its major version number (for example,\n  [v22.x](https://github.com/nodejs/node/tree/v22.x)). Node.js releases a new\n  major version every 6 months, allowing for breaking changes. This happens in\n  April and October every year. Releases appearing each October have a support\n  life of 8 months. Releases appearing each April convert to LTS (see below)\n  each October.\n* **LTS**: Releases that receive Long Term Support, with a focus on stability\n  and security. Every even-numbered major version will become an LTS release.\n  LTS releases receive 12 months of _Active LTS_ support and a further 18 months\n  of _Maintenance_. LTS release lines have alphabetically-ordered code names,\n  beginning with v4 Argon. There are no breaking changes or feature additions,\n  except in some special circumstances.\n* **Nightly**: Code from the Current branch built every 24-hours when there are\n  changes. Use with caution.\n\nCurrent and LTS releases follow [semantic versioning](https://semver.org). A\nmember of the Release Team [signs](#release-keys) each Current and LTS release.\nFor more information, see the\n[Release README](https://github.com/nodejs/Release#readme).\n\n### Download\n\nBinaries, installers, and source tarballs are available at\n<https://nodejs.org/en/download/>.\n\n#### Current and LTS releases\n\n<https://nodejs.org/download/release/>\n\nThe [latest](https://nodejs.org/download/release/latest/) directory is an\nalias for the latest Current release. The latest-_codename_ directory is an\nalias for the latest release from an LTS line. For example, the\n[latest-hydrogen](https://nodejs.org/download/release/latest-hydrogen/)\ndirectory contains the latest Hydrogen (Node.js 18) release.\n\n#### Nightly releases\n\n<https://nodejs.org/download/nightly/>\n\nEach directory and filename includes the version (e.g., `v22.0.0`),\nfollowed by the UTC date (e.g., `20240424` for April 24, 2024),\nand the short commit SHA of the HEAD of the release (e.g., `ddd0a9e494`).\nFor instance, a full directory name might look like `v22.0.0-nightly20240424ddd0a9e494`.\n\n#### API documentation\n\nDocumentation for the latest Current release is at <https://nodejs.org/api/>.\nVersion-specific documentation is available in each release directory in the\n_docs_ subdirectory. Version-specific documentation is also at\n<https://nodejs.org/download/docs/>.\n\n### Verifying binaries\n\nDownload directories contain a `SHASUMS256.txt.asc` file with SHA checksums for the\nfiles and the releaser PGP signature.\n\nYou can get a trusted keyring from nodejs/release-keys, e.g. using `curl`:\n\n```bash\ncurl -fsLo \"/path/to/nodejs-keyring.kbx\" \"https://github.com/nodejs/release-keys/raw/HEAD/gpg/pubring.kbx\"\n```\n\nAlternatively, you can import the releaser keys in your default keyring, see\n[Release keys](#release-keys) for commands to how to do that.\n\nThen, you can verify the files you've downloaded locally\n(if you're using your default keyring, pass `--keyring=\"${GNUPGHOME:-~/.gnupg}/pubring.kbx\"`):\n\n```bash\ncurl -fsO \"https://nodejs.org/dist/${VERSION}/SHASUMS256.txt.asc\" \\\n&& gpgv --keyring=\"/path/to/nodejs-keyring.kbx\" --output SHASUMS256.txt < SHASUMS256.txt.asc \\\n&& shasum --check SHASUMS256.txt --ignore-missing\n```\n\n## Building Node.js\n\nSee [BUILDING.md](BUILDING.md) for instructions on how to build Node.js from\nsource and a list of supported platforms.\n\n## Security\n\nFor information on reporting security vulnerabilities in Node.js, see\n[SECURITY.md](./SECURITY.md).\n\n## Contributing to Node.js\n\n* [Contributing to the project][]\n* [Working Groups][]\n* [Strategic initiatives][]\n* [Technical values and prioritization][]\n\n## Current project team members\n\nFor information about the governance of the Node.js project, see\n[GOVERNANCE.md](./GOVERNANCE.md).\n\n<!-- node-core-utils and find-inactive-tsc.mjs depend on the format of the TSC\n     list. If the format changes, those utilities need to be tested and\n     updated. -->\n\n### TSC (Technical Steering Committee)\n\n#### TSC voting members\n\n<!--lint disable prohibited-strings-->\n\n* [aduh95](https://github.com/aduh95) -\n  **Antoine du Hamel** <<duhamelantoine1995@gmail.com>> (he/him)\n* [anonrig](https://github.com/anonrig) -\n  **Yagiz Nizipli** <<yagiz@nizipli.com>> (he/him)\n* [benjamingr](https://github.com/benjamingr) -\n  **Benjamin Gruenbaum** <<benjamingr@gmail.com>>\n* [BridgeAR](https://github.com/BridgeAR) -\n  **Ruben Bridgewater** <<ruben@bridgewater.de>> (he/him)\n* [gireeshpunathil](https://github.com/gireeshpunathil) -\n  **Gireesh Punathil** <<gpunathi@in.ibm.com>> (he/him)\n* [jasnell](https://github.com/jasnell) -\n  **James M Snell** <<jasnell@gmail.com>> (he/him)\n* [joyeecheung](https://github.com/joyeecheung) -\n  **Joyee Cheung** <<joyeec9h3@gmail.com>> (she/her)\n* [legendecas](https://github.com/legendecas) -\n  **Chengzhong Wu** <<legendecas@gmail.com>> (he/him)\n* [marco-ippolito](https://github.com/marco-ippolito) -\n  **Marco Ippolito** <<marcoippolito54@gmail.com>> (he/him)\n* [mcollina](https://github.com/mcollina) -\n  **Matteo Collina** <<matteo.collina@gmail.com>> (he/him)\n* [panva](https://github.com/panva) -\n  **Filip Skokan** <<panva.ip@gmail.com>> (he/him)\n* [RafaelGSS](https://github.com/RafaelGSS) -\n  **Rafael Gonzaga** <<rafael.nunu@hotmail.com>> (he/him)\n* [RaisinTen](https://github.com/RaisinTen) -\n  **Darshan Sen** <<raisinten@gmail.com>> (he/him)\n* [richardlau](https://github.com/richardlau) -\n  **Richard Lau** <<richard.lau@ibm.com>>\n* [ronag](https://github.com/ronag) -\n  **Robert Nagy** <<ronagy@icloud.com>>\n* [ruyadorno](https://github.com/ruyadorno) -\n  **Ruy Adorno** <<ruy@vlt.sh>> (he/him)\n* [ShogunPanda](https://github.com/ShogunPanda) -\n  **Paolo Insogna** <<paolo@cowtech.it>> (he/him)\n* [targos](https://github.com/targos) -\n  **Micha√´l Zasso** <<targos@protonmail.com>> (he/him)\n* [tniessen](https://github.com/tniessen) -\n  **Tobias Nie√üen** <<tniessen@tnie.de>> (he/him)\n\n#### TSC regular members\n\n* [BethGriggs](https://github.com/BethGriggs) -\n  **Beth Griggs** <<bethanyngriggs@gmail.com>> (she/her)\n* [bnoordhuis](https://github.com/bnoordhuis) -\n  **Ben Noordhuis** <<info@bnoordhuis.nl>>\n* [cjihrig](https://github.com/cjihrig) -\n  **Colin Ihrig** <<cjihrig@gmail.com>> (he/him)\n* [codebytere](https://github.com/codebytere) -\n  **Shelley Vohr** <<shelley.vohr@gmail.com>> (she/her)\n* [GeoffreyBooth](https://github.com/GeoffreyBooth) -\n  **Geoffrey Booth** <<webadmin@geoffreybooth.com>> (he/him)\n* [MoLow](https://github.com/MoLow) -\n  **Moshe Atlow** <<moshe@atlow.co.il>> (he/him)\n* [Trott](https://github.com/Trott) -\n  **Rich Trott** <<rtrott@gmail.com>> (he/him)\n\n<details>\n\n<summary>TSC emeriti members</summary>\n\n#### TSC emeriti members\n\n* [addaleax](https://github.com/addaleax) -\n  **Anna Henningsen** <<anna@addaleax.net>> (she/her)\n* [apapirovski](https://github.com/apapirovski) -\n  **Anatoli Papirovski** <<apapirovski@mac.com>> (he/him)\n* [ChALkeR](https://github.com/ChALkeR) -\n  **–°–∫–æ–≤–æ—Ä–æ–¥–∞ –ù–∏–∫–∏—Ç–∞ –ê–Ω–¥—Ä–µ–µ–≤–∏—á** <<chalkerx@gmail.com>> (he/him)\n* [chrisdickinson](https://github.com/chrisdickinson) -\n  **Chris Dickinson** <<christopher.s.dickinson@gmail.com>>\n* [danbev](https://github.com/danbev) -\n  **Daniel Bevenius** <<daniel.bevenius@gmail.com>> (he/him)\n* [danielleadams](https://github.com/danielleadams) -\n  **Danielle Adams** <<adamzdanielle@gmail.com>> (she/her)\n* [evanlucas](https://github.com/evanlucas) -\n  **Evan Lucas** <<evanlucas@me.com>> (he/him)\n* [fhinkel](https://github.com/fhinkel) -\n  **Franziska Hinkelmann** <<franziska.hinkelmann@gmail.com>> (she/her)\n* [Fishrock123](https://github.com/Fishrock123) -\n  **Jeremiah Senkpiel** <<fishrock123@rocketmail.com>> (he/they)\n* [gabrielschulhof](https://github.com/gabrielschulhof) -\n  **Gabriel Schulhof** <<gabrielschulhof@gmail.com>>\n* [gibfahn](https://github.com/gibfahn) -\n  **Gibson Fahnestock** <<gibfahn@gmail.com>> (he/him)\n* [indutny](https://github.com/indutny) -\n  **Fedor Indutny** <<fedor@indutny.com>>\n* [isaacs](https://github.com/isaacs) -\n  **Isaac Z. Schlueter** <<i@izs.me>>\n* [joshgav](https://github.com/joshgav) -\n  **Josh Gavant** <<josh.gavant@outlook.com>>\n* [mhdawson](https://github.com/mhdawson) -\n  **Michael Dawson** <<midawson@redhat.com>> (he/him)\n* [mmarchini](https://github.com/mmarchini) -\n  **Mary Marchini** <<oss@mmarchini.me>> (she/her)\n* [mscdex](https://github.com/mscdex) -\n  **Brian White** <<mscdex@mscdex.net>>\n* [MylesBorins](https://github.com/MylesBorins) -\n  **Myles Borins** <<myles.borins@gmail.com>> (he/him)\n* [nebrius](https://github.com/nebrius) -\n  **Bryan Hughes** <<bryan@nebri.us>>\n* [ofrobots](https://github.com/ofrobots) -\n  **Ali Ijaz Sheikh** <<ofrobots@google.com>> (he/him)\n* [orangemocha](https://github.com/orangemocha) -\n  **Alexis Campailla** <<orangemocha@nodejs.org>>\n* [piscisaureus](https://github.com/piscisaureus) -\n  **Bert Belder** <<bertbelder@gmail.com>>\n* [rvagg](https://github.com/rvagg) -\n  **Rod Vagg** <<r@va.gg>>\n* [sam-github](https://github.com/sam-github) -\n  **Sam Roberts** <<vieuxtech@gmail.com>>\n* [shigeki](https://github.com/shigeki) -\n  **Shigeki Ohtsu** <<ohtsu@ohtsu.org>> (he/him)\n* [thefourtheye](https://github.com/thefourtheye) -\n  **Sakthipriyan Vairamani** <<thechargingvolcano@gmail.com>> (he/him)\n* [TimothyGu](https://github.com/TimothyGu) -\n  **Tiancheng \"Timothy\" Gu** <<timothygu99@gmail.com>> (he/him)\n* [trevnorris](https://github.com/trevnorris) -\n  **Trevor Norris** <<trev.norris@gmail.com>>\n\n</details>\n\n<!-- node-core-utils and find-inactive-collaborators.mjs depend on the format\n     of the collaborator list. If the format changes, those utilities need to be\n     tested and updated. -->\n\n### Collaborators\n\n* [abmusse](https://github.com/abmusse) -\n  **Abdirahim Musse** <<abdirahim.musse@ibm.com>>\n* [addaleax](https://github.com/addaleax) -\n  **Anna Henningsen** <<anna@addaleax.net>> (she/her)\n* [Aditi-1400](https://github.com/Aditi-1400) -\n  **Aditi Singh** <<aditisingh1400@gmail.com>> (she/her)\n* [aduh95](https://github.com/aduh95) -\n  **Antoine du Hamel** <<duhamelantoine1995@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/aduh95)\n* [anonrig](https://github.com/anonrig) -\n  **Yagiz Nizipli** <<yagiz@nizipli.com>> (he/him) - [Support me](https://github.com/sponsors/anonrig)\n* [atlowChemi](https://github.com/atlowChemi) -\n  **Chemi Atlow** <<chemi@atlow.co.il>> (he/him)\n* [avivkeller](https://github.com/avivkeller) -\n  **Aviv Keller** <<me@aviv.sh>> (he/him) - [Support me](https://github.com/sponsors/avivkeller)\n* [Ayase-252](https://github.com/Ayase-252) -\n  **Qingyu Deng** <<i@ayase-lab.com>>\n* [bengl](https://github.com/bengl) -\n  **Bryan English** <<bryan@bryanenglish.com>> (he/him)\n* [benjamingr](https://github.com/benjamingr) -\n  **Benjamin Gruenbaum** <<benjamingr@gmail.com>>\n* [BethGriggs](https://github.com/BethGriggs) -\n  **Beth Griggs** <<bethanyngriggs@gmail.com>> (she/her)\n* [bnb](https://github.com/bnb) -\n  **Tierney Cyren** <<hello@bnb.im>> (they/them)\n* [bnoordhuis](https://github.com/bnoordhuis) -\n  **Ben Noordhuis** <<info@bnoordhuis.nl>>\n* [BridgeAR](https://github.com/BridgeAR) -\n  **Ruben Bridgewater** <<ruben@bridgewater.de>> (he/him)\n* [cclauss](https://github.com/cclauss) -\n  **Christian Clauss** <<cclauss@me.com>> (he/him)\n* [cjihrig](https://github.com/cjihrig) -\n  **Colin Ihrig** <<cjihrig@gmail.com>> (he/him)\n* [codebytere](https://github.com/codebytere) -\n  **Shelley Vohr** <<shelley.vohr@gmail.com>> (she/her)\n* [cola119](https://github.com/cola119) -\n  **Kohei Ueno** <<kohei.ueno119@gmail.com>> (he/him)\n* [daeyeon](https://github.com/daeyeon) -\n  **Daeyeon Jeong** <<daeyeon.dev@gmail.com>> (he/him)\n* [dario-piotrowicz](https://github.com/dario-piotrowicz) -\n  **Dario Piotrowicz** <<dario.piotrowicz@gmail.com>> (he/him)\n* [debadree25](https://github.com/debadree25) -\n  **Debadree Chatterjee** <<debadree333@gmail.com>> (he/him)\n* [deokjinkim](https://github.com/deokjinkim) -\n  **Deokjin Kim** <<deokjin81.kim@gmail.com>> (he/him)\n* [edsadr](https://github.com/edsadr) -\n  **Adrian Estrada** <<edsadr@gmail.com>> (he/him)\n* [ErickWendel](https://github.com/ErickWendel) -\n  **Erick Wendel** <<erick.workspace@gmail.com>> (he/him)\n* [Ethan-Arrowood](https://github.com/Ethan-Arrowood) -\n  **Ethan Arrowood** <<ethan@arrowood.dev>> (he/him)\n* [fhinkel](https://github.com/fhinkel) -\n  **Franziska Hinkelmann** <<franziska.hinkelmann@gmail.com>> (she/her)\n* [Flarna](https://github.com/Flarna) -\n  **Gerhard St√∂bich** <<deb2001-github@yahoo.de>> (he/they)\n* [gabrielschulhof](https://github.com/gabrielschulhof) -\n  **Gabriel Schulhof** <<gabrielschulhof@gmail.com>>\n* [geeksilva97](https://github.com/geeksilva97) -\n  **Edy Silva** <<edigleyssonsilva@gmail.com>> (he/him)\n* [gengjiawen](https://github.com/gengjiawen) -\n  **Jiawen Geng** <<technicalcute@gmail.com>>\n* [GeoffreyBooth](https://github.com/GeoffreyBooth) -\n  **Geoffrey Booth** <<webadmin@geoffreybooth.com>> (he/him)\n* [gireeshpunathil](https://github.com/gireeshpunathil) -\n  **Gireesh Punathil** <<gpunathi@in.ibm.com>> (he/him)\n* [gurgunday](https://github.com/gurgunday) -\n  **G√ºrg√ºn Dayƒ±oƒülu** <<hey@gurgun.day>> (he/him)\n* [guybedford](https://github.com/guybedford) -\n  **Guy Bedford** <<guybedford@gmail.com>> (he/him)\n* [H4ad](https://github.com/H4ad) -\n  **Vin√≠cius Louren√ßo Claro Cardoso** <<contact@viniciusl.com.br>> (he/him)\n* [HarshithaKP](https://github.com/HarshithaKP) -\n  **Harshitha K P** <<harshitha014@gmail.com>> (she/her)\n* [himself65](https://github.com/himself65) -\n  **Zeyu \"Alex\" Yang** <<himself65@outlook.com>> (he/him)\n* [hybrist](https://github.com/hybrist) -\n  **Jan Martin** <<jan.krems@gmail.com>> (he/him)\n* [IlyasShabi](https://github.com/IlyasShabi) -\n  **Ilyas Shabi** <<ilyasshabi94@gmail.com>> (he/him)\n* [islandryu](https://github.com/islandryu) -\n  **Ryuhei Shima** <<shimaryuhei@gmail.com>> (he/him)\n* [jakecastelli](https://github.com/jakecastelli) -\n  **Jake Yuesong Li** <<jake.yuesong@gmail.com>> (he/him)\n* [JakobJingleheimer](https://github.com/JakobJingleheimer) -\n  **Jacob Smith** <<jacob@frende.me>> (he/him)\n* [jasnell](https://github.com/jasnell) -\n  **James M Snell** <<jasnell@gmail.com>> (he/him)\n* [jazelly](https://github.com/jazelly) -\n  **Jason Zhang** <<xzha4350@gmail.com>> (he/him)\n* [JonasBa](https://github.com/JonasBa) -\n  **Jonas Badalic** <<jonas.badalic@gmail.com>> (he/him)\n* [joyeecheung](https://github.com/joyeecheung) -\n  **Joyee Cheung** <<joyeec9h3@gmail.com>> (she/her)\n* [juanarbol](https://github.com/juanarbol) -\n  **Juan Jos√© Arboleda** <<soyjuanarbol@gmail.com>> (he/him)\n* [JungMinu](https://github.com/JungMinu) -\n  **Minwoo Jung** <<nodecorelab@gmail.com>> (he/him)\n* [KhafraDev](https://github.com/KhafraDev) -\n  **Matthew Aitken** <<maitken033380023@gmail.com>> (he/him)\n* [legendecas](https://github.com/legendecas) -\n  **Chengzhong Wu** <<legendecas@gmail.com>> (he/him)\n* [lemire](https://github.com/lemire) -\n  **Daniel Lemire** <<daniel@lemire.me>>\n* [LiviaMedeiros](https://github.com/LiviaMedeiros) -\n  **LiviaMedeiros** <<livia@cirno.name>>\n* [ljharb](https://github.com/ljharb) -\n  **Jordan Harband** <<ljharb@gmail.com>>\n* [lpinca](https://github.com/lpinca) -\n  **Luigi Pinca** <<luigipinca@gmail.com>> (he/him)\n* [Lxxyx](https://github.com/Lxxyx) -\n  **Zijian Liu** <<lxxyxzj@gmail.com>> (he/him)\n* [marco-ippolito](https://github.com/marco-ippolito) -\n  **Marco Ippolito** <<marcoippolito54@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/marco-ippolito)\n* [marsonya](https://github.com/marsonya) -\n  **Akhil Marsonya** <<akhil.marsonya27@gmail.com>> (he/him)\n* [MattiasBuelens](https://github.com/MattiasBuelens) -\n  **Mattias Buelens** <<mattias@buelens.com>> (he/him)\n* [mcollina](https://github.com/mcollina) -\n  **Matteo Collina** <<matteo.collina@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/mcollina)\n* [meixg](https://github.com/meixg) -\n  **Xuguang Mei** <<meixuguang@gmail.com>> (he/him)\n* [mhdawson](https://github.com/mhdawson) -\n  **Michael Dawson** <<midawson@redhat.com>> (he/him)\n* [MoLow](https://github.com/MoLow) -\n  **Moshe Atlow** <<moshe@atlow.co.il>> (he/him)\n* [MrJithil](https://github.com/MrJithil) -\n  **Jithil P Ponnan** <<jithil@outlook.com>> (he/him)\n* [ovflowd](https://github.com/ovflowd) -\n  **Claudio Wunder** <<cwunder@gnome.org>> (he/they)\n* [panva](https://github.com/panva) -\n  **Filip Skokan** <<panva.ip@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/panva)\n* [pimterry](https://github.com/pimterry) -\n  **Tim Perry** <<pimterry@gmail.com>> (he/him)\n* [pmarchini](https://github.com/pmarchini) -\n  **Pietro Marchini** <<pietro.marchini94@gmail.com>> (he/him)\n* [puskin](https://github.com/puskin) -\n  **Giovanni Bucci** <<github@puskin.it>> (he/him)\n* [Qard](https://github.com/Qard) -\n  **Stephen Belanger** <<admin@stephenbelanger.com>> (he/him)\n* [RafaelGSS](https://github.com/RafaelGSS) -\n  **Rafael Gonzaga** <<rafael.nunu@hotmail.com>> (he/him) - [Support me](https://github.com/sponsors/RafaelGSS)\n* [RaisinTen](https://github.com/RaisinTen) -\n  **Darshan Sen** <<raisinten@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/RaisinTen)\n* [Renegade334](https://github.com/Renegade334) -\n  **Ren√©** <<contact.9a5d6388@renegade334.me.uk>>\n* [richardlau](https://github.com/richardlau) -\n  **Richard Lau** <<richard.lau@ibm.com>>\n* [rluvaton](https://github.com/rluvaton) -\n  **Raz Luvaton** <<rluvaton@gmail.com>> (he/him)\n* [ronag](https://github.com/ronag) -\n  **Robert Nagy** <<ronagy@icloud.com>>\n* [ruyadorno](https://github.com/ruyadorno) -\n  **Ruy Adorno** <<ruy@vlt.sh>> (he/him)\n* [santigimeno](https://github.com/santigimeno) -\n  **Santiago Gimeno** <<santiago.gimeno@gmail.com>>\n* [ShogunPanda](https://github.com/ShogunPanda) -\n  **Paolo Insogna** <<paolo@cowtech.it>> (he/him)\n* [srl295](https://github.com/srl295) -\n  **Steven R Loomis** <<srl295@gmail.com>>\n* [StefanStojanovic](https://github.com/StefanStojanovic) -\n  **Stefan Stojanovic** <<stefan.stojanovic@janeasystems.com>> (he/him)\n* [sxa](https://github.com/sxa) -\n  **Stewart X Addison** <<sxa@redhat.com>> (he/him)\n* [targos](https://github.com/targos) -\n  **Micha√´l Zasso** <<targos@protonmail.com>> (he/him)\n* [theanarkh](https://github.com/theanarkh) -\n  **theanarkh** <<theratliter@gmail.com>> (he/him)\n* [tniessen](https://github.com/tniessen) -\n  **Tobias Nie√üen** <<tniessen@tnie.de>> (he/him)\n* [trivikr](https://github.com/trivikr) -\n  **Trivikram Kamat** <<trivikr.dev@gmail.com>>\n* [Trott](https://github.com/Trott) -\n  **Rich Trott** <<rtrott@gmail.com>> (he/him)\n* [UlisesGascon](https://github.com/UlisesGascon) -\n  **Ulises Gasc√≥n** <<ulisesgascongonzalez@gmail.com>> (he/him)\n* [vmoroz](https://github.com/vmoroz) -\n  **Vladimir Morozov** <<vmorozov@microsoft.com>> (he/him)\n* [VoltrexKeyva](https://github.com/VoltrexKeyva) -\n  **Mohammed Keyvanzadeh** <<mohammadkeyvanzade94@gmail.com>> (he/him)\n* [watilde](https://github.com/watilde) -\n  **Daijiro Wachi** <<daijiro.wachi@gmail.com>> (he/him)\n* [zcbenz](https://github.com/zcbenz) -\n  **Cheng Zhao** <<zcbenz@gmail.com>> (he/him)\n* [ZYSzys](https://github.com/ZYSzys) -\n  **Yongsheng Zhang** <<zyszys98@gmail.com>> (he/him)\n\n<details>\n\n<summary>Emeriti</summary>\n\n<!-- find-inactive-collaborators.mjs depends on the format of the emeriti list.\n     If the format changes, those utilities need to be tested and updated. -->\n\n### Collaborator emeriti\n\n* [ak239](https://github.com/ak239) -\n  **Aleksei Koziatinskii** <<ak239spb@gmail.com>>\n* [andrasq](https://github.com/andrasq) -\n  **Andras** <<andras@kinvey.com>>\n* [AndreasMadsen](https://github.com/AndreasMadsen) -\n  **Andreas Madsen** <<amwebdk@gmail.com>> (he/him)\n* [AnnaMag](https://github.com/AnnaMag) -\n  **Anna M. Kedzierska** <<anna.m.kedzierska@gmail.com>>\n* [antsmartian](https://github.com/antsmartian) -\n  **Anto Aravinth** <<anto.aravinth.cse@gmail.com>> (he/him)\n* [apapirovski](https://github.com/apapirovski) -\n  **Anatoli Papirovski** <<apapirovski@mac.com>> (he/him)\n* [aqrln](https://github.com/aqrln) -\n  **Alexey Orlenko** <<eaglexrlnk@gmail.com>> (he/him)\n* [AshCripps](https://github.com/AshCripps) -\n  **Ash Cripps** <<email@ashleycripps.co.uk>>\n* [bcoe](https://github.com/bcoe) -\n  **Ben Coe** <<bencoe@gmail.com>> (he/him)\n* [bmeck](https://github.com/bmeck) -\n  **Bradley Farias** <<bradley.meck@gmail.com>>\n* [bmeurer](https://github.com/bmeurer) -\n  **Benedikt Meurer** <<benedikt.meurer@gmail.com>>\n* [boneskull](https://github.com/boneskull) -\n  **Christopher Hiller** <<boneskull@boneskull.com>> (he/him)\n* [brendanashworth](https://github.com/brendanashworth) -\n  **Brendan Ashworth** <<brendan.ashworth@me.com>>\n* [bzoz](https://github.com/bzoz) -\n  **Bartosz Sosnowski** <<bartosz@janeasystems.com>>\n* [calvinmetcalf](https://github.com/calvinmetcalf) -\n  **Calvin Metcalf** <<calvin.metcalf@gmail.com>>\n* [ChALkeR](https://github.com/ChALkeR) -\n  **–°–∫–æ–≤–æ—Ä–æ–¥–∞ –ù–∏–∫–∏—Ç–∞ –ê–Ω–¥—Ä–µ–µ–≤–∏—á** <<chalkerx@gmail.com>> (he/him)\n* [chrisdickinson](https://github.com/chrisdickinson) -\n  **Chris Dickinson** <<christopher.s.dickinson@gmail.com>>\n* [claudiorodriguez](https://github.com/claudiorodriguez) -\n  **Claudio Rodriguez** <<cjrodr@yahoo.com>>\n* [danbev](https://github.com/danbev) -\n  **Daniel Bevenius** <<daniel.bevenius@gmail.com>> (he/him)\n* [danielleadams](https://github.com/danielleadams) -\n  **Danielle Adams** <<adamzdanielle@gmail.com>> (she/her)\n* [DavidCai1111](https://github.com/DavidCai1111) -\n  **David Cai** <<davidcai1993@yahoo.com>> (he/him)\n* [davisjam](https://github.com/davisjam) -\n  **Jamie Davis** <<davisjam@vt.edu>> (he/him)\n* [devnexen](https://github.com/devnexen) -\n  **David Carlier** <<devnexen@gmail.com>>\n* [devsnek](https://github.com/devsnek) -\n  **Gus Caplan** <<me@gus.host>> (they/them)\n* [digitalinfinity](https://github.com/digitalinfinity) -\n  **Hitesh Kanwathirtha** <<digitalinfinity@gmail.com>> (he/him)\n* [dmabupt](https://github.com/dmabupt) -\n  **Xu Meng** <<dmabupt@gmail.com>> (he/him)\n* [dnlup](https://github.com/dnlup) -\n  **dnlup** <<dnlup.dev@gmail.com>>\n* [eljefedelrodeodeljefe](https://github.com/eljefedelrodeodeljefe) -\n  **Robert Jefe Lindstaedt** <<robert.lindstaedt@gmail.com>>\n* [estliberitas](https://github.com/estliberitas) -\n  **Alexander Makarenko** <<estliberitas@gmail.com>>\n* [eugeneo](https://github.com/eugeneo) -\n  **Eugene Ostroukhov** <<eostroukhov@google.com>>\n* [evanlucas](https://github.com/evanlucas) -\n  **Evan Lucas** <<evanlucas@me.com>> (he/him)\n* [F3n67u](https://github.com/F3n67u) -\n  **Feng Yu** <<F3n67u@outlook.com>> (he/him)\n* [firedfox](https://github.com/firedfox) -\n  **Daniel Wang** <<wangyang0123@gmail.com>>\n* [Fishrock123](https://github.com/Fishrock123) -\n  **Jeremiah Senkpiel** <<fishrock123@rocketmail.com>> (he/they)\n* [gdams](https://github.com/gdams) -\n  **George Adams** <<gadams@microsoft.com>> (he/him)\n* [geek](https://github.com/geek) -\n  **Wyatt Preul** <<wpreul@gmail.com>>\n* [gibfahn](https://github.com/gibfahn) -\n  **Gibson Fahnestock** <<gibfahn@gmail.com>> (he/him)\n* [glentiki](https://github.com/glentiki) -\n  **Glen Keane** <<glenkeane.94@gmail.com>> (he/him)\n* [hashseed](https://github.com/hashseed) -\n  **Yang Guo** <<yangguo@chromium.org>> (he/him)\n* [hiroppy](https://github.com/hiroppy) -\n  **Yuta Hiroto** <<hello@hiroppy.me>> (he/him)\n* [iansu](https://github.com/iansu) -\n  **Ian Sutherland** <<ian@iansutherland.ca>>\n* [iarna](https://github.com/iarna) -\n  **Rebecca Turner** <<me@re-becca.org>>\n* [imran-iq](https://github.com/imran-iq) -\n  **Imran Iqbal** <<imran@imraniqbal.org>>\n* [imyller](https://github.com/imyller) -\n  **Ilkka Myller** <<ilkka.myller@nodefield.com>>\n* [indutny](https://github.com/indutny) -\n  **Fedor Indutny** <<fedor@indutny.com>>\n* [isaacs](https://github.com/isaacs) -\n  **Isaac Z. Schlueter** <<i@izs.me>>\n* [italoacasas](https://github.com/italoacasas) -\n  **Italo A. Casas** <<me@italoacasas.com>> (he/him)\n* [JacksonTian](https://github.com/JacksonTian) -\n  **Jackson Tian** <<shyvo1987@gmail.com>>\n* [jasongin](https://github.com/jasongin) -\n  **Jason Ginchereau** <<jasongin@microsoft.com>>\n* [jbergstroem](https://github.com/jbergstroem) -\n  **Johan Bergstr√∂m** <<bugs@bergstroem.nu>>\n* [jdalton](https://github.com/jdalton) -\n  **John-David Dalton** <<john.david.dalton@gmail.com>>\n* [jhamhader](https://github.com/jhamhader) -\n  **Yuval Brik** <<yuval@brik.org.il>>\n* [joaocgreis](https://github.com/joaocgreis) -\n  **Jo√£o Reis** <<reis@janeasystems.com>>\n* [joesepi](https://github.com/joesepi) -\n  **Joe Sepi** <<sepi@joesepi.com>> (he/him)\n* [joshgav](https://github.com/joshgav) -\n  **Josh Gavant** <<josh.gavant@outlook.com>>\n* [julianduque](https://github.com/julianduque) -\n  **Julian Duque** <<julianduquej@gmail.com>> (he/him)\n* [kfarnung](https://github.com/kfarnung) -\n  **Kyle Farnung** <<kfarnung@microsoft.com>> (he/him)\n* [kunalspathak](https://github.com/kunalspathak) -\n  **Kunal Pathak** <<kunal.pathak@microsoft.com>>\n* [kuriyosh](https://github.com/kuriyosh) -\n  **Yoshiki Kurihara** <<yosyos0306@gmail.com>> (he/him)\n* [kvakil](https://github.com/kvakil) -\n  **Keyhan Vakil** <<kvakil@sylph.kvakil.me>>\n* [lance](https://github.com/lance) -\n  **Lance Ball** <<lball@redhat.com>> (he/him)\n* [Leko](https://github.com/Leko) -\n  **Shingo Inoue** <<leko.noor@gmail.com>> (he/him)\n* [Linkgoron](https://github.com/Linkgoron) -\n  **Nitzan Uziely** <<linkgoron@gmail.com>>\n* [lucamaraschi](https://github.com/lucamaraschi) -\n  **Luca Maraschi** <<luca.maraschi@gmail.com>> (he/him)\n* [lukekarrys](https://github.com/lukekarrys) -\n  **Luke Karrys** <<luke@lukekarrys.com>> (he/him)\n* [lundibundi](https://github.com/lundibundi) -\n  **Denys Otrishko** <<shishugi@gmail.com>> (he/him)\n* [lxe](https://github.com/lxe) -\n  **Aleksey Smolenchuk** <<lxe@lxe.co>>\n* [maclover7](https://github.com/maclover7) -\n  **Jon Moss** <<me@jonathanmoss.me>> (he/him)\n* [mafintosh](https://github.com/mafintosh) -\n  **Mathias Buus** <<mathiasbuus@gmail.com>> (he/him)\n* [matthewloring](https://github.com/matthewloring) -\n  **Matthew Loring** <<mattloring@google.com>>\n* [Mesteery](https://github.com/Mesteery) -\n  **Mestery** <<mestery@protonmail.com>> (he/him)\n* [micnic](https://github.com/micnic) -\n  **Nicu Micleu»ôanu** <<micnic90@gmail.com>> (he/him)\n* [mikeal](https://github.com/mikeal) -\n  **Mikeal Rogers** <<mikeal.rogers@gmail.com>>\n* [miladfarca](https://github.com/miladfarca) -\n  **Milad Fa** <<mfarazma@redhat.com>> (he/him)\n* [mildsunrise](https://github.com/mildsunrise) -\n  **Alba Mendez** <<me@alba.sh>> (she/her)\n* [misterdjules](https://github.com/misterdjules) -\n  **Julien Gilli** <<jgilli@netflix.com>>\n* [mmarchini](https://github.com/mmarchini) -\n  **Mary Marchini** <<oss@mmarchini.me>> (she/her)\n* [monsanto](https://github.com/monsanto) -\n  **Christopher Monsanto** <<chris@monsan.to>>\n* [MoonBall](https://github.com/MoonBall) -\n  **Chen Gang** <<gangc.cxy@foxmail.com>>\n* [mscdex](https://github.com/mscdex) -\n  **Brian White** <<mscdex@mscdex.net>>\n* [MylesBorins](https://github.com/MylesBorins) -\n  **Myles Borins** <<myles.borins@gmail.com>> (he/him)\n* [not-an-aardvark](https://github.com/not-an-aardvark) -\n  **Teddy Katz** <<teddy.katz@gmail.com>> (he/him)\n* [ofrobots](https://github.com/ofrobots) -\n  **Ali Ijaz Sheikh** <<ofrobots@google.com>> (he/him)\n* [Olegas](https://github.com/Olegas) -\n  **Oleg Elifantiev** <<oleg@elifantiev.ru>>\n* [orangemocha](https://github.com/orangemocha) -\n  **Alexis Campailla** <<orangemocha@nodejs.org>>\n* [othiym23](https://github.com/othiym23) -\n  **Forrest L Norvell** <<ogd@aoaioxxysz.net>> (they/them/themself)\n* [oyyd](https://github.com/oyyd) -\n  **Ouyang Yadong** <<oyydoibh@gmail.com>> (he/him)\n* [petkaantonov](https://github.com/petkaantonov) -\n  **Petka Antonov** <<petka_antonov@hotmail.com>>\n* [phillipj](https://github.com/phillipj) -\n  **Phillip Johnsen** <<johphi@gmail.com>>\n* [piscisaureus](https://github.com/piscisaureus) -\n  **Bert Belder** <<bertbelder@gmail.com>>\n* [pmq20](https://github.com/pmq20) -\n  **Minqi Pan** <<pmq2001@gmail.com>>\n* [PoojaDurgad](https://github.com/PoojaDurgad) -\n  **Pooja D P** <<Pooja.D.P@ibm.com>> (she/her)\n* [princejwesley](https://github.com/princejwesley) -\n  **Prince John Wesley** <<princejohnwesley@gmail.com>>\n* [psmarshall](https://github.com/psmarshall) -\n  **Peter Marshall** <<petermarshall@chromium.org>> (he/him)\n* [puzpuzpuz](https://github.com/puzpuzpuz) -\n  **Andrey Pechkurov** <<apechkurov@gmail.com>> (he/him)\n* [refack](https://github.com/refack) -\n  **Refael Ackermann (◊®◊§◊ê◊ú ◊§◊ú◊ó◊ô)** <<refack@gmail.com>> (he/him/◊î◊ï◊ê/◊ê◊™◊î)\n* [rexagod](https://github.com/rexagod) -\n  **Pranshu Srivastava** <<rexagod@gmail.com>> (he/him)\n* [rickyes](https://github.com/rickyes) -\n  **Ricky Zhou** <<0x19951125@gmail.com>> (he/him)\n* [rlidwka](https://github.com/rlidwka) -\n  **Alex Kocharin** <<alex@kocharin.ru>>\n* [rmg](https://github.com/rmg) -\n  **Ryan Graham** <<r.m.graham@gmail.com>>\n* [robertkowalski](https://github.com/robertkowalski) -\n  **Robert Kowalski** <<rok@kowalski.gd>>\n* [romankl](https://github.com/romankl) -\n  **Roman Klauke** <<romaaan.git@gmail.com>>\n* [ronkorving](https://github.com/ronkorving) -\n  **Ron Korving** <<ron@ronkorving.nl>>\n* [RReverser](https://github.com/RReverser) -\n  **Ingvar Stepanyan** <<me@rreverser.com>>\n* [rubys](https://github.com/rubys) -\n  **Sam Ruby** <<rubys@intertwingly.net>>\n* [rvagg](https://github.com/rvagg) -\n  **Rod Vagg** <<rod@vagg.org>>\n* [ryzokuken](https://github.com/ryzokuken) -\n  **Ujjwal Sharma** <<ryzokuken@disroot.org>> (he/him)\n* [saghul](https://github.com/saghul) -\n  **Sa√∫l Ibarra Corretg√©** <<s@saghul.net>>\n* [sam-github](https://github.com/sam-github) -\n  **Sam Roberts** <<vieuxtech@gmail.com>>\n* [sebdeckers](https://github.com/sebdeckers) -\n  **Sebastiaan Deckers** <<sebdeckers83@gmail.com>>\n* [seishun](https://github.com/seishun) -\n  **Nikolai Vavilov** <<vvnicholas@gmail.com>>\n* [shigeki](https://github.com/shigeki) -\n  **Shigeki Ohtsu** <<ohtsu@ohtsu.org>> (he/him)\n* [shisama](https://github.com/shisama) -\n  **Masashi Hirano** <<shisama07@gmail.com>> (he/him)\n* [silverwind](https://github.com/silverwind) -\n  **Roman Reiss** <<me@silverwind.io>>\n* [starkwang](https://github.com/starkwang) -\n  **Weijia Wang** <<starkwang@126.com>>\n* [stefanmb](https://github.com/stefanmb) -\n  **Stefan Budeanu** <<stefan@budeanu.com>>\n* [tellnes](https://github.com/tellnes) -\n  **Christian Tellnes** <<christian@tellnes.no>>\n* [thefourtheye](https://github.com/thefourtheye) -\n  **Sakthipriyan Vairamani** <<thechargingvolcano@gmail.com>> (he/him)\n* [thlorenz](https://github.com/thlorenz) -\n  **Thorsten Lorenz** <<thlorenz@gmx.de>>\n* [TimothyGu](https://github.com/TimothyGu) -\n  **Tiancheng \"Timothy\" Gu** <<timothygu99@gmail.com>> (he/him)\n* [trevnorris](https://github.com/trevnorris) -\n  **Trevor Norris** <<trev.norris@gmail.com>>\n* [tunniclm](https://github.com/tunniclm) -\n  **Mike Tunnicliffe** <<m.j.tunnicliffe@gmail.com>>\n* [vdeturckheim](https://github.com/vdeturckheim) -\n  **Vladimir de Turckheim** <<vlad2t@hotmail.com>> (he/him)\n* [vkurchatkin](https://github.com/vkurchatkin) -\n  **Vladimir Kurchatkin** <<vladimir.kurchatkin@gmail.com>>\n* [vsemozhetbyt](https://github.com/vsemozhetbyt) -\n  **Vse Mozhet Byt** <<vsemozhetbyt@gmail.com>> (he/him)\n* [watson](https://github.com/watson) -\n  **Thomas Watson** <<w@tson.dk>>\n* [whitlockjc](https://github.com/whitlockjc) -\n  **Jeremy Whitlock** <<jwhitlock@apache.org>>\n* [XadillaX](https://github.com/XadillaX) -\n  **Khaidi Chu** <<i@2333.moe>> (he/him)\n* [yashLadha](https://github.com/yashLadha) -\n  **Yash Ladha** <<yash@yashladha.in>> (he/him)\n* [yhwang](https://github.com/yhwang) -\n  **Yihong Wang** <<yh.wang@ibm.com>>\n* [yorkie](https://github.com/yorkie) -\n  **Yorkie Liu** <<yorkiefixer@gmail.com>>\n* [yosuke-furukawa](https://github.com/yosuke-furukawa) -\n  **Yosuke Furukawa** <<yosuke.furukawa@gmail.com>>\n\n</details>\n\n<!--lint enable prohibited-strings-->\n\nCollaborators follow the [Collaborator Guide](./doc/contributing/collaborator-guide.md) in\nmaintaining the Node.js project.\n\n### Triagers\n\n* [1ilsang](https://github.com/1ilsang) -\n  **Sangchul Lee** <<1ilsang.dev@gmail.com>> (he/him)\n* [atlowChemi](https://github.com/atlowChemi) -\n  **Chemi Atlow** <<chemi@atlow.co.il>> (he/him)\n* [Ayase-252](https://github.com/Ayase-252) -\n  **Qingyu Deng** <<i@ayase-lab.com>>\n* [bjohansebas](https://github.com/bjohansebas) -\n  **Sebastian Beltran** <<bjohansebas@gmail.com>>\n* [bmuenzenmeyer](https://github.com/bmuenzenmeyer) -\n  **Brian Muenzenmeyer** <<brian.muenzenmeyer@gmail.com>> (he/him)\n* [CanadaHonk](https://github.com/CanadaHonk) -\n  **Oliver Medhurst** <<honk@goose.icu>> (they/them)\n* [daeyeon](https://github.com/daeyeon) -\n  **Daeyeon Jeong** <<daeyeon.dev@gmail.com>> (he/him)\n* [gireeshpunathil](https://github.com/gireeshpunathil) -\n  **Gireesh Punathil** <<gpunathi@in.ibm.com>> (he/him)\n* [gurgunday](https://github.com/gurgunday) -\n  **G√ºrg√ºn Dayƒ±oƒülu** <<hey@gurgun.day>>\n* [haramj](https://github.com/haramj) -\n  **Haram Jeong** <<haramj.dev@gmail.com>>\n* [HBSPS](https://github.com/HBSPS) -\n  **Wiyeong Seo** <<hbsps.dev@gmail.com>>\n* [iam-frankqiu](https://github.com/iam-frankqiu) -\n  **Frank Qiu** <<iam.frankqiu@gmail.com>> (he/him)\n* [KevinEady](https://github.com/KevinEady) -\n  **Kevin Eady** <<kevin.c.eady@gmail.com>> (he/him)\n* [marsonya](https://github.com/marsonya) -\n  **Akhil Marsonya** <<akhil.marsonya27@gmail.com>> (he/him)\n* [meixg](https://github.com/meixg) -\n  **Xuguang Mei** <<meixuguang@gmail.com>> (he/him)\n* [milesguicent](https://github.com/milesguicent) -\n  **Miles Guicent** <<guicent@pm.me>> (he/him)\n* [preveen-stack](https://github.com/preveen-stack) -\n  **Preveen Padmanabhan** <<wide4head@gmail.com>> (he/him)\n* [RaisinTen](https://github.com/RaisinTen) -\n  **Darshan Sen** <<raisinten@gmail.com>> (he/him)\n* [VoltrexKeyva](https://github.com/VoltrexKeyva) -\n  **Mohammed Keyvanzadeh** <<mohammadkeyvanzade94@gmail.com>> (he/him)\n\nTriagers follow the [Triage Guide](./doc/contributing/issues.md#triaging-a-bug-report) when\nresponding to new issues.\n\n### Release keys\n\nPrimary GPG keys for Node.js Releasers (some Releasers sign with subkeys):\n\n* **Antoine du Hamel** <<duhamelantoine1995@gmail.com>>\n  `5BE8A3F6C8A5C01D106C0AD820B1A390B168D356`\n* **Juan Jos√© Arboleda** <<soyjuanarbol@gmail.com>>\n  `DD792F5973C6DE52C432CBDAC77ABFA00DDBF2B7`\n* **Marco Ippolito** <<marcoippolito54@gmail.com>>\n  `CC68F5A3106FF448322E48ED27F5E38D5B0A215F`\n* **Micha√´l Zasso** <<targos@protonmail.com>>\n  `8FCCA13FEF1D0C2E91008E09770F7A9A5AE15600`\n* **Rafael Gonzaga** <<rafael.nunu@hotmail.com>>\n  `890C08DB8579162FEE0DF9DB8BEAB4DFCF555EF4`\n* **Richard Lau** <<richard.lau@ibm.com>>\n  `C82FA3AE1CBEDC6BE46B9360C43CEC45C17AB93C`\n* **Ruy Adorno** <<ruyadorno@hotmail.com>>\n  `108F52B48DB57BB0CC439B2997B01419BD92F80A`\n* **Ulises Gasc√≥n** <<ulisesgascongonzalez@gmail.com>>\n  `A363A499291CBBC940DD62E41F10027AF002F8B0`\n\nYou can use the keyring the project maintains at\n<https://github.com/nodejs/release-keys/raw/refs/heads/main/gpg-only-active-keys/pubring.kbx>.\nAlternatively, you can import them from a public key server. Have in mind that\nthe project cannot guarantee the availability of the server nor the keys on\nthat server.\n\n```bash\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 5BE8A3F6C8A5C01D106C0AD820B1A390B168D356 # Antoine du Hamel\ngpg --keyserver hkps://keys.openpgp.org --recv-keys DD792F5973C6DE52C432CBDAC77ABFA00DDBF2B7 # Juan Jos√© Arboleda\ngpg --keyserver hkps://keys.openpgp.org --recv-keys CC68F5A3106FF448322E48ED27F5E38D5B0A215F # Marco Ippolito\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 8FCCA13FEF1D0C2E91008E09770F7A9A5AE15600 # Micha√´l Zasso\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 890C08DB8579162FEE0DF9DB8BEAB4DFCF555EF4 # Rafael Gonzaga\ngpg --keyserver hkps://keys.openpgp.org --recv-keys C82FA3AE1CBEDC6BE46B9360C43CEC45C17AB93C # Richard Lau\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 108F52B48DB57BB0CC439B2997B01419BD92F80A # Ruy Adorno\ngpg --keyserver hkps://keys.openpgp.org --recv-keys A363A499291CBBC940DD62E41F10027AF002F8B0 # Ulises Gasc√≥n\n```\n\nSee [Verifying binaries](#verifying-binaries) for how to use these keys to\nverify a downloaded file.\n\n<details>\n\n<summary>Other keys used to sign some previous releases</summary>\n\n* **Antoine du Hamel** <<duhamelantoine1995@gmail.com>>\n  `C0D6248439F1D5604AAFFB4021D900FFDB233756`\n* **Beth Griggs** <<bethanyngriggs@gmail.com>>\n  `4ED778F539E3634C779C87C6D7062848A1AB005C`\n* **Bryan English** <<bryan@bryanenglish.com>>\n  `141F07595B7B3FFE74309A937405533BE57C7D57`\n* **Chris Dickinson** <<christopher.s.dickinson@gmail.com>>\n  `9554F04D7259F04124DE6B476D5A82AC7E37093B`\n* **Colin Ihrig** <<cjihrig@gmail.com>>\n  `94AE36675C464D64BAFA68DD7434390BDBE9B9C5`\n* **Danielle Adams** <<adamzdanielle@gmail.com>>\n  `1C050899334244A8AF75E53792EF661D867B9DFA`\n  `74F12602B6F1C4E913FAA37AD3A89613643B6201`\n* **Evan Lucas** <<evanlucas@me.com>>\n  `B9AE9905FFD7803F25714661B63B535A4C206CA9`\n* **Gibson Fahnestock** <<gibfahn@gmail.com>>\n  `77984A986EBC2AA786BC0F66B01FBB92821C587A`\n* **Isaac Z. Schlueter** <<i@izs.me>>\n  `93C7E9E91B49E432C2F75674B0A78B0A6C481CF6`\n* **Italo A. Casas** <<me@italoacasas.com>>\n  `56730D5401028683275BD23C23EFEFE93C4CFFFE`\n* **James M Snell** <<jasnell@keybase.io>>\n  `71DCFD284A79C3B38668286BC97EC7A07EDE3FC1`\n* **Jeremiah Senkpiel** <<fishrock@keybase.io>>\n  `FD3A5288F042B6850C66B31F09FE44734EB7990E`\n* **Juan Jos√© Arboleda** <<soyjuanarbol@gmail.com>>\n  `61FC681DFB92A079F1685E77973F295594EC4689`\n* **Julien Gilli** <<jgilli@fastmail.fm>>\n  `114F43EE0176B71C7BC219DD50A3051F888C628D`\n* **Myles Borins** <<myles.borins@gmail.com>>\n  `C4F0DFFF4E8C1A8236409D08E73BC641CC11F4C8`\n* **Rod Vagg** <<rod@vagg.org>>\n  `DD8F2338BAE7501E3DD5AC78C273792F7D83545D`\n* **Ruben Bridgewater** <<ruben@bridgewater.de>>\n  `A48C2BEE680E841632CD4E44F07496B3EB3C1762`\n* **Shelley Vohr** <<shelley.vohr@gmail.com>>\n  `B9E2F5981AA6E0CD28160D9FF13993A75599653C`\n* **Timothy J Fontaine** <<tjfontaine@gmail.com>>\n  `7937DFD2AB06298B2293C3187D33FF9D0246406D`\n\nThe project maintains a keyring able to verify all past releases of Node.js at\n<https://github.com/nodejs/release-keys/raw/refs/heads/main/gpg/pubring.kbx>.\n\n</details>\n\n### Security release stewards\n\nWhen possible, the commitment to take slots in the\nsecurity release steward rotation is made by companies in order\nto ensure individuals who act as security stewards have the\nsupport and recognition from their employer to be able to\nprioritize security releases. Security release stewards manage security\nreleases on a rotation basis as outlined in the\n[security release process](./doc/contributing/security-release-process.md).\n\n* [Datadog](https://www.datadoghq.com/)\n  * [bengl](https://github.com/bengl) -\n    **Bryan English** <<bryan@bryanenglish.com>> (he/him)\n* [HeroDevs](https://www.herodevs.com/)\n  * [marco-ippolito](https://github.com/marco-ippolito) - OpenJSF handle: `Marco Ippolito`\n    **Marco Ippolito** <<marcoippolito54@gmail.com>> (he/him)\n* [NodeSource](https://nodesource.com/)\n  * [juanarbol](https://github.com/juanarbol) -\n    **Juan Jos√© Arboleda** <<soyjuanarbol@gmail.com>> (he/him)\n  * [RafaelGSS](https://github.com/RafaelGSS) - OpenJSF handle: `RafaelGSS`\n    **Rafael Gonzaga** <<rafael.nunu@hotmail.com>> (he/him)\n* [Platformatic](https://platformatic.dev/)\n  * [mcollina](https://github.com/mcollina) - OpenJSF handle: `mcollina`\n    **Matteo Collina** <<matteo.collina@gmail.com>> (he/him)\n* [Red Hat](https://redhat.com) / [IBM](https://ibm.com)\n  * [joesepi](https://github.com/joesepi) -\n    **Joe Sepi** <<joesepi@ibm.com>> (he/him)\n  * [mhdawson](https://github.com/mhdawson) -\n    **Michael Dawson** <<midawson@redhat.com>> (he/him)\n\n## License\n\nNode.js is licensed under the [MIT License](https://opensource.org/licenses/MIT).\n\nThis project also depends on external libraries that may use different open-source\nlicenses. For a complete list of included licenses, please see the\n[LICENSE](https://github.com/nodejs/node/blob/main/LICENSE) file.\n\nIf you are contributing documentation or source changes, please ensure your\nadditions comply with the project‚Äôs license guidelines.\n\n[Code of Conduct]: https://github.com/nodejs/admin/blob/HEAD/CODE_OF_CONDUCT.md\n[Contributing to the project]: CONTRIBUTING.md\n[Node.js website]: https://nodejs.org/\n[OpenJS Foundation]: https://openjsf.org/\n[Strategic initiatives]: doc/contributing/strategic-initiatives.md\n[Technical values and prioritization]: doc/contributing/technical-values.md\n[Working Groups]: https://github.com/nodejs/TSC/blob/HEAD/WORKING_GROUPS.md\n",
      "stars_today": 23
    },
    {
      "id": 10744183,
      "name": "netdata",
      "full_name": "netdata/netdata",
      "description": "The fastest path to AI-powered full stack observability, even for lean teams.",
      "html_url": "https://github.com/netdata/netdata",
      "stars": 77470,
      "forks": 6314,
      "language": "C",
      "topics": [
        "ai",
        "alerting",
        "cncf",
        "data-visualization",
        "database",
        "devops",
        "docker",
        "grafana",
        "influxdb",
        "kubernetes",
        "linux",
        "machine-learning",
        "mcp",
        "mongodb",
        "monitoring",
        "mysql",
        "netdata",
        "observability",
        "postgresql",
        "prometheus"
      ],
      "created_at": "2013-06-17T18:39:10Z",
      "updated_at": "2026-01-23T01:13:00Z",
      "pushed_at": "2026-01-23T00:17:36Z",
      "open_issues": 240,
      "owner": {
        "login": "netdata",
        "avatar_url": "https://avatars.githubusercontent.com/u/43390781?v=4"
      },
      "readme": "<p align=\"center\">\n<a href=\"https://www.netdata.cloud#gh-light-mode-only\">\n  <img src=\"https://www.netdata.cloud/img/readme-images/netdata_readme_logo_light.png\" alt=\"Netdata\" width=\"300\"/>\n</a>\n<a href=\"https://www.netdata.cloud#gh-dark-mode-only\">\n  <img src=\"https://www.netdata.cloud/img/readme-images/netdata_readme_logo_dark.png\" alt=\"Netdata\" width=\"300\"/>\n</a>\n</p>\n<h3 align=\"center\">X-Ray Vision for your infrastructure!</h3>\n<h4 align=\"center\">Every Metric, Every Second. No BS.</h4>\n\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/netdata/netdata/\"><img src=\"https://img.shields.io/github/stars/netdata/netdata?style=social\" alt=\"GitHub Stars\"></a>\n  <br />\n  <a href=\"https://app.netdata.cloud/spaces/netdata-demo?utm_campaign=github_readme_demo_badge\"><img src=\"https://img.shields.io/badge/Live%20Demo-green\" alt=\"Live Demo\"></a>\n  <a href=\"https://github.com/netdata/netdata/releases/latest\"><img src=\"https://img.shields.io/github/release/netdata/netdata.svg\" alt=\"Latest release\"></a>\n  <a href=\"https://github.com/netdata/netdata-nightlies/releases/latest\"><img src=\"https://img.shields.io/github/release/netdata/netdata-nightlies.svg\" alt=\"Latest nightly build\"></a>\n  <br/>\n  <a href=\"https://community.netdata.cloud\"><img alt=\"Discourse topics\" src=\"https://img.shields.io/discourse/topics?server=https%3A%2F%2Fcommunity.netdata.cloud%2F&logo=discourse&label=discourse%20forum\"></a>\n  <a href=\"https://github.com/netdata/netdata/discussions\"><img alt=\"GitHub Discussions\" src=\"https://img.shields.io/github/discussions/netdata/netdata?logo=github&label=github%20discussions\"></a>\n  <br/>\n  <a href=\"https://bestpractices.coreinfrastructure.org/projects/2231\"><img src=\"https://bestpractices.coreinfrastructure.org/projects/2231/badge\" alt=\"CII Best Practices\"></a>\n  <a href=\"https://scan.coverity.com/projects/netdata-netdata?tab=overview\"><img alt=\"Coverity Scan\" src=\"https://img.shields.io/coverity/scan/netdata\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://registry.my-netdata.io/#menu_netdata_submenu_registry\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=netdata.registry_entries&dimensions=persons&label=user%20base&units=M&value_color=blue&precision=2&divide=1000000&options=unaligned&tier=1&v44\" alt=\"User base\"></a>\n  <a href=\"https://registry.my-netdata.io/#menu_netdata_submenu_registry\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=netdata.registry_entries&dimensions=machines&label=servers%20monitored&units=M&divide=1000000&value_color=orange&precision=2&options=unaligned&tier=1&v44\" alt=\"Servers monitored\"></a>\n  <a href=\"https://registry.my-netdata.io/#menu_netdata_submenu_registry\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=netdata.registry_sessions&label=sessions%20served&units=M&value_color=yellowgreen&precision=2&divide=1000000&options=unaligned&tier=1&v44\" alt=\"Sessions served\"></a>\n  <a href=\"https://hub.docker.com/r/netdata/netdata\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=dockerhub.pulls_sum&divide=1000000&precision=1&units=M&label=docker+hub+pulls&options=unaligned&tier=1&v44\" alt=\"Docker Hub pulls\"></a>\n</p>\n<p align=\"center\"><b>Visit our <a href=\"https://www.netdata.cloud\">Home Page</a></b></p>\n\n<hr class=\"solid\">\n\nMENU: **[WHO WE ARE](#who-we-are)** | **[KEY FEATURES](#key-features)** | **[GETTING STARTED](#getting-started)** | **[HOW IT WORKS](#how-it-works)** | **[FAQ](#faq)** | **[DOCS](#book-documentation)** | **[COMMUNITY](#tada-community)** | **[CONTRIBUTE](#pray-contribute)** | **[LICENSE](#scroll-license)**\n\n\n> [!WARNING]\n> People **get addicted to Netdata.**\n> Once you use it on your systems, *there's no going back.*\n\n[![Platforms](https://img.shields.io/badge/Platforms-Linux%20%7C%20macOS%20%7C%20FreeBSD%20%7C%20Windows-blue)]()\n\n---\n\n## WHO WE ARE\n\nNetdata is an open-source, real-time infrastructure monitoring platform. Monitor, detect, and act across your entire infrastructure.\n\n**Core Advantages:**\n\n* **Instant Insights** ‚Äì With Netdata you can access per-second metrics and visualizations.\n* **Zero Configuration** ‚Äì You can deploy immediately without complex setup.\n* **ML-Powered** ‚Äì You can detect anomalies, predict issues, and automate analysis.\n* **Efficient** ‚Äì You can monitor with minimal resource usage and maximum scalability.\n* **Secure & Distributed** ‚Äì You can keep your data local with no central collection needed.\n\nWith Netdata, you get real-time, per-second updates. Clear **insights at a glance**, no complexity.\n\n<details>\n  <summary><strong>All heroes have a great origin story. Click to discover ours.</strong></summary>\n  <br/>\n\nIn 2013, at the company where Costa Tsaousis was COO, a significant percentage of their cloud-based transactions failed silently, severely impacting business performance.\n\nCosta and his team tried every troubleshooting tool available at the time. None could identify the root cause. As Costa later wrote:\n\n‚Äú*I couldn‚Äôt believe that monitoring systems provide so few metrics and with such low resolution, scale so badly, and cost so much to run.*‚Äù\n\nFrustrated, he decided to build his own monitoring tool, starting from scratch.\n\nThat decision led to countless late nights and weekends. It also sparked a fundamental shift in how infrastructure monitoring and troubleshooting are approached, both in method and in cost.\n</details>\n\n### Most Energy-Efficient Monitoring Tool\n\n<p align=\"center\">\n<a href=\"https://www.ivanomalavolta.com/files/papers/ICSOC_2023.pdf#gh-dark-mode-only\">\n  <img src=\"https://github.com/netdata/netdata/assets/139226121/7118757a-38fb-48d7-b12a-53e709a8e8c0\" alt=\"Energy Efficiency\" width=\"800\"/>\n</a>\n<a href=\"https://www.ivanomalavolta.com/files/papers/ICSOC_2023.pdf#gh-light-mode-only\">\n  <img src=\"https://github.com/netdata/netdata/assets/139226121/4f64cbb6-05e4-48e3-b7c0-d1b79e37e219\" alt=\"Energy efficiency\" width=\"800\"/>\n</a>\n</p>\n\nAccording to the [University of Amsterdam study](https://www.ivanomalavolta.com/files/papers/ICSOC_2023.pdf), Netdata is the most energy-efficient tool for monitoring Docker-based systems. The study also shows Netdata excels in CPU usage, RAM usage, and execution time compared to other monitoring solutions.\n\n---\n\n## Key Features\n\n| Feature                    | Description                               | What Makes It Unique                                     |\n|----------------------------|-------------------------------------------|----------------------------------------------------------|\n| **Real-Time**              | Per-second data collection and processing | Works in a beat ‚Äì click and see results instantly        |\n| **Zero-Configuration**     | Automatic detection and discovery         | Auto-discovers everything on the nodes it runs           |\n| **ML-Powered**             | Unsupervised anomaly detection            | Trains multiple ML models per metric at the edge         |\n| **Long-Term Retention**    | High-performance storage                  | ~0.5 bytes per sample with tiered storage for archiving  |\n| **Advanced Visualization** | Rich, interactive dashboards              | Slice and dice data without query language               |\n| **Extreme Scalability**    | Native horizontal scaling                 | Parent-Child centralization with multi-million samples/s |\n| **Complete Visibility**    | From infrastructure to applications       | Simplifies operations and eliminates silos               |\n| **Edge-Based**             | Processing at your premises               | Distributes code instead of centralizing data            |\n\n> [!NOTE]  \n> Want to put Netdata to the test against Prometheus?\n> Explore the [full comparison](https://www.netdata.cloud/blog/netdata-vs-prometheus-2025/).\n\n---\n\n## Netdata Ecosystem\n\nThis three-part architecture enables you to scale from single nodes to complex multi-cloud environments:\n\n| Component         | Description                                                                                                                                                 | License                                         |\n|-------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------|\n| **Netdata Agent** | ‚Ä¢ Core monitoring engine<br>‚Ä¢ Handles collection, storage, ML, alerts, exports<br>‚Ä¢ Runs on servers, cloud, K8s, IoT<br>‚Ä¢ Zero production impact            | [GPL v3+](https://www.gnu.org/licenses/gpl-3.0) |\n| **Netdata Cloud** | ‚Ä¢ Enterprise features<br>‚Ä¢ User management, RBAC, horizontal scaling<br>‚Ä¢ Centralized alerts<br>‚Ä¢ Free community tier<br>‚Ä¢ No metric storage centralization |                                                 |\n| **Netdata UI**    | ‚Ä¢ Dashboards and visualizations<br>‚Ä¢ Free to use<br>‚Ä¢ Included in standard packages<br>‚Ä¢ Latest version via CDN                                             | [NCUL1](https://app.netdata.cloud/LICENSE.txt)  |\n\n## What You Can Monitor\n\nWith Netdata you can monitor all these components across platforms:\n\n|                                                                                                   Component |              Linux               | FreeBSD | macOS |                      Windows                      |\n|------------------------------------------------------------------------------------------------------------:|:--------------------------------:|:-------:|:-----:|:-------------------------------------------------:|\n|                             **System Resources**<small><br/>CPU, Memory and system shared resources</small> |               Full               |   Yes   |  Yes  |                        Yes                        |\n|                                **Storage**<small><br/>Disks, Mount points, Filesystems, RAID arrays</small> |               Full               |   Yes   |  Yes  |                        Yes                        |\n|                                 **Network**<small><br/>Network Interfaces, Protocols, Firewall, etc</small> |               Full               |   Yes   |  Yes  |                        Yes                        |\n|                        **Hardware & Sensors**<small><br/>Fans, Temperatures, Controllers, GPUs, etc</small> |               Full               |  Some   | Some  |                       Some                        |\n|                                       **O/S Services**<small><br/>Resources, Performance and Status</small> | Yes<small><br/>`systemd`</small> |    -    |   -   |                         -                         |\n|                                      **Processes**<small><br/>Resources, Performance, OOM, and more</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n|                                                                             System and Application **Logs** | Yes<small><br/>`systemd`-journal |    -    |   -   | Yes<small><br/>`Windows Event Log`, `ETW`</small> |\n|                                 **Network Connections**<small><br/>Live TCP and UDP sockets per PID</small> |               Yes                |    -    |   -   |                         -                         |\n|                               **Containers**<small><br/>Docker/containerd, LXC/LXD, Kubernetes, etc</small> |               Yes                |    -    |   -   |                         -                         |\n|                                 **VMs** (from the host)<small><br/>KVM, qemu, libvirt, Proxmox, etc</small> | Yes<small><br/>`cgroups`</small> |    -    |   -   |         Yes<small><br/>`Hyper-V`</small>          |\n|                       **Synthetic Checks**<small><br/>Test APIs, TCP ports, Ping, Certificates, etc</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n| **Packaged Applications**<small><br/>nginx, apache, postgres, redis, mongodb,<br/>and hundreds more</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n|                              **Cloud Provider Infrastructure**<small><br/>AWS, GCP, Azure, and more</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n|                       **Custom Applications**<small><br/>OpenMetrics, StatsD and soon OpenTelemetry</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n\nOn Linux, you can continuously monitor all kernel features and hardware sensors for errors, including Intel/AMD/Nvidia GPUs, PCI AER, RAM EDAC, IPMI, S.M.A.R.T, Intel RAPL, NVMe, fans, power supplies, and voltage readings.\n\n---\n\n## Getting Started\n\nYou can install Netdata on all major operating systems. To begin:\n\n### 1. Install Netdata\n\nChoose your platform and follow the installation guide:\n\n* [Linux Installation](https://learn.netdata.cloud/docs/installing/one-line-installer-for-all-linux-systems)\n* [macOS](https://learn.netdata.cloud/docs/installing/macos)\n* [FreeBSD](https://learn.netdata.cloud/docs/installing/freebsd)\n* [Windows](https://learn.netdata.cloud/docs/netdata-agent/installation/windows)\n* [Docker Guide](/packaging/docker/README.md)\n* [Kubernetes Setup](https://learn.netdata.cloud/docs/installation/install-on-specific-environments/kubernetes)\n\n> [!NOTE]\n> You can access the Netdata UI at `http://localhost:19999` (or `http://NODE:19999` if remote).\n\n### 2. Configure Collectors\n\nNetdata auto-discovers most metrics, but you can manually configure some collectors:\n\n* [All collectors](https://learn.netdata.cloud/docs/data-collection/)\n* [SNMP monitoring](https://learn.netdata.cloud/docs/data-collection/monitor-anything/networking/snmp)\n\n### 3. Configure Alerts\n\nYou can use hundreds of built-in alerts and integrate with:\n\n`email`, `Slack`, `Telegram`, `PagerDuty`, `Discord`, `Microsoft Teams`, and more.\n\n> [!NOTE]  \n> Email alerts work by default if there's a configured MTA.\n\n### 4. Configure Parents\n\nYou can centralize dashboards, alerts, and storage with Netdata Parents:\n\n* [Streaming Reference](https://learn.netdata.cloud/docs/streaming/streaming-configuration-reference)\n\n> [!NOTE]  \n> You can use Netdata Parents for central dashboards, longer retention, and alert configuration.\n\n### 5. Connect to Netdata Cloud\n\n[Sign in to Netdata Cloud](https://app.netdata.cloud/sign-in) and connect your nodes for:\n\n* Access from anywhere\n* Horizontal scalability and multi-node dashboards\n* UI configuration for alerts and data collection\n* Role-based access control\n* Free tier available\n\n> [!NOTE]  \n> Netdata Cloud is optional. Your data stays in your infrastructure.\n\n## Live Demo Sites\n\n<p align=\"center\">\n  <b>See Netdata in action</b><br/>\n  <a href=\"https://frankfurt.netdata.rocks\"><b>FRANKFURT</b></a> |\n  <a href=\"https://newyork.netdata.rocks\"><b>NEWYORK</b></a> |\n  <a href=\"https://atlanta.netdata.rocks\"><b>ATLANTA</b></a> |\n  <a href=\"https://sanfrancisco.netdata.rocks\"><b>SANFRANCISCO</b></a> |\n  <a href=\"https://toronto.netdata.rocks\"><b>TORONTO</b></a> |\n  <a href=\"https://singapore.netdata.rocks\"><b>SINGAPORE</b></a> |\n  <a href=\"https://bangalore.netdata.rocks\"><b>BANGALORE</b></a>\n  <br/>\n  <i>These demo clusters run with default configuration and show real monitoring data.</i>\n  <br/>\n  <i>Choose the instance closest to you for the best performance.</i>\n</p>\n\n---\n\n## How It Works\n\nWith Netdata you can run a modular pipeline for metrics collection, processing, and visualization.\n\n```mermaid\nflowchart TB\n  A[Netdata Agent]:::mainNode\n  A1(Collect):::green --> A\n  A2(Store):::green --> A\n  A3(Learn):::green --> A\n  A4(Detect):::green --> A\n  A5(Check):::green --> A\n  A6(Stream):::green --> A\n  A7(Archive):::green --> A\n  A8(Query):::green --> A\n  A9(Score):::green --> A\n\n  classDef green fill:#bbf3bb,stroke:#333,stroke-width:1px,color:#000\n  classDef mainNode fill:#f0f0f0,stroke:#333,stroke-width:1px,color:#333\n```\n\nWith each Agent you can:\n\n1. **Collect** ‚Äì Gather metrics from systems, containers, apps, logs, APIs, and synthetic checks.\n2. **Store** ‚Äì Save metrics to a high-efficiency, tiered time-series database.\n3. **Learn** ‚Äì Train ML models per metric using recent behavior.\n4. **Detect** ‚Äì Identify anomalies using trained ML models.\n5. **Check** ‚Äì Evaluate metrics against pre-set or custom alert rules.\n6. **Stream** ‚Äì Send metrics to Netdata Parents in real time.\n7. **Archive** ‚Äì Export metrics to Prometheus, InfluxDB, OpenTSDB, Graphite, and others.\n8. **Query** ‚Äì Access metrics via an API for dashboards or third-party tools.\n9. **Score** ‚Äì Use a scoring engine to find patterns and correlations across metrics.\n\n> [!NOTE]  \n> Learn more: [Netdata's architecture](https://learn.netdata.cloud/docs/netdata-agent/#distributed-observability-pipeline)\n\n## Agent Capabilities\n\nWith the Netdata Agent, you can use these core capabilities out-of-the-box:\n\n| Capability                   | Description                                                                                                                                   |\n|------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|\n| **Comprehensive Collection** | ‚Ä¢ 800+ integrations<br>‚Ä¢ Systems, containers, VMs, hardware sensors<br>‚Ä¢ OpenMetrics, StatsD, and logs<br>‚Ä¢ OpenTelemetry support coming soon |\n| **Performance & Precision**  | ‚Ä¢ Per-second collection<br>‚Ä¢ Real-time visualization with 1-second latency<br>‚Ä¢ High-resolution metrics                                       |\n| **Edge-Based ML**            | ‚Ä¢ ML models trained at the edge<br>‚Ä¢ Automatic anomaly detection per metric<br>‚Ä¢ Pattern recognition based on historical behavior             |\n| **Advanced Log Management**  | ‚Ä¢ Direct systemd-journald and Windows Event Log integration<br>‚Ä¢ Process logs at the edge<br>‚Ä¢ Rich log visualization                         |\n| **Observability Pipeline**   | ‚Ä¢ Parent-Child relationships<br>‚Ä¢ Flexible centralization<br>‚Ä¢ Multi-level replication and retention                                          |\n| **Automated Visualization**  | ‚Ä¢ NIDL data model<br>‚Ä¢ Auto-generated dashboards<br>‚Ä¢ No query language needed                                                                |\n| **Smart Alerting**           | ‚Ä¢ Pre-configured alerts<br>‚Ä¢ Multiple notification methods<br>‚Ä¢ Proactive detection                                                           |\n| **Low Maintenance**          | ‚Ä¢ Auto-detection<br>‚Ä¢ Zero-touch ML<br>‚Ä¢ Easy scalability<br>‚Ä¢ CI/CD friendly                                                                 |\n| **Open & Extensible**        | ‚Ä¢ Modular architecture<br>‚Ä¢ Easy to customize<br>‚Ä¢ Integrates with existing tools                                                             |\n\n---\n\n## CNCF Membership\n\n<p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/white/cncf-white.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/color/cncf-color.svg\">\n    <img alt=\"CNCF Logo\" src=\"https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/color/cncf-color.svg\" width=\"300\">\n  </picture>\n  <br />\n  Netdata actively supports and is a member of the Cloud Native Computing Foundation (CNCF).<br />\n  It is one of the most starred projects in the <a href=\"https://landscape.cncf.io/?item=observability-and-analysis--observability--netdata\">CNCF landscape</a>.\n</p>\n\n---\n\n## FAQ\n\n<details>\n<summary><strong>Is Netdata secure?</strong></summary>\n<br/>\n\nYes. Netdata follows [OpenSSF best practices](https://bestpractices.coreinfrastructure.org/en/projects/2231), has a security-first design, and is regularly audited by the community.\n\n* [Security design](https://learn.netdata.cloud/docs/security-and-privacy-design)\n* [Security policies and advisories](https://github.com/netdata/netdata/security)\n\n</details>\n\n<details>\n<summary><strong>Does Netdata use a lot of resources?</strong></summary>\n<br/>\n\nNo. Even with ML and per-second metrics, Netdata uses minimal resources.\n\n* \\~5% CPU and 150MiB RAM by default on production systems\n* <1% CPU and \\~100MiB RAM when ML and alerts are disabled and using ephemeral storage\n* Parents scale to millions of metrics per second with appropriate hardware\n\n> You can use the **Netdata Monitoring** section in the dashboard to inspect its resource usage.\n\n</details>\n\n<details>\n<summary><strong>How much data retention is possible?</strong></summary>\n<br/>\n\nAs much as your disk allows.\n\nWith Netdata you can use tiered retention:\n\n* Tier 0: per-second resolution\n* Tier 1: per-minute resolution\n* Tier 2: per-hour resolution\n\nThese are queried automatically based on the zoom level.\n</details>\n\n<details>\n<summary><strong>Can Netdata scale to many servers?</strong></summary>\n<br/>\n\nYes. With Netdata you can:\n\n* Scale horizontally with many Agents\n* Scale vertically with powerful Parents\n* Scale infinitely via Netdata Cloud\n\n> You can use Netdata Cloud to merge many independent infrastructures into one logical view.\n\n</details>\n\n<details>\n<summary><strong>Is disk I/O a concern?</strong></summary>\n<br/>\n\nNo. Netdata minimizes disk usage:\n\n* Metrics are flushed to disk every 17 minutes, spread out evenly\n* Uses direct I/O and compression (ZSTD)\n* Can run entirely in RAM or stream to a Parent\n\n> You can use `alloc` or `ram` mode for no disk writes.\n\n</details>\n\n<details>\n<summary><strong>How is Netdata different from Prometheus + Grafana?</strong></summary>\n<br/>\n\nWith Netdata you get a complete monitoring solution‚Äînot just tools.\n\n* No manual setup or dashboards needed\n* Built-in ML, alerts, dashboards, and correlations\n* More efficient and easier to deploy\n\n> [Performance comparison](https://blog.netdata.cloud/netdata-vs-prometheus-performance-analysis/)\n\n</details>\n\n<details>\n<summary><strong>How is Netdata different from commercial SaaS tools?</strong></summary>\n<br/>\n\nWith Netdata you can store all metrics on your infrastructure‚Äîno sampling, no aggregation, no loss.\n\n* High-resolution metrics by default\n* ML per metric, not shared models\n* Unlimited scalability without skyrocketing cost\n\n</details>\n\n<details>\n<summary><strong>Can Netdata run alongside Nagios, Zabbix, etc.?</strong></summary>\n<br/>\n\nYes. You can use Netdata together with traditional tools.\n\nWith Netdata you get:\n\n* Real-time, high-resolution monitoring\n* Zero configuration and auto-generated dashboards\n* Anomaly detection and advanced visualization\n\n</details>\n\n<details>\n<summary><strong>What if I feel overwhelmed?</strong></summary>\n<br/>\n\nYou can start small:\n\n* Use the dashboard's table of contents and search\n* Explore anomaly scoring (\"AR\" toggle)\n* Create custom dashboards in Netdata Cloud\n\n> [Docs and guides](https://learn.netdata.cloud/guides)\n\n</details>\n\n<details>\n<summary><strong>Do I have to use Netdata Cloud?</strong></summary>\n<br/>\n\nNo. Netdata Cloud is optional.\n\nNetdata works without it, but with Cloud you can:\n\n* Access remotely with SSO\n* Save dashboard customizations\n* Configure alerts centrally\n* Collaborate with role-based access\n\n</details>\n\n<details>\n<summary><strong>What telemetry does Netdata collect?</strong></summary>\n<br/>\n\nAnonymous telemetry helps improve the product. You can disable it:\n\n* Add `--disable-telemetry` to the installer, or\n* Create `/etc/netdata/.opt-out-from-anonymous-statistics` and restart Netdata\n\n> Telemetry helps us understand usage, not track users. No private data is collected.\n\n</details>\n\n<details>\n<summary><strong>Who uses Netdata?</strong></summary>\n<br/>\n\nYou'll join users including:\n\n* Major companies (Amazon, ABN AMRO Bank, Facebook, Google, IBM, Intel, Netflix, Samsung)\n* Universities (NYU, Columbia, Seoul National, UCL)\n* Government organizations worldwide\n* Infrastructure-intensive organizations\n* Technology operators\n* Startups and freelancers\n* SysAdmins and DevOps professionals\n\n</details>\n\n---\n\n## \\:book: Documentation\n\nVisit [Netdata Learn](https://learn.netdata.cloud) for full documentation and guides.\n\n> [!NOTE]  \n> Includes deployment, configuration, alerting, exporting, troubleshooting, and more.\n\n---\n\n## \\:tada: Community\n\nJoin the Netdata community:\n\n* [Discord](https://discord.com/invite/2mEmfW735j)\n* [Forum](https://community.netdata.cloud)\n* [GitHub Discussions](https://github.com/netdata/netdata/discussions)\n\n> [!NOTE]  \n> [Code of Conduct](https://github.com/netdata/.github/blob/main/CODE_OF_CONDUCT.md)\n\nFollow us on:\n[Twitter](https://twitter.com/netdatahq) | [Reddit](https://www.reddit.com/r/netdata/) | [YouTube](https://www.youtube.com/c/Netdata) | [LinkedIn](https://www.linkedin.com/company/netdata-cloud/)\n\n---\n\n## \\:pray: Contribute\n\nWe welcome your contributions.\n\nWays you help us stay sharp:\n\n* Share best practices and monitoring insights\n* Report issues or missing features\n* Improve documentation\n* Develop new integrations or collectors\n* Help users in forums and chats\n\n> [!NOTE]  \n> [Contribution guide](https://github.com/netdata/.github/blob/main/CONTRIBUTING.md)\n\n---\n\n## \\:scroll: License\n\nThe Netdata ecosystem includes:\n\n* **Netdata Agent** ‚Äì Open-source core (GPLv3+). **Includes** data collection, storage, ML, alerting, APIs and **redistributes** several other open-source tools and libraries.\n    * [Netdata Agent License](https://github.com/netdata/netdata/blob/master/LICENSE)\n    * [Netdata Agent Redistributed](https://github.com/netdata/netdata/blob/master/REDISTRIBUTED.md)\n* **Netdata UI** ‚Äì Closed-source but free to use with Netdata Agent and Cloud. Delivered via CDN. It integrates third-party open-source components.\n    * [Netdata Cloud UI License](https://app.netdata.cloud/LICENSE.txt)\n    * [Netdata UI third-party licenses](https://app.netdata.cloud/3D_PARTY_LICENSES.txt)\n* **Netdata Cloud** ‚Äì Closed-source, with free and paid tiers. Adds remote access, SSO, scalability.\n",
      "stars_today": 23
    },
    {
      "id": 268163609,
      "name": "qdrant",
      "full_name": "qdrant/qdrant",
      "description": "Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/",
      "html_url": "https://github.com/qdrant/qdrant",
      "stars": 28340,
      "forks": 2010,
      "language": "Rust",
      "topics": [
        "ai-search",
        "ai-search-engine",
        "embeddings-similarity",
        "hnsw",
        "image-search",
        "knn-algorithm",
        "machine-learning",
        "mlops",
        "nearest-neighbor-search",
        "neural-network",
        "neural-search",
        "recommender-system",
        "search",
        "search-engine",
        "search-engines",
        "similarity-search",
        "vector-database",
        "vector-search",
        "vector-search-engine"
      ],
      "created_at": "2020-05-30T21:37:01Z",
      "updated_at": "2026-01-23T01:33:33Z",
      "pushed_at": "2026-01-22T23:12:53Z",
      "open_issues": 459,
      "owner": {
        "login": "qdrant",
        "avatar_url": "https://avatars.githubusercontent.com/u/73504361?v=4"
      },
      "readme": "<p align=\"center\">\n  <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/qdrant/qdrant/raw/master/docs/logo-dark.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/qdrant/qdrant/raw/master/docs/logo-light.svg\">\n      <img height=\"100\" alt=\"Qdrant\" src=\"https://github.com/qdrant/qdrant/raw/master/docs/logo.svg\">\n  </picture>\n</p>\n\n<p align=\"center\">\n    <b>Vector Search Engine for the next generation of AI applications</b>\n</p>\n\n<p align=center>\n    <a href=\"https://github.com/qdrant/qdrant/actions/workflows/rust.yml\"><img src=\"https://img.shields.io/github/actions/workflow/status/qdrant/qdrant/rust.yml?style=flat-square\" alt=\"Tests status\"></a>\n    <a href=\"https://api.qdrant.tech/\"><img src=\"https://img.shields.io/badge/Docs-OpenAPI%203.0-success?style=flat-square\" alt=\"OpenAPI Docs\"></a>\n    <a href=\"https://github.com/qdrant/qdrant/blob/master/LICENSE\"><img src=\"https://img.shields.io/github/license/qdrant/qdrant?style=flat-square\" alt=\"Apache 2.0 License\"></a>\n    <a href=\"https://qdrant.to/discord\"><img src=\"https://img.shields.io/discord/907569970500743200?logo=Discord&style=flat-square&color=7289da\" alt=\"Discord\"></a>\n    <a href=\"https://qdrant.to/roadmap\"><img src=\"https://img.shields.io/badge/Roadmap-2025-bc1439.svg?style=flat-square\" alt=\"Roadmap 2025\"></a>\n    <a href=\"https://cloud.qdrant.io/\"><img src=\"https://img.shields.io/badge/Qdrant-Cloud-24386C.svg?logo=cloud&style=flat-square\" alt=\"Qdrant Cloud\"></a>\n</p>\n\n**Qdrant** (read: _quadrant_) is a vector similarity search engine and vector database.\nIt provides a production-ready service with a convenient API to store, search, and manage points‚Äîvectors with an additional payload\nQdrant is tailored to extended filtering support. It makes it useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications.\n\nQdrant is written in Rust ü¶Ä, which makes it fast and reliable even under high load. See [benchmarks](https://qdrant.tech/benchmarks/).\n\nWith Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\n\nQdrant is also available as a fully managed **[Qdrant Cloud](https://cloud.qdrant.io/)** ‚õÖ including a **free tier**.\n\n<p align=\"center\">\n<strong><a href=\"docs/QUICK_START.md\">Quick Start</a> ‚Ä¢ <a href=\"#clients\">Client Libraries</a> ‚Ä¢ <a href=\"#demo-projects\">Demo Projects</a> ‚Ä¢ <a href=\"#integrations\">Integrations</a> ‚Ä¢ <a href=\"#contacts\">Contact</a>\n\n</strong>\n</p>\n\n## Getting Started\n\n### Python\n\n```\npip install qdrant-client\n```\n\nThe python client offers a convenient way to start with Qdrant locally:\n\n```python\nfrom qdrant_client import QdrantClient\nqdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance, for testing, CI/CD\n# OR\nclient = QdrantClient(path=\"path/to/db\")  # Persists changes to disk, fast prototyping\n```\n\n### Client-Server\n\nTo experience the full power of Qdrant locally, run the container with this command:\n\n```bash\ndocker run -p 6333:6333 qdrant/qdrant\n```\n\n> [!CAUTION]\n> Starts an insecure deployment without authentication open to all network interfaces. Please refer to [secure your instance](https://qdrant.tech/documentation/guides/security/#secure-your-instance).\n\nNow you can connect to this with any client, including Python:\n\n```python\nqdrant = QdrantClient(\"http://localhost:6333\") # Connect to existing Qdrant instance\n```\n\nBefore deploying Qdrant to production, be sure to read our [installation](https://qdrant.tech/documentation/guides/installation/) and [security](https://qdrant.tech/documentation/guides/security/) guides.\n\n### Clients\n\nQdrant offers the following client libraries to help you integrate it into your application stack with ease:\n\n- Official:\n  - [Go client](https://github.com/qdrant/go-client)\n  - [Rust client](https://github.com/qdrant/rust-client)\n  - [JavaScript/TypeScript client](https://github.com/qdrant/qdrant-js)\n  - [Python client](https://github.com/qdrant/qdrant-client)\n  - [.NET/C# client](https://github.com/qdrant/qdrant-dotnet)\n  - [Java client](https://github.com/qdrant/java-client)\n- Community:\n  - [Elixir](https://hexdocs.pm/qdrant/readme.html)\n  - [PHP](https://github.com/hkulekci/qdrant-php)\n  - [Ruby](https://github.com/andreibondarev/qdrant-ruby)\n  - [Java](https://github.com/metaloom/qdrant-java-client)\n\n### Where do I go from here?\n\n- [Quick Start Guide](docs/QUICK_START.md)\n- End to End [Colab Notebook](https://colab.research.google.com/drive/1Bz8RSVHwnNDaNtDwotfPj0w7AYzsdXZ-?usp=sharing) demo with SentenceBERT and Qdrant\n- Detailed [Documentation](https://qdrant.tech/documentation/) are great starting points\n- [Step-by-Step Tutorial](https://qdrant.to/qdrant-tutorial) to create your first neural network project with Qdrant\n\n## Demo Projects<a href=\"https://replit.com/@qdrant\"><img align=\"right\" src=\"https://replit.com/badge/github/qdrant/qdrant\" alt=\"Run on Repl.it\"></a>\n\n### Discover Semantic Text Search üîç\n\nUnlock the power of semantic embeddings with Qdrant, transcending keyword-based search to find meaningful connections in short texts. Deploy a neural search in minutes using a pre-trained neural network, and experience the future of text search. [Try it online!](https://qdrant.to/semantic-search-demo)\n\n### Explore Similar Image Search - Food Discovery üçï\n\nThere's more to discovery than text search, especially when it comes to food. People often choose meals based on appearance rather than descriptions and ingredients. Let Qdrant help your users find their next delicious meal using visual search, even if they don't know the dish's name. [Check it out!](https://qdrant.to/food-discovery)\n\n### Master Extreme Classification - E-commerce Product Categorization üì∫\n\nEnter the cutting-edge realm of extreme classification, an emerging machine learning field tackling multi-class and multi-label problems with millions of labels. Harness the potential of similarity learning models, and see how a pre-trained transformer model and Qdrant can revolutionize e-commerce product categorization. [Play with it online!](https://qdrant.to/extreme-classification-demo)\n\n<details>\n<summary> More solutions </summary>\n\n<table>\n    <tr>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/text_search.png\">\n        </td>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/image_search.png\">\n        </td>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/recommendations.png\">\n        </td>\n    </tr>\n    <tr>\n        <td>\n            Semantic Text Search\n        </td>\n        <td>\n            Similar Image Search\n        </td>\n        <td>\n            Recommendations\n        </td>\n    </tr>\n</table>\n\n<table>\n    <tr>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/chat_bots.png\">\n        </td>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/matching_engines.png\">\n        </td>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/anomalies_detection.png\">\n        </td>\n    </tr>\n    <tr>\n        <td>\n            Chat Bots\n        </td>\n        <td>\n            Matching Engines\n        </td>\n        <td>\n            Anomaly Detection\n        </td>\n    </tr>\n</table>\n\n</details>\n\n## API\n\n### REST\n\nOnline OpenAPI 3.0 documentation is available [here](https://api.qdrant.tech/).\nOpenAPI makes it easy to generate a client for virtually any framework or programming language.\n\nYou can also download raw OpenAPI [definitions](https://github.com/qdrant/qdrant/blob/master/docs/redoc/master/openapi.json).\n\n### gRPC\n\nFor faster production-tier searches, Qdrant also provides a gRPC interface. You can find gRPC documentation [here](https://qdrant.tech/documentation/interfaces/#grpc-interface).\n\n## Features\n\n### Filtering and Payload\n\nQdrant can attach any JSON payloads to vectors, allowing for both the storage and filtering of data based on the values in these payloads.\nPayload supports a wide range of data types and query conditions, including keyword matching, full-text filtering, numerical ranges, geo-locations, and more.\n\nFiltering conditions can be combined in various ways, including `should`, `must`, and `must_not` clauses,\nensuring that you can implement any desired business logic on top of similarity matching.\n\n\n### Hybrid Search with Sparse Vectors\n\nTo address the limitations of vector embeddings when searching for specific keywords, Qdrant introduces support for sparse vectors in addition to the regular dense ones.\n\nSparse vectors can be viewed as an generalization of BM25 or TF-IDF ranking. They enable you to harness the capabilities of transformer-based neural networks to weigh individual tokens effectively.\n\n\n### Vector Quantization and On-Disk Storage\n\nQdrant provides multiple options to make vector search cheaper and more resource-efficient.\nBuilt-in vector quantization reduces RAM usage by up to 97% and dynamically manages the trade-off between search speed and precision.\n\n\n### Distributed Deployment\n\nQdrant offers comprehensive horizontal scaling support through two key mechanisms:\n1. Size expansion via sharding and throughput enhancement via replication\n2. Zero-downtime rolling updates and seamless dynamic scaling of the collections\n\n\n### Highlighted Features\n\n* **Query Planning and Payload Indexes** - leverages stored payload information to optimize query execution strategy.\n* **SIMD Hardware Acceleration** - utilizes modern CPU x86-x64 and Neon architectures to deliver better performance.\n* **Async I/O** - uses `io_uring` to maximize disk throughput utilization even on a network-attached storage.\n* **Write-Ahead Logging** - ensures data persistence with update confirmation, even during power outages.\n\n\n# Integrations\n\nExamples and/or documentation of Qdrant integrations:\n\n- [Cohere](https://docs.cohere.com/docs/qdrant-and-cohere) ([blogpost on building a QA app with Cohere and Qdrant](https://qdrant.tech/articles/qa-with-cohere-and-qdrant/)) - Use Cohere embeddings with Qdrant\n- [DocArray](https://docs.docarray.org/user_guide/storing/index_qdrant/) - Use Qdrant as a document store in DocArray\n- [Haystack](https://haystack.deepset.ai/integrations/qdrant-document-store) - Use Qdrant as a document store with Haystack ([blogpost](https://haystack.deepset.ai/blog/qdrant-integration)).\n- [LangChain](https://python.langchain.com/docs/integrations/providers/qdrant/) ([blogpost](https://qdrant.tech/articles/langchain-integration/)) - Use Qdrant as a memory backend for LangChain.\n- [LlamaIndex](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/QdrantIndexDemo.html) - Use Qdrant as a Vector Store with LlamaIndex.\n- [OpenAI - ChatGPT retrieval plugin](https://github.com/openai/chatgpt-retrieval-plugin/blob/main/docs/providers/qdrant/setup.md) - Use Qdrant as a memory backend for ChatGPT\n- [Microsoft Semantic Kernel](https://devblogs.microsoft.com/semantic-kernel/the-power-of-persistent-memory-with-semantic-kernel-and-qdrant-vector-database/) - Use Qdrant as persistent memory with Semantic Kernel\n\n## Contacts\n\n- Have questions? Join our [Discord channel](https://qdrant.to/discord) or mention [@qdrant_engine on Twitter](https://qdrant.to/twitter)\n- Want to stay in touch with latest releases? Subscribe to our [Newsletters](https://qdrant.tech/subscribe/)\n- Looking for a managed cloud? Check [pricing](https://qdrant.tech/pricing/), need something personalised? We're at [info@qdrant.tech](mailto:info@qdrant.tech)\n\n## License\n\nQdrant is licensed under the Apache License, Version 2.0. View a copy of the [License file](https://github.com/qdrant/qdrant/blob/master/LICENSE).\n",
      "stars_today": 23
    },
    {
      "id": 219616873,
      "name": "glow",
      "full_name": "charmbracelet/glow",
      "description": "Render markdown on the CLI, with pizzazz! üíÖüèª",
      "html_url": "https://github.com/charmbracelet/glow",
      "stars": 22388,
      "forks": 557,
      "language": "Go",
      "topics": [
        "cli",
        "excitement",
        "hacktoberfest",
        "markdown"
      ],
      "created_at": "2019-11-04T23:34:55Z",
      "updated_at": "2026-01-23T01:22:59Z",
      "pushed_at": "2026-01-12T11:55:43Z",
      "open_issues": 154,
      "owner": {
        "login": "charmbracelet",
        "avatar_url": "https://avatars.githubusercontent.com/u/57376114?v=4"
      },
      "readme": "# Glow\n\nRender markdown on the CLI, with _pizzazz_!\n\n<p align=\"center\">\n    <img src=\"https://stuff.charm.sh/glow/glow-banner-github.gif\" alt=\"Glow Logo\">\n    <a href=\"https://github.com/charmbracelet/glow/releases\"><img src=\"https://img.shields.io/github/release/charmbracelet/glow.svg\" alt=\"Latest Release\"></a>\n    <a href=\"https://pkg.go.dev/github.com/charmbracelet/glow?tab=doc\"><img src=\"https://godoc.org/github.com/golang/gddo?status.svg\" alt=\"GoDoc\"></a>\n    <a href=\"https://github.com/charmbracelet/glow/actions\"><img src=\"https://github.com/charmbracelet/glow/workflows/build/badge.svg\" alt=\"Build Status\"></a>\n    <a href=\"https://goreportcard.com/report/github.com/charmbracelet/glow\"><img src=\"https://goreportcard.com/badge/charmbracelet/glow\" alt=\"Go ReportCard\"></a>\n</p>\n\n<p align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/c2246366-f84b-4847-b431-32a61ca07b74\" width=\"800\" alt=\"Glow UI Demo\">\n</p>\n\n## What is it?\n\nGlow is a terminal based markdown reader designed from the ground up to bring\nout the beauty‚Äîand power‚Äîof the CLI.\n\nUse it to discover markdown files, read documentation directly on the command\nline. Glow will find local markdown files in subdirectories or a local\nGit repository.\n\n## Installation\n\n### Package Manager\n\n```bash\n# macOS or Linux\nbrew install glow\n```\n\n```bash\n# macOS (with MacPorts)\nsudo port install glow\n```\n\n```bash\n# Arch Linux (btw)\npacman -S glow\n```\n\n```bash\n# Void Linux\nxbps-install -S glow\n```\n\n```bash\n# Nix shell\nnix-shell -p glow --command glow\n```\n\n```bash\n# FreeBSD\npkg install glow\n```\n\n```bash\n# Solus\neopkg install glow\n```\n\n```bash\n# Windows (with Chocolatey, Scoop, or Winget)\nchoco install glow\nscoop install glow\nwinget install charmbracelet.glow\n```\n\n```bash\n# Android (with termux)\npkg install glow\n```\n\n```bash\n# Ubuntu (Snapcraft)\nsudo snap install glow\n```\n\n```bash\n# Debian/Ubuntu\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg\necho \"deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *\" | sudo tee /etc/apt/sources.list.d/charm.list\nsudo apt update && sudo apt install glow\n```\n\n```bash\n# Fedora/RHEL\necho '[charm]\nname=Charm\nbaseurl=https://repo.charm.sh/yum/\nenabled=1\ngpgcheck=1\ngpgkey=https://repo.charm.sh/yum/gpg.key' | sudo tee /etc/yum.repos.d/charm.repo\nsudo yum install glow\n```\n\nOr download a binary from the [releases][releases] page. MacOS, Linux, Windows,\nFreeBSD and OpenBSD binaries are available, as well as Debian, RPM, and Alpine\npackages. ARM builds are also available for macOS, Linux, FreeBSD and OpenBSD.\n\n### Go\n\nOr just install it with `go`:\n\n```bash\ngo install github.com/charmbracelet/glow/v2@latest\n```\n\n### Build (requires Go 1.21+)\n\n```bash\ngit clone https://github.com/charmbracelet/glow.git\ncd glow\ngo build\n```\n\n[releases]: https://github.com/charmbracelet/glow/releases\n\n## The TUI\n\nSimply run `glow` without arguments to start the textual user interface and\nbrowse local. Glow will find local markdown files in the\ncurrent directory and below or, if you‚Äôre in a Git repository, Glow will search\nthe repo.\n\nMarkdown files can be read with Glow's high-performance pager. Most of the\nkeystrokes you know from `less` are the same, but you can press `?` to list\nthe hotkeys.\n\n## The CLI\n\nIn addition to a TUI, Glow has a CLI for working with Markdown. To format a\ndocument use a markdown source as the primary argument:\n\n```bash\n# Read from file\nglow README.md\n\n# Read from stdin\necho \"[Glow](https://github.com/charmbracelet/glow)\" | glow -\n\n# Fetch README from GitHub / GitLab\nglow github.com/charmbracelet/glow\n\n# Fetch markdown from HTTP\nglow https://host.tld/file.md\n```\n\n### Word Wrapping\n\nThe `-w` flag lets you set a maximum width at which the output will be wrapped:\n\n```bash\nglow -w 60\n```\n\n### Paging\n\nCLI output can be displayed in your preferred pager with the `-p` flag. This defaults\nto the ANSI-aware `less -r` if `$PAGER` is not explicitly set.\n\n### Styles\n\nYou can choose a style with the `-s` flag. When no flag is provided `glow` tries\nto detect your terminal's current background color and automatically picks\neither the `dark` or the `light` style for you.\n\n```bash\nglow -s [dark|light]\n```\n\nAlternatively you can also supply a custom JSON stylesheet:\n\n```bash\nglow -s mystyle.json\n```\n\nFor additional usage details see:\n\n```bash\nglow --help\n```\n\nCheck out the [Glamour Style Section](https://github.com/charmbracelet/glamour/blob/master/styles/gallery/README.md)\nto find more styles. Or [make your own](https://github.com/charmbracelet/glamour/tree/master/styles)!\n\n## The Config File\n\nIf you find yourself supplying the same flags to `glow` all the time, it's\nprobably a good idea to create a config file. Run `glow config`, which will open\nit in your favorite $EDITOR. Alternatively you can manually put a file named\n`glow.yml` in the default config path of you platform. If you're not sure where\nthat is, please refer to `glow --help`.\n\nHere's an example config:\n\n```yaml\n# style name or JSON path (default \"auto\")\nstyle: \"light\"\n# mouse wheel support (TUI-mode only)\nmouse: true\n# use pager to display markdown\npager: true\n# at which column should we word wrap?\nwidth: 80\n# show all files, including hidden and ignored.\nall: false\n# show line numbers (TUI-mode only)\nshowLineNumbers: false\n# preserve newlines in the output\npreserveNewLines: false\n```\n\n## Contributing\n\nSee [contributing][contribute].\n\n[contribute]: https://github.com/charmbracelet/glow/contribute\n\n## Feedback\n\nWe‚Äôd love to hear your thoughts on this project. Feel free to drop us a note!\n\n- [Twitter](https://twitter.com/charmcli)\n- [The Fediverse](https://mastodon.social/@charmcli)\n- [Discord](https://charm.sh/chat)\n\n## License\n\n[MIT](https://github.com/charmbracelet/glow/raw/master/LICENSE)\n\n---\n\nPart of [Charm](https://charm.sh).\n\n<a href=\"https://charm.sh/\"><img alt=\"The Charm logo\" src=\"https://stuff.charm.sh/charm-badge.jpg\" width=\"400\"></a>\n\nCharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source\n",
      "stars_today": 23
    },
    {
      "id": 22067521,
      "name": "imgui",
      "full_name": "ocornut/imgui",
      "description": "Dear ImGui: Bloat-free Graphical User interface for C++ with minimal dependencies",
      "html_url": "https://github.com/ocornut/imgui",
      "stars": 70893,
      "forks": 11483,
      "language": "C++",
      "topics": [
        "api",
        "cplusplus",
        "framework",
        "game-development",
        "game-engine",
        "gamedev",
        "gui",
        "imgui",
        "immediate-gui",
        "library",
        "multi-platform",
        "native",
        "toolkit",
        "tools",
        "ui"
      ],
      "created_at": "2014-07-21T14:29:47Z",
      "updated_at": "2026-01-23T01:47:23Z",
      "pushed_at": "2026-01-22T19:20:40Z",
      "open_issues": 1196,
      "owner": {
        "login": "ocornut",
        "avatar_url": "https://avatars.githubusercontent.com/u/8225057?v=4"
      },
      "readme": "Dear ImGui\n=====\n\n<center><b><i>\"Give someone state and they'll have a bug one day, but teach them how to represent state in two separate locations that have to be kept in sync and they'll have bugs for a lifetime.\"</i></b></center> <a href=\"https://twitter.com/rygorous/status/1507178315886444544\">-ryg</a>\n\n----\n\n[![Build Status](https://github.com/ocornut/imgui/workflows/build/badge.svg)](https://github.com/ocornut/imgui/actions?workflow=build) [![Static Analysis Status](https://github.com/ocornut/imgui/workflows/static-analysis/badge.svg)](https://github.com/ocornut/imgui/actions?workflow=static-analysis) [![Tests Status](https://github.com/ocornut/imgui_test_engine/workflows/tests/badge.svg)](https://github.com/ocornut/imgui_test_engine/actions?workflow=tests)\n\n<sub>(This library is available under a free and permissive license, but needs financial support to sustain its continued improvements. In addition to maintenance and stability there are many desirable features yet to be added. If your company is using Dear ImGui, please consider reaching out.)</sub>\n\nBusinesses: support continued development and maintenance via invoiced sponsoring/support contracts:\n<br>&nbsp;&nbsp;_E-mail: contact @ dearimgui dot com_\n<br>Individuals: support continued development and maintenance [here](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=WGHNC6MBFLZ2S). Also see [Funding](https://github.com/ocornut/imgui/wiki/Funding) page.\n\n| [The Pitch](#the-pitch) - [Usage](#usage) - [How it works](#how-it-works) - [Releases & Changelogs](#releases--changelogs) - [Demo](#demo) - [Getting Started & Integration](#getting-started--integration) |\n:----------------------------------------------------------: |\n| [Gallery](#gallery) - [Support, FAQ](#support-frequently-asked-questions-faq) -  [How to help](#how-to-help) - **[Funding & Sponsors](https://github.com/ocornut/imgui/wiki/Funding)** - [Credits](#credits) - [License](#license) |\n| [Wiki](https://github.com/ocornut/imgui/wiki) - [Extensions](https://github.com/ocornut/imgui/wiki/Useful-Extensions) - [Language bindings & framework backends](https://github.com/ocornut/imgui/wiki/Bindings) - [Software using Dear ImGui](https://github.com/ocornut/imgui/wiki/Software-using-dear-imgui) - [User quotes](https://github.com/ocornut/imgui/wiki/Quotes) |\n\n### The Pitch\n\nDear ImGui is a **bloat-free graphical user interface library for C++**. It outputs optimized vertex buffers that you can render anytime in your 3D-pipeline-enabled application. It is fast, portable, renderer agnostic, and self-contained (no external dependencies).\n\nDear ImGui is designed to **enable fast iterations** and to **empower programmers** to create **content creation tools and visualization / debug tools** (as opposed to UI for the average end-user). It favors simplicity and productivity toward this goal and lacks certain features commonly found in more high-level libraries. Among other things, full internationalization (right-to-left text, bidirectional text, text shaping etc.) and accessibility features are not supported.\n\nDear ImGui is particularly suited to integration in game engines (for tooling), real-time 3D applications, fullscreen applications, embedded applications, or any applications on console platforms where operating system features are non-standard.\n\n - Minimize state synchronization.\n - Minimize UI-related state storage on user side.\n - Minimize setup and maintenance.\n - Easy to use to create dynamic UI which are the reflection of a dynamic data set.\n - Easy to use to create code-driven and data-driven tools.\n - Easy to use to create ad hoc short-lived tools and long-lived, more elaborate tools.\n - Easy to hack and improve.\n - Portable, minimize dependencies, run on target (consoles, phones, etc.).\n - Efficient runtime and memory consumption.\n - Battle-tested, used by [many major actors in the game industry](https://github.com/ocornut/imgui/wiki/Software-using-dear-imgui).\n\n### Usage\n\n**The core of Dear ImGui is self-contained within a few platform-agnostic files** which you can easily compile in your application/engine. They are all the files in the root folder of the repository (`imgui*.cpp`, `imgui*.h`). **No specific build process is required**: you can add all files into your existing project.\n\n**Backends for a variety of graphics API and rendering platforms** are provided in the [backends/](https://github.com/ocornut/imgui/tree/master/backends) folder, along with example applications in the [examples/](https://github.com/ocornut/imgui/tree/master/examples) folder. You may also create your own backend. Anywhere where you can render textured triangles, you can render Dear ImGui.\n\nC++20 users wishing to use a module may the use [stripe2933/imgui-module](https://github.com/stripe2933/imgui-module) third-party extension.\n\nSee the [Getting Started & Integration](#getting-started--integration) section of this document for more details.\n\nAfter Dear ImGui is set up in your application, you can use it from \\_anywhere\\_ in your program loop:\n```cpp\nImGui::Text(\"Hello, world %d\", 123);\nif (ImGui::Button(\"Save\"))\n    MySaveFunction();\nImGui::InputText(\"string\", buf, IM_COUNTOF(buf));\nImGui::SliderFloat(\"float\", &f, 0.0f, 1.0f);\n```\n![sample code output (dark, segoeui font, freetype)](https://user-images.githubusercontent.com/8225057/191050833-b7ecf528-bfae-4a9f-ac1b-f3d83437a2f4.png)\n![sample code output (light, segoeui font, freetype)](https://user-images.githubusercontent.com/8225057/191050838-8742efd4-504d-4334-a9a2-e756d15bc2ab.png)\n\n```cpp\n// Create a window called \"My First Tool\", with a menu bar.\nImGui::Begin(\"My First Tool\", &my_tool_active, ImGuiWindowFlags_MenuBar);\nif (ImGui::BeginMenuBar())\n{\n    if (ImGui::BeginMenu(\"File\"))\n    {\n        if (ImGui::MenuItem(\"Open..\", \"Ctrl+O\")) { /* Do stuff */ }\n        if (ImGui::MenuItem(\"Save\", \"Ctrl+S\"))   { /* Do stuff */ }\n        if (ImGui::MenuItem(\"Close\", \"Ctrl+W\"))  { my_tool_active = false; }\n        ImGui::EndMenu();\n    }\n    ImGui::EndMenuBar();\n}\n\n// Edit a color stored as 4 floats\nImGui::ColorEdit4(\"Color\", my_color);\n\n// Generate samples and plot them\nfloat samples[100];\nfor (int n = 0; n < 100; n++)\n    samples[n] = sinf(n * 0.2f + ImGui::GetTime() * 1.5f);\nImGui::PlotLines(\"Samples\", samples, 100);\n\n// Display contents in a scrolling region\nImGui::TextColored(ImVec4(1,1,0,1), \"Important Stuff\");\nImGui::BeginChild(\"Scrolling\");\nfor (int n = 0; n < 50; n++)\n    ImGui::Text(\"%04d: Some text\", n);\nImGui::EndChild();\nImGui::End();\n```\n![my_first_tool_v188](https://user-images.githubusercontent.com/8225057/191055698-690a5651-458f-4856-b5a9-e8cc95c543e2.gif)\n\nDear ImGui allows you to **create elaborate tools** as well as very short-lived ones. On the extreme side of short-livedness: using the Edit&Continue (hot code reload) feature of modern compilers you can add a few widgets to tweak variables while your application is running, and remove the code a minute later! Dear ImGui is not just for tweaking values. You can use it to trace a running algorithm by just emitting text commands. You can use it along with your own reflection data to browse your dataset live. You can use it to expose the internals of a subsystem in your engine, to create a logger, an inspection tool, a profiler, a debugger, an entire game-making editor/framework, etc.\n\n### How it works\n\nThe IMGUI paradigm through its API tries to minimize superfluous state duplication, state synchronization, and state retention from the user's point of view. It is less error-prone (less code and fewer bugs) than traditional retained-mode interfaces, and lends itself to creating dynamic user interfaces. Check out the Wiki's [About the IMGUI paradigm](https://github.com/ocornut/imgui/wiki#about-the-imgui-paradigm) section for more details.\n\nDear ImGui outputs vertex buffers and command lists that you can easily render in your application. The number of draw calls and state changes required to render them is fairly small. Because Dear ImGui doesn't know or touch graphics state directly, you can call its functions  anywhere in your code (e.g. in the middle of a running algorithm, or in the middle of your own rendering process). Refer to the sample applications in the examples/ folder for instructions on how to integrate Dear ImGui with your existing codebase.\n\n_A common misunderstanding is to mistake immediate mode GUI for immediate mode rendering, which usually implies hammering your driver/GPU with a bunch of inefficient draw calls and state changes as the GUI functions are called. This is NOT what Dear ImGui does. Dear ImGui outputs vertex buffers and a small list of draw calls batches. It never touches your GPU directly. The draw call batches are decently optimal and you can render them later, in your app or even remotely._\n\n### Releases & Changelogs\n\nSee [Releases](https://github.com/ocornut/imgui/releases) page for decorated Changelogs.\nReading the changelogs is a good way to keep up to date with the things Dear ImGui has to offer, and maybe will give you ideas of some features that you've been ignoring until now!\n\n### Demo\n\nCalling the `ImGui::ShowDemoWindow()` function will create a demo window showcasing a variety of features and examples. The code is always available for reference in `imgui_demo.cpp`. \n- [Web version of the demo](https://pthom.github.io/imgui_manual_online/manual/imgui_manual.html) courtesy of [@pthom](https://github.com/pthom).\n- [Screenshot of the demo](https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v167/v167-misc.png).\n\nYou should be able to build the examples from sources. If you don't, let us know! If you want to have a quick look at some Dear ImGui features, you can download Windows binaries of the demo app here:\n- [imgui-demo-binaries-20250625.zip](https://www.dearimgui.com/binaries/imgui-demo-binaries-20250625.zip) (Windows, 1.92.0, built 2025/06/25, master) or [older binaries](https://www.dearimgui.com/binaries).\n\n### Getting Started & Integration\n\nSee the [Getting Started](https://github.com/ocornut/imgui/wiki/Getting-Started) guide for details.\n\nOn most platforms and when using C++, **you should be able to use a combination of the [imgui_impl_xxxx](https://github.com/ocornut/imgui/tree/master/backends) backends without modification** (e.g. `imgui_impl_win32.cpp` + `imgui_impl_dx11.cpp`). If your engine supports multiple platforms, consider using more imgui_impl_xxxx files instead of rewriting them: this will be less work for you, and you can get Dear ImGui running immediately. You can _later_ decide to rewrite a custom backend using your custom engine functions if you wish so.\n\nIntegrating Dear ImGui within your custom engine is a matter of mainly 1) wiring mouse/keyboard/gamepad inputs 2) uploading a texture to your GPU/render engine 3) providing a render function that can create/update textures and render textured triangles. This is exactly what backends are doing.\n- The [examples/](https://github.com/ocornut/imgui/tree/master/examples) folder is populated with applications setting up a window and using standard backends.\n- The [Getting Started](https://github.com/ocornut/imgui/wiki/Getting-Started) guide has instructions to integrate imgui into an existing application using standard backends. It should in theory take you less than an hour to integrate Dear ImGui into your existing codebase where support libraries are linked. Less if you read carefully.\n- The [Backends](https://github.com/ocornut/imgui/blob/master/docs/BACKENDS.md) guide explains what backends are doing, and has instructions to implement a custom backend. You can also refer to the source code of our ~20 backends to understand how they work.\n- Generally, **make sure to spend time reading the [FAQ](https://www.dearimgui.com/faq), comments, and the examples applications!**\n\nOfficially maintained backends (in repository):\n- Renderers: DirectX9, DirectX10, DirectX11, DirectX12, Metal, OpenGL/ES/ES2, SDL_GPU, SDL_Renderer2/3, Vulkan, WebGPU.\n- Platforms: GLFW, SDL2/SDL3, Win32, Glut, OSX, Android.\n- Frameworks: Allegro5, Emscripten.\n\n[Third-party backends/bindings](https://github.com/ocornut/imgui/wiki/Bindings) wiki page:\n- Languages: C, C# and: Beef, ChaiScript, CovScript, Crystal, D, Go, Haskell, Haxe/hxcpp, Java, JavaScript, Julia, Kotlin, Lobster, Lua, Nim, Odin, Pascal, PureBasic, Python, ReaScript, Ruby, Rust, Swift, Zig...\n- Frameworks: AGS/Adventure Game Studio, Amethyst, Blender, bsf, Cinder, Cocos2d-x, Defold, Diligent Engine, Ebiten, Flexium, GML/Game Maker Studio, GLEQ, Godot, GTK3, Irrlicht Engine, JUCE, L√ñVE+LUA, Mach Engine, Magnum, Marmalade, Monogame, NanoRT, nCine, Nim Game Lib, Nintendo 3DS/Switch/WiiU (homebrew), Ogre, openFrameworks, OSG/OpenSceneGraph, Orx, Photoshop, px_render, Qt/QtDirect3D, raylib, SFML, Sokol, Unity, Unreal Engine 4/5, UWP, vtk, VulkanHpp, VulkanSceneGraph, Win32 GDI, WxWidgets.\n- Many bindings are auto-generated (by good old [cimgui](https://github.com/cimgui/cimgui) or our newer [dear_bindings](https://github.com/dearimgui/dear_bindings)), you can use their metadata output to generate bindings for other languages.\n\n[Useful Extensions/Widgets](https://github.com/ocornut/imgui/wiki/Useful-Extensions) wiki page:\n- Automation/testing, Text editors, node editors, timeline editors, plotting, software renderers, remote network access, memory editors, gizmos, etc. Notable and well supported extensions include [ImPlot](https://github.com/epezent/implot) and [Dear ImGui Test Engine](https://github.com/ocornut/imgui_test_engine).\n\nAlso see [Wiki](https://github.com/ocornut/imgui/wiki) for more links and ideas.\n\n### Gallery\n\nExamples projects using Dear ImGui: [Tracy](https://github.com/wolfpld/tracy) (profiler), [ImHex](https://github.com/WerWolv/ImHex) (hex editor/data analysis), [RemedyBG](https://remedybg.itch.io/remedybg) (debugger) and [hundreds of others](https://github.com/ocornut/imgui/wiki/Software-using-Dear-ImGui).\n\nFor more user-submitted screenshots of projects using Dear ImGui, check out the [Gallery Threads](https://github.com/ocornut/imgui/issues?q=label%3Agallery)!\n\nFor a list of third-party widgets and extensions, check out the [Useful Extensions/Widgets](https://github.com/ocornut/imgui/wiki/Useful-Extensions) wiki page.\n\n|  |  |\n|--|--|\n| Custom engine [erhe](https://github.com/tksuoran/erhe) (docking branch)<BR>[![erhe](https://user-images.githubusercontent.com/8225057/190203358-6988b846-0686-480e-8663-1311fbd18abd.jpg)](https://user-images.githubusercontent.com/994606/147875067-a848991e-2ad2-4fd3-bf71-4aeb8a547bcf.png) | Custom engine for [Wonder Boy: The Dragon's Trap](http://www.TheDragonsTrap.com) (2017)<BR>[![the dragon's trap](https://user-images.githubusercontent.com/8225057/190203379-57fcb80e-4aec-4fec-959e-17ddd3cd71e5.jpg)](https://cloud.githubusercontent.com/assets/8225057/20628927/33e14cac-b329-11e6-80f6-9524e93b048a.png) |\n| Custom engine (untitled)<BR>[![editor white](https://user-images.githubusercontent.com/8225057/190203393-c5ac9f22-b900-4d1e-bfeb-6027c63e3d92.jpg)](https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v160/editor_white.png) | Tracy Profiler ([github](https://github.com/wolfpld/tracy))<BR>[![tracy profiler](https://user-images.githubusercontent.com/8225057/190203401-7b595f6e-607c-44d3-97ea-4c2673244dfb.jpg)](https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v176/tracy_profiler.png) |\n\n### Support, Frequently Asked Questions (FAQ)\n\nSee: [Frequently Asked Questions (FAQ)](https://github.com/ocornut/imgui/blob/master/docs/FAQ.md) where common questions are answered.\n\nSee: [Getting Started](https://github.com/ocornut/imgui/wiki/Getting-Started) and [Wiki](https://github.com/ocornut/imgui/wiki) for many links, references, articles.\n\nSee: [Articles about the IMGUI paradigm](https://github.com/ocornut/imgui/wiki#about-the-imgui-paradigm) to read/learn about the Immediate Mode GUI paradigm.\n\nSee: [Upcoming Changes](https://github.com/ocornut/imgui/wiki/Upcoming-Changes).\n\nSee: [Dear ImGui Test Engine + Test Suite](https://github.com/ocornut/imgui_test_engine) for Automation & Testing.\n\nFor the purposes of getting search engines to crawl the wiki, here's a link to the [Crawlable Wiki](https://github-wiki-see.page/m/ocornut/imgui/wiki) (not for humans, [here's why](https://github-wiki-see.page/)).\n\nGetting started? For first-time users having issues compiling/linking/running or issues loading fonts, please use [GitHub Discussions](https://github.com/ocornut/imgui/discussions). For ANY other questions, bug reports, requests, feedback, please post on [GitHub Issues](https://github.com/ocornut/imgui/issues). Please read and fill the New Issue template carefully.\n\nPrivate support is available for paying business customers (E-mail: _contact @ dearimgui dot com_).\n\n**Which version should I get?**\n\nWe occasionally tag [Releases](https://github.com/ocornut/imgui/releases) (with nice releases notes) but it is generally safe and recommended to sync to latest `master` or `docking` branch. The library is fairly stable and regressions tend to be fixed fast when reported. Advanced users may want to use the `docking` branch with [Multi-Viewport](https://github.com/ocornut/imgui/wiki/Multi-Viewports) and [Docking](https://github.com/ocornut/imgui/wiki/Docking) features. This branch is kept in sync with master regularly.\n\n**Who uses Dear ImGui?**\n\nSee the [Quotes](https://github.com/ocornut/imgui/wiki/Quotes), [Funding & Sponsors](https://github.com/ocornut/imgui/wiki/Funding), and [Software using Dear ImGui](https://github.com/ocornut/imgui/wiki/Software-using-dear-imgui) Wiki pages for an idea of who is using Dear ImGui. Please add your game/software if you can! Also, see the [Gallery Threads](https://github.com/ocornut/imgui/issues?q=label%3Agallery)!\n\nHow to help\n-----------\n\n**How can I help?**\n\n- See [GitHub Forum/Issues](https://github.com/ocornut/imgui/issues).\n- You may help with development and submit pull requests! Please understand that by submitting a PR you are also submitting a request for the maintainer to review your code and then take over its maintenance forever. PR should be crafted both in the interest of the end-users and also to ease the maintainer into understanding and accepting it.\n- See [Help wanted](https://github.com/ocornut/imgui/wiki/Help-Wanted) on the [Wiki](https://github.com/ocornut/imgui/wiki/) for some more ideas.\n- Be a [Funding Supporter](https://github.com/ocornut/imgui/wiki/Funding)! Have your company financially support this project via invoiced sponsors/maintenance or by buying a license for [Dear ImGui Test Engine](https://github.com/ocornut/imgui_test_engine) (please reach out: contact AT dearimgui DOT com).\n\nSponsors\n--------\n\nOngoing Dear ImGui development is and has been financially supported by users and private sponsors.\n<BR>Please see the **[detailed list of current and past Dear ImGui funding supporters and sponsors](https://github.com/ocornut/imgui/wiki/Funding)** for details.\n<BR>From November 2014 to December 2019, ongoing development has also been financially supported by its users on Patreon and through individual donations.\n\n**THANK YOU to all past and present supporters for helping to keep this project alive and thriving!**\n\nDear ImGui is using software and services provided free of charge for open source projects:\n- [PVS-Studio](https://pvs-studio.com/en/pvs-studio/?utm_source=website&utm_medium=github&utm_campaign=open_source) for static analysis (supports C/C++/C#/Java).\n- [GitHub actions](https://github.com/features/actions) for continuous integration systems.\n- [OpenCppCoverage](https://github.com/OpenCppCoverage/OpenCppCoverage) for code coverage analysis.\n\nCredits\n-------\n\nDeveloped by [Omar Cornut](https://www.miracleworld.net) and every direct or indirect [contributors](https://github.com/ocornut/imgui/graphs/contributors) to the GitHub. The early version of this library was developed with the support of [Media Molecule](https://www.mediamolecule.com) and first used internally on the game [Tearaway](https://youtu.be/w0oxBviRGlU) (PS Vita).\n\nRecurring contributors include Rokas Kupstys [@rokups](https://github.com/rokups) (2020-2022): a good portion of work on automation system and regression tests now available in [Dear ImGui Test Engine](https://github.com/ocornut/imgui_test_engine).\n\nMaintenance/support contracts, sponsoring invoices and other B2B transactions are hosted and handled by [Disco Hello](https://www.discohello.com).\n\nOmar: \"I first discovered the IMGUI paradigm at [Q-Games](https://www.q-games.com) where Atman Binstock had dropped his own simple implementation in the codebase, which I spent quite some time improving and thinking about. It turned out that Atman was exposed to the concept directly by working with Casey. When I moved to Media Molecule I rewrote a new library trying to overcome the flaws and limitations of the first one I've worked with. It became this library and since then I have spent an unreasonable amount of time iterating and improving it.\"\n\nEmbeds [ProggyClean.ttf, ProggyVector.ttf](https://www.proggyfonts.net) fonts by Tristan Grimmer (MIT license).\n<br>Embeds [stb_textedit.h, stb_truetype.h, stb_rect_pack.h](https://github.com/nothings/stb/) by Sean Barrett (public domain).\n\nInspiration, feedback, and testing for early versions: Casey Muratori, Atman Binstock, Mikko Mononen, Emmanuel Briney, Stefan Kamoda, Anton Mikhailov, Matt Willis. Special thanks to Alex Evans, Patrick Doane, Marco Koegler for kindly helping. Also thank you to everyone posting feedback, questions and patches on GitHub.\n\nLicense\n-------\n\nDear ImGui is licensed under the MIT License, see [LICENSE.txt](https://github.com/ocornut/imgui/blob/master/LICENSE.txt) for more information.\n",
      "stars_today": 22
    },
    {
      "id": 837073921,
      "name": "boring.notch",
      "full_name": "TheBoredTeam/boring.notch",
      "description": "TheBoringNotch: Not so boring notch That Rocks üé∏üé∂",
      "html_url": "https://github.com/TheBoredTeam/boring.notch",
      "stars": 6620,
      "forks": 461,
      "language": "Swift",
      "topics": [],
      "created_at": "2024-08-02T06:48:39Z",
      "updated_at": "2026-01-22T23:48:39Z",
      "pushed_at": "2026-01-15T00:10:03Z",
      "open_issues": 171,
      "owner": {
        "login": "TheBoredTeam",
        "avatar_url": "https://avatars.githubusercontent.com/u/180768848?v=4"
      },
      "readme": "<h1 align=\"center\">\n  <br>\n  <a href=\"http://theboring.name\"><img src=\"https://framerusercontent.com/images/RFK4vs0kn8pRMuOO58JeyoemXA.png?scale-down-to=256\" alt=\"Boring Notch\" width=\"150\"></a>\n  <br>\n  Boring Notch\n  <br>\n</h1>\n\n\n<p align=\"center\">\n  <a title=\"Crowdin\" target=\"_blank\" href=\"https://crowdin.com/project/boring-notch\"><img src=\"https://badges.crowdin.net/boring-notch/localized.svg\"></a>\n  <img src=\"https://github.com/TheBoredTeam/boring.notch/actions/workflows/cicd.yml/badge.svg\" alt=\"TheBoringNotch Build & Test\" style=\"margin-right: 10px;\" />\n  <a href=\"https://discord.gg/c8JXA7qrPm\">\n    <img src=\"https://dcbadge.limes.pink/api/server/https://discord.gg/c8JXA7qrPm?style=flat\" alt=\"Discord Badge\" />\n  </a>\n  <a href=\"ttps://ko-fi.com/brandonhimpfen\">\n    <img src=\"https://srv-cdn.himpfen.io/badges/kofi/kofi-flat.svg\" alt=\"Ko-Fi\" />\n  </a>\n</p>\n\n<!--Welcome to **Boring.Notch**, the coolest way to make your MacBook's notch the star of the show! Forget about those boring status bars‚Äîour notch turns into a dynamic music control center, complete with a snazzy visualizer and all the music controls you need. It's like having a mini concert right at the top of your screen! -->\n\nSay hello to **Boring Notch**, the coolest way to make your MacBook‚Äôs notch the star of the show! Say goodbye to boring status bars: with Boring Notch, your notch transforms into a dynamic music control center, complete with a vibrant visualizer and all the essential music controls you need. But that‚Äôs just the start! Boring Notch also offers calendar integration, a handy file shelf with AirDrop support, a complete MacOS HUD replacement and more!\n\n<p align=\"center\">\n  <img src=\"https://github.com/user-attachments/assets/2d5f69c1-6e7b-4bc2-a6f1-bb9e27cf88a8\" alt=\"Demo GIF\" />\n</p>\n\n<!--https://github.com/user-attachments/assets/19b87973-4b3a-4853-b532-7e82d1d6b040-->\n---\n<!--## Table of Contents\n- [Installation](#installation)\n- [Usage](#usage)\n- [Roadmap](#-roadmap)\n- [Building from Source](#building-from-source)\n- [Contributing](#-contributing)\n- [Join our Discord Server](#join-our-discord-server)\n- [Star History](#star-history)\n- [Buy us a coffee!](#buy-us-a-coffee)\n- [Acknowledgments](#-acknowledgments)-->\n\n## Installation\n\n**System Requirements:**  \n- macOS **14 Sonoma** or later  \n- Apple Silicon or Intel Mac\n\n---\n> [!IMPORTANT]\n> We don't have an Apple Developer account yet. The application will show a popup on first launch that the app is from an unidentified developer.\n> 1. Click **OK** to close the popup.\n> 2. Open **System Settings** > **Privacy & Security**.\n> 3. Scroll down and click **Open Anyway** next to the warning about the app.\n> 4. Confirm your choice if prompted.\n>\n> You only need to do this once.\n\n\n### Option 1: Download and Install Manually\n<a href=\"https://github.com/TheBoredTeam/boring.notch/releases/latest/download/boringNotch.dmg\" target=\"_self\"><img width=\"200\" src=\"https://github.com/user-attachments/assets/e3179be1-8416-4b8a-b417-743e1ecc67d6\" alt=\"Download for macOS\" /></a>\n\n---\n\n### Option 2: Install via Homebrew\n\nYou can also install the app using [Homebrew](https://brew.sh):\n\n```bash\nbrew install --cask TheBoredTeam/boring-notch/boring-notch --no-quarantine\n```\n\n## Usage\n\n- Launch the app, and voil√†‚Äîyour notch is now the coolest part of your screen.\n- Hover over the notch to see it expand and reveal all its secrets.\n- Use the controls to manage your music like a rockstar.\n- Click the star in your menu bar to customize your notch to your heart's content.\n\n## üìã Roadmap\n- [x] Playback live activity üéß\n- [x] Calendar integration üìÜ\n- [x] Reminders integration ‚òëÔ∏è\n- [x] Mirror üì∑\n- [x] Charging indicator and current percentage üîã\n- [x] Customizable gesture control üëÜüèª\n- [x] Shelf functionality with AirDrop üìö\n- [x] Notch sizing customization, finetuning on different display sizes üñ•Ô∏è\n- [x] System HUD replacements (volume, brightness, backlight) üéöÔ∏èüí°‚å®Ô∏è\n- [ ] Bluetooth Live Activity (connect/disconnect for bluetooth devices) \n- [ ] Weather integration ‚õÖÔ∏è\n- [ ] Customizable Layout options üõ†Ô∏è\n- [ ] Lock Screen Widgets üîí\n- [ ] Extension system üß©\n- [ ] Notifications (under consideration) üîî\n<!-- - [ ] Clipboard history manager üìå `Extension` -->\n<!-- - [ ] Download indicator of different browsers (Safari, Chromium browsers, Firefox) üåç `Extension`-->\n<!-- - [ ] Customizable function buttons üéõÔ∏è -->\n<!-- - [ ] App switcher ü™Ñ -->\n\n<!-- ## üß© Extensions\n> [!NOTE]\n> We‚Äôre hard at work on some awesome extensions! Stay tuned, and we‚Äôll keep you updated as soon as they‚Äôre released. -->\n\n## Building from Source\n\n### Prerequisites\n\n- **macOS 14 or later**: If you‚Äôre not on the latest macOS, we might need to send a search party.\n- **Xcode 16 or later**: This is where the magic happens, so make sure it‚Äôs up-to-date.\n\n### Installation\n\n1. **Clone the Repository**:\n   ```bash\n   git clone https://github.com/TheBoredTeam/boring.notch.git\n   cd boring.notch\n   ```\n\n2. **Open the Project in Xcode**:\n   ```bash\n   open boringNotch.xcodeproj\n   ```\n\n3. **Build and Run**:\n    - Click the \"Run\" button or press `Cmd + R`. Watch the magic unfold!\n\n## ü§ù Contributing\n\nWe‚Äôre all about good vibes and awesome contributions! Read [CONTRIBUTING.md](CONTRIBUTING.md) to learn how you can join the fun!\n\n## Join our Discord Server\n\n<a href=\"https://discord.gg/GvYcYpAKTu\" target=\"_blank\"><img src=\"https://iili.io/28m3GHv.png\" alt=\"Join The Boring Server!\" style=\"height: 60px !important;width: 217px !important;\" ></a>\n\n## Star History\n\n<a href=\"https://www.star-history.com/#TheBoredTeam/boring.notch&Timeline\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=TheBoredTeam/boring.notch&type=Timeline&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=TheBoredTeam/boring.notch&type=Timeline\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=TheBoredTeam/boring.notch&type=Timeline\" />\n </picture>\n</a>\n\n## Support us on Ko-fi!\n<!-- <a href=\"https://www.buymeacoffee.com/jfxh67wvfxq\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/v2/default-red.png\" alt=\"Buy Me A Coffee\" style=\"height: 60px !important;width: 217px !important;\" ></a> -->\n<a href=\"https://www.ko-fi.com/alexander5015\" target=\"_blank\"><img src=\"https://github.com/user-attachments/assets//a76175ef-7e93-475a-8b67-4922ba5964c2\" alt=\"Support us on Ko-fi\" style=\"height: 70px !important;width: 346px !important;\" ></a>\n\n## üéâ Acknowledgments\n\nWe would like to express our gratitude to the authors and maintainers of the open-source projects that made this possible. \n\n## Notable Projects\n- **[MediaRemoteAdapter](https://github.com/ungive/mediaremote-adapter)** ‚Äì  An open-source project that allowed us to use the Now Playing source in macOS 15.4+\n- **[NotchDrop](https://github.com/Lakr233/NotchDrop)** ‚Äì An open-source project that has been instrumental in developing the first version of the \"Shelf\" feature in Boring Notch.\n\nFor a full list of licenses and attributions, please see the [Third-Party Licenses](./THIRD_PARTY_LICENSES.md) file.\n\n### Icon credits: [@maxtron95](https://github.com/maxtron95)\n### Website credits: [@himanshhhhuv](https://github.com/himanshhhhuv)\n\n- **SwiftUI**: For making us look like coding wizards.\n- **You**: For being awesome and checking out **boring.notch**!\n\n\n",
      "stars_today": 21
    },
    {
      "id": 1060901286,
      "name": "Wholphin",
      "full_name": "damontecres/Wholphin",
      "description": "An OSS Android TV client for Jellyfin",
      "html_url": "https://github.com/damontecres/Wholphin",
      "stars": 1029,
      "forks": 31,
      "language": "Kotlin",
      "topics": [
        "android-tv",
        "fire-tv",
        "jellyfin",
        "jellyfin-client"
      ],
      "created_at": "2025-09-20T20:31:30Z",
      "updated_at": "2026-01-23T00:07:09Z",
      "pushed_at": "2026-01-22T04:55:41Z",
      "open_issues": 180,
      "owner": {
        "login": "damontecres",
        "avatar_url": "https://avatars.githubusercontent.com/u/154766448?v=4"
      },
      "readme": "# Wholphin - an OSS Android TV client for Jellyfin\n\n> \"Never half-phin two jellies. Always wholphin one jelly.\"\n\nWholphin is an open-source Android TV client for Jellyfin. It aims to provide a different app UI that's inspired by Plex for users interested in migrating to Jellyfin.\n\nThis is not a fork of the [official client](https://github.com/jellyfin/jellyfin-androidtv). Wholphin's user interface and controls have been written completely from scratch. Wholphin `v0.3.0+` supports playing media using either ExoPlayer/Media3 or MPV (experimental).\n\n<p align=\"center\">\n<a href=\"https://github.com/damontecres/Wholphin/releases\">\n<img alt=\"Current Release\" src=\"https://img.shields.io/github/release/damontecres/wholphin.svg\"/>\n</a>\n<a href=\"https://translate.codeberg.org/engage/wholphin/\">\n<img src=\"https://translate.codeberg.org/widget/wholphin/wholphin/svg-badge.svg\" alt=\"Translation status\" />\n</a>\n<br/>\n<a href=\"https://play.google.com/store/apps/details?id=com.github.damontecres.wholphin\">\n<img width=\"180\" alt=\"Get Wholphin on Google Play\" src=\"https://github.com/user-attachments/assets/2550a4cb-ce46-47a1-ae24-f33a169234b7\"/>\n</a>\n<a href=\"https://www.amazon.com/gp/product/B0G8RQQR9T/ref=mas_pm_wholphin\">\n<img width=\"180\" alt=\"Get Wholphin on Amazon AppStore\" src=\"https://github.com/user-attachments/assets/1f3a3b26-4b4f-44b1-9741-f4c895c8a53b\"/>\n</a>\n\n\n</p>\n\n<img width=\"1280\" height=\"720\" alt=\"0_3_5_home\" src=\"https://github.com/user-attachments/assets/a485c015-ec21-442d-a757-1f18381bf799\" />\n\n## Features\n\n### User interface\n\n- A navigation drawer for quick access to libraries, favorites, search, and settings from almost anywhere in the app\n- Integration with [Seerr](https://github.com/seerr-team/seerr) to discover new movies and TV shows\n- Option to combine Continue Watching & Next Up rows\n- Show Movie/TV Show titles when browsing libraries\n- Play theme music, if available\n- Customize subtitle style for plain text subtitles\n- Search & download subtitles (requires compatible server plugin such as [OpenSubtitles](https://github.com/jellyfin/jellyfin-plugin-opensubtitles))\n- Customize layout grids for libraries\n- Multiple app color themes\n- Protect user profile switches with PIN code\n\n### Playback\n\n- Different media playback engines:\n  - **ExoPlayer** w/ optional extra audio & AV1 software decoding\n  - **MPV** for direct playing anything plus ASS subtitle support\n- Plex inspired playback controls:\n  - Using D-Pad left/right for seeking during playback\n  - Quickly access video chapters & queue during playback\n  - Optionally skip back a few seconds when resuming playback\n- Live TV & DVR support\n- Auto play next episodes with pass out protection\n- Option for automatic refresh rate & resolution switching on supported displays\n- Trickplay support\n- Subtly show playback position along the bottom of the screen while seeking w/ D-Pad\n\n\n### Roadmap\n\nSee [here for the roadmap](https://github.com/damontecres/Wholphin/wiki#roadmap)\n\n## Installation\n\nUsing [Google Play](https://play.google.com/store/apps/details?id=com.github.damontecres.wholphin) or [Amazon appstore](https://www.amazon.com/gp/product/B0G8RQQR9T/ref=mas_pm_wholphin) are the fastest way to install. But you can follow these instructions to install without needing an app store\n\nDownloader Code: `8668671`\n\n1. Enable side-loading \"unknown\" apps\n    - https://androidtvnews.com/unknown-sources-chromecast-google-tv/\n    - https://www.xda-developers.com/how-to-sideload-apps-android-tv/\n    - https://developer.android.com/distribute/marketing-tools/alternative-distribution#unknown-sources\n    - https://www.aftvnews.com/how-to-enable-apps-from-unknown-sources-on-an-amazon-fire-tv-or-fire-tv-stick/\n2. Install the APK on your Android TV device with one of these options:\n    - Install a browser program such as [Downloader](https://www.aftvnews.com/downloader/), use it to get the latest apk with short code `8668671` or URL: http://aftv.news/8668671\n    - Download the latest APK release from the [releases page](https://github.com/damontecres/Wholphin/releases/latest) or http://aftv.news/8668671\n        - Put the APK on an SD Card/USB stick/network share and use a file manager app from the Google Play Store / Amazon AppStore (e.g. `FX File Explorer`). Android's preinstalled file manager probably will not work!\n        - Use `Send files to TV` from the Google Play Store on your phone & TV\n        - (Expert) Use [ADB](https://developer.android.com/studio/command-line/adb) to install the APK from your computer ([guide](https://fossbytes.com/side-load-apps-android-tv/#h-how-to-sideload-apps-on-your-android-tv-using-adb))\n\n### Upgrading the app\n\nAfter the initial install above, the app will automatically check for updates. The updates can be installed in settings.\n\nThe first time you attempt an update, the OS should guide you through enabling the required additional permissions for the app to install updates.\n\nNote: if installed via an app store, the app store will handle updates.\n\n## Compatibility\n\nRequires Android 6+ (or Fire TV OS 6+) and Jellyfin server `10.10.x` or `10.11.x` (tested on primarily `10.11`).\n\nThe app is tested on a variety of Android TV/Fire TV OS devices, but if you encounter issues, please file an issue!\n\n## Contributions\n\nIssues and pull requests are always welcome! Please check before submitting that your issue or pull request is not a duplicate.\n\nIf you plan to contribute, please read the [contributing guide](CONTRIBUTING.md)!\n\nYou can [help translate Wholphin](https://translate.codeberg.org/engage/wholphin/)!\n\n## Acknowledgements\n\n- Thanks to the Jellyfin team for creating and maintaining such a great open-source media server\n- Thanks to the official Jellyfin Android TV client developers, some code for creating the device direct play profile is adapted from there\n- Thanks to the Jellyfin Kotlin SDK developers for making it easier to interact with the Jellyfin server API\n- Thanks to numerous other libraries that make app development even possible\n\n## Additional screenshots\n\n### Movie library browsing\n<img width=\"1280\" height=\"771\" alt=\"0 3 0_movies\" src=\"https://github.com/user-attachments/assets/a49829b5-bc2c-4af9-8d5d-2f7d0973ce01\" />\n\n### Movie page\n<img width=\"1280\" height=\"720\" alt=\"0_3_5_movie\" src=\"https://github.com/user-attachments/assets/86af5889-6761-426a-8649-422f9d0a1dc0\" />\n\n### Series page\n<img width=\"1280\" height=\"720\" alt=\"0_3_5_series\" src=\"https://github.com/user-attachments/assets/2dcb2260-53ce-49d6-9088-72cbd4563c48\" />\n\n### Playlist\n<img width=\"1280\" height=\"771\" alt=\"0 3 0_playlist\" src=\"https://github.com/user-attachments/assets/7ca589ab-9c88-483a-b769-35ffb5663d9e\" />\n",
      "stars_today": 21
    },
    {
      "id": 35780977,
      "name": "ImageMagick",
      "full_name": "ImageMagick/ImageMagick",
      "description": "ImageMagick is a free, open-source software suite for creating, editing, converting, and displaying images. It supports 200+ formats and offers powerful command-line tools and APIs for automation, scripting, and integration across platforms.",
      "html_url": "https://github.com/ImageMagick/ImageMagick",
      "stars": 15521,
      "forks": 1530,
      "language": "C",
      "topics": [
        "command-line-image-tool",
        "digital-image-editing",
        "image-conversion",
        "image-manipulation",
        "image-processing",
        "imagemagick",
        "mastering-digital-image-alchemy",
        "open-source-software"
      ],
      "created_at": "2015-05-17T20:07:50Z",
      "updated_at": "2026-01-23T02:05:41Z",
      "pushed_at": "2026-01-23T00:54:51Z",
      "open_issues": 91,
      "owner": {
        "login": "ImageMagick",
        "avatar_url": "https://avatars.githubusercontent.com/u/12486768?v=4"
      },
      "readme": "# ImageMagick\n\n[![Build Status](https://github.com/ImageMagick/ImageMagick/workflows/main/badge.svg)](https://github.com/ImageMagick/ImageMagick/actions)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/imagemagick.svg)](https://issues.oss-fuzz.com/issues?q=%22project%20ImageMagick%22)\n[![Donate](https://img.shields.io/badge/%24-donate-ff00ff.svg)](https://github.com/sponsors/ImageMagick)\n\n<p align=\"center\">\n<img align=\"center\" src=\"https://imagemagick.org/image/wizard.png\" alt=\"ImageMagick logo\" width=\"265\" height=\"353\"/>\n</p>\n\n[ImageMagick¬Æ](https://imagemagick.org/) is a free and [open-source](https://imagemagick.org/license/) software suite, used for editing and manipulating digital images. It can be used to create, edit, compose, or convert bitmap images, and supports a wide range of file [formats](https://imagemagick.org/script/formats.php), including JPEG, PNG, GIF, TIFF, and PDF.\n\n## What is ImageMagick?\n\nImageMagick is widely used in industries such as web development, graphic design, and video editing, as well as in scientific research, medical imaging, and astronomy. Its versatile and customizable nature, along with its robust image processing capabilities, make it a popular choice for a wide range of image-related tasks.\n\nImageMagick includes a command-line interface for executing complex image processing tasks, as well as APIs for integrating its features into software applications. It is written in C and can be used on a variety of operating systems, including Linux, Windows, and macOS.\n\nThe main website for ImageMagick can be found at [https://imagemagick.org](https://imagemagick.org/). The source code for this software can be accessed through a [repository](https://github.com/ImageMagick/ImageMagick). In addition, we maintain a legacy version of ImageMagick [version 6](https://legacy.imagemagick.org/).\n\nCreating a security policy that fits your specific local environment before making use of ImageMagick is highly advised. You can find guidance on setting up this [policy](https://imagemagick.org/script/security-policy.php). Also, it's important to verify your policy using the [validation tool](https://imagemagick.org/script/security-policy.php).\n\n## Features and Capabilities\n\nOne of the key features of ImageMagick is its support for scripting and automation. This allows users to create complex image manipulation pipelines that can be run automatically, without the need for manual intervention. This can be especially useful for tasks that require the processing of large numbers of images, or for tasks that need to be performed on a regular basis.\n\nIn addition to its core image manipulation capabilities, ImageMagick also includes a number of other features, such as support for animation, color management, and image rendering. These features make it a versatile tool for a wide range of image-related tasks, including graphic design, scientific visualization, and digital art.\n\nOverall, ImageMagick is a powerful and versatile software suite for displaying, converting, and editing image files. Its support for scripting and automation, along with its other features, make it a valuable tool for a wide range of image-related tasks.\n\nHere are just a few [examples](https://imagemagick.org/script/examples.php) of what ImageMagick can do:\n\n* [Animation](https://imagemagick.org/script/command-line-options.php#bilateral-blur): non-linear, edge-preserving, and noise-reducing smoothing filter.\n* [Bilateral Blur](https://imagemagick.org/script/command-line-options.php#bilateral-blur): non-linear, edge-preserving, and noise-reducing smoothing filter.\n* [Color management](https://imagemagick.org/script/color-management.php): accurate color management with color profiles or in lieu of-- built-in gamma compression or expansion as demanded by the colorspace.\n* [Color thresholding](https://imagemagick.org/script/color-management.php) force all pixels in the color range to white otherwise black.\n* [Command-line processing](https://imagemagick.org/script/command-line-processing.php) utilize ImageMagick from the command-line.\n* [Complex text layout](https://en.wikipedia.org/wiki/Complex_text_layout) bidirectional text support and shaping.\n* [Composite](https://imagemagick.org/script/composite.php): overlap one image over another.\n* [Connected component labeling](https://imagemagick.org/script/connected-components.php): uniquely label connected regions in an image.\n* [Convex hull](https://imagemagick.org/script/convex-hull.php) smallest area convex polygon containing the image foreground objects. In addition, the minimum bounding box and unrotate angle are also generated.\n* [Decorate](https://imagemagick.org/Usage/crop/): add a border or frame to an image.\n* [Delineate image features](https://imagemagick.org/Usage/transform/#vision): Canny edge detection, mean-shift, Hough lines.\n* [Discrete Fourier transform](https://imagemagick.org/Usage/fourier/): implements the forward and inverse [DFT](http://en.wikipedia.org/wiki/Discrete_Fourier_transform).\n* [Distributed pixel cache](https://imagemagick.org/script/distribute-pixel-cache.php): offload intermediate pixel storage to one or more remote servers.\n* [Draw](https://imagemagick.org/Usage/draw/): add shapes or text to an image.\n* [Encipher or decipher an image](https://imagemagick.org/script/cipher.php): convert ordinary images into unintelligible gibberish and back again.\n* [Format conversion](https://imagemagick.org/script/convert.php): convert an image from one [format](https://imagemagick.org/script/formats.php) to another (e.g.  PNG to JPEG).\n* [Generalized pixel distortion](https://imagemagick.org/Usage/distorts/): correct for, or induce image distortions including perspective.\n* [Heterogeneous distributed processing](https://imagemagick.org/script/architecture.php#distributed): certain algorithms are OpenCL-enabled to take advantage of speed-ups offered by executing in concert across heterogeneous platforms consisting of CPUs, GPUs, and other processors.\n* [High dynamic-range images](https://imagemagick.org/script/high-dynamic-range.php): accurately represent the wide range of intensity levels found in real scenes ranging from the brightest direct sunlight to the deepest darkest shadows.\n* [Histogram equalization](https://imagemagick.org/script/clahe.php) use adaptive histogram equalization to improve contrast in images.\n* [Image cache](https://imagemagick.org/script/magick-cache.php): secure methods and tools to cache images, image sequences, video, audio or metadata in a local folder.\n* [Image calculator](https://imagemagick.org/script/fx.php): apply a mathematical expression to an image or image channels.\n* [Image gradients](https://imagemagick.org/script/gradient.php): create a gradual blend of one color whose shape is horizontal, vertical, circular, or elliptical.\n* [Image identification](https://imagemagick.org/script/identify.php): describe the format and attributes of an image.\n* [ImageMagick on the iPhone](https://imagemagick.org/script/download.php#iOS): convert, edit, or compose images on your iPhone.\n* [Large image support](https://imagemagick.org/script/architecture.php#tera-pixel): read, process, or write mega-, giga-, or tera-pixel image sizes.\n* [Montage](https://imagemagick.org/script/montage.php): juxtapose image thumbnails on an image canvas.\n* [Morphology of shapes](https://imagemagick.org/Usage/morphology/): extract features, describe shapes and recognize patterns in images.\n* [Motion picture support](https://imagemagick.org/script/motion-picture.php): read and write the common image formats used in digital film work.\n* [Multispectral imagery](https://imagemagick.org/script/multispectral-imagery.php): support multispectral imagery up to 64 bands.\n* [Noise and color reduction](https://imagemagick.org/Usage/transform/#vision) Kuwahara Filter, mean-shift.\n* [Perceptual hash](http://www.fmwconcepts.com/misc_tests/perceptual_hash_test_results_510/index.html): maps visually identical images to the same or similar hash-- useful in image retrieval, authentication, indexing, or copy detection as well as digital watermarking.\n* [Special effects](https://imagemagick.org/Usage/blur/): blur, sharpen, threshold, or tint an image.\n* [Text & comments](https://imagemagick.org/Usage/text/): insert descriptive or artistic text in an image.\n* [Threads of execution support](https://imagemagick.org/script/architecture.php#threads): ImageMagick is thread safe and most internal algorithms are OpenMP-enabled to take advantage of speed-ups offered by multicore processor chips.\n* [Transform](https://imagemagick.org/Usage/resize/): resize, rotate, deskew, crop, flip or trim an image.\n* [Transparency](https://imagemagick.org/Usage/masking/): render portions of an image invisible.\n* [Virtual pixel support](https://imagemagick.org/script/architecture.php#virtual-pixels): convenient access to pixels outside the image region.\n\n[Examples of ImageMagick Usage](https://imagemagick.org/Usage/), demonstrates how to use the software from the [command line](https://imagemagick.org/script/command-line-processing.php) to achieve various effects. There are also several scripts available on the website called [Fred's ImageMagick Scripts](http://www.fmwconcepts.com/imagemagick/), which can be used to apply geometric transforms, blur and sharpen images, remove noise, and perform other operations. Additionally, there is a tool called [Magick.NET](https://github.com/dlemstra/Magick.NET) that allows users to access the functionality of ImageMagick without having to install the software on their own systems. Finally, the website also includes a [Cookbook](http://im.snibgo.com/) with tips and examples for using ImageMagick on Windows systems.\n\n## News\n\nCreating a security policy that fits your specific local environment before making use of ImageMagick is highly advised. You can find guidance on setting up this [policy](https://imagemagick.org/script/security-policy.php). Also, it's important to verify your policy using the [validation tool](https://imagemagick-secevaluator.doyensec.com/). As of ImageMagick version 7.1.1-16, you can choose and customize one of these [security policies](https://imagemagick.org/script/security-policy.php): Open, Limited, Secure, and Websafe.\n\nBy default, ImageMagick supports up to 32 channels. As of ImageMagick version 7.1.1-16, you can enable up to 64 channels by adding the **--enable-64bit-channel-masks** option to the Linux configure build script. For Windows this will be enabled automatically.\n\n\nWant more performance from ImageMagick? Try these options:\n\n* add more memory to your system, see the [pixel cache](https://imagemagick.org/script/architecture.php#cache);\n* add more cores to your system, see [threads of execution support](https://imagemagick.org/script/architecture.php#threads);\n* reduce lock contention with the [tcmalloc](http://goog-perftools.sourceforge.net/doc/tcmalloc.html) memory allocation library;\n* push large images to a solid-state drive, see [large image support](https://imagemagick.org/script/architecture.php#tera-pixel).\n\nIf these options are prohibitive, you can reduce the quality of the image results. The default build is Q16 HDRI. If you disable [HDRI](https://imagemagick.org/script/high-dynamic-range.php), you use half the memory and instead of predominantly floating point operations, you use the typically more efficient integer operations. The tradeoff is reduced precision and you cannot process out of range pixel values (e.g. negative). If you build the Q8 non-HDRI version of ImageMagick, you again reduce the memory requirements in half-- and once again there is a tradeoff, even less precision and no out of range pixel values. For a Q8 non-HDRI build of ImageMagick, use these configure script options: **--with-quantum-depth=8 --disable-hdri**.\n",
      "stars_today": 20
    },
    {
      "id": 268424739,
      "name": "helix",
      "full_name": "helix-editor/helix",
      "description": "A post-modern modal text editor.",
      "html_url": "https://github.com/helix-editor/helix",
      "stars": 42537,
      "forks": 3276,
      "language": "Rust",
      "topics": [
        "kakoune",
        "rust",
        "text-editor",
        "vim"
      ],
      "created_at": "2020-06-01T04:26:56Z",
      "updated_at": "2026-01-23T01:49:40Z",
      "pushed_at": "2026-01-21T06:52:46Z",
      "open_issues": 1412,
      "owner": {
        "login": "helix-editor",
        "avatar_url": "https://avatars.githubusercontent.com/u/66235900?v=4"
      },
      "readme": "<div align=\"center\">\n\n<h1>\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"logo_dark.svg\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"logo_light.svg\">\n  <img alt=\"Helix\" height=\"128\" src=\"logo_light.svg\">\n</picture>\n</h1>\n\n[![Build status](https://github.com/helix-editor/helix/actions/workflows/build.yml/badge.svg)](https://github.com/helix-editor/helix/actions)\n[![GitHub Release](https://img.shields.io/github/v/release/helix-editor/helix)](https://github.com/helix-editor/helix/releases/latest)\n[![Documentation](https://shields.io/badge/-documentation-452859)](https://docs.helix-editor.com/)\n[![GitHub contributors](https://img.shields.io/github/contributors/helix-editor/helix)](https://github.com/helix-editor/helix/graphs/contributors)\n[![Matrix Space](https://img.shields.io/matrix/helix-community:matrix.org)](https://matrix.to/#/#helix-community:matrix.org)\n\n</div>\n\n![Screenshot](./screenshot.png)\n\nA [Kakoune](https://github.com/mawww/kakoune) / [Neovim](https://github.com/neovim/neovim) inspired editor, written in Rust.\n\nThe editing model is very heavily based on Kakoune; during development I found\nmyself agreeing with most of Kakoune's design decisions.\n\nFor more information, see the [website](https://helix-editor.com) or\n[documentation](https://docs.helix-editor.com/).\n\nAll shortcuts/keymaps can be found [in the documentation on the website](https://docs.helix-editor.com/keymap.html).\n\n[Troubleshooting](https://github.com/helix-editor/helix/wiki/Troubleshooting)\n\n# Features\n\n- Vim-like modal editing\n- Multiple selections\n- Built-in language server support\n- Smart, incremental syntax highlighting and code editing via tree-sitter\n\nAlthough it's primarily a terminal-based editor, I am interested in exploring\na custom renderer (similar to Emacs) using wgpu.\n\nNote: Only certain languages have indentation definitions at the moment. Check\n`runtime/queries/<lang>/` for `indents.scm`.\n\n# Installation\n\n[Installation documentation](https://docs.helix-editor.com/install.html).\n\n[![Packaging status](https://repology.org/badge/vertical-allrepos/helix-editor.svg?exclude_unsupported=1)](https://repology.org/project/helix-editor/versions)\n\n# Contributing\n\nContributing guidelines can be found [here](./docs/CONTRIBUTING.md).\n\n# Getting help\n\nYour question might already be answered on the [FAQ](https://github.com/helix-editor/helix/wiki/FAQ).\n\nDiscuss the project on the community [Matrix Space](https://matrix.to/#/#helix-community:matrix.org) (make sure to join `#helix-editor:matrix.org` if you're on a client that doesn't support Matrix Spaces yet).\n\n# Credits\n\nThanks to [@jakenvac](https://github.com/jakenvac) for designing the logo!\n",
      "stars_today": 19
    },
    {
      "id": 1036441713,
      "name": "agent-sandbox",
      "full_name": "kubernetes-sigs/agent-sandbox",
      "description": "agent-sandbox enables easy management of isolated, stateful, singleton workloads, ideal for use cases like AI agent runtimes.",
      "html_url": "https://github.com/kubernetes-sigs/agent-sandbox",
      "stars": 769,
      "forks": 94,
      "language": "Go",
      "topics": [],
      "created_at": "2025-08-12T04:55:05Z",
      "updated_at": "2026-01-23T00:45:35Z",
      "pushed_at": "2026-01-20T17:51:26Z",
      "open_issues": 73,
      "owner": {
        "login": "kubernetes-sigs",
        "avatar_url": "https://avatars.githubusercontent.com/u/36015203?v=4"
      },
      "readme": "# Agent Sandbox\n\n**agent-sandbox enables easy management of isolated, stateful, singleton workloads, ideal for use cases like AI agent runtimes.**\n\nThis project is developing a `Sandbox` Custom Resource Definition (CRD) and controller for Kubernetes, under the umbrella of [SIG Apps](https://github.com/kubernetes/community/tree/master/sig-apps). The goal is to provide a declarative, standardized API for managing workloads that require the characteristics of a long-running, stateful, singleton container with a stable identity, much like a lightweight, single-container VM experience built on Kubernetes primitives.\n\n## Overview\n\n### Core: Sandbox\n\nThe `Sandbox` CRD is the core of agent-sandbox. It provides a declarative API for managing a single, stateful pod with a stable identity and persistent storage. This is useful for workloads that don't fit well into the stateless, replicated model of Deployments or the numbered, stable model of StatefulSets.\n\nKey features of the `Sandbox` CRD include:\n\n*   **Stable Identity:** Each Sandbox has a stable hostname and network identity.\n*   **Persistent Storage:** Sandboxes can be configured with persistent storage that survives restarts.\n*   **Lifecycle Management:** The Sandbox controller manages the lifecycle of the pod, including creation, scheduled deletion, pausing and resuming.\n\n### Extensions\n\nThe `extensions` module provides additional CRDs and controllers that build on the core `Sandbox` API to provide more advanced features.\n\n*   `SandboxTemplate`: Provides a way to define reusable templates for creating Sandboxes, making it easier to manage large numbers of similar Sandboxes.\n*   `SandboxClaim`: Allows users to create Sandboxes from a template, abstracting away the details of the underlying Sandbox configuration.\n*   `SandboxWarmPool`: Manages a pool of pre-warmed Sandbox Pods that can be quickly allocated to users, reducing the time it takes to get a new Sandbox up and running.\n\n## Installation\n\n### Core Components & Extensions\n\nYou can install the agent-sandbox controller and its CRDs with the following command.\n\n```sh\n# Replace \"vX.Y.Z\" with a specific version tag (e.g., \"v0.1.0\") from\n# https://github.com/kubernetes-sigs/agent-sandbox/releases\nexport VERSION=\"vX.Y.Z\"\n\n# To install only the core components:\nkubectl apply -f https://github.com/kubernetes-sigs/agent-sandbox/releases/download/${VERSION}/manifest.yaml\n\n# To install the extensions components:\nkubectl apply -f https://github.com/kubernetes-sigs/agent-sandbox/releases/download/${VERSION}/extensions.yaml\n```\n\n### Python SDK\n\nTo interact with the agent-sandbox programmatically, you can use the Python SDK. This client library provides a high-level interface for creating and managing sandboxes.\n\nFor detailed installation and usage instructions, please refer to the [Python SDK README](clients/python/agentic-sandbox-client/README.md).\n\n## Getting Started\n\nOnce you have installed the controller, you can create a simple Sandbox by applying the following YAML to your cluster:\n\n```yaml\napiVersion: agents.x-k8s.io/v1alpha1\nkind: Sandbox\nmetadata:\n  name: my-sandbox\nspec:\n  podTemplate:\n    spec:\n      containers:\n      - name: my-container\n        image: <IMAGE>\n```\n\nThis will create a new Sandbox named `my-sandbox` running the image you specify. You can then access the Sandbox using its stable hostname, `my-sandbox`.\n\nFor more complex examples, including how to use the extensions, please see the [examples/](examples/) and [extensions/examples/](extensions/examples/) directories.\n\n## Motivation\n\nKubernetes excels at managing stateless, replicated applications (Deployments) and stable, numbered sets of stateful pods (StatefulSets). However, there's a growing need for an abstraction to handle use cases such as:\n\n*   **Development Environments:** Isolated, persistent, network-accessible cloud environments for developers.\n*   **AI Agent Runtimes:** Isolated environments for executing untrusted, LLM-generated code.\n*   **Notebooks and Research Tools:** Persistent, single-container sessions for tools like Jupyter Notebooks.\n*   **Stateful Single-Pod Services:** Hosting single-instance applications (e.g., build agents, small databases) needing a stable identity without StatefulSet overhead.\n\nWhile these can be approximated by combining StatefulSets (size 1), Services, and PersistentVolumeClaims, this approach is cumbersome and lacks specialized lifecycle management like hibernation.\n\n## Desired Sandbox Characteristics\n\nWe aim for the Sandbox to be vendor-neutral, supporting various runtimes. Key characteristics include:\n\n*   **Strong Isolation:** Supporting different runtimes like gVisor or Kata Containers to provide enhanced security and isolation between the sandbox and the host, including both kernel and network isolation. This is crucial for running untrusted code or multi-tenant scenarios.\n*   **Deep hibernation:** Saving state to persistent storage and potentially archiving the Sandbox object.\n*   **Automatic resume:** Resuming a sandbox on network connection.\n*   **Efficient persistence:** Elastic and rapidly provisioned storage.\n*   **Memory sharing across sandboxes:** Exploring possibilities to share memory across Sandboxes on the same host, even if they are primarily non-homogenous. This capability is a feature of the specific runtime, and users should select a runtime that aligns with their security and performance requirements.\n*   **Rich identity & connectivity:** Exploring dual user/sandbox identities and efficient traffic routing without per-sandbox Services.\n*   **Programmable:** Encouraging applications and agents to programmatically consume the Sandbox API.\n\n## Community, Discussion, Contribution, and Support\n\nThis is a community-driven effort, and we welcome collaboration!\n\nLearn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).\n\nYou can reach the maintainers of this project at:\n\n- [Slack](https://kubernetes.slack.com/messages/sig-apps)\n- [Mailing List](https://groups.google.com/a/kubernetes.io/g/sig-apps)\n\nPlease feel free to open issues, suggest features, and contribute code!\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).\n\n[owners]: https://git.k8s.io/community/contributors/guide/owners.md\n[Creative Commons 4.0]: https://git.k8s.io/website/LICENSE\n",
      "stars_today": 19
    },
    {
      "id": 180687624,
      "name": "trivy",
      "full_name": "aquasecurity/trivy",
      "description": "Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more",
      "html_url": "https://github.com/aquasecurity/trivy",
      "stars": 31081,
      "forks": 2885,
      "language": "Go",
      "topics": [
        "containers",
        "devsecops",
        "docker",
        "go",
        "golang",
        "hacktoberfest",
        "iac",
        "infrastructure-as-code",
        "kubernetes",
        "misconfiguration",
        "security",
        "security-tools",
        "vulnerability",
        "vulnerability-detection",
        "vulnerability-scanners"
      ],
      "created_at": "2019-04-11T01:01:07Z",
      "updated_at": "2026-01-23T02:01:19Z",
      "pushed_at": "2026-01-22T20:30:39Z",
      "open_issues": 213,
      "owner": {
        "login": "aquasecurity",
        "avatar_url": "https://avatars.githubusercontent.com/u/12783832?v=4"
      },
      "readme": "<div align=\"center\">\n<img src=\"docs/imgs/logo.png\" width=\"200\">\n\n[![GitHub Release][release-img]][release]\n[![Test][test-img]][test]\n[![Go Report Card][go-report-img]][go-report]\n[![License: Apache-2.0][license-img]][license]\n[![GitHub Downloads][github-downloads-img]][release]\n![Docker Pulls][docker-pulls]\n\n[üìñ Documentation][docs]\n</div>\n\nTrivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.\nTrivy has *scanners* that look for security issues, and *targets* where it can find those issues.\n\nTargets (what Trivy can scan):\n\n- Container Image\n- Filesystem\n- Git Repository (remote)\n- Virtual Machine Image\n- Kubernetes\n\nScanners (what Trivy can find there):\n\n- OS packages and software dependencies in use (SBOM)\n- Known vulnerabilities (CVEs)\n- IaC issues and misconfigurations\n- Sensitive information and secrets\n- Software licenses\n\nTrivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.\n\nTo learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.\n\n## Quick Start\n\n### Get Trivy\n\nTrivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:\n\n- `brew install trivy`\n- `docker run aquasec/trivy`\n- Download binary from <https://github.com/aquasecurity/trivy/releases/latest/>\n- See [Installation] for more\n\nTrivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:\n\n- [GitHub Actions](https://github.com/aquasecurity/trivy-action)\n- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)\n- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)\n- See [Ecosystem] for more\n\n### Canary builds\nThere are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) generated with every push to the main branch.\n\nPlease be aware: canary builds might have critical bugs, so they are not recommended for use in production.\n\n### General usage\n\n```bash\ntrivy <target> [--scanners <scanner1,scanner2>] <subject>\n```\n\nExamples:\n\n```bash\ntrivy image python:3.4-alpine\n```\n\n<details>\n<summary>Result</summary>\n\nhttps://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov\n\n</details>\n\n```bash\ntrivy fs --scanners vuln,secret,misconfig myproject/\n```\n\n<details>\n<summary>Result</summary>\n\nhttps://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov\n\n</details>\n\n```bash\ntrivy k8s --report summary cluster\n```\n\n<details>\n<summary>Result</summary>\n\n![k8s summary](docs/imgs/trivy-k8s.png)\n\n</details>\n\n## FAQ\n\n### How to pronounce the name \"Trivy\"?\n\n`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.\n\n## Want more? Check out Aqua\n\nIf you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  \nYou can find a high level comparison table specific to Trivy users [here](https://trivy.dev/docs/latest/commercial/compare/).\nIn addition check out the <https://aquasec.com> website for more information about our products and services.\nIf you'd like to contact Aqua or request a demo, please use this form: <https://www.aquasec.com/demo>\n\n## Community\n\nTrivy is an [Aqua Security][aquasec] open source project.  \nLearn about our open source work and portfolio [here][oss].  \nContact us about any matter by opening a GitHub Discussion [here][discussions]\n\nPlease ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.\n\n[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml\n[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg\n[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy\n[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy\n[release]: https://github.com/aquasecurity/trivy/releases\n[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github\n[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github\n[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&label=docker%20pulls%20%2F%20trivy\n[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE\n[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg\n[homepage]: https://trivy.dev\n[docs]: https://trivy.dev/docs/latest/\n[pronunciation]: #how-to-pronounce-the-name-trivy\n[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md\n\n[Installation]:https://trivy.dev/docs/latest/getting-started/installation/\n[Ecosystem]: https://trivy.dev/docs/latest/ecosystem/\n[Scanning Coverage]: https://trivy.dev/docs/latest/coverage/\n\n[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/\n[rego]: https://www.openpolicyagent.org/docs/latest/#rego\n[sigstore]: https://www.sigstore.dev/\n\n[aquasec]: https://aquasec.com\n[oss]: https://www.aquasec.com/products/open-source-projects/\n[discussions]: https://github.com/aquasecurity/trivy/discussions\n",
      "stars_today": 18
    },
    {
      "id": 46398090,
      "name": "datahub",
      "full_name": "datahub-project/datahub",
      "description": "The Metadata Platform for your Data and AI Stack",
      "html_url": "https://github.com/datahub-project/datahub",
      "stars": 11477,
      "forks": 3345,
      "language": "Java",
      "topics": [
        "data-catalog",
        "data-discovery",
        "data-governance",
        "datahub",
        "hacktoberfest",
        "metadata"
      ],
      "created_at": "2015-11-18T05:47:40Z",
      "updated_at": "2026-01-23T00:11:41Z",
      "pushed_at": "2026-01-23T01:58:46Z",
      "open_issues": 714,
      "owner": {
        "login": "datahub-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/78121374?v=4"
      },
      "readme": "<!--HOSTED_DOCS_ONLY\nimport useBaseUrl from '@docusaurus/useBaseUrl';\n\nexport const Logo = (props) => {\n  return (\n    <div style={{ display: \"flex\", justifyContent: \"center\", padding: \"20px\", height: \"190px\" }}>\n      <img\n        alt=\"DataHub Logo\"\n        src=\"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/datahub-logo-color-mark.svg\"\n        {...props}\n      />\n    </div>\n  );\n};\n\n<Logo />\n\n<!--\nHOSTED_DOCS_ONLY-->\n<p align=\"center\">\n<a href=\"https://datahub.com\">\n<img alt=\"DataHub\" src=\"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/datahub-logo-color-mark.svg\" height=\"150\" />\n</a>\n</p>\n<!-- -->\n\n# DataHub: The Data Discovery Platform for the Modern Data Stack\n\n### Built with ‚ù§Ô∏è by <img src=\"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/datahub-logo-color-mark.svg\" width=\"20\"/> [DataHub](https://datahub.com) and <img src=\"https://docs.datahub.com/img/LI-In-Bug.png\" width=\"20\"/> [LinkedIn](https://engineering.linkedin.com)\n\n<div>\n  <a target=\"_blank\" href=\"https://github.com/datahub-project/datahub/blob/master/LICENSE\">\n    <img alt=\"Apache 2.0 License\" src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg?label=license&labelColor=133554&color=1890ff\" /></a>\n  <a target=\"_blank\" href=\"https://pypi.org/project/acryl-datahub/\">\n    <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/dm/acryl-datahub?label=downloads&labelColor=133554&color=1890ff\" /></a>\n  <a target=\"_blank\" href=\"https://github.com/datahub-project/datahub/pulse\">\n    <img alt=\"GitHub commit activity\" src=\"https://img.shields.io/github/commit-activity/m/datahub-project/datahub?label=commits&labelColor=133554&color=1890ff\" /></a>\n  <br />\n  <a target=\"_blank\" href=\"https://datahub.com/slack?utm_source=github&utm_medium=readme&utm_campaign=github_readme\">\n    <img alt=\"Slack\" src=\"https://img.shields.io/badge/slack-join_community-red.svg?logo=slack&labelColor=133554&color=1890ff\" /></a>\n  <a href=\"https://www.youtube.com/channel/UC3qFQC5IiwR5fvWEqi_tJ5w\">\n    <img alt=\"YouTube\" src=\"https://img.shields.io/youtube/channel/subscribers/UC3qFQC5IiwR5fvWEqi_tJ5w?style=flat&logo=youtube&label=subscribers&labelColor=133554&color=1890ff\"/></a>\n  <a href=\"https://medium.com/datahub-project/\">\n    <img alt=\"Medium\" src=\"https://img.shields.io/badge/blog-DataHub-red.svg?style=flat&logo=medium&logoColor=white&labelColor=133554&color=1890ff\" /></a>\n  <a href=\"https://x.com/datahubproject\">\n    <img alt=\"X (formerly Twitter) Follow\" src=\"https://img.shields.io/badge/follow-datahubproject-red.svg?style=flat&logo=x&labelColor=133554&color=1890ff\" /></a>\n</div>\n\n---\n\n### üè† Docs: [docs.datahub.com](https://docs.datahub.com/)\n\n[Quickstart](https://docs.datahub.com/docs/quickstart) |\n[Features](https://docs.datahub.com/docs/features) |\n[Roadmap](https://feature-requests.datahubproject.io/roadmap) |\n[Adoption](#adoption) |\n[Demo](https://demo.datahub.com/) |\n[Town Hall](https://docs.datahub.com/docs/townhalls)\n\n---\n\n> üì£‚ÄÇDataHub Town Hall is the 4th Thursday at 9am US PT of every month - [add it to your calendar!](https://lu.ma/datahubevents/)\n>\n> - Town-hall Zoom link: [zoom.datahubproject.io](https://zoom.datahubproject.io)\n> - [Meeting details](docs/townhalls.md) & [past recordings](docs/townhall-history.md)\n\n> ‚ú®‚ÄÇDataHub Community Highlights:\n>\n> - Read our Monthly Project Updates [here](https://medium.com/datahub-project/tagged/project-updates).\n> - Bringing The Power Of The DataHub Real-Time Metadata Graph To Everyone At DataHub: [Data Engineering Podcast](https://www.dataengineeringpodcast.com/acryl-data-datahub-metadata-graph-episode-230/)\n> - Check out our most-read blog post, [DataHub: Popular Metadata Architectures Explained](https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained) @ LinkedIn Engineering Blog.\n> - Join us on [Slack](docs/slack.md)! Ask questions and keep up with the latest announcements.\n\n## Introduction\n\nDataHub is an open-source data catalog for the modern data stack. Read about the architectures of different metadata systems and why DataHub excels [here](https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained). Also read our\n[LinkedIn Engineering blog post](https://engineering.linkedin.com/blog/2019/data-hub), check out our [Strata presentation](https://speakerdeck.com/shirshanka/the-evolution-of-metadata-linkedins-journey-strata-nyc-2019) and watch our [Crunch Conference Talk](https://www.youtube.com/watch?v=OB-O0Y6OYDE). You should also visit [DataHub Architecture](docs/architecture/architecture.md) to get a better understanding of how DataHub is implemented.\n\n## Features & Roadmap\n\nCheck out DataHub's [Features](docs/features.md) & [Roadmap](https://feature-requests.datahubproject.io/roadmap).\n\n## Demo and Screenshots\n\nThere's a [hosted demo environment](https://demo.datahub.com/) courtesy of DataHub where you can explore DataHub without installing it locally.\n\n## Quickstart\n\nPlease follow the [DataHub Quickstart Guide](https://docs.datahub.com/docs/quickstart) to run DataHub locally using [Docker](https://docker.com).\n\n## Development\n\nIf you're looking to build & modify datahub please take a look at our [Development Guide](https://docs.datahub.com/docs/developers).\n\n<p align=\"center\">\n<a href=\"https://demo.datahub.com/\">\n  <img width=\"70%\"  src=\"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/entity.png\"/>\n</a>\n</p>\n\n## Source Code and Repositories\n\n- [datahub-project/datahub](https://github.com/datahub-project/datahub): This repository contains the complete source code for DataHub's metadata model, metadata services, integration connectors and the web application.\n- [acryldata/datahub-actions](https://github.com/acryldata/datahub-actions): DataHub Actions is a framework for responding to changes to your DataHub Metadata Graph in real time.\n- [acryldata/datahub-helm](https://github.com/acryldata/datahub-helm): Helm charts for deploying DataHub on a Kubernetes cluster\n- [acryldata/meta-world](https://github.com/acryldata/meta-world): A repository to store recipes, custom sources, transformations and other things to make your DataHub experience magical.\n- [dbt-impact-action](https://github.com/acryldata/dbt-impact-action): A github action for commenting on your PRs with a summary of the impact of changes within a dbt project.\n- [datahub-tools](https://github.com/makenotion/datahub-tools): Additional python tools to interact with the DataHub GraphQL endpoints, built by Notion.\n- [business-glossary-sync-action](https://github.com/acryldata/business-glossary-sync-action): A github action that opens PRs to update your business glossary yaml file.\n- [mcp-server-datahub](https://github.com/acryldata/mcp-server-datahub): A [Model Context Protocol](https://modelcontextprotocol.io/) server implementation for DataHub.\n\n## Releases\n\nSee [Releases](https://github.com/datahub-project/datahub/releases) page for more details. We follow the [SemVer Specification](https://semver.org) when versioning the releases and adopt the [Keep a Changelog convention](https://keepachangelog.com/) for the changelog format.\n\n## Contributing\n\nWe welcome contributions from the community. Please refer to our [Contributing Guidelines](docs/CONTRIBUTING.md) for more details. We also have a [contrib](contrib) directory for incubating experimental features.\n\n## Community\n\nJoin our [Slack workspace](https://datahub.com/slack?utm_source=github&utm_medium=readme&utm_campaign=github_readme) for discussions and important announcements. You can also find out more about our upcoming [town hall meetings](docs/townhalls.md) and view past recordings.\n\n## Security\n\nSee [Security Stance](docs/SECURITY_STANCE.md) for information on DataHub's Security.\n\n## Adoption\n\nHere are the companies that have officially adopted DataHub. Please feel free to add yours to the list if we missed it.\n\n- [ABLY](https://ably.team/)\n- [Adevinta](https://www.adevinta.com/)\n- [Banksalad](https://www.banksalad.com)\n- [Cabify](https://cabify.tech/)\n- [ClassDojo](https://www.classdojo.com/)\n- [Coursera](https://www.coursera.org/)\n- [CVS Health](https://www.cvshealth.com/)\n- [DefinedCrowd](http://www.definedcrowd.com)\n- [DFDS](https://www.dfds.com/)\n- [Digital Turbine](https://www.digitalturbine.com/)\n- [Expedia Group](http://expedia.com)\n- [Experius](https://www.experius.nl)\n- [Geotab](https://www.geotab.com)\n- [Grofers](https://grofers.com)\n- [Haibo Technology](https://www.botech.com.cn)\n- [hipages](https://hipages.com.au/)\n- [inovex](https://www.inovex.de/)\n- [Inter&Co](https://inter.co/)\n- [IOMED](https://iomed.health)\n- [Klarna](https://www.klarna.com)\n- [LinkedIn](http://linkedin.com)\n- [Moloco](https://www.moloco.com/en)\n- [N26](https://n26brasil.com/)\n- [Optum](https://www.optum.com/)\n- [Peloton](https://www.onepeloton.com)\n- [PITS Global Data Recovery Services](https://www.pitsdatarecovery.net/)\n- [Razer](https://www.razer.com)\n- [Rippling](https://www.rippling.com/)\n- [Showroomprive](https://www.showroomprive.com/)\n- [SpotHero](https://spothero.com)\n- [Stash](https://www.stash.com)\n- [Shanghai HuaRui Bank](https://www.shrbank.com)\n- [s7 Airlines](https://www.s7.ru/)\n- [ThoughtWorks](https://www.thoughtworks.com)\n- [TypeForm](http://typeform.com)\n- [Udemy](https://www.udemy.com/)\n- [Uphold](https://uphold.com)\n- [Viasat](https://viasat.com)\n- [Wealthsimple](https://www.wealthsimple.com)\n- [Wikimedia](https://www.wikimedia.org)\n- [Wolt](https://wolt.com)\n- [Zynga](https://www.zynga.com)\n\n## Select Articles & Talks\n\n- [DataHub Blog](https://medium.com/datahub-project/)\n- [DataHub YouTube Channel](https://www.youtube.com/channel/UC3qFQC5IiwR5fvWEqi_tJ5w)\n- [Optum: Data Mesh via DataHub](https://opensource.optum.com/blog/2022/03/23/data-mesh-via-datahub)\n- [Saxo Bank: Enabling Data Discovery in Data Mesh](https://medium.com/datahub-project/enabling-data-discovery-in-a-data-mesh-the-saxo-journey-451b06969c8f)\n- [Bringing The Power Of The DataHub Real-Time Metadata Graph To Everyone At DataHub](https://www.dataengineeringpodcast.com/acryl-data-datahub-metadata-graph-episode-230/)\n- [DataHub: Popular Metadata Architectures Explained](https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained)\n- [Driving DataOps Culture with LinkedIn DataHub](https://www.youtube.com/watch?v=ccsIKK9nVxk) @ [DataOps Unleashed 2021](https://dataopsunleashed.com/#shirshanka-session)\n- [The evolution of metadata: LinkedIn‚Äôs story](https://speakerdeck.com/shirshanka/the-evolution-of-metadata-linkedins-journey-strata-nyc-2019) @ [Strata Data Conference 2019](https://conferences.oreilly.com/strata/strata-ny-2019.html)\n- [Journey of metadata at LinkedIn](https://www.youtube.com/watch?v=OB-O0Y6OYDE) @ [Crunch Data Conference 2019](https://crunchconf.com/2019)\n- [DataHub Journey with Expedia Group](https://www.youtube.com/watch?v=ajcRdB22s5o)\n- [Data Discoverability at SpotHero](https://www.slideshare.net/MaggieHays/data-discoverability-at-spothero)\n- [Data Catalogue ‚Äî Knowing your data](https://medium.com/albert-franzi/data-catalogue-knowing-your-data-15f7d0724900)\n- [DataHub: A Generalized Metadata Search & Discovery Tool](https://engineering.linkedin.com/blog/2019/data-hub)\n- [Open sourcing DataHub: LinkedIn‚Äôs metadata search and discovery platform](https://engineering.linkedin.com/blog/2020/open-sourcing-datahub--linkedins-metadata-search-and-discovery-p)\n- [Emerging Architectures for Modern Data Infrastructure](https://future.com/emerging-architectures-for-modern-data-infrastructure-2020/)\n\nSee the full list [here](docs/links.md).\n\n## License\n\n[Apache License 2.0](./LICENSE).\n",
      "stars_today": 18
    },
    {
      "id": 83799439,
      "name": "lawnchair",
      "full_name": "LawnchairLauncher/lawnchair",
      "description": "No clever tagline needed.",
      "html_url": "https://github.com/LawnchairLauncher/lawnchair",
      "stars": 11949,
      "forks": 1413,
      "language": "Java",
      "topics": [
        "android",
        "app",
        "hacktoberfest",
        "java",
        "kotlin",
        "launcher",
        "launcher3"
      ],
      "created_at": "2017-03-03T13:12:58Z",
      "updated_at": "2026-01-23T01:43:36Z",
      "pushed_at": "2026-01-23T02:04:03Z",
      "open_issues": 619,
      "owner": {
        "login": "LawnchairLauncher",
        "avatar_url": "https://avatars.githubusercontent.com/u/34144436?v=4"
      },
      "readme": "# Lawnchair 15\n\n[![Build debug APK](https://github.com/LawnchairLauncher/lawnchair/actions/workflows/ci.yml/badge.svg)](https://github.com/LawnchairLauncher/lawnchair/actions/workflows/ci.yml)\n[![Build release APK](https://github.com/LawnchairLauncher/lawnchair/actions/workflows/release_update.yml/badge.svg)](https://github.com/LawnchairLauncher/lawnchair/actions/workflows/release_update.yml)\n[![Crowdin](https://badges.crowdin.net/e/188ba69d884418987f0b7f1dd55e3a4e/localized.svg)](https://lawnchair.crowdin.com/lawnchair)\n[![OpenCollective](https://img.shields.io/opencollective/all/lawnchair?label=financial%20contributors&logo=open-collective)](https://opencollective.com/lawnchair)\n[![Telegram](https://img.shields.io/endpoint?url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Flccommunity)](https://t.me/lccommunity)\n[![Discord](https://img.shields.io/discord/803299970169700402?label=server&logo=discord)](https://discord.gg/3x8qNWxgGZ)\n[![GitHub Downloads](https://img.shields.io/github/downloads/LawnchairLauncher/lawnchair/total.svg?label=GitHub%20Downloads&logo=github)](https://github.com/LawnchairLauncher/lawnchair/releases)\n[![Play Store Installs](https://img.shields.io/endpoint?color=green&logo=googleplay&logoColor=green&url=https%3A%2F%2Fplay.cuzi.workers.dev%2Fplay%3Fi%3Dapp.lawnchair.play%26l%3DPlay%2520Store%2520Installs%26m%3D%24shortinstalls)](https://play.google.com/store/apps/details?id=app.lawnchair.play)\n\n<picture>\n    <!-- Avoid image being clickable with slight workaround -->\n    <!-- ‚ù§Ô∏è Credit to Raine for the original mockup on the Lawnchair Discord -->\n    <!-- ‚ù§Ô∏è Credit to Lawrence Kayku for the current mockup on Unsplash \n            https://unsplash.com/photos/photography-of-green-leaves-ZVKr8wADhpc \n    -->\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/assets/device-frame.png\" width=\"250px\">\n    <img alt=\"Google Pixel running Lawnchair Launcher with green wallpaper\" src=\"docs/assets/device-frame.png\" width=\"250px\">\n</picture>\n\nLawnchair is a free, open-source home app for Android. Taking Launcher3‚ÄîAndroid‚Äôs default home app‚Äîas a starting point, it ports Pixel Launcher features and introduces rich customization options.\n\nThis branch houses the codebase of Lawnchair 15, which is currently in beta and is based on Launcher3 from Android 15. For Lawnchair 9 to 14, see the branches with the `9-` to `14-` prefixes, respectively.\n\n## Features\n\n-   **Material You Theming:** Adapts to your wallpaper and system theme.\n-   **At a Glance Widget:** Displays information *at a glance* with support for [Smartspacer](https://github.com/KieronQuinn/Smartspacer).\n-   **QuickSwitch Support:** Integrates with Android Recents on Android 10 and newer. (requires root)\n-   **Global Search:** Allows quick access to apps, contacts, and web results from the home screen.\n-   **Customization Options:** Provides options to tweak icons, fonts, and colors to your liking.\n-   And more!\n\n## Download\n\n<p align=\"left\">\n  <a href=\"https://play.google.com/store/apps/details?id=app.lawnchair.play\">\n    <picture>\n      <!-- Avoid image being clickable with slight workaround -->\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/assets/badge-google-play.png\" height=\"60\">\n      <img alt=\"Get it on Google Play\" src=\"docs/assets/badge-google-play.png\" height=\"60\">\n    </picture>\n  </a>\n  <a href=\"https://apt.izzysoft.de/fdroid/index/apk/app.lawnchair\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/assets/badge-izzyondroid.png\" height=\"60\">\n      <img alt=\"Get it on IzzyOnDroid\" src=\"docs/assets/badge-izzyondroid.png\" height=\"60\">\n    </picture>\n  </a>\n  <a href=\"https://apps.obtainium.imranr.dev/redirect?r=obtainium://add/https://github.com/LawnchairLauncher/lawnchair/\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/assets/badge-obtainium.png\" height=\"60\">\n      <img alt=\"Get it on Obtainium\" src=\"docs/assets/badge-obtainium.png\" height=\"60\">\n    </picture>\n  </a>\n    <a href=\"https://github.com/LawnchairLauncher/lawnchair/releases\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/assets/badge-github.png\" height=\"60\">\n      <img alt=\"Get it on GitHub\" src=\"docs/assets/badge-github.png\" height=\"60\">\n    </picture>\n  </a>\n</p>\n\nLawnchair on Play Store will install as a different app from other sources. Some features may be restricted to comply with Google Play's publishing rules.\n\n### Development builds\n\nInterested in keeping yourself up-to-date with every Lawnchair development? Try our development builds!\n\nThese builds offer the latest features and bug fixes at a cost of being slower and introducing new bugs. Ensure that you make backups before installing.\n\n**Download:** [Obtainium][Obtainium link] ‚Ä¢ [GitHub][GitHub link] ‚Ä¢ [nightly.link][Nightly link]\n\n### Verification\n\nVerify the integrity of your Lawnchair download using these SHA-256 hashes:\n\n###### Google Play\n```\n47:AC:92:63:1C:60:35:13:CC:8D:26:DD:9C:FF:E0:71:9A:8B:36:55:44:DC:CE:C2:09:58:24:EC:25:61:20:A7\n```\n\n###### Elsewhere\n```\n74:7C:36:45:B3:57:25:8B:2E:23:E8:51:E5:3C:96:74:7F:E0:AD:D0:07:E5:BA:2C:D9:7E:8C:85:57:2E:4D:C5\n```\n\n## Contributing\n\nPlease visit the [Lawnchair Contributing Guidelines](CONTRIBUTING.md) for information and tips on contributing to Lawnchair.\n\n## Supporting Lawnchair\n\nIf you love what we do, consider [supporting us on Open Collective](https://opencollective.com/lawnchair)! Your contributions help keep Lawnchair independent and enable us to develop faster.\n\nA huge thank you to our **Core Backers ($5+)**:\n*(These backers directly fund our Project Velocity Fund)*\n\n[![Core Backers](https://opencollective.com/lawnchair/tiers/backer.svg?avatarHeight=64&width=890&button=false)](https://opencollective.com/lawnchair)\n\n[Become a supporter](https://opencollective.com/lawnchair) to help us cover our operational costs, or become a Core Backer to be featured here!\n\n## Quick links\n\n-   [Website](https://lawnchair.app)\n-   [News on Telegram](https://t.me/lawnchairci)\n-   [Discord](https://discord.com/invite/3x8qNWxgGZ)\n-   [Lawnchair on X (formerly Twitter)](https://x.com/lawnchairapp)\n-   [_XDA_ thread](https://xdaforums.com/t/lawnchair-customizable-pixel-launcher.3627137/)\n\nYou can view all our links in the [Lawnchair Wiki](https://github.com/LawnchairLauncher/lawnchair/wiki).\n\n<!-- Download link -->\n[Nightly link]: https://nightly.link/LawnchairLauncher/lawnchair/workflows/ci/15-dev\n[Obtainium link]: https://apps.obtainium.imranr.dev/redirect?r=obtainium://app/%7B%22id%22%3A%22app.lawnchair.nightly%22%2C%22url%22%3A%22https%3A%2F%2Fgithub.com%2Flawnchairlauncher%2Flawnchair%22%2C%22author%22%3A%22Lawnchair%20Launcher%22%2C%22name%22%3A%22Lawnchair%20(Debug)%22%2C%22preferredApkIndex%22%3A0%2C%22additionalSettings%22%3A%22%7B%5C%22includePrereleases%5C%22%3Atrue%2C%5C%22fallbackToOlderReleases%5C%22%3Afalse%2C%5C%22filterReleaseTitlesByRegEx%5C%22%3A%5C%22Lawnchair%20Nightly%5C%22%2C%5C%22filterReleaseNotesByRegEx%5C%22%3A%5C%22%5C%22%2C%5C%22verifyLatestTag%5C%22%3Afalse%2C%5C%22dontSortReleasesList%5C%22%3Afalse%2C%5C%22useLatestAssetDateAsReleaseDate%5C%22%3Afalse%2C%5C%22trackOnly%5C%22%3Afalse%2C%5C%22versionExtractionRegEx%5C%22%3A%5C%22%5C%22%2C%5C%22matchGroupToUse%5C%22%3A%5C%22%5C%22%2C%5C%22versionDetection%5C%22%3Afalse%2C%5C%22releaseDateAsVersion%5C%22%3Atrue%2C%5C%22useVersionCodeAsOSVersion%5C%22%3Afalse%2C%5C%22apkFilterRegEx%5C%22%3A%5C%22%5C%22%2C%5C%22invertAPKFilter%5C%22%3Afalse%2C%5C%22autoApkFilterByArch%5C%22%3Atrue%2C%5C%22appName%5C%22%3A%5C%22%5C%22%2C%5C%22shizukuPretendToBeGooglePlay%5C%22%3Afalse%2C%5C%22exemptFromBackgroundUpdates%5C%22%3Afalse%2C%5C%22skipUpdateNotifications%5C%22%3Afalse%2C%5C%22about%5C%22%3A%5C%22Lawnchair%20is%20a%20free%2C%20open-source%20home%20app%20for%20Android.%20(NOTE%3A%20This%20is%20the%20debug%20version%20of%20Lawnchair%2C%20for%20the%20beta%2Fstable%20versions%20see%20%5C%5C%5C%22Lawnchair%5C%5C%5C%22)%5C%22%7D%22%7D\n[GitHub link]: https://github.com/LawnchairLauncher/lawnchair/releases/tag/nightly\n",
      "stars_today": 18
    },
    {
      "id": 44662669,
      "name": "dbeaver",
      "full_name": "dbeaver/dbeaver",
      "description": "Free universal database tool and SQL client",
      "html_url": "https://github.com/dbeaver/dbeaver",
      "stars": 48352,
      "forks": 4007,
      "language": "Java",
      "topics": [
        "ai",
        "copilot",
        "database",
        "db2",
        "dbeaver",
        "erd",
        "gui",
        "java",
        "jdbc",
        "mysql",
        "nosql",
        "openai",
        "oracle",
        "postgresql",
        "redshift",
        "sql",
        "sqlite",
        "sqlserver"
      ],
      "created_at": "2015-10-21T08:26:28Z",
      "updated_at": "2026-01-23T02:05:21Z",
      "pushed_at": "2026-01-22T22:32:28Z",
      "open_issues": 3213,
      "owner": {
        "login": "dbeaver",
        "avatar_url": "https://avatars.githubusercontent.com/u/34743864?v=4"
      },
      "readme": "[![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/dbeaver_news.svg?style=social&label=Follow%20%40dbeaver_news)](https://twitter.com/dbeaver_news)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/fa0bb9cf5a904c7d87424f8f6351ba92)](https://app.codacy.com/gh/dbeaver/dbeaver/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n[![Apache 2.0](https://img.shields.io/github/license/cronn-de/jira-sync.svg)](http://www.apache.org/licenses/LICENSE-2.0)\n[![Tickets in review](https://img.shields.io/github/issues/dbeaver/dbeaver/wait%20for%20review)](https://github.com/dbeaver/dbeaver/issues?q=is%3Aissue+is%3Aopen+label%3A\"wait%20for%20review\")\n<img src=\"https://github.com/dbeaver/dbeaver/wiki/images/dbeaver-icon-64x64.png\" align=\"right\"/>\n\n# DBeaver\n\nFree multi-platform database tool for developers, SQL programmers, database administrators and analysts.  \n\n* Has a lot of <a href=\"https://github.com/dbeaver/dbeaver/wiki\">features</a> including schema editor, SQL editor, data editor, AI integration, ER diagrams, data export/import/migration, SQL execution plans, database administration tools, database dashboards, Spatial data viewer, proxy and SSH tunnelling, custom database drivers editor, etc.\n* Out of the box supports more than <a href=\"#supported-databases\">100 database drivers</a>.\n* Supports any database which has JDBC or ODBC driver (basically - almost all existing databases).\n* Supports smart AI completion and code generation with OpenAI or Copilot\n\n<a href=\"https://dbeaver.io/product/dbeaver-sql-editor.png\"><img src=\"https://dbeaver.io/product/dbeaver-sql-editor.png\" width=\"400\"/></a>\n<a href=\"https://dbeaver.io/product/dbeaver-gis-viewer.png\"><img src=\"https://dbeaver.io/product/dbeaver-gis-viewer.png\" width=\"400\"/></a>\n<a href=\"https://dbeaver.io/product/dbeaver-data-editor.png\"><img src=\"https://dbeaver.io/product/dbeaver-data-editor.png\" width=\"400\"/></a>\n<a href=\"https://dbeaver.io/product/dbeaver-erd.png\"><img src=\"https://dbeaver.io/product/dbeaver-erd.png\" width=\"400\"/></a>\n\n## Download\n\nYou can download prebuilt binaries from <a href=\"https://dbeaver.io/download\" target=\"_blank\">official website</a> or directly from <a href=\"https://github.com/dbeaver/dbeaver/releases\">GitHub releases</a>.  \nYou can also download <a href=\"https://dbeaver.io/files/ea\" target=\"_blank\">Early Access</a> version. We publish daily.  \n\n## Running\n\nJust run an installer (or unzip an archive) and run `dbeaver`.  \n\nNote: DBeaver needs Java to run. <a href=\"https://adoptium.net/temurin/releases/?package=jre\" target=\"_blank\">OpenJDK 21</a> is included in all DBeaver distributions.\nYou can change default JDK version by replacing directory `jre` in dbeaver installation folder.\n\n## Documentation\n\n* [Full product documentation](https://dbeaver.com/docs/dbeaver/)\n* [WIKI](https://github.com/dbeaver/dbeaver/wiki)\n* [Issue tracker](https://github.com/dbeaver/dbeaver/issues)\n* [Building from sources](https://github.com/dbeaver/dbeaver/wiki/Build-from-sources)\n\n## Architecture\n\n- DBeaver is written mostly on Java. However, it also uses a set of native OS-specific components for desktop UI, high performance database drivers and networking.\n- Basic frameworks:\n  - [OSGI](https://en.wikipedia.org/wiki/OSGi) platform for plugins and dependency management. Community version consists of 130+ plugins.\n  - [Eclipse RCP](https://github.com/eclipse-platform/eclipse.platform.ui/blob/master/docs/Rich_Client_Platform.md) platform for rich user interface build.\n  - [JDBC](https://en.wikipedia.org/wiki/Java_Database_Connectivity) for basic database connectivity API.\n  - [JSQLParser](https://github.com/JSQLParser/JSqlParser) and [Antlr4](https://github.com/antlr/antlr4) for SQL grammar and semantic parser.\n- For networking and additional functionality we use wide range of open source libraries such as [SSHJ](https://github.com/hierynomus/sshj), [Apache POI](https://github.com/apache/poi), [JFreeChart](https://github.com/jfree/jfreechart), [JTS](https://github.com/locationtech/jts), [Apache JEXL](https://github.com/apache/commons-jexl) etc.\n- We separate model plugins from desktop UI plugins. This allows us to use the same set of \"back-end\" plugins in both DBeaver and [CloudBeaver](https://github.com/dbeaver/cloudbeaver).\n- Dependencies: being an OSGI application we use P2 repositories for third party dependencies. For additional Maven dependencies we use our own [DBeaver P2 repo](https://github.com/dbeaver/dbeaver-deps-ce).\n\n## Supported databases\n\n### Community version\n\nOut of the box DBeaver supports following database drivers: \nMySQL, MariaDB, Oracle, DB2, PostgreSQL, SQL Server, Sybase, Apache Hive, Drill, Presto, Trino, Phoenix, Exasol, Informix, Teradata, Vertica, Netezza, Firebird, Derby, H2, H2GIS, WMI, Snowflake, Greenplum, Redshift, Athena, SAP HANA, MaxDB, NuoDB, MS Access, SQLite, CSV, DBF, Firebird, TimescaleDB, Yellowbrick, CockroachDB, OrientDB, MonetDB, Google BigQuery, Google Spanner, Apache Hive/Impala/Spark, Apache Ignite, MapD, Azure SQL, CrateDB, Elasticsearch, Ocient, Ingres, OmniSci, Yugabyte, IRIS, Data Virtuality, Denodo, Virtuoso, Machbase, DuckDB, Babelfish, OceanBase, Salesforce, EnterpriseDB, Apache Druid, Apache Kylin, Databricks, OpenSearch, TiDB, TDEngine, Materialize, JDBCX, Dameng, Altibase, StarRocks, CUBRID, GaussDB, DolphinDB, LibSQL, GBase 8s, Databend, Cloudberry, Teiid, Kingbase.\n\n### PRO versions\n\n<a href=\"https://dbeaver.com/download/\">Commercial versions</a> extends functionality of many popular drivers and also support non-JDBC datasources such as:\nODBC, MongoDB, Cassandra, Couchbase, CouchDB, Redis, InfluxDB, Firestore, BigTable, DynamoDB, Kafka KSQL, Neo4j, AWS Neptune, AWS Timestream, Azure CosmosDB, Yugabyte, Salesforce, etc.  \nAlso, we support flat files as databases: CSV, XLSX, Json, XML, Parquet.  \nYou can find the list of all databases supported in commercial versions <a href=\"https://dbeaver.com/databases/\">here</a>.\n\n## Feedback\n\n- For bug reports and feature requests - please <a href=\"https://github.com/dbeaver/dbeaver/issues\">create a ticket</a>.\n- To promote <a href=\"https://github.com/dbeaver/dbeaver/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22wait+for+votes%22\">a ticket</a> to a higher priority - please vote for it with üëç under the ticket description.\n- If you have any questions, ideas, etc - please <a href=\"https://github.com/dbeaver/dbeaver/discussions\">start a discussion</a>.\n- Pull requests are welcome. See our <a href=\"https://github.com/dbeaver/dbeaver/wiki/Contribute-your-code\">guide for contributors</a>.\n- Visit https://dbeaver.com for more information.\n- Follow us on [X](https://x.com/dbeaver_news/) and watch educational video on [YouTube](https://www.youtube.com/@DBeaver_video)\n- Thanks for using DBeaver! Star if you like it.\n\n## Contribution: help the Beaver!\n\nHooray, we have reached 40k+ stars on GitHub and continue to grow!  \nThat's really cool, and we are glad that you like DBeaver.\n\n- We are actively looking for new source code contributors. We have added labels ‚ÄúGood first issue‚Äù and ‚ÄúHelp wanted‚Äù to some tickets. If you want to be a part of our development team, just be brave and take a ticket. <a href=\"https://dbeaver.com/help-dbeaver/\">We are happy to reward</a> our most active contributors every major sprint.\n- You can buy <a href=\"https://dbeaver.com/buy/\">one of our commercial versions</a>. They include NoSQL databases support, additional extensions, and official online support. Also, licensed users have priorities in bug fixes and the development of new features.\n\nThank you!  \n\n- <a href=\"https://github.com/dbeaver/dbeaver/graphs/contributors\">DBeaver Team</a> (contributors)\n\n---------\n\n<a href=\"https://github.com/dbeaver/cloudbeaver/\"><img src=\"https://github.com/dbeaver/cloudbeaver/wiki/images/cloudbeaver-logo.png\" width=\"250\"/></a>\n\n<a href=\"https://github.com/dbeaver/cloudbeaver\">CloudBeaver</a> is a web-based database management tool built on the DBeaver platform. It brings the capabilities of DBeaver to the browser, enabling database management from any device with an internet connection and eliminating the need for local installation. Supporting any database, CloudBeaver incorporates most of DBeaver's features and includes advanced access management for secure collaboration.\nDesigned with a user-friendly interface, CloudBeaver simplifies complex database operations and is suitable for both individual developers and organizations. Its scalable architecture accommodates various needs, making it a convenient solution for managing databases anytime and anywhere through web-based accessibility.\n",
      "stars_today": 17
    },
    {
      "id": 1069446208,
      "name": "vibeproxy",
      "full_name": "automazeio/vibeproxy",
      "description": "Native macOS menu bar app to use your Claude Code & ChatGPT subscriptions with AI coding tools - no API keys needed",
      "html_url": "https://github.com/automazeio/vibeproxy",
      "stars": 1102,
      "forks": 71,
      "language": "Swift",
      "topics": [
        "claude-code",
        "claudecode",
        "cli-proxy",
        "codex",
        "factory-droids",
        "gpt-5-codex"
      ],
      "created_at": "2025-10-04T00:36:21Z",
      "updated_at": "2026-01-22T22:00:33Z",
      "pushed_at": "2026-01-22T00:05:51Z",
      "open_issues": 8,
      "owner": {
        "login": "automazeio",
        "avatar_url": "https://avatars.githubusercontent.com/u/125381035?v=4"
      },
      "readme": "# VibeProxy\n\n<p align=\"center\">\n  <img src=\"icon.png\" width=\"128\" height=\"128\" alt=\"VibeProxy Icon\">\n</p>\n\n<p align=\"center\">\n<a href=\"https://automaze.io\" rel=\"nofollow\"><img alt=\"Automaze\" src=\"https://img.shields.io/badge/By-automaze.io-4b3baf\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/automazeio/vibeproxy/blob/main/LICENSE\"><img alt=\"MIT License\" src=\"https://img.shields.io/badge/License-MIT-28a745\" style=\"max-width: 100%;\"></a>\n<a href=\"http://x.com/intent/follow?screen_name=aroussi\" rel=\"nofollow\"><img alt=\"Follow on ùïè\" src=\"https://img.shields.io/badge/Follow-%F0%9D%95%8F/@aroussi-1c9bf0\" style=\"max-width: 100%;\"></a>\n<a href=\"https://github.com/automazeio/vibeproxy\"><img alt=\"Star this repo\" src=\"https://img.shields.io/github/stars/automazeio/vibeproxy.svg?style=social&amp;label=Star%20this%20repo&amp;maxAge=60\" style=\"max-width: 100%;\"></a></p>\n</p>\n\n**Stop paying twice for AI.** VibeProxy is a beautiful native macOS menu bar app that lets you use your existing Claude Code, ChatGPT, **Gemini**, **Qwen**, **Antigravity**, and **Z.AI GLM** subscriptions with powerful AI coding tools like **[Factory Droids](https://app.factory.ai/r/FM8BJHFQ)** ‚Äì no separate API keys required.\n\nBuilt on [CLIProxyAPIPlus](https://github.com/router-for-me/CLIProxyAPIPlus), it handles OAuth authentication, token management, and API routing automatically. One click to authenticate, zero friction to code.\n\n\n<p align=\"center\">\n<br>\n  <a href=\"https://www.loom.com/share/5cf54acfc55049afba725ab443dd3777\"><img src=\"vibeproxy-factory-video.webp\" width=\"600\" height=\"380\" alt=\"VibeProxy Screenshot\" border=\"0\"></a>\n</p>\n\n> [!TIP]\n> üì£ **Latest models supported:**<br>Gemini 3 Pro Support (via Antigravity), GPT-5.1 / GPT-5.1 Codex, Claude Sonnet 4.5 / Opus 4.5 with extended thinking, GitHub Copilot, and Z.AI GLM-4.7! üöÄ \n> \n> **Setup Guides:**\n> - [Factory CLI Setup ‚Üí](FACTORY_SETUP.md) - Use Factory Droids with your AI subscriptions\n> - [Amp CLI Setup ‚Üí](AMPCODE_SETUP.md) - Use Amp CLI with fallback to your subscriptions\n\n---\n\n## Features\n\n- üéØ **Native macOS Experience** - Clean, native SwiftUI interface that feels right at home on macOS\n- üöÄ **One-Click Server Management** - Start/stop the proxy server from your menu bar\n- üîê **Easy Authentication** - Authenticate with Codex, Claude Code, Gemini, Qwen, Antigravity (OAuth), and Z.AI GLM (API key) directly from the app\n- üë• **Multi-Account Support** - Connect multiple accounts per provider with automatic round-robin distribution and failover when rate-limited\n- üéöÔ∏è **Provider Priority** - Enable/disable providers to control which models are available (instant hot reload)\n- üìä **Real-Time Status** - Live connection status and automatic credential detection\n- üîÑ **Automatic App Updates** - Starting with v1.6, VibeProxy checks for updates daily and installs them seamlessly via Sparkle\n- üé® **Beautiful Icons** - Custom icons with dark mode support\n- üíæ **Self-Contained** - Everything bundled inside the .app (server binary, config, static files)\n\n\n## Installation\n\n**Requirements:** macOS 13+ (Ventura or later)\n\n### Download Pre-built Release (Recommended)\n\n1. Go to the [**Releases**](https://github.com/automazeio/vibeproxy/releases) page\n2. Download the appropriate version for your Mac:\n   - **Apple Silicon** (M1/M2/M3/M4): `VibeProxy-arm64.zip`\n   - **Intel**: `VibeProxy-x86_64.zip` *(untested - please report issues)*\n3. Extract and drag `VibeProxy.app` to `/Applications`\n4. Launch VibeProxy\n\n**Code Signed & Notarized** ‚úÖ - No Gatekeeper warnings, installs seamlessly on macOS.\n\n### Build from Source\n\nWant to build it yourself? See [**INSTALLATION.md**](INSTALLATION.md) for detailed build instructions.\n\n## Usage\n\n### First Launch\n\n1. Launch VibeProxy - you'll see a menu bar icon\n2. Click the icon and select \"Open Settings\"\n3. The server will start automatically\n4. Click \"Connect\" for Claude Code, Codex, Gemini, Qwen, or Antigravity to authenticate, or \"Add Account\" for Z.AI GLM to enter your API key\n\n### Authentication\n\nWhen you click \"Connect\":\n1. Your browser opens with the OAuth page\n2. Complete the authentication in the browser\n3. VibeProxy automatically detects your credentials\n4. Status updates to show you're connected\n\n### Server Management\n\n- **Toggle Server**: Click the status (Running/Stopped) to start/stop\n- **Menu Bar Icon**: Shows active/inactive state\n- **Launch at Login**: Toggle to start VibeProxy automatically\n\n## Requirements\n\n- macOS 13.0 (Ventura) or later\n\n## Development\n\n### Project Structure\n\n```\nVibeProxy/\n‚îú‚îÄ‚îÄ Sources/\n‚îÇ   ‚îú‚îÄ‚îÄ main.swift              # App entry point\n‚îÇ   ‚îú‚îÄ‚îÄ AppDelegate.swift       # Menu bar & window management\n‚îÇ   ‚îú‚îÄ‚îÄ ServerManager.swift     # Server process control & auth\n‚îÇ   ‚îú‚îÄ‚îÄ SettingsView.swift      # Main UI\n‚îÇ   ‚îú‚îÄ‚îÄ AuthStatus.swift        # Auth file monitoring\n‚îÇ   ‚îî‚îÄ‚îÄ Resources/\n‚îÇ       ‚îú‚îÄ‚îÄ AppIcon.iconset     # App icon\n‚îÇ       ‚îú‚îÄ‚îÄ AppIcon.icns        # App icon\n‚îÇ       ‚îú‚îÄ‚îÄ cli-proxy-api-plus  # CLIProxyAPIPlus binary\n‚îÇ       ‚îú‚îÄ‚îÄ config.yaml         # CLIProxyAPIPlus config\n‚îÇ       ‚îú‚îÄ‚îÄ icon-active.png     # Menu bar icon (active)\n‚îÇ       ‚îú‚îÄ‚îÄ icon-inactive.png   # Menu bar icon (inactive)\n‚îÇ       ‚îú‚îÄ‚îÄ icon-claude.png     # Claude Code service icon\n‚îÇ       ‚îú‚îÄ‚îÄ icon-codex.png      # Codex service icon\n‚îÇ       ‚îú‚îÄ‚îÄ icon-gemini.png     # Gemini service icon\n‚îÇ       ‚îú‚îÄ‚îÄ icon-qwen.png       # Qwen service icon\n‚îÇ       ‚îî‚îÄ‚îÄ icon-zai.png        # Z.AI GLM service icon\n‚îú‚îÄ‚îÄ Package.swift               # Swift Package Manager config\n‚îú‚îÄ‚îÄ Info.plist                  # macOS app metadata\n‚îú‚îÄ‚îÄ build.sh                    # Resource bundling script\n‚îú‚îÄ‚îÄ create-app-bundle.sh        # App bundle creation script\n‚îî‚îÄ‚îÄ Makefile                    # Build automation\n```\n\n### Key Components\n\n- **AppDelegate**: Manages the menu bar item and settings window lifecycle\n- **ServerManager**: Controls the cli-proxy-api server process and OAuth authentication\n- **SettingsView**: SwiftUI interface with native macOS design\n- **AuthStatus**: Monitors `~/.cli-proxy-api/` for authentication files\n- **File Monitoring**: Real-time updates when auth files are added/removed\n\n## Credits\n\nVibeProxy is built on top of [CLIProxyAPIPlus](https://github.com/router-for-me/CLIProxyAPIPlus), an excellent unified proxy server for AI services with support for third-party providers.\n\nSpecial thanks to the CLIProxyAPIPlus project for providing the core functionality that makes VibeProxy possible.\n\n## License\n\nMIT License - see LICENSE file for details\n\n## Support\n\n- **Report Issues**: [GitHub Issues](https://github.com/automazeio/vibeproxy/issues)\n- **Website**: [automaze.io](https://automaze.io)\n\n---\n\n¬© 2025 [Automaze, Ltd.](https://automaze.io) All rights reserved.\n",
      "stars_today": 17
    },
    {
      "id": 24268127,
      "name": "nvm-windows",
      "full_name": "coreybutler/nvm-windows",
      "description": "A node.js version management utility for Windows. Ironically written in Go.",
      "html_url": "https://github.com/coreybutler/nvm-windows",
      "stars": 44567,
      "forks": 3706,
      "language": "Go",
      "topics": [
        "go",
        "management",
        "node",
        "node-version-manager",
        "nodejs",
        "nvm",
        "switch",
        "version",
        "version-manager",
        "versioning",
        "windows"
      ],
      "created_at": "2014-09-20T16:37:28Z",
      "updated_at": "2026-01-22T22:39:07Z",
      "pushed_at": "2025-10-06T12:58:49Z",
      "open_issues": 94,
      "owner": {
        "login": "coreybutler",
        "avatar_url": "https://avatars.githubusercontent.com/u/770982?v=4"
      },
      "readme": "<div align=\"center\"><h2>Notice: We are working full time on Author, which includes <a href=\"https://github.com/coreybutler/nvm-windows/wiki/Runtime\">Runtime</a>, the successor to NVM for Windows.</h2>Complete <a href=\"https://t.co/oGqQCM9FPx\">this form</a> to provide your thoughts and sign up for progress updates.<br/><br/>Updates will also be posted on the <A href=\"https://linkedin.com/company/authorsoftware\">Author Software LinkedIn Page</a>.</div>\n<br/><br/>\n<h1 align=\"center\">NVM for Windows</h1>\n\n<div align=\"center\">\n  The <a href=\"https://docs.microsoft.com/en-us/windows/nodejs/setup-on-windows\">Microsoft</a>/<a href=\"https://docs.npmjs.com/cli/v9/configuring-npm/install#windows-node-version-managers\">npm</a>/<a href=\"https://cloud.google.com/nodejs/docs/setup#installing_nvm\">Google</a> recommended Node.js version manager for <em>Windows</em>.<br/>\n\n<details>\n<summary><b>This is not the same thing as nvm!</b> (expand for details)</summary>\n\n_The original [nvm](https://github.com/nvm-sh/nvm) is a completely separate project for Mac/Linux only._ This project uses an entirely different philosophy and is not just a clone of nvm. Details are listed in [Why another version manager?](#bulb-why-another-version-manager) and [what&#39;s the big difference?](#bulb-whats-the-big-difference).\n</details>\n\n[![Download Now](https://img.shields.io/badge/-Download%20Now!-%2322A6F2)](https://github.com/coreybutler/nvm-windows/releases) [![GitHub tag (latest SemVer)](https://img.shields.io/github/v/tag/coreybutler/nvm-windows?label=Latest%20Release&style=social&x=1)]((https://github.com/coreybutler/nvm-windows/releases)) ![GitHub Release Date](https://img.shields.io/github/release-date/coreybutler/nvm-windows?label=Released&style=social) ![GitHub all releases](https://img.shields.io/github/downloads/coreybutler/nvm-windows/total?label=Downloads&style=social) [![Discuss](https://img.shields.io/badge/-Discuss-blue)](https://github.com/coreybutler/nvm-windows/discussions) [![Twitter URL](https://img.shields.io/twitter/url?style=social&url=https%3A%2F%2Ftwitter.com%2Fintent%2Ftweet%3Fhashtags%3Dnodejs%26original_referer%3Dhttp%253A%252F%252F127.0.0.1%253A91%252F%26text%3DCheck%2520out%2520NVM%2520for%2520Windows%21%26tw_p%3Dtweetbutton%26url%3Dhttp%253A%252F%252Fgithub.com%252Fcoreybutler%252Fnvm-windows%26via%3Dgoldglovecb)](https://twitter.com/intent/tweet?hashtags=nodejs&original_referer=http%3A%2F%2F127.0.0.1%3A91%2F&text=Check%20out%20NVM%20for%20Windows!&tw_p=tweetbutton&url=http%3A%2F%2Fgithub.com%2Fcoreybutler%2Fnvm-windows&via=goldglovecb)\n</div>\n\n<div align=\"center\">\n<a href=\"https://trendshift.io/repositories/4201\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/4201\" alt=\"coreybutler%2Fnvm-windows | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</div>\n\n<h5 align=\"center\">Sponsors</h5>\n\n<div align=\"center\">\n  <table cellpadding=\"5\" cellspacing=\"0\" border=\"0\" align=\"center\">\n    <tr>\n      <td><a href=\"https://linkedin.com/company/authorsoftware\"><img src=\"https://github.com/coreybutler/staticassets/blob/master/sponsors/logo_author_software_flat.png\" width=\"200px\"/></a></td>\n      <td width=\"33%\" align=\"center\"><a href=\"https://ecorventures.com\"><img src=\"https://avatars.githubusercontent.com/u/8259581?s=200&v=4\" height=\"30px\"/></a></td>\n      <td width=\"33%\" align=\"center\"><a href=\"https://github.com/microsoft\"><img src=\"https://user-images.githubusercontent.com/770982/195955265-5c3dca78-7140-4ec6-b05a-f308518643ee.png\" height=\"30px\"/></a></td>\n    </tr>\n    <tr>\n      <td colspan=\"4\" align=\"center\">\n        <a href=\"https://github.com/sponsors/coreybutler\"><img src=\"https://img.shields.io/github/sponsors/coreybutler?label=Individual%20Sponsors&logo=github&style=social\"/></a>\n        &nbsp;<a href=\"https://github.com/sponsors/coreybutler\"><img src=\"https://img.shields.io/badge/-Become%20a%20Sponsor-yellow\"/></a>\n      </td>\n    </tr>\n    <tr>\n      <td colspan=\"4\" align=\"center\">\n        <img src=\"https://github.blog/wp-content/uploads/2020/09/github-stars-logo_Color.png\" width=\"50\"/><br/>\n        <b>Can't sponsor?</b><br/>Consider <a href=\"https://stars.github.com/nominate/\" target=\"_blank\">nominating @coreybutler for a Github star</a>.\n      </td>\n    </tr>\n  </table>\n</div>\n<br/>\n\n<div align=\"center\"><b>Running into issues?</b> See the <a href=\"https://github.com/coreybutler/nvm-windows/wiki/Common-Issues\">common issues wiki</a>.</div>\n\n<br/>\n<table style=\"background-color:red;padding:6px;border-radius:3px;\">\n  <tr><td>\n    <h3>Seeking Feedback:</h3>\n    We're working on <a href=\"https://github.com/coreybutler/nvm-windows/wiki/Runtime\">Runtime (rt)</a>, the successor to NVM For Windows. Please contribute by taking a minute to complete <a href=\"https://t.co/oGqQCM9FPx\">this form</a>. Thank you!\n    <h3></h3>\n  </td></tr>\n</table>\n\n## Overview\n\nManage multiple installations of node.js on a Windows computer.\n\n**tl;dr** Similar (not identical) to [nvm](https://github.com/creationix/nvm), but for Windows. Has an installer. [Download Now](https://github.com/coreybutler/nvm-windows/releases)!\n\nThis has always been a node version manager, not an io.js manager, so there is no back-support for io.js. Node 4+ is supported. Remember when running `nvm install` or `nvm use`, Windows usually requires administrative rights (to create symlinks). To install the latest version of Node.js, run `nvm install latest`. To install the latest stable version, run `nvm install lts`.\n\n![NVM for Windows](https://github.com/coreybutler/staticassets/raw/master/images/nvm-1.1.8-screenshot.jpg)\n\nThere are situations where the ability to switch between different versions of Node.js can be very useful. For example, if you want to test a module you're developing with the latest bleeding edge version without uninstalling the stable version of node, this utility can help.\n\n![Switch between stable and unstable versions.](https://github.com/coreybutler/staticassets/raw/master/images/nvm-usage-highlighted.jpg)\n\n### Installation & Upgrades\n\n#### :star: :star: Uninstall any pre-existing Node installations!! :star: :star:\n\nThe simplest (recommended) way to get NVM for Windows running properly is to uninstall any prior Node installation _before_ installing NVM for Windows. It avoids all of the pitfalls listed below. However; you may not wish to nuke your Node installation if you've highly customized it. NVM for Windows _can_ assume management of an existing installation, but there are nuances to this (dependent entirely on the permissions of the user running the installation). If you have an administrative account, it's relatively safe to install NVM for Windows before uninstalling the original Node version. If you are working in a closed environment, such as a corporate Active Directory environment where installations/uninstallations are controlled by group policy, you should really consider removing the original version of Node before installing NVM4W.\n\n_Permission Problems_\nFor security reasons, Windows will not allow an application from one vendor to \"uninstall\" an application from a different vendor. The official NVM4W installer will attempt assume management of an existing installation of Node., but it cannot actually uninstall the original Node.js version. To work around this, NVM for Windows installer attempts to copy the original Node.js installation files to the NVM root. This includes global npm modules and configurations. Once this process is complete, the original Node.js installation can be uninstalled without losing data.\n\n_PATH Installation Problems_\nIf you attempt to configure the `NVM_SYMLINK` to use an existing directory (like `C:\\Program Files\\nodejs`), it will fail because a symlink cannot overwrite a physical directory. This is not a problem if you choose a different symlink path (such as `C:\\nvm\\node`).\n\n_PATH Conflicts_\nIf you do not uninstall the original version, running `nvm use` may appear to do nothing at all. Running `node -v` will always show the original installation version. This is due to a [`PATH` conflict](https://github.com/coreybutler/nvm-windows/wiki/Common-Issues#why-do-i-need-to-uninstall-nodejs-before-installing-nvm-for-windows) that presents when the same application is installed multiple times. In NVM4W 1.1.11+, run `nvm debug` to determine if you have a `PATH` conflict.\n\nFor simpliciy, we recommend uninstalling any existing versions of Node.js before using NVM for Windows. Delete any existing Node.js installation directories (e.g., `%ProgramFiles%\\nodejs`) that might remain. NVM's generated symlink will not overwrite an existing (even empty) installation directory.\n\n:eyes: **Backup any global `npmrc` config** :eyes:\n(e.g. `%AppData%\\npm\\etc\\npmrc`)\n\nAlternatively, copy the settings to the user config `%UserProfile%\\.npmrc`. Delete the existing npm install location (e.g. `%AppData%\\npm`) to prevent global module conflicts.\n\n#### Install nvm-windows\n\nUse the [latest installer](https://github.com/coreybutler/nvm/releases) (comes with an uninstaller). Alternatively, follow the  [manual installation](https://github.com/coreybutler/nvm-windows/wiki#manual-installation) guide.\n\n_If NVM4W doesn't appear to work immediately after installation, restart the terminal/powershell (not the whole computer)._\n\n![NVM for Windows Installer](https://github.com/coreybutler/staticassets/raw/master/images/nvm-installer.jpg)\n\n#### Reinstall any global utilities\n\nAfter install, reinstalling global utilities (e.g. yarn) will have to be done for each installed version of node:\n\n```\nnvm use 14.0.0\nnpm install -g yarn\nnvm use 12.0.1\nnpm install -g yarn\n```\n\n### Upgrading nvm-windows\n\n:bulb: _As of v1.1.8, there is an upgrade utility that will automate the upgrade process._\n\n**To upgrade nvm-windows**, run the new installer. It will safely overwrite the files it needs to update without touching your node.js installations. Make sure you use the same installation and symlink folder. If you originally installed to the default locations, you just need to click \"next\" on each window until it finishes.\n\n### Usage\n\n**nvm-windows runs in an Admin shell**. You'll need to start `powershell` or Command Prompt as Administrator to use nvm-windows\n\nNVM for Windows is a command line tool. Simply type `nvm` in the console for help. The basic commands are:\n\n- **`nvm arch [32|64]`**: Show if node is running in 32 or 64 bit mode. Specify 32 or 64 to override the default architecture.\n- **`nvm debug`**: Check the NVM4W process for known problems.\n- **`nvm current`**: Display active version.\n- **`nvm install <version> [arch]`**:  The version can be a specific version, \"latest\" for the latest current version, or \"lts\" for the most recent LTS version. Optionally specify whether to install the 32 or 64 bit version (defaults to system arch). Set [arch] to \"all\" to install 32 AND 64 bit versions. Add `--insecure` to the end of this command to bypass SSL validation of the remote download server.\n- **`nvm list [available]`**: List the node.js installations. Type `available` at the end to show a list of versions available for download.\n- **`nvm on`**: Enable node.js version management.\n- **`nvm off`**: Disable node.js version management (does not uninstall anything).\n- **`nvm proxy [url]`**: Set a proxy to use for downloads. Leave `[url]` blank to see the current proxy. Set `[url]` to \"none\" to remove the proxy.\n- **`nvm uninstall <version>`**: Uninstall a specific version.\n- **`nvm use <version> [arch]`**: Switch to use the specified version. Optionally use `latest`, `lts`, or `newest`. `newest` is the latest _installed_ version. Optionally specify 32/64bit architecture. `nvm use <arch>` will continue using the selected version, but switch to 32/64 bit mode. For information about using `use` in a specific directory (or using `.nvmrc`), please refer to [issue #16](https://github.com/coreybutler/nvm-windows/issues/16).\n- **`nvm root <path>`**: Set the directory where nvm should store different versions of node.js. If `<path>` is not set, the current root will be displayed.\n- **`nvm version`**: Displays the current running version of NVM for Windows.\n- **`nvm node_mirror <node_mirror_url>`**: Set the node mirror.People in China can use *https://npmmirror.com/mirrors/node/*\n- **`nvm npm_mirror <npm_mirror_url>`**: Set the npm mirror.People in China can use *https://npmmirror.com/mirrors/npm/*\n\n### :warning: Gotcha!\n\nPlease note that any global npm modules you may have installed are **not** shared between the various versions of node.js you have installed. Additionally, some npm modules may not be supported in the version of node you're using, so be aware of your environment as you work.\n\n### :name_badge: Antivirus\n\nUsers have reported some problems using antivirus, specifically McAfee. It appears the antivirus software is manipulating access to the VBScript engine. See [issue #133](https://github.com/coreybutler/nvm-windows/issues/133) for details and resolution.\n\n**v1.1.8 is not code signed**, but all other versions are signed by [Ecor Ventures LLC](https://ecorventures.com)/[Author.io](https://author.io). This should help prevent false positives with most antivirus software.\n\n> v1.1.8+ was not code signed due to an expired certificate (see the [release notes](https://github.com/coreybutler/nvm-windows/releases/tag/1.1.8) for reasons). **v1.1.9 _is_ code signed** thanks to [ajyong](https://github.com/ajyong), who sponsored the new certificate.\n\n### Using Yarn\n\n**tldr;** `npm i -g yarn`\n\nSee the [wiki](https://github.com/coreybutler/nvm-windows/wiki/Common-Issues#how-do-i-use-yarn-with-nvm-windows) for details.\n\n### Build from source\n\n- Install go from http://golang.org\n- Download source / Git Clone the repo\n- Change GOARCH to amd64 in build.bat if you feel like building a 64-bit executable\n- Fire up a Windows command prompt and change directory to project dir\n- Execute `go get github.com/blang/semver`\n- Execute `go get github.com/olekukonko/tablewriter`\n- Execute `build.bat`\n- Check the `dist`directory for generated setup program.\n\n---\n\n## :bulb: Why another version manager?\n\nThere are several version managers for node.js. Tools like [nvm](https://github.com/creationix/nvm) and [n](https://github.com/tj/n)\nonly run on Mac OSX and Linux. Windows users are left in the cold? No. [nvmw](https://github.com/hakobera/nvmw) and [nodist](https://github.com/marcelklehr/nodist)\nare both designed for Windows. So, why another version manager for Windows?\n\nThe architecture of most node version managers for Windows rely on `.bat` files, which do some clever tricks to set or mimic environment variables. Some of them use node itself (once it's downloaded), which is admirable, but prone to problems. Right around node 0.10.30, the installation structure changed a little, causing some of these to just stop working with anything new.\n\nAdditionally, some users struggle to install these modules since it requires a little more knowledge of node's installation structure. I believe if it were easier for people to switch between versions, people might take the time to test their code on back and future versions... which is just good practice.\n\n## :bulb: What's the big difference?\n\nFirst and foremost, this version of nvm has no dependency on node. It's written in [Go](https://golang.org/), which is a much more structured approach than hacking around a limited `.bat` file. It does not rely on having an existing node installation. Go offers the ability to create a Mac/Linux version on the same code base. In fact, this is already underway.\n\nThe control mechanism is also quite different. There are two general ways to support multiple node installations with hot switching capabilities. The first is to modify the system `PATH` any time you switch versions, or bypass it by using a `.bat` file to mimic the node executable and redirect accordingly. This always seemed a little hackish to me, and there are some quirks as a result of this implementation.\n\nThe second option is to use a symlink. This concept requires putting the symlink in the system `PATH`, then updating its target to the node installation directory you want to use. This is a straightforward approach, and seems to be what people recommend.... until they realize just how much of a pain symlinks are on Windows. This is why it hasn't happened before.\n\nIn order to create/modify a symlink, you must be running as an admin, and you must get around Windows UAC (that annoying prompt). Luckily, this is a challenge I already solved with some helper scripts in [node-windows](https://github.com/coreybutler/node-windows). As a result, NVM for Windows maintains a single symlink that is put in the system `PATH` during installation only. Switching to different versions of node is a matter of switching the symlink target. As a result, this utility does **not** require you to run `nvm use x.x.x` every time you open a console window. When you _do_ run `nvm use x.x.x`, the active version of node is automatically updated across all open console windows. It also persists between system reboots, so you only need to use nvm when you want to make a change.\n\nNVM for Windows comes with an installer, courtesy of a byproduct of my work on [Fenix Web Server](https://preview.fenixwebserver.com).\n\nOverall, this project brings together some ideas, a few battle-hardened pieces of other modules, and support for newer versions of node.\n\nNVM for Windows recognizes the \"latest\" versions using a [list](https://nodejs.org/download/release/index.json) provided by the Node project. Version 1.1.1+ use this list. Before this list existed, I was scraping releases and serving it as a standalone [data feed](https://github.com/coreybutler/nodedistro). This list was used in versions 1.1.0 and prior, but is now deprecated.\n\n## Motivation\n\nI needed it, plain and simple. Additionally, it's apparent that [support for multiple versions](https://github.com/nodejs/node-v0.x-archive/issues/8075) is not coming to node core. It was also an excuse to play with Go.\n\n## Why Go? Why not Node?\n\nI chose Go because it is cross-platform, felt like less overhead than Java, has been around longer than most people think. Plus, I wanted to experiment with it. I've been asked why I didn't write it with Node. Trying to write a tool with the tool you're trying to install doesn't make sense to me. As a result, my project requirements for this were simple... something that's not Node. Node will continue to evolve and change. If you need a reminder of that, remember io.js, Ayo, all the breaking changes between 4.x.x and 6.x.x, and the shift to ES Modules in 12+. Change is inevitable in the world of software. JavaScript is extremely dynamic.\n\n## :pray: Thanks\n\nThanks to everyone who has submitted issues on and off Github, made suggestions, and generally helped make this a better project. Special thanks to\n\n- [@vkbansal](https://github.com/vkbansal), who provided significant early feedback throughout the early releases.\n- [@rainabba](https://github.com/rainabba) and [@sullivanpt](https://github.com/sullivanpt) for getting Node v4 support integrated.\n- [@s-h-a-d-o-w](https://github.com/s-h-a-d-o-w) who resolved the longstanding space escaping issue in path names ([#355](https://github.com/coreybutler/nvm-windows/pull/355)).\n- [ajyong](https://github.com/ajyong) who sponsored the code signing certificate in late 2021.\n\n<br/>\n\n![Contributors](https://contrib.rocks/image?repo=coreybutler/nvm-windows)\n",
      "stars_today": 16
    },
    {
      "id": 698328708,
      "name": "EasyTier",
      "full_name": "EasyTier/EasyTier",
      "description": "A simple, decentralized mesh VPN with WireGuard support.",
      "html_url": "https://github.com/EasyTier/EasyTier",
      "stars": 9466,
      "forks": 897,
      "language": "Rust",
      "topics": [
        "nat-traversal",
        "p2p",
        "rust",
        "tailscale",
        "vpn",
        "zerotier"
      ],
      "created_at": "2023-09-29T17:03:53Z",
      "updated_at": "2026-01-23T01:55:03Z",
      "pushed_at": "2026-01-22T14:44:37Z",
      "open_issues": 344,
      "owner": {
        "login": "EasyTier",
        "avatar_url": "https://avatars.githubusercontent.com/u/169161851?v=4"
      },
      "readme": "# EasyTier\n\n[![Github release](https://img.shields.io/github/v/tag/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/releases)\n[![GitHub](https://img.shields.io/github/license/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/blob/main/LICENSE)\n[![GitHub last commit](https://img.shields.io/github/last-commit/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/commits/main)\n[![GitHub issues](https://img.shields.io/github/issues/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/issues)\n[![GitHub Core Actions](https://github.com/EasyTier/EasyTier/actions/workflows/core.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/core.yml)\n[![GitHub GUI Actions](https://github.com/EasyTier/EasyTier/actions/workflows/gui.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/gui.yml)\n[![GitHub Test Actions](https://github.com/EasyTier/EasyTier/actions/workflows/test.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/test.yml)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/EasyTier/EasyTier)\n\n[ÁÆÄ‰Ωì‰∏≠Êñá](/README_CN.md) | [English](/README.md)\n\n> ‚ú® A simple, secure, decentralized virtual private network solution powered by Rust and Tokio\n\n<p align=\"center\">\n<img src=\"assets/config-page.png\" width=\"300\" alt=\"config page\">\n<img src=\"assets/running-page.png\" width=\"300\" alt=\"running page\">\n</p>\n\nüìö **[Full Documentation](https://easytier.cn/en/)** | üñ•Ô∏è **[Web Console](https://easytier.cn/web)** | üìù **[Download Releases](https://github.com/EasyTier/EasyTier/releases)** | üß© **[Third Party Tools](https://easytier.cn/en/guide/installation_gui.html#third-party-graphical-interfaces)** | ‚ù§Ô∏è **[Sponsor](#sponsor)**\n\n## Features\n\n### Core Features\n\n- üîí **Decentralized**: Nodes are equal and independent, no centralized services required  \n- üöÄ **Easy to Use**: Multiple operation methods via web, client, and command line  \n- üåç **Cross-Platform**: Supports Win/MacOS/Linux/FreeBSD/Android and X86/ARM/MIPS architectures  \n- üîê **Secure**: AES-GCM or WireGuard encryption, prevents man-in-the-middle attacks  \n\n### Advanced Capabilities\n\n- üîå **Efficient NAT Traversal**: Supports UDP and IPv6 traversal, works with NAT4-NAT4 networks  \n- üåê **Subnet Proxy**: Nodes can share subnets for other nodes to access  \n- üîÑ **Intelligent Routing**: Latency priority and automatic route selection for best network experience  \n- ‚ö° **High Performance**: Zero-copy throughout the entire link, supports TCP/UDP/WSS/WG protocols  \n\n### Network Optimization\n\n- üìä **UDP Loss Resistance**: KCP/QUIC proxy optimizes latency and bandwidth in high packet loss environments  \n- üîß **Web Management**: Easy configuration and monitoring through web interface  \n- üõ†Ô∏è **Zero Config**: Simple deployment with statically linked executables  \n\n## Quick Start\n\n### üì• Installation\n\nChoose the installation method that best suits your needs:\n\n```bash\n# 1. Download pre-built binary (Recommended, All platforms supported)\n# Visit https://github.com/EasyTier/EasyTier/releases\n\n# 2. Install via cargo (Latest development version)\ncargo install --git https://github.com/EasyTier/EasyTier.git easytier\n\n# 3. Install via Docker\n# See https://easytier.cn/en/guide/installation.html#installation-methods\n\n# 4. Linux Quick Install\nwget -O- https://raw.githubusercontent.com/EasyTier/EasyTier/main/script/install.sh | sudo bash -s install\n\n# 5. MacOS via Homebrew\nbrew tap brewforge/chinese\nbrew install --cask easytier-gui\n\n# 6. OpenWrt Luci Web UI\n# Visit https://github.com/EasyTier/luci-app-easytier\n\n# 7. (Optional) Install shell completions:\neasytier-core --gen-autocomplete fish > ~/.config/fish/completions/easytier-core.fish\neasytier-cli gen-autocomplete fish > ~/.config/fish/completions/easytier-cli.fish\n\n```\n\n### üöÄ Basic Usage\n\n#### Quick Networking with Shared Nodes\n\nEasyTier supports quick networking using shared public nodes. When you don't have a public IP, you can use the free shared nodes provided by the EasyTier community. Nodes will automatically attempt NAT traversal and establish P2P connections. When P2P fails, data will be relayed through shared nodes.\n\nThe currently deployed shared public node is `tcp://public.easytier.cn:11010`.\n\nWhen using shared nodes, each node entering the network needs to provide the same `--network-name` and `--network-secret` parameters as the unique identifier of the network.\n\nTaking two nodes as an example (Please use more complex network name to avoid conflicts):\n\n1. Run on Node A:\n\n```bash\n# Run with administrator privileges\nsudo easytier-core -d --network-name abc --network-secret abc -p tcp://public.easytier.cn:11010\n```\n\n2. Run on Node B:\n\n```bash\n# Run with administrator privileges\nsudo easytier-core -d --network-name abc --network-secret abc -p tcp://public.easytier.cn:11010\n```\n\nAfter successful execution, you can check the network status using `easytier-cli`:\n\n```text\n| ipv4         | hostname       | cost  | lat_ms | loss_rate | rx_bytes | tx_bytes | tunnel_proto | nat_type | id         | version         |\n| ------------ | -------------- | ----- | ------ | --------- | -------- | -------- | ------------ | -------- | ---------- | --------------- |\n| 10.126.126.1 | abc-1          | Local | *      | *         | *        | *        | udp          | FullCone | 439804259  | 2.5.0-70e69a38~ |\n| 10.126.126.2 | abc-2          | p2p   | 3.452  | 0         | 17.33 kB | 20.42 kB | udp          | FullCone | 390879727  | 2.5.0-70e69a38~ |\n|              | PublicServer_a | p2p   | 27.796 | 0.000     | 50.01 kB | 67.46 kB | tcp          | Unknown  | 3771642457 | 2.5.0-70e69a38~ |\n```\n\nYou can test connectivity between nodes:\n\n```bash\n# Test connectivity\nping 10.126.126.1\nping 10.126.126.2\n```\n\nNote: If you cannot ping through, it may be that the firewall is blocking incoming traffic. Please turn off the firewall or add allow rules.\n\nTo improve availability, you can connect to multiple shared nodes simultaneously:\n\n```bash\n# Connect to multiple shared nodes\nsudo easytier-core -d --network-name abc --network-secret abc -p tcp://public.easytier.cn:11010 -p udp://public.easytier.cn:11010\n```\n\nOnce your network is set up successfully, you can easily configure it to start automatically on system boot. Refer to the [One-Click Register Service guide](https://easytier.cn/en/guide/network/oneclick-install-as-service.html) for step-by-step instructions on registering EasyTier as a system service.\n\n#### Decentralized Networking\n\nEasyTier is fundamentally decentralized, with no distinction between server and client. As long as one device can communicate with any node in the virtual network, it can join the virtual network. Here's how to set up a decentralized network:\n\n1. Start First Node (Node A):\n\n```bash\n# Start the first node\nsudo easytier-core -i 10.144.144.1\n```\n\nAfter startup, this node will listen on the following ports by default:\n- TCP: 11010\n- UDP: 11010\n- WebSocket: 11011\n- WebSocket SSL: 11012\n- WireGuard: 11013\n\n2. Connect Second Node (Node B):\n\n```bash\n# Connect to the first node using its public IP\nsudo easytier-core -i 10.144.144.2 -p udp://FIRST_NODE_PUBLIC_IP:11010\n```\n\n3. Verify Connection:\n\n```bash\n# Test connectivity\nping 10.144.144.2\n\n# View connected peers\neasytier-cli peer\n\n# View routing information\neasytier-cli route\n\n# View local node information\neasytier-cli node\n```\n\nFor more nodes to join the network, they can connect to any existing node in the network using the `-p` parameter:\n\n```bash\n# Connect to any existing node using its public IP\nsudo easytier-core -i 10.144.144.3 -p udp://ANY_EXISTING_NODE_PUBLIC_IP:11010\n```\n\n### üîç Advanced Features\n\n#### Subnet Proxy\n\nAssuming the network topology is as follows, Node B wants to share its accessible subnet 10.1.1.0/24 with other nodes:\n\n```mermaid\nflowchart LR\n\nsubgraph Node A Public IP 22.1.1.1\nnodea[EasyTier<br/>10.144.144.1]\nend\n\nsubgraph Node B\nnodeb[EasyTier<br/>10.144.144.2]\nend\n\nid1[[10.1.1.0/24]]\n\nnodea <--> nodeb <-.-> id1\n```\n\nTo share a subnet, add the `-n` parameter when starting EasyTier:\n\n```bash\n# Share subnet 10.1.1.0/24 with other nodes\nsudo easytier-core -i 10.144.144.2 -n 10.1.1.0/24\n```\n\nSubnet proxy information will automatically sync to each node in the virtual network, and each node will automatically configure the corresponding route. You can verify the subnet proxy setup:\n\n1. Check if the routing information has been synchronized (the proxy_cidrs column shows the proxied subnets):\n\n```bash\n# View routing information\neasytier-cli route\n```\n\n![Routing Information](/assets/image-3.png)\n\n2. Test if you can access nodes in the proxied subnet:\n\n```bash\n# Test connectivity to proxied subnet\nping 10.1.1.2\n```\n\n#### WireGuard Integration\n\nEasyTier can act as a WireGuard server, allowing any device with a WireGuard client (including iOS and Android) to access the EasyTier network. Here's an example setup:\n\n```mermaid\nflowchart LR\n\nios[[iPhone<br/>WireGuard Installed]]\n\nsubgraph Node A Public IP 22.1.1.1\nnodea[EasyTier<br/>10.144.144.1]\nend\n\nsubgraph Node B\nnodeb[EasyTier<br/>10.144.144.2]\nend\n\nid1[[10.1.1.0/24]]\n\nios <-.-> nodea <--> nodeb <-.-> id1\n```\n\n1. Start EasyTier with WireGuard portal enabled:\n\n```bash\n# Listen on 0.0.0.0:11013 and use 10.14.14.0/24 subnet for WireGuard clients\nsudo easytier-core -i 10.144.144.1 --vpn-portal wg://0.0.0.0:11013/10.14.14.0/24\n```\n\n2. Get WireGuard client configuration:\n\n```bash\n# Get WireGuard client configuration\neasytier-cli vpn-portal\n```\n\n3. In the output configuration:\n   - Set `Interface.Address` to an available IP from the WireGuard subnet\n   - Set `Peer.Endpoint` to the public IP/domain of your EasyTier node\n   - Import the modified configuration into your WireGuard client\n\n#### Self-Hosted Public Shared Node\n\nYou can run your own public shared node to help other nodes discover each other. A public shared node is just a regular EasyTier network (with same network name and secret) that other networks can connect to.\n\nTo run a public shared node:\n\n```bash\n# No need to specify IPv4 address for public shared nodes\nsudo easytier-core --network-name mysharednode --network-secret mysharednode\n```\n\n## Related Projects\n\n- [ZeroTier](https://www.zerotier.com/): A global virtual network for connecting devices.\n- [TailScale](https://tailscale.com/): A VPN solution aimed at simplifying network configuration.\n\n### Contact Us\n\n- üí¨ **[Telegram Group](https://t.me/easytier)**\n- üë• **[QQ Group]**\n  - No.1 [949700262](https://qm.qq.com/q/wFoTUChqZW)\n  - No.2 [837676408](https://qm.qq.com/q/4V33DrfgHe)\n  - No.3 [957189589](https://qm.qq.com/q/YNyTQjwlai)\n\n## License\n\nEasyTier is released under the [LGPL-3.0](https://github.com/EasyTier/EasyTier/blob/main/LICENSE).\n\n## Sponsor\n\nCDN acceleration and security protection for this project are sponsored by Tencent EdgeOne.\n\n<p align=\"center\">\n  <a href=\"https://edgeone.ai/?from=github\" target=\"_blank\">\n    <img src=\"assets/edgeone.png\" width=\"200\" alt=\"EdgeOne Logo\">\n  </a>\n</p>\n\nSpecial thanks to [Langlang Cloud](https://langlangy.cn/?i26c5a5)  and [RainCloud](https://www.rainyun.com/NjM0NzQ1_) for sponsoring our public servers.\n\n<p align=\"center\">\n<a href=\"https://langlangy.cn/?i26c5a5\" target=\"_blank\">\n<img src=\"assets/langlang.png\" width=\"200\">\n</a>\n<a href=\"https://langlangy.cn/?i26c5a5\" target=\"_blank\">\n<img src=\"assets/raincloud.png\" width=\"200\">\n</a>\n</p>\n\n\nIf you find EasyTier helpful, please consider sponsoring us. Software development and maintenance require a lot of time and effort, and your sponsorship will help us better maintain and improve EasyTier.\n\n<p align=\"center\">\n<img src=\"assets/wechat.png\" width=\"200\">\n<img src=\"assets/alipay.png\" width=\"200\">\n</p>\n",
      "stars_today": 16
    },
    {
      "id": 43441403,
      "name": "strapi",
      "full_name": "strapi/strapi",
      "description": "üöÄ Strapi is the leading open-source headless CMS. It‚Äôs 100% JavaScript/TypeScript, fully customizable, and developer-first.",
      "html_url": "https://github.com/strapi/strapi",
      "stars": 71049,
      "forks": 9385,
      "language": "TypeScript",
      "topics": [
        "api",
        "cms",
        "cms-framework",
        "content-management",
        "content-management-system",
        "customizable",
        "dashboard",
        "graphql",
        "hacktoberfest",
        "headless-cms",
        "jamstack",
        "javascript",
        "koa",
        "koa2",
        "mysql",
        "no-code",
        "nodejs",
        "rest",
        "strapi",
        "typescript"
      ],
      "created_at": "2015-09-30T15:34:48Z",
      "updated_at": "2026-01-23T01:37:16Z",
      "pushed_at": "2026-01-22T16:06:40Z",
      "open_issues": 753,
      "owner": {
        "login": "strapi",
        "avatar_url": "https://avatars.githubusercontent.com/u/19872173?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://strapi.io/#gh-light-mode-only\">\n    <img src=\"https://strapi.io/assets/strapi-logo-dark.svg\" width=\"318px\" alt=\"Strapi logo\" />\n  </a>\n  <a href=\"https://strapi.io/#gh-dark-mode-only\">\n    <img src=\"https://strapi.io/assets/strapi-logo-light.svg\" width=\"318px\" alt=\"Strapi logo\" />\n  </a>\n</p>\n\n<h3 align=\"center\">Open-source headless CMS, self-hosted or Cloud you‚Äôre in control.</h3>\n<p align=\"center\">The leading open-source headless CMS, 100% JavaScript/TypeScript, flexible and fully customizable.</p>\n<p align=\"center\"><a href=\"https://cloud.strapi.io/signups?source=github1\">Cloud</a> ¬∑ <a href=\"https://strapi.io/demo?utm_campaign=Growth-Experiments&utm_source=strapi%2Fstrapi%20README.md\">Try live demo</a></p>\n<br />\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.org/package/@strapi/strapi\">\n    <img src=\"https://img.shields.io/npm/v/@strapi/strapi/latest.svg\" alt=\"NPM Version\" />\n  </a>\n  <a href=\"https://github.com/strapi/strapi/actions/workflows/tests.yml\">\n    <img src=\"https://github.com/strapi/strapi/actions/workflows/tests.yml/badge.svg?branch=main\" alt=\"Tests\" />\n  </a>\n  <a href=\"https://discord.strapi.io\">\n    <img src=\"https://img.shields.io/discord/811989166782021633?label=Discord\" alt=\"Strapi on Discord\" />\n  </a>\n  <a href=\"https://github.com/strapi/strapi/actions/workflows/nightly.yml\">\n    <img src=\"https://github.com/strapi/strapi/actions/workflows/nightly.yml/badge.svg\" alt=\"Strapi Nightly Release Build Status\" />\n  </a>\n</p>\n\n<br>\n\n<p align=\"center\">\n  <a href=\"https://strapi.io\">\n    <img src=\"https://raw.githubusercontent.com/strapi/strapi/main/public/assets/admin-demo.gif\" alt=\"Administration panel\" />\n  </a>\n</p>\n\n<br>\n\nStrapi Community Edition is a free and open-source headless CMS enabling you to manage any content, anywhere.\n\n- **Self-hosted or Cloud**: You can host and scale Strapi projects the way you want. You can save time by deploying to [Strapi Cloud](https://cloud.strapi.io/signups?source=github1) or deploy to the hosting platform you want\\*\\*: AWS, Azure, Google Cloud, DigitalOcean.\n- **Modern Admin Panel**: Elegant, entirely customizable and a fully extensible admin panel.\n- **Multi-database support**: You can choose the database you prefer: PostgreSQL, MySQL, MariaDB, and SQLite.\n- **Customizable**: You can quickly build your logic by fully customizing APIs, routes, or plugins to fit your needs perfectly.\n- **Blazing Fast and Robust**: Built on top of Node.js and TypeScript, Strapi delivers reliable and solid performance.\n- **Front-end Agnostic**: Use any front-end framework (React, Next.js, Vue, Angular, etc.), mobile apps or even IoT.\n- **Secure by default**: Reusable policies, CORS, CSP, P3P, Xframe, XSS, and more.\n- **Powerful CLI**: Scaffold projects and APIs on the fly.\n\n## Getting Started\n\n<a href=\"https://docs.strapi.io/developer-docs/latest/getting-started/quick-start.html\" target=\"_blank\">Read the Getting Started tutorial</a> or follow the steps below:\n\n### ‚è≥ Installation\n\nUse the **Quickstart** command below to create a new Strapi project instantly:\n\n- We recommend using **yarn** to create a Strapi project.  \n  [View yarn installation docs](https://yarnpkg.com/lang/en/docs/install/).\n\n```bash\nyarn create strapi\n```\n\n**or**\n\n(Using npx to install the Latest Version Strapi project.)\n\n```bash\nnpx create-strapi@latest\n```\n\nThis command generates a brand new project with the default features (authentication, permissions, content management, content type builder & file upload).\n\nEnjoy üéâ\n\n### üñê Requirements\n\nComplete installation requirements can be found in the documentation under <a href=\"https://docs.strapi.io/developer-docs/latest/setup-deployment-guides/deployment.html\">Installation Requirements</a>.\n\n**Supported operating systems**:\n\n| OS              | Recommended | Minimum    |\n| --------------- | ----------- | ---------- |\n| Ubuntu          | 24.04       | LTS        |\n| Debian          | 11          | LTS        |\n| RHEL            | 9           | LTS        |\n| macOS           | 14          | 12         |\n| Windows Desktop | 11          | 10         |\n| Windows Server  | No Support  | No Support |\n| Docker          | N/A         | N/A        |\n\n(Please note that Strapi may work on other operating systems, but these are not tested nor officially supported at this time.)\n\n**Node:**\n\nStrapi only supports maintenance and LTS versions of Node.js. Please refer to the <a href=\"https://nodejs.org/en/about/releases/\">Node.js release schedule</a> for more information. NPM versions installed by default with Node.js are supported. Generally it's recommended to use yarn over npm where possible.\n\n| Strapi Version  | Recommended | Minimum |\n| --------------- | ----------- | ------- |\n| 5.31.0 and up   | 24.x        | 20.x    |\n| 5.0.0 to 5.30.1 | 20.x        | 18.x    |\n| 4.14.5 and up   | 20.x        | 18.x    |\n| 4.11.0 and up   | 18.x        | 16.x    |\n| 4.3.9 to 4.10.x | 18.x        | 14.x    |\n| 4.0.x to 4.3.8  | 16.x        | 14.x    |\n\n**Database:**\n\n| Database   | Recommended | Minimum |\n| ---------- | ----------- | ------- |\n| MySQL      | 8.0         | 8.0     |\n| MariaDB    | 11.2        | 10.3    |\n| PostgreSQL | 16.0        | 14.0    |\n| SQLite     | 3           | 3       |\n\n**We recommend always using the latest version of Strapi stable to start your new projects**.\n\n## Features\n\n- **Content Types Builder**: Build the most flexible publishing experience for your content managers, by giving them the freedom to create any page on the go with [fields](https://docs.strapi.io/user-docs/content-manager/writing-content#filling-up-fields), components and [Dynamic Zones](https://docs.strapi.io/user-docs/content-manager/writing-content#dynamic-zones).\n- **Media Library**: Upload your images, videos, audio or documents to the media library. Easily find the right asset, edit and reuse it.\n- **Internationalization**: The Internationalization (i18n) plugin allows Strapi users to create, manage and distribute localized content in different languages, called \"locales\"\n- **Role Based Access Control**: Create an unlimited number of custom roles and permissions for admin and end users.\n- **GraphQL or REST**: Consume the API using REST or GraphQL\n\nYou can unlock additional features such as SSO, Audit Logs, Review Workflows in [Strapi Cloud](https://cloud.strapi.io/login?source=github1) or [Strapi Enterprise](https://strapi.io/enterprise?source=github1).\n\n**[See more on our website](https://strapi.io/overview)**.\n\n## Contributing\n\nPlease read our [Contributing Guide](./CONTRIBUTING.md) before submitting a Pull Request to the project.\n\n## Community support\n\nFor general help using Strapi, please refer to [the official Strapi documentation](https://docs.strapi.io). For additional help, you can use one of these channels to ask a question:\n\n- [Discord](https://discord.strapi.io) (For live discussion with the Community and Strapi team)\n- [GitHub](https://github.com/strapi/strapi) (Bug reports, Contributions)\n- [Community Forum](https://forum.strapi.io) (Questions and Discussions)\n- [Feedback section](https://feedback.strapi.io) (Roadmap, Feature requests)\n- [Twitter](https://twitter.com/strapijs) (Get the news fast)\n- [Facebook](https://www.facebook.com/Strapi-616063331867161)\n- [YouTube Channel](https://www.youtube.com/strapi) (Learn from Video Tutorials)\n\n## Migration\n\nFollow our [migration guides](https://docs.strapi.io/developer-docs/latest/update-migration-guides/migration-guides.html) on the documentation to keep your projects up-to-date.\n\n## Roadmap\n\nCheck out our [roadmap](https://feedback.strapi.io) to get informed of the latest features released and the upcoming ones. You may also give us insights and vote for a specific feature.\n\n## Documentation\n\nSee our dedicated [repository](https://github.com/strapi/documentation) for the Strapi documentation, or view our documentation live:\n\n- [Developer docs](https://docs.strapi.io/developer-docs/latest/getting-started/introduction.html)\n- [User guide](https://docs.strapi.io/user-docs/latest/getting-started/introduction.html)\n- [Cloud guide](https://docs.strapi.io/cloud/intro)\n\n## Try live demo\n\nSee for yourself what's under the hood by getting access to a [hosted Strapi project](https://strapi.io/demo) with sample data.\n\n## License\n\nSee the [LICENSE](./LICENSE) file for licensing information.\n",
      "stars_today": 15
    },
    {
      "id": 19374812,
      "name": "tdesktop",
      "full_name": "telegramdesktop/tdesktop",
      "description": "Telegram Desktop messaging app",
      "html_url": "https://github.com/telegramdesktop/tdesktop",
      "stars": 29615,
      "forks": 6202,
      "language": "C++",
      "topics": [
        "messenger",
        "multi-platform",
        "telegram",
        "telegram-desktop",
        "telegram-solution"
      ],
      "created_at": "2014-05-02T12:36:31Z",
      "updated_at": "2026-01-23T01:43:39Z",
      "pushed_at": "2026-01-21T16:59:52Z",
      "open_issues": 936,
      "owner": {
        "login": "telegramdesktop",
        "avatar_url": "https://avatars.githubusercontent.com/u/6113871?v=4"
      },
      "readme": "# [Telegram Desktop][telegram_desktop] ‚Äì Official Messenger\n\nThis is the complete source code and the build instructions for the official [Telegram][telegram] messenger desktop client, based on the [Telegram API][telegram_api] and the [MTProto][telegram_proto] secure protocol.\n\n[![Version](https://badge.fury.io/gh/telegramdesktop%2Ftdesktop.svg)](https://github.com/telegramdesktop/tdesktop/releases)\n[![Build Status](https://github.com/telegramdesktop/tdesktop/workflows/Windows./badge.svg)](https://github.com/telegramdesktop/tdesktop/actions)\n[![Build Status](https://github.com/telegramdesktop/tdesktop/workflows/MacOS./badge.svg)](https://github.com/telegramdesktop/tdesktop/actions)\n[![Build Status](https://github.com/telegramdesktop/tdesktop/workflows/Linux./badge.svg)](https://github.com/telegramdesktop/tdesktop/actions)\n\n[![Preview of Telegram Desktop][preview_image]][preview_image_url]\n\nThe source code is published under GPLv3 with OpenSSL exception, the license is available [here][license].\n\n## Supported systems\n\nThe latest version is available for\n\n* [Windows 7 and above (64 bit)](https://telegram.org/dl/desktop/win64) ([portable](https://telegram.org/dl/desktop/win64_portable))\n* [Windows 7 and above (32 bit)](https://telegram.org/dl/desktop/win) ([portable](https://telegram.org/dl/desktop/win_portable))\n* [macOS 10.13 and above](https://telegram.org/dl/desktop/mac)\n* [Linux static build for 64 bit](https://telegram.org/dl/desktop/linux)\n* [Snap](https://snapcraft.io/telegram-desktop)\n* [Flatpak](https://flathub.org/apps/details/org.telegram.desktop)\n\n## Old system versions\n\nVersion **4.9.9** was the last that supports older systems\n\n* [macOS 10.12](https://updates.tdesktop.com/tmac/tsetup.4.9.9.dmg)\n* [Linux with glibc < 2.28 static build](https://updates.tdesktop.com/tlinux/tsetup.4.9.9.tar.xz)\n\nVersion **2.4.4** was the last that supports older systems\n\n* [OS X 10.10 and 10.11](https://updates.tdesktop.com/tosx/tsetup-osx.2.4.4.dmg)\n* [Linux static build for 32 bit](https://updates.tdesktop.com/tlinux32/tsetup32.2.4.4.tar.xz)\n\nVersion **1.8.15** was the last that supports older systems\n\n* [Windows XP and Vista](https://updates.tdesktop.com/tsetup/tsetup.1.8.15.exe) ([portable](https://updates.tdesktop.com/tsetup/tportable.1.8.15.zip))\n* [OS X 10.8 and 10.9](https://updates.tdesktop.com/tmac/tsetup.1.8.15.dmg)\n* [OS X 10.6 and 10.7](https://updates.tdesktop.com/tmac32/tsetup32.1.8.15.dmg)\n\n## Third-party\n\n* Qt 6 ([LGPL](http://doc.qt.io/qt-6/lgpl.html)) and Qt 5.15 ([LGPL](http://doc.qt.io/qt-5/lgpl.html)) slightly patched\n* OpenSSL 3.2.1 ([Apache License 2.0](https://www.openssl.org/source/apache-license-2.0.txt))\n* WebRTC ([New BSD License](https://github.com/desktop-app/tg_owt/blob/master/LICENSE))\n* zlib ([zlib License](http://www.zlib.net/zlib_license.html))\n* LZMA SDK 9.20 ([public domain](http://www.7-zip.org/sdk.html))\n* liblzma ([public domain](http://tukaani.org/xz/))\n* Google Breakpad ([License](https://chromium.googlesource.com/breakpad/breakpad/+/master/LICENSE))\n* Google Crashpad ([Apache License 2.0](https://chromium.googlesource.com/crashpad/crashpad/+/master/LICENSE))\n* GYP ([BSD License](https://github.com/bnoordhuis/gyp/blob/master/LICENSE))\n* Ninja ([Apache License 2.0](https://github.com/ninja-build/ninja/blob/master/COPYING))\n* OpenAL Soft ([LGPL](https://github.com/kcat/openal-soft/blob/master/COPYING))\n* Opus codec ([BSD License](http://www.opus-codec.org/license/))\n* FFmpeg ([LGPL](https://www.ffmpeg.org/legal.html))\n* Guideline Support Library ([MIT License](https://github.com/Microsoft/GSL/blob/master/LICENSE))\n* Range-v3 ([Boost License](https://github.com/ericniebler/range-v3/blob/master/LICENSE.txt))\n* Open Sans font ([Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0.html))\n* Vazirmatn font ([SIL Open Font License 1.1](https://github.com/rastikerdar/vazirmatn/blob/master/OFL.txt))\n* Emoji alpha codes ([MIT License](https://github.com/emojione/emojione/blob/master/extras/alpha-codes/LICENSE.md))\n* xxHash ([BSD License](https://github.com/Cyan4973/xxHash/blob/dev/LICENSE))\n* QR Code generator ([MIT License](https://github.com/nayuki/QR-Code-generator#license))\n* CMake ([New BSD License](https://github.com/Kitware/CMake/blob/master/Copyright.txt))\n* Hunspell ([LGPL](https://github.com/hunspell/hunspell/blob/master/COPYING.LESSER))\n* Ada ([Apache License 2.0](https://github.com/ada-url/ada/blob/main/LICENSE-APACHE))\n\n## Build instructions\n\n* Windows [(32-bit)][win32] [(64-bit)][win64]\n* [macOS][mac]\n* [GNU/Linux using Docker][linux]\n\n[//]: # (LINKS)\n[telegram]: https://telegram.org\n[telegram_desktop]: https://desktop.telegram.org\n[telegram_api]: https://core.telegram.org\n[telegram_proto]: https://core.telegram.org/mtproto\n[license]: LICENSE\n[win32]: docs/building-win.md\n[win64]: docs/building-win-x64.md\n[mac]: docs/building-mac.md\n[linux]: docs/building-linux.md\n[preview_image]: https://github.com/telegramdesktop/tdesktop/blob/dev/docs/assets/preview.png \"Preview of Telegram Desktop\"\n[preview_image_url]: https://raw.githubusercontent.com/telegramdesktop/tdesktop/dev/docs/assets/preview.png\n",
      "stars_today": 15
    },
    {
      "id": 337594329,
      "name": "SmsForwarder",
      "full_name": "pppscn/SmsForwarder",
      "description": "Áü≠‰ø°ËΩ¨ÂèëÂô®‚Äî‚ÄîÁõëÊéßAndroidÊâãÊú∫Áü≠‰ø°„ÄÅÊù•Áîµ„ÄÅAPPÈÄöÁü•ÔºåÂπ∂Ê†πÊçÆÊåáÂÆöËßÑÂàôËΩ¨ÂèëÂà∞ÂÖ∂‰ªñÊâãÊú∫ÔºöÈíâÈíâÁæ§Ëá™ÂÆö‰πâÊú∫Âô®‰∫∫„ÄÅÈíâÈíâ‰ºÅ‰∏öÂÜÖÊú∫Âô®‰∫∫„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Áæ§Êú∫Âô®‰∫∫„ÄÅÈ£û‰π¶Êú∫Âô®‰∫∫„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®Ê∂àÊÅØ„ÄÅÈÇÆÁÆ±„ÄÅbark„ÄÅwebhook„ÄÅTelegramÊú∫Âô®‰∫∫„ÄÅServerÈÖ±„ÄÅPushPlus„ÄÅÊâãÊú∫Áü≠‰ø°Á≠â„ÄÇÂåÖÊã¨‰∏ªÂä®ÊéßÂà∂ÊúçÂä°Á´Ø‰∏éÂÆ¢Êà∑Á´ØÔºåËÆ©‰Ω†ËΩªÊùæËøúÁ®ãÂèëÁü≠‰ø°„ÄÅÊü•Áü≠‰ø°„ÄÅÊü•ÈÄöËØù„ÄÅÊü•ËØùÁ∞ø„ÄÅÊü•ÁîµÈáèÁ≠â„ÄÇÔºàV3.0 Êñ∞Â¢ûÔºâPS.Ëøô‰∏™APK‰∏ªË¶ÅÊòØÂ≠¶‰π†‰∏éËá™Áî®ÔºåÂ¶ÇÊúâBUGËØ∑ÊèêISSUEÔºåÂêåÊó∂Ê¨¢ËøéÂ§ßÂÆ∂ÊèêPRÊåáÊ≠£",
      "html_url": "https://github.com/pppscn/SmsForwarder",
      "stars": 24242,
      "forks": 3092,
      "language": "Kotlin",
      "topics": [
        "android",
        "api",
        "app",
        "bark",
        "call",
        "chatgpt",
        "dingding",
        "forward",
        "mqtt",
        "pushdear",
        "pushplus",
        "serverchan",
        "sms",
        "smtp",
        "telegram",
        "webhook",
        "wechatapp"
      ],
      "created_at": "2021-02-10T02:23:07Z",
      "updated_at": "2026-01-23T01:07:25Z",
      "pushed_at": "2026-01-21T03:06:45Z",
      "open_issues": 41,
      "owner": {
        "login": "pppscn",
        "avatar_url": "https://avatars.githubusercontent.com/u/5105854?v=4"
      },
      "readme": "![SmsForwarder](pic/SmsForwarder.png)\r\n\r\n# SmsForwarder-Áü≠‰ø°ËΩ¨ÂèëÂô®\r\n\r\n[English Version](README_en.md)\r\n\r\n[![GitHub release](https://img.shields.io/github/release/pppscn/SmsForwarder.svg)](https://github.com/pppscn/SmsForwarder/releases) [![GitHub stars](https://img.shields.io/github/stars/pppscn/SmsForwarder)](https://github.com/pppscn/SmsForwarder/stargazers) [![GitHub forks](https://img.shields.io/github/forks/pppscn/SmsForwarder)](https://github.com/pppscn/SmsForwarder/network/members) [![GitHub issues](https://img.shields.io/github/issues/pppscn/SmsForwarder)](https://github.com/pppscn/SmsForwarder/issues) [![GitHub license](https://img.shields.io/github/license/pppscn/SmsForwarder)](https://github.com/pppscn/SmsForwarder/blob/main/LICENSE)\r\n\r\n--------\r\n\r\nÁü≠‰ø°ËΩ¨ÂèëÂô®‚Äî‚Äî‰∏ç‰ªÖÂè™ËΩ¨ÂèëÁü≠‰ø°ÔºåÂ§áÁî®Êú∫ÂøÖÂ§áÁ•ûÂô®ÔºÅ\r\n\r\nÁõëÊéßAndroidÊâãÊú∫Áü≠‰ø°„ÄÅÊù•Áîµ„ÄÅAPPÈÄöÁü•ÔºåÂπ∂Ê†πÊçÆÊåáÂÆöËßÑÂàôËΩ¨ÂèëÂà∞ÂÖ∂‰ªñÊâãÊú∫ÔºöÈíâÈíâÁæ§Ëá™ÂÆö‰πâÊú∫Âô®‰∫∫„ÄÅÈíâÈíâ‰ºÅ‰∏öÂÜÖÊú∫Âô®‰∫∫„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Áæ§Êú∫Âô®‰∫∫„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®Ê∂àÊÅØ„ÄÅÈ£û‰π¶Áæ§Êú∫Âô®‰∫∫„ÄÅÈ£û‰π¶‰ºÅ‰∏öÂ∫îÁî®„ÄÅÈÇÆÁÆ±„ÄÅbark„ÄÅwebhook„ÄÅTele****Êú∫Âô®‰∫∫„ÄÅServerÈÖ±„ÄÅPushPlus„ÄÅÊâãÊú∫Áü≠‰ø°Á≠â„ÄÇ\r\n\r\nÂåÖÊã¨‰∏ªÂä®ÊéßÂà∂ÊúçÂä°Á´Ø‰∏éÂÆ¢Êà∑Á´ØÔºåËÆ©‰Ω†ËΩªÊùæËøúÁ®ãÂèëÁü≠‰ø°„ÄÅÊü•Áü≠‰ø°„ÄÅÊü•ÈÄöËØù„ÄÅÊü•ËØùÁ∞ø„ÄÅÊü•ÁîµÈáèÁ≠â„ÄÇÔºàV3.0 Êñ∞Â¢ûÔºâ\r\n\r\nËá™Âä®‰ªªÂä°„ÉªÂø´Êç∑Êåá‰ª§ÔºåËΩªÊùæËá™Âä®ÂåñÔºåÂä©ÊÇ®‰∫ãÂçäÂäüÂÄçÔºåÊõ¥Â§öÊó∂Èó¥‰∫´Âèó‰∫≤ÊÉÖÈô™‰º¥ÔºÅÔºàv3.3 Êñ∞Â¢ûÔºâ\r\n\r\n> Ê≥®ÊÑèÔºö‰ªé`2022-06-06`ÂºÄÂßãÔºåÂéü`JavaÁâà`ÁöÑ‰ª£Á†ÅÂΩíÊ°£Âà∞`v2.x`ÂàÜÊîØÔºå‰∏çÂÜçÊõ¥Êñ∞ÔºÅ\r\n\r\n> `v3.x` ÈÄÇÈÖç Android 4.4 ~ 13.0\r\n\r\n> `Âä†ÂÖ•SmsFÈ¢ÑËßà‰ΩìÈ™åËÆ°Âàí`ÔºàÂú®Á∫øÊõ¥Êñ∞ÊØèÂë®ÊûÑÂª∫ÁâàÔºåÁéáÂÖà‰ΩìÈ™åÊñ∞Áâà&‰øÆÂ§çBUGÔºâ\r\n\r\n**ÂçáÁ∫ßÊìç‰ΩúÊèêÁ§∫Ôºö** \r\n- `Âä†ÂÖ•SmsFÈ¢ÑËßà‰ΩìÈ™åËÆ°Âàí`ÂêéÂú®Á∫øÊõ¥Êñ∞Ôºà`ÂÖ≥‰∫éËΩØ‰ª∂`È°µÈù¢ÂºÄÂêØÔºå`v3.3.0_240305+`ÈÄÇÁî®Ôºâ\r\n-  ÊâãÂä®‰∏ãËΩΩÔºöhttps://github.com/pppscn/SmsForwarder/actions/workflows/Weekly_Build.yml\r\n\r\n--------\r\n\r\n## ÁâπÂà´Â£∞Êòé:\r\n\r\n* Êú¨‰ªìÂ∫ìÂèëÂ∏ÉÁöÑ`SmsForwarder`È°πÁõÆ‰∏≠Ê∂âÂèäÁöÑ‰ªª‰Ωï‰ª£Á†Å/APKÔºå‰ªÖÁî®‰∫éÊµãËØïÂíåÂ≠¶‰π†Á†îÁ©∂ÔºåÁ¶ÅÊ≠¢Áî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºå‰∏çËÉΩ‰øùËØÅÂÖ∂ÂêàÊ≥ïÊÄßÔºåÂáÜÁ°ÆÊÄßÔºåÂÆåÊï¥ÊÄßÂíåÊúâÊïàÊÄßÔºåËØ∑Ê†πÊçÆÊÉÖÂÜµËá™Ë°åÂà§Êñ≠„ÄÇ\r\n\r\n* ‰ªª‰ΩïÁî®Êà∑Áõ¥Êé•ÊàñÈó¥Êé•‰ΩøÁî®Êàñ‰º†Êí≠`SmsForwarder`ÁöÑ‰ªª‰Ωï‰ª£Á†ÅÊàñAPKÔºåÊó†ËÆ∫ËØ•Á≠â‰ΩøÁî®ÊòØÂê¶Á¨¶ÂêàÂÖ∂ÊâÄÂú®ÂõΩÂÆ∂ÊàñÂú∞Âå∫ÔºåÊàñËØ•Á≠â‰ΩøÁî®Êàñ‰º†Êí≠ÂèëÁîüÁöÑÂõΩÂÆ∂ÊàñÂú∞Âå∫ÁöÑÊ≥ïÂæãÔºå`pppscn`Âíå/Êàñ‰ª£Á†Å‰ªìÂ∫ìÁöÑ‰ªª‰ΩïÂÖ∂‰ªñË¥°ÁåÆËÄÖÂùá‰∏çÂØπËØ•Á≠âË°å‰∏∫‰∫ßÁîüÁöÑ‰ªª‰ΩïÂêéÊûúÔºàÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÈöêÁßÅÊ≥ÑÈú≤ÔºâË¥üË¥£„ÄÇ\r\n\r\n* Â¶ÇÊûú‰ªª‰ΩïÂçï‰ΩçÊàñ‰∏™‰∫∫ËÆ§‰∏∫ËØ•È°πÁõÆÁöÑ‰ª£Á†Å/APKÂèØËÉΩÊ∂âÂ´å‰æµÁäØÂÖ∂ÊùÉÂà©ÔºåÂàôÂ∫îÂèäÊó∂ÈÄöÁü•Âπ∂Êèê‰æõË∫´‰ªΩËØÅÊòéÔºåÊâÄÊúâÊùÉËØÅÊòéÔºåÊàë‰ª¨Â∞ÜÂú®Êî∂Âà∞ËÆ§ËØÅÊñá‰ª∂ÂêéÂà†Èô§Áõ∏ÂÖ≥‰ª£Á†Å/APK„ÄÇ\r\n\r\n* ÈöêÁßÅÂ£∞ÊòéÔºö **SmsForwarder ‰∏ç‰ºöÊî∂ÈõÜ‰ªª‰ΩïÊÇ®ÁöÑÈöêÁßÅÊï∞ÊçÆÔºÅÔºÅÔºÅ** APPÂêØÂä®Êó∂ÂèëÈÄÅÁâàÊú¨‰ø°ÊÅØÂèëÈÄÅÂà∞ÂèãÁõüÁªüËÆ°ÔºõÊâãÂä®Ê£ÄÊü•Êñ∞ÁâàÊú¨Êó∂ÂèëÈÄÅÁâàÊú¨Âè∑Áî®‰∫éÊ£ÄÊü•Êñ∞ÁâàÊú¨ÔºõÈô§Ê≠§‰πãÂ§ñÔºåÊ≤°Êúâ‰ªª‰ΩïÊï∞ÊçÆÔºÅÔºÅÔºÅ\r\n\r\n* Èò≤ËØàÊèêÈÜíÔºö `SmsForwarder`ÂÆåÂÖ®ÂÖçË¥πÂºÄÊ∫êÔºåËØ∑ÊÇ®Âú® [ÊâìËµè](https://gitee.com/pp/SmsForwarder/wikis/pages?sort_id=4912193&doc_id=1821427) ÂâçÂä°ÂøÖÁ°ÆËÆ§ÊòØÂê¶Âá∫‰∫éËá™ÊÑøÔºüÊú¨È°πÁõÆ‰∏çÂèÇ‰∏é‰ªª‰ΩïÂà∑ÂçïËøîÂà©ÊãÖ‰øùÔºÅ**ËØ∑ÊÇ®ËøúÁ¶ªÂà∑ÂçïËøîÂà©Èô∑Èò±ÔºåË∞®Èò≤ÁΩëÁªúËØàÈ™óÔºÅ**\r\n\r\n--------\r\n\r\n## Â∑•‰ΩúÊµÅÁ®ãÔºö\r\n\r\n![Â∑•‰ΩúÊµÅÁ®ã](pic/working_principle.png \"working_principle.png\")\r\n\r\n--------\r\n\r\n## ÁïåÈù¢È¢ÑËßàÔºö\r\n\r\n![ÁïåÈù¢È¢ÑËßà](pic/screenshots.jpg \"screenshots.jpg\")\r\n\r\nÊõ¥Â§öÊà™ÂõæÂèÇËßÅ https://github.com/pppscn/SmsForwarder/wiki\r\n\r\n--------\r\n\r\n## ‰∏ãËΩΩÂú∞ÂùÄ\r\n\r\n> ‚ö† È¶ñÂèëÂú∞ÂùÄÔºöhttps://github.com/pppscn/SmsForwarder/releases\r\n\r\n> ‚ö† ÂõΩÂÜÖÈïúÂÉèÔºöhttps://gitee.com/pp/SmsForwarder/releases\r\n\r\n> ‚ö† ÁΩëÁõò‰∏ãËΩΩÔºöhttps://wws.lanzoui.com/b025yl86h ËÆøÈóÆÂØÜÁ†ÅÔºö`pppscn`\r\n\r\n--------\r\n\r\n## ‰ΩøÁî®ÊñáÊ°£„ÄêÊñ∞Áî®Êà∑ÂøÖÁúãÔºÅ„Äë\r\n\r\n> ‚ö† GitHub WikiÔºöhttps://github.com/pppscn/SmsForwarder/wiki\r\n\r\n> ‚ö† Gitee WikiÔºöhttps://gitee.com/pp/SmsForwarder/wikis/pages\r\n\r\n![‰ΩøÁî®ÊµÅÁ®ã‰∏éÈóÆÈ¢òÊéíÊü•ÊµÅÁ®ã](pic/Troubleshooting_Process.png \"Troubleshooting_Process.png\")\r\n\r\n--------\r\n\r\n## ÂèçÈ¶à‰∏éÂª∫ËÆÆÔºö\r\n\r\n+ Êèê‰∫§issues Êàñ pr\r\n+ Âä†ÂÖ•‰∫§ÊµÅÁæ§ÔºàÁæ§ÂÜÖÈÉΩÊòØÊú∫Ê≤π‰∫íÂ∏Æ‰∫íÂä©ÔºåÁ¶ÅÊ≠¢Âèë‰ªª‰Ωï‰∏éSmsForwarder‰ΩøÁî®Êó†ÂÖ≥ÁöÑÂÜÖÂÆπÔºâ\r\n\r\n|                      TG Group                       |\r\n|:---------------------------------------------------:|\r\n|         ![TG Group](pic/tg.png \"TG Group\")          |\r\n| [+QBZgnL_fxYM0NjE9](https://t.me/+QBZgnL_fxYM0NjE9) |\r\n\r\n## ÊÑüË∞¢\r\n\r\n> [ÊÑüË∞¢ÊâÄÊúâËµûÂä©Êú¨È°πÁõÆÁöÑÁÉ≠ÂøÉÁΩëÂèã --> ÊâìËµèÂêçÂçï](https://gitee.com/pp/SmsForwarder/wikis/pages?sort_id=4912193&doc_id=1821427)\r\n\r\n> Êú¨È°πÁõÆÂæóÂà∞‰ª•‰∏ãÈ°πÁõÆÁöÑÊîØÊåÅ‰∏éÂ∏ÆÂä©ÔºåÂú®Ê≠§Ë°®Á§∫Ë°∑ÂøÉÁöÑÊÑüË∞¢ÔºÅ\r\n\r\n+ https://github.com/xiaoyuanhost/TranspondSms (È°πÁõÆÂéüÂûã)\r\n+ https://github.com/xuexiangjys/XUI ÔºàUIÊ°ÜÊû∂Ôºâ\r\n+ https://github.com/xuexiangjys/XUpdate ÔºàÂú®Á∫øÂçáÁ∫ßÔºâ\r\n+ https://github.com/getActivity/XXPermissions (ÊùÉÈôêËØ∑Ê±ÇÊ°ÜÊû∂)\r\n+ https://github.com/mainfunx/frpc_android (ÂÜÖÁΩëÁ©øÈÄè)\r\n+ https://github.com/gyf-dev/Cactus (‰øùÊ¥ªÊé™ÊñΩ)\r\n+ https://github.com/yanzhenjie/AndServer (HttpServer)\r\n+ https://github.com/jenly1314/Location (Location)\r\n+ https://gitee.com/xuankaicat/kmnkt (socketÈÄö‰ø°)\r\n+ [<img src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg\" alt=\"GitHub license\" style=\"widthÔºö159px; height: 32px\" width=\"159\" height=\"32\" />](https://jb.gg/OpenSourceSupport)  (License Certificate for JetBrains All Products Pack)\r\n\r\n--------\r\n\r\n## Â¶ÇÊûúÊÇ®ËßâÂæóÊú¨Â∑•ÂÖ∑ÂØπÊÇ®ÊúâÂ∏ÆÂä©Ôºå‰∏çÂ¶®Âú®Âè≥‰∏äËßíÁÇπ‰∫Æ‰∏ÄÈ¢óÂ∞èÊòüÊòüÔºå‰ª•Á§∫ÈºìÂä±ÔºÅ\r\n\r\n<a href=\"https://star-history.com/#pppscn/SmsForwarder&Date\">\r\n  <picture>\r\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=pppscn/SmsForwarder&type=Date&theme=dark\" />\r\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=pppscn/SmsForwarder&type=Date\" />\r\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=pppscn/SmsForwarder&type=Date\" />\r\n  </picture>\r\n</a>\r\n\r\n--------\r\n\r\n## LICENSE\r\n\r\nBSD\r\n",
      "stars_today": 15
    },
    {
      "id": 100060912,
      "name": "terminal",
      "full_name": "microsoft/terminal",
      "description": "The new Windows Terminal and the original Windows console host, all in the same place!",
      "html_url": "https://github.com/microsoft/terminal",
      "stars": 101463,
      "forks": 9035,
      "language": "C++",
      "topics": [
        "cmd",
        "command-line",
        "console",
        "contributions-welcome",
        "good-first-issue",
        "hacktoberfest",
        "terminal",
        "windows",
        "windows-console",
        "windows-terminal",
        "wsl"
      ],
      "created_at": "2017-08-11T18:38:22Z",
      "updated_at": "2026-01-23T02:06:41Z",
      "pushed_at": "2026-01-22T23:16:30Z",
      "open_issues": 1696,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "![terminal-logos](https://github.com/microsoft/terminal/assets/91625426/333ddc76-8ab2-4eb4-a8c0-4d7b953b1179)\n\n[![Terminal Build Status](https://dev.azure.com/shine-oss/terminal/_apis/build/status%2FTerminal%20CI?branchName=main)](https://dev.azure.com/shine-oss/terminal/_build/latest?definitionId=1&branchName=main)\n\n# Welcome to the Windows Terminal, Console and Command-Line repo\n\n<details>\n  <summary><strong>Table of Contents</strong></summary>\n\n- [Installing and running Windows Terminal](#installing-and-running-windows-terminal)\n  - [Microsoft Store \\[Recommended\\]](#microsoft-store-recommended)\n  - [Other install methods](#other-install-methods)\n    - [Via GitHub](#via-github)\n    - [Via Windows Package Manager CLI (aka winget)](#via-windows-package-manager-cli-aka-winget)\n    - [Via Chocolatey (unofficial)](#via-chocolatey-unofficial)\n    - [Via Scoop (unofficial)](#via-scoop-unofficial)\n- [Installing Windows Terminal Canary](#installing-windows-terminal-canary)\n- [Windows Terminal Roadmap](#windows-terminal-roadmap)\n- [Terminal \\& Console Overview](#terminal--console-overview)\n  - [Windows Terminal](#windows-terminal)\n  - [The Windows Console Host](#the-windows-console-host)\n  - [Shared Components](#shared-components)\n  - [Creating the new Windows Terminal](#creating-the-new-windows-terminal)\n- [Resources](#resources)\n- [FAQ](#faq)\n  - [I built and ran the new Terminal, but it looks just like the old console](#i-built-and-ran-the-new-terminal-but-it-looks-just-like-the-old-console)\n- [Documentation](#documentation)\n- [Contributing](#contributing)\n- [Communicating with the Team](#communicating-with-the-team)\n- [Developer Guidance](#developer-guidance)\n- [Prerequisites](#prerequisites)\n- [Building the Code](#building-the-code)\n  - [Building in PowerShell](#building-in-powershell)\n  - [Building in Cmd](#building-in-cmd)\n- [Running \\& Debugging](#running--debugging)\n  - [Coding Guidance](#coding-guidance)\n- [Code of Conduct](#code-of-conduct)\n\n</details>\n\n<br />\n\nThis repository contains the source code for:\n\n* [Windows Terminal](https://aka.ms/terminal)\n* [Windows Terminal Preview](https://aka.ms/terminal-preview)\n* The Windows console host (`conhost.exe`)\n* Components shared between the two projects\n* [ColorTool](./src/tools/ColorTool)\n* [Sample projects](./samples)\n  that show how to consume the Windows Console APIs\n\nRelated repositories include:\n\n* [Windows Terminal Documentation](https://docs.microsoft.com/windows/terminal)\n  ([Repo: Contribute to the docs](https://github.com/MicrosoftDocs/terminal))\n* [Console API Documentation](https://github.com/MicrosoftDocs/Console-Docs)\n* [Cascadia Code Font](https://github.com/Microsoft/Cascadia-Code)\n\n## Installing and running Windows Terminal\n\n> [!NOTE]\n> Windows Terminal requires Windows 10 2004 (build 19041) or later\n\n### Microsoft Store [Recommended]\n\nInstall the [Windows Terminal from the Microsoft Store][store-install-link].\nThis allows you to always be on the latest version when we release new builds\nwith automatic upgrades.\n\nThis is our preferred method.\n\n### Other install methods\n\n#### Via GitHub\n\nFor users who are unable to install Windows Terminal from the Microsoft Store,\nreleased builds can be manually downloaded from this repository's [Releases\npage](https://github.com/microsoft/terminal/releases).\n\nDownload the `Microsoft.WindowsTerminal_<versionNumber>.msixbundle` file from\nthe **Assets** section. To install the app, you can simply double-click on the\n`.msixbundle` file, and the app installer should automatically run. If that\nfails for any reason, you can try the following command at a PowerShell prompt:\n\n```powershell\n# NOTE: If you are using PowerShell 7+, please run\n# Import-Module Appx -UseWindowsPowerShell\n# before using Add-AppxPackage.\n\nAdd-AppxPackage Microsoft.WindowsTerminal_<versionNumber>.msixbundle\n```\n\n> [!NOTE]\n> If you install Terminal manually:\n>\n> * You may need to install the [VC++ v14 Desktop Framework Package](https://docs.microsoft.com/troubleshoot/cpp/c-runtime-packages-desktop-bridge#how-to-install-and-update-desktop-framework-packages).\n>   This should only be necessary on older builds of Windows 10 and only if you get an error about missing framework packages.\n> * Terminal will not auto-update when new builds are released so you will need\n>   to regularly install the latest Terminal release to receive all the latest\n>   fixes and improvements!\n\n#### Via Windows Package Manager CLI (aka winget)\n\n[winget](https://github.com/microsoft/winget-cli) users can download and install\nthe latest Terminal release by installing the `Microsoft.WindowsTerminal`\npackage:\n\n```powershell\nwinget install --id Microsoft.WindowsTerminal -e\n```\n\n> [!NOTE]\n> Dependency support is available in WinGet version [1.6.2631 or later](https://github.com/microsoft/winget-cli/releases). To install the Terminal stable release 1.18 or later, please make sure you have the updated version of the WinGet client.\n\n#### Via Chocolatey (unofficial)\n\n[Chocolatey](https://chocolatey.org) users can download and install the latest\nTerminal release by installing the `microsoft-windows-terminal` package:\n\n```powershell\nchoco install microsoft-windows-terminal\n```\n\nTo upgrade Windows Terminal using Chocolatey, run the following:\n\n```powershell\nchoco upgrade microsoft-windows-terminal\n```\n\nIf you have any issues when installing/upgrading the package please go to the\n[Windows Terminal package\npage](https://chocolatey.org/packages/microsoft-windows-terminal) and follow the\n[Chocolatey triage process](https://chocolatey.org/docs/package-triage-process)\n\n#### Via Scoop (unofficial)\n\n[Scoop](https://scoop.sh) users can download and install the latest Terminal\nrelease by installing the `windows-terminal` package:\n\n```powershell\nscoop bucket add extras\nscoop install windows-terminal\n```\n\nTo update Windows Terminal using Scoop, run the following:\n\n```powershell\nscoop update windows-terminal\n```\n\nIf you have any issues when installing/updating the package, please search for\nor report the same on the [issues\npage](https://github.com/lukesampson/scoop-extras/issues) of Scoop Extras bucket\nrepository.\n\n---\n\n## Installing Windows Terminal Canary\nWindows Terminal Canary is a nightly build of Windows Terminal. This build has the latest code from our `main` branch, giving you an opportunity to try features before they make it to Windows Terminal Preview.\n\nWindows Terminal Canary is our least stable offering, so you may discover bugs before we have had a chance to find them.\n\nWindows Terminal Canary is available as an App Installer distribution and a Portable ZIP distribution.\n\nThe App Installer distribution supports automatic updates. Due to platform limitations, this installer only works on Windows 11.\n\nThe Portable ZIP distribution is a portable application. It will not automatically update and will not automatically check for updates. This portable ZIP distribution works on Windows 10 (19041+) and Windows 11.\n\n| Distribution  | Architecture    | Link                                                 |\n|---------------|:---------------:|------------------------------------------------------|\n| App Installer | x64, arm64, x86 | [Download](https://aka.ms/terminal-canary-installer) |\n| Portable ZIP  | x64             | [Download](https://aka.ms/terminal-canary-zip-x64)   |\n| Portable ZIP  | ARM64           | [Download](https://aka.ms/terminal-canary-zip-arm64) |\n| Portable ZIP  | x86             | [Download](https://aka.ms/terminal-canary-zip-x86)   |\n\n_Learn more about the [types of Windows Terminal distributions](https://learn.microsoft.com/windows/terminal/distributions)._\n\n---\n\n## Windows Terminal Roadmap\n\nThe plan for the Windows Terminal [is described here](/doc/roadmap-2023.md) and\nwill be updated as the project proceeds.\n\n## Terminal & Console Overview\n\nPlease take a few minutes to review the overview below before diving into the\ncode:\n\n### Windows Terminal\n\nWindows Terminal is a new, modern, feature-rich, productive terminal application\nfor command-line users. It includes many of the features most frequently\nrequested by the Windows command-line community including support for tabs, rich\ntext, globalization, configurability, theming & styling, and more.\n\nThe Terminal will also need to meet our goals and measures to ensure it remains\nfast and efficient, and doesn't consume vast amounts of memory or power.\n\n### The Windows Console Host\n\nThe Windows Console host, `conhost.exe`, is Windows' original command-line user\nexperience. It also hosts Windows' command-line infrastructure and the Windows\nConsole API server, input engine, rendering engine, user preferences, etc. The\nconsole host code in this repository is the actual source from which the\n`conhost.exe` in Windows itself is built.\n\nSince taking ownership of the Windows command-line in 2014, the team added\nseveral new features to the Console, including background transparency,\nline-based selection, support for [ANSI / Virtual Terminal\nsequences](https://en.wikipedia.org/wiki/ANSI_escape_code), [24-bit\ncolor](https://devblogs.microsoft.com/commandline/24-bit-color-in-the-windows-console/),\na [Pseudoconsole\n(\"ConPTY\")](https://devblogs.microsoft.com/commandline/windows-command-line-introducing-the-windows-pseudo-console-conpty/),\nand more.\n\nHowever, because Windows Console's primary goal is to maintain backward\ncompatibility, we have been unable to add many of the features the community\n(and the team) have been wanting for the last several years including tabs,\nunicode text, and emoji.\n\nThese limitations led us to create the new Windows Terminal.\n\n> You can read more about the evolution of the command-line in general, and the\n> Windows command-line specifically in [this accompanying series of blog\n> posts](https://devblogs.microsoft.com/commandline/windows-command-line-backgrounder/)\n> on the Command-Line team's blog.\n\n### Shared Components\n\nWhile overhauling Windows Console, we modernized its codebase considerably,\ncleanly separating logical entities into modules and classes, introduced some\nkey extensibility points, replaced several old, home-grown collections and\ncontainers with safer, more efficient [STL\ncontainers](https://docs.microsoft.com/en-us/cpp/standard-library/stl-containers?view=vs-2022),\nand made the code simpler and safer by using Microsoft's [Windows Implementation\nLibraries - WIL](https://github.com/Microsoft/wil).\n\nThis overhaul resulted in several of Console's key components being available\nfor re-use in any terminal implementation on Windows. These components include a\nnew DirectWrite-based text layout and rendering engine, a text buffer capable of\nstoring both UTF-16 and UTF-8, a VT parser/emitter, and more.\n\n### Creating the new Windows Terminal\n\nWhen we started planning the new Windows Terminal application, we explored and\nevaluated several approaches and technology stacks. We ultimately decided that\nour goals would be best met by continuing our investment in our C++ codebase,\nwhich would allow us to reuse several of the aforementioned modernized\ncomponents in both the existing Console and the new Terminal. Further, we\nrealized that this would allow us to build much of the Terminal's core itself as\na reusable UI control that others can incorporate into their own applications.\n\nThe result of this work is contained within this repo and delivered as the\nWindows Terminal application you can download from the Microsoft Store, or\n[directly from this repo's\nreleases](https://github.com/microsoft/terminal/releases).\n\n---\n\n## Resources\n\nFor more information about Windows Terminal, you may find some of these\nresources useful and interesting:\n\n* [Command-Line Blog](https://devblogs.microsoft.com/commandline)\n* [Command-Line Backgrounder Blog\n  Series](https://devblogs.microsoft.com/commandline/windows-command-line-backgrounder/)\n* Windows Terminal Launch: [Terminal \"Sizzle\n  Video\"](https://www.youtube.com/watch?v=8gw0rXPMMPE&list=PLEHMQNlPj-Jzh9DkNpqipDGCZZuOwrQwR&index=2&t=0s)\n* Windows Terminal Launch: [Build 2019\n  Session](https://www.youtube.com/watch?v=KMudkRcwjCw)\n* Run As Radio: [Show 645 - Windows Terminal with Richard\n  Turner](https://www.runasradio.com/Shows/Show/645)\n* Azure Devops Podcast: [Episode 54 - Kayla Cinnamon and Rich Turner on DevOps\n  on the Windows\n  Terminal](http://azuredevopspodcast.clear-measure.com/kayla-cinnamon-and-rich-turner-on-devops-on-the-windows-terminal-team-episode-54)\n* Microsoft Ignite 2019 Session: [The Modern Windows Command Line: Windows\n  Terminal -\n  BRK3321](https://myignite.techcommunity.microsoft.com/sessions/81329?source=sessions)\n\n---\n\n## FAQ\n\n### I built and ran the new Terminal, but it looks just like the old console\n\nCause: You're launching the incorrect solution in Visual Studio.\n\nSolution: Make sure you're building & deploying the `CascadiaPackage` project in\nVisual Studio.\n\n> [!NOTE]\n> `OpenConsole.exe` is just a locally-built `conhost.exe`, the classic\n> Windows Console that hosts Windows' command-line infrastructure. OpenConsole\n> is used by Windows Terminal to connect to and communicate with command-line\n> applications (via\n> [ConPty](https://devblogs.microsoft.com/commandline/windows-command-line-introducing-the-windows-pseudo-console-conpty/)).\n\n---\n\n## Documentation\n\nAll project documentation is located at [aka.ms/terminal-docs](https://aka.ms/terminal-docs). If you would like\nto contribute to the documentation, please submit a pull request on the [Windows\nTerminal Documentation repo](https://github.com/MicrosoftDocs/terminal).\n\n---\n\n## Contributing\n\nWe are excited to work alongside you, our amazing community, to build and\nenhance Windows Terminal\\!\n\n***BEFORE you start work on a feature/fix***, please read & follow our\n[Contributor's\nGuide](./CONTRIBUTING.md) to\nhelp avoid any wasted or duplicate effort.\n\n## Communicating with the Team\n\nThe easiest way to communicate with the team is via GitHub issues.\n\nPlease file new issues, feature requests and suggestions, but **DO search for\nsimilar open/closed preexisting issues before creating a new issue.**\n\nIf you would like to ask a question that you feel doesn't warrant an issue\n(yet), please reach out to us via Twitter:\n\n* Christopher Nguyen, Product Manager:\n  [@nguyen_dows](https://twitter.com/nguyen_dows)\n* Dustin Howett, Engineering Lead: [@dhowett](https://twitter.com/DHowett)\n* Mike Griese, Senior Developer: [@zadjii@mastodon.social](https://mastodon.social/@zadjii)\n* Carlos Zamora, Developer: [@cazamor_msft](https://twitter.com/cazamor_msft)\n* Pankaj Bhojwani, Developer\n* Leonard Hecker, Developer: [@LeonardHecker](https://twitter.com/LeonardHecker)\n\n## Developer Guidance\n\n## Prerequisites\n\nYou can configure your environment to build Terminal in one of two ways:\n\n### Using WinGet configuration file\n\nAfter cloning the repository, you can use a [WinGet configuration file](https://learn.microsoft.com/en-us/windows/package-manager/configuration/#use-a-winget-configuration-file-to-configure-your-machine)\nto set up your environment. The [default configuration file](.config/configuration.winget) installs Visual Studio 2022 Community & rest of the required tools. There are two other variants of the configuration file available in the [.config](.config) directory for Enterprise & Professional editions of Visual Studio 2022. To run the default configuration file, you can either double-click the file from explorer or run the following command:\n\n```powershell\nwinget configure .config\\configuration.winget\n```\n\n### Manual configuration\n\n* You must be running Windows 10 2004 (build >= 10.0.19041.0) or later to run\n  Windows Terminal\n* You must [enable Developer Mode in the Windows Settings\n  app](https://docs.microsoft.com/en-us/windows/uwp/get-started/enable-your-device-for-development)\n  to locally install and run Windows Terminal\n* You must have [PowerShell 7 or later](https://github.com/PowerShell/PowerShell/releases/latest) installed\n* You must have the [Windows 11 (10.0.22621.0)\n  SDK](https://developer.microsoft.com/en-us/windows/downloads/windows-sdk/)\n  installed\n* You must have at least [VS\n  2022](https://visualstudio.microsoft.com/downloads/) installed\n* You must install the following Workloads via the VS Installer. Note: Opening\n  the solution in VS 2022 will [prompt you to install missing components\n  automatically](https://devblogs.microsoft.com/setup/configure-visual-studio-across-your-organization-with-vsconfig/):\n  * Desktop Development with C++\n  * Universal Windows Platform Development\n  * **The following Individual Components**\n    * C++ (v143) Universal Windows Platform Tools\n* You must install the [.NET Framework Targeting Pack](https://docs.microsoft.com/dotnet/framework/install/guide-for-developers#to-install-the-net-framework-developer-pack-or-targeting-pack) to build test projects\n\n## Building the Code\n\nOpenConsole.slnx may be built from within Visual Studio or from the command-line\nusing a set of convenience scripts & tools in the **/tools** directory:\n\n### Building in PowerShell\n\n```powershell\nImport-Module .\\tools\\OpenConsole.psm1\nSet-MsBuildDevEnvironment\nInvoke-OpenConsoleBuild\n```\n\n### Building in Cmd\n\n```shell\n.\\tools\\razzle.cmd\nbcz\n```\n\n## Running & Debugging\n\nTo debug the Windows Terminal in VS, right click on `CascadiaPackage` (in the\nSolution Explorer) and go to properties. In the Debug menu, change \"Application\nprocess\" and \"Background task process\" to \"Native Only\".\n\nYou should then be able to build & debug the Terminal project by hitting\n<kbd>F5</kbd>. Make sure to select either the \"x64\" or the \"x86\" platform - the\nTerminal doesn't build for \"Any Cpu\" (because the Terminal is a C++ application,\nnot a C# one).\n\n> üëâ You will _not_ be able to launch the Terminal directly by running the\n> WindowsTerminal.exe. For more details on why, see\n> [#926](https://github.com/microsoft/terminal/issues/926),\n> [#4043](https://github.com/microsoft/terminal/issues/4043)\n\n### Coding Guidance\n\nPlease review these brief docs below about our coding practices.\n\n> üëâ If you find something missing from these docs, feel free to contribute to\n> any of our documentation files anywhere in the repository (or write some new\n> ones!)\n\nThis is a work in progress as we learn what we'll need to provide people in\norder to be effective contributors to our project.\n\n* [Coding Style](./doc/STYLE.md)\n* [Code Organization](./doc/ORGANIZATION.md)\n* [Exceptions in our legacy codebase](./doc/EXCEPTIONS.md)\n* [Helpful smart pointers and macros for interfacing with Windows in WIL](./doc/WIL.md)\n\n---\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of\nConduct][conduct-code]. For more information see the [Code of Conduct\nFAQ][conduct-FAQ] or contact [opencode@microsoft.com][conduct-email] with any\nadditional questions or comments.\n\n[conduct-code]: https://opensource.microsoft.com/codeofconduct/\n[conduct-FAQ]: https://opensource.microsoft.com/codeofconduct/faq/\n[conduct-email]: mailto:opencode@microsoft.com\n[store-install-link]: https://aka.ms/terminal\n",
      "stars_today": 14
    },
    {
      "id": 137078487,
      "name": "core",
      "full_name": "vuejs/core",
      "description": "üññ Vue.js is a progressive, incrementally-adoptable JavaScript framework for building UI on the web.",
      "html_url": "https://github.com/vuejs/core",
      "stars": 52786,
      "forks": 9033,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2018-06-12T13:49:36Z",
      "updated_at": "2026-01-23T01:52:28Z",
      "pushed_at": "2026-01-23T02:05:37Z",
      "open_issues": 1010,
      "owner": {
        "login": "vuejs",
        "avatar_url": "https://avatars.githubusercontent.com/u/6128107?v=4"
      },
      "readme": "# vuejs/core [![npm](https://img.shields.io/npm/v/vue.svg)](https://www.npmjs.com/package/vue) [![build status](https://github.com/vuejs/core/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/vuejs/core/actions/workflows/ci.yml) [![Download](https://img.shields.io/npm/dm/vue)](https://www.npmjs.com/package/vue)\n\n## Getting Started\n\nPlease follow the documentation at [vuejs.org](https://vuejs.org/)!\n\n## Sponsors\n\nVue.js is an MIT-licensed open source project with its ongoing development made possible entirely by the support of these awesome [backers](https://github.com/vuejs/core/blob/main/BACKERS.md). If you'd like to join them, please consider [ sponsoring Vue's development](https://vuejs.org/sponsor/).\n\n<p align=\"center\">\n  <h3 align=\"center\">Special Sponsor</h3>\n</p>\n\n<p align=\"center\">\n  <a target=\"_blank\" href=\"https://github.com/appwrite/appwrite\">\n  <img alt=\"special sponsor appwrite\" src=\"https://sponsors.vuejs.org/images/appwrite.svg\" width=\"300\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a target=\"_blank\" href=\"https://vuejs.org/sponsor/#current-sponsors\">\n    <img alt=\"sponsors\" src=\"https://sponsors.vuejs.org/sponsors.svg?v3\">\n  </a>\n</p>\n\n## Questions\n\nFor questions and support please use [the official forum](https://forum.vuejs.org) or [community chat](https://chat.vuejs.org/). The issue list of this repo is **exclusively** for bug reports and feature requests.\n\n## Issues\n\nPlease make sure to respect issue requirements and use [the new issue helper](https://new-issue.vuejs.org/) when opening an issue. Issues not conforming to the guidelines may be closed immediately.\n\n## Stay In Touch\n\n- [X](https://x.com/vuejs)\n- [Bluesky](https://bsky.app/profile/vuejs.org)\n- [Blog](https://blog.vuejs.org/)\n- [Job Board](https://vuejobs.com/?ref=vuejs)\n\n## Contribution\n\nPlease make sure to read the [Contributing Guide](https://github.com/vuejs/core/blob/main/.github/contributing.md) before making a pull request. If you have a Vue-related project/component/tool, add it with a pull request to [this curated list](https://github.com/vuejs/awesome-vue)!\n\nThank you to all the people who already contributed to Vue!\n\n<a href=\"https://github.com/vuejs/core/graphs/contributors\"><img src=\"https://opencollective.com/vuejs/contributors.svg?width=890&limit=500\" /></a>\n\n<sub>_Note: Showing the first 500 contributors only due to GitHub image size limitations_</sub>\n\n## License\n\n[MIT](https://opensource.org/licenses/MIT)\n\nCopyright (c) 2013-present, Yuxi (Evan) You\n",
      "stars_today": 14
    },
    {
      "id": 39840932,
      "name": "googletest",
      "full_name": "google/googletest",
      "description": "GoogleTest - Google Testing and Mocking Framework",
      "html_url": "https://github.com/google/googletest",
      "stars": 38115,
      "forks": 10676,
      "language": "C++",
      "topics": [],
      "created_at": "2015-07-28T15:07:53Z",
      "updated_at": "2026-01-22T18:37:44Z",
      "pushed_at": "2026-01-17T05:52:03Z",
      "open_issues": 506,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# GoogleTest\n\n### Announcements\n\n#### Documentation Updates\n\nOur documentation is now live on GitHub Pages at\nhttps://google.github.io/googletest/. We recommend browsing the documentation on\nGitHub Pages rather than directly in the repository.\n\n#### Release 1.17.0\n\n[Release 1.17.0](https://github.com/google/googletest/releases/tag/v1.17.0) is\nnow available.\n\nThe 1.17.x branch\n[requires at least C++17](https://opensource.google/documentation/policies/cplusplus-support#c_language_standard).\n\n#### Continuous Integration\n\nWe use Google's internal systems for continuous integration.\n\n#### Coming Soon\n\n*   We are planning to take a dependency on\n    [Abseil](https://github.com/abseil/abseil-cpp).\n\n## Welcome to **GoogleTest**, Google's C++ test framework!\n\nThis repository is a merger of the formerly separate GoogleTest and GoogleMock\nprojects. These were so closely related that it makes sense to maintain and\nrelease them together.\n\n### Getting Started\n\nSee the [GoogleTest User's Guide](https://google.github.io/googletest/) for\ndocumentation. We recommend starting with the\n[GoogleTest Primer](https://google.github.io/googletest/primer.html).\n\nMore information about building GoogleTest can be found at\n[googletest/README.md](googletest/README.md).\n\n## Features\n\n*   xUnit test framework: \\\n    Googletest is based on the [xUnit](https://en.wikipedia.org/wiki/XUnit)\n    testing framework, a popular architecture for unit testing\n*   Test discovery: \\\n    Googletest automatically discovers and runs your tests, eliminating the need\n    to manually register your tests\n*   Rich set of assertions: \\\n    Googletest provides a variety of assertions, such as equality, inequality,\n    exceptions, and more, making it easy to test your code\n*   User-defined assertions: \\\n    You can define your own assertions with Googletest, making it simple to\n    write tests that are specific to your code\n*   Death tests: \\\n    Googletest supports death tests, which verify that your code exits in a\n    certain way, making it useful for testing error-handling code\n*   Fatal and non-fatal failures: \\\n    You can specify whether a test failure should be treated as fatal or\n    non-fatal with Googletest, allowing tests to continue running even if a\n    failure occurs\n*   Value-parameterized tests: \\\n    Googletest supports value-parameterized tests, which run multiple times with\n    different input values, making it useful for testing functions that take\n    different inputs\n*   Type-parameterized tests: \\\n    Googletest also supports type-parameterized tests, which run with different\n    data types, making it useful for testing functions that work with different\n    data types\n*   Various options for running tests: \\\n    Googletest provides many options for running tests including running\n    individual tests, running tests in a specific order and running tests in\n    parallel\n\n## Supported Platforms\n\nGoogleTest follows Google's\n[Foundational C++ Support Policy](https://opensource.google/documentation/policies/cplusplus-support).\nSee\n[this table](https://github.com/google/oss-policies-info/blob/main/foundational-cxx-support-matrix.md)\nfor a list of currently supported versions of compilers, platforms, and build\ntools.\n\n## Who Is Using GoogleTest?\n\nIn addition to many internal projects at Google, GoogleTest is also used by the\nfollowing notable projects:\n\n*   The [Chromium projects](https://www.chromium.org/) (behind the Chrome\n    browser and Chrome OS).\n*   The [LLVM](https://llvm.org/) compiler.\n*   [Protocol Buffers](https://github.com/google/protobuf), Google's data\n    interchange format.\n*   The [OpenCV](https://opencv.org/) computer vision library.\n\n## Related Open Source Projects\n\n[GTest Runner](https://github.com/nholthaus/gtest-runner) is a Qt5 based\nautomated test-runner and Graphical User Interface with powerful features for\nWindows and Linux platforms.\n\n[GoogleTest UI](https://github.com/ospector/gtest-gbar) is a test runner that\nruns your test binary, allows you to track its progress via a progress bar, and\ndisplays a list of test failures. Clicking on one shows failure text. GoogleTest\nUI is written in C#.\n\n[GTest TAP Listener](https://github.com/kinow/gtest-tap-listener) is an event\nlistener for GoogleTest that implements the\n[TAP protocol](https://en.wikipedia.org/wiki/Test_Anything_Protocol) for test\nresult output. If your test runner understands TAP, you may find it useful.\n\n[gtest-parallel](https://github.com/google/gtest-parallel) is a test runner that\nruns tests from your binary in parallel to provide significant speed-up.\n\n[GoogleTest Adapter](https://marketplace.visualstudio.com/items?itemName=DavidSchuldenfrei.gtest-adapter)\nis a VS Code extension allowing to view GoogleTest in a tree view and run/debug\nyour tests.\n\n[C++ TestMate](https://github.com/matepek/vscode-catch2-test-adapter) is a VS\nCode extension allowing to view GoogleTest in a tree view and run/debug your\ntests.\n\n[Cornichon](https://pypi.org/project/cornichon/) is a small Gherkin DSL parser\nthat generates stub code for GoogleTest.\n\n## Contributing Changes\n\nPlease read\n[`CONTRIBUTING.md`](https://github.com/google/googletest/blob/main/CONTRIBUTING.md)\nfor details on how to contribute to this project.\n\nHappy testing!\n",
      "stars_today": 14
    },
    {
      "id": 37912398,
      "name": "nginx",
      "full_name": "nginx/nginx",
      "description": "The official NGINX Open Source repository.",
      "html_url": "https://github.com/nginx/nginx",
      "stars": 29158,
      "forks": 7732,
      "language": "C",
      "topics": [
        "content-cache",
        "http",
        "http2",
        "http3",
        "https",
        "load-balancer",
        "mail-proxy-server",
        "nginx",
        "quic",
        "reverse-proxy",
        "security",
        "tcp-proxy-server",
        "tls",
        "udp-proxy-server",
        "web-server"
      ],
      "created_at": "2015-06-23T10:26:27Z",
      "updated_at": "2026-01-22T18:27:56Z",
      "pushed_at": "2026-01-21T16:39:01Z",
      "open_issues": 330,
      "owner": {
        "login": "nginx",
        "avatar_url": "https://avatars.githubusercontent.com/u/1412239?v=4"
      },
      "readme": "<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/user-attachments/assets/9335b488-ffcc-4157-8364-2370a0b70ad0\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/user-attachments/assets/3a7eeb08-1133-47f5-859c-fad4f5a6a013\">\n  <img alt=\"NGINX Banner\">\n</picture>\n\n[![Project Status: Active ‚Äì The project has reached a stable, usable state and is being actively developed.](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)\n[![Community Forum](https://img.shields.io/badge/community-forum-009639?logo=discourse&link=https%3A%2F%2Fcommunity.nginx.org)](https://community.nginx.org)\n[![License](https://img.shields.io/badge/License-BSD%202--Clause-blue.svg)](/LICENSE)\n[![Code of Conduct](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](/CODE_OF_CONDUCT.md)\n\nNGINX (pronounced \"engine x\" or \"en-jin-eks\") is the world's most popular Web Server, high performance Load Balancer, Reverse Proxy, API Gateway and Content Cache.\n\nNGINX is free and open source software, distributed under the terms of a simplified [2-clause BSD-like license](LICENSE).\n\nEnterprise distributions, commercial support and training are available from [F5, Inc](https://www.f5.com/products/nginx).\n\n> [!IMPORTANT]\n> The goal of this README is to provide a basic, structured introduction to NGINX for novice users. Please refer to the [full NGINX documentation](https://nginx.org/en/docs/) for detailed information on [installing](https://nginx.org/en/docs/install.html), [building](https://nginx.org/en/docs/configure.html), [configuring](https://nginx.org/en/docs/dirindex.html), [debugging](https://nginx.org/en/docs/debugging_log.html), and more. These documentation pages also contain a more detailed [Beginners Guide](https://nginx.org/en/docs/beginners_guide.html), How-Tos, [Development guide](https://nginx.org/en/docs/dev/development_guide.html), and a complete module and [directive reference](https://nginx.org/en/docs/dirindex.html).\n\n# Table of contents\n- [How it works](#how-it-works)\n  - [Modules](#modules)\n  - [Configurations](#configurations)\n  - [Runtime](#runtime)\n- [Downloading and installing](#downloading-and-installing)\n  - [Stable and Mainline binaries](#stable-and-mainline-binaries)\n  - [Linux binary installation process](#linux-binary-installation-process)\n  - [FreeBSD installation process](#freebsd-installation-process)\n  - [Windows executables](#windows-executables)\n  - [Dynamic modules](#dynamic-modules)\n- [Getting started with NGINX](#getting-started-with-nginx)\n  - [Installing SSL certificates and enabling TLS encryption](#installing-ssl-certificates-and-enabling-tls-encryption)\n  - [Load Balancing](#load-balancing)\n  - [Rate limiting](#rate-limiting)\n  - [Content caching](#content-caching)\n- [Building from source](#building-from-source)\n  - [Installing dependencies](#installing-dependencies)\n  - [Cloning the NGINX GitHub repository](#cloning-the-nginx-github-repository)\n  - [Configuring the build](#configuring-the-build)\n  - [Compiling](#compiling)\n  - [Location of binary and installation](#location-of-binary-and-installation)\n  - [Running and testing the installed binary](#running-and-testing-the-installed-binary)\n- [Asking questions and reporting issues](#asking-questions-and-reporting-issues)\n- [Contributing code](#contributing-code)\n- [Additional help and resources](#additional-help-and-resources)\n- [Changelog](#changelog)\n- [License](#license)\n\n# How it works\nNGINX is installed software with binary packages available for all major operating systems and Linux distributions. See [Tested OS and Platforms](https://nginx.org/en/#tested_os_and_platforms) for a full list of compatible systems.\n\n> [!IMPORTANT]\n> While nearly all popular Linux-based operating systems are distributed with a community version of nginx, we highly advise installation and usage of official [packages](https://nginx.org/en/linux_packages.html) or sources from this repository. Doing so ensures that you're using the most recent release or source code, including the latest feature-set, fixes and security patches.\n\n## Modules\nNGINX is comprised of individual modules, each extending core functionality by providing additional, configurable features. See \"Modules reference\" at the bottom of [nginx documentation](https://nginx.org/en/docs/) for a complete list of official modules.\n\nNGINX modules can be built and distributed as static or dynamic modules. Static modules are defined at build-time, compiled, and distributed in the resulting binaries. See [Dynamic Modules](#dynamic-modules) for more information on how they work, as well as, how to obtain, install, and configure them.\n\n> [!TIP]\n> You can issue the following command to see which static modules your NGINX binaries were built with:\n```bash\nnginx -V\n```\n> See [Configuring the build](#configuring-the-build) for information on how to include specific Static modules into your nginx build.\n\n## Configurations\nNGINX is highly flexible and configurable. Provisioning the software is achieved via text-based config file(s) accepting parameters called \"[Directives](https://nginx.org/en/docs/dirindex.html)\". See [Configuration File's Structure](https://nginx.org/en/docs/beginners_guide.html#conf_structure) for a comprehensive description of how NGINX configuration files work.\n\n> [!NOTE]\n> The set of directives available to your distribution of NGINX is dependent on which [modules](#modules) have been made available to it.\n\n## Runtime\nRather than running in a single, monolithic process, NGINX is architected to scale beyond Operating System process limitations by operating as a collection of processes. They include:\n- A \"master\" process that maintains worker processes, as well as, reads and evaluates configuration files.\n- One or more \"worker\" processes that process data (eg. HTTP requests).\n\nThe number of [worker processes](https://nginx.org/en/docs/ngx_core_module.html#worker_processes) is defined in the configuration file and may be fixed for a given configuration or automatically adjusted to the number of available CPU cores. In most cases, the latter option optimally balances load across available system resources, as NGINX is designed to efficiently distribute work across all worker processes.\n\n> [!TIP]\n> Processes synchronize data through shared memory. For this reason, many NGINX directives require the allocation of shared memory zones. As an example, when configuring [rate limiting](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req), connecting clients may need to be tracked in a [common memory zone](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req_zone) so all worker processes can know how many times a particular client has accessed the server in a span of time.\n\n# Downloading and installing\nFollow these steps to download and install precompiled NGINX binaries. You may also choose to [build NGINX locally from source code](#building-from-source).\n\n## Stable and Mainline binaries\nNGINX binaries are built and distributed in two versions: stable and mainline. Stable binaries are built from stable branches and only contain critical fixes backported from the mainline version. Mainline binaries are built from the [master branch](https://github.com/nginx/nginx/tree/master) and contain the latest features and bugfixes. You'll need to [decide which is appropriate for your purposes](https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/#choosing-between-a-stable-or-a-mainline-version).\n\n## Linux binary installation process\nThe NGINX binary installation process takes advantage of package managers native to specific Linux distributions. For this reason, first-time installations involve adding the official NGINX package repository to your system's package manager. Follow [these steps](https://nginx.org/en/linux_packages.html) to download, verify, and install NGINX binaries using the package manager appropriate for your Linux distribution.\n\n### Upgrades\nFuture upgrades to the latest version can be managed using the same package manager without the need to manually download and verify binaries.\n\n## FreeBSD installation process\nFor more information on installing NGINX on FreeBSD system, visit https://nginx.org/en/docs/install.html\n\n## Windows executables\nWindows executables for mainline and stable releases can be found on the main [NGINX download page](https://nginx.org/en/download.html). Note that the current implementation of NGINX for Windows is at the Proof-of-Concept stage and should only be used for development and testing purposes. For additional information, please see [nginx for Windows](https://nginx.org/en/docs/windows.html).\n\n## Dynamic modules\nNGINX version 1.9.11 added support for [Dynamic Modules](https://nginx.org/en/docs/ngx_core_module.html#load_module). Unlike Static modules, dynamically built modules can be downloaded, installed, and configured after the core NGINX binaries have been built. [Official dynamic module binaries](https://nginx.org/en/linux_packages.html#dynmodules) are available from the same package repository as the core NGINX binaries described in previous steps.\n\n> [!TIP]\n> [NGINX JavaScript (njs)](https://github.com/nginx/njs), is a popular NGINX dynamic module that enables the extension of core NGINX functionality using familiar JavaScript syntax.\n\n> [!IMPORTANT]\n> If desired, dynamic modules can also be built statically into NGINX at compile time.\n\n# Getting started with NGINX\nFor a gentle introduction to NGINX basics, please see our [Beginner‚Äôs Guide](https://nginx.org/en/docs/beginners_guide.html).\n\n## Installing SSL certificates and enabling TLS encryption\nSee [Configuring HTTPS servers](https://nginx.org/en/docs/http/configuring_https_servers.html) for a quick guide on how to enable secure traffic to your NGINX installation.\n\n## Load Balancing\nFor a quick start guide on configuring NGINX as a Load Balancer, please see [Using nginx as HTTP load balancer](https://nginx.org/en/docs/http/load_balancing.html).\n\n## Rate limiting\nSee our [Rate Limiting with NGINX](https://blog.nginx.org/blog/rate-limiting-nginx) blog post for an overview of core concepts for provisioning NGINX as an API Gateway.\n\n## Content caching\nSee [A Guide to Caching with NGINX and NGINX Plus](https://blog.nginx.org/blog/nginx-caching-guide) blog post for an overview of how to use NGINX as a content cache (e.g. edge server of a content delivery network).\n\n# Building from source\nThe following steps can be used to build NGINX from source code available in this repository.\n\n## Installing dependencies\nMost Linux distributions will require several dependencies to be installed in order to build NGINX. The following instructions are specific to the `apt` package manager, widely available on most Ubuntu/Debian distributions and their derivatives.\n\n> [!TIP]\n> It is always a good idea to update your package repository lists prior to installing new packages.\n> ```bash\n> sudo apt update\n> ```\n\n### Installing compiler and make utility\nUse the following command to install the GNU C compiler and Make utility.\n\n```bash\nsudo apt install gcc make\n```\n\n### Installing dependency libraries\n\n```bash\nsudo apt install libpcre3-dev zlib1g-dev\n```\n\n> [!WARNING]\n> This is the minimal set of dependency libraries needed to build NGINX with rewriting and gzip capabilities. Other dependencies may be required if you choose to build NGINX with additional modules. Monitor the output of the `configure` command discussed in the following sections for information on which modules may be missing. For example, if you plan to use SSL certificates to encrypt traffic with TLS, you'll need to install the OpenSSL library. To do so, issue the following command.\n\n>```bash\n>sudo apt install libssl-dev\n\n## Cloning the NGINX GitHub repository\nUsing your preferred method, clone the NGINX repository into your development directory. See [Cloning a GitHub Repository](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository) for additional help.\n\n```bash\ngit clone https://github.com/nginx/nginx.git\n```\n\n## Configuring the build\nPrior to building NGINX, you must run the `configure` script with [appropriate flags](https://nginx.org/en/docs/configure.html). This will generate a Makefile in your NGINX source root directory that can then be used to compile NGINX with [options specified during configuration](https://nginx.org/en/docs/configure.html).\n\nFrom the NGINX source code repository's root directory:\n\n```bash\nauto/configure\n```\n\n> [!IMPORTANT]\n> Configuring the build without any flags will compile NGINX with the default set of options. Please refer to https://nginx.org/en/docs/configure.html for a full list of available build configuration options.\n\n## Compiling\nThe `configure` script will generate a `Makefile` in the NGINX source root directory upon successful execution. To compile NGINX into a binary, issue the following command from that same directory:\n\n```bash\nmake\n```\n\n## Location of binary and installation\nAfter successful compilation, a binary will be generated at `<NGINX_SRC_ROOT_DIR>/objs/nginx`. To install this binary, issue the following command from the source root directory:\n\n```bash\nsudo make install\n```\n\n> [!IMPORTANT]\n> The binary will be installed into the `/usr/local/nginx/` directory.\n\n## Running and testing the installed binary\nTo run the installed binary, issue the following command:\n\n```bash\nsudo /usr/local/nginx/sbin/nginx\n```\n\nYou may test NGINX operation using `curl`.\n\n```bash\ncurl localhost\n```\n\nThe output of which should start with:\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n```\n\n# Asking questions and reporting issues\nSee our [Support](SUPPORT.md) guidelines for information on how discuss the codebase, ask troubleshooting questions, and report issues.\n\n# Contributing code\nPlease see the [Contributing](CONTRIBUTING.md) guide for information on how to contribute code.\n\n# Additional help and resources\n- See the [NGINX Community Blog](https://blog.nginx.org/) for more tips, tricks and HOW-TOs related to NGINX and related projects.\n- Access [nginx.org](https://nginx.org/), your go-to source for all documentation, information and software related to the NGINX suite of projects.\n\n# Changelog\nSee our [changelog](https://nginx.org/en/CHANGES) to keep track of updates.\n\n# License\n[2-clause BSD-like license](LICENSE)\n\n---\nAdditional documentation available at: https://nginx.org/en/docs\n",
      "stars_today": 14
    },
    {
      "id": 391055597,
      "name": "DSA-Bootcamp-Java",
      "full_name": "kunal-kushwaha/DSA-Bootcamp-Java",
      "description": "This repository consists of the code samples, assignments, and notes for the Java data structures & algorithms + interview preparation bootcamp of WeMakeDevs.",
      "html_url": "https://github.com/kunal-kushwaha/DSA-Bootcamp-Java",
      "stars": 21675,
      "forks": 12991,
      "language": "Java",
      "topics": [
        "algorithms",
        "competitive-programming",
        "data-structures",
        "faang-interview",
        "faang-preparation",
        "faang-questions",
        "google-interview",
        "interview-preparation",
        "java",
        "leetcode",
        "leetcode-java",
        "leetcode-solutions",
        "math"
      ],
      "created_at": "2021-07-30T12:23:25Z",
      "updated_at": "2026-01-23T01:38:22Z",
      "pushed_at": "2024-08-18T08:21:57Z",
      "open_issues": 629,
      "owner": {
        "login": "kunal-kushwaha",
        "avatar_url": "https://avatars.githubusercontent.com/u/42698533?v=4"
      },
      "readme": "# DSA + Interview preparation bootcamp\n- Subscribe to the [YouTube channel](https://www.youtube.com/KunalKushwaha?sub_confirmation=1)\n- [Lectures](https://www.youtube.com/playlist?list=PL9gnSGHSqcnr_DxHsP7AW9ftq0AtAyYqJ)\n- [Course website](https://www.techwithkunal.com/courses/dsa)\n- [Assignments](https://github.com/kunal-kushwaha/DSA-Bootcamp-Java/tree/main/assignments) (solutions can be found on LeetCode)\n",
      "stars_today": 14
    },
    {
      "id": 65899476,
      "name": "esp-idf",
      "full_name": "espressif/esp-idf",
      "description": "Espressif IoT Development Framework. Official development framework for Espressif SoCs.",
      "html_url": "https://github.com/espressif/esp-idf",
      "stars": 17149,
      "forks": 8073,
      "language": "C",
      "topics": [],
      "created_at": "2016-08-17T10:40:35Z",
      "updated_at": "2026-01-22T23:24:30Z",
      "pushed_at": "2026-01-22T20:32:58Z",
      "open_issues": 1526,
      "owner": {
        "login": "espressif",
        "avatar_url": "https://avatars.githubusercontent.com/u/9460735?v=4"
      },
      "readme": "# Espressif IoT Development Framework\n\n* [‰∏≠ÊñáÁâà](./README_CN.md)\n\nESP-IDF is the development framework for Espressif SoCs supported on Windows, Linux and macOS.\n\n# ESP-IDF Release Support Schedule\n\n![Support Schedule](https://dl.espressif.com/dl/esp-idf/support-periods.svg?v=1)\n\n- Please read [the support policy](SUPPORT_POLICY.md) and [the documentation](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/versions.html) for more information about ESP-IDF versions.\n- Please see the [End-of-Life Advisories](https://www.espressif.com/en/support/documents/advisories?keys=&field_type_of_advisory_tid%5B%5D=817) for information about ESP-IDF releases with discontinued support.\n\n# ESP-IDF Release and SoC Compatibility\n\n![Chip support](https://dl.espressif.com/dl/esp-idf/chip-support.svg?v=1)\n\nSee [Compatibility Between ESP-IDF Releases and Revisions of Espressif SoCs](https://github.com/espressif/esp-idf/blob/master/COMPATIBILITY.md) for the details of the compatibility between ESP-IDF and chip revisions.\n\nEspressif SoCs released before 2016 (ESP8266 and ESP8285) are supported by [RTOS SDK](https://github.com/espressif/ESP8266_RTOS_SDK) instead.\n\n# Developing With ESP-IDF\n\n## Setting Up ESP-IDF\n\nSee https://idf.espressif.com/ for links to detailed instructions on how to set up the ESP-IDF depending on chip you use.\n\n**Note:** Each SoC series and each ESP-IDF release has its own documentation. Please see Section [Versions](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/versions.html) on how to find documentation and how to checkout specific release of ESP-IDF.\n\n### Non-GitHub forks\n\nESP-IDF uses relative locations as its submodules URLs ([.gitmodules](.gitmodules)). So they link to GitHub. If ESP-IDF is forked to a Git repository which is not on GitHub, you will need to run the script [tools/set-submodules-to-github.sh](tools/set-submodules-to-github.sh) after git clone.\n\nThe script sets absolute URLs for all submodules, allowing `git submodule update --init --recursive` to complete. If cloning ESP-IDF from GitHub, this step is not needed.\n\n## Finding a Project\n\nAs well as the [esp-idf-template](https://github.com/espressif/esp-idf-template) project mentioned in Getting Started, ESP-IDF comes with some example projects in the [examples](examples) directory.\n\nOnce you've found the project you want to work with, change to its directory and you can configure and build it.\n\nTo start your own project based on an example, copy the example project directory outside of the ESP-IDF directory.\n\n# Quick Reference\n\nSee the Getting Started guide links above for a detailed setup guide. This is a quick reference for common commands when working with ESP-IDF projects:\n\n## Setup Build Environment\n\n(See the Getting Started guide listed above for a full list of required steps with more details.)\n\n* Install host build dependencies mentioned in the Getting Started guide.\n* Run the install script to set up the build environment. The options include `install.bat` or `install.ps1` for Windows, and `install.sh` or `install.fish` for Unix shells.\n* Run the export script on Windows (`export.bat`) or source it on Unix (`source export.sh`) in every shell environment before using ESP-IDF.\n\n## Configuring the Project\n\n* `idf.py set-target <chip_name>` sets the target of the project to `<chip_name>`. Run `idf.py set-target` without any arguments to see a list of supported targets.\n* `idf.py menuconfig` opens a text-based configuration menu where you can configure the project.\n\n## Compiling the Project\n\n`idf.py build`\n\n... will compile app, bootloader and generate a partition table based on the config.\n\n## Flashing the Project\n\nWhen the build finishes, it will print a command line to use `esptool` to flash the chip. However you can also do this automatically by running:\n\n`idf.py -p PORT flash`\n\nReplace PORT with the name of your serial port (like `COM3` on Windows, `/dev/ttyUSB0` on Linux, or `/dev/cu.usbserial-X` on MacOS. If the `-p` option is left out, `idf.py flash` will try to flash the first available serial port.\n\nThis will flash the entire project (app, bootloader and partition table) to a new chip. The settings for serial port flashing can be configured with `idf.py menuconfig`.\n\nYou don't need to run `idf.py build` before running `idf.py flash`, `idf.py flash` will automatically rebuild anything which needs it.\n\n## Viewing Serial Output\n\nThe `idf.py monitor` target uses the [esp-idf-monitor tool](https://github.com/espressif/esp-idf-monitor) to display serial output from Espressif SoCs. esp-idf-monitor also has a range of features to decode crash output and interact with the device. [Check the documentation page for details](https://docs.espressif.com/projects/esp-idf/en/latest/get-started/idf-monitor.html).\n\nExit the monitor by typing Ctrl-].\n\nTo build, flash and monitor output in one pass, you can run:\n\n`idf.py flash monitor`\n\n## Compiling & Flashing Only the App\n\nAfter the initial flash, you may just want to build and flash just your app, not the bootloader and partition table:\n\n* `idf.py app` - build just the app.\n* `idf.py app-flash` - flash just the app.\n\n`idf.py app-flash` will automatically rebuild the app if any source files have changed.\n\n(In normal development there's no downside to reflashing the bootloader and partition table each time, if they haven't changed.)\n\n## Erasing Flash\n\nThe `idf.py flash` target does not erase the entire flash contents. However it is sometimes useful to set the device back to a totally erased state, particularly when making partition table changes or OTA app updates. To erase the entire flash, run `idf.py erase-flash`.\n\nThis can be combined with other targets, ie `idf.py -p PORT erase-flash flash` will erase everything and then re-flash the new app, bootloader and partition table.\n\n# Resources\n\n* Documentation for the latest version: https://docs.espressif.com/projects/esp-idf/. This documentation is built from the [docs directory](docs) of this repository.\n\n* [Beginner's Guide to Key Concepts and Resources of ESP-IDF](https://youtu.be/J8zc8mMNKtc?feature=shared)\n\n* The [esp32.com forum](https://esp32.com/) is a place to ask questions and find community resources.\n\n* [Check the Issues section on github](https://github.com/espressif/esp-idf/issues) if you find a bug or have a feature request. Please check existing Issues before opening a new one.\n\n* If you're interested in contributing to ESP-IDF, please check the [Contributions Guide](https://docs.espressif.com/projects/esp-idf/en/latest/contribute/index.html).\n",
      "stars_today": 14
    },
    {
      "id": 868065564,
      "name": "fesod",
      "full_name": "apache/fesod",
      "description": "Fast. Easy. Done. Processing spreadsheets without worrying about large files causing OOM.",
      "html_url": "https://github.com/apache/fesod",
      "stars": 5744,
      "forks": 475,
      "language": "Java",
      "topics": [
        "csv",
        "easyexcel",
        "excel",
        "fast-excel",
        "fastexcel",
        "java",
        "office",
        "poi",
        "xls",
        "xlsx"
      ],
      "created_at": "2024-10-05T11:42:50Z",
      "updated_at": "2026-01-23T01:33:02Z",
      "pushed_at": "2026-01-21T15:31:14Z",
      "open_issues": 132,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\n- Licensed to the Apache Software Foundation (ASF) under one or more\n- contributor license agreements.  See the NOTICE file distributed with\n- this work for additional information regarding copyright ownership.\n- The ASF licenses this file to You under the Apache License, Version 2.0\n- (the \"License\"); you may not use this file except in compliance with\n- the License.  You may obtain a copy of the License at\n-\n-   http://www.apache.org/licenses/LICENSE-2.0\n-\n- Unless required by applicable law or agreed to in writing, software\n- distributed under the License is distributed on an \"AS IS\" BASIS,\n- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- See the License for the specific language governing permissions and\n- limitations under the License.\n-->\n\n<p align=\"center\">\n  <a href=\"https://fesod.apache.org\">\n     <img alt=\"fesod\" src=\"logo.svg\" width=\"260\">\n  </a>\n</p>\n\n<p align=\"center\">\n<b>Readme</b>:\n<b><a href=\"README.md\">English</a></b> | <a href=\"README_CN.md\">‰∏≠Êñá</a> \n</p>\n\n[![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/apache/fesod/ci.yml?style=flat-square&logo=github)](https://github.com/apache/fesod/actions/workflows/ci.yml)\n[![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/apache/fesod/nightly.yml?style=flat-square&logo=github&label=nightly)](https://github.com/apache/fesod/actions/workflows/nightly.yml)\n[![GitHub License](https://img.shields.io/github/license/apache/fesod?logo=apache&style=flat-square)](https://github.com/apache/fesod/blob/main/LICENSE)\n![Maven Central Version](https://img.shields.io/maven-central/v/org.apache.fesod/fesod?logo=apachemaven&style=flat-square)\n[![Document](https://img.shields.io/github/actions/workflow/status/apache/fesod/ci.yml?style=flat-square&logo=read-the-docs&label=Document)](https://fesod.apache.org/)\n[![DeepWiki](https://img.shields.io/badge/DeepWiki-apache%2Ffesod-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/apache/fesod)\n\n**Home: [fesod.apache.org](https://fesod.apache.org)**   \n**Email: <a href=\"mailto:dev-subscribe@fesod.apache.org\">Mail to `dev-subscribe@fesod.apache.org`</a> to subscribe mailing lists**\n\n\n## Introduction\n\n**Apache Fesod (Incubating)** is a high-performance and memory-efficient Java library for reading and writing spreadsheet\nfiles, designed to simplify development and ensure reliability.\n\nApache Fesod (Incubating) can provide developers and enterprises with great freedom and flexibility. We plan to\nintroduce more new features in the future to continually enhance user experience and tool usability. Apache Fesod (\nIncubating) is committed to being your best choice for handling spreadsheet files.\n\nThe name fesod (pronounced `/Ààf…õs…íd/`), an acronym for \"fast easy spreadsheet and other documents,\" expresses the\nproject's origin, background, and vision.\n\n### Features\n\n- **High-performance Reading and Writing**: Apache Fesod (Incubating) focuses on performance optimization, capable of\n  efficiently handling large-scale spreadsheet data. Compared to some traditional spreadsheet processing libraries, it can\n  significantly reduce memory consumption.\n- **Simplicity and Ease of Use**: The library offers a simple and intuitive API, allowing developers to easily integrate\n  it into projects, whether for simple spreadsheet operations or complex data processing.\n- **Stream Operations**: Apache Fesod (Incubating) supports stream reading, minimizing the problem of loading large\n  amounts of data at once. This design is especially important when dealing with hundreds of thousands or even millions\n  of rows of data.\n\n## Installation\n\nApache Fesod (Incubating) requires **Java 1.8** or later. Using the latest LTS release of Java is encouraged. We\nstrongly recommend using the latest version of Apache Fesod (Incubating), as performance optimizations, bug fixes, and\nnew features in the latest version will enhance your experience.\n\n> Currently, Apache Fesod (Incubating) uses POI as its underlying package. If your project already includes POI-related\n> components, you\n> will need to manually exclude POI-related jar files.\n\n\n> We are currently preparing for the first release under the Apache Incubator. Current releases were non-Apache\n> releases. You can see previous versions in this link: https://fesod.apache.org/docs/quickstart/guide/\n\n### Maven\n\nIf you are using Maven for project building, add the following configuration in the `pom.xml` file:\n\n```xml\n\n<dependency>\n    <groupId>org.apache.fesod</groupId>\n    <artifactId>fesod</artifactId>\n    <version>version</version>\n</dependency>\n```\n\n### Gradle\n\nIf you are using Gradle for project building, add the following configuration in the build.gradle file:\n\n```gradle\ndependencies {\n    implementation 'org.apache.fesod:fesod:version'\n}\n```\n\n## QuickStart\n\n### Read\n\nBelow is an example of reading a spreadsheet document:\n\n```java\n// Implement the ReadListener interface to set up operations for reading data\npublic class DemoDataListener implements ReadListener<DemoData> {\n\n    @Override\n    public void invoke(DemoData data, AnalysisContext context) {\n        System.out.println(\"Parsed a data entry\" + JSON.toJSONString(data));\n    }\n\n    @Override\n    public void doAfterAllAnalysed(AnalysisContext context) {\n        System.out.println(\"All data parsed!\");\n    }\n}\n\npublic static void main(String[] args) {\n    String fileName = \"demo.xlsx\";\n    // Read spreadsheet file\n    FesodSheet.read(fileName, DemoData.class, new DemoDataListener()).sheet().doRead();\n}\n```\n\n### Write\n\nBelow is a simple example of creating a spreadsheet document:\n\n```java\n// Sample data class\npublic class DemoData {\n\n    @ExcelProperty(\"String Title\")\n    private String string;\n\n    @ExcelProperty(\"Date Title\")\n    private Date date;\n\n    @ExcelProperty(\"Number Title\")\n    private Double doubleData;\n\n    @ExcelIgnore\n    private String ignore;\n}\n\n// Prepare data to write\nprivate static List<DemoData> data() {\n    List<DemoData> list = new ArrayList<>();\n    for (int i = 0; i < 10; i++) {\n        DemoData data = new DemoData();\n        data.setString(\"String\" + i);\n        data.setDate(new Date());\n        data.setDoubleData(0.56);\n        list.add(data);\n    }\n    return list;\n}\n\npublic static void main(String[] args) {\n    String fileName = \"demo.xlsx\";\n    // Create a \"Template\" sheet and write data\n    FesodSheet.write(fileName, DemoData.class).sheet(\"Template\").doWrite(data());\n}\n```\n\n## Community\n\n### Contributors\n\nContributors are welcomed to join the Apache Fesod (Incubating). Please\ncheck [Contributing Guide](./CONTRIBUTING.md) about how to contribute to this project.\n\nThank you to all the people who already contributed to the Apache Fesod (Incubating) !\n\n<a href=\"https://github.com/apache/fesod/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=apache/fesod\"/>\n</a>\n\n> Note: Showing the first 100 contributors only due to GitHub image size limitations\n\n### Subscribe Mailing Lists\n\nMail List is the most recognized form of communication in the Apache community. Contact us through the following mailing\nlist.\n\n| Name                                                | Mailing list                                                                                                  |\n|:----------------------------------------------------|:--------------------------------------------------------------------------------------------------------------|\n| [dev@fesod.apache.org](mailto:dev@fesod.apache.org) | [Subscribe](mailto:dev-subscribe@fesod.apache.org)  ÔΩú  [Unsubscribe](mailto:dev-unsubscribe@fesod.apache.org) |\n\n### Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=apache/fesod&type=Date)](https://www.star-history.com/#apache/fesod&Date)\n\n## License\n\nApache Fesod (Incubating) project is licensed under the [Apache License 2.0](LICENSE).\n",
      "stars_today": 14
    },
    {
      "id": 449738859,
      "name": "geode",
      "full_name": "geode-sdk/geode",
      "description": "The ultimate Geometry Dash modding framework",
      "html_url": "https://github.com/geode-sdk/geode",
      "stars": 1450,
      "forks": 267,
      "language": "C++",
      "topics": [
        "cpp",
        "cross-platform",
        "geode",
        "geode-sdk",
        "geometry-dash",
        "low-level",
        "mod",
        "modding",
        "modding-framework",
        "modding-library"
      ],
      "created_at": "2022-01-19T15:05:21Z",
      "updated_at": "2026-01-23T01:54:24Z",
      "pushed_at": "2026-01-22T22:10:39Z",
      "open_issues": 135,
      "owner": {
        "login": "geode-sdk",
        "avatar_url": "https://avatars.githubusercontent.com/u/88206422?v=4"
      },
      "readme": "<p align=\"center\">\n\t<img src=\"/title.png\" />\n\t<h3 align=\"center\">\n\t\t<a href=\"https://geode-sdk.org\">Home page</a>\n\t</h3>\n</p>\n\n<p align=\"center\"><b>Geode</b> is a <a href=\"https://store.steampowered.com/app/322170/Geometry_Dash/\">Geometry Dash</a> <b>mod loader</b> and <b>modding SDK</b> with a modern approach towards mod development.</p>\n\n## Why Geode?\n\nUnlike previous mod loaders, which merely inject the DLLs and let devs handle the rest, Geode aims to be a more comprehensive project that provides all the tools needed for creating mods in one package.\n\nGeode's goal is to solve **mod incompatibility** - to ensure that mods work together without buttons getting misplaced or hooks mysteriously disappearing.\n\n## \"Hello World!\" Example\n\nHere's a **Hello World** mod in Geode:\n\n```cpp\n#include <Geode/Bindings.hpp>\n#include <Geode/modify/MenuLayer.hpp>\n\nusing namespace geode::prelude;\n\nclass $modify(MenuLayer) {\n\tvoid onMoreGames(CCObject*) {\n\t\tFLAlertLayer::create(\n\t\t\t\"Geode\",\n\t\t\t\"Hello World from my Custom Mod!\",\n\t\t\t\"OK\"\n\t\t)->show();\n\t}\n};\n```\n\nThis code modifies what happens when the \"More Games\" button is clicked on the home scene in Geometry Dash, showing a custom popup.\n\n## Documentation\n\nDetailed documentation, tutorials, and installation instructions on using Geode can be found [here](https://docs.geode-sdk.org).\n\nNew to modding GD? Geode's documentation also comes with a handy [tutorial book](https://docs.geode-sdk.org/#/handbook/chap0) that explains all the basics of GD modding!\n\n## Contribution\n\nYou can contribute to Geode by opening a [Pull Request](https://github.com/geode-sdk/geode/pulls)! Please follow the contribution guidelines.\n\n## Questions, help, etc.\n\nIf you have any further questions, need help, or just want to share your love for catgirls, be sure to join [our Discord server](https://discord.gg/9e43WMKzhp)!\n",
      "stars_today": 14
    },
    {
      "id": 6296790,
      "name": "spring-boot",
      "full_name": "spring-projects/spring-boot",
      "description": "Spring Boot helps you to create Spring-powered, production-grade applications and services with absolute minimum fuss.",
      "html_url": "https://github.com/spring-projects/spring-boot",
      "stars": 79746,
      "forks": 41824,
      "language": "Java",
      "topics": [
        "framework",
        "java",
        "spring",
        "spring-boot"
      ],
      "created_at": "2012-10-19T15:02:57Z",
      "updated_at": "2026-01-22T20:30:03Z",
      "pushed_at": "2026-01-22T15:21:12Z",
      "open_issues": 472,
      "owner": {
        "login": "spring-projects",
        "avatar_url": "https://avatars.githubusercontent.com/u/317776?v=4"
      },
      "readme": "= Spring Boot image:https://github.com/spring-projects/spring-boot/actions/workflows/build-and-deploy-snapshot.yml/badge.svg?branch=main[\"Build Status\", link=\"https://github.com/spring-projects/spring-boot/actions/workflows/build-and-deploy-snapshot.yml?query=branch%3Amain\"] image:https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A[\"Revved up by Develocity\", link=\"https://ge.spring.io/scans?&search.rootProjectNames=Spring%20Boot%20Build&search.rootProjectNames=spring-boot-build\"]\n\n:docs: https://docs.spring.io/spring-boot\n:github: https://github.com/spring-projects/spring-boot\n\nSpring Boot helps you to create Spring-powered, production-grade applications and services with absolute minimum fuss.\nIt takes an opinionated view of the Spring platform so that new and existing users can quickly get to the bits they need.\n\nYou can use Spring Boot to create stand-alone Java applications that can be started using `java -jar` or more traditional WAR deployments.\nWe also provide a command-line tool that runs Spring scripts.\n\nOur primary goals are:\n\n* Provide a radically faster and widely accessible getting started experience for all Spring development.\n* Be opinionated, but get out of the way quickly as requirements start to diverge from the defaults.\n* Provide a range of non-functional features common to large classes of projects (for example, embedded servers, security, metrics, health checks, externalized configuration).\n* Absolutely no code generation and no requirement for XML configuration.\n\n\n\n== Installation and Getting Started\n\nThe {docs}[reference documentation] includes detailed {docs}/installing.html[installation instructions] as well as a comprehensive {docs}/tutorial/first-application/index.html[``getting started``] guide.\n\nHere is a quick teaser of a complete Spring Boot application in Java:\n\n[source,java]\n----\nimport org.springframework.boot.*;\nimport org.springframework.boot.autoconfigure.*;\nimport org.springframework.web.bind.annotation.*;\n\n@RestController\n@SpringBootApplication\npublic class Example {\n\n\t@RequestMapping(\"/\")\n\tString home() {\n\t\treturn \"Hello World!\";\n\t}\n\n\tpublic static void main(String[] args) {\n\t\tSpringApplication.run(Example.class, args);\n\t}\n\n}\n----\n\n\n\n== Getting Help\n\nAre you having trouble with Spring Boot? We want to help!\n\n* Check the {docs}/[reference documentation], especially the {docs}/how-to/index.html[How-to's] -- they provide solutions to the most common questions.\n* Learn the Spring basics -- Spring Boot builds on many other Spring projects; check the https://spring.io[spring.io] website for a wealth of reference documentation.\n  If you are new to Spring, try one of the https://spring.io/guides[guides].\n* If you are upgrading, read the {github}/wiki[release notes] for upgrade instructions and \"new and noteworthy\" features.\n* Ask a question -- we monitor https://stackoverflow.com[stackoverflow.com] for questions tagged with https://stackoverflow.com/tags/spring-boot[`spring-boot`].\n* Report bugs with Spring Boot at {github}/issues[github.com/spring-projects/spring-boot/issues].\n\n\n\n== Contributing\n\nWe welcome contributions of all kinds!\nPlease read our link:CONTRIBUTING.adoc[contribution guidelines] before submitting a pull request.\n\n\n\n== Reporting Issues\n\nSpring Boot uses GitHub's integrated issue tracking system to record bugs and feature requests.\nIf you want to raise an issue, please follow the recommendations below:\n\n* Before you log a bug, please search the {github}/issues[issue tracker] to see if someone has already reported the problem.\n* If the issue doesn't already exist, {github}/issues/new[create a new issue].\n* Please provide as much information as possible with the issue report.\nWe like to know the Spring Boot version, operating system, and JVM version you're using.\n* If you need to paste code or include a stack trace, use Markdown.\n+++```+++ escapes before and after your text.\n* If possible, try to create a test case or project that replicates the problem and attach it to the issue.\n\n\n\n== Building from Source\n\nYou don't need to build from source to use Spring Boot.\nIf you want to try out the latest and greatest, Spring Boot can be built and published to your local Maven cache using the https://docs.gradle.org/current/userguide/gradle_wrapper.html[Gradle wrapper].\nYou also need JDK 25.\n\n[source,shell]\n----\n$ ./gradlew publishToMavenLocal\n----\n\nThis command builds all modules and publishes them to your local Maven cache.\nIt won't run any of the tests.\nIf you want to build everything, use the `build` task:\n\n[source,shell]\n----\n$ ./gradlew build\n----\n\n\n\n== Guides\n\nThe https://spring.io/[spring.io] site contains several guides that show how to use Spring Boot step-by-step:\n\n* https://spring.io/guides/gs/spring-boot/[Building an Application with Spring Boot] is an introductory guide that shows you how to create an application, run it, and add some management services.\n* https://spring.io/guides/gs/actuator-service/[Building a RESTful Web Service with Spring Boot Actuator] is a guide to creating a REST web service and also shows how the server can be configured.\n\n\n\n== License\n\nSpring Boot is Open Source software released under the https://www.apache.org/licenses/LICENSE-2.0.html[Apache 2.0 license].\n",
      "stars_today": 13
    },
    {
      "id": 510342492,
      "name": "client",
      "full_name": "Droid-ify/client",
      "description": "Clutterfree F-Droid client",
      "html_url": "https://github.com/Droid-ify/client",
      "stars": 6230,
      "forks": 160,
      "language": "Kotlin",
      "topics": [
        "android",
        "android-application",
        "fdroid",
        "kotlin",
        "kotlin-android",
        "kotlin-flow"
      ],
      "created_at": "2022-07-04T12:03:15Z",
      "updated_at": "2026-01-23T01:25:54Z",
      "pushed_at": "2026-01-22T10:02:15Z",
      "open_issues": 197,
      "owner": {
        "login": "Droid-ify",
        "avatar_url": "https://avatars.githubusercontent.com/u/123971387?v=4"
      },
      "readme": "<div align=\"center\">\n\n<img width=\"\" src=\"metadata/en-US/images/featureGraphic.png\" alt=\"Droid-ify\" align=\"center\">\n\n> **Clutterfree F-Droid client**\n\n[![GitHub stars](https://img.shields.io/github/stars/Iamlooker/Droid-ify?color=%2359a14f&style=for-the-badge)](https://github.com/Iamlooker/Droid-ify/stargazers)\n[![GitHub downloads](https://img.shields.io/github/downloads/Iamlooker/Droid-ify/total.svg?color=%236f9645&style=for-the-badge)](https://github.com/Iamlooker/Droid-ify/releases/)\n[![GitHub latest release](https://img.shields.io/github/v/release/Iamlooker/Droid-ify?display_name=tag&color=%23d97706&style=for-the-badge)](https://github.com/Iamlooker/Droid-ify/releases/latest)\n[![F-Droid latest release](https://img.shields.io/f-droid/v/com.looker.droidify?color=%23ea9010&style=for-the-badge)](https://f-droid.org/packages/com.looker.droidify)\n</div>\n<div align=\"left\">\n\n<img src=\"metadata/en-US/images/phoneScreenshots/1.png\" width=\"25%\" /><img src=\"metadata/en-US/images/phoneScreenshots/2.png\" width=\"25%\" /><img src=\"metadata/en-US/images/phoneScreenshots/3.png\" width=\"25%\" /><img src=\"metadata/en-US/images/phoneScreenshots/4.png\" width=\"25%\" />\n\n* Browse and install apps from F-Droid repositories\n* Automatic app updates in the background\n* Multiple installation methods (Session, Root, Shizuku)\n* Add custom repositories with one tap\n* Works completely offline after initial sync\n\n### Get Started\n\n**Download**: [GitHub Releases](https://github.com/Iamlooker/Droid-ify/releases/latest) ‚Ä¢ [F-Droid](https://f-droid.org/packages/com.looker.droidify)\n\n**Signature:**\n```\nED:88:59:C5:5A:F3:11:16:26:58:B9:4A:F9:82:B9:F0:91:DC:D2:76:28:D4:DE:34:86:D1:21:7E:BF:3C:99:35\n```\n\n> [!IMPORTANT]\n> Signature for older versions on F-Droid might be different\n\n**Build**: See [Building Guide](docs/building.md) for development setup\n\n### Contributing\n\n**Want to help?** Check out our [Contributing Guide](CONTRIBUTING.md)\n\n### Translations\n\n[![Translation status](https://hosted.weblate.org/widgets/droidify/-/horizontal-auto.svg)](https://hosted.weblate.org/engage/droidify/?utm_source=widget)\n\n### License\n\n```\nDroid-ify\n\nCopyright (C) 2025 LooKeR\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n```\n\n</div>\n",
      "stars_today": 13
    },
    {
      "id": 743200516,
      "name": "komikku",
      "full_name": "komikku-app/komikku",
      "description": "Free and open source manga reader for Android",
      "html_url": "https://github.com/komikku-app/komikku",
      "stars": 3169,
      "forks": 127,
      "language": "Kotlin",
      "topics": [
        "android",
        "j2k",
        "komga",
        "kotlin",
        "manga",
        "manga-downloader",
        "manga-reader",
        "mangadex",
        "mangadex-downloader",
        "mangadownloader",
        "mangareader",
        "mihon",
        "neko",
        "tachiyomi",
        "tachiyomisy"
      ],
      "created_at": "2024-01-14T16:25:54Z",
      "updated_at": "2026-01-23T02:02:59Z",
      "pushed_at": "2026-01-22T11:15:13Z",
      "open_issues": 312,
      "owner": {
        "login": "komikku-app",
        "avatar_url": "https://avatars.githubusercontent.com/u/160299335?v=4"
      },
      "readme": "<div align=\"center\">\n\n<a href=\"https://komikku-app.github.io\">\n  <img width=200px height=200px src=\"./.github/readme-images/app-icon.png\"/>\n</a><br/>\n<a href=\"https://trendshift.io/repositories/13696\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13696\" alt=\"komikku-app%2Fkomikku | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n <h1 align=\"center\"> Komikku </h1>\n\n| Releases | Preview |\n|----------|---------|\n| <div align=\"center\"> [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku/latest/total?label=Latest%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku/releases/latest) [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku/total?label=Total%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku/releases) [![Stable build](https://img.shields.io/github/actions/workflow/status/komikku-app/komikku/build_release.yml?labelColor=27303D&label=Stable&labelColor=06599d&color=043b69)](https://github.com/komikku-app/komikku/actions/workflows/build_release.yml) | <div align=\"center\"> [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku-preview/latest/total?label=Latest%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku-preview/releases/latest) [![GitHub downloads](https://img.shields.io/github/downloads/komikku-app/komikku-preview/total?label=Total%20Downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://github.com/komikku-app/komikku-preview/releases) [![Preview build](https://img.shields.io/github/actions/workflow/status/komikku-app/komikku-preview/build_app.yml?labelColor=27303D&label=Preview&labelColor=2c2c47&color=1c1c39)](https://github.com/komikku-app/komikku-preview/actions/workflows/build_app.yml) |\n\n*Requires Android 8.0 or higher.*\n\n[![Discord](https://img.shields.io/discord/1242381704459452488.svg?label=&labelColor=6A7EC2&color=7389D8&logo=discord&logoColor=FFFFFF)](https://discord.gg/85jB7V5AJR)\n[![CI](https://img.shields.io/github/actions/workflow/status/komikku-app/komikku/build_push.yml?labelColor=27303D&label=CI)](https://github.com/komikku-app/komikku/actions/workflows/build_push.yml)\n[![License: Apache-2.0](https://img.shields.io/github/license/komikku-app/komikku?labelColor=27303D&color=0877d2)](/LICENSE)\n[![Translation status](https://img.shields.io/weblate/progress/komikku-app?labelColor=27303D&color=946300)](https://hosted.weblate.org/engage/komikku-app/)\n\n## Download\n\n[![Stable](https://img.shields.io/github/release/komikku-app/komikku.svg?maxAge=3600&label=Stable&labelColor=06599d&color=043b69)](https://github.com/komikku-app/komikku/releases/latest)\n[![Preview](https://img.shields.io/github/v/release/komikku-app/komikku-preview.svg?maxAge=3600&label=Preview&labelColor=2c2c47&color=1c1c39)](https://github.com/komikku-app/komikku-preview/releases/latest)\n\n*Requires Android 8.0 or higher.*\n\n[![Sponsor me on GitHub](https://custom-icon-badges.demolab.com/badge/-Sponsor-ea4aaa?style=for-the-badge&logo=heart&logoColor=white)](https://github.com/sponsors/cuong-tran \"Sponsor me on GitHub\")\n\n<div align=\"left\">\nA free and open source manga reader which is based off TachiyomiSY & Mihon/Tachiyomi. This fork is meant to provide new & useful features while regularly take features/updates from Mihon or other forks like SY, J2K and Neko...\n\n![screenshots of app](./.github/readme-images/screens.png)\n\n<div align=\"left\">\n\n## Features\n\n### Komikku's unique features:\n- `Suggestions` automatically showing source-website's recommendations / suggestions / related to current entry for all sources.\n- `Hidden categories` to hide yours things from *nosy* people.\n- `Auto theme color` based on each entry's cover for entry View & Reader.\n- `App custom theme` with `Color palettes` for endless color lover.\n- `Bulk-favorite` multiple entries all at once.\n- Source & Language icon on Library & various places. (Some language flags are not really accurate)\n- `Feed` now supports **all** sources, with more items (20 for now).\n- Fast browsing (for who with large library experiencing slow loading)\n- Grouped entries in Update tab (inspired by J2K).\n- Update notification with manga cover.\n- Auto `2-way sync` progress with trackers.\n- Chips for `Saved search` in source browse\n- `Panorama cover` showing wide cover in full.\n- `Merge multiple` library entries together at same time.\n- `Range-selection` for Migration.\n- Ability to `enable/disable repo`, with icon.\n- `Update Error` screen & migrating them away.\n- `to-be-updated` screen: which entries are going to be checked with smart-update?\n- `Search for sources` & Quick NSFW sources filter in Extensions, Browse & Migration screen.\n- `Feed` backup/restore/sync/re-order.\n- Long-click to add/remove single entry to/from library, everywhere.\n- Docking Read/Resume button to left/right.\n- In-app progress banner shows Library syncing / Backup restoring / Library updating progress.\n- Auto-install app update.\n- Configurable interval to refresh entries from downloaded storage.\n- Forked from SY so everything from SY.\n- Always up-to-date with Mihon & SY\n- More app themes & better UI, improvements...\n\n\n<details>\n  <summary>Features from Mihon / Tachiyomi</summary>\n\n#### All up-to-date features from Mihon / Tachiyomi (original), include:\n\n* Online reading from a variety of sources\n* Local reading of downloaded content\n* A configurable reader with multiple viewers, reading directions and other settings.\n* Tracker support: [MyAnimeList](https://myanimelist.net/), [AniList](https://anilist.co/), [Kitsu](https://kitsu.app/), [MangaUpdates](https://mangaupdates.com), [Shikimori](https://shikimori.one), [Bangumi](https://bgm.tv/)\n* Categories to organize your library\n* Light and dark themes\n* Schedule updating your library for new chapters\n* Create backups locally to read offline or to your desired cloud service\n* Continue reading button in library\n\n</details>\n\n<details>\n  <summary>Features from Tachiyomi SY</summary>\n\n#### All features from TachiyomiSY:\n* Feed tab, where you can easily view the latest entries or saved search from multiple sources at same time.\n* Automatic webtoon detection, allowing the reader to switch to webtoon mode automatically when viewing one\n* Manga recommendations, uses MAL and Anilist, as well as Neko Similar Manga for Mangadex manga (Thanks to Az, She11Shocked, Carlos, and Goldbattle)\n* Lewd filter, hide the lewd manga in your library when you want to\n* Tracking filter, filter your tracked manga so you can see them or see non-tracked manga, made by She11Shocked\n* Search tracking status in library, made by She11Shocked\n* Custom categories for sources, liked the pinned sources, but you can make your own versions and put any sources in them\n* Manga info edit\n* Manga Cover view + share and save\n* Dynamic Categories, view the library in multiple ways\n* Smart background for reading modes like LTR or Vertical, changes the background based on the page color\n* Force disable webtoon zoom\n* Hentai features enable/disable, in advanced settings\n* Quick clean titles\n* Source migration, migrate all your manga from one source to another\n* Saving searches\n* Autoscroll\n* Page preload customization\n* Customize image cache size\n* Batch import of custom sources and featured extensions\n* Advanced source settings page, searching, enable/disable all\n* Click tag for local search, long click tag for global search\n* Merge multiple of the same manga from different sources\n* Drag and drop library sorting\n* Library search engine, includes exclude, quotes as absolute, and a bunch of other ways to search\n* New E-Hentai/ExHentai features, such as language settings and watched list settings\n* Enhanced views for internal and integrated sources\n* Enhanced usability for internal and delegated sources\n\nCustom sources:\n* E-Hentai/ExHentai\n\nAdditional features for some extensions, features include custom description, opening in app, batch add to library, and a bunch of other things based on the source:\n* 8Muses (EroMuse)\n* HBrowse\n* Mangadex\n* NHentai\n* Puruin\n* Tsumino\n\n</details>\n\n## Issues, Feature Requests and Contributing\n\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\n<details><summary>Issues</summary>\n\n[Website](https://komikku-app.github.io/)\n\n1. **Before reporting a new issue, take a look at the [FAQ](https://komikku-app.github.io/docs/faq/general), the [changelog](https://github.com/komikku-app/komikku/releases) and the already opened [issues](https://github.com/komikku-app/komikku/issues).**\n2. If you are unsure, ask here: [![Discord](https://img.shields.io/discord/1242381704459452488.svg?label=&labelColor=6A7EC2&color=7389D8&logo=discord&logoColor=FFFFFF)](https://discord.gg/85jB7V5AJR)\n\n</details>\n\n<details><summary>Bugs</summary>\n\n* Include version (More ‚Üí About ‚Üí Version)\n * If not latest, try updating, it may have already been solved\n * Preview version is equal to the number of commits as seen on the main page\n* Include steps to reproduce (if not obvious from description)\n* Include screenshot (if needed)\n* If it could be device-dependent, try reproducing on another device (if possible)\n* Don't group unrelated requests into one issue\n\nUse the [issue forms](https://github.com/komikku-app/komikku/issues/new/choose) to submit a bug.\n\n</details>\n\n<details><summary>Feature Requests</summary>\n\n* Write a detailed issue, explaining what it should do or how.\n* Include screenshot (if needed).\n</details>\n\n<details><summary>Contributing</summary>\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md).\n</details>\n\n<details><summary>Code of Conduct</summary>\n\nSee [CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md).\n</details>\n\n<div align=\"center\">\n\n### Credits\n\nThank you to all the people who have contributed!\n\n<a href=\"https://github.com/komikku-app/komikku/graphs/contributors\">\n    <img src=\"https://contrib.rocks/image?repo=komikku-app/komikku\" alt=\"Komikku app contributors\" title=\"Komikku app contributors\" width=\"800\"/>\n</a>\n\n![Visitor Count](https://count.getloli.com/get/@komikku-app?theme=capoo-2)\n\n### Disclaimer\n\nThe developer(s) of this application does not have any affiliation with the content providers available, and this application hosts zero content.\n\n<div align=\"left\">\n\n## License\n\n    Copyright 2015 Javier Tom√°s\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n",
      "stars_today": 13
    },
    {
      "id": 1048623630,
      "name": "ArchiveTune",
      "full_name": "koiverse/ArchiveTune",
      "description": "The cutest Material 3 Expressive music streaming client for Android, built for performance and extensibility.",
      "html_url": "https://github.com/koiverse/ArchiveTune",
      "stars": 402,
      "forks": 15,
      "language": "Kotlin",
      "topics": [
        "android-application",
        "android-studio",
        "foss",
        "jetpack-compose",
        "kotlin",
        "material3",
        "music-player-foss",
        "nvvm",
        "streaming-apps",
        "youtube-music-client"
      ],
      "created_at": "2025-09-01T18:42:42Z",
      "updated_at": "2026-01-23T02:11:04Z",
      "pushed_at": "2026-01-23T00:09:24Z",
      "open_issues": 9,
      "owner": {
        "login": "koiverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/107134739?v=4"
      },
      "readme": "<div align=\"center\">\n\n  <img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/icon.png\" width=\"160\" height=\"160\" alt=\"ArchiveTune Logo\" style=\"border-radius: 22%\">\n\n  <h1>ArchiveTune</h1>\n\n  <p align=\"center\">\n    <strong>Redefining the YouTube Music Experience on Android.</strong>\n    <br />\n    <em>High-performance. Privacy-centric. Audiophile-grade features.</em>\n  </p>\n\n  <p align=\"center\">\n    <a href=\"https://archivetune.koiiverse.cloud\"><b>Official Website</b></a> ‚Ä¢\n    <a href=\"#-key-highlights\"><b>Features</b></a> ‚Ä¢\n    <a href=\"#-installation\"><b>Download</b></a> ‚Ä¢\n    <a href=\"#-showcase\"><b>Showcase</b></a> ‚Ä¢\n    <a href=\"https://github.com/koiverse/ArchiveTune/issues/new/choose\"><b>Support</b></a>\n  </p>\n\n  <div align=\"center\">\n    <img src=\"https://img.shields.io/github/v/release/koiverse/ArchiveTune?style=for-the-badge&color=6366f1&labelColor=1e1e2e&logo=github\" alt=\"Latest Version\" />\n    <img src=\"https://img.shields.io/github/downloads/koiverse/ArchiveTune/total?style=for-the-badge&color=6366f1&labelColor=1e1e2e&logo=github\" alt=\"Downloads\" />\n    <img src=\"https://img.shields.io/github/stars/koiverse/ArchiveTune?style=for-the-badge&color=6366f1&labelColor=1e1e2e&logo=github\" alt=\"Stars\" />\n    <img src=\"https://img.shields.io/github/license/koiverse/ArchiveTune?style=for-the-badge&color=6366f1&labelColor=1e1e2e\" alt=\"License\" />\n    <img src=\"https://img.shields.io/badge/Architecture-MVVM-6366f1?style=for-the-badge&labelColor=1e1e2e&logo=kotlin\" alt=\"MVVM Architecture\" />\n    <img src=\"https://img.shields.io/badge/Language-Kotlin-7f52ff?style=for-the-badge&logo=kotlin&color=6366f1&labelColor=1e1e2e\" alt=\"Kotlin Language\" />\n    <img src=\"https://img.shields.io/badge/Toolkit-Jetpack_Compose-4285f4?style=for-the-badge&logo=jetpack-compose&color=6366f1&labelColor=1e1e2e\" alt=\"Jetpack Compose Toolkit\" />\n    <img src=\"https://img.shields.io/badge/Design-Material_3-000000?style=for-the-badge&logo=material-design&color=6366f1&labelColor=1e1e2e\" alt=\"Material Design 3\" />\n  </div>\n  \n  <br />\n\n  <a href=\"https://trendshift.io/repositories/17521\" target=\"_blank\">\n    <img src=\"https://trendshift.io/api/badge/repositories/17521\" alt=\"ArchiveTune | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/>\n  </a>\n</div>\n\n<hr />\n\n**ArchiveTune** isn't just a wrapper‚Äîit's a precision-engineered music ecosystem. We believe your music library should be private, beautiful, and powerful. Designed for power users who refuse to compromise on audio quality or UI aesthetics.\n\n---\n\n### üöÄ Core Experience\n* **Ad-Free Core:** A pure, uninterrupted listening experience.\n* **Deep Library Sync:** Instant access to your Liked Songs, Playlists, and Subscriptions.\n* **Smart Caching:** High-speed playback with intelligent data management.\n* **Background Mastery:** Optimized background playback that respects your battery.\n\n### üéöÔ∏è Professional Audio Suite\n* **Loudness Normalization:** Industry-standard volume leveling (EBU R128).\n* **Precision Control:** On-the-fly **Tempo & Pitch** manipulation for musicians and DJs.\n* **The \"Gapless\" Flow:** Integrated **Crossfade** and **Silence Skipping**.\n* **System EQ Bridge:** Seamlessly integrates with system-level equalizers and spatial audio.\n\n### üé® Visual & Identity\n* **Material You (MD3E):** The UI breathes through your wallpaper‚Äôs color palette.\n* **Synced Lyrics:** Beautiful, word-by-word playback with translation & romanization.\n* **Music Insights:** Native \"Year in Review\" and real-time listening statistics.\n* **Discord RPC:** Show the world your vibe with high-quality Rich Presence.\n\n---\n\n## üì∏ Showcase\n\n<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/koiverse/ArchiveTune/refs/heads/dev/fastlane/metadata/android/en-US/images/ArchiveTuneBanner.png\" alt=\"ArchiveTune Banner\" style=\"width: 100%; max-width: 400px; border-radius: 12px;\">\n  <table border=\"0\">\n    <tr>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_1.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_2.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_3.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_4.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_5.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n      <td><img src=\"https://github.com/koiverse/ArchiveTune/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/screenshot_6.jpg\" width=\"180\" style=\"border-radius: 12px;\"></td>\n    </tr>\n    <tr align=\"center\">\n      <td><sub>Player</sub></td>\n      <td><sub>Live Lyrics</sub></td>\n      <td><sub>Theme Customization</sub></td>\n      <td><sub>Live Statistics</sub></td>\n      <td><sub>Artist UI</sub></td>\n      <td><sub>Album UI</sub></td>\n    </tr>\n  </table>\n</div>\n\n---\n\n## üì• Installation\n\n<table>\n  <tr>\n    <td align=\"center\">\n      <a href=\"https://github.com/koiverse/ArchiveTune/releases/latest\">\n        <img src=\"https://raw.githubusercontent.com/koiverse/ArchiveTune/refs/heads/main/assets/badge_github.png\" height=\"40\" alt=\"Get it on GitHub\">\n      </a>\n    </td>\n    <td align=\"center\">\n      <a href=\"https://apt.izzysoft.de/fdroid/index/apk/moe.koiverse.archivetune\">\n        <img src=\"https://raw.githubusercontent.com/koiverse/ArchiveTune/757d5932832e1da27ced56de98c5ad1275cf0db1/assets/IzzyOnDroidButtonBorder.svg\" height=\"40\" alt=\"Get it on IzzyOnDroid\">\n      </a>\n    </td>\n    <td align=\"center\">\n      <a href=\"https://www.openapk.net/archivetune/moe.koiverse.archivetune/\">\n        <img src=\"https://www.openapk.net/images/openapk-badge.png\" height=\"60\" alt=\"Get it on OpenAPK\">\n      </a>\n    </td>\n  </tr>\n</table>\n\n\n\n> [!IMPORTANT]  \n> **Geographic Availability:** If YouTube Music is not supported in your region, a VPN or Proxy set to a supported region is required for initial data fetching.\n\n---\n\n## üåç Globalization\n\nArchiveTune belongs to everyone. Help us localize the experience for your region.\n\n<div align=\"center\">\n  <a href=\"https://translate.codeberg.org/engage/archivetune/\">\n    <img src=\"https://translate.codeberg.org/widget/archivetune/horizontal-blue.svg\" alt=\"Translation status\" />\n  </a>\n</div>\n\n### ‚ú® Project Contributors\n<a href=\"https://github.com/koiverse/ArchiveTune/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=koiverse/ArchiveTune\" />\n</a>\n\n### üõ†Ô∏è Development & Engineering\nInterested in building the project or contributing? ArchiveTune is built on a high-performance Kotlin stack.\n<a href=\"BUILDING.md\"><b>Read the Build & Contribution Guide ‚Üí</b></a>\n\n---\n\n## ü§ù Acknowledgments\n\nWe stand on the shoulders of open-source giants:\n- **Metrolist** by [Mostafa Alagamy](https://github.com/mostafaalagamy/Metrolist) For Base framework.\n- **Kizzy** by [dead8309](https://github.com/dead8309/Kizzy) For Discord Integration.\n- **SimpMusic** by [maxrave-dev](https://github.com/maxrave-dev/SimpMusic) For Lyrics API Provider.\n- [BetterLyrics](https://better-lyrics.boidu.dev/) For word-by-word Lyrics API Provider.\n- [Material Color Utilities](https://github.com/material-foundation/material-color-utilities)\n- [Read You](https://github.com/Ashinch/ReadYou) and [Seal](https://github.com/JunkFood02/Seal) for Ui Components.\n- The global community of translators and beta testers.\n\n---\n\n## ‚öñÔ∏è Legal Disclaimer\n\nArchiveTune is an independent third-party client.\n- Not affiliated with Google LLC or YouTube.\n- Does not bypass YouTube's technical protections.\n- Users are encouraged to support artists by purchasing music via official channels.\n\n---\n\n<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/koiverse/ArchiveTune/refs/heads/dev/fastlane/metadata/android/en-US/images/ArchiveTuneFull.png\" alt=\"ArchiveTune Banner\" style=\"width: 100%; max-width: 500px;\">\n  <p><b>If ArchiveTune elevated your music experience, please consider giving us a ‚≠ê</b></p>\n  <br />\n  Made with üíú by <strong>Koiverse</strong>\n</div>",
      "stars_today": 13
    },
    {
      "id": 262126497,
      "name": "syft",
      "full_name": "anchore/syft",
      "description": "CLI tool and library for generating a Software Bill of Materials from container images and filesystems",
      "html_url": "https://github.com/anchore/syft",
      "stars": 8259,
      "forks": 754,
      "language": "Go",
      "topics": [
        "containers",
        "cyclonedx",
        "docker",
        "go",
        "golang",
        "hacktoberfest",
        "oci",
        "sbom",
        "spdx",
        "static-analysis",
        "tool"
      ],
      "created_at": "2020-05-07T18:19:29Z",
      "updated_at": "2026-01-22T23:50:55Z",
      "pushed_at": "2026-01-22T18:04:47Z",
      "open_issues": 516,
      "owner": {
        "login": "anchore",
        "avatar_url": "https://avatars.githubusercontent.com/u/16208487?v=4"
      },
      "readme": "<p align=\"center\">\n    <img src=\"https://user-images.githubusercontent.com/5199289/136844524-1527b09f-c5cb-4aa9-be54-5aa92a6086c1.png\" width=\"271\" alt=\"Cute pink owl syft logo\">\n</p>\n\n# Syft\n\n**A CLI tool and Go library for generating a Software Bill of Materials (SBOM) from container images and filesystems. Exceptional for vulnerability detection when used with a scanner like [Grype](https://github.com/anchore/grype).**\n\n<p align=\"center\">\n &nbsp;<a href=\"https://github.com/anchore/syft/actions/workflows/validations.yaml\" target=\"_blank\"><img alt=\"Validations\" src=\"https://github.com/anchore/syft/actions/workflows/validations.yaml/badge.svg\"></a>&nbsp;\n &nbsp;<a href=\"https://goreportcard.com/report/github.com/anchore/syft\" target=\"_blank\"><img alt=\"Go Report Card\" src=\"https://goreportcard.com/badge/github.com/anchore/syft\"></a>&nbsp;\n &nbsp;<a href=\"https://github.com/anchore/syft/releases/latest\" target=\"_blank\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/anchore/syft.svg\"></a>&nbsp;\n &nbsp;<a href=\"https://github.com/anchore/syft\" target=\"_blank\"><img alt=\"GitHub go.mod Go version\" src=\"https://img.shields.io/github/go-mod/go-version/anchore/syft.svg\"></a>&nbsp;\n &nbsp;<a href=\"\" target=\"_blank\"><img alt=\"License: Apache-2.0\" src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\"></a>&nbsp;\n &nbsp;<a href=\"https://anchore.com/discourse\" target=\"_blank\"><img alt=\"Join our Discourse\" src=\"https://img.shields.io/badge/Discourse-Join-blue?logo=discourse\"/></a>&nbsp;\n &nbsp;<a rel=\"me\" href=\"https://fosstodon.org/@syft\"><img alt=\"Follow on Mastodon\" src=\"https://img.shields.io/badge/Mastodon-Follow-blue?logoColor=white&logo=mastodon\"/></a>&nbsp;\n</p>\n\n![syft-demo](https://user-images.githubusercontent.com/590471/90277200-2a253000-de33-11ea-893f-32c219eea11a.gif)\n\n## Features\n\n- Generates SBOMs for **container images**, **filesystems**, **archives** (see the docs for a full list of [supported scan targets](https://oss.anchore.com/docs/guides/sbom/scan-targets/))\n- Supports dozens of packaging ecosystems (e.g. Alpine (apk), Debian (dpkg), RPM, Go, Python, Java, JavaScript, Ruby, Rust, PHP, .NET, and [many more](https://oss.anchore.com/docs/capabilities/all-packages/))\n- Supports OCI, Docker, [Singularity](https://github.com/sylabs/singularity), and [more image formats](https://oss.anchore.com/docs/guides/sbom/scan-targets/)\n- Works seamlessly with [Grype](https://github.com/anchore/grype) for vulnerability scanning\n- Multiple output formats (**CycloneDX**, **SPDX**, **Syft JSON**, and [more](https://oss.anchore.com/docs/guides/sbom/formats/)) including the ability to [convert between SBOM formats](https://oss.anchore.com/docs/guides/sbom/conversion/)\n- Create signed SBOM attestations using the [in-toto specification](https://github.com/in-toto/attestation/blob/main/spec/README.md)\n\n> [!TIP]\n> **New to Syft? Check out the [Getting Started guide](https://oss.anchore.com/docs/guides/sbom/getting-started/) for a walkthrough!**\n\n## Installation\n\nThe quickest way to get up and going:\n```bash\ncurl -sSfL https://get.anchore.io/syft | sudo sh -s -- -b /usr/local/bin\n```\n\n> [!TIP]\n> **See [Installation docs](https://oss.anchore.com/docs/installation/syft/) for more ways to get Syft, including Homebrew, Docker, Scoop, Chocolatey, Nix, and more!**\n\n## The basics\n\nSee the packages within a container image or directory:\n\n```bash\n# container image\nsyft alpine:latest\n\n# directory\nsyft ./my-project\n```\n\nTo get an SBOM, specify one or more output formats:\n\n```bash\n# SBOM to stdout\nsyft <image> -o cyclonedx-json\n\n# Multiple SBOMs to files\nsyft <image> -o spdx-json=./spdx.json -o cyclonedx-json=./cdx.json\n```\n\n\n> [!TIP]\n> **Check out the [Getting Started guide](https://oss.anchore.com/docs/guides/sbom/getting-started/)** to explore all of the capabilities and features.\n>\n> **Want to know all of the ins-and-outs of Syft?** Check out the [CLI docs](https://oss.anchore.com/docs/reference/syft/cli/),  [configuration docs](https://oss.anchore.com/docs/reference/syft/configuration/), and [JSON schema](https://oss.anchore.com/docs/reference/syft/json/latest/).\n\n\n## Contributing\n\nWe encourage users to help make these tools better by [submitting issues](https://github.com/anchore/syft/issues) when you find a bug or want a new feature. \nCheck out our [contributing overview](https://oss.anchore.com/docs/contributing/) and [developer-specific documentation](https://oss.anchore.com/docs/contributing/syft/) if you are interested in providing code contributions.\n\n\n\n<p xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dct=\"http://purl.org/dc/terms/\">\n  Syft development is sponsored by <a href=\"https://anchore.com/\">Anchore</a>, and is released under the <a href=\"https://github.com/anchore/syft?tab=Apache-2.0-1-ov-file\">Apache-2.0 License</a>.\n  The <a property=\"dct:title\" rel=\"cc:attributionURL\" href=\"https://anchore.com/wp-content/uploads/2024/11/syft-logo.svg\">Syft logo</a> by <a rel=\"cc:attributionURL dct:creator\" property=\"cc:attributionName\" href=\"https://anchore.com/\">Anchore</a> is licensed under <a href=\"https://creativecommons.org/licenses/by/4.0/\" target=\"_blank\" rel=\"license noopener noreferrer\" style=\"display:inline-block;\">CC BY 4.0<img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg\" alt=\"\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg\" alt=\"\"></a>\n</p>\n\nFor commercial support options with Syft or Grype, please [contact Anchore](https://get.anchore.com/contact/).\n\n## Come talk to us!\n\nThe Syft Team holds regular community meetings online. All are welcome to join to bring topics for discussion.\n- Check the [calendar](https://calendar.google.com/calendar/u/0/r?cid=Y182OTM4dGt0MjRtajI0NnNzOThiaGtnM29qNEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t) for the next meeting date.\n- Add items to the [agenda](https://docs.google.com/document/d/1ZtSAa6fj2a6KRWviTn3WoJm09edvrNUp4Iz_dOjjyY8/edit?usp=sharing) (join [this group](https://groups.google.com/g/anchore-oss-community) for write access to the [agenda](https://docs.google.com/document/d/1ZtSAa6fj2a6KRWviTn3WoJm09edvrNUp4Iz_dOjjyY8/edit?usp=sharing))\n- See you there!\n",
      "stars_today": 12
    },
    {
      "id": 167174,
      "name": "jquery",
      "full_name": "jquery/jquery",
      "description": "jQuery JavaScript Library",
      "html_url": "https://github.com/jquery/jquery",
      "stars": 59786,
      "forks": 20501,
      "language": "JavaScript",
      "topics": [
        "jquery"
      ],
      "created_at": "2009-04-03T15:20:14Z",
      "updated_at": "2026-01-22T22:54:00Z",
      "pushed_at": "2026-01-21T23:02:23Z",
      "open_issues": 94,
      "owner": {
        "login": "jquery",
        "avatar_url": "https://avatars.githubusercontent.com/u/70142?v=4"
      },
      "readme": "# [jQuery](https://jquery.com/) ‚Äî New Wave JavaScript\n\nMeetings are currently held on the [matrix.org platform](https://matrix.to/#/#jquery_meeting:gitter.im).\n\nMeeting minutes can be found at [meetings.jquery.org](https://meetings.jquery.org/category/core/).\n\nThe latest version of jQuery is available at [https://jquery.com/download/](https://jquery.com/download/).\n\n## Version support\n\n| Version | Branch     | Status   |\n| ------- | ---------- | -------- |\n| 4.x     | main       | Beta     |\n| 3.x     | 3.x-stable | Active   |\n| 2.x     | 2.x-stable | Inactive |\n| 1.x     | 1.x-stable | Inactive |\n\nOnce 4.0.0 final is released, the 3.x branch will continue to receive updates for a limited time. The 2.x and 1.x branches are no longer supported.\n\nCommercial support for inactive versions is available from [HeroDevs](https://herodevs.com/support/jquery-nes).\n\nLearn more about our [version support](https://jquery.com/support/).\n\n## Contribution Guides\n\nIn the spirit of open source software development, jQuery always encourages community code contribution. To help you get started and before you jump into writing code, be sure to read these important contribution guidelines thoroughly:\n\n1. [Getting Involved](https://contribute.jquery.org/)\n2. [Core Style Guide](https://contribute.jquery.org/style-guide/js/)\n3. [Writing Code for jQuery Projects](https://contribute.jquery.org/code/)\n\n### References to issues/PRs\n\nGitHub issues/PRs are usually referenced via `gh-NUMBER`, where `NUMBER` is the numerical ID of the issue/PR. You can find such an issue/PR under `https://github.com/jquery/jquery/issues/NUMBER`.\n\njQuery has used a different bug tracker - based on Trac - in the past, available under [bugs.jquery.com](https://bugs.jquery.com/). It is being kept in read only mode so that referring to past discussions is possible. When jQuery source references one of those issues, it uses the pattern `trac-NUMBER`, where `NUMBER` is the numerical ID of the issue. You can find such an issue under `https://bugs.jquery.com/ticket/NUMBER`.\n\n## Environments in which to use jQuery\n\n- [Browser support](https://jquery.com/browser-support/)\n- jQuery also supports Node, browser extensions, and other non-browser environments.\n\n## What you need to build your own jQuery\n\nTo build jQuery, you need to have the latest Node.js/npm and git 1.7 or later. Earlier versions might work, but are not supported.\n\nFor Windows, you have to download and install [git](https://git-scm.com/downloads) and [Node.js](https://nodejs.org/en/download/).\n\nmacOS users should install [Homebrew](https://brew.sh/). Once Homebrew is installed, run `brew install git` to install git,\nand `brew install node` to install Node.js.\n\nLinux/BSD users should use their appropriate package managers to install git and Node.js, or build from source\nif you swing that way. Easy-peasy.\n\n## How to build your own jQuery\n\nFirst, [clone the jQuery git repo](https://help.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository).\n\nThen, enter the jquery directory, install dependencies, and run the build script:\n\n```bash\ncd jquery\nnpm install\nnpm run build\n```\n\nThe built version of jQuery will be placed in the `dist/` directory, along with a minified copy and associated map file.\n\n## Build all jQuery release files\n\nTo build all variants of jQuery, run the following command:\n\n```bash\nnpm run build:all\n```\n\nThis will create all of the variants that jQuery includes in a release, including `jquery.js`, `jquery.slim.js`, `jquery.module.js`, and `jquery.slim.module.js` along their associated minified files and sourcemaps.\n\n`jquery.module.js` and `jquery.slim.module.js` are [ECMAScript modules](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules) that export `jQuery` and `$` as named exports are placed in the `dist-module/` directory rather than the `dist/` directory.\n\n## Building a Custom jQuery\n\nThe build script can be used to create a custom version of jQuery that includes only the modules you need.\n\nAny module may be excluded except for `core`. When excluding `selector`, it is not removed but replaced with a small wrapper around native `querySelectorAll` (see below for more information).\n\n### Build Script Help\n\nTo see the full list of available options for the build script, run the following:\n\n```bash\nnpm run build -- --help\n```\n\n### Modules\n\nTo exclude a module, pass its path relative to the `src` folder (without the `.js` extension) to the `--exclude` option. When using the `--include` option, the default includes are dropped and a build is created with only those modules.\n\nSome example modules that can be excluded or included are:\n\n- **ajax**: All AJAX functionality: `$.ajax()`, `$.get()`, `$.post()`, `$.ajaxSetup()`, `.load()`, transports, and ajax event shorthands such as `.ajaxStart()`.\n- **ajax/xhr**: The XMLHTTPRequest AJAX transport only.\n- **ajax/script**: The `<script>` AJAX transport only; used to retrieve scripts.\n- **ajax/jsonp**: The JSONP AJAX transport only; depends on the ajax/script transport.\n- **css**: The `.css()` method. Also removes **all** modules depending on css (including **effects**, **dimensions**, and **offset**).\n- **css/showHide**: Non-animated `.show()`, `.hide()` and `.toggle()`; can be excluded if you use classes or explicit `.css()` calls to set the `display` property. Also removes the **effects** module.\n- **deprecated**: Methods documented as deprecated but not yet removed.\n- **dimensions**: The `.width()` and `.height()` methods, including `inner-` and `outer-` variations.\n- **effects**: The `.animate()` method and its shorthands such as `.slideUp()` or `.hide(\"slow\")`.\n- **event**: The `.on()` and `.off()` methods and all event functionality.\n- **event/trigger**: The `.trigger()` and `.triggerHandler()` methods.\n- **offset**: The `.offset()`, `.position()`, `.offsetParent()`, `.scrollLeft()`, and `.scrollTop()` methods.\n- **wrap**: The `.wrap()`, `.wrapAll()`, `.wrapInner()`, and `.unwrap()` methods.\n- **core/ready**: Exclude the ready module if you place your scripts at the end of the body. Any ready callbacks bound with `jQuery()` will simply be called immediately. However, `jQuery(document).ready()` will not be a function and `.on(\"ready\", ...)` or similar will not be triggered.\n- **deferred**: Exclude jQuery.Deferred. This also excludes all modules that rely on Deferred, including **ajax**, **effects**, and **queue**, but replaces **core/ready** with **core/ready-no-deferred**.\n- **exports/global**: Exclude the attachment of global jQuery variables ($ and jQuery) to the window.\n- **exports/amd**: Exclude the AMD definition.\n\n- **selector**: The full jQuery selector engine. When this module is excluded, it is replaced with a rudimentary selector engine based on the browser's `querySelectorAll` method that does not support jQuery selector extensions or enhanced semantics. See the [selector-native.js](https://github.com/jquery/jquery/blob/main/src/selector-native.js) file for details.\n\n*Note*: Excluding the full `selector` module will also exclude all jQuery selector extensions (such as `effects/animatedSelector` and `css/hiddenVisibleSelectors`).\n\n##### AMD name\n\nYou can set the module name for jQuery's AMD definition. By default, it is set to \"jquery\", which plays nicely with plugins and third-party libraries, but there may be cases where you'd like to change this. Pass it to the `--amd` parameter:\n\n```bash\nnpm run build -- --amd=\"custom-name\"\n```\n\nOr, to define anonymously, leave the name blank.\n\n```bash\nnpm run build -- --amd\n```\n\n##### File name and directory\n\nThe default name for the built jQuery file is `jquery.js`; it is placed under the `dist/` directory. It's possible to change the file name using `--filename` and the directory using `--dir`. `--dir` is relative to the project root.\n\n```bash\nnpm run build -- --slim --filename=\"jquery.slim.js\" --dir=\"/tmp\"\n```\n\nThis would create a slim version of jQuery and place it under `tmp/jquery.slim.js`.\n\n##### ECMAScript Module (ESM) mode\n\nBy default, jQuery generates a regular script JavaScript file. You can also generate an ECMAScript module exporting `jQuery` as the default export using the `--esm` parameter:\n\n```bash\nnpm run build -- --filename=jquery.module.js --esm\n```\n\n##### Factory mode\n\nBy default, jQuery depends on a global `window`. For environments that don't have one, you can generate a factory build that exposes a function accepting `window` as a parameter that you can provide externally (see [`README` of the published package](build/fixtures/README.md) for usage instructions). You can generate such a factory using the `--factory` parameter:\n\n```bash\nnpm run build -- --filename=jquery.factory.js --factory\n```\n\nThis option can be mixed with others like `--esm` or `--slim`:\n\n```bash\nnpm run build -- --filename=jquery.factory.slim.module.js --factory --esm --slim --dir=\"/dist-module\"\n```\n\n#### Custom Build Examples\n\nCreate a custom build using `npm run build`, listing the modules to be excluded. Excluding a top-level module also excludes its corresponding directory of modules.\n\nExclude all **ajax** functionality:\n\n```bash\nnpm run build -- --exclude=ajax\n```\n\nExcluding **css** removes modules depending on CSS: **effects**, **offset**, **dimensions**.\n\n```bash\nnpm run build -- --exclude=css\n```\n\nExclude a bunch of modules (`-e` is an alias for `--exclude`):\n\n```bash\nnpm run build -- -e ajax/jsonp -e css -e deprecated -e dimensions -e effects -e offset -e wrap\n```\n\nThere is a special alias to generate a build with the same configuration as the official jQuery Slim build:\n\n```bash\nnpm run build -- --filename=jquery.slim.js --slim\n```\n\nOr, to create the slim build as an esm module:\n\n```bash\nnpm run build -- --filename=jquery.slim.module.js --slim --esm\n```\n\n*Non-official custom builds are not regularly tested. Use them at your own risk.*\n\n## Running the Unit Tests\n\nMake sure you have the necessary dependencies:\n\n```bash\nnpm install\n```\n\nStart `npm start` to auto-build jQuery as you work:\n\n```bash\nnpm start\n```\n\nRun the unit tests with a local server that supports PHP. Ensure that you run the site from the root directory, not the \"test\" directory. No database is required. Pre-configured php local servers are available for Windows and Mac. Here are some options:\n\n- Windows: [WAMP download](https://www.wampserver.com/en/)\n- Mac: [MAMP download](https://www.mamp.info/en/downloads/)\n- Linux: [Setting up LAMP](https://www.linux.com/training-tutorials/easy-lamp-server-installation/)\n- [Mongoose (most platforms)](https://code.google.com/p/mongoose/)\n\n## Essential Git\n\nAs the source code is handled by the Git version control system, it's useful to know some features used.\n\n### Cleaning\n\nIf you want to purge your working directory back to the status of upstream, the following commands can be used (remember everything you've worked on is gone after these):\n\n```bash\ngit reset --hard upstream/main\ngit clean -fdx\n```\n\n### Rebasing\n\nFor feature/topic branches, you should always use the `--rebase` flag to `git pull`, or if you are usually handling many temporary \"to be in a github pull request\" branches, run the following to automate this:\n\n```bash\ngit config branch.autosetuprebase local\n```\n\n(see `man git-config` for more information)\n\n### Handling merge conflicts\n\nIf you're getting merge conflicts when merging, instead of editing the conflicted files manually, you can use the feature\n`git mergetool`. Even though the default tool `xxdiff` looks awful/old, it's rather useful.\n\nThe following are some commands that can be used there:\n\n- `Ctrl + Alt + M` - automerge as much as possible\n- `b` - jump to next merge conflict\n- `s` - change the order of the conflicted lines\n- `u` - undo a merge\n- `left mouse button` - mark a block to be the winner\n- `middle mouse button` - mark a line to be the winner\n- `Ctrl + S` - save\n- `Ctrl + Q` - quit\n\n## [QUnit](https://api.qunitjs.com) Reference\n\n### Test methods\n\n```js\nexpect( numAssertions );\nstop();\nstart();\n```\n\n*Note*: QUnit's eventual addition of an argument to stop/start is ignored in this test suite so that start and stop can be passed as callbacks without worrying about their parameters.\n\n### Test assertions\n\n```js\nok( value, [message] );\nequal( actual, expected, [message] );\nnotEqual( actual, expected, [message] );\ndeepEqual( actual, expected, [message] );\nnotDeepEqual( actual, expected, [message] );\nstrictEqual( actual, expected, [message] );\nnotStrictEqual( actual, expected, [message] );\nthrows( block, [expected], [message] );\n```\n\n## Test Suite Convenience Methods Reference\n\nSee [test/data/testinit.js](https://github.com/jquery/jquery/blob/main/test/data/testinit.js).\n\n### Returns an array of elements with the given IDs\n\n```js\nq( ... );\n```\n\nExample:\n\n```js\nq( \"main\", \"foo\", \"bar\" );\n\n=> [ div#main, span#foo, input#bar ]\n```\n\n### Asserts that a selection matches the given IDs\n\n```js\nt( testName, selector, [ \"array\", \"of\", \"ids\" ] );\n```\n\nExample:\n\n```js\nt(\"Check for something\", \"//[a]\", [\"foo\", \"bar\"]);\n```\n\n### Fires a native DOM event without going through jQuery\n\n```js\nfireNative( node, eventType );\n```\n\nExample:\n\n```js\nfireNative( jQuery( \"#elem\" )[ 0 ], \"click\" );\n```\n\n### Add random number to url to stop caching\n\n```js\nurl( \"some/url\" );\n```\n\nExample:\n\n```js\nurl( \"index.html\" );\n\n=> \"data/index.html?10538358428943\"\n\n\nurl( \"mock.php?foo=bar\" );\n\n=> \"data/mock.php?foo=bar&10538358345554\"\n```\n\n### Run tests in an iframe\n\nSome tests may require a document other than the standard test fixture, and\nthese can be run in a separate iframe. The actual test code and assertions\nremain in jQuery's main test files; only the minimal test fixture markup\nand setup code should be placed in the iframe file.\n\n```js\ntestIframe( testName, fileName,\n  function testCallback(\n      assert, jQuery, window, document,\n\t  [ additional args ] ) {\n\t...\n  } );\n```\n\nThis loads a page, constructing a url with fileName `\"./data/\" + fileName`.\nThe iframed page determines when the callback occurs in the test by\nincluding the \"/test/data/iframeTest.js\" script and calling\n`startIframeTest( [ additional args ] )` when appropriate. Often this\nwill be after either document ready or `window.onload` fires.\n\nThe `testCallback` receives the QUnit `assert` object created by `testIframe`\nfor this test, followed by the global `jQuery`, `window`, and `document` from\nthe iframe. If the iframe code passes any arguments to `startIframeTest`,\nthey follow the `document` argument.\n\n## Questions?\n\nIf you have any questions, please feel free to ask on the\n[Developing jQuery Core forum](https://forum.jquery.com/developing-jquery-core) or in #jquery on [libera](https://web.libera.chat/).\n",
      "stars_today": 10
    },
    {
      "id": 8859474,
      "name": "jadx",
      "full_name": "skylot/jadx",
      "description": "Dex to Java decompiler",
      "html_url": "https://github.com/skylot/jadx",
      "stars": 46983,
      "forks": 5401,
      "language": "Java",
      "topics": [
        "android",
        "decompiler",
        "dex",
        "java"
      ],
      "created_at": "2013-03-18T17:08:21Z",
      "updated_at": "2026-01-23T01:50:05Z",
      "pushed_at": "2026-01-21T20:30:40Z",
      "open_issues": 405,
      "owner": {
        "login": "skylot",
        "avatar_url": "https://avatars.githubusercontent.com/u/118523?v=4"
      },
      "readme": "<img src=\"https://raw.githubusercontent.com/skylot/jadx/master/jadx-gui/src/main/resources/logos/jadx-logo.png\" width=\"64\" align=\"left\" />\n\n## JADX\n\n![Build status](https://img.shields.io/github/actions/workflow/status/skylot/jadx/build-artifacts.yml)\n![GitHub contributors](https://img.shields.io/github/contributors/skylot/jadx)\n![GitHub all releases](https://img.shields.io/github/downloads/skylot/jadx/total)\n![GitHub release (latest by SemVer)](https://img.shields.io/github/downloads/skylot/jadx/latest/total)\n![Latest release](https://img.shields.io/github/release/skylot/jadx.svg)\n[![Maven Central](https://img.shields.io/maven-central/v/io.github.skylot/jadx-core)](https://search.maven.org/search?q=g:io.github.skylot%20AND%20jadx)\n![Java 11+](https://img.shields.io/badge/Java-11%2B-blue)\n[![License](http://img.shields.io/:license-apache-blue.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)\n\n**jadx** - Dex to Java decompiler\n\nCommand line and GUI tools for producing Java source code from Android Dex and Apk files\n\n> [!WARNING]\n> Please note that in most cases **jadx** can't decompile all 100% of the code, so errors will occur.<br />\n> Check [Troubleshooting guide](https://github.com/skylot/jadx/wiki/Troubleshooting-Q&A#decompilation-issues) for workarounds.\n\n**Main features:**\n- decompile Dalvik bytecode to Java code from APK, dex, aar, aab and zip files\n- decode `AndroidManifest.xml` and other resources from `resources.arsc`\n- deobfuscator included\n\n**jadx-gui features:**\n- view decompiled code with highlighted syntax\n- jump to declaration\n- find usage\n- full text search\n- smali debugger, check [wiki page](https://github.com/skylot/jadx/wiki/Smali-debugger) for setup and usage\n\nJadx-gui key bindings can be found [here](https://github.com/skylot/jadx/wiki/JADX-GUI-Key-bindings)\n\nSee these features in action here: [jadx-gui features overview](https://github.com/skylot/jadx/wiki/jadx-gui-features-overview)\n\n<img src=\"https://user-images.githubusercontent.com/118523/142730720-839f017e-38db-423e-b53f-39f5f0a0316f.png\" width=\"700\"/>\n\n### Download\n- release\n  from [github: ![Latest release](https://img.shields.io/github/release/skylot/jadx.svg)](https://github.com/skylot/jadx/releases/latest)\n- latest [unstable build ![GitHub commits since tagged version (branch)](https://img.shields.io/github/commits-since/skylot/jadx/latest/master)](https://nightly.link/skylot/jadx/workflows/build-artifacts/master)\n\nAfter download unpack zip file go to `bin` directory and run:\n- `jadx` - command line version\n- `jadx-gui` - UI version\n\nOn Windows run `.bat` files with double-click\\\n**Note:** ensure you have installed Java 11 or later 64-bit version.\nFor Windows, you can download it from [oracle.com](https://www.oracle.com/java/technologies/downloads/#jdk17-windows) (select x64 Installer).\n\n### Install\n- Arch Linux\n  [![Arch Linux package](https://img.shields.io/archlinux/v/extra/any/jadx)](https://archlinux.org/packages/extra/any/jadx/)\n  [![AUR Version](https://img.shields.io/aur/version/jadx-git)](https://aur.archlinux.org/packages/jadx-git)\n  ```bash\n  sudo pacman -S jadx\n  ```\n- macOS\n  [![homebrew version](https://img.shields.io/homebrew/v/jadx)](https://formulae.brew.sh/formula/jadx)\n  ```bash\n  brew install jadx\n  ```\n- Flathub\n  [![Flathub Version](https://img.shields.io/flathub/v/com.github.skylot.jadx)](https://flathub.org/apps/com.github.skylot.jadx)\n  ```bash\n  flatpak install flathub com.github.skylot.jadx\n  ```\n\n### Use jadx as a library\nYou can use jadx in your java projects, check details on [wiki page](https://github.com/skylot/jadx/wiki/Use-jadx-as-a-library)\n\n### Build from source\nJDK 11 or higher must be installed:\n```\ngit clone https://github.com/skylot/jadx.git\ncd jadx\n./gradlew dist\n```\n\n(on Windows, use `gradlew.bat` instead of `./gradlew`)\n\nScripts for run jadx will be placed in `build/jadx/bin`\nand also packed to `build/jadx-<version>.zip`\n\n### Usage\n```\njadx[-gui] [command] [options] <input files> (.apk, .dex, .jar, .class, .smali, .zip, .aar, .arsc, .aab, .xapk, .apkm, .jadx.kts)\ncommands (use '<command> --help' for command options):\n  plugins\t  - manage jadx plugins\n\noptions:\n  -d, --output-dir                              - output directory\n  -ds, --output-dir-src                         - output directory for sources\n  -dr, --output-dir-res                         - output directory for resources\n  -r, --no-res                                  - do not decode resources\n  -s, --no-src                                  - do not decompile source code\n  -j, --threads-count                           - processing threads count, default: 16\n  --single-class                                - decompile a single class, full name, raw or alias\n  --single-class-output                         - file or dir for write if decompile a single class\n  --output-format                               - can be 'java' or 'json', default: java\n  -e, --export-gradle                           - save as gradle project (set '--export-gradle-type' to 'auto')\n  --export-gradle-type                          - Gradle project template for export:\n                                                   'auto' - detect automatically\n                                                   'android-app' - Android Application (apk)\n                                                   'android-library' - Android Library (aar)\n                                                   'simple-java' - simple Java\n  -m, --decompilation-mode                      - code output mode:\n                                                   'auto' - trying best options (default)\n                                                   'restructure' - restore code structure (normal java code)\n                                                   'simple' - simplified instructions (linear, with goto's)\n                                                   'fallback' - raw instructions without modifications\n  --show-bad-code                               - show inconsistent code (incorrectly decompiled)\n  --no-xml-pretty-print                         - do not prettify XML\n  --no-imports                                  - disable use of imports, always write entire package name\n  --no-debug-info                               - disable debug info parsing and processing\n  --add-debug-lines                             - add comments with debug line numbers if available\n  --no-inline-anonymous                         - disable anonymous classes inline\n  --no-inline-methods                           - disable methods inline\n  --no-move-inner-classes                       - disable move inner classes into parent\n  --no-inline-kotlin-lambda                     - disable inline for Kotlin lambdas\n  --no-finally                                  - don't extract finally block\n  --no-restore-switch-over-string               - don't restore switch over string\n  --no-replace-consts                           - don't replace constant value with matching constant field\n  --escape-unicode                              - escape non latin characters in strings (with \\u)\n  --respect-bytecode-access-modifiers           - don't change original access modifiers\n  --mappings-path                               - deobfuscation mappings file or directory. Allowed formats: Tiny and Tiny v2 (both '.tiny'), Enigma (.mapping) or Enigma directory\n  --mappings-mode                               - set mode for handling the deobfuscation mapping file:\n                                                   'read' - just read, user can always save manually (default)\n                                                   'read-and-autosave-every-change' - read and autosave after every change\n                                                   'read-and-autosave-before-closing' - read and autosave before exiting the app or closing the project\n                                                   'ignore' - don't read or save (can be used to skip loading mapping files referenced in the project file)\n  --deobf                                       - activate deobfuscation\n  --deobf-min                                   - min length of name, renamed if shorter, default: 3\n  --deobf-max                                   - max length of name, renamed if longer, default: 64\n  --deobf-whitelist                             - space separated list of classes (full name) and packages (ends with '.*') to exclude from deobfuscation, default: android.support.v4.* android.support.v7.* android.support.v4.os.* android.support.annotation.Px androidx.core.os.* androidx.annotation.Px\n  --deobf-cfg-file                              - deobfuscation mappings file used for JADX auto-generated names (in the JOBF file format), default: same dir and name as input file with '.jobf' extension\n  --deobf-cfg-file-mode                         - set mode for handling the JADX auto-generated names' deobfuscation map file:\n                                                   'read' - read if found, don't save (default)\n                                                   'read-or-save' - read if found, save otherwise (don't overwrite)\n                                                   'overwrite' - don't read, always save\n                                                   'ignore' - don't read and don't save\n  --deobf-res-name-source                       - better name source for resources:\n                                                   'auto' - automatically select best name (default)\n                                                   'resources' - use resources names\n                                                   'code' - use R class fields names\n  --use-source-name-as-class-name-alias         - use source name as class name alias:\n                                                   'always' - always use source name if it's available\n                                                   'if-better' - use source name if it seems better than the current one\n                                                   'never' - never use source name, even if it's available\n  --source-name-repeat-limit                    - allow using source name if it appears less than a limit number, default: 10\n  --use-kotlin-methods-for-var-names            - use kotlin intrinsic methods to rename variables, values: disable, apply, apply-and-hide, default: apply\n  --use-headers-for-detect-resource-extensions  - Use headers for detect resource extensions if resource obfuscated\n  --rename-flags                                - fix options (comma-separated list of):\n                                                   'case' - fix case sensitivity issues (according to --fs-case-sensitive option),\n                                                   'valid' - rename java identifiers to make them valid,\n                                                   'printable' - remove non-printable chars from identifiers,\n                                                  or single 'none' - to disable all renames\n                                                  or single 'all' - to enable all (default)\n  --integer-format                              - how integers are displayed:\n                                                   'auto' - automatically select (default)\n                                                   'decimal' - use decimal\n                                                   'hexadecimal' - use hexadecimal\n  --type-update-limit                           - type update limit count (per one instruction), default: 10\n  --fs-case-sensitive                           - treat filesystem as case sensitive, false by default\n  --cfg                                         - save methods control flow graph to dot file\n  --raw-cfg                                     - save methods control flow graph (use raw instructions)\n  -f, --fallback                                - set '--decompilation-mode' to 'fallback' (deprecated)\n  --use-dx                                      - use dx/d8 to convert java bytecode\n  --comments-level                              - set code comments level, values: error, warn, info, debug, user-only, none, default: info\n  --log-level                                   - set log level, values: quiet, progress, error, warn, info, debug, default: progress\n  -v, --verbose                                 - verbose output (set --log-level to DEBUG)\n  -q, --quiet                                   - turn off output (set --log-level to QUIET)\n  --disable-plugins                             - comma separated list of plugin ids to disable\n  --config <config-ref>                         - load configuration from file, <config-ref> can be:\n                                                   path to '.json' file\n                                                   short name - uses file with this name from config directory\n                                                   'none' - to disable config loading\n  --save-config <config-ref>                    - save current options into configuration file and exit, <config-ref> can be:\n                                                   empty - for default config\n                                                   path to '.json' file\n                                                   short name - file will be saved in config directory\n  --print-files                                 - print files and directories used by jadx (config, cache, temp)\n  --version                                     - print jadx version\n  -h, --help                                    - print this help\n\nPlugin options (-P<name>=<value>):\n  dex-input: Load .dex and .apk files\n    - dex-input.verify-checksum                 - verify dex file checksum before load, values: [yes, no], default: yes\n  java-convert: Convert .class, .jar and .aar files to dex\n    - java-convert.mode                         - convert mode, values: [dx, d8, both], default: both\n    - java-convert.d8-desugar                   - use desugar in d8, values: [yes, no], default: no\n  kotlin-metadata: Use kotlin.Metadata annotation for code generation\n    - kotlin-metadata.class-alias               - rename class alias, values: [yes, no], default: yes\n    - kotlin-metadata.method-args               - rename function arguments, values: [yes, no], default: yes\n    - kotlin-metadata.fields                    - rename fields, values: [yes, no], default: yes\n    - kotlin-metadata.companion                 - rename companion object, values: [yes, no], default: yes\n    - kotlin-metadata.data-class                - add data class modifier, values: [yes, no], default: yes\n    - kotlin-metadata.to-string                 - rename fields using toString, values: [yes, no], default: yes\n    - kotlin-metadata.getters                   - rename simple getters to field names, values: [yes, no], default: yes\n  kotlin-smap: Use kotlin.SourceDebugExtension annotation for rename class alias\n    - kotlin-smap.class-alias-source-dbg        - rename class alias from SourceDebugExtension, values: [yes, no], default: no\n  rename-mappings: various mappings support\n    - rename-mappings.format                    - mapping format, values: [AUTO, TINY_FILE, TINY_2_FILE, ENIGMA_FILE, ENIGMA_DIR, PROGUARD_FILE, SRG_FILE, XSRG_FILE, JAM_FILE, CSRG_FILE, TSRG_FILE, TSRG_2_FILE, INTELLIJ_MIGRATION_MAP_FILE, RECAF_SIMPLE_FILE, JOBF_FILE], default: AUTO\n    - rename-mappings.invert                    - invert mapping on load, values: [yes, no], default: no\n  smali-input: Load .smali files\n    - smali-input.api-level                     - Android API level, default: 27\n\nEnvironment variables:\n  JADX_DISABLE_XML_SECURITY - set to 'true' to disable all security checks for XML files\n  JADX_DISABLE_ZIP_SECURITY - set to 'true' to disable all security checks for zip files\n  JADX_ZIP_MAX_ENTRIES_COUNT - maximum allowed number of entries in zip files (default: 100 000)\n  JADX_CONFIG_DIR - custom config directory, using system by default\n  JADX_CACHE_DIR - custom cache directory, using system by default\n  JADX_TMP_DIR - custom temp directory, using system by default\n\nExamples:\n  jadx -d out classes.dex\n  jadx --rename-flags \"none\" classes.dex\n  jadx --rename-flags \"valid, printable\" classes.dex\n  jadx --log-level ERROR app.apk\n  jadx -Pdex-input.verify-checksum=no app.apk\n```\nThese options also work in jadx-gui running from command line and override options from preferences' dialog\n\nUsage for `plugins` command\n```\nusage: plugins [options]\noptions:\n  -i, --install <locationId>      - install plugin with locationId\n  -j, --install-jar <path-to.jar> - install plugin from jar file\n  -l, --list                      - list installed plugins\n  -a, --available                 - list available plugins from jadx-plugins-list (aka marketplace)\n  -u, --update                    - update installed plugins\n  --uninstall <pluginId>          - uninstall plugin with pluginId\n  --disable <pluginId>            - disable plugin with pluginId\n  --enable <pluginId>             - enable plugin with pluginId\n  --list-all                      - list all plugins including bundled and dropins\n  --list-versions <locationId>    - fetch latest versions of plugin from locationId (will download all artefacts, limited to 10)\n  -h, --help                      - print this help\n```\n\n\n### Troubleshooting\nPlease check wiki page [Troubleshooting Q&A](https://github.com/skylot/jadx/wiki/Troubleshooting-Q&A)\n\n### Contributing\nTo support this project you can:\n  - Post thoughts about new features/optimizations that important to you\n  - Submit decompilation issues, please read before proceed: [Open issue](CONTRIBUTING.md#Open-Issue)\n  - Open pull request, please follow these rules: [Pull Request Process](CONTRIBUTING.md#Pull-Request-Process)\n\n---------------------------------------\n*Licensed under the Apache 2.0 License*\n",
      "stars_today": 10
    },
    {
      "id": 75277003,
      "name": "thingsboard",
      "full_name": "thingsboard/thingsboard",
      "description": "Open-source IoT Platform - Device management, data collection, processing and visualization.",
      "html_url": "https://github.com/thingsboard/thingsboard",
      "stars": 20973,
      "forks": 6054,
      "language": "Java",
      "topics": [
        "cloud",
        "coap",
        "dashboard",
        "iot",
        "iot-analytics",
        "iot-platform",
        "iot-solutions",
        "java",
        "kafka",
        "lwm2m",
        "microservices",
        "middleware",
        "mqtt",
        "netty",
        "platform",
        "snmp",
        "thingsboard",
        "visualization",
        "websockets",
        "widgets"
      ],
      "created_at": "2016-12-01T09:33:30Z",
      "updated_at": "2026-01-23T00:38:44Z",
      "pushed_at": "2026-01-22T14:33:36Z",
      "open_issues": 164,
      "owner": {
        "login": "thingsboard",
        "avatar_url": "https://avatars.githubusercontent.com/u/24291394?v=4"
      },
      "readme": "![banner](https://github.com/user-attachments/assets/3584b592-33dd-4fb4-91d4-47b62b34806c)\n\n<div align=\"center\">\n\n# Open-source IoT platform for data collection, processing, visualization, and device management.\n\n</div>\n<br>\n<div align=\"center\">\n \nüí° [Get started](https://thingsboard.io/docs/getting-started-guides/helloworld/)&ensp;‚Ä¢&ensp;üåê [Website](https://thingsboard.io/)&ensp;‚Ä¢&ensp;üìö [Documentation](https://thingsboard.io/docs/)&ensp;‚Ä¢&ensp;üìî [Blog](https://thingsboard.io/blog/)&ensp;‚Ä¢&ensp;‚ñ∂Ô∏è [Live demo](https://demo.thingsboard.io/signup)&ensp;‚Ä¢&ensp;üîó [LinkedIn](https://www.linkedin.com/company/thingsboard/posts/?feedView=all)\n\n</div>\n\n## üöÄ Installation options\n\n* Install ThingsBoard [On-premise](https://thingsboard.io/docs/user-guide/install/installation-options/?ceInstallType=onPremise)\n* Try [ThingsBoard Cloud](https://thingsboard.io/installations/)\n* or [Use our Live demo](https://demo.thingsboard.io/signup)\n\n## üí° Getting started with ThingsBoard\n\nCheck out our [Getting Started guide](https://thingsboard.io/docs/getting-started-guides/helloworld/) or [watch the video](https://www.youtube.com/watch?v=80L0ubQLXsc) to learn the basics of ThingsBoard and create your first dashboard! You will learn to:\n\n* Connect devices to ThingsBoard\n* Push data from devices to ThingsBoard\n* Build real-time dashboards\n* Create a Customer and assign the dashboard with them.\n* Define thresholds and trigger alarms\n* Set up notifications via email, SMS, mobile apps, or integrate with third-party services.\n\n## ‚ú® Features\n\n<table>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/255cca4f-b111-44e8-99ea-0af55f8e3681\" alt=\"Provision and manage devices and assets\" width=\"378\" />\n        <h3>Provision and manage <br> devices and assets</h3>\n      </div>\n      <div align=\"center\">\n        <p>Provision, monitor and control your IoT entities in secure way using rich server-side APIs. Define relations between your devices, assets, customers or any other entities.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/docs/user-guide/entities-and-relations/\">Read more ‚ûú</a>\n      </div>\n      <br>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/24b41d10-150a-42dd-ab1a-32ac9b5978c1\" alt=\"Collect and visualize your data\" width=\"378\" />\n        <h3>Collect and visualize <br> your data</h3>\n      </div>\n      <div align=\"center\">\n        <p>Collect and store telemetry data in scalable and fault-tolerant way. Visualize your data with built-in or custom widgets and flexible dashboards. Share dashboards with your customers.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/iot-data-visualization/\">Read more ‚ûú</a>\n      </div>\n      <br>\n    </td>\n  </tr>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/6f2a6dd2-7b33-4d17-8b92-d1f995adda2c\" alt=\"SCADA Dashboards\" width=\"378\" />\n        <h3>SCADA Dashboards</h3>\n      </div>\n      <div align=\"center\">\n        <p>Monitor and control your industrial processes in real time with SCADA. Use SCADA symbols on dashboards to create and manage any workflow, offering full flexibility to design and oversee operations according to your requirements.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/use-cases/scada/\">Read more ‚ûú</a>\n      </div>\n      <br>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/c23dcc9b-aeba-40ef-9973-49b953fc1257\" alt=\"Process and React\" width=\"378\" />\n        <h3>Process and React</h3>\n      </div>\n      <div align=\"center\">\n        <p>Define data processing rule chains. Transform and normalize your device data. Raise alarms on incoming telemetry events, attribute updates, device inactivity and user actions.<br></p>\n      </div>\n      <br>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/\">Read more ‚ûú</a>\n      </div>\n      <br>\n    </td>\n  </tr>\n</table>\n\n## ‚öôÔ∏è Powerful IoT Rule Engine\n\nThingsBoard allows you to create complex [Rule Chains](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/) to process data from your devices and match your application specific use cases.\n\n[![IoT Rule Engine](https://github.com/user-attachments/assets/43d21dc9-0e18-4f1b-8f9a-b72004e12f07 \"IoT Rule Engine\")](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/)\n\n<div align=\"center\">\n\n[**Read more about Rule Engine ‚ûú**](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/)\n\n</div>\n\n## üì¶ Real-Time IoT Dashboards\n\nThingsBoard is a scalable, user-friendly, and device-agnostic IoT platform that speeds up time-to-market with powerful built-in solution templates. It enables data collection and analysis from any devices, saving resources on routine tasks and letting you focus on your solution‚Äôs unique aspects. See more our Use Cases [here](https://thingsboard.io/iot-use-cases/).\n\n[**Smart energy**](https://thingsboard.io/use-cases/smart-energy/)\n\n[![Smart energy](https://github.com/user-attachments/assets/2a0abf13-6dc5-4f5e-9c30-1aea1d39af1e \"Smart energy\")](https://thingsboard.io/use-cases/smart-energy/)\n\n[**SCADA swimming pool**](https://thingsboard.io/use-cases/scada/)\n\n[![SCADA Swimming pool](https://github.com/user-attachments/assets/68fd9e29-99f1-4c16-8c4c-476f4ccb20c0 \"SCADA Swimming pool\")](https://thingsboard.io/use-cases/scada/)\n\n[**Fleet tracking**](https://thingsboard.io/use-cases/fleet-tracking/)\n\n[![Fleet tracking](https://github.com/user-attachments/assets/9e8938ba-ee0c-4599-9494-d74b7de8a63d \"Fleet tracking\")](https://thingsboard.io/use-cases/fleet-tracking/)\n\n[**Smart farming**](https://thingsboard.io/use-cases/smart-farming/)\n\n[![Smart farming](https://github.com/user-attachments/assets/56b84c99-ef24-44e5-a903-b925b7f9d142 \"Smart farming\")](https://thingsboard.io/use-cases/smart-farming/)\n\n[**Smart metering**](https://thingsboard.io/smart-metering/)\n\n[![Smart metering](https://github.com/user-attachments/assets/adc05e3d-397c-48ef-bed6-535bbd698455 \"Smart metering\")](https://thingsboard.io/smart-metering/)\n\n<div align=\"center\">\n\n[**Check more of our use cases ‚ûú**](https://thingsboard.io/iot-use-cases/)\n\n</div>\n\n## ü´∂ Support\n\nTo get support, please visit our [GitHub issues page](https://github.com/thingsboard/thingsboard/issues)\n\n## üìÑ Licenses\n\nThis project is released under [Apache 2.0 License](./LICENSE)\n",
      "stars_today": 10
    },
    {
      "id": 59771425,
      "name": "zephyr",
      "full_name": "zephyrproject-rtos/zephyr",
      "description": "Primary Git Repository for the Zephyr Project. Zephyr is a new generation, scalable, optimized, secure RTOS for multiple hardware architectures.",
      "html_url": "https://github.com/zephyrproject-rtos/zephyr",
      "stars": 14251,
      "forks": 8542,
      "language": "C",
      "topics": [
        "bluetooth",
        "bluetooth-le",
        "embedded",
        "embedded-c",
        "iot",
        "mcu",
        "microcontroller",
        "real-time",
        "rtos",
        "zephyr",
        "zephyr-rtos",
        "zephyros"
      ],
      "created_at": "2016-05-26T17:54:19Z",
      "updated_at": "2026-01-23T02:10:29Z",
      "pushed_at": "2026-01-22T20:35:12Z",
      "open_issues": 3423,
      "owner": {
        "login": "zephyrproject-rtos",
        "avatar_url": "https://avatars.githubusercontent.com/u/19595895?v=4"
      },
      "readme": ".. raw:: html\n\n   <a href=\"https://www.zephyrproject.org\">\n     <p align=\"center\">\n       <picture>\n         <source media=\"(prefers-color-scheme: dark)\" srcset=\"doc/_static/images/logo-readme-dark.svg\">\n         <source media=\"(prefers-color-scheme: light)\" srcset=\"doc/_static/images/logo-readme-light.svg\">\n         <img src=\"doc/_static/images/logo-readme-light.svg\">\n       </picture>\n     </p>\n   </a>\n\n   <a href=\"https://bestpractices.coreinfrastructure.org/projects/74\"><img src=\"https://bestpractices.coreinfrastructure.org/projects/74/badge\"></a>\n   <a href=\"https://scorecard.dev/viewer/?uri=github.com/zephyrproject-rtos/zephyr\"><img src=\"https://api.securityscorecards.dev/projects/github.com/zephyrproject-rtos/zephyr/badge\"></a>\n   <a href=\"https://github.com/zephyrproject-rtos/zephyr/actions/workflows/twister.yaml?query=branch%3Amain\"><img src=\"https://github.com/zephyrproject-rtos/zephyr/actions/workflows/twister.yaml/badge.svg?event=push\"></a>\n\n\nThe Zephyr Project is a scalable real-time operating system (RTOS) supporting\nmultiple hardware architectures, optimized for resource constrained devices,\nand built with security in mind.\n\nThe Zephyr OS is based on a small-footprint kernel designed for use on\nresource-constrained systems: from simple embedded environmental sensors and\nLED wearables to sophisticated smart watches and IoT wireless gateways.\n\nThe Zephyr kernel supports multiple architectures, including ARM (Cortex-A,\nCortex-R, Cortex-M), Intel x86, ARC, Tensilica Xtensa, and RISC-V,\nSPARC, MIPS, and a large number of `supported boards`_.\n\n.. below included in doc/introduction/introduction.rst\n\n\nGetting Started\n***************\n\nWelcome to Zephyr! See the `Introduction to Zephyr`_ for a high-level overview,\nand the documentation's `Getting Started Guide`_ to start developing.\n\n.. start_include_here\n\nCommunity Support\n*****************\n\nCommunity support is provided via mailing lists and Discord; see the Resources\nbelow for details.\n\n.. _project-resources:\n\nResources\n*********\n\nHere's a quick summary of resources to help you find your way around:\n\nGetting Started\n---------------\n\n  | üìñ `Zephyr Documentation`_\n  | üöÄ `Getting Started Guide`_\n  | üôãüèΩ `Tips when asking for help`_\n  | üíª `Code samples`_\n\nCode and Development\n--------------------\n\n  | üåê `Source Code Repository`_\n  | üì¶ `Releases`_\n  | ü§ù `Contribution Guide`_\n\nCommunity and Support\n---------------------\n\n  | üí¨ `Discord Server`_ for real-time community discussions\n  | üìß `User mailing list (users@lists.zephyrproject.org)`_\n  | üìß `Developer mailing list (devel@lists.zephyrproject.org)`_\n  | üì¨ `Other project mailing lists`_\n  | üìö `Project Wiki`_\n\nIssue Tracking and Security\n---------------------------\n\n  | üêõ `GitHub Issues`_\n  | üîí `Security documentation`_\n  | üõ°Ô∏è `Security Advisories Repository`_\n  | ‚ö†Ô∏è Report security vulnerabilities at vulnerabilities@zephyrproject.org\n\nAdditional Resources\n--------------------\n  | üåê `Zephyr Project Website`_\n  | üì∫ `Zephyr Tech Talks`_\n\n.. _Zephyr Project Website: https://www.zephyrproject.org\n.. _Discord Server: https://chat.zephyrproject.org\n.. _supported boards: https://docs.zephyrproject.org/latest/boards/index.html\n.. _Zephyr Documentation: https://docs.zephyrproject.org\n.. _Introduction to Zephyr: https://docs.zephyrproject.org/latest/introduction/index.html\n.. _Getting Started Guide: https://docs.zephyrproject.org/latest/develop/getting_started/index.html\n.. _Contribution Guide: https://docs.zephyrproject.org/latest/contribute/index.html\n.. _Source Code Repository: https://github.com/zephyrproject-rtos/zephyr\n.. _GitHub Issues: https://github.com/zephyrproject-rtos/zephyr/issues\n.. _Releases: https://github.com/zephyrproject-rtos/zephyr/releases\n.. _Project Wiki: https://github.com/zephyrproject-rtos/zephyr/wiki\n.. _User mailing list (users@lists.zephyrproject.org): https://lists.zephyrproject.org/g/users\n.. _Developer mailing list (devel@lists.zephyrproject.org): https://lists.zephyrproject.org/g/devel\n.. _Other project mailing lists: https://lists.zephyrproject.org/g/main/subgroups\n.. _Code samples: https://docs.zephyrproject.org/latest/samples/index.html\n.. _Security documentation: https://docs.zephyrproject.org/latest/security/index.html\n.. _Security Advisories Repository: https://github.com/zephyrproject-rtos/zephyr/security\n.. _Tips when asking for help: https://docs.zephyrproject.org/latest/develop/getting_started/index.html#asking-for-help\n.. _Zephyr Tech Talks: https://www.zephyrproject.org/tech-talks\n",
      "stars_today": 10
    },
    {
      "id": 5179099,
      "name": "go-redis",
      "full_name": "redis/go-redis",
      "description": "Redis Go client",
      "html_url": "https://github.com/redis/go-redis",
      "stars": 21840,
      "forks": 2527,
      "language": "Go",
      "topics": [
        "go",
        "golang",
        "redis",
        "redis-client",
        "redis-cluster"
      ],
      "created_at": "2012-07-25T13:01:39Z",
      "updated_at": "2026-01-23T01:35:26Z",
      "pushed_at": "2026-01-22T17:53:23Z",
      "open_issues": 66,
      "owner": {
        "login": "redis",
        "avatar_url": "https://avatars.githubusercontent.com/u/1529926?v=4"
      },
      "readme": "# Redis client for Go\n\n[![build workflow](https://github.com/redis/go-redis/actions/workflows/build.yml/badge.svg)](https://github.com/redis/go-redis/actions)\n[![PkgGoDev](https://pkg.go.dev/badge/github.com/redis/go-redis/v9)](https://pkg.go.dev/github.com/redis/go-redis/v9?tab=doc)\n[![Documentation](https://img.shields.io/badge/redis-documentation-informational)](https://redis.io/docs/latest/develop/clients/go/)\n[![Go Report Card](https://goreportcard.com/badge/github.com/redis/go-redis/v9)](https://goreportcard.com/report/github.com/redis/go-redis/v9)\n[![codecov](https://codecov.io/github/redis/go-redis/graph/badge.svg?token=tsrCZKuSSw)](https://codecov.io/github/redis/go-redis)\n\n[![Discord](https://img.shields.io/discord/697882427875393627.svg?style=social&logo=discord)](https://discord.gg/W4txy5AeKM)\n[![Twitch](https://img.shields.io/twitch/status/redisinc?style=social)](https://www.twitch.tv/redisinc)\n[![YouTube](https://img.shields.io/youtube/channel/views/UCD78lHSwYqMlyetR0_P4Vig?style=social)](https://www.youtube.com/redisinc)\n[![Twitter](https://img.shields.io/twitter/follow/redisinc?style=social)](https://twitter.com/redisinc)\n[![Stack Exchange questions](https://img.shields.io/stackexchange/stackoverflow/t/go-redis?style=social&logo=stackoverflow&label=Stackoverflow)](https://stackoverflow.com/questions/tagged/go-redis)\n\n> go-redis is the official Redis client library for the Go programming language. It offers a straightforward interface for interacting with Redis servers. \n\n## Supported versions\n\nIn `go-redis` we are aiming to support the last three releases of Redis. Currently, this means we do support:\n- [Redis 8.0](https://raw.githubusercontent.com/redis/redis/8.0/00-RELEASENOTES) - using Redis CE 8.0\n- [Redis 8.2](https://raw.githubusercontent.com/redis/redis/8.2/00-RELEASENOTES) - using Redis CE 8.2 \n- [Redis 8.4](https://raw.githubusercontent.com/redis/redis/8.4/00-RELEASENOTES) - using Redis CE 8.4\n\nAlthough the `go.mod` states it requires at minimum `go 1.21`, our CI is configured to run the tests against all three\nversions of Redis and multiple versions of Go ([1.21](https://go.dev/doc/devel/release#go1.21.0),\n[1.23](https://go.dev/doc/devel/release#go1.23.0), oldstable, and stable). We observe that some modules related test may not pass with\nRedis Stack 7.2 and some commands are changed with Redis CE 8.0.\nAlthough it is not officially supported, `go-redis/v9`  should be able to work with any Redis 7.0+.\nPlease do refer to the documentation and the tests if you experience any issues.\n\n## How do I Redis?\n\n[Learn for free at Redis University](https://university.redis.com/)\n\n[Build faster with the Redis Launchpad](https://launchpad.redis.com/)\n\n[Try the Redis Cloud](https://redis.com/try-free/)\n\n[Dive in developer tutorials](https://developer.redis.com/)\n\n[Join the Redis community](https://redis.com/community/)\n\n[Work at Redis](https://redis.com/company/careers/jobs/)\n\n\n## Resources\n\n- [Discussions](https://github.com/redis/go-redis/discussions)\n- [Chat](https://discord.gg/W4txy5AeKM)\n- [Reference](https://pkg.go.dev/github.com/redis/go-redis/v9)\n- [Examples](https://pkg.go.dev/github.com/redis/go-redis/v9#pkg-examples)\n\n## old documentation\n\n- [English](https://redis.uptrace.dev)\n- [ÁÆÄ‰Ωì‰∏≠Êñá](https://redis.uptrace.dev/zh/)\n\n## Ecosystem\n\n- [Entra ID (Azure AD)](https://github.com/redis/go-redis-entraid)\n- [Distributed Locks](https://github.com/bsm/redislock)\n- [Redis Cache](https://github.com/go-redis/cache)\n- [Rate limiting](https://github.com/go-redis/redis_rate)\n\n## Features\n\n- Redis commands except QUIT and SYNC.\n- Automatic connection pooling.\n- [StreamingCredentialsProvider (e.g. entra id, oauth)](#1-streaming-credentials-provider-highest-priority) (experimental)\n- [Pub/Sub](https://redis.uptrace.dev/guide/go-redis-pubsub.html).\n- [Pipelines and transactions](https://redis.uptrace.dev/guide/go-redis-pipelines.html).\n- [Scripting](https://redis.uptrace.dev/guide/lua-scripting.html).\n- [Redis Sentinel](https://redis.uptrace.dev/guide/go-redis-sentinel.html).\n- [Redis Cluster](https://redis.uptrace.dev/guide/go-redis-cluster.html).\n- [Redis Performance Monitoring](https://redis.uptrace.dev/guide/redis-performance-monitoring.html).\n- [Redis Probabilistic [RedisStack]](https://redis.io/docs/data-types/probabilistic/)\n- [Customizable read and write buffers size.](#custom-buffer-sizes)\n\n## Installation\n\ngo-redis supports 2 last Go versions and requires a Go version with\n[modules](https://github.com/golang/go/wiki/Modules) support. So make sure to initialize a Go\nmodule:\n\n```shell\ngo mod init github.com/my/repo\n```\n\nThen install go-redis/**v9**:\n\n```shell\ngo get github.com/redis/go-redis/v9\n```\n\n## Quickstart\n\n```go\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/redis/go-redis/v9\"\n)\n\nvar ctx = context.Background()\n\nfunc ExampleClient() {\n    rdb := redis.NewClient(&redis.Options{\n        Addr:     \"localhost:6379\",\n        Password: \"\", // no password set\n        DB:       0,  // use default DB\n    })\n    defer rdb.Close()\n\n    err := rdb.Set(ctx, \"key\", \"value\", 0).Err()\n    if err != nil {\n        panic(err)\n    }\n\n    val, err := rdb.Get(ctx, \"key\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"key\", val)\n\n    val2, err := rdb.Get(ctx, \"key2\").Result()\n    if err == redis.Nil {\n        fmt.Println(\"key2 does not exist\")\n    } else if err != nil {\n        panic(err)\n    } else {\n        fmt.Println(\"key2\", val2)\n    }\n    // Output: key value\n    // key2 does not exist\n}\n```\n\n### Authentication\n\nThe Redis client supports multiple ways to provide authentication credentials, with a clear priority order. Here are the available options:\n\n#### 1. Streaming Credentials Provider (Highest Priority) - Experimental feature\n\nThe streaming credentials provider allows for dynamic credential updates during the connection lifetime. This is particularly useful for managed identity services and token-based authentication.\n\n```go\ntype StreamingCredentialsProvider interface {\n    Subscribe(listener CredentialsListener) (Credentials, UnsubscribeFunc, error)\n}\n\ntype CredentialsListener interface {\n    OnNext(credentials Credentials)  // Called when credentials are updated\n    OnError(err error)              // Called when an error occurs\n}\n\ntype Credentials interface {\n    BasicAuth() (username string, password string)\n    RawCredentials() string\n}\n```\n\nExample usage:\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr: \"localhost:6379\",\n    StreamingCredentialsProvider: &MyCredentialsProvider{},\n})\n```\n\n**Note:** The streaming credentials provider can be used with [go-redis-entraid](https://github.com/redis/go-redis-entraid) to enable Entra ID (formerly Azure AD) authentication. This allows for seamless integration with Azure's managed identity services and token-based authentication.\n\nExample with Entra ID:\n```go\nimport (\n    \"github.com/redis/go-redis/v9\"\n    \"github.com/redis/go-redis-entraid\"\n)\n\n// Create an Entra ID credentials provider\nprovider := entraid.NewDefaultAzureIdentityProvider()\n\n// Configure Redis client with Entra ID authentication\nrdb := redis.NewClient(&redis.Options{\n    Addr: \"your-redis-server.redis.cache.windows.net:6380\",\n    StreamingCredentialsProvider: provider,\n    TLSConfig: &tls.Config{\n        MinVersion: tls.VersionTLS12,\n    },\n})\n```\n\n#### 2. Context-based Credentials Provider\n\nThe context-based provider allows credentials to be determined at the time of each operation, using the context.\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr: \"localhost:6379\",\n    CredentialsProviderContext: func(ctx context.Context) (string, string, error) {\n        // Return username, password, and any error\n        return \"user\", \"pass\", nil\n    },\n})\n```\n\n#### 3. Regular Credentials Provider\n\nA simple function-based provider that returns static credentials.\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr: \"localhost:6379\",\n    CredentialsProvider: func() (string, string) {\n        // Return username and password\n        return \"user\", \"pass\"\n    },\n})\n```\n\n#### 4. Username/Password Fields (Lowest Priority)\n\nThe most basic way to provide credentials is through the `Username` and `Password` fields in the options.\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr:     \"localhost:6379\",\n    Username: \"user\",\n    Password: \"pass\",\n})\n```\n\n#### Priority Order\n\nThe client will use credentials in the following priority order:\n1. Streaming Credentials Provider (if set)\n2. Context-based Credentials Provider (if set)\n3. Regular Credentials Provider (if set)\n4. Username/Password fields (if set)\n\nIf none of these are set, the client will attempt to connect without authentication.\n\n### Protocol Version\n\nThe client supports both RESP2 and RESP3 protocols. You can specify the protocol version in the options:\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr:     \"localhost:6379\",\n    Password: \"\", // no password set\n    DB:       0,  // use default DB\n    Protocol: 3,  // specify 2 for RESP 2 or 3 for RESP 3\n})\n```\n\n### Connecting via a redis url\n\ngo-redis also supports connecting via the\n[redis uri specification](https://github.com/redis/redis-specifications/tree/master/uri/redis.txt).\nThe example below demonstrates how the connection can easily be configured using a string, adhering\nto this specification.\n\n```go\nimport (\n    \"github.com/redis/go-redis/v9\"\n)\n\nfunc ExampleClient() *redis.Client {\n    url := \"redis://user:password@localhost:6379/0?protocol=3\"\n    opts, err := redis.ParseURL(url)\n    if err != nil {\n        panic(err)\n    }\n\n    return redis.NewClient(opts)\n}\n\n```\n\n### Instrument with OpenTelemetry\n\n```go\nimport (\n    \"github.com/redis/go-redis/v9\"\n    \"github.com/redis/go-redis/extra/redisotel/v9\"\n    \"errors\"\n)\n\nfunc main() {\n    ...\n    rdb := redis.NewClient(&redis.Options{...})\n\n    if err := errors.Join(redisotel.InstrumentTracing(rdb), redisotel.InstrumentMetrics(rdb)); err != nil {\n        log.Fatal(err)\n    }\n```\n\n\n### Buffer Size Configuration\n\ngo-redis uses 32KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr:            \"localhost:6379\",\n    ReadBufferSize:  1024 * 1024, // 1MiB read buffer\n    WriteBufferSize: 1024 * 1024, // 1MiB write buffer\n})\n```\n\n### Advanced Configuration\n\ngo-redis supports extending the client identification phase to allow projects to send their own custom client identification.\n\n#### Default Client Identification\n\nBy default, go-redis automatically sends the client library name and version during the connection process. This feature is available in redis-server as of version 7.2. As a result, the command is \"fire and forget\", meaning it should fail silently, in the case that the redis server does not support this feature.\n\n#### Disabling Identity Verification\n\nWhen connection identity verification is not required or needs to be explicitly disabled, a `DisableIdentity` configuration option exists.\nInitially there was a typo and the option was named `DisableIndentity` instead of `DisableIdentity`. The misspelled option is marked as Deprecated and will be removed in V10 of this library.\nAlthough both options will work at the moment, the correct option is `DisableIdentity`. The deprecated option will be removed in V10 of this library, so please use the correct option name to avoid any issues.\n\nTo disable verification, set the `DisableIdentity` option to `true` in the Redis client options:\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr:            \"localhost:6379\",\n    Password:        \"\",\n    DB:              0,\n    DisableIdentity: true, // Disable set-info on connect\n})\n```\n\n#### Unstable RESP3 Structures for RediSearch Commands\nWhen integrating Redis with application functionalities using RESP3, it's important to note that some response structures aren't final yet. This is especially true for more complex structures like search and query results. We recommend using RESP2 when using the search and query capabilities, but we plan to stabilize the RESP3-based API-s in the coming versions. You can find more guidance in the upcoming release notes.\n\nTo enable unstable RESP3, set the option in your client configuration:\n\n```go\nredis.NewClient(&redis.Options{\n\t\t\tUnstableResp3: true,\n\t\t})\n```\n**Note:** When UnstableResp3 mode is enabled, it's necessary to use RawResult() and RawVal() to retrieve a raw data.\n          Since, raw response is the only option for unstable search commands Val() and Result() calls wouldn't have any affect on them:\n\n```go\nres1, err := client.FTSearchWithArgs(ctx, \"txt\", \"foo bar\", &redis.FTSearchOptions{}).RawResult()\nval1 := client.FTSearchWithArgs(ctx, \"txt\", \"foo bar\", &redis.FTSearchOptions{}).RawVal()\n```\n\n#### Redis-Search Default Dialect\n\nIn the Redis-Search module, **the default dialect is 2**. If needed, you can explicitly specify a different dialect using the appropriate configuration in your queries.\n\n**Important**: Be aware that the query dialect may impact the results returned. If needed, you can revert to a different dialect version by passing the desired dialect in the arguments of the command you want to execute.\nFor example:\n```\n\tres2, err := rdb.FTSearchWithArgs(ctx,\n\t\t\"idx:bicycle\",\n\t\t\"@pickup_zone:[CONTAINS $bike]\",\n\t\t&redis.FTSearchOptions{\n\t\t\tParams: map[string]interface{}{\n\t\t\t\t\"bike\": \"POINT(-0.1278 51.5074)\",\n\t\t\t},\n\t\t\tDialectVersion: 3,\n\t\t},\n\t).Result()\n```\nYou can find further details in the [query dialect documentation](https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/dialects/).\n\n#### Custom buffer sizes\nPrior to v9.12, the buffer size was the default go value of 4096 bytes. Starting from v9.12, \ngo-redis uses 32KiB read and write buffers by default for optimal performance.\nFor high-throughput applications or large pipelines, you can customize buffer sizes:\n\n```go\nrdb := redis.NewClient(&redis.Options{\n    Addr:            \"localhost:6379\",\n    ReadBufferSize:  1024 * 1024, // 1MiB read buffer\n    WriteBufferSize: 1024 * 1024, // 1MiB write buffer\n})\n```\n\n**Important**: If you experience any issues with the default buffer sizes, please try setting them to the go default of 4096 bytes.\n\n## Contributing\nWe welcome contributions to the go-redis library! If you have a bug fix, feature request, or improvement, please open an issue or pull request on GitHub.\nWe appreciate your help in making go-redis better for everyone.\nIf you are interested in contributing to the go-redis library, please check out our [contributing guidelines](CONTRIBUTING.md) for more information on how to get started.\n\n## Look and feel\n\nSome corner cases:\n\n```go\n// SET key value EX 10 NX\nset, err := rdb.SetNX(ctx, \"key\", \"value\", 10*time.Second).Result()\n\n// SET key value keepttl NX\nset, err := rdb.SetNX(ctx, \"key\", \"value\", redis.KeepTTL).Result()\n\n// SORT list LIMIT 0 2 ASC\nvals, err := rdb.Sort(ctx, \"list\", &redis.Sort{Offset: 0, Count: 2, Order: \"ASC\"}).Result()\n\n// ZRANGEBYSCORE zset -inf +inf WITHSCORES LIMIT 0 2\nvals, err := rdb.ZRangeByScoreWithScores(ctx, \"zset\", &redis.ZRangeBy{\n    Min: \"-inf\",\n    Max: \"+inf\",\n    Offset: 0,\n    Count: 2,\n}).Result()\n\n// ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 AGGREGATE SUM\nvals, err := rdb.ZInterStore(ctx, \"out\", &redis.ZStore{\n    Keys: []string{\"zset1\", \"zset2\"},\n    Weights: []int64{2, 3}\n}).Result()\n\n// EVAL \"return {KEYS[1],ARGV[1]}\" 1 \"key\" \"hello\"\nvals, err := rdb.Eval(ctx, \"return {KEYS[1],ARGV[1]}\", []string{\"key\"}, \"hello\").Result()\n\n// custom command\nres, err := rdb.Do(ctx, \"set\", \"key\", \"value\").Result()\n```\n\n## Typed Errors\n\ngo-redis provides typed error checking functions for common Redis errors:\n\n```go\n// Cluster and replication errors\nredis.IsLoadingError(err)        // Redis is loading the dataset\nredis.IsReadOnlyError(err)       // Write to read-only replica\nredis.IsClusterDownError(err)    // Cluster is down\nredis.IsTryAgainError(err)       // Command should be retried\nredis.IsMasterDownError(err)     // Master is down\nredis.IsMovedError(err)          // Returns (address, true) if key moved\nredis.IsAskError(err)            // Returns (address, true) if key being migrated\n\n// Connection and resource errors\nredis.IsMaxClientsError(err)     // Maximum clients reached\nredis.IsAuthError(err)           // Authentication failed (NOAUTH, WRONGPASS, unauthenticated)\nredis.IsPermissionError(err)     // Permission denied (NOPERM)\nredis.IsOOMError(err)            // Out of memory (OOM)\n\n// Transaction errors\nredis.IsExecAbortError(err)      // Transaction aborted (EXECABORT)\n```\n\n### Error Wrapping in Hooks\n\nWhen wrapping errors in hooks, use custom error types with `Unwrap()` method (preferred) or `fmt.Errorf` with `%w`. Always call `cmd.SetErr()` to preserve error type information:\n\n```go\n// Custom error type (preferred)\ntype AppError struct {\n    Code      string\n    RequestID string\n    Err       error\n}\n\nfunc (e *AppError) Error() string {\n    return fmt.Sprintf(\"[%s] request_id=%s: %v\", e.Code, e.RequestID, e.Err)\n}\n\nfunc (e *AppError) Unwrap() error {\n    return e.Err\n}\n\n// Hook implementation\nfunc (h MyHook) ProcessHook(next redis.ProcessHook) redis.ProcessHook {\n    return func(ctx context.Context, cmd redis.Cmder) error {\n        err := next(ctx, cmd)\n        if err != nil {\n            // Wrap with custom error type\n            wrappedErr := &AppError{\n                Code:      \"REDIS_ERROR\",\n                RequestID: getRequestID(ctx),\n                Err:       err,\n            }\n            cmd.SetErr(wrappedErr)\n            return wrappedErr  // Return wrapped error to preserve it\n        }\n        return nil\n    }\n}\n\n// Typed error detection works through wrappers\nif redis.IsLoadingError(err) {\n    // Retry logic\n}\n\n// Extract custom error if needed\nvar appErr *AppError\nif errors.As(err, &appErr) {\n    log.Printf(\"Request: %s\", appErr.RequestID)\n}\n```\n\nAlternatively, use `fmt.Errorf` with `%w`:\n```go\nwrappedErr := fmt.Errorf(\"context: %w\", err)\ncmd.SetErr(wrappedErr)\n```\n\n### Pipeline Hook Example\n\nFor pipeline operations, use `ProcessPipelineHook`:\n\n```go\ntype PipelineLoggingHook struct{}\n\nfunc (h PipelineLoggingHook) DialHook(next redis.DialHook) redis.DialHook {\n    return next\n}\n\nfunc (h PipelineLoggingHook) ProcessHook(next redis.ProcessHook) redis.ProcessHook {\n    return next\n}\n\nfunc (h PipelineLoggingHook) ProcessPipelineHook(next redis.ProcessPipelineHook) redis.ProcessPipelineHook {\n    return func(ctx context.Context, cmds []redis.Cmder) error {\n        start := time.Now()\n\n        // Execute the pipeline\n        err := next(ctx, cmds)\n\n        duration := time.Since(start)\n        log.Printf(\"Pipeline executed %d commands in %v\", len(cmds), duration)\n\n        // Process individual command errors\n        // Note: Individual command errors are already set on each cmd by the pipeline execution\n        for _, cmd := range cmds {\n            if cmdErr := cmd.Err(); cmdErr != nil {\n                // Check for specific error types using typed error functions\n                if redis.IsAuthError(cmdErr) {\n                    log.Printf(\"Auth error in pipeline command %s: %v\", cmd.Name(), cmdErr)\n                } else if redis.IsPermissionError(cmdErr) {\n                    log.Printf(\"Permission error in pipeline command %s: %v\", cmd.Name(), cmdErr)\n                }\n\n                // Optionally wrap individual command errors to add context\n                // The wrapped error preserves type information through errors.As()\n                wrappedErr := fmt.Errorf(\"pipeline cmd %s failed: %w\", cmd.Name(), cmdErr)\n                cmd.SetErr(wrappedErr)\n            }\n        }\n\n        // Return the pipeline-level error (connection errors, etc.)\n        // You can wrap it if needed, or return it as-is\n        return err\n    }\n}\n\n// Register the hook\nrdb.AddHook(PipelineLoggingHook{})\n\n// Use pipeline - errors are still properly typed\npipe := rdb.Pipeline()\npipe.Set(ctx, \"key1\", \"value1\", 0)\npipe.Get(ctx, \"key2\")\n_, err := pipe.Exec(ctx)\n```\n\n## Run the test\n\nRecommended to use Docker, just need to run:\n```shell\nmake test\n```\n\n## See also\n\n- [Golang ORM](https://bun.uptrace.dev) for PostgreSQL, MySQL, MSSQL, and SQLite\n- [Golang PostgreSQL](https://bun.uptrace.dev/postgres/)\n- [Golang HTTP router](https://bunrouter.uptrace.dev/)\n- [Golang ClickHouse ORM](https://github.com/uptrace/go-clickhouse)\n\n## Contributors\n\n> The go-redis project was originally initiated by :star: [**uptrace/uptrace**](https://github.com/uptrace/uptrace).\n> Uptrace is an open-source APM tool that supports distributed tracing, metrics, and logs. You can\n> use it to monitor applications and set up automatic alerts to receive notifications via email,\n> Slack, Telegram, and others.\n>\n> See [OpenTelemetry](https://github.com/redis/go-redis/tree/master/example/otel) example which\n> demonstrates how you can use Uptrace to monitor go-redis.\n\nThanks to all the people who already contributed!\n\n<a href=\"https://github.com/redis/go-redis/graphs/contributors\">\n  <img src=\"https://contributors-img.web.app/image?repo=redis/go-redis\" />\n</a>\n",
      "stars_today": 10
    },
    {
      "id": 437245741,
      "name": "dragonfly",
      "full_name": "dragonflydb/dragonfly",
      "description": "A modern replacement for Redis and Memcached",
      "html_url": "https://github.com/dragonflydb/dragonfly",
      "stars": 29807,
      "forks": 1136,
      "language": "C++",
      "topics": [
        "cache",
        "cpp",
        "database",
        "fibers",
        "in-memory",
        "in-memory-database",
        "key-value",
        "keydb",
        "memcached",
        "message-broker",
        "multi-threading",
        "nosql",
        "redis",
        "valkey",
        "vector-search"
      ],
      "created_at": "2021-12-11T10:00:42Z",
      "updated_at": "2026-01-23T00:41:56Z",
      "pushed_at": "2026-01-22T21:05:49Z",
      "open_issues": 318,
      "owner": {
        "login": "dragonflydb",
        "avatar_url": "https://avatars.githubusercontent.com/u/104819355?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://dragonflydb.io\">\n    <img  src=\"/.github/images/logo-full.svg\"\n      width=\"284\" border=\"0\" alt=\"Dragonfly\">\n  </a>\n</p>\n\n[![ci-tests](https://github.com/dragonflydb/dragonfly/actions/workflows/ci.yml/badge.svg)](https://github.com/dragonflydb/dragonfly/actions/workflows/ci.yml) [![Twitter URL](https://img.shields.io/twitter/follow/dragonflydbio?style=social)](https://twitter.com/dragonflydbio)\n\n> Before moving on, please consider giving us a GitHub star ‚≠êÔ∏è. Thank you!\n\nOther languages:  [ÁÆÄ‰Ωì‰∏≠Êñá](README.zh-CN.md) [Êó•Êú¨Ë™û](README.ja-JP.md) [ÌïúÍµ≠Ïñ¥](README.ko-KR.md) [Portugu√™s](README.pt-BR.md)\n\n[Website](https://www.dragonflydb.io/) ‚Ä¢ [Docs](https://dragonflydb.io/docs) ‚Ä¢ [Quick Start](https://www.dragonflydb.io/docs/getting-started) ‚Ä¢ [Community Discord](https://discord.gg/HsPjXGVH85) ‚Ä¢ [Dragonfly Forum](https://dragonfly.discourse.group/) ‚Ä¢ [Join the Dragonfly Community](https://www.dragonflydb.io/community)\n\n[GitHub Discussions](https://github.com/dragonflydb/dragonfly/discussions) ‚Ä¢ [GitHub Issues](https://github.com/dragonflydb/dragonfly/issues) ‚Ä¢ [Contributing](https://github.com/dragonflydb/dragonfly/blob/main/CONTRIBUTING.md) ‚Ä¢ [AI Agents Guide](AGENTS.md) ‚Ä¢ [Dragonfly Cloud](https://www.dragonflydb.io/cloud)\n\n## The world's most efficient in-memory data store\n\nDragonfly is an in-memory data store built for modern application workloads.\n\nFully compatible with Redis and Memcached APIs, Dragonfly requires no code changes to adopt. Compared to legacy in-memory datastores, Dragonfly delivers 25X more throughput, higher cache hit rates with lower tail latency, and can run on up to 80% less resources for the same sized workload.\n\n## Contents\n\n- [Benchmarks](#benchmarks)\n- [Quick start](https://github.com/dragonflydb/dragonfly/tree/main/docs/quick-start)\n- [Configuration](#configuration)\n- [Roadmap and status](#roadmap-status)\n- [Design decisions](#design-decisions)\n- [Background](#background)\n- [Build from source](./docs/build-from-source.md)\n\n## <a name=\"benchmarks\"><a/>Benchmarks\n\nWe first compare Dragonfly with Redis on `m5.large` instance which is commonly used to run Redis\ndue to its single-threaded architecture. The benchmark program runs from another\nload-test instance (c5n) in the same AZ using `memtier_benchmark  -c 20 --test-time 100 -t 4 -d 256 --distinct-client-seed`\n\nDragonfly shows a comparable performance:\n\n1. SETs (`--ratio 1:0`):\n\n|  Redis                                   |      DF                                |\n| -----------------------------------------|----------------------------------------|\n| QPS: 159K, P99.9: 1.16ms, P99: 0.82ms    | QPS:173K, P99.9: 1.26ms, P99: 0.9ms    |\n|                                          |                                        |\n\n2. GETs (`--ratio 0:1`):\n\n|  Redis                                  |      DF                                |\n| ----------------------------------------|----------------------------------------|\n| QPS: 194K, P99.9: 0.8ms, P99: 0.65ms    | QPS: 191K, P99.9: 0.95ms, P99: 0.8ms   |\n\nThe benchmark above shows that the algorithmic layer inside DF that allows it to scale vertically\ndoes not take a large toll when running single-threaded.\n\nHowever, if we take a bit stronger instance (m5.xlarge), the gap between DF and Redis starts growing.\n(`memtier_benchmark  -c 20 --test-time 100 -t 6 -d 256 --distinct-client-seed`):\n1. SETs (`--ratio 1:0`):\n\n|  Redis                                  |      DF                                |\n| ----------------------------------------|----------------------------------------|\n| QPS: 190K, P99.9: 2.45ms, P99: 0.97ms   |  QPS: 279K , P99.9: 1.95ms, P99: 1.48ms|\n\n2. GETs (`--ratio 0:1`):\n\n|  Redis                                  |      DF                                |\n| ----------------------------------------|----------------------------------------|\n| QPS: 220K, P99.9: 0.98ms , P99: 0.8ms   |  QPS: 305K, P99.9: 1.03ms, P99: 0.87ms |\n\n\nDragonfly throughput capacity continues to grow with instance size,\nwhile single-threaded Redis is bottlenecked on CPU and reaches local maxima in terms of performance.\n\n<img src=\"http://static.dragonflydb.io/repo-assets/aws-throughput.svg\" width=\"80%\" border=\"0\"/>\n\nIf we compare Dragonfly and Redis on the most network-capable instance c6gn.16xlarge,\nDragonfly showed a 25X increase in throughput compared to Redis single process, crossing 3.8M QPS.\n\nDragonfly's 99th percentile latency metrics at its peak throughput:\n\n| op    | r6g   | c6gn  | c7g   |\n|-------|-------|-------|-------|\n| set   | 0.8ms | 1ms   | 1ms   |\n| get   | 0.9ms | 0.9ms | 0.8ms |\n| setex | 0.9ms | 1.1ms | 1.3ms |\n\n*All benchmarks were performed using `memtier_benchmark` (see below) with number of threads tuned per server and instance type. `memtier` was run on a separate c6gn.16xlarge machine. We set the expiry time to 500 for the SETEX benchmark to ensure it would survive the end of the test.*\n\n```bash\n  memtier_benchmark --ratio ... -t <threads> -c 30 -n 200000 --distinct-client-seed -d 256 \\\n     --expiry-range=...\n```\n\nIn pipeline mode `--pipeline=30`, Dragonfly reaches **10M QPS** for SET and **15M QPS** for GET operations.\n\n### Dragonfly vs. Memcached\n\nWe compared Dragonfly with Memcached on a c6gn.16xlarge instance on AWS.\n\nWith a comparable latency, Dragonfly throughput outperformed Memcached throughput in both write and read workloads. Dragonfly demonstrated better latency in write workloads due to contention on the [write path in Memcached](docs/memcached_benchmark.md).\n\n#### SET benchmark\n\n| Server    | QPS(thousands qps) | latency 99% | 99.9%   |\n|:---------:|:------------------:|:-----------:|:-------:|\n| Dragonfly |  üü© 3844           |üü© 0.9ms     | üü© 2.4ms |\n| Memcached |   806              |   1.6ms     | 3.2ms    |\n\n#### GET benchmark\n\n| Server    | QPS(thousands qps) | latency 99% | 99.9%   |\n|-----------|:------------------:|:-----------:|:-------:|\n| Dragonfly | üü© 3717            |   1ms       | 2.4ms   |\n| Memcached |   2100             |  üü© 0.34ms  | üü© 0.6ms |\n\n\nMemcached exhibited lower latency for the read benchmark, but also lower throughput.\n\n### Memory efficiency\n\nTo test memory efficiency, we filled Dragonfly and Redis with ~5GB of data using the `debug populate 5000000 key 1024` command, sent update traffic with `memtier`, and kicked off the snapshotting with the `bgsave` command.\n\nThis figure demonstrates how each server behaved in terms of memory efficiency.\n\n<img src=\"http://static.dragonflydb.io/repo-assets/bgsave-memusage.svg\" width=\"70%\" border=\"0\"/>\n\nDragonfly was 30% more memory efficient than Redis in the idle state and did not show any visible increase in memory use during the snapshot phase. At peak, Redis memory use increased to almost 3X that of Dragonfly.\n\nDragonfly finished the snapshot faster, within a few seconds.\n\nFor more info about memory efficiency in Dragonfly, see our [Dashtable doc](/docs/dashtable.md).\n\n\n\n## <a name=\"configuration\"><a/>Configuration\n\nDragonfly supports common Redis arguments where applicable. For example, you can run: `dragonfly --requirepass=foo --bind localhost`.\n\nDragonfly currently supports the following Redis-specific arguments:\n * `port`: Redis connection port (`default: 6379`).\n * `bind`: Use `localhost` to only allow localhost connections or a public IP address to allow connections **to that IP** address (i.e. from outside too). Use `0.0.0.0` to allow all IPv4.\n * `requirepass`: The password for AUTH authentication (`default: \"\"`).\n * `maxmemory`: Limit on maximum memory (in human-readable bytes) used by the database (`default: 0`). A `maxmemory` value of `0` means the program will automatically determine its maximum memory usage.\n * `dir`: Dragonfly Docker uses the `/data` folder for snapshotting by default, the CLI uses `\"\"`. You can use the `-v` Docker option to map it to your host folder.\n * `dbfilename`: The filename to save and load the database (`default: dump`).\n\nThere are also some Dragonfly-specific arguments:\n * `memcached_port`: The port to enable Memcached-compatible API on (`default: disabled`).\n * `keys_output_limit`: Maximum number of returned keys in `keys` command (`default: 8192`). Note that `keys` is a dangerous command. We truncate its result to avoid a blowup in memory use when fetching too many keys.\n * `dbnum`: Maximum number of supported databases for `select`.\n * `cache_mode`: See the [novel cache design](#novel-cache-design) section below.\n * `hz`: Key expiry evaluation frequency (`default: 100`). Lower frequency uses less CPU when idle at the expense of a slower eviction rate.\n * `snapshot_cron`: Cron schedule expression for automatic backup snapshots using standard cron syntax with the granularity of minutes (`default: \"\"`).\n   Here are some cron schedule expression examples below, and feel free to read more about this argument in our [documentation](https://www.dragonflydb.io/docs/managing-dragonfly/backups#the-snapshot_cron-flag).\n\n   | Cron Schedule Expression | Description                                |\n   |--------------------------|--------------------------------------------|\n   | `* * * * *`              | At every minute                            |\n   | `*/5 * * * *`            | At every 5th minute                        |\n   | `5 */2 * * *`            | At minute 5 past every 2nd hour            |\n   | `0 0 * * *`              | At 00:00 (midnight) every day              |\n   | `0 6 * * 1-5`            | At 06:00 (dawn) from Monday through Friday |\n\n * `primary_port_http_enabled`: Allows accessing HTTP console on main TCP port if `true` (`default: true`).\n * `admin_port`: To enable admin access to the console on the assigned port (`default: disabled`). Supports both HTTP and RESP protocols.\n * `admin_bind`: To bind the admin console TCP connection to a given address (`default: any`). Supports both HTTP and RESP protocols.\n * `admin_nopass`: To enable open admin access to console on the assigned port, without auth token needed (`default: false`). Supports both HTTP and RESP protocols.\n * `cluster_mode`: Cluster mode supported (`default: \"\"`). Currently supports only `emulated`.\n * `cluster_announce_ip`: The IP that cluster commands announce to the client.\n * `announce_port`: The port that cluster commands announce to the client, and to replication master.\n\n### Example start script with popular options:\n\n```bash\n./dragonfly-x86_64 --logtostderr --requirepass=youshallnotpass --cache_mode=true -dbnum 1 --bind localhost --port 6379 --maxmemory=12gb --keys_output_limit=12288 --dbfilename dump.rdb\n```\n\nArguments can be also provided via:\n * `--flagfile <filename>`: The file should list one flag per line, with equal signs instead of spaces for key-value flags. No quotes are needed for flag values.\n * Setting environment variables. Set `DFLY_x`, where `x` is the exact name of the flag, case sensitive.\n\nFor more options like logs management or TLS support, run `dragonfly --help`.\n\n## <a name=\"roadmap-status\"><a/>Roadmap and status\n\nDragonfly currently supports ~185 Redis commands and all Memcached commands besides `cas`. Almost on par with the Redis 5 API, Dragonfly's next milestone will be to stabilize basic functionality and implement the replication API. If there is a command you need that is not implemented yet, please open an issue.\n\nFor Dragonfly-native replication, we are designing a distributed log format that will support order-of-magnitude higher speeds.\n\nFollowing the replication feature, we will continue adding missing commands for Redis versions 3-6 APIs.\n\nPlease see our [Command Reference](https://dragonflydb.io/docs/category/command-reference) for the current commands supported by Dragonfly.\n\n## <a name=\"design-decisions\"><a/> Design decisions\n\n### Novel cache design\n\nDragonfly has a single, unified, adaptive caching algorithm that is simple and memory efficient.\n\nYou can enable caching mode by passing the `--cache_mode=true` flag. Once this mode is on, Dragonfly will evict items least likely to be stumbled upon in the future but only when it is near the `maxmemory` limit.\n\n### Expiration deadlines with relative accuracy\n\nExpiration ranges are limited to ~8 years.\n\nExpiration deadlines with millisecond precision (PEXPIRE, PSETEX, etc.) are rounded to the closest second **for deadlines greater than 2^28ms**, which has less than 0.001% error and should be acceptable for large ranges. If this is not suitable for your use case, get in touch or open an issue explaining your case.\n\nFor more detailed differences between Dragonfly expiration deadlines and Redis implementations, [see here](docs/differences.md).\n\n### Native HTTP console and Prometheus-compatible metrics\n\nBy default, Dragonfly allows HTTP access via its main TCP port (6379). That's right, you can connect to Dragonfly via Redis protocol and via HTTP protocol ‚Äî the server recognizes the protocol automatically during the connection initiation. Go ahead and try it with your browser. HTTP access currently does not have much info but will include useful debugging and management info in the future.\n\nGo to the URL `:6379/metrics` to view Prometheus-compatible metrics.\n\nThe Prometheus exported metrics are compatible with the Grafana dashboard, [see here](tools/local/monitoring/grafana/provisioning/dashboards/dashboard.json).\n\n\nImportant! The HTTP console is meant to be accessed within a safe network. If you expose Dragonfly's TCP port externally, we advise you to disable the console with `--http_admin_console=false` or `--nohttp_admin_console`.\n\n\n## <a name=\"background\"><a/>Background\n\nDragonfly started as an experiment to see how an in-memory datastore could look if it was designed in 2022. Based on lessons learned from our experience as users of memory stores and engineers who worked for cloud companies, we knew that we need to preserve two key properties for Dragonfly: Atomicity guarantees for all operations and low, sub-millisecond latency over very high throughput.\n\nOur first challenge was how to fully utilize CPU, memory, and I/O resources using servers that are available today in public clouds. To solve this, we use [shared-nothing architecture](https://en.wikipedia.org/wiki/Shared-nothing_architecture), which allows us to partition the keyspace of the memory store between threads so that each thread can manage its own slice of dictionary data. We call these slices \"shards\". The library that powers thread and I/O management for shared-nothing architecture is open-sourced [here](https://github.com/romange/helio).\n\nTo provide atomicity guarantees for multi-key operations, we use the advancements from recent academic research. We chose the paper [\"VLL: a lock manager redesign for main memory database systems‚Äù](https://www.cs.umd.edu/~abadi/papers/vldbj-vll.pdf) to develop the transactional framework for Dragonfly. The choice of shared-nothing architecture and VLL allowed us to compose atomic multi-key operations without using mutexes or spinlocks. This was a major milestone for our PoC and its performance stood out from other commercial and open-source solutions.\n\nOur second challenge was to engineer more efficient data structures for the new store. To achieve this goal, we based our core hashtable structure on the paper [\"Dash: Scalable Hashing on Persistent Memory\"](https://arxiv.org/pdf/2003.07302.pdf). The paper itself is centered around the persistent memory domain and is not directly related to main-memory stores, but it's still most applicable to our problem. The hashtable design suggested in the paper allowed us to maintain two special properties that are present in the Redis dictionary: The incremental hashing ability during datastore growth the ability to traverse the dictionary under changes using a stateless scan operation. In addition to these two properties, Dash is more efficient in CPU and memory use. By leveraging Dash's design, we were able to innovate further with the following features:\n * Efficient record expiry for TTL records.\n * A novel cache eviction algorithm that achieves higher hit rates than other caching strategies like LRU and LFU with **zero memory overhead**.\n * A novel **fork-less** snapshotting algorithm.\n\nOnce we had built the foundation for Dragonfly and [we were happy with its performance](#benchmarks), we went on to implement the Redis and Memcached functionality. We have to date implemented ~185 Redis commands (roughly equivalent to Redis 5.0 API) and 13 Memcached commands.\n\nAnd finally, <br>\n<em>Our mission is to build a well-designed, ultra-fast, cost-efficient in-memory datastore for cloud workloads that takes advantage of the latest hardware advancements. We intend to address the pain points of current solutions while preserving their product APIs and propositions.</em>\n",
      "stars_today": 10
    },
    {
      "id": 146327667,
      "name": "vector",
      "full_name": "vectordotdev/vector",
      "description": "A high-performance observability data pipeline.",
      "html_url": "https://github.com/vectordotdev/vector",
      "stars": 21160,
      "forks": 1983,
      "language": "Rust",
      "topics": [
        "events",
        "forwarder",
        "hacktoberfest",
        "logs",
        "metrics",
        "observability",
        "parser",
        "pipeline",
        "router",
        "rust",
        "stream-processing",
        "vector"
      ],
      "created_at": "2018-08-27T16:57:34Z",
      "updated_at": "2026-01-23T01:53:37Z",
      "pushed_at": "2026-01-22T22:39:21Z",
      "open_issues": 2232,
      "owner": {
        "login": "vectordotdev",
        "avatar_url": "https://avatars.githubusercontent.com/u/16866914?v=4"
      },
      "readme": "[![Nightly](https://github.com/vectordotdev/vector/actions/workflows/nightly.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/nightly.yml)\n[![Integration/E2E Test Suite](https://github.com/vectordotdev/vector/actions/workflows/integration.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/integration.yml/badge.svg?event=merge_group)\n[![Component Features](https://github.com/vectordotdev/vector/actions/workflows/component_features.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/component_features.yml)\n\n<p align=\"center\">\n  <img src=\"website/static/img/diagram.svg\" alt=\"Vector\">\n</p>\n\n<p align=\"center\">\n  <strong>\n    <a href=\"https://vector.dev/docs/setup/quickstart/\">Quickstart</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://vector.dev/docs/\">Docs</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://vector.dev/guides/\">Guides</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://vector.dev/components/\">Integrations</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://chat.vector.dev\">Chat</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://vector.dev/releases/latest/download/\">Download</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;\n    <a href=\"https://rust-doc.vector.dev/\">Rust Crate Docs</a>\n  </strong>\n</p>\n\n## What is Vector?\n\nVector is a high-performance, end-to-end (agent & aggregator) observability data\npipeline that puts you in control of your observability data.\n[Collect][docs.sources], [transform][docs.transforms], and [route][docs.sinks]\nall your logs and metrics to any vendors you want today and any other\nvendors you may want tomorrow. Vector enables dramatic cost reduction, novel\ndata enrichment, and data security where you need it, not where it is most\nconvenient for your vendors. Additionally, it is open source and up to 10x\nfaster than every alternative in the space.\n\nTo get started, follow our [**quickstart guide**][docs.quickstart] or [**install\nVector**][docs.installation].\n\nVector is maintained by Datadog's [Community Open Source Engineering team](https://opensource.datadoghq.com/about/#the-community-open-source-engineering-team).\n\n### Principles\n\n* **Reliable** - Built in [Rust][urls.rust], Vector's primary design goal is reliability.\n* **End-to-end** - Deploys as an [agent][docs.roles#agent] or [aggregator][docs.roles#aggregator]. Vector is a complete platform.\n* **Unified** - [Logs][docs.data-model.log], [metrics][docs.data-model.metric] (beta), and traces (coming soon). One tool for all of your data.\n\n### Use cases\n\n* Reduce total observability costs.\n* Transition vendors without disrupting workflows.\n* Enhance data quality and improve insights.\n* Consolidate agents and eliminate agent fatigue.\n* Improve overall observability performance and reliability.\n\n### Community\n\n* Vector is relied on by startups and enterprises like **Atlassian**, **T-Mobile**,\n  **Comcast**, **Zendesk**, **Discord**, **Fastly**, **CVS**, **Trivago**,\n  **Tuple**, **Douban**, **Visa**, **Mambu**, **Blockfi**, **Claranet**,\n  **Instacart**, **Forcepoint**, and [many more][urls.production_users].\n* Vector is **downloaded over 100,000 times per day**.\n* Vector's largest user **processes over 500TB daily**.\n* Vector has **over 500 contributors** and growing.\n\n## Documentation\n\nAll user documentation is available at **[vector.dev/docs](https://vector.dev/docs)**.\n\nOther Resources:\n\n* [**Vector Calendar**][urls.vector_calendar]\n* **Policies**:\n  * [**Code of Conduct**][urls.vector_code_of_conduct]\n  * [**Contributing**][urls.vector_contributing_policy]\n  * [**Privacy**][urls.vector_privacy_policy]\n  * [**Releases**][urls.vector_releases_policy]\n  * [**Versioning**][urls.vector_versioning_policy]\n  * [**Security**][urls.vector_security_policy]\n\n## Comparisons\n\n### Performance\n\nThe following performance tests demonstrate baseline performance between\ncommon protocols with the exception of the Regex Parsing test.\n\n| Test                                                                                                                   | Vector          | Filebeat | FluentBit       | FluentD   | Logstash  | SplunkUF        | SplunkHF |\n| ---------------------------------------------------------------------------------------------------------------------- | --------------- | -------- | --------------- | --------- | --------- | --------------- | -------- |\n| [TCP to Blackhole](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_blackhole_performance) | _**86mib/s**_   | n/a      | 64.4mib/s       | 27.7mib/s | 40.6mib/s | n/a             | n/a      |\n| [File to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_to_tcp_performance)           | _**76.7mib/s**_ | 7.8mib/s | 35mib/s         | 26.1mib/s | 3.1mib/s  | 40.1mib/s       | 39mib/s  |\n| [Regex Parsing](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/regex_parsing_performance)       | 13.2mib/s       | n/a      | _**20.5mib/s**_ | 2.6mib/s  | 4.6mib/s  | n/a             | 7.8mib/s |\n| [TCP to HTTP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_http_performance)           | _**26.7mib/s**_ | n/a      | 19.6mib/s       | <1mib/s   | 2.7mib/s  | n/a             | n/a      |\n| [TCP to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_tcp_performance)             | 69.9mib/s       | 5mib/s   | 67.1mib/s       | 3.9mib/s  | 10mib/s   | _**70.4mib/s**_ | 7.6mib/s |\n\nTo learn more about our performance tests, please see the [Vector test harness][urls.vector_test_harness].\n\n### Correctness\n\nThe following correctness tests are not exhaustive, but they demonstrate\nfundamental differences in quality and attention to detail:\n\n| Test                                                                                                                                 | Vector | Filebeat | FluentBit | FluentD | Logstash | Splunk UF | Splunk HF |\n| ------------------------------------------------------------------------------------------------------------------------------------ | ------ | -------- | --------- | ------- | -------- | --------- | --------- |\n| [Disk Buffer Persistence](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/disk_buffer_persistence_correctness) | **‚úì**  | ‚úì        |           |         | ‚ö†        | ‚úì         | ‚úì         |\n| [File Rotate (create)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_create_correctness)         | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |\n| [File Rotate (copytruncate)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_truncate_correctness) | **‚úì**  |          |           |         |          | ‚úì         | ‚úì         |\n| [File Truncation](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_truncate_correctness)                   | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |\n| [Process (SIGHUP)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/sighup_correctness)                         | **‚úì**  |          |           |         | ‚ö†        | ‚úì         | ‚úì         |\n| [JSON (wrapped)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/wrapped_json_correctness)                     | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |\n\nTo learn more about our correctness tests, please see the [Vector test harness][urls.vector_test_harness].\n\n### Features\n\nVector is an end-to-end, unified, open data platform.\n\n|                     | **Vector** | Beats | Fluentbit | Fluentd | Logstash | Splunk UF | Splunk HF | Telegraf |\n| ------------------- | ---------- | ----- | --------- | ------- | -------- | --------- | --------- | -------- |\n| **End-to-end**      | **‚úì**      |       |           |         |          |           |           | ‚úì        |\n| Agent               | **‚úì**      | ‚úì     | ‚úì         |         |          | ‚úì         |           | ‚úì        |\n| Aggregator          | **‚úì**      |       |           | ‚úì       | ‚úì        |           | ‚úì         | ‚úì        |\n| **Unified**         | **‚úì**      |       |           |         |          |           |           | ‚úì        |\n| Logs                | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         | ‚úì        |\n| Metrics             | **‚úì**      | ‚ö†     | ‚ö†         | ‚ö†       | ‚ö†        | ‚ö†         | ‚ö†         | ‚úì        |\n| Traces              | üöß         |       |           |         |          |           |           |          |\n| **Open**            | **‚úì**      |       | ‚úì         | ‚úì       |          |           |           | ‚úì        |\n| Open-source         | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        |           |           | ‚úì        |\n| Vendor-neutral      | **‚úì**      |       | ‚úì         | ‚úì       |          |           |           | ‚úì        |\n| **Reliability**     | **‚úì**      |       |           |         |          |           |           |          |\n| Memory-safe         | **‚úì**      |       |           |         |          |           |           | ‚úì        |\n| Delivery guarantees | **‚úì**      |       |           |         |          | ‚úì         | ‚úì         |          |\n| Multi-core          | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         | ‚úì        |\n\n\n‚ö† = Not interoperable, metrics are represented as structured logs\n\n---\n\n<p align=\"center\">\n  Developed with ‚ù§Ô∏è by <strong><a href=\"https://datadoghq.com\">Datadog</a></strong> - <a href=\"https://github.com/vectordotdev/vector/security/policy\">Security Policy</a> - <a href=\"https://github.com/vectordotdev/vector/blob/master/PRIVACY.md\">Privacy Policy</a>\n</p>\n\n[docs.about.concepts]: https://vector.dev/docs/introduction/concepts/\n[docs.about.introduction]: https://vector.dev/docs/introduction/\n[docs.administration.monitoring]: https://vector.dev/docs/administration/monitoring/\n[docs.administration.management]: https://vector.dev/docs/administration/management/\n[docs.administration.upgrading]: https://vector.dev/docs/administration/upgrading/\n[docs.administration.validating]: https://vector.dev/docs/administration/validating/\n[docs.architecture.concurrency-model]: https://vector.dev/docs/architecture/concurrency-model/\n[docs.architecture.data-model]: https://vector.dev/docs/architecture/data-model/\n[docs.architecture.pipeline-model]: https://vector.dev/docs/architecture/pipeline-model/\n[docs.architecture.runtime-model]: https://vector.dev/docs/architecture/runtime-model/\n[docs.configuration.sinks]: https://vector.dev/docs/reference/configuration/sinks/\n[docs.configuration.sources]: https://vector.dev/docs/reference/configuration/sources/\n[docs.configuration.tests]: https://vector.dev/docs/reference/configuration/tests/\n[docs.configuration.transforms]: https://vector.dev/docs/reference/configuration/transforms/\n[docs.configuration.enrichment_tables]: https://vector.dev/docs/reference/configuration/global-options/#enrichment_tables\n[docs.data-model.log]: https://vector.dev/docs/architecture/data-model/log/\n[docs.data-model.metric]: https://vector.dev/docs/architecture/data-model/metric/\n[docs.deployment.roles]: https://vector.dev/docs/setup/deployment/roles/\n[docs.deployment.topologies]: https://vector.dev/docs/setup/deployment/topologies/\n[docs.deployment]: https://vector.dev/docs/setup/deployment/\n[docs.installation.manual]: https://vector.dev/docs/setup/installation/manual/\n[docs.installation.operating_systems]: https://vector.dev/docs/setup/installation/operating-systems/\n[docs.installation.package_managers]: https://vector.dev/docs/setup/installation/package-managers/\n[docs.installation.platforms]: https://vector.dev/docs/setup/installation/platforms/\n[docs.installation]: https://vector.dev/docs/setup/installation/\n[docs.architecture.adaptive-request-concurrency]: https://vector.dev/docs/architecture/arc/\n[docs.platforms.kubernetes]: https://vector.dev/docs/setup/installation/platforms/kubernetes/\n[docs.quickstart]: https://vector.dev/docs/setup/quickstart/\n[docs.reference.api]: https://vector.dev/docs/reference/api/\n[docs.reference.cli]: https://vector.dev/docs/reference/cli/\n[docs.reference.vrl]: https://vector.dev/docs/reference/vrl/\n[docs.roles#agent]: https://vector.dev/docs/setup/deployment/roles/#agent\n[docs.roles#aggregator]: https://vector.dev/docs/setup/deployment/roles/#aggregator\n[docs.setup.installation]: https://vector.dev/docs/setup/installation/\n[docs.setup.quickstart]: https://vector.dev/docs/setup/quickstart/\n[docs.sinks.aws_cloudwatch_logs]: https://vector.dev/docs/reference/configuration/sinks/aws_cloudwatch_logs/\n[docs.sinks.aws_s3]: https://vector.dev/docs/reference/configuration/sinks/aws_s3/\n[docs.sinks.clickhouse]: https://vector.dev/docs/reference/configuration/sinks/clickhouse/\n[docs.sinks.elasticsearch]: https://vector.dev/docs/reference/configuration/sinks/elasticsearch/\n[docs.sinks.gcp_cloud_storage]: https://vector.dev/docs/reference/configuration/sinks/gcp_cloud_storage/\n[docs.sinks]: https://vector.dev/docs/reference/configuration/sinks/\n[docs.sources.docker_logs]: https://vector.dev/docs/reference/configuration/sources/docker_logs/\n[docs.sources.file]: https://vector.dev/docs/reference/configuration/sources/file/\n[docs.sources.http]: https://vector.dev/docs/reference/configuration/sources/http/\n[docs.sources.journald]: https://vector.dev/docs/reference/configuration/sources/journald/\n[docs.sources.kafka]: https://vector.dev/docs/reference/configuration/sources/kafka/\n[docs.sources.socket]: https://vector.dev/docs/reference/configuration/sources/socket/\n[docs.sources]: https://vector.dev/docs/reference/configuration/sources/\n[docs.transforms.dedupe]: https://vector.dev/docs/reference/configuration/transforms/dedupe/\n[docs.transforms.filter]: https://vector.dev/docs/reference/configuration/transforms/filter/\n[docs.transforms.log_to_metric]: https://vector.dev/docs/reference/configuration/transforms/log_to_metric/\n[docs.transforms.lua]: https://vector.dev/docs/reference/configuration/transforms/lua/\n[docs.transforms.remap]: https://vector.dev/docs/reference/configuration/transforms/remap/\n[docs.transforms]: https://vector.dev/docs/reference/configuration/transforms/\n[docs.introduction.architecture]: https://vector.dev/docs/architecture/\n[docs.introduction.guarantees]: https://vector.dev/docs/introduction/guarantees/\n[docs.introduction.architecture]: https://vector.dev/docs/architecture/\n[urls.production_users]: https://github.com/vectordotdev/vector/issues/790\n[urls.rust]: https://www.rust-lang.org/\n[urls.vector_calendar]: https://calendar.vector.dev\n[urls.vector_chat]: https://chat.vector.dev\n[urls.vector_code_of_conduct]: https://github.com/vectordotdev/vector/blob/master/CODE_OF_CONDUCT.md\n[urls.vector_contributing_policy]: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md\n[urls.vector_community]: https://vector.dev/community/\n[urls.vector_privacy_policy]: https://github.com/vectordotdev/vector/blob/master/PRIVACY.md\n[urls.vector_release_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASING.md\n[urls.vector_releases]: https://vector.dev/releases/\n[urls.vector_releases_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASES.md\n[urls.vector_security_policy]: https://github.com/vectordotdev/vector/security/policy\n[urls.vector_test_harness]: https://github.com/vectordotdev/vector-test-harness/\n[urls.vector_twitter]: https://twitter.com/vectordotdev\n[urls.vector_versioning_policy]: https://github.com/vectordotdev/vector/blob/master/VERSIONING.md\n[urls.vote_feature]: https://github.com/vectordotdev/vector/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22type%3A+feature%22\n",
      "stars_today": 10
    },
    {
      "id": 51840802,
      "name": "pino",
      "full_name": "pinojs/pino",
      "description": "üå≤ super fast, all natural json logger",
      "html_url": "https://github.com/pinojs/pino",
      "stars": 17202,
      "forks": 937,
      "language": "JavaScript",
      "topics": [
        "fast",
        "json",
        "logger",
        "nodejs",
        "pino"
      ],
      "created_at": "2016-02-16T14:14:29Z",
      "updated_at": "2026-01-23T01:26:07Z",
      "pushed_at": "2026-01-22T14:33:32Z",
      "open_issues": 142,
      "owner": {
        "login": "pinojs",
        "avatar_url": "https://avatars.githubusercontent.com/u/23048140?v=4"
      },
      "readme": "![banner](pino-banner.png)\n\n# pino\n[![npm version](https://img.shields.io/npm/v/pino)](https://www.npmjs.com/package/pino)\n[![Build Status](https://img.shields.io/github/actions/workflow/status/pinojs/pino/ci.yml)](https://github.com/pinojs/pino/actions)\n[![js-standard-style](https://img.shields.io/badge/code%20style-standard-brightgreen.svg?style=flat)](https://standardjs.com/)\n\n[Very low overhead](#low-overhead) JavaScript logger.\n\n## Documentation\n\n* [Benchmarks ‚áó](/docs/benchmarks.md)\n* [API ‚áó](/docs/api.md)\n* [Browser API ‚áó](/docs/browser.md)\n* [Redaction ‚áó](/docs/redaction.md)\n* [Child Loggers ‚áó](/docs/child-loggers.md)\n* [Transports ‚áó](/docs/transports.md)\n* [Diagnostics ‚áó](/docs/diagnostics.md)\n* [Web Frameworks ‚áó](/docs/web.md)\n* [Pretty Printing ‚áó](/docs/pretty.md)\n* [Asynchronous Logging ‚áó](/docs/asynchronous.md)\n* [Ecosystem ‚áó](/docs/ecosystem.md)\n* [Help ‚áó](/docs/help.md)\n* [Long Term Support Policy ‚áó](/docs/lts.md)\n\n## Runtimes\n\n### Node.js\n\nPino is built to run on [Node.js](http://nodejs.org).\n\n### Bare\n\nPino works on [Bare](https://github.com/holepunchto/bare) with the [`pino-bare`](https://github.com/pinojs/pino-bare) compatability module.\n\n### Pear\n\nPino works on [Pear](https://docs.pears.com), which is built on [Bare](https://github.com/holepunchto/bare), with the [`pino-bare`](https://github.com/pinojs/pino-bare) compatibility module.\n\n\n## Install\n\nUsing NPM:\n```\n$ npm install pino\n```\n\nUsing YARN:\n```\n$ yarn add pino\n```\n\nIf you would like to install pino v6, refer to https://github.com/pinojs/pino/tree/v6.x.\n\n## Usage\n\n```js\nconst logger = require('pino')()\n\nlogger.info('hello world')\n\nconst child = logger.child({ a: 'property' })\nchild.info('hello child!')\n```\n\nThis produces:\n\n```\n{\"level\":30,\"time\":1531171074631,\"msg\":\"hello world\",\"pid\":657,\"hostname\":\"Davids-MBP-3.fritz.box\"}\n{\"level\":30,\"time\":1531171082399,\"msg\":\"hello child!\",\"pid\":657,\"hostname\":\"Davids-MBP-3.fritz.box\",\"a\":\"property\"}\n```\n\nFor using Pino with a web framework see:\n\n* [Pino with Fastify](docs/web.md#fastify)\n* [Pino with Express](docs/web.md#express)\n* [Pino with Hapi](docs/web.md#hapi)\n* [Pino with Restify](docs/web.md#restify)\n* [Pino with Koa](docs/web.md#koa)\n* [Pino with Node core `http`](docs/web.md#http)\n* [Pino with Nest](docs/web.md#nest)\n* [Pino with Hono](docs/web.md#hono)\n\n<a name=\"essentials\"></a>\n## Essentials\n\n### Development Formatting\n\nThe [`pino-pretty`](https://github.com/pinojs/pino-pretty) module can be used to\nformat logs during development:\n\n![pretty demo](pretty-demo.png)\n\n### Transports & Log Processing\n\nDue to Node's single-threaded event-loop, it's highly recommended that sending,\nalert triggering, reformatting, and all forms of log processing\nare conducted in a separate process or thread.\n\nIn Pino terminology, we call all log processors \"transports\" and recommend that the\ntransports be run in a worker thread using our `pino.transport` API.\n\nFor more details see our [Transports‚áó](docs/transports.md) document.\n\n### Low overhead\n\nUsing minimum resources for logging is very important. Log messages\ntend to get added over time and this can lead to a throttling effect\non applications ‚Äì¬†such as reduced requests per second.\n\nIn many cases, Pino is over 5x faster than alternatives.\n\nSee the [Benchmarks](docs/benchmarks.md) document for comparisons.\n\n### Bundling support\n\nPino supports being bundled using tools like webpack or esbuild. \n\nSee [Bundling](docs/bundling.md) document for more information.\n\n<a name=\"team\"></a>\n## The Team\n\n### Matteo Collina\n\n<https://github.com/mcollina>\n\n<https://www.npmjs.com/~matteo.collina>\n\n<https://twitter.com/matteocollina>\n\n### David Mark Clements\n\n<https://github.com/davidmarkclements>\n\n<https://www.npmjs.com/~davidmarkclements>\n\n<https://twitter.com/davidmarkclem>\n\n### James Sumners\n\n<https://github.com/jsumners>\n\n<https://www.npmjs.com/~jsumners>\n\n<https://twitter.com/jsumners79>\n\n### Thomas Watson Steen\n\n<https://github.com/watson>\n\n<https://www.npmjs.com/~watson>\n\n<https://twitter.com/wa7son>\n\n## Contributing\n\nPino is an **OPEN Open Source Project**. This means that:\n\n> Individuals making significant and valuable contributions are given commit-access to the project to contribute as they see fit. This project is more like an open wiki than a standard guarded open source project.\n\nSee the [CONTRIBUTING.md](https://github.com/pinojs/pino/blob/main/CONTRIBUTING.md) file for more details.\n\n<a name=\"acknowledgments\"></a>\n## Acknowledgments\n\nThis project was kindly sponsored by [nearForm](https://nearform.com).\nThis project is kindly sponsored by [Platformatic](https://platformatic.dev).\n\nLogo and identity designed by Cosmic Fox Design: https://www.behance.net/cosmicfox.\n\n## License\n\nLicensed under [MIT](./LICENSE).\n\n[elasticsearch]: https://www.elastic.co/products/elasticsearch\n[kibana]: https://www.elastic.co/products/kibana\n",
      "stars_today": 10
    },
    {
      "id": 476642602,
      "name": "rspack",
      "full_name": "web-infra-dev/rspack",
      "description": "The fast Rust-based JavaScript bundler with webpack-compatible API ü¶ÄÔ∏è",
      "html_url": "https://github.com/web-infra-dev/rspack",
      "stars": 12420,
      "forks": 757,
      "language": "Rust",
      "topics": [
        "build-tool",
        "bundler",
        "compiler",
        "esm",
        "javascript",
        "jsx",
        "loaders",
        "module-bundler",
        "rspack",
        "rstack",
        "rust",
        "typescript",
        "web",
        "web-performance",
        "webpack"
      ],
      "created_at": "2022-04-01T08:45:30Z",
      "updated_at": "2026-01-22T20:26:18Z",
      "pushed_at": "2026-01-22T16:31:25Z",
      "open_issues": 201,
      "owner": {
        "login": "web-infra-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/87694465?v=4"
      },
      "readme": "<picture>\n  <img alt=\"Rspack Banner\" src=\"https://assets.rspack.rs/rspack/rspack-banner.png\">\n</picture>\n\n# Rspack\n\n<p>\n  <a href=\"https://discord.gg/79ZZ66GH9E\"><img src=\"https://img.shields.io/badge/chat-discord-blue?style=flat-square&logo=discord&colorA=564341&colorB=EDED91\" alt=\"discord channel\" /></a>\n  <a href=\"https://www.npmjs.com/package/@rspack/core?activeTab=readme\"><img src=\"https://img.shields.io/npm/v/@rspack/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>\n  <a href=\"https://crates.io/crates/rspack_core\"><img src=\"https://img.shields.io/crates/v/rspack_core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"crates version\" /></a>\n  <a href=\"https://npmcharts.com/compare/@rspack/core?minimal=true\"><img src=\"https://img.shields.io/npm/dm/@rspack/core.svg?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"downloads\" /></a>\n  <a href=\"https://nodejs.org/en/about/previous-releases\"><img src=\"https://img.shields.io/node/v/@rspack/core.svg?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"node version\"></a>\n  <a href=\"https://github.com/web-infra-dev/rspack/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"license\" /></a>\n  <a href=\"https://codspeed.io/web-infra-dev/rspack\"><img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fcodspeed.io%2Fbadge.json&style=flat-square&colorA=564341&colorB=EDED91\" alt=\"codspeed\" /></a>\n</p>\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md)\n\nRspack is a high performance JavaScript bundler written in Rust. It offers strong compatibility with the webpack ecosystem, allowing for seamless replacement of webpack, and provides lightning fast build speeds.\n\n## ‚ú® Features\n\n- üöÄ **Fast Startup**: Based on Rust, the build speed is extremely fast, bringing you the ultimate development experience.\n- ‚ö° **Lightning HMR**: With a built-in incremental compilation mechanism, HMR is extremely fast and fully capable of developing large-scale projects.\n- üì¶ **Webpack Compatible**: Compatible with plugins and loaders in the webpack ecosystem, seamlessly integrating excellent libraries built by the community.\n- üé® **Module Federation**: Provide first-class support for Module Federation to facilitate the development of large-scale web applications.\n- üõ†Ô∏è **Production Optimization**: Various optimization strategies are built in by default, such as tree shaking, minification, etc.\n- üéØ **Framework Agnostic**: Not bound to any frontend framework, ensuring enough flexibility.\n\nRead [Introduction](https://rspack.rs/guide/start/introduction) for details.\n\n## ü¶Ä Rstack\n\nRstack is a unified JavaScript toolchain centered on Rspack, with high performance and consistent architecture.\n\n| Name                                                  | Description              | Version                                                                                                                                                                          |\n| ----------------------------------------------------- | ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [Rspack](https://github.com/web-infra-dev/rspack)     | Bundler                  | <a href=\"https://npmjs.com/package/@rspack/core\"><img src=\"https://img.shields.io/npm/v/@rspack/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>     |\n| [Rsbuild](https://github.com/web-infra-dev/rsbuild)   | Build tool               | <a href=\"https://npmjs.com/package/@rsbuild/core\"><img src=\"https://img.shields.io/npm/v/@rsbuild/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>   |\n| [Rslib](https://github.com/web-infra-dev/rslib)       | Library development tool | <a href=\"https://npmjs.com/package/@rslib/core\"><img src=\"https://img.shields.io/npm/v/@rslib/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>       |\n| [Rspress](https://github.com/web-infra-dev/rspress)   | Static site generator    | <a href=\"https://npmjs.com/package/@rspress/core\"><img src=\"https://img.shields.io/npm/v/@rspress/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>   |\n| [Rsdoctor](https://github.com/web-infra-dev/rsdoctor) | Build analyzer           | <a href=\"https://npmjs.com/package/@rsdoctor/core\"><img src=\"https://img.shields.io/npm/v/@rsdoctor/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a> |\n| [Rstest](https://github.com/web-infra-dev/rstest)     | Testing framework        | <a href=\"https://npmjs.com/package/@rstest/core\"><img src=\"https://img.shields.io/npm/v/@rstest/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>     |\n| [Rslint](https://github.com/web-infra-dev/rslint)     | Linter                   | <a href=\"https://npmjs.com/package/@rslint/core\"><img src=\"https://img.shields.io/npm/v/@rslint/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>     |\n\n## Getting started\n\n<p>\n  <a target=\"_blank\" href=\"https://stackblitz.com/fork/github/rstackjs/rspack-stackblitz-example\">\n    <img\n      alt=\"Open in StackBlitz\"\n      src=\"https://developer.stackblitz.com/img/open_in_stackblitz.svg\"\n    />\n  </a>\n</p>\n\nSee [Quick start](https://rspack.rs/guide/start/quick-start).\n\n## Contribution\n\nPlease read the [contributing guide](./CONTRIBUTING.md) and let's build Rspack together.\n\n### Code of conduct\n\nThis repo has adopted the ByteDance Open Source Code of Conduct. Please check [Code of conduct](./CODE_OF_CONDUCT.md) for more details.\n\n## Community\n\nCome chat with us on [Discord](https://discord.gg/79ZZ66GH9E)! Rspack team and Rspack users are active there, and we're always looking for contributions.\n\n## Links\n\n| Name                                                                           | Description                                                                   |\n| ------------------------------------------------------------------------------ | ----------------------------------------------------------------------------- |\n| [awesome-rstack](https://github.com/rstackjs/awesome-rstack)                   | A curated list of awesome things related to Rstack                            |\n| [Rspack 1.x documentation](https://rspack.rs/)                                 | Documentation for Rspack 1.x (latest)                                         |\n| [Rspack 0.x documentation](https://v0.rspack.rs/)                              | Documentation for Rspack 0.x version                                          |\n| [rspack-dev-server](https://github.com/web-infra-dev/rspack-dev-server)        | Dev server for Rspack                                                         |\n| [rstack-examples](https://github.com/rstackjs/rstack-examples)                 | Examples showcasing Rstack                                                    |\n| [rspack-sources](https://github.com/rstackjs/rspack-sources)                   | Rust port of [webpack-sources](https://www.npmjs.com/package/webpack-sources) |\n| [rstack-design-resources](https://github.com/rstackjs/rstack-design-resources) | Design resources for Rstack                                                   |\n\n## Contributors\n\n<a href=\"https://github.com/web-infra-dev/rspack/graphs/contributors\"><img src=\"https://opencollective.com/rspack/contributors.svg?width=890&button=false\" /></a>\n\n## Benchmark\n\nSee [Benchmark](https://ecosystem-benchmark.rspack.rs/).\n\n## Credits\n\nThanks to:\n\n- [The webpack team and community](https://webpack.js.org/) for creating a great bundler and ecosystem from which we draw a lot of inspiration.\n- [@sokra](https://github.com/sokra) for the great work on the [webpack](https://github.com/webpack/webpack) project.\n- [@ScriptedAlchemy](https://github.com/ScriptedAlchemy) for creating Module Federation and helping Rspack connect with the community.\n- The [SWC](https://github.com/swc-project/swc) project created by [@kdy1](https://github.com/kdy1), which powers Rspack's code parsing, transformation and minification.\n- The [esbuild](https://github.com/evanw/esbuild) project created by [@evanw](https://github.com/evanw), which inspired the concurrent architecture of Rspack.\n- The [NAPI-RS](https://github.com/napi-rs/napi-rs) project created by [@Brooooooklyn](https://github.com/Brooooooklyn), which powers Rspack's node-binding implementation.\n- The [Parcel](https://github.com/parcel-bundler/parcel) project created by [@devongovett](https://github.com/devongovett) which is the pioneer of rust bundler and inspired Rspack's incremental rebuild design.\n- The [Vite](https://github.com/vitejs/vite) project created by [Evan You](https://github.com/yyx990803) which inspired Rspack's compatibility design of webpack's ecosystem.\n- The `rolldown-legacy` project created by old Rolldown team, It's the predecessor of the [rolldown](https://github.com/rolldown) project, which explores the possibility of making a performant bundler in Rust with Rollup-compatible API. It inspires the design principles of Rspack.\n- The [html-webpack-plugin](https://github.com/jantimon/html-webpack-plugin) project created by [@jantimon](https://github.com/jantimon), `@rspack/html-plugin` is a fork of [html-webpack-plugin](https://github.com/jantimon/html-webpack-plugin) to avoid some webpack API usage not supported in Rspack.\n- The [Turbopack](https://github.com/vercel/turbo) project which inspired the AST path logic of Rspack.\n- The [react-refresh-webpack-plugin](https://github.com/pmmmwh/react-refresh-webpack-plugin) created by [@pmmmwh](https://github.com/pmmmwh), which inspires implement [react refresh rspack plugin](https://github.com/rstackjs/rspack-plugin-react-refresh).\n- The [prefresh](https://github.com/preactjs/prefresh) created by [@Jovi De Croock](https://github.com/JoviDeCroock), which inspires implement [preact refresh rspack plugin](https://github.com/rstackjs/rspack-plugin-preact-refresh).\n- The [mini-css-extract-plugin](https://github.com/webpack/mini-css-extract-plugin) project created by [@sokra](https://github.com/sokra) which inspired implement css extract plugin.\n- The [copy-webpack-plugin](https://github.com/webpack/copy-webpack-plugin) project created by [@kevlened](https://github.com/kevlened) which inspired implement copy rspack plugin.\n- The [webpack-subresource-integrity](https://github.com/waysact/webpack-subresource-integrity) project created by [@jscheid](https://github.com/jscheid), which inspires implement subresource integrity rspack plugin.\n- The [circular-dependency-plugin](https://github.com/aackerman/circular-dependency-plugin) project created by [@aackerman](https://github.com/aackerman), which inspres implement circular dependency rspack plugin.\n- The [tracing-chrome](https://github.com/thoren-d/tracing-chrome) project created by [thoren-d](https://github.com/thoren-d), which inspires the implementation of Rspack tracing.\n\n## License\n\nRspack is [MIT licensed](https://github.com/web-infra-dev/rspack/blob/main/LICENSE).\n",
      "stars_today": 10
    },
    {
      "id": 969892666,
      "name": "SQLBot",
      "full_name": "dataease/SQLBot",
      "description": "üî• Âü∫‰∫éÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªüÔºåÂØπËØùÂºèÊï∞ÊçÆÂàÜÊûêÁ•ûÂô®„ÄÇText-to-SQL Generation via LLMs using RAG.",
      "html_url": "https://github.com/dataease/SQLBot",
      "stars": 5329,
      "forks": 567,
      "language": "JavaScript",
      "topics": [
        "chatbi",
        "deepseek",
        "llm",
        "nl2sql",
        "rag",
        "sqlbot",
        "text-to-sql",
        "text2sql"
      ],
      "created_at": "2025-04-21T05:33:53Z",
      "updated_at": "2026-01-23T01:19:48Z",
      "pushed_at": "2026-01-22T09:30:29Z",
      "open_issues": 71,
      "owner": {
        "login": "dataease",
        "avatar_url": "https://avatars.githubusercontent.com/u/75054108?v=4"
      },
      "readme": "<p align=\"center\"><img src=\"https://resource-fit2cloud-com.oss-cn-hangzhou.aliyuncs.com/sqlbot/sqlbot.png\" alt=\"SQLBot\" width=\"300\" /></p>\n<h3 align=\"center\">Âü∫‰∫éÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªü</h3>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/14540\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/14540\" alt=\"dataease%2FSQLBot | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/dataease/SQLBot/releases/latest\"><img src=\"https://img.shields.io/github/v/release/dataease/SQLBot\" alt=\"Latest release\"></a>\n  <a href=\"https://github.com/dataease/SQLBot\"><img src=\"https://img.shields.io/github/stars/dataease/SQLBot?color=%231890FF&style=flat-square\" alt=\"Stars\"></a>    \n  <a href=\"https://hub.docker.com/r/dataease/SQLbot\"><img src=\"https://img.shields.io/docker/pulls/dataease/sqlbot?label=downloads\" alt=\"Download\"></a><br/>\n</p>\n\n<p align=\"center\">\n  <a href=\"README.md\"><img alt=\"‰∏≠Êñá(ÁÆÄ‰Ωì)\" src=\"https://img.shields.io/badge/‰∏≠Êñá(ÁÆÄ‰Ωì)-d9d9d9\"></a>\n  <a href=\"/docs/README.en.md\"><img alt=\"English\" src=\"https://img.shields.io/badge/English-d9d9d9\"></a>\n</p>\n<hr/>\n\n\nSQLBot ÊòØ‰∏ÄÊ¨æÂü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªüÔºåÁî± DataEase ÂºÄÊ∫êÈ°πÁõÆÁªÑÂå†ÂøÉÂá∫ÂìÅ„ÄÇÂÄüÂä© SQLBotÔºåÁî®Êà∑ÂèØ‰ª•ÂÆûÁé∞ÂØπËØùÂºèÊï∞ÊçÆÂàÜÊûêÔºàChatBIÔºâÔºåÂø´ÈÄüÊèêÁÇºËé∑ÂèñÊâÄÈúÄÁöÑÊï∞ÊçÆ‰ø°ÊÅØÂèäÂèØËßÜÂåñÂõæË°®ÔºåÂπ∂‰∏îÊîØÊåÅËøõ‰∏ÄÊ≠•ÂºÄÂ±ïÊô∫ËÉΩÂàÜÊûê„ÄÇ\n\n## Â∑•‰ΩúÂéüÁêÜ\n\n<img width=\"1153\" height=\"563\" alt=\"image\" src=\"https://github.com/user-attachments/assets/8bc40db1-2602-4b68-9802-b9be36281967\" />\n\n## Ê†∏ÂøÉ‰ºòÂäø\n\n- **ÂºÄÁÆ±Âç≥Áî®**Ôºö‰ªÖÈúÄÁÆÄÂçïÈÖçÁΩÆÂ§ßÊ®°Âûã‰∏éÊï∞ÊçÆÊ∫êÔºåÊó†ÈúÄÂ§çÊùÇÂºÄÂèëÔºåÂç≥ÂèØÂø´ÈÄüÂºÄÂêØÊô∫ËÉΩÈóÆÊï∞Ôºõ‰æùÊâòÂ§ßÊ®°ÂûãËá™ÁÑ∂ËØ≠Ë®ÄÁêÜËß£‰∏é SQL ÁîüÊàêËÉΩÂäõÔºåÁªìÂêà RAG ÊäÄÊúØÔºåÂÆûÁé∞È´òË¥®Èáè Text-to-SQL ËΩ¨Êç¢„ÄÇ\n- **ÂÆâÂÖ®ÂèØÊéß**ÔºöÊèê‰æõÂ∑•‰ΩúÁ©∫Èó¥Á∫ßËµÑÊ∫êÈöîÁ¶ªÊú∫Âà∂ÔºåÊûÑÂª∫Ê∏ÖÊô∞Êï∞ÊçÆËæπÁïåÔºå‰øùÈöúÊï∞ÊçÆËÆøÈóÆÂÆâÂÖ®ÔºõÊîØÊåÅÁªÜÁ≤íÂ∫¶Êï∞ÊçÆÊùÉÈôêÈÖçÁΩÆÔºåÂº∫ÂåñÊùÉÈôêÁÆ°ÊéßËÉΩÂäõÔºåÁ°Æ‰øù‰ΩøÁî®ËøáÁ®ãÂêàËßÑÂèØÊéß„ÄÇ\n- **Êòì‰∫éÈõÜÊàê**ÔºöÊîØÊåÅÂ§öÁßçÈõÜÊàêÊñπÂºèÔºåÊèê‰æõ Web ÂµåÂÖ•„ÄÅÂºπÁ™óÂµåÂÖ•„ÄÅMCP Ë∞ÉÁî®Á≠âËÉΩÂäõÔºõËÉΩÂ§üÂø´ÈÄüÂµåÂÖ•Âà∞ n8n„ÄÅDify„ÄÅMaxKB„ÄÅDataEase Á≠âÂ∫îÁî®ÔºåËÆ©ÂêÑÁ±ªÂ∫îÁî®Âø´ÈÄüÊã•ÊúâÊô∫ËÉΩÈóÆÊï∞ËÉΩÂäõ„ÄÇ\n- **Ë∂äÈóÆË∂äÂáÜ**ÔºöÊîØÊåÅËá™ÂÆö‰πâÊèêÁ§∫ËØç„ÄÅÊúØËØ≠Â∫ìÈÖçÁΩÆÔºåÂèØÁª¥Êä§ SQL Á§∫‰æãÊ†°ÂáÜÈÄªËæëÔºåÁ≤æÂáÜÂåπÈÖç‰∏öÂä°Âú∫ÊôØÔºõÈ´òÊïàËøêËê•ÔºåÂü∫‰∫éÁî®Êà∑‰∫§‰∫íÊï∞ÊçÆÊåÅÁª≠Ëø≠‰ª£‰ºòÂåñÔºåÈóÆÊï∞ÊïàÊûúÈöè‰ΩøÁî®ÈÄêÊ≠•ÊèêÂçáÔºåË∂äÈóÆË∂äÂáÜ„ÄÇ\n\n## Âø´ÈÄüÂºÄÂßã\n\n### ÂÆâË£ÖÈÉ®ÁΩ≤\n\nÂáÜÂ§á‰∏ÄÂè∞ Linux ÊúçÂä°Âô®ÔºåÂÆâË£ÖÂ•Ω [Docker](https://docs.docker.com/get-docker/)ÔºåÊâßË°å‰ª•‰∏ã‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨Ôºö\n\n```bash\ndocker run -d \\\n  --name sqlbot \\\n  --restart unless-stopped \\\n  -p 8000:8000 \\\n  -p 8001:8001 \\\n  -v ./data/sqlbot/excel:/opt/sqlbot/data/excel \\\n  -v ./data/sqlbot/file:/opt/sqlbot/data/file \\\n  -v ./data/sqlbot/images:/opt/sqlbot/images \\\n  -v ./data/sqlbot/logs:/opt/sqlbot/app/logs \\\n  -v ./data/postgresql:/var/lib/postgresql/data \\\n  --privileged=true \\\n  dataease/sqlbot\n```\n\n‰Ω†‰πüÂèØ‰ª•ÈÄöËøá [1Panel Â∫îÁî®ÂïÜÂ∫ó](https://apps.fit2cloud.com/1panel) Âø´ÈÄüÈÉ®ÁΩ≤ SQLBot„ÄÇ\n\nÂ¶ÇÊûúÊòØÂÜÖÁΩëÁéØÂ¢ÉÔºå‰Ω†ÂèØ‰ª•ÈÄöËøá [Á¶ªÁ∫øÂÆâË£ÖÂåÖÊñπÂºè](https://community.fit2cloud.com/#/products/sqlbot/downloads) ÈÉ®ÁΩ≤ SQLBot„ÄÇ\n\n### ËÆøÈóÆÊñπÂºè\n\n- Âú®ÊµèËßàÂô®‰∏≠ÊâìÂºÄ: http://<‰Ω†ÁöÑÊúçÂä°Âô®IP>:8000/\n- Áî®Êà∑Âêç: admin\n- ÂØÜÁ†Å: SQLBot@123456\n\n### ËÅîÁ≥ªÊàë‰ª¨\n\nÂ¶Ç‰Ω†ÊúâÊõ¥Â§öÈóÆÈ¢òÔºåÂèØ‰ª•Âä†ÂÖ•Êàë‰ª¨ÁöÑÊäÄÊúØ‰∫§ÊµÅÁæ§‰∏éÊàë‰ª¨‰∫§ÊµÅ„ÄÇ\n\n<img width=\"180\" height=\"180\" alt=\"contact_me_qr\" src=\"https://github.com/user-attachments/assets/2594ff29-5426-4457-b051-279855610030\" />\n\n## UI Â±ïÁ§∫\n\n  <tr>\n    <img alt=\"q&a\" src=\"https://github.com/user-attachments/assets/55526514-52f3-4cfe-98ec-08a986259280\"   />\n  </tr>\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=dataease/sqlbot&type=Date)](https://www.star-history.com/#dataease/sqlbot&Date)\n\n## È£ûËá¥‰∫ëÊóó‰∏ãÁöÑÂÖ∂‰ªñÊòéÊòüÈ°πÁõÆ\n\n- [DataEase](https://github.com/dataease/dataease/) - ‰∫∫‰∫∫ÂèØÁî®ÁöÑÂºÄÊ∫ê BI Â∑•ÂÖ∑\n- [1Panel](https://github.com/1panel-dev/1panel/) - Áé∞‰ª£Âåñ„ÄÅÂºÄÊ∫êÁöÑ Linux ÊúçÂä°Âô®ËøêÁª¥ÁÆ°ÁêÜÈù¢Êùø\n- [MaxKB](https://github.com/1panel-dev/MaxKB/) - Âº∫Â§ßÊòìÁî®ÁöÑ‰ºÅ‰∏öÁ∫ßÊô∫ËÉΩ‰ΩìÂπ≥Âè∞\n- [JumpServer](https://github.com/jumpserver/jumpserver/) - ÂπøÂèóÊ¨¢ËøéÁöÑÂºÄÊ∫êÂ†°ÂûíÊú∫\n- [Cordys CRM](https://github.com/1Panel-dev/CordysCRM) - Êñ∞‰∏Ä‰ª£ÁöÑÂºÄÊ∫ê AI CRM Á≥ªÁªü\n- [Halo](https://github.com/halo-dev/halo/) - Âº∫Â§ßÊòìÁî®ÁöÑÂºÄÊ∫êÂª∫Á´ôÂ∑•ÂÖ∑\n- [MeterSphere](https://github.com/metersphere/metersphere/) - Êñ∞‰∏Ä‰ª£ÁöÑÂºÄÊ∫êÊåÅÁª≠ÊµãËØïÂ∑•ÂÖ∑\n\n## License\n\nÊú¨‰ªìÂ∫ìÈÅµÂæ™ [FIT2CLOUD Open Source License](LICENSE) ÂºÄÊ∫êÂçèËÆÆÔºåËØ•ËÆ∏ÂèØËØÅÊú¨Ë¥®‰∏äÊòØ GPLv3Ôºå‰ΩÜÊúâ‰∏Ä‰∫õÈ¢ùÂ§ñÁöÑÈôêÂà∂„ÄÇ\n\n‰Ω†ÂèØ‰ª•Âü∫‰∫é SQLBot ÁöÑÊ∫ê‰ª£Á†ÅËøõË°å‰∫åÊ¨°ÂºÄÂèëÔºå‰ΩÜÊòØÈúÄË¶ÅÈÅµÂÆà‰ª•‰∏ãËßÑÂÆöÔºö\n\n- ‰∏çËÉΩÊõøÊç¢Âíå‰øÆÊîπ SQLBot ÁöÑ Logo ÂíåÁâàÊùÉ‰ø°ÊÅØÔºõ\n- ‰∫åÊ¨°ÂºÄÂèëÂêéÁöÑË°çÁîü‰ΩúÂìÅÂøÖÈ°ªÈÅµÂÆà GPL V3 ÁöÑÂºÄÊ∫ê‰πâÂä°„ÄÇ\n\nÂ¶ÇÈúÄÂïÜ‰∏öÊéàÊùÉÔºåËØ∑ËÅîÁ≥ª support@fit2cloud.com „ÄÇ\n",
      "stars_today": 10
    },
    {
      "id": 407972408,
      "name": "Kvaesitso",
      "full_name": "MM2-0/Kvaesitso",
      "description": "A search-focused Android launcher",
      "html_url": "https://github.com/MM2-0/Kvaesitso",
      "stars": 4179,
      "forks": 184,
      "language": "Kotlin",
      "topics": [
        "android",
        "jetpack-compose",
        "kotlin",
        "launcher"
      ],
      "created_at": "2021-09-18T21:35:28Z",
      "updated_at": "2026-01-23T00:36:54Z",
      "pushed_at": "2026-01-22T23:20:43Z",
      "open_issues": 645,
      "owner": {
        "login": "MM2-0",
        "avatar_url": "https://avatars.githubusercontent.com/u/15646950?v=4"
      },
      "readme": "# Kvaesitso\n\n<img src=\"https://raw.githubusercontent.com/MM2-0/Kvaesitso/main/assets/icons/ic_launcher.png\" width=\"128\">\n\nKvaesitso is a search focused, free and open source launcher for Android.\n\n[Website and documentation](https://kvaesitso.mm20.de)\n\n## Installation\n\n### Using an F-Droid client and MM20's repo\n\nThe preferred way of installation is using the [F-Droid](https://f-droid.org) application. That way\nyou will always be notified about updates. Kvaesitso is available in the official F-Droid\nrepository, but all features depending on non-foss external APIs were removed.\nFor feature-complete builds you can add [MM20's repository](https://fdroid.mm20.de). Just scan the code below or open\nthe link on your phone:\n\n<img src=\"https://fdroid.mm20.de/repo/index.png\" width=\"150\" alt=\"QR code\">\n\nhttps://fdroid.mm20.de/repo/\n\nThe same version is also available in [IzzyOnDroid's repository](https://apt.izzysoft.de/fdroid/index/apk/de.mm20.launcher2.release).\n\n### Manual installation\n\nYou can also download the latest release from\nthe [releases page](https://github.com/MM2-0/Kvaesitso/releases/latest) and install it manually.\n\n## Report issues\n\nIf you notice any bugs or issues create a new issue in\nthe [issue tracker](https://github.com/MM2-0/Kvaesitso/issues). Before you do, please search the\nexisting issues for any similar issues. Please include any relevant information such as steps to\nreproduce, stack traces, logs, and device information. These information can be founder under\nSettings > Debug > Crash reporter and Settings > Debug > Export debug information.\n\n## Feature requests\n\nIf you have an idea for a new feature, just create a new issue. However, there is no guarantee that\nthey will be implemented. If it's important for you, consider implementing it yourself,\nsee [contribute](#contribute).\n\n\n## Contribute\n\nContributions are always welcome. If you want to fix any existing issues or implement smaller new\nfeatures just create a new pull request. If you plan to implement any (bigger) new features, please\ncreate an issue first so we can discuss if and how this feature should be implemented.\n\nIf you want to help translating, see [how to translate the project.](https://kvaesitso.mm20.de/docs/contributor-guide/i18n)\n\n<a href=\"https://i18n.mm20.de/engage/kvaesitso/\">\n<img src=\"https://i18n.mm20.de/widgets/kvaesitso/-/287x66-grey.png\" alt =\"Translation Status\">\n</a>\n\n## Links\n\n- User guide: https://kvaesitso.mm20.de/docs/user-guide\n- F-Droid-Repository: https://fdroid.mm20.de\n\n## Thanks to\n\n- [@EliotAku](https://github.com/EliotAku) for the app icon\n- All [translators and code contributors](https://github.com/MM2-0/Kvaesitso/graphs/contributors)\n\n## License\n\nThis software is free software licensed under the GNU General Public License 3.0.\n\n```\n\nCopyright (C) 2021‚Äì2025 MM2-0 and the Kvaesitso contributors\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <https://www.gnu.org/licenses/>.\n```\n\nThe plugin SDK modules (`plugins/sdk` and `core/shared`) are licensed under the Apache License 2.0.\n",
      "stars_today": 10
    },
    {
      "id": 67962648,
      "name": "vuetify",
      "full_name": "vuetifyjs/vuetify",
      "description": "üêâ Vue Component Framework",
      "html_url": "https://github.com/vuetifyjs/vuetify",
      "stars": 40911,
      "forks": 7145,
      "language": "TypeScript",
      "topics": [
        "javascript",
        "material",
        "material-components",
        "material-design",
        "material-theme",
        "semantic",
        "typescript",
        "ui",
        "ui-components",
        "ui-design",
        "ui-kit",
        "ui-library",
        "vue",
        "vue-components",
        "vue-material",
        "vuejs",
        "vuejs3",
        "vuetify",
        "vuetifyjs"
      ],
      "created_at": "2016-09-12T00:39:35Z",
      "updated_at": "2026-01-22T23:04:48Z",
      "pushed_at": "2026-01-23T01:24:26Z",
      "open_issues": 667,
      "owner": {
        "login": "vuetifyjs",
        "avatar_url": "https://avatars.githubusercontent.com/u/22138497?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://vuetifyjs.com\" target=\"_blank\">\n    <img alt=\"Vuetify Logo\" width=\"100\" src=\"https://cdn.vuetifyjs.com/images/logos/logo.svg\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/vuetify\">\n    <img src=\"https://img.shields.io/npm/dt/vuetify.svg\" alt=\"Downloads\">\n  </a>\n  <a href=\"https://www.npmjs.com/package/vuetify\">\n    <img src=\"https://img.shields.io/npm/dm/vuetify.svg\" alt=\"Downloads\">\n  </a>\n  <br>\n  <a href=\"https://github.com/vuetifyjs/vuetify/blob/master/LICENSE.md\">\n    <img src=\"https://img.shields.io/npm/l/vuetify.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://community.vuetifyjs.com\">\n    <img src=\"https://discordapp.com/api/guilds/340160225338195969/widget.png\" alt=\"Chat\">\n  </a>\n  <br>\n  <a href=\"https://www.npmjs.com/package/vuetify\">\n    <img src=\"https://img.shields.io/npm/v/vuetify.svg\" alt=\"Version\">\n  </a>\n  <a href=\"https://cdnjs.com/libraries/vuetify\">\n    <img src=\"https://img.shields.io/cdnjs/v/vuetify.svg\" alt=\"CDN\">\n  </a>\n</p>\n\n### üñ•Ô∏è Documentation\n\nTo check out the documentation, visit [vuetifyjs.com](https://vuetifyjs.com).\n\n![Crowdin Uploads](https://github.com/vuetifyjs/vuetify/workflows/Crowdin%20Uploads/badge.svg?branch=master)\n\n### ‚ö° Quick Start\n\nGetting started with Vuetify is easy. To create a new project, choose your package manager and run one of the following commands:\n\nUsing [pnpm](https://pnpm.io/)\n\n```bash\npnpm create vuetify\n```\n\nUsing [yarn](https://yarnpkg.com/)\n\n```bash\nyarn create vuetify\n```\n\nUsing [npm](https://npmjs.com/)\n\n```bash\nnpm create vuetify@latest\n```\n\nUsing [bun](https://bun.sh/)\n\n```bash\nbun create vuetify\n```\n\nFor more information on how to get started, such as using Nuxt or Laravel, check out the official [Installation guide](https://vuetifyjs.com/getting-started/installation/).\n\n### üíñ Supporting Vuetify\n\nVuetify is a [MIT licensed](http://opensource.org/licenses/MIT) project that is developed and maintained by the [Core Team](https://vuetifyjs.com/about/meet-the-team/). Sponsor Vuetify and receive some **awesome perks** and support Open Source Software at the same time! üéâ\n\n<ul>\n  <li>\n    <a href=\"https://github.com/users/johnleider/sponsorship\">Become a backer or sponsor on GitHub</a>\n  </li>\n  <li>\n    <a href=\"https://opencollective.com/vuetify\">Become a backer or sponsor on Open Collective</a>\n    <strong><small>(supports the Core team)</small></strong>\n  </li>\n  <li>\n    <a href=\"https://tidelift.com/subscription/request-a-demo?utm_source=npm-vuetify&utm_medium=referral&utm_campaign=enterprise\">Become a subscriber on Tidelift</a>\n  </li>\n  <li>\n    <a href=\"https://paypal.me/vuetify\">Make a one-time payment with Paypal</a>\n  </li>\n</ul>\n\n### What's the difference between GitHub Sponsors and OpenCollective?\n\nFunds donated through GitHub Sponsors directly support [John Leider](https://github.com/sponsors/johnleider) and the ongoing development and maintenance of Vuetify. Funds donated via Open Collective are managed with transparent expenses and will be used for compensating work and expenses for Core team members. Your name/logo will receive proper recognition and exposure by donating on either platform.\n\n<h3><b>Special Sponsor</b></h3>\n\n<table>\n  <tbody>\n    <tr>\n      <td>\n        <a href=\"https://www.deepcloud.swiss/\" target=\"_blank\">\n          <img height=\"65px\" src=\"https://cdn.cosmicjs.com/20504e40-6cbc-11ef-b5ae-a594bb4a8e67-deepcloud-light.svg\">\n        </a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<h3><b>Diamond Sponsors</b></h3>\n\n<table>\n  <tbody>\n    <tr>\n      <td>\n        <a href=\"https://route4me.com/\">\n          <img height=\"40px\" src=\"https://cdn.cosmicjs.com/3b7a95b0-5360-11ef-b1ea-f56c65dfade9-route-4-me-light.png\">\n        </a>\n      </td>\n      <td>\n        <a href=\"https://www.abacus.ch/\">\n          <img height=\"40px\" src=\"https://cdn.cosmicjs.com/0b978be0-6cbb-11ef-b5ae-a594bb4a8e67-abacus-light.svg\">\n        </a>\n      </td>\n      <td>\n        <a href=\"https://www.hoop.swiss/\">\n          <img height=\"40px\" src=\"https://cdn.cosmicjs.com/94012850-6cbc-11ef-b5ae-a594bb4a8e67-hoop-light.svg\">\n        </a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<h3><b>Platinum Sponsors</b></h3>\n\n<table>\n  <tbody>\n    <tr>\n      <td style=\"text-align: center;\">\n        <a href=\"https://www.muenchen.de/\">\n          <img height=\"30px\" src=\"https://imgix.cosmicjs.com/af2ce530-eaa2-11ed-ba82-019c4666da06-itm-logo.png\">\n        </a>\n      </td>\n      <td>\n        <a href=\"https://views4you.com/buy-instagram-followers/\">\n          <img height=\"30px\" src=\"https://cdn.cosmicjs.com/861b0ce0-50e4-11ef-b1ea-f56c65dfade9-views-4-you-light.png\">\n        </a>\n      </td>\n      <td>\n        <a href=\"https://word.tips/\">\n          <img height=\"30px\" src=\"https://cdn.cosmicjs.com/5b16bd20-afab-11ef-bee4-3bb1d3c55332-wordtips-light.svg\">\n        </a>\n      </td>\n    </tr>\n    <tr></tr>\n    <tr>\n      <td>\n        <a href=\"https://www.vso.org.uk/\">\n          <img height=\"30px\" src=\"https://cdn.cosmicjs.com/64287760-e7c2-11ef-b333-e101bec29f3d-horizontal_logo.svg\">\n        </a>\n      </td>\n      </td>\n      <td style=\"text-align: center;\">\n        <a href=\"https://haircenterofturkey.com/\">\n          <img height=\"30px\" src=\"https://cdn.cosmicjs.com/ba1af160-1a27-11f0-a229-dfe84053cfeb-hcof-logo-light-1.png\">\n        </a>\n      </td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n\n---\n\n### üöÄ Introduction\n\nVuetify is a no design skills required UI Library with beautifully handcrafted Vue Components. No design skills required ‚Äî everything you need to create amazing applications is at your fingertips. Vuetify has a massive API that supports any use-case. Some highlights include:\n\n- **Customizable:** Extensive customization options with [SASS/SCSS](https://vuetifyjs.com/features/sass-variables/) and [Default configuration](https://vuetifyjs.com/features/presets/) and [Blueprints](https://vuetifyjs.com/features/blueprints/)\n- **Responsive Layout:** The default configuration of Vuetify components is responsive, allowing your application to adapt to different screen sizes.\n- **Theme System:** A powerful color system that makes it easy to style your application with a consistent color palette.\n- **Vite Support:** _Smaller_ bundle sizes with **automatic** tree-shaking\n- **6 months** Long-term support for [Major releases](https://vuetifyjs.com/introduction/long-term-support/)\n- **Internationalization:** 42+ supported languages\n\n#### Browser Support\n\nVuetify supports all **modern browsers**, including Safari 13+ (using [polyfills](https://vuetifyjs.com/getting-started/browser-support)). Components are designed for a minimum width of _320px_.\n\n### üåé Vuetify Ecosystem\n\n#### Resources\n\n<table>\n  <thead>\n    <tr>\n      <th>Name</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>\n        <a href=\"https://github.com/vuetifyjs/awesome/\">\n          üï∂Ô∏è&nbsp;Vuetify&nbsp;Awesome\n        </a>\n      </td>\n      <td>Awesome stuff built with Vuetify.</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://bin.vuetifyjs.com/\">\n          üóëÔ∏è&nbsp;Vuetify&nbsp;Bin\n        </a>\n      </td>\n      <td>A pastebin for saving code snippets.</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://bin.vuetifyjs.com/\">\n          ü´ß&nbsp;Vuetify&nbsp;Create\n        </a>\n      </td>\n      <td>Scaffolding tools for creating new Vuetify projects.</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://community.vuetifyjs.com/\">\n          üí≠&nbsp;Vuetify&nbsp;Discord\n        </a>\n      </td>\n      <td>Our massive and inclusive Discord server where you can ask questions, share feedback, and connect with other Vuetify developers.</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/vuetifyjs/eslint-config-vuetify\">\n          üßπ&nbsp;Vuetify&nbsp;ESLint\n        </a>\n      </td>\n      <td>An opinionated [ESLint config](https://github.com/vuetifyjs/eslint-config-vuetify) for styling and an [ESLint plugin](https://github.com/vuetifyjs/eslint-plugin-vuetify) for upgrading Vuetify version.</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://issues.vuetifyjs.com/\">\n          üêõ&nbsp;Vuetify&nbsp;Issues\n        </a>\n      </td>\n      <td>A web application for reporting bugs and issues with Vuetify, Documentation, or one of our other packages.</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/vuetifyjs/vuetify-loader\">\n          üì¶&nbsp;Vuetify&nbsp;Loader\n        </a>\n      </td>\n      <td>A monorepo of compiler plugins for autoloading Vuetify components and configuring styles.</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://github.com/vuetifyjs/mcp/\">\n          üß†&nbsp;Vuetify&nbsp;MCP\n        </a>\n      </td>\n      <td>A Model Context Protocol server for developing with Vuetify and Agents.</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://play.vuetifyjs.com/\">\n          üéÆ&nbsp;Vuetify&nbsp;Playground\n        </a>\n      </td>\n      <td>A Vuetify 3 playground built using <a href=\"https://github.com/vuejs/repl\">vuejs/repl</a> where you can play with our components.</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://snips.vuetifyjs.com\">\n          ‚úÇÔ∏è&nbsp;Vuetify&nbsp;Snips\n        </a>\n      </td>\n      <td>Pre-built code snippets for Vuetify components that you can use in your projects</td>\n    </tr>\n    <tr>\n      <td>\n        <a href=\"https://store.vuetifyjs.com/\">\n          üõí&nbsp;Vuetify&nbsp;Store\n        </a>\n      </td>\n      <td>The official Vuetify Store where you can download free digital products, purchase pre-made themes, and more.</td>\n    </tr>\n  </tbody>\n</table>\n\n### üôã‚Äç‚ôÇÔ∏è Questions\n\nFor help and support questions, please use our [Discord community](https://community.vuetifyjs.com). This issue list of this repo is **exclusively** for bug reports and feature requests.\n\n### üêõ Issues\n\nUse our [Issue generator](https://issues.vuetifyjs.com) to report bugs and request new features.\n\nPlease make sure to read the [Important Information](https://github.com/vuetifyjs/vuetify/blob/master/.github/CONTRIBUTING.md#important-information) before opening an issue. Issues not confirming to the guidelines may be closed immediately.\n\n2Ô∏è‚É£ Vuetify 2 Support\nVuetify 2 is now End Of Life (EOL) and is no longer supported, even for security issues. Commercial support for this version is available from our partner, [HeroDevs](https://www.herodevs.com/support/vuetify-nes?utm_source=partnership&utm_medium=partnership&utm_campaign=partnership&utm_id=vuetify2).\n\n### üìù Changelog\n\nDetailed changes for each release are documented in the [release notes](https://vuetifyjs.com/getting-started/release-notes/).\n\n### üíÅ‚Äç‚ôÇÔ∏è Contributing\n\nDevelopers interested in contributing should read the [Code of Conduct](./CODE_OF_CONDUCT.md) and the [Contribution Guide](https://vuetifyjs.com/getting-started/contributing/).\n\n> Please do **not** ask general questions in an issue. Issues are only to report bugs, suggest\n  enhancements, or request new features. For general questions and discussions, ask in the [community chat](https://community.vuetifyjs.com/).\n\nTo help you get you familiar with our contribution process, we have a list of [good first issues](https://github.com/vuetifyjs/vuetify/labels/good%20first%20issue) that contain bugs which have a relatively limited scope. This is a great place to get started. If you have any questions, please join us on the [community chat](https://community.vuetifyjs.com).\n\nWe also have a list of [help wanted](https://github.com/vuetifyjs/vuetify/labels/help%20wanted) issues that you might want to check.\n\n### üìë License\n\nVuetify is available under the [MIT](http://opensource.org/licenses/MIT) software license.\n\nCopyright (c) 2016-present Vuetify, LLC\n\n---\n\nThis project exists thanks to all the people who contribute üòç!\n\n<a href=\"https://github.com/vuetifyjs/vuetify/graphs/contributors\"><img src=\"https://opencollective.com/vuetify/contributors.svg?width=890&button=false\" /></a>\n",
      "stars_today": 9
    },
    {
      "id": 40556106,
      "name": "wazuh",
      "full_name": "wazuh/wazuh",
      "description": "Wazuh - The Open Source Security Platform. Unified XDR and SIEM protection for endpoints and cloud workloads.",
      "html_url": "https://github.com/wazuh/wazuh",
      "stars": 14533,
      "forks": 2124,
      "language": "C",
      "topics": [
        "cloud-security",
        "compliance",
        "configuration-assessement",
        "container-security",
        "cybersecurity",
        "file-integrity-monitoring",
        "incident-response",
        "infosec",
        "log-analysis",
        "malware-detection",
        "pci-dss",
        "security",
        "security-audit",
        "security-automation",
        "security-hardening",
        "security-tools",
        "siem",
        "vulnerability-detection",
        "wazuh",
        "xdr"
      ],
      "created_at": "2015-08-11T17:39:03Z",
      "updated_at": "2026-01-22T21:50:01Z",
      "pushed_at": "2026-01-23T02:06:44Z",
      "open_issues": 2802,
      "owner": {
        "login": "wazuh",
        "avatar_url": "https://avatars.githubusercontent.com/u/13752566?v=4"
      },
      "readme": "# Wazuh\n\n[![Slack](https://img.shields.io/badge/slack-join-blue.svg)](https://wazuh.com/community/join-us-on-slack/)\n[![Email](https://img.shields.io/badge/email-join-blue.svg)](https://groups.google.com/forum/#!forum/wazuh)\n[![Documentation](https://img.shields.io/badge/docs-view-green.svg)](https://documentation.wazuh.com)\n[![Documentation](https://img.shields.io/badge/web-view-green.svg)](https://wazuh.com)\n[![Coverity](https://scan.coverity.com/projects/10992/badge.svg)](https://scan.coverity.com/projects/wazuh-wazuh)\n[![Twitter](https://img.shields.io/twitter/follow/wazuh?style=social)](https://twitter.com/wazuh)\n[![YouTube](https://img.shields.io/youtube/views/peTSzcAueEc?style=social)](https://www.youtube.com/watch?v=peTSzcAueEc)\n\n\nWazuh is a free and open source platform used for threat prevention, detection, and response. It is capable of protecting workloads across on-premises, virtualized, containerized, and cloud-based environments.\n\nWazuh solution consists of an endpoint security agent, deployed to the monitored systems, and a management server, which collects and analyzes data gathered by the agents. Besides, Wazuh has been fully integrated with the Elastic Stack, providing a search engine and data visualization tool that allows users to navigate through their security alerts.\n\n## Wazuh capabilities\n\nA brief presentation of some of the more common use cases of the Wazuh solution.\n\n**Intrusion detection**\n\nWazuh agents scan the monitored systems looking for malware, rootkits and suspicious anomalies. They can detect hidden files, cloaked processes or unregistered network listeners, as well as inconsistencies in system call responses.\n\nIn addition to agent capabilities, the server component uses a signature-based approach to intrusion detection, using its regular expression engine to analyze collected log data and look for indicators of compromise.\n\n**Log data analysis**\n\nWazuh agents read operating system and application logs, and securely forward them to a central manager for rule-based analysis and storage. When no agent is deployed, the server can also receive data via syslog from network devices or applications.\n\nThe Wazuh rules help make you aware of application or system errors, misconfigurations, attempted and/or successful malicious activities, policy violations and a variety of other security and operational issues.\n\n**File integrity monitoring**\n\nWazuh monitors the file system, identifying changes in content, permissions, ownership, and attributes of files that you need to keep an eye on. In addition, it natively identifies users and applications used to create or modify files.\n\nFile integrity monitoring capabilities can be used in combination with threat intelligence to identify threats or compromised hosts. In addition, several regulatory compliance standards, such as PCI DSS, require it.\n\n**Vulnerability detection**\n\nWazuh agents pull software inventory data and send this information to the server, where it is correlated with continuously updated CVE (Common Vulnerabilities and Exposure) databases, in order to identify well-known vulnerable software.\n\nAutomated vulnerability assessment helps you find the weak spots in your critical assets and take corrective action before attackers exploit them to sabotage your business or steal confidential data.\n\n**Configuration assessment**\n\nWazuh monitors system and application configuration settings to ensure they are compliant with your security policies, standards and/or hardening guides. Agents perform periodic scans to detect applications that are known to be vulnerable, unpatched, or insecurely configured.\n\nAdditionally, configuration checks can be customized, tailoring them to properly align with your organization. Alerts include recommendations for better configuration, references and mapping with regulatory compliance.\n\n**Incident response**\n\nWazuh provides out-of-the-box active responses to perform various countermeasures to address active threats, such as blocking access to a system from the threat source when certain criteria are met.\n\nIn addition, Wazuh can be used to remotely run commands or system queries, identifying indicators of compromise (IOCs) and helping perform other live forensics or incident response tasks.\n\n**Regulatory compliance**\n\nWazuh provides some of the necessary security controls to become compliant with industry standards and regulations. These features, combined with its scalability and multi-platform support help organizations meet technical compliance requirements.\n\nWazuh is widely used by payment processing companies and financial institutions to meet PCI DSS (Payment Card Industry Data Security Standard) requirements. Its web user interface provides reports and dashboards that can help with this and other regulations (e.g. GPG13 or GDPR).\n\n**Cloud security**\n\nWazuh helps monitoring cloud infrastructure at an API level, using integration modules that are able to pull security data from well known cloud providers, such as Amazon AWS, Azure or Google Cloud. In addition, Wazuh provides rules to assess the configuration of your cloud environment, easily spotting weaknesses.\n\nIn addition, Wazuh light-weight and multi-platform agents are commonly used to monitor cloud environments at the instance level.\n\n**Containers security**\n\nWazuh provides security visibility into your Docker hosts and containers, monitoring their behavior and detecting threats, vulnerabilities and anomalies. The Wazuh agent has native integration with the Docker engine allowing users to monitor images, volumes, network settings, and running containers.\n\nWazuh continuously collects and analyzes detailed runtime information. For example, alerting for containers running in privileged mode, vulnerable applications, a shell running in a container, changes to persistent volumes or images, and other possible threats.\n\n## WUI\n\nThe Wazuh WUI provides a powerful user interface for data visualization and analysis. This interface can also be used to manage Wazuh configuration and to monitor its status.\n\n**Modules overview**\n\n![Modules overview](https://github.com/wazuh/wazuh-dashboard-plugins/raw/main/screenshots/app.png)\n\n**Security events**\n\n![Overview](https://github.com/wazuh/wazuh-dashboard-plugins/blob/main/screenshots/app2.png)\n\n**Integrity monitoring**\n\n![Overview](https://github.com/wazuh/wazuh-dashboard-plugins/blob/main/screenshots/app3.png)\n\n**Vulnerability detection**\n\n![Overview](https://github.com/wazuh/wazuh-dashboard-plugins/blob/main/screenshots/app4.png)\n\n**Regulatory compliance**\n\n![Overview](https://github.com/wazuh/wazuh-dashboard-plugins/blob/main/screenshots/app5.png)\n\n**Agents overview**\n\n![Overview](https://github.com/wazuh/wazuh-dashboard-plugins/blob/main/screenshots/app6.png)\n\n**Agent summary**\n\n![Overview](https://github.com/wazuh/wazuh-dashboard-plugins/blob/main/screenshots/app7.png)\n\n## Orchestration\n\nHere you can find all the automation tools maintained by the Wazuh team.\n\n* [Wazuh AWS CloudFormation](https://github.com/wazuh/wazuh-cloudformation)\n\n* [Docker containers](https://github.com/wazuh/wazuh-docker)\n\n* [Wazuh Ansible](https://github.com/wazuh/wazuh-ansible)\n\n* [Wazuh Chef](https://github.com/wazuh/wazuh-chef)\n\n* [Wazuh Puppet](https://github.com/wazuh/wazuh-puppet)\n\n* [Wazuh Kubernetes](https://github.com/wazuh/wazuh-kubernetes)\n\n* [Wazuh Bosh](https://github.com/wazuh/wazuh-bosh)\n\n* [Wazuh Salt](https://github.com/wazuh/wazuh-salt)\n\n## Branches\n\n* `main` branch contains the latest code, be aware of possible bugs on this branch.\n\n## Software and libraries used\n\n|Software|Version|Author|License|\n|---|---|---|---|\n|[bpftool](https://github.com/libbpf/bpftool)|7.5.0|libbpf|GNU Public License version 2|\n|[bzip2](https://github.com/libarchive/bzip2)|1.0.8|Julian Seward|BSD License|\n|[cJSON](https://github.com/DaveGamble/cJSON)|1.7.18|Dave Gamble|MIT License|\n|[cpp-httplib](https://github.com/yhirose/cpp-httplib)|0.25.0|yhirose|MIT License|\n|[cPython](https://github.com/python/cpython)|3.10.19|Guido van Rossum|Python Software Foundation License version 2|\n|[cURL](https://github.com/curl/curl)|8.12.1|Daniel Stenberg|MIT License|\n|[dbus](https://gitlab.freedesktop.org/dbus/dbus)|1.14.10|freedesktop.org|GNU Public License version 2|\n|[Flatbuffers](https://github.com/google/flatbuffers/)|23.5.26|Google Inc.|Apache 2.0 License|\n|[Google Benchmark](https://github.com/google/benchmark)|1.6.1|Google Inc.|Apache 2.0 License||\n|[GoogleTest](https://github.com/google/googletest)|1.11.0|Google Inc.|3-Clause \"New\" BSD License|\n|[jemalloc](https://github.com/jemalloc/jemalloc)|5.2.1|Jason Evans|2-Clause \"Simplified\" BSD License|\n|[libarchive](https://github.com/libarchive/libarchive)|3.8.1|Tim Kientzle|3-Clause \"New\" BSD License|\n|[libbpf](https://github.com/libbpf/libbpf)|1.5.0|libbpf|GNU Lesser General Public License version 2.1|\n|[libdb](https://github.com/yasuhirokimura/db18)|18.1.40|Oracle Corporation|Affero GPL v3|\n|[libffi](https://github.com/libffi/libffi)|3.2.1|Anthony Green|MIT License|\n|[libpcre2](https://github.com/PCRE2Project/pcre2)|10.42.0|Philip Hazel|BSD License|\n|[libplist](https://github.com/libimobiledevice/libplist)|2.2.0|Aaron Burghardt et al.|GNU Lesser General Public License version 2.1|\n|[libYAML](https://github.com/yaml/libyaml)|0.1.7|Kirill Simonov|MIT License|\n|[liblzma](https://github.com/tukaani-project/xz)|5.4.2|Lasse Collin, Jia Tan et al.|GNU Public License version 3|\n|[Linux Audit userspace](https://github.com/linux-audit/audit-userspace)|2.8.4|Rik Faith|GNU Lesser General Public License|\n|[Lua](https://github.com/lua/lua)|5.4.8|PUC-Rio|MIT License|\n|[msgpack](https://github.com/msgpack/msgpack-c)|3.1.1|Sadayuki Furuhashi|Boost Software License version 1.0|\n|[nlohmann](https://github.com/nlohmann/json)|3.11.2|Niels Lohmann|MIT License|\n|[OpenSSL](https://github.com/openssl/openssl)|3.5.1|OpenSSL Software Foundation|Apache 2.0 License|\n|[pacman](https://gitlab.archlinux.org/pacman/pacman)|5.2.2|Judd Vinet|GNU Public License version 2|\n|[popt](https://github.com/rpm-software-management/popt)|1.16|Jeff Johnson & Erik Troan|MIT License|\n|[procps](https://gitlab.com/procps-ng/procps)|2.8.3|Brian Edmonds et al.|GNU Lesser General Public License|\n|[RocksDB](https://github.com/facebook/rocksdb/)|8.3.2|Facebook Inc.|Apache 2.0 License|\n|[rpm](https://github.com/rpm-software-management/rpm)|4.20.1|Marc Ewing & Erik Troan|GNU Public License version 2|\n|[simdjson](https://github.com/simdjson/simdjson)|3.13.0|Daniel Lemire|Apache License 2.0|\n|[sqlite](https://github.com/sqlite/sqlite)|3.50.4|D. Richard Hipp|Public Domain (no restrictions)|\n|[zlib](https://github.com/madler/zlib)|1.3.1|Jean-loup Gailly & Mark Adler|zlib/libpng License|\n\n* [PyPi packages](framework/requirements.txt)\n\n## Documentation\n\n* [Full documentation](http://documentation.wazuh.com)\n* [Wazuh installation guide](https://documentation.wazuh.com/current/installation-guide/index.html)\n\n## Get involved\n\nBecome part of the [Wazuh's community](https://wazuh.com/community/) to learn from other users, participate in discussions, talk to our developers and contribute to the project.\n\nIf you want to contribute to our project please don‚Äôt hesitate to make pull-requests, submit issues or send commits, we will review all your questions.\n\nYou can also join our [Slack community channel](https://wazuh.com/community/join-us-on-slack/) and [mailing list](https://groups.google.com/d/forum/wazuh) by sending an email to [wazuh+subscribe@googlegroups.com](mailto:wazuh+subscribe@googlegroups.com), to ask questions and participate in discussions.\n\nStay up to date on news, releases, engineering articles and more.\n\n* [Wazuh website](http://wazuh.com)\n* [Linkedin](https://www.linkedin.com/company/wazuh)\n* [YouTube](https://www.youtube.com/c/wazuhsecurity)\n* [Twitter](https://twitter.com/wazuh)\n* [Wazuh blog](https://wazuh.com/blog/)\n* [Slack announcements channel](https://wazuh.com/community/join-us-on-slack/)\n\n## Authors\n\nWazuh Copyright (C) 2015-2023 Wazuh Inc. (License GPLv2)\n\nBased on the OSSEC project started by Daniel Cid.\n",
      "stars_today": 9
    },
    {
      "id": 118654121,
      "name": "skaffold",
      "full_name": "GoogleContainerTools/skaffold",
      "description": "Easy and Repeatable Kubernetes Development",
      "html_url": "https://github.com/GoogleContainerTools/skaffold",
      "stars": 15717,
      "forks": 1691,
      "language": "Go",
      "topics": [
        "containers",
        "developer-tools",
        "docker",
        "kubernetes"
      ],
      "created_at": "2018-01-23T18:51:29Z",
      "updated_at": "2026-01-22T23:47:29Z",
      "pushed_at": "2026-01-22T20:54:43Z",
      "open_issues": 866,
      "owner": {
        "login": "GoogleContainerTools",
        "avatar_url": "https://avatars.githubusercontent.com/u/38444003?v=4"
      },
      "readme": "<!-- github does not support `width` with markdown images-->\n<img src=\"logo/skaffold.png\" width=\"220\">\n\n---------------------\n\n[![Code Coverage](https://codecov.io/gh/GoogleContainerTools/skaffold/branch/main/graph/badge.svg)](https://codecov.io/gh/GoogleContainerTools/skaffold)\n[![LICENSE](https://img.shields.io/github/license/GoogleContainerTools/skaffold.svg)](https://github.com/GoogleContainerTools/skaffold/blob/main/LICENSE)\n[![Releases](https://img.shields.io/github/release-pre/GoogleContainerTools/skaffold.svg)](https://github.com/GoogleContainerTools/skaffold/releases)\n\nSkaffold is a command line tool that facilitates continuous development for\nKubernetes applications. You can iterate on your application source code\nlocally then deploy to local or remote Kubernetes clusters. Skaffold handles\nthe workflow for building, pushing and deploying your application. It also\nprovides building blocks and describe customizations for a CI/CD pipeline.\n\n---------------------\n\n## [Install Skaffold](https://skaffold.dev/docs/install/)\n\nOr, check out our [Github Releases](https://github.com/GoogleContainerTools/skaffold/releases) page for release info or to install a specific version.\n\n![Demo](docs/static/images/intro.gif)\n\n## Features\n\n* Blazing fast local development\n  * **optimized source-to-deploy** - Skaffold detects changes in your source code and handles the pipeline to\n  **build**, **push**, and **deploy** your application automatically with **policy based image tagging**\n  * **continuous feedback** - Skaffold automatically aggregates logs from deployed resources and forwards container ports to your local machine\n* Project portability\n  * **share with other developers** - Skaffold is the easiest way to **share your project** with the world: `git clone` and `skaffold run`\n  * **context aware** - use Skaffold profiles, user level config, environment variables and flags to describe differences in environments\n  * **CI/CD building blocks** - use `skaffold run` end-to-end, or use individual Skaffold phases to build up your CI/CD pipeline. `skaffold render` outputs hydrated Kubernetes manifests that can be used in GitOps workflows.\n* Pluggable, declarative configuration for your project\n  * **skaffold init** - Skaffold discovers your files and generates its own config file\n  * **multi-component apps** - Skaffold supports applications consisting of multiple components\n  * **bring your own tools** - Skaffold has a pluggable architecture to integrate with any build or deploy tool\n* Lightweight\n  * **client-side only** - Skaffold has no cluster-side component, so there is no overhead or maintenance burden\n  * **minimal pipeline** - Skaffold provides an opinionated, minimal pipeline to keep things simple\n\n### Check out our [examples page](./examples) for more complex workflows!\n\n## IDE integrations\n\nFor a managed experience of Skaffold you can install the Google `Cloud Code` extensions:\n- for [Visual Studio Code](https://cloud.google.com/code/docs/vscode/quickstart-k8s#installing)\n- for [JetBrains IDEs](https://cloud.google.com/code/docs/intellij/quickstart-k8s#installing_the_plugin). \n\nIt can manage and keep Skaffold  up-to-date while providing a more guided startup experience, along with providing and managing other common dependencies, and works with any kubernetes cluster. \n\n## Contributing to Skaffold\n\nWe welcome any contributions from the community with open arms - Skaffold wouldn't be where it is today without contributions from the community! Have a look at our [contribution guide](./CONTRIBUTING.md) for more information on how to get started on sending your first PR.\n\n## Community\n\n* [#skaffold on Kubernetes Slack](https://kubernetes.slack.com/messages/CABQMSZA6/)\n* [skaffold-users mailing list](https://groups.google.com/forum/#!forum/skaffold-users)\n\n## Support \n\nSkaffold is generally available and considered production ready.\nDetailed feature maturity information and how we deprecate features are described in our [Deprecation Policy](https://skaffold.dev/docs/references/deprecation).\n\n## Security Disclosures\n\nPlease see our [security disclosure process](SECURITY.md).  All [security advisories](https://github.com/GoogleContainerTools/skaffold/security/advisories) are managed on Github.\n",
      "stars_today": 9
    },
    {
      "id": 514553345,
      "name": "OrcaSlicer",
      "full_name": "OrcaSlicer/OrcaSlicer",
      "description": "G-code generator for 3D printers (Bambu, Prusa, Voron, VzBot, RatRig, Creality, etc.)",
      "html_url": "https://github.com/OrcaSlicer/OrcaSlicer",
      "stars": 12287,
      "forks": 1655,
      "language": "C++",
      "topics": [
        "3d-printer",
        "3d-printing",
        "makers",
        "orca",
        "orcaslicer",
        "slicer"
      ],
      "created_at": "2022-07-16T11:01:21Z",
      "updated_at": "2026-01-23T02:03:27Z",
      "pushed_at": "2026-01-22T17:57:35Z",
      "open_issues": 1648,
      "owner": {
        "login": "OrcaSlicer",
        "avatar_url": "https://avatars.githubusercontent.com/u/134699248?v=4"
      },
      "readme": "<div align=\"center\">\n\n<picture>\n  <img alt=\"OrcaSlicer logo\" src=\"resources/images/OrcaSlicer.png\" width=\"15%\" height=\"15%\">\n</picture>\n\n<a href=\"https://trendshift.io/repositories/952\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/952\" alt=\"SoftFever%2FOrcaSlicer | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n[![GitHub Repo stars](https://img.shields.io/github/stars/OrcaSlicer/OrcaSlicer)](https://github.com/OrcaSlicer/OrcaSlicer/stargazers) [![Build all](https://github.com/OrcaSlicer/OrcaSlicer/actions/workflows/build_all.yml/badge.svg?branch=main)](https://github.com/OrcaSlicer/OrcaSlicer/actions/workflows/build_all.yml)\n\nOrcaSlicer: an open source Next-Gen Slicing Software for Precision 3D Prints.  \nOptimize your prints with ultra-fast slicing, intelligent support generation, and seamless printer compatibility‚Äîengineered for perfection.\n<h3>\n\n# Official links and community\n\n#### Official Website:\n<a href=\"https://www.orcaslicer.com/\" style=\"font-size:2em;\">OrcaSlicer.com</a>\n\n#### Github Repository:\n<a href=\"https://github.com/OrcaSlicer/OrcaSlicer\"><img src=\"https://img.shields.io/badge/OrcaSlicer-181717?style=flat&logo=github&logoColor=white\" width=\"200\" alt=\"GitHub Logo\"/> </a>\n\n#### Follow us:\n<a href=\"https://twitter.com/real_OrcaSlicer\"><img src=\"https://img.shields.io/badge/real__OrcaSlicer-000000?style=flat&logo=x&logoColor=white\" width=\"200\" alt=\"X Logo\"/> </a>\n\n#### Join our Discord community:\n<a href=\"https://discord.gg/P4VE9UY9gJ\"><img src=\"https://img.shields.io/badge/-Discord-5865F2?style=flat&logo=discord&logoColor=fff\" width=\"200\" alt=\"discord logo\"/> </a>\n\n<table border=\"2\" style=\"border-color: #ffa500; background-color:rgb(232, 220, 180); color: #856404;\">\n<tr>\n<td>\n<strong>‚ö†Ô∏è CAUTION:</strong><br>\nSeveral clickbait and malicious websites, such as <b>orca-slicer[.]com</b> and <b>orcaslicer[.]net</b>, are pretending to be the official OrcaSlicer site. These sites may redirect you to dangerous downloads or contain misleading information.<br>\n<b>Our only official website is <a href=\"https://www.orcaslicer.com/\">www.orcaslicer.com</a>.</b><br><br>\nIf you come across any of these in search results, please <b>report them</b> as unsafe or phishing to help keep the community secure with:<br>\n - <a href=\"https://safebrowsing.google.com/safebrowsing/report_phish/\">Google Safe Browsing</a><br>\n - <a href=\"https://www.microsoft.com/en-us/wdsi/support/report-unsafe-site\">Microsoft Security Intelligence</a><br>\n - <a href=\"https://ipthreat.net/tools/reportphishing\">IPThreat</a>\n</td>\n</tr>\n</table>\n\n</div>\n\n# Main features\n\n- **[Advanced Calibration Tools](https://www.orcaslicer.com/wiki/Calibration)**  \n  Comprehensive suite: temperature towers, flow rate, retraction & more for optimal performance.\n- **[Precise Wall](https://www.orcaslicer.com/wiki/quality_settings_precision#precise-wall) and [Seam Control](https://www.orcaslicer.com/wiki/quality_settings_seam)**  \n  Adjust outer wall spacing and apply scarf seams to enhance print accuracy.\n- **[Sandwich Mode](https://www.orcaslicer.com/wiki/quality_settings_wall_and_surfaces#innerouterinner) and [Polyholes](https://www.orcaslicer.com/wiki/quality_settings_precision#polyholes) Support**  \n  Use varied infill [patterns](https://www.orcaslicer.com/wiki/strength_settings_patterns) and accurate hole shapes for improved clarity.\n- **[Overhang](https://www.orcaslicer.com/wiki/quality_settings_overhangs) and [Support Optimization](https://www.orcaslicer.com/wiki#support-settings)**  \n  Modify geometry for printable overhangs with precise support placement.\n- **[Granular Controls and Customization](https://www.orcaslicer.com/wiki#process-settings)**  \n  Fine-tune print speed, layer height, pressure, and temperature with precision.\n- **Network Printer Support**  \n  Seamless integration with Klipper, PrusaLink, and OctoPrint for remote control.\n- **[Mouse Ear Brims](https://www.orcaslicer.com/wiki/others_settings_brim) & [Adaptive Bed Mesh](https://www.orcaslicer.com/wiki/printer_basic_information_adaptive_bed_mesh)**  \n  Automatic brims and adaptive mesh calibration ensure consistent adhesion.\n- **User-Friendly Interface**  \n  Intuitive drag-and-drop design with pre-made profiles for popular printers.\n- **[Open-Source](https://github.com/OrcaSlicer/OrcaSlicer) & [Community Driven](https://discord.gg/P4VE9UY9gJ)**  \n  Regular updates fueled by continuous community contributions.\n- **Wide Printer Compatibility**  \n  Supports a broad range of printers: Bambu Lab, Prusa, Creality, Voron, and more.\n- Additional features can be found in the [change notes](https://github.com/OrcaSlicer/OrcaSlicer/releases/).\n\n# Wiki\n\nThe [wiki](https://www.orcaslicer.com/wiki) aims to provide a detailed explanation of the slicer settings, including how to maximize their use and how to calibrate and set up your printer.\n\n- **[Access the wiki here](https://www.orcaslicer.com/wiki)**\n- **[Contribute to the wiki](https://www.orcaslicer.com/wiki/How-to-wiki)**\n\n# Download\n\n## Stable Release\n\nüì• **[Download the Latest Stable Release](https://github.com/OrcaSlicer/OrcaSlicer/releases/latest)**  \nVisit our GitHub Releases page for the latest stable version of OrcaSlicer, recommended for most users.\n\n## Nightly Builds\n\nüåô **[Download the Latest Nightly Build](https://github.com/OrcaSlicer/OrcaSlicer/releases/tag/nightly-builds)**  \nExplore the latest developments in OrcaSlicer with our nightly builds. Feedback on these versions is highly appreciated.\n\n# How to install\n\n## Windows\n\nDownload the **Windows Installer exe**  for your preferred version from the [releases page](https://github.com/OrcaSlicer/OrcaSlicer/releases).\n\n - *For convenience there is also a portable build available.*\n    <details>\n    <summary>Troubleshooting</summary>\n\n    - *If you have troubles to run the build, you might need to install following runtimes:*\n    - [MicrosoftEdgeWebView2RuntimeInstallerX64](https://github.com/OrcaSlicer/OrcaSlicer/releases/download/v1.0.10-sf2/MicrosoftEdgeWebView2RuntimeInstallerX64.exe)\n        - [Details of this runtime](https://aka.ms/webview2)\n        - [Alternative Download Link Hosted by Microsoft](https://go.microsoft.com/fwlink/p/?LinkId=2124703)\n    - [vcredist2019_x64](https://github.com/OrcaSlicer/OrcaSlicer/releases/download/v1.0.10-sf2/vcredist2019_x64.exe)\n        -  [Alternative Download Link Hosted by Microsoft](https://aka.ms/vs/17/release/vc_redist.x64.exe)\n        -  This file may already be available on your computer if you've installed visual studio.  Check the following location: `%VCINSTALLDIR%Redist\\MSVC\\v142`\n    </details>\n\nWindows Package Manager\n\n```shell\nwinget install --id=SoftFever.OrcaSlicer -e\n```\n\n## Mac\n\n1. Download the DMG for your computer: `arm64` version for Apple Silicon and `x86_64` for Intel CPU.\n2. Drag OrcaSlicer.app to Application folder.\n3. *If you want to run a build from a PR, you also need to follow the instructions below:*\n\n    <details>\n    <summary>Quarantine</summary>\n\n    - Option 1 (You only need to do this once. After that the app can be opened normally.):\n      - Step 1: Hold _cmd_ and right click the app, from the context menu choose **Open**.\n      - Step 2: A warning window will pop up, click _Open_\n\n    - Option 2:\n      Execute this command in terminal:\n\n      ```shell\n      xattr -dr com.apple.quarantine /Applications/OrcaSlicer.app\n      ```\n\n    - Option 3:\n        - Step 1: open the app, a warning window will pop up  \n            ![mac_cant_open](./SoftFever_doc/mac_cant_open.png)\n        - Step 2: in `System Settings` -> `Privacy & Security`, click `Open Anyway`:  \n            ![mac_security_setting](./SoftFever_doc/mac_security_setting.png)\n    </details>\n\n## Linux (Ubuntu)\n\n 1. If you run into trouble executing it, try this command in the terminal:\n    `chmod +x /path_to_appimage/OrcaSlicer_Linux.AppImage`\n\n# How to Compile\n\nAll updated build instructions for Windows, macOS, and Linux are now available on the official [OrcaSlicer Wiki - How to build](https://www.orcaslicer.com/wiki/How-to-build) page.\n\nPlease refer to the wiki to ensure you're following the latest and most accurate steps for your platform.\n\n# Klipper Note\n\nIf you're running Klipper, it's recommended to add the following configuration to your `printer.cfg` file.\n\n```gcode\n# Enable object exclusion\n[exclude_object]\n\n# Enable arcs support\n[gcode_arcs]\nresolution: 0.1\n```\n\n# Supports\n\n**OrcaSlicer** is an open-source project and I'm deeply grateful to all my sponsors and backers.  \nTheir generous support enables me to purchase filaments and other essential 3D printing materials for the project.  \nThank you! :)\n\n## Sponsors:\n\n<table>\n<tr>\n<td>\n<a href=\"https://qidi3d.com/\" style=\"display:inline-block; border-radius:8px; background:#fff;\">\n  <img src=\"SoftFever_doc\\sponsor_logos\\QIDI.png\" alt=\"QIDI\" width=\"100\" height=\"100\">\n</a>\n</td>\n<td>\n<a href=\"https://bigtree-tech.com/\" style=\"display:inline-block; border-radius:8px; background:#222;\">\n    <img src=\"SoftFever_doc\\sponsor_logos\\BigTreeTech.png\" alt=\"BIGTREE TECH\" width=\"100\" height=\"100\">\n</a>\n</td>\n</tr>\n</table>\n\n## Backers:\n\n**Ko-fi supporters** ‚òï: [Backers list](https://github.com/user-attachments/files/16147016/Supporters_638561417699952499.csv)\n\n## Support me\n\n<a href=\"https://github.com/sponsors/SoftFever\"><img src=\"https://img.shields.io/badge/GitHub%20Sponsors-30363D?style=flat&logo=GitHub-Sponsors&logoColor=EA4AAA\" height=\"50\"></a>\n<a href=\"https://ko-fi.com/G2G5IP3CP\"><img src=\"https://img.shields.io/badge/Support_me_on_Ko--fi-FF5E5B?style=flat&logo=ko-fi&logoColor=white\" height=\"50\"></a>\n<a href=\"https://paypal.me/softfever3d\"><img src=\"https://img.shields.io/badge/PayPal-003087?style=flat&logo=paypal&logoColor=fff\" height=\"50\"></a>\n\n## Some background\n\nOrcaSlicer was originally forked from Bambu Studio, it was previously known as BambuStudio-SoftFever.\n\n[Bambu Studio](https://github.com/bambulab/BambuStudio) is forked from [PrusaSlicer](https://github.com/prusa3d/PrusaSlicer) by Prusa Research, which is from [Slic3r](https://github.com/Slic3r/Slic3r) by Alessandro Ranellucci and the RepRap community.\nOrcaSlicer incorporates a lot of features from [SuperSlicer](https://github.com/supermerill/SuperSlicer) by @supermerill\nOrcaSlicer's logo is designed by community member Justin Levine (@freejstnalxndr).\n\n# License\n\n- **OrcaSlicer** is licensed under the GNU Affero General Public License, version 3. OrcaSlicer is based on Bambu Studio by BambuLab.\n- **Bambu Studio** is licensed under the GNU Affero General Public License, version 3. Bambu Studio is based on PrusaSlicer by PrusaResearch.\n- **PrusaSlicer** is licensed under the GNU Affero General Public License, version 3. PrusaSlicer is owned by Prusa Research. PrusaSlicer is originally based on Slic3r by Alessandro Ranellucci.\n- **Slic3r** is licensed under the GNU Affero General Public License, version 3. Slic3r was created by Alessandro Ranellucci with the help of many other contributors.\n- The **GNU Affero General Public License**, version 3 ensures that if you use any part of this software in any way (even behind a web server), your software must be released under the same license.\n- OrcaSlicer includes a **pressure advance calibration pattern test** adapted from Andrew Ellis' generator, which is licensed under GNU General Public License, version 3. Ellis' generator is itself adapted from a generator developed by Sineos for Marlin, which is licensed under GNU General Public License, version 3.\n- The **Bambu networking plugin** is based on non-free libraries from BambuLab. It is optional to the OrcaSlicer and provides extended functionalities for Bambulab printer users.\n",
      "stars_today": 9
    },
    {
      "id": 248058818,
      "name": "tracy",
      "full_name": "wolfpld/tracy",
      "description": "Frame profiler",
      "html_url": "https://github.com/wolfpld/tracy",
      "stars": 15105,
      "forks": 989,
      "language": "C++",
      "topics": [
        "gamedev",
        "gamedev-library",
        "gamedevelopment",
        "library",
        "performance",
        "performance-analysis",
        "profiler",
        "profiling",
        "profiling-library"
      ],
      "created_at": "2020-03-17T19:43:04Z",
      "updated_at": "2026-01-22T22:17:46Z",
      "pushed_at": "2026-01-18T11:28:53Z",
      "open_issues": 240,
      "owner": {
        "login": "wolfpld",
        "avatar_url": "https://avatars.githubusercontent.com/u/600573?v=4"
      },
      "readme": "# Tracy Profiler\n\n[![Sponsor](.github/sponsor.png)](https://github.com/sponsors/wolfpld/)\n\n### A real time, nanosecond resolution, remote telemetry, hybrid frame and sampling profiler for games and other applications.\n\nTracy supports profiling CPU (Direct support is provided for C, C++, Lua, Python and Fortran integration. At the same time, third-party bindings to many other languages exist on the internet, such as [Rust](https://github.com/nagisa/rust_tracy_client), [Zig](https://github.com/tealsnow/zig-tracy), [C#](https://github.com/clibequilibrium/Tracy-CSharp), [OCaml](https://github.com/imandra-ai/ocaml-tracy), [Odin](https://github.com/oskarnp/odin-tracy), etc.), GPU (All major graphic APIs: OpenGL, Vulkan, Direct3D 11/12, Metal, OpenCL, CUDA.), memory allocations, locks, context switches, automatically attribute screenshots to captured frames, and much more.\n\n- [Documentation](https://github.com/wolfpld/tracy/releases/latest/download/tracy.pdf) for usage and build process instructions\n- [Releases](https://github.com/wolfpld/tracy/releases) containing the documentation (`tracy.pdf`) and compiled Windows x64 binaries (`Tracy-<version>.7z`) as assets\n- [Changelog](NEWS)\n- [Interactive demo](https://tracy.nereid.pl/)\n\n![](doc/profiler.png)\n\n![](doc/profiler2.png)\n\n![](doc/profiler3.png)\n\n[An Introduction to Tracy Profiler in C++ - Marcos Slomp - CppCon 2023](https://youtu.be/ghXk3Bk5F2U?t=37)\n\n[Introduction to Tracy Profiler v0.2](https://www.youtube.com/watch?v=fB5B46lbapc)  \n[New features in Tracy Profiler v0.3](https://www.youtube.com/watch?v=3SXpDpDh2Uo)  \n[New features in Tracy Profiler v0.4](https://www.youtube.com/watch?v=eAkgkaO8B9o)  \n[New features in Tracy Profiler v0.5](https://www.youtube.com/watch?v=P6E7qLMmzTQ)  \n[New features in Tracy Profiler v0.6](https://www.youtube.com/watch?v=uJkrFgriuOo)  \n[New features in Tracy Profiler v0.7](https://www.youtube.com/watch?v=_hU7vw00MZ4)  \n[New features in Tracy Profiler v0.8](https://www.youtube.com/watch?v=30wpRpHTTag)\n",
      "stars_today": 9
    },
    {
      "id": 358917318,
      "name": "datafusion",
      "full_name": "apache/datafusion",
      "description": "Apache DataFusion SQL Query Engine",
      "html_url": "https://github.com/apache/datafusion",
      "stars": 8305,
      "forks": 1903,
      "language": "Rust",
      "topics": [
        "arrow",
        "big-data",
        "dataframe",
        "datafusion",
        "olap",
        "python",
        "query-engine",
        "rust",
        "sql"
      ],
      "created_at": "2021-04-17T15:40:23Z",
      "updated_at": "2026-01-22T23:41:15Z",
      "pushed_at": "2026-01-22T23:02:12Z",
      "open_issues": 1666,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!---\n  Licensed to the Apache Software Foundation (ASF) under one\n  or more contributor license agreements.  See the NOTICE file\n  distributed with this work for additional information\n  regarding copyright ownership.  The ASF licenses this file\n  to you under the Apache License, Version 2.0 (the\n  \"License\"); you may not use this file except in compliance\n  with the License.  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing,\n  software distributed under the License is distributed on an\n  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n  KIND, either express or implied.  See the License for the\n  specific language governing permissions and limitations\n  under the License.\n-->\n\n# Apache DataFusion\n\n[![Crates.io][crates-badge]][crates-url]\n[![Apache licensed][license-badge]][license-url]\n[![Build Status][actions-badge]][actions-url]\n![Commit Activity][commit-activity-badge]\n[![Open Issues][open-issues-badge]][open-issues-url]\n[![Pending PRs][pending-pr-badge]][pending-pr-url]\n[![Discord chat][discord-badge]][discord-url]\n[![Linkedin][linkedin-badge]][linkedin-url]\n![Crates.io MSRV][msrv-badge]\n\n[crates-badge]: https://img.shields.io/crates/v/datafusion.svg\n[crates-url]: https://crates.io/crates/datafusion\n[license-badge]: https://img.shields.io/badge/license-Apache%20v2-blue.svg\n[license-url]: https://github.com/apache/datafusion/blob/main/LICENSE.txt\n[actions-badge]: https://github.com/apache/datafusion/actions/workflows/rust.yml/badge.svg\n[actions-url]: https://github.com/apache/datafusion/actions?query=branch%3Amain\n[discord-badge]: https://img.shields.io/badge/Chat-Discord-purple\n[discord-url]: https://discord.com/invite/Qw5gKqHxUM\n[commit-activity-badge]: https://img.shields.io/github/commit-activity/m/apache/datafusion\n[open-issues-badge]: https://img.shields.io/github/issues-raw/apache/datafusion\n[open-issues-url]: https://github.com/apache/datafusion/issues\n[pending-pr-badge]: https://img.shields.io/github/issues-search/apache/datafusion?query=is%3Apr+is%3Aopen+draft%3Afalse+review%3Arequired+status%3Asuccess&label=Pending%20PRs&logo=github\n[pending-pr-url]: https://github.com/apache/datafusion/pulls?q=is%3Apr+is%3Aopen+draft%3Afalse+review%3Arequired+status%3Asuccess+sort%3Aupdated-desc\n[linkedin-badge]: https://img.shields.io/badge/Follow-Linkedin-blue\n[linkedin-url]: https://www.linkedin.com/company/apache-datafusion/\n[msrv-badge]: https://img.shields.io/crates/msrv/datafusion?label=Min%20Rust%20Version\n\n[Website](https://datafusion.apache.org/) |\n[API Docs](https://docs.rs/datafusion/latest/datafusion/) |\n[Chat](https://discord.com/channels/885562378132000778/885562378132000781)\n\n<a href=\"https://datafusion.apache.org/\">\n  <img src=\"https://github.com/apache/datafusion/raw/HEAD/docs/source/_static/images/2x_bgwhite_original.png\" width=\"512\" alt=\"logo\"/>\n</a>\n\nDataFusion is an extensible query engine written in [Rust] that\nuses [Apache Arrow] as its in-memory format.\n\nThis crate provides libraries and binaries for developers building fast and\nfeature rich database and analytic systems, customized to particular workloads.\nSee [use cases] for examples. The following related subprojects target end users:\n\n- [DataFusion Python](https://github.com/apache/datafusion-python/) offers a Python interface for SQL and DataFrame\n  queries.\n- [DataFusion Comet](https://github.com/apache/datafusion-comet/) is an accelerator for Apache Spark based on\n  DataFusion.\n\n\"Out of the box,\"\nDataFusion offers [SQL](https://datafusion.apache.org/user-guide/sql/index.html) and [Dataframe](https://datafusion.apache.org/user-guide/dataframe.html) APIs, excellent [performance],\nbuilt-in support for CSV, Parquet, JSON, and Avro, extensive customization, and\na great community.\n\nDataFusion features a full query planner, a columnar, streaming, multi-threaded,\nvectorized execution engine, and partitioned data sources. You can\ncustomize DataFusion at almost all points including additional data sources,\nquery languages, functions, custom operators and more.\nSee the [Architecture] section for more details.\n\n[rust]: http://rustlang.org\n[apache arrow]: https://arrow.apache.org\n[use cases]: https://datafusion.apache.org/user-guide/introduction.html#use-cases\n[python bindings]: https://github.com/apache/datafusion-python\n[performance]: https://benchmark.clickhouse.com/\n[architecture]: https://datafusion.apache.org/contributor-guide/architecture.html\n\nHere are links to some important information\n\n- [Project Site](https://datafusion.apache.org/)\n- [Installation](https://datafusion.apache.org/user-guide/cli/installation.html)\n- [Rust Getting Started](https://datafusion.apache.org/user-guide/example-usage.html)\n- [Rust DataFrame API](https://datafusion.apache.org/user-guide/dataframe.html)\n- [Rust API docs](https://docs.rs/datafusion/latest/datafusion)\n- [Rust Examples](https://github.com/apache/datafusion/tree/main/datafusion-examples)\n- [Python DataFrame API](https://arrow.apache.org/datafusion-python/)\n- [Architecture](https://docs.rs/datafusion/latest/datafusion/index.html#architecture)\n\n## What can you do with this crate?\n\nDataFusion is great for building projects such as domain specific query engines, new database platforms and data pipelines, query languages and more.\nIt lets you start quickly from a fully working engine, and then customize those features specific to your use. [Click Here](https://datafusion.apache.org/user-guide/introduction.html#known-users) to see a list known users.\n\n## Contributing to DataFusion\n\nPlease see the [contributor guide] and [communication] pages for more information.\n\n[contributor guide]: https://datafusion.apache.org/contributor-guide\n[communication]: https://datafusion.apache.org/contributor-guide/communication.html\n\n## Crate features\n\nThis crate has several [features] which can be specified in your `Cargo.toml`.\n\n[features]: https://doc.rust-lang.org/cargo/reference/features.html\n\nDefault features:\n\n- `nested_expressions`: functions for working with nested type function such as `array_to_string`\n- `compression`: reading files compressed with `xz2`, `bzip2`, `flate2`, and `zstd`\n- `crypto_expressions`: cryptographic functions such as `md5` and `sha256`\n- `datetime_expressions`: date and time functions such as `to_timestamp`\n- `encoding_expressions`: `encode` and `decode` functions\n- `parquet`: support for reading the [Apache Parquet] format\n- `sql`: Support for sql parsing / planning\n- `regex_expressions`: regular expression functions, such as `regexp_match`\n- `unicode_expressions`: Include unicode aware functions such as `character_length`\n- `unparser`: enables support to reverse LogicalPlans back into SQL\n- `recursive_protection`: uses [recursive](https://docs.rs/recursive/latest/recursive/) for stack overflow protection.\n\nOptional features:\n\n- `avro`: support for reading the [Apache Avro] format\n- `backtrace`: include backtrace information in error messages\n- `parquet_encryption`: support for using [Parquet Modular Encryption]\n- `serde`: enable arrow-schema's `serde` feature\n\n[apache avro]: https://avro.apache.org/\n[apache parquet]: https://parquet.apache.org/\n[parquet modular encryption]: https://parquet.apache.org/docs/file-format/data-pages/encryption/\n\n## DataFusion API Evolution and Deprecation Guidelines\n\nPublic methods in Apache DataFusion evolve over time: while we try to maintain a\nstable API, we also improve the API over time. As a result, we typically\ndeprecate methods before removing them, according to the [deprecation guidelines].\n\n[deprecation guidelines]: https://datafusion.apache.org/contributor-guide/api-health.html\n\n## Dependencies and `Cargo.lock`\n\nFollowing the [guidance] on committing `Cargo.lock` files, this project commits\nits `Cargo.lock` file.\n\nCI uses the committed `Cargo.lock` file, and dependencies are updated regularly\nusing [Dependabot] PRs.\n\n[guidance]: https://blog.rust-lang.org/2023/08/29/committing-lockfiles.html\n[dependabot]: https://docs.github.com/en/code-security/dependabot/working-with-dependabot\n",
      "stars_today": 9
    },
    {
      "id": 14747598,
      "name": "json-server",
      "full_name": "typicode/json-server",
      "description": "Get a full fake REST API with zero coding in less than 30 seconds (seriously)",
      "html_url": "https://github.com/typicode/json-server",
      "stars": 75589,
      "forks": 7270,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2013-11-27T13:21:13Z",
      "updated_at": "2026-01-23T01:24:29Z",
      "pushed_at": "2026-01-22T09:37:25Z",
      "open_issues": 713,
      "owner": {
        "login": "typicode",
        "avatar_url": "https://avatars.githubusercontent.com/u/5502029?v=4"
      },
      "readme": "# JSON-Server\n\n[![Node.js CI](https://github.com/typicode/json-server/actions/workflows/node.js.yml/badge.svg)](https://github.com/typicode/json-server/actions/workflows/node.js.yml)\n\n> [!IMPORTANT]\n> Viewing beta v1 documentation ‚Äì usable but expect breaking changes. For stable version, see [here](https://github.com/typicode/json-server/tree/v0.17.4)\n\n> [!NOTE]\n> Using React ‚öõÔ∏è and tired of CSS-in-JS? See [MistCSS](https://github.com/typicode/mistcss) üëÄ\n\n## Install\n\n```shell\nnpm install json-server\n```\n\n## Usage\n\nCreate a `db.json` or `db.json5` file\n\n```json\n{\n  \"$schema\": \"./node_modules/json-server/schema.json\",\n  \"posts\": [\n    { \"id\": \"1\", \"title\": \"a title\", \"views\": 100 },\n    { \"id\": \"2\", \"title\": \"another title\", \"views\": 200 }\n  ],\n  \"comments\": [\n    { \"id\": \"1\", \"text\": \"a comment about post 1\", \"postId\": \"1\" },\n    { \"id\": \"2\", \"text\": \"another comment about post 1\", \"postId\": \"1\" }\n  ],\n  \"profile\": {\n    \"name\": \"typicode\"\n  }\n}\n```\n\n<details>\n\n<summary>View db.json5 example</summary>\n\n```json5\n{\n  posts: [\n    { id: \"1\", title: \"a title\", views: 100 },\n    { id: \"2\", title: \"another title\", views: 200 },\n  ],\n  comments: [\n    { id: \"1\", text: \"a comment about post 1\", postId: \"1\" },\n    { id: \"2\", text: \"another comment about post 1\", postId: \"1\" },\n  ],\n  profile: {\n    name: \"typicode\",\n  },\n}\n```\n\nYou can read more about JSON5 format [here](https://github.com/json5/json5).\n\n</details>\n\nPass it to JSON Server CLI\n\n```shell\n$ npx json-server db.json\n```\n\nGet a REST API\n\n```shell\n$ curl http://localhost:3000/posts/1\n{\n  \"id\": \"1\",\n  \"title\": \"a title\",\n  \"views\": 100\n}\n```\n\nRun `json-server --help` for a list of options\n\n## Sponsors ‚ú®\n\n### Gold\n\n|                                                                                                                                                            |\n| :--------------------------------------------------------------------------------------------------------------------------------------------------------: |\n|               <a href=\"https://mockend.com/\" target=\"_blank\"><img src=\"https://jsonplaceholder.typicode.com/mockend.svg\" height=\"100px\"></a>               |\n| <a href=\"https://zuplo.link/json-server-gh\"><img src=\"https://github.com/user-attachments/assets/adfee31f-a8b6-4684-9a9b-af4f03ac5b75\" height=\"100px\"></a> |\n|     <a href=\"https://www.mintlify.com/\"><img src=\"https://github.com/user-attachments/assets/bcc8cc48-b2d9-4577-8939-1eb4196b7cc5\" height=\"100px\"></a>     |\n\n### Silver\n\n|                                                                                                                                                                                                                                         |\n| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\n| <a href=\"https://requestly.com?utm_source=githubsponsor&utm_medium=jsonserver&utm_campaign=jsonserver\"><img src=\"https://github.com/user-attachments/assets/f7e7b3cf-97e2-46b8-81c8-cb3992662a1c\" style=\"height:70px; width:auto;\"></a> |\n\n### Bronze\n\n|                                                                                                                                                                                |                                                                                                                                                                              |\n| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\n| <a href=\"https://www.storyblok.com/\" target=\"_blank\"><img src=\"https://github.com/typicode/json-server/assets/5502029/c6b10674-4ada-4616-91b8-59d30046b45a\" height=\"35px\"></a> | <a href=\"https://betterstack.com/\" target=\"_blank\"><img src=\"https://github.com/typicode/json-server/assets/5502029/44679f8f-9671-470d-b77e-26d90b90cbdc\" height=\"35px\"></a> |\n\n[Become a sponsor and have your company logo here](https://github.com/users/typicode/sponsorship)\n\n## Sponsorware\n\n> [!NOTE]\n> This project uses the [Fair Source License](https://fair.io/). Only organizations with 3+ users are kindly asked to contribute a small amount through sponsorship [sponsor](https://github.com/sponsors/typicode) for usage. **This license helps keep the project sustainable and healthy, benefiting everyone.**\n>\n> For more information, FAQs, and the rationale behind this, visit [https://fair.io/](https://fair.io/).\n\n## Routes\n\nBased on the example `db.json`, you'll get the following routes:\n\n```\nGET    /posts\nGET    /posts/:id\nPOST   /posts\nPUT    /posts/:id\nPATCH  /posts/:id\nDELETE /posts/:id\n\n# Same for comments\n```\n\n```\nGET   /profile\nPUT   /profile\nPATCH /profile\n```\n\n## Params\n\n### Conditions\n\n- ` ` ‚Üí `==`\n- `lt` ‚Üí `<`\n- `lte` ‚Üí `<=`\n- `gt` ‚Üí `>`\n- `gte` ‚Üí `>=`\n- `ne` ‚Üí `!=`\n\n```\nGET /posts?views_gt=9000\n```\n\n### Range\n\n- `start`\n- `end`\n- `limit`\n\n```\nGET /posts?_start=10&_end=20\nGET /posts?_start=10&_limit=10\n```\n\n### Paginate\n\n- `page`\n- `per_page` (default = 10)\n\n```\nGET /posts?_page=1&_per_page=25\n```\n\n### Sort\n\n- `_sort=f1,f2`\n\n```\nGET /posts?_sort=id,-views\n```\n\n### Nested and array fields\n\n- `x.y.z...`\n- `x.y.z[i]...`\n\n```\nGET /foo?a.b=bar\nGET /foo?x.y_lt=100\nGET /foo?arr[0]=bar\n```\n\n### Embed\n\n```\nGET /posts?_embed=comments\nGET /comments?_embed=post\n```\n\n## Delete\n\n```\nDELETE /posts/1\nDELETE /posts/1?_dependent=comments\n```\n\n## Serving static files\n\nIf you create a `./public` directory, JSON Server will serve its content in addition to the REST API.\n\nYou can also add custom directories using `-s/--static` option.\n\n```sh\njson-server -s ./static\njson-server -s ./static -s ./node_modules\n```\n\n## Notable differences with v0.17\n\n- `id` is always a string and will be generated for you if missing\n- use `_per_page` with `_page` instead of `_limit`for pagination\n- use Chrome's `Network tab > throtling` to delay requests instead of `--delay` CLI option\n",
      "stars_today": 8
    },
    {
      "id": 5405654,
      "name": "learnGitBranching",
      "full_name": "pcottle/learnGitBranching",
      "description": "An interactive git visualization and tutorial. Aspiring students of git can use this app to educate and challenge themselves towards mastery of git!",
      "html_url": "https://github.com/pcottle/learnGitBranching",
      "stars": 33060,
      "forks": 5950,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2012-08-13T22:36:09Z",
      "updated_at": "2026-01-23T00:54:35Z",
      "pushed_at": "2026-01-22T00:02:55Z",
      "open_issues": 56,
      "owner": {
        "login": "pcottle",
        "avatar_url": "https://avatars.githubusercontent.com/u/1135007?v=4"
      },
      "readme": "# LearnGitBranching\n\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?)](https://github.com/pcottle/learnGitBranching/pulls)\n\nLearnGitBranching is a git repository visualizer, sandbox, and a series of educational tutorials and challenges. Its primary purpose is to help developers understand git through the power of visualization (something that's absent when working on the command line). This is achieved through a game with different levels to get acquainted with the different git commands.\n\nYou can input a variety of commands into LearnGitBranching (LGB) -- as commands are processed, the nearby commit tree will dynamically update to reflect the effects of each command:\n\n![demo-gif](https://user-images.githubusercontent.com/6324814/108740487-02c3c400-7536-11eb-9dd1-53275cdf76fb.gif)\n\nThis visualization combined with tutorials and \"levels\" can help both beginners and intermediate developers polish their version control skills. A quick demo is available here:\nhttps://pcottle.github.io/learnGitBranching/?demo\n\nOr, you can launch the application normally here:\nhttps://pcottle.github.io/learnGitBranching/\n\n### Sandbox Mode\n\nBy default the application launches in \"sandbox mode\" with a basic repository already created. Here you can enter commands and mess around with a repository as much as you like. Keep in mind you can\n\n* `undo` to undo the effects of the last command\n* `reset` to start over with a clean slate (works in levels too)\n* `git clone` to simulate remote repositories!\n\nSandbox mode can be great for demonstrating something to a friend, but the real learning is with levels...\n\n## Levels\n\nType `levels` to see the available lessons / challenges (and which ones you have solved so far). Each level series aims to teach some high-level git concept, and each tab of levels separates major worlds of info (like remote repositories versus local).\n\nFor some added fun, there is a \"git golf\" concept where we keep track of how many commands you use to solve each level. See if you can match all of our records!\n\n### Sharing permalinks\n\nYou can share a link to LearnGitBranching with an arbitrary set of commands that will execute upon load by using the `command` URL parameter. You will also likely want to disable the intro dialog for this case with the `NODEMO` url param; here is [an example](https://learngitbranching.js.org/?NODEMO&command=echo%20%22hello%22;%20git%20commit) to get started.\n\n### Level Builder\n\nYou can build levels with the `build level` command. A dialog will walk you through the process, and at the end it will show you a JSON blob that represents the level you just created. Paste that in a [gist](https://gist.github.com) or directly into an issue and I can check it out / merge in your changes! You can also share this level directly with friends by having them run `import level` and paste the JSON in the resulting text field, or simply send them a custom URL with the the gist ID in the parameters, like so:\nhttps://pcottle.github.io/learnGitBranching/?gist_level_id=a84407351f9c9f0cb241\n\n## Reporting Bugs / Opening Issues\n\nWhen reporting bugs, try running the command `debug_copyTree()` in your JS console when in a state just before reproducing a bug. This can avoid having to copy all the commands you used to get into a specific state. (I can then use the `importTreeNow` command to get to that exact state)\n\n## Building yourself / Contributing Functionality\n\nFor contributing core functionality in the app, you'll probably want to test your changes\nat least once before submitting a pull request. That means you'll need the \"gulp.js\" build tool to build the app:\n\nhttps://gulpjs.com/docs/en/getting-started/quick-start\n\nYou'll also need `yarn` to download all the dependencies of the project.\n\nThe general workflow / steps are below:\n\n```bash\ngit clone <your fork of the repo>\ncd learnGitBranching\nyarn install\n\ngit checkout -b newAwesomeFeature\nvim ./src/js/git/index.js # some changes\nyarn gulp fastBuild # skips tests and linting, faster build\n\n# after building you can open up your browser to the index.html\nopen ./index.html\n# file generated and see your changes\n\nvim ./src/js/git/index.js # more changes\nyarn gulp build # runs tests and lint\n\ngit commit -am \"My new sweet feature!\"\ngit push\n# go online and request a pull\n```\n\nAlternatively, you can also build and run the app in a pre-configured online workspace:\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/pcottle/learnGitBranching/blob/main/src/js/git/index.js)\n[![Open in Codeanywhere](https://codeanywhere.com/img/open-in-codeanywhere-btn.svg)](https://app.codeanywhere.com/#https://github.com/pcottle/learnGitBranching)\n\n\n## Other Technical Details\n\nLearnGitBranching is a pretty simple application (from a technical perspective). There's no backend database or any AJAX requests -- it's a 100% clientside application written in JavaScript. The production version (on github.io) literally just serves up an HTML page with some JS and CSS.\n\nHere is the high-level process of the build:\n\n* CSS is written into just one stylesheet (there is not a whole ton of styling)\n* New HTML is written into a template HTML file (`template.index.html`). This is only needed\n  for new views\n* The app is \"built\", which outputs:\n  * `index.html` in the root directory\n  * CSS and JS files in `./build` directory\n* If the app is being built for production, then these CSS and JS files\n  are hashed (to bust caches) and tests are run\n* That's it!\n\nThus, if you build the app locally, all you have to do in order to run the app is just open up `index.html` in the root directory of the repo. Pretty simple\n\n### Docker\n\nYou can run the most recently built stable image with `docker run -p 8080:80 ghcr.io/pcottle/learngitbranching:main`. Access your environment with at [http://localhost:8080/](<http://localhost:8080/>)\n\nYou can build the app and image with the command: `docker build -t ghcr.io/pcottle/learngitbranching:latest`. See the [Makefile](Makefile) for information on how to build locally with docker.\n\n## Some of our amazing contributors\n\n[//]: contributor-faces\n<a href=\"https://github.com/pcottle\"><img src=\"https://avatars0.githubusercontent.com/u/1135007?v=4\" title=\"pcottle\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/Hongarc\"><img src=\"https://avatars1.githubusercontent.com/u/19208123?v=4\" title=\"Hongarc\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/twmht\"><img src=\"https://avatars1.githubusercontent.com/u/1567200?v=4\" title=\"twmht\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/JuhoKang\"><img src=\"https://avatars1.githubusercontent.com/u/4745294?v=4\" title=\"JuhoKang\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/sunshowers\"><img src=\"https://avatars3.githubusercontent.com/u/180618?v=4\" title=\"sunshowers\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/sPATROL\"><img src=\"https://avatars0.githubusercontent.com/u/11875983?v=4\" title=\"sPATROL\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/coyl\"><img src=\"https://avatars1.githubusercontent.com/u/274452?v=4\" title=\"coyl\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/alexeiberkov\"><img src=\"https://avatars1.githubusercontent.com/u/4151345?v=4\" title=\"alexeiberkov\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/aschrab\"><img src=\"https://avatars1.githubusercontent.com/u/39620?v=4\" title=\"aschrab\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/bcbcarl\"><img src=\"https://avatars0.githubusercontent.com/u/135734?v=4\" title=\"bcbcarl\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/ahonorat\"><img src=\"https://avatars1.githubusercontent.com/u/5851945?v=4\" title=\"ahonorat\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/nem75\"><img src=\"https://avatars0.githubusercontent.com/u/1327785?v=4\" title=\"nem75\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/eatdrinksleepcode\"><img src=\"https://avatars0.githubusercontent.com/u/2099560?v=4\" title=\"eatdrinksleepcode\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/nlehuby\"><img src=\"https://avatars3.githubusercontent.com/u/919962?v=4\" title=\"nlehuby\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/alexandear\"><img src=\"https://avatars2.githubusercontent.com/u/3228886?v=4\" title=\"alexandear\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/PanAeon\"><img src=\"https://avatars3.githubusercontent.com/u/686076?v=4\" title=\"PanAeon\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/donkirkby\"><img src=\"https://avatars1.githubusercontent.com/u/1639148?v=4\" title=\"donkirkby\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/lroellin\"><img src=\"https://avatars1.githubusercontent.com/u/3150983?v=4\" title=\"lroellin\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/ptsoccer\"><img src=\"https://avatars1.githubusercontent.com/u/1102725?v=4\" title=\"ptsoccer\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/jankeromnes\"><img src=\"https://avatars2.githubusercontent.com/u/599268?v=4\" title=\"jankeromnes\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/qiansen1386\"><img src=\"https://avatars2.githubusercontent.com/u/1759658?v=4\" title=\"qiansen1386\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/renderf0x\"><img src=\"https://avatars1.githubusercontent.com/u/6155643?v=4\" title=\"renderf0x\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/filipefilardi\"><img src=\"https://avatars1.githubusercontent.com/u/7308241?v=4\" title=\"filipefilardi\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/rebangm\"><img src=\"https://avatars2.githubusercontent.com/u/1638136?v=4\" title=\"rebangm\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/marcolivierarsenault\"><img src=\"https://avatars2.githubusercontent.com/u/2634090?v=4\" title=\"marcolivierarsenault\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/pengi\"><img src=\"https://avatars0.githubusercontent.com/u/1087673?v=4\" title=\"pengi\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/waldyrious\"><img src=\"https://avatars2.githubusercontent.com/u/478237?v=4\" title=\"waldyrious\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/tym-network\"><img src=\"https://avatars1.githubusercontent.com/u/2879545?v=4\" title=\"tym-network\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/zhyu\"><img src=\"https://avatars1.githubusercontent.com/u/1728523?v=4\" title=\"zhyu\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/mgarciaisaia\"><img src=\"https://avatars1.githubusercontent.com/u/1190974?v=4\" title=\"mgarciaisaia\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/YourSenseiCreeper\"><img src=\"https://avatars1.githubusercontent.com/u/6324814?&v=4\" title=\"YourSenseiCreeper\" width=\"80\" height=\"80\"></a>\n<a href=\"https://github.com/olsza\"><img src=\"https://avatars1.githubusercontent.com/u/12556170?v=4\" title=\"Olsza\" width=\"80\" height=\"80\"></a>\n\n[//]: contributor-faces\n\n## Helpful Folks\nA big shoutout to these brave souls for extensively testing our sandbox and finding bugs and/or inconsistencies:\n\n* Nikita Kouevda\n* Maksim Ioffe\n* Dan Miller\n\nAnd the following heroes for assisting in translating:\n* Jake Chen\n* Ïö∞Î¶¨ÍπÉ (\"urigit\")\n* \"bcho\"\n* \"scientific-coder\"\n* \"ace-coder\"\n* Jo√´l Thieffry\n* Jens Bremmekamp (\"nem75\")\n* \"hilojack\"\n* Ming-Hsuan-Tu (\"twmht\")\n* Mikhail Usov (\"mikhailusov\")\n* Matias Garcia Isaia (\"mgarciaisaia\")\n* Marc-Olivier Arsenault (\"marcolivierarsenault\")\n* Eroany H Leader (\"lhyqy5\")\n* Honorat (\"ahonorat\")\n* Vasil Kulakov (\"coyl\") & Lyubov Agadjanyan (\"shayenblue\")\n* Aliaksei Berkau (\"alexeiberkov\")\n* Mizunashi Mana (\"mizunashi-mana\")\n* YourSenseiCreeper\n* Olsza\n\nAlso huge shoutout for everyone who has put up a pull request that was pulled! Check out the 30+ contributors we have in the [Contributors View](https://github.com/pcottle/learnGitBranching/graphs/contributors)\n\nAnd everyone who has reported an issue that was successfully closed!\n",
      "stars_today": 8
    },
    {
      "id": 133134007,
      "name": "openapi-generator",
      "full_name": "OpenAPITools/openapi-generator",
      "description": "OpenAPI Generator allows generation of API client libraries (SDK generation), server stubs, documentation and configuration automatically given an OpenAPI Spec (v2, v3)",
      "html_url": "https://github.com/OpenAPITools/openapi-generator",
      "stars": 25658,
      "forks": 7363,
      "language": "Java",
      "topics": [
        "api",
        "api-client",
        "api-server",
        "generator",
        "hacktoberfest",
        "openapi",
        "openapi-generator",
        "openapi3",
        "rest",
        "rest-api",
        "rest-client",
        "restful-api",
        "sdk"
      ],
      "created_at": "2018-05-12T09:57:56Z",
      "updated_at": "2026-01-22T23:45:14Z",
      "pushed_at": "2026-01-22T18:26:38Z",
      "open_issues": 5572,
      "owner": {
        "login": "OpenAPITools",
        "avatar_url": "https://avatars.githubusercontent.com/u/37325267?v=4"
      },
      "readme": "<h1 align=\"center\">OpenAPI Generator</h1>\n\n\n<div align=\"center\">\n\n[![Stable releases in Maven Central](https://img.shields.io/maven-metadata/v/https/repo1.maven.org/maven2/org/openapitools/openapi-generator/maven-metadata.xml.svg)](http://search.maven.org/#search%7Cgav%7C1%7Cg%3A%22org.openapitools%22%20AND%20a%3A%22openapi-generator%22)\n[![Apache 2.0 License](https://img.shields.io/badge/License-Apache%202.0-orange)](./LICENSE)\n[![Open Collective backers](https://img.shields.io/opencollective/backers/openapi_generator?color=orange&label=OpenCollective%20Backers)](https://opencollective.com/openapi_generator)\n[![Join the Slack chat room](https://img.shields.io/badge/Slack-Join%20the%20chat%20room-orange)](https://join.slack.com/t/openapi-generator/shared_invite/zt-36ucx4ybl-jYrN6euoYn6zxXNZdldoZA)\n[![Follow OpenAPI Generator Twitter account to get the latest update](https://img.shields.io/twitter/follow/oas_generator.svg?style=social&label=Follow)](https://twitter.com/oas_generator)\n[![Contribute with Gitpod](https://img.shields.io/badge/Contribute%20with-Gitpod-908a85?logo=gitpod)](https://gitpod.io/#https://github.com/OpenAPITools/openapi-generator)\n[![Conan Center](https://shields.io/conan/v/openapi-generator)](https://conan.io/center/recipes/openapi-generator)\n[![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A)](https://ge.openapi-generator.tech/scans)\n</div>\n\n<div align=\"center\">\n\n[Master](https://github.com/OpenAPITools/openapi-generator/tree/master) (`7.20.0`):\n[![Integration Test2](https://circleci.com/gh/OpenAPITools/openapi-generator.svg?style=shield)](https://circleci.com/gh/OpenAPITools/openapi-generator)\n[![Bitrise](https://img.shields.io/bitrise/4a2b10a819d12b67/master?label=bitrise%3A%20Swift+4,5&token=859FMDR8QHwabCzwvZK6vQ)](https://app.bitrise.io/app/4a2b10a819d12b67)\n\n</div>\n\n<div align=\"center\">\n\n:star::star::star: If you would like to contribute, please refer to [guidelines](CONTRIBUTING.md) and a list of [open tasks](https://github.com/openapitools/openapi-generator/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22). :star::star::star:\n\n:bangbang: To migrate from Swagger Codegen to OpenAPI Generator, please refer to the [migration guide](docs/migration-from-swagger-codegen.md) :bangbang:\n\n:notebook_with_decorative_cover: For more information, please refer to the [Wiki page](https://github.com/openapitools/openapi-generator/wiki) and [FAQ](https://github.com/openapitools/openapi-generator/wiki/FAQ) :notebook_with_decorative_cover:\n\n:notebook_with_decorative_cover: The eBook [A Beginner's Guide to Code Generation for REST APIs](https://gum.co/openapi_generator_ebook) is a good starting point for beginners :notebook_with_decorative_cover:\n\n:warning: If the OpenAPI spec, templates or any input (e.g. options, environment variables) is obtained from an untrusted source or environment, please make sure you've reviewed these inputs before using OpenAPI Generator to generate the API client, server stub or documentation to avoid potential security issues (e.g. [code injection](https://en.wikipedia.org/wiki/Code_injection)). For security vulnerabilities, please contact [team@openapitools.org](mailto:team@openapitools.org). :warning:\n\n:bangbang: Both \"OpenAPI Tools\" (https://OpenAPITools.org - the parent organization of OpenAPI Generator) and \"OpenAPI Generator\" are not affiliated with OpenAPI Initiative (OAI) :bangbang:\n\n</div>\n\n## Sponsors\n\nIf you find OpenAPI Generator useful for work, please consider asking your company to support this Open Source project by [becoming a sponsor](https://opencollective.com/openapi_generator). You can also individually sponsor the project by [becoming a backer](https://opencollective.com/openapi_generator).\n\n#### Thank you to our bronze sponsors!\n\n[![NamSor](https://openapi-generator.tech/img/companies/namsor.png)](https://www.namsor.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[![LightBow](https://openapi-generator.tech/img/companies/lightbow.png)](https://www.lightbow.net/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/docspring.png\" width=\"128\" height=\"128\">](https://docspring.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/datadog.png\" width=\"128\" height=\"128\">](https://datadoghq.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/thales.jpg\" width=\"128\" height=\"128\">](https://cpl.thalesgroup.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/apideck.jpg\" width=\"128\" height=\"128\">](https://www.apideck.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/pexa.png\" width=\"128\" height=\"128\">](https://www.pexa.com.au/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/numary.png\" width=\"128\" height=\"128\">](https://www.numary.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/onesignal.png\" width=\"128\" height=\"128\">](https://www.onesignal.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/virtualansoftware.png\" width=\"128\" height=\"128\">](https://www.virtualansoftware.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/mergedev.jpeg\" width=\"128\" height=\"128\">](https://www.merge.dev/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/burkert.jpg\" width=\"128\" height=\"128\">](https://www.burkert.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/finbourne.png\" width=\"128\" height=\"128\">](https://www.finbourne.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/bumpsh.png\" width=\"128\" height=\"128\">](https://bump.sh/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/bileto.png\" width=\"128\" height=\"128\">](https://www.bileto.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/bairesdev.png\" width=\"128\" height=\"128\">](https://www.bairesdev.com/sponsoring-open-source-projects/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/dmtech.jpeg\" width=\"128\" height=\"128\">](https://www.dmtech.de/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/adyen.png\" width=\"128\" height=\"128\">](https://adyen.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/fornex.png\" width=\"128\" height=\"128\">](https://fornex.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/alloyautomation.png\" width=\"128\" height=\"128\">](https://runalloy.com/signup?utm_source=github&utm_medium=referral&utm_campaign=1524_openapigenerator)\n[<img src=\"https://openapi-generator.tech/img/companies/ssstwitter.png\" width=\"128\" height=\"128\">](https://ssstwitter.com/?utm_source=github&utm_medium=referral&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/svix.png\" width=\"128\" height=\"128\">](https://www.svix.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/litslink.png\" width=\"128\" height=\"128\">](https://litslink.com/services/artificial-intelligence?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/designli.jpg\" width=\"128\" height=\"128\">](https://designli.co?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/itm.png\" width=\"128\" height=\"128\">](https://opensource.muenchen.de?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/kong.png\" width=\"128\" height=\"128\">](https://konghq.com/products/kong-konnect?utm_medium=referral&utm_source=github&utm_campaign=platform&utm_content=openapi-generator)\n[<img src=\"https://openapi-generator.tech/img/companies/route4me.png\" width=\"128\" height=\"128\">](https://route4me.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/dm.png\" width=\"128\" height=\"128\">](https://www.dotcom-monitor.com/sponsoring-open-source-projects/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/clickit.jpg\" width=\"128\" height=\"128\">](https://www.clickittech.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/unified_to.jpg\" width=\"128\" height=\"128\">](https://unified.to/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/savetwt.jpg\" width=\"128\" height=\"128\">](https://savetwt.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/serpapi.png\" width=\"128\" height=\"128\">](https://serpapi.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n\n#### Thank you GoDaddy for sponsoring the domain names, Linode for sponsoring the VPS, Checkly for sponsoring the API monitoring and Gradle for sponsoring Develocity\n\n[<img src=\"https://openapi-generator.tech/img/companies/godaddy.png\" width=\"150\">](https://www.godaddy.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[![Linode](https://www.linode.com/media/images/logos/standard/light/linode-logo_standard_light_small.png)](https://www.linode.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRAhEYadUyZYzGUotZiSdXkVMqqLGuohyixLl4eUpUV6pAbUULL\" width=\"150\">](https://checklyhq.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Gradle_logo.png/320px-Gradle_logo.png\" width=\"150\">](https://gradle.org?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n\n## Overview\n\nOpenAPI Generator allows generation of API client libraries (SDK generation), server stubs,  documentation and configuration automatically given an [OpenAPI Spec](https://github.com/OAI/OpenAPI-Specification) (both 2.0 and 3.0 are supported). Currently, the following languages/frameworks are supported:\n\n|                                  | Languages/Frameworks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n| -------------------------------- |--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **API clients**                  | **ActionScript**, **Ada**, **Apex**, **Bash**, **C**, **C#** (.net 2.0, 3.5 or later, .NET Standard 1.3 - 2.1, .NET Core 3.1, .NET 5.0. Libraries: RestSharp, GenericHost, HttpClient), **C++** (Arduino, cpp-restsdk, Qt5, Tizen, Unreal Engine 4), **Clojure**, **Crystal**, **Dart**, **Elixir**, **Elm**, **Eiffel**, **Erlang**, **Go**, **Groovy**, **Haskell** (http-client, Servant), **Java** (Apache HttpClient 4.x, Apache HttpClient 5.x, Jersey2.x, OkHttp, Retrofit1.x, Retrofit2.x, Feign, RestTemplate, RESTEasy, Vertx, Google API Client Library for Java, Rest-assured, Spring 5 Web Client, Spring 6 RestClient, MicroProfile Rest Client, Helidon), **Jetbrains HTTP Client**, **Julia**, **k6**, **Kotlin**, **Lua**, **N4JS**, **Nim**, **Node.js/JavaScript** (ES5, ES6, AngularJS with Google Closure Compiler annotations, Flow types, Apollo GraphQL DataStore), **Objective-C**, **OCaml**, **Perl**, **PHP**, **PowerShell**, **Python**, **R**, **Ruby**, **Rust** (hyper, reqwest, rust-server), **Scala** (akka, http4s, scalaz, sttp, swagger-async-httpclient, pekko), **Swift** (2.x, 3.x, 4.x, 5.x, 6.x), **Typescript** (AngularJS, Angular (9.x - 19.x), Aurelia, Axios, Fetch, Inversify, jQuery, Nestjs, Node, redux-query, Rxjs), **XoJo**, **Zapier** |\n| **Server stubs**                 | **Ada**, **C#** (ASP.NET Core, Azure Functions), **C++** (Oat++, Pistache, Restbed, Qt5 QHTTPEngine), **Erlang**, **F#** (Giraffe), **Go** (net/http, Gin, Echo), **Haskell** (Servant, Yesod), **Java** (MSF4J, Spring, Undertow, JAX-RS: CDI, CXF, Inflector, Jersey, RestEasy, Play Framework, [PKMST](https://github.com/ProKarma-Inc/pkmst-getting-started-examples), [Vert.x](https://vertx.io/), [Apache Camel](https://camel.apache.org/), [Helidon](https://helidon.io/)), **Julia**, **Kotlin** (Spring Boot, [Ktor](https://github.com/ktorio/ktor), [Vert.x](https://vertx.io/)), **PHP** ([Flight](https://docs.flightphp.com/), Laravel, Lumen, [Mezzio (fka Zend Expressive)](https://github.com/mezzio/mezzio), Slim, Silex, [Symfony](https://symfony.com/)), **Python** (FastAPI, Flask), **NodeJS**, **Ruby** (Sinatra, Rails5), **Rust** ([rust-server](https://openapi-generator.tech/docs/generators/rust-server/)), **Scala** (Akka, [Finch](https://github.com/finagle/finch), [Lagom](https://github.com/lagom/lagom), [Play](https://www.playframework.com/), [Cask](https://github.com/com-lihaoyi/cask), Scalatra)                                                                                                                                                    |\n| **API documentation generators** | **HTML**, **Confluence Wiki**, **Asciidoc**, **Markdown**, **PlantUML**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n| **Configuration files**          | [**Apache2**](https://httpd.apache.org/)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n| **Others**                       | **GraphQL**, **JMeter**, **Ktorm**, **MySQL Schema**, **Postman Collection**, **Protocol Buffer**, **WSDL**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n\n## Table of contents\n\n- [Sponsors](#sponsors)\n    - [Thank you to our bronze sponsors!](#thank-you-to-our-bronze-sponsors)\n    - [Thank you GoDaddy for sponsoring the domain names, Linode for sponsoring the VPS, Checkly for sponsoring the API monitoring and Gradle for sponsoring Develocity](#thank-you-godaddy-for-sponsoring-the-domain-names-linode-for-sponsoring-the-vps-checkly-for-sponsoring-the-api-monitoring-and-gradle-for-sponsoring-develocity)\n- [Overview](#overview)\n- [Table of contents](#table-of-contents)\n- [1 - Installation](#1---installation)\n  - [1.1 - Compatibility](#11---compatibility)\n- [1.2 - Artifacts on Maven Central](#12---artifacts-on-maven-central)\n  - [1.3 - Download JAR](#13---download-jar)\n  - [Launcher Script](#launcher-script)\n  - [1.4 - Build Projects](#14---build-projects)\n    - [Nix users](#nix-users)\n  - [1.5 - Homebrew](#15---homebrew)\n  - [1.6 - Docker](#16---docker)\n    - [Public Pre-built Docker images](#public-pre-built-docker-images)\n    - [OpenAPI Generator CLI Docker Image](#openapi-generator-cli-docker-image)\n    - [OpenAPI Generator Online Docker Image](#openapi-generator-online-docker-image)\n    - [Development in docker](#development-in-docker)\n      - [Troubleshooting](#troubleshooting)\n    - [Run Docker in Vagrant](#run-docker-in-vagrant)\n  - [1.7 - NPM](#17---npm)\n  - [1.8 - pip](#18---pip)\n- [2 - Getting Started](#2---getting-started)\n- [3 - Usage](#3---usage)\n  - [To generate a sample client library](#to-generate-a-sample-client-library)\n  - [3.1 - Customization](#31---customization)\n  - [3.2 - Workflow Integration (Maven, Gradle, Github, CI/CD)](#32---workflow-integration-maven-gradle-github-cicd)\n  - [3.3 - Online OpenAPI generator](#33---online-openapi-generator)\n  - [3.4 - License information on Generated Code](#34---license-information-on-generated-code)\n  - [3.5 - IDE Integration](#35---ide-integration)\n- [4 - Companies/Projects using OpenAPI Generator](#4---companiesprojects-using-openapi-generator)\n- [5 - Presentations/Videos/Tutorials/Books](#5---presentationsvideostutorialsbooks)\n- [6 - About Us](#6---about-us)\n  - [6.1 - OpenAPI Generator Core Team](#61---openapi-generator-core-team)\n    - [Core Team Members](#core-team-members)\n    - [Template Creator](#template-creator)\n    - [How to join the core team](#how-to-join-the-core-team)\n  - [6.2 - OpenAPI Generator Technical Committee](#62---openapi-generator-technical-committee)\n    - [Members of Technical Committee](#members-of-technical-committee)\n  - [6.3 - History of OpenAPI Generator](#63---history-of-openapi-generator)\n    - [Founding Members (alphabetical order):](#founding-members-alphabetical-order)\n- [7 - License](#7---license)\n\n## [1 - Installation](#table-of-contents)\n\n### [1.1 - Compatibility](#table-of-contents)\n\nThe OpenAPI Specification has undergone 3 revisions since initial creation in 2010.  The openapi-generator project has the following compatibilities with the OpenAPI Specification:\n\n| OpenAPI Generator Version                                                                                                                                 | Release Date | Notes                                             |\n| --------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------ | ------------------------------------------------- |\n| 7.20.0 (upcoming minor release) [SNAPSHOT](https://github.com/OpenAPITools/openapi-generator/wiki/FAQ#how-to-test-with-the-latest-master-of-openapi-generator) | 20.02.2026   | Minor release with breaking changes (with fallback) |\n| [7.19.0](https://github.com/OpenAPITools/openapi-generator/releases/tag/v7.19.0) (latest stable release)                                                    | 20.01.2026   | Minor release with breaking changes (with fallback) |\n| [6.6.0](https://github.com/OpenAPITools/openapi-generator/releases/tag/v6.6.0)                                                    | 11.05.2023   | Minor release with breaking changes (with fallback) |\n| [5.4.0](https://github.com/OpenAPITools/openapi-generator/releases/tag/v5.4.0)                                                    | 31.01.2022   | Minor release with breaking changes (with fallback) |\n| [4.3.1](https://github.com/OpenAPITools/openapi-generator/releases/tag/v4.3.1)                                                    | 06.05.2020   | Patch release (enhancements, bug fixes, etc)                       |\n\nOpenAPI Spec compatibility: 1.0, 1.1, 1.2, 2.0, 3.0, 3.1 (beta support)\n\n(We do not publish daily/nightly build. Please use SNAPSHOT instead)\n\nFor old releases, please refer to the [**Release**](https://github.com/OpenAPITools/openapi-generator/releases) page.\n\nFor decommissioned generators/libraries/frameworks, please refer to [the \"Decommission\" label](https://github.com/OpenAPITools/openapi-generator/issues?q=label%3ADecommission+is%3Amerged+) in the pull request page.\n\n## [1.2 - Artifacts on Maven Central](#table-of-contents)\n\nYou can find our released artifacts on maven central:\n\n**Core:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\nSee the different versions of the [openapi-generator](https://search.maven.org/artifact/org.openapitools/openapi-generator) artifact available on maven central.\n\n**Cli:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator-cli</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\nSee the different versions of the [openapi-generator-cli](https://search.maven.org/artifact/org.openapitools/openapi-generator-cli) artifact available on maven central.\n\n**Maven plugin:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator-maven-plugin</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\n* See the different versions of the [openapi-generator-maven-plugin](https://search.maven.org/artifact/org.openapitools/openapi-generator-maven-plugin) artifact available on maven central.\n* [Readme](https://github.com/OpenAPITools/openapi-generator/blob/master/modules/openapi-generator-maven-plugin/README.md)\n\n**Gradle plugin:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator-gradle-plugin</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\n* See the different versions of the [openapi-generator-gradle-plugin](https://search.maven.org/artifact/org.openapitools/openapi-generator-gradle-plugin) artifact available on maven central.\n* [Readme](https://github.com/OpenAPITools/openapi-generator/blob/master/modules/openapi-generator-gradle-plugin/README.adoc)\n\n### [1.3 - Download JAR](#table-of-contents)\n<!-- RELEASE_VERSION -->\nIf you're looking for the latest stable version, you can grab it directly from Maven.org (Java 11 runtime at a minimum):\n\nJAR location: `https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar`\n\nFor **Mac/Linux** users:\n```sh\nwget https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar -O openapi-generator-cli.jar\n```\n\nFor **Windows** users, you will need to install [wget](http://gnuwin32.sourceforge.net/packages/wget.htm) or you can use Invoke-WebRequest in PowerShell (3.0+), e.g.\n```\nInvoke-WebRequest -OutFile openapi-generator-cli.jar https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar\n```\n\nAfter downloading the JAR, run `java -jar openapi-generator-cli.jar help` to show the usage.\n\nFor Mac users, please make sure Java 11 is installed (Tips: run `java -version` to check the version), and export `JAVA_HOME` in order to use the supported Java version:\n```sh\nexport JAVA_HOME=`/usr/libexec/java_home -v 1.11`\nexport PATH=${JAVA_HOME}/bin:$PATH\n```\n\n<!-- /RELEASE_VERSION -->\n### Launcher Script\n\nOne downside to manual jar downloads is that you don't keep up-to-date with the latest released version. We have a Bash launcher script at [bin/utils/openapi-generator.cli.sh](./bin/utils/openapi-generator-cli.sh) which resolves this issue.\n\nTo install the launcher script, copy the contents of the script to a location on your path and make the script executable.\n\nAn example of setting this up (NOTE: Always evaluate scripts curled from external systems before executing them).\n\n```\nmkdir -p ~/bin/openapitools\ncurl https://raw.githubusercontent.com/OpenAPITools/openapi-generator/master/bin/utils/openapi-generator-cli.sh > ~/bin/openapitools/openapi-generator-cli\nchmod u+x ~/bin/openapitools/openapi-generator-cli\nexport PATH=$PATH:~/bin/openapitools/\n```\n\nNow, `openapi-generator-cli` is \"installed\". On invocation, it will query the GitHub repository for the most recently released version. If this matches the last downloaded jar,\nit will execute as normal. If a newer version is found, the script will download the latest release and execute it.\n\nIf you need to invoke an older version of the generator, you can define the variable `OPENAPI_GENERATOR_VERSION` either ad hoc or globally. You can export this variable if you'd like to persist a specific release version.\n\nExamples:\n\n```\n# Execute latest released openapi-generator-cli\nopenapi-generator-cli version\n\n# Execute version 4.1.0 for the current invocation, regardless of the latest released version\nOPENAPI_GENERATOR_VERSION=4.1.0 openapi-generator-cli version\n\n# Execute version 4.1.0-SNAPSHOT for the current invocation\nOPENAPI_GENERATOR_VERSION=4.1.0-SNAPSHOT openapi-generator-cli version\n\n# Execute version 4.0.2 for every invocation in the current shell session\nexport OPENAPI_GENERATOR_VERSION=4.0.2\nopenapi-generator-cli version # is 4.0.2\nopenapi-generator-cli version # is also 4.0.2\n\n# To \"install\" a specific version, set the variable in .bashrc/.bash_profile\necho \"export OPENAPI_GENERATOR_VERSION=4.0.2\" >> ~/.bashrc\nsource ~/.bashrc\nopenapi-generator-cli version # is always 4.0.2, unless any of the above overrides are done ad hoc\n```\n\n### [1.4 - Build Projects](#table-of-contents)\n\nTo build from source, you need the following installed and available in your `$PATH:`\n\n* [Java 11](https://adoptium.net/)\n\n* [Apache Maven 3.8.8 or greater](https://maven.apache.org/) (optional)\n\nAfter cloning the project, you can build it from source using [maven wrapper](https://maven.apache.org/wrapper/):\n\n- Linux: `./mvnw clean install`\n- Windows: `mvnw.cmd clean install`\n\n#### Nix users\n\nIf you're a nix user, you can enter OpenAPI Generator shell, by typing:\n```sh\nnix develop\n```\nIt will enter a shell with Java 11 installed.\n\nDirenv supports automatically loading of the nix developer shell, so if you're using direnv too, type:\n```sh\ndirenv allow\n```\nand have `java` and `mvn` set up with correct versions each time you enter project directory.\n\nThe default build contains minimal static analysis (via CheckStyle). To run your build with PMD and Spotbugs, use the `static-analysis` profile:\n\n- Linux: `./mvnw -Pstatic-analysis clean install`\n- Windows: `mvnw.cmd -Pstatic-analysis clean install`\n\n### [1.5 - Homebrew](#table-of-contents)\n\nTo install, run `brew install openapi-generator`\n\nHere is an example usage to generate a Ruby client:\n```sh\nopenapi-generator generate -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml -g ruby -o /tmp/test/\n```\n\nTo reinstall with the latest master, run `brew uninstall openapi-generator && brew install --HEAD openapi-generator`\n\nTo install OpenJDK (pre-requisites), please run\n```sh\nbrew tap AdoptOpenJDK/openjdk\nbrew install --cask adoptopenjdk11\nexport JAVA_HOME=`/usr/libexec/java_home -v 1.11`\n```\n\nor download installer via https://adoptium.net/\n\nTo install Maven (optional), please run\n```sh\nbrew install maven\n```\n\n### [1.6 - Docker](#table-of-contents)\n\n#### Public Pre-built Docker images\n\n - [https://hub.docker.com/r/openapitools/openapi-generator-cli/](https://hub.docker.com/r/openapitools/openapi-generator-cli/) (official CLI)\n - [https://hub.docker.com/r/openapitools/openapi-generator-online/](https://hub.docker.com/r/openapitools/openapi-generator-online/) (official web service)\n\n\n#### OpenAPI Generator CLI Docker Image\n\nThe OpenAPI Generator image acts as a standalone executable. It can be used as an alternative to installing via homebrew, or for developers who are unable to install Java or upgrade the installed version.\n\nTo generate code with this image, you'll need to mount a local location as a volume.\n\nExample:\n\n```sh\ndocker run --rm -v \"${PWD}:/local\" openapitools/openapi-generator-cli generate \\\n    -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n    -g go \\\n    -o /local/out/go\n```\n\nThe generated code will be located under `./out/go` in the current directory.\n\n#### OpenAPI Generator Online Docker Image\n\nThe openapi-generator-online image can act as a self-hosted web application and API for generating code. This container can be incorporated into a CI pipeline, and requires at least two HTTP requests and some docker orchestration to access generated code.\n\nExample usage:\n\n```sh\n# Start container at port 8888 and save the container id\n> CID=$(docker run -d -p 8888:8080 openapitools/openapi-generator-online)\n\n# allow for startup\n> sleep 10\n\n# Get the IP of the running container (optional)\nGEN_IP=$(docker inspect --format '{{.NetworkSettings.IPAddress}}'  $CID)\n\n# Execute an HTTP request to generate a Ruby client\n> curl -X POST --header 'Content-Type: application/json' --header 'Accept: application/json' \\\n-d '{\"openAPIUrl\": \"https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml\"}' \\\n'http://localhost:8888/api/gen/clients/ruby'\n\n{\"code\":\"c2d483.3.4672-40e9-91df-b9ffd18d22b8\",\"link\":\"http://localhost:8888/api/gen/download/c2d483.3.4672-40e9-91df-b9ffd18d22b8\"}\n\n# Download the generated zip file\n> wget http://localhost:8888/api/gen/download/c2d483.3.4672-40e9-91df-b9ffd18d22b8\n\n# Unzip the file\n> unzip c2d483.3.4672-40e9-91df-b9ffd18d22b8\n\n# Shutdown the openapi generator image\n> docker stop $CID && docker rm $CID\n```\n\n#### Development in docker\n\nYou can use `run-in-docker.sh` to do all development. This script maps your local repository to `/gen`\nin the docker container. It also maps `~/.m2/repository` to the appropriate container location.\n\nTo execute `mvn package`:\n\n```sh\ngit clone https://github.com/openapitools/openapi-generator\ncd openapi-generator\n./run-in-docker.sh mvn package\n```\n\nBuild artifacts are now accessible in your working directory.\n\nOnce built, `run-in-docker.sh` will act as an executable for openapi-generator-cli. To generate code, you'll need to output to a directory under `/gen` (e.g. `/gen/out`). For example:\n\n```sh\n./run-in-docker.sh help # Executes 'help' command for openapi-generator-cli\n./run-in-docker.sh list # Executes 'list' command for openapi-generator-cli\n./run-in-docker.sh generate -i modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n    -g go -o /gen/out/go-petstore -p packageName=petstore # generates go client, outputs locally to ./out/go-petstore\n```\n\n##### Troubleshooting\n\nIf an error like this occurs, just execute the **./mvnw clean install -U** command:\n\n> org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project openapi-generator: A type incompatibility occurred while executing org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test: java.lang.ExceptionInInitializerError cannot be cast to java.io.IOException\n\n```sh\n./run-in-docker.sh ./mvnw clean install -U\n```\n\n> Failed to execute goal org.fortasoft:gradle-maven-plugin:1.0.8:invoke (default) on project openapi-generator-gradle-plugin-mvn-wrapper: org.gradle.tooling.BuildException: Could not execute build using Gradle distribution 'https://services.gradle.org/distributions/gradle-4.7-bin.zip'\n\nRight now: no solution for this one :|\n\n#### Run Docker in Vagrant\nPrerequisite: install [Vagrant](https://www.vagrantup.com/downloads.html) and [VirtualBox](https://www.virtualbox.org/wiki/Downloads).\n ```sh\ngit clone https://github.com/openapitools/openapi-generator.git\ncd openapi-generator\nvagrant up\nvagrant ssh\ncd /vagrant\n./run-in-docker.sh ./mvnw package\n```\n\n### [1.7 - NPM](#table-of-contents)\n\nThere is also an [NPM package wrapper](https://www.npmjs.com/package/@openapitools/openapi-generator-cli) available for different platforms (e.g. Linux, Mac, Windows). (JVM is still required)\nPlease see the [project's README](https://github.com/openapitools/openapi-generator-cli) there for more information.\n\nInstall it globally to get the CLI available on the command line:\n\n```sh\nnpm install @openapitools/openapi-generator-cli -g\nopenapi-generator-cli version\n```\n\n<!-- RELEASE_VERSION -->\nTo use a specific version of \"openapi-generator-cli\"\n\n```sh\nopenapi-generator-cli version-manager set 7.19.0\n```\n\nOr install it as dev-dependency:\n\n```sh\nnpm install @openapitools/openapi-generator-cli -D\n```\n<!-- /RELEASE_VERSION -->\n\nYou can use [locally built JARs](https://github.com/OpenAPITools/openapi-generator-cli?tab=readme-ov-file#use-locally-built-jar) or [`SNAPSHOT` versions](https://github.com/OpenAPITools/openapi-generator-cli?tab=readme-ov-file#use-nightly-snapshot-build) as well.\n\n### [1.8 - pip](#table-of-contents)\n\n\n> **Platform(s)**: Linux, macOS, Windows\n**Install** via [PyPI](https://pypi.org/) (`java` executable is needed to run):\n\n```\npip install openapi-generator-cli\n```\n\nTo install a specific version\n```\npip install openapi-generator-cli==7.19.0\n```\n\nYou can also install with [jdk4py](https://github.com/activeviam/jdk4py) instead of java binary. (python>=3.10 is required)\n\n```\npip install openapi-generator-cli[jdk4py]\n```\n\nRef: https://github.com/openAPITools/openapi-generator-pip\n\n## [2 - Getting Started](#table-of-contents)\n\nTo generate a PHP client for [petstore.yaml](https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml), please run the following\n```sh\ngit clone https://github.com/openapitools/openapi-generator\ncd openapi-generator\n./mvnw clean package\njava -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar generate \\\n   -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n   -g php \\\n   -o /var/tmp/php_api_client\n```\n(if you're on Windows, replace the last command with `java -jar modules\\openapi-generator-cli\\target\\openapi-generator-cli.jar generate -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml -g php -o c:\\temp\\php_api_client`)\n\n<!-- RELEASE_VERSION -->\nYou can also download the JAR (latest release) directly from [maven.org](https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar)\n<!-- /RELEASE_VERSION -->\n\nTo get a list of **general** options available, please run `java -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar help generate`\n\nTo get a list of PHP specified options (which can be passed to the generator with a config file via the `-c` option), please run `java -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar config-help -g php`\n\n## [3 - Usage](#table-of-contents)\n\n### To generate a sample client library\nYou can build a client against the [Petstore API](https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml) as follows:\n\n```sh\n./bin/generate-samples.sh ./bin/configs/java-okhttp-gson.yaml\n```\n\n(On Windows, please install [GIT Bash for Windows](https://gitforwindows.org/) to run the command above)\n\nThis script uses the default library, which is `okhttp-gson`. It will run the generator with this command:\n\n```sh\njava -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar generate \\\n  -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n  -g java \\\n  -t modules/openapi-generator/src/main/resources/Java \\\n  --additional-properties artifactId=petstore-okhttp-gson,hideGenerationTimestamp=true \\\n  -o samples/client/petstore/java/okhttp-gson\n```\n\nwith a number of options. [The java options are documented here.](docs/generators/java.md)\n\nYou can also get the options with the `help generate` command (below only shows partial results):\n\n```\nNAME\n        openapi-generator-cli generate - Generate code with the specified\n        generator.\n\nSYNOPSIS\n        openapi-generator-cli generate\n                [(-a <authorization> | --auth <authorization>)]\n                [--api-name-suffix <api name suffix>] [--api-package <api package>]\n                [--artifact-id <artifact id>] [--artifact-version <artifact version>]\n                [(-c <configuration file> | --config <configuration file>)] [--dry-run]\n                [(-e <templating engine> | --engine <templating engine>)]\n                [--enable-post-process-file]\n                [(-g <generator name> | --generator-name <generator name>)]\n                [--generate-alias-as-model] [--git-host <git host>]\n                [--git-repo-id <git repo id>] [--git-user-id <git user id>]\n                [--global-property <global properties>...] [--group-id <group id>]\n                [--http-user-agent <http user agent>]\n                [(-i <spec file> | --input-spec <spec file>)]\n                [--ignore-file-override <ignore file override location>]\n                [--import-mappings <import mappings>...]\n                [--instantiation-types <instantiation types>...]\n                [--invoker-package <invoker package>]\n                [--language-specific-primitives <language specific primitives>...]\n                [--legacy-discriminator-behavior] [--library <library>]\n                [--log-to-stderr] [--minimal-update]\n                [--model-name-prefix <model name prefix>]\n                [--model-name-suffix <model name suffix>]\n                [--model-package <model package>]\n                [(-o <output directory> | --output <output directory>)] [(-p <additional properties> | --additional-properties <additional properties>)...]\n                [--package-name <package name>] [--release-note <release note>]\n                [--remove-operation-id-prefix]\n                [--reserved-words-mappings <reserved word mappings>...]\n                [(-s | --skip-overwrite)] [--server-variables <server variables>...]\n                [--skip-validate-spec] [--strict-spec <true/false strict behavior>]\n                [(-t <template directory> | --template-dir <template directory>)]\n                [--type-mappings <type mappings>...] [(-v | --verbose)]\n\nOPTIONS\n        -a <authorization>, --auth <authorization>\n            adds authorization headers when fetching the OpenAPI definitions\n            remotely. Pass in a URL-encoded string of name:header with a comma\n            separating multiple values\n\n...... (results omitted)\n\n        -v, --verbose\n            verbose mode\n\n```\n\nYou can then compile and run the client, as well as unit tests against it:\n\n```sh\ncd samples/client/petstore/java/okhttp-gson\nmvn package\n```\n\nOther generators have [samples](https://github.com/OpenAPITools/openapi-generator/tree/master/samples) too.\n\n### [3.1 - Customization](#table-of-contents)\n\nPlease refer to [customization.md](docs/customization.md) on how to customize the output (e.g. package name, version)\n\n### [3.2 - Workflow Integration (Maven, Gradle, Github, CI/CD)](#table-of-contents)\n\nPlease refer to [integration.md](docs/integration.md) on how to integrate OpenAPI generator with Maven, Gradle, sbt, Bazel, Github and CI/CD.\n\n### [3.3 - Online OpenAPI generator](#table-of-contents)\n\nHere are the public online services:\n\n- latest stable version: https://api.openapi-generator.tech\n- latest master: https://api-latest-master.openapi-generator.tech (updated with latest master every hour)\n\nThe server is sponsored by [Linode](https://www.linode.com/) [![Linode Logo](https://www.linode.com/media/images/logos/standard/light/linode-logo_standard_light_small.png)](https://www.linode.com/)\n\n(These services are beta and do not have any guarantee on service level)\n\nPlease refer to [online.md](docs/online.md) on how to run and use the `openapi-generator-online` - a web service for `openapi-generator`.\n\n### [3.4 - License information on Generated Code](#table-of-contents)\n\nThe OpenAPI Generator project is intended as a benefit for users of the Open API Specification.  The project itself has the [License](#7---license) as specified. In addition, please understand the following points:\n\n* The templates included with this project are subject to the [License](#7---license).\n* Generated code is intentionally _not_ subject to the parent project license\n\nWhen code is generated from this project, it shall be considered **AS IS** and owned by the user of the software.  There are no warranties--expressed or implied--for generated code.  You can do what you wish with it, and once generated, the code is your responsibility and subject to the licensing terms that you deem appropriate.\n\n### [3.5 - IDE Integration](#table-of-contents)\n\nHere is a list of community-contributed IDE plug-ins that integrate with OpenAPI Generator:\n\n- Eclipse: [Codewind OpenAPI Tools for Eclipse](https://www.eclipse.org/codewind/open-api-tools-for-eclipse.html) by [IBM](https://www.ibm.com)\n- IntelliJ IDEA: [OpenAPI Generator](https://plugins.jetbrains.com/plugin/8433-openapi-generator) by [Jim Schubert](https://jimschubert.us/#/)\n- IntelliJ IDEA: [Senya Editor](https://plugins.jetbrains.com/plugin/10690-senya-editor) by [senya.io](https://senya.io)\n- [RepreZen API Studio](https://www.reprezen.com/)\n- Visual Studio: [REST API Client Code Generator](https://marketplace.visualstudio.com/items?itemName=ChristianResmaHelle.ApiClientCodeGenerator) by [Christian Resma Helle](https://christian-helle.blogspot.com/)\n- Visual Studio Code: [Codewind OpenAPI Tools](https://marketplace.visualstudio.com/items?itemName=IBM.codewind-openapi-tools) by [IBM](https://marketplace.visualstudio.com/publishers/IBM)\n\n\n## [4 - Companies/Projects using OpenAPI Generator](#table-of-contents)\nHere are some companies/projects (alphabetical order) using OpenAPI Generator in production. To add your company/project to the list, please visit [README.md](README.md) and click on the icon to edit the page.\n\n- [Aalborg University](https://www.aau.dk)\n- [act coding](https://github.com/actcoding)\n- [Adaptant Solutions AG](https://www.adaptant.io/)\n- [adesso SE](https://www.adesso.de/)\n- [adorsys GmbH & Co.KG](https://adorsys.com/)\n- [Adyen](https://www.adyen.com/)\n- [Agoda](https://www.agoda.com/)\n- [Airthings](https://www.airthings.com/)\n- [Aleri Solutions Gmbh](https://www.aleri.de/)\n- [Allianz](https://www.allianz.com)\n- [Angular.Schule](https://angular.schule/)\n- [Aqovia](https://aqovia.com/)\n- [Australia and New Zealand Banking Group (ANZ)](http://www.anz.com/)\n- [Arduino](https://www.arduino.cc/)\n- [ASKUL](https://www.askul.co.jp)\n- [Amazon Web Services (AWS)](https://aws.amazon.com/)\n- [b<>com](https://b-com.com/en)\n- [ÁôæÂ∫¶Ëê•ÈîÄ](https://e.baidu.com)\n- [Bandwidth](https://dev.bandwidth.com)\n- [Banzai Cloud](https://banzaicloud.com)\n- [BIMData.io](https://bimdata.io)\n- [Bithost GmbH](https://www.bithost.ch)\n- [Bosch Connected Industry](https://www.bosch-connected-industry.com)\n- [Boxever](https://www.boxever.com/)\n- [Brevy](https://www.brevy.com)\n- [Bunker Holding Group](https://www.bunker-holding.com/)\n- [California State University, Northridge](https://www.csun.edu)\n- [CAM](https://www.cam-inc.co.jp/)\n- [Camptocamp](https://www.camptocamp.com/en)\n- [Carlsberg Group](https://www.carlsberggroup.com/)\n- [CERN](https://home.cern/)\n- [Christopher Queen Consulting](https://www.christopherqueenconsulting.com/)\n- [Cisco](https://www.cisco.com/)\n- [codecentric AG](https://www.codecentric.de/)\n- [CoinAPI](https://www.coinapi.io/)\n- [Commencis](https://www.commencis.com/)\n- [ConfigCat](https://configcat.com/)\n- [cronn GmbH](https://www.cronn.de/)\n- [Crossover Health](https://crossoverhealth.com/)\n- [Cupix](https://www.cupix.com/)\n- [Datadog](https://www.datadoghq.com)\n- [DB Systel](https://www.dbsystel.de)\n- [Deeporute.ai](https://www.deeproute.ai/)\n- [Devsupply](https://www.devsupply.com/)\n- [dmTECH GmbH](https://www.dmTECH.de)\n- [DocSpring](https://docspring.com/)\n- [dwango](https://dwango.co.jp/)\n- [Edge Impulse](https://www.edgeimpulse.com/)\n- [Element AI](https://www.elementai.com/)\n- [Embotics](https://www.embotics.com/)\n- [emineo](https://www.emineo.ch)\n- [fastly](https://www.fastly.com/)\n- [Fenergo](https://www.fenergo.com/)\n- [freee](https://corp.freee.co.jp/en/)\n- [FreshCells](https://www.freshcells.de/)\n- [Fuse](https://www.fuse.no/)\n- [Gantner](https://www.gantner.com)\n- [GenFlow](https://github.com/RepreZen/GenFlow)\n- [GetYourGuide](https://www.getyourguide.com/)\n- [Glovo](https://glovoapp.com/)\n- [GMO Pepabo](https://pepabo.com/en/)\n- [GoDaddy](https://godaddy.com)\n- [Gumtree](https://gumtree.com)\n- [Here](https://developer.here.com/)\n- [IBM](https://www.ibm.com/)\n- [Instana](https://www.instana.com)\n- [Interxion](https://www.interxion.com)\n- [Inquisico](https://inquisico.com)\n- [JustStar](https://www.juststarinfo.com)\n- [k6.io](https://k6.io/)\n- [Klarna](https://www.klarna.com/)\n- [Kronsoft Development](https://www.kronsoft.ro/home/)\n- [Kubernetes](https://kubernetes.io)\n- [Landeshauptstadt M√ºnchen - it@M](https://muenchen.digital/it-at-m/)\n- [Linode](https://www.linode.com/)\n- [Logicdrop](https://www.logicdrop.com)\n- [Lumeris](https://www.lumeris.com)\n- [LVM Versicherungen](https://www.lvm.de)\n- [MailSlurp](https://www.mailslurp.com)\n- [Manticore Search](https://manticoresearch.com)\n- [Mastercard](https://developers.mastercard.com)\n- [M√©diavision](https://www.mediavision.fr/)\n- [Metaswitch](https://www.metaswitch.com/)\n- [MoonVision](https://www.moonvision.io/)\n- [Myworkout](https://myworkout.com)\n- [NamSor](https://www.namsor.com/)\n- [Neverfail](https://www.neverfail.com/)\n- [NeuerEnergy](https://neuerenergy.com)\n- [Nokia](https://www.nokia.com/)\n- [OneSignal](https://www.onesignal.com/)\n- [Options Clearing Corporation (OCC)](https://www.theocc.com/)\n- [Openet](https://www.openet.com/)\n- [openVALIDATION](https://openvalidation.io/)\n- [Oracle](https://www.oracle.com/)\n- [Paxos](https://www.paxos.com)\n- [Plaid](https://plaid.com)\n- [PLAID, Inc.](https://plaid.co.jp/)\n- [Pinterest](https://www.pinterest.com)\n- [Ponicode](https://ponicode.dev/)\n- [Pricefx](https://www.pricefx.com/)\n- [PrintNanny](https://www.print-nanny.com/)\n- [Prometheus/Alertmanager](https://github.com/prometheus/alertmanager)\n- [Qavar](https://www.qavar.com)\n- [QEDIT](https://qed-it.com)\n- [Qovery](https://qovery.com)\n- [Qulix Systems](https://www.qulix.com)\n- [Raksul](https://corp.raksul.com)\n- [Raiffeisen Schweiz Genossenschaft](https://www.raiffeisen.ch)\n- [RedHat](https://www.redhat.com)\n- [RepreZen API Studio](https://www.reprezen.com/swagger-openapi-code-generation-api-first-microservices-enterprise-development)\n- [REST United](https://restunited.com)\n- [Robocorp](https://www.robocorp.com)\n- [Robotinfra](https://www.robotinfra.com)\n- [Sarvika Technologies Pvt. Ltd.](https://www.sarvika.com)\n- [SearchApi](https://www.searchapi.io/)\n- [SmartHR](https://smarthr.co.jp/)\n- [Sony Interactive Entertainment](https://www.sie.com/en/index.html)\n- [Splitit](https://www.splitit.com/)\n- [Stingray](http://www.stingray.com)\n- [Suva](https://www.suva.ch/)\n- [Svix](https://www.svix.com/)\n- [Telstra](https://dev.telstra.com)\n- [Tencent](https://www.tencent.com)\n- [The University of Aizu](https://www.u-aizu.ac.jp/en/)\n- [TINQIN](https://www.tinqin.com/)\n- [Translucent ApS](https://www.translucent.dk)\n- [TravelTime platform](https://www.traveltimeplatform.com/)\n- [TribalScale](https://www.tribalscale.com)\n- [Trifork](https://trifork.com)\n- [TUI InfoTec GmbH](http://www.tui-infotec.com/)\n- [Twilio](https://www.twilio.com/)\n- [Twitter](https://twitter.com)\n- [unblu inc.](https://www.unblu.com/)\n- [Veamly](https://www.veamly.com/)\n- [VMWare](https://www.vmware.com/)\n- [wbt-solutions](https://www.wbt-solutions.de/)\n- [Woleet](https://www.woleet.io/)\n- [WSO2](https://wso2.com/)\n- [Vouchery.io](https://vouchery.io)\n- [Xero](https://www.xero.com/)\n- [Yahoo Japan](https://www.yahoo.co.jp/)\n- [viadee](https://www.viadee.de/)\n- [Vonage](https://vonage.com)\n- [YITU Technology](https://www.yitutech.com/)\n- [Yelp](https://www.yelp.com/)\n- [Zalando](https://www.zalando.com)\n- [3DS Outscale](https://www.outscale.com/)\n\n## [5 - Presentations/Videos/Tutorials/Books](#table-of-contents)\n\n- 2018/05/12 - [OpenAPI Generator - community driven„ÅßÊàêÈï∑„Åô„Çã„Ç≥„Éº„Éâ„Ç∏„Çß„Éç„É¨„Éº„Çø](https://ackintosh.github.io/blog/2018/05/12/openapi-generator/) by [‰∏≠ÈáéÊöÅ‰∫∫](https://github.com/ackintosh)\n- 2018/05/15 - [Starting a new open-source project](http://jmini.github.io/blog/2018/2018-05-15_new-open-source-project.html) by [Jeremie Bresson](https://github.com/jmini)\n- 2018/05/15 - [REST API‰ªïÊßò„Åã„ÇâAPI„ÇØ„É©„Ç§„Ç¢„É≥„Éà„ÇÑ„Çπ„Çø„Éñ„Çµ„Éº„Éê„ÇíËá™ÂãïÁîüÊàê„Åô„Çã„ÄåOpenAPI Generator„Äç„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„ÅßÂÖ¨Èñã„ÄÇSwagger Codegen„Åã„Çâ„ÅÆ„Éï„Ç©„Éº„ÇØ](https://www.publickey1.jp/blog/18/rest_apiapiopenapi_generatorswagger_generator.html) by [Publickey](https://www.publickey1.jp)\n- 2018/06/08 - [Swagger Codegen is now OpenAPI Generator](https://angular.schule/blog/2018-06-swagger-codegen-is-now-openapi-generator) by [JohannesHoppe](https://github.com/JohannesHoppe)\n- 2018/06/21 - [Connect your JHipster apps to the world of APIs with OpenAPI and gRPC](https://fr.slideshare.net/chbornet/jhipster-conf-2018-connect-your-jhipster-apps-to-the-world-of-apis-with-openapi-and-grpc) by [Christophe Bornet](https://github.com/cbornet) at [JHipster Conf 2018](https://jhipster-conf.github.io/)\n- 2018/06/22 - [OpenAPI Generator „Åß Gatling Client „ÇíÁîüÊàê„Åó„Å¶„Åø„Åü](https://rohki.hatenablog.com/entry/2018/06/22/073000) at [„ÇΩ„É¢„Çµ„É≥](https://rohki.hatenablog.com/)\n- 2018/06/27 - [Lessons Learned from Leading an Open-Source Project Supporting 30+ Programming Languages](https://speakerdeck.com/wing328/lessons-learned-from-leading-an-open-source-project-supporting-30-plus-programming-languages) - [William Cheng](https://github.com/wing328) at [LinuxCon + ContainerCon + CloudOpen China 2018](http://bit.ly/2waDKKX)\n- 2018/07/19 - [OpenAPI Generator Contribution Quickstart - RingCentral Go SDK](https://medium.com/ringcentral-developers/openapi-generator-for-go-contribution-quickstart-8cc72bf37b53) by [John Wang](https://github.com/grokify)\n- 2018/08/22 - [OpenAPI Generator„ÅÆ„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊßãÊàê„Å™„Å©„ÅÆ„É°„É¢](https://yinm.info/20180822/) by [Yusuke Iinuma](https://github.com/yinm)\n- 2018/09/12 - [RepreZen and OpenAPI 3.0: Now is the Time](https://www.reprezen.com/blog/reprezen-openapi-3.0-upgrade-now-is-the-time) by [Miles Daffin](https://www.reprezen.com/blog/author/miles-daffin)\n- 2018/10/31 - [A node package wrapper for openapi-generator](https://github.com/HarmoWatch/openapi-generator-cli)\n- 2018/11/03 - [OpenAPI Generator + golang + Flutter „Åß„Ç¢„Éó„É™ÈñãÁô∫](http://ryuichi111std.hatenablog.com/entry/2018/11/03/214005) by [Ryuichi Daigo](https://github.com/ryuichi111)\n- 2018/11/15 - [Âü∫‰∫éopenapi3.0ÁöÑyamlÊñá‰ª∂ÁîüÊàêjava‰ª£Á†ÅÁöÑ‰∏ÄÊ¨°ÂÆûË∑µ](https://blog.csdn.net/yzy199391/article/details/84023982) by [ÁÑ±È≠îÁéã](https://me.csdn.net/yzy199391)\n- 2018/11/18 - [Generating PHP library code from OpenAPI](https://lornajane.net/posts/2018/generating-php-library-code-from-openapi) by [Lorna Jane](https://lornajane.net/) at [LORNAJANE Blog](https://lornajane.net/blog)\n- 2018/11/19 - [OpenAPIs are everywhere](https://youtu.be/-lDot4Yn7Dg) by [Jeremie Bresson (Unblu)](https://github.com/jmini) at [EclipseCon Europe 2018](https://www.eclipsecon.org/europe2018)\n- 2018/12/09 - [openapi-generator „Çí„Ç´„Çπ„Çø„Éû„Ç§„Ç∫„Åô„ÇãÊñπÊ≥ï](https://qiita.com/watiko/items/0961287c02eac9211572) by [@watiko](https://qiita.com/watiko)\n- 2019/01/03 - [Calling a Swagger service from Apex using openapi-generator](https://lekkimworld.com/2019/01/03/calling-a-swagger-service-from-apex-using-openapi-generator/) by [Mikkel Flindt Heisterberg](https://lekkimworld.com)\n- 2019/01/13 - [OpenAPI Generator„ÅßRESTful API„ÅÆÂÆöÁæ©Êõ∏„Åã„ÇâËâ≤„ÄÖËá™ÂãïÁîüÊàê„Åô„Çã](https://ky-yk-d.hatenablog.com/entry/2019/01/13/234108) by [@ky_yk_d](https://twitter.com/ky_yk_d)\n- 2019/01/20 - [Contract-First API Development with OpenAPI Generator and Connexion](https://medium.com/commencis/contract-first-api-development-with-openapi-generator-and-connexion-b21bbf2f9244) by [Anil Can Aydin](https://github.com/anlcnydn)\n- 2019/01/30 - [Rapid Application Development With API First Approach Using Open-API Generator](https://dzone.com/articles/rapid-api-development-using-open-api-generator) by [Milan Sonkar](https://dzone.com/users/828329/milan_sonkar.html)\n- 2019/02/02 - [Âπ≥Èùô„Çí‰øù„Å°„ÄÅ„Ç≥„Éº„Éâ„ÇíÁîüÊàê„Åõ„Çà „Äú OpenAPI GeneratorË™ïÁîü„ÅÆËÉåÊôØ„Å®ËªåË∑° „Äú](https://speakerdeck.com/akihito_nakano/gunmaweb34) by [‰∏≠ÈáéÊöÅ‰∫∫](https://github.com/ackintosh) at [Gunma.web #34 „Çπ„Ç≠„Éº„ÉûÈßÜÂãïÈñãÁô∫](https://gunmaweb.connpass.com/event/113974/)\n- 2019/02/20 - [An adventure in OpenAPI V3 code generation](https://mux.com/blog/an-adventure-in-openapi-v3-api-code-generation/) by [Phil Cluff](https://mux.com/blog/author/philc/)\n- 2019/02/26 - [Building API Services: A Beginner‚Äôs Guide](https://medium.com/google-cloud/building-api-services-a-beginners-guide-7274ae4c547f) by [Ratros Y.](https://medium.com/@ratrosy) in [Google Cloud Platform Blog](https://medium.com/google-cloud)\n- 2019/02/26 - [Building APIs with OpenAPI: Continued](https://medium.com/@ratrosy/building-apis-with-openapi-continued-5d0faaed32eb) by [Ratros Y.](https://medium.com/@ratrosy) in [Google Cloud Platform Blog](https://medium.com/google-cloud)\n- 2019-03-07 - [OpenAPI Generator „Åß Spring Boot „Å® Angular „Çí„Çø„Ç§„Éó„Çª„Éº„Éï„Å´Áπã„Åê](https://qiita.com/chibato/items/e4a748db12409b40c02f) by [Tomofumi Chiba](https://github.com/chibat)\n- 2019-03-16 - [A Quick introduction to manual OpenAPI V3](https://vadosware.io/post/quick-intro-to-manual-openapi-v3/) by [vados](https://github.com/t3hmrman) at [VADOSWARE](https://vadosware.io)\n- 2019-03-25 - [Access any REST service with the SAP S/4HANA Cloud SDK](https://blogs.sap.com/2019/03/25/integrate-sap-s4hana-cloud-sdk-with-open-api/) by [Alexander Duemont](https://people.sap.com/alexander.duemont)\n- 2019-03-25 - [OpenAPI generator„ÇíË©¶„Åó„Å¶„Åø„Çã](https://qiita.com/amuyikam/items/e8a45daae59c68be0fc8) by [@amuyikam](https://twitter.com/amuyikam)\n- 2019-03-27 - [OpenAPI3„Çí‰Ωø„Å£„Å¶„Åø„Çà„ÅÜÔºÅGoË®ÄË™û„Åß„ÇØ„É©„Ç§„Ç¢„É≥„Éà„Å®„Çπ„Çø„Éñ„ÅÆËá™ÂãïÁîüÊàê„Åæ„ÅßÔºÅ](https://techblog.zozo.com/entry/openapi3/go) by [@gold_kou](https://twitter.com/gold_kou)\n- 2019-04-17 - [OpenAPI„Å´„Çà„Çã„Çπ„Ç≠„Éº„Éû„Éï„Ç°„Éº„Çπ„ÉàÈñãÁô∫„ÅÆÂÆüÊñΩ„Çµ„É≥„Éó„É´„Å®Cloud Run„Å´„Å§„ÅÑ„Å¶](https://tech-blog.optim.co.jp/entry/2019/04/17/174000) by [@yukey1031](https://twitter.com/yukey1031)\n- 2019-04-18 - [How to use OpenAPI3 for API developer (RubyKaigi 2019)](https://speakerdeck.com/ota42y/how-to-use-openapi3-for-api-developer) by [@ota42y](https://twitter.com/ota42y) at [RubyKaigi 2019](https://rubykaigi.org/2019)\n- 2019-04-29 - [A Beginner's Guide to Code Generation for REST APIs (OpenAPI Generator)](https://gum.co/openapi_generator_ebook) by [William Cheng](https://twitter.com/wing328)\n- 2019-05-01 - [Design and generate a REST API from Swagger / OpenAPI in Java, Python, C# and more](https://simply-how.com/design-and-generate-api-code-from-openapi) by [Simply How](https://simply-how.com/)\n- 2019-05-17 - [Generate Spring Boot REST API using Swagger/OpenAPI](https://www.47northlabs.com/knowledge-base/generate-spring-boot-rest-api-using-swagger-openapi/) by [Antonie Zafirov](https://www.47northlabs.com/author/antonie-zafirov/)\n- 2019-05-22 - [REST APIs‰ª£Á†ÅÁîüÊàêÊåáÂçó(OpenAPI Generator)](https://gum.co/openapi_generator_ebook_gb) by [William Cheng](https://twitter.com/wing328), [Xin Meng](https://github.com/xmeng1)\n- 2019-05-24 - [REST API ‰ª£Á¢ºÁîüÊàêÊåáÂçó (OpenAPI Generator)](https://gum.co/openapi_generator_ebook_big5) by [William Cheng](https://twitter.com/wing328)\n- 2019-06-24 - [Kubernetes Clients and OpenAPI Generator](https://speakerdeck.com/wing328/kubernetes-clients-and-openapi-generator) by [William Cheng](https://twitter.com/wing328) at [Kubernetes Contributor Summits Shanghai 2019](https://www.lfasiallc.com/events/contributors-summit-china-2019/)\n- 2019-06-28 [Codewind OpenAPI Tools](https://marketplace.eclipse.org/content/codewind-openapi-tools) in [Eclipse Marketplace](https://marketplace.eclipse.org/) by IBM\n- 2019-06-29 [Codewind OpenAPI Tools](https://marketplace.visualstudio.com/items?itemName=IBM.codewind-openapi-tools) in [Visual Studio Marketplace](https://marketplace.visualstudio.com/) by IBM\n- 2019-07-04 - [REST API „ÅÆ„Åü„ÇÅ„ÅÆ„Ç≥„Éº„Éà„ÇôÁîüÊàêÂÖ•ÈñÄ (OpenAPI Generator)](https://gum.co/openapi_generator_ebook_big5) by [William Cheng](https://twitter.com/wing328), [‰∏≠ÈáéÊöÅ‰∫∫](https://github.com/ackintosh), [ÂíåÁî∞ÊãìÊúó](https://github.com/taxpon)\n- 2019-07-08 - [OpenAPI Generator „Å´„Ç≥„É≥„Éà„É™„Éì„É•„Éº„Éà„Åó„Åü„ÇâÁ§æÂêç„ÅåËºâ„Å£„ÅüË©±„ÄÇ(CAM) - CAM TECH BLOG](https://tech.cam-inc.co.jp/entry/2019/07/08/140000) by [CAM, Inc.](https://www.cam-inc.co.jp/)\n- 2019-07-14 - [OpenAPI Generator„ÅßPython„ÅÆ„ÇØ„É©„Ç§„Ç¢„É≥„Éà„É©„Ç§„Éñ„É©„É™„Çí‰ΩúÊàê„Åó„Åü](https://qiita.com/yuji38kwmt/items/dfb929316a1335a161c0) by [yuji38kwmt](https://qiita.com/yuji38kwmt)\n- 2019-07-19 - [Developer Experience (DX) for Open-Source Projects: How to Engage Developers and Build a Growing Developer Community](https://speakerdeck.com/wing328/developer-experience-dx-for-open-source-projects-english-japanese) by [William Cheng](https://twitter.com/wing328), [‰∏≠ÈáéÊöÅ‰∫∫](https://github.com/ackintosh) at [Open Source Summit Japan 2019](https://events.linuxfoundation.org/events/open-source-summit-japan-2019/)\n- 2019-08-14 - [Our OpenAPI journey with Standardizing SDKs](https://bitmovin.com/our-openapi-journey-with-standardizing-sdks/) by [Sebastian Burgstaller](https://bitmovin.com/author/sburgstaller/) at [Bitmovin](https://www.bitmovin.com)\n- 2019-08-15 - [API„ÅÆ„Ç≥„Éº„Éâ„ÇíËá™ÂãïÁîüÊàê„Åï„Åõ„Åü„ÅÑ„Å†„Åë„Å™„ÇâgRPC„Åß„Å™„Åè„Å¶„ÇÇ„Çà„Åè„Å™„ÅÑ?](https://www.m3tech.blog/entry/2019/08/15/110000) by [M3, Inc.](https://corporate.m3.com/)\n- 2019-08-22 - [„Éû„Ç§„ÇØ„É≠„Çµ„Éº„Éì„Çπ„Å´„Åä„Åë„ÇãWeb API„Çπ„Ç≠„Éº„Éû„ÅÆÁÆ°ÁêÜ‚îÄ GraphQL„ÄÅgRPC„ÄÅOpenAPI„ÅÆÁâπÂæ¥„Å®‰Ωø„ÅÑ„Å©„Åì„Çç](https://employment.en-japan.com/engineerhub/entry/2019/08/22/103000) by [@ota42y](https://twitter.com/ota42y)\n- 2019-08-24 - [Swagger„Éâ„Ç≠„É•„É°„É≥„Éà„Åã„ÇâOpenAPI Generator„Çí‰Ωø„Å£„Å¶„É¢„ÉÉ„ÇØ„Çµ„Éº„Éê„Éº‰ΩúÊàê](https://qiita.com/masayoshi0222/items/4845e4c715d04587c104) by [ÂùÇÊú¨Ê≠£Áæ©](https://qiita.com/masayoshi0222)\n- 2019-08-29 - [OpenAPIÂàùÊé¢](https://cloud.tencent.com/developer/article/1495986) by [peakxie](https://cloud.tencent.com/developer/user/1113152) at [ËÖæËÆØ‰∫ëÁ§æÂå∫](https://cloud.tencent.com/developer)\n- 2019-08-29 - [ÂÖ®Èù¢ËøõÂåñÔºöKubernetes CRD 1.16 GAÂâçÁûª](https://www.servicemesher.com/blog/kubernetes-1.16-crd-ga-preview/) by [Min Kim](https://github.com/yue9944882) at [ServiceMesher Blog](https://www.servicemesher.com/blog/)\n- 2019-09-01 - [Creating a PHP-Slim server using OpenAPI (Youtube video)](https://www.youtube.com/watch?v=5cJtbIrsYkg) by [Daniel Persson](https://www.youtube.com/channel/UCnG-TN23lswO6QbvWhMtxpA)\n- 2019-09-06 - [Vert.x and OpenAPI](https://wissel.net/blog/2019/09/vertx-and-openapi.html) by [Stephan H Wissel](https://twitter.com/notessensei) at [wissel.net blog](https://wissel.net)\n- 2019-09-09 - [Cloud-native development - Creating RESTful microservices](https://cloud.ibm.com/docs/cloud-native?topic=cloud-native-rest-api) in [IBM Cloud Docs](https://cloud.ibm.com/docs)\n- 2019-09-14 - [Generating and Configuring a Mastercard API Client](https://developer.mastercard.com/platform/documentation/generating-and-configuring-a-mastercard-api-client/) at [Mastercard Developers Platform](https://developer.mastercard.com/platform/documentation/)\n- 2019-09-15 - [OpenAPI(Swagger)Â∞éÂÖ•‰∏ãË™ø„Åπ](https://qiita.com/ShoichiKuraoka/items/f1f7a3c2376f7cd9c56a) by [Shoichi Kuraoka](https://qiita.com/ShoichiKuraoka)\n- 2019-09-17 - [Tutorial: Documenting http4k APIs with OpenApi3](https://www.http4k.org/tutorials/documenting_apis_with_openapi/) by [http4k](https://www.http4k.org/)\n- 2019-09-22 - [OpenAPI 3„ÇíÂÆåÂÖ®„Å´ÁêÜËß£„Åß„Åç„ÇãÊú¨](https://booth.pm/ja/items/1571902) by [@ota42y](https://twitter.com/ota42y)\n- 2019-09-22 - [RESTful APIs: Tutorial of OpenAPI Specification](https://medium.com/@amirm.lavasani/restful-apis-tutorial-of-openapi-specification-eeada0e3901d) by [Amir Lavasani](https://medium.com/@amirm.lavasani)\n- 2019-09-22 - [Redefining SDKs as software diversity kits](https://devrel.net/dev-rel/redefining-sdks-as-software-diversity-kits) by [Sid Maestre (Xero)](https://twitter.com/sidneyallen) at [DevRelCon San Francisco 2019](https://sf2019.devrel.net/)\n- 2019-09-23 - [swagger„Åã„ÇâOpenApi Generator„ÅßSpring„ÅÆ„Ç≥„Éº„Éâ„ÇíËá™ÂãïÁîüÊàê](https://qiita.com/littleFeet/items/492df2ad68a0799a5e5e) by [@littleFeet](https://qiita.com/littleFeet) at [Qiita](https://qiita.com/)\n- 2019-09-24 - [Eine Stunde was mit Api First!](https://www.slideshare.net/JanWeinschenker/eine-stunde-was-mit-api-first) by [@janweinschenker](https://twitter.com/janweinschenker) at [Java Forum Nord](https://javaforumnord.de/)\n- 2019-10-09 - [openapi-generator „ÅßÁîüÊàê„Åó„Åü Go „ÇØ„É©„Ç§„Ç¢„É≥„Éà„Åß Bearer Ë™çË®º„Çí„Åô„Çã](https://autopp-tech.hatenablog.com/entry/2019/10/09/222039) by [Akira Tanimura](https://github.com/autopp)\n- 2019-10-10 - [Automatic Generation of REST Clients](https://www.meetup.com/fr-FR/Criteo-Labs-Tech-Talks/events/264775768/) by Thomas Peyrard, Senior Software Engineer at Criteo in [Full-Stack Tech Talks (Meetup)](https://www.meetup.com/fr-FR/Criteo-Labs-Tech-Talks/events/264775768/)\n- 2019-10-12 - [OpenApiËá™Âä®ÁîüÊàêclient](https://blog.csdn.net/wxid2798226/article/details/102527467) by [ÈÉëÊ≥ΩÊ¥≤](https://me.csdn.net/wxid2798226)\n- 2019-10-16 - [How to ship APIs faster?](https://medium.com/@accounts_76224/how-to-ship-apis-faster-cabef2f819e4) by [Simon Guilliams @ PoniCode](https://ponicode.dev)\n- 2019-10-22 - [OpenAPI + Spring Boot(Kotlin)„Åß„Éï„Ç°„Ç§„É´„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâAPI„Çí‰ΩúÊàê„Åô„Çã](https://qiita.com/boronngo/items/4b78b92526209daeaee9) by [Yuki Furukawa](https://twitter.com/yuki_furukawa5)\n- 2019-10-24 - [Microprofile OpenAPI - Code First or Design First?](https://github.com/pe-st/apidocs/blob/master/MicroProfile-OpenAPI-all-slides.pdf) by [Peter [p…õ É…ô] Steiner](https://twitter.com/pesche) at [eclipsecon Europe 2019](https://www.eclipsecon.org/europe2019/sessions/microprofile-openapi-code-first-or-design-first)\n- 2019-11-06 - [Generating API clients based on OpenAPI v3 specifications](https://98elements.com/blog/generating-api-clients-based-on-openapi-v3-specifications) by [Dominik Jastrzƒôbski @ 98elements](https://98elements.com)\n- 2019-11-06 - [OpenAPI„ÇíÂà©Áî®„Åó„Å¶Ëá™Ââç„ÅÆAPI„Çµ„Éº„Éê„Éº(Sinatra)„ÇíÁßªÊ§ç„Åó„ÅüÊôÇ„ÅÆ„É°„É¢](https://qiita.com/YasuhiroABE/items/c73920eab2d9d6e97fd9) by [Yasuhiro ABE](https://twitter.com/YasuhiroABE)\n- 2019-11-07 - [API First development with OpenAPI - You should you practise it !?](https://www.youtube.com/watch?v=F9iF3a1Z8Y8) by [Nick Van Hoof](https://www.nickvanhoof.com/) at [Devoxx Belgium 2019](https://devoxx.be/)\n- 2019-11-08 - [JHipster beyond CRUD - API-First for Enterprises by Enrico Costanzi](https://www.youtube.com/watch?v=m28JFovKQ20) by [Enrico Costanzi](https://twitter.com/enricocostanzi) at [JHipster Conf 2019 in Paris](https://jhipster-conf.github.io/)\n- 2019-11-11 - [TypeScript REST API„ÇØ„É©„Ç§„Ç¢„É≥„Éà](https://qiita.com/unhurried/items/7b74f7d3c43545dadd2b) by [@unhurried](https://qiita.com/unhurried)\n- 2019-11-11 - [One Spec to Rule them all - OpenAPI in Action](https://www.youtube.com/watch?v=MMay_nht8ec) by [Andreas Litt](https://github.com/littldr) at [code.talks 2019](https://www.codetalks.com/)\n- 2019-11-13 - [OpenAPI 3.0 Editor And Generator With A Spring Boot Example](https://simply-how.com/design-and-generate-api-code-from-openapi) at [Simply How](https://simply-how.com/)\n- 2019-11-17 - [OpenAPI Generator YouTube playlist](https://www.youtube.com/playlist?list=PLtJyHVMdzfF6fBkOUV5VDVErP23CGgHIy) at [YouTube](https://www.youtube.com)\n- 2019-11-20 - [Introduction to OpenAPI](https://noti.st/lornajane/HvDH7U/introduction-to-openapi) by [Lorna Mitchell](https://twitter.com/lornajane) at [GOTO Copenhagen 2019](https://gotocph.com/2019/)\n- 2019-11-20 - [How to Generate Angular code from OpenAPI specifications](https://dotnetthoughts.net/how-to-generate-angular-code-from-openapi-specifications/) by Anuraj\n- 2019-11-23 - [Swagger „Åß„ÅØ„Å™„ÅÑ OpenAPI Specification 3.0 „Å´„Çà„Çã API „Çµ„Éº„Éê„ÉºÈñãÁô∫](https://www.slideshare.net/techblogyahoo/swagger-openapi-specification-30-api) by [Tetsuya Morimoto](https://github.com/t2y) at [JJUG CCC 2019 Fall](https://ccc2019fall.java-users.jp/)\n- 2019-11-24 - [Accelerate Flutter development with OpenAPI and Dart code generation](https://medium.com/@irinasouthwell_220/accelerate-flutter-development-with-openapi-and-dart-code-generation-1f16f8329a6a) by [Irina Southwell](https://medium.com/@irinasouthwell_220)\n- 2019-11-25 - [openapi-generator„ÅßÊâãËªΩ„Å´„Çπ„Çø„Éñ„Çµ„Éº„Éê„Å®„ÇØ„É©„Ç§„Ç¢„É≥„Éà„ÅÆÁîüÊàê](https://qiita.com/pochopocho13/items/8db662e1934fb2b408b8) by [@pochopocho13](https://twitter.com/pochopocho13)\n- 2019-11-26 - [CordaCon 2019 Highlights: Braid Server and OpenAPI Generator for Corda Client API‚Äôs](https://blog.b9lab.com/cordacon-2019-highlights-braid-server-and-openapi-generator-for-corda-flows-api-s-d24179ccb27c) by [Adel Rustum](https://blog.b9lab.com/@adelrestom) at [B9lab](https://blog.b9lab.com/)\n- 2019-12-03 - [A Road to Less Coding: Auto-Generate APILibrary](https://www.corda.net/blog/a-road-to-less-coding-auto-generate-apilibrary/) at [Corda Blog](https://www.corda.net/blog/)\n- 2019-12-04 - [AngularÔºãNestJSÔºãOpenAPIÔºàSwaggerÔºâ„Åß„Éû„Ç§„ÇØ„É≠„Çµ„Éº„Éì„Çπ„ÇíË¶ñÈáé„Å´ÂÖ•„Çå„ÅüÁí∞Â¢É„ÇíËÄÉ„Åà„Çã](https://qiita.com/teracy55/items/0327c7a170ec772970c6) by [„Å¶„Çâ„Åó„Éº](https://twitter.com/teracy55)\n- 2019-12-05 - [Code generation on the Java VM](https://speakerdeck.com/sullis/code-generation-on-the-java-vm-2019-12-05) by [Sean Sullivan](https://speakerdeck.com/sullis)\n- 2019-12-17 - [OpenAPI Generator „Åß OAuth2 „Ç¢„ÇØ„Çª„Çπ„Éà„Éº„ÇØ„É≥Áô∫Ë°å„ÅÆ„Ç≥„Éº„Éâ„Åæ„ÅßÁîüÊàê„Åó„Å¶„Åø„Çã](https://www.techscore.com/blog/2019/12/17/openapi-generator-oauth2-accesstoken/) by [TECHSCORE](https://www.techscore.com/blog/)\n- 2019-12-23 - [Use Ada for Your Web Development](https://www.electronicdesign.com/technologies/embedded-revolution/article/21119177/use-ada-for-your-web-development) by [Stephane Carrez](https://github.com/stcarrez)\n- 2019-12-23 - [OpenAPI„ÅÆ„Çπ„Ç≠„Éº„Éû„ÇíÂàÜÂâ≤„ÉªÊßãÈÄ†Âåñ„Åó„Å¶„ÅÑ„ÅèÊñπÊ≥ï](https://gift-tech.co.jp/articles/structured-openapi-schema) by [Â∞èÈ£ØÂ°öÈÅî‰πü](https://github.com/t2h5) at [GiFT, Inc](https://gift-tech.co.jp/)\n- 2020-01-17 - [OpenAPI demo for Pulp 3.0 GA](https://www.youtube.com/watch?v=mFBP-M0ZPfw&t=178s) by [Pulp](https://www.youtube.com/channel/UCI43Ffs4VPDv7awXvvBJfRQ) at [Youtube](https://www.youtube.com/)\n- 2020-01-19 - [Why document a REST API as code?](https://dev.to/rolfstreefkerk/why-document-a-rest-api-as-code-5e7p) by [Rolf Streefkerk](https://github.com/rpstreef) at [DEV Community](https://dev.to)\n- 2020-01-28 - [Get Your Serverless Swagger Back with OpenAPI](https://dev.to/matttyler/get-your-serverless-swagger-back-with-openapi-48gc) by [Matt Tyler](https://dev.to/matttyler)\n- 2020-01-30 - [OpenAPI Generator„Å∏„ÅÆ„Ç≥„É≥„Éà„É™„Éì„É•„Éº„Éà](https://www.yutaka0m.work/entry/2020/01/30/163905) by [yutaka0m](https://github.com/yutaka0m)\n- 2020-02-01 - [Using OpenAPI to Maximise Your Pulp 3 Experience](https://fosdem.org/2020/schedule/event/openapi/) by [Dennis Kliban](https://github.com/dkliban/) at [FOSDEM](https://fosdem.org/)\n- 2020-02-07 - [Why you should use OpenAPI for your API design](https://www.youtube.com/watch?v=zhb7vUApLW8&t=927s) by [Nick Van Hoof](https://apiconference.net/speaker/nick-van-hoof/) at [API Conference](https://apiconference.net/)\n- 2020-02-17 - [Rubynetes: using OpenAPI to validate Kubernetes configs](https://www.brightbox.com/blog/2020/02/17/using-openapi-to-validate-kubernetes-configs/) by Neil Wilson at [Brightbox](https://www.brightbox.com/)\n- 2020-02-20 - [Building SDKs for the future](https://devblog.xero.com/building-sdks-for-the-future-b79ff726dfd6) by [Sid Maestre (Xero)](https://twitter.com/sidneyallen)\n- 2020-02-27 - [NuxtÂà©Áî®„Éó„É≠„ÉÄ„ÇØ„Éà„ÅßIE11„Å®‰ª≤ËâØ„Åè„Åô„Çã„Åü„ÇÅ„ÅÆE2E](https://tech.medpeer.co.jp/entry/e2e-ie11) at [Medpeer.co.jp Tech Blog](https://tech.medpeer.co.jp/)\n- 2020-02-29 - [Providing Support to IoT Devices Deployed in Disconnected Rural Environment (Conference paper)](https://link.springer.com/chapter/10.1007/978-3-030-41494-8_14) by Sergio Laso, Daniel Flores-Mart√≠n, Juan Luis HerreraCarlos, CanalJuan Manuel, MurilloJavier Berrocal\n- 2020-03-02 - [How To Generate Angular & Spring Code From OpenAPI Specification](https://www.mokkapps.de/blog/how-to-generate-angular-and-spring-code-from-open-api-specification/) by [Michael Hoffmann](https://www.mokkapps.de/)\n- 2020-03-02 - [OpenAPI Generator + TypeScript „ÅßÂßã„ÇÅ„ÇãËá™ÂãïÁîüÊàê„ÅÆÂûã„Å´ÂÆà„Çâ„Çå„ÅüË±ä„Åã„Å™„ÇØ„É©„Ç§„Ç¢„É≥„ÉàÁîüÊ¥ª](https://gift-tech.co.jp/articles/openapi-generator-typescript) by [‰∫îÁôæËîµ Áõ¥Ê®π](https://gift-tech.co.jp/members/naokiioroi) at [GiFTÊ†™Âºè‰ºöÁ§æ](https://gift-tech.co.jp/)\n- 2020-03-10 - [OpenAPI Generator Meetup #1](https://speakerdeck.com/akihito_nakano/openapi-generator-meetup-number-1) by [‰∏≠ÈáéÊöÅ‰∫∫](https://github.com/ackintosh) at [OpenAPI Generator Meetup #1](https://openapi-generator-meetup.connpass.com/event/168187/)\n- 2020-03-15 - [Load Testing Your API with Swagger/OpenAPI and k6](https://k6.io/blog/load-testing-your-api-with-swagger-openapi-and-k6)\n- 2020-04-13 - [‰ø∫ÁöÑ„ÄêOAS„Äë„Å®„ÅÆÂêë„ÅçÂêà„ÅÑÊñπ (ÁàÜÈÄü„ÅßOpenAPI„Å®ÂèãÈÅî„Å´„Å™„Çç„ÅÜ)](https://tech-blog.optim.co.jp/entry/2020/04/13/100000) in [OPTim Blog](https://tech-blog.optim.co.jp/)\n- 2020-04-22 - [Introduction to OpenAPI Generator](https://nordicapis.com/introduction-to-openapi-generator/) by [Kristopher Sandoval](https://nordicapis.com/author/sandovaleffect/) in [Nordic APIs](https://nordicapis.com/)\n- 2020-04-27 - [How we use Open API v3 specification to auto-generate API documentation, code-snippets and clients](https://medium.com/pdf-generator-api/how-we-use-open-api-v3-specification-to-auto-generate-api-documentation-code-snippets-and-clients-d127a3cea784) by [Tanel T√§hep√µld](https://medium.com/@tanel.tahepold)\n- 2020-05-09 - [OpenAPI„Åß„ÅäÊâãËªΩ„Å´„É¢„ÉÉ„ÇØAPI„Çµ„Éº„Éê„Éº„ÇíÂãï„Åã„Åô](https://qiita.com/kasa_le/items/97ca6a8dd4605695c25c) by [Sachie Kamba](https://qiita.com/kasa_le)\n- 2020-05-18 - [Spring Boot REST with OpenAPI 3](https://dev.to/alfonzjanfrithz/spring-boot-rest-with-openapi-3-59jm) by [Alfonz Jan Frithz](https://dev.to/alfonzjanfrithz)\n- 2020-05-19 - [Dead Simple APIs with Open API](https://www.youtube.com/watch?v=sIaXmR6xRAw) by [Chris Tankersley](https://github.com/dragonmantank) at [Nexmo](https://developer.nexmo.com/)\n- 2020-05-22 - [TypeScript REST API Client](https://dev.to/unhurried/typescript-rest-api-client-4in3) by [\"unhurried\"](https://dev.to/unhurried)\n- 2020-05-28 - [„Äê‰ΩøÁî® lotify + Swagger Âª∫ÁΩÆÂèØÂÖ±Áî®ÁöÑ LINE Notify bot„Äë - #NiJia @ Chatbot Developer Taiwan Á¨¨ #19 Â∞èËÅö](https://www.youtube.com/watch?v=agYVz6dzh1I) by [Chatbot Developer Taiwan](https://www.youtube.com/channel/UCxeYUyZNnHmpX23YNF-ewvw)\n- 2020-05-28 - [Building APIs with Laravel using OpenAPI](https://www.youtube.com/watch?v=xexLvQqAhiA) by [Chris Tankersley](https://github.com/dragonmantank) at [Laracon EU](https://laracon.eu/)\n- 2020-06-12 - [Interoperability by construction: code generation for Arrowhead Clients](https://ieeexplore.ieee.org/document/9274746) by Michele Albano, Brian Nielsen at [2020 IEEE Conference on Industrial Cyberphysical Systems (ICPS)](https://ieeexplore.ieee.org/xpl/conhome/9274544/proceeding)\n- 2020-06-23 - [Êñ∞Ë¶è„Çµ„Éº„Éê„Éº„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Å´TypeScript„ÇíÊé°Áî®„Åó„Å¶„Åø„Åü](https://www.cam-inc.co.jp/news/20200623) at [CAM Tech Blog](https://www.cam-inc.co.jp/news/tech-blog/)\n- 2020-06-29 - [Artifact Abstract: Deployment of APIs on Android Mobile Devices and Microcontrollers](https://ieeexplore.ieee.org/document/9127353) by [Sergio Laso ; Marino Linaje ; Jose Garcia-Alonso ; Juan M. Murillo ; Javier Berrocal](https://ieeexplore.ieee.org/document/9127353/authors#authors) at [2020 IEEE International Conference on Pervasive Computing and Communications (PerCom)](https://ieeexplore.ieee.org/xpl/conhome/9125449/proceeding)\n- 2020-07-07 - [5 Best API Documentation Tools](https://blog.dreamfactory.com/5-best-api-documentation-tools/) by Susanna Bouse at [DreamFactory Blog](https://blog.dreamfactory.com/)\n- 2020-07-12 - [Open API 3.0„ÅÆÂÆöÁæ©„Åã„Çâgolang„ÅÆ„Çµ„Éº„Éê„Ç≥„Éº„Éâ„ÅÆ„Çπ„Ç±„É´„Éà„É≥„Çí‰ΩúÊàê„Åô„Çã](https://qiita.com/professor/items/4cbd04ec084d13057bc2) by [@professor (Qiita Blog)](https://qiita.com/professor)\n- 2020-07-20 - [Datadog API client libraries now available for Java and Go](https://www.datadoghq.com/blog/java-go-libraries/) by Jordan Obey at [Datadog Blog](https://www.datadoghq.com/blog)\n- 2020-07-23 - [Generate Client SDK for .NET Core using Open Api](https://dev.to/no0law1/generate-client-sdk-for-net-core-using-open-api-2dgh) by [Nuno Reis](https://dev.to/no0law1)\n- 2020-07-26 - [Dart„ÅÆhttp_interceptor„É©„Ç§„Éñ„É©„É™„Çí‰Ωø„ÅÜ„Å®ÈÖçÂàó„ÅÆ„ÇØ„Ç®„É™„Éë„É©„É°„Éº„Çø„ÅåÊ∂à„Åà„Å¶„Åó„Åæ„ÅÜ‰ª∂„ÅÆÂøúÊÄ•Âá¶ÁΩÆ](https://qiita.com/gyamoto/items/eeeff81b6770487319ed) by [@gyamoto](https://qiita.com/gyamoto)\n- 2020-08-01 - [Generate Angular ReactiveForms from Swagger/OpenAPI](https://dev.to/martinmcwhorter/generate-angular-reactiveforms-from-swagger-openapi-35h9) by [Martin McWhorter](https://dev.to/martinmcwhorter)\n- 2020-08-03 - [Criando Bibliotecas para APIs RESTful com OpenAPI, Swagger Editor e OpenAPI Generator](https://medium.com/@everisBrasil/criando-bibliotecas-para-apis-restful-com-openapi-swagger-editor-e-openapi-generator-75349a6420fd) by [everis Brasil (an NTT DATA Company)](https://medium.com/@everisBrasil)\n- 2020-08-19 - [„Éû„Ç§„ÇØ„É≠„Çµ„Éº„Éì„Çπ„ÇíÈÄ£Êê∫„Åó„Å¶„Åø„Çà„ÅÜ](https://thinkit.co.jp/article/17704) by [Â≤°‰∫ï Ë£ïÁü¢(„Åä„Åã„ÅÑ „ÇÜ„ÅÜ„ÇÑ)](https://thinkit.co.jp/author/17588), [Ê≥â Âãù(„ÅÑ„Åö„Åø „Åæ„Åï„Çã)](https://thinkit.co.jp/author/17705) at [Think ITÔºà„Ç∑„É≥„ÇØ„Ç§„ÉÉ„ÉàÔºâ](https://thinkit.co.jp/)\n- 2020-08-25 - [OpenAPI Generator „Å® TypeScript „ÅßÂûãÂÆâÂÖ®„Å´„Éï„É≠„É≥„Éà„Ç®„É≥„ÉâÈñãÁô∫„Çí„Åó„Å¶„ÅÑ„ÇãË©±](https://tech.smarthr.jp/entry/2020/08/25/135631) at [SmartHR Tech Blog](https://tech.smarthr.jp/)\n- 2020-09-10 - [Introduction to OpenAPI with Instana](https://www.instana.com/blog/introduction-to-openapi-with-instana/) by [Cedric Ziel](https://www.instana.com/blog/author/cedricziel/) at [Instana Blog](https://www.instana.com/blog/)\n- 2020-09-17 - [Generate PowerShellSDK using openapi-generator](https://medium.com/@ghufz.learn/generate-powershellsdk-using-openapi-generator-33b700891e33) by [Ghufran Zahidi](https://medium.com/@ghufz.learn)\n- 2020-09-24 - [How to automate API code generation (OpenAPI/Swagger) and boost productivity - Tutorial with React Native featuring TypeScript](https://medium.com/@sceleski/how-to-automate-api-code-generation-openapi-swagger-and-boost-productivity-1176a0056d8a) by [Sanjin Celeski](https://medium.com/@sceleski)\n- 2020-09-25 - [Generate OpenAPI Angular Client](https://medium.com/@pguso/generate-openapi-angular-client-8c9288e8bbd4) by [Patric](https://medium.com/@pguso)\n- 2020-10-24 - [Working with Microsoft Identity - React Native Client](https://www.josephguadagno.net/2020/10/24/working-with-microsoft-identity-react-native-client) by [Joseph Guadagno](https://www.josephguadagno.net/)\n- 2020-10-31 - [[B2] OpenAPI SpecificationÏúºÎ°ú ÌÉÄÏûÖ-ÏÑ∏Ïù¥ÌîÑÌïòÍ≤å API Í∞úÎ∞úÌïòÍ∏∞: Ìù¨ÎßùÌé∏ VS Ï†àÎßùÌé∏](https://www.youtube.com/watch?v=J4JHLESAiFk) by ÏµúÌÉúÍ±¥ at [FEConf 2020](https://2020.feconf.kr/)\n- 2020-11-05 - [Automated REST-Api Code Generation: Wie IT-Systeme miteinander sprechen](https://www.massiveart.com/blog/automated-rest-api-code-generation-wie-it-systeme-miteinander-sprechen) by Stefan Rottensteiner at [MASSIVE ART Blog](https://www.massiveart.com/blog)\n- 2020-12-01 - [OpenAPI Generator„ÅßGo„ÅÆAPI„Çµ„Éº„Éê„Éº/„ÇØ„É©„Ç§„Ç¢„É≥„Éà„Ç≥„Éº„Éâ„ÇíËá™ÂãïÁîüÊàê„Åô„Çã](https://qiita.com/saki-engineering/items/b20d8b6074c4da9664a5) by [@saki-engineering](https://qiita.com/saki-engineering)\n- 2020-12-04 - [Scaling the Test Coverage of OpenAPI Generator for 30+ Programming Languages](https://www.youtube.com/watch?v=7Lke9dHRqT0) by [William Cheng](https://github.com/wing328) at [Open Source Summit Japan + Automotive Linux Summit 2020](https://events.linuxfoundation.org/archive/2020/open-source-summit-japan/) ([Slides](https://speakerdeck.com/wing328/scaling-the-test-coverage-of-openapi-generator-for-30-plus-programming-languages))\n- 2020-12-09 - [„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´OpenAPI Generator„ÅßËá™ÂãïÁîüÊàê„Åï„Çå„ÅüÂûã‰ªò„ÅçAPI Client„ÇíÂ∞éÂÖ•„Åó„ÅüË©±](https://qiita.com/yoshifujiT/items/905c18700ede23f40840) by [@yoshifujiT](https://github.com/yoshifujiT)\n- 2020-12-15 - [Next.js + NestJS + GraphQL„ÅßÂ§âÂåñ„Å´ËøΩÂæì„Åô„Çã„Éï„É≠„É≥„Éà„Ç®„É≥„Éâ„Å∏ „Äú „Ç∑„Éß„ÉÉ„Éî„É≥„Ç∞„ÇØ„Éº„Éù„É≥„ÅÆ‰∫ã‰æãÁ¥π‰ªã](https://techblog.yahoo.co.jp/entry/2020121530052952/) by [Â∞èÂÄâ Èô∏](https://github.com/ogugu9) at [Yahoo! JAPAN Tech Blog](https://techblog.yahoo.co.jp/)\n- 2021-01-08 - [Hello, New API ‚Äì Part 1](https://www.nginx.com/blog/hello-new-api-part-1/) by [Jeremy Schulman](https://www.nginx.com/people/jeremy-schulman/) at [Major League Baseball](https://www.mlb.com)\n- 2021-01-18 - [„Äå„Ç¢„Éó„É™ÈñãÁô∫„ÅÇ„Çã„ÅÇ„Çã„Äç„ÇíÁñë„ÅÜ„Åì„Å®„Åã„ÇâÂßã„Åæ„Å£„Åü„ÄÅAPI Client„Ç≥„Éº„Éâ„ÅÆËá™ÂãïÁîüÊàê„Äê„Éá„Éñ„Çπ„Éà2020„Äë](https://codezine.jp/article/detail/13406?p=2) by [CodeZineÁ∑®ÈõÜÈÉ®](https://codezine.jp/author/1)\n- 2021-02-05 - [REST-API-Roundtrip with SpringDoc and OpenAPI Generator](https://blog.viadee.de/en/rest-api-roundtrip) by [Benjamin Klatt](https://twitter.com/benklatt) at [viadee](https://www.viadee.de/en/)\n- 2021-02-17 - [REST-API-Roundtrip with SpringDoc and OpenAPI Generator](https://medium.com/nerd-for-tech/rest-api-roundtrip-with-springdoc-and-openapi-generator-30bd27ccf698) by [cloud @viadee](https://cloud-viadee.medium.com/)\n- 2021-03-08 - [OpenAPI Generator Â∑•ÂÖ∑ÁöÑË∫∫ÂùëÂ∞ùËØï](https://blog.csdn.net/u013019701/article/details/114531975) by [Áã¨ÂÆ∂Èõ®Â§©](https://blog.csdn.net/u013019701) at [CSDNÂÆòÊñπÂçöÂÆ¢](https://blog.csdn.net/)\n- 2021-03-16 - [Â¶Ç‰ΩïÂü∫‰∫é Swagger ‰ΩøÁî® OpenAPI Generator ÁîüÊàê JMeter ËÑöÊú¨Ôºü](https://cloud.tencent.com/developer/article/1802704) by [È´òÊ•ºZee](https://cloud.tencent.com/developer/user/5836255) at [ËÖæËÆØ‰∫ë‰∏ìÊ†è](https://cloud.tencent.com/developer/column)\n- 2021-03-24 - [openapi-generator-cli „Å´„Çà„Çã TypeScript ÂûãÂÆöÁæ©](https://zenn.dev/takepepe/articles/openapi-generator-cli-ts) by [Takefumi Yoshii](https://zenn.dev/takepepe)\n- 2021-03-28 - [Trying out NestJS part 4: Generate Typescript clients from OpenAPI documents](https://dev.to/arnaudcortisse/trying-out-nestjs-part-4-generate-typescript-clients-from-openapi-documents-28mk) by [Arnaud Cortisse](https://dev.to/arnaudcortisse)\n- 2021-03-31 - [Open API Server Implementation Using OpenAPI Generator](https://www.baeldung.com/java-openapi-generator-server) at [Baeldung](https://www.baeldung.com/)\n- 2021-03-31 - [‰ΩøÁî®OpenAPI GeneratorÂØ¶ÁèæOpen API Server](https://www.1ju.org/article/java-openapi-generator-server) at [ÂÑÑËÅöÁ∂≤](https://www.1ju.org/)\n- 2021-04-19 - [Introducing Twilio‚Äôs OpenAPI Specification Beta](https://www.twilio.com/blog/introducing-twilio-open-api-specification-beta) by [GARETH PAUL JONES](https://www.twilio.com/blog/author/gpj) at [Twilio Blog](https://www.twilio.com/blog)\n- 2021-04-22 - [Leveraging OpenApi strengths in a Micro-Service environment](https://medium.com/unibuddy-technology-blog/leveraging-openapi-strengths-in-a-micro-service-environment-3d7f9e7c26ff) by Nicolas Jellab at [Unibuddy Technology Blog](https://medium.com/unibuddy-technology-blog)\n- 2021-04-27 - [From zero to publishing PowerShell API clients in PowerShell Gallery within minutes](https://speakerdeck.com/wing328/from-zero-to-publishing-powershell-api-clients-in-powershell-gallery-within-minutes) by [William Cheng](https://github.com/wing328) at [PowerShell + DevOps Global Summit 2021](https://events.devopscollective.org/event/powershell-devops-global-summit-2021/)\n- 2021-05-31 - [Flutter„ÅßOpen Api Generator(Swagger)„Çí‰Ωø„ÅÜ](https://aakira.app/blog/2021/05/flutter-open-api/) by [AAkira](https://twitter.com/_a_akira)\n- 2021-06-22 - [Rest API Documentation and Client Generation With OpenAPI](https://dzone.com/articles/rest-api-documentation-and-client-generation-with) by [Prasanth Gullapalli](https://dzone.com/users/1011797/prasanthnath.g@gmail.com.html)\n- 2021-07-16 - [ÈäÄË°å‰∫ãÊ•≠„ÅÆ„Çµ„Éº„Éê„Éº„Çµ„Ç§„ÉâÈñãÁô∫„Å´„Å§„ÅÑ„Å¶ / LINE ‰∫¨ÈÉΩÈñãÁô∫ÂÆ§ „Ç®„É≥„Ç∏„Éã„Ç¢Êé°Áî®Ë™¨Êòé‰ºö](https://www.youtube.com/watch?v=YrrKQHxLPpQ) by ÈáéÁî∞Ë™†‰∫∫, Robert Mitchell\n- 2021-07-19 - [OpenAPI code generation with kotlin](https://sylhare.github.io/2021/07/19/Openapi-swagger-codegen-with-kotlin.html) by [sylhare](https://github.com/sylhare)\n- 2021-07-29 - [How To Rewrite a Huge Codebase](https://dzone.com/articles/how-to-rewrite-a-huge-code-base) by [Curtis Poe](https://dzone.com/users/4565446/publiusovidius.html)\n- 2021-08-21 - [Generating Client APIs using Swagger Part 1](https://medium.com/@flowsquad/generating-client-apis-using-swagger-part-1-2d46f13f5e92) by [FlowSquad.io](https://medium.com/@flowsquad)\n- 2021-09-11 - [Invoking AWS ParallelCluster API](https://docs.aws.amazon.com/parallelcluster/latest/ug/api-reference-v3.html) at [AWS ParallelCluster API official documentation](https://docs.aws.amazon.com/parallelcluster/latest/ug/api-reference-v3.html)\n- 2021-09-20 - [OpenAPI Generator - The Babel Fish of the API World](https://www.youtube.com/watch?v=s2zMtwd5klg) by [Cliffano Subagio (Principal Engineer at Shine Solutions)](https://github.com/cliffano) at [Apidays LIVE Australia 2021](https://www.apidays.global/australia2021/)\n- 2021-10-02 - [How to Write Fewer Lines of Code with the OpenAPI Generator](https://hackernoon.com/how-to-write-fewer-lines-of-code-with-the-openapi-generator) by [Mikhail Alfa](https://hackernoon.com/u/alphamikle)\n- 2021-10-12 - [OpenAPI Generator : 4000 √©toiles sur GitHub et des spaghettis](https://www.youtube.com/watch?v=9hEsNBSqTFk) by [J√©r√©mie Bresson](https://github.com/jmini) at [Devoxx FR 2021](https://cfp.devoxx.fr/2021/speaker/jeremie_bresson)\n- 2021-10-17 - [Generate a TypeScript HTTP Client From An OpenAPI Spec In DotNET 5](https://richardwillis.info/blog/generate-a-type-script-http-client-from-an-open-api-spec-in-dot-net-5) by [Richard Willis](https://github.com/badsyntax)\n- 2021-11-06 - [„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó„ÅÆÈñãÁô∫„ÅßÊÑèË≠ò„Åó„Åü„Åì„Å®](https://zenn.dev/woo_noo/articles/5cb09f8e2899ae782ad1) by [woo-noo](https://zenn.dev/woo_noo)\n- 2021-11-09 - [Effective Software Development using OpenAPI Generator](https://apexlabs.ai/post/effective-software-development-using-openapi-generator) by Ajil Oomme\n- 2021-12-07 - [An Introduction to OpenAPI](https://betterprogramming.pub/4-use-cases-of-openapi-which-are-good-to-know-1a041f4ad71e) by [Na'aman Hirschfeld](https://naamanhirschfeld.medium.com/)\n- 2022-01-02 - [Towards a secure API client generator for IoT devices](https://arxiv.org/abs/2201.00270) by Anders Aaen Springborg, Martin Kaldahl Andersen, Kaare Holland Hattel, Michele Albano\n- 2022-02-02 - [Use OpenApi generator to share your models between Flutter and your backend](https://www.youtube.com/watch?v=kPW7ccu9Yvk) by [Guillaume Bernos](https://feb2022.fluttervikings.com/speakers/guillaume_bernos) at [Flutter Vikings Conference 2022 (Hybrid)](https://feb2022.fluttervikings.com/)\n- 2022-03-15 - [OpenAPI Spec„Åß„Éè„Ç§„Éï„É≥Âå∫Âàá„Çä„ÅÆEnumÂÄ§„ÇíOpenAPI Generator„ÅßÂá∫Âäõ„Åô„Çã„Å®„ÄÅ„Éè„Ç§„Éï„É≥Âå∫Âàá„Çä„ÅÆ„Åæ„ÅæÂá∫Âäõ„Åï„Çå„Çã](https://qiita.com/yuji38kwmt/items/824d74d4889055ab37d8) by [yuji38kwmt](https://qiita.com/yuji38kwmt)\n- 2022-04-01 - [OpenAPI Generator„ÅÆ„Ç≥„Éº„ÉâÁîüÊàê„Å®Spring Framework„ÅÆ„Ç´„Çπ„Çø„É†„Éá„Éº„Çø„Éê„Ç§„É≥„Éá„Ç£„É≥„Ç∞„ÇíÂÖ±Â≠ò„Åï„Åõ„Çã](https://techblog.zozo.com/entry/coexistence-of-openapi-and-spring) in [ZOZO Tech Blog](https://techblog.zozo.com/)\n- 2022-04-06 - [Effective Software Development using OpenAPI Generator](https://apexlabs.ai/post/openapi-generator) by Ajil Oommen (Senior Flutter Developer)\n- 2022-05-13 - [A Path From an API To Client Libraries](https://www.youtube.com/watch?v=XC8oVn_efTw) by [Filip Srnec](https://www.devoxx.co.uk/talk/?id=11211) at Infobip\n- 2022-06-01 - [API First, using OpenAPI and Spring Boot](https://medium.com/xgeeks/api-first-using-openapi-and-spring-boot-2602c04bb0d3) by [Micael Estr√°zulas Vianna](https://estrazulas.medium.com/)\n- 2022-06-10 - [Autogenerating Clients with FastAPI and Github Actions](https://www.propelauth.com/post/autogenerating-clients-with-fastapi-and-github-actions) by [Andrew Israel](https://www.propelauth.com/author/andrew)\n- 2022-06-12 - [Mustache templates with OpenAPI specs](https://medium.com/geekculture/mustache-templates-with-openapi-specs-f24711c67dec) by [Beppe Catanese](https://github.com/gcatanese)\n- 2022-07-01 - [Generate API contract using OpenAPI Generator Maven plugin](https://huongdanjava.com/generate-api-contract-using-openapi-generator-maven-plugin.html) by [Khanh Nguyen](https://huongdanjava.com/)\n- 2022-07-22 - [‰ΩøÁî®OpenAPI Generator Maven pluginÂºÄÂèëapi‰ºòÂÖàÁöÑjavaÂÆ¢Êà∑Á´ØÂíåÊúçÂä°Á´Ø‰ª£Á†Å](https://blog.roccoshi.top/2022/java/openapi-generator%E7%9A%84%E4%BD%BF%E7%94%A8/) by [Lincest](https://github.com/Lincest)\n- 2022-08-01 - [Tutorial: Etsy Open API v3 (ruby)](https://blog.tjoyal.dev/etsy-open-api-v3/) by [Thierry Joyal](https://github.com/tjoyal)\n- 2022-09-03 - [OpenAPI Generator For Go Web Development](https://blog.kevinhu.me/2022/09/03/03-openapi-generator/) by [Kevin Hu](https://twitter.com/Oldgunix)\n- 2022-10-01 - [OpenAPI Generator„Çí„Ç´„Çπ„Çø„Éû„Ç§„Ç∫„Åó„Åü„Ç≥„Éº„Éâ„ÇíÁîüÊàê„Åô„ÇãÔºàSwagger Codegen„Å®„Åª„ÅºÂêå„ÅòÔºâ](https://nainaistar.hatenablog.com/entry/2022/10/03/120000) by [„Åç„Çä‰∏∏](https://twitter.com/nainaistar)\n- 2022-10-21 - [KotlinÔºàSpring BootÔºâ„ÅÆ API „Çí OpenAPI Generator „ÅßËá™ÂãïÁîüÊàê](https://zenn.dev/msksgm/articles/20221021-kotlin-spring-openapi-generator) by [msksgm](https://zenn.dev/msksgm)\n- 2022-10-26 - [Quarkus Insights #106: Quarkiverse Extension Spotlight: OpenApi Generator](https://www.youtube.com/watch?v=_s_if69t2iQ) by [Quarkusio](https://www.youtube.com/c/Quarkusio)\n- 2022-11-28 - [The REST API implementation flow](https://tmsvr.com/openapi-code-generation-for-rest-apis/) by [Imre T√∂m√∂sv√°ri](https://tmsvr.com/author/imre/)\n- 2022-12-13 - [API-First with Spring WebFlux and OpenAPI Generator](https://boottechnologies-ci.medium.com/api-first-with-spring-webflux-and-openapi-generator-38b7804c4ed4) by [Eric Anicet](https://boottechnologies-ci.medium.com/)\n- 2023-01-06 - [Major Improvements with Helidon and OpenAPI](https://medium.com/helidon/major-improvements-with-helidon-and-openapi-f76a0951508e) by [Tim Quinn](https://medium.com/@tquinno600)\n- 2023-02-02 - [Replacing Postman with the Jetbrains HTTP Client](https://lengrand.fr/replacing-postman-in-seconds-with-the-jetbrains-http-client/) by [julien Lengrand-Lambert](https://github.com/jlengrand)\n- 2023-03-15 - [OpenAPI Generator„Å´ÈÅ©„Åó„ÅüOpenAPI„ÅÆÊõ∏„ÅçÊñπ](https://techblog.zozo.com/entry/how-to-write-openapi-for-openapi-generator) by [ZOZO Tech Blog](https://techblog.zozo.com/)\n- 2023-03-19 - [EXOGEM: Extending OpenAPI Generator for Monitoring of RESTful APIs](https://link.springer.com/chapter/10.1007/978-3-031-26507-5_10) by Daniel Friis Holtebo, Jannik Lucas Sommer, Magnus M√∏lgaard Lund, Alessandro Tibo, Junior Dongo & Michele Albano at \"ICSOC 2022: Service-Oriented Computing ‚Äì ICSOC 2022 Workshops\"\n- 2023-03-28 - [API-First Design with OpenAPI Generator](https://www.linkedin.com/pulse/api-first-design-openapi-generator-jonathan-manera/) by [Jonathan Manera](https://www.linkedin.com/in/manerajona/)\n- 2023-03-28 - [„Éè„É≥„Ç∫„Ç™„É≥„ÅßÂ≠¶„Å∂„Çµ„Éº„Éê„Éº„Çµ„Ç§„Éâ KotlinÔºàSpring Boot&Arrow&OpenAPI GeneratorÔºâv1.0.1](https://zenn.dev/msksgm/books/implementing-server-side-kotlin-development) by [msk](https://zenn.dev/msksgm)\n- 2023-04-01 - [OpenAPI Client Code Generation](https://testingboss.com/blog/openapi-client-generation/) by Kwo Ding\n- 2023-04-27 - [Create an Angular Client using OpenAPI Specifications](Create an Angular Client using OpenAPI Specifications) by [Patric](https://pguso.medium.com/)\n- 2023-05-16 - [Adyen for Java developers](https://www.adyen.com/blog/adyen-java-library) by [Beppe Catanese, Developer Advocate, Adyen](https://github.com/gcatanese)\n- 2023-05-18 - [Â¶Ç‰ΩïÂü∫‰∫é Swagger ‰ΩøÁî® OpenAPI Generator ÁîüÊàê JMeter ËÑöÊú¨Ôºü](https://blog.51cto.com/u_15181572/6294974) by [È´òÊ•ºÔºàZee)](https://blog.51cto.com/u_15181572)\n- 2023-06-28 - [Generate API contract using OpenAPI Generator Maven plugin](https://huongdanjava.com/generate-api-contract-using-openapi-generator-maven-plugin.html) by [Khanh Nguyen](https://huongdanjava.com/)\n- 2023-06-30 - [Generate Client SDKs with OpenApi Generator in Springboot](https://medium.com/@ramavathvinayak/generate-client-sdks-with-openapi-generator-in-springboot-f9f012e73c0b) by [Vinayak Ramavath](https://medium.com/@ramavathvinayak)\n- 2023-12-10 - [Unity„ÅßOpenAPI Generator„Çí‰Ωø„ÅÜ](https://www.youtube.com/watch?v=CbNwKVV5LRM) by [Soup Tori](https://www.youtube.com/@souptori8417)\n- 2024-01-24 - [Comment g√©n√©rer des stubs wiremock avec openapi generator](https://www.youtube.com/watch?v=0jhONfBrcKw) by [Alexis Couvreur](https://github.com/acouvreur)\n- 2024-03-04 - [Generating TypeScript Types with OpenAPI for REST API Consumption](https://www.pullrequest.com/blog/generating-typescript-types-with-openapi-for-rest-api-consumption/) by [PullRequest](https://www.pullrequest.com/)\n- 2024-03-07 - [Fully typed Web Apps with OpenAPI (Part 1)](https://medium.com/@gfox1984/fully-typed-web-apps-with-openapi-part-1-595d55766670) by [Guillaume Renard](https://medium.com/@gfox1984)\n- 2024-03-08 - [Laravel OpenAPI„Å´„Çà„Çã \"Ëæõ„Åè„Å™„ÅÑ\" „Çπ„Ç≠„Éº„ÉûÈßÜÂãïÈñãÁô∫](https://fortee.jp/phperkaigi-2024/proposal/9e2e6c38-d078-4efa-99b4-83ebf9033b34) by [KentarouTakeda](https://twitter.com/KentarouTakeda)\n- 2024-04-04 - [Working with OpenAPI using Rust](https://www.shuttle.dev/blog/2024/04/04/using-openapi-rust) by [Joshua Mo](https://twitter.com/joshmo_dev)\n- 2024-04-08 - [Implement API first strategy with OpenAPI generator plugin](https://medium.com/javarevisited/implement-api-first-strategy-with-openapi-generator-plugin-e4bbe7f0d778) by [Rui Zhou](https://medium.com/@wirelesser)\n- 2024-05-06 - [OpenAPI Generator Custom Templates](https://www.javacodegeeks.com/openapi-generator-custom-templates.html) by [Mary Zheng](https://www.javacodegeeks.com/author/mary-zheng)\n- 2025-02-09 - [Custom validation with OpenApiGenerator and Spring Boot 3](https://medium.com/@jugurtha.aitoufella/custom-validation-with-openapigenerator-and-spring-boot-3-34a656e815c8) by [Jugurtha Aitoufella](https://medium.com/@jugurtha.aitoufella)\n- 2025-02-20 - [Optimizing API Integration in a Large React Application Using OpenAPI Generator](https://www.youtube.com/watch?v=-B33pQnGQUI) by Stefano Marzo\n\n\n## [6 - About Us](#table-of-contents)\n\nWhat's the design philosophy or principle behind OpenAPI Generator?\n\nWe focus on developer experience. The generators should produce code, config, documentation, and more that are easily understandable and consumable by users. We focused on simple use cases to start with (bottom-up approach). Since then the project and the community have grown a lot: 600k weekly downloads via NPM CLI wrapper, 30M downloads via openapi-generator-cli docker image just to highlight a few. We've gradually supported more features (e.g. oneOf, anyOf introduced in OpenAPI 3.0) in various generators and we will continue this approach to deliver something based on our understanding of user demand and what they want, and continue to add support of new features introduced in OpenAPI specification (such as v3.1 and future versions of the OpenAPI specification).\n\n### [6.1 - OpenAPI Generator Core Team](#table-of-contents)\n\nOpenAPI Generator core team members are contributors who have been making significant contributions (review issues, fix bugs, make enhancements, etc) to the project on a regular basis.\n\n#### Core Team Members\n* [@wing328](https://github.com/wing328) (2015/07) [:heart:](https://www.patreon.com/wing328)\n* [@jimschubert](https://github.com/jimschubert) (2016/05) [:heart:](https://www.patreon.com/jimschubert)\n* [@cbornet](https://github.com/cbornet) (2016/05)\n* [@jmini](https://github.com/jmini) (2018/04)  [:heart:](https://www.patreon.com/jmini)\n* [@etherealjoy](https://github.com/etherealjoy) (2019/06)\n\n:heart: = Link to support the contributor directly\n\n#### Template Creator\n\n**NOTE**: Embedded templates are only supported in _Mustache_ format. Support for all other formats is experimental and subject to change at any time.\n\nHere is a list of template creators:\n * API Clients:\n   * Ada: @stcarrez\n   * Apex: @asnelling\n   * Bash: @bkryza\n   * C: @PowerOfCreation @zhemant [:heart:](https://www.patreon.com/zhemant)\n   * C++ Oat++: @Kraust\n   * C++ REST: @Danielku15\n   * C++ Tiny: @AndersSpringborg @kaareHH @michelealbano @mkakbas\n   * C++ UE4: @Kahncode\n   * C# (.NET 2.0): @who\n   * C# (.NET Standard 1.3 ): @Gronsak\n   * C# (.NET 4.5 refactored): @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * C# (GenericHost): @devhl-labs\n   * C# (HttpClient): @Blackclaws\n   * Clojure: @xhh\n   * Crystal: @wing328\n   * Dart: @yissachar\n   * Dart (refactor): @joernahrens\n   * Dart 2: @swipesight\n   * Dart (Jaguar): @jaumard\n   * Dart (Dio): @josh-burton\n   * Elixir: @niku\n   * Elm: @eriktim\n   * Eiffel: @jvelilla\n   * Erlang: @tsloughter\n   * Erlang (PropEr): @jfacorro @robertoaloi\n   * Groovy: @victorgit\n   * Go: @wing328 [:heart:](https://www.patreon.com/wing328)\n   * Go (rewritten in 2.3.0): @antihax\n   * Godot (GDScript): @Goutte [:heart:](https://liberapay.com/Goutte)\n   * Haskell (http-client): @jonschoning\n   * Java (Feign): @davidkiss\n   * Java (Retrofit): @0legg\n   * Java (Retrofit2): @emilianobonassi\n   * Java (Jersey2): @xhh\n   * Java (okhttp-gson): @xhh\n   * Java (RestTemplate): @nbruno\n   * Java (Spring 5 WebClient): @daonomic\n   * Java (Spring 6 RestClient): @nicklas2751\n   * Java (RESTEasy): @gayathrigs\n   * Java (Vertx): @lopesmcc\n   * Java (Google APIs Client Library): @charlescapps\n   * Java (Rest-assured): @viclovsky\n   * Java (Java 11 Native HTTP client): @bbdouglas\n   * Java (Apache HttpClient 5.x): @harrywhite4 @andrevegas\n   * Java (Helidon): @spericas @tjquinno @tvallin\n   * Javascript/NodeJS: @jfiala\n   * JavaScript (Apollo DataSource): @erithmetic\n   * JavaScript (Closure-annotated Angular) @achew22\n   * JavaScript (Flow types) @jaypea\n   * Jetbrains HTTP Client : @jlengrand\n   * JMeter: @davidkiss\n   * Julia: @tanmaykm\n   * Kotlin: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * Kotlin (MultiPlatform): @andrewemery\n   * Kotlin (Volley): @alisters\n   * Kotlin (jvm-spring-webclient): @stefankoppier\n   * Kotlin (jvm-spring-restclient): @stefankoppier\n   * Lua: @daurnimator\n   * N4JS: @mmews-n4\n   * Nim: @hokamoto\n   * OCaml: @cgensoul\n   * Perl: @wing328 [:heart:](https://www.patreon.com/wing328)\n   * PHP (Guzzle): @baartosz\n   * PHP (with Data Transfer): @Articus\n   * PowerShell: @beatcracker\n   * PowerShell (refactored in 5.0.0): @wing328\n   * Python: @spacether [:heart:][spacether sponsorship]\n   * Python-Experimental: @spacether [:heart:][spacether sponsorship]\n   * Python (refactored in 7.0.0): @wing328\n   * R: @ramnov\n   * Ruby (Faraday): @meganemura @dkliban\n   * Ruby (HTTPX): @honeyryderchuck\n   * Rust: @farcaller\n   * Rust (rust-server): @metaswitch\n   * Scala (scalaz & http4s): @tbrown1979\n   * Scala (Akka): @cchafer\n   * Scala (sttp): @chameleon82\n   * Scala (sttp4): @flsh86\n   * Scala (scala-sttp4-jsoniter): @lbialy\n   * Scala (Pekko): @mickaelmagniez\n   * Scala (http4s): @JennyLeahy\n   * Swift: @tkqubo\n   * Swift 3: @hexelon\n   * Swift 4: @ehyche\n   * Swift 5: @4brunu\n   * Swift 6: @4brunu\n   * Swift Combine: @dydus0x14\n   * TypeScript (Angular1): @mhardorf\n   * TypeScript (Angular2): @roni-frantchi\n   * TypeScript (Angular6): @akehir\n   * TypeScript (Angular7): @topce\n   * TypeScript (Axios): @nicokoenig\n   * TypeScript (Fetch): @leonyu\n   * TypeScript (Inversify): @gualtierim\n   * TypeScript (jQuery): @bherila\n   * TypeScript (Nestjs): @vfrank66\n   * TypeScript (Node):  @mhardorf\n   * TypeScript (Rxjs): @denyo\n   * TypeScript (redux-query): @petejohansonxo\n   * Xojo: @Topheee\n   * Zapier: @valmoz, @emajo\n * Server Stubs\n   * Ada: @stcarrez\n   * C# ASP.NET 5: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * C# ASP.NET Core 3.0: @A-Joshi\n   * C# APS.NET Core 3.1: @phatcher\n   * C# Azure functions: @Abrhm7786\n   * C# NancyFX: @mstefaniuk\n   * C++ (Qt5 QHttpEngine): @etherealjoy\n   * C++ Oat++: @Kraust\n   * C++ Pistache: @sebymiano\n   * C++ Restbed: @stkrwork\n   * Erlang Server: @galaxie @nelsonvides\n   * F# (Giraffe) Server: @nmfisher\n   * Go Server: @guohuang\n   * Go Server (refactored in 7.0.0): @lwj5\n   * Go (Echo) Server: @ph4r5h4d\n   * Go (Gin) Server: @kemokemo\n   * GraphQL Express Server: @renepardon\n   * Haskell Servant: @algas\n   * Haskell Yesod: @yotsuya\n   * Java Camel: @carnevalegiacomo\n   * Java Dubbo: @redoom\n   * Java MSF4J: @sanjeewa-malalgoda\n   * Java Spring Boot: @diyfr\n   * Java Undertow: @stevehu\n   * Java Play Framework: @JFCote\n   * Java PKMST: @anshu2185 @sanshuman @rkumar-pk @ninodpillai\n   * Java Vert.x: @lwlee2608\n   * Java Micronaut: @andriy-dmytruk\n   * Java Helidon: @spericas @tjquinno @tvallin\n   * Java WireMock: [@acouvreur](https://github.com/acouvreur)\n   * JAX-RS RestEasy: @chameleon82\n   * JAX-RS CXF: @hiveship\n   * JAX-RS CXF (CDI): @nickcmaynard\n   * JAX-RS RestEasy (JBoss EAP): @jfiala\n   * Julia: @tanmaykm\n   * Kotlin: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * Kotlin (Spring Boot): @dr4ke616\n   * Kotlin (Vertx): @Wooyme\n   * Kotlin (JAX-RS): @anttileppa\n   * Kotlin Misk: @andrewwilsonnew @guiarn\n   * Kotlin WireMock: @stefankoppier\n   * NodeJS Express: @YishTish\n   * PHP Flight: @daniel-sc\n   * PHP Laravel: @renepardon\n   * PHP Laravel (refactor in 7.12.0): @gijs-blanken\n   * PHP Lumen: @abcsun\n   * PHP Mezzio (with Path Handler): @Articus\n   * PHP Slim: @jfastnacht\n   * PHP Slim4: [@ybelenko](https://github.com/ybelenko)\n   * PHP Symfony: @ksm2\n   * PHP Symfony6: @BenjaminHae\n   * Python FastAPI: @krjakbrjak\n   * Python AIOHTTP:\n   * Ruby on Rails 5: @zlx\n   * Rust (rust-server): @metaswitch\n   * Rust (rust-axum): @linxGnu\n   * Scala Akka: @Bouillie\n   * Scala Cask: @aaronp\n   * Scala Finch: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * Scala Lagom: @gmkumar2005\n   * Scala Play: @adigerber\n   * TypeScript NestJS: @aryobenholzner\n * Documentation\n   * AsciiDoc: @man-at-home\n   * HTML Doc 2: @jhitchcock\n   * Confluence Wiki: @jhitchcock\n   * PlantUML: @pburls\n * Configuration\n   * Apache2: @stkrwork\n   * k6: @mostafa\n * Schema\n   * Avro: @sgadouar\n   * GraphQL: @wing328 [:heart:](https://www.patreon.com/wing328)\n   * Ktorm: @Luiz-Monad\n   * MySQL: [@ybelenko](https://github.com/ybelenko)\n   * PostgreSQL: [@iri](https://github.com/iri)\n   * Postman Collection: @gcatanese\n   * Protocol Buffer: @wing328\n   * WSDL: @adessoDpd\n\n:heart: = Link to support the contributor directly\n\n#### How to join the core team\n\nHere are the requirements to become a core team member:\n- rank within top 50 in https://github.com/openapitools/openapi-generator/graphs/contributors\n  - to contribute, here are some good [starting points](https://github.com/openapitools/openapi-generator/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)\n- regular contributions to the project\n  - about 3 hours per week\n  - for contribution, it can be addressing issues, reviewing PRs submitted by others, submitting PR to fix bugs or make enhancements, etc\n  - must be active in the past 3 months at the time of application\n\n To join the core team, please reach out to team@openapitools.org for more information.\n\n To become a Template Creator, simply submit a PR for new API client (e.g. Rust, Elixir) or server stub (e.g. Ruby Grape) generator.\n\n### [6.2 - OpenAPI Generator Technical Committee](#table-of-contents)\n\nMembers of the OpenAPI Generator technical committee shoulder the following responsibilities:\n\n- Provides guidance and direction to other users\n- Reviews pull requests and issues\n- Improves the generator by making enhancements, fixing bugs or updating documentations\n- Sets the technical direction of the generator\n\nWho is eligible? Those who want to join must have at least 3 PRs merged into a generator. (Exceptions can be granted to template creators or contributors who have made a lot of code changes with less than 3 merged PRs)\n\nIf you want to join the committee, please kindly apply by sending an email to team@openapitools.org with your Github ID.\n\n#### Members of Technical Committee\n\n| Languages/Generators  | Member (join date)                                                                                                                                                                                                                                    |\n|:----------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| ActionScript          |                                                                                                                                                                                                                                                       |\n| Ada                   | @stcarrez (2018/02) @michelealbano (2018/02)                                                                                                                                                                                                          |\n| Android               | @jaz-ah (2017/09)                                                                                                                                                                                                                                     |\n| Apex                  |                                                                                                                                                                                                                                                       |\n| Bash                  | @frol (2017/07) @bkryza (2017/08) @kenjones-cisco (2017/09)                                                                                                                                                                                           |\n| C                     | @zhemant (2018/11) @ityuhui (2019/12) @michelealbano (2020/03) @eafer (2024/12)                                                                                                                                                                                        |\n| C++                   | @ravinikam (2017/07) @stkrwork (2017/07) @etherealjoy (2018/02) @martindelille (2018/03) @muttleyxd (2019/08) @aminya (2025/05)                                                                                                                                         |\n| C#                    | @mandrean (2017/08) @shibayan (2020/02) @Blackclaws (2021/03) @lucamazzanti (2021/05) @iBicha (2023/07)                                                                                                                                          |\n| Clojure               |                                                                                                                                                                                                                                                       |\n| Crystal               | @cyangle (2021/01)                                                                                                                                                                                                                                    |\n| Dart                  | @jaumard (2018/09) @josh-burton (2019/12) @amondnet (2019/12) @sbu-WBT (2020/12) @kuhnroyal (2020/12) @agilob (2020/12) @ahmednfwela (2021/08)                                                                                                        |\n| Eiffel                | @jvelilla (2017/09)                                                                                                                                                                                                                                   |\n| Elixir                | @mrmstn (2018/12)                                                                                                                                                                                                                                     |\n| Elm                   | @eriktim (2018/09)                                                                                                                                                                                                                                    |\n| Erlang                | @tsloughter (2017/11) @jfacorro (2018/10) @robertoaloi (2018/10) @nelsonvides (2024/09)                                                                                                                                                               |\n| F#                    | @nmfisher (2019/05)                                                                                                                                                                                                                                   |\n| Go                    | @antihax (2017/11) @grokify (2018/07) @kemokemo (2018/09) @jirikuncar (2021/01) @ph4r5h4d (2021/04) @lwj5 (2023/04)                                                                                                                                                   |\n| GraphQL               | @renepardon (2018/12)                                                                                                                                                                                                                                 |\n| Groovy                |                                                                                                                                                                                                                                                       |\n| Haskell               |                                                                                                                                                                                                                                                       |\n| Java                  | @bbdouglas (2017/07) @sreeshas (2017/08) @jfiala (2017/08) @lukoyanov (2017/09) @cbornet (2017/09) @jeff9finger (2018/01) @karismann (2019/03) @Zomzog (2019/04) @lwlee2608 (2019/10) @martin-mfg (2023/08)                                                                 |\n| Java Spring           | @cachescrubber (2022/02) @welshm (2022/02) @MelleD (2022/02) @atextor (2022/02) @manedev79 (2022/02) @javisst (2022/02) @borsch (2022/02) @banlevente (2022/02) @Zomzog (2022/09) @martin-mfg (2023/08)                                                                     |\n| JMeter                | @kannkyo (2021/01)                                                                                                                                                                                                                                    |\n| Jetbrains HTTP Client | @jlengrand (2023/01)                                                                                                                                                                                                                                  |\n| Julia                 | @tanmaykm (2023/01)                                                                                                                                                                                                                                   |\n| Kotlin                | @karismann (2019/03) @Zomzog (2019/04) @andrewemery (2019/10) @4brunu (2019/11) @yutaka0m (2020/03) @stefankoppier (2022/06) @e5l (2024/10)                                          |\n| Lua                   | @daurnimator (2017/08)                                                                                                                                                                                                                                |\n| N4JS                  | @mmews-n4 (2023/03)                                                                                                                                                                                      |\n| Nim                   |                                                                                                                                                                                                                                                       |\n| NodeJS/Javascript     | @CodeNinjai (2017/07) @frol (2017/07) @cliffano (2017/07)                                                                                                                                                                                             |\n| ObjC                  |                                                                                                                                                                                                                                                       |\n| OCaml                 | @cgensoul (2019/08), @sir4ur0n (2025/08)                                                                                                                                                                                                              |\n| Perl                  | @wing328 (2017/07) [:heart:](https://www.patreon.com/wing328) @yue9944882 (2019/06)                                                                                                                                                                   |\n| PHP                   | @jebentier (2017/07), @dkarlovi (2017/07), @mandrean (2017/08), @jfastnacht (2017/09), [@ybelenko](https://github.com/ybelenko) (2018/07), @renepardon (2018/12)                                                                                      |\n| PowerShell            | @wing328 (2020/05)                                                                                                                                                                                                                                    |\n| Python                | @cbornet (2017/09) @tomplus (2018/10) @krjakbrjak (2023/02) @fa0311 (2023/10) @multani (2023/10) |\n| R                     | @Ramanth (2019/07) @saigiridhar21 (2019/07)                                                                                                                                                                                                           |\n| Ruby                  | @cliffano (2017/07) @zlx (2017/09) @autopp (2019/02)                                                                                                                                                                                                  |\n| Rust                  | @frol (2017/07) @farcaller (2017/08) @richardwhiuk (2019/07) @paladinzh (2020/05) @jacob-pro (2022/10) @dsteeley (2025/07)                                                                                                                                               |\n| Scala                 | @clasnake (2017/07), @shijinkui  (2018/01), @ramzimaalej (2018/03), @chameleon82 (2020/03), @Bouillie (2020/04) @fish86 (2023/06)                                                               |\n| Swift                 | @jgavris (2017/07) @ehyche (2017/08) @Edubits (2017/09) @jaz-ah (2017/09) @4brunu (2019/11) @dydus0x14 (2023/06)                                                                                                                                                           |\n| TypeScript            | @TiFu (2017/07) @taxpon (2017/07) @sebastianhaas (2017/07) @kenisteward (2017/07) @Vrolijkx (2017/09) @macjohnny (2018/01) @topce (2018/10) @akehir (2019/07) @petejohansonxo (2019/11) @amakhrov (2020/02) @davidgamero (2022/03) @mkusaka (2022/04) @joscha (2024/10)    |\n| Xojo                  | @Topheee (2023/04)                                                                                                                                                                                                                                    |\n\n\nPast Members of Technical Committee:\n| Languages/Generators         | Member (join date)                                                                                                                                                                                                                |\n| :---------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Python            | @taxpon (2017/07) @frol (2017/07) @mbohlool (2017/07) @cbornet (2017/09) @kenjones-cisco (2017/11) @tomplus (2018/10) @arun-nalla (2019/11)  |\n\n\n:heart: = Link to support the contributor directly\n\n### [6.3 - History of OpenAPI Generator](#table-of-contents)\n\nOpenAPI Generator is a fork of [Swagger Codegen](https://github.com/swagger-api/swagger-codegen). In view of the issues with the Swagger Codegen 3.0.0 (beta) release and the disagreement on the project's direction, more than 40 top contributors and template creators of Swagger Codegen decided to fork Swagger Codegen and maintain a community-driven version called \"OpenAPI Generator\". Please refer to the [Q&A](docs/qna.md) for more information.\n\n#### Founding Members (alphabetical order):\n\n- [Akihito Nakano](https://github.com/ackintosh)\n- [Artem Ocheredko](https://github.com/galaxie)\n- [Arthur Mogliev](https://github.com/Articus)\n- [Bartek Kryza](https://github.com/bkryza)\n- [Ben Wells](https://github.com/bvwells)\n- [Benjamin Gill](https://github.com/bjgill)\n- [Christophe Bornet](https://github.com/cbornet)\n- [Cliffano Subagio](https://github.com/cliffano)\n- [Daiki Matsudate](https://github.com/d-date)\n- [Daniel](https://github.com/Danielku15)\n- [Emiliano Bonassi](https://github.com/emilianobonassi)\n- [Erik Timmers](https://github.com/eriktim)\n- [Esteban Gehring](https://github.com/macjohnny)\n- [Gustavo Paz](https://github.com/gustavoapaz)\n- [Javier Velilla](https://github.com/jvelilla)\n- [Jean-Fran√ßois C√¥t√©](https://github.com/JFCote)\n- [Jim Schubert](https://github.com/jimschubert)\n- [Jon Schoning](https://github.com/jonschoning)\n- [J√©r√©mie Bresson](https://github.com/jmini) [:heart:](https://www.patreon.com/jmini)\n- [J√∂rn Ahrens](https://github.com/jayearn)\n- [Keni Steward](https://github.com/kenisteward)\n- [Marcin Stefaniuk](https://github.com/mstefaniuk)\n- [Martin Delille](https://github.com/MartinDelille)\n- [Masahiro Yamauchi](https://github.com/algas)\n- [Michele Albano](https://github.com/michelealbano)\n- [Ramzi Maalej](https://github.com/ramzimaalej)\n- [Ravindra Nikam](https://github.com/ravinikam)\n- [Ricardo Cardona](https://github.com/ricardona)\n- [Sebastian Haas](https://github.com/sebastianhaas)\n- [Sebastian Mandrean](https://github.com/mandrean)\n- [Sreenidhi Sreesha](https://github.com/sreeshas)\n- [Stefan Krismann](https://github.com/stkrwork)\n- [Stephane Carrez](https://github.com/stcarrez)\n- [Takuro Wada](https://github.com/taxpon)\n- [Tomasz Prus](https://github.com/tomplus)\n- [Tristan Sloughter](https://github.com/tsloughter)\n- [Victor Orlovsky](https://github.com/viclovsky)\n- [Victor Trakhtenberg](https://github.com/victorgit)\n- [Vlad Frolov](https://github.com/frol)\n- [Vladimir Pouzanov](https://github.com/farcaller)\n- [William Cheng](https://github.com/wing328)\n- [Xin Meng](https://github.com/xmeng1) [:heart:](https://www.patreon.com/user/overview?u=16435385)\n- [Xu Hui Hui](https://github.com/xhh)\n- [antihax](https://github.com/antihax)\n- [beatcracker](https://github.com/beatcracker)\n- [daurnimator](https:/github.com/daurnimator)\n- [etherealjoy](https://github.com/etherealjoy)\n- [jfiala](https://github.com/jfiala)\n- [lukoyanov](https://github.com/lukoyanov)\n\n:heart: = Link to support the contributor directly\n\n## [7 - License](#table-of-contents)\n-------\n\nCopyright 2018 OpenAPI-Generator Contributors (https://openapi-generator.tech)\nCopyright 2018 SmartBear Software\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at [apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n---\n",
      "stars_today": 8
    },
    {
      "id": 132145189,
      "name": "golangci-lint",
      "full_name": "golangci/golangci-lint",
      "description": "Fast linters runner for Go",
      "html_url": "https://github.com/golangci/golangci-lint",
      "stars": 18349,
      "forks": 1535,
      "language": "Go",
      "topics": [
        "ci",
        "go",
        "golang",
        "golangci-lint",
        "linter"
      ],
      "created_at": "2018-05-04T13:41:15Z",
      "updated_at": "2026-01-22T23:45:11Z",
      "pushed_at": "2026-01-22T21:29:49Z",
      "open_issues": 114,
      "owner": {
        "login": "golangci",
        "avatar_url": "https://avatars.githubusercontent.com/u/35628013?v=4"
      },
      "readme": "<p align=\"center\">\n  <img alt=\"golangci-lint logo\" src=\"assets/go.png\" height=\"150\" />\n  <h3 align=\"center\">golangci-lint</h3>\n  <p align=\"center\">Fast linters runner for Go</p>\n</p>\n\n---\n\n`golangci-lint` is a fast Go linters runner.\n\nIt runs linters in parallel, uses caching, supports YAML configuration,\nintegrates with all major IDEs, and includes over a hundred linters.\n\n## Install `golangci-lint`\n\n- [On my machine](https://golangci-lint.run/docs/welcome/install/local);\n- [On CI/CD systems](https://golangci-lint.run/docs/welcome/install/ci).\n\n## Documentation\n\nDocumentation is hosted at https://golangci-lint.run.\n\n## Social Networks\n\n[![Join Slack](https://img.shields.io/badge/Slack-4285F4?logo=slack&logoColor=white)](https://gophers.slack.com/archives/CS0TBRKPC)\n[![Follow on Mastodon](https://img.shields.io/badge/Mastodon-6364FF?logo=mastodon&logoColor=white)](https://fosstodon.org/@golangcilint)\n[![Follow on Bluesky](https://img.shields.io/badge/Bluesky-0a7aff?logo=bluesky&logoColor=white)](https://bsky.app/profile/golangci-lint.run)\n[![Follow on Twitter](https://img.shields.io/badge/Twitter-1DA1F2?logo=x&logoColor=white)](https://twitter.com/golangci)\n\n## Support Us\n\n`golangci-lint` is a free and open-source project built by volunteers.\n\nIf you value it, consider supporting us, we appreciate it! :heart:\n\n[![Golangci-lint](https://img.shields.io/badge/Support-golangci_lint-blue?style=for-the-badge)](https://donate.golangci.org)\n[![Linter Authors](https://img.shields.io/badge/Support-Linter_Authors-blue?style=for-the-badge)](https://golangci-lint.run/docs/product/thanks/)\n\n## Badges\n\n![Build Status](https://github.com/golangci/golangci-lint/workflows/CI/badge.svg)\n[![License](https://img.shields.io/github/license/golangci/golangci-lint)](/LICENSE)\n[![Release](https://img.shields.io/github/release/golangci/golangci-lint.svg)](https://github.com/golangci/golangci-lint/releases/latest)\n[![Docker](https://img.shields.io/docker/pulls/golangci/golangci-lint)](https://hub.docker.com/r/golangci/golangci-lint)\n[![GitHub Releases Stats of golangci-lint](https://img.shields.io/github/downloads/golangci/golangci-lint/total.svg?logo=github)](https://somsubhra.github.io/github-release-stats/?username=golangci&repository=golangci-lint)\n\n## Contributors\n\nThis project exists thanks to all the people who contribute. [How to contribute](https://golangci-lint.run/docs/contributing/).\n\n<a href=\"https://github.com/golangci/golangci-lint/graphs/contributors\">\n  <img src=\"https://opencollective.com/golangci-lint/contributors.svg?width=890&button=false&skip=golangcidev,CLAassistant,renovate,fossabot,golangcibot,kortschak,golangci-releaser,dependabot%5Bbot%5D\" />\n</a>\n\n## Sponsors\n\n<p>&nbsp;</p>\n<p float=\"left\">\n  <a href=\"https://www.jetbrains.com/go/?utm_source=OSS&utm_medium=referral&utm_campaign=golangci\" target=\"_blank\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"assets/goland-white.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"assets/goland.svg\">\n      <img alt=\"The complete IDE crafted for professional Go developers.\" src=\"assets/goland.svg\" width=\"150\" />\n    </picture>\n  </a>\n</p>\n\n## Stargazers over time\n\n[![Stargazers over time](https://starchart.cc/golangci/golangci-lint.svg?variant=adaptive)](https://starchart.cc/golangci/golangci-lint)\n",
      "stars_today": 8
    },
    {
      "id": 248400799,
      "name": "LibChecker",
      "full_name": "LibChecker/LibChecker",
      "description": "An app to view libraries used in apps in your device.",
      "html_url": "https://github.com/LibChecker/LibChecker",
      "stars": 6479,
      "forks": 405,
      "language": "Kotlin",
      "topics": [
        "android",
        "f-droid",
        "fdroid",
        "kotlin"
      ],
      "created_at": "2020-03-19T03:21:14Z",
      "updated_at": "2026-01-22T13:29:37Z",
      "pushed_at": "2026-01-21T11:23:25Z",
      "open_issues": 26,
      "owner": {
        "login": "LibChecker",
        "avatar_url": "https://avatars.githubusercontent.com/u/116417672?v=4"
      },
      "readme": "# LibChecker\n\n[![Android CI](https://github.com/LibChecker/LibChecker/actions/workflows/android.yml/badge.svg)](https://github.com/LibChecker/LibChecker/actions/workflows/android.yml)\n[![License](https://img.shields.io/github/license/LibChecker/LibChecker?label=License)](https://choosealicense.com/licenses/apache-2.0/)\n[![Discussion](https://img.shields.io/badge/Telegram-Group-blue.svg?logo=telegram)](https://t.me/libcheckerr)\n[![Crowdin](https://badges.crowdin.net/libchecker/localized.svg)](https://crowdin.com/project/libchecker)\n\n![Header](./source/header.png)\n\n## What's this?\nThis app is used to view the third-party libraries used by applications in your device. It can view the ABI architecture of the application's native library (in general, whether the application is 64-bit or 32-bit). It can also view well-known libraries marked by the rules repository on [GitHub](https://github.com/LibChecker/LibChecker-Rules) or [GitLab](https://gitlab.com/zhaobozhen/LibChecker-Rules), and can even sort and view them according to the number of libraries references.\n\n## Supported versions\nAndroid 7.0 ~ 16\n\nAndroid 6 [Marshmallow](https://github.com/LibChecker/LibChecker/tree/marshmallow)\n\n## Document\n[LibChecker-Docs](https://github.com/LibChecker/LibChecker-Docs)\n\n## Download\n<!-- [<img src=\"./source/coolapk-badge.png\" width=\"323\" height=\"125\" />](https://www.coolapk.com/apk/com.absinthe.libchecker) -->\n[<img src=\"https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png\" width=\"323\" height=\"125\" />](https://play.google.com/store/apps/details?id=com.absinthe.libchecker)\n[<img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" width=\"323\" height=\"125\" />](https://f-droid.org/packages/com.absinthe.libchecker/)\n[<img src=\"https://gitlab.com/IzzyOnDroid/repo/-/raw/master/assets/IzzyOnDroid.png\" width=\"323\" height=\"125\" />](https://apt.izzysoft.de/fdroid/index/apk/com.absinthe.libchecker)\n\n## Discussions\n[Github Discussions](https://github.com/LibChecker/LibChecker/discussions)\n\n### Telegram Group\n<img src=\"./source/tg_group_dark.png#gh-dark-mode-only\" width=\"240\" height=\"240\" />\n<img src=\"./source/tg_group_light.png#gh-light-mode-only\" width=\"240\" height=\"240\" />\n",
      "stars_today": 8
    },
    {
      "id": 907869862,
      "name": "mcp-grafana",
      "full_name": "grafana/mcp-grafana",
      "description": "MCP server for Grafana",
      "html_url": "https://github.com/grafana/mcp-grafana",
      "stars": 2162,
      "forks": 239,
      "language": "Go",
      "topics": [],
      "created_at": "2024-12-24T15:44:23Z",
      "updated_at": "2026-01-22T20:09:24Z",
      "pushed_at": "2026-01-22T16:28:41Z",
      "open_issues": 68,
      "owner": {
        "login": "grafana",
        "avatar_url": "https://avatars.githubusercontent.com/u/7195757?v=4"
      },
      "readme": "# Grafana MCP server\n\n[![Unit Tests](https://github.com/grafana/mcp-grafana/actions/workflows/unit.yml/badge.svg)](https://github.com/grafana/mcp-grafana/actions/workflows/unit.yml)\n[![Integration Tests](https://github.com/grafana/mcp-grafana/actions/workflows/integration.yml/badge.svg)](https://github.com/grafana/mcp-grafana/actions/workflows/integration.yml)\n[![E2E Tests](https://github.com/grafana/mcp-grafana/actions/workflows/e2e.yml/badge.svg)](https://github.com/grafana/mcp-grafana/actions/workflows/e2e.yml)\n[![Go Reference](https://pkg.go.dev/badge/github.com/grafana/mcp-grafana.svg)](https://pkg.go.dev/github.com/grafana/mcp-grafana)\n[![MCP Catalog](https://archestra.ai/mcp-catalog/api/badge/quality/grafana/mcp-grafana)](https://archestra.ai/mcp-catalog/grafana__mcp-grafana)\n\nA [Model Context Protocol][mcp] (MCP) server for Grafana.\n\nThis provides access to your Grafana instance and the surrounding ecosystem.\n\n## Requirements\n\n- **Grafana version 9.0 or later** is required for full functionality. Some features, particularly datasource-related operations, may not work correctly with earlier versions due to missing API endpoints.\n\n## Features\n\n_The following features are currently available in MCP server. This list is for informational purposes only and does not represent a roadmap or commitment to future features._\n\n### Dashboards\n\n- **Search for dashboards:** Find dashboards by title or other metadata\n- **Get dashboard by UID:** Retrieve full dashboard details using its unique identifier. _Warning: Large dashboards can consume significant context window space._\n- **Get dashboard summary:** Get a compact overview of a dashboard including title, panel count, panel types, variables, and metadata without the full JSON to minimize context window usage\n- **Get dashboard property:** Extract specific parts of a dashboard using JSONPath expressions (e.g., `$.title`, `$.panels[*].title`) to fetch only needed data and reduce context window consumption\n- **Update or create a dashboard:** Modify existing dashboards or create new ones. _Warning: Requires full dashboard JSON which can consume large amounts of context window space._\n- **Patch dashboard:** Apply specific changes to a dashboard without requiring the full JSON, significantly reducing context window usage for targeted modifications\n- **Get panel queries and datasource info:** Get the title, query string, and datasource information (including UID and type, if available) from every panel in a dashboard\n\n#### Context Window Management\n\nThe dashboard tools now include several strategies to manage context window usage effectively ([issue #101](https://github.com/grafana/mcp-grafana/issues/101)):\n\n- **Use `get_dashboard_summary`** for dashboard overview and planning modifications\n- **Use `get_dashboard_property`** with JSONPath when you only need specific dashboard parts\n- **Avoid `get_dashboard_by_uid`** unless you specifically need the complete dashboard JSON\n\n### Datasources\n\n- **List and fetch datasource information:** View all configured datasources and retrieve detailed information about each.\n  - _Supported datasource types: Prometheus, Loki._\n\n### Prometheus Querying\n\n- **Query Prometheus:** Execute PromQL queries (supports both instant and range metric queries) against Prometheus datasources.\n- **Query Prometheus metadata:** Retrieve metric metadata, metric names, label names, and label values from Prometheus datasources.\n\n### Loki Querying\n\n- **Query Loki logs and metrics:** Run both log queries and metric queries using LogQL against Loki datasources.\n- **Query Loki metadata:** Retrieve label names, label values, and stream statistics from Loki datasources.\n\n### Incidents\n\n- **Search, create, and update incidents:** Manage incidents in Grafana Incident, including searching, creating, and adding activities to incidents.\n\n### Sift Investigations\n\n- **List Sift investigations:** Retrieve a list of Sift investigations, with support for a limit parameter.\n- **Get Sift investigation:** Retrieve details of a specific Sift investigation by its UUID.\n- **Get Sift analyses:** Retrieve a specific analysis from a Sift investigation.\n- **Find error patterns in logs:** Detect elevated error patterns in Loki logs using Sift.\n- **Find slow requests:** Detect slow requests using Sift (Tempo).\n\n### Alerting\n\n- **List and fetch alert rule information:** View alert rules and their statuses (firing/normal/error/etc.) in Grafana. Supports both Grafana-managed rules and datasource-managed rules from Prometheus or Loki datasources.\n- **Create and update alert rules:** Create new alert rules or modify existing ones.\n- **Delete alert rules:** Remove alert rules by UID.\n- **List contact points:** View configured notification contact points in Grafana. Supports both Grafana-managed contact points and receivers from external Alertmanager datasources (Prometheus Alertmanager, Mimir, Cortex).\n\n### Grafana OnCall\n\n- **List and manage schedules:** View and manage on-call schedules in Grafana OnCall.\n- **Get shift details:** Retrieve detailed information about specific on-call shifts.\n- **Get current on-call users:** See which users are currently on call for a schedule.\n- **List teams and users:** View all OnCall teams and users.\n- **List alert groups:** View and filter alert groups from Grafana OnCall by various criteria including state, integration, labels, and time range.\n- **Get alert group details:** Retrieve detailed information about a specific alert group by its ID.\n\n### Admin\n\n> **Note:** Admin tools are **disabled by default**. To enable them, include `admin` in your `--enabled-tools` flag.\n- **List teams:** View all configured teams in Grafana.\n- **List Users:** View all users in an organization in Grafana.\n- **List all roles:** List all Grafana roles, with an optional filter for delegatable roles.\n- **Get role details:** Get details for a specific Grafana role by UID.\n- **List assignments for a role:** List all users, teams, and service accounts assigned to a role.\n- **List roles for users:** List all roles assigned to one or more users.\n- **List roles for teams:** List all roles assigned to one or more teams.\n- **List permissions for a resource:** List all permissions defined for a specific resource (dashboard, datasource, folder, etc.).\n- **Describe a Grafana resource:** List available permissions and assignment capabilities for a resource type.\n\n### Navigation\n\n- **Generate deeplinks:** Create accurate deeplink URLs for Grafana resources instead of relying on LLM URL guessing.\n  - **Dashboard links:** Generate direct links to dashboards using their UID (e.g., `http://localhost:3000/d/dashboard-uid`)\n  - **Panel links:** Create links to specific panels within dashboards with viewPanel parameter (e.g., `http://localhost:3000/d/dashboard-uid?viewPanel=5`)\n  - **Explore links:** Generate links to Grafana Explore with pre-configured datasources (e.g., `http://localhost:3000/explore?left={\"datasource\":\"prometheus-uid\"}`)\n  - **Time range support:** Add time range parameters to links (`from=now-1h&to=now`)\n  - **Custom parameters:** Include additional query parameters like dashboard variables or refresh intervals\n\n### Annotations\n\n- **Get Annotations:** Query annotations with filters. Supports time range, dashboard UID, tags, and match mode.\n- **Create Annotation:** Create a new annotation on a dashboard or panel.\n- **Create Graphite Annotation:** Create annotations using Graphite format (`what`, `when`, `tags`, `data`).\n- **Update Annotation:** Replace all fields of an existing annotation (full update).\n- **Patch Annotation:** Update only specific fields of an annotation (partial update).\n- **Get Annotation Tags:** List available annotation tags with optional filtering.\n\n### Rendering\n\n- **Get panel or dashboard image:** Render a Grafana dashboard panel or full dashboard as a PNG image. Returns the image as base64 encoded data for use in reports, alerts, or presentations. Supports customizing dimensions, time range, theme, scale, and dashboard variables.\n  - _Note: Requires the [Grafana Image Renderer](https://grafana.com/docs/grafana/latest/setup-grafana/image-rendering/) service to be installed and configured._\n\nThe list of tools is configurable, so you can choose which tools you want to make available to the MCP client.\nThis is useful if you don't use certain functionality or if you don't want to take up too much of the context window.\nTo disable a category of tools, use the `--disable-<category>` flag when starting the server. For example, to disable\nthe OnCall tools, use `--disable-oncall`, or to disable navigation deeplink generation, use `--disable-navigation`.\n\n\n#### RBAC Permissions\n\nEach tool requires specific RBAC permissions to function properly. When creating a service account for the MCP server, ensure it has the necessary permissions based on which tools you plan to use. The permissions listed are the minimum required actions - you may also need appropriate scopes (e.g., `datasources:*`, `dashboards:*`, `folders:*`) depending on your use case.\n\nTip: If you're not familiar with Grafana RBAC or you want a quicker, simpler setup instead of configuring many granular scopes, you can assign a built-in role such as `Editor` to the service account. The `Editor` role grants broad read/write access that will allow most MCP server operations; it is less granular (and therefore less restrictive) than manually-applied scopes, so use it only when convenience is more important than strict least-privilege access.\n\n**Note:** Grafana Incident and Sift tools use basic Grafana roles instead of fine-grained RBAC permissions:\n- **Viewer role:** Required for read-only operations (list incidents, get investigations)\n- **Editor role:** Required for write operations (create incidents, modify investigations)\n\nFor more information about Grafana RBAC, see the [official documentation](https://grafana.com/docs/grafana/latest/administration/roles-and-permissions/access-control/).\n\n#### RBAC Scopes\n\nScopes define the specific resources that permissions apply to. Each action requires both the appropriate permission and scope combination.\n\n**Common Scope Patterns:**\n\n- **Broad access:** Use `*` wildcards for organization-wide access\n\n  - `datasources:*` - Access to all datasources\n  - `dashboards:*` - Access to all dashboards\n  - `folders:*` - Access to all folders\n  - `teams:*` - Access to all teams\n\n- **Limited access:** Use specific UIDs or IDs to restrict access to individual resources\n  - `datasources:uid:prometheus-uid` - Access only to a specific Prometheus datasource\n  - `dashboards:uid:abc123` - Access only to dashboard with UID `abc123`\n  - `folders:uid:xyz789` - Access only to folder with UID `xyz789`\n  - `teams:id:5` - Access only to team with ID `5`\n  - `global.users:id:123` - Access only to user with ID `123`\n\n**Examples:**\n\n- **Full MCP server access:** Grant broad permissions for all tools\n\n  ```\n  datasources:* (datasources:read, datasources:query)\n  dashboards:* (dashboards:read, dashboards:create, dashboards:write)\n  folders:* (for dashboard creation and alert rules)\n  teams:* (teams:read)\n  global.users:* (users:read)\n  ```\n\n- **Limited datasource access:** Only query specific Prometheus and Loki instances\n\n  ```\n  datasources:uid:prometheus-prod (datasources:query)\n  datasources:uid:loki-prod (datasources:query)\n  ```\n\n- **Dashboard-specific access:** Read only specific dashboards\n  ```\n  dashboards:uid:monitoring-dashboard (dashboards:read)\n  dashboards:uid:alerts-dashboard (dashboards:read)\n  ```\n\n### Tools\n\n| Tool                              | Category    | Description                                                         | Required RBAC Permissions               | Required Scopes                                     |\n| --------------------------------- | ----------- | ------------------------------------------------------------------- | --------------------------------------- | --------------------------------------------------- |\n| `list_teams`                      | Admin       | List all teams                                                      | `teams:read`                            | `teams:*` or `teams:id:1`                           |\n| `list_users_by_org`               | Admin       | List all users in an organization                                   | `users:read`                            | `global.users:*` or `global.users:id:123`           |\n| `list_all_roles`          | Admin    | List all Grafana roles                              | `roles:read`              | `roles:*`                         |\n| `get_role_details`        | Admin    | Get details for a Grafana role                      | `roles:read`              | `roles:uid:editor`                |\n| `get_role_assignments`    | Admin    | List assignments for a role                         | `roles:read`              | `roles:uid:editor`                |\n| `list_user_roles`         | Admin    | List roles for users                                | `roles:read`              | `global.users:id:123`             |\n| `list_team_roles`         | Admin    | List roles for teams                                | `roles:read`              | `teams:id:7`                      |\n| `get_resource_permissions`| Admin    | List permissions for a resource                     | `permissions:read`        | `dashboards:uid:abcd1234`         |\n| `get_resource_description`| Admin    | Describe a Grafana resource type                    | `permissions:read`        | `dashboards:*`                    |\n| `search_dashboards`               | Search      | Search for dashboards                                               | `dashboards:read`                       | `dashboards:*` or `dashboards:uid:abc123`           |\n| `get_dashboard_by_uid`            | Dashboard   | Get a dashboard by uid                                              | `dashboards:read`                       | `dashboards:uid:abc123`                             |\n| `update_dashboard`                | Dashboard   | Update or create a new dashboard                                    | `dashboards:create`, `dashboards:write` | `dashboards:*`, `folders:*` or `folders:uid:xyz789` |\n| `get_dashboard_panel_queries`     | Dashboard   | Get panel title, queries, datasource UID and type from a dashboard  | `dashboards:read`                       | `dashboards:uid:abc123`                             |\n| `get_dashboard_property`          | Dashboard   | Extract specific parts of a dashboard using JSONPath expressions    | `dashboards:read`                       | `dashboards:uid:abc123`                             |\n| `get_dashboard_summary`           | Dashboard   | Get a compact summary of a dashboard without full JSON              | `dashboards:read`                       | `dashboards:uid:abc123`                             |\n| `list_datasources`                | Datasources | List datasources                                                    | `datasources:read`                      | `datasources:*`                                     |\n| `get_datasource_by_uid`           | Datasources | Get a datasource by uid                                             | `datasources:read`                      | `datasources:uid:prometheus-uid`                    |\n| `get_datasource_by_name`          | Datasources | Get a datasource by name                                            | `datasources:read`                      | `datasources:*` or `datasources:uid:loki-uid`       |\n| `query_prometheus`                | Prometheus  | Execute a query against a Prometheus datasource                     | `datasources:query`                     | `datasources:uid:prometheus-uid`                    |\n| `list_prometheus_metric_metadata` | Prometheus  | List metric metadata                                                | `datasources:query`                     | `datasources:uid:prometheus-uid`                    |\n| `list_prometheus_metric_names`    | Prometheus  | List available metric names                                         | `datasources:query`                     | `datasources:uid:prometheus-uid`                    |\n| `list_prometheus_label_names`     | Prometheus  | List label names matching a selector                                | `datasources:query`                     | `datasources:uid:prometheus-uid`                    |\n| `list_prometheus_label_values`    | Prometheus  | List values for a specific label                                    | `datasources:query`                     | `datasources:uid:prometheus-uid`                    |\n| `list_incidents`                  | Incident    | List incidents in Grafana Incident                                  | Viewer role                             | N/A                                                 |\n| `create_incident`                 | Incident    | Create an incident in Grafana Incident                              | Editor role                             | N/A                                                 |\n| `add_activity_to_incident`        | Incident    | Add an activity item to an incident in Grafana Incident             | Editor role                             | N/A                                                 |\n| `get_incident`                    | Incident    | Get a single incident by ID                                         | Viewer role                             | N/A                                                 |\n| `query_loki_logs`                 | Loki        | Query and retrieve logs using LogQL (either log or metric queries)  | `datasources:query`                     | `datasources:uid:loki-uid`                          |\n| `list_loki_label_names`           | Loki        | List all available label names in logs                              | `datasources:query`                     | `datasources:uid:loki-uid`                          |\n| `list_loki_label_values`          | Loki        | List values for a specific log label                                | `datasources:query`                     | `datasources:uid:loki-uid`                          |\n| `query_loki_stats`                | Loki        | Get statistics about log streams                                    | `datasources:query`                     | `datasources:uid:loki-uid`                          |\n| `list_alert_rules`                | Alerting    | List alert rules                                                    | `alert.rules:read`                      | `folders:*` or `folders:uid:alerts-folder`          |\n| `get_alert_rule_by_uid`           | Alerting    | Get alert rule by UID                                               | `alert.rules:read`                      | `folders:uid:alerts-folder`                         |\n| `create_alert_rule`               | Alerting    | Create a new alert rule                                             | `alert.rules:write`                     | `folders:*` or `folders:uid:alerts-folder`          |\n| `update_alert_rule`               | Alerting    | Update an existing alert rule                                       | `alert.rules:write`                     | `folders:uid:alerts-folder`                         |\n| `delete_alert_rule`               | Alerting    | Delete an alert rule by UID                                         | `alert.rules:write`                     | `folders:uid:alerts-folder`                         |\n| `list_contact_points`             | Alerting    | List notification contact points (Grafana-managed and Alertmanager) | `alert.notifications:read`              | Global scope                                        |\n| `list_oncall_schedules`           | OnCall      | List schedules from Grafana OnCall                                  | `grafana-oncall-app.schedules:read`     | Plugin-specific scopes                              |\n| `get_oncall_shift`                | OnCall      | Get details for a specific OnCall shift                             | `grafana-oncall-app.schedules:read`     | Plugin-specific scopes                              |\n| `get_current_oncall_users`        | OnCall      | Get users currently on-call for a specific schedule                 | `grafana-oncall-app.schedules:read`     | Plugin-specific scopes                              |\n| `list_oncall_teams`               | OnCall      | List teams from Grafana OnCall                                      | `grafana-oncall-app.user-settings:read` | Plugin-specific scopes                              |\n| `list_oncall_users`               | OnCall      | List users from Grafana OnCall                                      | `grafana-oncall-app.user-settings:read` | Plugin-specific scopes                              |\n| `list_alert_groups`               | OnCall      | List alert groups from Grafana OnCall with filtering options        | `grafana-oncall-app.alert-groups:read`  | Plugin-specific scopes                              |\n| `get_alert_group`                 | OnCall      | Get a specific alert group from Grafana OnCall by its ID            | `grafana-oncall-app.alert-groups:read`  | Plugin-specific scopes                              |\n| `get_sift_investigation`          | Sift        | Retrieve an existing Sift investigation by its UUID                 | Viewer role                             | N/A                                                 |\n| `get_sift_analysis`               | Sift        | Retrieve a specific analysis from a Sift investigation              | Viewer role                             | N/A                                                 |\n| `list_sift_investigations`        | Sift        | Retrieve a list of Sift investigations with an optional limit       | Viewer role                             | N/A                                                 |\n| `find_error_pattern_logs`         | Sift        | Finds elevated error patterns in Loki logs.                         | Editor role                             | N/A                                                 |\n| `find_slow_requests`              | Sift        | Finds slow requests from the relevant tempo datasources.            | Editor role                             | N/A                                                 |\n| `list_pyroscope_label_names`      | Pyroscope   | List label names matching a selector                                | `datasources:query`                     | `datasources:uid:pyroscope-uid`                     |\n| `list_pyroscope_label_values`     | Pyroscope   | List label values matching a selector for a label name              | `datasources:query`                     | `datasources:uid:pyroscope-uid`                     |\n| `list_pyroscope_profile_types`    | Pyroscope   | List available profile types                                        | `datasources:query`                     | `datasources:uid:pyroscope-uid`                     |\n| `fetch_pyroscope_profile`         | Pyroscope   | Fetches a profile in DOT format for analysis                        | `datasources:query`                     | `datasources:uid:pyroscope-uid`                     |\n| `get_assertions`                  | Asserts     | Get assertion summary for a given entity                            | Plugin-specific permissions             | Plugin-specific scopes                              |\n| `generate_deeplink`               | Navigation  | Generate accurate deeplink URLs for Grafana resources               | None (read-only URL generation)         | N/A                                                 |\n| `get_annotations`                 | Annotations | Fetch annotations with filters                                      | `annotations:read`                      | `annotations:*` or `annotations:id:123`             |\n| `create_annotation`               | Annotations | Create a new annotation on a dashboard or panel                     | `annotations:write`                     | `annotations:*`                                     |\n| `create_graphite_annotation`      | Annotations | Create an annotation using Graphite format                          | `annotations:write`                     | `annotations:*`                                     |\n| `update_annotation`               | Annotations | Replace all fields of an annotation (full update)                   | `annotations:write`                     | `annotations:*`                                     |\n| `patch_annotation`                | Annotations | Update only specific fields of an annotation (partial update)       | `annotations:write`                     | `annotations:*`                                     |\n| `get_annotation_tags`             | Annotations | List annotation tags with optional filtering                        | `annotations:read`                      | `annotations:*`                                     |\n| `get_panel_image`                 | Rendering   | Render a dashboard panel or full dashboard as a PNG image           | `dashboards:read`                       | `dashboards:uid:abc123`                             |\n\n## CLI Flags Reference\n\nThe `mcp-grafana` binary supports various command-line flags for configuration:\n\n**Transport Options:**\n- `-t, --transport`: Transport type (`stdio`, `sse`, or `streamable-http`) - default: `stdio`\n- `--address`: The host and port for SSE/streamable-http server - default: `localhost:8000`\n- `--base-path`: Base path for the SSE/streamable-http server\n- `--endpoint-path`: Endpoint path for the streamable-http server - default: `/`\n\n**Debug and Logging:**\n- `--debug`: Enable debug mode for detailed HTTP request/response logging\n\n**Tool Configuration:**\n- `--enabled-tools`: Comma-separated list of enabled categories - default: all categories except `admin`, to enable admin tools, add `admin` to the list (e.g., `\"search,datasource,...,admin\"`)\n- `--disable-search`: Disable search tools\n- `--disable-datasource`: Disable datasource tools\n- `--disable-incident`: Disable incident tools\n- `--disable-prometheus`: Disable prometheus tools\n- `--disable-write`: Disable write tools (create/update operations)\n- `--disable-loki`: Disable loki tools\n- `--disable-alerting`: Disable alerting tools\n- `--disable-dashboard`: Disable dashboard tools\n- `--disable-oncall`: Disable oncall tools\n- `--disable-asserts`: Disable asserts tools\n- `--disable-sift`: Disable sift tools\n- `--disable-admin`: Disable admin tools\n- `--disable-pyroscope`: Disable pyroscope tools\n- `--disable-navigation`: Disable navigation tools\n- `--disable-rendering`: Disable rendering tools (panel/dashboard image export)\n### Read-Only Mode\n\nThe `--disable-write` flag provides a way to run the MCP server in read-only mode, preventing any write operations to your Grafana instance. This is useful for scenarios where you want to provide safe, read-only access such as:\n\n- Using service accounts with limited read-only permissions\n- Providing AI assistants with observability data without modification capabilities\n- Running in production environments where write access should be restricted\n- Testing and development scenarios where you want to prevent accidental modifications\n\nWhen `--disable-write` is enabled, the following write operations are disabled:\n\n**Dashboard Tools:**\n- `update_dashboard`\n\n**Folder Tools:**\n- `create_folder`\n\n**Incident Tools:**\n- `create_incident`\n- `add_activity_to_incident`\n\n**Alerting Tools:**\n- `create_alert_rule`\n- `update_alert_rule`\n- `delete_alert_rule`\n\n**Annotation Tools:**\n- `create_annotation`\n- `create_graphite_annotation`\n- `update_annotation`\n- `patch_annotation`\n\n**Sift Tools:**\n- `find_error_pattern_logs` (creates investigations)\n- `find_slow_requests` (creates investigations)\n\nAll read operations remain available, allowing you to query dashboards, run PromQL/LogQL queries, list resources, and retrieve data.\n\n**Client TLS Configuration (for Grafana connections):**\n- `--tls-cert-file`: Path to TLS certificate file for client authentication\n- `--tls-key-file`: Path to TLS private key file for client authentication\n- `--tls-ca-file`: Path to TLS CA certificate file for server verification\n- `--tls-skip-verify`: Skip TLS certificate verification (insecure)\n\n**Server TLS Configuration (streamable-http transport only):**\n- `--server.tls-cert-file`: Path to TLS certificate file for server HTTPS\n- `--server.tls-key-file`: Path to TLS private key file for server HTTPS\n\n## Usage\n\nThis MCP server works with both local Grafana instances and Grafana Cloud. For Grafana Cloud, use your instance URL (e.g., `https://myinstance.grafana.net`) instead of `http://localhost:3000` in the configuration examples below.\n\n1. If using service account token authentication, create a service account in Grafana with enough permissions to use the tools you want to use,\n   generate a service account token, and copy it to the clipboard for use in the configuration file.\n   Follow the [Grafana service account documentation][service-account] for details on creating service account tokens.\n   Tip: If you're not comfortable configuring fine-grained RBAC scopes, a simpler (but less restrictive) option is to assign the built-in `Editor` role to the service account. This grants broad read/write access that covers most MCP server operations ‚Äî use it when convenience outweighs strict least-privilege requirements.\n\n   > **Note:** The environment variable `GRAFANA_API_KEY` is deprecated and will be removed in a future version. Please migrate to using `GRAFANA_SERVICE_ACCOUNT_TOKEN` instead. The old variable name will continue to work for backward compatibility but will show deprecation warnings.\n\n### Multi-Organization Support\n \nYou can specify which organization to interact with using either:\n\n- **Environment variable:** Set `GRAFANA_ORG_ID` to the numeric organization ID\n- **HTTP header:** Set `X-Grafana-Org-Id` when using SSE or streamable HTTP transports (header takes precedence over environment variable - meaning you can set a default org as well).\n\nWhen an organization ID is provided, the MCP server will set the `X-Grafana-Org-Id` header on all requests to Grafana, ensuring that operations are performed within the specified organization context.\n\n**Example with organization ID:**\n\n```json\n{\n  \"mcpServers\": {\n    \"grafana\": {\n      \"command\": \"mcp-grafana\",\n      \"args\": [],\n      \"env\": {\n        \"GRAFANA_URL\": \"http://localhost:3000\",\n        \"GRAFANA_USERNAME\": \"<your username>\",\n        \"GRAFANA_PASSWORD\": \"<your password>\",\n        \"GRAFANA_ORG_ID\": \"2\"\n      }\n    }\n  }\n}\n```\n\n2. You have several options to install `mcp-grafana`:\n\n   - **Docker image**: Use the pre-built Docker image from Docker Hub.\n\n     **Important**: The Docker image's entrypoint is configured to run the MCP server in SSE mode by default, but most users will want to use STDIO mode for direct integration with AI assistants like Claude Desktop:\n\n     1. **STDIO Mode**: For stdio mode you must explicitly override the default with `-t stdio` and include the `-i` flag to keep stdin open:\n\n     ```bash\n     docker pull grafana/mcp-grafana\n     # For local Grafana:\n     docker run --rm -i -e GRAFANA_URL=http://localhost:3000 -e GRAFANA_SERVICE_ACCOUNT_TOKEN=<your service account token> grafana/mcp-grafana -t stdio\n     # For Grafana Cloud:\n     docker run --rm -i -e GRAFANA_URL=https://myinstance.grafana.net -e GRAFANA_SERVICE_ACCOUNT_TOKEN=<your service account token> grafana/mcp-grafana -t stdio\n     ```\n\n     2. **SSE Mode**: In this mode, the server runs as an HTTP server that clients connect to. You must expose port 8000 using the `-p` flag:\n\n     ```bash\n     docker pull grafana/mcp-grafana\n     docker run --rm -p 8000:8000 -e GRAFANA_URL=http://localhost:3000 -e GRAFANA_SERVICE_ACCOUNT_TOKEN=<your service account token> grafana/mcp-grafana\n     ```\n\n     3. **Streamable HTTP Mode**: In this mode, the server operates as an independent process that can handle multiple client connections. You must expose port 8000 using the `-p` flag: For this mode you must explicitly override the default with `-t streamable-http`\n\n     ```bash\n     docker pull grafana/mcp-grafana\n     docker run --rm -p 8000:8000 -e GRAFANA_URL=http://localhost:3000 -e GRAFANA_SERVICE_ACCOUNT_TOKEN=<your service account token> grafana/mcp-grafana -t streamable-http\n     ```\n\n     For HTTPS streamable HTTP mode with server TLS certificates:\n\n     ```bash\n     docker pull grafana/mcp-grafana\n     docker run --rm -p 8443:8443 \\\n       -v /path/to/certs:/certs:ro \\\n       -e GRAFANA_URL=http://localhost:3000 \\\n       -e GRAFANA_SERVICE_ACCOUNT_TOKEN=<your service account token> \\\n       grafana/mcp-grafana \\\n       -t streamable-http \\\n       -addr :8443 \\\n       --server.tls-cert-file /certs/server.crt \\\n       --server.tls-key-file /certs/server.key\n     ```\n\n   - **Download binary**: Download the latest release of `mcp-grafana` from the [releases page](https://github.com/grafana/mcp-grafana/releases) and place it in your `$PATH`.\n\n   - **Build from source**: If you have a Go toolchain installed you can also build and install it from source, using the `GOBIN` environment variable\n     to specify the directory where the binary should be installed. This should also be in your `PATH`.\n\n     ```bash\n     GOBIN=\"$HOME/go/bin\" go install github.com/grafana/mcp-grafana/cmd/mcp-grafana@latest\n     ```\n\n   - **Deploy to Kubernetes using Helm**: use the [Helm chart from the Grafana helm-charts repository](https://github.com/grafana/helm-charts/tree/main/charts/grafana-mcp)\n\n     ```bash\n     helm repo add grafana https://grafana.github.io/helm-charts\n     helm install --set grafana.apiKey=<Grafana_ApiKey> --set grafana.url=<GrafanaUrl> my-release grafana/grafana-mcp\n     ```\n\n\n3. Add the server configuration to your client configuration file. For example, for Claude Desktop:\n\n   **If using the binary:**\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"grafana\": {\n         \"command\": \"mcp-grafana\",\n         \"args\": [],\n         \"env\": {\n           \"GRAFANA_URL\": \"http://localhost:3000\",  // Or \"https://myinstance.grafana.net\" for Grafana Cloud\n           \"GRAFANA_SERVICE_ACCOUNT_TOKEN\": \"<your service account token>\",\n           // If using username/password authentication\n           \"GRAFANA_USERNAME\": \"<your username>\",\n           \"GRAFANA_PASSWORD\": \"<your password>\",\n           // Optional: specify organization ID for multi-org support\n           \"GRAFANA_ORG_ID\": \"1\"\n         }\n       }\n     }\n   }\n   ```\n\n> Note: if you see `Error: spawn mcp-grafana ENOENT` in Claude Desktop, you need to specify the full path to `mcp-grafana`.\n\n**If using Docker:**\n\n```json\n{\n  \"mcpServers\": {\n    \"grafana\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\",\n        \"GRAFANA_URL\",\n        \"-e\",\n        \"GRAFANA_SERVICE_ACCOUNT_TOKEN\",\n        \"grafana/mcp-grafana\",\n        \"-t\",\n        \"stdio\"\n      ],\n      \"env\": {\n        \"GRAFANA_URL\": \"http://localhost:3000\",  // Or \"https://myinstance.grafana.net\" for Grafana Cloud\n        \"GRAFANA_SERVICE_ACCOUNT_TOKEN\": \"<your service account token>\",\n        // If using username/password authentication\n        \"GRAFANA_USERNAME\": \"<your username>\",\n        \"GRAFANA_PASSWORD\": \"<your password>\",\n        // Optional: specify organization ID for multi-org support\n        \"GRAFANA_ORG_ID\": \"1\"\n      }\n    }\n  }\n}\n```\n\n> Note: The `-t stdio` argument is essential here because it overrides the default SSE mode in the Docker image.\n\n**Using VSCode with remote MCP server**\n\nIf you're using VSCode and running the MCP server in SSE mode (which is the default when using the Docker image without overriding the transport), make sure your `.vscode/settings.json` includes the following:\n\n```json\n\"mcp\": {\n  \"servers\": {\n    \"grafana\": {\n      \"type\": \"sse\",\n      \"url\": \"http://localhost:8000/sse\"\n    }\n  }\n}\n```\n\nFor HTTPS streamable HTTP mode with server TLS certificates:\n\n```json\n\"mcp\": {\n  \"servers\": {\n    \"grafana\": {\n      \"type\": \"sse\",\n      \"url\": \"https://localhost:8443/sse\"\n    }\n  }\n}\n```\n\n### Debug Mode\n\nYou can enable debug mode for the Grafana transport by adding the `-debug` flag to the command. This will provide detailed logging of HTTP requests and responses between the MCP server and the Grafana API, which can be helpful for troubleshooting.\n\nTo use debug mode with the Claude Desktop configuration, update your config as follows:\n\n**If using the binary:**\n\n```json\n{\n  \"mcpServers\": {\n    \"grafana\": {\n      \"command\": \"mcp-grafana\",\n      \"args\": [\"-debug\"],\n      \"env\": {\n        \"GRAFANA_URL\": \"http://localhost:3000\",  // Or \"https://myinstance.grafana.net\" for Grafana Cloud\n        \"GRAFANA_SERVICE_ACCOUNT_TOKEN\": \"<your service account token>\"\n      }\n    }\n  }\n}\n```\n\n**If using Docker:**\n\n```json\n{\n  \"mcpServers\": {\n    \"grafana\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\",\n        \"GRAFANA_URL\",\n        \"-e\",\n        \"GRAFANA_SERVICE_ACCOUNT_TOKEN\",\n        \"grafana/mcp-grafana\",\n        \"-t\",\n        \"stdio\",\n        \"-debug\"\n      ],\n      \"env\": {\n        \"GRAFANA_URL\": \"http://localhost:3000\",  // Or \"https://myinstance.grafana.net\" for Grafana Cloud\n        \"GRAFANA_SERVICE_ACCOUNT_TOKEN\": \"<your service account token>\"\n      }\n    }\n  }\n}\n```\n\n> Note: As with the standard configuration, the `-t stdio` argument is required to override the default SSE mode in the Docker image.\n\n### TLS Configuration\n\nIf your Grafana instance is behind mTLS or requires custom TLS certificates, you can configure the MCP server to use custom certificates. The server supports the following TLS configuration options:\n\n- `--tls-cert-file`: Path to TLS certificate file for client authentication\n- `--tls-key-file`: Path to TLS private key file for client authentication\n- `--tls-ca-file`: Path to TLS CA certificate file for server verification\n- `--tls-skip-verify`: Skip TLS certificate verification (insecure, use only for testing)\n\n**Example with client certificate authentication:**\n\n```json\n{\n  \"mcpServers\": {\n    \"grafana\": {\n      \"command\": \"mcp-grafana\",\n      \"args\": [\n        \"--tls-cert-file\",\n        \"/path/to/client.crt\",\n        \"--tls-key-file\",\n        \"/path/to/client.key\",\n        \"--tls-ca-file\",\n        \"/path/to/ca.crt\"\n      ],\n      \"env\": {\n        \"GRAFANA_URL\": \"https://secure-grafana.example.com\",\n        \"GRAFANA_SERVICE_ACCOUNT_TOKEN\": \"<your service account token>\"\n      }\n    }\n  }\n}\n```\n\n**Example with Docker:**\n\n```json\n{\n  \"mcpServers\": {\n    \"grafana\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-v\",\n        \"/path/to/certs:/certs:ro\",\n        \"-e\",\n        \"GRAFANA_URL\",\n        \"-e\",\n        \"GRAFANA_SERVICE_ACCOUNT_TOKEN\",\n        \"grafana/mcp-grafana\",\n        \"-t\",\n        \"stdio\",\n        \"--tls-cert-file\",\n        \"/certs/client.crt\",\n        \"--tls-key-file\",\n        \"/certs/client.key\",\n        \"--tls-ca-file\",\n        \"/certs/ca.crt\"\n      ],\n      \"env\": {\n        \"GRAFANA_URL\": \"https://secure-grafana.example.com\",\n        \"GRAFANA_SERVICE_ACCOUNT_TOKEN\": \"<your service account token>\"\n      }\n    }\n  }\n}\n```\n\nThe TLS configuration is applied to all HTTP clients used by the MCP server, including:\n\n- The main Grafana OpenAPI client\n- Prometheus datasource clients\n- Loki datasource clients\n- Incident management clients\n- Sift investigation clients\n- Alerting clients\n- Asserts clients\n\n**Direct CLI Usage Examples:**\n\nFor testing with self-signed certificates:\n\n```bash\n./mcp-grafana --tls-skip-verify -debug\n```\n\nWith client certificate authentication:\n\n```bash\n./mcp-grafana \\\n  --tls-cert-file /path/to/client.crt \\\n  --tls-key-file /path/to/client.key \\\n  --tls-ca-file /path/to/ca.crt \\\n  -debug\n```\n\nWith custom CA certificate only:\n\n```bash\n./mcp-grafana --tls-ca-file /path/to/ca.crt\n```\n\n**Programmatic Usage:**\n\nIf you're using this library programmatically, you can also create TLS-enabled context functions:\n\n```go\n// Using struct literals\ntlsConfig := &mcpgrafana.TLSConfig{\n    CertFile: \"/path/to/client.crt\",\n    KeyFile:  \"/path/to/client.key\",\n    CAFile:   \"/path/to/ca.crt\",\n}\ngrafanaConfig := mcpgrafana.GrafanaConfig{\n    Debug:     true,\n    TLSConfig: tlsConfig,\n}\ncontextFunc := mcpgrafana.ComposedStdioContextFunc(grafanaConfig)\n\n// Or inline\ngrafanaConfig := mcpgrafana.GrafanaConfig{\n    Debug: true,\n    TLSConfig: &mcpgrafana.TLSConfig{\n        CertFile: \"/path/to/client.crt\",\n        KeyFile:  \"/path/to/client.key\",\n        CAFile:   \"/path/to/ca.crt\",\n    },\n}\ncontextFunc := mcpgrafana.ComposedStdioContextFunc(grafanaConfig)\n```\n\n### Server TLS Configuration (Streamable HTTP Transport Only)\n\nWhen using the streamable HTTP transport (`-t streamable-http`), you can configure the MCP server to serve HTTPS instead of HTTP. This is useful when you need to secure the connection between your MCP client and the server itself.\n\nThe server supports the following TLS configuration options for the streamable HTTP transport:\n\n- `--server.tls-cert-file`: Path to TLS certificate file for server HTTPS (required for TLS)\n- `--server.tls-key-file`: Path to TLS private key file for server HTTPS (required for TLS)\n\n**Note**: These flags are completely separate from the client TLS flags documented above. The client TLS flags configure how the MCP server connects to Grafana, while these server TLS flags configure how clients connect to the MCP server when using streamable HTTP transport.\n\n**Example with HTTPS streamable HTTP server:**\n\n```bash\n./mcp-grafana \\\n  -t streamable-http \\\n  --server.tls-cert-file /path/to/server.crt \\\n  --server.tls-key-file /path/to/server.key \\\n  -addr :8443\n```\n\nThis would start the MCP server on HTTPS port 8443. Clients would then connect to `https://localhost:8443/` instead of `http://localhost:8000/`.\n\n**Docker example with server TLS:**\n\n```bash\ndocker run --rm -p 8443:8443 \\\n  -v /path/to/certs:/certs:ro \\\n  -e GRAFANA_URL=http://localhost:3000 \\\n  -e GRAFANA_SERVICE_ACCOUNT_TOKEN=<your service account token> \\\n  grafana/mcp-grafana \\\n  -t streamable-http \\\n  -addr :8443 \\\n  --server.tls-cert-file /certs/server.crt \\\n  --server.tls-key-file /certs/server.key\n```\n\n### Health Check Endpoint\n\nWhen using the SSE (`-t sse`) or streamable HTTP (`-t streamable-http`) transports, the MCP server exposes a health check endpoint at `/healthz`. This endpoint can be used by load balancers, monitoring systems, or orchestration platforms to verify that the server is running and accepting connections.\n\n**Endpoint:** `GET /healthz`\n\n**Response:**\n- Status Code: `200 OK`\n- Body: `ok`\n\n**Example usage:**\n\n```bash\n# For streamable HTTP or SSE transport on default port\ncurl http://localhost:8000/healthz\n\n# With custom address\ncurl http://localhost:9090/healthz\n```\n\n**Note:** The health check endpoint is only available when using SSE or streamable HTTP transports. It is not available when using the stdio transport (`-t stdio`), as stdio does not expose an HTTP server.\n\n## Troubleshooting\n\n### Grafana Version Compatibility\n\nIf you encounter the following error when using datasource-related tools:\n\n```\nget datasource by uid : [GET /datasources/uid/{uid}][400] getDataSourceByUidBadRequest {\"message\":\"id is invalid\"}\n```\n\nThis typically indicates that you are using a Grafana version earlier than 9.0. The `/datasources/uid/{uid}` API endpoint was introduced in Grafana 9.0, and datasource operations will fail on earlier versions.\n\n**Solution:** Upgrade your Grafana instance to version 9.0 or later to resolve this issue.\n\n## Development\n\nContributions are welcome! Please open an issue or submit a pull request if you have any suggestions or improvements.\n\nThis project is written in Go. Install Go following the instructions for your platform.\n\nTo run the server locally in STDIO mode (which is the default for local development), use:\n\n```bash\nmake run\n```\n\nTo run the server locally in SSE mode, use:\n\n```bash\ngo run ./cmd/mcp-grafana --transport sse\n```\n\nYou can also run the server using the SSE transport inside a custom built Docker image. Just like the published Docker image, this custom image's entrypoint defaults to SSE mode. To build the image, use:\n\n```\nmake build-image\n```\n\nAnd to run the image in SSE mode (the default), use:\n\n```\ndocker run -it --rm -p 8000:8000 mcp-grafana:latest\n```\n\nIf you need to run it in STDIO mode instead, override the transport setting:\n\n```\ndocker run -it --rm mcp-grafana:latest -t stdio\n```\n\n### Testing\n\nThere are three types of tests available:\n\n1. Unit Tests (no external dependencies required):\n\n```bash\nmake test-unit\n```\n\nYou can also run unit tests with:\n\n```bash\nmake test\n```\n\n2. Integration Tests (requires docker containers to be up and running):\n\n```bash\nmake test-integration\n```\n\n3. Cloud Tests (requires cloud Grafana instance and credentials):\n\n```bash\nmake test-cloud\n```\n\n> Note: Cloud tests are automatically configured in CI. For local development, you'll need to set up your own Grafana Cloud instance and credentials.\n\nMore comprehensive integration tests will require a Grafana instance to be running locally on port 3000; you can start one with Docker Compose:\n\n```bash\ndocker-compose up -d\n```\n\nThe integration tests can be run with:\n\n```bash\nmake test-all\n```\n\nIf you're adding more tools, please add integration tests for them. The existing tests should be a good starting point.\n\n### Linting\n\nTo lint the code, run:\n\n```bash\nmake lint\n```\n\nThis includes a custom linter that checks for unescaped commas in `jsonschema` struct tags. The commas in `description` fields must be escaped with `\\\\,` to prevent silent truncation. You can run just this linter with:\n\n```bash\nmake lint-jsonschema\n```\n\nSee the [JSONSchema Linter documentation](internal/linter/jsonschema/README.md) for more details.\n\n## License\n\nThis project is licensed under the [Apache License, Version 2.0](LICENSE).\n\n[mcp]: https://modelcontextprotocol.io/\n[service-account]: https://grafana.com/docs/grafana/latest/administration/service-accounts/#add-a-token-to-a-service-account-in-grafana\n",
      "stars_today": 8
    },
    {
      "id": 974197583,
      "name": "kotlin-lsp",
      "full_name": "Kotlin/kotlin-lsp",
      "description": "Kotlin Language Server and plugin for Visual Studio Code",
      "html_url": "https://github.com/Kotlin/kotlin-lsp",
      "stars": 2812,
      "forks": 62,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2025-04-28T12:03:49Z",
      "updated_at": "2026-01-22T21:48:11Z",
      "pushed_at": "2026-01-20T13:32:42Z",
      "open_issues": 80,
      "owner": {
        "login": "Kotlin",
        "avatar_url": "https://avatars.githubusercontent.com/u/1446536?v=4"
      },
      "readme": "Language Server for Kotlin\n========\n\n[![Kotlin Alpha](https://kotl.in/badges/experimental.svg)](https://kotlinlang.org/docs/components-stability.html)\n[![JetBrains incubator project](https://jb.gg/badges/incubator.svg)](https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub)\n[![GitHub Release](https://img.shields.io/github/v/release/Kotlin/kotlin-lsp)](https://github.com/Kotlin/kotlin-lsp/releases/latest)\n\nPre-alpha official Kotlin support for Visual Studio Code and an implementation of [Language Server Protocol](https://github.com/Microsoft/language-server-protocol)\nfor the Kotlin language.\n\nThe server is based on [IntelliJ IDEA](https://github.com/JetBrains/intellij-community) and the [IntelliJ IDEA Kotlin Plugin](https://github.com/JetBrains/intellij-community/tree/master/plugins/kotlin)\nimplementation.\n\n### VS Code Quick Start\n\n1. Download the latest build of VSC extension or Standalone version from the [Releases Page](https://github.com/Kotlin/kotlin-lsp/releases)\n2. Install it as a VSC Extension via `Extensions | More Action | Install from VSIX`\n    * Alternatively, it is possible to drag-and-drop VSIX extension directly into `Extensions` tool window\n3. Ensure that your Java version is 17 or above\n4. Open a folder with JVM-only Kotlin Gradle project and the project will be immediately recognized and LSP activated\n\n![quickstart_sample.gif](images/quickstart_sample.gif)\n\n### Install kotlin-lsp CLI\n\nFor brew users: `brew install JetBrains/utils/kotlin-lsp`\n\nManual installation:\n1. Download the standalone zip from the [Releases Page](https://github.com/Kotlin/kotlin-lsp/releases)\n2. Unpack zip\n3. `chmod +x $KOTLIN_LSP_DIR/kotlin-lsp.sh`\n4. Create a symlink inside your PATH `ln -s $KOTLIN_LSP_DIR/kotlin-lsp.sh $HOME/.local/bin/kotlin-lsp`\n\n### Supported features and Roadmap\n\nThe best way to track current capabilities and what is going to be supported in the next builds is this table:\n\n>Important note: currently, only JVM-only Kotlin Gradle projects are supported out-of-the box.\n\n* [ ] Project import\n  * [x] Gradle JVM project import\n  * [ ] Gradle KMP project import\n  * [x] JSON-based build system agnostic import\n    * [ ] Quickstart for JSON\n  * [ ] Maven/Amper import\n  * [ ] Dumb mode for no build system at all\n* [x] Highlighting\n  * [x] Semantic highlighting\n* [x] Navigation\n  * [x] Navigation to Kotlin (source, binary)\n  * [x] Navigation to Kotlin builtins\n  * [x] Navigation to Java (source, binary)\n* [x] Code actions\n  * [x] Quickfixes (i.e. `replace with`)\n  * [x] Kotlin inspections\n  * [x] Organize imports\n  * [x] Go to reference\n* [ ] Refactorings\n  * [x] Rename\n  * [ ] Move\n  * [ ] Change signature\n* [x] On-the-fly Kotlin diagnostics\n* [x] Completion\n  * [x] Analysis-API based completion\n  * [x] IJ-based completion\n    * [x] Enable IJ-based completion\n* [ ] KDoc support\n  * [x] In-project documentation hovers\n  * [ ] Dependencies/Java documentation hovers from `source.jar`\n* [ ] Code formatting\n* [ ] Fully-featured Windows support\n* [x] Reactive updates from the filesystem\n* [x] Document symbols (Outline) \n\n\n### Project Status\n\n**The project is in an experimental, pre-alpha, exploratory phase** with the intention to be productionized.\n\nWe [move fast, break things](https://xkcd.com/1428/), and explore various aspects of the seamless developer experience \nincluding Java interoperability, limits of IntelliJ capabilities as a standalone server, native binaries of the LSP, and \ndebug capabilities.\n\nThe LSP supports most of the essential parts, but its final shape is not near to be defined and \neven the most basic and core parts are being changed on a regular basis.\n\nSo we have the corresponding stability guarantees -- **none**. It is okay to use it in your toy \nprojects, to experiment with it and to provide your feedback, but it is not recommended \nto depend on its stability in your day-to-day work.\n\n\n### Supported platforms\n\nIn the current state, the golden path has been tested for Visual Studio Code with macOS and Linux platforms.\n\nYou can use Kotlin LSP with other LSP-compliant editors, but configuration must be done manually.\nPlease note that Kotlin LSP uses pull-based diagnostics, so the editor must support that.\n\nYou can find a standalone LSP launch script in [kotlin-lsp.sh](scripts/kotlin-lsp.sh) along\nwith _very experimental_ (aka \"works on someone's machine\") instructions that setup LSP for other editors in [scripts](scripts) folder.\nSee `./kotlin-lsp.sh --help` for available options.\n\n### Source code\n\nCurrently, the LSP implementation is partially closed-source, primarily for the sake of development speed convenience -- \nit heavily depends on parts of IntelliJ, Fleet, and our distributed Bazel build that allows us to \niterate quickly and experiment much faster, cutting corners and re-using internal infrastructure where it helps.\nAfter the initial stabilization phase and defining the final set of capabilities, we will de-couple the LSP implementation from the internal repository \nand build pipelines and open source it completely (with an explicit dependency on IntelliJ), this is a temporary constraint.\nVSC extension is mirrored into [kotlin-vscode](kotlin-vscode) as it does not depend on anything internal.\n\n### Feedback and issues\n\nThe best way to provide your feedback or report an issue is to file a bug [in GitHub issues](https://github.com/Kotlin/kotlin-lsp/issues/new).\n\nAs a temporary limitation, direct contributions are not supported as this repository is a read-only mirror,\nbut it is possible to open a PR into the documentation, and it will be integrated manually by maintainers.\n",
      "stars_today": 8
    },
    {
      "id": 137451403,
      "name": "nacos",
      "full_name": "alibaba/nacos",
      "description": "an easy-to-use dynamic service discovery, configuration and service management platform for building AI cloud native applications.",
      "html_url": "https://github.com/alibaba/nacos",
      "stars": 32569,
      "forks": 13242,
      "language": "Java",
      "topics": [
        "a2a-registry",
        "agent",
        "ai-registry",
        "configuration-management",
        "distributed-configuration",
        "dns",
        "dubbo",
        "istio",
        "kubernetes",
        "mcp",
        "mcp-management",
        "mcp-registry",
        "microservices",
        "nacos",
        "prompt",
        "skills",
        "spring-cloud"
      ],
      "created_at": "2018-06-15T06:49:27Z",
      "updated_at": "2026-01-23T02:04:49Z",
      "pushed_at": "2026-01-22T18:23:07Z",
      "open_issues": 258,
      "owner": {
        "login": "alibaba",
        "avatar_url": "https://avatars.githubusercontent.com/u/1961952?v=4"
      },
      "readme": "\n<img src=\"doc/Nacos_Logo.png\" width=\"50%\" syt height=\"50%\" />\n\n# Nacos: Dynamic  *Na*ming and *Co*nfiguration *S*ervice\n\n[![Gitter](https://badges.gitter.im/alibaba/nacos.svg)](https://gitter.im/alibaba/nacos?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)   [![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![Gitter](https://travis-ci.org/alibaba/nacos.svg?branch=master)](https://travis-ci.org/alibaba/nacos)\n[![](https://img.shields.io/badge/Nacos-Check%20Your%20Contribution-orange)](https://opensource.alibaba.com/contribution_leaderboard/details?projectValue=nacos)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/alibaba/nacos)\n\n-------\n\n## What does it do\n\nNacos (official site: [nacos.io](https://nacos.io)) is an easy-to-use platform designed for dynamic service discovery and configuration and service management. It helps you to build cloud native applications and microservices platform easily.\n\nService is a first-class citizen in Nacos. Nacos supports almost all type of servicesÔºåfor exampleÔºå[Dubbo/gRPC service](https://nacos.io/docs/latest/ecology/use-nacos-with-dubbo/), [Spring Cloud RESTFul service](https://nacos.io/docs/latest/ecology/use-nacos-with-spring-cloud/) or [Kubernetes service](https://nacos.io/docs/latest/quickstart/quick-start-kubernetes/).\n\nNacos provides four major functions.\n\n* **Service Discovery and Service Health Check** \n    \n    Nacos makes it simple for services to register themselves and to discover other services via a DNS or HTTP interface. Nacos also provides real-time health checks of services to prevent sending requests to unhealthy hosts or service instances.\n\n* **Dynamic Configuration Management**\n  \n    Dynamic Configuration Service allows you to manage configurations of all services in a centralized and dynamic manner across all environments. Nacos eliminates the need to redeploy applications and services when configurations are updated, which makes configuration changes more efficient and agile.\n\n* **Dynamic DNS Service**\n    \n    Nacos supports weighted routing, making it easier for you to implement mid-tier load balancing, flexible routing policies, flow control, and simple DNS resolution services in the production environment within your data center. It helps you to implement DNS-based service discovery easily and prevent applications from coupling to vendor-specific service discovery APIs.\n\n* **Service and MetaData Management**\n\t\n    Nacos provides an easy-to-use service dashboard to help you manage your services metadata, configuration, kubernetes DNS, service health and metrics statistics.\n \n\n## Quick Start\nIt is super easy to get started with your first project.\n\n### Deploying Nacos on cloud\n\nYou can deploy Nacos on cloud, which is the easiest and most convenient way to start Nacos. \n\nUse the following [Nacos deployment guide](https://cn.aliyun.com/product/aliware/mse?spm=nacos-website.topbar.0.0.0) to see more information and deploy a stable and out-of-the-box Nacos server.\n\n\n### Start by the provided startup package\n\n#### Step 1: Download the binary package \n\nYou can download the package from the [latest stable release](https://github.com/alibaba/nacos/releases).  \n\nTake release `nacos-server-1.0.0.zip` for example:\n```sh\nunzip nacos-server-1.0.0.zip\ncd nacos/bin \n``` \n\n#### Step 2: Start Server\n\nOn the **Linux/Unix/Mac** platform, run the following command to start server with standalone mode: \n```sh\nsh startup.sh -m standalone\n```\n\nOn the **Windows** platform, run the following command to start server with standalone mode.  Alternatively, you can also double-click the `startup.cmd` to run NacosServer.\n```\nstartup.cmd -m standalone\n```\n\nFor more details, see [quick-start.](https://nacos.io/docs/latest/quickstart/quick-start/)\n\n## Quick start for other open-source projects:\n* [Quick start with Nacos command and console](https://nacos.io/docs/latest/quickstart/quick-start/)\n\n* [Quick start with dubbo](https://nacos.io/docs/latest/ecology/use-nacos-with-dubbo/)\n\n* [Quick start with spring cloud](https://nacos.io/docs/latest/ecology/use-nacos-with-spring-cloud/)\n\n* [Quick start with kubernetes](https://nacos.io/docs/latest/quickstart/quick-start-kubernetes/)\n\n\n## Documentation\n\nYou can view the full documentation from the [Nacos website](https://nacos.io/docs/latest/overview/).\n\nYou can also read this online eBook from the [NACOS ARCHITECTURE & PRINCIPLES](https://nacos.io/docs/ebook/kbyo6n/).\n\nAll the latest and long-term notice can also be found here from [GitHub notice issue](https://github.com/alibaba/nacos/labels/notice).\n\n## Contributing\n\nContributors are welcomed to join Nacos project. Please check [CONTRIBUTING](./CONTRIBUTING.md) about how to contribute to this project.\n\n### How can I contribute?\n\n* Take a look at issues with tags marked [`good first issue`](https://github.com/alibaba/nacos/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) or [`contribution welcome`](https://github.com/alibaba/nacos/issues?q=is%3Aopen+is%3Aissue+label%3A%22contribution+welcome%22).\n* Answer questions on [issues](https://github.com/alibaba/nacos/issues).\n* Fix bugs reported on [issues](https://github.com/alibaba/nacos/issues), and send us a pull request.\n* Review the existing [pull request](https://github.com/alibaba/nacos/pulls).\n* Improve the [website](https://github.com/nacos-group/nacos-group.github.io), typically we need\n  * blog post\n  * translation on documentation\n  * use cases around the integration of Nacos in enterprise systems.\n\n## Other Related Project Repositories\n\n* [nacos-spring-project](https://github.com/nacos-group/nacos-spring-project) provides the integration functionality for Spring.\n* [nacos-group](https://github.com/nacos-group) is the repository that hosts the eco tools for Nacos, such as SDK, synchronization tool, etc.\n* [spring-cloud-alibaba](https://github.com/spring-cloud-incubator/spring-cloud-alibaba) provides the one-stop solution for application development over Alibaba middleware which includes Nacos.\n\n## Contact\n\n* [Gitter](https://gitter.im/alibaba/nacos): Nacos's IM tool for community messaging, collaboration and discovery.\n* [Twitter](https://twitter.com/nacos2): Follow along for latest nacos news on Twitter.\n* [Weibo](https://weibo.com/u/6574374908): Follow along for latest nacos news on Weibo (Twitter of China version).\n* [Nacos Segmentfault](https://segmentfault.com/t/nacos): Get latest notice and prompt help from Segmentfault.\n* Email Group:\n     * users-nacos@googlegroups.com: Nacos usage general discussion.\n     * dev-nacos@googlegroups.com: Nacos developer discussion (APIs, feature design, etc).\n     * commits-nacos@googlegroups.com: Commits notice, very high frequency.\n* Join us from DingDing(Group 1: 21708933(full), Group 2: 30438813(full), Group 3: 31222241(full), Group 4: 12810027056). \n\n### DingDing Group QR Code\n\n![](https://cdn.nlark.com/yuque/0/2025/png/1577777/1750054497446-f834cba6-fa83-4421-b202-a0dc1d5cc28b.png)\n\n### DingDing MCP Group QR Code\n\n![](https://cdn.nlark.com/yuque/0/2025/png/1577777/1750054500395-e271cbe4-2dd8-4723-8cd0-bd8a731b812a.png)\n\n### WeChat Group QR Code\n\n![](https://cdn.nlark.com/yuque/0/2025/png/1577777/1750054421702-a7d1421a-ab8e-42da-bc59-01b5d287b290.png)\n\n## Enterprise Service\nIf you need Nacos enterprise service support, or purchase cloud product services, you can join the discussion by scanning the following DingTalk group. It can also be directly activated and used through the microservice engine (MSE) provided by Alibaba Cloud.\nhttps://cn.aliyun.com/product/aliware/mse?spm=nacos-website.topbar.0.0.0\n\n<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01RTfN7q1KUzX4TcH08_!!6000000001168-2-tps-864-814.png\" width=\"500\">\n\n\n## Download\n\n- [Nacos Official Website](https://nacos.io/download/nacos-server)\n- [GitHub Release](https://github.com/alibaba/nacos/releases)\n  \n## Who is using\n\nThese are only part of the companies using Nacos, for reference only. If you are using Nacos, please [add your company here](https://github.com/alibaba/nacos/issues/273) to tell us your scenario to make Nacos better.\n\n<table>\n  <tr>\n    <td><img src=\"https://data.alibabagroup.com/ecms-files/886024452/296d05a1-c52a-4f5e-abf2-0d49d4c0d6b3.png\"  alt=\"Alibaba Group\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://a.msstatic.com/huya/main/img/logo.png\"  alt=\"ËôéÁâôÁõ¥Êí≠\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://v.icbc.com.cn/userfiles/Resources/ICBC/shouye/images/2017/logo.png\"  alt=\"ICBC\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://pic2.iqiyipic.com/lequ/20220422/e7fe69c75e2541f2a931c9e538e2ab9d.jpg\"  alt=\"Áà±Â•áËâ∫\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1pwi9EwHqK1RjSZJnXXbNLpXa-479-59.png\"  alt=\"Âπ≥ÂÆâÁßëÊäÄ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1MZWSEzDpK1RjSZFrXXa78VXa-269-69.png\"  alt=\"ÂçéÂ§è‰ø°Ë¥¢\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://www.urwork.cn/public/images/ui/logo.png\"  alt=\"‰ºòÂÆ¢Â∑•Âú∫\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1ebu.EAvoK1RjSZFwXXciCFXa-224-80.png\"  alt=\"Ë¥ùÂ£≥ÊâæÊàø\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1lxu7EBLoK1RjSZFuXXXn0XXa-409-74.png\"  alt=\"ÁëûÂÆâÂÜúÊùëÂïÜ‰∏öÈì∂Ë°å\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1L16eEzTpK1RjSZKPXXa3UpXa-302-50.png\"  alt=\"Âè∏Ê≥ïÂ§ßÊï∞ÊçÆ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://www.souyidai.com/www-style/images/logo.gif\"  alt=\"ÊêúÊòìË¥∑\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1OigyDyLaK1RjSZFxXXamPFXa-168-70.png\"  alt=\"Âπ≥Ë°å‰∫ë\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1gJ4vIhTpK1RjSZR0XXbEwXXa-462-60.jpg\"  alt=\"ÁîòËÇÉÁ¥´ÂÖâ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"http://www.seaskylight.com/cn/uploadfiles/image/logo.png\"  alt=\"Êµ∑‰∫ëÂ§©\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1DZWSEzDpK1RjSZFrXXa78VXa-240-62.png\"  alt=\"Acmedcare+\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://14605854.s21i.faiusr.com/4/ABUIABAEGAAg4OvkzwUo8b-qlwUwxQ449gM!300x300.png\"  alt=\"Âåó‰∫¨Â§©Âêà‰∫íËÅî‰ø°ÊÅØÊúâÈôêÂÖ¨Âè∏\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"http://www.mwclg.com/static-resource/front/images/home/img_logo_nav.png\"  alt=\"‰∏äÊµ∑ÂØÜÂ∞îÂÖãÂç´ÂåñÂ∑•\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://www.synwe.com/logo-full.png\"  alt=\"Â§ßËøûÊñ∞ÂîØ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://user-images.githubusercontent.com/10215557/51593180-7563af00-1f2c-11e9-95b1-ec2c645d6a0b.png\"  alt=\"Á´ãÊÄùËæ∞\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1zWW2EpYqK1RjSZLeXXbXppXa-262-81.png\"  alt=\"‰∏úÂÆ∂\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"http://www.sh-guiyao.com/images/logo.jpg\"  alt=\"‰∏äÊµ∑ÂÖãÂûö\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"http://www.lckjep.com:80//theme/img/logoTop.png\"  alt=\"ËÅîÈááÁßëÊäÄ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1G216EsbpK1RjSZFyXXX_qFXa-325-53.jpg\"  alt=\"Âçó‰∫¨28Á†îÁ©∂ÊâÄ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://p1.ifengimg.com/auto/image/2017/0922/auto_logo.png\"  alt=\"Âá§Âá∞ÁΩë-Ê±ΩËΩ¶\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"http://www.sinochemitech.com/zhxx/lib/images/-logo.png\"  alt=\"‰∏≠Âåñ‰ø°ÊÅØ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1DXerNgDqK1RjSZSyXXaxEVXa-333-103.png\"  alt=\"‰∏ÄÁÇπËΩ¶\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1VfOANgHqK1RjSZFPXXcwapXa-313-40.png\"  alt=\"Êòé‰º†Êó†Á∫ø\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1lvCyNhTpK1RjSZFMXXbG_VXa-130-60.png\"  alt=\"Â¶ô‰ºòËΩ¶\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1kY9qNgTqK1RjSZPhXXXfOFXa-120-50.png\"  alt=\"ËúÇÂ∑¢\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1G.GBNbrpK1RjSZTEXXcWAVXa-234-65.png\"  alt=\"ÂçéÂ≠òÊï∞ÊçÆ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1qsurNgDqK1RjSZSyXXaxEVXa-300-90.png\"  alt=\"Êï∞‰∫ë\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB13aywNhTpK1RjSZR0XXbEwXXa-98-38.png\"  alt=\"ÂπøÈÄöËΩØ‰ª∂\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1xqmBNjTpK1RjSZKPXXa3UpXa-162-70.png\"  alt=\"ËèúËèú\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB18DmINcfpK1RjSZFOXXa6nFXa-200-200.png\"  alt=\"ÁßëËìùÂÖ¨Âè∏\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB15uqANXzqK1RjSZFoXXbfcXXa-188-86.png\"  alt=\"Êµ©È≤∏\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1mvmyNkvoK1RjSZPfXXXPKFXa-238-46.png\"  alt=\"Êú™ÂêçÂ§©Êó•ËØ≠\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1PSWsNmrqK1RjSZK9XXXyypXa-195-130.jpg\"  alt=\"ÈáëËÅîÂàõ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1k1qzNbvpK1RjSZFqXXcXUVXa-160-69.png\"  alt=\"ÂêåÁ™óÈìæ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1HdyvNmzqK1RjSZFLXXcn2XXa-143-143.jpg\"  alt=\"È°∫ËÉΩ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1UdaGNgHqK1RjSZJnXXbNLpXa-277-62.png\"  alt=\"Áôæ‰∏ñÂø´ÈÄí\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"https://img.alicdn.com/tfs/TB17OqENbrpK1RjSZTEXXcWAVXa-240-113.jpg\"  alt=\"Ê±ΩËΩ¶‰πãÂÆ∂\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1q71ANkvoK1RjSZPfXXXPKFXa-257-104.png\"  alt=\"È≤∏ÊâìÂç°\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1UzuyNhTpK1RjSZR0XXbEwXXa-201-86.jpg\"  alt=\"Êó∂‰ª£ÂÖâÂçé\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB19RCANgHqK1RjSZFPXXcwapXa-180-180.jpg\"  alt=\"Â∫∑Áæé\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1iCGyNb2pK1RjSZFsXXaNlXXa-143-143.jpg\"  alt=\"ÁéØÁêÉÊòìË¥≠\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://avatars0.githubusercontent.com/u/16344119?s=200&v=4\"  alt=\"Nepxion\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1aUe5EpzqK1RjSZSgXXcpAVXa-248-124.png\"  alt=\"chigua\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1H9O5EAvoK1RjSZFNXXcxMVXa-221-221.jpg\"  alt=\"ÂÆÖÊó†Èôê\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1rNq4EwHqK1RjSZFgXXa7JXXa-200-200.jpg\"  alt=\"Â§©Èòô\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1CRAxDxYaK1RjSZFnXXa80pXa-190-190.jpg\"  alt=\"ËÅîÂêàÊ∞∏ÈÅì\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img.alicdn.com/tfs/TB1.q14ErrpK1RjSZTEXXcWAVXa-219-219.jpg\"  alt=\"ÊòéÊ∫ê‰∫ë\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://www.daocloud.io/static/Logo-Light.png\"  alt=\"DaoCloud\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"https://www.meicai.cn/img/logo.9210b6eb.jpg\"  alt=\"ÁæéËèú\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://img5.tianyancha.com/logo/lll/3aad34039972b57e70874df8c919ae8b.png@!f_200x200\"  alt=\"ÊùæÊ†ºÁßëÊäÄ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://www.jsic-tech.com/Public/uploads/20191206/5de9b9baac696.jpg\"  alt=\"ÈõÜËêÉÊô∫ËÉΩ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://www.wuuxiang.com/theme/images/common/logo1.png\"  alt=\"Âêæ‰∫´\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"http://www.tpson.cn/static/upload/image/20230111/1673427385140440.png\"  alt=\"ÊãìÊ∑±ÁßëÊäÄ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://www.sunline.cn/u_file/fileUpload/2021-06/25/2021062586431.png\"  alt=\"Èïø‰∫ÆÁßëÊäÄ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"http://pmt2f499f.pic44.websiteonline.cn/upload/wv0c.png\"  alt=\"Ê∑±Âú≥ÊòìÂÅúËΩ¶Â∫ì\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"http://www.dragonwake.cn/static/css/default/img/logo.png\"  alt=\"Ê≠¶Ê±âÊó•ÂàõÁßëÊäÄ\" width=\"180\" height=\"120\"></td>\n  </tr>\n  <tr>\n    <td><img src=\"https://i4im-web.oss-cn-shanghai.aliyuncs.com/images/logo.png\"  alt=\"ÊòìÁÆ°Êô∫ËÉΩ\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://www.yunzhangfang.com/assets/img/logo.4096cf52.png\"  alt=\"‰∫ëÂ∏êÊàø\" width=\"180\" height=\"120\"></td>\n    <td><img src=\"https://www.sinocare.com/sannuo/templates/web/img/bocweb-logo.svg\"  alt=\"‰∏âËØ∫ÁîüÁâ©\" width=\"180\" height=\"120\"></td>\n    <td></td>\n  </tr>\n  <tr>\n    <td>ÈÉëÂ∑ûÂ±±Ê∞¥</td>\n    <td>Áü•Ê∞èÊïôËÇ≤</td>\n    <td></td>\n    <td></td>\n  </tr>\n</table>\n",
      "stars_today": 7
    },
    {
      "id": 14812739,
      "name": "libuv",
      "full_name": "libuv/libuv",
      "description": "Cross-platform asynchronous I/O",
      "html_url": "https://github.com/libuv/libuv",
      "stars": 26497,
      "forks": 3827,
      "language": "C",
      "topics": [
        "asynchronous",
        "deep-io",
        "io",
        "networking",
        "unicorns",
        "unix",
        "velociraptors",
        "windows"
      ],
      "created_at": "2013-11-30T00:29:56Z",
      "updated_at": "2026-01-23T00:43:33Z",
      "pushed_at": "2026-01-21T21:34:30Z",
      "open_issues": 210,
      "owner": {
        "login": "libuv",
        "avatar_url": "https://avatars.githubusercontent.com/u/4030929?v=4"
      },
      "readme": "![libuv][libuv_banner]\n\n## Overview\n\nlibuv is a multi-platform support library with a focus on asynchronous I/O. It\nwas primarily developed for use by [Node.js][], but it's also\nused by [Luvit](http://luvit.io/), [Julia](http://julialang.org/),\n[uvloop](https://github.com/MagicStack/uvloop), and [others](https://github.com/libuv/libuv/blob/v1.x/LINKS.md).\n\n## Feature highlights\n\n * Full-featured event loop backed by epoll, kqueue, IOCP, event ports.\n\n * Asynchronous TCP and UDP sockets\n\n * Asynchronous DNS resolution\n\n * Asynchronous file and file system operations\n\n * File system events\n\n * ANSI escape code controlled TTY\n\n * IPC with socket sharing, using Unix domain sockets or named pipes (Windows)\n\n * Child processes\n\n * Thread pool\n\n * Signal handling\n\n * High resolution clock\n\n * Threading and synchronization primitives\n\n## Versioning\n\nStarting with version 1.0.0 libuv follows the [semantic versioning](http://semver.org/)\nscheme. The API change and backwards compatibility rules are those indicated by\nSemVer. libuv will keep a stable ABI across major releases.\n\nThe ABI/API changes can be tracked [here](http://abi-laboratory.pro/tracker/timeline/libuv/).\n\n## Licensing\n\nlibuv is licensed under the MIT license. Check the [LICENSE](LICENSE) and\n[LICENSE-extra](LICENSE-extra) files.\n\nThe documentation is licensed under the CC BY 4.0 license. Check the\n[LICENSE-docs file](LICENSE-docs).\n\n## Community\n\n * [Support](https://github.com/libuv/libuv/discussions)\n * [Mailing list](http://groups.google.com/group/libuv)\n\n## Documentation\n\n### Official documentation\n\nLocated in the docs/ subdirectory. It uses the [Sphinx](http://sphinx-doc.org/)\nframework, which makes it possible to build the documentation in multiple\nformats.\n\nShow different supported building options:\n\n```bash\n$ make help\n```\n\nBuild documentation as HTML:\n\n```bash\n$ make html\n```\n\nBuild documentation as HTML and live reload it when it changes (this requires\nsphinx-autobuild to be installed and is only supported on Unix):\n\n```bash\n$ make livehtml\n```\n\nBuild documentation as man pages:\n\n```bash\n$ make man\n```\n\nBuild documentation as ePub:\n\n```bash\n$ make epub\n```\n\nNOTE: Windows users need to use make.bat instead of plain 'make'.\n\nDocumentation can be browsed online [here](http://docs.libuv.org).\n\nThe [tests and benchmarks](https://github.com/libuv/libuv/tree/master/test)\nalso serve as API specification and usage examples.\n\n### Other resources\n\n * [LXJS 2012 talk](http://www.youtube.com/watch?v=nGn60vDSxQ4)\n   &mdash; High-level introductory talk about libuv.\n * [libuv-dox](https://github.com/thlorenz/libuv-dox)\n   &mdash; Documenting types and methods of libuv, mostly by reading uv.h.\n * [learnuv](https://github.com/thlorenz/learnuv)\n   &mdash; Learn uv for fun and profit, a self guided workshop to libuv.\n\nThese resources are not handled by libuv maintainers and might be out of\ndate. Please verify it before opening new issues.\n\n## Downloading\n\nlibuv can be downloaded either from the\n[GitHub repository](https://github.com/libuv/libuv)\nor from the [downloads site](http://dist.libuv.org/dist/).\n\nBefore verifying the git tags or signature files, importing the relevant keys\nis necessary. Key IDs are listed in the\n[MAINTAINERS](https://github.com/libuv/libuv/blob/master/MAINTAINERS.md)\nfile, but are also available as git blob objects for easier use.\n\nImporting a key the usual way:\n\n```bash\n$ gpg --keyserver pool.sks-keyservers.net --recv-keys AE9BC059\n```\n\nImporting a key from a git blob object:\n\n```bash\n$ git show pubkey-saghul | gpg --import\n```\n\n### Verifying releases\n\nGit tags are signed with the developer's key, they can be verified as follows:\n\n```bash\n$ git verify-tag v1.6.1\n```\n\nStarting with libuv 1.7.0, the tarballs stored in the\n[downloads site](http://dist.libuv.org/dist/) are signed and an accompanying\nsignature file sit alongside each. Once both the release tarball and the\nsignature file are downloaded, the file can be verified as follows:\n\n```bash\n$ gpg --verify libuv-1.7.0.tar.gz.sign\n```\n\n## Build Instructions\n\nFor UNIX-like platforms, including macOS, there are two build methods:\nautotools or [CMake][].\n\nFor Windows, [CMake][] is the only supported build method and has the\nfollowing prerequisites:\n\n<details>\n\n* One of:\n  * [Visual C++ Build Tools][]\n  * [Visual Studio 2015 Update 3][], all editions\n    including the Community edition (remember to select\n    \"Common Tools for Visual C++ 2015\" feature during installation).\n  * [Visual Studio 2017][], any edition (including the Build Tools SKU).\n    **Required Components:** \"MSbuild\", \"VC++ 2017 v141 toolset\" and one of the\n    Windows SDKs (10 or 8.1).\n* Basic Unix tools required for some tests,\n  [Git for Windows][] includes Git Bash\n  and tools which can be included in the global `PATH`.\n\n</details>\n\nTo build with autotools:\n\n```bash\n$ sh autogen.sh\n$ ./configure\n$ make\n$ make check\n$ make install\n```\n\nTo build with [CMake][]:\n\n```bash\n$ cmake -B build -DBUILD_TESTING=ON         # generate project with tests\n$ cmake --build build                       # add `-j <n>` with cmake >= 3.12\n\n# Run tests:\n$ (cd build && ctest -C Debug --output-on-failure)\n\n# Or manually run tests:\n$ build/uv_run_tests                        # shared library build\n$ build/uv_run_tests_a                      # static library build\n```\n\nTo cross-compile with [CMake][] (unsupported but generally works):\n\n```bash\n$ cmake ../..                 \\\n  -DCMAKE_SYSTEM_NAME=Windows \\\n  -DCMAKE_SYSTEM_VERSION=6.1  \\\n  -DCMAKE_C_COMPILER=i686-w64-mingw32-gcc\n```\n\n### Install with Homebrew\n\n```bash\n$ brew install --HEAD libuv\n```\n\nNote to macOS users:\n\nMake sure that you specify the architecture you wish to build for in the\n\"ARCHS\" flag. You can specify more than one by delimiting with a space\n(e.g. \"x86_64 i386\").\n\n### Install with vcpkg\n\n```bash\n$ git clone https://github.com/microsoft/vcpkg.git\n$ ./bootstrap-vcpkg.bat # for powershell\n$ ./bootstrap-vcpkg.sh # for bash\n$ ./vcpkg install libuv\n```\n\n### Install with Conan\n\nYou can install pre-built binaries for libuv or build it from source using [Conan](https://conan.io/). Use the following command:\n\n```bash\nconan install --requires=\"libuv/[*]\" --build=missing\n```\n\nThe libuv Conan recipe is kept up to date by Conan maintainers and community contributors.\nIf the version is out of date, please [create an issue or pull request](https://github.com/conan-io/conan-center-index) on the ConanCenterIndex repository.\n\n\n### Running tests\n\nSome tests are timing sensitive. Relaxing test timeouts may be necessary\non slow or overloaded machines:\n\n```bash\n$ env UV_TEST_TIMEOUT_MULTIPLIER=2 build/uv_run_tests # 10s instead of 5s\n```\n\n#### Run one test\n\nThe list of all tests is in `test/test-list.h`.\n\nThis invocation will cause the test driver to fork and execute `TEST_NAME` in\na child process:\n\n```bash\n$ build/uv_run_tests_a TEST_NAME\n```\n\nThis invocation will cause the test driver to execute the test in\nthe same process:\n\n```bash\n$ build/uv_run_tests_a TEST_NAME TEST_NAME\n```\n\n#### Debugging tools\n\nWhen running the test from within the test driver process\n(`build/uv_run_tests_a TEST_NAME TEST_NAME`), tools like gdb and valgrind\nwork normally.\n\nWhen running the test from a child of the test driver process\n(`build/uv_run_tests_a TEST_NAME`), use these tools in a fork-aware manner.\n\n##### Fork-aware gdb\n\nUse the [follow-fork-mode](https://sourceware.org/gdb/onlinedocs/gdb/Forks.html) setting:\n\n```\n$ gdb --args build/uv_run_tests_a TEST_NAME\n\n(gdb) set follow-fork-mode child\n...\n```\n\n##### Fork-aware valgrind\n\nUse the `--trace-children=yes` parameter:\n\n```bash\n$ valgrind --trace-children=yes -v --tool=memcheck --leak-check=full --track-origins=yes --leak-resolution=high --show-reachable=yes --log-file=memcheck-%p.log build/uv_run_tests_a TEST_NAME\n```\n\n### Running benchmarks\n\nSee the section on running tests.\nThe benchmark driver is `./uv_run_benchmarks_a` and the benchmarks are\nlisted in `test/benchmark-list.h`.\n\n## Supported Platforms\n\nCheck the [SUPPORTED_PLATFORMS file](SUPPORTED_PLATFORMS.md).\n\n### `-fno-strict-aliasing`\n\nIt is recommended to turn on the `-fno-strict-aliasing` compiler flag in\nprojects that use libuv. The use of ad hoc \"inheritance\" in the libuv API\nmay not be safe in the presence of compiler optimizations that depend on\nstrict aliasing.\n\nMSVC does not have an equivalent flag but it also does not appear to need it\nat the time of writing (December 2019.)\n\n### AIX Notes\n\nAIX compilation using IBM XL C/C++ requires version 12.1 or greater.\n\nAIX support for filesystem events requires the non-default IBM `bos.ahafs`\npackage to be installed.  This package provides the AIX Event Infrastructure\nthat is detected by `autoconf`.\n[IBM documentation](http://www.ibm.com/developerworks/aix/library/au-aix_event_infrastructure/)\ndescribes the package in more detail.\n\n### z/OS Notes\n\nz/OS compilation requires [ZOSLIB](https://github.com/ibmruntimes/zoslib) to be installed. When building with [CMake][], use the flag `-DZOSLIB_DIR` to specify the path to [ZOSLIB](https://github.com/ibmruntimes/zoslib):\n\n```bash\n$ (cd build && cmake .. -DBUILD_TESTING=ON -DZOSLIB_DIR=/path/to/zoslib)\n$ cmake --build build\n```\n\nz/OS creates System V semaphores and message queues. These persist on the system\nafter the process terminates unless the event loop is closed.\n\nUse the `ipcrm` command to manually clear up System V resources.\n\n## Patches\n\nSee the [guidelines for contributing][].\n\n[CMake]: https://cmake.org/\n[node.js]: http://nodejs.org/\n[guidelines for contributing]: https://github.com/libuv/libuv/blob/master/CONTRIBUTING.md\n[libuv_banner]: https://raw.githubusercontent.com/libuv/libuv/master/img/banner.png\n[Visual C++ Build Tools]: https://visualstudio.microsoft.com/visual-cpp-build-tools/\n[Visual Studio 2015 Update 3]: https://www.visualstudio.com/vs/older-downloads/\n[Visual Studio 2017]: https://www.visualstudio.com/downloads/\n[Git for Windows]: http://git-scm.com/download/win\n",
      "stars_today": 7
    },
    {
      "id": 13624859,
      "name": "websocket",
      "full_name": "gorilla/websocket",
      "description": "Package gorilla/websocket is a fast, well-tested and widely used WebSocket implementation for Go.",
      "html_url": "https://github.com/gorilla/websocket",
      "stars": 24442,
      "forks": 3583,
      "language": "Go",
      "topics": [
        "go",
        "golang",
        "gorilla",
        "gorilla-web-toolkit",
        "websocket",
        "websockets"
      ],
      "created_at": "2013-10-16T16:41:46Z",
      "updated_at": "2026-01-22T23:07:45Z",
      "pushed_at": "2025-03-19T13:29:08Z",
      "open_issues": 69,
      "owner": {
        "login": "gorilla",
        "avatar_url": "https://avatars.githubusercontent.com/u/489566?v=4"
      },
      "readme": "# Gorilla WebSocket\n\n[![GoDoc](https://godoc.org/github.com/gorilla/websocket?status.svg)](https://godoc.org/github.com/gorilla/websocket)\n[![CircleCI](https://circleci.com/gh/gorilla/websocket.svg?style=svg)](https://circleci.com/gh/gorilla/websocket)\n\nGorilla WebSocket is a [Go](http://golang.org/) implementation of the\n[WebSocket](http://www.rfc-editor.org/rfc/rfc6455.txt) protocol.\n\n\n### Documentation\n\n* [API Reference](https://pkg.go.dev/github.com/gorilla/websocket?tab=doc)\n* [Chat example](https://github.com/gorilla/websocket/tree/main/examples/chat)\n* [Command example](https://github.com/gorilla/websocket/tree/main/examples/command)\n* [Client and server example](https://github.com/gorilla/websocket/tree/main/examples/echo)\n* [File watch example](https://github.com/gorilla/websocket/tree/main/examples/filewatch)\n\n### Status\n\nThe Gorilla WebSocket package provides a complete and tested implementation of\nthe [WebSocket](http://www.rfc-editor.org/rfc/rfc6455.txt) protocol. The\npackage API is stable.\n\n### Installation\n\n    go get github.com/gorilla/websocket\n\n### Protocol Compliance\n\nThe Gorilla WebSocket package passes the server tests in the [Autobahn Test\nSuite](https://github.com/crossbario/autobahn-testsuite) using the application in the [examples/autobahn\nsubdirectory](https://github.com/gorilla/websocket/tree/main/examples/autobahn).\n",
      "stars_today": 7
    },
    {
      "id": 70127218,
      "name": "arduino-esp32",
      "full_name": "espressif/arduino-esp32",
      "description": "Arduino core for the ESP32",
      "html_url": "https://github.com/espressif/arduino-esp32",
      "stars": 16136,
      "forks": 7792,
      "language": "C++",
      "topics": [
        "arduino",
        "esp-idf",
        "esp32"
      ],
      "created_at": "2016-10-06T06:04:20Z",
      "updated_at": "2026-01-22T23:01:28Z",
      "pushed_at": "2026-01-23T00:32:16Z",
      "open_issues": 144,
      "owner": {
        "login": "espressif",
        "avatar_url": "https://avatars.githubusercontent.com/u/9460735?v=4"
      },
      "readme": "# Arduino core for the ESP32 family of SoCs\n\n[![Build Status](https://img.shields.io/github/actions/workflow/status/espressif/arduino-esp32/push.yml?branch=master&event=push&label=Compilation%20Tests)](https://github.com/espressif/arduino-esp32/actions/workflows/push.yml?query=branch%3Amaster+event%3Apush)\n[![Verbose Build Status](https://img.shields.io/github/actions/workflow/status/espressif/arduino-esp32/push.yml?branch=master&event=schedule&label=Compilation%20Tests%20(Verbose))](https://github.com/espressif/arduino-esp32/actions/workflows/push.yml?query=branch%3Amaster+event%3Aschedule)\n[![External Libraries Test](https://img.shields.io/github/actions/workflow/status/espressif/arduino-esp32/lib.yml?branch=master&event=schedule&label=External%20Libraries%20Test)](https://github.com/espressif/arduino-esp32/blob/gh-pages/LIBRARIES_TEST.md)\n[![Runtime Tests](https://github.com/espressif/arduino-esp32/blob/gh-pages/runtime-test-results/badge.svg)](https://github.com/espressif/arduino-esp32/blob/gh-pages/runtime-test-results/RUNTIME_TEST_RESULTS.md)\n\n### Need help or have a question? Join the chat at [Discord](https://discord.gg/8xY6e9crwv) or [open a new Discussion](https://github.com/espressif/arduino-esp32/discussions)\n\n[![Discord invite](https://img.shields.io/discord/1327272229427216425?logo=discord&logoColor=white&logoSize=auto&label=Discord)](https://discord.gg/8xY6e9crwv)\n\n## Contents\n\n  - [Development Status](#development-status)\n  - [Development Planning](#development-planning)\n  - [Documentation](#documentation)\n  - [Supported Chips](#supported-chips)\n  - [Decoding exceptions](#decoding-exceptions)\n  - [Issue/Bug report template](#issuebug-report-template)\n  - [Contributing](#contributing)\n\n### Development Status\n\n#### Latest Stable Release\n\n[![Release Version](https://img.shields.io/github/release/espressif/arduino-esp32.svg)](https://github.com/espressif/arduino-esp32/releases/latest/)\n[![Release Date](https://img.shields.io/github/release-date/espressif/arduino-esp32.svg)](https://github.com/espressif/arduino-esp32/releases/latest/)\n[![Downloads](https://img.shields.io/github/downloads/espressif/arduino-esp32/latest/total.svg)](https://github.com/espressif/arduino-esp32/releases/latest/)\n\n#### Latest Development Release\n\n[![Release Version](https://img.shields.io/github/release/espressif/arduino-esp32/all.svg)](https://github.com/espressif/arduino-esp32/releases/)\n[![Release Date](https://img.shields.io/github/release-date-pre/espressif/arduino-esp32.svg)](https://github.com/espressif/arduino-esp32/releases/)\n[![Downloads](https://img.shields.io/github/downloads-pre/espressif/arduino-esp32/latest/total.svg)](https://github.com/espressif/arduino-esp32/releases/)\n\n### Development Planning\n\nOur Development is fully tracked on this public **[Roadmap üéâ](https://github.com/orgs/espressif/projects/3)**\n\nFor even more information you can join our **[Monthly Community Meetings üîî](https://github.com/espressif/arduino-esp32/discussions/categories/monthly-community-meetings).**\n\n### Documentation\n\nYou can use the [Arduino-ESP32 Online Documentation](https://docs.espressif.com/projects/arduino-esp32/en/latest/) to get all information about this project.\n\n---\n\n**Migration guide from version 2.x to 3.x is available [here](https://docs.espressif.com/projects/arduino-esp32/en/latest/migration_guides/2.x_to_3.0.html).**\n\n---\n\n**APIs compatibility with ESP8266 and Arduino-CORE (Arduino.cc) is explained [here](https://docs.espressif.com/projects/arduino-esp32/en/latest/libraries.html#apis).**\n\n---\n\n* [Getting Started](https://docs.espressif.com/projects/arduino-esp32/en/latest/getting_started.html)\n* [Installing (Windows, Linux and macOS)](https://docs.espressif.com/projects/arduino-esp32/en/latest/installing.html)\n* [Libraries](https://docs.espressif.com/projects/arduino-esp32/en/latest/libraries.html)\n* [Arduino as an ESP-IDF component](https://docs.espressif.com/projects/arduino-esp32/en/latest/esp-idf_component.html)\n* [FAQ](https://docs.espressif.com/projects/arduino-esp32/en/latest/faq.html)\n* [Troubleshooting](https://docs.espressif.com/projects/arduino-esp32/en/latest/troubleshooting.html)\n\n### Supported Chips\n\nHere are the ESP32 series supported by the Arduino-ESP32 project:\n\n| **SoC**  | **Stable** | **Development** |                                           **Datasheet**                                           |\n|----------|:----------:|:---------------:|:-------------------------------------------------------------------------------------------------:|\n| ESP32    |     Yes    |       Yes       |    [ESP32](https://www.espressif.com/sites/default/files/documentation/esp32_datasheet_en.pdf)    |\n| ESP32-C3 |     Yes    |       Yes       | [ESP32-C3](https://www.espressif.com/sites/default/files/documentation/esp32-c3_datasheet_en.pdf) |\n| ESP32-C5 |     Yes    |       Yes       | [ESP32-C5](https://www.espressif.com/sites/default/files/documentation/esp32-c5_datasheet_en.pdf) |\n| ESP32-C6 |     Yes    |       Yes       | [ESP32-C6](https://www.espressif.com/sites/default/files/documentation/esp32-c6_datasheet_en.pdf) |\n| ESP32-H2 |     Yes    |       Yes       | [ESP32-H2](https://www.espressif.com/sites/default/files/documentation/esp32-h2_datasheet_en.pdf) |\n| ESP32-P4 |     Yes    |       Yes       | [ESP32-P4](https://www.espressif.com/sites/default/files/documentation/esp32-p4_datasheet_en.pdf) |\n| ESP32-S2 |     Yes    |       Yes       | [ESP32-S2](https://www.espressif.com/sites/default/files/documentation/esp32-s2_datasheet_en.pdf) |\n| ESP32-S3 |     Yes    |       Yes       | [ESP32-S3](https://www.espressif.com/sites/default/files/documentation/esp32-s3_datasheet_en.pdf) |\n\n> [!NOTE]\n> ESP32-C2 and ESP32-C61 are also supported by Arduino-ESP32 but require using Arduino as an ESP-IDF component or rebuilding the static libraries.\n> For more information, see the [Arduino as an ESP-IDF component documentation](https://docs.espressif.com/projects/arduino-esp32/en/latest/esp-idf_component.html) or the\n> [Lib Builder documentation](https://docs.espressif.com/projects/arduino-esp32/en/latest/lib_builder.html), respectively.\n\nFor more details visit the [supported chips](https://docs.espressif.com/projects/arduino-esp32/en/latest/getting_started.html#supported-soc-s) documentation page.\n\n### Decoding exceptions\n\nYou can use [EspExceptionDecoder](https://github.com/me-no-dev/EspExceptionDecoder) to get meaningful call trace.\n\n### Issue/Bug report template\n\nBefore reporting an issue, make sure you've searched for similar one that was already created. Also make sure to go through all the issues labeled as [Type: For reference](https://github.com/espressif/arduino-esp32/issues?q=is%3Aissue+label%3A%22Type%3A+For+reference%22+).\n\nFinally, if you are sure no one else had the issue, follow the **Issue template** or **Feature request template** while reporting any [new Issue](https://github.com/espressif/arduino-esp32/issues/new/choose).\n\n### External libraries compilation test\n\nWe have set-up CI testing for external libraries for ESP32 Arduino core. You can check test results in the file [LIBRARIES_TEST](https://github.com/espressif/arduino-esp32/blob/gh-pages/LIBRARIES_TEST.md).\nFor more information and how to add your library to the test see [external library testing](https://docs.espressif.com/projects/arduino-esp32/en/latest/external_libraries_test.html) in the documentation.\n\n### Contributing\n\nWe welcome contributions to the Arduino ESP32 project!\n\nSee [contributing](https://docs.espressif.com/projects/arduino-esp32/en/latest/contributing.html) in the documentation for more information on how to contribute to the project.\n\n> We would like to have this repository in a polite and friendly atmosphere, so please be kind and respectful to others. For more details, look at [Code of Conduct](https://github.com/espressif/arduino-esp32/blob/master/CODE_OF_CONDUCT.md).\n",
      "stars_today": 7
    },
    {
      "id": 304344049,
      "name": "kit",
      "full_name": "sveltejs/kit",
      "description": "web development, streamlined",
      "html_url": "https://github.com/sveltejs/kit",
      "stars": 20205,
      "forks": 2194,
      "language": "JavaScript",
      "topics": [
        "hacktoberfest",
        "svelte"
      ],
      "created_at": "2020-10-15T14:00:23Z",
      "updated_at": "2026-01-23T00:20:23Z",
      "pushed_at": "2026-01-23T00:21:12Z",
      "open_issues": 1069,
      "owner": {
        "login": "sveltejs",
        "avatar_url": "https://avatars.githubusercontent.com/u/23617963?v=4"
      },
      "readme": "[![Chat](https://img.shields.io/discord/457912077277855764?label=chat&logo=discord)](https://svelte.dev/chat)\n\n# SvelteKit\n\nWeb development, streamlined. Read the [documentation](https://svelte.dev/docs/kit) to get started.\n\n### Packages\n\n| Package                                                                     | Changelog                                                     |\n| --------------------------------------------------------------------------- | ------------------------------------------------------------- |\n| [@sveltejs/kit](packages/kit)                                               | [Changelog](packages/kit/CHANGELOG.md)                        |\n| [@sveltejs/adapter-auto](packages/adapter-auto)                             | [Changelog](packages/adapter-auto/CHANGELOG.md)               |\n| [@sveltejs/adapter-cloudflare](packages/adapter-cloudflare)                 | [Changelog](packages/adapter-cloudflare/CHANGELOG.md)         |\n| [@sveltejs/adapter-netlify](packages/adapter-netlify)                       | [Changelog](packages/adapter-netlify/CHANGELOG.md)            |\n| [@sveltejs/adapter-node](packages/adapter-node)                             | [Changelog](packages/adapter-node/CHANGELOG.md)               |\n| [@sveltejs/adapter-static](packages/adapter-static)                         | [Changelog](packages/adapter-static/CHANGELOG.md)             |\n| [@sveltejs/adapter-vercel](packages/adapter-vercel)                         | [Changelog](packages/adapter-vercel/CHANGELOG.md)             |\n| [@sveltejs/amp](packages/amp)                                               | [Changelog](packages/amp/CHANGELOG.md)                        |\n| [@sveltejs/enhanced-img](packages/enhanced-img)                             | [Changelog](packages/enhanced-img/CHANGELOG.md)               |\n| [@sveltejs/package](packages/package)                                       | [Changelog](packages/package/CHANGELOG.md)                    |\n\n[Additional adapters](https://sveltesociety.dev/packages?category=sveltekit-adapters) are maintained by the community.\n\n## Bug reporting\n\nPlease make sure the issue you're reporting involves SvelteKit. Many issues related to how a project builds originate from [Vite](https://vitejs.dev/), which is used to build a SvelteKit project. You can create a new Vite project with `npm create vite@latest` for client-side only repros and `npm create vite-extra@latest` for SSR or library repros.\n\nIf an issue originates from Vite, please report it in the [Vite issue tracker](https://github.com/vitejs/vite/issues).\n\n## Contributing\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for information on how to develop SvelteKit locally.\n\n## Supporting Svelte\n\nSvelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you'd like to support their efforts, please consider:\n\n- [Becoming a backer on Open Collective](https://opencollective.com/svelte).\n\nFunds donated via Open Collective will be used for compensating expenses related to Svelte's development such as hosting costs. If sufficient donations are received, funds may also be used to support Svelte's development more directly.\n\n## License\n\n[MIT](https://github.com/sveltejs/kit/blob/main/LICENSE)\n",
      "stars_today": 7
    },
    {
      "id": 48009214,
      "name": "react-native-windows",
      "full_name": "microsoft/react-native-windows",
      "description": "A framework for building native Windows apps with React.",
      "html_url": "https://github.com/microsoft/react-native-windows",
      "stars": 17162,
      "forks": 1188,
      "language": "C++",
      "topics": [
        "dotnet",
        "react",
        "react-native",
        "uwp",
        "xbox"
      ],
      "created_at": "2015-12-15T00:16:54Z",
      "updated_at": "2026-01-22T09:31:12Z",
      "pushed_at": "2026-01-22T13:03:21Z",
      "open_issues": 758,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "![Hero Image with Logo](https://github.com/microsoft/react-native-windows/raw/main/.github/hero3.png)\n\n<h1 align=\"center\"> React Native for Windows </h1>\n\n<p align=\"center\">\n  <a href=\"https://twitter.com/intent/follow?&screen_name=ReactNativeMSFT\">\n    <img src=\"https://img.shields.io/twitter/follow/ReactNativeMSFT?style=for-the-badge&logo=X&labelColor=black&color=white\" alt=\"Follow @ReactNativeMSFT\" />\n  </a>\n</p>\n\n<h3 align=\"center\">\n  <a href=\"https://microsoft.github.io/react-native-windows\">Website</a>\n  <span> ¬∑ </span>\n  <a href=\"https://microsoft.github.io/react-native-windows/docs/getting-started\">Documentation</a>\n  <span> ¬∑ </span>\n  <a href=\"https://github.com/microsoft/react-native-windows/releases\">Release notes</a>\n</h3>\n\n> See the official [React Native website](https://reactnative.dev/) for an introduction to React Native.\n\n[React Native](https://reactnative.dev) is a framework developed by Meta that enables you to build world-class application experiences on native platforms using a consistent developer experience based on JavaScript and [React](https://reactjs.org/). The focus of React Native is on developer efficiency across all the platforms you care about - learn once, write anywhere.\n\nThis repository adds support for the [Windows 10 SDK](https://developer.microsoft.com/en-us/windows/downloads), which allows you to build apps for [all devices supported by Windows 10](https://developer.microsoft.com/en-us/windows/get-started-windows-10) including PCs, tablets, 2-in-1s, Xbox, Mixed reality devices etc.\n\nVisit the official [React Native for Windows + macOS website](https://microsoft.github.io/react-native-windows) to learn more.\n\n## üõ£Ô∏è Roadmap\n[Check out our blog](https://microsoft.github.io/react-native-windows/blog/) if you'd like to stay up to date on the status of React Native for Windows and check out current and past roadmaps.\n\n### New Architecture\n[Fabric](https://reactnative.dev/architecture/fabric-renderer) is the new rendering system for React Native, designed to share more rendering logic cross-platform. RNW's existing Paper renderer is built on UWP XAML, dropping down into native Composition as need be; the new RNW Fabric renderer targets Composition from the start but has the ability to host islands of XAML for advanced native controls. Apps on the new architecture will be [WinAppSDK](https://learn.microsoft.com/en-us/windows/apps/windows-app-sdk/) Win32 by default. For more details on our roadmap to Fabric, check out [this pinned issue](https://github.com/microsoft/react-native-windows/issues/12042).\n\n## üñºÔ∏è React Native Gallery\nMake sure to also check out the [React Native Gallery](https://github.com/microsoft/react-native-gallery), our interactive sample experience showing everything you can do with React Native for Windows.\n\n<p align=\"center\">\n<img src=\"docs/img/rn-gallery.png\" alt=\"WinUI 3 Gallery\" width=\"400\"/>\n</p>\n<p align=\"center\">\n<a href=\"https://www.microsoft.com/en-us/p/react-native-gallery/9npg0b292h4r?launch=true\n\t&mode=mini\">\n\t<img src=\"docs/img/storeBadge.png\" width=\"200\"/>\n</a>\n</p>\n</br>\n\n## üìã Getting Started\nSee the [Getting Started Guide](https://microsoft.github.io/react-native-windows/docs/getting-started) on our React Native for Windows + macOS website to build your first React Native for Windows app.\n\n### Requirements\nYou can run React Native Windows apps only on devices supported by the [Windows 10 SDK](https://developer.microsoft.com/en-us/windows/downloads).\n\nFor a full and detailed list of the system requirements and how to set up your development platform, see our [System Requirements](https://microsoft.github.io/react-native-windows/docs/rnw-dependencies) documentation on our website.\n\n### Logging Issues\nSearch the [existing issues](https://github.com/microsoft/react-native-windows/issues) and try to make sure your problem doesn‚Äôt already exist before opening a new issue. If your issue doesn't exist yet, provide as much information as possible so we can better help you. Include the information requested by the [appropriate issue template](https://github.com/microsoft/react-native-windows/issues/new/choose).\n\n## Documentation\nReact Native has [great documentation](https://reactnative.dev/docs/getting-started). React Native for Windows adds its own separate [Windows and macOS documentation](https://microsoft.github.io/react-native-windows/) for desktop platform information like API docs and blog updates.\n\n### Examples\n- Using the CLI in the [Getting Started](https://microsoft.github.io/react-native-windows/docs/getting-started) guide will set you up with a sample React Native for Windows app that you can begin editing right away.\n- Check the [samples repo](https://github.com/microsoft/react-native-windows-samples) for more standalone samples.\n- The [React Native Gallery](https://github.com/microsoft/react-native-gallery) app demonstrates various components in an interactive way.\n- Check out the [React Native Developer Blog](https://devblogs.microsoft.com/react-native/) to see examples from past conference talks, blog posts, and more.\n- For more sample code browse the [RNTester folder](https://github.com/microsoft/react-native-windows/tree/main/packages/e2e-test-app-fabric/windows/RNTesterApp) in the GitHub web UI.\n\n## üì¢ Contributing\nSee [Contributing guidelines](https://github.com/microsoft/react-native-windows/blob/main/CONTRIBUTING.md) for how to setup your fork of the repo and start a PR to contribute to React Native for Windows.\n\nNot sure where to start? The [good first issue](https://github.com/microsoft/react-native-windows/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22) and [help wanted](https://github.com/microsoft/react-native-windows/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22help%20wanted%22) labels are the best starting points.\n\n## Code of Conduct\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n",
      "stars_today": 7
    },
    {
      "id": 79307564,
      "name": "WeChatTweak",
      "full_name": "sunnyyoung/WeChatTweak",
      "description": "A command-line tool for tweaking WeChat - È¶ñÊ¨æÂæÆ‰ø° macOS ÂÆ¢Êà∑Á´ØÊí§ÂõûÊã¶Êà™‰∏éÂ§öÂºÄ üî®",
      "html_url": "https://github.com/sunnyyoung/WeChatTweak",
      "stars": 13299,
      "forks": 1566,
      "language": "Swift",
      "topics": [
        "alfred",
        "alfred-workflow",
        "macos",
        "no-revoke",
        "norevoke",
        "raycast-extension",
        "revoke",
        "tweak",
        "wechat",
        "wechat-macos",
        "wechat-plugin",
        "wechat-plugin-macos",
        "wechat-raycast",
        "wechat-tweak",
        "wechathook",
        "wechattweak",
        "wechattweak-macos",
        "weixin",
        "weixin-plugin",
        "weixin-tweak"
      ],
      "created_at": "2017-01-18T05:42:16Z",
      "updated_at": "2026-01-23T02:08:02Z",
      "pushed_at": "2025-12-13T17:05:51Z",
      "open_issues": 64,
      "owner": {
        "login": "sunnyyoung",
        "avatar_url": "https://avatars.githubusercontent.com/u/5926284?v=4"
      },
      "readme": "# WeChatTweak\n\n[![README](https://img.shields.io/badge/GitHub-black?logo=github&logoColor=white)](https://github.com/sunnyyoung/WeChatTweak)\n[![README](https://img.shields.io/badge/Telegram-black?logo=telegram&logoColor=white)](https://t.me/wechattweak)\n[![README](https://img.shields.io/badge/FAQ-black?logo=googledocs&logoColor=white)](https://github.com/sunnyyoung/WeChatTweak/wiki/FAQ)\n\nA command-line tool for tweaking WeChat.\n\n## ÂäüËÉΩ\n\n- ÈòªÊ≠¢Ê∂àÊÅØÊí§Âõû\n- ÈòªÊ≠¢Ëá™Âä®Êõ¥Êñ∞\n- ÂÆ¢Êà∑Á´ØÂ§öÂºÄ\n\n## ÂÆâË£Ö&‰ΩøÁî®\n\n```bash\n# ÂÆâË£Ö\nbrew install sunnyyoung/tap/wechattweak\n\n# Êõ¥Êñ∞\nbrew upgrade wechattweak\n\n# ÊâßË°å Patch\nwechattweak patch\n\n# Êü•ÁúãÊâÄÊúâÊîØÊåÅÁöÑ WeChat ÁâàÊú¨\nwechattweak versions\n```\n\n## ÂèÇËÄÉ\n\n- [ÂæÆ‰ø° macOS ÂÆ¢Êà∑Á´ØÊó†ÈôêÂ§öÂºÄÂäüËÉΩÂÆûË∑µ](https://blog.sunnyyoung.net/wei-xin-macos-ke-hu-duan-wu-xian-duo-kai-gong-neng-shi-jian/)\n- [ÂæÆ‰ø° macOS ÂÆ¢Êà∑Á´ØÊã¶Êà™Êí§ÂõûÂäüËÉΩÂÆûË∑µ](https://blog.sunnyyoung.net/wei-xin-macos-ke-hu-duan-lan-jie-che-hui-gong-neng-shi-jian/)\n- [ËÆ©ÂæÆ‰ø° macOS ÂÆ¢Êà∑Á´ØÊîØÊåÅ Alfred](https://blog.sunnyyoung.net/rang-wei-xin-macos-ke-hu-duan-zhi-chi-alfred/)\n\n## Ë¥°ÁåÆËÄÖ\n\nThis project exists thanks to all the people who contribute.\n\n[![Contributors](https://contrib.rocks/image?repo=sunnyyoung/WeChatTweak)](https://github.com/sunnyyoung/WeChatTweak/graphs/contributors)\n\n## License\n\nThe [AGPL-3.0](LICENSE).\n",
      "stars_today": 7
    },
    {
      "id": 189044704,
      "name": "AFLplusplus",
      "full_name": "AFLplusplus/AFLplusplus",
      "description": "The fuzzer afl++ is afl with community patches, qemu 5.1 upgrade, collision-free coverage, enhanced laf-intel & redqueen, AFLfast++ power schedules, MOpt mutators, unicorn_mode, and a lot more!",
      "html_url": "https://github.com/AFLplusplus/AFLplusplus",
      "stars": 6256,
      "forks": 1244,
      "language": "C",
      "topics": [
        "afl",
        "afl-compiler",
        "afl-fuzz",
        "afl-fuzzer",
        "afl-gcc",
        "fuzz-testing",
        "fuzzer",
        "fuzzer-afl",
        "fuzzing",
        "instrumentation",
        "qemu",
        "security",
        "testing",
        "unicorn-emulator",
        "unicorn-mode"
      ],
      "created_at": "2019-05-28T14:29:06Z",
      "updated_at": "2026-01-22T14:16:52Z",
      "pushed_at": "2026-01-22T11:33:05Z",
      "open_issues": 33,
      "owner": {
        "login": "AFLplusplus",
        "avatar_url": "https://avatars.githubusercontent.com/u/62360046?v=4"
      },
      "readme": "# American Fuzzy Lop plus plus (AFL++)\n\n<img align=\"right\" src=\"https://raw.githubusercontent.com/AFLplusplus/Website/main/static/aflpp_bg.svg\" alt=\"AFL++ logo\" width=\"250\" height=\"250\">\n\nRelease version: [4.35c](https://github.com/AFLplusplus/AFLplusplus/releases)\n\nGitHub version: 4.36a\n\nRepository:\n[https://github.com/AFLplusplus/AFLplusplus](https://github.com/AFLplusplus/AFLplusplus)\n\nAFL++ is maintained by:\n\n* Marc \"van Hauser\" Heuse <mh@mh-sec.de>\n* Dominik Maier <mail@dmnk.co>\n* Andrea Fioraldi <andreafioraldi@gmail.com>\n* Heiko \"hexcoder-\" Eissfeldt <heiko.eissfeldt@hexco.de>\n* frida_mode is maintained by @Worksbutnottested\n\nOriginally developed by Michal \"lcamtuf\" Zalewski.\n\nAFL++ is a superior fork to Google's AFL - more speed, more and better\nmutations, more and better instrumentation, custom module support, etc.\n\nYou are free to copy, modify, and distribute AFL++ with attribution under the\nterms of the Apache-2.0 License. See the [LICENSE](LICENSE) for details.\n\n## Getting started\n\nHere is some information to get you started:\n\n* For an overview of the AFL++ documentation and a very helpful graphical guide,\n  please visit [docs/README.md](docs/README.md).\n* To get you started with tutorials, go to\n  [docs/tutorials.md](docs/tutorials.md).\n* For releases, see the\n  [Releases tab](https://github.com/AFLplusplus/AFLplusplus/releases) and\n  [branches](#branches). The best branches to use are, however, `stable` or\n  `dev` - depending on your risk appetite. Also take a look at the list of\n  [important changes in AFL++](docs/important_changes.md) and the list of\n  [features](docs/features.md).\n* If you want to use AFL++ for your academic work, check the\n  [papers page](https://aflplus.plus/papers/) on the website.\n* To cite our work, look at the [Cite](#cite) section.\n* For comparisons, use the fuzzbench `aflplusplus` setup, or use\n  `afl-clang-fast` with `AFL_LLVM_CMPLOG=1`. You can find the `aflplusplus`\n  default configuration on Google's\n  [fuzzbench](https://github.com/google/fuzzbench/tree/master/fuzzers/aflplusplus).\n\n## Building and installing AFL++\n\nTo have AFL++ easily available with everything compiled, pull the image directly\nfrom the Docker Hub (available for both x86_64 and arm64):\n\n```shell\ndocker pull aflplusplus/aflplusplus\ndocker run -ti -v /location/of/your/target:/src aflplusplus/aflplusplus\n```\n\nThis image is automatically published when a push to the stable branch happens\n(see [branches](#branches)). If you use the command above, you will find your\ntarget source code in `/src` in the container.\n\nNote: you can also pull `aflplusplus/aflplusplus:dev` which is the most current\ndevelopment state of AFL++.\n\nTo build AFL++ yourself - *which we recommend* - continue at\n[docs/INSTALL.md](docs/INSTALL.md).\n\n## Quick start: Fuzzing with AFL++\n\n*NOTE: Before you start, please read about the\n[common sense risks of fuzzing](docs/fuzzing_in_depth.md#0-common-sense-risks).*\n\nThis is a quick start for fuzzing targets with the source code available. To\nread about the process in detail, see\n[docs/fuzzing_in_depth.md](docs/fuzzing_in_depth.md).\n\nTo learn about fuzzing other targets, see:\n* Binary-only targets:\n  [docs/fuzzing_binary-only_targets.md](docs/fuzzing_binary-only_targets.md)\n* Network services:\n  [docs/best_practices.md#fuzzing-a-network-service](docs/best_practices.md#fuzzing-a-network-service)\n* GUI programs:\n  [docs/best_practices.md#fuzzing-a-gui-program](docs/best_practices.md#fuzzing-a-gui-program)\n\nStep-by-step quick start:\n\n1. Compile the program or library to be fuzzed using `afl-cc`. A common way to\n   do this would be:\n\n   ```\n   CC=/path/to/afl-cc CXX=/path/to/afl-c++ ./configure --disable-shared\n   make clean all\n   ```\n\n2. Get a small but valid input file that makes sense to the program. When\n   fuzzing verbose syntax (SQL, HTTP, etc.), create a dictionary as described in\n   [dictionaries/README.md](dictionaries/README.md), too.\n\n3. If the program reads from stdin, run `afl-fuzz` like so:\n\n   ```\n   ./afl-fuzz -i seeds_dir -o output_dir -- \\\n   /path/to/tested/program [...program's cmdline...]\n   ```\n\n   To add a dictionary, add `-x /path/to/dictionary.txt` to afl-fuzz.\n\n   If the program takes input from a file, you can put `@@` in the program's\n   command line; AFL++ will put an auto-generated file name in there for you.\n\n4. Investigate anything shown in red in the fuzzer UI by promptly consulting\n   [docs/afl-fuzz_approach.md#understanding-the-status-screen](docs/afl-fuzz_approach.md#understanding-the-status-screen).\n\n5. You will find found crashes and hangs in the subdirectories `crashes/` and\n   `hangs/` in the `-o output_dir` directory. You can replay the crashes by\n   feeding them to the target, e.g. if your target is using stdin:\n\n   ```\n   cat output_dir/crashes/id:000000,* | /path/to/tested/program [...program's cmdline...]\n   ```\n\n   You can generate cores or use gdb directly to follow up the crashes.\n\n6. We cannot stress this enough - if you want to fuzz effectively, read the\n   [docs/fuzzing_in_depth.md](docs/fuzzing_in_depth.md) document!\n\n## Contact\n\nQuestions? Concerns? Bug reports?\n\n* The contributors can be reached via (e.g., by creating an issue):\n  [https://github.com/AFLplusplus/AFLplusplus](https://github.com/AFLplusplus/AFLplusplus).\n* Take a look at our [FAQ](docs/FAQ.md). If you find an interesting or important\n  question missing, submit it via\n  [https://github.com/AFLplusplus/AFLplusplus/discussions](https://github.com/AFLplusplus/AFLplusplus/discussions).\n* Best: join the [Awesome Fuzzing](https://discord.gg/gCraWct) Discord server.\n* There is a (not really used) mailing list for the AFL/AFL++ project\n  ([browse archive](https://groups.google.com/group/afl-users)). To compare\n  notes with other users or to get notified about major new features, send an\n  email to <afl-users+subscribe@googlegroups.com>, but note that this is not\n  managed by us.\n\n## Branches\n\nThe following branches exist:\n\n* [release](https://github.com/AFLplusplus/AFLplusplus/tree/release): the latest\n  release\n* [stable/trunk](https://github.com/AFLplusplus/AFLplusplus/): stable state of\n  AFL++ - it is synced from dev from time to time when we are satisfied with its\n  stability\n* [dev](https://github.com/AFLplusplus/AFLplusplus/tree/dev): development state\n  of AFL++ - bleeding edge and you might catch a checkout which does not compile\n  or has a bug. **We only accept PRs (pull requests) for the 'dev' branch!**\n* (any other): experimental branches to work on specific features or testing new\n  functionality or changes.\n\n## Help wanted\n\nWe have several [ideas](docs/ideas.md) we would like to see in AFL++ to make it\neven better. However, we already work on so many things that we do not have the\ntime for all the big ideas.\n\nThis can be your way to support and contribute to AFL++ - extend it to do\nsomething cool.\n\nFor everyone who wants to contribute (and send pull requests), please read our\n[contributing guidelines](CONTRIBUTING.md) before you submit.\n\n## Special thanks\n\nMany of the improvements to the original AFL and AFL++ wouldn't be possible\nwithout feedback, bug reports, or patches from our contributors.\n\nThank you! (For people sending pull requests - please add yourself to this list\n:-)\n\n<details>\n\n  <summary>List of contributors</summary>\n\n  ```\n    Jann Horn                             Hanno Boeck\n    Felix Groebert                        Jakub Wilk\n    Richard W. M. Jones                   Alexander Cherepanov\n    Tom Ritter                            Hovik Manucharyan\n    Sebastian Roschke                     Eberhard Mattes\n    Padraig Brady                         Ben Laurie\n    @dronesec                             Luca Barbato\n    Tobias Ospelt                         Thomas Jarosch\n    Martin Carpenter                      Mudge Zatko\n    Joe Zbiciak                           Ryan Govostes\n    Michael Rash                          William Robinet\n    Jonathan Gray                         Filipe Cabecinhas\n    Nico Weber                            Jodie Cunningham\n    Andrew Griffiths                      Parker Thompson\n    Jonathan Neuschaefer                  Tyler Nighswander\n    Ben Nagy                              Samir Aguiar\n    Aidan Thornton                        Aleksandar Nikolich\n    Sam Hakim                             Laszlo Szekeres\n    David A. Wheeler                      Turo Lamminen\n    Andreas Stieger                       Richard Godbee\n    Louis Dassy                           teor2345\n    Alex Moneger                          Dmitry Vyukov\n    Keegan McAllister                     Kostya Serebryany\n    Richo Healey                          Martijn Bogaard\n    rc0r                                  Jonathan Foote\n    Christian Holler                      Dominique Pelle\n    Jacek Wielemborek                     Leo Barnes\n    Jeremy Barnes                         Jeff Trull\n    Guillaume Endignoux                   ilovezfs\n    Daniel Godas-Lopez                    Franjo Ivancic\n    Austin Seipp                          Daniel Komaromy\n    Daniel Binderman                      Jonathan Metzman\n    Vegard Nossum                         Jan Kneschke\n    Kurt Roeckx                           Marcel Boehme\n    Van-Thuan Pham                        Abhik Roychoudhury\n    Joshua J. Drake                       Toby Hutton\n    Rene Freingruber                      Sergey Davidoff\n    Sami Liedes                           Craig Young\n    Andrzej Jackowski                     Daniel Hodson\n    Nathan Voss                           Dominik Maier\n    Andrea Biondo                         Vincent Le Garrec\n    Khaled Yakdan                         Kuang-che Wu\n    Josephine Calliotte                   Konrad Welc\n    Thomas Rooijakkers                    David Carlier\n    Ruben ten Hove                        Joey Jiao\n    fuzzah                                @intrigus-lgtm\n    Yaakov Saxon                          Sergej Schumilo\n    Ziqiao Kong                           Ryan Berger\n    Sangjun Park                          Scott Guest\n    Fabian Keil\n  ```\n\n</details>\n\n## Cite\n\nIf you use AFL++ in scientific work, consider citing\n[our paper](https://www.usenix.org/conference/woot20/presentation/fioraldi)\npresented at WOOT'20:\n\n    Andrea Fioraldi, Dominik Maier, Heiko Ei√üfeldt, and Marc Heuse. ‚ÄúAFL++: Combining incremental steps of fuzzing research‚Äù. In 14th USENIX Workshop on Offensive Technologies (WOOT 20). USENIX Association, Aug. 2020.\n\n<details>\n\n<summary>BibTeX</summary>\n\n  ```bibtex\n  @inproceedings {AFLplusplus-Woot20,\n  author = {Andrea Fioraldi and Dominik Maier and Heiko Ei{\\ss}feldt and Marc Heuse},\n  title = {{AFL++}: Combining Incremental Steps of Fuzzing Research},\n  booktitle = {14th {USENIX} Workshop on Offensive Technologies ({WOOT} 20)},\n  year = {2020},\n  publisher = {{USENIX} Association},\n  month = aug,\n  }\n  ```\n\n</details>\n\n[![zread](https://img.shields.io/badge/Ask_Zread-_.svg?style=flat&color=00b0aa&labelColor=000000&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&logoColor=ffffff)](https://zread.ai/AFLplusplus/AFLplusplus)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/AFLplusplus/AFLplusplus)\n",
      "stars_today": 7
    },
    {
      "id": 206791328,
      "name": "highway",
      "full_name": "google/highway",
      "description": "Performance-portable, length-agnostic SIMD with runtime dispatch",
      "html_url": "https://github.com/google/highway",
      "stars": 5282,
      "forks": 399,
      "language": "C++",
      "topics": [
        "avx",
        "avx-512",
        "avx-instructions",
        "avx2",
        "avx512",
        "intrinsics",
        "neon",
        "simd",
        "simd-instructions",
        "simd-intrinsics",
        "simd-library",
        "simd-parallelism",
        "simd-programming",
        "sse42",
        "wasm"
      ],
      "created_at": "2019-09-06T12:41:23Z",
      "updated_at": "2026-01-22T15:19:51Z",
      "pushed_at": "2026-01-20T23:15:18Z",
      "open_issues": 54,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# Efficient and performance-portable vector software\n\n[//]: # (placeholder, do not remove)\n\nHighway is a C++ library that provides portable SIMD/vector intrinsics.\n\n[Documentation](https://google.github.io/highway/en/master/)\n\nPreviously licensed under Apache 2, now dual-licensed as Apache 2 / BSD-3.\n\n## Why\n\nWe are passionate about high-performance software. We see major untapped\npotential in CPUs (servers, mobile, desktops). Highway is for engineers who want\nto reliably and economically push the boundaries of what is possible in\nsoftware.\n\n## How\n\nCPUs provide SIMD/vector instructions that apply the same operation to multiple\ndata items. This can reduce energy usage e.g. *fivefold* because fewer\ninstructions are executed. We also often see *5-10x* speedups.\n\nHighway makes SIMD/vector programming practical and workable according to these\nguiding principles:\n\n**Does what you expect**: Highway is a C++ library with carefully-chosen\nfunctions that map well to CPU instructions without extensive compiler\ntransformations. The resulting code is more predictable and robust to code\nchanges/compiler updates than autovectorization.\n\n**Works on widely-used platforms**: Highway supports seven architectures; the\nsame application code can target various instruction sets, including those with\n'scalable' vectors (size unknown at compile time). Highway only requires C++17\n(language features, not necessarily the library) and supports four families of\ncompilers. If you want to use Highway on other platforms, please raise an issue.\n\n**Flexible to deploy**: Applications using Highway can run on heterogeneous\nclouds or client devices, choosing the best available instruction set at\nruntime. Alternatively, developers may choose to target a single instruction set\nwithout any runtime overhead. In both cases, the application code is the same\nexcept for swapping `HWY_STATIC_DISPATCH` with `HWY_DYNAMIC_DISPATCH` plus one\nline of code. See also @kfjahnke's\n[introduction to dispatching](https://github.com/kfjahnke/zimt/blob/main/examples/multi_isa_example/multi_simd_isa.md).\n\n**Suitable for a variety of domains**: Highway provides an extensive set of\noperations, used for image processing (floating-point), compression, video\nanalysis, linear algebra, cryptography, sorting and random generation. We\nrecognise that new use-cases may require additional ops and are happy to add\nthem where it makes sense (e.g. no performance cliffs on some architectures). If\nyou would like to discuss, please file an issue.\n\n**Rewards data-parallel design**: Highway provides tools such as Gather,\nMaskedLoad, and FixedTag to enable speedups for legacy data structures. However,\nthe biggest gains are unlocked by designing algorithms and data structures for\nscalable vectors. Helpful techniques include batching, structure-of-array\nlayouts, and aligned/padded allocations.\n\nWe recommend these resources for getting started:\n\n-   [SIMD programming with Highway talk](https://www.youtube.com/watch?v=R57biOOhnJM)\n-   [SIMD for C++ Developers](http://const.me/articles/simd/simd.pdf)\n-   [Algorithms for Modern Hardware](https://en.algorithmica.org/hpc/)\n-   [Optimizing software in C++](https://agner.org/optimize/optimizing_cpp.pdf)\n-   [Improving performance with SIMD intrinsics in three use cases](https://stackoverflow.blog/2020/07/08/improving-performance-with-simd-intrinsics-in-three-use-cases/)\n\n## Examples\n\nOnline demos using Compiler Explorer:\n\n-   [multiple targets with dynamic dispatch](https://gcc.godbolt.org/z/KM3ben7ET)\n    (more complicated, but flexible and uses best available SIMD)\n-   [single target using -m flags](https://gcc.godbolt.org/z/rGnjMevKG)\n    (simpler, but requires/only uses the instruction set enabled by compiler\n    flags)\n\nWe observe that Highway is referenced in the following open source projects,\nfound via sourcegraph.com. Most are GitHub repositories. If you would like to\nadd your project or link to it directly, feel free to raise an issue or contact\nus via the below email.\n\n*   Audio: [Zimtohrli perceptual metric](https://github.com/google/zimtohrli)\n*   Browsers: Chromium (+Vivaldi), Firefox (+floorp / foxhound / librewolf /\n    Waterfox)\n*   Computational biology: [RNA analysis](https://github.com/bnprks/BPCells),\n    [long-sequence preprocessing](https://github.com/OpenGene/fastplong)\n*   Computer graphics: ghostty-org/ghostty,\n    [Sparse voxel renderer](https://github.com/rools/voxl),\n    [tgfx 2D Graphics library](https://github.com/Tencent/tgfx)\n*   Cryptography: google/distributed_point_functions, google/shell-encryption\n*   Data structures: bkille/BitLib\n*   Image codecs: eustas/2im,\n    [Grok JPEG 2000](https://github.com/GrokImageCompression/grok),\n    [JPEG XL](https://github.com/libjxl/libjxl),\n    [JPEGenc](https://github.com/osamu620/JPEGenc),\n    [Jpegli](https://github.com/google/jpegli),\n    [libaom](https://aomedia.googlesource.com/aom/),\n    [OpenHTJ2K](https://github.com/osamu620/OpenHTJ2K)\n*   Image processing: awxkee/aire, cloudinary/ssimulacra2,\n    [libvips](https://github.com/libvips/libvips), m-ab-s/media-autobuild_suite,\n*   Image viewers: AlienCowEatCake/ImageViewer, diffractor/diffractor,\n    [Lux panorama/image viewer](https://bitbucket.org/kfj/pv/),\n    mirillis/jpegxl-wic\n*   Information retrieval:\n    [iresearch database index](https://github.com/iresearch-toolkit/iresearch),\n    michaeljclark/zvec,\n    [nebula interactive analytics / OLAP](https://github.com/varchar-io/nebula),\n    [`ScaNN` Scalable Nearest Neighbors](https://github.com/google-research/google-research/tree/7a269cb2ce0ae1db591fe11b62cbc0be7d72532a/scann),\n*   Machine learning: array2d/deepx,\n    [gemma.cpp](https://github.com/google/gemma.cpp), Tensorflow, Numpy,\n    zpye/SimpleInfer\n*   Programming languages:\n    [AOT-compiled python](https://github.com/exaloop/codon), oven-sh/bun, V8/V8,\n    yinqiwen/rapidudf\n*   Robotics:\n    [MIT Model-Based Design and Verification](https://github.com/RobotLocomotion/drake)\n*   Vector search: 1yefuwang1/vectorlite, vespa-engine/vespa\n\nOther\n\n*   [Evaluation of C++ SIMD Libraries](https://www.mnm-team.org/pub/Fopras/rock23/):\n    \"Highway excelled with a strong performance across multiple SIMD extensions\n    [..]. Thus, Highway may currently be the most suitable SIMD library for many\n    software projects.\"\n*   [zimt](https://github.com/kfjahnke/zimt): C++11 template library to process n-dimensional arrays with multi-threaded SIMD code\n*   [vectorized Quicksort](https://github.com/google/highway/tree/master/hwy/contrib/sort) ([paper](https://arxiv.org/abs/2205.05982))\n\nIf you'd like to get Highway, in addition to cloning from this GitHub repository\nor using it as a Git submodule, you can also find it in the following package\nmanagers or repositories:\n\n*   alpinelinux\n*   conan-io\n*   conda-forge\n*   DragonFlyBSD,\n*   fd00/yacp\n*   freebsd\n*   getsolus/packages\n*   ghostbsd\n*   microsoft/vcpkg\n*   MidnightBSD\n*   MSYS2\n*   NetBSD\n*   openSUSE\n*   opnsense\n*   Xilinx/Vitis_Libraries\n*   xmake-io/xmake-repo\n\nSee also the list at https://repology.org/project/highway-simd-library/versions\n.\n\n## Current status\n\n### Targets\n\nHighway supports 27 targets, listed in alphabetical order of platform:\n\n-   Any: `EMU128`, `SCALAR`;\n-   Armv7+: `NEON_WITHOUT_AES`, `NEON`, `NEON_BF16`, `SVE`, `SVE2`, `SVE_256`,\n    `SVE2_128`;\n-   IBM Z: `Z14`, `Z15`;\n-   LoongArch: `LSX`, `LASX`;\n-   POWER: `PPC8` (v2.07), `PPC9` (v3.0), `PPC10` (v3.1B, not yet supported due\n    to compiler bugs, see #1207; also requires QEMU 7.2);\n-   RISC-V: `RVV` (1.0);\n-   WebAssembly: `WASM`, `WASM_EMU256` (a 2x unrolled version of wasm128,\n    enabled if `HWY_WANT_WASM2` is defined. This will remain supported until it\n    is potentially superseded by a future version of WASM.);\n-   x86:\n    -   `SSE2`\n    -   `SSSE3` (~Intel Core)\n    -   `SSE4` (~Nehalem, also includes AES + CLMUL).\n    -   `AVX2` (~Haswell, also includes BMI2 + F16 + FMA)\n    -   `AVX3` (~Skylake, AVX-512F/BW/CD/DQ/VL)\n    -   `AVX3_DL` (~Icelake, includes `BitAlg` + `CLMUL` + `GFNI` + `VAES` +\n        `VBMI` + `VBMI2` + `VNNI` + `VPOPCNT`),\n    -   `AVX3_ZEN4` (AVX3_DL plus BF16, optimized for AMD Zen4; requires opt-in\n        by defining `HWY_WANT_AVX3_ZEN4` if compiling for static dispatch, but\n        enabled by default for runtime dispatch),\n    -   `AVX3_SPR` (~Sapphire Rapids, includes AVX-512FP16)\n    -   `AVX10_2` (~Diamond Rapids)\n\nOur policy is that unless otherwise specified, targets will remain supported as\nlong as they can be (cross-)compiled with currently supported Clang or GCC, and\ntested using QEMU. If the target can be compiled with LLVM trunk and tested\nusing our version of QEMU without extra flags, then it is eligible for inclusion\nin our continuous testing infrastructure. Otherwise, the target will be manually\ntested before releases with selected versions/configurations of Clang and GCC.\n\nSVE was initially tested using farm_sve (see acknowledgments).\n\n### Versioning\n\nHighway releases aim to follow the semver.org system (MAJOR.MINOR.PATCH),\nincrementing MINOR after backward-compatible additions and PATCH after\nbackward-compatible fixes. We recommend using releases (rather than the Git tip)\nbecause they are tested more extensively, see below.\n\nThe current version 1.0 signals an increased focus on backwards compatibility.\nApplications using documented functionality will remain compatible with future\nupdates that have the same major version number.\n\n### Testing\n\nContinuous integration tests build with a recent version of Clang (running on\nnative x86, or QEMU for RISC-V and Arm) and MSVC 2019 (v19.28, running on native\nx86).\n\nBefore releases, we also test on x86 with Clang and GCC, and Armv7/8 via GCC\ncross-compile. See the [testing process](g3doc/release_testing_process.md) for\ndetails.\n\n### Related modules\n\nThe `contrib` directory contains SIMD-related utilities: an image class with\naligned rows, a math library (16 functions already implemented, mostly\ntrigonometry), and functions for computing dot products and sorting.\n\n### Other libraries\n\nIf you only require x86 support, you may also use Agner Fog's\n[VCL vector class library](https://github.com/vectorclass). It includes many\nfunctions including a complete math library.\n\nIf you have existing code using x86/NEON intrinsics, you may be interested in\n[SIMDe](https://github.com/simd-everywhere/simde), which emulates those\nintrinsics using other platforms' intrinsics or autovectorization.\n\n## Installation\n\nThis project uses CMake to generate and build. In a Debian-based system you can\ninstall it via:\n\n```bash\nsudo apt install cmake\n```\n\nHighway's unit tests use [googletest](https://github.com/google/googletest).\nBy default, Highway's CMake downloads this dependency at configuration time.\nYou can avoid this by setting the `HWY_SYSTEM_GTEST` CMake variable to ON and\ninstalling gtest separately:\n\n```bash\nsudo apt install libgtest-dev\n```\n\nAlternatively, you can define `HWY_TEST_STANDALONE=1` and remove all occurrences\nof `gtest_main` in each BUILD file, then tests avoid the dependency on GUnit.\n\nRunning cross-compiled tests requires support from the OS, which on Debian is\nprovided by the `qemu-user-binfmt` package.\n\nTo build Highway as a shared or static library (depending on BUILD_SHARED_LIBS),\nthe standard CMake workflow can be used:\n\n```bash\nmkdir -p build && cd build\ncmake ..\nmake -j && make test\n```\n\nOr you can run `run_tests.sh` (`run_tests.bat` on Windows).\n\nBazel is also supported for building, but it is not as widely used/tested.\n\nWhen building for Armv7, a limitation of current compilers requires you to add\n`-DHWY_CMAKE_ARM7:BOOL=ON` to the CMake command line; see #834 and #1032. We\nunderstand that work is underway to remove this limitation.\n\nTo benefit from Armv8/v9 vusdot and vusdotq instructions, you can add \"+i8mm\" to\nthe -march compiler flag, assuming the target CPU(s) support that.\n\nBuilding on 32-bit x86 is not officially supported, and AVX2/3 are disabled by\ndefault there. Note that johnplatts has successfully built and run the Highway\ntests on 32-bit x86, including AVX2/3, on GCC 7/8 and Clang 8/11/12. On Ubuntu\n22.04, Clang 11 and 12, but not later versions, require extra compiler flags\n`-m32 -isystem /usr/i686-linux-gnu/include`. Clang 10 and earlier require the\nabove plus `-isystem /usr/i686-linux-gnu/include/c++/12/i686-linux-gnu`. See\n#1279.\n\n## Building highway - Using vcpkg\n\nhighway is now available in [vcpkg](https://github.com/Microsoft/vcpkg)\n\n```bash\nvcpkg install highway\n```\n\nThe highway port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n## Quick start\n\nYou can use the `benchmark` inside examples/ as a starting point.\n\nA [quick-reference page](g3doc/quick_reference.md) briefly lists all operations\nand their parameters, and the [instruction_matrix](g3doc/instruction_matrix.pdf)\nindicates the number of instructions per operation.\n\nThe [FAQ](g3doc/faq.md) answers questions about portability, API design and\nwhere to find more information.\n\nWe recommend using full SIMD vectors whenever possible for maximum performance\nportability. To obtain them, pass a `ScalableTag<float>` (or equivalently\n`HWY_FULL(float)`) tag to functions such as `Zero/Set/Load`. There are two\nalternatives for use-cases requiring an upper bound on the lanes:\n\n-   For up to `N` lanes, specify `CappedTag<T, N>` or the equivalent\n    `HWY_CAPPED(T, N)`. The actual number of lanes will be `N` rounded down to\n    the nearest power of two, such as 4 if `N` is 5, or 8 if `N` is 8. This is\n    useful for data structures such as a narrow matrix. A loop is still required\n    because vectors may actually have fewer than `N` lanes.\n\n-   For exactly a power of two `N` lanes, specify `FixedTag<T, N>`. The largest\n    supported `N` depends on the target, but is guaranteed to be at least\n    `16/sizeof(T)`.\n\nDue to ADL restrictions, user code calling Highway ops must either:\n\n*   Reside inside `namespace hwy { namespace HWY_NAMESPACE {`; or\n*   prefix each op with an alias such as `namespace hn = hwy::HWY_NAMESPACE;\n    hn::Add()`; or\n*   add using-declarations for each op used: `using hwy::HWY_NAMESPACE::Add;`.\n\nAdditionally, each function that calls Highway ops (such as `Load`) must either\nbe prefixed with `HWY_ATTR`, OR reside between `HWY_BEFORE_NAMESPACE()` and\n`HWY_AFTER_NAMESPACE()`. Lambda functions currently require `HWY_ATTR` before\ntheir opening brace.\n\nDo not use namespace-scope nor `static` initializers for SIMD vectors because\nthis can cause SIGILL when using runtime dispatch and the compiler chooses an\ninitializer compiled for a target not supported by the current CPU. Instead,\nconstants initialized via `Set` should generally be local (const) variables.\n\nThe entry points into code using Highway differ slightly depending on whether\nthey use static or dynamic dispatch. In both cases, we recommend that the\ntop-level function receives one or more pointers to arrays, rather than\ntarget-specific vector types.\n\n*   For static dispatch, `HWY_TARGET` will be the best available target among\n    `HWY_BASELINE_TARGETS`, i.e. those allowed for use by the compiler (see\n    [quick-reference](g3doc/quick_reference.md)). Functions inside\n    `HWY_NAMESPACE` can be called using `HWY_STATIC_DISPATCH(func)(args)` within\n    the same module they are defined in. You can call the function from other\n    modules by wrapping it in a regular function and declaring the regular\n    function in a header.\n\n*   For dynamic dispatch, a table of function pointers is generated via the\n    `HWY_EXPORT` macro that is used by `HWY_DYNAMIC_DISPATCH(func)(args)` to\n    call the best function pointer for the current CPU's supported targets. A\n    module is automatically compiled for each target in `HWY_TARGETS` (see\n    [quick-reference](g3doc/quick_reference.md)) if `HWY_TARGET_INCLUDE` is\n    defined and `foreach_target.h` is included. Note that the first invocation\n    of `HWY_DYNAMIC_DISPATCH`, or each call to the pointer returned by the first\n    invocation of `HWY_DYNAMIC_POINTER`, involves some CPU detection overhead.\n    You can prevent this by calling the following before any invocation of\n    `HWY_DYNAMIC_*`: `hwy::GetChosenTarget().Update(hwy::SupportedTargets());`.\n\nSee also a separate\n[introduction to dynamic dispatch](https://github.com/kfjahnke/zimt/blob/multi_isa/examples/multi_isa_example/multi_simd_isa.md)\nby @kfjahnke.\n\nWhen using dynamic dispatch, `foreach_target.h` is included from translation\nunits (.cc files), not headers. Headers containing vector code shared between\nseveral translation units require a special include guard, for example the\nfollowing taken from `examples/skeleton-inl.h`:\n\n```\n#if defined(HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_) == defined(HWY_TARGET_TOGGLE)\n#ifdef HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_\n#undef HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_\n#else\n#define HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_\n#endif\n\n#include \"hwy/highway.h\"\n// Your vector code\n#endif\n```\n\nBy convention, we name such headers `-inl.h` because their contents (often\nfunction templates) are usually inlined.\n\n## Compiler flags\n\nApplications should be compiled with optimizations enabled. Without inlining\nSIMD code may slow down by factors of 10 to 100. For clang and GCC, `-O2` is\ngenerally sufficient.\n\nFor MSVC, we recommend compiling with `/Gv` to allow non-inlined functions to\npass vector arguments in registers. If intending to use the AVX2 target together\nwith half-width vectors (e.g. for `PromoteTo`), it is also important to compile\nwith `/arch:AVX2`. This seems to be the only way to reliably generate\nVEX-encoded SSE instructions on MSVC. Sometimes MSVC generates VEX-encoded SSE\ninstructions, if they are mixed with AVX, but not always, see\n[DevCom-10618264](https://developercommunity.visualstudio.com/t/10618264).\nOtherwise, mixing VEX-encoded AVX2 instructions and non-VEX SSE may cause severe\nperformance degradation. Unfortunately, with `/arch:AVX2` option, the resulting\nbinary will then require AVX2. Note that no such flag is needed for clang and\nGCC because they support target-specific attributes, which we use to ensure\nproper VEX code generation for AVX2 targets.\n\n## Strip-mining loops\n\nWhen vectorizing a loop, an important question is whether and how to deal with\na number of iterations ('trip count', denoted `count`) that does not evenly\ndivide the vector size `N = Lanes(d)`. For example, it may be necessary to avoid\nwriting past the end of an array.\n\nIn this section, let `T` denote the element type and `d = ScalableTag<T>`.\nAssume the loop body is given as a function `template<bool partial, class D>\nvoid LoopBody(D d, size_t index, size_t max_n)`.\n\n\"Strip-mining\" is a technique for vectorizing a loop by transforming it into an\nouter loop and inner loop, such that the number of iterations in the inner loop\nmatches the vector width. Then, the inner loop is replaced with vector\noperations.\n\nHighway offers several strategies for loop vectorization:\n\n*   Ensure all inputs/outputs are padded. Then the (outer) loop is simply\n\n    ```\n    for (size_t i = 0; i < count; i += N) LoopBody<false>(d, i, 0);\n    ```\n    Here, the template parameter and second function argument are not needed.\n\n    This is the preferred option, unless `N` is in the thousands and vector\n    operations are pipelined with long latencies. This was the case for\n    supercomputers in the 90s, but nowadays ALUs are cheap and we see most\n    implementations split vectors into 1, 2 or 4 parts, so there is little cost\n    to processing entire vectors even if we do not need all their lanes. Indeed\n    this avoids the (potentially large) cost of predication or partial\n    loads/stores on older targets, and does not duplicate code.\n\n*   Process whole vectors and include previously processed elements\n    in the last vector:\n    ```\n    for (size_t i = 0; i < count; i += N) LoopBody<false>(d, HWY_MIN(i, count - N), 0);\n    ```\n\n    This is the second preferred option provided that `count >= N`\n    and `LoopBody` is idempotent. Some elements might be processed twice, but\n    a single code path and full vectorization is usually worth it. Even if\n    `count < N`, it usually makes sense to pad inputs/outputs up to `N`.\n\n*   Use the `Transform*` functions in hwy/contrib/algo/transform-inl.h. This\n    takes care of the loop and remainder handling and you simply define a\n    generic lambda function (C++14) or functor which receives the current vector\n    from the input/output array, plus optionally vectors from up to two extra\n    input arrays, and returns the value to write to the input/output array.\n\n    Here is an example implementing the BLAS function SAXPY (`alpha * x + y`):\n\n    ```\n    Transform1(d, x, n, y, [](auto d, const auto v, const auto v1) HWY_ATTR {\n      return MulAdd(Set(d, alpha), v, v1);\n    });\n    ```\n\n*   Process whole vectors as above, followed by a scalar loop:\n\n    ```\n    size_t i = 0;\n    for (; i + N <= count; i += N) LoopBody<false>(d, i, 0);\n    for (; i < count; ++i) LoopBody<false>(CappedTag<T, 1>(), i, 0);\n    ```\n    The template parameter and second function arguments are again not needed.\n\n    This avoids duplicating code, and is reasonable if `count` is large.\n    If `count` is small, the second loop may be slower than the next option.\n\n*   Process whole vectors as above, followed by a single call to a modified\n    `LoopBody` with masking:\n\n    ```\n    size_t i = 0;\n    for (; i + N <= count; i += N) {\n      LoopBody<false>(d, i, 0);\n    }\n    if (i < count) {\n      LoopBody<true>(d, i, count - i);\n    }\n    ```\n    Now the template parameter and third function argument can be used inside\n    `LoopBody` to non-atomically 'blend' the first `num_remaining` lanes of `v`\n    with the previous contents of memory at subsequent locations:\n    `BlendedStore(v, FirstN(d, num_remaining), d, pointer);`. Similarly,\n    `MaskedLoad(FirstN(d, num_remaining), d, pointer)` loads the first\n    `num_remaining` elements and returns zero in other lanes.\n\n    This is a good default when it is infeasible to ensure vectors are padded,\n    but is only safe `#if !HWY_MEM_OPS_MIGHT_FAULT`!\n    In contrast to the scalar loop, only a single final iteration is needed.\n    The increased code size from two loop bodies is expected to be worthwhile\n    because it avoids the cost of masking in all but the final iteration.\n\n## Additional resources\n\n*   [Highway introduction (slides)](g3doc/highway_intro.pdf)\n*   [Overview of instructions per operation on different architectures](g3doc/instruction_matrix.pdf)\n*   [Design philosophy and comparison](g3doc/design_philosophy.md)\n*   [Implementation details](g3doc/impl_details.md)\n\n## Acknowledgments\n\nWe have used [farm-sve](https://gitlab.inria.fr/bramas/farm-sve) by Berenger\nBramas; it has proved useful for checking the SVE port on an x86 development\nmachine.\n\nThis is not an officially supported Google product.\nContact: janwas@google.com\n",
      "stars_today": 7
    },
    {
      "id": 7056202,
      "name": "fmt",
      "full_name": "fmtlib/fmt",
      "description": "A modern formatting library",
      "html_url": "https://github.com/fmtlib/fmt",
      "stars": 23186,
      "forks": 2813,
      "language": "C++",
      "topics": [
        "c-plus-plus",
        "chrono",
        "cpp",
        "cross-platform",
        "floating-point",
        "formatting",
        "multiplatform",
        "output",
        "performance",
        "printf",
        "ranges",
        "unicode"
      ],
      "created_at": "2012-12-07T16:26:46Z",
      "updated_at": "2026-01-22T19:26:30Z",
      "pushed_at": "2026-01-22T19:24:11Z",
      "open_issues": 11,
      "owner": {
        "login": "fmtlib",
        "avatar_url": "https://avatars.githubusercontent.com/u/7280830?v=4"
      },
      "readme": "<img src=\"https://user-images.githubusercontent.com/576385/156254208-f5b743a9-88cf-439d-b0c0-923d53e8d551.png\" alt=\"{fmt}\" width=\"25%\"/>\n\n[![image](https://github.com/fmtlib/fmt/workflows/linux/badge.svg)](https://github.com/fmtlib/fmt/actions?query=workflow%3Alinux)\n[![image](https://github.com/fmtlib/fmt/workflows/macos/badge.svg)](https://github.com/fmtlib/fmt/actions?query=workflow%3Amacos)\n[![image](https://github.com/fmtlib/fmt/workflows/windows/badge.svg)](https://github.com/fmtlib/fmt/actions?query=workflow%3Awindows)\n[![fmt is continuously fuzzed at oss-fuzz](https://oss-fuzz-build-logs.storage.googleapis.com/badges/fmt.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?\\%0Acolspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20\\%0ASummary&q=proj%3Dfmt&can=1)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/8880/badge)](https://www.bestpractices.dev/projects/8880)\n[![image](https://api.securityscorecards.dev/projects/github.com/fmtlib/fmt/badge)](https://securityscorecards.dev/viewer/?uri=github.com/fmtlib/fmt)\n[![Ask questions at StackOverflow with the tag fmt](https://img.shields.io/badge/stackoverflow-fmt-blue.svg)](https://stackoverflow.com/questions/tagged/fmt)\n\n**{fmt}** is an open-source formatting library providing a fast and safe\nalternative to C stdio and C++ iostreams.\n\nIf you like this project, please consider donating to one of the funds\nthat help victims of the war in Ukraine: <https://u24.gov.ua/>.\n\n[Documentation](https://fmt.dev)\n\n[Cheat Sheets](https://hackingcpp.com/cpp/libs/fmt.html)\n\nQ&A: ask questions on [StackOverflow with the tag\nfmt](https://stackoverflow.com/questions/tagged/fmt).\n\nTry {fmt} in [Compiler Explorer](https://godbolt.org/z/8Mx1EW73v).\n\n# Features\n\n- Simple [format API](https://fmt.dev/latest/api/) with positional\n  arguments for localization\n- Implementation of [C++20\n  std::format](https://en.cppreference.com/w/cpp/utility/format) and\n  [C++23 std::print](https://en.cppreference.com/w/cpp/io/print)\n- [Format string syntax](https://fmt.dev/latest/syntax/) similar\n  to Python\\'s\n  [format](https://docs.python.org/3/library/stdtypes.html#str.format)\n- Fast IEEE 754 floating-point formatter with correct rounding,\n  shortness and round-trip guarantees using the\n  [Dragonbox](https://github.com/jk-jeon/dragonbox) algorithm\n- Portable Unicode support\n- Safe [printf\n  implementation](https://fmt.dev/latest/api/#printf-formatting)\n  including the POSIX extension for positional arguments\n- Extensibility: [support for user-defined\n  types](https://fmt.dev/latest/api/#formatting-user-defined-types)\n- High performance: faster than common standard library\n  implementations of `(s)printf`, iostreams, `to_string` and\n  `to_chars`, see [Speed tests](#speed-tests) and [Converting a\n  hundred million integers to strings per\n  second](http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html)\n- Small code size both in terms of source code with the minimum\n  configuration consisting of just three files, `base.h`, `format.h`\n  and `format-inl.h`, and compiled code; see [Compile time and code\n  bloat](#compile-time-and-code-bloat)\n- Reliability: the library has an extensive set of\n  [tests](https://github.com/fmtlib/fmt/tree/master/test) and is\n  [continuously fuzzed](https://bugs.chromium.org/p/oss-fuzz/issues/list?colspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20Summary&q=proj%3Dfmt&can=1)\n- Safety: the library is fully type-safe, errors in format strings can\n  be reported at compile time, automatic memory management prevents\n  buffer overflow errors\n- Ease of use: small self-contained code base, no external\n  dependencies, permissive MIT\n  [license](https://github.com/fmtlib/fmt/blob/master/LICENSE)\n- [Portability](https://fmt.dev/latest/#portability) with\n  consistent output across platforms and support for older compilers\n- Clean warning-free codebase even on high warning levels such as\n  `-Wall -Wextra -pedantic`\n- Locale independence by default\n- Optional header-only configuration enabled with the\n  `FMT_HEADER_ONLY` macro\n\nSee the [documentation](https://fmt.dev) for more details.\n\n# Examples\n\n**Print to stdout** ([run](https://godbolt.org/z/Tevcjh))\n\n``` c++\n#include <fmt/base.h>\n\nint main() {\n  fmt::print(\"Hello, world!\\n\");\n}\n```\n\n**Format a string** ([run](https://godbolt.org/z/oK8h33))\n\n``` c++\nstd::string s = fmt::format(\"The answer is {}.\", 42);\n// s == \"The answer is 42.\"\n```\n\n**Format a string using positional arguments**\n([run](https://godbolt.org/z/Yn7Txe))\n\n``` c++\nstd::string s = fmt::format(\"I'd rather be {1} than {0}.\", \"right\", \"happy\");\n// s == \"I'd rather be happy than right.\"\n```\n\n**Print dates and times** ([run](https://godbolt.org/z/c31ExdY3W))\n\n``` c++\n#include <fmt/chrono.h>\n\nint main() {\n  auto now = std::chrono::system_clock::now();\n  fmt::print(\"Date and time: {}\\n\", now);\n  fmt::print(\"Time: {:%H:%M}\\n\", now);\n}\n```\n\nOutput:\n\n    Date and time: 2023-12-26 19:10:31.557195597\n    Time: 19:10\n\n**Print a container** ([run](https://godbolt.org/z/MxM1YqjE7))\n\n``` c++\n#include <vector>\n#include <fmt/ranges.h>\n\nint main() {\n  std::vector<int> v = {1, 2, 3};\n  fmt::print(\"{}\\n\", v);\n}\n```\n\nOutput:\n\n    [1, 2, 3]\n\n**Check a format string at compile time**\n\n``` c++\nstd::string s = fmt::format(\"{:d}\", \"I am not a number\");\n```\n\nThis gives a compile-time error in C++20 because `d` is an invalid\nformat specifier for a string.\n\n**Write a file from a single thread**\n\n``` c++\n#include <fmt/os.h>\n\nint main() {\n  auto out = fmt::output_file(\"guide.txt\");\n  out.print(\"Don't {}\", \"Panic\");\n}\n```\n\nThis can be [up to 9 times faster than `fprintf`](\nhttp://www.zverovich.net/2020/08/04/optimal-file-buffer-size.html).\n\n**Print with colors and text styles**\n\n``` c++\n#include <fmt/color.h>\n\nint main() {\n  fmt::print(fg(fmt::color::crimson) | fmt::emphasis::bold,\n             \"Hello, {}!\\n\", \"world\");\n  fmt::print(fg(fmt::color::floral_white) | bg(fmt::color::slate_gray) |\n             fmt::emphasis::underline, \"Ol√°, {}!\\n\", \"Mundo\");\n  fmt::print(fg(fmt::color::steel_blue) | fmt::emphasis::italic,\n             \"‰Ω†Â•Ω{}ÔºÅ\\n\", \"‰∏ñÁïå\");\n}\n```\n\nOutput on a modern terminal with Unicode support:\n\n![image](https://github.com/fmtlib/fmt/assets/%0A576385/2a93c904-d6fa-4aa6-b453-2618e1c327d7)\n\n# Benchmarks\n\n## Speed tests\n\n| Library           | Method        | Run Time, s |\n|-------------------|---------------|-------------|\n| libc              | printf        |   0.66      |\n| libc++            | std::ostream  |   1.63      |\n| {fmt} 12.1        | fmt::print    |   0.44      |\n| Boost Format 1.88 | boost::format |   3.89      |\n| Folly Format      | folly::format |   1.28      |\n\n{fmt} is the fastest of the benchmarked methods, \\~50% faster than\n`printf`.\n\nThe above results were generated by building `tinyformat_test.cpp` on\nmacOS 15.6.1 with `clang++ -O3 -DNDEBUG -DSPEED_TEST -DHAVE_FORMAT`, and\ntaking the best of three runs. In the test, the format string\n`\"%0.10f:%04d:%+g:%s:%p:%c:%%\\n\"` or equivalent is filled 2,000,000\ntimes with output sent to `/dev/null`; for further details refer to the\n[source](https://github.com/fmtlib/format-benchmark/blob/master/src/tinyformat-test.cc).\n\n{fmt} is up to 20-30x faster than `std::ostringstream` and `sprintf` on\nIEEE754 `float` and `double` formatting\n([dtoa-benchmark](https://github.com/fmtlib/dtoa-benchmark)) and faster\nthan [double-conversion](https://github.com/google/double-conversion)\nand [ryu](https://github.com/ulfjack/ryu):\n\n[![image](https://user-images.githubusercontent.com/576385/95684665-11719600-0ba8-11eb-8e5b-972ff4e49428.png)](https://fmt.dev/unknown_mac64_clang12.0.html)\n\n## Compile time and code bloat\n\nThe script [bloat-test.py][test] from [format-benchmark][bench] tests compile\ntime and code bloat for nontrivial projects. It generates 100 translation units\nand uses `printf()` or its alternative five times in each to simulate a\nmedium-sized project. The resulting executable size and compile time (Apple\nclang version 15.0.0 (clang-1500.1.0.2.5), macOS Sonoma, best of three) is shown\nin the following tables.\n\n[test]: https://github.com/fmtlib/format-benchmark/blob/master/bloat-test.py\n[bench]: https://github.com/fmtlib/format-benchmark\n\n**Optimized build (-O3)**\n\n| Method          | Compile Time, s | Executable size, KiB | Stripped size, KiB |\n|-----------------|-----------------|----------------------|--------------------|\n| printf          |             1.6 |                   54 |                 50 |\n| IOStreams       |            28.4 |                   98 |                 84 |\n| {fmt} `1122268` |             5.0 |                   54 |                 50 |\n| tinyformat      |            32.6 |                  164 |                136 |\n| Boost Format    |            55.0 |                  530 |                317 |\n\n{fmt} is fast to compile and is comparable to `printf` in terms of per-call\nbinary size (within a rounding error on this system).\n\n**Non-optimized build**\n\n| Method          | Compile Time, s | Executable size, KiB | Stripped size, KiB |\n|-----------------|-----------------|----------------------|--------------------|\n| printf          |             1.4 |                   54 |                 50 |\n| IOStreams       |            27.0 |                   88 |                 68 |\n| {fmt} `1122268` |             4.7 |                   87 |                 84 |\n| tinyformat      |            28.1 |                  185 |                145 |\n| Boost Format    |            38.9 |                  678 |                381 |\n\n`libc`, `lib(std)c++`, and `libfmt` are all linked as shared libraries\nto compare formatting function overhead only. Boost Format is a\nheader-only library so it doesn\\'t provide any linkage options.\n\n## Running the tests\n\nPlease refer to [Building the\nlibrary](https://fmt.dev/latest/get-started/#building-from-source) for\ninstructions on how to build the library and run the unit tests.\n\nBenchmarks reside in a separate repository,\n[format-benchmarks](https://github.com/fmtlib/format-benchmark), so to\nrun the benchmarks you first need to clone this repository and generate\nMakefiles with CMake:\n\n    $ git clone --recursive https://github.com/fmtlib/format-benchmark.git\n    $ cd format-benchmark\n    $ cmake .\n\nThen you can run the speed test:\n\n    $ make speed-test\n\nor the bloat test:\n\n    $ make bloat-test\n\n# Migrating code\n\n[clang-tidy](https://clang.llvm.org/extra/clang-tidy/) v18 provides the\n[modernize-use-std-print](https://clang.llvm.org/extra/clang-tidy/checks/modernize/use-std-print.html)\ncheck that is capable of converting occurrences of `printf` and\n`fprintf` to `fmt::print` if configured to do so. (By default it\nconverts to `std::print`.)\n\n# Notable projects using this library\n\n- [0 A.D.](https://play0ad.com/): a free, open-source, cross-platform\n  real-time strategy game\n- [AMPL/MP](https://github.com/ampl/mp): an open-source library for\n  mathematical programming\n- [Apple's FoundationDB](https://github.com/apple/foundationdb): an open-source,\n  distributed, transactional key-value store\n- [Aseprite](https://github.com/aseprite/aseprite): animated sprite\n  editor & pixel art tool\n- [AvioBook](https://www.aviobook.aero/en): a comprehensive aircraft\n  operations suite\n- [Blizzard Battle.net](https://battle.net/): an online gaming\n  platform\n- [Celestia](https://celestia.space/): real-time 3D visualization of\n  space\n- [Ceph](https://ceph.com/): a scalable distributed storage system\n- [ccache](https://ccache.dev/): a compiler cache\n- [ClickHouse](https://github.com/ClickHouse/ClickHouse): an\n  analytical database management system\n- [ContextVision](https://www.contextvision.com/): medical imaging software\n- [Contour](https://github.com/contour-terminal/contour/): a modern\n  terminal emulator\n- [CUAUV](https://cuauv.org/): Cornell University\\'s autonomous\n  underwater vehicle\n- [Drake](https://drake.mit.edu/): a planning, control, and analysis\n  toolbox for nonlinear dynamical systems (MIT)\n- [Envoy](https://github.com/envoyproxy/envoy): C++ L7 proxy and\n  communication bus (Lyft)\n- [FiveM](https://fivem.net/): a modification framework for GTA V\n- [fmtlog](https://github.com/MengRao/fmtlog): a performant\n  fmtlib-style logging library with latency in nanoseconds\n- [Folly](https://github.com/facebook/folly): Facebook open-source\n  library\n- [GemRB](https://gemrb.org/): a portable open-source implementation\n  of Bioware's Infinity Engine\n- [Grand Mountain\n  Adventure](https://store.steampowered.com/app/1247360/Grand_Mountain_Adventure/):\n  a beautiful open-world ski & snowboarding game\n- [HarpyWar/pvpgn](https://github.com/pvpgn/pvpgn-server): Player vs\n  Player Gaming Network with tweaks\n- [KBEngine](https://github.com/kbengine/kbengine): an open-source\n  MMOG server engine\n- [Keypirinha](https://keypirinha.com/): a semantic launcher for\n  Windows\n- [Kodi](https://kodi.tv/) (formerly xbmc): home theater software\n- [Knuth](https://kth.cash/): high-performance Bitcoin full-node\n- [libunicode](https://github.com/contour-terminal/libunicode/): a\n  modern C++17 Unicode library\n- [MariaDB](https://mariadb.org/): relational database management\n  system\n- [Microsoft Verona](https://github.com/microsoft/verona): research\n  programming language for concurrent ownership\n- [MongoDB](https://mongodb.com/): distributed document database\n- [MongoDB Smasher](https://github.com/duckie/mongo_smasher): a small\n  tool to generate randomized datasets\n- [OpenSpace](https://openspaceproject.com/): an open-source\n  astrovisualization framework\n- [PenUltima Online (POL)](https://www.polserver.com/): an MMO server,\n  compatible with most Ultima Online clients\n- [PyTorch](https://github.com/pytorch/pytorch): an open-source\n  machine learning library\n- [quasardb](https://www.quasardb.net/): a distributed,\n  high-performance, associative database\n- [Quill](https://github.com/odygrd/quill): asynchronous low-latency\n  logging library\n- [QKW](https://github.com/ravijanjam/qkw): generalizing aliasing to\n  simplify navigation, and execute complex multi-line terminal\n  command sequences\n- [redis-cerberus](https://github.com/HunanTV/redis-cerberus): a Redis\n  cluster proxy\n- [redpanda](https://vectorized.io/redpanda): a 10x faster Kafka¬Æ\n  replacement for mission-critical systems written in C++\n- [rpclib](http://rpclib.net/): a modern C++ msgpack-RPC server and\n  client library\n- [Salesforce Analytics\n  Cloud](https://www.salesforce.com/analytics-cloud/overview/):\n  business intelligence software\n- [Scylla](https://www.scylladb.com/): a Cassandra-compatible NoSQL\n  data store that can handle 1 million transactions per second on a\n  single server\n- [Seastar](http://www.seastar-project.org/): an advanced, open-source\n  C++ framework for high-performance server applications on modern\n  hardware\n- [spdlog](https://github.com/gabime/spdlog): super fast C++ logging\n  library\n- [Stellar](https://www.stellar.org/): financial platform\n- [Touch Surgery](https://www.touchsurgery.com/): surgery simulator\n- [TrinityCore](https://github.com/TrinityCore/TrinityCore):\n  open-source MMORPG framework\n- [üêô userver framework](https://userver.tech/): open-source\n  asynchronous framework with a rich set of abstractions and database\n  drivers\n- [Windows Terminal](https://github.com/microsoft/terminal): the new\n  Windows terminal\n\n[More\\...](https://github.com/search?q=fmtlib&type=Code)\n\nIf you are aware of other projects using this library, please let me\nknow by [email](mailto:victor.zverovich@gmail.com) or by submitting an\n[issue](https://github.com/fmtlib/fmt/issues).\n\n# Motivation\n\nSo why yet another formatting library?\n\nThere are plenty of methods for doing this task, from standard ones like\nthe printf family of function and iostreams to Boost Format and\nFastFormat libraries. The reason for creating a new library is that\nevery existing solution that I found either had serious issues or\ndidn\\'t provide all the features I needed.\n\n## printf\n\nThe good thing about `printf` is that it is pretty fast and readily\navailable being a part of the C standard library. The main drawback is\nthat it doesn\\'t support user-defined types. `printf` also has safety\nissues although they are somewhat mitigated with [\\_\\_attribute\\_\\_\n((format (printf,\n\\...))](https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html) in\nGCC. There is a POSIX extension that adds positional arguments required\nfor\n[i18n](https://en.wikipedia.org/wiki/Internationalization_and_localization)\nto `printf` but it is not a part of C99 and may not be available on some\nplatforms.\n\n## iostreams\n\nThe main issue with iostreams is best illustrated with an example:\n\n``` c++\nstd::cout << std::setprecision(2) << std::fixed << 1.23456 << \"\\n\";\n```\n\nwhich is a lot of typing compared to printf:\n\n``` c++\nprintf(\"%.2f\\n\", 1.23456);\n```\n\nMatthew Wilson, the author of FastFormat, called this \\\"chevron hell\\\".\niostreams don\\'t support positional arguments by design.\n\nThe good part is that iostreams support user-defined types and are safe\nalthough error handling is awkward.\n\n## Boost Format\n\nThis is a very powerful library that supports both `printf`-like format\nstrings and positional arguments. Its main drawback is performance.\nAccording to various benchmarks, it is much slower than other methods\nconsidered here. Boost Format also has excessive build times and severe\ncode bloat issues (see [Benchmarks](#benchmarks)).\n\n## FastFormat\n\nThis is an interesting library that is fast, safe and has positional\narguments. However, it has significant limitations, citing its author:\n\n> Three features that have no hope of being accommodated within the\n> current design are:\n>\n> - Leading zeros (or any other non-space padding)\n> - Octal/hexadecimal encoding\n> - Runtime width/alignment specification\n\nIt is also quite big and has a heavy dependency, on STLSoft, which might be\ntoo restrictive for use in some projects.\n\n## Boost Spirit.Karma\n\nThis is not a formatting library but I decided to include it here for\ncompleteness. As iostreams, it suffers from the problem of mixing\nverbatim text with arguments. The library is pretty fast, but slower on\ninteger formatting than `fmt::format_to` with format string compilation\non Karma\\'s own benchmark, see [Converting a hundred million integers to\nstrings per\nsecond](http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html).\n\n# License\n\n{fmt} is distributed under the MIT\n[license](https://github.com/fmtlib/fmt/blob/master/LICENSE).\n\n# Documentation License\n\nThe [Format String Syntax](https://fmt.dev/latest/syntax/) section\nin the documentation is based on the one from Python [string module\ndocumentation](https://docs.python.org/3/library/string.html#module-string).\nFor this reason, the documentation is distributed under the Python\nSoftware Foundation license available in\n[doc/python-license.txt](https://raw.github.com/fmtlib/fmt/master/doc/python-license.txt).\nIt only applies if you distribute the documentation of {fmt}.\n\n# Maintainers\n\nThe {fmt} library is maintained by Victor Zverovich\n([vitaut](https://github.com/vitaut)) with contributions from many other\npeople. See\n[Contributors](https://github.com/fmtlib/fmt/graphs/contributors) and\n[Releases](https://github.com/fmtlib/fmt/releases) for some of the\nnames. Let us know if your contribution is not listed or mentioned\nincorrectly and we\\'ll make it right.\n\n# Security Policy\n\nTo report a security issue, please disclose it at [security\nadvisory](https://github.com/fmtlib/fmt/security/advisories/new).\n\nThis project is maintained by a team of volunteers on a\nreasonable-effort basis. As such, please give us at least *90* days to\nwork on a fix before public exposure.\n",
      "stars_today": 6
    },
    {
      "id": 99919302,
      "name": "doris",
      "full_name": "apache/doris",
      "description": "Apache Doris is an easy-to-use, high performance and unified analytics database.",
      "html_url": "https://github.com/apache/doris",
      "stars": 14914,
      "forks": 3691,
      "language": "Java",
      "topics": [
        "agent",
        "ai",
        "bigquery",
        "database",
        "dbt",
        "delta-lake",
        "elt",
        "hudi",
        "iceberg",
        "lakehouse",
        "olap",
        "paimon",
        "query-engine",
        "real-time",
        "redshift",
        "snowflake",
        "spark",
        "sql"
      ],
      "created_at": "2017-08-10T12:13:30Z",
      "updated_at": "2026-01-23T01:51:24Z",
      "pushed_at": "2026-01-23T01:52:39Z",
      "open_issues": 769,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n## üåç Read this in other languages\n\n[English](README.md) ‚Ä¢ [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](docs/ar-SA/README.md) ‚Ä¢ [‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](docs/bn-BD/README.md) ‚Ä¢ [Deutsch](docs/de-DE/README.md) ‚Ä¢ [Espa√±ol](docs/es-ES/README.md) ‚Ä¢ [ŸÅÿßÿ±ÿ≥€å](docs/fa-IR/README.md) ‚Ä¢ [Fran√ßais](docs/fr-FR/README.md) ‚Ä¢ [‡§π‡§ø‡§®‡•ç‡§¶‡•Ä](docs/hi-IN/README.md) ‚Ä¢ [Bahasa Indonesia](docs/id-ID/README.md) ‚Ä¢ [Italiano](docs/it-IT/README.md) ‚Ä¢ [Êó•Êú¨Ë™û](docs/ja-JP/README.md) ‚Ä¢ [ÌïúÍµ≠Ïñ¥](docs/ko-KR/README.md) ‚Ä¢ [Polski](docs/pl-PL/README.md) ‚Ä¢ [Portugu√™s](docs/pt-BR/README.md) ‚Ä¢ [Rom√¢nƒÉ](docs/ro-RO/README.md) ‚Ä¢ [–†—É—Å—Å–∫–∏–π](docs/ru-RU/README.md) ‚Ä¢ [Sloven≈°ƒçina](docs/sl-SI/README.md) ‚Ä¢ [‡πÑ‡∏ó‡∏¢](docs/th-TH/README.md) ‚Ä¢ [T√ºrk√ße](docs/tr-TR/README.md) ‚Ä¢ [–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](docs/uk-UA/README.md) ‚Ä¢ [Ti·∫øng Vi·ªát](docs/vi-VN/README.md) ‚Ä¢ [ÁÆÄ‰Ωì‰∏≠Êñá](docs/zh-CN/README.md) ‚Ä¢ [ÁπÅÈ´î‰∏≠Êñá](docs/zh-TW/README.md)\n\n<div align=\"center\">\n\n# Apache Doris\n\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![GitHub release](https://img.shields.io/github/release/apache/doris.svg)](https://github.com/apache/doris/releases)\n[![OSSRank](https://shields.io/endpoint?url=https://ossrank.com/shield/516)](https://ossrank.com/p/516)\n[![Commit activity](https://img.shields.io/github/commit-activity/m/apache/doris)](https://github.com/apache/doris/commits/master/)\n[![EN doc](https://img.shields.io/badge/Docs-English-blue.svg)](https://doris.apache.org/docs/gettingStarted/what-is-apache-doris)\n[![CN doc](https://img.shields.io/badge/ÊñáÊ°£-‰∏≠ÊñáÁâà-blue.svg)](https://doris.apache.org/zh-CN/docs/gettingStarted/what-is-apache-doris)\n\n<div>\n\n[![Official Website](<https://img.shields.io/badge/-Visit%20the%20Official%20Website%20%E2%86%92-rgb(15,214,106)?style=for-the-badge>)](https://doris.apache.org/)\n[![Quick Download](<https://img.shields.io/badge/-Quick%20%20Download%20%E2%86%92-rgb(66,56,255)?style=for-the-badge>)](https://doris.apache.org/download)\n\n\n</div>\n\n\n<div>\n    <a href=\"https://twitter.com/doris_apache\"><img src=\"https://img.shields.io/badge/- @Doris_Apache -424549?style=social&logo=x\" height=25></a>\n    &nbsp;\n    <a href=\"https://github.com/apache/doris/discussions\"><img src=\"https://img.shields.io/badge/- Discussion -red?style=social&logo=discourse\" height=25></a>\n    &nbsp;\n    <a href=\"https://doris.apache.org/slack\" height=25></a>\n    &nbsp;\n    <a href=\"https://medium.com/@ApacheDoris\"><img src=\"https://img.shields.io/badge/-Medium-red?style=social&logo=medium\" height=25></a>\n\n</div>\n\n</div>\n\n---\n\n<p align=\"center\">\n\n  <a href=\"https://trendshift.io/repositories/1156\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/1156\" alt=\"apache%2Fdoris | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n</p>\n\n\n\n\nApache Doris is an easy-to-use, high-performance and real-time analytical database based on MPP architecture, known for its extreme speed and ease of use. It only requires a sub-second response time to return query results under massive data and can support not only high-concurrency point query scenarios but also high-throughput complex analysis scenarios.\n\nAll this makes Apache Doris an ideal tool for scenarios including report analysis, ad-hoc query, unified data warehouse, and data lake query acceleration. On Apache Doris, users can build various applications, such as user behavior analysis, AB test platform, log retrieval analysis, user portrait analysis, and order analysis.\n\nüéâ Check out the üîó[All releases](https://doris.apache.org/docs/releasenotes/all-release), where you'll find a chronological summary of Apache Doris versions released over the past year.\n\nüëÄ Explore the üîó[Official Website](https://doris.apache.org/) to discover Apache Doris's core features, blogs, and user cases in detail.\n\n## üìà Usage Scenarios\n\nAs shown in the figure below, after various data integration and processing, the data sources are usually stored in the real-time data warehouse Apache Doris and the offline data lake or data warehouse (in Apache Hive, Apache Iceberg or Apache Hudi).\n\n<br />\n\n<img src=\"https://cdn.selectdb.com/static/What_is_Apache_Doris_3_a61692c2ce.png\" />\n\n<br />\n\n\nApache Doris is widely used in the following scenarios:\n\n- **Real-time Data Analysis**:\n\n  - **Real-time Reporting and Decision-making**: Doris provides real-time updated reports and dashboards for both internal and external enterprise use, supporting real-time decision-making in automated processes.\n  \n  - **Ad Hoc Analysis**: Doris offers multidimensional data analysis capabilities, enabling rapid business intelligence analysis and ad hoc queries to help users quickly uncover insights from complex data.\n  \n  - **User Profiling and Behavior Analysis**: Doris can analyze user behaviors such as participation, retention, and conversion, while also supporting scenarios like population insights and crowd selection for behavior analysis.\n\n- **Lakehouse Analytics**:\n\n  - **Lakehouse Query Acceleration**: Doris accelerates lakehouse data queries with its efficient query engine.\n  \n  - **Federated Analytics**: Doris supports federated queries across multiple data sources, simplifying architecture and eliminating data silos.\n  \n  - **Real-time Data Processing**: Doris combines real-time data streams and batch data processing capabilities to meet the needs of high concurrency and low-latency complex business requirements.\n\n- **SQL-based Observability**:\n\n  - **Log and Event Analysis**: Doris enables real-time or batch analysis of logs and events in distributed systems, helping to identify issues and optimize performance.\n\n\n## Overall Architecture\n\nApache Doris uses the MySQL protocol, is highly compatible with MySQL syntax, and supports standard SQL. Users can access Apache Doris through various client tools, and it seamlessly integrates with BI tools.\n\n### Storage-Compute Integrated Architecture\n\nThe storage-compute integrated architecture of Apache Doris is streamlined and easy to maintain. As shown in the figure below, it consists of only two types of processes:\n\n- **Frontend (FE):** Primarily responsible for handling user requests, query parsing and planning, metadata management, and node management tasks.\n\n- **Backend (BE):** Primarily responsible for data storage and query execution. Data is partitioned into shards and stored with multiple replicas across BE nodes.\n\n![The overall architecture of Apache Doris](https://cdn.selectdb.com/static/What_is_Apache_Doris_adb26397e2.png)\n\n<br />\n\nIn a production environment, multiple FE nodes can be deployed for disaster recovery. Each FE node maintains a full copy of the metadata. The FE nodes are divided into three roles:\n\n| Role      | Function                                                     |\n| --------- | ------------------------------------------------------------ |\n| Master    | The FE Master node is responsible for metadata read and write operations. When metadata changes occur in the Master, they are synchronized to Follower or Observer nodes via the BDB JE protocol. |\n| Follower  | The Follower node is responsible for reading metadata. If the Master node fails, a Follower node can be selected as the new Master. |\n| Observer  | The Observer node is responsible for reading metadata and is mainly used to increase query concurrency. It does not participate in cluster leadership elections. |\n\nBoth FE and BE processes are horizontally scalable, enabling a single cluster to support hundreds of machines and tens of petabytes of storage capacity. The FE and BE processes use a consistency protocol to ensure high availability of services and high reliability of data. The storage-compute integrated architecture is highly integrated, significantly reducing the operational complexity of distributed systems.\n\n\n## Core Features of Apache Doris\n\n- **High Availability**: In Apache Doris, both metadata and data are stored with multiple replicas, synchronizing data logs via the quorum protocol. Data write is considered successful once a majority of replicas have completed the write, ensuring that the cluster remains available even if a few nodes fail. Apache Doris supports both same-city and cross-region disaster recovery, enabling dual-cluster master-slave modes. When some nodes experience failures, the cluster can automatically isolate the faulty nodes, preventing the overall cluster availability from being affected.\n\n- **High Compatibility**: Apache Doris is highly compatible with the MySQL protocol and supports standard SQL syntax, covering most MySQL and Hive functions. This high compatibility allows users to seamlessly migrate and integrate existing applications and tools. Apache Doris supports the MySQL ecosystem, enabling users to connect Doris using MySQL Client tools for more convenient operations and maintenance. It also supports MySQL protocol compatibility for BI reporting tools and data transmission tools, ensuring efficiency and stability in data analysis and data transmission processes.\n\n- **Real-Time Data Warehouse**: Based on Apache Doris, a real-time data warehouse service can be built. Apache Doris offers second-level data ingestion capabilities, capturing incremental changes from upstream online transactional databases into Doris within seconds. Leveraging vectorized engines, MPP architecture, and Pipeline execution engines, Doris provides sub-second data query capabilities, thereby constructing a high-performance, low-latency real-time data warehouse platform.\n\n- **Unified Lakehouse**: Apache Doris can build a unified lakehouse architecture based on external data sources such as data lakes or relational databases. The Doris unified lakehouse solution enables seamless integration and free data flow between data lakes and data warehouses, helping users directly utilize data warehouse capabilities to solve data analysis problems in data lakes while fully leveraging data lake data management capabilities to enhance data value.\n\n- **Flexible Modeling**: Apache Doris offers various modeling approaches, such as wide table models, pre-aggregation models, star/snowflake schemas, etc. During data import, data can be flattened into wide tables and written into Doris through compute engines like Flink or Spark, or data can be directly imported into Doris, performing data modeling operations through views, materialized views, or real-time multi-table joins.\n\n## Technical overview\n\nDoris provides an efficient SQL interface and is fully compatible with the MySQL protocol. Its query engine is based on an MPP (Massively Parallel Processing) architecture, capable of efficiently executing complex analytical queries and achieving low-latency real-time queries. Through columnar storage technology for data encoding and compression, it significantly optimizes query performance and storage compression ratio.\n\n### Interface\n\nApache Doris adopts the MySQL protocol, supports standard SQL, and is highly compatible with MySQL syntax. Users can access Apache Doris through various client tools and seamlessly integrate it with BI tools, including but not limited to Smartbi, DataEase, FineBI, Tableau, Power BI, and Apache Superset. Apache Doris can work as the data source for any BI tools that support the MySQL protocol.\n\n### Storage engine\n\nApache Doris has a columnar storage engine, which encodes, compresses, and reads data by column. This enables a very high data compression ratio and largely reduces unnecessary data scanning, thus making more efficient use of IO and CPU resources.\n\nApache Doris supports various index structures to minimize data scans:\n\n- **Sorted Compound Key Index**: Users can specify three columns at most to form a compound sort key. This can effectively prune data to better support highly concurrent reporting scenarios.\n\n- **Min/Max Index**: This enables effective data filtering in equivalence and range queries of numeric types.\n\n- **BloomFilter Index**: This is very effective in equivalence filtering and pruning of high-cardinality columns.\n\n- **Inverted Index**: This enables fast searching for any field.\n\nApache Doris supports a variety of data models and has optimized them for different scenarios:\n\n- **Detail Model (Duplicate Key Model):** A detail data model designed to meet the detailed storage requirements of fact tables.\n\n- **Primary Key Model (Unique Key Model):** Ensures unique keys; data with the same key is overwritten, enabling row-level data updates.\n\n- **Aggregate Model (Aggregate Key Model):** Merges value columns with the same key, significantly improving performance through pre-aggregation.\n\nApache Doris also supports strongly consistent single-table materialized views and asynchronously refreshed multi-table materialized views. Single-table materialized views are automatically refreshed and maintained by the system, requiring no manual intervention from users. Multi-table materialized views can be refreshed periodically using in-cluster scheduling or external scheduling tools, reducing the complexity of data modeling.\n\n### üîç Query Engine\n\nApache Doris has an MPP-based query engine for parallel execution between and within nodes. It supports distributed shuffle join for large tables to better handle complicated queries.\n\n<br />\n\n![Query Engine](https://cdn.selectdb.com/static/What_is_Apache_Doris_1_c6f5ba2af9.png)\n\n<br />\n\nThe query engine of Apache Doris is fully vectorized, with all memory structures laid out in a columnar format. This can largely reduce virtual function calls, increase cache hit rates, and make efficient use of SIMD instructions. Apache Doris delivers a 5~10 times higher performance in wide table aggregation scenarios than non-vectorized engines.\n\n<br />\n\n![Doris query engine](https://cdn.selectdb.com/static/What_is_Apache_Doris_2_29cf58cc6b.png)\n\n<br />\n\nApache Doris uses adaptive query execution technology to dynamically adjust the execution plan based on runtime statistics. For example, it can generate a runtime filter and push it to the probe side. Specifically, it pushes the filters to the lowest-level scan node on the probe side, which largely reduces the data amount to be processed and increases join performance. The runtime filter of Apache Doris supports In/Min/Max/Bloom Filter.\n\nApache Doris uses a Pipeline execution engine that breaks down queries into multiple sub-tasks for parallel execution, fully leveraging multi-core CPU capabilities. It simultaneously addresses the thread explosion problem by limiting the number of query threads. The Pipeline execution engine reduces data copying and sharing, optimizes sorting and aggregation operations, thereby significantly improving query efficiency and throughput.\n\nIn terms of the optimizer, Apache Doris employs a combined optimization strategy of CBO (Cost-Based Optimizer), RBO (Rule-Based Optimizer), and HBO (History-Based Optimizer). RBO supports constant folding, subquery rewriting, predicate pushdown, and more. CBO supports join reordering and other optimizations. HBO recommends the optimal execution plan based on historical query information. These multiple optimization measures ensure that Doris can enumerate high-performance query plans across various types of queries.\n\n\n## üéÜ Why choose Apache Doris?\n\n- üéØ **Easy to Use:** Two processes, no other dependencies; online cluster scaling, automatic replica recovery; compatible with MySQL protocol, and using standard SQL.\n\n- üöÄ **High Performance:** Extremely fast performance for low-latency and high-throughput queries with columnar storage engine, modern MPP architecture, vectorized query engine, pre-aggregated materialized view and data index.\n\n- üñ•Ô∏è **Single Unified:** A single system can support real-time data serving, interactive data analysis and offline data processing scenarios.\n\n- ‚öõÔ∏è **Federated Querying:** Supports federated querying of data lakes such as Hive, Iceberg, Hudi, and databases such as MySQL and Elasticsearch.\n\n- ‚è© **Various Data Import Methods:** Supports batch import from HDFS/S3 and stream import from MySQL Binlog/Kafka; supports micro-batch writing through HTTP interface and real-time writing using Insert in JDBC.\n\n- üöô **Rich Ecology:** Spark uses Spark-Doris-Connector to read and write Doris; Flink-Doris-Connector enables Flink CDC to implement exactly-once data writing to Doris; DBT Doris Adapter is provided to transform data in Doris with DBT.\n\n## üôå Contributors\n\n**Apache Doris has graduated from Apache incubator successfully and become a Top-Level Project in June 2022**. \n\nWe deeply appreciate üîó[community contributors](https://github.com/apache/doris/graphs/contributors) for their contribution to Apache Doris.\n\n[![contrib graph](https://contrib.rocks/image?repo=apache/doris)](https://github.com/apache/doris/graphs/contributors)\n\n## üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Users\n\nApache Doris now has a wide user base in China and around the world, and as of today, **Apache Doris is used in production environments in thousands of companies worldwide.** More than 80% of the top 50 Internet companies in China in terms of market capitalization or valuation have been using Apache Doris for a long time, including Baidu, Meituan, Xiaomi, Jingdong, Bytedance, Tencent, NetEase, Kwai, Sina, 360, Mihoyo, and Ke Holdings. It is also widely used in some traditional industries such as finance, energy, manufacturing, and telecommunications.\n\nThe users of Apache Doris: üîó[Users](https://doris.apache.org/users)\n\nAdd your company logo at Apache Doris Website: üîó[Add Your Company](https://github.com/apache/doris/discussions/27683)\n \n## üë£ Get Started\n\n### üìö Docs\n\nAll Documentation   üîó[Docs](https://doris.apache.org/docs/gettingStarted/what-is-apache-doris)  \n\n### ‚¨áÔ∏è Download \n\nAll release and binary version üîó[Download](https://doris.apache.org/download) \n\n### üóÑÔ∏è Compile\n\nSee how to compile  üîó[Compilation](https://doris.apache.org/community/source-install/compilation-with-docker))\n\n### üìÆ Install\n\nSee how to install and deploy üîó[Installation and deployment](https://doris.apache.org/docs/install/preparation/env-checking) \n\n## üß© Components\n\n### üìù Doris Connector\n\nDoris provides support for Spark/Flink to read data stored in Doris through Connector, and also supports to write data to Doris through Connector.\n\nüîó[apache/doris-flink-connector](https://github.com/apache/doris-flink-connector)\n\nüîó[apache/doris-spark-connector](https://github.com/apache/doris-spark-connector)\n\n\n## üåà Community and Support\n\n### üì§ Subscribe Mailing Lists\n\nMail List is the most recognized form of communication in Apache community. See how to üîó[Subscribe Mailing Lists](https://doris.apache.org/community/subscribe-mail-list)\n\n### üôã Report Issues or Submit Pull Request\n\nIf you meet any questions, feel free to file a üîó[GitHub Issue](https://github.com/apache/doris/issues) or post it in üîó[GitHub Discussion](https://github.com/apache/doris/discussions) and fix it by submitting a üîó[Pull Request](https://github.com/apache/doris/pulls) \n\n### üçª How to Contribute\n\nWe welcome your suggestions, comments (including criticisms), comments and contributions. See üîó[How to Contribute](https://doris.apache.org/community/how-to-contribute/) and üîó[Code Submission Guide](https://doris.apache.org/community/how-to-contribute/pull-request/)\n\n### ‚å®Ô∏è Doris Improvement Proposals (DSIP)\n\nüîó[Doris Improvement Proposal (DSIP)](https://cwiki.apache.org/confluence/display/DORIS/Doris+Improvement+Proposals) can be thought of as **A Collection of Design Documents for all Major Feature Updates or Improvements**.\n\n### üîë Backend C++ Coding Specification\nüîó [Backend C++ Coding Specification](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=240883637) should be strictly followed, which will help us achieve better code quality.\n\n## üí¨ Contact Us\n\nContact us through the following mailing list.\n\n| Name                                                                          | Scope                           |                                                                 |                                                                     |                                                                              |\n|:------------------------------------------------------------------------------|:--------------------------------|:----------------------------------------------------------------|:--------------------------------------------------------------------|:-----------------------------------------------------------------------------|\n| [dev@doris.apache.org](mailto:dev@doris.apache.org)     | Development-related discussions | [Subscribe](mailto:dev-subscribe@doris.apache.org)   | [Unsubscribe](mailto:dev-unsubscribe@doris.apache.org)   | [Archives](http://mail-archives.apache.org/mod_mbox/doris-dev/)   |\n\n## üß∞ Links\n\n* Apache Doris Official Website - [Site](https://doris.apache.org)\n* Developer Mailing list - <dev@doris.apache.org>. Mail to <dev-subscribe@doris.apache.org>, follow the reply to subscribe the mail list.\n* Slack channel - [Join the Slack](https://doris.apache.org/slack)\n* Twitter - [Follow @doris_apache](https://twitter.com/doris_apache)\n\n\n## üìú License\n\n[Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\n> **Note**\n> Some licenses of the third-party dependencies are not compatible with Apache 2.0 License. So you need to disable\nsome Doris features to be complied with Apache 2.0 License. For details, refer to the `thirdparty/LICENSE.txt`\n\n\n\n",
      "stars_today": 6
    },
    {
      "id": 22711503,
      "name": "gcc",
      "full_name": "gcc-mirror/gcc",
      "description": null,
      "html_url": "https://github.com/gcc-mirror/gcc",
      "stars": 10634,
      "forks": 4677,
      "language": "C++",
      "topics": [],
      "created_at": "2014-08-07T06:50:37Z",
      "updated_at": "2026-01-23T00:20:51Z",
      "pushed_at": "2026-01-23T00:20:37Z",
      "open_issues": 49,
      "owner": {
        "login": "gcc-mirror",
        "avatar_url": "https://avatars.githubusercontent.com/u/8382043?v=4"
      },
      "readme": "This directory contains the GNU Compiler Collection (GCC).\n\nThe GNU Compiler Collection is free software.  See the files whose\nnames start with COPYING for copying permission.  The manuals, and\nsome of the runtime libraries, are under different terms; see the\nindividual source files for details.\n\nThe directory INSTALL contains copies of the installation information\nas HTML and plain text.  The source of this information is\ngcc/doc/install.texi.  The installation information includes details\nof what is included in the GCC sources and what files GCC installs.\n\nSee the file gcc/doc/gcc.texi (together with other files that it\nincludes) for usage and porting information.  An online readable\nversion of the manual is in the files gcc/doc/gcc.info*.\n\nSee http://gcc.gnu.org/bugs/ for how to report bugs usefully.\n\nCopyright years on GCC source files may be listed using range\nnotation, e.g., 1987-2012, indicating that every year in the range,\ninclusive, is a copyrightable year that could otherwise be listed\nindividually.\n",
      "stars_today": 6
    },
    {
      "id": 80087836,
      "name": "badger",
      "full_name": "dgraph-io/badger",
      "description": "Fast key-value DB in Go.",
      "html_url": "https://github.com/dgraph-io/badger",
      "stars": 15405,
      "forks": 1276,
      "language": "Go",
      "topics": [
        "database",
        "document-database",
        "go",
        "golang",
        "key-value",
        "library",
        "ssd"
      ],
      "created_at": "2017-01-26T05:09:49Z",
      "updated_at": "2026-01-22T23:27:55Z",
      "pushed_at": "2026-01-16T21:08:21Z",
      "open_issues": 38,
      "owner": {
        "login": "dgraph-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/13958706?v=4"
      },
      "readme": "# BadgerDB\n\n[![Go Reference](https://pkg.go.dev/badge/github.com/dgraph-io/badger/v4.svg)](https://pkg.go.dev/github.com/dgraph-io/badger/v4)\n[![Go Report Card](https://goreportcard.com/badge/github.com/dgraph-io/badger/v4)](https://goreportcard.com/report/github.com/dgraph-io/badger/v4)\n[![Sourcegraph](https://sourcegraph.com/github.com/dgraph-io/badger/-/badge.svg)](https://sourcegraph.com/github.com/dgraph-io/badger?badge)\n[![ci-badger-tests](https://github.com/dgraph-io/badger/actions/workflows/ci-badger-tests.yml/badge.svg)](https://github.com/dgraph-io/badger/actions/workflows/ci-badger-tests.yml)\n[![ci-badger-bank-tests](https://github.com/dgraph-io/badger/actions/workflows/ci-badger-bank-tests.yml/badge.svg)](https://github.com/dgraph-io/badger/actions/workflows/ci-badger-bank-tests.yml)\n[![ci-badger-bank-tests-nightly](https://github.com/dgraph-io/badger/actions/workflows/ci-badger-bank-tests-nightly.yml/badge.svg)](https://github.com/dgraph-io/badger/actions/workflows/ci-badger-bank-tests-nightly.yml)\n\n![Badger mascot](images/diggy-shadow.png)\n\nBadgerDB is an embeddable, persistent and fast key-value (KV) database written in pure Go. It is the\nunderlying database for [Dgraph](https://github.com/dgraph-io/dgraph), a fast, distributed graph\ndatabase. It's meant to be a performant alternative to non-Go-based key-value stores like RocksDB.\n\n## Project Status\n\nBadger is stable and is being used to serve data sets worth hundreds of terabytes. Badger supports\nconcurrent ACID transactions with serializable snapshot isolation (SSI) guarantees. A Jepsen-style\nbank test runs nightly for 8h, with `--race` flag and ensures the maintenance of transactional\nguarantees. Badger has also been tested to work with filesystem level anomalies, to ensure\npersistence and consistency. Badger is being used by a number of projects which includes Dgraph,\nJaeger Tracing, UsenetExpress, and many more.\n\nThe list of projects using Badger can be found [here](#projects-using-badger).\n\nPlease consult the [Changelog] for more detailed information on releases.\n\nNote: Badger is built with go 1.23 and we refrain from bumping this version to minimize downstream\neffects of those using Badger in applications built with older versions of Go.\n\n[Changelog]: https://github.com/dgraph-io/badger/blob/main/CHANGELOG.md\n\n## Table of Contents\n\n- [BadgerDB](#badgerdb)\n  - [Project Status](#project-status)\n  - [Table of Contents](#table-of-contents)\n  - [Getting Started](#getting-started)\n    - [Installing](#installing)\n      - [Installing Badger Command Line Tool](#installing-badger-command-line-tool)\n      - [Choosing a version](#choosing-a-version)\n  - [Badger Documentation](#badger-documentation)\n  - [Resources](#resources)\n    - [Blog Posts](#blog-posts)\n  - [Design](#design)\n    - [Comparisons](#comparisons)\n    - [Benchmarks](#benchmarks)\n  - [Projects Using Badger](#projects-using-badger)\n  - [Contributing](#contributing)\n  - [Contact](#contact)\n\n## Getting Started\n\n### Installing\n\nTo start using Badger, install Go 1.23 or above. Badger v3 and above needs go modules. From your\nproject, run the following command\n\n```sh\ngo get github.com/dgraph-io/badger/v4\n```\n\nThis will retrieve the library.\n\n#### Installing Badger Command Line Tool\n\nBadger provides a CLI tool which can perform certain operations like offline backup/restore. To\ninstall the Badger CLI, retrieve the repository and checkout the desired version. Then run\n\n```sh\ncd badger\ngo install .\n```\n\nThis will install the badger command line utility into your $GOBIN path.\n\n## Badger Documentation\n\nBadger Documentation is available at [https://badger.dgraph.io](https://badger.dgraph.io)\n\n## Resources\n\n### Blog Posts\n\n1. [Introducing Badger: A fast key-value store written natively in Go](https://hypermode.com/blog/badger/)\n2. [Make Badger crash resilient with ALICE](https://hypermode.com/blog/alice/)\n3. [Badger vs LMDB vs BoltDB: Benchmarking key-value databases in Go](https://hypermode.com/blog/badger-lmdb-boltdb/)\n4. [Concurrent ACID Transactions in Badger](https://hypermode.com/blog/badger-txn/)\n\n## Design\n\nBadger was written with these design goals in mind:\n\n- Write a key-value database in pure Go.\n- Use latest research to build the fastest KV database for data sets spanning terabytes.\n- Optimize for SSDs.\n\nBadger‚Äôs design is based on a paper titled _[WiscKey: Separating Keys from Values in SSD-conscious\nStorage][wisckey]_.\n\n[wisckey]: https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf\n\n### Comparisons\n\n| Feature                       | Badger                                     | RocksDB                       | BoltDB    |\n| ----------------------------- | ------------------------------------------ | ----------------------------- | --------- |\n| Design                        | LSM tree with value log                    | LSM tree only                 | B+ tree   |\n| High Read throughput          | Yes                                        | No                            | Yes       |\n| High Write throughput         | Yes                                        | Yes                           | No        |\n| Designed for SSDs             | Yes (with latest research <sup>1</sup>)    | Not specifically <sup>2</sup> | No        |\n| Embeddable                    | Yes                                        | Yes                           | Yes       |\n| Sorted KV access              | Yes                                        | Yes                           | Yes       |\n| Pure Go (no Cgo)              | Yes                                        | No                            | Yes       |\n| Transactions                  | Yes, ACID, concurrent with SSI<sup>3</sup> | Yes (but non-ACID)            | Yes, ACID |\n| Snapshots                     | Yes                                        | Yes                           | Yes       |\n| TTL support                   | Yes                                        | Yes                           | No        |\n| 3D access (key-value-version) | Yes<sup>4</sup>                            | No                            | No        |\n\n<sup>1</sup> The [WISCKEY paper][wisckey] (on which Badger is based) saw big wins with separating\nvalues from keys, significantly reducing the write amplification compared to a typical LSM tree.\n\n<sup>2</sup> RocksDB is an SSD optimized version of LevelDB, which was designed specifically for\nrotating disks. As such RocksDB's design isn't aimed at SSDs.\n\n<sup>3</sup> SSI: Serializable Snapshot Isolation. For more details, see the blog post\n[Concurrent ACID Transactions in Badger](https://hypermode.com/blog/badger-txn/)\n\n<sup>4</sup> Badger provides direct access to value versions via its Iterator API. Users can also\nspecify how many versions to keep per key via Options.\n\n### Benchmarks\n\nWe have run comprehensive benchmarks against RocksDB, Bolt and LMDB. The benchmarking code, and the\ndetailed logs for the benchmarks can be found in the [badger-bench] repo. More explanation,\nincluding graphs can be found the blog posts (linked above).\n\n[badger-bench]: https://github.com/dgraph-io/badger-bench\n\n## Projects Using Badger\n\nBelow is a list of known projects that use Badger:\n\n- [Dgraph](https://github.com/dgraph-io/dgraph) - Distributed graph database.\n- [Jaeger](https://github.com/jaegertracing/jaeger) - Distributed tracing platform.\n- [go-ipfs](https://github.com/ipfs/go-ipfs) - Go client for the InterPlanetary File System (IPFS),\n  a new hypermedia distribution protocol.\n- [Riot](https://github.com/go-ego/riot) - An open-source, distributed search engine.\n- [emitter](https://github.com/emitter-io/emitter) - Scalable, low latency, distributed pub/sub\n  broker with message storage, uses MQTT, gossip and badger.\n- [OctoSQL](https://github.com/cube2222/octosql) - Query tool that allows you to join, analyse and\n  transform data from multiple databases using SQL.\n- [Dkron](https://dkron.io/) - Distributed, fault tolerant job scheduling system.\n- [smallstep/certificates](https://github.com/smallstep/certificates) - Step-ca is an online\n  certificate authority for secure, automated certificate management.\n- [Sandglass](https://github.com/celrenheit/sandglass) - distributed, horizontally scalable,\n  persistent, time sorted message queue.\n- [TalariaDB](https://github.com/grab/talaria) - Grab's Distributed, low latency time-series\n  database.\n- [Sloop](https://github.com/salesforce/sloop) - Salesforce's Kubernetes History Visualization\n  Project.\n- [Usenet Express](https://usenetexpress.com/) - Serving over 300TB of data with Badger.\n- [gorush](https://github.com/appleboy/gorush) - A push notification server written in Go.\n- [0-stor](https://github.com/zero-os/0-stor) - Single device object store.\n- [Dispatch Protocol](https://github.com/dispatchlabs/disgo) - Blockchain protocol for distributed\n  application data analytics.\n- [GarageMQ](https://github.com/valinurovam/garagemq) - AMQP server written in Go.\n- [RedixDB](https://alash3al.github.io/redix/) - A real-time persistent key-value store with the\n  same redis protocol.\n- [BBVA](https://github.com/BBVA/raft-badger) - Raft backend implementation using BadgerDB for\n  Hashicorp raft.\n- [Fantom](https://github.com/Fantom-foundation/go-lachesis) - aBFT Consensus platform for\n  distributed applications.\n- [decred](https://github.com/decred/dcrdata) - An open, progressive, and self-funding\n  cryptocurrency with a system of community-based governance integrated into its blockchain.\n- [OpenNetSys](https://github.com/opennetsys/c3-go) - Create useful dApps in any software language.\n- [HoneyTrap](https://github.com/honeytrap/honeytrap) - An extensible and opensource system for\n  running, monitoring and managing honeypots.\n- [Insolar](https://github.com/insolar/insolar) - Enterprise-ready blockchain platform.\n- [IoTeX](https://github.com/iotexproject/iotex-core) - The next generation of the decentralized\n  network for IoT powered by scalability- and privacy-centric blockchains.\n- [go-sessions](https://github.com/kataras/go-sessions) - The sessions manager for Go net/http and\n  fasthttp.\n- [Babble](https://github.com/mosaicnetworks/babble) - BFT Consensus platform for distributed\n  applications.\n- [Tormenta](https://github.com/jpincas/tormenta) - Embedded object-persistence layer / simple JSON\n  database for Go projects.\n- [BadgerHold](https://github.com/timshannon/badgerhold) - An embeddable NoSQL store for querying Go\n  types built on Badger\n- [Goblero](https://github.com/didil/goblero) - Pure Go embedded persistent job queue backed by\n  BadgerDB\n- [Surfline](https://www.surfline.com) - Serving global wave and weather forecast data with Badger.\n- [Cete](https://github.com/mosuka/cete) - Simple and highly available distributed key-value store\n  built on Badger. Makes it easy bringing up a cluster of Badger with Raft consensus algorithm by\n  hashicorp/raft.\n- [Volument](https://volument.com/) - A new take on website analytics backed by Badger.\n- [KVdb](https://kvdb.io/) - Hosted key-value store and serverless platform built on top of Badger.\n- [Terminotes](https://gitlab.com/asad-awadia/terminotes) - Self hosted notes storage and search\n  server - storage powered by BadgerDB\n- [Pyroscope](https://github.com/pyroscope-io/pyroscope) - Open source continuous profiling platform\n  built with BadgerDB\n- [Veri](https://github.com/bgokden/veri) - A distributed feature store optimized for Search and\n  Recommendation tasks.\n- [bIter](https://github.com/MikkelHJuul/bIter) - A library and Iterator interface for working with\n  the `badger.Iterator`, simplifying from-to, and prefix mechanics.\n- [ld](https://github.com/MikkelHJuul/ld) - (Lean Database) A very simple gRPC-only key-value\n  database, exposing BadgerDB with key-range scanning semantics.\n- [Souin](https://github.com/darkweak/Souin) - A RFC compliant HTTP cache with lot of other features\n  based on Badger for the storage. Compatible with all existing reverse-proxies.\n- [Xuperchain](https://github.com/xuperchain/xupercore) - A highly flexible blockchain architecture\n  with great transaction performance.\n- [m2](https://github.com/qichengzx/m2) - A simple http key/value store based on the raft protocol.\n- [chaindb](https://github.com/ChainSafe/chaindb) - A blockchain storage layer used by\n  [Gossamer](https://chainsafe.github.io/gossamer/), a Go client for the\n  [Polkadot Network](https://polkadot.network/).\n- [vxdb](https://github.com/vitalvas/vxdb) - Simple schema-less Key-Value NoSQL database with\n  simplest API interface.\n- [Opacity](https://github.com/opacity/storage-node) - Backend implementation for the Opacity\n  storage project\n- [Vephar](https://github.com/vaccovecrana/vephar) - A minimal key/value store using hashicorp-raft\n  for cluster coordination and Badger for data storage.\n- [gowarcserver](https://github.com/nlnwa/gowarcserver) - Open-source server for warc files. Can be\n  used in conjunction with pywb\n- [flow-go](https://github.com/onflow/flow-go) - A fast, secure, and developer-friendly blockchain\n  built to support the next generation of games, apps and the digital assets that power them.\n- [Wrgl](https://www.wrgl.co) - A data version control system that works like Git but specialized to\n  store and diff CSV.\n- [Loggie](https://github.com/loggie-io/loggie) - A lightweight, cloud-native data transfer agent\n  and aggregator.\n- [raft-badger](https://github.com/rfyiamcool/raft-badger) - raft-badger implements LogStore and\n  StableStore Interface of hashcorp/raft. it is used to store raft log and metadata of\n  hashcorp/raft.\n- [DVID](https://github.com/janelia-flyem/dvid) - A dataservice for branched versioning of a variety\n  of data types. Originally created for large-scale brain reconstructions in Connectomics.\n- [KVS](https://github.com/tauraamui/kvs) - A library for making it easy to persist, load and query\n  full structs into BadgerDB, using an ownership hierarchy model.\n- [LLS](https://github.com/Boc-chi-no/LLS) - LLS is an efficient URL Shortener that can be used to\n  shorten links and track link usage. Support for BadgerDB and MongoDB. Improved performance by more\n  than 30% when using BadgerDB\n- [lakeFS](https://github.com/treeverse/lakeFS) - lakeFS is an open-source data version control that\n  transforms your object storage to Git-like repositories. lakeFS uses BadgerDB for its underlying\n  local metadata KV store implementation\n- [Goptivum](https://github.com/smegg99/Goptivum) - Goptivum is a better frontend and API for the\n  Vulcan Optivum schedule program\n- [ActionManager](https://mftlabs.io/actionmanager) - A dynamic entity manager based on rjsf schema\n  and badger db\n- [MightyMap](https://github.com/thisisdevelopment/mightymap) - Mightymap: Conveys both robustness\n  and high capability, fitting for a powerful concurrent map.\n- [FlowG](https://github.com/link-society/flowg) - A low-code log processing facility\n- [Bluefin](https://github.com/blinklabs-io/bluefin) - Bluefin is a TUNA Proof of Work miner for the\n  Fortuna smart contract on the Cardano blockchain\n- [cDNSd](https://github.com/blinklabs-io/cdnsd) - A Cardano blockchain backed DNS server daemon\n- [Dingo](https://github.com/blinklabs-io/dingo) - A Cardano blockchain data node\n\nIf you are using Badger in a project please send a pull request to add it to the list.\n\n## Contributing\n\nIf you're interested in contributing to Badger see [CONTRIBUTING](./CONTRIBUTING.md).\n\n## Contact\n\n- Please use [Github issues](https://github.com/dgraph-io/badger/issues) for filing bugs.\n- Please use [Discussions](https://github.com/orgs/dgraph-io/discussions) for questions,\n  discussions, and feature requests.\n",
      "stars_today": 6
    },
    {
      "id": 201517171,
      "name": "tonic",
      "full_name": "hyperium/tonic",
      "description": "A native gRPC client & server implementation with async/await support.",
      "html_url": "https://github.com/hyperium/tonic",
      "stars": 11745,
      "forks": 1167,
      "language": "Rust",
      "topics": [
        "async",
        "grpc",
        "proto",
        "rpc",
        "rust"
      ],
      "created_at": "2019-08-09T17:59:37Z",
      "updated_at": "2026-01-23T00:40:45Z",
      "pushed_at": "2026-01-16T12:04:42Z",
      "open_issues": 313,
      "owner": {
        "login": "hyperium",
        "avatar_url": "https://avatars.githubusercontent.com/u/8730506?v=4"
      },
      "readme": "![](https://github.com/hyperium/tonic/raw/master/.github/assets/tonic-banner.svg?sanitize=true)\n\n\nA rust implementation of [gRPC], a high performance, open source, general\nRPC framework that puts mobile and HTTP/2 first.\n\n> **Note**: tonic's [master](https://github.com/hyperium/tonic) branch is\n> currently preparing breaking changes. For the most recently *released* code,\n> look to the [0.14.x branch](https://github.com/hyperium/tonic/tree/v0.14.x).\n\n[`tonic`] is a gRPC over HTTP/2 implementation focused on high performance, interoperability, and flexibility. This library was created to have first class support of async/await and to act as a core building block for production systems written in Rust.\n\n[![Crates.io](https://img.shields.io/crates/v/tonic)](https://crates.io/crates/tonic)\n[![Documentation](https://docs.rs/tonic/badge.svg)](https://docs.rs/tonic)\n[![Crates.io](https://img.shields.io/crates/l/tonic)](LICENSE)\n\n\n[Examples] | [Website] | [Docs] | [Chat][discord]\n\n## Overview\n\n[`tonic`] is composed of three main components: the generic gRPC implementation, the high performance HTTP/2\nimplementation and the codegen powered by [`prost`]. The generic implementation can support any HTTP/2\nimplementation and any encoding via a set of generic traits. The HTTP/2 implementation is based on [`hyper`],\na fast HTTP/1.1 and HTTP/2 client and server built on top of the robust [`tokio`] stack. The codegen\ncontains the tools to build clients and servers from [`protobuf`] definitions.\n\n## Features\n\n- Bi-directional streaming\n- High performance async io\n- Interoperability\n- TLS backed by [`rustls`]\n- Load balancing\n- Custom metadata\n- Authentication\n- Health Checking\n\n## Getting Started\n\n- The [`helloworld`][helloworld-tutorial] tutorial provides a basic example of using `tonic`, perfect for first time users!\n- The [`routeguide`][routeguide-tutorial] tutorial provides a complete example of using `tonic` and all its features.\n\nExamples can be found in [`examples`] and for more complex scenarios [`interop`]\nmay be a good resource as it shows examples of many of the gRPC features.\n\n### Rust Version\n\n`tonic`'s MSRV is `1.75`.\n\n### Dependencies\n\n[`tonic-build`] uses `protoc` [Protocol Buffers compiler] in some APIs which compile Protocol Buffers resource files such as [`tonic_build::compile_protos()`].\n\n[Protocol Buffers compiler]: https://protobuf.dev/downloads/\n[`tonic_build::compile_protos()`]: https://docs.rs/tonic-build/latest/tonic_build/fn.compile_protos.html\n\n## Getting Help\n\nFirst, see if the answer to your question can be found in the API documentation.\nIf the answer is not there, there is an active community in\nthe [Tonic Discord channel][discord]. We would be happy to try to answer your\nquestion. If that doesn't work, try opening an [issue] with the question.\n\n[issue]: https://github.com/hyperium/tonic/issues/new/choose\n\n## Project Layout\n\n- [`tonic`]: Generic gRPC and HTTP/2 client/server implementation.\n- [`tonic-build`]: [`prost`] based service codegen.\n- [`tonic-types`]: [`prost`] based grpc utility types including support for gRPC Well Known Types.\n- [`tonic-health`]: Implementation of the standard [gRPC health checking service][healthcheck].\n  Also serves as an example of both unary and response streaming.\n- [`tonic-reflection`]: A tonic based gRPC reflection implementation.\n- [`examples`]: Example gRPC implementations showing off tls, load balancing and bi-directional streaming.\n- [`interop`]: Interop tests implementation.\n\n## Contributing\n\n:balloon: Thanks for your help improving the project! We are so happy to have\nyou! We have a [contributing guide][guide] to help you get involved in the Tonic\nproject.\n\n[guide]: CONTRIBUTING.md\n\n## License\n\nThis project is licensed under the [MIT license](LICENSE).\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in Tonic by you, shall be licensed as MIT, without any additional\nterms or conditions.\n\n\n[gRPC]: https://grpc.io\n[`tonic`]: ./tonic\n[`tonic-build`]: ./tonic-build\n[`tonic-types`]: ./tonic-types\n[`tonic-health`]: ./tonic-health\n[`tonic-reflection`]: ./tonic-reflection\n[`examples`]: ./examples\n[`interop`]: ./interop\n[`tokio`]: https://github.com/tokio-rs/tokio\n[`hyper`]: https://github.com/hyperium/hyper\n[`prost`]: https://github.com/tokio-rs/prost\n[`protobuf`]: https://protobuf.dev/\n[`rustls`]: https://github.com/rustls/rustls\n[`interop`]: https://github.com/hyperium/tonic/tree/master/interop\n[Examples]: https://github.com/hyperium/tonic/tree/master/examples\n[Website]: https://github.com/hyperium/tonic\n[Docs]: https://docs.rs/tonic\n[discord]: https://discord.gg/6yGkFeN\n[routeguide-tutorial]: https://github.com/hyperium/tonic/blob/master/examples/routeguide-tutorial.md\n[helloworld-tutorial]: https://github.com/hyperium/tonic/blob/master/examples/helloworld-tutorial.md\n[healthcheck]: https://grpc.io/docs/guides/health-checking/\n",
      "stars_today": 6
    },
    {
      "id": 1023406764,
      "name": "TrackWeight",
      "full_name": "KrishKrosh/TrackWeight",
      "description": "Use your Mac trackpad as a weighing scale",
      "html_url": "https://github.com/KrishKrosh/TrackWeight",
      "stars": 8568,
      "forks": 371,
      "language": "Swift",
      "topics": [],
      "created_at": "2025-07-21T05:55:02Z",
      "updated_at": "2026-01-22T20:53:21Z",
      "pushed_at": "2025-07-27T02:34:55Z",
      "open_issues": 20,
      "owner": {
        "login": "KrishKrosh",
        "avatar_url": "https://avatars.githubusercontent.com/u/50386081?v=4"
      },
      "readme": "# TrackWeight\n\n**Turn your MacBook's trackpad into a precise digital weighing scale**\n\n[TrackWeight](\nhttps://x.com/KrishRShah/status/1947186835811193330) is a macOS application that transforms your MacBook's trackpad into an accurate weighing scale by leveraging the Force Touch pressure sensors built into modern MacBook trackpads.\n\nhttps://github.com/user-attachments/assets/7eaf9e0b-3dec-4829-b868-f54a8fd53a84\n\nTo use it yourself:\n\n1. Open the scale\n2. Rest your finger on the trackpad\n3. While maintaining finger contact, put your object on the trackpad\n4. Try to put as little pressure on the trackpad while still maintaining contact. This is the weight of your object\n\n## How It Works\n\nTrackWeight utilizes a custom fork of the [Open Multi-Touch Support library](https://github.com/krishkrosh/OpenMultitouchSupport) by [Takuto Nakamura](https://github.com/Kyome22) to gain private access to all mouse and trackpad events on macOS. This library provides detailed touch data including pressure readings that are normally inaccessible to standard applications.\n\nThe key insight is that trackpad pressure events are only generated when there's capacitance detected on the trackpad surface - meaning your finger (or another conductive object) must be in contact with the trackpad. When this condition is met, the trackpad's Force Touch sensors provide precise pressure readings that can be calibrated and converted into weight measurements.\n\n## Requirements\n\n- **macOS 13.0+** (Ventura or later)\n- **MacBook with Force Touch trackpad** (2015 or newer MacBook Pro, 2016 or newer MacBook)\n- **App Sandbox disabled** (required for low-level trackpad access)\n- **Xcode 16.0+** and **Swift 6.0+** (for development)\n\n## Installation\n\n### Option 1: Download DMG (Recommended)\n\n1. Go to the [Releases](https://github.com/krishkrosh/TrackWeight/releases) page\n2. Download the latest TrackWeight DMG file\n3. Open the DMG and drag TrackWeight.app to your Applications folder\n4. Run the application (you may need to allow it in System Preferences > Security & Privacy for unsigned builds)\n\n### Option 2: Homebrew\n```bash\nbrew install --cask krishkrosh/apps/trackweight --force\n```\n \n### Option 3: Build from Source\n\n1. Clone this repository\n2. Open `TrackWeight.xcodeproj` in Xcode\n3. Disable App Sandbox in the project settings (required for trackpad access)\n4. Build and run the application\n\nFor more information about setting up the build pipeline, see [.github/workflows/README.md](.github/workflows/README.md).\n\n### Calibration Process\n\nThe weight calculations have been validated by:\n1. Placing the MacBook trackpad directly on top of a conventional digital scale\n2. Applying various known weights while maintaining finger contact with the trackpad\n3. Comparing and calibrating the pressure readings against the reference scale measurements\n4. Ensuring consistent accuracy across different weight ranges\n\nIt turns out that the data we get from MultitouchSupport is already in grams!\n\n## Limitations\n\n- **Finger contact required**: The trackpad only provides pressure readings when it detects capacitance (finger touch), so you cannot weigh objects directly without maintaining contact\n- **Surface contact**: Objects being weighed must be placed in a way that doesn't interfere with the required finger contact\n- **Metal objects**: Metal objects may be detected as a finger touch, so you may need to place a piece of paper or a cloth between the object and the trackpad to get an accurate reading\n\n## Technical Details\n\nThe application is built using:\n- **SwiftUI** for the user interface\n- **Combine** for reactive data flow\n- **Open Multi-Touch Support library** for low-level trackpad access\n\n### Open Multi-Touch Support Library\n\nThis project relies heavily on the excellent work by **Takuto Nakamura** ([@Kyome22](https://github.com/Kyome22)) and the [Open Multi-Touch Support library](https://github.com/krishkrosh/OpenMultitouchSupport). The library provides:\n\n- Access to global multitouch events on macOS trackpads\n- Detailed touch data including position, pressure, angle, and density\n- Thread-safe async/await support for touch event streams\n- Touch state tracking and comprehensive sensor data\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Disclaimer\n\nThis application is for experimental and educational purposes. While efforts have been made to ensure accuracy, TrackWeight should not be used for critical measurements or commercial applications where precision is essential. Always verify measurements with a calibrated scale for important use cases.\n",
      "stars_today": 6
    },
    {
      "id": 129699403,
      "name": "tuist",
      "full_name": "tuist/tuist",
      "description": "A virtual platform team for mobile devs who ship ",
      "html_url": "https://github.com/tuist/tuist",
      "stars": 5481,
      "forks": 689,
      "language": "Swift",
      "topics": [
        "ios",
        "objective-c",
        "productivity",
        "scalability",
        "swift",
        "xcode"
      ],
      "created_at": "2018-04-16T07:02:54Z",
      "updated_at": "2026-01-22T21:54:26Z",
      "pushed_at": "2026-01-22T21:55:57Z",
      "open_issues": 257,
      "owner": {
        "login": "tuist",
        "avatar_url": "https://avatars.githubusercontent.com/u/38419084?v=4"
      },
      "readme": "<div align=\"center\">\n  <div>\n    <a href=\"https://tuist.dev\" target=\"_blank\"><img src=\"assets/header.png\" alt=\"header\"/></a>\n  </div>\n  <img src=\"https://img.shields.io/github/commit-activity/w/tuist/tuist?style=flat-square&label=commits\" alt=\"Commit Activity\">\n  <a href=\"https://fosstodon.org/@tuist\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=mastodon&logoColor=f5f5f5\" alt=\"Mastodon badge\"></a>\n  <a href=\"https://bsky.app/profile/tuist.dev\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=bluesky\" alt=\"Bluesky badge\"></a>\n  <a href=\"https://join.slack.com/t/tuistapp/shared_invite/zt-1lqw355mp-zElRwLeoZ2EQsgGEkyaFgg\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=slack\" alt=\"Slack Workspace\"></a>\n  <a href=\"https://t.me/tuist\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=telegram\" alt=\"Slack Workspace\"></a>\n  <div>\n    <a href=\"https://cal.com/team/tuist/cloud?utm_source=banner&utm_campaign=oss\" target=\"_blank\"><img alt=\"Book us with Cal.com\" src=\"https://cal.com/book-with-cal-dark.svg\" width=\"150\"/></a>\n  </div>\n  <a href=\"https://translate.tuist.dev/engage/tuist/\">\n  <img src=\"https://translate.tuist.dev/widget/tuist/svg-badge.svg\" alt=\"Translation status\" />\n  </a>\n</div>\n\n# Tuist\n\nTuist is a virtual platform team for Swift app devs who ship. Through an integrated platform that integrates with your toolchain and projects, we help you stay focused and productive while building apps.\n\nThe following solutions are part of Tuist:\n\n- [üóÇÔ∏è **Generated projects**](https://docs.tuist.dev/en/guides/develop/projects): A solution for more accessible and easier-to-manage Xcode projects.\n- [üöù **Cache**](https://docs.tuist.dev/en/guides/develop/cache): Speed up builds across environments with a content-addressable store.\n- [‚úÖ **Selective testing**](https://docs.tuist.dev/en/guides/develop/selective-testing): Run tests faster by selecting them based on the file changes.\n- [üì¶ **Registry**](https://docs.tuist.dev/en/guides/develop/registry): Speed up the resolution of [Swift Package Index](https://swiftpackageindex.com/)-indexed packages.\n- [üìà **Build insights**](https://docs.tuist.dev/en/guides/develop/insights): Get actionable insights from your projects, builds, and test runs to make informed decisions.\n- [üì± **Bundle insights**](https://docs.tuist.dev/en/guides/develop/bundle-size): Analyze your built apps and get suggestions to improve them.\n- [üì± **Previews**](https://docs.tuist.dev/en/guides/features/previews): Sharing apps (previews) as easy as sharing a link.\n- [‚úÖ **QA**](https://docs.tuist.dev/en/guides/features/qa): QA your app using LLM-based agents.\n\nOpenness and community are cornerstones in shaping Tuist, as we believe they are the key to building the best solution. We recommend checking out the following resources:\n\n- [üìë **Documentation**](https://docs.tuist.dev)\n- [üìö **Handbook**](https://handbook.tuist.dev)\n- [üí¨ **Community forum**](https://community.tuist.dev)\n\n> [!NOTE]\n> Even though our current focus is on the development phase of Apple native apps, we'll gradually expand our focus to include other ecosystems (e.g., Android, RN, and Flutter), and expand beyond just development.\n\n## Get started\n\nYou can run the following command to get started with [Mise] (check out [this page](https://docs.tuist.dev/en/guides/quick-start/get-started) for other methods):\n\n```bash\nmise x tuist@latest -- tuist init\n```\n\n> [!IMPORTANT]\n> The `init` workflow is designed to integrate with an existing Xcode project or create [a generated project](https://docs.tuist.dev/en/guides/features/projects). If you are migrating an existing Xcode project to a generated project, we recommend [checking out these docs](https://docs.tuist.dev/en/guides/features/projects/adoption/migrate/xcode-project).\n\n## Documentation\n\nDo you want to know more about what Tuist can offer you? Or perhaps want to contribute to the project and you need a starting point?\n\nYou can check out [the project documentation](https://docs.tuist.dev).\n\n### Sample projects\n\nYou can find some sample projects in the [examples folder](examples/xcode) or the [awesome Tuist repo](https://github.com/tuist/awesome-tuist)! üéâ\n\n## Development\n\nThis repository represents a monorepo with the following projects:\n\n| Project | Description |\n| ------ | -------  |\n| [cli](/cli) | The command line interface for Tuist |\n| [app](/app) | The Swift-powered iOS and macOS app |\n| [docs](/docs) | The documentation for Tuist |\n| [handbook](/handbook) | The company's handbook |\n\n## Sponsors\n\nSome companies support our community and open source efforts with contributions through [GitHub Sponsors](https://github.com/sponsors/tuist) and [Open Collective Backers](https://opencollective.com/tuistapp). We'd like to give a special mention to the following sponsors:\n\n<table>\n  <tbody>\n    <tr>\n      <td width=\"30%\" align=\"center\">\n        <a href=\"https://monday.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\" target=\"_blank\">\n          <img width=\"300\" src=\"assets/companies/monday.com.svg\" alt=\"mondaycom_logo\"/>\n        </a>\n      </td>\n      <td><a href=\"https://monday.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\">Monday.com</a> is a cloud-based work operating system (Work OS) that empowers teams to run projects and workflows with confidence. It's a versatile platform that combines features of project management, workflow automation, and team collaboration to streamline the way teams work together.</td>\n    </tr>\n    <tr>\n      <td width=\"30%\" align=\"center\">\n        <a href=\"https://lapse.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\" target=\"_blank\">\n          <img width=\"200\" src=\"assets/companies/lapse.svg\" alt=\"lapse_logo\"/>\n        </a>\n      </td>\n      <td><a href=\"https://lapse.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\">Lapse</a> is an app designed to reclaim how we take and share memories. A camera for living in the moment and a private photo journal for friends, not followers.</td>\n    </tr>\n  </tbody>\n</table>\n\n## Companies using Tuist\n\n<table>\n  <tbody>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://play.tv2.no\" target=\"_blank\">\n          <img src=\"assets/companies/tv2.svg\" alt=\"tv2_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.depop.com\" target=\"_blank\">\n          <img src=\"assets/companies/depop.svg\" alt=\"depop_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://bendingspoons.com\" target=\"_blank\">\n          <picture>\n            <source\n              srcset=\"assets/companies/bendingspoons-darkmode.png\"\n              media=\"(prefers-color-scheme: dark)\">\n            <img src=\"assets/companies/bendingspoons.png\" alt=\"bendingspoons_logo\"/>\n          </picture>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://globekeeper.com\" target=\"_blank\">\n          <img src=\"assets/companies/globekeeper.png\" alt=\"globekeeper_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://getyourguide.com\" target=\"_blank\">\n          <img src=\"assets/companies/getyourguide.png\" alt=\"getyourguide_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://emplate.it\" target=\"_blank\">\n          <img src=\"assets/companies/emplate.svg\" alt=\"emplate_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.trendyol.com\" target=\"_blank\">\n          <img src=\"assets/companies/Trendyol.png\" alt=\"trendyol_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://angrynerds.co\" target=\"_blank\">\n          <img src=\"assets/companies/angrynerds.svg\" alt=\"angrynerds_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.compass.com\" target=\"_blank\">\n          <img src=\"assets/companies/compass.png\" alt=\"compass_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.wefox.com\" target=\"_blank\">\n          <img src=\"assets/companies/wefox.png\" alt=\"wefox_logo\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.hedvig.com\" target=\"_blank\">\n            <img src=\"assets/companies/hedvig.svg\" alt=\"hedvig_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.takeoutcentral.com\" target=\"_blank\">\n          <img src=\"assets/companies/takeoutcentral.svg\" alt=\"takeoutcentral_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.olx.com.br\" target=\"_blank\">\n          <img src=\"assets/companies/olx.png\" alt=\"olx_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.justeattakeaway.com\" target=\"_blank\">\n          <img src=\"assets/companies/justeattakeaway.svg\" alt=\"justeattakeaway_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://qnips.io\" target=\"_blank\">\n          <img src=\"assets/companies/qnips.svg\" alt=\"qnips_logo\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.telepass.com\" target=\"_blank\">\n          <img src=\"assets/companies/telepass.svg\" alt=\"telepass_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.crunchyroll.com\" target=\"_blank\">\n          <img src=\"assets/companies/crunchyroll.svg\" alt=\"crunchyroll_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://altel.kz\" target=\"_blank\">\n          <img src=\"assets/companies/altel.svg\" alt=\"altel_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://tele2.kz\" target=\"_blank\">\n          <img src=\"assets/companies/tele2.svg\" alt=\"altel_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://izi.me/kz\" target=\"_blank\">\n          <img src=\"assets/companies/izi.svg\" alt=\"izi_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://wise.com\" target=\"_blank\">\n          <img src=\"assets/companies/wise.png\" alt=\"wise_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://zapis.kz/\" target=\"_blank\">\n          <img src=\"assets/companies/zapis.svg\" alt=\"wise_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://apps.apple.com/kz/app/rbk-business/id1466194695\" target=\"_blank\">\n          <img src=\"assets/companies/rbkbusiness.svg\" alt=\"rbkbusiness_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://snoonu.com/\" target=\"_blank\">\n          <img src=\"assets/companies/snoonu.svg\" alt=\"rbkbusiness_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://get.sajda.app\" target=\"_blank\">\n          <img src=\"assets/companies/sajda_app.svg\" alt=\"sajda_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n     <td width=\"20%\" align=\"center\">\n        <a href=\"https://abb-bank.az\" target=\"_blank\">\n          <img src=\"assets/companies/abb-logo-slogan.png\" alt=\"abb_mobile_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n    </tr>\n  </tbody>\n</table>\n\n## Want to contribute?\n\nYou can use our [contribution docs](https://docs.tuist.dev/en/contributors/code) to get started. You can find good issues for first-time contributors [here](https://github.com/tuist/tuist/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22).\n\n## Core Alumni\n\nThe following people were once core contributors helping steer the project in the right direction and ensuring we have a reliable foundation we can build new features upon:\n\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"http://www.matrixprojects.net\"><img src=\"https://avatars3.githubusercontent.com/u/11914919?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kas</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/danyf90\"><img src=\"https://avatars.githubusercontent.com/u/2794031?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniele Formichelli</b></sub></a><br /></td>\n    <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/waltflanagan\"><img src=\"https://avatars.githubusercontent.com/u/398293?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mike Simons</b></sub></a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://natanrolnik.me\"><img src=\"https://avatars3.githubusercontent.com/u/1164565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Natan Rolnik</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/andreacipriani\"><img src=\"https://avatars3.githubusercontent.com/u/536929?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrea Cipriani</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/ollieatkinson\"><img src=\"https://avatars1.githubusercontent.com/u/1382565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Oliver Atkinson</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/RomainBoulay\"><img src=\"https://avatars1.githubusercontent.com/u/169323?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Romain Boulay</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/laxmorek\"><img src=\"https://avatars1.githubusercontent.com/u/4774319?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kamil Harasimowicz</b></sub></a><br /></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://www.luispadron.com\"><img src=\"https://avatars3.githubusercontent.com/u/13840545?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luis Padron</b></sub></a></td>\n    <td align=\"center\"><a href=\"https://github.com/adellibovi\"><img src=\"https://avatars3.githubusercontent.com/u/67916?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alfredo Delli Bovi</b></sub></a><br /></td>\n  </tr>\n</table>\n\n## Contributors\n\nThanks goes to these wonderful people:\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kalkwarf\"><img src=\"https://avatars1.githubusercontent.com/u/1033839?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kalkwarf</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/fortmarek\"><img src=\"https://avatars0.githubusercontent.com/u/9371695?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marek Fo≈ôt</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.matrixprojects.net\"><img src=\"https://avatars3.githubusercontent.com/u/11914919?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kas</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://natanrolnik.me\"><img src=\"https://avatars3.githubusercontent.com/u/1164565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Natan Rolnik</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/svastven\"><img src=\"https://avatars0.githubusercontent.com/u/42235915?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>svastven</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://bhuemer.github.io\"><img src=\"https://avatars2.githubusercontent.com/u/1212480?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Bernhard Huemer</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://djankowski.dev\"><img src=\"https://avatars0.githubusercontent.com/u/10795657?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniel Jankowski</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/facumenzella\"><img src=\"https://avatars1.githubusercontent.com/u/1125252?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Facundo Menzella</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/eito\"><img src=\"https://avatars3.githubusercontent.com/u/775643?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Eric Ito</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/laxmorek\"><img src=\"https://avatars2.githubusercontent.com/u/4774319?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kamil Harasimowicz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/olejnjak\"><img src=\"https://avatars1.githubusercontent.com/u/3148214?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jakub Olejn√≠k</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lakpa\"><img src=\"https://avatars0.githubusercontent.com/u/389328?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ldindu</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gtsifrikas\"><img src=\"https://avatars2.githubusercontent.com/u/8904378?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>George Tsifrikas</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yurapriv\"><img src=\"https://avatars2.githubusercontent.com/u/7814127?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Privezentsev Yura</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ferologics.github.io\"><img src=\"https://avatars2.githubusercontent.com/u/5576161?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Fero</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://heberti.com\"><img src=\"https://avatars0.githubusercontent.com/u/103670?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Heberti Almeida</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://benscheirman.com\"><img src=\"https://avatars0.githubusercontent.com/u/59140?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ben Scheirman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jsorge.net\"><img src=\"https://avatars3.githubusercontent.com/u/2585841?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jared Sorge</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://joeblau.com\"><img src=\"https://avatars1.githubusercontent.com/u/1218847?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Joe Blau</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/dchavezlive\"><img src=\"https://avatars0.githubusercontent.com/u/2475932?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Chavez</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/—Ä–æ–º–∞–Ω-–ø–æ–¥—ã–º–æ–≤-72338ab0/\"><img src=\"https://avatars3.githubusercontent.com/u/10789692?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Roman Podymov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/marcinreliga-fn\"><img src=\"https://avatars0.githubusercontent.com/u/76949651?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marcin Religa</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/adellibovi\"><img src=\"https://avatars3.githubusercontent.com/u/67916?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alfredo Delli Bovi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Jake-Prickett\"><img src=\"https://avatars1.githubusercontent.com/u/26095410?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jake Prickett</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danyf90\"><img src=\"https://avatars.githubusercontent.com/u/2794031?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniele Formichelli</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.facebook.com/PetrachkovSergey\"><img src=\"https://avatars.githubusercontent.com/u/7995896?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sergey Petrachkov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jinuman.github.io/resume\"><img src=\"https://avatars.githubusercontent.com/u/26243835?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jinwoo, Kim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/thedavidharris\"><img src=\"https://avatars.githubusercontent.com/u/5666250?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Harris</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DimaMishchenko\"><img src=\"https://avatars.githubusercontent.com/u/25247301?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmytro Mishchenko</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.sampettersson.com\"><img src=\"https://avatars.githubusercontent.com/u/5459507?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Pettersson</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.joshholtz.com\"><img src=\"https://avatars.githubusercontent.com/u/401294?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Josh Holtz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jierong.dev\"><img src=\"https://avatars.githubusercontent.com/u/7414906?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jierong Li</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/freak4pc\"><img src=\"https://avatars.githubusercontent.com/u/605076?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shai Mishali</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/FranzJBusch\"><img src=\"https://avatars.githubusercontent.com/u/3491887?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Franz Busch</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tiarnann\"><img src=\"https://avatars.githubusercontent.com/u/10522081?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>T√≠arn√°n McGrath</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/softmaxsg\"><img src=\"https://avatars.githubusercontent.com/u/3723817?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vitaly Chupryk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rmnblm\"><img src=\"https://avatars.githubusercontent.com/u/5942764?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Roman Blum</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://nanotek.me\"><img src=\"https://avatars.githubusercontent.com/u/7265334?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Giovanni Filaferro</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/tovkal\"><img src=\"https://avatars.githubusercontent.com/u/5960675?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andr√©s Piz√° B√ºckmann</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://coutinho.dev\"><img src=\"https://avatars.githubusercontent.com/u/17842860?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gabriel Coutinho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@riccardocipolleschi\"><img src=\"https://avatars.githubusercontent.com/u/11162307?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Riccardo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bolismauro\"><img src=\"https://avatars.githubusercontent.com/u/771999?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mauro Bolis</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/iteractive_man\"><img src=\"https://avatars.githubusercontent.com/u/461805?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Peter Weishapl</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://stackoverflow.com/users/1878594/swiftycruz\"><img src=\"https://avatars.githubusercontent.com/u/2609775?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Cruz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/svenmuennich\"><img src=\"https://avatars.githubusercontent.com/u/1932115?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sven M√ºnnich</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/santi-d\"><img src=\"https://avatars.githubusercontent.com/u/993826?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Santiago A. Delgado</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://wojciechkulik.pl\"><img src=\"https://avatars.githubusercontent.com/u/3128467?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Wojciech Kulik</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/iainsmith\"><img src=\"https://avatars.githubusercontent.com/u/993745?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Iain Smith</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/havebeenfitz\"><img src=\"https://avatars.githubusercontent.com/u/31866271?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Max Kraev</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mstfy\"><img src=\"https://avatars.githubusercontent.com/u/5105861?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Yusuf</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/danielbarden\"><img src=\"https://avatars.githubusercontent.com/u/104456?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniel Barden</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zzzkk\"><img src=\"https://avatars.githubusercontent.com/u/12541603?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Zofia Kulus</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://randombits.org/\"><img src=\"https://avatars.githubusercontent.com/u/3589315?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Peterson</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://bandism.net/\"><img src=\"https://avatars.githubusercontent.com/u/22633385?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ikko Ashimine</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/setoelkahfi\"><img src=\"https://avatars.githubusercontent.com/u/1797197?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Seto Elkahfi / Â°ûÊâò¬∑ÂüÉÂ∞îÂç°Ëè≤</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://apps4everyone.at\"><img src=\"https://avatars.githubusercontent.com/u/1915802?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>apps4everyone</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/LorDisturbia\"><img src=\"https://avatars.githubusercontent.com/u/12445776?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lorenzo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DarkoDamjanovic\"><img src=\"https://avatars.githubusercontent.com/u/11902775?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Darko Damjanovic</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/MarvinNazari\"><img src=\"https://avatars.githubusercontent.com/u/926772?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marvin Nazari</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/codeOfRobin\"><img src=\"https://avatars.githubusercontent.com/u/5009041?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Robin Malhotra</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/astromonkee\"><img src=\"https://avatars.githubusercontent.com/u/44421303?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Astromonkee</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ezraberch\"><img src=\"https://avatars.githubusercontent.com/u/49635435?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ezraberch</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/cconstable\"><img src=\"https://avatars.githubusercontent.com/u/564781?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Christopher Constable</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/neakor\"><img src=\"https://avatars.githubusercontent.com/u/1827517?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yi Wang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.mustafadur.com\"><img src=\"https://avatars.githubusercontent.com/u/971530?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Dur</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lucabartoletti\"><img src=\"https://avatars.githubusercontent.com/u/838925?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luca Bartoletti</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sujata23\"><img src=\"https://avatars.githubusercontent.com/u/1849089?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sujata Chakraborty</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.viber.com\"><img src=\"https://avatars.githubusercontent.com/u/5096762?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Pavel Trafimuk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://alexsilva.dev/\"><img src=\"https://avatars.githubusercontent.com/u/633535?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alejandro Silva Fern√°ndez</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.jakeadams.co\"><img src=\"https://avatars.githubusercontent.com/u/3605966?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jake Adams</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wattson12\"><img src=\"https://avatars.githubusercontent.com/u/1217873?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Watts</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://erkekin.com\"><img src=\"https://avatars.githubusercontent.com/u/701481?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Erk Ekin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/morozkin\"><img src=\"https://avatars.githubusercontent.com/u/16591888?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Denis Morozov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/orbitekk\"><img src=\"https://avatars.githubusercontent.com/u/4222449?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>orbitekk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.naver.com/wogus3602\"><img src=\"https://avatars.githubusercontent.com/u/46857148?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Park Jae Hyun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/regularberry\"><img src=\"https://avatars.githubusercontent.com/u/565192?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sean Berry</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://hisaac.net\"><img src=\"https://avatars.githubusercontent.com/u/923876?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Isaac Halvorson</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mohitsaxenaknoldus\"><img src=\"https://avatars.githubusercontent.com/u/76725454?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mohit Saxena</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikchmie\"><img src=\"https://avatars.githubusercontent.com/u/15248837?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Miko≈Çaj Chmielewski</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/takinwande\"><img src=\"https://avatars.githubusercontent.com/u/4744429?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Tope Akinwande</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.theinkedengineer.com\"><img src=\"https://avatars.githubusercontent.com/u/13349066?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TheInkedEngineer</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://alexanderweiss.dev\"><img src=\"https://avatars.githubusercontent.com/u/12934015?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander Wei√ü</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kyungpyoda\"><img src=\"https://avatars.githubusercontent.com/u/44656036?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kyungpyoda</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.villewitt.net\"><img src=\"https://avatars.githubusercontent.com/u/522544?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ville Witt</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/paulsamuels\"><img src=\"https://avatars.githubusercontent.com/u/527091?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>paul.s</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aniltaskiran\"><img src=\"https://avatars.githubusercontent.com/u/16738729?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>aniltaskiran</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/unxavi\"><img src=\"https://avatars.githubusercontent.com/u/3817679?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Javier Vieira</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/a-sarris\"><img src=\"https://avatars.githubusercontent.com/u/78614622?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Aris Sarris</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://xxw9999.notion.site/xxw9999/iOS-8585a34b2886419586960c5c02b9d845\"><img src=\"https://avatars.githubusercontent.com/u/67373938?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kimxwan0319</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://florian.codes\"><img src=\"https://avatars.githubusercontent.com/u/7734806?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Florian Fittschen</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jesus-mg-ios\"><img src=\"https://avatars.githubusercontent.com/u/85997060?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jesus (iOS)</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nicholaskim94\"><img src=\"https://avatars.githubusercontent.com/u/7912759?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nicholas Kim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Smponias\"><img src=\"https://avatars.githubusercontent.com/u/14213855?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexandros Smponias</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mangofever\"><img src=\"https://avatars.githubusercontent.com/u/724343?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Go</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AlbGarciam\"><img src=\"https://avatars.githubusercontent.com/u/45308839?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alberto Garcia</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/andreascuderi/\"><img src=\"https://avatars.githubusercontent.com/u/8319309?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrea Scuderi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dogoautilio.wordpress.com/\"><img src=\"https://avatars.githubusercontent.com/u/1487375?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Diogo Autilio</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shahzadmajeed\"><img src=\"https://avatars.githubusercontent.com/u/1209459?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shahzad Majeed</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danrevah\"><img src=\"https://avatars.githubusercontent.com/u/7808742?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nivanchikov\"><img src=\"https://avatars.githubusercontent.com/u/1830010?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nikita Ivanchikov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/xoxo-anastasi-xoxo\"><img src=\"https://avatars.githubusercontent.com/u/28875920?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Anastasia Kazantseva</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/MonocularVision\"><img src=\"https://avatars.githubusercontent.com/u/429790?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Michael McGuire</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.michaelfcollins3.me\"><img src=\"https://avatars.githubusercontent.com/u/104274?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Michael Collins</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/devyhan\"><img src=\"https://avatars.githubusercontent.com/u/45344633?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>YoHan Cho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/euriasb\"><img src=\"https://avatars.githubusercontent.com/u/3721257?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>euriasb</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MontakOleg\"><img src=\"https://avatars.githubusercontent.com/u/1800899?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>MontakOleg</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/oozoofrog\"><img src=\"https://avatars.githubusercontent.com/u/3011832?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>oozoofrog</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MartinStrambach\"><img src=\"https://avatars.githubusercontent.com/u/11178869?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Martin Strambach</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sh-a-n\"><img src=\"https://avatars.githubusercontent.com/u/2219548?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>sh-a-n</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://linkedin.com/in/batuhansaka\"><img src=\"https://avatars.githubusercontent.com/u/9626765?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Batuhan Saka</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jcsoohwancho.github.io\"><img src=\"https://avatars.githubusercontent.com/u/51935215?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>SooHwanCho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.bouncingball.mobi\"><img src=\"https://avatars.githubusercontent.com/u/798117?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gary Riches</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mustiikhalil.github.io/mustiikhalil/\"><img src=\"https://avatars.githubusercontent.com/u/26250654?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mustiikhalil</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/serejahh\"><img src=\"https://avatars.githubusercontent.com/u/2575555?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Serhii Butenko</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/petrukha-ivan\"><img src=\"https://avatars.githubusercontent.com/u/93926277?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Petrukha Ivan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lo1tuma\"><img src=\"https://avatars.githubusercontent.com/u/169170?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mathias Schreck</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Buju77\"><img src=\"https://avatars.githubusercontent.com/u/266349?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yen-Chia Lin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://coolmathgames.tech\"><img src=\"https://avatars.githubusercontent.com/u/6877780?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mary </b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/woohyunjin06\"><img src=\"https://avatars.githubusercontent.com/u/30452977?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hyunjin</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kevin58332\"><img src=\"https://avatars.githubusercontent.com/u/47673410?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kevin Aguilar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://andrewroan.com\"><img src=\"https://avatars.githubusercontent.com/u/9873566?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrew Roan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/ibrahim-oktay-518b4939/\"><img src=\"https://avatars.githubusercontent.com/u/36792481?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ibrahim oktay</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/navartis\"><img src=\"https://avatars.githubusercontent.com/u/7813723?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmitriy Kulakov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/woin2ee\"><img src=\"https://avatars.githubusercontent.com/u/81426024?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jaewon-Yun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tatagrigory\"><img src=\"https://avatars.githubusercontent.com/u/5187973?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tatagrigory</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://linkedin.com/in/denilchungath\"><img src=\"https://avatars.githubusercontent.com/u/95201442?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Denil Chungath</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/victor-sarda/\"><img src=\"https://avatars.githubusercontent.com/u/6460866?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Victor Sarda</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tzxdtc\"><img src=\"https://avatars.githubusercontent.com/u/19767846?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tzxdtc10</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ThiemeFM\"><img src=\"https://avatars.githubusercontent.com/u/143395823?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Thieme</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Lilfaen\"><img src=\"https://avatars.githubusercontent.com/u/39119695?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Clemens Beck</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://macpaw.com/\"><img src=\"https://avatars.githubusercontent.com/u/119268?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Paul Taykalo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/in4lio\"><img src=\"https://avatars.githubusercontent.com/u/976061?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vitaly Kravtsov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dc.wtf\"><img src=\"https://avatars.githubusercontent.com/u/643865?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>dc</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/baekteun\"><img src=\"https://avatars.githubusercontent.com/u/74440939?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>baegteun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://vcoutasso.com\"><img src=\"https://avatars.githubusercontent.com/u/44986513?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vin√≠cius Couto Tasso</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://blog.jihoon.me\"><img src=\"https://avatars.githubusercontent.com/u/68891494?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ÏïàÏßÄÌõà</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dxmvsh\"><img src=\"https://avatars.githubusercontent.com/u/44325936?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dimash</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danibachar\"><img src=\"https://avatars.githubusercontent.com/u/6380777?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>danibachar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dp221125\"><img src=\"https://avatars.githubusercontent.com/u/10572119?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ÌïúÏÑùÌò∏(MilKyo)</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@haifengkaohaifengkao&usg=AOvVaw2_xG-ZLdBawBIyS7m-99RQ\"><img src=\"https://avatars.githubusercontent.com/u/4080524?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hai Feng Kao</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anlaital-oura\"><img src=\"https://avatars.githubusercontent.com/u/133648611?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Antti Laitala</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PushedCrayon\"><img src=\"https://avatars.githubusercontent.com/u/37077444?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>PushedCrayon</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://stefanomondino.com\"><img src=\"https://avatars.githubusercontent.com/u/1691903?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Stefano Mondino</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/leszko11\"><img src=\"https://avatars.githubusercontent.com/u/23533452?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>≈Åukasz Lech</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/costapombo\"><img src=\"https://avatars.githubusercontent.com/u/31352351?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>costapombo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/isavynskyi\"><img src=\"https://avatars.githubusercontent.com/u/18377497?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ihor Savynskyi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kapitoshka438\"><img src=\"https://avatars.githubusercontent.com/u/3232401?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Eduard Miniakhmetov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alexfilimon\"><img src=\"https://avatars.githubusercontent.com/u/19904867?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander Filimonov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rofle100lvl\"><img src=\"https://avatars.githubusercontent.com/u/45801227?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gorbenko Roman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/lucas-paim/\"><img src=\"https://avatars.githubusercontent.com/u/7849484?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lucas Mrowskovsky Paim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://actuallytaylor.com\"><img src=\"https://avatars.githubusercontent.com/u/32944568?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Taylor Lineman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nandodelauni\"><img src=\"https://avatars.githubusercontent.com/u/1938501?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Miguel Ferrando</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/barredewe\"><img src=\"https://avatars.githubusercontent.com/u/19188911?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>BarredEwe</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chris-livefront\"><img src=\"https://avatars.githubusercontent.com/u/126101032?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Chris Sessions</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ajkolean\"><img src=\"https://avatars.githubusercontent.com/u/5394701?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andy Kolean</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Binlogo\"><img src=\"https://avatars.githubusercontent.com/u/7845507?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Binlogo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DevilDimon\"><img src=\"https://avatars.githubusercontent.com/u/10220441?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmitry Serov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://darrarski.pl\"><img src=\"https://avatars.githubusercontent.com/u/1384684?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dariusz Rybicki</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dansinclair25\"><img src=\"https://avatars.githubusercontent.com/u/2573447?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dan Sinclair</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.kaioelfke.de\"><img src=\"https://avatars.githubusercontent.com/u/1190948?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kai Oelfke</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://stackoverflow.com/users/468724/inder-kumar-rathore\"><img src=\"https://avatars.githubusercontent.com/u/352443?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Inder</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kyounh12\"><img src=\"https://avatars.githubusercontent.com/u/25301615?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kyounh12</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alvar-bolt\"><img src=\"https://avatars.githubusercontent.com/u/72379847?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alvar Hansen</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/barakwei\"><img src=\"https://avatars.githubusercontent.com/u/5232161?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Barak Weiss</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hiltonc\"><img src=\"https://avatars.githubusercontent.com/u/470753?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hilton Campbell</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rgnns\"><img src=\"https://avatars.githubusercontent.com/u/811827?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gabriel Li√©vano</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vijaytholpadi\"><img src=\"https://avatars.githubusercontent.com/u/1171868?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vijay Tholpadi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://withiosdeveloper.blogspot.com/\"><img src=\"https://avatars.githubusercontent.com/u/27220138?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Minhoi Goo</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sphanley\"><img src=\"https://avatars.githubusercontent.com/u/1323769?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Hanley</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ahmdyasser\"><img src=\"https://avatars.githubusercontent.com/u/42544598?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ahmdyasser</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/minhaaan\"><img src=\"https://avatars.githubusercontent.com/u/87178301?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>minhaaan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TamarMilchtaich\"><img src=\"https://avatars.githubusercontent.com/u/49520876?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Tamar Milchtaich Lavi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rock88\"><img src=\"https://avatars.githubusercontent.com/u/323908?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrey K</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://2stable.com\"><img src=\"https://avatars.githubusercontent.com/u/69604865?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alex Vera</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.annalisemariottini.com\"><img src=\"https://avatars.githubusercontent.com/u/14299642?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Annalise Mariottini</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gustn3965\"><img src=\"https://avatars.githubusercontent.com/u/48749182?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>HyunSu Park</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vldalx\"><img src=\"https://avatars.githubusercontent.com/u/13873200?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vladimir</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://rhysmorgan.co\"><img src=\"https://avatars.githubusercontent.com/u/11096937?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Rhys Morgan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pierrerodgers\"><img src=\"https://avatars.githubusercontent.com/u/48193278?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>pierrerodgers</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/honghoker\"><img src=\"https://avatars.githubusercontent.com/u/50417461?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>eunpyo hong</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@dbstj169\"><img src=\"https://avatars.githubusercontent.com/u/65678579?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yunseo Kang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ilia3546\"><img src=\"https://avatars.githubusercontent.com/u/4445510?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ilya Kharlamov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/brianvar\"><img src=\"https://avatars.githubusercontent.com/u/115399684?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>brianvar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/HossamYoussof\"><img src=\"https://avatars.githubusercontent.com/u/6381926?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hossam Youssof</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/devMinseok\"><img src=\"https://avatars.githubusercontent.com/u/51021614?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Minseok Kang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alpanyukov\"><img src=\"https://avatars.githubusercontent.com/u/36258478?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sanghyeok-kim\"><img src=\"https://avatars.githubusercontent.com/u/57667738?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Loyle</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vvisionnn\"><img src=\"https://avatars.githubusercontent.com/u/24761186?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ydna</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://brucemcrooster.dev\"><img src=\"https://avatars.githubusercontent.com/u/53529192?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Evan</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.snipnotes.de\"><img src=\"https://avatars.githubusercontent.com/u/5102728?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Felix Lisczyk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lukaswuerzburger\"><img src=\"https://avatars.githubusercontent.com/u/10812458?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lukas W√ºrzburger</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/GetToSet\"><img src=\"https://avatars.githubusercontent.com/u/8158163?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ethan Wong</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tdkn.dev\"><img src=\"https://avatars.githubusercontent.com/u/1296540?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shun Tedokon</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://connorricks.com\"><img src=\"https://avatars.githubusercontent.com/u/13373737?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Connor Ricks</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://franciscodiaz.cl\"><img src=\"https://avatars.githubusercontent.com/u/530662?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Francisco Diaz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ethan-IS\"><img src=\"https://avatars.githubusercontent.com/u/140235921?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ethan Parker</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lukevanin\"><img src=\"https://avatars.githubusercontent.com/u/550579?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luke Van In</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mustafataibah.vercel.app/\"><img src=\"https://avatars.githubusercontent.com/u/83141712?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Taibah</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vkondrashkov\"><img src=\"https://avatars.githubusercontent.com/u/16046780?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vladislav Kondrashkov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chrisjrex\"><img src=\"https://avatars.githubusercontent.com/u/4457170?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Christopher Rex</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bahattinkoc\"><img src=\"https://avatars.githubusercontent.com/u/61124759?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>baaddin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mattjung\"><img src=\"https://avatars.githubusercontent.com/u/19891158?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Matt Jung</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://imaginativeworld.org\"><img src=\"https://avatars.githubusercontent.com/u/1952630?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Md. Mahmudul Hasan Shohag</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ma.tyas.cz\"><img src=\"https://avatars.githubusercontent.com/u/6033733?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Matty Cross</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/YIshihara11201\"><img src=\"https://avatars.githubusercontent.com/u/98417271?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>YIshihara11201</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PhilippeWeidmann\"><img src=\"https://avatars.githubusercontent.com/u/5843044?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Philippe Weidmann</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Zentaur0\"><img src=\"https://avatars.githubusercontent.com/u/75909658?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Anton SVTSV</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://johannes.plunien.com\"><img src=\"https://avatars.githubusercontent.com/u/31597?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Johannes Plunien</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://emirhankarahan.com\"><img src=\"https://avatars.githubusercontent.com/u/48404459?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Emirhan KARAHAN</b></sub></a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n",
      "stars_today": 6
    },
    {
      "id": 15999638,
      "name": "criu",
      "full_name": "checkpoint-restore/criu",
      "description": "Checkpoint/Restore tool",
      "html_url": "https://github.com/checkpoint-restore/criu",
      "stars": 3646,
      "forks": 696,
      "language": "C",
      "topics": [
        "blcr",
        "checkpoint",
        "container",
        "containers",
        "criu",
        "dmtcp",
        "highly-available",
        "linux",
        "memory-tracking",
        "migration",
        "parasite",
        "post-copy",
        "restore",
        "snapshot",
        "suspend",
        "userfaultfd",
        "zero-downtime"
      ],
      "created_at": "2014-01-17T12:53:25Z",
      "updated_at": "2026-01-22T21:47:23Z",
      "pushed_at": "2026-01-21T00:25:44Z",
      "open_issues": 267,
      "owner": {
        "login": "checkpoint-restore",
        "avatar_url": "https://avatars.githubusercontent.com/u/32352560?v=4"
      },
      "readme": "[![X86_64 GCC Test](https://github.com/checkpoint-restore/criu/workflows/X86_64%20GCC%20Test/badge.svg)](\n    https://github.com/checkpoint-restore/criu/actions/workflows/x86-64-gcc-test.yml)\n[![Docker Test](https://github.com/checkpoint-restore/criu/actions/workflows/docker-test.yml/badge.svg)](\n    https://github.com/checkpoint-restore/criu/actions/workflows/docker-test.yml)\n[![Podman Test](https://github.com/checkpoint-restore/criu/actions/workflows/podman-test.yml/badge.svg)](\n    https://github.com/checkpoint-restore/criu/actions/workflows/podman-test.yml)\n[![CircleCI](https://circleci.com/gh/checkpoint-restore/criu.svg?style=svg)](\n    https://circleci.com/gh/checkpoint-restore/criu)\n\n<p align=\"center\"><img src=\"Documentation/logo.svg\" width=\"256px\"/></p>\n\n## CRIU -- A project to implement checkpoint/restore functionality for Linux\n\nCRIU (stands for Checkpoint and Restore in Userspace) is a utility to checkpoint/restore Linux tasks.\n\nUsing this tool, you can freeze a running application (or part of it) and checkpoint\nit to a hard drive as a collection of files. You can then use the files to restore and run the\napplication from the point it was frozen at. The distinctive feature of the CRIU\nproject is that it is mainly implemented in user space. There are some more projects\ndoing C/R for Linux, and so far CRIU [appears to be](https://criu.org/Comparison_to_other_CR_projects)\nthe most feature-rich and up-to-date with the kernel.\n\nCRIU project is (almost) the never-ending story, because we have to always keep up with the\nLinux kernel supporting checkpoint and restore for all the features it provides. Thus we're\nlooking for contributors of all kinds -- feedback, bug reports, testing, coding, writing, etc.\nPlease refer to [CONTRIBUTING.md](CONTRIBUTING.md) if you would like to get involved.\n\nThe project [started](https://criu.org/History) as the way to do live migration for OpenVZ\nLinux containers, but later grew to more sophisticated and flexible tool. It is currently\nused by (integrated into) OpenVZ, LXC/LXD, Docker, and other software, project gets tremendous\nhelp from the community, and its packages are included into many Linux distributions.\n\nThe project home is at http://criu.org. This wiki contains all the knowledge base for CRIU we have.\nPages worth starting with are:\n- [Installation instructions](http://criu.org/Installation)\n- [A simple example of usage](http://criu.org/Simple_loop)\n- [Examples of more advanced usage](https://criu.org/Category:HOWTO)\n- Troubleshooting can be hard, some help can be found [here](https://criu.org/When_C/R_fails), [here](https://criu.org/What_cannot_be_checkpointed) and [here](https://criu.org/index.php?title=FAQ)\n\n### Checkpoint and restore of simple loop process\n<p align=\"center\"><a href=\"https://asciinema.org/a/232445\"><img src=\"https://asciinema.org/a/232445.png\" width=\"572px\" height=\"412px\"/></a></p>\n\n## Advanced features\n\nAs main usage for CRIU is live migration, there's a library for it called P.Haul. Also the\nproject exposes two cool core features as standalone libraries. These are libcompel for parasite code\ninjection and libsoccr for TCP connections checkpoint-restore.\n\n### Live migration\n\nTrue [live migration](https://criu.org/Live_migration) using CRIU is possible, but doing\nall the steps by hands might be complicated. The [phaul sub-project](https://criu.org/P.Haul)\nprovides a Go library that encapsulates most of the complexity. This library and the Go bindings\nfor CRIU are stored in the [go-criu](https://github.com/checkpoint-restore/go-criu) repository.\n\n\n### Parasite code injection\n\nIn order to get state of the running process CRIU needs to make this process execute\nsome code, that would fetch the required information. To make this happen without\nkilling the application itself, CRIU uses the [parasite code injection](https://criu.org/Parasite_code)\ntechnique, which is also available as a standalone library called [libcompel](https://criu.org/Compel).\n\n### TCP sockets checkpoint-restore\n\nOne of the CRIU features is the ability to save and restore state of a TCP socket\nwithout breaking the connection. This functionality is considered to be useful by\nitself, and we have it available as the [libsoccr library](https://criu.org/Libsoccr).\n\n## Licence\n\nThe project is licensed under GPLv2 (though files sitting in the lib/ directory are LGPLv2.1).\n\nAll files in the images/ directory are licensed under the Expat license (so-called MIT).\nSee the images/LICENSE file.\n",
      "stars_today": 6
    },
    {
      "id": 457435290,
      "name": "go-whatsapp-web-multidevice",
      "full_name": "aldinokemal/go-whatsapp-web-multidevice",
      "description": "GOWA - WhatsApp REST API with support for UI, Multi Account, Webhooks, and MCP. Built with Golang for efficient memory use. ",
      "html_url": "https://github.com/aldinokemal/go-whatsapp-web-multidevice",
      "stars": 3390,
      "forks": 793,
      "language": "Go",
      "topics": [
        "bot",
        "go",
        "golang",
        "golang-whatsapp",
        "golang-whatsapp-api",
        "rest",
        "rest-api",
        "whatsapp",
        "whatsapp-api",
        "whatsapp-api-go",
        "whatsapp-multi-device",
        "whatsapp-web-multi-device"
      ],
      "created_at": "2022-02-09T16:19:30Z",
      "updated_at": "2026-01-23T00:52:57Z",
      "pushed_at": "2026-01-18T06:18:31Z",
      "open_issues": 20,
      "owner": {
        "login": "aldinokemal",
        "avatar_url": "https://avatars.githubusercontent.com/u/14232125?v=4"
      },
      "readme": "<!-- markdownlint-disable MD041 -->\n<!-- markdownlint-disable-next-line MD033 -->\n<div align=\"center\">\n  <!-- markdownlint-disable-next-line MD033 -->\n  <img src=\"src/views/assets/gowa.svg\" alt=\"GoWA Logo\" width=\"200\" height=\"200\">\n\n## Golang WhatsApp - Built with Go for efficient memory use\n\n</div>\n\n[![Patreon](https://img.shields.io/badge/Support%20on-Patreon-orange.svg)](https://www.patreon.com/c/aldinokemal)\n**If you're using this tools to generate income, consider supporting its development by becoming a Patreon member!**\nYour support helps ensure the library stays maintained and receives regular updates!\n___\n\n![release version](https://img.shields.io/github/v/release/aldinokemal/go-whatsapp-web-multidevice)\n![Build Image](https://github.com/aldinokemal/go-whatsapp-web-multidevice/actions/workflows/build-docker-image.yaml/badge.svg)\n![Binary Release](https://github.com/aldinokemal/go-whatsapp-web-multidevice/actions/workflows/release.yml/badge.svg)\n\n## Support for `ARM` & `AMD` Architecture along with `MCP` Support\n\nDownload:\n\n- [Release](https://github.com/aldinokemal/go-whatsapp-web-multidevice/releases/latest)\n- [Docker Hub](https://hub.docker.com/r/aldinokemal2104/go-whatsapp-web-multidevice/tags)\n- [GitHub Container Registry](https://github.com/aldinokemal/go-whatsapp-web-multidevice/pkgs/container/go-whatsapp-web-multidevice)\n\n## Support n8n package (n8n.io)\n\n- [n8n package](https://www.npmjs.com/package/@aldinokemal2104/n8n-nodes-gowa)\n- Go to Settings -> Community Nodes -> Input `@aldinokemal2104/n8n-nodes-gowa` -> Install\n\n## Breaking Changes\n\n- `v6`\n  - For REST mode, you need to run `<binary> rest` instead of `<binary>`\n    - for example: `./whatsapp rest` instead of ~~./whatsapp~~\n  - For MCP mode, you need to run `<binary> mcp`\n    - for example: `./whatsapp mcp`\n- `v7`\n  - Starting version 7.x we are using goreleaser to build the binary, so you can download the binary\n      from [release](https://github.com/aldinokemal/go-whatsapp-web-multidevice/releases/latest)\n- `v8`\n  - **Multi-device support**: You can now connect and manage multiple WhatsApp accounts simultaneously in a single\n      server instance\n  - **New Device Management API**: New endpoints under `/devices` for managing multiple devices\n  - **Device scoping required**: All device-scoped REST API calls now require either:\n    - `X-Device-Id` header, or\n    - `device_id` query parameter\n    - If only one device is registered, it will be used as the default\n  - **WebSocket device scoping**: Connect to `/ws?device_id=<id>` to scope WebSocket to a specific device\n  - **Webhook payload changes**: All webhook payloads now include a top-level `device_id` field identifying which\n      device received the event:\n\n        ```json\n        {\n          \"event\": \"message\",\n          \"device_id\": \"628123456789@s.whatsapp.net\",\n          \"payload\": { ... }\n        }\n        ```\n\n## Feature\n\n- Send WhatsApp message via http API, [docs/openapi.yml](./docs/openapi.yaml) for more details\n- **MCP (Model Context Protocol) Server Support** - Integrate with AI agents and tools using standardized protocol\n- Mention someone\n  - `@phoneNumber`\n  - example: `Hello @628974812XXXX, @628974812XXXX`\n- **Ghost Mentions (Mention All)** - Mention group participants without showing `@phone` in message text\n  - Pass phone numbers in `mentions` field to mention users without visible `@` in message\n  - Use special keyword `@everyone` to automatically mention ALL group participants\n  - UI checkbox available in Send Message modal for groups\n- Post Whatsapp Status\n- **Send Stickers** - Automatically converts images to WebP sticker format\n  - Supports JPG, JPEG, PNG, WebP, and GIF formats\n  - Automatic resizing to 512x512 pixels\n  - Preserves transparency for PNG images\n  - **Animated WebP stickers** are supported but must meet WhatsApp requirements:\n    - Must be exactly **512x512 pixels**\n    - Must be under **500KB** file size\n    - Maximum **10 seconds** duration\n    - If your animated sticker doesn't meet these requirements, please resize it before uploading using tools like [ezgif.com](https://ezgif.com/resize)\n- Compress image before send\n- Compress video before send\n- Change OS name become your app (it's the device name when connect via mobile)\n  - `--os=Chrome` or `--os=MyApplication`\n- Basic Auth (able to add multi credentials)\n  - `--basic-auth=kemal:secret,toni:password,userName:secretPassword`, or you can simplify\n  - `-b=kemal:secret,toni:password,userName:secretPassword`\n- Subpath deployment support\n  - `--base-path=\"/gowa\"` (allows deployment under a specific path like `/gowa/sub/path`)\n- Customizable port and debug mode\n  - `--port 8000`\n  - `--debug true`\n- Auto reply message\n  - `--autoreply=\"Don't reply this message\"`\n- Auto mark read incoming messages\n  - `--auto-mark-read=true` (automatically marks incoming messages as read)\n- Auto download media from incoming messages\n  - `--auto-download-media=false` (disable automatic media downloads, default: `true`)\n- Webhook for received message\n  - `--webhook=\"http://yourwebhook.site/handler\"`, or you can simplify\n  - `-w=\"http://yourwebhook.site/handler\"`\n  - for more detail, see [Webhook Payload Documentation](./docs/webhook-payload.md)\n- Webhook Secret\n  Our webhook will be sent to you with an HMAC header and a sha256 default key `secret`.\n\n  You may modify this by using the option below:\n  - `--webhook-secret=\"secret\"`\n- **Webhook Payload Documentation**\n  For detailed webhook payload schemas, security implementation, and integration examples,\n  see [Webhook Payload Documentation](./docs/webhook-payload.md)\n- **Webhook Event Filtering**\n  You can filter which events are forwarded to your webhook using:\n  - `--webhook-events=\"message,message.ack\"` (comma-separated list)\n  - Or environment variable: `WHATSAPP_WEBHOOK_EVENTS=message,message.ack`\n\n  **Available Webhook Events:**\n\n  | Event                | Description                                   |\n  |----------------------|-----------------------------------------------|\n  | `message`            | Text, media, contact, location messages       |\n  | `message.reaction`   | Emoji reactions to messages                   |\n  | `message.revoked`    | Deleted/revoked messages                      |\n  | `message.edited`     | Edited messages                               |\n  | `message.ack`        | Delivery and read receipts                    |\n  | `message.deleted`    | Messages deleted for the user                 |\n  | `group.participants` | Group member join/leave/promote/demote events |\n\n  If not configured (empty), all events will be forwarded.\n- **Webhook TLS Configuration**\n\n  If you encounter TLS certificate verification errors when using webhooks (e.g., with Cloudflare tunnels or self-signed\n  certificates):\n\n  ```\n  tls: failed to verify certificate: x509: certificate signed by unknown authority\n  ```\n\n  You can disable TLS certificate verification using:\n  - `--webhook-insecure-skip-verify=true`\n  - Or environment variable: `WHATSAPP_WEBHOOK_INSECURE_SKIP_VERIFY=true`\n\n  **Security Warning**: This option disables TLS certificate verification and should only be used in:\n  - Development/testing environments\n  - Cloudflare tunnels (which provide their own security layer)\n  - Internal networks with self-signed certificates\n\n  **For production environments**, it's strongly recommended to use proper SSL certificates (e.g., Let's Encrypt)\n  instead of disabling verification.\n\n## Configuration\n\nYou can configure the application using either command-line flags (shown above) or environment variables. Configuration\ncan be set in three ways (in order of priority):\n\n1. Command-line flags (highest priority)\n2. Environment variables\n3. `.env` file (lowest priority)\n\n### Environment Variables\n\nYou can configure the application using environment variables. Configuration can be set in three ways (in order of\npriority):\n\n1. Command-line flags (highest priority)\n2. Environment variables\n3. `.env` file (lowest priority)\n\nTo use environment variables:\n\n1. Copy `.env.example` to `.env` in your project root (`cp src/.env.example src/.env`)\n2. Modify the values in `.env` according to your needs\n3. Or set the same variables as system environment variables\n\n#### Available Environment Variables\n\n| Variable                                | Description                                                   | Default                                      | Example                                       |\n|-----------------------------------------|---------------------------------------------------------------|----------------------------------------------|-----------------------------------------------|\n| `APP_PORT`                              | Application port                                              | `3000`                                       | `APP_PORT=8080`                               |\n| `APP_HOST`                              | Host address to bind the server                               | `0.0.0.0`                                    | `APP_HOST=127.0.0.1`                          |\n| `APP_DEBUG`                             | Enable debug logging                                          | `false`                                      | `APP_DEBUG=true`                              |\n| `APP_OS`                                | OS name (device name in WhatsApp)                             | `Chrome`                                     | `APP_OS=MyApp`                                |\n| `APP_BASIC_AUTH`                        | Basic authentication credentials                              | -                                            | `APP_BASIC_AUTH=user1:pass1,user2:pass2`      |\n| `APP_BASE_PATH`                         | Base path for subpath deployment                              | -                                            | `APP_BASE_PATH=/gowa`                         |\n| `APP_TRUSTED_PROXIES`                   | Trusted proxy IP ranges for reverse proxy                     | -                                            | `APP_TRUSTED_PROXIES=0.0.0.0/0`               |\n| `DB_URI`                                | Database connection URI                                       | `file:storages/whatsapp.db?_foreign_keys=on` | `DB_URI=postgres://user:pass@host/db`         |\n| `WHATSAPP_AUTO_REPLY`                   | Auto-reply message                                            | -                                            | `WHATSAPP_AUTO_REPLY=\"Auto reply message\"`    |\n| `WHATSAPP_AUTO_MARK_READ`               | Auto-mark incoming messages as read                           | `false`                                      | `WHATSAPP_AUTO_MARK_READ=true`                |\n| `WHATSAPP_AUTO_DOWNLOAD_MEDIA`          | Auto-download media from incoming messages                    | `true`                                       | `WHATSAPP_AUTO_DOWNLOAD_MEDIA=false`          |\n| `WHATSAPP_WEBHOOK`                      | Webhook URL(s) for events (comma-separated)                   | -                                            | `WHATSAPP_WEBHOOK=https://webhook.site/xxx`   |\n| `WHATSAPP_WEBHOOK_SECRET`               | Webhook secret for validation                                 | `secret`                                     | `WHATSAPP_WEBHOOK_SECRET=super-secret-key`    |\n| `WHATSAPP_WEBHOOK_INSECURE_SKIP_VERIFY` | Skip TLS verification for webhooks (insecure)                 | `false`                                      | `WHATSAPP_WEBHOOK_INSECURE_SKIP_VERIFY=true`  |\n| `WHATSAPP_WEBHOOK_EVENTS`               | Whitelist of events to forward (comma-separated, empty = all) | -                                            | `WHATSAPP_WEBHOOK_EVENTS=message,message.ack` |\n| `WHATSAPP_ACCOUNT_VALIDATION`           | Enable account validation                                     | `true`                                       | `WHATSAPP_ACCOUNT_VALIDATION=false`           |\n\nNote: Command-line flags will override any values set in environment variables or `.env` file.\n\n- For more command `./whatsapp --help`\n\n## Requirements\n\n### System Requirements\n\n- **Go 1.24.0 or higher** (for building from source)\n- **FFmpeg** (for media processing)\n\n### Platform Support\n\n- Linux (x86_64, ARM64)\n- macOS (Intel, Apple Silicon)\n- Windows (x86_64) - WSL recommended\n\n### Dependencies (without docker)\n\n- Mac OS:\n  - `brew install ffmpeg webp`\n  - `export CGO_CFLAGS_ALLOW=\"-Xpreprocessor\"`\n- Linux:\n  - `sudo apt update`\n  - `sudo apt install ffmpeg webp`\n- Windows (not recommended, prefer using [WSL](https://docs.microsoft.com/en-us/windows/wsl/install)):\n  - Install ffmpeg: [download here](https://www.ffmpeg.org/download.html#build-windows)\n  - Install libwebp: [download here](https://developers.google.com/speed/webp/download) (extract and add `bin` folder to PATH)\n  - Add both to [environment variable](https://www.google.com/search?q=windows+add+to+environment+path)\n\n> **Note**: The `webp` package provides `cwebp` (encoder), `dwebp` (decoder), and `webpmux` (frame extractor) tools.\n> FFmpeg is required for media processing. The libwebp tools (`webpmux` + `dwebp`) are used for animated WebP sticker support.\n\n## How to use\n\n### Basic\n\n1. Clone this repo: `git clone https://github.com/aldinokemal/go-whatsapp-web-multidevice`\n2. Open the folder that was cloned via cmd/terminal.\n3. run `cd src`\n4. run `go run . rest` (for REST API mode)\n5. Open `http://localhost:3000`\n\n### Docker (you don't need to install in required)\n\n1. Clone this repo: `git clone https://github.com/aldinokemal/go-whatsapp-web-multidevice`\n2. Open the folder that was cloned via cmd/terminal.\n3. run `docker-compose up -d --build`\n4. open `http://localhost:3000`\n\n### Build your own binary\n\n1. Clone this repo `git clone https://github.com/aldinokemal/go-whatsapp-web-multidevice`\n2. Open the folder that was cloned via cmd/terminal.\n3. run `cd src`\n4. run\n    1. Linux & MacOS: `go build -o whatsapp`\n    2. Windows (CMD / PowerShell): `go build -o whatsapp.exe`\n5. run\n    1. Linux & MacOS: `./whatsapp rest` (for REST API mode)\n        1. run `./whatsapp --help` for more detail flags\n    2. Windows: `.\\whatsapp.exe rest` (for REST API mode)\n        1. run `.\\whatsapp.exe --help` for more detail flags\n6. open `http://localhost:3000` in browser\n\n### MCP Server (Model Context Protocol)\n\nThis application can also run as an MCP server, allowing AI agents and tools to interact with WhatsApp through a\nstandardized protocol.\n\n1. Clone this repo `git clone https://github.com/aldinokemal/go-whatsapp-web-multidevice`\n2. Open the folder that was cloned via cmd/terminal.\n3. run `cd src`\n4. run `go run . mcp` or build the binary and run `./whatsapp mcp`\n5. The MCP server will start on `http://localhost:8080` by default\n\n#### MCP Server Options\n\n- `--host localhost` - Set the host for MCP server (default: localhost)\n- `--port 8080` - Set the port for MCP server (default: 8080)\n\n#### Available MCP Tools\n\nThe WhatsApp MCP server provides comprehensive tools for AI agents to interact with WhatsApp through a standardized\nprotocol. Below is the complete list of available tools:\n\n##### **üì± Connection Management**\n\n- `whatsapp_connection_status` - Check whether the WhatsApp client is connected and logged in\n- `whatsapp_login_qr` - Initiate QR code based login flow with image output\n- `whatsapp_login_with_code` - Generate pairing code for multi-device login using phone number\n- `whatsapp_logout` - Sign out the current WhatsApp session\n- `whatsapp_reconnect` - Attempt to reconnect to WhatsApp using stored session\n\n##### **üí¨ Messaging & Communication**\n\n- `whatsapp_send_text` - Send text messages with reply and forwarding support\n- `whatsapp_send_contact` - Send contact cards with name and phone number\n- `whatsapp_send_link` - Send links with custom captions\n- `whatsapp_send_location` - Send location coordinates (latitude/longitude)\n- `whatsapp_send_image` - Send images with captions, compression, and view-once options\n- `whatsapp_send_sticker` - Send stickers with automatic WebP conversion (supports JPG/PNG/GIF)\n\n##### **üìã Chat & Contact Management**\n\n- `whatsapp_list_contacts` - Retrieve all contacts in your WhatsApp account\n- `whatsapp_list_chats` - Get recent chats with pagination and search filters\n- `whatsapp_get_chat_messages` - Fetch messages from specific chats with time/media filtering\n- `whatsapp_download_message_media` - Download images/videos from messages\n- `whatsapp_archive_chat` - Archive or unarchive a chat conversation\n\n##### **üë• Group Management**\n\n- `whatsapp_group_create` - Create new groups with optional initial participants\n- `whatsapp_group_join_via_link` - Join groups using invite links\n- `whatsapp_group_leave` - Leave groups by group ID\n- `whatsapp_group_participants` - List all participants in a group\n- `whatsapp_group_manage_participants` - Add, remove, promote, or demote group members\n- `whatsapp_group_invite_link` - Get or reset group invite links\n- `whatsapp_group_info` - Get detailed group information\n- `whatsapp_group_set_name` - Update group display name\n- `whatsapp_group_set_topic` - Update group description/topic\n- `whatsapp_group_set_locked` - Toggle admin-only group info editing\n- `whatsapp_group_set_announce` - Toggle announcement-only mode\n- `whatsapp_group_join_requests` - List pending join requests\n- `whatsapp_group_manage_join_requests` - Approve or reject join requests\n\n#### MCP Endpoints\n\n- SSE endpoint: `http://localhost:8080/sse`\n- Message endpoint: `http://localhost:8080/message`\n\n### MCP Configuration\n\nMake sure you have the MCP server running: `./whatsapp mcp`\n\nFor AI tools that support MCP with SSE (like Cursor), add this configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"whatsapp\": {\n      \"url\": \"http://localhost:8080/sse\"\n    }\n  }\n}\n```\n\n### Production Mode REST (docker)\n\nUsing Docker Hub:\n\n```bash\ndocker run --detach --publish=3000:3000 --name=whatsapp --restart=always --volume=$(docker volume create --name=whatsapp):/app/storages aldinokemal2104/go-whatsapp-web-multidevice rest --autoreply=\"Dont't reply this message please\"\n```\n\nUsing GitHub Container Registry:\n\n```bash\ndocker run --detach --publish=3000:3000 --name=whatsapp --restart=always --volume=$(docker volume create --name=whatsapp):/app/storages ghcr.io/aldinokemal/go-whatsapp-web-multidevice rest --autoreply=\"Dont't reply this message please\"\n```\n\n### Production Mode REST (docker compose)\n\ncreate `docker-compose.yml` file with the following configuration:\n\nUsing Docker Hub:\n\n```yml\nservices:\n  whatsapp:\n    image: aldinokemal2104/go-whatsapp-web-multidevice\n    container_name: whatsapp\n    restart: always\n    ports:\n      - \"3000:3000\"\n    volumes:\n      - whatsapp:/app/storages\n    command:\n      - rest\n      - --basic-auth=admin:admin\n      - --port=3000\n      - --debug=true\n      - --os=Chrome\n      - --account-validation=false\n\nvolumes:\n  whatsapp:\n```\n\nUsing GitHub Container Registry:\n\n```yml\nservices:\n  whatsapp:\n    image: ghcr.io/aldinokemal/go-whatsapp-web-multidevice\n    container_name: whatsapp\n    restart: always\n    ports:\n      - \"3000:3000\"\n    volumes:\n      - whatsapp:/app/storages\n    command:\n      - rest\n      - --basic-auth=admin:admin\n      - --port=3000\n      - --debug=true\n      - --os=Chrome\n      - --account-validation=false\n\nvolumes:\n  whatsapp:\n```\n\nor with env file (Docker Hub):\n\n```yml\nservices:\n  whatsapp:\n    image: aldinokemal2104/go-whatsapp-web-multidevice\n    container_name: whatsapp\n    restart: always\n    ports:\n      - \"3000:3000\"\n    volumes:\n      - whatsapp:/app/storages\n    environment:\n      - APP_BASIC_AUTH=admin:admin\n      - APP_PORT=3000\n      - APP_DEBUG=true\n      - APP_OS=Chrome\n      - APP_ACCOUNT_VALIDATION=false\n\nvolumes:\n  whatsapp:\n```\n\nor with env file (GitHub Container Registry):\n\n```yml\nservices:\n  whatsapp:\n    image: ghcr.io/aldinokemal/go-whatsapp-web-multidevice\n    container_name: whatsapp\n    restart: always\n    ports:\n      - \"3000:3000\"\n    volumes:\n      - whatsapp:/app/storages\n    environment:\n      - APP_BASIC_AUTH=admin:admin\n      - APP_PORT=3000\n      - APP_DEBUG=true\n      - APP_OS=Chrome\n      - APP_ACCOUNT_VALIDATION=false\n\nvolumes:\n  whatsapp:\n```\n\n### Production Mode (binary)\n\n- download binary from [release](https://github.com/aldinokemal/go-whatsapp-web-multidevice/releases)\n\nYou can fork or edit this source code !\n\n## Current API\n\n### MCP (Model Context Protocol) API\n\n- MCP server provides standardized tools for AI agents to interact with WhatsApp\n- Supports Server-Sent Events (SSE) transport\n- Available tools: `whatsapp_send_text`, `whatsapp_send_contact`, `whatsapp_send_link`, `whatsapp_send_location`\n- Compatible with MCP-enabled AI tools and agents\n\n### HTTP REST API\n\n- [API Specification Document](https://bump.sh/aldinokemal/doc/go-whatsapp-web-multidevice).\n- Check [docs/openapi.yml](./docs/openapi.yaml) for detailed API specifications.\n- Use [SwaggerEditor](https://editor.swagger.io) to visualize the API.\n- Generate HTTP clients using [openapi-generator](https://openapi-generator.tech/#try).\n\n| Feature  | Menu                                   | Method | URL                                 |\n|----------|----------------------------------------|--------|-------------------------------------|\n| ‚úÖ       | List Devices                           | GET    | /devices                            |\n| ‚úÖ       | Add Device                             | POST   | /devices                            |\n| ‚úÖ       | Get Device Info                        | GET    | /devices/:device_id                 |\n| ‚úÖ       | Remove Device                          | DELETE | /devices/:device_id                 |\n| ‚úÖ       | Login Device (QR)                      | GET    | /devices/:device_id/login           |\n| ‚úÖ       | Login Device (Code)                    | POST   | /devices/:device_id/login/code      |\n| ‚úÖ       | Logout Device                          | POST   | /devices/:device_id/logout          |\n| ‚úÖ       | Reconnect Device                       | POST   | /devices/:device_id/reconnect       |\n| ‚úÖ       | Get Device Status                      | GET    | /devices/:device_id/status          |\n| ‚úÖ       | Login with Scan QR                     | GET    | /app/login                          |\n| ‚úÖ       | Login With Pair Code                   | GET    | /app/login-with-code                |\n| ‚úÖ       | Logout                                 | GET    | /app/logout                         |\n| ‚úÖ       | Reconnect                              | GET    | /app/reconnect                      |\n| ‚úÖ       | Devices                                | GET    | /app/devices                        |\n| ‚úÖ       | Connection Status                      | GET    | /app/status                         |\n| ‚úÖ       | User Info                              | GET    | /user/info                          |\n| ‚úÖ       | User Avatar                            | GET    | /user/avatar                        |\n| ‚úÖ       | User Change Avatar                     | POST   | /user/avatar                        |\n| ‚úÖ       | User Change PushName                   | POST   | /user/pushname                      |\n| ‚úÖ       | User My Groups                         | GET    | /user/my/groups                     |\n| ‚úÖ       | User My Newsletter                     | GET    | /user/my/newsletters                |\n| ‚úÖ       | User My Privacy Setting                | GET    | /user/my/privacy                    |\n| ‚úÖ       | User My Contacts                       | GET    | /user/my/contacts                   |\n| ‚úÖ       | User Check                             | GET    | /user/check                         |\n| ‚úÖ       | User Business Profile                  | GET    | /user/business-profile              |\n| ‚úÖ       | Send Message                           | POST   | /send/message                       |\n| ‚úÖ       | Send Image                             | POST   | /send/image                         |\n| ‚úÖ       | Send Audio                             | POST   | /send/audio                         |\n| ‚úÖ       | Send File                              | POST   | /send/file                          |\n| ‚úÖ       | Send Video                             | POST   | /send/video                         |\n| ‚úÖ       | Send Sticker                           | POST   | /send/sticker                       |\n| ‚úÖ       | Send Contact                           | POST   | /send/contact                       |\n| ‚úÖ       | Send Link                              | POST   | /send/link                          |\n| ‚úÖ       | Send Location                          | POST   | /send/location                      |\n| ‚úÖ       | Send Poll / Vote                       | POST   | /send/poll                          |\n| ‚úÖ       | Send Presence                          | POST   | /send/presence                      |\n| ‚úÖ       | Send Chat Presence (Typing Indicator)  | POST   | /send/chat-presence                 |\n| ‚úÖ       | Revoke Message                         | POST   | /message/:message_id/revoke         |\n| ‚úÖ       | React Message                          | POST   | /message/:message_id/reaction       |\n| ‚úÖ       | Delete Message                         | POST   | /message/:message_id/delete         |\n| ‚úÖ       | Edit Message                           | POST   | /message/:message_id/update         |\n| ‚úÖ       | Read Message (DM)                      | POST   | /message/:message_id/read           |\n| ‚úÖ       | Star Message                           | POST   | /message/:message_id/star           |\n| ‚úÖ       | Unstar Message                         | POST   | /message/:message_id/unstar         |\n| ‚úÖ       | Download Message Media                 | GET    | /message/:message_id/download       |\n| ‚úÖ       | Join Group With Link                   | POST   | /group/join-with-link               |\n| ‚úÖ       | Group Info From Link                   | GET    | /group/info-from-link               |\n| ‚úÖ       | Group Info                             | GET    | /group/info                         |\n| ‚úÖ       | Leave Group                            | POST   | /group/leave                        |\n| ‚úÖ       | Create Group                           | POST   | /group                              |\n| ‚úÖ       | List Participants in Group             | GET    | /group/participants                 |\n| ‚úÖ       | Add Participants in Group              | POST   | /group/participants                 |\n| ‚úÖ       | Remove Participant in Group            | POST   | /group/participants/remove          |\n| ‚úÖ       | Promote Participant in Group           | POST   | /group/participants/promote         |\n| ‚úÖ       | Demote Participant in Group            | POST   | /group/participants/demote          |\n| ‚úÖ       | Export Group Participants (CSV)        | GET    | /group/participants/export          |\n| ‚úÖ       | List Requested Participants in Group   | GET    | /group/participant-requests         |\n| ‚úÖ       | Approve Requested Participant in Group | POST   | /group/participant-requests/approve |\n| ‚úÖ       | Reject Requested Participant in Group  | POST   | /group/participant-requests/reject  |\n| ‚úÖ       | Set Group Photo                        | POST   | /group/photo                        |\n| ‚úÖ       | Set Group Name                         | POST   | /group/name                         |\n| ‚úÖ       | Set Group Locked                       | POST   | /group/locked                       |\n| ‚úÖ       | Set Group Announce                     | POST   | /group/announce                     |\n| ‚úÖ       | Set Group Topic                        | POST   | /group/topic                        |\n| ‚úÖ       | Get Group Invite Link                  | GET    | /group/invite-link                  |\n| ‚úÖ       | Unfollow Newsletter                    | POST   | /newsletter/unfollow                |\n| ‚úÖ       | Get Chat List                          | GET    | /chats                              |\n| ‚úÖ       | Get Chat Messages                      | GET    | /chat/:chat_jid/messages            |\n| ‚úÖ       | Label Chat                             | POST   | /chat/:chat_jid/label               |\n| ‚úÖ       | Pin Chat                               | POST   | /chat/:chat_jid/pin                 |\n| ‚úÖ       | Archive Chat                           | POST   | /chat/:chat_jid/archive             |\n| ‚úÖ       | Set Disappearing Messages              | POST   | /chat/:chat_jid/disappearing        |\n\n```\n‚úÖ = Available\n‚ùå = Not Available Yet\n```\n\n## User Interface\n\n### MCP UI\n\n- Setup MCP (tested in cursor)\n  ![Setup MCP](https://i.ibb.co/vCg4zNWt/mcpsetup.png)\n- Test MCP\n  ![Test MCP](https://i.ibb.co/B2LX38DW/mcptest.png)\n- Successfully setup MCP\n  ![Success MCP](https://i.ibb.co/1fCx0Myc/mcpsuccess.png)\n\n### HTTP REST API UI\n\n| Description          | Image                                                         |\n|----------------------|---------------------------------------------------------------|\n| Homepage             | ![Homepage](./gallery/homepage.png?v=1)                       |\n| Login                | ![Login](./gallery/login.png)                                 |\n| Login With Code      | ![Login With Code](./gallery/login-with-code.png)             |\n| Send Message         | ![Send Message](./gallery/send-message.png)                   |\n| Send Image           | ![Send Image](./gallery/send-image.png)                       |\n| Send File            | ![Send File](./gallery/send-file.png)                         |\n| Send Video           | ![Send Video](./gallery/send-video.png)                       |\n| Send Sticker         | ![Send Sticker](./gallery/send-sticker.png)                   |\n| Send Contact         | ![Send Contact](./gallery/send-contact.png)                   |\n| Send Location        | ![Send Location](./gallery/send-location.png)                 |\n| Send Audio           | ![Send Audio](./gallery/send-audio.png)                       |\n| Send Poll            | ![Send Poll](./gallery/send-poll.png)                         |\n| Send Presence        | ![Send Presence](./gallery/send-presence.png)                 |\n| Send Link            | ![Send Link](./gallery/send-link.png)                         |\n| My Group             | ![My Group](./gallery/group-list.png)                         |\n| Group Info From Link | ![Group Info From Link](./gallery/group-info-from-link.png)   |\n| Create Group         | ![Create Group](./gallery/group-create.png)                   |\n| Join Group with Link | ![Join Group with Link](./gallery/group-join-link.png)        |\n| Manage Participant   | ![Manage Participant](./gallery/group-manage-participant.png) |\n| My Newsletter        | ![My Newsletter](./gallery/newsletter-list.png)               |\n| My Contacts          | ![My Contacts](./gallery/contact-list.png)                    |\n| Business Profile     | ![Business Profile](./gallery/business-profile.png)           |\n\n### Mac OS NOTE\n\n- Please do this if you have an error (invalid flag in pkg-config --cflags: -Xpreprocessor)\n  `export CGO_CFLAGS_ALLOW=\"-Xpreprocessor\"`\n\n## Important\n\n- This project is unofficial and not affiliated with WhatsApp.\n- Please use official WhatsApp API to avoid any issues.\n- We only able to run MCP or REST API, this is limitation from whatsmeow library. independent MCP will be available in\n  the future.\n",
      "stars_today": 6
    },
    {
      "id": 294501642,
      "name": "Holy-Unblocker",
      "full_name": "QuiteAFancyEmerald/Holy-Unblocker",
      "description": "Holy Unblocker LTS is a web proxy service that helps you access websites that may be blocked by your network, government or policy all within your browser with no download or setup. It does this securely and with additional privacy features. Browse Tor/Onion sites in any browser, hide browsing activity and bypass filters. (Star if you fork it!)",
      "html_url": "https://github.com/QuiteAFancyEmerald/Holy-Unblocker",
      "stars": 1181,
      "forks": 4456,
      "language": "JavaScript",
      "topics": [
        "adblocking",
        "anonymity",
        "browsersync",
        "bypass",
        "bypass-recaptchav3",
        "docker",
        "fastify",
        "https-proxy",
        "javascript",
        "nodejs",
        "onion-service",
        "privacy",
        "proxy",
        "socks5-proxy",
        "tor",
        "unblock",
        "unblocker",
        "vpn",
        "web-proxy",
        "webproxy"
      ],
      "created_at": "2020-09-10T19:18:23Z",
      "updated_at": "2026-01-23T01:56:26Z",
      "pushed_at": "2026-01-22T00:38:50Z",
      "open_issues": 10,
      "owner": {
        "login": "QuiteAFancyEmerald",
        "avatar_url": "https://avatars.githubusercontent.com/u/46467239?v=4"
      },
      "readme": "<img align=\"center\" src=\"https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/github_banner.png\"></img>\n\n<img align=\"left\" width=\"40px\" src=\"https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/logo_github.png\"></img>\n\n# Holy Unblocker LTS (v6.x.x)\n\n![GitHub Actions Status](https://github.com/QuiteAFancyEmerald/Holy-Unblocker/workflows/CI-Production/badge.svg)\n![GitHub Actions Status](https://github.com/QuiteAFancyEmerald/Holy-Unblocker/workflows/CI-Win/badge.svg)\n[![Docker Image Version](https://img.shields.io/docker/v/quiteafancyemerald/holy-unblocker.svg)](https://hub.docker.com/r/quiteafancyemerald/holy-unblocker)\n[![Docker Pulls](https://img.shields.io/docker/pulls/quiteafancyemerald/holy-unblocker.svg)](https://hub.docker.com/r/quiteafancyemerald/holy-unblocker)\n\nHoly Unblocker LTS is an experimental web proxy service that can bypass web filters or \"blockers\" regardless of whether the method of censorship is client-side or network-based. This includes the ability to bypass content blockers from governments, chrome extensions, localized client firewalls, and network-related filters. The project even allows the ability to browse Tor/Onion sites in any browser (even Chromium) all through a website!\n\n## You can support Holy Unblocker by starring the repository!\n\nThis project serves mostly as a proof of concept for the ideal clientless solution to bypassing censorship. A good use case of this project would be if you ever needed a clientless solution to use Tor or leave minimal traces of device activity. Simply host this project on any domain and have an alternative solution to a VPN without needing to download anything on said device. Being a secure web proxy service, it supports numerous sites while being updated frequently and concentrating on being easy to self-host. Holy Unblocker LTS works with a large number of sites, including YouTube, Discord, GeForce NOW and more!\nAlso has a good amount of locally hosted games featured on the site.\n\n### Over 30M+ users since 2020. Thank you so much for the support I could have never imagined how massive the web proxy community has become.\n\n#### Current Branch: Latest\n\n<details><summary>Branch Types</summary>\n\n- Latest (master; built for FOSS and SEO)\n- Beta (pending changes; changes that may break things)\n- Production (v4, v5, v6; stable version of Holy Unblocker LTS. Changes for self hosting in production settings; max filtering evasion and request handling)\n</details>\n\n#### Considering switching branches for self-hosting to a production branch!\n\nView the <a href=\"#deploy-holy-unblocker\">self-deployment options</a> if you wish to self host this project. Can't deploy using any of the free options? Check out Railway or look into cheap, paid VPS hosting solutions. If you don't wish to self-host join the discord for more official instance links that are restocked frequently.\n\n**Be sure to join Titanium Network's Discord for more official site links:** <a href=\"https://discord.gg/unblock\">https://discord.gg/unblock</a>\n\n<br>\n\n> [!CAUTION]\n> If you are going to self-host Holy Unblocker LTS please switch to the PRODUCTION branch for filter evasion features. The master branch is intended for development work and a highly readable source for developers. You can select a production branch (v6.x_production) via the branches dropdown.\n\n> [!TIP]\n> Holy Unblocker LTS is optimized for self-hosting to provide you with maximum privacy control! Fork this repository and consider starring. You can self-host using either free or paid deployment options, or set it up on a dedicated instance (VPS) for enhanced performance.\n\n| **Supported Sites**        | **Features**                                                                                                                          |\n| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |\n| Youtube                    | Built-in variety of open source web proxies with both a focus on speed and/or security                                                |\n| Reddit                     | Features Source Randomization and DOM Masquerading to circumvent major filters effectively along with randomizations to proxy globals |\n| Discord                    | Tab title + icon customization using the Settings Menu for improved browsing history stealth                                          |\n| Instagram                  | Adblocking support across all websites while surfing and low latency DNS on official servers                                          |\n| Reddit.com                 | SOCKS5 and Onion routing support with Tor within the Settings Menu. Use Tor/Onion sites in any browser!                               |\n| GeForce NOW                | Game library with moderately decent titles and open-source emulation projects                                                         |\n| Spotify                    | Bypass regional proxy blocks by swapping regions or enabling Tor                                                                      |\n| And essentially all sites! | Built for intensive production loads and ease of setup                                                                                |\n\n<img src=\"https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/preview/hu-v6.4.3-preview.png\"></img>\n<img src=\"https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/preview/hu-v6.3.0-preview-settings.png\"></img>\n\n## Deploy Holy Unblocker\n\n### Free Deployments\n\n[![Deploy to Koyeb](https://binbashbanana.github.io/deploy-buttons/buttons/remade/koyeb.svg)](https://app.koyeb.com/deploy?name=holy-unblocker&type=git&repository=QuiteAFancyEmerald%2FHoly-Unblocker&branch=v6.9.4_production&builder=buildpack&env%5B%5D=&ports=8080%3Bhttp%3B%2F)\n[![Deploy to Oracle Cloud](https://binbashbanana.github.io/deploy-buttons/buttons/remade/oraclecloud.svg)](https://cloud.oracle.com/resourcemanager/stacks/create?zipUrl=https://github.com/BinBashBanana/deploy-buttons/archive/refs/heads/main.zip)\n\n<details><summary>Alternative Free Sources</summary>\n\n[![Deploy to Cyclic](https://binbashbanana.github.io/deploy-buttons/buttons/remade/cyclic.svg)](https://app.cyclic.sh/api/app/deploy/shuttlenetwork/shuttle)\n[![Deploy to Render](https://render.com/images/deploy-to-render-button.svg)](https://render.com/deploy?repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n[![Deploy to Fly.io](https://img.shields.io/badge/Deploy%20to-Fly.io-blue?logo=fly.io)](https://fly.io/launch?repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n\n</details>\n\n### Production Paid/Free Options (Requires Payment Info)\n\n[![Deploy to Azure](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/azure.svg)](https://deploy.azure.com/?repository=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n[![Deploy to IBM Cloud](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/ibmcloud.svg)](https://cloud.ibm.com/devops/setup/deploy?repository=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n[![Deploy to Amplify Console](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/amplifyconsole.svg)](https://console.aws.amazon.com/amplify/home#/deploy?repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n[![Run on Google Cloud](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/googlecloud.svg)](https://deploy.cloud.run/?git_repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n\n#### What happened to Replit/Heroku Deployment?\n\nReplit is no longer free and Heroku has a set policy against web proxies. Try GitHub Codespaces or Gitpod instead for development on the cloud OR Koyeb for free hosting.\n\n### GitHub Codespaces\n\n<details><summary>Setup Instructions</summary>\n\n- Fork (and star!) this repository to your GitHub account\n- Head to the official <a href=\"https://github.com/codespaces\">Codespaces</a> website (ensure you have a GitHub account already made)\n- Select **New Codespaces** and look for _[USERNAME]/Holy-Unblocker_ on your account\n- Ensure the branch is set to `master` and the dev container configuration is set to **Holy Unblocker LTS**\n- Select **Create Codespace** and allow the container to setup\n- Type `npm run fresh-install` and `npm start` in the terminal\n- Click \"Make public\" on the application popup, then access the deployed website via the ports tab.\n\n</details>\n\n## Table of contents:\n\n- [Setup](#how-to-setup)\n  - [Terminal](#terminal)\n  - [Project Configuration](#configuration)\n    - [Server Configuration](#server-configuration-setup)\n    - [TOR Routing](#toronion-routing-setup)\n    - [Proxy](#proxy-configuration)\n    - [Client Navigation](#client-navigation-configuration)\n    - [Games Management](#games-management)\n  - [Structure](#structure)\n    - [Structure Information](#structure-information)\n    - [Static Files](#details-of-views)\n    - [Scripts](#scripts-located-in-viewsassetsjs)\n  - [Future Additions](#future-additions)\n  - [Beginner's Explanation](#vauge-explanation-for-beginners-with-external-proxies-and-hosting)\n    - [Hosting Providers](#list-of-some-good-hosting-options)\n    - [Domain Setup](#freenomdomain-steps)\n    - [Cloudflare Setup](#cloudflare-steps)\n    - [Workspace Configurations](#workspace-configurations)\n  - [Detailed FAQ](#detailed-faq)\n  - [More Information](#more-information)\n\n## How to Setup\n\n#### It is highly recommended you switch branches via your IDE to a production released branch. Often the master branch contains unstable or WIP changes.|\n\n#### Example: v6.x_production instead of master\n\n### Terminal\n\nEither use the button above to deploy to the deployment options above or type the commands below on a dedicated server\n\n**THIS PROJECT REQUIRES NGINX NOT CADDY.** \n\nPlease ensure you are using Node 20.x as well:\n\n```bash\ngit clone https://github.com/QuiteAFancyEmerald/Holy-Unblocker.git\n\ncd Holy-Unblocker\n\n# Edit config.js and set production to true if you want to use pm2 (Allows for easier VPS hosting)\nnpm run fresh-install\nnpm start\n\n# Or on subsequent uses...\nnpm restart\n\n# For killing any production processes made with pm2\nnpm run kill\n\n# For clearing respective Rammerhead cache\nnpm run clean\n\n# If you encounter any build errors...\nnpm run build\n\n# If you encounter any service errors...\nnpm run test\n```\n\nThis website is hosted locally with Scramjet, Ultraviolet (Wisp, Bare-Mux, EpoxyTransport, CurlTransport) and Rammerhead built-in.\n\n### For security reasons when hosting with a reverse proxy PLEASE use NGINX not Caddy. This is due to wisp-js using loopbacks.\n\n#### Detailed Setup (Ubuntu Example)\nYou will need Node.js 20.x and Git installed; below is an example for Debian/Ubuntu setup.\n<details>\n\nFor simplicity sake you can join the TN discord at discord.gg/unblock and request for mirror site links (that are restocked and unblocked).\n\n### Hosting\n\nIf you wish to self-host however you will first need a VPS or hosting provider: \n\n- https://docs.titaniumnetwork.org/guides/vps-hosting/\n- https://github.com/QuiteAFancyEmerald/Holy-Unblocker#deploy-holy-unblocker\n- https://docs.titaniumnetwork.org/guides/dns-setup/\n\n### Dependencies\n\nYou will then need to setup git, nginx (or caddy) and Node.js. Here is an example for Ubuntu LTS:\n```\nsudo apt update\nsudo apt upgrade\nsudo apt install curl git nginx\n\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\"\n\nnvm install 20\nnvm use 20\n```\nhttps://github.com/nvm-sh/nvm\nhttps://docs.titaniumnetwork.org/guides/nginx/\n\n### Tor Support (Optional)\nhttps://github.com/QuiteAFancyEmerald/Holy-Unblocker#toronionsocks5-routing-setup\n\n### Configurating Holy Unblocker\nMost important options are production along with the obfuscation and DOM masquerading techniques. \n\nFrom there just configure as needed: https://github.com/QuiteAFancyEmerald/Holy-Unblocker#configuration\n\n### Cloning and Running Holy Unblocker\n\nThen run the respective process; if you have production set to true in the configuration pm2 will be automatically enabled with our own workers/cache system. \n\n```\ngit clone https://github.com/QuiteAFancyEmerald/Holy-Unblocker.git\ncd Holy-Unblocker\n\nnpm run fresh-start\n```\n\nThen of course if you used NGINX or caddy please restart/reload it\n```\nsudo systemctl restart nginx\nsudo systemctl restart tor\n```\n\n</details>\n\n\nResources for self-hosting:\n\n- https://github.com/nvm-sh/nvm\n- https://docs.titaniumnetwork.org/guides/nginx/\n- https://docs.titaniumnetwork.org/guides/vps-hosting/\n- https://docs.titaniumnetwork.org/guides/dns-setup/\n\n### Configuration\n\n#### Server Configuration Setup\n\nThe default PORT for the proxy when started is `http://localhost:8080`. You can change the PORT and other production metrics if needed in `./ecosystem.config.js`. \n\nThe default PORT for Rammerhead is `3000`. You can change this <a href=\"https://github.com/QuiteAFancyEmerald/Holy-Unblocker/blob/8f6dcfedb71439a43a19cc0a015ee6ca7e29fd11/lib/rammerhead/holy-config.js#L9\">here</a>.\n\nEvery other localized changes for source randomization, auto-minify, etc. are located in `./config.json`.\n\n**config.json**\n- `minifyScripts`: Automatically minify respective static assets upon starting the server.\n- `randomizeIdentifiers`: Enable experimental proxy global randomization for Ultraviolet. This reduces the chances of UV being detected by any extension based filters.\n- `production`: Utilize a pre-configured production setup for server hosting. Automatically has cache control, session jobs for Rammerhead and source rewrites setup.\n- `disguiseFiles`: Enable DOM masquerading which obfuscates real the real content fetches for HU LTS. This is done through disguising requests, decompressing and then reconstructing the DOM tree.\n- `usingSEO`: Enable Source Randomization which randomizes the source by swapping chunks of data specified in `./src/data.json`. Highly useful for masking keywords that will automatically flag or block Holy Unblocker LTS as well as preventing source blocks.\n\n#### Tor/Onion/SOCKS5 Routing Setup\n\nYou need to setup Tor (no GUI need/GUI is alright. With GUI replace port 9050 with 9150) in order for the Onion Routing setting to work!\n\nSimply host Tor using this guide: https://tb-manual.torproject.org/installation/\n\nAlternative Guide (for CLI): https://community.torproject.org/onion-services/setup/install/\n\nIf you are hosting Holy Unblocker LTS on a VPS utilizing Ubuntu consider attaching Tor to systemctl for easier production management. Once Tor is up and running on either Linux or Windows it will work automatically with Holy Unblocker LTS when enabled by the user via the Settings menu.\n\nIf you wish to use a custom HTTP/HTTPS/SOCKS5 proxy to route all traffic through for Scramjet and Ultraviolet this is handled in `./views/assets/js/register-sw.js.` Modify `proxyUrl` with the respective protocol and address. This is done via the proxy option for Wisp. You can change the cases as needed.\n\n```js\n  proxyUrl = {\n    tor: 'socks5h://localhost:9050',\n    eu: 'socks5h://localhost:7000',\n    jp: 'socks5h://localhost:7001',\n  }\n```\n\n#### Proxy Configuration\n\nThe primary location for tweaking any web proxy related settings assigned via the Settings menu is `./views/assets/js/register-sw.js`. Here you can modify the provided transport options set locally via a cookie, swap out SOCKS5 proxies, change Onion routing ports, specify a blacklist, and more.\n\n- `stockSW`: The default service worker configuration file for Ultraviolet. For Holy Unblocker however adblocking is automatically enabled so this is not used by default.\n- `blacklistSW`: A modified version of Ultraviolet that allows for blacklisting domains and adblocking.\n- `proxyUrl`: Specifies a SOCKS5/HTTPS/HTTP protocol URL defaulting to the default Tor proxy port. This can be swapped out with any valid port or SOCK5s proxy. This is done via the proxy option for both epoxy and libcurl.\n- `transports`: Specifies any provided ports to be swapped via Bare-Mux and utilize Wisp.\n- `wispUrl`: Modify the pathname or url handling for Wisp\n- `defaultMode`: Specify the default transport used globally (can be swapped by the users still via the Settings menu)\n- `ScramjetController`: This constructor allows you to swap out the prefix used for Scramjet dynamically and specify file locations. Note you may need to edit `./views/scram/scramjet.sw` when changing file names.\n\n#### Client Navigation Configuration\n\nThe primary location for any client side navigation scripts is `./views/assets/js/common.js`. This file is primary used for Omnibox (Search Engine) functionality, swapping proxy options and linking games.\n\n- `getDomain`: This constant is used for specifying any subdomains to remove when appending a URL into the omnibox.\n- `goFrame`: This specifies the stealth frame used for Holy Unblocker LTS\n- `sx`: This constant specifies the search engine you want to be proxied whenever a user types something in that isn't a URL\n- `search/uvUrl/sjUrl`: These functions specify and parse the queries used for submitted URLs\n- `RammerheadEncode:` This constant is a dependency for Rammerhead parsing and querying\n- `urlHandler/asyncUrlHandler`: Used to set functions for the goProx object.\n- `goProx`: This constant allows for the mapping of URL handling for specific proxies, games or links that need to fall under a web proxy.\n\n```js\nconst goProx = Object.freeze({\n  ultraviolet: urlHandler(uvUrl),\n\n  scramjet: urlHandler(sjUrl),\n\n  rammerhead: asyncUrlHandler(\n    async (url) => location.origin + (await RammerheadEncode(search(url)))\n  ),\n\n  // `location.protocol + \"//\" + getDomain()` more like `location.origin`\n\n  examplepath: urlHandler(location.protocol + `//c.${getDomain()}/example/`),\n\n  examplesubdomain: urlHandler(location.protocol + '//c.' + getDomain()),\n\n  example: urlHandler(sjUrl('https://example.com')),\n});\n```\n\n- `prSet`: Attaches event listeners using goProx for any buttons or inputs needed\n\n```js\n// prSet function code here....\n\nprSet('pr-uv', 'ultraviolet');\nprSet('pr-sj', 'scramjet');\nprSet('pr-rh', 'rammerhead');\nprSet('pr-yt', 'youtube');\nprSet('pr-example', 'example');\n```\n\n- `huLinks/navLists`: Automatically takes paths stated in `./views/assets/json` and appends them depending on the page and usage. This is used for hiding links that would lead to filter blocks and create an easier system for adding games.\n\n#### Games Management\n\nAs stated above all game links that need to be appended to a page (including images and descriptions) are managed via the nav files in`./views/assets/json`. \n\nDownload the latest release <a href=\"https://github.com/QuiteAFancyEmerald/Holy-Unblocker/blob/master/views/GAMES.md\">here</a> and extract it within a folder called `/views/archive`.\n\n- `views/archive/g`: Contains any local or external HTML5/web games.\n- `views/archive/gfiles/flash`: Contains Ruffle (an Adobe Flash emulator) and a collection of flash games linked to an external CDN.\n- `views/archive/gfiles/rarch`: Contains webretro which is a project that ports RetroArch to WASM. Supports many systems like GBA, N64, etc; ROMS are NOT INCLUDED.\n\n## Structure\n\n<details><summary>Web Pages</summary>\n\n### Structure Information\n\n- `/views/`: The physical site base of Holy Unblocker goes here where static assets are served.\n- `/src/`: For future implementation of obfuscation and keyword removing features.\n\n#### Details of `/views/`\n\n- `/dist/` is used for minfied files. Created on build.\n- `/pages/` is used for the HTML for the site.\n- `/assets/` is used for storing various CSS, JS, image, and JSON files.\n- `/scram/` contains the respective local Scramjet implementation. Some files are overridden by the node module.\n- `/uv/` contains the UV implementation.\n\n#### Scripts located in `/views/assets/js/`\n\n- `card.js` adds a fancy visual effect to the box cards displayed on the welcome screen.\n- `common.js` is used on all pages and allows most site features to function such as autocomplete.\n- `csel.js` manages the settings menu, omnibox function and other additional features.\n- `loader.js` is used as an asset for DOM masquerading.\n- `register-sw.js` creates and manages service workers that allow Ultraviolet to function, and also uses bare transport.\n\n</details>\n\n## Future Additions\n\n<a href=\"https://github.com/QuiteAFancyEmerald/Holy-Unblocker/blob/master/TODO.md\">This</a> is our nonexhaustive todo list for Holy Unblocker LTS v6.x.x and above. Release for production will be v7.x.x and above.\n\n## Vague Explanation for Beginners With External Proxies and Hosting\n\nYou will first want to host your proxies locally or externally.\n\n#### List of some good hosting options:\n\n- <a href=\"https://crunchbits.com/\">Crunchbits</a> ( Current Hosting Provider)\n- <a href=\"https://greencloudvps.com\">Greencloud</a> (Paid)\n- <a href=\"https://www.oracle.com/cloud\">Oracle Cloud</a> (Free, Paid, Dedicated)\n- <a href=\"https://azure.microsoft.com\">Azure</a> (Free and Paid)\n\nOut of the list of hosting providers Dedipath and Azure rank first as a preference. You may also self-host.\n\nAfter you have selected a decent VPS, use Cloudflare for the DNS records for both the site and the subdomains for the proxies.\n\nThis is an example of DNS records. Self-hosting will require `A records` preferably.\n<img src=\"https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/dnssetup.png\" width=\"500\"></img>\n\n- `@` and `www.example.com` are being used for Holy Unblocker LTS.\n- `a.example.com` is being used for other instances like Libreddit, Invidious or web ported games depending on what the site maintainer needs.\n\nAs stated previously, Holy Unblocker is hosted locally with Scramjet, Ultraviolet and Rammerhead out of the box. No need for external instances.\n\n#### Domain Steps\n\n- If you prefer to obtain premium domains (TLDs) then use <a href=\"https://porkbun.com\">Porkbun</a>, which offers domains for amazing prices. Literally a `.org` domain normally costs around $5 first year.\n\n#### Cloudflare Steps\n\n- Use Cloudflare (make an account), add your site and then add your various DNS targets to Cloudflare. Make sure you add Cloudflare's Nameservers which will be given later when you are adding your site.\n\nMake sure they are CNAME although A records also work and try to follow this structure:\n\n**Type | Name | Target**\n\n`A | @ | VPS IP GOES HERE`  \n`A | www | VPS IP GOES HERE`  \n`A | a | VPS IP GOES HERE`\n\nMake sure HTTPS is forced and have SSL set to Flexible (if you don't use LetsEncrypt). Otherwise you can have SSL set to Full.\n\n#### Workspace Configurations\n\nPreferably if you have your own device use Visual Studio Code. Pretty much the best option you can get but obviously this is an opinion. Also make sure you have <a href=\"https://nodejs.org/\">Node.JS</a> installed on your machine.\n\nNot going to go too in depth with this part but first fork this repository. The clone it locally through a Terminal of some sort depending on what OS you are on. Make sure you navigate to the folder you want to set this up in.\n\n```\ngit clone https://github.com/QuiteAFancyEmerald/Holy-Unblocker.git\n\ncd Holy-Unblocker\n\nnpm run fresh-install\n\n# If you wish to start the project\n\nnpm start\n\n# For testing endpoints and errors\n\nnpm run test\n```\n\nNow simply add the folder you cloned this repo in in VSC. Then run `npm install`. I recommend that if you are releasing this publically on GitHub that you add a `.gitignore` in your root directory with the following exclusions:\n\n```\nnode_modules\n```\n\nNow you have your following workspace environment setup. To deploy the following workspace you just created you will need to look up depending on your hosting provider.\n\nFor an online IDE that you can use on your school computer and/or chromebook use GitPod. Basically the equivalent of Visual Studio Code but with in-browser support.\n\n- Make an account: `https://gitpod.io/`\n- Fork this repo and enter in this URL to setup your workspace: `https://gitpod.io#https://github.com/YourNameHere/Holy-Unblocker/`\n\nUse the same steps above by running `npm install` in your repository and adding a `.gitignore` in your root directory specifying to exclude `node_modules`.\n\n## Detailed FAQ\n\n<details>\n<summary>Quick FAQ</summary>\n\n#### Where can I find the games for this repo? (404 errors, etc.)\n\nDue to piracy concerns, size, etc. this has been moved over <a href=\"https://github.com/QuiteAFancyEmerald/HU-Archive\">here</a>. EmuLibrary is not featured in the public version.\n\n**Why is the site I am on not working correctly or having CAPTCHA errors?**\n\nCaptcha support is spotty on all of the current proxies sadly. It is primarily supported by Scramjet. Therefore some sites may not work with any of the sites.\n\n**I am getting 502 errors. What do I do?**\n\nWhen this happens you may either switch sites to fix the error or wait a bit. Sometimes clearing your cache can help.\n\nIf you still have any questions feel free to ask them in the discord linked here.\n\n</details>\n\n### Why are official domains now numbered? Is this project maintained again?\n\nYes, this project is active again for LTS support! However, the approach is now much simpler to ensure functionality: domain restocks as needed and a highly maintained source. More than ever, this project serves as a proof of concept for the brave souls willing to innovate in the web proxy service space.\n\n<details><summary>Former Closing Message (Original - 2022)</summary>\n\nThis isn‚Äôt the greatest announcement sorry. After lots of thought and severe hesitation I‚Äôm shutting down Holy Unblocker and leaving TN. It's just been something that I‚Äôve been super conflicted with for months hence the lack of updates and the massive gaps that happened last year. I just didn‚Äôt want to throw away a project that I passionately enjoyed and spent time on while making amazing friends and meeting epic devs here. I could go on forever for who these people are but ima like leave it here. They know who they are :D\n\nThe main change of thought is that I‚Äôm finally just putting an end right now due to 1) the lack of motivation 2) the community is NOT the greatest at time and not the nicest at times (have to put that out here) 3) the future doesn‚Äôt look so good for HU/TN as a project.\n\nSome things I‚Äôll be keeping secret since there are more reasons to this choice unless otherwise for those who don‚Äôt find this enough information. Good friends here will know that I‚Äôve been super stressed about this choice for months now. Also regardless a good motivator for this choice is the fact that I‚Äôll be graduating soon.\n\nIt‚Äôs possible that I may continue/come back for this in the future or keep it on GitHub only. I leave this here because even now I am still doubting myself about this change. But for now I‚Äôd check out other proxy sites like Incognito (Duce DOES a ton of updates frequently and he is the creator/developer of Ultraviolet so give him some love) :yayy_hopi:\n\nCheck out his Patreon also! For current HU patrons you will not be billed next month and the HU Patreon will be archived so head over to Duce‚Äôs patron so he can purchase more domains for Incognito.\n\nWith love <3\nEmerald :HuTaoHype:\n\n</details>\n\n## More Information\n\nThis project is maintained by the Holy Unblocker LTS team and is an official flagship Titanium Network web proxy site.\n\n- <a href=\"https://github.com/titaniumnetwork-dev/\">https://github.com/titaniumnetwork-dev/</a>\n- <a href=\"https://titaniumnetwork.org/\">https://titaniumnetwork.org/</a>\n\nView the official website for more detail and credits.\n\n### Web Proxy Sources:\n\nThis project currently uses Scramjet and Ultraviolet as web proxies adhering to the Wisp protocol. Bare-Mux is utilized for swapping transport systems to be utilized with Wisp. The included transport systems are EpoxyTransport and libcurl-transport. Rammerhead is also provided as an additional web proxy option.\n\n- <a href=\"https://github.com/MercuryWorkshop/scramjet\">Scramjet</a>\n- <a href=\"https://github.com/titaniumnetwork-dev/Ultraviolet\">Ultraviolet</a>\n- <a href=\"https://github.com/MercuryWorkshop/wisp-server-node\">Wisp-Server-Node</a>\n- <a href=\"https://github.com/MercuryWorkshop/wisp-server-python\">Wisp-Server-Python</a>\n- <a href=\"https://github.com/MercuryWorkshop/EpoxyTransport\">EpoxyTransport</a>\n- <a href=\"https://github.com/MercuryWorkshop/CurlTransport\">libcurl-transport</a>\n- <a href=\"https://github.com/MercuryWorkshop/bare-mux\">Bare-Mux</a>\n- <a href=\"https://github.com/binary-person/rammerhead\">Rammerhead</a>\n- <a href=\"https://gist.github.com/BinBashBanana/a1fd7345e2d86e69d5a532f16cbdbdaa\">DetectorDetector</a>\n\n### Other Dependencies:\n\n- <a href=\"https://github.com/tsparticles/tsparticles\">tsparticles</a>\n- <a href=\"https://github.com/fastify/fastify\">fastify</a>\n- <a href=\"https://github.com/fastify/fastify-helmet\">@fastify/helmet</a>\n- <a href=\"https://github.com/fastify/fastify-static\">@fastify/static</a>\n- <a href=\"https://github.com/DerpmanDev/modal\">Modal</a>\n- <a href=\"https://github.com/BinBashBanana/webretro\">webretro</a>\n- <a href=\"https://ruffle.rs/\">Ruffle</a>\n- <a href=\"https://github.com/michalsnik/aos\">AOS</a>\n- <a href=\"https://github.com/nordtheme\">Nord Theme</a>\n- <a href=\"https://fontawesome.com/\">Font Awesome</a>\n\n### Notable Mentions:\n\n- <a href=\"https://crunchbits.com/\">Crunchbits</a> (Hosting Provider)\n",
      "stars_today": 6
    },
    {
      "id": 7634677,
      "name": "openssl",
      "full_name": "openssl/openssl",
      "description": "TLS/SSL and crypto library",
      "html_url": "https://github.com/openssl/openssl",
      "stars": 29415,
      "forks": 11007,
      "language": "C",
      "topics": [
        "cryptography",
        "decryption",
        "encryption",
        "openssl",
        "ssl",
        "tls"
      ],
      "created_at": "2013-01-15T22:34:48Z",
      "updated_at": "2026-01-22T21:35:24Z",
      "pushed_at": "2026-01-22T17:20:16Z",
      "open_issues": 1589,
      "owner": {
        "login": "openssl",
        "avatar_url": "https://avatars.githubusercontent.com/u/3279138?v=4"
      },
      "readme": "Welcome to the OpenSSL Project\n==============================\n\n[![openssl logo]][www.openssl.org]\n\n[![github actions ci badge]][github actions ci]\n[![Nightly OS Zoo ci badge](https://github.com/openssl/openssl/actions/workflows/os-zoo.yml/badge.svg)](https://github.com/openssl/openssl/actions/workflows/os-zoo.yml)\n[![Provider Compatibility](https://github.com/openssl/openssl/actions/workflows/provider-compatibility.yml/badge.svg)](https://github.com/openssl/openssl/actions/workflows/provider-compatibility.yml)\n[![Quic Interop](https://github.com/openssl/openssl/actions/workflows/run_quic_interop.yml/badge.svg)](https://github.com/openssl/openssl/actions/workflows/run_quic_interop.yml)\n[![Daily checks](https://github.com/openssl/openssl/actions/workflows/run-checker-daily.yml/badge.svg)](https://github.com/openssl/openssl/actions/workflows/run-checker-daily.yml)\n[![LFX Health Score](https://insights.linuxfoundation.org/api/badge/health-score?project=openssl)](https://insights.linuxfoundation.org/project/openssl)\n\nOpenSSL is a robust, commercial-grade, full-featured Open Source Toolkit\nfor the Transport Layer Security (TLS, formerly SSL), Datagram TLS (DTLS), and QUIC protocols.\n\nThe protocol implementations are based on a full-strength general purpose\ncryptographic library, which can also be used stand-alone. Also included is a\ncryptographic module validated to conform with FIPS standards.\n\nOpenSSL is descended from the SSLeay library developed by Eric A. Young\nand Tim J. Hudson.\n\nThe official Home Page of the OpenSSL Project is [www.openssl.org].\n\nTable of Contents\n=================\n\n - [Overview](#overview)\n - [Download](#download)\n - [Build and Install](#build-and-install)\n - [Documentation](#documentation)\n - [License](#license)\n - [Support](#support)\n - [Contributing](#contributing)\n - [Legalities](#legalities)\n\nOverview\n========\n\nThe OpenSSL toolkit includes:\n\n- **libssl**\n  an implementation of all TLS protocol versions up to TLSv1.3 ([RFC 8446]),\n  DTLS protocol versions up to DTLSv1.2 ([RFC 6347]) and\n  the QUIC version 1 protocol ([RFC 9000]).\n\n- **libcrypto**\n  a full-strength general purpose cryptographic library. It constitutes the\n  basis of the TLS implementation, but can also be used independently.\n\n- **openssl**\n  the OpenSSL command line tool, a swiss army knife for cryptographic tasks,\n  testing and analyzing. It can be used for\n  - creation of key parameters\n  - creation of X.509 certificates, CSRs and CRLs\n  - calculation of message digests\n  - encryption and decryption\n  - SSL/TLS/DTLS and client and server tests\n  - QUIC client tests\n  - handling of S/MIME signed or encrypted mail\n  - and more...\n\nDownload\n========\n\nFor Production Use\n------------------\n\nSource code tarballs of the official releases can be downloaded from\n[openssl-library.org/source/](https://openssl-library.org/source/).\nThe OpenSSL project does not distribute the toolkit in binary form.\n\nHowever, for a large variety of operating systems precompiled versions\nof the OpenSSL toolkit are available. In particular, on Linux and other\nUnix operating systems, it is normally recommended to link against the\nprecompiled shared libraries provided by the distributor or vendor.\n\nWe also maintain a list of third parties that produce OpenSSL binaries for\nvarious Operating Systems (including Windows) on the [Binaries] page on our\nwiki.\n\nFor Testing and Development\n---------------------------\n\nAlthough testing and development could in theory also be done using\nthe source tarballs, having a local copy of the git repository with\nthe entire project history gives you much more insight into the\ncode base.\n\nThe main OpenSSL Git repository is private.\nThere is a public GitHub mirror of it at [github.com/openssl/openssl],\nwhich is updated automatically from the former on every commit.\n\nA local copy of the Git repository can be obtained by cloning it from\nthe GitHub mirror using\n\n    git clone https://github.com/openssl/openssl.git\n\nIf you intend to contribute to OpenSSL, either to fix bugs or contribute\nnew features, you need to fork the GitHub mirror and clone your public fork\ninstead.\n\n    git clone https://github.com/yourname/openssl.git\n\nThis is necessary because all development of OpenSSL nowadays is done via\nGitHub pull requests. For more details, see [Contributing](#contributing).\n\nBuild and Install\n=================\n\nAfter obtaining the Source, have a look at the [INSTALL](INSTALL.md) file for\ndetailed instructions about building and installing OpenSSL. For some\nplatforms, the installation instructions are amended by a platform specific\ndocument.\n\n * [Notes for UNIX-like platforms](NOTES-UNIX.md)\n * [Notes for Android platforms](NOTES-ANDROID.md)\n * [Notes for Windows platforms](NOTES-WINDOWS.md)\n * [Notes for the DOS platform with DJGPP](NOTES-DJGPP.md)\n * [Notes for the OpenVMS platform](NOTES-VMS.md)\n * [Notes on Perl](NOTES-PERL.md)\n * [Notes on Valgrind](NOTES-VALGRIND.md)\n\nSpecific notes on upgrading to OpenSSL 3.x from previous versions can be found\nin the [ossl-guide-migration(7ossl)] manual page.\n\nDocumentation\n=============\n\nREADME Files\n------------\n\nThere are some README.md files in the top level of the source distribution\ncontaining additional information on specific topics.\n\n * [Information about the OpenSSL QUIC protocol implementation](README-QUIC.md)\n * [Information about the OpenSSL Provider architecture](README-PROVIDERS.md)\n * [Information about using the OpenSSL FIPS validated module](README-FIPS.md)\n\nThe OpenSSL Guide\n-----------------\n\nThere are some tutorial and introductory pages on some important OpenSSL topics\nwithin the [OpenSSL Guide].\n\nManual Pages\n------------\n\nThe manual pages for the master branch and all current stable releases are\navailable online.\n\n- [OpenSSL master](https://docs.openssl.org/master/)\n- [OpenSSL 3.5](https://docs.openssl.org/3.5/)\n- [OpenSSL 3.4](https://docs.openssl.org/3.4/)\n- [OpenSSL 3.3](https://docs.openssl.org/3.3/)\n- [OpenSSL 3.2](https://docs.openssl.org/3.2/)\n- [OpenSSL 3.0](https://docs.openssl.org/3.0/)\n\nDemos\n-----\n\nThere are numerous source code demos for using various OpenSSL capabilities in the\n[demos subfolder](./demos).\n\nWiki\n----\n\nThere is a [GitHub Wiki] which is currently not very active.\n\nLicense\n=======\n\nOpenSSL is licensed under the Apache License 2.0, which means that\nyou are free to get and use it for commercial and non-commercial\npurposes as long as you fulfill its conditions.\n\nSee the [LICENSE.txt](LICENSE.txt) file for more details.\n\nSupport\n=======\n\nThere are various ways to get in touch. The correct channel depends on\nyour requirement. See the [SUPPORT](SUPPORT.md) file for more details.\n\nContributing\n============\n\nIf you are interested and willing to contribute to the OpenSSL project,\nplease take a look at the [CONTRIBUTING](CONTRIBUTING.md) file.\n\nLegalities\n==========\n\nA number of nations restrict the use or export of cryptography. If you are\npotentially subject to such restrictions, you should seek legal advice before\nattempting to develop or distribute cryptographic code.\n\nCopyright\n=========\n\nCopyright (c) 1998-2025 The OpenSSL Project Authors\n\nCopyright (c) 1995-1998 Eric A. Young, Tim J. Hudson\n\nAll rights reserved.\n\n<!-- Links  -->\n\n[www.openssl.org]:\n    <https://www.openssl.org>\n    \"OpenSSL Homepage\"\n\n[github.com/openssl/openssl]:\n    <https://github.com/openssl/openssl>\n    \"OpenSSL GitHub Mirror\"\n\n[GitHub Wiki]:\n    <https://github.com/openssl/openssl/wiki>\n    \"OpenSSL Wiki\"\n\n[ossl-guide-migration(7ossl)]:\n    <https://docs.openssl.org/master/man7/ossl-guide-migration>\n    \"OpenSSL Migration Guide\"\n\n[RFC 8446]:\n     <https://tools.ietf.org/html/rfc8446>\n\n[RFC 6347]:\n     <https://tools.ietf.org/html/rfc6347>\n\n[RFC 9000]:\n     <https://tools.ietf.org/html/rfc9000>\n\n[Binaries]:\n    <https://github.com/openssl/openssl/wiki/Binaries>\n    \"List of third party OpenSSL binaries\"\n\n[OpenSSL Guide]:\n    <https://docs.openssl.org/master/man7/ossl-guide-introduction>\n    \"An introduction to OpenSSL\"\n\n<!-- Logos and Badges -->\n\n[openssl logo]:\n    doc/images/openssl.svg\n    \"OpenSSL Logo\"\n\n[github actions ci badge]:\n    <https://github.com/openssl/openssl/workflows/GitHub%20CI/badge.svg>\n    \"GitHub Actions CI Status\"\n\n[github actions ci]:\n    <https://github.com/openssl/openssl/actions/workflows/ci.yml>\n    \"GitHub Actions CI\"\n\n[appveyor badge]:\n    <https://ci.appveyor.com/api/projects/status/8e10o7xfrg73v98f/branch/master?svg=true>\n    \"AppVeyor Build Status\"\n\n[appveyor jobs]:\n    <https://ci.appveyor.com/project/openssl/openssl/branch/master>\n    \"AppVeyor Jobs\"\n",
      "stars_today": 5
    },
    {
      "id": 1062572,
      "name": "Catch2",
      "full_name": "catchorg/Catch2",
      "description": "A modern, C++-native, test framework for unit-tests, TDD and BDD - using C++14, C++17 and later (C++11 support is in v2.x branch, and C++03 on the Catch1.x branch)",
      "html_url": "https://github.com/catchorg/Catch2",
      "stars": 20149,
      "forks": 3187,
      "language": "C++",
      "topics": [
        "bdd",
        "cpp",
        "cpp14",
        "framework",
        "no-dependencies",
        "tdd",
        "test-framework",
        "testing"
      ],
      "created_at": "2010-11-08T18:22:56Z",
      "updated_at": "2026-01-23T02:06:41Z",
      "pushed_at": "2026-01-19T14:14:53Z",
      "open_issues": 416,
      "owner": {
        "login": "catchorg",
        "avatar_url": "https://avatars.githubusercontent.com/u/33321405?v=4"
      },
      "readme": "<a id=\"top\"></a>\n\n<table width=\"100%\">\n  <tr>\n    <td align=\"center\" width=\"50%\"><img src=\"/data/artwork/catch2-logo-full-with-background.svg\" width=\"100%\"></td>\n    <td align=\"center\" width=\"50%\">\n      <figure>\n        <figcaption>Special thanks to:</figcaption>\n        <a href=\"https://tuple.app/catch2\"><img src=\"/data/sponsors/github_repo_sponsorship.png\" width=\"100%\"></a>\n      </figure>\n    </td>\n  </tr>\n</table>\n\n[![Github Releases](https://img.shields.io/github/release/catchorg/catch2.svg)](https://github.com/catchorg/catch2/releases)\n[![Linux build status](https://github.com/catchorg/Catch2/actions/workflows/linux-simple-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/linux-simple-builds.yml)\n[![Linux build status](https://github.com/catchorg/Catch2/actions/workflows/linux-other-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/linux-other-builds.yml)\n[![MacOS build status](https://github.com/catchorg/Catch2/actions/workflows/mac-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/mac-builds.yml)\n[![Build Status](https://ci.appveyor.com/api/projects/status/github/catchorg/Catch2?svg=true&branch=devel)](https://ci.appveyor.com/project/catchorg/catch2)\n[![Code Coverage](https://codecov.io/gh/catchorg/Catch2/branch/devel/graph/badge.svg)](https://codecov.io/gh/catchorg/Catch2)\n[![Try online](https://img.shields.io/badge/try-online-blue.svg)](https://godbolt.org/z/EdoY15q9G)\n[![Join the chat in Discord: https://discord.gg/4CWS9zD](https://img.shields.io/badge/Discord-Chat!-brightgreen.svg)](https://discord.gg/4CWS9zD)\n\n\n## What is Catch2?\n\nCatch2 is mainly a unit testing framework for C++, but it also\nprovides basic micro-benchmarking features, and simple BDD macros.\n\nCatch2's main advantage is that using it is both simple and natural.\nTest names do not have to be valid identifiers, assertions look like\nnormal C++ boolean expressions, and sections provide a nice and local way\nto share set-up and tear-down code in tests.\n\n**Example unit test**\n```cpp\n#include <catch2/catch_test_macros.hpp>\n\n#include <cstdint>\n\nuint32_t factorial( uint32_t number ) {\n    return number <= 1 ? number : factorial(number-1) * number;\n}\n\nTEST_CASE( \"Factorials are computed\", \"[factorial]\" ) {\n    REQUIRE( factorial( 1) == 1 );\n    REQUIRE( factorial( 2) == 2 );\n    REQUIRE( factorial( 3) == 6 );\n    REQUIRE( factorial(10) == 3'628'800 );\n}\n```\n\n**Example microbenchmark**\n```cpp\n#include <catch2/catch_test_macros.hpp>\n#include <catch2/benchmark/catch_benchmark.hpp>\n\n#include <cstdint>\n\nuint64_t fibonacci(uint64_t number) {\n    return number < 2 ? number : fibonacci(number - 1) + fibonacci(number - 2);\n}\n\nTEST_CASE(\"Benchmark Fibonacci\", \"[!benchmark]\") {\n    REQUIRE(fibonacci(5) == 5);\n\n    REQUIRE(fibonacci(20) == 6'765);\n    BENCHMARK(\"fibonacci 20\") {\n        return fibonacci(20);\n    };\n\n    REQUIRE(fibonacci(25) == 75'025);\n    BENCHMARK(\"fibonacci 25\") {\n        return fibonacci(25);\n    };\n}\n```\n\n_Note that benchmarks are not run by default, so you need to run it explicitly\nwith the `[!benchmark]` tag._\n\n\n## Catch2 v3 has been released!\n\nYou are on the `devel` branch, where the v3 version is being developed.\nv3 brings a bunch of significant changes, the big one being that Catch2\nis no longer a single-header library. Catch2 now behaves as a normal\nlibrary, with multiple headers and separately compiled implementation.\n\nThe documentation is slowly being updated to take these changes into\naccount, but this work is currently still ongoing.\n\nFor migrating from the v2 releases to v3, you should look at [our\ndocumentation](docs/migrate-v2-to-v3.md#top). It provides a simple\nguidelines on getting started, and collects most common migration\nproblems.\n\nFor the previous major version of Catch2 [look into the `v2.x` branch\nhere on GitHub](https://github.com/catchorg/Catch2/tree/v2.x).\n\n\n## How to use it\nThis documentation comprises these three parts:\n\n* [Why do we need yet another C++ Test Framework?](docs/why-catch.md#top)\n* [Tutorial](docs/tutorial.md#top) - getting started\n* [Reference section](docs/Readme.md#top) - all the details\n\n\n## More\n* Issues and bugs can be raised on the [Issue tracker on GitHub](https://github.com/catchorg/Catch2/issues)\n* For discussion or questions please use [our Discord](https://discord.gg/4CWS9zD)\n* See who else is using Catch2 in [Open Source Software](docs/opensource-users.md#top)\nor [commercially](docs/commercial-users.md#top).\n",
      "stars_today": 5
    },
    {
      "id": 3199002,
      "name": "linux",
      "full_name": "raspberrypi/linux",
      "description": "Kernel source tree for Raspberry Pi-provided kernel builds. Issues unrelated to the linux kernel should be posted on the community forum at https://forums.raspberrypi.com/",
      "html_url": "https://github.com/raspberrypi/linux",
      "stars": 12440,
      "forks": 5349,
      "language": "C",
      "topics": [],
      "created_at": "2012-01-17T12:10:20Z",
      "updated_at": "2026-01-23T00:17:02Z",
      "pushed_at": "2026-01-21T13:13:08Z",
      "open_issues": 1052,
      "owner": {
        "login": "raspberrypi",
        "avatar_url": "https://avatars.githubusercontent.com/u/1294177?v=4"
      },
      "readme": "Linux kernel\n============\n\nThere are several guides for kernel developers and users. These guides can\nbe rendered in a number of formats, like HTML and PDF. Please read\nDocumentation/admin-guide/README.rst first.\n\nIn order to build the documentation, use ``make htmldocs`` or\n``make pdfdocs``.  The formatted documentation can also be read online at:\n\n    https://www.kernel.org/doc/html/latest/\n\nThere are various text files in the Documentation/ subdirectory,\nseveral of them using the Restructured Text markup notation.\n\nPlease read the Documentation/process/changes.rst file, as it contains the\nrequirements for building and running the kernel, and information about\nthe problems which may result by upgrading your kernel.\n\nBuild status for rpi-6.1.y:\n[![Pi kernel build tests](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml/badge.svg?branch=rpi-6.1.y)](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml)\n[![dtoverlaycheck](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml/badge.svg?branch=rpi-6.1.y)](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml)\n\nBuild status for rpi-6.6.y:\n[![Pi kernel build tests](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml/badge.svg?branch=rpi-6.6.y)](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml)\n[![dtoverlaycheck](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml/badge.svg?branch=rpi-6.6.y)](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml)\n\nBuild status for rpi-6.12.y:\n[![Pi kernel build tests](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml/badge.svg?branch=rpi-6.12.y)](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml)\n[![dtoverlaycheck](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml/badge.svg?branch=rpi-6.12.y)](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml)\n",
      "stars_today": 5
    },
    {
      "id": 118105436,
      "name": "migrate",
      "full_name": "golang-migrate/migrate",
      "description": "Database migrations. CLI and Golang library.",
      "html_url": "https://github.com/golang-migrate/migrate",
      "stars": 17988,
      "forks": 1541,
      "language": "Go",
      "topics": [
        "aws-s3",
        "cassandra",
        "database",
        "databases",
        "go",
        "golang",
        "google-cloud-spanner",
        "google-cloud-storage",
        "hacktoberfest",
        "mariadb",
        "migration",
        "migrations",
        "mongodb",
        "mysql",
        "neo4j",
        "postgres",
        "spanner",
        "sql",
        "sqlite"
      ],
      "created_at": "2018-01-19T09:30:58Z",
      "updated_at": "2026-01-23T01:47:18Z",
      "pushed_at": "2025-12-14T23:16:48Z",
      "open_issues": 448,
      "owner": {
        "login": "golang-migrate",
        "avatar_url": "https://avatars.githubusercontent.com/u/35595841?v=4"
      },
      "readme": "[![GitHub Workflow Status (branch)](https://img.shields.io/github/actions/workflow/status/golang-migrate/migrate/ci.yaml?branch=master)](https://github.com/golang-migrate/migrate/actions/workflows/ci.yaml?query=branch%3Amaster)\n[![GoDoc](https://pkg.go.dev/badge/github.com/golang-migrate/migrate)](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)\n[![Coverage Status](https://img.shields.io/coveralls/github/golang-migrate/migrate/master.svg)](https://coveralls.io/github/golang-migrate/migrate?branch=master)\n[![packagecloud.io](https://img.shields.io/badge/deb-packagecloud.io-844fec.svg)](https://packagecloud.io/golang-migrate/migrate?filter=debs)\n[![Docker Pulls](https://img.shields.io/docker/pulls/migrate/migrate.svg)](https://hub.docker.com/r/migrate/migrate/)\n![Supported Go Versions](https://img.shields.io/badge/Go-1.24%2C%201.25-lightgrey.svg)\n[![GitHub Release](https://img.shields.io/github/release/golang-migrate/migrate.svg)](https://github.com/golang-migrate/migrate/releases)\n[![Go Report Card](https://goreportcard.com/badge/github.com/golang-migrate/migrate/v4)](https://goreportcard.com/report/github.com/golang-migrate/migrate/v4)\n\n# migrate\n\n__Database migrations written in Go. Use as [CLI](#cli-usage) or import as [library](#use-in-your-go-project).__\n\n* Migrate reads migrations from [sources](#migration-sources)\n   and applies them in correct order to a [database](#databases).\n* Drivers are \"dumb\", migrate glues everything together and makes sure the logic is bulletproof.\n   (Keeps the drivers lightweight, too.)\n* Database drivers don't assume things or try to correct user input. When in doubt, fail.\n\nForked from [mattes/migrate](https://github.com/mattes/migrate)\n\n## Databases\n\nDatabase drivers run migrations. [Add a new database?](database/driver.go)\n\n* [PostgreSQL](database/postgres)\n* [PGX v4](database/pgx)\n* [PGX v5](database/pgx/v5)\n* [Redshift](database/redshift)\n* [Ql](database/ql)\n* [Cassandra / ScyllaDB](database/cassandra)\n* [SQLite](database/sqlite)\n* [SQLite3](database/sqlite3) ([todo #165](https://github.com/mattes/migrate/issues/165))\n* [SQLCipher](database/sqlcipher)\n* [MySQL / MariaDB](database/mysql)\n* [Neo4j](database/neo4j)\n* [MongoDB](database/mongodb)\n* [CrateDB](database/crate) ([todo #170](https://github.com/mattes/migrate/issues/170))\n* [Shell](database/shell) ([todo #171](https://github.com/mattes/migrate/issues/171))\n* [Google Cloud Spanner](database/spanner)\n* [CockroachDB](database/cockroachdb)\n* [YugabyteDB](database/yugabytedb)\n* [ClickHouse](database/clickhouse)\n* [Firebird](database/firebird)\n* [MS SQL Server](database/sqlserver)\n* [rqlite](database/rqlite)\n\n### Database URLs\n\nDatabase connection strings are specified via URLs. The URL format is driver dependent but generally has the form: `dbdriver://username:password@host:port/dbname?param1=true&param2=false`\n\nAny [reserved URL characters](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters) need to be escaped. Note, the `%` character also [needs to be escaped](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_the_percent_character)\n\nExplicitly, the following characters need to be escaped:\n`!`, `#`, `$`, `%`, `&`, `'`, `(`, `)`, `*`, `+`, `,`, `/`, `:`, `;`, `=`, `?`, `@`, `[`, `]`\n\nIt's easiest to always run the URL parts of your DB connection URL (e.g. username, password, etc) through an URL encoder. See the example Python snippets below:\n\n```bash\n$ python3 -c 'import urllib.parse; print(urllib.parse.quote(input(\"String to encode: \"), \"\"))'\nString to encode: FAKEpassword!#$%&'()*+,/:;=?@[]\nFAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D\n$ python2 -c 'import urllib; print urllib.quote(raw_input(\"String to encode: \"), \"\")'\nString to encode: FAKEpassword!#$%&'()*+,/:;=?@[]\nFAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D\n$\n```\n\n## Migration Sources\n\nSource drivers read migrations from local or remote sources. [Add a new source?](source/driver.go)\n\n* [Filesystem](source/file) - read from filesystem\n* [io/fs](source/iofs) - read from a Go [io/fs](https://pkg.go.dev/io/fs#FS)\n* [Go-Bindata](source/go_bindata) - read from embedded binary data ([jteeuwen/go-bindata](https://github.com/jteeuwen/go-bindata))\n* [pkger](source/pkger) - read from embedded binary data ([markbates/pkger](https://github.com/markbates/pkger))\n* [GitHub](source/github) - read from remote GitHub repositories\n* [GitHub Enterprise](source/github_ee) - read from remote GitHub Enterprise repositories\n* [Bitbucket](source/bitbucket) - read from remote Bitbucket repositories\n* [Gitlab](source/gitlab) - read from remote Gitlab repositories\n* [AWS S3](source/aws_s3) - read from Amazon Web Services S3\n* [Google Cloud Storage](source/google_cloud_storage) - read from Google Cloud Platform Storage\n\n## CLI usage\n\n* Simple wrapper around this library.\n* Handles ctrl+c (SIGINT) gracefully.\n* No config search paths, no config files, no magic ENV var injections.\n\n[CLI Documentation](cmd/migrate) (includes CLI install instructions)\n\n### Basic usage\n\n```bash\n$ migrate -source file://path/to/migrations -database postgres://localhost:5432/database up 2\n```\n\n### Docker usage\n\n```bash\n$ docker run -v {{ migration dir }}:/migrations --network host migrate/migrate\n    -path=/migrations/ -database postgres://localhost:5432/database up 2\n```\n\n## Use in your Go project\n\n* API is stable and frozen for this release (v3 & v4).\n* Uses [Go modules](https://golang.org/cmd/go/#hdr-Modules__module_versions__and_more) to manage dependencies.\n* To help prevent database corruptions, it supports graceful stops via `GracefulStop chan bool`.\n* Bring your own logger.\n* Uses `io.Reader` streams internally for low memory overhead.\n* Thread-safe and no goroutine leaks.\n\n__[Go Documentation](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)__\n\n```go\nimport (\n    \"github.com/golang-migrate/migrate/v4\"\n    _ \"github.com/golang-migrate/migrate/v4/database/postgres\"\n    _ \"github.com/golang-migrate/migrate/v4/source/github\"\n)\n\nfunc main() {\n    m, err := migrate.New(\n        \"github://mattes:personal-access-token@mattes/migrate_test\",\n        \"postgres://localhost:5432/database?sslmode=enable\")\n    m.Steps(2)\n}\n```\n\nWant to use an existing database client?\n\n```go\nimport (\n    \"database/sql\"\n    _ \"github.com/lib/pq\"\n    \"github.com/golang-migrate/migrate/v4\"\n    \"github.com/golang-migrate/migrate/v4/database/postgres\"\n    _ \"github.com/golang-migrate/migrate/v4/source/file\"\n)\n\nfunc main() {\n    db, err := sql.Open(\"postgres\", \"postgres://localhost:5432/database?sslmode=enable\")\n    driver, err := postgres.WithInstance(db, &postgres.Config{})\n    m, err := migrate.NewWithDatabaseInstance(\n        \"file:///migrations\",\n        \"postgres\", driver)\n    m.Up() // or m.Steps(2) if you want to explicitly set the number of migrations to run\n}\n```\n\n## Getting started\n\nGo to [getting started](GETTING_STARTED.md)\n\n## Tutorials\n\n* [CockroachDB](database/cockroachdb/TUTORIAL.md)\n* [PostgreSQL](database/postgres/TUTORIAL.md)\n\n(more tutorials to come)\n\n## Migration files\n\nEach migration has an up and down migration. [Why?](FAQ.md#why-two-separate-files-up-and-down-for-a-migration)\n\n```bash\n1481574547_create_users_table.up.sql\n1481574547_create_users_table.down.sql\n```\n\n[Best practices: How to write migrations.](MIGRATIONS.md)\n\n## Coming from another db migration tool?\n\nCheck out [migradaptor](https://github.com/musinit/migradaptor/).\n*Note: migradaptor is not affiliated or supported by this project*\n\n## Versions\n\nVersion | Supported? | Import | Notes\n--------|------------|--------|------\n**master** | :white_check_mark: | `import \"github.com/golang-migrate/migrate/v4\"` | New features and bug fixes arrive here first |\n**v4** | :white_check_mark: | `import \"github.com/golang-migrate/migrate/v4\"` | Used for stable releases |\n**v3** | :x: | `import \"github.com/golang-migrate/migrate\"` (with package manager) or `import \"gopkg.in/golang-migrate/migrate.v3\"` (not recommended) | **DO NOT USE** - No longer supported |\n\n## Development and Contributing\n\nYes, please! [`Makefile`](Makefile) is your friend,\nread the [development guide](CONTRIBUTING.md).\n\nAlso have a look at the [FAQ](FAQ.md).\n\n---\n\nLooking for alternatives? [https://awesome-go.com/#database](https://awesome-go.com/#database).\n",
      "stars_today": 5
    },
    {
      "id": 19429698,
      "name": "Signal-iOS",
      "full_name": "signalapp/Signal-iOS",
      "description": "A private messenger for iOS.",
      "html_url": "https://github.com/signalapp/Signal-iOS",
      "stars": 11806,
      "forks": 3337,
      "language": "Swift",
      "topics": [],
      "created_at": "2014-05-04T15:42:40Z",
      "updated_at": "2026-01-22T19:33:07Z",
      "pushed_at": "2026-01-22T23:02:22Z",
      "open_issues": 128,
      "owner": {
        "login": "signalapp",
        "avatar_url": "https://avatars.githubusercontent.com/u/702459?v=4"
      },
      "readme": "# Signal iOS\n\nSignal is a free and open source messaging app for simple private communication with friends.\n\n[![Available on the App Store](https://signal.org/external/images/app-store-download-badge.svg)](https://apps.apple.com/app/id874139669)\n\nAlso available on [Android](https://github.com/signalapp/signal-android) and [Desktop](https://github.com/signalapp/signal-desktop).\n\n## Questions?\n\nFor troubleshooting and questions, please visit our [support center](https://support.signal.org/) or [unofficial community forum](https://community.signalusers.org/).\n\n## Contributing Bug Reports\n\nThe best way to submit a bug report or support request is [via the Support Center](https://support.signal.org/hc/requests/new). Signal iOS doesn't collect any analytics or telemetry, and we rely on your feedback to help us troubleshoot and fix problems when something isn't working correctly.\n\n## Contributing Code\n\nInstructions for how to configure your development environment and build Signal iOS can be found in [BUILDING.md](https://github.com/signalapp/Signal-iOS/blob/main/BUILDING.md). We also recommend reading the [contribution guidelines](https://github.com/signalapp/Signal-iOS/blob/main/CONTRIBUTING.md).\n\n## Contributing Ideas\n\nHave something you want to say about Signal Foundation projects or want to be part of the conversation? Get involved in the [community forum](https://community.signalusers.org).\n\n## Cryptography Notice\n\nThis distribution includes cryptographic software. The country in which you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of encryption software.\nBEFORE using any encryption software, please check your country's laws, regulations and policies concerning the import, possession, or use, and re-export of encryption software, to see if this is permitted.\nSee <http://www.wassenaar.org/> for more information.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and Security (BIS), has classified this software as Export Commodity Control Number (ECCN) 5D002.C.1, which includes information security software using or performing cryptographic functions with asymmetric algorithms.\nThe form and manner of this distribution makes it eligible for export under the License Exception ENC Technology Software Unrestricted (TSU) exception (see the BIS Export Administration Regulations, Section 740.13) for both object code and source code.\n\n## License\n\nCopyright 2013-2025 Signal Messenger, LLC\n\nLicensed under the GNU AGPLv3: https://www.gnu.org/licenses/agpl-3.0.html\n\n_Apple and the Apple logo are trademarks of Apple Inc., registered in the U.S. and other countries. App Store is a service mark of Apple Inc., registered in the U.S. and other countries._\n",
      "stars_today": 5
    },
    {
      "id": 6220644,
      "name": "OpenRefine",
      "full_name": "OpenRefine/OpenRefine",
      "description": "OpenRefine is a free, open source power tool for working with messy data and improving it",
      "html_url": "https://github.com/OpenRefine/OpenRefine",
      "stars": 11702,
      "forks": 2122,
      "language": "Java",
      "topics": [
        "data-analysis",
        "data-science",
        "data-wrangling",
        "datacleaning",
        "datacleansing",
        "datajournalism",
        "datamining",
        "java",
        "journalism",
        "opendata",
        "reconciliation",
        "wikidata"
      ],
      "created_at": "2012-10-15T02:22:48Z",
      "updated_at": "2026-01-22T22:37:32Z",
      "pushed_at": "2026-01-21T23:08:20Z",
      "open_issues": 701,
      "owner": {
        "login": "OpenRefine",
        "avatar_url": "https://avatars.githubusercontent.com/u/2538880?v=4"
      },
      "readme": "# OpenRefine\n\n[![DOI](https://zenodo.org/badge/6220644.svg)](https://zenodo.org/badge/latestdoi/6220644)\n[![Join the chat at https://gitter.im/OpenRefine/OpenRefine](https://badges.gitter.im/OpenRefine/OpenRefine.svg)](https://gitter.im/OpenRefine/OpenRefine)\n[![Snapshot release](https://github.com/OpenRefine/OpenRefine/actions/workflows/snapshot_release.yml/badge.svg)](https://github.com/OpenRefine/OpenRefine/actions/workflows/snapshot_release.yml) [![Coverage Status](https://coveralls.io/repos/github/OpenRefine/OpenRefine/badge.svg?branch=master)](https://coveralls.io/github/OpenRefine/OpenRefine?branch=master) [![Translation progress](https://hosted.weblate.org/widgets/openrefine/-/svg-badge.svg)](https://hosted.weblate.org/engage/openrefine/?utm_source=widget)\n[![Sponsor on GitHub](https://img.shields.io/badge/Sponsor-GitHub-blue)](https://github.com/sponsors/OpenRefine)\n[![Donate](https://img.shields.io/badge/Donate-OpenRefine-blue)](https://openrefine.org/donate)\n[![OpenRefine Store](https://img.shields.io/badge/üõçÔ∏èShop-OpenRefine_Store-blue)](https://store.openrefine.org)\n\nOpenRefine is a Java-based power tool that allows you to load data, understand it,\nclean it up, reconcile it, and augment it with data coming from\nthe web. All from a web browser and the comfort and privacy of your own computer.\n\nOfficial website: **https://openrefine.org**\n\nCommunity forum: **https://forum.openrefine.org**\n\n[<img src=\"https://github.com/OpenRefine/OpenRefine/blob/master/graphics/icon/open-refine-320px.png\" align=\"right\">](https://openrefine.org)\n\n## Download\n\n* [OpenRefine Releases](https://github.com/OpenRefine/OpenRefine/releases)\n\n## Snapshot releases\n\nYou can download snapshots of the development version of OpenRefine.\nTo do so, you need to be logged in to GitHub. Then, click on the first item with a green tick / check mark on [this page](https://github.com/OpenRefine/OpenRefine/actions/workflows/snapshot_release.yml) and scroll down to the Artifacts section to find the version that matches your operating system.\n\n## Run from source\n\nIf you have cloned this repository to your computer, you can run OpenRefine with:\n\n* `./refine` on Mac OS and Linux\n* `refine.bat` on Windows\n\nThis requires [JDK 11](https://adoptium.net/) or newer, [Apache Maven](https://maven.apache.org/) and [Node.js 18](https://nodejs.org/) or newer.\n\n## Documentation\n\n* [User Manual](https://openrefine.org/docs)\n* [FAQ](https://github.com/OpenRefine/OpenRefine/wiki/FAQ)\n\n## Contributing to the project\n\n* [Developers Guide & Architecture](https://github.com/OpenRefine/OpenRefine/wiki/Documentation-For-Developers)\n* [Contributing Guide](https://github.com/OpenRefine/OpenRefine/blob/master/CONTRIBUTING.md)\n* [Project Governance](https://github.com/OpenRefine/OpenRefine/blob/master/GOVERNANCE.md)\n\n## Contact us\n\n* [Community forum](https://forum.openrefine.org)\n* [Twitter](https://www.twitter.com/openrefine)\n* [Gitter](https://gitter.im/OpenRefine/OpenRefine)\n* [Matrix (bridged from Gitter)](https://matrix.to/#/#OpenRefine_OpenRefine:gitter.im)\n\n## Licensing and legal issues\n\nOpenRefine is open source software and is licensed under the BSD license located in the [LICENSE.txt](LICENSE.txt). See the folders `licenses` under `/main/webapp/` as well as within each `/extensions` for information on open source libraries that OpenRefine depends on.\n\n## Funding OpenRefine\n\nOpenRefine is maintained by a small core team and relies on grants plus community support.\n‚Ä¢ **Donate** or become a monthly sponsor: https://openrefine.org/donate\n‚Ä¢ **See our backers**: https://openrefine.org/backers\n‚Ä¢ **Machine-readable manifest**: https://openrefine.org/funding.json\n\n## Credits\n\nThis software was created by Metaweb Technologies, Inc. and originally written and conceived by [David Huynh](https://github.com/dfhuynh). Metaweb Technologies, Inc. was acquired by Google, Inc. in July 2010 and the product was renamed Google Refine. In October 2012, it was renamed OpenRefine as it transitioned to a community-driven project.\n\nSince 2020, OpenRefine is fiscally sponsored by [Code for Science and Society](https://www.codeforsociety.org/) (CS&S).\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for instructions on how to contribute yourself.\n",
      "stars_today": 5
    },
    {
      "id": 1524684,
      "name": "SFML",
      "full_name": "SFML/SFML",
      "description": "Simple and Fast Multimedia Library",
      "html_url": "https://github.com/SFML/SFML",
      "stars": 11597,
      "forks": 1898,
      "language": "C++",
      "topics": [
        "audio",
        "c-plus-plus",
        "cross-platform",
        "games",
        "graphics",
        "hacktoberfest",
        "multimedia",
        "opengl",
        "sdk",
        "sfml"
      ],
      "created_at": "2011-03-25T08:05:25Z",
      "updated_at": "2026-01-22T21:46:13Z",
      "pushed_at": "2026-01-21T16:02:30Z",
      "open_issues": 149,
      "owner": {
        "login": "SFML",
        "avatar_url": "https://avatars.githubusercontent.com/u/4226899?v=4"
      },
      "readme": "[![SFML logo](https://www.sfml-dev.org/images/logo.png)](https://www.sfml-dev.org)\n\n# SFML ‚Äî Simple and Fast Multimedia Library\n\nSFML is a simple, fast, cross-platform and object-oriented multimedia API. It provides access to windowing, graphics, audio and network. It is written in C++ and has bindings for various languages such as C, .Net, Ruby, Python.\n\n## State of Development\n\nDevelopment is focused on version 3 in the `master` branch.\nNo more features are planned for the 2.x release series.\n\n## CMake Template\n\nThe easiest way to get started with SFML is our [CMake-based project template](https://github.com/SFML/cmake-sfml-project/blob/master/README.md).\nThis template will automatically download and build SFML alongside your own application.\nRead the README for full instructions on how to use it.\n\n## Download\n\n-   You can get the latest official release on [SFML's website](https://www.sfml-dev.org/download.php).\n-   You can also get the source code of the current development version from the [Git repository](https://github.com/SFML/SFML).\n-   Alternatively, you can get the latest snapshot / artifact builds from the [artifacts storage](https://artifacts.sfml-dev.org/by-branch/master/).\n\n## Install\n\nFollow the instructions of the [tutorials](https://www.sfml-dev.org/tutorials/), there is one for each platform/compiler that SFML supports.\n\n## Learn\n\nThere are several places to learn SFML:\n\n-   The [official tutorials](https://www.sfml-dev.org/tutorials/)\n-   The [online API documentation](https://www.sfml-dev.org/documentation/)\n-   The [community wiki](https://github.com/SFML/SFML/wiki/)\n\n## Community\n\nHere are some useful community links:\n\n-   [Discord](https://discord.gg/nr4X7Fh)\n-   [Twitter](https://twitter.com/sfmldev)\n-   [Forum](https://en.sfml-dev.org/forums/) ([French](https://fr.sfml-dev.org/forums/))\n\n## Contribute\n\nSFML is an open-source project, and it needs your help to go on growing and improving. If you want to get involved and suggest some additional features, file a bug report or submit a patch, please have a look at the [contribution guidelines](https://www.sfml-dev.org/contribute.php).\n\n## Authors\n\n-   Laurent Gomila (laurent@sfml-dev.org)\n-   Marco Antognini (hiura@sfml-dev.org)\n-   binary1248 (binary1248@hotmail.com)\n-   Lukas D√ºrrenberger (eXpl0it3r@sfml-dev.org)\n-   Jonathan De Wachter (dewachter.jonathan@gmail.com)\n-   Jan Haller (bromeon@sfml-dev.org)\n-   Mario Liebisch (mario@sfml-dev.org)\n-   Stefan Schindler (tank@sfml-dev.org)\n-   Artur Moreira (artturmoreira@gmail.com)\n-   Vittorio Romeo (vittorioromeo@sfml-dev.org)\n-   Chris Thrasher (thrasher@sfml-dev.org)\n-   And many other members of the SFML community\n\n## License\n\nThe SFML libraries and source code are distributed under the [zlib/libpng license](https://opensource.org/licenses/Zlib). See [license.md](license.md). External libraries used by SFML are distributed under their own licenses.\n\nIn short, SFML is free for any use (commercial or personal, proprietary or open-source). You can use SFML in your project without any restriction. You can even omit to mention that you use SFML -- although it would be appreciated.\n\n## External libraries used by SFML\n\n-   [_stb_image_ and _stb_image_write_](https://github.com/nothings/stb) are [public domain](https://github.com/nothings/stb/blob/master/LICENSE)\n-   [_freetype_](https://gitlab.freedesktop.org/freetype/freetype) is under the [FreeType license or the GPL license](https://gitlab.freedesktop.org/freetype/freetype/-/blob/master/LICENSE.TXT)\n-   [_libogg_](https://gitlab.xiph.org/xiph/ogg) is under the [BSD license](https://gitlab.xiph.org/xiph/ogg/-/blob/master/COPYING)\n-   [_libvorbis_](https://gitlab.xiph.org/xiph/vorbis) is under the [BSD license](https://gitlab.xiph.org/xiph/vorbis/-/blob/master/COPYING)\n-   [_libflac_](https://gitlab.xiph.org/xiph/flac) is under the [BSD license](https://gitlab.xiph.org/xiph/flac/-/blob/master/COPYING.Xiph)\n-   [_minimp3_](https://github.com/lieff/minimp3) is under the [CC0 license](https://github.com/lieff/minimp3/blob/master/LICENSE)\n-   [_miniaudio_](https://github.com/mackron/miniaudio) is [public domain or under the MIT No Attribution license](https://github.com/mackron/miniaudio/blob/master/LICENSE)\n-   [_cpp-unicodelib_](https://github.com/yhirose/cpp-unicodelib) is under the [MIT license](https://github.com/yhirose/cpp-unicodelib/blob/master/LICENSE)\n-   [_HarfBuzz_](https://github.com/harfbuzz/harfbuzz) is under the [Old MIT license](https://github.com/harfbuzz/harfbuzz/blob/main/COPYING)\n-   [_SheenBidi_](https://github.com/Tehreer/SheenBidi) is under the [Apache license](https://github.com/Tehreer/SheenBidi/blob/master/LICENSE)\n-   [_qoi_](https://github.com/phoboslab/qoi) is under the [MIT license](https://github.com/phoboslab/qoi/blob/master/LICENSE)\n-   [_Mbed TLS_](https://github.com/Mbed-TLS/mbedtls) is under the [Apache license or the GPL license](https://github.com/Mbed-TLS/mbedtls/blob/main/LICENSE)\n",
      "stars_today": 5
    },
    {
      "id": 23780138,
      "name": "riscv-gnu-toolchain",
      "full_name": "riscv-collab/riscv-gnu-toolchain",
      "description": "GNU toolchain for RISC-V, including GCC",
      "html_url": "https://github.com/riscv-collab/riscv-gnu-toolchain",
      "stars": 4335,
      "forks": 1340,
      "language": "C",
      "topics": [],
      "created_at": "2014-09-08T05:22:03Z",
      "updated_at": "2026-01-23T00:18:48Z",
      "pushed_at": "2026-01-22T20:52:30Z",
      "open_issues": 37,
      "owner": {
        "login": "riscv-collab",
        "avatar_url": "https://avatars.githubusercontent.com/u/89536104?v=4"
      },
      "readme": "RISC-V GNU Compiler Toolchain\n=============================\n\nThis is the RISC-V C and C++ cross-compiler. It supports two build modes:\na generic ELF/Newlib toolchain and a more sophisticated Linux-ELF/glibc\ntoolchain.\n\n###  Getting the sources\n\nThis repository uses submodules, but submodules will fetch automatically on demand,\nso `--recursive` or `git submodule update --init --recursive` is not needed.\n\n    $ git clone https://github.com/riscv/riscv-gnu-toolchain\n\n**Warning: git clone takes around 6.65 GB of disk and download size**\n\n### Prerequisites\n\nSeveral standard packages are needed to build the toolchain.\n\nOn Ubuntu, executing the following command should suffice:\n\n    $ sudo apt-get install autoconf automake autotools-dev curl python3 python3-pip python3-tomli libmpc-dev libmpfr-dev libgmp-dev gawk build-essential bison flex texinfo gperf libtool patchutils bc zlib1g-dev libexpat-dev ninja-build git cmake libglib2.0-dev libslirp-dev libncurses-dev\n\nOn Fedora/CentOS/RHEL OS, executing the following command should suffice:\n\n    $ sudo yum install autoconf automake python3 libmpc-devel mpfr-devel gmp-devel gawk  bison flex texinfo patchutils gcc gcc-c++ zlib-devel expat-devel libslirp-devel ncurses-devel\n\nOn Arch Linux, executing the following command should suffice:\n\n    $ sudo pacman -Syu curl python3 libmpc mpfr gmp base-devel texinfo gperf patchutils bc zlib expat libslirp ncurses\n\nAlso available for Arch users on the AUR: [https://aur.archlinux.org/packages/riscv-gnu-toolchain-bin](https://aur.archlinux.org/packages/riscv-gnu-toolchain-bin)\n\nOn macOS, you can use [Homebrew](http://brew.sh) to install the dependencies:\n\n    $ brew install python3 gawk gnu-sed make gmp mpfr libmpc isl zlib expat texinfo flock libslirp ncurses ninja bison m4 wget\n\nWhen executing the instructions in this README, please use `gmake` instead of `make` to use the newly installed version of make.\nTo build the glibc (Linux) on macOS, you will need to build within a case-sensitive file\nsystem.  The simplest approach is to create and mount a new disk image with\na case sensitive format.  Make sure that the mount point does not contain spaces. This is not necessary to build newlib or gcc itself on macOS.\n\nThis process will start by downloading about 200 MiB of upstream sources, then\nwill patch, build, and install the toolchain.  If a local cache of the\nupstream sources exists in $(DISTDIR), it will be used; the default location\nis /var/cache/distfiles.  Your computer will need about 8 GiB of disk space to\ncomplete the process.\n\n### Installation (Newlib)\n\nTo build the Newlib cross-compiler, pick an install path (that is writeable).\nIf you choose, say, `/opt/riscv`, then add `/opt/riscv/bin` to your `PATH`.\nThen, simply run the following command:\n\n    ./configure --prefix=/opt/riscv\n    make\n\nYou should now be able to use riscv64-unknown-elf-gcc and its cousins.\n\nNote: If you're planning to use an external library that replaces part of newlib (for example `libgloss-htif`), [read the FAQ](#ensuring-code-model-consistency).\n\n### Installation (Linux)\n\nTo build the Linux cross-compiler, pick an install path (that is writeable).\nIf you choose, say, `/opt/riscv`, then add `/opt/riscv/bin` to your `PATH`.\nThen, simply run the following command:\n\n    ./configure --prefix=/opt/riscv\n    make linux\n\nThe build defaults to targeting RV64GC (64-bit) with glibc, even on a 32-bit\nbuild environment. To build the 32-bit RV32GC toolchain, use:\n\n    ./configure --prefix=/opt/riscv --with-arch=rv32gc --with-abi=ilp32d\n    make linux\n\nIn case you prefer musl libc over glibc, configure just like above and opt for\n`make musl` instead of `make linux`.\n\nSupported architectures are rv32i or rv64i plus standard extensions (a)tomics,\n(m)ultiplication and division, (f)loat, (d)ouble, or (g)eneral for MAFD.\n\nSupported ABIs are ilp32 (32-bit soft-float), ilp32d (32-bit hard-float),\nilp32f (32-bit with single-precision in registers and double in memory, niche\nuse only), lp64 lp64f lp64d (same but with 64-bit long and pointers).\n\n### Installation (Newlib/Linux multilib)\n\nTo build either cross-compiler with support for both 32-bit and\n64-bit, run the following command:\n\n    ./configure --prefix=/opt/riscv --enable-multilib\n\nAnd then either `make`, `make linux` or `make musl` for the Newlib, Linux\nglibc-based or Linux musl libc-based cross-compiler, respectively.\n\nThe multilib compiler will have the prefix riscv64-unknown-elf- or\nriscv64-unknown-linux-gnu- but will be able to target both 32-bit and 64-bit\nsystems.\nIt will support the most common `-march`/`-mabi` options, which can be seen by\nusing the `--print-multi-lib` flag on either cross-compiler.\n\nLinux toolchain has an additional option `--enable-default-pie` to control the\ndefault PIE enablement for GCC, which is disable by default.\n\nTo customize the enabled languages, use option `--with-languages=`. For example,\nif you want to enable `c,c++,fortran`, use `./configure --with-languages=c,c++,fortran`.\nThis option only takes effect for the GNU toolchain.\n\nThe toolchain has an option `--enable-strip` to control strip of host binaries,\nstrip is disabled by default.\n\n### Installation (MacOS ARM)\n\nFirst, ensure you have cloned the toolchain repository in a case-sensitive volume. \n\nNow source `macos.zsh` to setup the PATH variable so that the build scripts can use the tools from homebrew, which are needed to build the GNU toolchain.\n\nThen, run configure with your desired flags - For example:\n```\n./configure --prefix=/Volumes/case-sensitive/opt/riscv --with-arch=rv64gc_zifencei --with-abi=lp64d --enable-linux --disable-gdb\n```\n\nThen, raise the limit of open files. Run: `ulimit -n 65536`\n\nBuilds on MacOS are highly specific to OS versions and the versions of the developer tools installed. We recommend running `make check-binutils` first, which will help surface a some of the more frequent build errors we've seen without having to start a full build.\n\nIf `make check-binutils` errors, check the [following documentation](./macos-build.md) for a list of common errors when building on MacOS and their solutions.\n\nWhen `make check-binutils` finishes successfully, you run the build normally with `make` or `make linux`.\n\n### Troubleshooting Build Problems\n\nBuilds work best if installing into an empty directory.  If you build a\nhard-float toolchain and then try to build a soft-float toolchain with\nthe same --prefix directory, then the build scripts may get confused\nand exit with a linker error complaining that hard float code can't be\nlinked with soft float code.  Removing the existing toolchain first, or\nusing a different prefix for the second build, avoids the problem.  It\nis OK to build one newlib and one linux toolchain with the same prefix.\nBut you should avoid building two newlib or two linux toolchains with\nthe same prefix.\n\nIf building a linux toolchain on a MacOS system, or on a Windows system\nusing the Linux subsystem or cygwin, you must ensure that the filesystem\nis case-sensitive.  A build on a case-insensitive filesystem will fail when\nbuilding glibc because \\*.os and \\*.oS files will clobber each other during\nthe build eventually resulting in confusing link errors.\n\nCentOS (and RHEL) provide old GNU tools versions that may be too old to build\na RISC-V toolchain.  There is an alternate toolset provided that includes\ncurrent versions of the GNU tools.  This is the devtoolset provided as part\nof the Software Collection service.  For more info, see the\n[devtoolset-7](https://www.softwarecollections.org/en/scls/rhscl/devtoolset-7/)\nURL.  There are various versions of the devtoolset that are available, so you\ncan also try other versions of it, but we have at least one report that\ndevtoolset-7 works.\n\n### Advanced Options\n\nThere are a number of additional options that may be passed to\nconfigure.  See './configure --help' for more details.\n\nAlso you can define extra flags to pass to specific projects: ```BINUTILS_NATIVE_FLAGS_EXTRA,\nBINUTILS_TARGET_FLAGS_EXTRA, GCC_EXTRA_CONFIGURE_FLAGS, GDB_NATIVE_FLAGS_EXTRA,\nGDB_TARGET_FLAGS_EXTRA, GLIBC_TARGET_FLAGS_EXTRA, NEWLIB_TARGET_FLAGS_EXTRA,\nLLVM_EXTRA_CONFIGURE_FLAGS, QEMU_EXTRA_CONFIGURE_FLAGS```.\nExample: ```GCC_EXTRA_CONFIGURE_FLAGS=--with-gmp=/opt/gmp make linux```\n\n#### Set default ISA spec version\n\n`--with-isa-spec=` can specify the default version of the RISC-V Unprivileged\n(formerly User-Level) ISA specification.\n\nPossible options are: `2.2`, `20190608` and `20191213`.\n\nThe default version is `20191213`.\n\nMore details about this option you can refer this post [RISC-V GNU toolchain bumping default ISA spec to 20191213](https://groups.google.com/a/groups.riscv.org/g/sw-dev/c/aE1ZeHHCYf4).\n\n#### Build with customized multi-lib configure.\n\n`--with-multilib-generator=` can specify what multilibs to build.  The argument\nis a semicolon separated list of values, possibly consisting of a single value.\nCurrently only supported for riscv*-*-elf*.  The accepted values and meanings\nare given below.\n\nEvery config is constructed with four components: architecture string, ABI,\nreuse rule with architecture string and reuse rule with sub-extension.\n\nRe-use part support expansion operator (*) to simplify the combination of\ndifferent sub-extensions, example 4 demonstrate how it uses and works.\n\nExample 1: Add multi-lib support for rv32i with ilp32.\n```\n./configure --with-multilib-generator=\"rv32i-ilp32--\"\n```\n\nExample 2: Add multi-lib support for rv32i with ilp32 and rv32imafd with ilp32.\n\n```\n./configure --with-multilib-generator=\"rv32i-ilp32--;rv32imafd-ilp32--\"\n```\n\nExample 3: Add multi-lib support for rv32i with ilp32; rv32im with ilp32 and\nrv32ic with ilp32 will reuse this multi-lib set.\n```\n./configure --with-multilib-generator=\"rv32i-ilp32-rv32im-c\"\n```\n\nExample 4: Add multi-lib support for rv64ima with lp64; rv64imaf with lp64,\nrv64imac with lp64 and rv64imafc with lp64 will reuse this multi-lib set.\n```\n./configure --with-multilib-generator=\"rv64ima-lp64--f*c\"\n```\n\n#### Enabling QEMU System Targets\n\nThe `--enable-qemu-system` configuration flag allows you to include QEMU system emulation targets in addition to the default user-mode emulation.\n\n- **Enabled targets**:\n  - `riscv64-linux-user`\n  - `riscv32-linux-user`\n  - `riscv64-softmmu`\n  - `riscv32-softmmu`\n\n- **Default targets** (without this flag):\n  - `riscv64-linux-user`\n  - `riscv32-linux-user`\n\nUse this option if you need full system emulation for RISC-V. Example configuration:\n\n```bash\n./configure --enable-qemu-system --prefix=/opt/riscv\nmake build-sim SIM=qemu\n```\n\nThis flag is particularly useful for developers testing and emulating full RISC-V systems rather than just user-space applications.\n\n### Test Suite\n\nThe Dejagnu test suite has been ported to RISC-V. This can be run with a\nsimulator for the elf and linux toolchains. The simulator can be selected\nby the SIM variable in the Makefile, e.g. SIM=qemu, SIM=gdb, or SIM=spike\n(experimental).In addition, the simulator can also be selected with the\nconfigure time option `--with-sim=`.However, the testsuite allowlist is\nonly maintained for qemu.Other simulators might get extra failures.\n\n#### Additional Prerequisite\n\nA helper script to setup testing environment requires\n[pyelftools](https://github.com/eliben/pyelftools).\n\nOn newer versions of Ubuntu, executing the following command\nshould suffice:\n\n    $ sudo apt-get install python3-pyelftools\n\nOn newer versions of Fedora and CentOS/RHEL OS (9 or later), executing\nthe following command should suffice:\n\n    $ sudo yum install python3-pyelftools\n\nOn Arch Linux, executing the following command should suffice:\n\n    $ sudo pacman -Syyu python-pyelftools python-sphinx python-sphinx_rtd_theme ninja\n\nIf your distribution/OS does not have pyelftools package, you can install\nit using PIP.\n\n    # Assuming that PIP is installed\n    $ pip3 install --user pyelftools\n\n#### Testing GCC\n\nTo test GCC, run the following commands:\n\n    ./configure --prefix=$RISCV --disable-linux --with-arch=rv64ima # or --with-arch=rv32ima\n    make newlib\n    make report-newlib SIM=gdb # Run with gdb simulator\n\n    ./configure --prefix=$RISCV\n    make linux\n    make report-linux SIM=qemu # Run with qemu\n\n    ./configure --prefix=$RISCV --with-sim=spike\n    make linux\n    make report               # Run with spike\n\nNote:\n- spike only support rv64* bare-metal/elf toolchain.\n- gdb simulator only support bare-metal/elf toolchain.\n\n#### Selecting the tests to run in GCC's regression test suite\n\nBy default GCC will execute all tests of its regression test suite.\nWhile running them in parallel (e.g. `make -j$(nproc) report`) will\nsignificantly speed up the execution time on multi-processor systems,\nthe required time for executing all tests is usually too high for\ntypical development cycles. Therefore GCC allows to select the tests\nthat are being executed using the environment variable `RUNTESTFLAGS`.\n\nTo restrict a test run to only RISC-V specific tests\nthe following command can be used:\n\n    RUNTESTFLAGS=\"riscv.exp\" make report\n\nTo restrict a test run to only RISC-V specific tests with match the\npattern \"zb*.c\" and \"sm*.c\" the following command can be used:\n\n    RUNTESTFLAGS=\"riscv.exp=zb*.c\\ sm*.c\" make report\n\n#### Testing GCC, Binutils, and glibc of a Linux toolchain\n\nThe default Makefile target to run toolchain tests is `report`.\nThis will run all tests of the GCC regression test suite.\nAlternatively, the following command can be used to do the same:\n\n    make check-gcc\n\nThe following command can be used to run the Binutils tests:\n\n    make check-binutils\n\nThe command below can be used to run the glibc tests:\n\n    make check-glibc-linux\n\n##### Adding more arch/abi combination for testing without introducing multilib\n\n`--with-extra-multilib-test` can be used when you want to test more combination\nof arch/ABI, for example: built a linux toolchain with multilib with\n`rv64gc/lp64d` and `rv64imac/lp64`, but you want to test more configuration like\n`rv64gcv/lp64d` or `rv64gcv_zba/lp64d`, then you can use --with-extra-multilib-test\nto specify that via `--with-extra-multilib-test=\"rv64gcv-lp64d;rv64gcv_zba-lp64d\"`,\nthen the testing will run for `rv64gc/lp64d`, `rv64imac/lp64`, `rv64gcv/lp64d`\nand `rv64gcv_zba/lp64d`.\n\n`--with-extra-multilib-test` support bare-metal and linux toolchain and support\neven multilib is disable, but the user must ensure extra multilib test\nconfiguration can be work with existing lib/multilib, e.g. rv32gcv/ilp32 test\ncan't work if multilib didn't have any rv32 multilib.\n\n`--with-extra-multilib-test` also support more complicated format to fit the\nrequirements of end-users. First of all, the argument is a list of test\nconfigurations. Each test configuration are separated by `;`. For example:\n\n  `rv64gcv-lp64d;rv64_zvl256b_zvfh-lp64d`\n\nFor each test configuration, it has two parts, aka required arch-abi part and\noptional build flags. We leverage `:` to separate them with some restrictions.\n\n  * arch-abi should be required and there must be only one at the begining of\n    the test configuration.\n  * build flags is a array-like flags after the arch-abi, there will be two\n    ways to arrange them, aka AND, OR operation.\n  * If you would like the flags in build flags array acts on arch-abi\n    __simultaneously__, you can use `:` to separate them. For example:\n\n   ```\n   rv64gcv-lp64d:--param=riscv-autovec-lmul=dynamic:--param=riscv-autovec-preference=fixed-vlmax\n   ```\n\n   will be consider as one target board same as below:\n\n   ```\n   riscv-sim/-march=rv64gcv/-mabi=lp64d/-mcmodel=medlow/--param=riscv-autovec-lmul=dynamic/--param=riscv-autovec-preference=fixed-vlmax\n   ```\n\n  * If you would like the flags in build flags array acts on arch-abi\n    __respectively__, you can use ',' to separate them. For example:\n\n   ```\n   rv64gcv-lp64d:--param=riscv-autovec-lmul=dynamic,--param=riscv-autovec-preference=fixed-vlmax\n   ```\n\n   will be consider as two target boards same as below:\n\n   ```\n   riscv-sim/-march=rv64gcv/-mabi=lp64d/-mcmodel=medlow/--param=riscv-autovec-preference=fixed-vlmax\n   riscv-sim/-march=rv64gcv/-mabi=lp64d/-mcmodel=medlow/--param=riscv-autovec-lmul=dynamic\n   ```\n\n  * However, you can also leverage AND(`:`), OR(`,`) operator together but the\n    OR(`,`) will always have the higher priority. For example:\n\n   ```\n   rv64gcv-lp64d:--param=riscv-autovec-lmul=dynamic:--param=riscv-autovec-preference=fixed-vlmax,--param=riscv-autovec-lmul=m2\n   ```\n\n   will be consider as tow target boars same as below:\n\n   ```\n   riscv-sim/-march=rv64gcv/-mabi=lp64d/-mcmodel=medlow/--param=riscv-autovec-lmul=dynamic/--param=riscv-autovec-preference=fixed-vlmax\n   riscv-sim/-march=rv64gcv/-mabi=lp64d/-mcmodel=medlow/--param=riscv-autovec-lmul=m2\n   ```\n\n### LLVM / clang\n\nLLVM can be used in combination with the RISC-V GNU Compiler Toolchain\nto build RISC-V applications. To build LLVM with C and C++ support the\nconfigure flag `--enable-llvm` can be used.\n\nE.g. to build LLVM on top of a RV64 Linux toolchain the following commands\ncan be used:\n\n  ./configure --prefix=$RISCV --enable-llvm --enable-linux\n  make\n\nNote, that a combination of `--enable-llvm` and multilib configuration flags\nis not supported.\n\nBelow are examples how to build a rv64gc Linux/newlib toolchain with LLVM support,\nhow to use it to build a C and a C++ application using clang, and how to\nexecute the generated binaries using QEMU.\n\nBuild Linux toolchain and run examples:\n\n    # Build rv64gc toolchain with LLVM\n    ./configure --prefix=$RISCV --enable-llvm --enable-linux --with-arch=rv64gc --with-abi=lp64d\n    make -j$(nproc) all build-sim SIM=qemu\n    # Build C application with clang\n    $RISCV/bin/clang -march=rv64imafdc -o hello_world hello_world.c\n    $RISCV/bin/qemu-riscv64 -L $RISCV/sysroot ./hello_world\n    # Build C++ application with clang\n    $RISCV/bin/clang++ -march=rv64imafdc -stdlib=libc++ -o hello_world_cpp hello_world_cpp.cxx\n    $RISCV/bin/qemu-riscv64 -L $RISCV/sysroot ./hello_world_cpp\n\nBuild newlib toolchain and run examples (don't work with `--with-multilib-generator=`):\n\n    # Build rv64gc bare-metal toolchain with LLVM\n    ./configure --prefix=$RISCV --enable-llvm --disable-linux --with-arch=rv64gc --with-abi=lp64d\n    make -j$(nproc) all build-sim SIM=qemu\n    # Build C application with clang\n    $RISCV/bin/clang -march=rv64imafdc -o hello_world hello_world.c\n    $RISCV/bin/qemu-riscv64 -L $RISCV/sysroot ./hello_world\n    # Build C++ application with clang using static link\n    $RISCV/bin/clang++ -march=rv64imafdc -static -o hello_world_cpp hello_world_cpp.cxx\n    $RISCV/bin/qemu-riscv64 -L $RISCV/sysroot ./hello_world_cpp\n\n### Development\n\nThis section is only for developer or advanced user, or you want to build\ntoolchain with your own source tree.\n\n#### Update Source Tree\n\n`riscv-gnu-toolchain` contain stable but not latest source for each submodule,\nin case you want to using latest development tree, you can use following command\nto upgrade all submodule.\n\n    git submodule update --remote\n\nOr you can upgrade specific submodule only.\n\n    git submodule update --remote <component>\n\nFor example, upgrade gcc only, you can using following command:\n\n    git submodule update --remote gcc\n\n#### How to Check Which Branch are Used for Specific submodule\n\nThe branch info has recorded in `.gitmodules` file, which can set or update via\n`git submodule add -b` or `git submodule set-branch`.\n\nHowever the only way to check which branch are using is to check `.gitmodules`\nfile, here is the example for `gcc`, it's using releases/gcc-12 branch, so\nit will has a section named `gcc` and has a field `branch` is\n`releases/gcc-12`.\n\n```\n[submodule \"gcc\"]\n        path = gcc\n        url = ../gcc.git\n        branch = releases/gcc-12\n```\n\n#### Use Source Tree Other Than `riscv-gnu-toolchain`\n\n`riscv-gnu-toolchain` also supports using out-of-tree source to build the toolchain.\nThere are several configure options for specifying the source tree of each\nsubmodule/component.\n\nFor example, if you have GCC sources in `$HOME/gcc`, use `--with-gcc-src` to build the toolchain using those sources:\n\n    ./configure ... --with-gcc-src=$HOME/gcc\n\nHere is the list of configure options for specifying alternative sources for the various submodules/components:\n\n    --with-binutils-src\n    --with-dejagnu-src\n    --with-gcc-src\n    --with-gdb-src\n    --with-glibc-src\n    --with-linux-headers-src\n    --with-llvm-src\n    --with-musl-src\n    --with-newlib-src\n    --with-pk-src\n    --with-qemu-src\n    --with-spike-src\n    --with-uclibc-src\n\n#### Build host GCC to check for compiler warnings\n\nGCC contributions have to meet several requirements to qualify for upstream\ninclusion.  Warning free compilation with a compiler build from the same\nsources is among them.  The flag `--enable-host-gcc` does exaclty that:\n\n* Initially a host GCC will be built\n* This host GCC is then used to build the cross compiler\n* The cross compiler will be built with `-Werror` to identify code issues\n\n### FAQ\n#### Ensuring Code Model Consistency\nIf parts of newlib are going to be replaced with an external library (such as with [libgloss-htif](https://github.com/ucb-bar/libgloss-htif) for Berkeley Host-Target Interface),\nyou should take care to ensure that both newlib and the external library are built using the same code model. For more information about RISC-V code models,\n[read this SiFive blog article](https://www.sifive.com/blog/all-aboard-part-4-risc-v-code-models).\n\nErrors that indicate a code model mismatch include \"relocation overflow\" or \"relocation truncated\" errors from the linker being unable to successfully relocate symbols in the executable.\n\nBy default, `riscv-gnu-toolchain` builds newlib with `-mcmodel=medlow`. You can use the alternative `medany` code model (as used in libgloss-htif) by passing `--with-cmodel=medany` to the configure script.\n",
      "stars_today": 5
    },
    {
      "id": 105010691,
      "name": "desktop",
      "full_name": "nextcloud/desktop",
      "description": "üíª Desktop sync client for Nextcloud",
      "html_url": "https://github.com/nextcloud/desktop",
      "stars": 3585,
      "forks": 913,
      "language": "C++",
      "topics": [
        "c-plus-plus",
        "cpp",
        "desktop",
        "hacktoberfest",
        "nextcloud",
        "nextcloud-desktop-client"
      ],
      "created_at": "2017-09-27T11:38:04Z",
      "updated_at": "2026-01-22T19:56:45Z",
      "pushed_at": "2026-01-22T14:48:02Z",
      "open_issues": 736,
      "owner": {
        "login": "nextcloud",
        "avatar_url": "https://avatars.githubusercontent.com/u/19211038?v=4"
      },
      "readme": "<!--\n  - SPDX-FileCopyrightText: 2017 Nextcloud GmbH and Nextcloud contributors\n  - SPDX-FileCopyrightText: 2011 Nextcloud GmbH and Nextcloud contributors\n  - SPDX-License-Identifier: GPL-2.0-or-later\n-->\n# Nextcloud Desktop Client\n\n[![REUSE status](https://api.reuse.software/badge/github.com/nextcloud/desktop)](https://api.reuse.software/info/github.com/nextcloud/desktop)\n\nThe Nextcloud Desktop Client is a tool to synchronize files from Nextcloud Server with your computer.\n\n<p align=\"center\">\n    <img src=\"doc/images/main_dialog_christine.png\" alt=\"Desktop Client on Windows\" width=\"450\">\n</p>\n\n## :rocket: Releases\nFor the latest stable recommended version, please refer to the [download page https://nextcloud.com/install/#install-clients](https://nextcloud.com/install/#install-clients)\n\n## Contributing to the desktop client\n:v: Please read the [Code of Conduct](https://nextcloud.com/community/code-of-conduct/). This document offers some guidance to ensure Nextcloud participants can cooperate effectively in a positive and inspiring atmosphere and to explain how together we can strengthen and support each other.\n\n### üë™ Join the team\nThere are many ways to contribute, of which development is only one! Find out [how to get involved](https://nextcloud.com/contribute/), including as a translator, designer, tester, helping others, and much more! üòç\n\n### Help testing\nDownload and install the client:<br>\n[üîΩ All releases](https://github.com/nextcloud-releases/desktop/releases)<br>\n[üîΩ Daily master builds](https://download.nextcloud.com/desktop/daily)\n\n### Reporting issues\nIf you find any bugs or have any suggestion for improvement, please\n[open an issue in this repository](https://github.com/nextcloud/desktop/issues).\n\n### Bug fixing and development\n\n> [!TIP]\n> For building the client on macOS we have a tool called `mac-crafter`.\n> You will find more information about it in [its dedicated README](admin/osx/mac-crafter/README.md).\n> Also, please note the [README in the NextcloudIntegration project](shell_integration/MacOSX/NextcloudIntegration/README.md) which provides an even more convenient way to work on and build the desktop client on macOS by using Xcode.\n\n#### 1. üöÄ Set up your local development environment\n\n> [!NOTE]  \n> Find the system requirements and instructions on [how to work on Windows with KDE Craft](https://github.com/nextcloud/desktop-client-blueprints/) on our [desktop client blueprints repository](https://github.com/nextcloud/desktop-client-blueprints/).\n\n1.1 System requirements\n- [Windows 10, Windows 11](https://github.com/nextcloud/desktop-client-blueprints/), macOS 10.14 Mojave (or newer) or Linux\n- [üîΩ Inkscape (to generate icons)](https://inkscape.org/release/)\n- Developer tools: cmake, clang/gcc/g++:\n- Qt6 since 3.14, Qt5 for earlier versions\n- OpenSSL\n- [üîΩ QtKeychain](https://github.com/frankosterfeld/qtkeychain)\n- SQLite\n\n1.2 Optional\n- [Qt Creator IDE](https://www.qt.io/product/development-tools)\n- [delta: A viewer for git and diff output](https://github.com/dandavison/delta)\n\n> [!TIP]\n> We highly recommend [Nextcloud development environment on Docker Compose](https://juliusknorr.github.io/nextcloud-docker-dev/) for testing/bug fixing/development.<br>\n> ‚ñ∂Ô∏è https://juliusknorr.github.io/nextcloud-docker-dev/\n\n1.3 Step by step instructions on how to build the client to contribute\n1. Clone the Github repository:\n```\ngit clone https://github.com/nextcloud/desktop.git\n```\n2. Create <build directory>:\n```\nmkdir <build directory>\n```\n3. Compile:\n```\ncd <build directory>\ncmake -S <cloned desktop repo> -B build -DCMAKE_PREFIX_PATH=<dependencies> -DCMAKE_BUILD_TYPE=Debug -DCMAKE_INSTALL_PREFIX=. -DNEXTCLOUD_DEV=ON\n```\n\n> [!TIP]\n> The cmake variable NEXTCLOUD_DEV allows you to run your own build of the client while developing in parallel with an installed version of the client.\n\n4. Build it:\n- Windows:\n```\ncmake --build .\n```\n- Other platforms:\n```\nmake\n```\n\n5. üêõ [Pick a good first issue](https://github.com/nextcloud/desktop/labels/good%20first%20issue)\n6. üë©‚Äçüîß Create a branch and make your changes. Remember to sign off your commits using `git commit -sm \"Your commit message\"`\n7. ‚¨Ü Create a [pull request](https://opensource.guide/how-to-contribute/#opening-a-pull-request) and `@mention` the people from the issue to review\n8. üëç Fix things that come up during a review\n9. üéâ Wait for it to get merged!\n\n## Get in touch üí¨\n* [üìã Forum](https://help.nextcloud.com)\n* [üë• Facebook](https://www.facebook.com/nextclouders)\n* [üê£ Twitter](https://twitter.com/Nextclouders)\n* [üêò Mastodon](https://mastodon.xyz/@nextcloud)\n\nYou can also [get support for Nextcloud](https://nextcloud.com/support)!\n\n## :scroll: License\n\n    This program is free software; you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation; either version 2 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful, but\n    WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n    or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License\n    for more details.\n",
      "stars_today": 5
    },
    {
      "id": 219058535,
      "name": "gateway-api",
      "full_name": "kubernetes-sigs/gateway-api",
      "description": "Repository for the next iteration of composite service (e.g. Ingress) and load balancing APIs.",
      "html_url": "https://github.com/kubernetes-sigs/gateway-api",
      "stars": 2594,
      "forks": 657,
      "language": "Go",
      "topics": [
        "gateway-api",
        "k8s-sig-network",
        "kubernetes",
        "networking",
        "sig-network"
      ],
      "created_at": "2019-11-01T20:33:32Z",
      "updated_at": "2026-01-22T21:30:01Z",
      "pushed_at": "2026-01-22T05:39:28Z",
      "open_issues": 211,
      "owner": {
        "login": "kubernetes-sigs",
        "avatar_url": "https://avatars.githubusercontent.com/u/36015203?v=4"
      },
      "readme": "# Kubernetes Gateway API\n\nThe Gateway API is a part of [SIG Network][sn], and this repository contains\nthe specification and Custom Resource Definitions (CRDs).\n\n## Status\n\nThe latest supported version is `v1` as released by\nthe [v1.4.1 release][gh_release] of this project.\n\nThis version of the API has GA level support for the following resources:\n\n- `v1.GatewayClass`\n- `v1.Gateway`\n- `v1.HTTPRoute`\n- `v1.GRPCRoute`\n- `v1.BackendTLSPolicy`\n\nFor all the other APIs and their support levels please consult [the spec][spec].\n\n## Documentation\n\n### Website\n\nThe API specification and detailed documentation is available on the project\nwebsite: [https://gateway-api.sigs.k8s.io][ghp].\n\n### Concepts\n\nTo get started, please read through [API concepts][concepts] and\n[Security model][security-model]. These documents give the necessary background\nto understand the API and the use-cases it targets.\n\n### Getting started\n\nOnce you have a good understanding of the API at a higher-level, check out\n[getting started][getting-started] to install your first Gateway controller and try out\none of the guides.\n\n### References\n\nFor a complete API reference, please refer to:\n\n- [API reference][spec]\n- [Go docs for the package][godoc]\n\n## Gateway API conformance\n\nIf you are developing a Gateway API implementation and want to run conformance tests\nagainst your project and eventually submit the proof of conformance, visit the [conformance\ndocumentation][conformance-docs] for the test suite documentation, and the conformance\nreports [readme][reports-readme] to see the reports submission rules. If you\nare a user who wants to explore the features supported by the various implementations,\nnavigate the [conformance reports][conformance-reports]\n\n## Contributing\n\nCommunity meeting schedule, notes and developer guide can be found on the\n[community page][cm].\nOur Kubernetes Slack channel is [#sig-network-gateway-api][slack].\n\n### Code of conduct\n\nParticipation in the Kubernetes community is governed by the\n[Kubernetes Code of Conduct](code-of-conduct.md).\n\n[ghp]: https://gateway-api.sigs.k8s.io/\n[sn]: https://github.com/kubernetes/community/tree/master/sig-network\n[cm]: https://gateway-api.sigs.k8s.io/contributing/community\n[slack]: https://kubernetes.slack.com/messages/sig-network-gateway-api\n[getting-started]: https://gateway-api.sigs.k8s.io/guides/\n[spec]: https://gateway-api.sigs.k8s.io/reference/spec/\n[concepts]: https://gateway-api.sigs.k8s.io/concepts/api-overview\n[security-model]: https://gateway-api.sigs.k8s.io/concepts/security-model\n[gh_release]: https://github.com/kubernetes-sigs/gateway-api/releases/tag/v1.4.1\n[godoc]: https://pkg.go.dev/sigs.k8s.io/gateway-api\n[conformance-docs]: https://gateway-api.sigs.k8s.io/concepts/conformance/\n[reports-readme]: ./conformance/reports/README.md\n[conformance-reports]: ./conformance/reports/\n",
      "stars_today": 5
    },
    {
      "id": 746689243,
      "name": "kafka-ui",
      "full_name": "kafbat/kafka-ui",
      "description": "Open-Source Web UI for managing Apache Kafka clusters",
      "html_url": "https://github.com/kafbat/kafka-ui",
      "stars": 1950,
      "forks": 241,
      "language": "Java",
      "topics": [
        "apache-kafka",
        "big-data",
        "cluster-management",
        "event-streaming",
        "foss",
        "hacktoberfest",
        "kafka",
        "kafka-brokers",
        "kafka-client",
        "kafka-cluster",
        "kafka-connect",
        "kafka-manager",
        "kafka-producer",
        "kafka-streams",
        "kafka-ui",
        "opensource",
        "streaming-data",
        "streams",
        "web-ui"
      ],
      "created_at": "2024-01-22T13:38:08Z",
      "updated_at": "2026-01-23T01:17:04Z",
      "pushed_at": "2026-01-22T16:56:36Z",
      "open_issues": 255,
      "owner": {
        "login": "kafbat",
        "avatar_url": "https://avatars.githubusercontent.com/u/98461227?v=4"
      },
      "readme": "<div align=\"center\">\n<img src=\"documentation/images/logo_new.png\" alt=\"logo\"/>\n<h3>Kafbat UI</h3>\n\nVersatile, fast and lightweight web UI for managing Apache Kafka¬Æ clusters.\n</div>\n\n<div align=\"center\">\n<a href=\"https://github.com/kafbat/kafka-ui/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" alt=\"License\"/></a>\n<img src=\"documentation/images/free-open-source.svg\" alt=\"price free\"/>\n<a href=\"https://github.com/kafbat/kafka-ui/releases\"><img src=\"https://img.shields.io/github/v/release/kafbat/kafka-ui\" alt=\"latest release version\"/></a>\n<a href=\"https://discord.gg/4DWzD7pGE5\"><img src=\"https://img.shields.io/discord/897805035122077716\" alt=\"discord online number count\"/></a>\n<a href=\"https://github.com/sponsors/kafbat\"><img src=\"https://img.shields.io/github/sponsors/kafbat?style=flat&logo=githubsponsors&logoColor=%23EA4AAA&label=Support%20us\" alt=\"\" /></a>\n</div>\n\n<p align=\"center\">\n    <a href=\"https://ui.docs.kafbat.io/\">Documentation</a> ‚Ä¢ \n    <a href=\"https://ui.docs.kafbat.io/quick-start/demo-run\">Quick Start</a> ‚Ä¢ \n    <a href=\"https://discord.gg/4DWzD7pGE5\">Community</a>\n    <br/>\n    <a href=\"https://aws.amazon.com/marketplace/pp/prodview-6tdqqzzjwmejq\">AWS Marketplace</a>  ‚Ä¢\n    <a href=\"https://www.producthunt.com/products/ui-for-apache-kafka/reviews/new\">ProductHunt</a>\n</p>\n\n<p align=\"center\">\n  <img src=\"https://repobeats.axiom.co/api/embed/88d2bd9887380c7d86e2f986725d9af52ebad7f4.svg\" alt=\"stats\"/>\n</p>\n\n#### Kafbat UI is a free, open-source web UI to monitor and manage Apache Kafka clusters.\n\n[Kafbat UI](https://kafbat.io/) is a simple tool that makes your data flows observable, helps find and troubleshoot issues faster and deliver optimal performance. Its lightweight dashboard makes it easy to track key metrics of your Kafka clusters - Brokers, Topics, Partitions, Production, and Consumption.\n\n<i>\nKafbat UI, developed by <b>Kafbat</b>*, proudly carries forward the legacy of the UI Apache Kafka project.\nOur dedication is reflected in the continuous evolution of the project, ensuring adherence to its foundational vision while adapting to meet modern demands.\nWe extend our gratitude to Provectus for their past support in groundbreaking work, which serves as a cornerstone for our ongoing innovation and dedication.\n\n<b>*</b> - The <b>Kafbat</b> team comprises key contributors from the project's inception, bringing a wealth of experience and insight to this renewed endeavor.\n</i>\n\n# Interface\n\n![Interface](https://raw.githubusercontent.com/kafbat/kafka-ui/images/overview.gif)\n\n# Features\n\n* **Topic Insights** ‚Äì View essential topic details including partition count, replication status, and custom configurations.\n* **Configuration Wizard** ‚Äì Set up and configure your Kafka clusters directly through the UI.\n* **Multi-Cluster Management** ‚Äì Monitor and manage all your Kafka clusters in one unified interface.\n* **Metrics Dashboard** ‚Äì Track key Kafka metrics in real time with a streamlined, lightweight dashboard.\n* **Kafka Brokers Overview** ‚Äì Inspect brokers, including partition assignments and controller status.\n* **Consumer Group Details** ‚Äì Analyze parked offsets per partition, and monitor both combined and partition-specific lag.\n* **Message Browser** ‚Äì Explore messages in JSON, plain text, or Avro encoding formats. Live view is supported, enriched with user-defined CEL message filters.\n* **Dynamic Topic Management** ‚Äì Create and configure new topics with flexible, real-time settings.\n* **Pluggable Authentication** ‚Äì Secure your UI using OAuth 2.0 (GitHub, GitLab, Google), LDAP, or basic authentication.\n* **Cloud IAM Support** ‚Äì Integrate with **GCP IAM**, **Azure IAM**, and **AWS IAM** for cloud-native identity and access management.\n* **Managed Kafka Service Support** ‚Äì Full support for **Azure EventHub**, **Google Cloud Managed Service for Apache Kafka**, and **AWS Managed Streaming for Apache Kafka (MSK)**‚Äîboth server-based and serverless.\n* **Custom SerDe Plugin Support** ‚Äì Use built-in serializers/deserializers like AWS Glue and Smile, or create your own custom plugins.\n* **Role-Based Access Control** ‚Äì [Manage granular UI permissions](https://ui.docs.kafbat.io/configuration/rbac-role-based-access-control) with RBAC.\n* **Data Masking** ‚Äì [Obfuscate sensitive data](https://ui.docs.kafbat.io/configuration/data-masking) in topic messages to enhance privacy and compliance.\n* **MCP Server** - [Model Context Protocol](https://ui.docs.kafbat.io/faq/mcp) Server\n\n\n## Feature overview\n\n<details>\n    <summary>Click here for the feature overview</summary>\n\n# The Interface\nKafbat UI wraps major functions of Apache Kafka with an intuitive user interface.\n\n![Interface](documentation/images/Interface.gif)\n\n## Topics\nKafbat UI makes it easy for you to create topics in your browser with just a few clicks, by pasting your own parameters, and viewing topics in the list.\n\n![Create Topic](documentation/images/Create_topic_kafka-ui.gif)\n\nYou can jump from the connectors view to corresponding topics and from a topic to consumers (back and forth) for more convenient navigation, including connectors and overview topic settings.\n\n![Connector_Topic_Consumer](documentation/images/Connector_Topic_Consumer.gif)\n\n### Messages\nSuppose you want to produce messages for your topic. With Kafbat UI, you can easily send or write data/messages to Kafka topics by specifying parameters and viewing messages in the list.\n\n![Produce Message](documentation/images/Create_message_kafka-ui.gif)\n\n## Schema registry\nThere are three supported types of schemas: Avro¬Æ, JSON Schema, and Protobuf schemas.\n\n![Create Schema Registry](documentation/images/Create_schema.gif)\n\nBefore producing Avro/Protobuf encoded messages, you need to add a schema for the topic in the Schema Registry. All these steps are now easy to do with just a few clicks in a user-friendly interface.\n\n![Avro Schema Topic](documentation/images/Schema_Topic.gif)\n\n</details>\n\n# Getting Started\n\nTo run Kafbat UI, you can use either a pre-built Docker image or build it (or a jar file) yourself.\n\n## Quick start (Demo run)\n\n```bash\ndocker run -it -p 8080:8080 -e DYNAMIC_CONFIG_ENABLED=true ghcr.io/kafbat/kafka-ui\n```\n\nThen access the web UI at [http://localhost:8080](http://localhost:8080)\n\nThis command is sufficient to try things out. When you're done, you can proceed with a [persistent installation](https://ui.docs.kafbat.io/quick-start/persistent-start).\n\n## Persistent installation\n\n```yml\nservices:\n  kafbat-ui:\n    container_name: kafbat-ui\n    image: ghcr.io/kafbat/kafka-ui:latest\n    ports:\n      - 8080:8080\n    environment:\n      DYNAMIC_CONFIG_ENABLED: 'true'\n    volumes:\n      - ~/kui/config.yml:/etc/kafkaui/dynamic_config.yaml\n```\n\nPlease refer to our [configuration](https://ui.docs.kafbat.io/configuration/configuration-file) page to proceed with further app configuration.\n\n## Some useful configuration related links\n\n[Web UI Cluster Configuration Wizard](https://ui.docs.kafbat.io/configuration/configuration-wizard)\n\n[Configuration file explanation](https://ui.docs.kafbat.io/configuration/configuration-file)\n\n[Docker Compose examples](https://ui.docs.kafbat.io/configuration/compose-examples)\n\n[Misc configuration properties](https://ui.docs.kafbat.io/configuration/misc-configuration-properties)\n\n## Helm charts\n\n[Quick start](https://ui.docs.kafbat.io/configuration/helm-charts/quick-start)\n\n## Building from sources\n\n[Quick start](https://ui.docs.kafbat.io/development/building/prerequisites) for building from source\n\n## Liveliness and readiness probes\nThe liveness and readiness endpoint is at `/actuator/health`.<br/>\nThe info endpoint (build info) is located at `/actuator/info`.\n\n# Configuration options\n\nAll environment variables and configuration properties can be found [here](https://ui.docs.kafbat.io/configuration/misc-configuration-properties).\n\n# Contributing\n\nPlease refer to the [contributing guide](https://ui.docs.kafbat.io/development/contributing); we'll guide you from there.\n\n# Support\n\nAs we're fully independent, team members contribute in their free time.\nYour support is crucial for us, if you wish to sponsor us, take a look [here](https://github.com/sponsors/kafbat)\n\n# Powered by\n\n[![JetBrains logo.](https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg)](https://jb.gg/OpenSourceSupport)\n",
      "stars_today": 5
    },
    {
      "id": 1025940468,
      "name": "Wild_KSU",
      "full_name": "WildKernels/Wild_KSU",
      "description": "An advanced Kernel based root solution for Android",
      "html_url": "https://github.com/WildKernels/Wild_KSU",
      "stars": 247,
      "forks": 43,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2025-07-25T04:10:12Z",
      "updated_at": "2026-01-22T16:07:59Z",
      "pushed_at": "2026-01-23T00:55:45Z",
      "open_issues": 11,
      "owner": {
        "login": "WildKernels",
        "avatar_url": "https://avatars.githubusercontent.com/u/197178878?v=4"
      },
      "readme": "<div align=\"center\">\n  <img src=\"../assets/wksu.png\" width=\"120\" alt=\"Wild KSU Logo\">\n  \n  # Wild KSU\n  \n  **üî• A customization and root hiding focused fork üî•**\n  \n  > ‚ö†Ô∏è **IMPORTANT NOTICE**: This project is currently in testing mode. All releases should be considered unstable and may be unstable until version 1.0.0 is released. Use at your own risk.\n  \n  <p align=\"center\">\n    <a href=\"https://github.com/WildKernels/Wild_KSU/releases/latest\">\n      <img src=\"https://img.shields.io/github/v/release/WildKernels/Wild_KSU?label=Release&logo=github&style=for-the-badge&color=blue\" alt=\"Latest Release\">\n    </a>\n    <a href=\"https://nightly.link/WildKernels/Wild_KSU/workflows/build-manager-ci/wild/Manager\">\n      <img src=\"https://img.shields.io/badge/Nightly-Build-purple?logo=hackthebox&logoColor=fff&style=for-the-badge\" alt=\"Nightly Build\">\n    </a>\n  </p>\n  \n  <p align=\"center\">\n    <a href=\"https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html\">\n      <img src=\"https://img.shields.io/badge/License-GPL%20v2-orange.svg?logo=gnu&style=for-the-badge\" alt=\"GPL v2 License\">\n    </a>\n    <a href=\"https://www.gnu.org/licenses/gpl-3.0.en.html\">\n      <img src=\"https://img.shields.io/badge/License-GPL%20v3-red.svg?logo=gnu&style=for-the-badge\" alt=\"GPL v3 License\">\n    </a>\n  </p>\n  \n  <p align=\"center\">\n    <a href=\"https://crowdin.com/project/wild-ksu\">\n      <img src=\"https://img.shields.io/badge/Crowdin-Translate-green?logo=crowdin&logoColor=white&style=for-the-badge\" alt=\"Crowdin Translations\">\n    </a>\n  </p>\n  \n  ---\n  \n  ![cat](../assets/gray0_ctp_on_line.svg)\n  \n  ---\n  \n  ### üåç Languages & Translations\n  \n  **English** (Current)\n  \n  > üåê **Translation contributions are welcome!**  \n  > Help us make Wild KSU accessible to more users worldwide by contributing translations via:  \n  > - üìù **Pull Requests** - Submit translation files directly  \n  > - üîó **[Crowdin](https://crowdin.com/project/wild-ksu)** - Collaborative translation platform\n  \n</div>\n\n---\n\n## ‚ú® What is Wild KSU?\n\nWild KSU is a fork of KernelSU Next focused on customization and root hiding.\n\n**What is KernelSU?**\nKernelSU is a root solution for Android GKI devices, it works in kernel mode and grants root permission to userspace apps directly in kernel space.\n\n**Features**\nThe main feature of KernelSU is that it's kernel-based. KernelSU works in 2 modes:\n- **GKI**: Replace the original kernel of the device with the Generic Kernel Image (GKI) provided by KernelSU.\n- **LKM**: Load the Loadable Kernel Module (LKM) into the device kernel without replacing the original kernel.\n\nThese two modes are suitable for different scenarios, and you can choose the one according to your needs.\n\n---\n\n## üîß Kernel Integration / GKI Mode\n\n> üöÄ **Ready to integrate Wild KSU into your kernel?** \n> \n> Use our automated setup script to integrate Wild KSU into your kernel source:\n\n```bash\ncurl -LSs \"https://raw.githubusercontent.com/WildKernels/Wild_KSU/wild/kernel/setup.sh\" | bash -s wild\n```\n\n> üìã **Note:** This script will automatically configure your kernel source tree with Wild KSU support.\n\n### üìö Documentation\n\nFor detailed documentation, please refer to the original KernelSU project:\n\nüîó **[KernelSU Official Documentation](https://kernelsu.org/guide/what-is-kernelsu.html)**\n\nThis documentation covers installation procedures, usage guidelines, and technical details that apply to Wild KSU as well.\n\n---\n\n## ‚úÖ Compatibility Matrix\n\nWild KSU supports a wide range of Android kernel versions from **4.4 up to 6.6**:\n\n| üîß Kernel Version | üì± Support Level | üìù Implementation Notes |\n|-------------------|------------------|-------------------------|\n| **5.10+ (GKI 2.0)** | ‚úÖ **Full Support** | Pre-built images, LKM/KMI support |\n| **4.19 ‚Äì 5.4 (GKI 1.0)** | ‚úÖ **Supported** | Requires built-in KernelSU driver |\n| **< 4.14 (EOL)** | ‚ö†Ô∏è **Limited** | Requires driver (3.18+ experimental, may need backports) |\n\n### üèóÔ∏è **Supported Architectures**\n- `arm64-v8a` - 64-bit ARM\n- `armeabi-v7a` - 32-bit ARM\n- `x86_64` - 64-bit x86\n\n---\n\n## üîê Security & Reporting\n\nSecurity is our top priority. If you discover any security vulnerabilities or issues:\n\nüìã **Please review our [Security Policy](SECURITY.md)** for responsible disclosure guidelines.\n\n---\n\n## üìú License Information\n\nWild KSU is open-source software distributed under multiple licenses:\n\n| üìÅ **Directory** | ‚öñÔ∏è **License** |\n|------------------|----------------|\n| `/kernel` | [GPL-2.0-only](https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html) |\n| **All other files** | [GPL-3.0-or-later](https://www.gnu.org/licenses/gpl-3.0.html) |\n\n---\n\n## üíù Support the Project\n\nIf Wild KSU has been helpful to you, consider supporting our development efforts:\n\n### üí∞ **Donations**\n\n| üí± **Method** | üìç **Address/Link** |\n|---------------|--------------------|\n| **PayPal** | `bauhd@outlook.com` |\n| **Card** | [`https://buy.stripe.com/5kQ28sdi08Nr0Xc2fU5os00`](https://buy.stripe.com/5kQ28sdi08Nr0Xc2fU5os00) |\n| **LTC** | `MVaN1ToSuks2cdK9mB3M8EHCfzQSyEMf6h` |\n| **BTC** | `3BBXAMS4ZuCZwfbTXxWGczxHF4isymeyxG` |\n| **ETH** | `0x2b9C846c84d58717e784458406235C09a834274e` |\n\n> üí° **Support the original project:** For donations to KernelSU Next, visit [`https://github.com/KernelSU-Next/KernelSU-Next`](https://github.com/KernelSU-Next/KernelSU-Next)\n\n---\n\n## üôè Acknowledgments\n\nWild KSU stands on the shoulders of giants. We extend our gratitude to:\n\n- üöÄ **[KernelSU Next](https://github.com/KernelSU-Next/KernelSU-Next)** - The fork base that made Wild KSU possible\n- üåü **[KernelSU](https://github.com/tiann/KernelSU)** - The original foundational project\n\n---\n\n<div align=\"center\">\n  \n  ### üåü **Star this repository if Wild KSU helped you!** üåü\n  \n  **Made with ‚ù§Ô∏è by the Wild Kernels Team**\n  \n  ---\n  \n  [![GitHub stars](https://img.shields.io/github/stars/WildKernels/Wild_KSU?style=social)](https://github.com/WildKernels/Wild_KSU/stargazers)\n  [![GitHub forks](https://img.shields.io/github/forks/WildKernels/Wild_KSU?style=social)](https://github.com/WildKernels/Wild_KSU/network/members)\n  [![GitHub watchers](https://img.shields.io/github/watchers/WildKernels/Wild_KSU?style=social)](https://github.com/WildKernels/Wild_KSU/watchers)\n  \n  ![Stats](../assets/gray0_ctp_on_line.svg)\n  \n</div>\n",
      "stars_today": 5
    },
    {
      "id": 95189138,
      "name": "p3c",
      "full_name": "alibaba/p3c",
      "description": "Alibaba Java Coding Guidelines pmd implements and IDE plugin",
      "html_url": "https://github.com/alibaba/p3c",
      "stars": 30809,
      "forks": 8060,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2017-06-23T06:15:51Z",
      "updated_at": "2026-01-22T12:47:06Z",
      "pushed_at": "2024-08-06T08:22:02Z",
      "open_issues": 186,
      "owner": {
        "login": "alibaba",
        "avatar_url": "https://avatars.githubusercontent.com/u/1961952?v=4"
      },
      "readme": "# P3C\n\nÊúÄÊñ∞ÁâàÊú¨ÔºöÈªÑÂ±±ÁâàÔºà2022.2.3ÂèëÂ∏ÉÔºâ\n\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n\n## <font color=\"green\">Preface</font>\n> We are pleased to present Alibaba Java Coding Guidelines which consolidates the best programming practices over the years from Alibaba Group's technical teams. A vast number of Java programming teams impose demanding requirements on code quality across projects as we encourage reuse and better understanding of each other's programs. We have seen many programming problems in the past. For example, defective database table structures and index designs may cause software architecture flaws and performance risks. Another example is confusing code structures being difficult to maintain. Furthermore, vulnerable code without authentication is prone to hackers‚Äô attacks. To address these kinds of problems, we developed this document for Java developers at Alibaba.\n \nFor more information please refer the *Alibaba Java Coding Guidelines*:\n- ‰∏≠ÊñáÁâà: Áõ¥Êé•‰∏ãËΩΩ‰∏äÊñπÁöÑPDFÊñá‰ª∂ÔºàÈªÑÂ±±ÁâàÔºâ\n- English Version: *[Alibaba Java Coding Guidelines](https://alibaba.github.io/Alibaba-Java-Coding-Guidelines)*\n\n## <font color=\"green\">Introduction</font>\nThe project consists of 3 parts:  \n- [PMD implementations](p3c-pmd)  \n- [IntelliJ IDEA plugin](idea-plugin)  \n- [Eclipse plugin](eclipse-plugin)   \n\n## <font color=\"green\">Rules</font>\n<font color=\"blue\">Forty-nine rules are realized based on PMD, please refer the P3C-PMD documentation for more detailed information. Four rules are implemented within IDE plugins (IDEA and Eclipse) as follows:</font>  \n\n- ``[Mandatory]`` Using a deprecated class or method is prohibited.  \n   Note: For example, decode(String source, String encode) should be used instead of the deprecated method decode(String encodeStr). Once an interface has been deprecated, the interface provider has the obligation to provide a new one. At the same time, client programmers have the obligation to check out what its new implementation is.\n   \n- ``[Mandatory]`` An overridden method from an interface or abstract class must be marked with @Override annotation.\n   Counter example: For getObject() and get0bject(), the first one has a letter 'O', and the second one has a number '0'. To accurately determine whether the overriding is successful, an @Override annotation is necessary. Meanwhile, once the method signature in the abstract class is changed, the implementation class will report a compile-time error immediately.\n   \n- ``[Mandatory]`` A static field or method should be directly referred by its class name instead of its corresponding object name.\n\n- ``[Mandatory]`` The usage of hashCode and equals should follow:\n    1. Override hashCode if equals is overridden.\n    2. These two methods must be overridden for Set since they are used to ensure that no duplicate object will be inserted in Set.\n    3. These two methods must be overridden if self-defined object is used as the key of Map.\n   Note: String can be used as the key of Map since these two methods have been rewritten.\n\n",
      "stars_today": 4
    },
    {
      "id": 72891330,
      "name": "ingress-nginx",
      "full_name": "kubernetes/ingress-nginx",
      "description": "Ingress NGINX Controller for Kubernetes",
      "html_url": "https://github.com/kubernetes/ingress-nginx",
      "stars": 19275,
      "forks": 8506,
      "language": "Go",
      "topics": [
        "ingress-controller",
        "kubernetes",
        "nginx"
      ],
      "created_at": "2016-11-04T22:54:14Z",
      "updated_at": "2026-01-22T18:48:38Z",
      "pushed_at": "2026-01-22T21:43:26Z",
      "open_issues": 354,
      "owner": {
        "login": "kubernetes",
        "avatar_url": "https://avatars.githubusercontent.com/u/13629408?v=4"
      },
      "readme": "# Ingress NGINX Retirement\n\n## Retiring\n\n[What You Need to Know about Ingress NGINX Retirement](https://www.kubernetes.io/blog/2025/11/11/ingress-nginx-retirement/):\n\n* Best-effort maintenance will continue until March 2026.\n* Afterward, there will be no further releases, no bugfixes, and no updates to resolve any security vulnerabilities that may be discovered.\n* Existing deployments of Ingress NGINX will not be broken.\n  * Existing project artifacts such as Helm charts and container images will remain available.\n\n# Ingress NGINX Controller\n\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5691/badge)](https://bestpractices.coreinfrastructure.org/projects/5691)\n[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/ingress-nginx)](https://goreportcard.com/report/github.com/kubernetes/ingress-nginx)\n[![GitHub license](https://img.shields.io/github/license/kubernetes/ingress-nginx.svg)](https://github.com/kubernetes/ingress-nginx/blob/main/LICENSE)\n[![GitHub stars](https://img.shields.io/github/stars/kubernetes/ingress-nginx.svg)](https://github.com/kubernetes/ingress-nginx/stargazers)\n\n## Overview\n\ningress-nginx was an Ingress controller for Kubernetes using [NGINX](https://www.nginx.org/) as a reverse proxy and load\nbalancer.\n\n[Learn more about Ingress on the Kubernetes documentation site](https://kubernetes.io/docs/concepts/services-networking/ingress/).\n\n## Usage warnings\n\nIf you are not already using ingress-nginx, you should not be deploying it as it is [not being developed](#retiring). Instead you should identify a [Gateway API](https://gateway-api.sigs.k8s.io/guides/) implementation and use it.\n\nDo not use in multi-tenant Kubernetes production installations. This project assumes that users that can create Ingress objects are administrators of the cluster. See the [FAQ](https://kubernetes.github.io/ingress-nginx/faq/#faq) for more.\n\n## Troubleshooting\n\nIf you encounter issues, review the [troubleshooting docs](docs/troubleshooting.md),\n[search for an issue](https://github.com/kubernetes/ingress-nginx/issues), or talk to us on the\n[#ingress-nginx-users channel](https://kubernetes.slack.com/messages/ingress-nginx-users) on the Kubernetes Slack server.\n\n## Changelog\n\nSee [the list of releases](https://github.com/kubernetes/ingress-nginx/releases) for all changes.\nFor detailed changes for each release, please check the [changelog-$version.md](./changelog) file for the release version.\nFor detailed changes on the `ingress-nginx` helm chart, please check the changelog folder for a specific version.\n[CHANGELOG-$current-version.md](./charts/ingress-nginx/changelog) file.\n\n### Supported Versions table\n\nSupported versions for the ingress-nginx project mean that we have completed E2E tests, and they are passing for\nthe versions listed. Ingress-Nginx versions **may** work on older versions, but the project does not make that guarantee.\n\n| Supported | Ingress-NGINX version | k8s supported version         | Alpine Version | Nginx Version | Helm Chart Version |\n| :-------: | --------------------- | ----------------------------- | -------------- | ------------- | ------------------ |\n|    üîÑ     | **v1.14.1**           | 1.34, 1.33, 1.32, 1.31, 1.30  | 3.22.2         | 1.27.1        | 4.14.1             |\n|    üîÑ     | **v1.14.0**           | 1.34, 1.33, 1.32, 1.31, 1.30  | 3.22.2         | 1.27.1        | 4.14.0             |\n|    üîÑ     | **v1.13.5**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.2         | 1.27.1        | 4.13.5             |\n|    üîÑ     | **v1.13.4**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.2         | 1.27.1        | 4.13.4             |\n|    üîÑ     | **v1.13.3**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.1         | 1.27.1        | 4.13.3             |\n|    üîÑ     | **v1.13.2**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.1         | 1.27.1        | 4.13.2             |\n|    üîÑ     | **v1.13.1**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.1         | 1.27.1        | 4.13.1             |\n|    üîÑ     | **v1.13.0**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.0         | 1.27.1        | 4.13.0             |\n|           | v1.12.8               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.22.2         | 1.25.5        | 4.12.8             |\n|           | v1.12.7               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.22.1         | 1.25.5        | 4.12.7             |\n|           | v1.12.6               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.22.1         | 1.25.5        | 4.12.6             |\n|           | v1.12.5               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.22.1         | 1.25.5        | 4.12.5             |\n|           | v1.12.4               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.22.0         | 1.25.5        | 4.12.4             |\n|           | v1.12.3               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.21.3         | 1.25.5        | 4.12.3             |\n|           | v1.12.2               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.21.3         | 1.25.5        | 4.12.2             |\n|           | v1.12.1               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.21.3         | 1.25.5        | 4.12.1             |\n|           | v1.12.0               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.21.0         | 1.25.5        | 4.12.0             |\n|           | v1.12.0-beta.0        | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.20.3         | 1.25.5        | 4.12.0-beta.0      |\n|           | v1.11.8               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.22.0         | 1.25.5        | 4.11.8             |\n|           | v1.11.7               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.3         | 1.25.5        | 4.11.7             |\n|           | v1.11.6               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.3         | 1.25.5        | 4.11.6             |\n|           | v1.11.5               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.3         | 1.25.5        | 4.11.5             |\n|           | v1.11.4               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.0         | 1.25.5        | 4.11.4             |\n|           | v1.11.3               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.3         | 1.25.5        | 4.11.3             |\n|           | v1.11.2               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.11.2             |\n|           | v1.11.1               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.11.1             |\n|           | v1.11.0               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.11.0             |\n|           | v1.10.6               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.0         | 1.25.5        | 4.10.6             |\n|           | v1.10.5               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.3         | 1.25.5        | 4.10.5             |\n|           | v1.10.4               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.10.4             |\n|           | v1.10.3               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.10.3             |\n|           | v1.10.2               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.10.2             |\n|           | v1.10.1               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.19.1         | 1.25.3        | 4.10.1             |\n|           | v1.10.0               | 1.29, 1.28, 1.27, 1.26        | 3.19.1         | 1.25.3        | 4.10.0             |\n|           | v1.9.6                | 1.29, 1.28, 1.27, 1.26, 1.25  | 3.19.0         | 1.21.6        | 4.9.1              |\n|           | v1.9.5                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.9.0              |\n|           | v1.9.4                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.3              |\n|           | v1.9.3                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.*              |\n|           | v1.9.1                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.*              |\n|           | v1.9.0                | 1.28, 1.27, 1.26, 1.25        | 3.18.2         | 1.21.6        | 4.8.*              |\n|           | v1.8.4                | 1.27, 1.26, 1.25, 1.24        | 3.18.2         | 1.21.6        | 4.7.*              |\n|           | v1.7.1                | 1.27, 1.26, 1.25, 1.24        | 3.17.2         | 1.21.6        | 4.6.*              |\n|           | v1.6.4                | 1.26, 1.25, 1.24, 1.23        | 3.17.0         | 1.21.6        | 4.5.*              |\n|           | v1.5.1                | 1.25, 1.24, 1.23              | 3.16.2         | 1.21.6        | 4.4.*              |\n|           | v1.4.0                | 1.25, 1.24, 1.23, 1.22        | 3.16.2         | 1.19.10‚Ä†      | 4.3.0              |\n|           | v1.3.1                | 1.24, 1.23, 1.22, 1.21, 1.20  | 3.16.2         | 1.19.10‚Ä†      | 4.2.5              |\n\nSee [Updating NGINX-Ingress to use the stable Ingress API (July 26, 2021)](https://kubernetes.io/blog/2021/07/26/update-with-ingress-nginx/)\nto upgrade to the stable Ingress API before upgrading to Kubernetes 1.22.\n\n## Get Involved\n\nThanks for taking the time to join our community and start contributing!\n\n- This project adheres to the [Kubernetes Community Code of Conduct](https://git.k8s.io/community/code-of-conduct.md).\n  By participating in this project, you agree to abide by its terms.\n- **Contributing**: Documentation contributions are welcome.\n\n  - Read [`CONTRIBUTING.md`](CONTRIBUTING.md) for information about the workflow that we\n    expect and instructions on the developer certificate of origin that we require.\n  - Join our Kubernetes Slack channel for developer discussion : [#ingress-nginx-dev](https://kubernetes.slack.com/archives/C021E147ZA4).\n  - Submit GitHub issues for documentation problems.\n    - Please make sure to read the [Issue Reporting Checklist](https://github.com/kubernetes/ingress-nginx/blob/main/CONTRIBUTING.md#issue-reporting-guidelines) before opening an issue. Issues not conforming to the guidelines **may be closed immediately**.\n\n- **Support**:\n\n  - Join the [#ingress-nginx-users](https://kubernetes.slack.com/messages/CANQGM8BA/) channel inside the [Kubernetes Slack](http://slack.kubernetes.io/) to ask questions or get support from the maintainers and other users.\n  - The [GitHub issues](https://github.com/kubernetes/ingress-nginx/issues) in the repository are **exclusively** for bug reports and feature requests.\n\n## License\n\n[Apache License 2.0](https://github.com/kubernetes/ingress-nginx/blob/main/LICENSE)\n",
      "stars_today": 4
    },
    {
      "id": 924551,
      "name": "rabbitmq-server",
      "full_name": "rabbitmq/rabbitmq-server",
      "description": "Open source RabbitMQ: core server and tier 1 (built-in) plugins",
      "html_url": "https://github.com/rabbitmq/rabbitmq-server",
      "stars": 13417,
      "forks": 3988,
      "language": "JavaScript",
      "topics": [
        "amqp",
        "amqp-0-9-1",
        "amqp1-0",
        "message-broker",
        "messaging",
        "mqtt",
        "rabbitmq",
        "stomp",
        "streaming",
        "streams"
      ],
      "created_at": "2010-09-20T10:29:16Z",
      "updated_at": "2026-01-22T23:01:18Z",
      "pushed_at": "2026-01-22T20:09:24Z",
      "open_issues": 261,
      "owner": {
        "login": "rabbitmq",
        "avatar_url": "https://avatars.githubusercontent.com/u/96669?v=4"
      },
      "readme": "# RabbitMQ Server\n\n[![CI](https://github.com/rabbitmq/rabbitmq-server/actions/workflows/test-make.yaml/badge.svg)](https://github.com/rabbitmq/rabbitmq-server/actions/workflows/test-make.yaml)\n\n[RabbitMQ](https://rabbitmq.com) is a [feature rich](https://www.rabbitmq.com/docs),\nmulti-protocol messaging and streaming broker. It supports:\n\n * AMQP 1.0\n * AMQP 0-9-1\n * [RabbitMQ Stream Protocol](https://www.rabbitmq.com/docs/streams)\n * MQTT 3.1, 3.1.1, and 5.0\n * STOMP 1.0 through 1.2\n * [MQTT over WebSocket](https://www.rabbitmq.com/docs/web-mqtt)\n * [STOMP over WebSocket](https://www.rabbitmq.com/docs/web-stomp)\n * AMQP 1.0 over WebSocket (supported in [VMware Tanzu RabbitMQ](https://www.vmware.com/products/app-platform/tanzu-rabbitmq))\n\n\n## Installation\n\n * [Currently supported](https://www.rabbitmq.com/release-information) released series\n * [Installation guides](https://www.rabbitmq.com/docs/download) for various platforms\n * [Kubernetes Cluster Operator](https://www.rabbitmq.com/kubernetes/operator/operator-overview)\n * [Changelog](https://www.rabbitmq.com/release-information)\n * [Releases](https://github.com/rabbitmq/rabbitmq-server/releases) on GitHub\n * [Community Support Eligibility Policy](https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md)\n * [Supported Erlang versions](https://www.rabbitmq.com/docs/which-erlang)\n\n\n## Tutorials and Documentation\n\n * [RabbitMQ tutorials](https://www.rabbitmq.com/tutorials) and their [executable versions on GitHub](https://github.com/rabbitmq/rabbitmq-tutorials)\n * [Documentation guides](https://rabbitmq.com/docs/)\n * [RabbitMQ blog](https://blog.rabbitmq.com/)\n\nSome key doc guides include\n\n * [CLI tools guide](https://www.rabbitmq.com/docs/cli)\n * [Clustering](https://www.rabbitmq.com/docs/clustering) and [Cluster Formation](https://www.rabbitmq.com/docs/cluster-formation)\n * [Configuration guide](https://www.rabbitmq.com/docs/configure)\n * [Client libraries and tools](https://www.rabbitmq.com/client-libraries/devtools)\n * [Monitoring](https://www.rabbitmq.com/docs/monitoring) and [Prometheus/Grafana](https://www.rabbitmq.com/docs/prometheus)\n * [Upgrading](https://www.rabbitmq.com/docs/upgrade)\n * [Kubernetes Cluster Operator](https://www.rabbitmq.com/kubernetes/operator/operator-overview)\n * [Production checklist](https://www.rabbitmq.com/docs/production-checklist)\n * [Quorum queues](https://www.rabbitmq.com/docs/quorum-queues): a replicated, data safety- and consistency-oriented queue type\n * [Streams](https://www.rabbitmq.com/docs/streams): a persistent and replicated append-only log with non-destructive consumer semantics\n * [Runtime Parameters and Policies](https://www.rabbitmq.com/docs/parameters)\n * [Runnable tutorials](https://github.com/rabbitmq/rabbitmq-tutorials/)\n\nRabbitMQ documentation is also [developed on GitHub](https://github.com/rabbitmq/rabbitmq-website/).\n\n## Commercial Features and Support\n\n * [Commercial editions of RabbitMQ](https://tanzu.vmware.com/rabbitmq)\n * [Commercial edition for Kubernetes](https://docs.vmware.com/en/VMware-RabbitMQ-for-Kubernetes/1/rmq/installation.html)\n * [Commercial support](https://tanzu.vmware.com/rabbitmq/oss) from [Broadcom](https://vmware.com) for open source RabbitMQ\n\n## Getting Help from the Community\n\nPlease read the [Community Support Eligibility Policy](https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md) document\nfirst.\n\nThe recommended community forums are\n\n * [GitHub Discussions](https://github.com/rabbitmq/rabbitmq-server/discussions/)\n * [Community Discord server](https://rabbitmq.com/discord/)\n * `#rabbitmq` on [Libera Chat](https://libera.chat/)\n\n\n## Contributing\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) and our [development process overview](https://www.rabbitmq.com/github).\n\nQuestions about contributing, internals and so on are very welcome in [GitHub Discussions](https://github.com/rabbitmq/rabbitmq-server/discussions)\nor [community Discord server](https://www.rabbitmq.com/discord/) in the `contributors` channel.\n\n\n## Licensing\n\nRabbitMQ server is [licensed under the MPL 2.0](LICENSE-MPL-RabbitMQ).\n\n[Community Support Eligibility Policy](https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md)\ndocument explains the open source RabbitMQ support policy adopted by the RabbitMQ Core Team.\n\n\n## AI Agent Instructions\n\nSee `AGENTS.md`.\n\n\n## Building From Source and Packaging\n\n * [Contributor resources](https://github.com/rabbitmq/contribute)\n * [Building RabbitMQ from Source](https://www.rabbitmq.com/docs/build-server)\n * [Building RabbitMQ Distribution Packages](https://www.rabbitmq.com/docs/build-server)\n\n\n## Copyright\n\n(c) 2007-2026 Broadcom. All Rights Reserved. The term ‚ÄúBroadcom‚Äù refers to Broadcom Inc. and/or its subsidiaries.\n",
      "stars_today": 4
    },
    {
      "id": 97716052,
      "name": "XcodeGen",
      "full_name": "yonaskolb/XcodeGen",
      "description": "A Swift command line tool for generating your Xcode project",
      "html_url": "https://github.com/yonaskolb/XcodeGen",
      "stars": 8018,
      "forks": 870,
      "language": "Swift",
      "topics": [
        "ci",
        "cli",
        "generator",
        "specification",
        "swift",
        "xcode",
        "xcodeproj",
        "xcodeproject",
        "yaml"
      ],
      "created_at": "2017-07-19T12:56:04Z",
      "updated_at": "2026-01-22T23:39:48Z",
      "pushed_at": "2025-07-25T03:27:54Z",
      "open_issues": 388,
      "owner": {
        "login": "yonaskolb",
        "avatar_url": "https://avatars.githubusercontent.com/u/2393781?v=4"
      },
      "readme": "<p align=\"center\">\n<a href=\"https://github.com/yonaskolb/XcodeGen\">\n<img src=\"Assets/Logo_animated.gif\" alt=\"XcodeGen\" />\n</a>\n</p>\n<p align=\"center\">\n  <a href=\"https://github.com/yonaskolb/XcodeGen/releases\">\n    <img src=\"https://img.shields.io/github/release/yonaskolb/xcodegen.svg\"/>\n  </a>\n  <a href=\"https://swiftpackageindex.com/yonaskolb/XcodeGen\">\n    <img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fyonaskolb%2FXcodeGen%2Fbadge%3Ftype%3Dplatforms\" alt=\"Swift Package Manager Platforms\" />\n  </a>\n  <a href=\"https://swiftpackageindex.com/yonaskolb/XcodeGen\">\n    <img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fyonaskolb%2FXcodeGen%2Fbadge%3Ftype%3Dswift-versions\" alt=\"Swift Versions\" />\n  </a>\n  <a href=\"https://github.com/yonaskolb/XcodeGen/blob/master/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/yonaskolb/XcodeGen.svg\"/>\n  </a>\n</p>\n\n# XcodeGen\n\nXcodeGen is a command line tool written in Swift that generates your Xcode project using your folder structure and a project spec.\n\nThe project spec is a YAML or JSON file that defines your targets, configurations, schemes, custom build settings and many other options. All your source directories are automatically parsed and referenced appropriately while preserving your folder structure. Sensible defaults are used in many places, so you only need to customize what is needed. Very complex projects can also be defined using more advanced features.\n\n- ‚úÖ Generate projects on demand and remove your `.xcodeproj` from git, which means **no more merge conflicts**!\n- ‚úÖ Groups and files in Xcode are always **synced** to your directories on disk\n- ‚úÖ Easy **configuration** of projects which is human readable and git friendly\n- ‚úÖ Easily copy and paste **files and directories** without having to edit anything in Xcode\n- ‚úÖ Share build settings across multiple targets with **build setting groups**\n- ‚úÖ Automatically generate Schemes for **different environments** like test and production\n- ‚úÖ Easily **create new projects** with complicated setups on demand without messing around with Xcode\n- ‚úÖ Generate from anywhere including on **CI**\n- ‚úÖ Distribute your spec amongst multiple files for easy **sharing** and overriding\n- ‚úÖ Easily create **multi-platform** frameworks\n- ‚úÖ Integrate **Carthage** frameworks without any work\n\nGiven an example project spec:\n\n```yaml\nname: MyProject\ninclude:\n  - base_spec.yml\noptions:\n  bundleIdPrefix: com.myapp\npackages:\n  Yams:\n    url: https://github.com/jpsim/Yams\n    from: 2.0.0\ntargets:\n  MyApp:\n    type: application\n    platform: iOS\n    deploymentTarget: \"10.0\"\n    sources: [MyApp]\n    settings:\n      configs:\n        debug:\n          CUSTOM_BUILD_SETTING: my_debug_value\n        release:\n          CUSTOM_BUILD_SETTING: my_release_value\n    dependencies:\n      - target: MyFramework\n      - carthage: Alamofire\n      - framework: Vendor/MyFramework.framework\n      - sdk: Contacts.framework\n      - sdk: libc++.tbd\n      - package: Yams\n  MyFramework:\n    type: framework\n    platform: iOS\n    sources: [MyFramework]\n```\nA project would be created with 2 connected targets, with all the required configurations and build settings. See the [Project Spec](Docs/ProjectSpec.md) documentation for all the options you can specify, and [Usage](Docs/Usage.md) for more general documentation.\n\n## Installing\n\nMake sure the latest stable (non-beta) version of Xcode is installed first.\n\n### [Mint](https://github.com/yonaskolb/mint)\n```sh\nmint install yonaskolb/xcodegen\n```\n\n### Make\n\n```shell\ngit clone https://github.com/yonaskolb/XcodeGen.git\ncd XcodeGen\nmake install\n```\n\n### Homebrew\n\n```shell\nbrew install xcodegen\n```\n\n### Swift Package Manager\n\n**Use as CLI**\n\n```shell\ngit clone https://github.com/yonaskolb/XcodeGen.git\ncd XcodeGen\nswift run xcodegen\n```\n\n**Use as dependency**\n\nAdd the following to your Package.swift file's dependencies:\n\n```swift\n.package(url: \"https://github.com/yonaskolb/XcodeGen.git\", from: \"2.44.1\"),\n```\n\nAnd then import wherever needed: `import XcodeGenKit`\n\n## Usage\n\nSimply run:\n\n```shell\nxcodegen generate\n```\n\nThis will look for a project spec in the current directory called `project.yml` and generate an Xcode project with the name defined in the spec.\n\nOptions:\n\n- **--spec**: An optional path to a `.yml` or `.json` project spec. Defaults to `project.yml`. (It is also possible to link to multiple spec files by comma separating them. Note that all other flags will be the same.)\n- **--project**: An optional path to a directory where the project will be generated. By default this is the directory the spec lives in.\n- **--quiet**: Suppress informational and success messages.\n- **--use-cache**: Used to prevent unnecessarily generating the project. If this is set, then a cache file will be written to when a project is generated. If `xcodegen` is later run but the spec and all the files it contains are the same, the project won't be generated.\n- **--cache-path**: A custom path to use for your cache file. This defaults to `~/.xcodegen/cache/{PROJECT_SPEC_PATH_HASH}`\n\nThere are other commands as well such as `xcodegen dump` which lets one output the resolved spec in many different formats, or write it to a file. Use `xcodegen help` to see more detailed usage information.\n\n## Editing\n```shell\ngit clone https://github.com/yonaskolb/XcodeGen.git\ncd XcodeGen\nswift package generate-xcodeproj\n```\nThis uses Swift Package Manager to create an `xcodeproj` file that you can open, edit and run in Xcode, which makes editing any code easier.\n\nIf you want to pass any required arguments when running in Xcode, you can edit the scheme to include launch arguments.\n\n## Documentation\n- See [Project Spec](Docs/ProjectSpec.md) documentation for all the various properties and options that can be set\n- See [Usage](Docs/Usage.md) for more specific usage and use case documentation\n- See [FAQ](Docs/FAQ.md) for a list of some frequently asked questions\n- See [Examples](Docs/Examples.md) for some real world XcodeGen project specs out in the wild\n\n## Alternatives\nIf XcodeGen doesn't meet your needs try these great alternatives:\n- [Tuist](https://github.com/tuist/tuist)\n- [Xcake](https://github.com/igor-makarov/xcake)\n- [struct](https://github.com/workshop/struct)\n\n## Attributions\nThis tool is powered by:\n\n- [XcodeProj](https://github.com/tuist/XcodeProj)\n- [JSONUtilities](https://github.com/yonaskolb/JSONUtilities)\n- [Spectre](https://github.com/kylef/Spectre)\n- [PathKit](https://github.com/kylef/PathKit)\n- [Yams](https://github.com/jpsim/Yams)\n- [SwiftCLI](https://github.com/jakeheis/SwiftCLI)\n\nInspiration for this tool came from:\n\n- [struct](https://github.com/workshop/struct)\n- [Xcake](https://github.com/igor-makarov/xcake)\n- [CocoaPods Xcodeproj](https://github.com/CocoaPods/Xcodeproj)\n\n## Contributions\nPull requests and issues are always welcome. Please open any issues and PRs for bugs, features, or documentation.\n\n[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/0)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/0)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/1)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/1)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/2)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/2)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/3)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/3)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/4)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/4)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/5)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/5)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/6)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/6)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/7)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/7)\n\n## License\n\nXcodeGen is licensed under the MIT license. See [LICENSE](LICENSE) for more info.\n",
      "stars_today": 4
    },
    {
      "id": 740710728,
      "name": "extensions-source",
      "full_name": "keiyoushi/extensions-source",
      "description": "Source code of extensions in https://github.com/keiyoushi/extensions",
      "html_url": "https://github.com/keiyoushi/extensions-source",
      "stars": 3617,
      "forks": 1061,
      "language": "Kotlin",
      "topics": [
        "android",
        "hacktoberfest",
        "kotlin",
        "mihon",
        "tachiyomi"
      ],
      "created_at": "2024-01-08T22:47:46Z",
      "updated_at": "2026-01-23T00:43:27Z",
      "pushed_at": "2026-01-22T05:38:26Z",
      "open_issues": 778,
      "owner": {
        "login": "keiyoushi",
        "avatar_url": "https://avatars.githubusercontent.com/u/113362897?v=4"
      },
      "readme": "# Keiyoushi Extensions\n\n### Please give the repo a :star:\n\n| Build                                                                                                                                                                               | Need Help?                                                                                                                                              |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [![CI](https://github.com/keiyoushi/extensions-source/actions/workflows/build_push.yml/badge.svg)](https://github.com/keiyoushi/extensions-source/actions/workflows/build_push.yml) | [![Discord](https://img.shields.io/discord/1193460528052453448.svg?label=discord&labelColor=7289da&color=2c2f33&style=flat)](https://discord.gg/3FbCpdKbdY) |\n\n## Usage\n**If you are new to repository/extensions, please read the [Keiyoushi Getting Started guide](https://keiyoushi.github.io/docs/guides/getting-started#adding-the-extension-repo) first.**\n\n* You can add our repo by visiting the [Keiyoushi Website](https://keiyoushi.github.io/add-repo)\n* Otherwise, copy & paste the following URL: https://raw.githubusercontent.com/keiyoushi/extensions/repo/index.min.json\n\n## Requests\n\nTo request a new source or bug fix, [create an issue](https://github.com/keiyoushi/extensions-source/issues/new/choose).\n\nPlease note that creating an issue does not mean that the source will be added or fixed in a timely\nfashion, because the work is volunteer-based. Some sources may also be impossible to do or prohibitively\ndifficult to maintain.\n\nIf you would like to see a request fulfilled and have the necessary skills to do so, consider contributing!\nIssues are up-for-grabs for any developer if there is no assigned user already.\n\n## Contributing\n\nContributions are welcome!\n\nCheck out the repo's [issue backlog](https://github.com/keiyoushi/extensions-source/issues) for source requests and bug reports.\n\n## License\n\n    Copyright 2015 Javier Tom√°s\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n\n## Disclaimer\n\nThis project does not have any affiliation with the content providers available.\n\nThis project is not affiliated with Mihon/Tachiyomi. Don't ask for help about these extensions at the\nofficial support means of Mihon/Tachiyomi. All credits to the codebase goes to the original contributors.\n",
      "stars_today": 4
    },
    {
      "id": 976095156,
      "name": "koog",
      "full_name": "JetBrains/koog",
      "description": "Koog is the official Kotlin framework for building predictable, fault-tolerant and enterprise-ready AI agents across all platforms ‚Äì from backend services to Android and iOS, JVM, and even in-browser environments. Koog is based on our AI products expertise and provides proven solutions for complex LLM and AI problems",
      "html_url": "https://github.com/JetBrains/koog",
      "stars": 3648,
      "forks": 301,
      "language": "Kotlin",
      "topics": [
        "agentframework",
        "agentic-ai",
        "agents",
        "ai",
        "ai-agents-framework",
        "aiagentframework",
        "android-ai",
        "anthropic",
        "genai",
        "generative-ai",
        "java",
        "jvm",
        "kotlin",
        "ktor",
        "llm",
        "mcp",
        "multi-agent-systems",
        "ollama",
        "openai",
        "spring"
      ],
      "created_at": "2025-05-01T13:38:01Z",
      "updated_at": "2026-01-22T22:06:51Z",
      "pushed_at": "2026-01-22T20:05:35Z",
      "open_issues": 200,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "# Koog\n\n[![Kotlin Alpha](https://kotl.in/badges/alpha.svg)](https://kotlinlang.org/docs/components-stability.html)\n[![Maven Central](https://img.shields.io/maven-central/v/ai.koog/koog-agents)](https://search.maven.org/artifact/ai.koog/koog-agents)\n[![JetBrains incubator project](https://jb.gg/badges/incubator.svg)](https://github.com/JetBrains#jetbrains-on-github)\n[![Kotlin](https://img.shields.io/badge/kotlin-2.2-blue.svg?logo=kotlin)](http://kotlinlang.org)\n[![CI status](https://img.shields.io/github/checks-status/JetBrains/koog/main)](https://github.com/JetBrains/koog/actions?query=branch%3Amain)\n[![GitHub license](https://img.shields.io/github/license/JetBrains/koog)](LICENSE.txt)\n\nBuild status:\n\n[![Checks](https://github.com/JetBrains/koog/actions/workflows/checks.yml/badge.svg?branch=develop)](https://github.com/JetBrains/koog/actions/workflows/checks.yml?query=branch%3Adevelop)\n[![Heavy Tests](https://github.com/JetBrains/koog/actions/workflows/heavy-tests.yml/badge.svg?branch=develop)](https://github.com/JetBrains/koog/actions/workflows/heavy-tests.yml?query=branch%3Adevelop)\n[![Ollama Tests](https://github.com/JetBrains/koog/actions/workflows/ollama-tests.yml/badge.svg?branch=develop)](https://github.com/JetBrains/koog/actions/workflows/ollama-tests.yml?query=branch%3Adevelop)\n\nUseful links:\n\n* [Documentation](https://docs.koog.ai/)\n* [API reference](https://api.koog.ai/)\n* [Slack channel](https://docs.koog.ai/koog-slack-channel/)\n* [Issue tracker](https://youtrack.jetbrains.com/issues/KG)\n\n## Overview\n\nKoog is a Kotlin-based framework designed to build and run AI agents entirely in idiomatic Kotlin. It lets you create agents that can interact with tools, handle complex workflows, and communicate with users.\n\n### Key features\n\nKey features of Koog include:\n\n- **Multiplatform development**: Deploy agents across JVM, JS, WasmJS, Android, and iOS targets using Kotlin Multiplatform.\n- **Reliability and fault-tolerance**: Handle failures with built-in retries and restore the agent state at specific points during execution with the agent persistence feature.\n- **Intelligent history compression**: Optimize token usage while maintaining context in long-running conversations using advanced built-in history compression techniques.\n- **Enterprise-ready integrations**: Utilize integration with popular JVM frameworks such as Spring Boot and Ktor to embed Koog into your applications.\n- **Observability with OpenTelemetry exporters**: Monitor and debug applications with built-in support for popular observability providers (W&B Weave, Langfuse).\n- **LLM switching and seamless history adaptation**: Switch to a different LLM at any point without losing the existing conversation history, or reroute between multiple LLM providers.\n- **Integration with JVM and Kotlin applications**: Build AI agents with an idiomatic, type-safe Kotlin DSL designed specifically for JVM and Kotlin developers.\n- **Model Context Protocol integration**: Use Model Context Protocol (MCP) tools in AI agents.\n- **Agent Client Protocol integration**: Build ACP-compliant agents that can communicate with standardized client applications using the Agent Client Protocol (ACP).\n- **Knowledge retrieval and memory**: Retain and retrieve knowledge across conversations using vector embeddings, ranked document storage, and shared agent memory.\n- **Powerful Streaming API**: Process responses in real-time with streaming support and parallel tool calls.\n- **Modular feature system**: Customize agent capabilities through a composable architecture.\n- **Flexible graph workflows**: Design complex agent behaviors using intuitive graph-based workflows.\n- **Custom tool creation**: Enhance your agents with tools that access external systems and APIs.\n- **Comprehensive tracing**: Debug and monitor agent execution with detailed, configurable tracing.\n\n### Available LLM providers and platforms\n\nThe LLM providers and platforms whose LLMs you can use to power your agent capabilities:\n\n- Google\n- OpenAI\n- Anthropic\n- DeepSeek\n- OpenRouter\n- Ollama\n- Bedrock\n\n### Quickstart example\n\nTo help you get started with AI agents, here is a quick example:\n\n```kotlin\nfun main() = runBlocking {\n    // Before you run the example, assign a corresponding API key as an environment variable.\n   val apiKey = System.getenv(\"OPENAI_API_KEY\") // or Anthropic, Google, OpenRouter, etc.\n\n   val agent = AIAgent(\n      promptExecutor = simpleOpenAIExecutor(apiKey), // or Anthropic, Google, OpenRouter, etc.\n      systemPrompt = \"You are a helpful assistant. Answer user questions concisely.\",\n      llmModel = OpenAIModels.Chat.GPT4o\n   )\n\n   val result = agent.run(\"Hello! How can you help me?\")\n   println(result)\n}\n```\n\n## Using in your projects\n\n### Supported targets\n\nCurrently, the framework supports the JVM, JS, WasmJS and iOS targets.\n\n### Requirements\n\n- JDK 17 or higher is required to use the framework on JVM.\n- kotlinx-coroutines 1.10.2 and kotlinx-serialization 1.8.1 versions should be set explicitly in existing projects. Please check the [libs.versions.toml](gradle/libs.versions.toml) to know more about the Koog dependencies.\n\n### Gradle (Kotlin DSL)\n\n1. Add dependencies to the `build.gradle.kts` file:\n\n    ```\n    dependencies {\n        implementation(\"ai.koog:koog-agents:0.6.0\")\n    }\n    ```\n2. Make sure that you have `mavenCentral()` in the list of repositories.\n### Gradle (Groovy)\n\n1. Add dependencies to the `build.gradle` file:\n\n    ```\n    dependencies {\n        implementation 'ai.koog:koog-agents:0.6.0'\n    }\n    ```\n2. Make sure that you have `mavenCentral()` in the list of repositories.\n### Maven\n\n1. Add dependencies to the `pom.xml` file:\n\n    ```\n    <dependency>\n        <groupId>ai.koog</groupId>\n        <artifactId>koog-agents-jvm</artifactId>\n        <version>0.6.0</version>\n    </dependency>\n    ```\n2. Make sure that you have `mavenCentral` in the list of repositories.\n## Contributing\nRead the [Contributing Guidelines](CONTRIBUTING.md).\n\n## Code of Conduct\nThis project and the corresponding community are governed by the [JetBrains Open Source and Community Code of Conduct](https://github.com/jetbrains#code-of-conduct). Please make sure you read it.\n\n## License\nKoog is licensed under the [Apache 2.0 License](LICENSE.txt).\n\n## Support\n\nPlease feel free to ask any questions in our [official Slack\nchannel](https://docs.koog.ai/koog-slack-channel/) and to\nuse [Koog official YouTrack project](https://youtrack.jetbrains.com/issues/KG)\nfor filing feature requests and bug reports.\n\n\n",
      "stars_today": 4
    },
    {
      "id": 663996831,
      "name": "NeoForge",
      "full_name": "neoforged/NeoForge",
      "description": "Neo Modding API for Minecraft: Java Edition, based on Forge",
      "html_url": "https://github.com/neoforged/NeoForge",
      "stars": 1775,
      "forks": 281,
      "language": "Java",
      "topics": [
        "hacktoberfest",
        "minecraft",
        "modding-api",
        "neoforge",
        "renovated"
      ],
      "created_at": "2023-07-08T16:30:30Z",
      "updated_at": "2026-01-22T17:23:15Z",
      "pushed_at": "2026-01-22T18:29:57Z",
      "open_issues": 141,
      "owner": {
        "login": "neoforged",
        "avatar_url": "https://avatars.githubusercontent.com/u/138629134?v=4"
      },
      "readme": "![NeoForged Logo](./assets/neoforged_logo.png)\n\nNeoForge\n=============\n[![Discord](https://img.shields.io/discord/313125603924639766.svg?color=%237289da&label=Discord&logo=discord&logoColor=%237289da)][Discord] \n\n\nNeoForge is a free, open-source, community-oriented modding API for Minecraft.\n\n| Version | Support |\n|---------|---------|\n| 1.21.x  | Active  |\n\n* [Download]\n* [Discord]\n* [Documentation]\n\n## Installing NeoForge\n\nGo to the [Download] page, select the Minecraft version and installer, and run it.\nThe installer will attempt to install NeoForge into your vanilla launcher environment,\nwhere you can then create a new profile using that version and play the game!\n \nFor support and questions, visit [the NeoForged Discord server][Discord].\n\n## Creating Mods\n\n[See the \"Getting Started\" section in the NeoForged Documentation][Getting-Started].\n\n## Contribute to NeoForge\n\nIf you wish to actually inspect NeoForge, submit PRs or otherwise work\nwith NeoForge itself, you're in the right place!\n\nCheck the [contribution workflow][Contributing] for details.\n\n### Translations\n\nTranslations are done on [Crowdin][Crowdin].\n\n### Pull requests\n\nPlease read the contributing guidelines found [here][Contributing] before making a pull request.\n\n### Contributor License Agreement\nWe require all contributors to acknowledge the [NeoForged Contributor License Agreement][CLA]. \nPlease ensure you have a valid email address associated with your GitHub account to do this. If you have previously \n signed it, you should be OK.\n\n[CLA]: https://cla-assistant.io/neoforged/NeoForge\n[Crowdin]: https://crowdin.neoforged.net/neoforge\n[Contributing]: ../docs/CONTRIBUTING.md\n[Discord]: https://discord.neoforged.net/\n[Documentation]: https://docs.neoforged.net/\n[Download]: https://neoforged.net/\n[Getting-Started]: https://docs.neoforged.net/docs/gettingstarted/\n",
      "stars_today": 4
    },
    {
      "id": 881501535,
      "name": "openai-java",
      "full_name": "openai/openai-java",
      "description": "The official Java library for the OpenAI API",
      "html_url": "https://github.com/openai/openai-java",
      "stars": 1311,
      "forks": 195,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2024-10-31T17:42:57Z",
      "updated_at": "2026-01-22T03:31:03Z",
      "pushed_at": "2026-01-22T23:06:56Z",
      "open_issues": 49,
      "owner": {
        "login": "openai",
        "avatar_url": "https://avatars.githubusercontent.com/u/14957082?v=4"
      },
      "readme": "# OpenAI Java API Library\n\n<!-- x-release-please-start-version -->\n\n[![Maven Central](https://img.shields.io/maven-central/v/com.openai/openai-java)](https://central.sonatype.com/artifact/com.openai/openai-java/4.16.0)\n[![javadoc](https://javadoc.io/badge2/com.openai/openai-java/4.16.0/javadoc.svg)](https://javadoc.io/doc/com.openai/openai-java/4.16.0)\n\n<!-- x-release-please-end -->\n\nThe OpenAI Java SDK provides convenient access to the [OpenAI REST API](https://platform.openai.com/docs) from applications written in Java.\n\n<!-- x-release-please-start-version -->\n\nThe REST API documentation can be found on [platform.openai.com](https://platform.openai.com/docs). Javadocs are available on [javadoc.io](https://javadoc.io/doc/com.openai/openai-java/4.16.0).\n\n<!-- x-release-please-end -->\n\n## Installation\n\n<!-- x-release-please-start-version -->\n\n[_Try `openai-java-spring-boot-starter` if you're using Spring Boot!_](#spring-boot)\n\n### Gradle\n\n```kotlin\nimplementation(\"com.openai:openai-java:4.16.0\")\n```\n\n### Maven\n\n```xml\n<dependency>\n  <groupId>com.openai</groupId>\n  <artifactId>openai-java</artifactId>\n  <version>4.16.0</version>\n</dependency>\n```\n\n<!-- x-release-please-end -->\n\n## Requirements\n\nThis library requires Java 8 or later.\n\n## Usage\n\n> [!TIP]\n> See the [`openai-java-example`](openai-java-example/src/main/java/com/openai/example) directory for complete and runnable examples!\n\nThe primary API for interacting with OpenAI models is the [Responses API](https://platform.openai.com/docs/api-reference/responses). You can generate text from the model with the code below.\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.ChatModel;\nimport com.openai.models.responses.Response;\nimport com.openai.models.responses.ResponseCreateParams;\n\n// Configures using the `OPENAI_API_KEY`, `OPENAI_ORG_ID` and `OPENAI_PROJECT_ID` environment variables\nOpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\nResponseCreateParams params = ResponseCreateParams.builder()\n        .input(\"Say this is a test\")\n        .model(ChatModel.GPT_4_1)\n        .build();\nResponse response = client.responses().create(params);\n```\n\nThe previous standard (supported indefinitely) for generating text is the [Chat Completions API](https://platform.openai.com/docs/api-reference/chat). You can use that API to generate text from the model with the code below.\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.ChatModel;\nimport com.openai.models.chat.completions.ChatCompletion;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\n\n// Configures using the `openai.apiKey`, `openai.orgId`, `openai.projectId`, `openai.webhookSecret` and `openai.baseUrl` system properties\n// Or configures using the `OPENAI_API_KEY`, `OPENAI_ORG_ID`, `OPENAI_PROJECT_ID`, `OPENAI_WEBHOOK_SECRET` and `OPENAI_BASE_URL` environment variables\nOpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\nChatCompletionCreateParams params = ChatCompletionCreateParams.builder()\n    .addUserMessage(\"Say this is a test\")\n    .model(ChatModel.GPT_4O)\n    .build();\nChatCompletion chatCompletion = client.chat().completions().create(params);\n```\n\n## Client configuration\n\nConfigure the client using system properties or environment variables:\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\n\n// Configures using the `openai.apiKey`, `openai.orgId`, `openai.projectId`, `openai.webhookSecret` and `openai.baseUrl` system properties\n// Or configures using the `OPENAI_API_KEY`, `OPENAI_ORG_ID`, `OPENAI_PROJECT_ID`, `OPENAI_WEBHOOK_SECRET` and `OPENAI_BASE_URL` environment variables\nOpenAIClient client = OpenAIOkHttpClient.fromEnv();\n```\n\nOr manually:\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\n\nOpenAIClient client = OpenAIOkHttpClient.builder()\n    .apiKey(\"My API Key\")\n    .build();\n```\n\nOr using a combination of the two approaches:\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\n\nOpenAIClient client = OpenAIOkHttpClient.builder()\n    // Configures using the `openai.apiKey`, `openai.orgId`, `openai.projectId`, `openai.webhookSecret` and `openai.baseUrl` system properties\n    // Or configures using the `OPENAI_API_KEY`, `OPENAI_ORG_ID`, `OPENAI_PROJECT_ID`, `OPENAI_WEBHOOK_SECRET` and `OPENAI_BASE_URL` environment variables\n    .fromEnv()\n    .apiKey(\"My API Key\")\n    .build();\n```\n\nSee this table for the available options:\n\n| Setter          | System property        | Environment variable    | Required | Default value                 |\n| --------------- | ---------------------- | ----------------------- | -------- | ----------------------------- |\n| `apiKey`        | `openai.apiKey`        | `OPENAI_API_KEY`        | true     | -                             |\n| `organization`  | `openai.orgId`         | `OPENAI_ORG_ID`         | false    | -                             |\n| `project`       | `openai.projectId`     | `OPENAI_PROJECT_ID`     | false    | -                             |\n| `webhookSecret` | `openai.webhookSecret` | `OPENAI_WEBHOOK_SECRET` | false    | -                             |\n| `baseUrl`       | `openai.baseUrl`       | `OPENAI_BASE_URL`       | true     | `\"https://api.openai.com/v1\"` |\n\nSystem properties take precedence over environment variables.\n\n> [!TIP]\n> Don't create more than one client in the same application. Each client has a connection pool and\n> thread pools, which are more efficient to share between requests.\n\n### Modifying configuration\n\nTo temporarily use a modified client configuration, while reusing the same connection and thread pools, call `withOptions()` on any client or service:\n\n```java\nimport com.openai.client.OpenAIClient;\n\nOpenAIClient clientWithOptions = client.withOptions(optionsBuilder -> {\n    optionsBuilder.baseUrl(\"https://example.com\");\n    optionsBuilder.maxRetries(42);\n});\n```\n\nThe `withOptions()` method does not affect the original client or service.\n\n## Requests and responses\n\nTo send a request to the OpenAI API, build an instance of some `Params` class and pass it to the corresponding client method. When the response is received, it will be deserialized into an instance of a Java class.\n\nFor example, `client.chat().completions().create(...)` should be called with an instance of `ChatCompletionCreateParams`, and it will return an instance of `ChatCompletion`.\n\n## Immutability\n\nEach class in the SDK has an associated [builder](https://blogs.oracle.com/javamagazine/post/exploring-joshua-blochs-builder-design-pattern-in-java) or factory method for constructing it.\n\nEach class is [immutable](https://docs.oracle.com/javase/tutorial/essential/concurrency/immutable.html) once constructed. If the class has an associated builder, then it has a `toBuilder()` method, which can be used to convert it back to a builder for making a modified copy.\n\nBecause each class is immutable, builder modification will _never_ affect already built class instances.\n\n## Asynchronous execution\n\nThe default client is synchronous. To switch to asynchronous execution, call the `async()` method:\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.ChatModel;\nimport com.openai.models.chat.completions.ChatCompletion;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\nimport java.util.concurrent.CompletableFuture;\n\n// Configures using the `openai.apiKey`, `openai.orgId`, `openai.projectId`, `openai.webhookSecret` and `openai.baseUrl` system properties\n// Or configures using the `OPENAI_API_KEY`, `OPENAI_ORG_ID`, `OPENAI_PROJECT_ID`, `OPENAI_WEBHOOK_SECRET` and `OPENAI_BASE_URL` environment variables\nOpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\nChatCompletionCreateParams params = ChatCompletionCreateParams.builder()\n    .addUserMessage(\"Say this is a test\")\n    .model(ChatModel.GPT_4O)\n    .build();\nCompletableFuture<ChatCompletion> chatCompletion = client.async().chat().completions().create(params);\n```\n\nOr create an asynchronous client from the beginning:\n\n```java\nimport com.openai.client.OpenAIClientAsync;\nimport com.openai.client.okhttp.OpenAIOkHttpClientAsync;\nimport com.openai.models.ChatModel;\nimport com.openai.models.chat.completions.ChatCompletion;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\nimport java.util.concurrent.CompletableFuture;\n\n// Configures using the `openai.apiKey`, `openai.orgId`, `openai.projectId`, `openai.webhookSecret` and `openai.baseUrl` system properties\n// Or configures using the `OPENAI_API_KEY`, `OPENAI_ORG_ID`, `OPENAI_PROJECT_ID`, `OPENAI_WEBHOOK_SECRET` and `OPENAI_BASE_URL` environment variables\nOpenAIClientAsync client = OpenAIOkHttpClientAsync.fromEnv();\n\nChatCompletionCreateParams params = ChatCompletionCreateParams.builder()\n    .addUserMessage(\"Say this is a test\")\n    .model(ChatModel.GPT_4O)\n    .build();\nCompletableFuture<ChatCompletion> chatCompletion = client.chat().completions().create(params);\n```\n\nThe asynchronous client supports the same options as the synchronous one, except most methods return `CompletableFuture`s.\n\n## Streaming\n\nThe SDK defines methods that return response \"chunk\" streams, where each chunk can be individually processed as soon as it arrives instead of waiting on the full response. Streaming methods generally correspond to [SSE](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events) or [JSONL](https://jsonlines.org) responses.\n\nSome of these methods may have streaming and non-streaming variants, but a streaming method will always have a `Streaming` suffix in its name, even if it doesn't have a non-streaming variant.\n\nThese streaming methods return [`StreamResponse`](openai-java-core/src/main/kotlin/com/openai/core/http/StreamResponse.kt) for synchronous clients:\n\n```java\nimport com.openai.core.http.StreamResponse;\nimport com.openai.models.chat.completions.ChatCompletionChunk;\n\ntry (StreamResponse<ChatCompletionChunk> streamResponse = client.chat().completions().createStreaming(params)) {\n    streamResponse.stream().forEach(chunk -> {\n        System.out.println(chunk);\n    });\n    System.out.println(\"No more chunks!\");\n}\n```\n\nOr [`AsyncStreamResponse`](openai-java-core/src/main/kotlin/com/openai/core/http/AsyncStreamResponse.kt) for asynchronous clients:\n\n```java\nimport com.openai.core.http.AsyncStreamResponse;\nimport com.openai.models.chat.completions.ChatCompletionChunk;\nimport java.util.Optional;\n\nclient.async().chat().completions().createStreaming(params).subscribe(chunk -> {\n    System.out.println(chunk);\n});\n\n// If you need to handle errors or completion of the stream\nclient.async().chat().completions().createStreaming(params).subscribe(new AsyncStreamResponse.Handler<>() {\n    @Override\n    public void onNext(ChatCompletionChunk chunk) {\n        System.out.println(chunk);\n    }\n\n    @Override\n    public void onComplete(Optional<Throwable> error) {\n        if (error.isPresent()) {\n            System.out.println(\"Something went wrong!\");\n            throw new RuntimeException(error.get());\n        } else {\n            System.out.println(\"No more chunks!\");\n        }\n    }\n});\n\n// Or use futures\nclient.async().chat().completions().createStreaming(params)\n    .subscribe(chunk -> {\n        System.out.println(chunk);\n    })\n    .onCompleteFuture();\n    .whenComplete((unused, error) -> {\n        if (error != null) {\n            System.out.println(\"Something went wrong!\");\n            throw new RuntimeException(error);\n        } else {\n            System.out.println(\"No more chunks!\");\n        }\n    });\n```\n\nAsync streaming uses a dedicated per-client cached thread pool [`Executor`](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Executor.html) to stream without blocking the current thread. This default is suitable for most purposes.\n\nTo use a different `Executor`, configure the subscription using the `executor` parameter:\n\n```java\nimport java.util.concurrent.Executor;\nimport java.util.concurrent.Executors;\n\nExecutor executor = Executors.newFixedThreadPool(4);\nclient.async().chat().completions().createStreaming(params).subscribe(\n    chunk -> System.out.println(chunk), executor\n);\n```\n\nOr configure the client globally using the `streamHandlerExecutor` method:\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport java.util.concurrent.Executors;\n\nOpenAIClient client = OpenAIOkHttpClient.builder()\n    .fromEnv()\n    .streamHandlerExecutor(Executors.newFixedThreadPool(4))\n    .build();\n```\n\n### Streaming helpers\n\nThe SDK provides conveniences for streamed chat completions. A\n[`ChatCompletionAccumulator`](openai-java-core/src/main/kotlin/com/openai/helpers/ChatCompletionAccumulator.kt)\ncan record the stream of chat completion chunks in the response as they are processed and accumulate\na [`ChatCompletion`](openai-java-core/src/main/kotlin/com/openai/models/chat/completions/ChatCompletion.kt)\nobject similar to that which would have been returned by the non-streaming API.\n\nFor a synchronous response add a\n[`Stream.peek()`](https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html#peek-java.util.function.Consumer-)\ncall to the stream pipeline to accumulate each chunk:\n\n```java\nimport com.openai.core.http.StreamResponse;\nimport com.openai.helpers.ChatCompletionAccumulator;\nimport com.openai.models.chat.completions.ChatCompletion;\nimport com.openai.models.chat.completions.ChatCompletionChunk;\n\nChatCompletionAccumulator chatCompletionAccumulator = ChatCompletionAccumulator.create();\n\ntry (StreamResponse<ChatCompletionChunk> streamResponse =\n        client.chat().completions().createStreaming(createParams)) {\n    streamResponse.stream()\n            .peek(chatCompletionAccumulator::accumulate)\n            .flatMap(completion -> completion.choices().stream())\n            .flatMap(choice -> choice.delta().content().stream())\n            .forEach(System.out::print);\n}\n\nChatCompletion chatCompletion = chatCompletionAccumulator.chatCompletion();\n```\n\nFor an asynchronous response, add the `ChatCompletionAccumulator` to the `subscribe()` call:\n\n```java\nimport com.openai.helpers.ChatCompletionAccumulator;\nimport com.openai.models.chat.completions.ChatCompletion;\n\nChatCompletionAccumulator chatCompletionAccumulator = ChatCompletionAccumulator.create();\n\nclient.chat()\n        .completions()\n        .createStreaming(createParams)\n        .subscribe(chunk -> chatCompletionAccumulator.accumulate(chunk).choices().stream()\n                .flatMap(choice -> choice.delta().content().stream())\n                .forEach(System.out::print))\n        .onCompleteFuture()\n        .join();\n\nChatCompletion chatCompletion = chatCompletionAccumulator.chatCompletion();\n```\n\nThe SDK provides conveniences for streamed responses. A\n[`ResponseAccumulator`](openai-java-core/src/main/kotlin/com/openai/helpers/ResponseAccumulator.kt)\ncan record the stream of response events as they are processed and accumulate a\n[`Response`](openai-java-core/src/main/kotlin/com/openai/models/responses/Response.kt)\nobject similar to that which would have been returned by the non-streaming API.\n\nFor a synchronous response add a\n[`Stream.peek()`](https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html#peek-java.util.function.Consumer-)\ncall to the stream pipeline to accumulate each event:\n\n```java\nimport com.openai.core.http.StreamResponse;\nimport com.openai.helpers.ResponseAccumulator;\nimport com.openai.models.responses.Response;\nimport com.openai.models.responses.ResponseStreamEvent;\n\nResponseAccumulator responseAccumulator = ResponseAccumulator.create();\n\ntry (StreamResponse<ResponseStreamEvent> streamResponse =\n        client.responses().createStreaming(createParams)) {\n    streamResponse.stream()\n            .peek(responseAccumulator::accumulate)\n            .flatMap(event -> event.outputTextDelta().stream())\n            .forEach(textEvent -> System.out.print(textEvent.delta()));\n}\n\nResponse response = responseAccumulator.response();\n```\n\nFor an asynchronous response, add the `ResponseAccumulator` to the `subscribe()` call:\n\n```java\nimport com.openai.helpers.ResponseAccumulator;\nimport com.openai.models.responses.Response;\n\nResponseAccumulator responseAccumulator = ResponseAccumulator.create();\n\nclient.responses()\n        .createStreaming(createParams)\n        .subscribe(event -> responseAccumulator.accumulate(event)\n                .outputTextDelta().ifPresent(textEvent -> System.out.print(textEvent.delta())))\n        .onCompleteFuture()\n        .join();\n\nResponse response = responseAccumulator.response();\n```\n\n## Structured outputs with JSON schemas\n\nOpen AI [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat)\nis a feature that ensures that the model will always generate responses that adhere to a supplied\n[JSON schema](https://json-schema.org/overview/what-is-jsonschema).\n\nA JSON schema can be defined by creating a\n[`ResponseFormatJsonSchema`](openai-java-core/src/main/kotlin/com/openai/models/ResponseFormatJsonSchema.kt)\nand setting it on the input parameters. However, for greater convenience, a JSON schema can instead\nbe derived automatically from the structure of an arbitrary Java class. The JSON content from the\nresponse will then be converted automatically to an instance of that Java class. A full, working\nexample of the use of Structured Outputs with arbitrary Java classes can be seen in\n[`StructuredOutputsExample`](openai-java-example/src/main/java/com/openai/example/StructuredOutputsExample.java).\n\nJava classes can contain fields declared to be instances of other classes and can use collections\n(see [Defining JSON schema properties](#defining-json-schema-properties) for more details):\n\n```java\nclass Person {\n    public String name;\n    public int birthYear;\n}\n\nclass Book {\n    public String title;\n    public Person author;\n    public int publicationYear;\n}\n\nclass BookList {\n    public List<Book> books;\n}\n```\n\nPass the top-level class‚Äî`BookList` in this example‚Äîto `responseFormat(Class<T>)` when building the\nparameters and then access an instance of `BookList` from the generated message content in the\nresponse:\n\n```java\nimport com.openai.models.ChatModel;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\nimport com.openai.models.chat.completions.StructuredChatCompletionCreateParams;\n\nStructuredChatCompletionCreateParams<BookList> params = ChatCompletionCreateParams.builder()\n        .addUserMessage(\"List some famous late twentieth century novels.\")\n        .model(ChatModel.GPT_4_1)\n        .responseFormat(BookList.class)\n        .build();\n\nclient.chat().completions().create(params).choices().stream()\n        .flatMap(choice -> choice.message().content().stream())\n        .flatMap(bookList -> bookList.books.stream())\n        .forEach(book -> System.out.println(book.title + \" by \" + book.author.name));\n```\n\nYou can start building the parameters with an instance of\n[`ChatCompletionCreateParams.Builder`](openai-java-core/src/main/kotlin/com/openai/models/chat/completions/ChatCompletionCreateParams.kt)\nor\n[`StructuredChatCompletionCreateParams.Builder`](openai-java-core/src/main/kotlin/com/openai/models/chat/completions/StructuredChatCompletionCreateParams.kt).\nIf you start with the former (which allows for more compact code) the builder type will change to\nthe latter when `ChatCompletionCreateParams.Builder.responseFormat(Class<T>)` is called.\n\nIf a field in a class is optional and does not require a defined value, you can represent this using\nthe [`java.util.Optional`](https://docs.oracle.com/javase/8/docs/api/java/util/Optional.html) class.\nIt is up to the AI model to decide whether to provide a value for that field or leave it empty.\n\n```java\nimport java.util.Optional;\n\nclass Book {\n    public String title;\n    public Person author;\n    public int publicationYear;\n    public Optional<String> isbn;\n}\n```\n\nGeneric type information for fields is retained in the class's metadata, but _generic type erasure_\napplies in other scopes. While, for example, a JSON schema defining an array of books can be derived\nfrom the `BookList.books` field with type `List<Book>`, a valid JSON schema cannot be derived from a\nlocal variable of that same type, so the following will _not_ work:\n\n```java\nList<Book> books = new ArrayList<>();\n\nStructuredChatCompletionCreateParams<List<Book>> params = ChatCompletionCreateParams.builder()\n        .responseFormat(books.getClass())\n        // ...\n        .build();\n```\n\nIf an error occurs while converting a JSON response to an instance of a Java class, the error\nmessage will include the JSON response to assist in diagnosis. For instance, if the response is\ntruncated, the JSON data will be incomplete and cannot be converted to a class instance. If your\nJSON response may contain sensitive information, avoid logging it directly, or ensure that you\nredact any sensitive details from the error message.\n\n### Local JSON schema validation\n\nStructured Outputs supports a\n[subset](https://platform.openai.com/docs/guides/structured-outputs#supported-schemas) of the JSON\nSchema language. Schemas are generated automatically from classes to align with this subset.\nHowever, due to the inherent structure of the classes, the generated schema may still violate\ncertain OpenAI schema restrictions, such as exceeding the maximum nesting depth or utilizing\nunsupported data types.\n\nTo facilitate compliance, the method `responseFormat(Class<T>)` performs a validation check on the\nschema derived from the specified class. This validation ensures that all restrictions are adhered\nto. If any issues are detected, an exception will be thrown, providing a detailed message outlining\nthe reasons for the validation failure.\n\n- **Local Validation**: The validation process occurs locally, meaning no requests are sent to the\n  remote AI model. If the schema passes local validation, it is likely to pass remote validation as\n  well.\n- **Remote Validation**: The remote AI model will conduct its own validation upon receiving the JSON\n  schema in the request.\n- **Version Compatibility**: There may be instances where local validation fails while remote\n  validation succeeds. This can occur if the SDK version is outdated compared to the restrictions\n  enforced by the remote AI model.\n- **Disabling Local Validation**: If you encounter compatibility issues and wish to bypass local\n  validation, you can disable it by passing\n  [`JsonSchemaLocalValidation.NO`](openai-java-core/src/main/kotlin/com/openai/core/JsonSchemaLocalValidation.kt)\n  to the `responseFormat(Class<T>, JsonSchemaLocalValidation)` method when building the parameters.\n  (The default value for this parameter is `JsonSchemaLocalValidation.YES`.)\n\n```java\nimport com.openai.core.JsonSchemaLocalValidation;\nimport com.openai.models.ChatModel;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\nimport com.openai.models.chat.completions.StructuredChatCompletionCreateParams;\n\nStructuredChatCompletionCreateParams<BookList> params = ChatCompletionCreateParams.builder()\n        .addUserMessage(\"List some famous late twentieth century novels.\")\n        .model(ChatModel.GPT_4_1)\n        .responseFormat(BookList.class, JsonSchemaLocalValidation.NO)\n        .build();\n```\n\nBy following these guidelines, you can ensure that your structured outputs conform to the necessary\nschema requirements and minimize the risk of remote validation errors.\n\n### Usage with the Responses API\n\n_Structured Outputs_ are also supported for the Responses API. The usage is the same as described\nexcept where the Responses API differs slightly from the Chat Completions API. Pass the top-level\nclass to `text(Class<T>)` when building the parameters and then access an instance of the class from\nthe generated message content in the response.\n\nYou can start building the parameters with an instance of\n[`ResponseCreateParams.Builder`](openai-java-core/src/main/kotlin/com/openai/models/responses/ResponseCreateParams.kt)\nor\n[`StructuredResponseCreateParams.Builder`](openai-java-core/src/main/kotlin/com/openai/models/responses/StructuredResponseCreateParams.kt).\nIf you start with the former (which allows for more compact code) the builder type will change to\nthe latter when `ResponseCreateParams.Builder.text(Class<T>)` is called.\n\nFor a full example of the usage of _Structured Outputs_ with the Responses API, see\n[`ResponsesStructuredOutputsExample`](openai-java-example/src/main/java/com/openai/example/ResponsesStructuredOutputsExample.java).\n\nInstead of using `ResponseCreateParams.text(Class<T>)`, you can build a\n[`StructuredResponseTextConfig`](openai-java-core/src/main/kotlin/com/openai/models/responses/StructuredResponseTextConfig.kt)\nand set it on the `ResponseCreateParams` using the `text(StructuredResponseTextConfig)` method.\nSimilar to using `ResponseCreateParams`, you can start with a `ResponseTextConfig.Builder` and its\n`format(Class<T>)` method will change it to a `StructuredResponseTextConfig.Builder`. This also\nallows you to set the `verbosity` configuration parameter on the text configuration before adding it\nto the `ResponseCreateParams`.\n\nFor a full example of the usage of _Structured Outputs_ with the `ResponseTextConfig` and its\n`verbosity` parameter, see\n[`ResponsesStructuredOutputsVerbosityExample`](openai-java-example/src/main/java/com/openai/example/ResponsesStructuredOutputsVerbosityExample.java).\n\n### Usage with streaming\n\n_Structured Outputs_ can also be used with [Streaming](#streaming) and the Chat Completions API. As\nresponses are returned in \"chunks\", the full response must first be accumulated to concatenate the\nJSON strings that can then be converted into instances of the arbitrary Java class. Normal streaming\noperations can be performed while accumulating the JSON strings.\n\nUse the [`ChatCompletionAccumulator`](openai-java-core/src/main/kotlin/com/openai/helpers/ChatCompletionAccumulator.kt)\nas described in the section on [Streaming helpers](#streaming-helpers) to accumulate the JSON\nstrings. Once accumulated, use `ChatCompletionAccumulator.chatCompletion(Class<T>)` to convert the\naccumulated `ChatCompletion` into a\n[`StructuredChatCompletion`](openai-java-core/src/main/kotlin/com/openai/models/chat/completions/StructuredChatCompletion.kt).\nThe `StructuredChatCompletion` can then automatically deserialize the JSON strings into instances of\nyour Java class.\n\nFor a full example of the usage of _Structured Outputs_ with Streaming and the Chat Completions API,\nsee\n[`StructuredOutputsStreamingExample`](openai-java-example/src/main/java/com/openai/example/StructuredOutputsStreamingExample.java).\n\nWith the Responses API, accumulate events while streaming using the\n[`ResponseAccumulator`](openai-java-core/src/main/kotlin/com/openai/helpers/ResponseAccumulator.kt).\nOnce accumulated, use `ResponseAccumulator.response(Class<T>)` to convert the accumulated `Response`\ninto a\n[`StructuredResponse`](openai-java-core/src/main/kotlin/com/openai/models/responses/StructuredResponse.kt).\nThe [`StructuredResponse`] can then automatically deserialize the JSON strings into instances of\nyour Java class.\n\nFor a full example of the usage of _Structured Outputs_ with Streaming and the Responses API, see\n[`ResponsesStructuredOutputsStreamingExample`](openai-java-example/src/main/java/com/openai/example/ResponsesStructuredOutputsStreamingExample.java).\n\n### Defining JSON schema properties\n\nWhen a JSON schema is derived from your Java classes, all properties represented by `public` fields\nor `public` getter methods are included in the schema by default. Non-`public` fields and getter\nmethods are _not_ included by default. You can exclude `public`, or include non-`public` fields or\ngetter methods, by using the `@JsonIgnore` or `@JsonProperty` annotations respectively (see\n[Annotating classes and JSON schemas](#annotating-classes-and-json-schemas) for details).\n\nIf you do not want to define `public` fields, you can define `private` fields and corresponding\n`public` getter methods. For example, a `private` field `myValue` with a `public` getter method\n`getMyValue()` will result in a `\"myValue\"` property being included in the JSON schema. If you\nprefer not to use the conventional Java \"get\" prefix for the name of the getter method, then you\n_must_ annotate the getter method with the `@JsonProperty` annotation and the full method name will\nbe used as the property name. You do not have to define any corresponding setter methods if you do\nnot need them.\n\nEach of your classes _must_ define at least one property to be included in the JSON schema. A\nvalidation error will occur if any class contains no fields or getter methods from which schema\nproperties can be derived. This may occur if, for example:\n\n- There are no fields or getter methods in the class.\n- All fields and getter methods are `public`, but all are annotated with `@JsonIgnore`.\n- All fields and getter methods are non-`public`, but none are annotated with `@JsonProperty`.\n- A field or getter method is declared with a `Map` type. A `Map` is treated like a separate class\n  with no named properties, so it will result in an empty `\"properties\"` field in the JSON schema.\n\n### Annotating classes and JSON schemas\n\nYou can use annotations to add further information to the JSON schema derived from your Java\nclasses, or to control which fields or getter methods will be included in the schema. Details from\nannotations captured in the JSON schema may be used by the AI model to improve its response. The SDK\nsupports the use of [Jackson Databind](https://github.com/FasterXML/jackson-databind) annotations.\n\n```java\nimport com.fasterxml.jackson.annotation.JsonClassDescription;\nimport com.fasterxml.jackson.annotation.JsonIgnore;\nimport com.fasterxml.jackson.annotation.JsonPropertyDescription;\n\nclass Person {\n    @JsonPropertyDescription(\"The first name and surname of the person\")\n    public String name;\n    public int birthYear;\n    @JsonPropertyDescription(\"The year the person died, or 'present' if the person is living.\")\n    public String deathYear;\n}\n\n@JsonClassDescription(\"The details of one published book\")\nclass Book {\n    public String title;\n    public Person author;\n    @JsonPropertyDescription(\"The year in which the book was first published.\")\n    public int publicationYear;\n    @JsonIgnore public String genre;\n}\n\nclass BookList {\n    public List<Book> books;\n}\n```\n\n- Use `@JsonClassDescription` to add a detailed description to a class.\n- Use `@JsonPropertyDescription` to add a detailed description to a field or getter method of a\n  class.\n- Use `@JsonIgnore` to exclude a `public` field or getter method of a class from the generated JSON\n  schema.\n- Use `@JsonProperty` to include a non-`public` field or getter method of a class in the generated\n  JSON schema.\n\nIf you use `@JsonProperty(required = false)`, the `false` value will be ignored. OpenAI JSON schemas\nmust mark all properties as _required_, so the schema generated from your Java classes will respect\nthat restriction and ignore any annotation that would violate it.\n\nYou can also use [OpenAPI Swagger 2](https://swagger.io/specification/v2/)\n[`@Schema`](https://github.com/swagger-api/swagger-core/wiki/Swagger-2.X---Annotations#schema) and\n[`@ArraySchema`](https://github.com/swagger-api/swagger-core/wiki/Swagger-2.X---Annotations#arrayschema)\nannotations. These allow type-specific constraints to be added to your schema properties. You can\nlearn more about the supported constraints in the OpenAI documentation on\n[Supported properties](https://platform.openai.com/docs/guides/structured-outputs#supported-properties).\n\n```java\nimport io.swagger.v3.oas.annotations.media.Schema;\nimport io.swagger.v3.oas.annotations.media.ArraySchema;\n\nclass Article {\n    @ArraySchema(minItems = 1, maxItems = 10)\n    public List<String> authors;\n\n    @Schema(pattern = \"^[A-Za-z ]+$\")\n    public String title;\n\n    @Schema(format = \"date\")\n    public String publicationDate;\n\n    @Schema(minimum = \"1\")\n    public int pageCount;\n}\n```\n\nLocal validation will check that you have not used any unsupported constraint keywords. However, the\nvalues of the constraints are _not_ validated locally. For example, if you use a value for the\n`\"format\"` constraint of a string property that is not in the list of\n[supported format names](https://platform.openai.com/docs/guides/structured-outputs#supported-properties),\nthen local validation will pass, but the AI model may report an error.\n\nIf you use both Jackson and Swagger annotations to set the same schema field, the Jackson annotation\nwill take precedence. In the following example, the description of `myProperty` will be set to\n\"Jackson description\"; \"Swagger description\" will be ignored:\n\n```java\nimport com.fasterxml.jackson.annotation.JsonPropertyDescription;\nimport io.swagger.v3.oas.annotations.media.Schema;\n\nclass MyObject {\n    @Schema(description = \"Swagger description\")\n    @JsonPropertyDescription(\"Jackson description\")\n    public String myProperty;\n}\n```\n\n## Function calling with JSON schemas\n\nOpenAI [Function Calling](https://platform.openai.com/docs/guides/function-calling?api-mode=chat)\nlets you integrate external functions directly into the language model's responses. Instead of\nproducing plain text, the model can output instructions (with parameters) for calling a function\nwhen appropriate. You define a [JSON schema](https://json-schema.org/overview/what-is-jsonschema)\nfor functions, and the model uses it to decide when and how to trigger these calls, enabling more\ninteractive, data-driven applications.\n\nA JSON schema describing a function's parameters can be defined via the API by building a\n[`ChatCompletionTool`](openai-java-core/src/main/kotlin/com/openai/models/chat/completions/ChatCompletionTool.kt)\ncontaining a\n[`FunctionDefinition`](openai-java-core/src/main/kotlin/com/openai/models/FunctionDefinition.kt)\nand then using `addTool` to set it on the input parameters. The response from the AI model may then\ncontain requests to call your functions, detailing the functions' names and their parameter values\nas JSON data that conforms to the JSON schema from the function definition. You can then parse the\nparameter values from this JSON, invoke your functions, and pass your functions' results back to the\nAI model. A full, working example of _Function Calling_ using the low-level API can be seen in\n[`FunctionCallingRawExample`](openai-java-example/src/main/java/com/openai/example/FunctionCallingRawExample.java).\n\nHowever, for greater convenience, the SDK can derive a function and its parameters automatically\nfrom the structure of an arbitrary Java class: the class's name provides the function name, and the\nclass's fields define the function's parameters. When the AI model responds with the parameter\nvalues in JSON form, you can then easily convert that JSON to an instance of your Java class and\nuse the parameter values to invoke your custom function. A full, working example of the use of\n_Function Calling_ with Java classes to define function parameters can be seen in\n[`FunctionCallingExample`](openai-java-example/src/main/java/com/openai/example/FunctionCallingExample.java).\n\nLike for [Structured Outputs](#structured-outputs-with-json-schemas), Java classes can contain\nfields declared to be instances of other classes and can use collections (see\n[Defining JSON schema properties](#defining-json-schema-properties) for more details). Optionally,\nannotations can be used to set the descriptions of the function (class) and its parameters (fields)\nto assist the AI model in understanding the purpose of the function and the possible values of its\nparameters.\n\n```java\nimport com.fasterxml.jackson.annotation.JsonClassDescription;\nimport com.fasterxml.jackson.annotation.JsonPropertyDescription;\n\n@JsonClassDescription(\"Gets the quality of the given SDK.\")\nstatic class GetSdkQuality {\n    @JsonPropertyDescription(\"The name of the SDK.\")\n    public String name;\n\n    public SdkQuality execute() {\n        return new SdkQuality(\n                name, name.contains(\"OpenAI\") ? \"It's robust and polished!\" : \"*shrug*\");\n    }\n}\n\nstatic class SdkQuality {\n    public String quality;\n\n    public SdkQuality(String name, String evaluation) {\n        quality = name + \": \" + evaluation;\n    }\n}\n\n@JsonClassDescription(\"Gets the review score (out of 10) for the named SDK.\")\nstatic class GetSdkScore {\n  public String name;\n\n  public int execute() {\n    return name.contains(\"OpenAI\") ? 10 : 3;\n  }\n}\n```\n\nWhen your functions are defined, add them to the input parameters using `addTool(Class<T>)` and then\ncall them if requested to do so in the AI model's response. `Function.argments(Class<T>)` can be\nused to parse a function's parameters in JSON form to an instance of your function-defining class.\nThe fields of that instance will be set to the values of the parameters to the function call.\n\nAfter calling the function, use `ChatCompletionToolMessageParam.Builder.contentAsJson(Object)` to\npass the function's result back to the AI model. The method will convert the result to JSON form\nfor consumption by the model. The `Object` can be any object, including simple `String` instances\nand boxed primitive types.\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.ChatModel;\nimport com.openai.models.chat.completions.*;\nimport java.util.Collection;\n\nOpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\nChatCompletionCreateParams.Builder createParamsBuilder = ChatCompletionCreateParams.builder()\n        .model(ChatModel.GPT_3_5_TURBO)\n        .maxCompletionTokens(2048)\n        .addTool(GetSdkQuality.class)\n        .addTool(GetSdkScore.class)\n        .addUserMessage(\"How good are the following SDKs and what do reviewers say: \"\n                + \"OpenAI Java SDK, Unknown Company SDK.\");\n\nclient.chat().completions().create(createParamsBuilder.build()).choices().stream()\n        .map(ChatCompletion.Choice::message)\n        // Add each assistant message onto the builder so that we keep track of the\n        // conversation for asking a follow-up question later.\n        .peek(createParamsBuilder::addMessage)\n        .flatMap(message -> {\n            message.content().ifPresent(System.out::println);\n            return message.toolCalls().stream().flatMap(Collection::stream);\n        })\n        .forEach(toolCall -> {\n            Object result = callFunction(toolCall.function());\n            // Add the tool call result to the conversation.\n            createParamsBuilder.addMessage(ChatCompletionToolMessageParam.builder()\n                    .toolCallId(toolCall.id())\n                    .contentAsJson(result)\n                    .build());\n        });\n\n// Ask a follow-up question about the function call result.\ncreateParamsBuilder.addUserMessage(\"Why do you say that?\");\nclient.chat().completions().create(createParamsBuilder.build()).choices().stream()\n        .flatMap(choice -> choice.message().content().stream())\n        .forEach(System.out::println);\n\nstatic Object callFunction(ChatCompletionMessageToolCall.Function function) {\n  switch (function.name()) {\n    case \"GetSdkQuality\":\n      return function.arguments(GetSdkQuality.class).execute();\n    case \"GetSdkScore\":\n      return function.arguments(GetSdkScore.class).execute();\n    default:\n      throw new IllegalArgumentException(\"Unknown function: \" + function.name());\n  }\n}\n```\n\nIn the code above, an `execute()` method encapsulates each function's logic. However, there is no\nrequirement to follow that pattern. You are free to implement your function's logic in any way that\nbest suits your use case. The pattern above is only intended to _suggest_ that a suitable pattern\nmay make the process of function calling simpler to understand and implement.\n\n### Usage with the Responses API\n\n_Function Calling_ is also supported for the Responses API. The usage is the same as described\nexcept where the Responses API differs slightly from the Chat Completions API. Pass the top-level\nclass to `addTool(Class<T>)` when building the parameters. In the response, look for\n[`RepoonseOutputItem`](openai-java-core/src/main/kotlin/com/openai/models/responses/ResponseOutputItem.kt)\ninstances that are function calls. Parse the parameters to each function call to an instance of the\nclass using\n[`ResponseFunctionToolCall.arguments(Class<T>)`](openai-java-core/src/main/kotlin/com/openai/models/responses/ResponseFunctionToolCall.kt).\nFinally, pass the result of each call back to the model.\n\nFor a full example of the usage of _Function Calling_ with the Responses API using the low-level\nAPI to define and parse function parameters, see\n[`ResponsesFunctionCallingRawExample`](openai-java-example/src/main/java/com/openai/example/ResponsesFunctionCallingRawExample.java).\n\nFor a full example of the usage of _Function Calling_ with the Responses API using Java classes to\ndefine and parse function parameters, see\n[`ResponsesFunctionCallingExample`](openai-java-example/src/main/java/com/openai/example/ResponsesFunctionCallingExample.java).\n\n### Local function JSON schema validation\n\nLike for _Structured Outputs_, you can perform local validation to check that the JSON schema\nderived from your function class respects the restrictions imposed by OpenAI on such schemas. Local\nvalidation is enabled by default, but it can be disabled by adding `JsonSchemaLocalValidation.NO` to\nthe call to `addTool`.\n\n```java\nChatCompletionCreateParams.Builder createParamsBuilder = ChatCompletionCreateParams.builder()\n        .model(ChatModel.GPT_3_5_TURBO)\n        .maxCompletionTokens(2048)\n        .addTool(GetSdkQuality.class, JsonSchemaLocalValidation.NO)\n        .addTool(GetSdkScore.class, JsonSchemaLocalValidation.NO)\n        .addUserMessage(\"How good are the following SDKs and what do reviewers say: \"\n                + \"OpenAI Java SDK, Unknown Company SDK.\");\n```\n\nSee [Local JSON schema validation](#local-json-schema-validation) for more details on local schema\nvalidation and under what circumstances you might want to disable it.\n\n### Annotating function classes\n\nYou can use annotations to add further information about functions to the JSON schemas that are\nderived from your function classes, or to control which fields or getter methods will be used as\nparameters to the function. Details from annotations captured in the JSON schema may be used by the\nAI model to improve its response. The SDK supports the use of\n[Jackson Databind](https://github.com/FasterXML/jackson-databind) annotations.\n\n- Use `@JsonClassDescription` to add a description to a function class detailing when and how to use\n  that function.\n- Use `@JsonTypeName` to set the function name to something other than the simple name of the class,\n  which is used by default.\n- Use `@JsonPropertyDescription` to add a detailed description to function parameter (a field or\n  getter method of a function class).\n- Use `@JsonIgnore` to exclude a `public` field or getter method of a class from the generated JSON\n  schema for a function's parameters.\n- Use `@JsonProperty` to include a non-`public` field or getter method of a class in the generated\n  JSON schema for a function's parameters.\n\nOpenAI provides some\n[Best practices for defining functions](https://platform.openai.com/docs/guides/function-calling#best-practices-for-defining-functions)\nthat may help you to understand how to use the above annotations effectively for your functions.\n\nSee also [Defining JSON schema properties](#defining-json-schema-properties) for more details on how\nto use fields and getter methods and combine access modifiers and annotations to define the\nparameters of your functions. The same rules apply to function classes and to the structured output\nclasses described in that section.\n\n## File uploads\n\nThe SDK defines methods that accept files.\n\nTo upload a file, pass a [`Path`](https://docs.oracle.com/javase/8/docs/api/java/nio/file/Path.html):\n\n```java\nimport com.openai.models.files.FileCreateParams;\nimport com.openai.models.files.FileObject;\nimport com.openai.models.files.FilePurpose;\nimport java.nio.file.Paths;\n\nFileCreateParams params = FileCreateParams.builder()\n    .purpose(FilePurpose.FINE_TUNE)\n    .file(Paths.get(\"input.jsonl\"))\n    .build();\nFileObject fileObject = client.files().create(params);\n```\n\nOr an arbitrary [`InputStream`](https://docs.oracle.com/javase/8/docs/api/java/io/InputStream.html):\n\n```java\nimport com.openai.models.files.FileCreateParams;\nimport com.openai.models.files.FileObject;\nimport com.openai.models.files.FilePurpose;\nimport java.net.URL;\n\nFileCreateParams params = FileCreateParams.builder()\n    .purpose(FilePurpose.FINE_TUNE)\n    .file(new URL(\"https://example.com/input.jsonl\").openStream())\n    .build();\nFileObject fileObject = client.files().create(params);\n```\n\nOr a `byte[]` array:\n\n```java\nimport com.openai.models.files.FileCreateParams;\nimport com.openai.models.files.FileObject;\nimport com.openai.models.files.FilePurpose;\n\nFileCreateParams params = FileCreateParams.builder()\n    .purpose(FilePurpose.FINE_TUNE)\n    .file(\"content\".getBytes())\n    .build();\nFileObject fileObject = client.files().create(params);\n```\n\nNote that when passing a non-`Path` its filename is unknown so it will not be included in the request. To manually set a filename, pass a [`MultipartField`](openai-java-core/src/main/kotlin/com/openai/core/Values.kt):\n\n```java\nimport com.openai.core.MultipartField;\nimport com.openai.models.files.FileCreateParams;\nimport com.openai.models.files.FileObject;\nimport com.openai.models.files.FilePurpose;\nimport java.io.InputStream;\nimport java.net.URL;\n\nFileCreateParams params = FileCreateParams.builder()\n    .purpose(FilePurpose.FINE_TUNE)\n    .file(MultipartField.<InputStream>builder()\n        .value(new URL(\"https://example.com/input.jsonl\").openStream())\n        .filename(\"input.jsonl\")\n        .build())\n    .build();\nFileObject fileObject = client.files().create(params);\n```\n\n## Webhook Verification\n\nVerifying webhook signatures is _optional but encouraged_.\n\nFor more information about webhooks, see [the API docs](https://platform.openai.com/docs/guides/webhooks).\n\n### Parsing webhook payloads\n\nFor most use cases, you will likely want to verify the webhook and parse the payload at the same time. To achieve this, we provide the method `client.webhooks().unwrap()`, which parses a webhook request and verifies that it was sent by OpenAI. This method will throw an exception if the signature is invalid.\n\nNote that the `body` parameter must be the raw JSON string sent from the server (do not parse it first). The `.unwrap()` method will parse this JSON for you into an event object after verifying the webhook was sent from OpenAI.\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.core.http.Headers;\nimport com.openai.models.webhooks.UnwrapWebhookEvent;\nimport java.util.Optional;\n\nOpenAIClient client = OpenAIOkHttpClient.fromEnv(); // OPENAI_WEBHOOK_SECRET env var used by default\n\npublic void handleWebhook(String body, Map<String, String> headers) {\n    try {\n        Headers headersList = Headers.builder()\n                .putAll(headers)\n                .build();\n\n        UnwrapWebhookEvent event = client.webhooks().unwrap(body, headersList, Optional.empty());\n\n        if (event.isResponseCompletedWebhookEvent()) {\n            System.out.println(\"Response completed: \" + event.asResponseCompletedWebhookEvent().data());\n        } else if (event.isResponseFailed()) {\n            System.out.println(\"Response failed: \" + event.asResponseFailed().data());\n        } else {\n            System.out.println(\"Unhandled event type: \" + event.getClass().getSimpleName());\n        }\n    } catch (Exception e) {\n        System.err.println(\"Invalid webhook signature: \" + e.getMessage());\n        // Handle invalid signature\n    }\n}\n```\n\n### Verifying webhook payloads directly\n\nIn some cases, you may want to verify the webhook separately from parsing the payload. If you prefer to handle these steps separately, we provide the method `client.webhooks().verifySignature()` to _only verify_ the signature of a webhook request. Like `.unwrap()`, this method will throw an exception if the signature is invalid.\n\nNote that the `body` parameter must be the raw JSON string sent from the server (do not parse it first). You will then need to parse the body after verifying the signature.\n\n```java\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.core.http.Headers;\nimport com.openai.models.webhooks.WebhookVerificationParams;\nimport java.util.Optional;\n\nOpenAIClient client = OpenAIOkHttpClient.fromEnv(); // OPENAI_WEBHOOK_SECRET env var used by default\nObjectMapper objectMapper = new ObjectMapper();\n\npublic void handleWebhook(String body, Map<String, String> headers) {\n    try {\n        Headers headersList = Headers.builder()\n                .putAll(headers)\n                .build();\n\n        client.webhooks().verifySignature(\n            WebhookVerificationParams.builder()\n                .payload(body)\n                .headers(headersList)\n                .build()\n        );\n\n        // Parse the body after verification\n        Map<String, Object> event = objectMapper.readValue(body, Map.class);\n        System.out.println(\"Verified event: \" + event);\n    } catch (Exception e) {\n        System.err.println(\"Invalid webhook signature: \" + e.getMessage());\n        // Handle invalid signature\n    }\n}\n```\n\n## Binary responses\n\nThe SDK defines methods that return binary responses, which are used for API responses that shouldn't necessarily be parsed, like non-JSON data.\n\nThese methods return [`HttpResponse`](openai-java-core/src/main/kotlin/com/openai/core/http/HttpResponse.kt):\n\n```java\nimport com.openai.core.http.HttpResponse;\nimport com.openai.models.files.FileContentParams;\n\nHttpResponse response = client.files().content(\"file_id\");\n```\n\nTo save the response content to a file, use the [`Files.copy(...)`](https://docs.oracle.com/javase/8/docs/api/java/nio/file/Files.html#copy-java.io.InputStream-java.nio.file.Path-java.nio.file.CopyOption...-) method:\n\n```java\nimport com.openai.core.http.HttpResponse;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.nio.file.StandardCopyOption;\n\ntry (HttpResponse response = client.files().content(params)) {\n    Files.copy(\n        response.body(),\n        Paths.get(path),\n        StandardCopyOption.REPLACE_EXISTING\n    );\n} catch (Exception e) {\n    System.out.println(\"Something went wrong!\");\n    throw new RuntimeException(e);\n}\n```\n\nOr transfer the response content to any [`OutputStream`](https://docs.oracle.com/javase/8/docs/api/java/io/OutputStream.html):\n\n```java\nimport com.openai.core.http.HttpResponse;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\ntry (HttpResponse response = client.files().content(params)) {\n    response.body().transferTo(Files.newOutputStream(Paths.get(path)));\n} catch (Exception e) {\n    System.out.println(\"Something went wrong!\");\n    throw new RuntimeException(e);\n}\n```\n\n## Raw responses\n\nThe SDK defines methods that deserialize responses into instances of Java classes. However, these methods don't provide access to the response headers, status code, or the raw response body.\n\nTo access this data, prefix any HTTP method call on a client or service with `withRawResponse()`:\n\n```java\nimport com.openai.core.http.Headers;\nimport com.openai.core.http.HttpResponseFor;\nimport com.openai.models.ChatModel;\nimport com.openai.models.chat.completions.ChatCompletion;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\n\nChatCompletionCreateParams params = ChatCompletionCreateParams.builder()\n    .addUserMessage(\"Say this is a test\")\n    .model(ChatModel.GPT_4O)\n    .build();\nHttpResponseFor<ChatCompletion> chatCompletion = client.chat().completions().withRawResponse().create(params);\n\nint statusCode = chatCompletion.statusCode();\nHeaders headers = chatCompletion.headers();\n```\n\nYou can still deserialize the response into an instance of a Java class if needed:\n\n```java\nimport com.openai.models.chat.completions.ChatCompletion;\n\nChatCompletion parsedChatCompletion = chatCompletion.parse();\n```\n\n### Request IDs\n\n> For more information on debugging requests, see [the API docs](https://platform.openai.com/docs/api-reference/debugging-requests).\n\nWhen using raw responses, you can access the `x-request-id` response header using the `requestId()` method:\n\n```java\nimport com.openai.core.http.HttpResponseFor;\nimport com.openai.models.chat.completions.ChatCompletion;\nimport java.util.Optional;\n\nHttpResponseFor<ChatCompletion> chatCompletion = client.chat().completions().withRawResponse().create(params);\nOptional<String> requestId = chatCompletion.requestId();\n```\n\nThis can be used to quickly log failing requests and report them back to OpenAI.\n\n## Error handling\n\nThe SDK throws custom unchecked exception types:\n\n- [`OpenAIServiceException`](openai-java-core/src/main/kotlin/com/openai/errors/OpenAIServiceException.kt): Base class for HTTP errors. See this table for which exception subclass is thrown for each HTTP status code:\n\n  | Status | Exception                                                                                                              |\n  | ------ | ---------------------------------------------------------------------------------------------------------------------- |\n  | 400    | [`BadRequestException`](openai-java-core/src/main/kotlin/com/openai/errors/BadRequestException.kt)                     |\n  | 401    | [`UnauthorizedException`](openai-java-core/src/main/kotlin/com/openai/errors/UnauthorizedException.kt)                 |\n  | 403    | [`PermissionDeniedException`](openai-java-core/src/main/kotlin/com/openai/errors/PermissionDeniedException.kt)         |\n  | 404    | [`NotFoundException`](openai-java-core/src/main/kotlin/com/openai/errors/NotFoundException.kt)                         |\n  | 422    | [`UnprocessableEntityException`](openai-java-core/src/main/kotlin/com/openai/errors/UnprocessableEntityException.kt)   |\n  | 429    | [`RateLimitException`](openai-java-core/src/main/kotlin/com/openai/errors/RateLimitException.kt)                       |\n  | 5xx    | [`InternalServerException`](openai-java-core/src/main/kotlin/com/openai/errors/InternalServerException.kt)             |\n  | others | [`UnexpectedStatusCodeException`](openai-java-core/src/main/kotlin/com/openai/errors/UnexpectedStatusCodeException.kt) |\n\n  [`SseException`](openai-java-core/src/main/kotlin/com/openai/errors/SseException.kt) is thrown for errors encountered during [SSE streaming](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events) after a successful initial HTTP response.\n\n- [`OpenAIIoException`](openai-java-core/src/main/kotlin/com/openai/errors/OpenAIIoException.kt): I/O networking errors.\n\n- [`OpenAIRetryableException`](openai-java-core/src/main/kotlin/com/openai/errors/OpenAIRetryableException.kt): Generic error indicating a failure that could be retried by the client.\n\n- [`OpenAIInvalidDataException`](openai-java-core/src/main/kotlin/com/openai/errors/OpenAIInvalidDataException.kt): Failure to interpret successfully parsed data. For example, when accessing a property that's supposed to be required, but the API unexpectedly omitted it from the response.\n\n- [`OpenAIException`](openai-java-core/src/main/kotlin/com/openai/errors/OpenAIException.kt): Base class for all exceptions. Most errors will result in one of the previously mentioned ones, but completely generic errors may be thrown using the base class.\n\n## Pagination\n\nThe SDK defines methods that return a paginated lists of results. It provides convenient ways to access the results either one page at a time or item-by-item across all pages.\n\n### Auto-pagination\n\nTo iterate through all results across all pages, use the `autoPager()` method, which automatically fetches more pages as needed.\n\nWhen using the synchronous client, the method returns an [`Iterable`](https://docs.oracle.com/javase/8/docs/api/java/lang/Iterable.html)\n\n```java\nimport com.openai.models.finetuning.jobs.FineTuningJob;\nimport com.openai.models.finetuning.jobs.JobListPage;\n\nJobListPage page = client.fineTuning().jobs().list();\n\n// Process as an Iterable\nfor (FineTuningJob job : page.autoPager()) {\n    System.out.println(job);\n}\n\n// Process as a Stream\npage.autoPager()\n    .stream()\n    .limit(50)\n    .forEach(job -> System.out.println(job));\n```\n\nWhen using the asynchronous client, the method returns an [`AsyncStreamResponse`](openai-java-core/src/main/kotlin/com/openai/core/http/AsyncStreamResponse.kt):\n\n```java\nimport com.openai.core.http.AsyncStreamResponse;\nimport com.openai.models.finetuning.jobs.FineTuningJob;\nimport com.openai.models.finetuning.jobs.JobListPageAsync;\nimport java.util.Optional;\nimport java.util.concurrent.CompletableFuture;\n\nCompletableFuture<JobListPageAsync> pageFuture = client.async().fineTuning().jobs().list();\n\npageFuture.thenRun(page -> page.autoPager().subscribe(job -> {\n    System.out.println(job);\n}));\n\n// If you need to handle errors or completion of the stream\npageFuture.thenRun(page -> page.autoPager().subscribe(new AsyncStreamResponse.Handler<>() {\n    @Override\n    public void onNext(FineTuningJob job) {\n        System.out.println(job);\n    }\n\n    @Override\n    public void onComplete(Optional<Throwable> error) {\n        if (error.isPresent()) {\n            System.out.println(\"Something went wrong!\");\n            throw new RuntimeException(error.get());\n        } else {\n            System.out.println(\"No more!\");\n        }\n    }\n}));\n\n// Or use futures\npageFuture.thenRun(page -> page.autoPager()\n    .subscribe(job -> {\n        System.out.println(job);\n    })\n    .onCompleteFuture()\n    .whenComplete((unused, error) -> {\n        if (error != null) {\n            System.out.println(\"Something went wrong!\");\n            throw new RuntimeException(error);\n        } else {\n            System.out.println(\"No more!\");\n        }\n    }));\n```\n\n### Manual pagination\n\nTo access individual page items and manually request the next page, use the `items()`,\n`hasNextPage()`, and `nextPage()` methods:\n\n```java\nimport com.openai.models.finetuning.jobs.FineTuningJob;\nimport com.openai.models.finetuning.jobs.JobListPage;\n\nJobListPage page = client.fineTuning().jobs().list();\nwhile (true) {\n    for (FineTuningJob job : page.items()) {\n        System.out.println(job);\n    }\n\n    if (!page.hasNextPage()) {\n        break;\n    }\n\n    page = page.nextPage();\n}\n```\n\n## Logging\n\nThe SDK uses the standard [OkHttp logging interceptor](https://github.com/square/okhttp/tree/master/okhttp-logging-interceptor).\n\nEnable logging by setting the `OPENAI_LOG` environment variable to `info`:\n\n```sh\nexport OPENAI_LOG=info\n```\n\nOr to `debug` for more verbose logging:\n\n```sh\nexport OPENAI_LOG=debug\n```\n\n## ProGuard and R8\n\nAlthough the SDK uses reflection, it is still usable with [ProGuard](https://github.com/Guardsquare/proguard) and [R8](https://developer.android.com/topic/performance/app-optimization/enable-app-optimization) because `openai-java-core` is published with a [configuration file](openai-java-core/src/main/resources/META-INF/proguard/openai-java-core.pro) containing [keep rules](https://www.guardsquare.com/manual/configuration/usage).\n\nProGuard and R8 should automatically detect and use the published rules, but you can also manually copy the keep rules if necessary.\n\n## GraalVM\n\nAlthough the SDK uses reflection, it is still usable in [GraalVM](https://www.graalvm.org) because `openai-java-core` is published with [reachability metadata](https://www.graalvm.org/latest/reference-manual/native-image/metadata/).\n\nGraalVM should automatically detect and use the published metadata, but [manual configuration](https://www.graalvm.org/jdk24/reference-manual/native-image/overview/BuildConfiguration/) is also available.\n\n## Spring Boot\n\nIf you're using Spring Boot, then you can use the SDK's [Spring Boot starter](https://docs.spring.io/spring-boot/docs/2.7.18/reference/htmlsingle/#using.build-systems.starters) to simplify configuration and get set up quickly.\n\n### Installation\n\n<!-- x-release-please-start-version -->\n\n#### Gradle\n\n```kotlin\nimplementation(\"com.openai:openai-java-spring-boot-starter:4.16.0\")\n```\n\n#### Maven\n\n```xml\n<dependency>\n  <groupId>com.openai</groupId>\n  <artifactId>openai-java-spring-boot-starter</artifactId>\n  <version>4.16.0</version>\n</dependency>\n```\n\n<!-- x-release-please-end -->\n\n### Configuration\n\nThe [client's environment variable options](#client-configuration) can be configured in [`application.properties` or `application.yml`](https://docs.spring.io/spring-boot/how-to/properties-and-configuration.html).\n\n#### `application.properties`\n\n```properties\nopenai.base-url=https://api.openai.com/v1\nopenai.api-key=My API Key\nopenai.org-id=My Organization\nopenai.project-id=My Project\nopenai.webhook-secret=My Webhook Secret\n```\n\n#### `application.yml`\n\n```yaml\nopenai:\n  base-url: https://api.openai.com/v1\n  api-key: My API Key\n  org-id: My Organization\n  project-id: My Project\n  webhook-secret: My Webhook Secret\n```\n\n#### Other configuration\n\nConfigure any other client option by providing one or more instances of [`OpenAIClientCustomizer`](openai-java-spring-boot-starter/src/main/kotlin/com/openai/springboot/OpenAIClientCustomizer.kt). For example, here's how you'd set [`maxRetries`](#retries):\n\n```java\nimport com.openai.springboot.OpenAIClientCustomizer;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\npublic class OpenAIConfig {\n    @Bean\n    public OpenAIClientCustomizer customizer() {\n        return builder -> builder.maxRetries(3);\n    }\n}\n```\n\n### Usage\n\n[Inject](https://docs.spring.io/spring-framework/reference/core/beans/dependencies/factory-collaborators.html) [`OpenAIClient`](openai-java-core/src/main/kotlin/com/openai/client/OpenAIClient.kt) anywhere and start using it!\n\n## Jackson\n\nThe SDK depends on [Jackson](https://github.com/FasterXML/jackson) for JSON serialization/deserialization. It is compatible with version 2.13.4 or higher, but depends on version 2.18.2 by default.\n\nThe SDK throws an exception if it detects an incompatible Jackson version at runtime (e.g. if the default version was overridden in your Maven or Gradle config).\n\nIf the SDK threw an exception, but you're _certain_ the version is compatible, then disable the version check using the `checkJacksonVersionCompatibility` on [`OpenAIOkHttpClient`](openai-java-client-okhttp/src/main/kotlin/com/openai/client/okhttp/OpenAIOkHttpClient.kt) or [`OpenAIOkHttpClientAsync`](openai-java-client-okhttp/src/main/kotlin/com/openai/client/okhttp/OpenAIOkHttpClientAsync.kt).\n\n> [!CAUTION]\n> We make no guarantee that the SDK works correctly when the Jackson version check is disabled.\n\nAlso note that there are bugs in older Jackson versions that can affect the SDK. We don't work around all Jackson bugs ([example](https://github.com/FasterXML/jackson-databind/issues/3240)) and expect users to upgrade Jackson for those instead.\n\n## Microsoft Azure\n\nTo use this library with [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/overview), use the same\nOpenAI client builder but with the Azure-specific configuration.\n\n```java\nOpenAIClient client = OpenAIOkHttpClient.builder()\n        // Gets the API key and endpoint from the `AZURE_OPENAI_KEY` and `OPENAI_BASE_URL` environment variables, respectively\n        .fromEnv()\n        // Set the Azure Entra ID\n        .credential(BearerTokenCredential.create(AuthenticationUtil.getBearerTokenSupplier(\n                new DefaultAzureCredentialBuilder().build(), \"https://cognitiveservices.azure.com/.default\")))\n        .build();\n```\n\nSee the complete Azure OpenAI example in the [`openai-java-example`](openai-java-example/src/main/java/com/openai/example/AzureEntraIdExample.java) directory. The other examples in the directory also work with Azure as long as the client is configured to use it.\n\n### Optional: URL path mode configuration\n\nThe [`ClientOptions`](openai-java-core/src/main/kotlin/com/openai/core/ClientOptions.kt) can be configured to treat Azure OpenAI endpoint URLs differently, depending on your service setup. The default value is [`AzureUrlPathMode.AUTO`](openai-java-core/src/main/kotlin/com/openai/azure/AzureUrlPathMode.kt). To customize the SDK behavior, each value does the following:\n- `AzureUrlPathMode.LEGACY`: forces the deployment or model name into the path.\n- `AzureUrlPathMode.UNIFIED`: for newer endpoints ending in `/openai/v1` the service behaviour matches OpenAI's, therefore [`AzureOpenAIServiceVersion`](openai-java-core/src/main/kotlin/com/openai/azure/AzureOpenAIServiceVersion.kt) becomes optional and the model is passed in the request object.\n- `AzureUrlPathMode.AUTO`: automatically detects the path mode based on the base URL. Default value.\n\n## Network options\n\n### Retries\n\nThe SDK automatically retries 2 times by default, with a short exponential backoff between requests.\n\nOnly the following error types are retried:\n\n- Connection errors (for example, due to a network connectivity problem)\n- 408 Request Timeout\n- 409 Conflict\n- 429 Rate Limit\n- 5xx Internal\n\nThe API may also explicitly instruct the SDK to retry or not retry a request.\n\nTo set a custom number of retries, configure the client using the `maxRetries` method:\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\n\nOpenAIClient client = OpenAIOkHttpClient.builder()\n    .fromEnv()\n    .maxRetries(4)\n    .build();\n```\n\n### Timeouts\n\nRequests time out after 10 minutes by default.\n\nTo set a custom timeout, configure the method call using the `timeout` method:\n\n```java\nimport com.openai.models.chat.completions.ChatCompletion;\n\nChatCompletion chatCompletion = client.chat().completions().create(\n  params, RequestOptions.builder().timeout(Duration.ofSeconds(30)).build()\n);\n```\n\nOr configure the default for all method calls at the client level:\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport java.time.Duration;\n\nOpenAIClient client = OpenAIOkHttpClient.builder()\n    .fromEnv()\n    .timeout(Duration.ofSeconds(30))\n    .build();\n```\n\n### Proxies\n\nTo route requests through a proxy, configure the client using the `proxy` method:\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport java.net.InetSocketAddress;\nimport java.net.Proxy;\n\nOpenAIClient client = OpenAIOkHttpClient.builder()\n    .fromEnv()\n    .proxy(new Proxy(\n      Proxy.Type.HTTP, new InetSocketAddress(\n        \"https://example.com\", 8080\n      )\n    ))\n    .build();\n```\n\n### HTTPS\n\n> [!NOTE]\n> Most applications should not call these methods, and instead use the system defaults. The defaults include\n> special optimizations that can be lost if the implementations are modified.\n\nTo configure how HTTPS connections are secured, configure the client using the `sslSocketFactory`, `trustManager`, and `hostnameVerifier` methods:\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\n\nOpenAIClient client = OpenAIOkHttpClient.builder()\n    .fromEnv()\n    // If `sslSocketFactory` is set, then `trustManager` must be set, and vice versa.\n    .sslSocketFactory(yourSSLSocketFactory)\n    .trustManager(yourTrustManager)\n    .hostnameVerifier(yourHostnameVerifier)\n    .build();\n```\n\n### Custom HTTP client\n\nThe SDK consists of three artifacts:\n\n- `openai-java-core`\n  - Contains core SDK logic\n  - Does not depend on [OkHttp](https://square.github.io/okhttp)\n  - Exposes [`OpenAIClient`](openai-java-core/src/main/kotlin/com/openai/client/OpenAIClient.kt), [`OpenAIClientAsync`](openai-java-core/src/main/kotlin/com/openai/client/OpenAIClientAsync.kt), [`OpenAIClientImpl`](openai-java-core/src/main/kotlin/com/openai/client/OpenAIClientImpl.kt), and [`OpenAIClientAsyncImpl`](openai-java-core/src/main/kotlin/com/openai/client/OpenAIClientAsyncImpl.kt), all of which can work with any HTTP client\n- `openai-java-client-okhttp`\n  - Depends on [OkHttp](https://square.github.io/okhttp)\n  - Exposes [`OpenAIOkHttpClient`](openai-java-client-okhttp/src/main/kotlin/com/openai/client/okhttp/OpenAIOkHttpClient.kt) and [`OpenAIOkHttpClientAsync`](openai-java-client-okhttp/src/main/kotlin/com/openai/client/okhttp/OpenAIOkHttpClientAsync.kt), which provide a way to construct [`OpenAIClientImpl`](openai-java-core/src/main/kotlin/com/openai/client/OpenAIClientImpl.kt) and [`OpenAIClientAsyncImpl`](openai-java-core/src/main/kotlin/com/openai/client/OpenAIClientAsyncImpl.kt), respectively, using OkHttp\n- `openai-java`\n  - Depends on and exposes the APIs of both `openai-java-core` and `openai-java-client-okhttp`\n  - Does not have its own logic\n\nThis structure allows replacing the SDK's default HTTP client without pulling in unnecessary dependencies.\n\n#### Customized [`OkHttpClient`](https://square.github.io/okhttp/3.x/okhttp/okhttp3/OkHttpClient.html)\n\n> [!TIP]\n> Try the available [network options](#network-options) before replacing the default client.\n\nTo use a customized `OkHttpClient`:\n\n1. Replace your [`openai-java` dependency](#installation) with `openai-java-core`\n2. Copy `openai-java-client-okhttp`'s [`OkHttpClient`](openai-java-client-okhttp/src/main/kotlin/com/openai/client/okhttp/OkHttpClient.kt) class into your code and customize it\n3. Construct [`OpenAIClientImpl`](openai-java-core/src/main/kotlin/com/openai/client/OpenAIClientImpl.kt) or [`OpenAIClientAsyncImpl`](openai-java-core/src/main/kotlin/com/openai/client/OpenAIClientAsyncImpl.kt), similarly to [`OpenAIOkHttpClient`](openai-java-client-okhttp/src/main/kotlin/com/openai/client/okhttp/OpenAIOkHttpClient.kt) or [`OpenAIOkHttpClientAsync`](openai-java-client-okhttp/src/main/kotlin/com/openai/client/okhttp/OpenAIOkHttpClientAsync.kt), using your customized client\n\n### Completely custom HTTP client\n\nTo use a completely custom HTTP client:\n\n1. Replace your [`openai-java` dependency](#installation) with `openai-java-core`\n2. Write a class that implements the [`HttpClient`](openai-java-core/src/main/kotlin/com/openai/core/http/HttpClient.kt) interface\n3. Construct [`OpenAIClientImpl`](openai-java-core/src/main/kotlin/com/openai/client/OpenAIClientImpl.kt) or [`OpenAIClientAsyncImpl`](openai-java-core/src/main/kotlin/com/openai/client/OpenAIClientAsyncImpl.kt), similarly to [`OpenAIOkHttpClient`](openai-java-client-okhttp/src/main/kotlin/com/openai/client/okhttp/OpenAIOkHttpClient.kt) or [`OpenAIOkHttpClientAsync`](openai-java-client-okhttp/src/main/kotlin/com/openai/client/okhttp/OpenAIOkHttpClientAsync.kt), using your new client class\n\n## Undocumented API functionality\n\nThe SDK is typed for convenient usage of the documented API. However, it also supports working with undocumented or not yet supported parts of the API.\n\n### Parameters\n\nTo set undocumented parameters, call the `putAdditionalHeader`, `putAdditionalQueryParam`, or `putAdditionalBodyProperty` methods on any `Params` class:\n\n```java\nimport com.openai.core.JsonValue;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\n\nChatCompletionCreateParams params = ChatCompletionCreateParams.builder()\n    .putAdditionalHeader(\"Secret-Header\", \"42\")\n    .putAdditionalQueryParam(\"secret_query_param\", \"42\")\n    .putAdditionalBodyProperty(\"secretProperty\", JsonValue.from(\"42\"))\n    .build();\n```\n\nThese can be accessed on the built object later using the `_additionalHeaders()`, `_additionalQueryParams()`, and `_additionalBodyProperties()` methods.\n\nTo set undocumented parameters on _nested_ headers, query params, or body classes, call the `putAdditionalProperty` method on the nested class:\n\n```java\nimport com.openai.core.JsonValue;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\n\nChatCompletionCreateParams params = ChatCompletionCreateParams.builder()\n    .responseFormat(ChatCompletionCreateParams.ResponseFormat.builder()\n        .putAdditionalProperty(\"secretProperty\", JsonValue.from(\"42\"))\n        .build())\n    .build();\n```\n\nThese properties can be accessed on the nested built object later using the `_additionalProperties()` method.\n\nTo set a documented parameter or property to an undocumented or not yet supported _value_, pass a [`JsonValue`](openai-java-core/src/main/kotlin/com/openai/core/Values.kt) object to its setter:\n\n```java\nimport com.openai.core.JsonValue;\nimport com.openai.models.ChatModel;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\n\nChatCompletionCreateParams params = ChatCompletionCreateParams.builder()\n    .messages(JsonValue.from(42))\n    .model(ChatModel.GPT_4O)\n    .build();\n```\n\nThe most straightforward way to create a [`JsonValue`](openai-java-core/src/main/kotlin/com/openai/core/Values.kt) is using its `from(...)` method:\n\n```java\nimport com.openai.core.JsonValue;\nimport java.util.List;\nimport java.util.Map;\n\n// Create primitive JSON values\nJsonValue nullValue = JsonValue.from(null);\nJsonValue booleanValue = JsonValue.from(true);\nJsonValue numberValue = JsonValue.from(42);\nJsonValue stringValue = JsonValue.from(\"Hello World!\");\n\n// Create a JSON array value equivalent to `[\"Hello\", \"World\"]`\nJsonValue arrayValue = JsonValue.from(List.of(\n  \"Hello\", \"World\"\n));\n\n// Create a JSON object value equivalent to `{ \"a\": 1, \"b\": 2 }`\nJsonValue objectValue = JsonValue.from(Map.of(\n  \"a\", 1,\n  \"b\", 2\n));\n\n// Create an arbitrarily nested JSON equivalent to:\n// {\n//   \"a\": [1, 2],\n//   \"b\": [3, 4]\n// }\nJsonValue complexValue = JsonValue.from(Map.of(\n  \"a\", List.of(\n    1, 2\n  ),\n  \"b\", List.of(\n    3, 4\n  )\n));\n```\n\nNormally a `Builder` class's `build` method will throw [`IllegalStateException`](https://docs.oracle.com/javase/8/docs/api/java/lang/IllegalStateException.html) if any required parameter or property is unset.\n\nTo forcibly omit a required parameter or property, pass [`JsonMissing`](openai-java-core/src/main/kotlin/com/openai/core/Values.kt):\n\n```java\nimport com.openai.core.JsonMissing;\nimport com.openai.models.ChatModel;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\n\nChatCompletionCreateParams params = ChatCompletionCreateParams.builder()\n    .model(ChatModel.GPT_4O)\n    .messages(JsonMissing.of())\n    .build();\n```\n\n### Response properties\n\nTo access undocumented response properties, call the `_additionalProperties()` method:\n\n```java\nimport com.openai.core.JsonValue;\nimport java.util.Map;\n\nMap<String, JsonValue> additionalProperties = client.chat().completions().create(params)._additionalProperties();\nJsonValue secretPropertyValue = additionalProperties.get(\"secretProperty\");\n\nString result = secretPropertyValue.accept(new JsonValue.Visitor<>() {\n    @Override\n    public String visitNull() {\n        return \"It's null!\";\n    }\n\n    @Override\n    public String visitBoolean(boolean value) {\n        return \"It's a boolean!\";\n    }\n\n    @Override\n    public String visitNumber(Number value) {\n        return \"It's a number!\";\n    }\n\n    // Other methods include `visitMissing`, `visitString`, `visitArray`, and `visitObject`\n    // The default implementation of each unimplemented method delegates to `visitDefault`, which throws by default, but can also be overridden\n});\n```\n\nTo access a property's raw JSON value, which may be undocumented, call its `_` prefixed method:\n\n```java\nimport com.openai.core.JsonField;\nimport com.openai.models.chat.completions.ChatCompletionMessageParam;\nimport java.util.Optional;\n\nJsonField<List<ChatCompletionMessageParam>> messages = client.chat().completions().create(params)._messages();\n\nif (messages.isMissing()) {\n  // The property is absent from the JSON response\n} else if (messages.isNull()) {\n  // The property was set to literal null\n} else {\n  // Check if value was provided as a string\n  // Other methods include `asNumber()`, `asBoolean()`, etc.\n  Optional<String> jsonString = messages.asString();\n\n  // Try to deserialize into a custom type\n  MyClass myObject = messages.asUnknown().orElseThrow().convert(MyClass.class);\n}\n```\n\n### Response validation\n\nIn rare cases, the API may return a response that doesn't match the expected type. For example, the SDK may expect a property to contain a `String`, but the API could return something else.\n\nBy default, the SDK will not throw an exception in this case. It will throw [`OpenAIInvalidDataException`](openai-java-core/src/main/kotlin/com/openai/errors/OpenAIInvalidDataException.kt) only if you directly access the property.\n\nIf you would prefer to check that the response is completely well-typed upfront, then either call `validate()`:\n\n```java\nimport com.openai.models.chat.completions.ChatCompletion;\n\nChatCompletion chatCompletion = client.chat().completions().create(params).validate();\n```\n\nOr configure the method call to validate the response using the `responseValidation` method:\n\n```java\nimport com.openai.models.chat.completions.ChatCompletion;\n\nChatCompletion chatCompletion = client.chat().completions().create(\n  params, RequestOptions.builder().responseValidation(true).build()\n);\n```\n\nOr configure the default for all method calls at the client level:\n\n```java\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\n\nOpenAIClient client = OpenAIOkHttpClient.builder()\n    .fromEnv()\n    .responseValidation(true)\n    .build();\n```\n\n## FAQ\n\n### Why don't you use plain `enum` classes?\n\nJava `enum` classes are not trivially [forwards compatible](https://www.stainless.com/blog/making-java-enums-forwards-compatible). Using them in the SDK could cause runtime exceptions if the API is updated to respond with a new enum value.\n\n### Why do you represent fields using `JsonField<T>` instead of just plain `T`?\n\nUsing `JsonField<T>` enables a few features:\n\n- Allowing usage of [undocumented API functionality](#undocumented-api-functionality)\n- Lazily [validating the API response against the expected shape](#response-validation)\n- Representing absent vs explicitly null values\n\n### Why don't you use [`data` classes](https://kotlinlang.org/docs/data-classes.html)?\n\nIt is not [backwards compatible to add new fields to a data class](https://kotlinlang.org/docs/api-guidelines-backward-compatibility.html#avoid-using-data-classes-in-your-api) and we don't want to introduce a breaking change every time we add a field to a class.\n\n### Why don't you use checked exceptions?\n\nChecked exceptions are widely considered a mistake in the Java programming language. In fact, they were omitted from Kotlin for this reason.\n\nChecked exceptions:\n\n- Are verbose to handle\n- Encourage error handling at the wrong level of abstraction, where nothing can be done about the error\n- Are tedious to propagate due to the [function coloring problem](https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function)\n- Don't play well with lambdas (also due to the function coloring problem)\n\n## Semantic versioning\n\nThis package generally follows [SemVer](https://semver.org/spec/v2.0.0.html) conventions, though certain backwards-incompatible changes may be released as minor versions:\n\n1. Changes to library internals which are technically public but not intended or documented for external use. _(Please open a GitHub issue to let us know if you are relying on such internals.)_\n2. Changes that we do not expect to impact the vast majority of users in practice.\n\nWe take backwards-compatibility seriously and work hard to ensure you can rely on a smooth upgrade experience.\n\nWe are keen for your feedback; please open an [issue](https://www.github.com/openai/openai-java/issues) with questions, bugs, or suggestions.\n",
      "stars_today": 4
    },
    {
      "id": 22458259,
      "name": "Alamofire",
      "full_name": "Alamofire/Alamofire",
      "description": "Elegant HTTP Networking in Swift",
      "html_url": "https://github.com/Alamofire/Alamofire",
      "stars": 42314,
      "forks": 7670,
      "language": "Swift",
      "topics": [
        "alamofire",
        "carthage",
        "certificate-pinning",
        "cocoapods",
        "httpurlresponse",
        "networking",
        "parameter-encoding",
        "public-key-pinning",
        "request",
        "response",
        "swift",
        "swift-package-manager",
        "urlrequest",
        "urlsession",
        "xcode"
      ],
      "created_at": "2014-07-31T05:56:19Z",
      "updated_at": "2026-01-22T16:56:59Z",
      "pushed_at": "2025-12-20T07:34:46Z",
      "open_issues": 40,
      "owner": {
        "login": "Alamofire",
        "avatar_url": "https://avatars.githubusercontent.com/u/7774181?v=4"
      },
      "readme": "![Alamofire: Elegant Networking in Swift](https://raw.githubusercontent.com/Alamofire/Alamofire/master/Resources/AlamofireLogo.png)\n\n[![Swift](https://img.shields.io/badge/Swift-6.0_6.1_6.2-orange?style=flat-square)](https://img.shields.io/badge/Swift-6.0_6.1_6.2-Orange?style=flat-square)\n[![Platforms](https://img.shields.io/badge/Platforms-macOS_iOS_tvOS_watchOS_visionOS_Linux_Windows_Android-yellowgreen?style=flat-square)](https://img.shields.io/badge/Platforms-macOS_iOS_tvOS_watchOS_vision_OS_Linux_Windows_Android-Green?style=flat-square)\n[![CocoaPods Compatible](https://img.shields.io/cocoapods/v/Alamofire.svg?style=flat-square)](https://img.shields.io/cocoapods/v/Alamofire.svg)\n[![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat-square)](https://github.com/Carthage/Carthage)\n[![Swift Package Manager](https://img.shields.io/badge/Swift_Package_Manager-compatible-orange?style=flat-square)](https://img.shields.io/badge/Swift_Package_Manager-compatible-orange?style=flat-square)\n[![Swift Forums](https://img.shields.io/badge/Swift_Forums-Alamofire-orange?style=flat-square)](https://forums.swift.org/c/related-projects/alamofire/37)\n\nAlamofire is an HTTP networking library written in Swift.\n\n- [Features](#features)\n- [Component Libraries](#component-libraries)\n- [Requirements](#requirements)\n- [Migration Guides](#migration-guides)\n- [Communication](#communication)\n- [Installation](#installation)\n- [Contributing](#contributing)\n- [Usage](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#using-alamofire)\n  - [**Introduction -**](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#introduction) [Making Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#making-requests), [Response Handling](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-handling), [Response Validation](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-validation), [Response Caching](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-caching)\n  - **HTTP -** [HTTP Methods](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#http-methods), [Parameters and Parameter Encoder](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md##request-parameters-and-parameter-encoders), [HTTP Headers](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#http-headers), [Authentication](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#authentication)\n  - **Large Data -** [Downloading Data to a File](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#downloading-data-to-a-file), [Uploading Data to a Server](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#uploading-data-to-a-server)\n  - **Tools -** [Statistical Metrics](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#statistical-metrics), [cURL Command Output](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#curl-command-output)\n- [Advanced Usage](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md)\n  - **URL Session -** [Session Manager](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#session), [Session Delegate](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#sessiondelegate), [Request](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#request)\n  - **Routing -** [Routing Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#routing-requests), [Adapting and Retrying Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#adapting-and-retrying-requests-with-requestinterceptor)\n  - **Model Objects -** [Custom Response Handlers](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#customizing-response-handlers)\n  - **Advanced Concurrency -** [Swift Concurrency](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#using-alamofire-with-swift-concurrency) and [Combine](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#using-alamofire-with-combine)\n  - **Connection -** [Security](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#security), [Network Reachability](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#network-reachability)\n- [Open Radars](#open-radars)\n- [FAQ](#faq)\n- [Credits](#credits)\n- [Donations](#donations)\n- [License](#license)\n\n## Features\n\n- [x] Chainable Request / Response Methods\n- [x] Swift Concurrency Support Back to iOS 13, macOS 10.15, tvOS 13, and watchOS 6.\n- [x] Combine Support\n- [x] URL / JSON Parameter Encoding\n- [x] Upload File / Data / Stream / MultipartFormData\n- [x] Download File using Request or Resume Data\n- [x] Authentication with `URLCredential`\n- [x] HTTP Response Validation\n- [x] Upload and Download Progress Closures with Progress\n- [x] cURL Command Output\n- [x] Dynamically Adapt and Retry Requests\n- [x] TLS Certificate and Public Key Pinning\n- [x] Network Reachability\n- [x] Comprehensive Unit and Integration Test Coverage\n- [x] [Complete Documentation](https://alamofire.github.io/Alamofire)\n\n## Write Requests Fast!\n\nAlamofire's compact syntax and extensive feature set allow requests with powerful features like automatic retry to be written in just a few lines of code.\n\n```swift\n// Automatic String to URL conversion, Swift concurrency support, and automatic retry.\nlet response = await AF.request(\"https://httpbin.org/get\", interceptor: .retryPolicy)\n                       // Automatic HTTP Basic Auth.\n                       .authenticate(username: \"user\", password: \"pass\")\n                       // Caching customization.\n                       .cacheResponse(using: .cache)\n                       // Redirect customization.\n                       .redirect(using: .follow)\n                       // Validate response code and Content-Type.\n                       .validate()\n                       // Produce a cURL command for the request.\n                       .cURLDescription { description in\n                         print(description)\n                       }\n                       // Automatic Decodable support with background parsing.\n                       .serializingDecodable(DecodableType.self)\n                       // Await the full response with metrics and a parsed body.\n                       .response\n// Detailed response description for easy debugging.\ndebugPrint(response)\n```\n\n## Component Libraries\n\nIn order to keep Alamofire focused specifically on core networking implementations, additional component libraries have been created by the [Alamofire Software Foundation](https://github.com/Alamofire/Foundation) to bring additional functionality to the Alamofire ecosystem.\n\n- [AlamofireImage](https://github.com/Alamofire/AlamofireImage) - An image library including image response serializers, `UIImage` and `UIImageView` extensions, custom image filters, an auto-purging in-memory cache, and a priority-based image downloading system.\n- [AlamofireNetworkActivityIndicator](https://github.com/Alamofire/AlamofireNetworkActivityIndicator) - Controls the visibility of the network activity indicator on iOS using Alamofire. It contains configurable delay timers to help mitigate flicker and can support `URLSession` instances not managed by Alamofire.\n\n## Requirements\n\n| Platform                                             | Minimum Swift Version | Installation                                                                                                         | Status                   |\n| ---------------------------------------------------- | --------------------- | -------------------------------------------------------------------------------------------------------------------- | ------------------------ |\n| iOS 10.0+ / macOS 10.12+ / tvOS 10.0+ / watchOS 3.0+ | 6.0 / Xcode 16.0      | [CocoaPods](#cocoapods), [Carthage](#carthage), [Swift Package Manager](#swift-package-manager), [Manual](#manually) | Fully Tested             |\n| Linux                                                | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n| Windows                                              | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n| Android                                              | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n\n#### Known Issues on Linux and Windows\n\nAlamofire builds on Linux, Windows, and Android but there are missing features and many issues in the underlying `swift-corelibs-foundation` that prevent full functionality and may cause crashes. These include:\n\n- `ServerTrustManager` and associated certificate functionality is unavailable, so there is no certificate pinning and no client certificate support.\n- Various methods of HTTP authentication may crash, including HTTP Basic and HTTP Digest. Crashes may occur if responses contain server challenges.\n- Cache control through `CachedResponseHandler` and associated APIs is unavailable, as the underlying delegate methods aren't called.\n- `URLSessionTaskMetrics` are never gathered.\n- `WebSocketRequest` is not available.\n\nDue to these issues, Alamofire is unsupported on Linux, Windows, and Android. Please report any crashes to the [Swift bug reporter](https://bugs.swift.org).\n\n## Migration Guides\n\n- [Alamofire 5.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%205.0%20Migration%20Guide.md)\n- [Alamofire 4.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%204.0%20Migration%20Guide.md)\n- [Alamofire 3.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%203.0%20Migration%20Guide.md)\n- [Alamofire 2.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%202.0%20Migration%20Guide.md)\n\n## Communication\n\n- If you **need help with making network requests** using Alamofire, use [Stack Overflow](https://stackoverflow.com/questions/tagged/alamofire) and tag `alamofire`.\n- If you need to **find or understand an API**, check [our documentation](http://alamofire.github.io/Alamofire/) or [Apple's documentation for `URLSession`](https://developer.apple.com/documentation/foundation/url_loading_system), on top of which Alamofire is built.\n- If you need **help with an Alamofire feature**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you'd like to **discuss Alamofire best practices**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you'd like to **discuss a feature request**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you **found a bug**, open an issue here on GitHub and follow the guide. The more detail the better!\n\n## Installation\n\n### Swift Package Manager\n\nThe [Swift Package Manager](https://swift.org/package-manager/) is a tool for automating the distribution of Swift code and is integrated into the `swift` compiler.\n\nOnce you have your Swift package set up, adding Alamofire as a dependency is as easy as adding it to the `dependencies` value of your `Package.swift` or the Package list in Xcode.\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/Alamofire/Alamofire.git\", .upToNextMajor(from: \"5.11.0\"))\n]\n```\n\nNormally you'll want to depend on the `Alamofire` target:\n\n```swift\n.product(name: \"Alamofire\", package: \"Alamofire\")\n```\n\nBut if you want to force Alamofire to be dynamically linked (do not do this unless you're sure you need it), you can depend on the `AlamofireDynamic` target:\n\n```swift\n.product(name: \"AlamofireDynamic\", package: \"Alamofire\")\n```\n\n### CocoaPods\n\n[CocoaPods](https://cocoapods.org) is a dependency manager for Cocoa projects. For usage and installation instructions, visit their website. To integrate Alamofire into your Xcode project using CocoaPods, specify it in your `Podfile`:\n\n```ruby\npod 'Alamofire'\n```\n\n### Carthage\n\n[Carthage](https://github.com/Carthage/Carthage) is a decentralized dependency manager that builds your dependencies and provides you with binary frameworks. To integrate Alamofire into your Xcode project using Carthage, specify it in your `Cartfile`:\n\n```ogdl\ngithub \"Alamofire/Alamofire\"\n```\n\n### Manually\n\nIf you prefer not to use any of the aforementioned dependency managers, you can integrate Alamofire into your project manually.\n\n#### Embedded Framework\n\n- Open up Terminal, `cd` into your top-level project directory, and run the following command \"if\" your project is not initialized as a git repository:\n\n  ```bash\n  $ git init\n  ```\n\n- Add Alamofire as a git [submodule](https://git-scm.com/docs/git-submodule) by running the following command:\n\n  ```bash\n  $ git submodule add https://github.com/Alamofire/Alamofire.git\n  ```\n\n- Open the new `Alamofire` folder, and drag the `Alamofire.xcodeproj` into the Project Navigator of your application's Xcode project.\n\n  > It should appear nested underneath your application's blue project icon. Whether it is above or below all the other Xcode groups does not matter.\n\n- Select the `Alamofire.xcodeproj` in the Project Navigator and verify the deployment target matches that of your application target.\n- Next, select your application project in the Project Navigator (blue project icon) to navigate to the target configuration window and select the application target under the \"Targets\" heading in the sidebar.\n- In the tab bar at the top of that window, open the \"General\" panel.\n- Click on the `+` button under the \"Embedded Binaries\" section.\n- You will see two different `Alamofire.xcodeproj` folders each with two different versions of the `Alamofire.framework` nested inside a `Products` folder.\n\n  > It does not matter which `Products` folder you choose from, but it does matter whether you choose the top or bottom `Alamofire.framework`.\n\n- Select the top `Alamofire.framework` for iOS and the bottom one for macOS.\n\n  > You can verify which one you selected by inspecting the build log for your project. The build target for `Alamofire` will be listed as `Alamofire iOS`, `Alamofire macOS`, `Alamofire tvOS`, or `Alamofire watchOS`.\n\n- And that's it!\n\n  > The `Alamofire.framework` is automagically added as a target dependency, linked framework and embedded framework in a copy files build phase which is all you need to build on the simulator and a device.\n\n## Contributing\n\nBefore contributing to Alamofire, please read the instructions detailed in our [contribution guide](https://github.com/Alamofire/Alamofire/blob/master/CONTRIBUTING.md).\n\n## Open Radars\n\nThe following radars have some effect on the current implementation of Alamofire.\n\n- [`rdar://21349340`](http://www.openradar.me/radar?id=5517037090635776) - Compiler throwing warning due to toll-free bridging issue in the test case\n- `rdar://26870455` - Background URL Session Configurations do not work in the simulator\n- `rdar://26849668` - Some URLProtocol APIs do not properly handle `URLRequest`\n\n## Resolved Radars\n\nThe following radars have been resolved over time after being filed against the Alamofire project.\n\n- [`rdar://26761490`](http://www.openradar.me/radar?id=5010235949318144) - Swift string interpolation causing memory leak with common usage.\n  - (Resolved): 9/1/17 in Xcode 9 beta 6.\n- [`rdar://36082113`](http://openradar.appspot.com/radar?id=4942308441063424) - `URLSessionTaskMetrics` failing to link on watchOS 3.0+\n  - (Resolved): Just add `CFNetwork` to your linked frameworks.\n- `FB7624529` - `urlSession(_:task:didFinishCollecting:)` never called on watchOS\n  - (Resolved): Metrics now collected on watchOS 7+.\n\n## FAQ\n\n### What's the origin of the name Alamofire?\n\nAlamofire is named after the [Alamo Fire flower](https://aggie-horticulture.tamu.edu/wildseed/alamofire.html), a hybrid variant of the Bluebonnet, the official state flower of Texas.\n\n## Credits\n\nAlamofire is owned and maintained by the [Alamofire Software Foundation](http://alamofire.org). You can follow them on Twitter at [@AlamofireSF](https://twitter.com/AlamofireSF) for project updates and releases.\n\n### Security Disclosure\n\nIf you believe you have identified a security vulnerability with Alamofire, you should report it as soon as possible via email to security@alamofire.org. Please do not post it to a public issue tracker.\n\n## Sponsorship\n\nThe [ASF](https://github.com/Alamofire/Foundation#members) is looking to raise money to officially stay registered as a federal non-profit organization.\nRegistering will allow Foundation members to gain some legal protections and also allow us to put donations to use, tax-free.\nSponsoring the ASF will enable us to:\n\n- Pay our yearly legal fees to keep the non-profit in good status\n- Pay for our mail servers to help us stay on top of all questions and security issues\n- Potentially fund test servers to make it easier for us to test the edge cases\n- Potentially fund developers to work on one of our projects full-time\n\nThe community adoption of the ASF libraries has been amazing.\nWe are greatly humbled by your enthusiasm around the projects and want to continue to do everything we can to move the needle forward.\nWith your continued support, the ASF will be able to improve its reach and also provide better legal safety for the core members.\nIf you use any of our libraries for work, see if your employers would be interested in donating.\nAny amount you can donate, whether once or monthly, to help us reach our goal would be greatly appreciated.\n\n[Sponsor Alamofire](https://github.com/sponsors/Alamofire)\n\n## Supporters\n\n[MacStadium](https://macstadium.com) provides Alamofire with a free, hosted Mac mini.\n\n![Powered by MacStadium](https://raw.githubusercontent.com/Alamofire/Alamofire/master/Resources/MacStadiumLogo.png)\n\n## License\n\nAlamofire is released under the MIT license. [See LICENSE](https://github.com/Alamofire/Alamofire/blob/master/LICENSE) for details.\n",
      "stars_today": 3
    },
    {
      "id": 112785414,
      "name": "spring-cloud-alibaba",
      "full_name": "alibaba/spring-cloud-alibaba",
      "description": "Spring Cloud Alibaba provides a one-stop solution for application development for the distributed solutions of Alibaba middleware.",
      "html_url": "https://github.com/alibaba/spring-cloud-alibaba",
      "stars": 29021,
      "forks": 8524,
      "language": "Java",
      "topics": [
        "alibaba",
        "alibaba-middleware",
        "alibaba-oss",
        "aliyun",
        "circuit-breaker",
        "cloud-native",
        "distributed-configuration",
        "distributed-messaging",
        "distributed-transaction",
        "dubbo",
        "java",
        "microservices",
        "nacos",
        "rocketmq",
        "service-discovery",
        "service-registry",
        "spring",
        "spring-cloud",
        "spring-cloud-alibaba",
        "spring-cloud-core"
      ],
      "created_at": "2017-12-01T20:49:15Z",
      "updated_at": "2026-01-22T09:40:07Z",
      "pushed_at": "2026-01-13T10:56:33Z",
      "open_issues": 174,
      "owner": {
        "login": "alibaba",
        "avatar_url": "https://avatars.githubusercontent.com/u/1961952?v=4"
      },
      "readme": "# Spring Cloud Alibaba\n\n[![CircleCI](https://circleci.com/gh/alibaba/spring-cloud-alibaba/tree/2025.1.x.svg?style=svg)](https://circleci.com/gh/alibaba/spring-cloud-alibaba/tree/2025.1.x)\n[![Maven Central](https://img.shields.io/maven-central/v/com.alibaba.cloud/spring-cloud-alibaba-dependencies.svg?label=Maven%20Central)](https://search.maven.org/search?q=g:com.alibaba.cloud%20AND%20a:spring-cloud-alibaba-dependencies)\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![actions](https://github.com/alibaba/spring-cloud-alibaba/workflows/Integration%20Testing/badge.svg)](https://github.com/alibaba/spring-cloud-alibaba/actions)\n[![Leaderboard](https://img.shields.io/badge/SCA-Check%20Your%20Contribution-orange)](https://opensource.alibaba.com/contribution_leaderboard/details?projectValue=sca)\n\nA project maintained by Alibaba.\n\nSee the [‰∏≠ÊñáÊñáÊ°£](https://github.com/alibaba/spring-cloud-alibaba/blob/2025.1.x/README-zh.md) for Chinese readme.\n\nSpring Cloud Alibaba provides a one-stop solution for distributed application development. It contains all the components required to develop distributed applications, making it easy for you to develop your applications using Spring Cloud.\n\nWith Spring Cloud Alibaba, you only need to add some annotations and a small amount of configurations to connect Spring Cloud applications to the distributed solutions of Alibaba, and build a distributed application system with Alibaba middleware.\n\n\n## Features\n\n* **Flow control and service degradation**: Flow control for HTTP services is supported by default. You can also customize flow control and service degradation rules using annotations. The rules can be changed dynamically.\n* **Service registration and discovery**: Service can be registered and clients can discover the instances using Spring-managed beans. Load balancing is consistent with that supported by the corresponding Spring Cloud.\n* **Distributed configuration**: Support for externalized configuration in a distributed system, auto refresh when configuration changes.\n* **Event-driven**: Support for building highly scalable event-driven microservices connected with shared messaging systems.\n* **Distributed Transaction**: Support for distributed transaction solution with high performance and ease of use.\n* **Alibaba Cloud Object Storage**: Massive, secure, low-cost, and highly reliable cloud storage services. Support for storing and accessing any type of data in any application, anytime, anywhere.\n* **Alibaba Cloud SchedulerX**: Accurate, highly reliable, and highly available scheduled job scheduling services with response time within seconds.\n* **Alibaba Cloud SMS**: A messaging service that covers the globe, Alibaba SMS provides convenient, efficient, and intelligent communication capabilities that help businesses quickly contact their customers.\n\nFor more features, please refer to [Roadmap](https://github.com/alibaba/spring-cloud-alibaba/blob/2025.1.x/Roadmap.md).\n\nIn addition to the above-mentioned features, for the needs of enterprise users' scenarios, [Microservices Engine (MSE)](https://www.aliyun.com/product/aliware/mse?spm=github.spring.com.topbar) of Spring Cloud Alibaba's enterprise version provides an enterprise-level microservices governance center, which includes more powerful governance capabilities such as Grayscale Release, Service Warm-up, Lossless Online and Offline and Outlier Ejection. At the same time, it also provides a variety of products and solutions such as enterprise-level Nacos registration / configuration center, enterprise-level cloud native gateway.\n\n\n## Components\n\n**[Sentinel](https://github.com/alibaba/Sentinel)**: Sentinel takes \"traffic flow\" as the breakthrough point, and provides solutions in areas such as flow control, concurrency, circuit breaking, and load protection to protect service stability.\n\n**[Nacos](https://github.com/alibaba/Nacos)**: An easy-to-use dynamic service discovery, configuration and service management platform for building cloud native applications.\n\n**[RocketMQ](https://rocketmq.apache.org/)**: A distributed messaging and streaming platform with low latency, high performance and reliability, trillion-level capacity and flexible scalability.\n\n**[Seata](https://github.com/seata/seata)**: A distributed transaction solution with high performance and ease of use for microservices architecture.\n\n**[Alibaba Cloud OSS](https://www.aliyun.com/product/oss)**: An encrypted and secure cloud storage service which stores, processes and accesses massive amounts of data from anywhere in the world.\n\n**[Alibaba Cloud SMS](https://www.aliyun.com/product/sms)**: A messaging service that covers the globe, Alibaba SMS provides convenient, efficient, and intelligent communication capabilities that help businesses quickly contact their customers.\n\n**[Alibaba Cloud SchedulerX](https://www.aliyun.com/aliware/schedulerx?spm=5176.10695662.784137.1.4b07363dej23L3)**: Accurate, highly reliable, and highly available scheduled job scheduling services with response time within seconds.\n\nFor more features please refer to [Roadmap](https://github.com/alibaba/spring-cloud-alibaba/blob/2025.1.x/Roadmap.md).\n\n## How to build\n* **2025.1.x branch**: Corresponds to Spring Cloud 2025.1.x & Spring Boot 4.0.x, JDK 17 or later versions are supported.\n* **2025.0.x branch**: Corresponds to Spring Cloud 2025.0.x & Spring Boot 3.5.x, JDK 17 or later versions are supported.\n* **2023.x branch**: Corresponds to Spring Cloud 2023 & Spring Boot 3.2.x, JDK 17 or later versions are supported.\n* **2022.x branch**: Corresponds to Spring Cloud 2022 & Spring Boot 3.0.x, JDK 17 or later versions are supported.\n* **2021.x branch**: Corresponds to Spring Cloud 2021 & Spring Boot 2.6.x. JDK 1.8 or later versions are supported.\n* **2020.0 branch**: Corresponds to Spring Cloud 2020 & Spring Boot 2.4.x. JDK 1.8 or later versions are supported.\n* **2.2.x branch**: Corresponds to Spring Cloud Hoxton & Spring Boot 2.2.x. JDK 1.8 or later versions are supported.\n* **greenwich branch**: Corresponds to Spring Cloud Greenwich & Spring Boot 2.1.x. JDK 1.8 or later versions are supported.\n* **finchley branch**: Corresponds to Spring Cloud Finchley & Spring Boot 2.0.x. JDK 1.8 or later versions are supported.\n* **1.x branch**: Corresponds to Spring Cloud Edgware & Spring Boot 1.x, JDK 1.7 or later versions are supported.\n\nSpring Cloud uses Maven for most build-related activities, and you should be able to get off the ground quite quickly by cloning the project you are interested in and typing:\n```bash\n./mvnw install\n```\n\n## How to Use\n\n### Add maven dependency \n\n#### Release Version\n\nThese artifacts are available from Maven Central and Spring Release repository via BOM:\n```xml\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n            <version>2025.0.0.0</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\nadd the module in  `dependencies`. If you want to choose an older version, you can refer to the [Release Notes](https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E).\n\n#### Snapshot\n\nIf you need to use the already published `Snapshot Version`, add the following configuration in the `dependencyManagement`.\n```xml\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n            <version>2025.1.0.0-SNAPSHOT</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\n\nAdd the following configuration in `repositories`.\n```xml\n<repositories>\n    <repository>\n        <id>github</id>\n        <url>https://maven.pkg.github.com/alibaba/spring-cloud-alibaba</url>\n        <releases>\n            <enabled>false</enabled>\n        </releases>\n        <snapshots>\n            <enabled>true</enabled>\n        </snapshots>\n    </repository>\n</repositories>\n```\n\nAdd the following configuration in `settings.xml`.\n```xml\n<servers>\n    <server>\n        <id>github</id>\n        <username>Your GitHub Username</username>\n        <password>Your GitHub Token (requires read:packages permission)</password>\n    </server>\n</servers>\n```\n\n## Examples\n\nA `spring-cloud-alibaba-examples` module is included in our project for you to get started with Spring Cloud Alibaba quickly. It contains an example, and you can refer to the readme file in the example project for a quick walkthrough.\n\nExamplesÔºö\n\n[Sentinel Example](https://github.com/alibaba/spring-cloud-alibaba/tree/2025.1.x/spring-cloud-alibaba-examples/sentinel-example/sentinel-core-example/readme.md)\n\n[Nacos Example](https://github.com/alibaba/spring-cloud-alibaba/blob/2025.1.x/spring-cloud-alibaba-examples/nacos-example/readme.md)\n\n[RocketMQ Example](https://github.com/alibaba/spring-cloud-alibaba/blob/2025.1.x/spring-cloud-alibaba-examples/rocketmq-example/readme.md)\n\n[Alibaba Cloud OSS Example](https://github.com/alibaba/aliyun-spring-boot/tree/master/aliyun-spring-boot-samples/aliyun-oss-spring-boot-sample)\n\n## Version control guidelines\nThe version number of the project is in the form of x.x.x, where x is a number, starting from 0, and is not limited to the range 0~9. When the project is in the incubator phase, the version number is 0.x.x.\n\nAs the interfaces and annotations of Spring Boot 1 and Spring Boot 2 have been changed significantly in the Actuator module, and spring-cloud-commons is also changed quite a lot from 1.x.x to 2.0.0, we take the same version rule as SpringBoot version number.\n\n* 1.5.x for Spring Boot 1.5.x\n* 2.0.x for Spring Boot 2.0.x\n* 2.1.x for Spring Boot 2.1.x\n* 2.2.x for Spring Boot 2.2.x\n* 2020.x for Spring Boot 2.4.x\n* 2021.x for Spring Boot 2.6.x\n* 2022.x for Spring Boot 3.0.x\n* 2023.x for Spring Boot 3.2.x\n* 2025.0.x for Spring Boot 3.5.x\n* 2025.1.x for Spring Boot 4.0.x\n\n## Code of Conduct\nThis project is a sub-project of Spring Cloud, it adheres to the Contributor Covenant [code of conduct](https://sca.aliyun.com/en-us/community/developer/contributor-guide/new-contributor-guide_dev/). By participating, you are expected to uphold this code. Please report unacceptable behavior to spring-code-of-conduct@pivotal.io.\n\n## Code Conventions and Housekeeping\nNone of these is essential for a pull request, but they will all help. They can also be added after the original pull request but before a merge.\n\nUse the Spring Framework code format conventions. If you use Eclipse you can import formatter settings using the eclipse-code-formatter.xml file from the Spring Cloud Build project. If using IntelliJ, you can use the Eclipse Code Formatter Plugin to import the same file.\n\nMake sure all new .java files to have a simple Javadoc class comment with at least an @author tag identifying you, and preferably at least a paragraph on what the class is for.\n\nAdd the ASF license header comment to all new .java files (copy from existing files in the project)\n\nAdd yourself as an @author to the .java files that you modify substantially (more than cosmetic changes).\n\nAdd some Javadocs and, if you change the namespace, some XSD doc elements.\n\nA few unit tests would help a lot as well‚Äâ‚Äî‚Äî‚Äâsomeone has to do it.\n\nIf no-one else is using your branch, please rebase it against the current 2023.x (or other target branch in the main project).\n\nWhen writing a commit message please follow these conventions, if you are fixing an existing issue please add Fixes gh-XXXX at the end of the commit message (where XXXX is the issue number).\n\n## Contact Us\nMailing list is recommended for discussing almost anything related to spring-cloud-alibaba. \n\nspring-cloud-alibaba@googlegroups.com: You can ask questions here if you encounter any problem when using or developing spring-cloud-alibaba.\n",
      "stars_today": 3
    },
    {
      "id": 100982449,
      "name": "argo-workflows",
      "full_name": "argoproj/argo-workflows",
      "description": "Workflow Engine for Kubernetes",
      "html_url": "https://github.com/argoproj/argo-workflows",
      "stars": 16385,
      "forks": 3459,
      "language": "Go",
      "topics": [
        "airflow",
        "argo",
        "argo-workflows",
        "batch-processing",
        "cloud-native",
        "cncf",
        "dag",
        "data-engineering",
        "gitops",
        "hacktoberfest",
        "k8s",
        "knative",
        "kubernetes",
        "machine-learning",
        "mlops",
        "pipelines",
        "workflow",
        "workflow-engine"
      ],
      "created_at": "2017-08-21T18:50:44Z",
      "updated_at": "2026-01-23T00:20:09Z",
      "pushed_at": "2026-01-22T09:13:51Z",
      "open_issues": 1353,
      "owner": {
        "login": "argoproj",
        "avatar_url": "https://avatars.githubusercontent.com/u/30269780?v=4"
      },
      "readme": "<!-- markdownlint-disable-next-line MD041 -->\n[![Security Status](https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml/badge.svg?branch=main)](https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml?query=branch%3Amain)\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/3830/badge)](https://bestpractices.coreinfrastructure.org/projects/3830)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows/badge)](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows)\n[![FOSSA License Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows?ref=badge_shield)\n[![Slack](https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack)](https://argoproj.github.io/community/join-slack)\n[![X Follow](https://img.shields.io/twitter/follow/argoproj?style=social)](https://x.com/argoproj)\n[![LinkedIn](https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin)](https://www.linkedin.com/company/argoproj/)\n[![Bluesky](https://img.shields.io/badge/Bluesky-argoproj-blue.svg?style=social&logo=bluesky)](https://bsky.app/profile/argoproj.bsky.social)\n[![Release Version](https://img.shields.io/github/v/release/argoproj/argo-workflows?label=argo-workflows)](https://github.com/argoproj/argo-workflows/releases/latest)\n[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-workflows)](https://artifacthub.io/packages/helm/argo/argo-workflows)\n\n## What is Argo Workflows?\n\nArgo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes.\nArgo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition).\n\n* Define workflows where each step is a container.\n* Model multi-step workflows as a sequence of tasks or capture the dependencies between tasks using a directed acyclic graph (DAG).\n* Easily run compute intensive jobs for machine learning or data processing in a fraction of the time using Argo Workflows on Kubernetes.\n\nArgo is a [Cloud Native Computing Foundation (CNCF)](https://cncf.io/) graduated project.\n\n## Use Cases\n\n* [Machine Learning pipelines](https://argo-workflows.readthedocs.io/en/latest/use-cases/machine-learning/)\n* [Data and batch processing](https://argo-workflows.readthedocs.io/en/latest/use-cases/data-processing/)\n* [Infrastructure automation](https://argo-workflows.readthedocs.io/en/latest/use-cases/infrastructure-automation/)\n* [CI/CD](https://argo-workflows.readthedocs.io/en/latest/use-cases/ci-cd/)\n* [Other use cases](https://argo-workflows.readthedocs.io/en/latest/use-cases/other/)\n\n## Why Argo Workflows?\n\n* Argo Workflows is the most popular workflow execution engine for Kubernetes.\n* Light-weight, scalable, and easier to use.\n    * Including for Python users through [the Hera Python SDK for Argo Workflows](https://hera.readthedocs.io/en/stable/).\n* Designed from the ground up for containers without the overhead and limitations of legacy VM and server-based environments.\n* Cloud agnostic and can run on any Kubernetes cluster.\n\n[Read what people said in our latest survey](https://blog.argoproj.io/argo-workflows-events-2023-user-survey-results-82c53bc30543)\n\n## Try Argo Workflows\n\nYou can try Argo Workflows via one of the following:\n\n1. [Interactive Training Material](https://killercoda.com/argoproj/course/argo-workflows/)\n1. [Access the demo environment](https://workflows.apps.argoproj.io/workflows/argo)\n\n![Screenshot](docs/assets/screenshot.png)\n\n## Who uses Argo Workflows?\n\n[About 200+ organizations are officially using Argo Workflows](USERS.md)\n\n## Ecosystem\n\nJust some of the projects that use or rely on Argo Workflows (complete list [here](https://github.com/akuity/awesome-argo#ecosystem-projects)):\n\n* [Argo Events](https://github.com/argoproj/argo-events)\n* [Couler](https://github.com/couler-proj/couler)\n* [Hera](https://github.com/argoproj-labs/hera-workflows)\n* [Katib](https://github.com/kubeflow/katib)\n* [Kedro](https://kedro.readthedocs.io/en/stable/)\n* [Kubeflow Pipelines](https://github.com/kubeflow/pipelines)\n* [Netflix Metaflow](https://metaflow.org)\n* [Onepanel](https://github.com/onepanelio/onepanel)\n* [Orchest](https://github.com/orchest/orchest/)\n* [Piper](https://github.com/quickube/piper)\n* [Ploomber](https://github.com/ploomber/ploomber)\n* [Seldon](https://github.com/SeldonIO/seldon-core)\n* [SQLFlow](https://github.com/sql-machine-learning/sqlflow)\n\n## Client Libraries\n\nCheck out our [Java, Golang, and Python (Hera) clients](docs/client-libraries.md).\n\n## Quickstart\n\n* [Get started here](https://argo-workflows.readthedocs.io/en/latest/quick-start/)\n* [Walk-through examples](https://argo-workflows.readthedocs.io/en/latest/walk-through/)\n\n## Documentation\n\n[View the docs](https://argo-workflows.readthedocs.io/en/latest/)\n\n## Features\n\nAn incomplete list of features Argo Workflows provides:\n\n* UI to visualize and manage Workflows\n* Artifact support (S3, Artifactory, Alibaba Cloud OSS, Azure Blob Storage, HTTP, Git, GCS, raw, plugins)\n* Workflow templating to store commonly used Workflows in the cluster\n* Archiving Workflows after executing for later access\n* Scheduled workflows using cron\n* Server interface with REST API (HTTP and GRPC)\n* DAG or Steps based declaration of workflows\n* Step level input & outputs (artifacts/parameters)\n* Loops\n* Parameterization\n* Conditionals\n* Timeouts (step & workflow level)\n* Retry (step & workflow level)\n* Resubmit (memoized)\n* Suspend & Resume\n* Cancellation\n* K8s resource orchestration\n* Exit Hooks (notifications, cleanup)\n* Garbage collection of completed workflow\n* Scheduling (affinity/tolerations/node selectors)\n* Volumes (ephemeral/existing)\n* Parallelism limits\n* Daemoned steps\n* DinD (docker-in-docker)\n* Script steps\n* Event emission\n* Prometheus metrics\n* Multiple executors\n* Multiple pod and workflow garbage collection strategies\n* Automatically calculated resource usage per step\n* Java, Golang, and Python (Hera) SDKs\n* Pod Disruption Budget support\n* Single-sign on (OAuth2/OIDC)\n* Webhook triggering\n* CLI\n* Out-of-the box and custom Prometheus metrics\n* Windows container support\n* Embedded widgets\n* Multiplex log viewer\n\n## Community Meetings\n\nWe host monthly community meetings where we and the community showcase demos and discuss the current and future state of the project. Feel free to join us!\nFor Community Meeting information, minutes and recordings, please [see here](https://bit.ly/argo-wf-cmty-mtng).\n\nParticipation in Argo Workflows is governed by the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md)\n\n## Community Blogs and Presentations\n\n* [Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo](https://github.com/terrytangyuan/awesome-argo)\n* [Automation of Everything - How To Combine Argo Events, Workflows & Pipelines, CD, and Rollouts](https://youtu.be/XNXJtxkUKeY)\n* [Argo Workflows and Pipelines - CI/CD, Machine Learning, and Other Kubernetes Workflows](https://youtu.be/UMaivwrAyTA)\n* [Argo Ansible role: Provisioning Argo Workflows on OpenShift](https://medium.com/@marekermk/provisioning-argo-on-openshift-with-ansible-and-kustomize-340a1fda8b50)\n* [Argo Workflows vs Apache Airflow](http://bit.ly/30YNIvT)\n* [Beyond Prototypes: Production-Ready ML Systems with Metaflow and Argo](https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-na-2023-metaflow-argo)\n* [CI/CD with Argo on Kubernetes](https://medium.com/@bouwe.ceunen/ci-cd-with-argo-on-kubernetes-28c1a99616a9)\n* [Define Your CI/CD Pipeline with Argo Workflows](https://haque-zubair.medium.com/define-your-ci-cd-pipeline-with-argo-workflows-25aefb02fa63)\n* [Distributed Machine Learning Patterns from Manning Publication](https://github.com/terrytangyuan/distributed-ml-patterns)\n* [Engineering Cloud Native AI Platform](https://github.com/terrytangyuan/public-talks/tree/main/talks/platform-con-2024-engineering-cloud-native-ai-platform)\n* [Managing Thousands of Automatic Machine Learning Experiments with Argo and Katib](https://github.com/terrytangyuan/public-talks/blob/main/talks/argocon-automl-experiments-2022)\n* [Autonomous Driving Data Pipelines Reconstruction With Argo Workflows](https://www.youtube.com/watch?v=oTgIQxbsLhU)\n* [Revolutionizing Scientific Simulations with Argo Workflows](https://www.youtube.com/watch?v=BYVf7GhfiRg)\n* [Running Argo Workflows Across Multiple Kubernetes Clusters](https://admiralty.io/blog/running-argo-workflows-across-multiple-kubernetes-clusters/)\n* [Scaling Kubernetes: Best Practices for Managing Large-Scale Batch Jobs with Spark and Argo Workflow](https://www.youtube.com/watch?v=KqEKRPjy4aE)\n* [Open Source Model Management Roundup: Polyaxon, Argo, and Seldon](https://www.anaconda.com/blog/developer-blog/open-source-model-management-roundup-polyaxon-argo-and-seldon/)\n* [Producing 200 OpenStreetMap extracts in 35 minutes using a scalable data workflow](https://www.interline.io/blog/scaling-openstreetmap-data-workflows/)\n* [Production-Ready AI Platform on Kubernetes](https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-europe-2024-production-ai-platform-on-k8s)\n* [Argo integration review](http://dev.matt.hillsdon.net/2018/03/24/argo-integration-review.html)\n* TGI Kubernetes with Joe Beda: [Argo workflow system](https://www.youtube.com/watch?v=M_rxPPLG8pU&start=859)\n\n## Project Resources\n\n* [Argo Project GitHub organization](https://github.com/argoproj)\n* [Argo Website](https://argoproj.github.io/)\n* [Argo Slack](https://argoproj.github.io/community/join-slack)\n\n## Security\n\nSee [SECURITY.md](SECURITY.md).\n",
      "stars_today": 3
    },
    {
      "id": 15122806,
      "name": "benchmark",
      "full_name": "google/benchmark",
      "description": "A microbenchmark support library",
      "html_url": "https://github.com/google/benchmark",
      "stars": 9966,
      "forks": 1731,
      "language": "C++",
      "topics": [
        "benchmark"
      ],
      "created_at": "2013-12-12T00:10:48Z",
      "updated_at": "2026-01-23T00:37:18Z",
      "pushed_at": "2026-01-22T20:07:59Z",
      "open_issues": 182,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# Benchmark\n\n[![build-and-test](https://github.com/google/benchmark/workflows/build-and-test/badge.svg)](https://github.com/google/benchmark/actions?query=workflow%3Abuild-and-test)\n[![bazel](https://github.com/google/benchmark/actions/workflows/bazel.yml/badge.svg)](https://github.com/google/benchmark/actions/workflows/bazel.yml)\n[![test-bindings](https://github.com/google/benchmark/workflows/test-bindings/badge.svg)](https://github.com/google/benchmark/actions?query=workflow%3Atest-bindings)\n[![Coverage Status](https://coveralls.io/repos/google/benchmark/badge.svg)](https://coveralls.io/r/google/benchmark)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/google/benchmark/badge)](https://securityscorecards.dev/viewer/?uri=github.com/google/benchmark)\n\n[![Discord](https://discordapp.com/api/guilds/1125694995928719494/widget.png?style=shield)](https://discord.gg/cz7UX7wKC2)\n\nA library to benchmark code snippets, similar to unit tests. Example:\n\n```c++\n#include <benchmark/benchmark.h>\n\nstatic void BM_SomeFunction(benchmark::State& state) {\n  // Perform setup here\n  for (auto _ : state) {\n    // This code gets timed\n    SomeFunction();\n  }\n}\n// Register the function as a benchmark\nBENCHMARK(BM_SomeFunction);\n// Run the benchmark\nBENCHMARK_MAIN();\n```\n\n## Getting Started\n\nTo get started, see [Requirements](#requirements) and\n[Installation](#installation). See [Usage](#usage) for a full example and the\n[User Guide](docs/user_guide.md) for a more comprehensive feature overview.\n\nIt may also help to read the [Google Test documentation](https://github.com/google/googletest/blob/main/docs/primer.md)\nas some of the structural aspects of the APIs are similar.\n\n## Resources\n\n[Discussion group](https://groups.google.com/d/forum/benchmark-discuss)\n\nIRC channels:\n* [libera](https://libera.chat) #benchmark\n\n[Additional Tooling Documentation](docs/tools.md)\n\n[Assembly Testing Documentation](docs/AssemblyTests.md)\n\n[Building and installing Python bindings](docs/python_bindings.md)\n\n## Requirements\n\nThe library can be used with C++11. However, it requires C++17 to build,\nincluding compiler and standard library support.\n\n_See [dependencies.md](docs/dependencies.md) for more details regarding supported\ncompilers and standards._\n\nIf you have need for a particular compiler to be supported, patches are very welcome.\n\nSee [Platform-Specific Build Instructions](docs/platform_specific_build_instructions.md).\n\n## Installation\n\nThis describes the installation process using cmake. As pre-requisites, you'll\nneed git and cmake installed.\n\n_See [dependencies.md](docs/dependencies.md) for more details regarding supported\nversions of build tools._\n\n```bash\n# Check out the library.\n$ git clone https://github.com/google/benchmark.git\n# Go to the library root directory\n$ cd benchmark\n# Make a build directory to place the build output.\n$ cmake -E make_directory \"build\"\n# Generate build system files with cmake, and download any dependencies.\n$ cmake -E chdir \"build\" cmake -DBENCHMARK_DOWNLOAD_DEPENDENCIES=on -DCMAKE_BUILD_TYPE=Release ../\n# or, starting with CMake 3.13, use a simpler form:\n# cmake -DBENCHMARK_DOWNLOAD_DEPENDENCIES=on -DCMAKE_BUILD_TYPE=Release -S . -B \"build\"\n# Build the library.\n$ cmake --build \"build\" --config Release\n```\nThis builds the `benchmark` and `benchmark_main` libraries and tests.\nOn a unix system, the build directory should now look something like this:\n\n```\n/benchmark\n  /build\n    /src\n      /libbenchmark.a\n      /libbenchmark_main.a\n    /test\n      ...\n```\n\nNext, you can run the tests to check the build.\n\n```bash\n$ cmake -E chdir \"build\" ctest --build-config Release\n```\n\nIf you want to install the library globally, also run:\n\n```\nsudo cmake --build \"build\" --config Release --target install\n```\n\nNote that Google Benchmark requires Google Test to build and run the tests. This\ndependency can be provided two ways:\n\n* Checkout the Google Test sources into `benchmark/googletest`.\n* Otherwise, if `-DBENCHMARK_DOWNLOAD_DEPENDENCIES=ON` is specified during\n  configuration as above, the library will automatically download and build\n  any required dependencies.\n\nIf you do not wish to build and run the tests, add `-DBENCHMARK_ENABLE_GTEST_TESTS=OFF`\nto `CMAKE_ARGS`.\n\n### Debug vs Release\n\nBy default, benchmark builds as a debug library. You will see a warning in the\noutput when this is the case. To build it as a release library instead, add\n`-DCMAKE_BUILD_TYPE=Release` when generating the build system files, as shown\nabove. The use of `--config Release` in build commands is needed to properly\nsupport multi-configuration tools (like Visual Studio for example) and can be\nskipped for other build systems (like Makefile).\n\nTo enable link-time optimisation, also add `-DBENCHMARK_ENABLE_LTO=true` when\ngenerating the build system files.\n\nIf you are using gcc, you might need to set `GCC_AR` and `GCC_RANLIB` cmake\ncache variables, if autodetection fails.\n\nIf you are using clang, you may need to set `LLVMAR_EXECUTABLE`,\n`LLVMNM_EXECUTABLE` and `LLVMRANLIB_EXECUTABLE` cmake cache variables.\n\nTo enable sanitizer checks (eg., `asan` and `tsan`), add:\n```\n -DCMAKE_C_FLAGS=\"-g -O2 -fno-omit-frame-pointer -fsanitize=address -fsanitize=thread -fno-sanitize-recover=all\"\n -DCMAKE_CXX_FLAGS=\"-g -O2 -fno-omit-frame-pointer -fsanitize=address -fsanitize=thread -fno-sanitize-recover=all \"  \n```\n\n### Stable and Experimental Library Versions\n\nThe main branch contains the latest stable version of the benchmarking library;\nthe API of which can be considered largely stable, with source breaking changes\nbeing made only upon the release of a new major version.\n\nNewer, experimental, features are implemented and tested on the\n[`v2` branch](https://github.com/google/benchmark/tree/v2). Users who wish\nto use, test, and provide feedback on the new features are encouraged to try\nthis branch. However, this branch provides no stability guarantees and reserves\nthe right to change and break the API at any time.\n\n## Usage\n\n### Basic usage\n\nDefine a function that executes the code to measure, register it as a benchmark\nfunction using the `BENCHMARK` macro, and ensure an appropriate `main` function\nis available:\n\n```c++\n#include <benchmark/benchmark.h>\n\nstatic void BM_StringCreation(benchmark::State& state) {\n  for (auto _ : state)\n    std::string empty_string;\n}\n// Register the function as a benchmark\nBENCHMARK(BM_StringCreation);\n\n// Define another benchmark\nstatic void BM_StringCopy(benchmark::State& state) {\n  std::string x = \"hello\";\n  for (auto _ : state)\n    std::string copy(x);\n}\nBENCHMARK(BM_StringCopy);\n\nBENCHMARK_MAIN();\n```\n\nTo run the benchmark, compile and link against the `benchmark` library\n(libbenchmark.a/.so). If you followed the build steps above, this library will \nbe under the build directory you created.\n\n```bash\n# Example on linux after running the build steps above. Assumes the\n# `benchmark` and `build` directories are under the current directory.\n$ g++ mybenchmark.cc -std=c++11 -isystem benchmark/include \\\n  -Lbenchmark/build/src -lbenchmark -lpthread -o mybenchmark\n```\n\nAlternatively, link against the `benchmark_main` library and remove\n`BENCHMARK_MAIN();` above to get the same behavior.\n\nThe compiled executable will run all benchmarks by default. Pass the `--help`\nflag for option information or see the [User Guide](docs/user_guide.md).\n\n### Usage with CMake\n\nIf using CMake, it is recommended to link against the project-provided\n`benchmark::benchmark` and `benchmark::benchmark_main` targets using\n`target_link_libraries`.\nIt is possible to use ```find_package``` to import an installed version of the\nlibrary.\n```cmake\nfind_package(benchmark REQUIRED)\n```\nAlternatively, ```add_subdirectory``` will incorporate the library directly in\nto one's CMake project.\n```cmake\nadd_subdirectory(benchmark)\n```\nEither way, link to the library as follows.\n```cmake\ntarget_link_libraries(MyTarget benchmark::benchmark)\n```\n",
      "stars_today": 3
    },
    {
      "id": 93446042,
      "name": "terraform-provider-azurerm",
      "full_name": "hashicorp/terraform-provider-azurerm",
      "description": "Terraform provider for Azure Resource Manager",
      "html_url": "https://github.com/hashicorp/terraform-provider-azurerm",
      "stars": 4890,
      "forks": 4930,
      "language": "Go",
      "topics": [
        "azure",
        "azure-resource-manager",
        "terraform",
        "terraform-provider"
      ],
      "created_at": "2017-06-05T20:53:54Z",
      "updated_at": "2026-01-22T23:16:14Z",
      "pushed_at": "2026-01-22T23:16:09Z",
      "open_issues": 3795,
      "owner": {
        "login": "hashicorp",
        "avatar_url": "https://avatars.githubusercontent.com/u/761456?v=4"
      },
      "readme": "<a href=\"https://terraform.io\">\n    <img src=\".github/tf.png\" alt=\"Terraform logo\" title=\"Terraform\" align=\"left\" height=\"50\" />\n</a>\n\n# Terraform Provider for Azure (Resource Manager)\n\nThe AzureRM Terraform Provider allows managing resources within Azure Resource Manager.\n\nWhen using version 4.0 of the AzureRM Provider we recommend using the latest version of Terraform Core ([the latest version can be found here](https://developer.hashicorp.com/terraform/install)). \n\n* [Terraform Website](https://www.terraform.io)\n* [AzureRM Provider Documentation](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs)\n* [AzureRM Provider Usage Examples](https://github.com/hashicorp/terraform-provider-azurerm/tree/main/examples)\n* [Slack Workspace for Contributors](https://terraform-azure.slack.com) ([Request Invite](https://join.slack.com/t/terraform-azure/shared_invite/enQtNDMzNjQ5NzcxMDc3LWNiY2ZhNThhNDgzNmY0MTM0N2MwZjE4ZGU0MjcxYjUyMzRmN2E5NjZhZmQ0ZTA1OTExMGNjYzA4ZDkwZDYxNDE))\n\n## Usage Example\n\n```hcl\n# 1. Specify the version of the AzureRM Provider to use\nterraform {\n  required_providers {\n    azurerm = {\n      source = \"hashicorp/azurerm\"\n      version = \"=4.0.0\"\n    }\n  }\n}\n\n# 2. Configure the AzureRM Provider\nprovider \"azurerm\" {\n  # The AzureRM Provider supports authenticating using via the Azure CLI, a Managed Identity\n  # and a Service Principal. More information on the authentication methods supported by\n  # the AzureRM Provider can be found here:\n  # https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs#authenticating-to-azure\n\n  # The features block allows changing the behaviour of the Azure Provider, more\n  # information can be found here:\n  # https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/guides/features-block\n  features {}\n}\n\n# 3. Create a resource group\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"example-resources\"\n  location = \"West Europe\"\n}\n\n# 4. Create a virtual network within the resource group\nresource \"azurerm_virtual_network\" \"example\" {\n  name                = \"example-network\"\n  resource_group_name = azurerm_resource_group.example.name\n  location            = azurerm_resource_group.example.location\n  address_space       = [\"10.0.0.0/16\"]\n}\n```\n\n* [Usage documentation for the AzureRM Provider can be found in the Terraform Registry](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs).\n* [Learn more about Terraform and the AzureRM Provider on HashiCorp Learn](https://learn.hashicorp.com/collections/terraform/azure-get-started).\n* [Additional examples can be found in the `./examples` folder within this repository](https://github.com/hashicorp/terraform-provider-azurerm/tree/main/examples).\n\n## Developing & Contributing to the Provider\n\nThe [DEVELOPER.md](DEVELOPER.md) file is a basic outline on how to build and develop the provider while more detailed guides geared towards contributors can be found in the [`/contributing`](https://github.com/hashicorp/terraform-provider-azurerm/tree/main/contributing) directory of this repository.\n",
      "stars_today": 3
    },
    {
      "id": 340402576,
      "name": "react-native-vision-camera",
      "full_name": "mrousavy/react-native-vision-camera",
      "description": "üì∏ A powerful, high-performance React Native Camera library.",
      "html_url": "https://github.com/mrousavy/react-native-vision-camera",
      "stars": 9130,
      "forks": 1318,
      "language": "Swift",
      "topics": [
        "ai",
        "android",
        "barcode",
        "camera",
        "instagram",
        "ios",
        "javascript",
        "jsi",
        "library",
        "native",
        "qr",
        "qrcode",
        "react",
        "react-native",
        "react-native-camera",
        "scanner",
        "snapchat",
        "typescript",
        "vision",
        "worklet"
      ],
      "created_at": "2021-02-19T14:59:44Z",
      "updated_at": "2026-01-22T13:45:39Z",
      "pushed_at": "2026-01-07T18:05:33Z",
      "open_issues": 365,
      "owner": {
        "login": "mrousavy",
        "avatar_url": "https://avatars.githubusercontent.com/u/15199031?v=4"
      },
      "readme": "<a href=\"https://margelo.com\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"./docs/static/img/banner-dark.png\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"./docs/static/img/banner-light.png\" />\n    <img alt=\"VisionCamera\" src=\"./docs/static/img/banner-light.png\" />\n  </picture>\n</a>\n\n<br />\n\n<div>\n  <img align=\"right\" width=\"35%\" src=\"docs/static/img/example.png\">\n</div>\n\n### Features\n\nVisionCamera is a powerful, high-performance Camera library for React Native. It features:\n\n* üì∏ Photo and Video capture\n* üëÅÔ∏è QR/Barcode scanner\n* üì± Customizable devices and multi-cameras (\"fish-eye\" zoom)\n* üéûÔ∏è Customizable resolutions and aspect-ratios (4k/8k images)\n* ‚è±Ô∏è Customizable FPS (30..240 FPS)\n* üß© [Frame Processors](https://react-native-vision-camera.com/docs/guides/frame-processors) (JS worklets to run facial recognition, AI object detection, realtime video chats, ...)\n* üé® Drawing shapes, text, filters or shaders onto the Camera\n* üîç Smooth zooming (Reanimated)\n* ‚èØÔ∏è Fast pause and resume\n* üåì HDR & Night modes\n* ‚ö° Custom C++/GPU accelerated video pipeline (OpenGL)\n\nInstall VisionCamera from npm:\n\n```sh\nnpm i react-native-vision-camera\ncd ios && pod install\n```\n\n..and get started by [setting up permissions](https://react-native-vision-camera.com/docs/guides)!\n\n### Documentation\n\n* [Guides](https://react-native-vision-camera.com/docs/guides)\n* [API](https://react-native-vision-camera.com/docs/api)\n* [Example](./example/)\n* [Frame Processor Plugins](https://react-native-vision-camera.com/docs/guides/frame-processor-plugins-community)\n\n### ShadowLens\n\nTo see VisionCamera in action, check out [ShadowLens](https://mrousavy.com/projects/shadowlens)!\n\n<div>\n  <a href=\"https://apps.apple.com/app/shadowlens/id6471849004\">\n    <img height=\"40\" src=\"docs/static/img/appstore.svg\" />\n  </a>\n  <a href=\"https://play.google.com/store/apps/details?id=com.mrousavy.shadowlens\">\n    <img height=\"40\" src=\"docs/static/img/googleplay.svg\" />\n  </a>\n</div>\n\n### Example\n\n```tsx\nfunction App() {\n  const device = useCameraDevice('back')\n\n  if (device == null) return <NoCameraErrorView />\n  return (\n    <Camera\n      style={StyleSheet.absoluteFill}\n      device={device}\n      isActive={true}\n    />\n  )\n}\n```\n\n> See the [example](./example/) app\n\n### Adopting at scale\n\n<a href=\"https://github.com/sponsors/mrousavy\">\n  <img align=\"right\" width=\"160\" alt=\"This library helped you? Consider sponsoring!\" src=\".github/funding-octocat.svg\">\n</a>\n\nVisionCamera is provided _as is_, I work on it in my free time.\n\nIf you're integrating VisionCamera in a production app, consider [funding this project](https://github.com/sponsors/mrousavy) and <a href=\"mailto:me@mrousavy.com?subject=Adopting VisionCamera at scale\">contact me</a> to receive premium enterprise support, help with issues, prioritize bugfixes, request features, help at integrating VisionCamera and/or Frame Processors, and more.\n\n### Socials\n\n* üê¶ [**Follow me on Twitter**](https://twitter.com/mrousavy) for updates\n* üìù [**Check out my blog**](https://mrousavy.com/blog) for examples and experiments\n* üí¨ [**Join the Margelo Community Discord**](https://margelo.com/discord) for chatting about VisionCamera\n* üíñ [**Sponsor me on GitHub**](https://github.com/sponsors/mrousavy) to support my work\n* üç™ [**Buy me a Ko-Fi**](https://ko-fi.com/mrousavy) to support my work\n",
      "stars_today": 3
    },
    {
      "id": 93515203,
      "name": "koin",
      "full_name": "InsertKoinIO/koin",
      "description": "Koin - a pragmatic lightweight dependency injection framework for Kotlin & Kotlin Multiplatform",
      "html_url": "https://github.com/InsertKoinIO/koin",
      "stars": 9801,
      "forks": 771,
      "language": "Kotlin",
      "topics": [
        "android",
        "dependency-injection",
        "injection",
        "kotlin",
        "kotlin-multiplatform",
        "kotlin-multiplatform-library",
        "library"
      ],
      "created_at": "2017-06-06T12:21:06Z",
      "updated_at": "2026-01-22T14:14:44Z",
      "pushed_at": "2026-01-21T06:53:50Z",
      "open_issues": 71,
      "owner": {
        "login": "InsertKoinIO",
        "avatar_url": "https://avatars.githubusercontent.com/u/38280958?v=4"
      },
      "readme": "![logo](./docs/img/koin_main_logo.png)\n\n[![Kotlin](https://img.shields.io/badge/Kotlin-2.2.21-blue.svg?style=flat&logo=kotlin)](https://kotlinlang.org)\n![Github Actions](https://github.com/InsertKoinIO/koin/actions/workflows/build.yml/badge.svg)\n[![Apache 2 License](https://img.shields.io/github/license/InsertKoinIO/koin)](https://github.com/InsertKoinIO/koin/blob/main/LICENSE.txt)\n[![Slack channel](https://img.shields.io/badge/Chat-Slack-orange.svg?style=flat&logo=slack)](https://kotlinlang.slack.com/messages/koin/)\n\n[![Free Monitoring](https://img.shields.io/badge/Kotzilla.io-Free%20Monitoring-brightgreen?style=flat&logo=kotlin&logoColor=white)]([https://forms.gle/YOUR-FORM-ID](https://bit.ly/koin_opensource_monitoring))\n\n\n# What is KOIN? ‚ú®\n \nKoin is a pragmatic, lightweight dependency injection framework for Kotlin developers, developed by [Kotzilla](https://kotzilla.io) and open-source [contributors](https://github.com/InsertKoinIO/koin/graphs/contributors).\n\n`Koin is a DSL, a light container and a pragmatic API`\n\n\n## Setup & Current Version üì¶\n\nFollow the dedicated [setup page](https://insert-koin.io/docs/setup/koin) to setup Koin for your project.\nHere are the currently available Koin versions:\n\n- **Stable** Version : [![Maven Central](https://img.shields.io/maven-central/v/io.insert-koin/koin-core/4.1.1)](https://mvnrepository.com/artifact/io.insert-koin/koin-core/4.1.1)\n- **Unstable** Version : [![Maven Central](https://img.shields.io/maven-central/v/io.insert-koin/koin-core)](https://mvnrepository.com/artifact/io.insert-koin/koin-core)\n\nTake a look at:\n- [Release Upgrade Guide](https://insert-koin.io/docs/support/releases) to anticipate your next version upgrade.\n- [Versioning](https://insert-koin.io/docs/support/)\n- [API Stability](https://insert-koin.io/docs/support/api-stability)\n\n## Community & Enterprise Support üí¨\n\n- Come talk on slack [#koin](https://kotlinlang.slack.com/?redir=%2Fmessages%2Fkoin) channel\n- Post your question on [Stackoverflow](https://stackoverflow.com/questions/tagged/koin)\n- Found a bug or a problem? Open an issue on [Github issues](https://github.com/InsertKoinIO/koin/issues)\n- Opt into [Koin 3.5 LTS](https://kotzilla.io/koin-lts) SLA-backed updates, long-term maintenance, and direct access to Kotzilla experts\n\n## Debugging & Performance Monitoring üõ†Ô∏è\n\n- **Koin Plugin** can be freely downloaded on [Jetbrains Marketplace](https://plugins.jetbrains.com/plugin/26131-koin-dependency-injection-official-/versions/stable)\n> The pragmatic Kotlin and Kotlin Multiplatform Dependency Injection framework now with native support for IntelliJ IDEA and Android Studio.\n\n- **Kotzilla Platform** Free signup on [Kotzilla](https://kotzilla.io)\n> is a console-based suite with connected cloud services that visualizes your Koin module structure, monitors runtime performance and memory metrics, provides advanced debugging and tracing, and seamlessly integrates with Kotlin Multiplatform projects. \n\n### üöÄ Free Monitoring for Koin Apps\n\nKotzilla.io ‚Äî the team behind [Koin](https://insert-koin.io) ‚Äî offers **free monitoring** for any open source Android or KMP app using Koin and published on the Google Play Store.\n\nüëâ [Apply for Free Monitoring](https://bit.ly/koin_opensource_monitoring)\n\n## Latest News & Resources üåê\n- Official Website: [insert-koin.io](https://insert-koin.io)\n- Twitter: [@insertkoin_io](https://twitter.com/insertkoin_io)\n- Blog: [Koin Developers](https://blog.insert-koin.io)\n- Newsletter: [Koin Newsletter](https://bit.ly/koin_newsletter)\n\n## Koin Tutorials üöÄ\n\nYou can find here tutorials to help you learn and get started with the Koin framework:\n- [Kotlin](https://insert-koin.io/docs/quickstart/kotlin)\n- [Kotlin with Koin Annotations](https://insert-koin.io/docs/quickstart/kotlin-annotations)\n- [Android](https://insert-koin.io/docs/quickstart/android-viewmodel)\n- [Android with Koin Annotations](https://insert-koin.io/docs/quickstart/android-annotations)\n- [Android Jetpack Compose](https://insert-koin.io/docs/quickstart/android-compose)\n- [Kotlin Multiplatform](https://insert-koin.io/docs/quickstart/kmp)\n- [Ktor](https://insert-koin.io/docs/quickstart/ktor)\n\n## Contributing üõ†\n\nWant to help or share a proposal about Koin? Problem with a specific feature? \n\n- Open an issue to explain the issue you want to solve [Open an issue](https://github.com/InsertKoinIO/koin/issues)\n- Come talk on slack [#koin-dev](https://kotlinlang.slack.com/?redir=%2Fmessages%2Fkoin-dev) channel\n- After discussion to validate your ideas, you can open a PR or even a draft PR if the contribution is a big one [Current PRs](https://github.com/InsertKoinIO/koin/pulls)\n\nAdditional readings about basic setup: https://github.com/InsertKoinIO/koin/blob/master/CONTRIBUTING.adoc\n\n### Contributors\n\nThank you all for your work! ‚ù§Ô∏è\n\n<a href=\"https://github.com/InsertKoinIO/koin/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=InsertKoinIO/koin\" />\n</a>\n\n## OpenCollective - Sponsorship ‚ù§Ô∏è\n\nSupport this project by becoming a sponsor and be displayed on the offcial website. [[Help us and Become a sponsor!](https://opencollective.com/koin#sponsor)]\n",
      "stars_today": 3
    },
    {
      "id": 3276860,
      "name": "Unity",
      "full_name": "ThrowTheSwitch/Unity",
      "description": "Simple unit testing for C",
      "html_url": "https://github.com/ThrowTheSwitch/Unity",
      "stars": 5008,
      "forks": 1095,
      "language": "C",
      "topics": [
        "c",
        "unit-testing"
      ],
      "created_at": "2012-01-26T19:52:36Z",
      "updated_at": "2026-01-22T04:04:41Z",
      "pushed_at": "2025-11-12T14:50:31Z",
      "open_issues": 110,
      "owner": {
        "login": "ThrowTheSwitch",
        "avatar_url": "https://avatars.githubusercontent.com/u/1049138?v=4"
      },
      "readme": "# Unity Test ![CI][]\n\n__Copyright (c) 2007 - 2024 Unity Project by Mike Karlesky, Mark VanderVoord, and Greg Williams__\n\nWelcome to the Unity Test Project, one of the main projects of ThrowTheSwitch.org.\nUnity Test is a unit testing framework built for C, with a focus on working with embedded toolchains.\n\nThis project is made to test code targetting microcontrollers big and small.\nThe core project is a single C file and a pair of headers, allowing it to be added to your existing build setup without too much headache.\nYou may use any compiler you wish, and may use most existing build systems including Make, CMake, etc.\nIf you'd like to leave the hard work to us, you might be interested in Ceedling, a build tool also by ThrowTheSwitch.org.\n\nIf you're new to Unity, we encourage you to tour the [getting started guide][].\n\nYou can also find the [change log][] and [known issues][] in our documentation.\n\n## Getting Started\n\nThe [docs][] folder contains a [getting started guide][] and much more tips about using Unity.\n\n## Unity Assertion Summary\n\nFor the full list, see [UnityAssertionsReference.md][].\n\n### Basic Validity Tests\n\n    TEST_ASSERT_TRUE(condition)\n\nEvaluates whatever code is in condition and fails if it evaluates to false\n\n    TEST_ASSERT_FALSE(condition)\n\nEvaluates whatever code is in condition and fails if it evaluates to true\n\n    TEST_ASSERT(condition)\n\nAnother way of calling `TEST_ASSERT_TRUE`\n\n    TEST_ASSERT_UNLESS(condition)\n\nAnother way of calling `TEST_ASSERT_FALSE`\n\n    TEST_FAIL()\n    TEST_FAIL_MESSAGE(message)\n\nThis test is automatically marked as a failure.\nThe message is output stating why.\n\n### Numerical Assertions: Integers\n\n    TEST_ASSERT_EQUAL_INT(expected, actual)\n    TEST_ASSERT_EQUAL_INT8(expected, actual)\n    TEST_ASSERT_EQUAL_INT16(expected, actual)\n    TEST_ASSERT_EQUAL_INT32(expected, actual)\n    TEST_ASSERT_EQUAL_INT64(expected, actual)\n\nCompare two integers for equality and display errors as signed integers.\nA cast will be performed to your natural integer size so often this can just be used.\nWhen you need to specify the exact size, you can use a specific version.\n\n    TEST_ASSERT_EQUAL_UINT(expected, actual)\n    TEST_ASSERT_EQUAL_UINT8(expected, actual)\n    TEST_ASSERT_EQUAL_UINT16(expected, actual)\n    TEST_ASSERT_EQUAL_UINT32(expected, actual)\n    TEST_ASSERT_EQUAL_UINT64(expected, actual)\n\nCompare two integers for equality and display errors as unsigned integers.\nLike INT, there are variants for different sizes also.\n\n    TEST_ASSERT_EQUAL_HEX(expected, actual)\n    TEST_ASSERT_EQUAL_HEX8(expected, actual)\n    TEST_ASSERT_EQUAL_HEX16(expected, actual)\n    TEST_ASSERT_EQUAL_HEX32(expected, actual)\n    TEST_ASSERT_EQUAL_HEX64(expected, actual)\n\nCompares two integers for equality and display errors as hexadecimal.\nLike the other integer comparisons, you can specify the size... \nhere the size will also affect how many nibbles are shown (for example, `HEX16` will show 4 nibbles).\n\n    TEST_ASSERT_EQUAL(expected, actual)\n\nAnother way of calling TEST_ASSERT_EQUAL_INT\n\n    TEST_ASSERT_INT_WITHIN(delta, expected, actual)\n\nAsserts that the actual value is within plus or minus delta of the expected value.\nThis also comes in size specific variants.\n\n    TEST_ASSERT_GREATER_THAN(threshold, actual)\n\nAsserts that the actual value is greater than the threshold.\nThis also comes in size specific variants.\n\n    TEST_ASSERT_LESS_THAN(threshold, actual)\n\nAsserts that the actual value is less than the threshold.\nThis also comes in size specific variants.\n\n### Arrays\n\n    _ARRAY\n\nYou can append `_ARRAY` to any of these macros to make an array comparison of that type.\nHere you will need to care a bit more about the actual size of the value being checked.\nYou will also specify an additional argument which is the number of elements to compare.\nFor example:\n\n    TEST_ASSERT_EQUAL_HEX8_ARRAY(expected, actual, elements)\n\n    _EACH_EQUAL\n\nAnother array comparison option is to check that EVERY element of an array is equal to a single expected value.\nYou do this by specifying the EACH_EQUAL macro.\nFor example:\n\n    TEST_ASSERT_EACH_EQUAL_INT32(expected, actual, elements)\n\n### Numerical Assertions: Bitwise\n\n    TEST_ASSERT_BITS(mask, expected, actual)\n\nUse an integer mask to specify which bits should be compared between two other integers.\nHigh bits in the mask are compared, low bits ignored.\n\n    TEST_ASSERT_BITS_HIGH(mask, actual)\n\nUse an integer mask to specify which bits should be inspected to determine if they are all set high.\nHigh bits in the mask are compared, low bits ignored.\n\n    TEST_ASSERT_BITS_LOW(mask, actual)\n\nUse an integer mask to specify which bits should be inspected to determine if they are all set low.\nHigh bits in the mask are compared, low bits ignored.\n\n    TEST_ASSERT_BIT_HIGH(bit, actual)\n\nTest a single bit and verify that it is high.\nThe bit is specified 0-31 for a 32-bit integer.\n\n    TEST_ASSERT_BIT_LOW(bit, actual)\n\nTest a single bit and verify that it is low.\nThe bit is specified 0-31 for a 32-bit integer.\n\n### Numerical Assertions: Floats\n\n    TEST_ASSERT_FLOAT_WITHIN(delta, expected, actual)\n    TEST_ASSERT_DOUBLE_WITHIN(delta, expected, actual)\n\nAsserts that the actual value is within plus or minus delta of the expected value.\n\n    TEST_ASSERT_FLOAT_NOT_WITHIN(delta, expected, actual)\n    TEST_ASSERT_DOUBLE_NOT_WITHIN(delta, expected, actual)\n\nAsserts that the actual value is NOT within plus or minus delta of the expected value.\n\n    TEST_ASSERT_EQUAL_FLOAT(expected, actual)\n    TEST_ASSERT_EQUAL_DOUBLE(expected, actual)\n\nAsserts that two floating point values are \"equal\" within a small % delta of the expected value.\n\n    TEST_ASSERT_NOT_EQUAL_FLOAT(expected, actual)\n    TEST_ASSERT_NOT_EQUAL_DOUBLE(expected, actual)\n\nAsserts that two floating point values are NOT \"equal\" within a small % delta of the expected value.\n\n    TEST_ASSERT_LESS_THAN_FLOAT(threshold, actual)\n    TEST_ASSERT_LESS_THAN_DOUBLE(threshold, actual)\n    TEST_ASSERT_GREATER_THAN_FLOAT(threshold, actual)\n    TEST_ASSERT_GREATER_THAN_DOUBLE(threshold, actual)\n\nAsserts that the actual value is less than or greater than the threshold.\n\nThere are also `LESS_OR_EQUAL` and `GREATER_OR_EQUAL` variations.\nThese obey the same rules for equality as do `TEST_ASSERT_EQUAL_FLOAT` and `TEST_ASSERT_EQUAL_DOUBLE`:\nIf the two values are within a small % delta of the expected value, the assertion will pass.\n\n### String Assertions\n\n    TEST_ASSERT_EQUAL_STRING(expected, actual)\n\nCompare two null-terminate strings.\nFail if any character is different or if the lengths are different.\n\n    TEST_ASSERT_EQUAL_STRING_LEN(expected, actual, len)\n\nCompare two strings.\nFail if any character is different, stop comparing after len characters.\n\n    TEST_ASSERT_EQUAL_STRING_MESSAGE(expected, actual, message)\n\nCompare two null-terminate strings.\nFail if any character is different or if the lengths are different.\nOutput a custom message on failure.\n\n    TEST_ASSERT_EQUAL_STRING_LEN_MESSAGE(expected, actual, len, message)\n\nCompare two strings.\nFail if any character is different, stop comparing after len characters.\nOutput a custom message on failure.\n\n### Pointer Assertions\n\nMost pointer operations can be performed by simply using the integer comparisons above.\nHowever, a couple of special cases are added for clarity.\n\n    TEST_ASSERT_NULL(pointer)\n\nFails if the pointer is not equal to NULL\n\n    TEST_ASSERT_NOT_NULL(pointer)\n\nFails if the pointer is equal to NULL\n\n### Memory Assertions\n\n    TEST_ASSERT_EQUAL_MEMORY(expected, actual, len)\n\nCompare two blocks of memory.\nThis is a good generic assertion for types that can't be coerced into acting like standard types... \nbut since it's a memory compare, you have to be careful that your data types are packed.\n\n### \\_MESSAGE\n\nYou can append `\\_MESSAGE` to any of the macros to make them take an additional argument.\nThis argument is a string that will be printed at the end of the failure strings.\nThis is useful for specifying more information about the problem.\n\n[CI]: https://github.com/ThrowTheSwitch/Unity/workflows/CI/badge.svg\n[getting started guide]: docs/UnityGettingStartedGuide.md\n[change log]: docs/UnityChangeLog.md\n[known issues]: docs/UnityKnownIssues.md\n[docs]: docs/\n[UnityAssertionsReference.md]: docs/UnityAssertionsReference.md\n",
      "stars_today": 3
    },
    {
      "id": 280608729,
      "name": "ORB_SLAM3",
      "full_name": "UZ-SLAMLab/ORB_SLAM3",
      "description": "ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM",
      "html_url": "https://github.com/UZ-SLAMLab/ORB_SLAM3",
      "stars": 8209,
      "forks": 2965,
      "language": "C++",
      "topics": [
        "slam-algorithms"
      ],
      "created_at": "2020-07-18T07:47:46Z",
      "updated_at": "2026-01-22T21:16:20Z",
      "pushed_at": "2024-07-24T08:41:52Z",
      "open_issues": 562,
      "owner": {
        "login": "UZ-SLAMLab",
        "avatar_url": "https://avatars.githubusercontent.com/u/25055183?v=4"
      },
      "readme": "# ORB-SLAM3\n\n### V1.0, December 22th, 2021\n**Authors:** Carlos Campos, Richard Elvira, Juan J. G√≥mez Rodr√≠guez, [Jos√© M. M. Montiel](http://webdiis.unizar.es/~josemari/), [Juan D. Tardos](http://webdiis.unizar.es/~jdtardos/).\n\nThe [Changelog](https://github.com/UZ-SLAMLab/ORB_SLAM3/blob/master/Changelog.md) describes the features of each version.\n\nORB-SLAM3 is the first real-time SLAM library able to perform **Visual, Visual-Inertial and Multi-Map SLAM** with **monocular, stereo and RGB-D** cameras, using **pin-hole and fisheye** lens models. In all sensor configurations, ORB-SLAM3 is as robust as the best systems available in the literature, and significantly more accurate. \n\nWe provide examples to run ORB-SLAM3 in the [EuRoC dataset](http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets) using stereo or monocular, with or without IMU, and in the [TUM-VI dataset](https://vision.in.tum.de/data/datasets/visual-inertial-dataset) using fisheye stereo or monocular, with or without IMU. Videos of some example executions can be found at [ORB-SLAM3 channel](https://www.youtube.com/channel/UCXVt-kXG6T95Z4tVaYlU80Q).\n\nThis software is based on [ORB-SLAM2](https://github.com/raulmur/ORB_SLAM2) developed by [Raul Mur-Artal](http://webdiis.unizar.es/~raulmur/), [Juan D. Tardos](http://webdiis.unizar.es/~jdtardos/), [J. M. M. Montiel](http://webdiis.unizar.es/~josemari/) and [Dorian Galvez-Lopez](http://doriangalvez.com/) ([DBoW2](https://github.com/dorian3d/DBoW2)).\n\n<a href=\"https://youtu.be/HyLNq-98LRo\" target=\"_blank\"><img src=\"https://img.youtube.com/vi/HyLNq-98LRo/0.jpg\" \nalt=\"ORB-SLAM3\" width=\"240\" height=\"180\" border=\"10\" /></a>\n\n### Related Publications:\n\n[ORB-SLAM3] Carlos Campos, Richard Elvira, Juan J. G√≥mez Rodr√≠guez, Jos√© M. M. Montiel and Juan D. Tard√≥s, **ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM**, *IEEE Transactions on Robotics 37(6):1874-1890, Dec. 2021*. **[PDF](https://arxiv.org/abs/2007.11898)**.\n\n[IMU-Initialization] Carlos Campos, J. M. M. Montiel and Juan D. Tard√≥s, **Inertial-Only Optimization for Visual-Inertial Initialization**, *ICRA 2020*. **[PDF](https://arxiv.org/pdf/2003.05766.pdf)**\n\n[ORBSLAM-Atlas] Richard Elvira, J. M. M. Montiel and Juan D. Tard√≥s, **ORBSLAM-Atlas: a robust and accurate multi-map system**, *IROS 2019*. **[PDF](https://arxiv.org/pdf/1908.11585.pdf)**.\n\n[ORBSLAM-VI] Ra√∫l Mur-Artal, and Juan D. Tard√≥s, **Visual-inertial monocular SLAM with map reuse**, IEEE Robotics and Automation Letters, vol. 2 no. 2, pp. 796-803, 2017. **[PDF](https://arxiv.org/pdf/1610.05949.pdf)**. \n\n[Stereo and RGB-D] Ra√∫l Mur-Artal and Juan D. Tard√≥s. **ORB-SLAM2: an Open-Source SLAM System for Monocular, Stereo and RGB-D Cameras**. *IEEE Transactions on Robotics,* vol. 33, no. 5, pp. 1255-1262, 2017. **[PDF](https://arxiv.org/pdf/1610.06475.pdf)**.\n\n[Monocular] Ra√∫l Mur-Artal, Jos√© M. M. Montiel and Juan D. Tard√≥s. **ORB-SLAM: A Versatile and Accurate Monocular SLAM System**. *IEEE Transactions on Robotics,* vol. 31, no. 5, pp. 1147-1163, 2015. (**2015 IEEE Transactions on Robotics Best Paper Award**). **[PDF](https://arxiv.org/pdf/1502.00956.pdf)**.\n\n[DBoW2 Place Recognition] Dorian G√°lvez-L√≥pez and Juan D. Tard√≥s. **Bags of Binary Words for Fast Place Recognition in Image Sequences**. *IEEE Transactions on Robotics,* vol. 28, no. 5, pp. 1188-1197, 2012. **[PDF](http://doriangalvez.com/php/dl.php?dlp=GalvezTRO12.pdf)**\n\n# 1. License\n\nORB-SLAM3 is released under [GPLv3 license](https://github.com/UZ-SLAMLab/ORB_SLAM3/LICENSE). For a list of all code/library dependencies (and associated licenses), please see [Dependencies.md](https://github.com/UZ-SLAMLab/ORB_SLAM3/blob/master/Dependencies.md).\n\nFor a closed-source version of ORB-SLAM3 for commercial purposes, please contact the authors: orbslam (at) unizar (dot) es.\n\nIf you use ORB-SLAM3 in an academic work, please cite:\n  \n    @article{ORBSLAM3_TRO,\n      title={{ORB-SLAM3}: An Accurate Open-Source Library for Visual, Visual-Inertial \n               and Multi-Map {SLAM}},\n      author={Campos, Carlos AND Elvira, Richard AND G\\¬¥omez, Juan J. AND Montiel, \n              Jos\\'e M. M. AND Tard\\'os, Juan D.},\n      journal={IEEE Transactions on Robotics}, \n      volume={37},\n      number={6},\n      pages={1874-1890},\n      year={2021}\n     }\n\n# 2. Prerequisites\nWe have tested the library in **Ubuntu 16.04** and **18.04**, but it should be easy to compile in other platforms. A powerful computer (e.g. i7) will ensure real-time performance and provide more stable and accurate results.\n\n## C++11 or C++0x Compiler\nWe use the new thread and chrono functionalities of C++11.\n\n## Pangolin\nWe use [Pangolin](https://github.com/stevenlovegrove/Pangolin) for visualization and user interface. Dowload and install instructions can be found at: https://github.com/stevenlovegrove/Pangolin.\n\n## OpenCV\nWe use [OpenCV](http://opencv.org) to manipulate images and features. Dowload and install instructions can be found at: http://opencv.org. **Required at leat 3.0. Tested with OpenCV 3.2.0 and 4.4.0**.\n\n## Eigen3\nRequired by g2o (see below). Download and install instructions can be found at: http://eigen.tuxfamily.org. **Required at least 3.1.0**.\n\n## DBoW2 and g2o (Included in Thirdparty folder)\nWe use modified versions of the [DBoW2](https://github.com/dorian3d/DBoW2) library to perform place recognition and [g2o](https://github.com/RainerKuemmerle/g2o) library to perform non-linear optimizations. Both modified libraries (which are BSD) are included in the *Thirdparty* folder.\n\n## Python\nRequired to calculate the alignment of the trajectory with the ground truth. **Required Numpy module**.\n\n* (win) http://www.python.org/downloads/windows\n* (deb) `sudo apt install libpython2.7-dev`\n* (mac) preinstalled with osx\n\n## ROS (optional)\n\nWe provide some examples to process input of a monocular, monocular-inertial, stereo, stereo-inertial or RGB-D camera using ROS. Building these examples is optional. These have been tested with ROS Melodic under Ubuntu 18.04.\n\n# 3. Building ORB-SLAM3 library and examples\n\nClone the repository:\n```\ngit clone https://github.com/UZ-SLAMLab/ORB_SLAM3.git ORB_SLAM3\n```\n\nWe provide a script `build.sh` to build the *Thirdparty* libraries and *ORB-SLAM3*. Please make sure you have installed all required dependencies (see section 2). Execute:\n```\ncd ORB_SLAM3\nchmod +x build.sh\n./build.sh\n```\n\nThis will create **libORB_SLAM3.so**  at *lib* folder and the executables in *Examples* folder.\n\n# 4. Running ORB-SLAM3 with your camera\n\nDirectory `Examples` contains several demo programs and calibration files to run ORB-SLAM3 in all sensor configurations with Intel Realsense cameras T265 and D435i. The steps needed to use your own camera are: \n\n1. Calibrate your camera following `Calibration_Tutorial.pdf` and write your calibration file `your_camera.yaml`\n\n2. Modify one of the provided demos to suit your specific camera model, and build it\n\n3. Connect the camera to your computer using USB3 or the appropriate interface\n\n4. Run ORB-SLAM3. For example, for our D435i camera, we would execute:\n\n```\n./Examples/Stereo-Inertial/stereo_inertial_realsense_D435i Vocabulary/ORBvoc.txt ./Examples/Stereo-Inertial/RealSense_D435i.yaml\n```\n\n# 5. EuRoC Examples\n[EuRoC dataset](http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets) was recorded with two pinhole cameras and an inertial sensor. We provide an example script to launch EuRoC sequences in all the sensor configurations.\n\n1. Download a sequence (ASL format) from http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets\n\n2. Open the script \"euroc_examples.sh\" in the root of the project. Change **pathDatasetEuroc** variable to point to the directory where the dataset has been uncompressed. \n\n3. Execute the following script to process all the sequences with all sensor configurations:\n```\n./euroc_examples\n```\n\n## Evaluation\nEuRoC provides ground truth for each sequence in the IMU body reference. As pure visual executions report trajectories centered in the left camera, we provide in the \"evaluation\" folder the transformation of the ground truth to the left camera reference. Visual-inertial trajectories use the ground truth from the dataset.\n\nExecute the following script to process sequences and compute the RMS ATE:\n```\n./euroc_eval_examples\n```\n\n# 6. TUM-VI Examples\n[TUM-VI dataset](https://vision.in.tum.de/data/datasets/visual-inertial-dataset) was recorded with two fisheye cameras and an inertial sensor.\n\n1. Download a sequence from https://vision.in.tum.de/data/datasets/visual-inertial-dataset and uncompress it.\n\n2. Open the script \"tum_vi_examples.sh\" in the root of the project. Change **pathDatasetTUM_VI** variable to point to the directory where the dataset has been uncompressed. \n\n3. Execute the following script to process all the sequences with all sensor configurations:\n```\n./tum_vi_examples\n```\n\n## Evaluation\nIn TUM-VI ground truth is only available in the room where all sequences start and end. As a result the error measures the drift at the end of the sequence. \n\nExecute the following script to process sequences and compute the RMS ATE:\n```\n./tum_vi_eval_examples\n```\n\n# 7. ROS Examples\n\n### Building the nodes for mono, mono-inertial, stereo, stereo-inertial and RGB-D\nTested with ROS Melodic and ubuntu 18.04.\n\n1. Add the path including *Examples/ROS/ORB_SLAM3* to the ROS_PACKAGE_PATH environment variable. Open .bashrc file:\n  ```\n  gedit ~/.bashrc\n  ```\nand add at the end the following line. Replace PATH by the folder where you cloned ORB_SLAM3:\n\n  ```\n  export ROS_PACKAGE_PATH=${ROS_PACKAGE_PATH}:PATH/ORB_SLAM3/Examples/ROS\n  ```\n  \n2. Execute `build_ros.sh` script:\n\n  ```\n  chmod +x build_ros.sh\n  ./build_ros.sh\n  ```\n  \n### Running Monocular Node\nFor a monocular input from topic `/camera/image_raw` run node ORB_SLAM3/Mono. You will need to provide the vocabulary file and a settings file. See the monocular examples above.\n\n  ```\n  rosrun ORB_SLAM3 Mono PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE\n  ```\n\n### Running Monocular-Inertial Node\nFor a monocular input from topic `/camera/image_raw` and an inertial input from topic `/imu`, run node ORB_SLAM3/Mono_Inertial. Setting the optional third argument to true will apply CLAHE equalization to images (Mainly for TUM-VI dataset).\n\n  ```\n  rosrun ORB_SLAM3 Mono PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE [EQUALIZATION]\t\n  ```\n\n### Running Stereo Node\nFor a stereo input from topic `/camera/left/image_raw` and `/camera/right/image_raw` run node ORB_SLAM3/Stereo. You will need to provide the vocabulary file and a settings file. For Pinhole camera model, if you **provide rectification matrices** (see Examples/Stereo/EuRoC.yaml example), the node will recitify the images online, **otherwise images must be pre-rectified**. For FishEye camera model, rectification is not required since system works with original images:\n\n  ```\n  rosrun ORB_SLAM3 Stereo PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE ONLINE_RECTIFICATION\n  ```\n\n### Running Stereo-Inertial Node\nFor a stereo input from topics `/camera/left/image_raw` and `/camera/right/image_raw`, and an inertial input from topic `/imu`, run node ORB_SLAM3/Stereo_Inertial. You will need to provide the vocabulary file and a settings file, including rectification matrices if required in a similar way to Stereo case:\n\n  ```\n  rosrun ORB_SLAM3 Stereo_Inertial PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE ONLINE_RECTIFICATION [EQUALIZATION]\t\n  ```\n  \n### Running RGB_D Node\nFor an RGB-D input from topics `/camera/rgb/image_raw` and `/camera/depth_registered/image_raw`, run node ORB_SLAM3/RGBD. You will need to provide the vocabulary file and a settings file. See the RGB-D example above.\n\n  ```\n  rosrun ORB_SLAM3 RGBD PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE\n  ```\n\n**Running ROS example:** Download a rosbag (e.g. V1_02_medium.bag) from the EuRoC dataset (http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets). Open 3 tabs on the terminal and run the following command at each tab for a Stereo-Inertial configuration:\n  ```\n  roscore\n  ```\n  \n  ```\n  rosrun ORB_SLAM3 Stereo_Inertial Vocabulary/ORBvoc.txt Examples/Stereo-Inertial/EuRoC.yaml true\n  ```\n  \n  ```\n  rosbag play --pause V1_02_medium.bag /cam0/image_raw:=/camera/left/image_raw /cam1/image_raw:=/camera/right/image_raw /imu0:=/imu\n  ```\n  \nOnce ORB-SLAM3 has loaded the vocabulary, press space in the rosbag tab.\n\n**Remark:** For rosbags from TUM-VI dataset, some play issue may appear due to chunk size. One possible solution is to rebag them with the default chunk size, for example:\n  ```\n  rosrun rosbag fastrebag.py dataset-room1_512_16.bag dataset-room1_512_16_small_chunks.bag\n  ```\n\n# 8. Running time analysis\nA flag in `include\\Config.h` activates time measurements. It is necessary to uncomment the line `#define REGISTER_TIMES` to obtain the time stats of one execution which is shown at the terminal and stored in a text file(`ExecTimeMean.txt`).\n\n# 9. Calibration\nYou can find a tutorial for visual-inertial calibration and a detailed description of the contents of valid configuration files at  `Calibration_Tutorial.pdf`\n",
      "stars_today": 2
    },
    {
      "id": 27911088,
      "name": "nifi",
      "full_name": "apache/nifi",
      "description": "Apache NiFi",
      "html_url": "https://github.com/apache/nifi",
      "stars": 5925,
      "forks": 2926,
      "language": "Java",
      "topics": [
        "apache",
        "hacktoberfest",
        "java",
        "nifi"
      ],
      "created_at": "2014-12-12T08:00:05Z",
      "updated_at": "2026-01-23T00:42:00Z",
      "pushed_at": "2026-01-22T19:48:25Z",
      "open_issues": 25,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\n  Licensed to the Apache Software Foundation (ASF) under one or more\n  contributor license agreements.  See the NOTICE file distributed with\n  this work for additional information regarding copyright ownership.\n  The ASF licenses this file to You under the Apache License, Version 2.0\n  (the \"License\"); you may not use this file except in compliance with\n  the License.  You may obtain a copy of the License at\n      http://www.apache.org/licenses/LICENSE-2.0\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n-->\n\n# Apache NiFi\n\n<img src=\"https://nifi.apache.org/images/apache-nifi-logo.svg\" width=\"300\" alt=\"Apache NiFi\"/>\n\n### Status\n\n[![ci-workflow](https://github.com/apache/nifi/workflows/ci-workflow/badge.svg)](https://github.com/apache/nifi/actions/workflows/ci-workflow.yml)\n[![system-tests](https://github.com/apache/nifi/workflows/system-tests/badge.svg)](https://github.com/apache/nifi/actions/workflows/system-tests.yml)\n[![integration-tests](https://github.com/apache/nifi/actions/workflows/integration-tests.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/integration-tests.yml)\n[![docker-tests](https://github.com/apache/nifi/actions/workflows/docker-tests.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/docker-tests.yml)\n[![code-compliance](https://github.com/apache/nifi/actions/workflows/code-compliance.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/code-compliance.yml)\n[![code-coverage](https://github.com/apache/nifi/actions/workflows/code-coverage.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/code-coverage.yml)\n[![codecov](https://codecov.io/gh/apache/nifi/branch/main/graph/badge.svg)](https://codecov.io/gh/apache/nifi)\n\n### Resources\n\n[![NiFi API](https://img.shields.io/maven-central/v/org.apache.nifi/nifi-api.svg?label=nifi-api&logo=apachenifi&logoColor=ffffff&color=728e9b)](https://central.sonatype.com/artifact/org.apache.nifi/nifi-api)\n[![NiFi NAR Maven Plugin](https://img.shields.io/maven-central/v/org.apache.nifi/nifi-nar-maven-plugin.svg?label=nifi-nar-maven-plugin&logo=apachenifi&logoColor=ffffff&color=728e9b)](https://central.sonatype.com/artifact/org.apache.nifi/nifi-nar-maven-plugin)\n[![NiFi Framework](https://img.shields.io/maven-central/v/org.apache.nifi/nifi.svg?label=nifi-framework&logo=apachenifi&logoColor=ffffff&color=728e9b)](https://nifi.apache.org/download/)\n[![NiFI Docker Pulls](https://img.shields.io/docker/pulls/apache/nifi.svg?logo=docker&logoColor=ffffff)](https://hub.docker.com/r/apache/nifi/)\n[![License](https://img.shields.io/github/license/apache/nifi)](https://github.com/apache/nifi/blob/main/LICENSE)\n[![NiFi API Javadoc](https://javadoc.io/badge2/org.apache.nifi/nifi-api/javadoc.svg)](https://javadoc.io/doc/org.apache.nifi/nifi-api)\n\n### Contacts\n\n[![Track Issues](https://img.shields.io/badge/track-Issues-728e9b.svg?logo=jirasoftware)](https://issues.apache.org/jira/browse/NIFI)\n[![Chat on Slack](https://img.shields.io/badge/chat-Slack-728e9b.svg?logo=slack)](https://s.apache.org/nifi-community-slack)\n[![Contact Developers](https://img.shields.io/badge/contact-Developers-728e9b.svg?logo=apache)](https://lists.apache.org/list.html?dev@nifi.apache.org)\n[![Contact Users](https://img.shields.io/badge/contact-Users-728e9b.svg?logo=apache)](https://lists.apache.org/list.html?users@nifi.apache.org)\n\n### Community\n\n[![Join Slack Community](https://img.shields.io/badge/join-Slack-728e9b.svg?logo=slack)](https://join.slack.com/t/apachenifi/shared_invite/zt-11njbtkdx-ZRU8FKYSWoEHRJetidy0zA)\n[![Follow on LinkedIn](https://img.shields.io/badge/follow-Apache%20NiFi-728e9b.svg?logo=linkedin)](https://www.linkedin.com/company/apache-nifi/)\n[![Follow on X](https://img.shields.io/badge/follow-apachenifi-728e9b.svg?logo=x)](https://x.com/apachenifi)\n\n## Features\n\n[Apache NiFi](https://nifi.apache.org/) is an easy to use, powerful, and reliable system to process and distribute data.\n\nNiFi automates cybersecurity, observability, event streams, and generative AI data pipelines and distribution\nfor thousands of companies worldwide across every industry.\n\n- Browser User Interface\n  - Seamless experience for design, control, and monitoring\n  - Runtime management and versioned pipelines\n  - Secure by default with HTTPS\n- Scalable Processing\n  - Configurable prioritization for throughput and latency\n  - Guaranteed delivery with retry and backoff strategies\n  - Horizontal scaling with clustering\n- Provenance Tracking \n  - Searchable history with configurable attributes\n  - Graph data lineage from source to destination\n  - Metadata and content for each processing decision\n- Extensible Design\n  - Plugin interface for Processors and Controller Services\n  - Support for Processors in native Python\n  - REST API for orchestration and monitoring\n- Secure Configuration\n  - Single sign-on with OpenID Connect or SAML 2\n  - Flexible authorization policies for role-based access\n  - Encrypted communication with TLS and SFTP\n\n## Requirements\n\nNiFi supports modern operating systems and requires recent language versions for developing and running the application.\n\n### Platform Requirements\n\n- Java 21\n\n### Optional Dependencies\n\n- Python 3.10 or higher\n\n## Projects\n\nThe source repository includes several component projects.\n\nPlease review individual project documentation for additional details.\n\n- [Apache NiFi](https://nifi.apache.org/documentation/)\n- [Apache NiFi Registry](https://github.com/apache/nifi/blob/main/nifi-registry/nifi-registry-assembly/README.md)\n- [Apache NiFi MiNiFi](https://github.com/apache/nifi/blob/main/minifi/minifi-assembly/README.md)\n\n## Getting Started\n\nProject guides provide extensive documentation for installing and extending the application.\n\n- [Getting Started](https://nifi.apache.org/documentation/nifi-latest/html/getting-started.html)\n- [User Guide](https://nifi.apache.org/documentation/nifi-latest/html/user-guide.html)\n- [Administrator Guide](https://nifi.apache.org/documentation/nifi-latest/html/administration-guide.html)\n- [Developer Guide](https://nifi.apache.org/documentation/nifi-latest/html/developer-guide.html)\n\n## Developing\n\nNiFi uses the [Maven Wrapper](https://maven.apache.org/wrapper/) for project development. The Maven Wrapper provides\nshell scripts that download and cache a selected version of [Apache Maven](https://maven.apache.org/) for running build\ncommands.\n\nDeveloping on Microsoft Windows requires using `mvnw.cmd` instead of `mvnw` to run Maven commands.\n\n### Building\n\nRun the following command to build project modules using parallel execution:\n\n```shell\n./mvnw install -T1C\n```\n\nRun the following command to build project modules using parallel execution with static analysis to confirm compliance\nwith code and licensing requirements:\n\n```shell\n./mvnw install -T1C -P contrib-check\n```\n\nRun the following command to build the application binaries without building other optional modules:\n\n```shell\n./mvnw install -T1C -am -pl :nifi-assembly\n```\n\n### Binaries\n\nThe `nifi-assembly` module contains the binary distribution.\n\n```shell\nls nifi-assembly/target/nifi-*-bin.zip\n```\n\nThe `nifi-assembly` module includes the binary distribution in a directory for local development and testing.\n\n```shell\ncd nifi-assembly/target/nifi-*-bin/nifi-*/\n```\n\n## Running\n\nNiFi provides shell scripts for starting and stopping the system.\n\nRunning on Microsoft Windows requires using `nifi.cmd` instead of `nifi.sh` for system commands.\n\n### Starting\n\nRun the following command to start NiFi from the distribution directory:\n\n```shell\n./bin/nifi.sh start\n```\n\n### Accessing\n\nThe default configuration generates a random username and password on startup. NiFi writes the generated credentials\nto the application log located in `logs/nifi-app.log` under the NiFi installation directory.\n\nThe following command can be used to find the generated credentials on operating systems with `grep` installed:\n\n```shell\ngrep Generated logs/nifi-app*log\n```\n\nNiFi logs the generated credentials as follows:\n\n```shell\nGenerated Username [USERNAME]\nGenerated Password [PASSWORD]\n```\n\nThe `USERNAME` will be a random UUID composed of 36 characters. The `PASSWORD` will be a random string.\n\nThe username and password can be replaced with custom credentials using the following command:\n\n```shell\n./bin/nifi.sh set-single-user-credentials <username> <password>\n```\n\nNiFi defaults to running on the `localhost` address with HTTPS on port `8443` at the following URL:\n\n```\nhttps://localhost:8443/nifi\n```\n\nBrowsers will display a warning message indicating a potential security risk due to the self-signed certificate\ngenerated during initialization. Production deployments should provision a certificate from a trusted certificate\nauthority and update the NiFi keystore and truststore configuration.\n\n## License\n\nExcept as otherwise noted this software is licensed under the\n[Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0.html)\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  https://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n## Export Control\n\nThis distribution includes cryptographic software. The country in which you\ncurrently reside may have restrictions on the import, possession, use, and/or\nre-export to another country, of encryption software. BEFORE using any\nencryption software, please check your country's laws, regulations and\npolicies concerning the import, possession, or use, and re-export of encryption\nsoftware, to see if this is permitted. See https://www.wassenaar.org for more\ninformation.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and Security\n(BIS), has classified this software as Export Commodity Control Number (ECCN)\n5D002.C.1, which includes information security software using or performing\ncryptographic functions with asymmetric algorithms. The form and manner of this\nApache Software Foundation distribution makes it eligible for export under the\nLicense Exception ENC Technology Software Unrestricted (TSU) exception (see the\nBIS Export Administration Regulations, Section 740.13) for both object code and\nsource code.\n\nThe following provides more details on the included cryptographic software:\n\nApache NiFi uses the following libraries and frameworks for encrypted\ncommunication and storage of sensitive information:\n\n- [Apache MINA SSHD](https://mina.apache.org/sshd-project/)\n- [Bouncy Castle](https://www.bouncycastle.org)\n- [Jagged](https://github.com/exceptionfactory/jagged)\n- [Java Cryptography Architecture](https://docs.oracle.com/en/java/javase/21/security/java-cryptography-architecture-jca-reference-guide.html)\n",
      "stars_today": 2
    },
    {
      "id": 38304949,
      "name": "GRDB.swift",
      "full_name": "groue/GRDB.swift",
      "description": "A toolkit for SQLite databases, with a focus on application development",
      "html_url": "https://github.com/groue/GRDB.swift",
      "stars": 8121,
      "forks": 831,
      "language": "Swift",
      "topics": [
        "database",
        "database-observation",
        "grdb",
        "spm",
        "sql",
        "sql-builder",
        "sqlite",
        "sqlite-databases"
      ],
      "created_at": "2015-06-30T11:17:06Z",
      "updated_at": "2026-01-23T01:51:14Z",
      "pushed_at": "2026-01-16T12:18:54Z",
      "open_issues": 12,
      "owner": {
        "login": "groue",
        "avatar_url": "https://avatars.githubusercontent.com/u/54219?v=4"
      },
      "readme": "<picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB~dark.png\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB.png\">\n    <img alt=\"GRDB: A toolkit for SQLite databases, with a focus on application development.\" src=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB.png\">\n</picture>\n\n<p align=\"center\">\n    <strong>A toolkit for SQLite databases, with a focus on application development</strong><br>\n    Proudly serving the community since 2015\n</p>\n\n<p align=\"center\">\n    <a href=\"https://developer.apple.com/swift/\"><img alt=\"Swift 6.1\" src=\"https://img.shields.io/badge/swift-6.1-orange.svg?style=flat\"></a>\n    <a href=\"https://github.com/groue/GRDB.swift/blob/master/LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/github/license/groue/GRDB.swift.svg?maxAge=2592000\"></a>\n    <a href=\"https://github.com/groue/GRDB.swift/actions/workflows/CI.yml\"><img alt=\"CI Status\" src=\"https://github.com/groue/GRDB.swift/actions/workflows/CI.yml/badge.svg?branch=master\"></a>\n</p>\n\n**Latest release**: December 13, 2025 ‚Ä¢ [version 7.9.0](https://github.com/groue/GRDB.swift/tree/v7.9.0) ‚Ä¢ [CHANGELOG](CHANGELOG.md) ‚Ä¢ [Migrating From GRDB 6 to GRDB 7](Documentation/GRDB7MigrationGuide.md)\n\n**Requirements**: iOS 13.0+ / macOS 10.15+ / tvOS 13.0+ / watchOS 7.0+ &bull; SQLite 3.20.0+ &bull; Swift 6.1+ / Xcode 16.3+\n\n**Contact**:\n\n- Release announcements and usage tips: follow [@groue@hachyderm.io](https://hachyderm.io/@groue) on Mastodon.\n- Report bugs in a [Github issue](https://github.com/groue/GRDB.swift/issues/new). Make sure you check the [existing issues](https://github.com/groue/GRDB.swift/issues?q=is%3Aopen) first.\n- A question? Looking for advice? Do you wonder how to contribute? Fancy a chat? Go to the [GitHub discussions](https://github.com/groue/GRDB.swift/discussions), or the [GRDB forums](https://forums.swift.org/c/related-projects/grdb).\n\n\n## What is GRDB?\n\nUse this library to save your application‚Äôs permanent data into SQLite databases. It comes with built-in tools that address common needs:\n\n- **SQL Generation**\n    \n    Enhance your application models with persistence and fetching methods, so that you don't have to deal with SQL and raw database rows when you don't want to.\n\n- **Database Observation**\n    \n    Get notifications when database values are modified. \n\n- **Robust Concurrency**\n    \n    Multi-threaded applications can efficiently use their databases, including WAL databases that support concurrent reads and writes. \n\n- **Migrations**\n    \n    Evolve the schema of your database as you ship new versions of your application.\n    \n- **Leverage your SQLite skills**\n\n    Not all developers need advanced SQLite features. But when you do, GRDB is as sharp as you want it to be. Come with your SQL and SQLite skills, or learn new ones as you go!\n\n---\n\n<p align=\"center\">\n    <a href=\"#usage\">Usage</a> &bull;\n    <a href=\"#documentation\">Documentation</a> &bull;\n    <a href=\"#installation\">Installation</a> &bull;\n    <a href=\"#faq\">FAQ</a>\n</p>\n\n---\n\n## Usage\n\n<details open>\n  <summary>Start using the database in four steps</summary>\n\n```swift\nimport GRDB\n\n// 1. Open a database connection\nlet dbQueue = try DatabaseQueue(path: \"/path/to/database.sqlite\")\n\n// 2. Define the database schema\ntry dbQueue.write { db in\n    try db.create(table: \"player\") { t in\n        t.primaryKey(\"id\", .text)\n        t.column(\"name\", .text).notNull()\n        t.column(\"score\", .integer).notNull()\n    }\n}\n\n// 3. Define a record type\nstruct Player: Codable, Identifiable, FetchableRecord, PersistableRecord {\n    var id: String\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// 4. Write and read in the database\ntry dbQueue.write { db in\n    try Player(id: \"1\", name: \"Arthur\", score: 100).insert(db)\n    try Player(id: \"2\", name: \"Barbara\", score: 1000).insert(db)\n}\n\ntry dbQueue.read { db in\n    let player = try Player.find(db, id: \"1\"))\n    \n    let bestPlayers = try Player\n        .order(\\.score.desc)\n        .limit(10)\n        .fetchAll(db)\n}\n```\n\n</details>\n\n<details>\n    <summary>Access to raw SQL</summary>\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player (\n          id TEXT PRIMARY KEY,\n          name TEXT NOT NULL,\n          score INT NOT NULL)\n        \"\"\")\n    \n    try db.execute(sql: \"\"\"\n        INSERT INTO player (id, name, score)\n        VALUES (?, ?, ?)\n        \"\"\", arguments: [\"1\", \"Arthur\", 100])\n    \n    // Avoid SQL injection with SQL interpolation\n    let id = \"2\"\n    let name = \"O'Brien\"\n    let score = 1000\n    try db.execute(literal: \"\"\"\n        INSERT INTO player (id, name, score)\n        VALUES (\\(id), \\(name), \\(score))\n        \"\"\")\n}\n```\n\nSee [Executing Updates](#executing-updates)\n\n</details>\n\n<details>\n    <summary>Access to raw database rows and values</summary>\n\n```swift\ntry dbQueue.read { db in\n    // Fetch database rows\n    let rows = try Row.fetchCursor(db, sql: \"SELECT * FROM player\")\n    while let row = try rows.next() {\n        let id: String = row[\"id\"]\n        let name: String = row[\"name\"]\n        let score: Int = row[\"score\"]\n    }\n    \n    // Fetch values\n    let playerCount = try Int.fetchOne(db, sql: \"SELECT COUNT(*) FROM player\")! // Int\n    let playerNames = try String.fetchAll(db, sql: \"SELECT name FROM player\") // [String]\n}\n\nlet playerCount = try dbQueue.read { db in\n    try Int.fetchOne(db, sql: \"SELECT COUNT(*) FROM player\")!\n}\n```\n\nSee [Fetch Queries](#fetch-queries)\n\n</details>\n\n<details>\n    <summary>Database model types aka \"records\"</summary>\n\n```swift\nstruct Player: Codable, Identifiable, FetchableRecord, PersistableRecord {\n    var id: String\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\ntry dbQueue.write { db in\n    // Create database table\n    try db.create(table: \"player\") { t in\n        t.primaryKey(\"id\", .text)\n        t.column(\"name\", .text).notNull()\n        t.column(\"score\", .integer).notNull()\n    }\n    \n    // Insert a record\n    var player = Player(id: \"1\", name: \"Arthur\", score: 100)\n    try player.insert(db)\n    \n    // Update a record\n    player.score += 10\n    try score.update(db)\n    \n    try player.updateChanges { $0.score += 10 }\n    \n    // Delete a record\n    try player.delete(db)\n}\n```\n\nSee [Records](#records)\n\n</details>\n\n<details>\n    <summary>Query the database with the Swift query interface</summary>\n\n```swift\ntry dbQueue.read { db in\n    // Player\n    let player = try Player.find(db, id: \"1\")\n    \n    // Player?\n    let arthur = try Player.filter { $0.name == \"Arthur\" }.fetchOne(db)\n    \n    // [Player]\n    let bestPlayers = try Player.order(\\.score.desc).limit(10).fetchAll(db)\n    \n    // Int\n    let playerCount = try Player.fetchCount(db)\n    \n    // SQL is always welcome\n    let players = try Player.fetchAll(db, sql: \"SELECT * FROM player\")\n}\n```\n\nSee the [Query Interface](#the-query-interface)\n\n</details>\n\n<details>\n    <summary>Database changes notifications</summary>\n\n```swift\n// Define the observed value\nlet observation = ValueObservation.tracking { db in\n    try Player.fetchAll(db)\n}\n\n// Start observation\nlet cancellable = observation.start(\n    in: dbQueue,\n    onError: { error in ... },\n    onChange: { (players: [Player]) in print(\"Fresh players: \\(players)\") })\n```\n\nReady-made support for Combine and RxSwift:\n\n```swift\n// Swift concurrency\nfor try await players in observation.values(in: dbQueue) {\n    print(\"Fresh players: \\(players)\")\n}\n\n// Combine\nlet cancellable = observation.publisher(in: dbQueue).sink(\n    receiveCompletion: { completion in ... },\n    receiveValue: { (players: [Player]) in print(\"Fresh players: \\(players)\") })\n\n// RxSwift\nlet disposable = observation.rx.observe(in: dbQueue).subscribe(\n    onNext: { (players: [Player]) in print(\"Fresh players: \\(players)\") },\n    onError: { error in ... })\n```\n\nSee [Database Observation], [Combine Support], [RxGRDB].\n\n</details>\n\nDocumentation\n=============\n\n**GRDB runs on top of SQLite**: you should get familiar with the [SQLite FAQ](http://www.sqlite.org/faq.html). For general and detailed information, jump to the [SQLite Documentation](http://www.sqlite.org/docs.html).\n\n\n#### Demo Applications & Frequently Asked Questions\n\n- [Demo Applications]\n- [FAQ]\n\n#### Reference\n\n- üìñ [GRDB Reference](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/)\n\n#### Getting Started\n\n- [Installation](#installation)\n- [Database Connections]: Connect to SQLite databases\n\n#### SQLite and SQL\n\n- [SQLite API](#sqlite-api): The low-level SQLite API &bull; [executing updates](#executing-updates) &bull; [fetch queries](#fetch-queries) &bull; [SQL Interpolation]\n\n#### Records and the Query Interface\n\n- [Records](#records): Fetching and persistence methods for your custom structs and class hierarchies\n- [Query Interface](#the-query-interface): A swift way to generate SQL &bull; [create tables, indexes, etc](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema) &bull; [requests](#requests) ‚Ä¢ [associations between record types](Documentation/AssociationsBasics.md)\n\n#### Application Tools\n\n- [Migrations]: Transform your database as your application evolves.\n- [Full-Text Search]: Perform efficient and customizable full-text searches.\n- [Database Observation]: Observe database changes and transactions.\n- [Encryption](#encryption): Encrypt your database with SQLCipher.\n- [Backup](#backup): Dump the content of a database to another.\n- [Interrupt a Database](#interrupt-a-database): Abort any pending database operation.\n- [Sharing a Database]: How to share an SQLite database between multiple processes - recommendations for App Group containers, App Extensions, App Sandbox, and file coordination.\n\n#### Good to Know\n\n- [Concurrency]: How to access databases in a multi-threaded application.\n- [Combine](Documentation/Combine.md): Access and observe the database with Combine publishers.\n- [Avoiding SQL Injection](#avoiding-sql-injection)\n- [Error Handling](#error-handling)\n- [Unicode](#unicode)\n- [Memory Management](#memory-management)\n- [Data Protection](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections)\n- :bulb: [Migrating From GRDB 6 to GRDB 7](Documentation/GRDB7MigrationGuide.md)\n- :bulb: [Why Adopt GRDB?](Documentation/WhyAdoptGRDB.md)\n- :bulb: [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices)\n\n#### Companion Libraries\n\n- [GRDBQuery](https://github.com/groue/GRDBQuery): Access and observe the database from your SwiftUI views.\n- [GRDBSnapshotTesting](https://github.com/groue/GRDBSnapshotTesting): Test your database. \n\n**[FAQ]**\n\n**[Sample Code](#sample-code)**\n\n\nInstallation\n============\n\n**The installation procedures below have GRDB use the version of SQLite that ships with the target operating system.**\n\nSee [Encryption](#encryption) for the installation procedure of GRDB with SQLCipher.\n\nSee [Custom SQLite builds](Documentation/CustomSQLiteBuilds.md) for the installation procedure of GRDB with a customized build of SQLite.\n\n\n## Swift Package Manager\n\nThe [Swift Package Manager](https://swift.org/package-manager/) automates the distribution of Swift code. To use GRDB with SPM, add a dependency to `https://github.com/groue/GRDB.swift.git`\n\nGRDB offers two libraries, `GRDB` and `GRDB-dynamic`. Pick only one. When in doubt, prefer `GRDB`. The `GRDB-dynamic` library can reveal useful if you are going to link it with multiple targets within your app and only wish to link to a shared, dynamic framework once. See [How to link a Swift Package as dynamic](https://forums.swift.org/t/how-to-link-a-swift-package-as-dynamic/32062) for more information.\n\n> **Note**: Linux support is provided by contributors. It is not automatically tested, and not officially maintained. If you notice a build or runtime failure on Linux, please open a pull request with the necessary fix, thank you!\n\n\n## CocoaPods\n\n[CocoaPods](http://cocoapods.org/) is a dependency manager for Xcode projects. To use GRDB with CocoaPods (version 1.2 or higher), specify in your `Podfile`:\n\n```ruby\npod 'GRDB.swift'\n```\n\nGRDB can be installed as a framework, or a static library.\n\n**Important Note for CocoaPods installation**\n\nDue to an [issue](https://github.com/CocoaPods/CocoaPods/issues/11839) in CocoaPods, it is currently not possible to deploy new versions of GRDB to CocoaPods. The last version available on CocoaPods is 6.24.1. To install later versions of GRDB using CocoaPods, use one of the following workarounds:\n\n- Depend on the `GRDB7` branch. This is more or less equivalent to what `pod 'GRDB.swift', '~> 7.0'` would normally do, if CocoaPods would accept new GRDB versions to be published:\n\n    ```ruby\n    # Can't use semantic versioning due to https://github.com/CocoaPods/CocoaPods/issues/11839\n    pod 'GRDB.swift', git: 'https://github.com/groue/GRDB.swift.git', branch: 'GRDB7'\n    ```\n\n- Depend on a specific version explicitly (Replace the tag with the version you want to use):\n\n    ```ruby\n    # Can't use semantic versioning due to https://github.com/CocoaPods/CocoaPods/issues/11839\n    # Replace the tag with the tag that you want to use.\n    pod 'GRDB.swift', git: 'https://github.com/groue/GRDB.swift.git', tag: 'v6.29.0' \n    ```\n\n## Carthage\n\n[Carthage](https://github.com/Carthage/Carthage) is **unsupported**. For some context about this decision, see [#433](https://github.com/groue/GRDB.swift/issues/433).\n\n\n## Manually\n\n1. [Download](https://github.com/groue/GRDB.swift/releases) a copy of GRDB, or clone its repository and make sure you checkout the latest tagged version.\n\n2. Embed the `GRDB.xcodeproj` project in your own project.\n\n3. Add the `GRDB` target in the **Target Dependencies** section of the **Build Phases** tab of your application target (extension target for WatchOS).\n\n4. Add the `GRDB.framework` to the **Embedded Binaries** section of the **General**  tab of your application target (extension target for WatchOS).\n\n\nDatabase Connections\n====================\n\nGRDB provides two classes for accessing SQLite databases: [`DatabaseQueue`] and [`DatabasePool`]:\n\n```swift\nimport GRDB\n\n// Pick one:\nlet dbQueue = try DatabaseQueue(path: \"/path/to/database.sqlite\")\nlet dbPool = try DatabasePool(path: \"/path/to/database.sqlite\")\n```\n\nThe differences are:\n\n- Database pools allow concurrent database accesses (this can improve the performance of multithreaded applications).\n- Database pools open your SQLite database in the [WAL mode](https://www.sqlite.org/wal.html) (unless read-only).\n- Database queues support [in-memory databases](https://www.sqlite.org/inmemorydb.html).\n\n**If you are not sure, choose [`DatabaseQueue`].** You will always be able to switch to [`DatabasePool`] later.\n\nFor more information and tips when opening connections, see [Database Connections](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections).\n\n\nSQLite API\n==========\n\n**In this section of the documentation, we will talk SQL.** Jump to the [query interface](#the-query-interface) if SQL is not your cup of tea.\n\n- [Executing Updates](#executing-updates)\n- [Fetch Queries](#fetch-queries)\n    - [Fetching Methods](#fetching-methods)\n    - [Row Queries](#row-queries)\n    - [Value Queries](#value-queries)\n- [Values](#values)\n    - [Data](#data-and-memory-savings)\n    - [Date and DateComponents](#date-and-datecomponents)\n    - [NSNumber, NSDecimalNumber, and Decimal](#nsnumber-nsdecimalnumber-and-decimal)\n    - [Swift enums](#swift-enums)\n    - [`DatabaseValueConvertible`]: the protocol for custom value types\n- [Transactions and Savepoints]\n- [SQL Interpolation]\n\nAdvanced topics:\n\n- [Prepared Statements]\n- [Custom SQL Functions and Aggregates](#custom-sql-functions-and-aggregates)\n- [Database Schema Introspection](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschemaintrospection)\n- [Row Adapters](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter)\n- [Raw SQLite Pointers](#raw-sqlite-pointers)\n\n\n## Executing Updates\n\nOnce granted with a [database connection], the [`execute(sql:arguments:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/execute(sql:arguments:)) method executes the SQL statements that do not return any database row, such as `CREATE TABLE`, `INSERT`, `DELETE`, `ALTER`, etc.\n\nFor example:\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            name TEXT NOT NULL,\n            score INT)\n        \"\"\")\n    \n    try db.execute(\n        sql: \"INSERT INTO player (name, score) VALUES (?, ?)\",\n        arguments: [\"Barbara\", 1000])\n    \n    try db.execute(\n        sql: \"UPDATE player SET score = :score WHERE id = :id\",\n        arguments: [\"score\": 1000, \"id\": 1])\n    }\n}\n```\n\nThe `?` and colon-prefixed keys like `:score` in the SQL query are the **statements arguments**. You pass arguments with arrays or dictionaries, as in the example above. See [Values](#values) for more information on supported arguments types (Bool, Int, String, Date, Swift enums, etc.), and [`StatementArguments`] for a detailed documentation of SQLite arguments.\n\nYou can also embed query arguments right into your SQL queries, with [`execute(literal:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/execute(literal:)), as in the example below. See [SQL Interpolation] for more details.\n\n```swift\ntry dbQueue.write { db in\n    let name = \"O'Brien\"\n    let score = 550\n    try db.execute(literal: \"\"\"\n        INSERT INTO player (name, score) VALUES (\\(name), \\(score))\n        \"\"\")\n}\n```\n\n**Never ever embed values directly in your raw SQL strings**. See [Avoiding SQL Injection](#avoiding-sql-injection) for more information:\n\n```swift\n// WRONG: don't embed values in raw SQL strings\nlet id = 123\nlet name = textField.text\ntry db.execute(\n    sql: \"UPDATE player SET name = '\\(name)' WHERE id = \\(id)\")\n\n// CORRECT: use arguments dictionary\ntry db.execute(\n    sql: \"UPDATE player SET name = :name WHERE id = :id\",\n    arguments: [\"name\": name, \"id\": id])\n\n// CORRECT: use arguments array\ntry db.execute(\n    sql: \"UPDATE player SET name = ? WHERE id = ?\",\n    arguments: [name, id])\n\n// CORRECT: use SQL Interpolation\ntry db.execute(\n    literal: \"UPDATE player SET name = \\(name) WHERE id = \\(id)\")\n```\n\n**Join multiple statements with a semicolon**:\n\n```swift\ntry db.execute(sql: \"\"\"\n    INSERT INTO player (name, score) VALUES (?, ?);\n    INSERT INTO player (name, score) VALUES (?, ?);\n    \"\"\", arguments: [\"Arthur\", 750, \"Barbara\", 1000])\n\ntry db.execute(literal: \"\"\"\n    INSERT INTO player (name, score) VALUES (\\(\"Arthur\"), \\(750));\n    INSERT INTO player (name, score) VALUES (\\(\"Barbara\"), \\(1000));\n    \"\"\")\n```\n\nWhen you want to make sure that a single statement is executed, use a prepared [`Statement`].\n\n**After an INSERT statement**, you can get the row ID of the inserted row with [`lastInsertedRowID`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/lastinsertedrowid):\n\n```swift\ntry db.execute(\n    sql: \"INSERT INTO player (name, score) VALUES (?, ?)\",\n    arguments: [\"Arthur\", 1000])\nlet playerId = db.lastInsertedRowID\n```\n\nDon't miss [Records](#records), that provide classic **persistence methods**:\n\n```swift\nvar player = Player(name: \"Arthur\", score: 1000)\ntry player.insert(db)\nlet playerId = player.id\n```\n\n\n## Fetch Queries\n\n[Database connections] let you fetch database rows, plain values, and custom models aka \"records\".\n\n**Rows** are the raw results of SQL queries:\n\n```swift\ntry dbQueue.read { db in\n    if let row = try Row.fetchOne(db, sql: \"SELECT * FROM wine WHERE id = ?\", arguments: [1]) {\n        let name: String = row[\"name\"]\n        let color: Color = row[\"color\"]\n        print(name, color)\n    }\n}\n```\n\n\n**Values** are the Bool, Int, String, Date, Swift enums, etc. stored in row columns:\n\n```swift\ntry dbQueue.read { db in\n    let urls = try URL.fetchCursor(db, sql: \"SELECT url FROM wine\")\n    while let url = try urls.next() {\n        print(url)\n    }\n}\n```\n\n\n**Records** are your application objects that can initialize themselves from rows:\n\n```swift\nlet wines = try dbQueue.read { db in\n    try Wine.fetchAll(db, sql: \"SELECT * FROM wine\")\n}\n```\n\n- [Fetching Methods](#fetching-methods) and [Cursors](#cursors)\n- [Row Queries](#row-queries)\n- [Value Queries](#value-queries)\n- [Records](#records)\n\n\n### Fetching Methods\n\n**Throughout GRDB**, you can always fetch *cursors*, *arrays*, *sets*, or *single values* of any fetchable type (database [row](#row-queries), simple [value](#value-queries), or custom [record](#records)):\n\n```swift\ntry Row.fetchCursor(...) // A Cursor of Row\ntry Row.fetchAll(...)    // [Row]\ntry Row.fetchSet(...)    // Set<Row>\ntry Row.fetchOne(...)    // Row?\n```\n\n- `fetchCursor` returns a **[cursor](#cursors)** over fetched values:\n    \n    ```swift\n    let rows = try Row.fetchCursor(db, sql: \"SELECT ...\") // A Cursor of Row\n    ```\n    \n- `fetchAll` returns an **array**:\n    \n    ```swift\n    let players = try Player.fetchAll(db, sql: \"SELECT ...\") // [Player]\n    ```\n\n- `fetchSet` returns a **set**:\n    \n    ```swift\n    let names = try String.fetchSet(db, sql: \"SELECT ...\") // Set<String>\n    ```\n\n- `fetchOne` returns a **single optional value**, and consumes a single database row (if any).\n    \n    ```swift\n    let count = try Int.fetchOne(db, sql: \"SELECT COUNT(*) ...\") // Int?\n    ```\n\n**All those fetching methods require an SQL string that contains a single SQL statement.** When you want to fetch from multiple statements joined with a semicolon, iterate the multiple [prepared statements] found in the SQL string.\n\n### Cursors\n\nüìñ [`Cursor`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/cursor)\n\n**Whenever you consume several rows from the database, you can fetch an Array, a Set, or a Cursor**.\n\nThe `fetchAll()` and `fetchSet()` methods return regular Swift array and sets, that you iterate like all other arrays and sets:\n\n```swift\ntry dbQueue.read { db in\n    // [Player]\n    let players = try Player.fetchAll(db, sql: \"SELECT ...\")\n    for player in players {\n        // use player\n    }\n}\n```\n\nUnlike arrays and sets, cursors returned by `fetchCursor()` load their results step after step:\n\n```swift\ntry dbQueue.read { db in\n    // Cursor of Player\n    let players = try Player.fetchCursor(db, sql: \"SELECT ...\")\n    while let player = try players.next() {\n        // use player\n    }\n}\n```\n\n- **Cursors can not be used on any thread**: you must consume a cursor on the dispatch queue it was created in. Particularly, don't extract a cursor out of a database access method:\n    \n    ```swift\n    // Wrong\n    let cursor = try dbQueue.read { db in\n        try Player.fetchCursor(db, ...)\n    }\n    while let player = try cursor.next() { ... }\n    ```\n    \n    Conversely, arrays and sets may be consumed on any thread:\n    \n    ```swift\n    // OK\n    let array = try dbQueue.read { db in\n        try Player.fetchAll(db, ...)\n    }\n    for player in array { ... }\n    ```\n    \n- **Cursors can be iterated only one time.** Arrays and sets can be iterated many times.\n\n- **Cursors iterate database results in a lazy fashion**, and don't consume much memory. Arrays and sets contain copies of database values, and may take a lot of memory when there are many fetched results.\n\n- **Cursors are granted with direct access to SQLite,** unlike arrays and sets that have to take the time to copy database values. If you look after extra performance, you may prefer cursors.\n\n- **Cursors can feed Swift collections.**\n    \n    You will most of the time use `fetchAll` or `fetchSet` when you want an array or a set. For more specific needs, you may prefer one of the initializers below. All of them accept an extra optional `minimumCapacity` argument which helps optimizing your app when you have an idea of the number of elements in a cursor (the built-in `fetchAll` and `fetchSet` do not perform such an optimization).\n    \n    **Arrays** and all types conforming to `RangeReplaceableCollection`:\n    \n    ```swift\n    // [String]\n    let cursor = try String.fetchCursor(db, ...)\n    let array = try Array(cursor)\n    ```\n    \n    **Sets**:\n    \n    ```swift\n    // Set<Int>\n    let cursor = try Int.fetchCursor(db, ...)\n    let set = try Set(cursor)\n    ```\n    \n    **Dictionaries**:\n    \n    ```swift\n    // [Int64: [Player]]\n    let cursor = try Player.fetchCursor(db)\n    let dictionary = try Dictionary(grouping: cursor, by: { $0.teamID })\n    \n    // [Int64: Player]\n    let cursor = try Player.fetchCursor(db).map { ($0.id, $0) }\n    let dictionary = try Dictionary(uniqueKeysWithValues: cursor)\n    ```\n\n- **Cursors adopt the [Cursor](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/cursor) protocol, which looks a lot like standard [lazy sequences](https://developer.apple.com/reference/swift/lazysequenceprotocol) of Swift.** As such, cursors come with many convenience methods: `compactMap`, `contains`, `dropFirst`, `dropLast`, `drop(while:)`, `enumerated`, `filter`, `first`, `flatMap`, `forEach`, `joined`, `joined(separator:)`, `max`, `max(by:)`, `min`, `min(by:)`, `map`, `prefix`, `prefix(while:)`, `reduce`, `reduce(into:)`, `suffix`:\n    \n    ```swift\n    // Prints all Github links\n    try URL\n        .fetchCursor(db, sql: \"SELECT url FROM link\")\n        .filter { url in url.host == \"github.com\" }\n        .forEach { url in print(url) }\n    \n    // An efficient cursor of coordinates:\n    let locations = try Row.\n        .fetchCursor(db, sql: \"SELECT latitude, longitude FROM place\")\n        .map { row in\n            CLLocationCoordinate2D(latitude: row[0], longitude: row[1])\n        }\n    ```\n\n- **Cursors are not Swift sequences.** That's because Swift sequences can't handle iteration errors, when reading SQLite results may fail at any time.\n\n- **Cursors require a little care**:\n    \n    - Don't modify the results during a cursor iteration:\n        \n        ```swift\n        // Undefined behavior\n        while let player = try players.next() {\n            try db.execute(sql: \"DELETE ...\")\n        }\n        ```\n    \n    - Don't turn a cursor of `Row` into an array or a set. You would not get the distinct rows you expect. To get a array of rows, use `Row.fetchAll(...)`. To get a set of rows, use `Row.fetchSet(...)`. Generally speaking, make sure you copy a row whenever you extract it from a cursor for later use: `row.copy()`.\n\nIf you don't see, or don't care about the difference, use arrays. If you care about memory and performance, use cursors when appropriate.\n\n\n### Row Queries\n\n- [Fetching Rows](#fetching-rows)\n- [Column Values](#column-values)\n- [DatabaseValue](#databasevalue)\n- [Rows as Dictionaries](#rows-as-dictionaries)\n- üìñ [`Row`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/row)\n\n\n#### Fetching Rows\n\nFetch **cursors** of rows, **arrays**, **sets**, or **single** rows (see [fetching methods](#fetching-methods)):\n\n```swift\ntry dbQueue.read { db in\n    try Row.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Row\n    try Row.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Row]\n    try Row.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Row>\n    try Row.fetchOne(db, sql: \"SELECT ...\", arguments: ...)    // Row?\n    \n    let rows = try Row.fetchCursor(db, sql: \"SELECT * FROM wine\")\n    while let row = try rows.next() {\n        let name: String = row[\"name\"]\n        let color: Color = row[\"color\"]\n        print(name, color)\n    }\n}\n\nlet rows = try dbQueue.read { db in\n    try Row.fetchAll(db, sql: \"SELECT * FROM player\")\n}\n```\n\nArguments are optional arrays or dictionaries that fill the positional `?` and colon-prefixed keys like `:name` in the query:\n\n```swift\nlet rows = try Row.fetchAll(db,\n    sql: \"SELECT * FROM player WHERE name = ?\",\n    arguments: [\"Arthur\"])\n\nlet rows = try Row.fetchAll(db,\n    sql: \"SELECT * FROM player WHERE name = :name\",\n    arguments: [\"name\": \"Arthur\"])\n```\n\nSee [Values](#values) for more information on supported arguments types (Bool, Int, String, Date, Swift enums, etc.), and [`StatementArguments`] for a detailed documentation of SQLite arguments.\n\nUnlike row arrays that contain copies of the database rows, row cursors are close to the SQLite metal, and require a little care:\n\n> **Note**: **Don't turn a cursor of `Row` into an array or a set**. You would not get the distinct rows you expect. To get a array of rows, use `Row.fetchAll(...)`. To get a set of rows, use `Row.fetchSet(...)`. Generally speaking, make sure you copy a row whenever you extract it from a cursor for later use: `row.copy()`.\n\n\n#### Column Values\n\n**Read column values** by index or column name:\n\n```swift\nlet name: String = row[0]      // 0 is the leftmost column\nlet name: String = row[\"name\"] // Leftmost matching column - lookup is case-insensitive\nlet name: String = row[Column(\"name\")] // Using query interface's Column\n```\n\nMake sure to ask for an optional when the value may be NULL:\n\n```swift\nlet name: String? = row[\"name\"]\n```\n\nThe `row[]` subscript returns the type you ask for. See [Values](#values) for more information on supported value types:\n\n```swift\nlet bookCount: Int     = row[\"bookCount\"]\nlet bookCount64: Int64 = row[\"bookCount\"]\nlet hasBooks: Bool     = row[\"bookCount\"] // false when 0\n\nlet string: String     = row[\"date\"]      // \"2015-09-11 18:14:15.123\"\nlet date: Date         = row[\"date\"]      // Date\nself.date = row[\"date\"] // Depends on the type of the property.\n```\n\nYou can also use the `as` type casting operator:\n\n```swift\nrow[...] as Int\nrow[...] as Int?\n```\n\nThrowing accessors exist as well. Their use is not encouraged, because a database decoding error is a programming error. If an application stores invalid data in the database file, that is a bug that needs to be fixed:\n\n```swift\nlet name = try row.decode(String.self, atIndex: 0)\nlet bookCount = try row.decode(Int.self, forColumn: \"bookCount\")\n```\n\n> **Warning**: avoid the `as!` and `as?` operators:\n> \n> ```swift\n> if let int = row[...] as? Int { ... } // BAD - doesn't work\n> if let int = row[...] as Int? { ... } // GOOD\n> ```\n\n> **Warning**: avoid nil-coalescing row values, and prefer the `coalesce` method instead:\n>\n> ```swift\n> let name: String? = row[\"nickname\"] ?? row[\"name\"]     // BAD - doesn't work\n> let name: String? = row.coalesce([\"nickname\", \"name\"]) // GOOD\n> ```\n\nGenerally speaking, you can extract the type you need, provided it can be converted from the underlying SQLite value:\n\n- **Successful conversions include:**\n    \n    - All numeric SQLite values to all numeric Swift types, and Bool (zero is the only false boolean).\n    - Text SQLite values to Swift String.\n    - Blob SQLite values to Foundation Data.\n    \n    See [Values](#values) for more information on supported types (Bool, Int, String, Date, Swift enums, etc.)\n    \n- **NULL returns nil.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT NULL\")!\n    row[0] as Int? // nil\n    row[0] as Int  // fatal error: could not convert NULL to Int.\n    ```\n    \n    There is one exception, though: the [DatabaseValue](#databasevalue) type:\n    \n    ```swift\n    row[0] as DatabaseValue // DatabaseValue.null\n    ```\n    \n- **Missing columns return nil.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'foo' AS foo\")!\n    row[\"missing\"] as String? // nil\n    row[\"missing\"] as String  // fatal error: no such column: missing\n    ```\n    \n    You can explicitly check for a column presence with the `hasColumn` method.\n\n- **Invalid conversions throw a fatal error.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'Mom‚Äôs birthday'\")!\n    row[0] as String // \"Mom‚Äôs birthday\"\n    row[0] as Date?  // fatal error: could not convert \"Mom‚Äôs birthday\" to Date.\n    row[0] as Date   // fatal error: could not convert \"Mom‚Äôs birthday\" to Date.\n    \n    let row = try Row.fetchOne(db, sql: \"SELECT 256\")!\n    row[0] as Int    // 256\n    row[0] as UInt8? // fatal error: could not convert 256 to UInt8.\n    row[0] as UInt8  // fatal error: could not convert 256 to UInt8.\n    ```\n    \n    Those conversion fatal errors can be avoided with the [DatabaseValue](#databasevalue) type:\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'Mom‚Äôs birthday'\")!\n    let dbValue: DatabaseValue = row[0]\n    if dbValue.isNull {\n        // Handle NULL\n    } else if let date = Date.fromDatabaseValue(dbValue) {\n        // Handle valid date\n    } else {\n        // Handle invalid date\n    }\n    ```\n    \n    This extra verbosity is the consequence of having to deal with an untrusted database: you may consider fixing the content of your database instead. See [Fatal Errors](#fatal-errors) for more information.\n    \n- **SQLite has a weak type system, and provides [convenience conversions](https://www.sqlite.org/c3ref/column_blob.html) that can turn String to Int, Double to Blob, etc.**\n    \n    GRDB will sometimes let those conversions go through:\n    \n    ```swift\n    let rows = try Row.fetchCursor(db, sql: \"SELECT '20 small cigars'\")\n    while let row = try rows.next() {\n        row[0] as Int   // 20\n    }\n    ```\n    \n    Don't freak out: those conversions did not prevent SQLite from becoming the immensely successful database engine you want to use. And GRDB adds safety checks described just above. You can also prevent those convenience conversions altogether by using the [DatabaseValue](#databasevalue) type.\n\n\n#### DatabaseValue\n\nüìñ [`DatabaseValue`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalue)\n\n**`DatabaseValue` is an intermediate type between SQLite and your values, which gives information about the raw value stored in the database.**\n\nYou get `DatabaseValue` just like other value types:\n\n```swift\nlet dbValue: DatabaseValue = row[0]\nlet dbValue: DatabaseValue? = row[\"name\"] // nil if and only if column does not exist\n\n// Check for NULL:\ndbValue.isNull // Bool\n\n// The stored value:\ndbValue.storage.value // Int64, Double, String, Data, or nil\n\n// All the five storage classes supported by SQLite:\nswitch dbValue.storage {\ncase .null:                 print(\"NULL\")\ncase .int64(let int64):     print(\"Int64: \\(int64)\")\ncase .double(let double):   print(\"Double: \\(double)\")\ncase .string(let string):   print(\"String: \\(string)\")\ncase .blob(let data):       print(\"Data: \\(data)\")\n}\n```\n\nYou can extract regular [values](#values) (Bool, Int, String, Date, Swift enums, etc.) from `DatabaseValue` with the [fromDatabaseValue()](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible/fromdatabasevalue(_:)-21zzv) method:\n\n```swift\nlet dbValue: DatabaseValue = row[\"bookCount\"]\nlet bookCount   = Int.fromDatabaseValue(dbValue)   // Int?\nlet bookCount64 = Int64.fromDatabaseValue(dbValue) // Int64?\nlet hasBooks    = Bool.fromDatabaseValue(dbValue)  // Bool?, false when 0\n\nlet dbValue: DatabaseValue = row[\"date\"]\nlet string = String.fromDatabaseValue(dbValue)     // \"2015-09-11 18:14:15.123\"\nlet date   = Date.fromDatabaseValue(dbValue)       // Date?\n```\n\n`fromDatabaseValue` returns nil for invalid conversions:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 'Mom‚Äôs birthday'\")!\nlet dbValue: DatabaseValue = row[0]\nlet string = String.fromDatabaseValue(dbValue) // \"Mom‚Äôs birthday\"\nlet int    = Int.fromDatabaseValue(dbValue)    // nil\nlet date   = Date.fromDatabaseValue(dbValue)   // nil\n```\n\n\n#### Rows as Dictionaries\n\nRow adopts the standard [RandomAccessCollection](https://developer.apple.com/documentation/swift/randomaccesscollection) protocol, and can be seen as a dictionary of [DatabaseValue](#databasevalue):\n\n```swift\n// All the (columnName, dbValue) tuples, from left to right:\nfor (columnName, dbValue) in row {\n    ...\n}\n```\n\n**You can build rows from dictionaries** (standard Swift dictionaries and NSDictionary). See [Values](#values) for more information on supported types:\n\n```swift\nlet row: Row = [\"name\": \"foo\", \"date\": nil]\nlet row = Row([\"name\": \"foo\", \"date\": nil])\nlet row = Row(/* [AnyHashable: Any] */) // nil if invalid dictionary\n```\n\nYet rows are not real dictionaries: they may contain duplicate columns:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 1 AS foo, 2 AS foo\")!\nrow.columnNames    // [\"foo\", \"foo\"]\nrow.databaseValues // [1, 2]\nrow[\"foo\"]         // 1 (leftmost matching column)\nfor (columnName, dbValue) in row { ... } // (\"foo\", 1), (\"foo\", 2)\n```\n\n**When you build a dictionary from a row**, you have to disambiguate identical columns, and choose how to present database values. For example:\n\n- A `[String: DatabaseValue]` dictionary that keeps leftmost value in case of duplicated column name:\n\n    ```swift\n    let dict = Dictionary(row, uniquingKeysWith: { (left, _) in left })\n    ```\n\n- A `[String: AnyObject]` dictionary which keeps rightmost value in case of duplicated column name. This dictionary is identical to FMResultSet's resultDictionary from FMDB. It contains NSNull values for null columns, and can be shared with Objective-C:\n\n    ```swift\n    let dict = Dictionary(\n        row.map { (column, dbValue) in\n            (column, dbValue.storage.value as AnyObject)\n        },\n        uniquingKeysWith: { (_, right) in right })\n    ```\n\n- A `[String: Any]` dictionary that can feed, for example, JSONSerialization:\n    \n    ```swift\n    let dict = Dictionary(\n        row.map { (column, dbValue) in\n            (column, dbValue.storage.value)\n        },\n        uniquingKeysWith: { (left, _) in left })\n    ```\n\nSee the documentation of [`Dictionary.init(_:uniquingKeysWith:)`](https://developer.apple.com/documentation/swift/dictionary/2892961-init) for more information.\n\n\n### Value Queries\n\nüìñ [`DatabaseValueConvertible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible)\n\n**Instead of rows, you can directly fetch values.** There are many supported [value types](#values) (Bool, Int, String, Date, Swift enums, etc.).\n\nLike rows, fetch values as **cursors**, **arrays**, **sets**, or **single** values (see [fetching methods](#fetching-methods)). Values are extracted from the leftmost column of the SQL queries:\n\n```swift\ntry dbQueue.read { db in\n    try Int.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Int\n    try Int.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Int]\n    try Int.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Int>\n    try Int.fetchOne(db, sql: \"SELECT ...\", arguments: ...)    // Int?\n    \n    let maxScore = try Int.fetchOne(db, sql: \"SELECT MAX(score) FROM player\") // Int?\n    let names = try String.fetchAll(db, sql: \"SELECT name FROM player\")       // [String]\n}\n```\n\n`Int.fetchOne` returns nil in two cases: either the SELECT statement yielded no row, or one row with a NULL value:\n\n```swift\n// No row:\ntry Int.fetchOne(db, sql: \"SELECT 42 WHERE FALSE\") // nil\n\n// One row with a NULL value:\ntry Int.fetchOne(db, sql: \"SELECT NULL\")           // nil\n\n// One row with a non-NULL value:\ntry Int.fetchOne(db, sql: \"SELECT 42\")             // 42\n```\n\nFor requests which may contain NULL, fetch optionals:\n\n```swift\ntry dbQueue.read { db in\n    try Optional<Int>.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Int?\n    try Optional<Int>.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Int?]\n    try Optional<Int>.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Int?>\n}\n```\n\n> :bulb: **Tip**: One advanced use case, when you fetch one value, is to distinguish the cases of a statement that yields no row, or one row with a NULL value. To do so, use `Optional<Int>.fetchOne`, which returns a double optional `Int??`:\n> \n> ```swift\n> // No row:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT 42 WHERE FALSE\") // .none\n> // One row with a NULL value:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT NULL\")           // .some(.none)\n> // One row with a non-NULL value:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT 42\")             // .some(.some(42))\n> ```\n\nThere are many supported value types (Bool, Int, String, Date, Swift enums, etc.). See [Values](#values) for more information.\n\n\n## Values\n\nGRDB ships with built-in support for the following value types:\n\n- **Swift Standard Library**: Bool, Double, Float, all signed and unsigned integer types, String, [Swift enums](#swift-enums).\n    \n- **Foundation**: [Data](#data-and-memory-savings), [Date](#date-and-datecomponents), [DateComponents](#date-and-datecomponents), [Decimal](#nsnumber-nsdecimalnumber-and-decimal), NSNull, [NSNumber](#nsnumber-nsdecimalnumber-and-decimal), NSString, URL, [UUID](#uuid).\n    \n- **CoreGraphics**: CGFloat.\n\n- **[DatabaseValue](#databasevalue)**, the type which gives information about the raw value stored in the database.\n\n- **Full-Text Patterns**: [FTS3Pattern](Documentation/FullTextSearch.md#fts3pattern) and [FTS5Pattern](Documentation/FullTextSearch.md#fts5pattern).\n\n- Generally speaking, all types that adopt the [`DatabaseValueConvertible`] protocol.\n\nValues can be used as [statement arguments](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments):\n\n```swift\nlet url: URL = ...\nlet verified: Bool = ...\ntry db.execute(\n    sql: \"INSERT INTO link (url, verified) VALUES (?, ?)\",\n    arguments: [url, verified])\n```\n\nValues can be [extracted from rows](#column-values):\n\n```swift\nlet rows = try Row.fetchCursor(db, sql: \"SELECT * FROM link\")\nwhile let row = try rows.next() {\n    let url: URL = row[\"url\"]\n    let verified: Bool = row[\"verified\"]\n}\n```\n\nValues can be [directly fetched](#value-queries):\n\n```swift\nlet urls = try URL.fetchAll(db, sql: \"SELECT url FROM link\")  // [URL]\n```\n\nUse values in [Records](#records):\n\n```swift\nstruct Link: FetchableRecord {\n    var url: URL\n    var isVerified: Bool\n    \n    init(row: Row) {\n        url = row[\"url\"]\n        isVerified = row[\"verified\"]\n    }\n}\n```\n\nUse values in the [query interface](#the-query-interface):\n\n```swift\nlet url: URL = ...\nlet link = try Link.filter { $0.url == url }.fetchOne(db)\n```\n\n\n### Data (and Memory Savings)\n\n**Data** suits the BLOB SQLite columns. It can be stored and fetched from the database just like other [values](#values):\n\n```swift\nlet rows = try Row.fetchCursor(db, sql: \"SELECT data, ...\")\nwhile let row = try rows.next() {\n    let data: Data = row[\"data\"]\n}\n```\n\nAt each step of the request iteration, the `row[]` subscript creates *two copies* of the database bytes: one fetched by SQLite, and another, stored in the Swift Data value.\n\n**You have the opportunity to save memory** by not copying the data fetched by SQLite:\n\n```swift\nwhile let row = try rows.next() {\n    try row.withUnsafeData(name: \"data\") { (data: Data?) in\n        ...\n    }\n}\n```\n\nThe non-copied data does not live longer than the iteration step: make sure that you do not use it past this point.\n\n\n### Date and DateComponents\n\n[**Date**](#date) and [**DateComponents**](#datecomponents) can be stored and fetched from the database.\n\nHere is how GRDB supports the various [date formats](https://www.sqlite.org/lang_datefunc.html) supported by SQLite:\n\n| SQLite format                | Date               | DateComponents |\n|:---------------------------- |:------------------:|:--------------:|\n| YYYY-MM-DD                   |       Read ¬π       | Read / Write   |\n| YYYY-MM-DD HH:MM             |       Read ¬π ¬≤     | Read ¬≤ / Write |\n| YYYY-MM-DD HH:MM:SS          |       Read ¬π ¬≤     | Read ¬≤ / Write |\n| YYYY-MM-DD HH:MM:SS.SSS      | Read ¬π ¬≤ / Write ¬π | Read ¬≤ / Write |\n| YYYY-MM-DD**T**HH:MM         |       Read ¬π ¬≤     |      Read ¬≤    |\n| YYYY-MM-DD**T**HH:MM:SS      |       Read ¬π ¬≤     |      Read ¬≤    |\n| YYYY-MM-DD**T**HH:MM:SS.SSS  |       Read ¬π ¬≤     |      Read ¬≤    |\n| HH:MM                        |                    | Read ¬≤ / Write |\n| HH:MM:SS                     |                    | Read ¬≤ / Write |\n| HH:MM:SS.SSS                 |                    | Read ¬≤ / Write |\n| Timestamps since unix epoch  |       Read ¬≥       |                |\n| `now`                        |                    |                |\n\n¬π Missing components are assumed to be zero. Dates are stored and read in the UTC time zone, unless the format is followed by a timezone indicator ‚ÅΩ¬≤‚Åæ.\n\n¬≤ This format may be optionally followed by a timezone indicator of the form `[+-]HH:MM` or just `Z`.\n\n¬≥ GRDB 2+ interprets numerical values as timestamps that fuel `Date(timeIntervalSince1970:)`. Previous GRDB versions used to interpret numbers as [julian days](https://en.wikipedia.org/wiki/Julian_day). Julian days are still supported, with the `Date(julianDay:)` initializer.\n\n> **Warning**: the range of valid years in the SQLite date formats is 0000-9999. You will need to pick another date format when your application needs to process years outside of this range. See the following chapters.\n\n\n#### Date\n\n**Date** can be stored and fetched from the database just like other [values](#values):\n\n```swift\ntry db.execute(\n    sql: \"INSERT INTO player (creationDate, ...) VALUES (?, ...)\",\n    arguments: [Date(), ...])\n\nlet row = try Row.fetchOne(db, ...)!\nlet creationDate: Date = row[\"creationDate\"]\n```\n\nDates are stored using the format \"YYYY-MM-DD HH:MM:SS.SSS\" in the UTC time zone. It is precise to the millisecond.\n\n> **Note**: this format was chosen because it is the only format that is:\n> \n> - Comparable (`ORDER BY date` works)\n> - Comparable with the SQLite keyword CURRENT_TIMESTAMP (`WHERE date > CURRENT_TIMESTAMP` works)\n> - Able to feed [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html)\n> - Precise enough\n>\n> **Warning**: the range of valid years in the SQLite date format is 0000-9999. You will experience problems with years outside of this range, such as decoding errors, or invalid date computations with [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html).\n\nSome applications may prefer another date format:\n\n- Some may prefer ISO-8601, with a `T` separator.\n- Some may prefer ISO-8601, with a time zone.\n- Some may need to store years beyond the 0000-9999 range.\n- Some may need sub-millisecond precision.\n- Some may need exact `Date` roundtrip.\n- Etc.\n\n**You should think twice before choosing a different date format:**\n\n- ISO-8601 is about *exchange and communication*, when SQLite is about *storage and data manipulation*. Sharing the same representation in your database and in JSON files only provides a superficial convenience, and should be the least of your priorities. Don't store dates as ISO-8601 without understanding what you lose. For example, ISO-8601 time zones forbid database-level date comparison. \n- Sub-millisecond precision and exact `Date` roundtrip are not as obvious needs as it seems at first sight. Dates generally don't precisely roundtrip as soon as they leave your application anyway, because the other systems your app communicates with use their own date representation (the Android version of your app, the server your application is talking to, etc.) On top of that, `Date` comparison is at least as hard and nasty as [floating point comparison](https://www.google.com/search?q=floating+point+comparison+is+hard).\n\nThe customization of date format is explicit. For example:\n\n```swift\nlet date = Date()\nlet timeInterval = date.timeIntervalSinceReferenceDate\ntry db.execute(\n    sql: \"INSERT INTO player (creationDate, ...) VALUES (?, ...)\",\n    arguments: [timeInterval, ...])\n\nif let row = try Row.fetchOne(db, ...) {\n    let timeInterval: TimeInterval = row[\"creationDate\"]\n    let creationDate = Date(timeIntervalSinceReferenceDate: timeInterval)\n}\n```\n\nSee also [Codable Records] for more date customization options, and [`DatabaseValueConvertible`] if you want to define a Date-wrapping type with customized database representation.\n\n\n#### DateComponents\n\nDateComponents is indirectly supported, through the **DatabaseDateComponents** helper type.\n\nDatabaseDateComponents reads date components from all [date formats supported by SQLite](https://www.sqlite.org/lang_datefunc.html), and stores them in the format of your choice, from HH:MM to YYYY-MM-DD HH:MM:SS.SSS.\n\n> **Warning**: the range of valid years is 0000-9999. You will experience problems with years outside of this range, such as decoding errors, or invalid date computations with [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html). See [Date](#date) for more information.\n\nDatabaseDateComponents can be stored and fetched from the database just like other [values](#values):\n\n```swift\nlet components = DateComponents()\ncomponents.year = 1973\ncomponents.month = 9\ncomponents.day = 18\n\n// Store \"1973-09-18\"\nlet dbComponents = DatabaseDateComponents(components, format: .YMD)\ntry db.execute(\n    sql: \"INSERT INTO player (birthDate, ...) VALUES (?, ...)\",\n    arguments: [dbComponents, ...])\n\n// Read \"1973-09-18\"\nlet row = try Row.fetchOne(db, sql: \"SELECT birthDate ...\")!\nlet dbComponents: DatabaseDateComponents = row[\"birthDate\"]\ndbComponents.format         // .YMD (the actual format found in the database)\ndbComponents.dateComponents // DateComponents\n```\n\n\n### NSNumber, NSDecimalNumber, and Decimal\n\n**NSNumber** and **Decimal** can be stored and fetched from the database just like other [values](#values).\n\nHere is how GRDB supports the various data types supported by SQLite:\n\n|                 |    Integer   |     Double   |    String    |\n|:--------------- |:------------:|:------------:|:------------:|\n| NSNumber        | Read / Write | Read / Write |     Read     |\n| NSDecimalNumber | Read / Write | Read / Write |     Read     |\n| Decimal         |     Read     |     Read     | Read / Write |\n\n- All three types can decode database integers and doubles:\n\n    ```swift\n    let number = try NSNumber.fetchOne(db, sql: \"SELECT 10\")            // NSNumber\n    let number = try NSDecimalNumber.fetchOne(db, sql: \"SELECT 1.23\")   // NSDecimalNumber\n    let number = try Decimal.fetchOne(db, sql: \"SELECT -100\")           // Decimal\n    ```\n    \n- All three types decode database strings as decimal numbers:\n\n    ```swift\n    let number = try NSNumber.fetchOne(db, sql: \"SELECT '10'\")          // NSDecimalNumber (sic)\n    let number = try NSDecimalNumber.fetchOne(db, sql: \"SELECT '1.23'\") // NSDecimalNumber\n    let number = try Decimal.fetchOne(db, sql: \"SELECT '-100'\")         // Decimal\n    ```\n\n- `NSNumber` and `NSDecimalNumber` send 64-bit signed integers and doubles in the database:\n\n    ```swift\n    // INSERT INTO transfer VALUES (10)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSNumber(value: 10)])\n    \n    // INSERT INTO transfer VALUES (10.0)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSNumber(value: 10.0)])\n    \n    // INSERT INTO transfer VALUES (10)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSDecimalNumber(string: \"10.0\")])\n    \n    // INSERT INTO transfer VALUES (10.5)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSDecimalNumber(string: \"10.5\")])\n    ```\n    \n    > **Warning**: since SQLite does not support decimal numbers, sending a non-integer `NSDecimalNumber` can result in a loss of precision during the conversion to double.\n    >\n    > Instead of sending non-integer `NSDecimalNumber` to the database, you may prefer:\n    >\n    > - Send `Decimal` instead (those store decimal strings in the database).\n    > - Send integers instead (for example, store amounts of cents instead of amounts of Euros).\n\n- `Decimal` sends decimal strings in the database:\n\n    ```swift\n    // INSERT INTO transfer VALUES ('10')\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [Decimal(10)])\n    \n    // INSERT INTO transfer VALUES ('10.5')\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [Decimal(string: \"10.5\")!])\n    ```\n\n\n### UUID\n\n**UUID** can be stored and fetched from the database just like other [values](#values).\n\nGRDB stores uuids as 16-bytes data blobs, and decodes them from both 16-bytes data blobs and strings such as \"E621E1F8-C36C-495A-93FC-0C247A3E6E5F\".\n\n\n### Swift Enums\n\n**Swift enums** and generally all types that adopt the [RawRepresentable](https://developer.apple.com/library/tvos/documentation/Swift/Reference/Swift_RawRepresentable_Protocol/index.html) protocol can be stored and fetched from the database just like their raw [values](#values):\n\n```swift\nenum Color : Int {\n    case red, white, rose\n}\n\nenum Grape : String {\n    case chardonnay, merlot, riesling\n}\n\n// Declare empty DatabaseValueConvertible adoption\nextension Color : DatabaseValueConvertible { }\nextension Grape : DatabaseValueConvertible { }\n\n// Store\ntry db.execute(\n    sql: \"INSERT INTO wine (grape, color) VALUES (?, ?)\",\n    arguments: [Grape.merlot, Color.red])\n\n// Read\nlet rows = try Row.fetchCursor(db, sql: \"SELECT * FROM wine\")\nwhile let row = try rows.next() {\n    let grape: Grape = row[\"grape\"]\n    let color: Color = row[\"color\"]\n}\n```\n\n**When a database value does not match any enum case**, you get a fatal error. This fatal error can be avoided with the [DatabaseValue](#databasevalue) type:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 'syrah'\")!\n\nrow[0] as String  // \"syrah\"\nrow[0] as Grape?  // fatal error: could not convert \"syrah\" to Grape.\nrow[0] as Grape   // fatal error: could not convert \"syrah\" to Grape.\n\nlet dbValue: DatabaseValue = row[0]\nif dbValue.isNull {\n    // Handle NULL\n} else if let grape = Grape.fromDatabaseValue(dbValue) {\n    // Handle valid grape\n} else {\n    // Handle unknown grape\n}\n```\n\n\n## Custom SQL Functions and Aggregates\n\n**SQLite lets you define SQL functions and aggregates.**\n\nA custom SQL function or aggregate extends SQLite:\n\n```sql\nSELECT reverse(name) FROM player;   -- custom function\nSELECT maxLength(name) FROM player; -- custom aggregate\n```\n\n- [Custom SQL Functions](#custom-sql-functions)\n- [Custom Aggregates](#custom-aggregates)\n\n\n### Custom SQL Functions\n\nüìñ [`DatabaseFunction`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasefunction)\n\nA *function* argument takes an array of [DatabaseValue](#databasevalue), and returns any valid [value](#values) (Bool, Int, String, Date, Swift enums, etc.) The number of database values is guaranteed to be *argumentCount*.\n\nSQLite has the opportunity to perform additional optimizations when functions are \"pure\", which means that their result only depends on their arguments. So make sure to set the *pure* argument to true when possible.\n\n```swift\nlet reverse = DatabaseFunction(\"reverse\", argumentCount: 1, pure: true) { (values: [DatabaseValue]) in\n    // Extract string value, if any...\n    guard let string = String.fromDatabaseValue(values[0]) else {\n        return nil\n    }\n    // ... and return reversed string:\n    return String(string.reversed())\n}\n```\n\nYou make a function available to a database connection through its configuration:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(function: reverse)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // \"oof\"\n    try String.fetchOne(db, sql: \"SELECT reverse('foo')\")!\n}\n```\n\n\n**Functions can take a variable number of arguments:**\n\nWhen you don't provide any explicit *argumentCount*, the function can take any number of arguments:\n\n```swift\nlet averageOf = DatabaseFunction(\"averageOf\", pure: true) { (values: [DatabaseValue]) in\n    let doubles = values.compactMap { Double.fromDatabaseValue($0) }\n    return doubles.reduce(0, +) / Double(doubles.count)\n}\ndb.add(function: averageOf)\n\n// 2.0\ntry Double.fetchOne(db, sql: \"SELECT averageOf(1, 2, 3)\")!\n```\n\n\n**Functions can throw:**\n\n```swift\nlet sqrt = DatabaseFunction(\"sqrt\", argumentCount: 1, pure: true) { (values: [DatabaseValue]) in\n    guard let double = Double.fromDatabaseValue(values[0]) else {\n        return nil\n    }\n    guard double >= 0 else {\n        throw DatabaseError(message: \"invalid negative number\")\n    }\n    return sqrt(double)\n}\ndb.add(function: sqrt)\n\n// SQLite error 1 with statement `SELECT sqrt(-1)`: invalid negative number\ntry Double.fetchOne(db, sql: \"SELECT sqrt(-1)\")!\n```\n\n\n**Use custom functions in the [query interface](#the-query-interface):**\n\n```swift\n// SELECT reverseString(\"name\") FROM player\nPlayer.select { reverseString($0.name) }\n```\n\n\n**GRDB ships with built-in SQL functions that perform unicode-aware string transformations.** See [Unicode](#unicode).\n\n\n### Custom Aggregates\n\nüìñ [`DatabaseFunction`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasefunction), [`DatabaseAggregate`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseaggregate)\n\nBefore registering a custom aggregate, you need to define a type that adopts the `DatabaseAggregate` protocol:\n\n```swift\nprotocol DatabaseAggregate {\n    // Initializes an aggregate\n    init()\n    \n    // Called at each step of the aggregation\n    mutating func step(_ dbValues: [DatabaseValue]) throws\n    \n    // Returns the final result\n    func finalize() throws -> DatabaseValueConvertible?\n}\n```\n\nFor example:\n\n```swift\nstruct MaxLength : DatabaseAggregate {\n    var maxLength: Int = 0\n    \n    mutating func step(_ dbValues: [DatabaseValue]) {\n        // At each step, extract string value, if any...\n        guard let string = String.fromDatabaseValue(dbValues[0]) else {\n            return\n        }\n        // ... and update the result\n        let length = string.count\n        if length > maxLength {\n            maxLength = length\n        }\n    }\n    \n    func finalize() -> DatabaseValueConvertible? {\n        maxLength\n    }\n}\n\nlet maxLength = DatabaseFunction(\n    \"maxLength\",\n    argumentCount: 1,\n    pure: true,\n    aggregate: MaxLength.self)\n```\n\nLike [custom SQL Functions](#custom-sql-functions), you make an aggregate function available to a database connection through its configuration:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(function: maxLength)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // Some Int\n    try Int.fetchOne(db, sql: \"SELECT maxLength(name) FROM player\")!\n}\n```\n\nThe `step` method of the aggregate takes an array of [DatabaseValue](#databasevalue). This array contains as many values as the *argumentCount* parameter (or any number of values, when *argumentCount* is omitted).\n\nThe `finalize` method of the aggregate returns the final aggregated [value](#values) (Bool, Int, String, Date, Swift enums, etc.).\n\nSQLite has the opportunity to perform additional optimizations when aggregates are \"pure\", which means that their result only depends on their inputs. So make sure to set the *pure* argument to true when possible.\n\n\n**Use custom aggregates in the [query interface](#the-query-interface):**\n\n```swift\n// SELECT maxLength(\"name\") FROM player\nlet request = Player.select { maxLength($0.name) }\ntry Int.fetchOne(db, request) // Int?\n```\n\n\n## Raw SQLite Pointers\n\n**If not all SQLite APIs are exposed in GRDB, you can still use the [SQLite C Interface](https://www.sqlite.org/c3ref/intro.html) and call [SQLite C functions](https://www.sqlite.org/c3ref/funclist.html).**\n\nTo access the C SQLite functions from SQLCipher or the system SQLite, you need to perform an extra import:\n\n```swift\nimport SQLite3   // System SQLite\nimport SQLCipher // SQLCipher\n\nlet sqliteVersion = String(cString: sqlite3_libversion())\n```\n\nRaw pointers to database connections and statements are available through the `Database.sqliteConnection` and `Statement.sqliteStatement` properties:\n\n```swift\ntry dbQueue.read { db in\n    // The raw pointer to a database connection:\n    let sqliteConnection = db.sqliteConnection\n\n    // The raw pointer to a statement:\n    let statement = try db.makeStatement(sql: \"SELECT ...\")\n    let sqliteStatement = statement.sqliteStatement\n}\n```\n\n> **Note**\n>\n> - Those pointers are owned by GRDB: don't close connections or finalize statements created by GRDB.\n> - GRDB opens SQLite connections in the \"[multi-thread mode](https://www.sqlite.org/threadsafe.html)\", which (oddly) means that **they are not thread-safe**. Make sure you touch raw databases and statements inside their dedicated dispatch queues.\n> - Use the raw SQLite C Interface at your own risk. GRDB won't prevent you from shooting yourself in the foot.\n\n\nRecords\n=======\n\n**On top of the [SQLite API](#sqlite-api), GRDB provides protocols** that help manipulating database rows as regular objects named \"records\":\n\n```swift\ntry dbQueue.write { db in\n    if var place = try Player.fetchOne(db, id: 1) {\n        player.score += 10\n        try player.update(db)\n    }\n}\n```\n\nOf course, you need to open a [database connection], and [create database tables](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema) first.\n\nTo define a record type, define a type and extend it with database protocols:\n\n- `FetchableRecord` makes it possible to fetch instances from the database.\n- `PersistableRecord` makes it possible to save instances into the database.\n- `Codable` (not mandatory) provides ready-made serialization to and from database rows.\n- `Identifiable` (not mandatory) provides extra convenience database methods.\n\nTo make it easier to customize database requests, also nest a `Columns` enum: \n\n```swift\nstruct Player: Codable, Identifiable {\n    var id: Int64\n    var name: String\n    var score: Int\n    var team: String?\n}\n\n// Add database support\nextension Player: FetchableRecord, PersistableRecord {\n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n        static let team = Column(CodingKeys.team)\n    }\n}\n```\n\nSee more [examples of record definitions](#examples-of-record-definitions) below.\n\n> Note: if you are familiar with Core Data's NSManagedObject or Realm's Object, you may experience a cultural shock: GRDB records are not uniqued, do not auto-update, and do not lazy-load. This is both a purpose, and a consequence of protocol-oriented programming.\n>\n> Tip: The [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices) guide provides general guidance..\n>\n> Tip: See the [Demo Applications] for sample apps that uses records.\n\n**Overview**\n\n- [Inserting Records](#inserting-records)\n- [Fetching Records](#fetching-records)\n- [Updating Records](#updating-records)\n- [Deleting Records](#deleting-records)\n- [Counting Records](#counting-records)\n\n**Protocols and the Record Class**\n\n- [Record Protocols Overview](#record-protocols-overview)\n- [FetchableRecord Protocol](#fetchablerecord-protocol)\n- [TableRecord Protocol](#tablerecord-protocol)\n- [PersistableRecord Protocol](#persistablerecord-protocol)\n    - [Persistence Methods]\n    - [Persistence Methods and the `RETURNING` clause]\n    - [Persistence Callbacks]\n- [Identifiable Records]\n- [Codable Records]\n- [Record Comparison]\n- [Record Customization Options]\n- [Record Timestamps and Transaction Date]\n\n\n### Inserting Records\n\nTo insert a record in the database, call the `insert` method:\n\n```swift\nlet player = Player(id: 1, name: \"Arthur\", score: 1000)\ntry player.insert(db)\n```\n\n:point_right: `insert` is available for types that adopt the [PersistableRecord] protocol.\n\n\n### Fetching Records\n\nTo fetch records from the database, call a [fetching method](#fetching-methods):\n\n```swift\nlet arthur = try Player.fetchOne(db,            // Player?\n    sql: \"SELECT * FROM players WHERE name = ?\",\n    arguments: [\"Arthur\"])\n\nlet bestPlayers = try Player                    // [Player]\n    .order(\\.score.desc)\n    .limit(10)\n    .fetchAll(db)\n    \nlet spain = try Country.fetchOne(db, id: \"ES\")  // Country?\nlet italy = try Country.find(db, id: \"IT\")      // Country\n```\n\n:point_right: Fetching from raw SQL is available for types that adopt the [FetchableRecord] protocol.\n\n:point_right: Fetching without SQL, using the [query interface](#the-query-interface), is available for types that adopt both [FetchableRecord] and [TableRecord] protocol.\n\n\n### Updating Records\n\nTo update a record in the database, call the `update` method:\n\n```swift\nvar player: Player = ...\nplayer.score = 1000\ntry player.update(db)\n```\n\nIt is possible to [avoid useless updates](#record-comparison):\n\n```swift\n// does not hit the database if score has not changed\ntry player.updateChanges(db) {\n    $0.score = 1000\n}\n```\n\nSee the [query interface](#the-query-interface) for batch updates:\n\n```swift\ntry Player\n    .filter { $0.team == \"red\" }\n    .updateAll(db) { $0.score += 1 }\n```\n\n:point_right: update methods are available for types that adopt the [PersistableRecord] protocol. Batch updates are available on the [TableRecord] protocol.\n\n\n### Deleting Records\n\nTo delete a record in the database, call the `delete` method:\n\n```swift\nlet player: Player = ...\ntry player.delete(db)\n```\n\nYou can also delete by primary key, unique key, or perform batch deletes (see [Delete Requests](#delete-requests)):\n\n```swift\ntry Player.deleteOne(db, id: 1)\ntry Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\ntry Country.deleteAll(db, ids: [\"FR\", \"US\"])\ntry Player\n    .filter { $0.email == nil }\n    .deleteAll(db)\n```\n\n:point_right: delete methods are available for types that adopt the [PersistableRecord] protocol. Batch deletes are available on the [TableRecord] protocol.\n\n\n### Counting Records\n\nTo count records, call the `fetchCount` method:\n\n```swift\nlet playerCount: Int = try Player.fetchCount(db)\n\nlet playerWithEmailCount: Int = try Player\n    .filter { $0.email == nil }\n    .fetchCount(db)\n```\n\n:point_right: `fetchCount` is available for types that adopt the [TableRecord] protocol.\n\n\nDetails follow:\n\n- [Record Protocols Overview](#record-protocols-overview)\n- [FetchableRecord Protocol](#fetchablerecord-protocol)\n- [TableRecord Protocol](#tablerecord-protocol)\n- [PersistableRecord Protocol](#persistablerecord-protocol)\n- [Identifiable Records]\n- [Codable Records]\n- [Record Comparison]\n- [Record Customization Options]\n- [Examples of Record Definitions](#examples-of-record-definitions)\n\n\n## Record Protocols Overview\n\n**GRDB ships with three record protocols**. Your own types will adopt one or several of them, according to the abilities you want to extend your types with.\n\n- [FetchableRecord] is able to **decode database rows**.\n    \n    ```swift\n    struct Place: FetchableRecord { ... }\n    \n    let places = try dbQueue.read { db in\n        try Place.fetchAll(db, sql: \"SELECT * FROM place\")\n    }\n    ```\n    \n    > :bulb: **Tip**: `FetchableRecord` can derive its implementation from the standard `Decodable` protocol. See [Codable Records] for more information.\n    \n    `FetchableRecord` can decode database rows, but it is not able to build SQL requests for you. For that, you also need `TableRecord`:\n    \n- [TableRecord] is able to **generate SQL queries**:\n    \n    ```swift\n    struct Place: TableRecord { ... }\n    \n    let placeCount = try dbQueue.read { db in\n        // Generates and runs `SELECT COUNT(*) FROM place`\n        try Place.fetchCount(db)\n    }\n    ```\n    \n    When a type adopts both `TableRecord` and `FetchableRecord`, it can load from those requests:\n    \n    ```swift\n    struct Place: TableRecord, FetchableRecord { ... }\n    \n    try dbQueue.read { db in\n        let places = try Place.order(\\.title).fetchAll(db)\n        let paris = try Place.fetchOne(id: 1)\n    }\n    ```\n\n- [PersistableRecord] is able to **write**: it can create, update, and delete rows in the database:\n    \n    ```swift\n    struct Place : PersistableRecord { ... }\n    \n    try dbQueue.write { db in\n        try Place.delete(db, id: 1)\n        try Place(...).insert(db)\n    }\n    ```\n    \n    A persistable record can also [compare](#record-comparison) itself against other records, and avoid useless database updates.\n    \n    > :bulb: **Tip**: `PersistableRecord` can derive its implementation from the standard `Encodable` protocol. See [Codable Records] for more information.\n\n\n## FetchableRecord Protocol\n\nüìñ [`FetchableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/fetchablerecord)\n\n**The FetchableRecord protocol grants fetching methods to any type** that can be built from a database row:\n\n```swift\nprotocol FetchableRecord {\n    /// Row initializer\n    init(row: Row) throws\n}\n```\n\nFor example:\n\n```swift\nstruct Place {\n    var id: Int64?\n    var title: String\n    var coordinate: CLLocationCoordinate2D\n}\n\nextension Place: FetchableRecord {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n    \n    init(row: Row) {\n        id = row[Columns.id]\n        title = row[Columns.title]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[Columns.latitude],\n            longitude: row[Columns.longitude])\n    }\n}\n```\n\nSee [column values](#column-values) for more information about the `row[]` subscript.\n\nWhen your record type adopts the standard Decodable protocol, you don't have to provide the implementation for `init(row:)`. See [Codable Records] for more information:\n\n```swift\n// That's all\nstruct Player: Decodable, FetchableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n```\n\nFetchableRecord allows adopting types to be fetched from SQL queries:\n\n```swift\ntry Place.fetchCursor(db, sql: \"SELECT ...\", arguments:...) // A Cursor of Place\ntry Place.fetchAll(db, sql: \"SELECT ...\", arguments:...)    // [Place]\ntry Place.fetchSet(db, sql: \"SELECT ...\", arguments:...)    // Set<Place>\ntry Place.fetchOne(db, sql: \"SELECT ...\", arguments:...)    // Place?\n```\n\nSee [fetching methods](#fetching-methods) for information about the `fetchCursor`, `fetchAll`, `fetchSet` and `fetchOne` methods. See [`StatementArguments`] for more information about the query arguments.\n\n> **Note**: for performance reasons, the same row argument to `init(row:)` is reused during the iteration of a fetch query. If you want to keep the row for later use, make sure to store a copy: `self.row = row.copy()`.\n\n> **Note**: The `FetchableRecord.init(row:)` initializer fits the needs of most applications. But some application are more demanding than others. When FetchableRecord does not exactly provide the support you need, have a look at the [Beyond FetchableRecord] chapter.\n\n\n## TableRecord Protocol\n\nüìñ [`TableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord)\n\n**The TableRecord protocol** generates SQL for you:\n\n```swift\nprotocol TableRecord {\n    static var databaseTableName: String { get }\n    static var databaseSelection: [any SQLSelectable] { get }\n}\n```\n\nThe `databaseSelection` type property is optional, and documented in the [Columns Selected by a Request] chapter.\n\nThe `databaseTableName` type property is the name of a database table. By default, it is derived from the type name:\n\n```swift\nstruct Place: TableRecord { }\n\nprint(Place.databaseTableName) // prints \"place\"\n```\n\nFor example:\n\n- Place: `place`\n- Country: `country`\n- PostalAddress: `postalAddress`\n- HTTPRequest: `httpRequest`\n- TOEFL: `toefl`\n\nYou can still provide a custom table name:\n\n```swift\nstruct Place: TableRecord {\n    static let databaseTableName = \"location\"\n}\n\nprint(Place.databaseTableName) // prints \"location\"\n```\n\nWhen a type adopts both TableRecord and [FetchableRecord](#fetchablerecord-protocol), it can be fetched using the [query interface](#the-query-interface):\n\n```swift\n// SELECT * FROM place WHERE name = 'Paris'\nlet paris = try Place.filter { $0.name == \"Paris\" }.fetchOne(db)\n```\n\nTableRecord can also fetch deal with primary and unique keys: see [Fetching by Key](#fetching-by-key) and [Testing for Record Existence](#testing-for-record-existence).\n\n\n## PersistableRecord Protocol\n\nüìñ [`EncodableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/encodablerecord), [`MutablePersistableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/mutablepersistablerecord), [`PersistableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/persistablerecord)\n\n**GRDB record types can create, update, and delete rows in the database.**\n\nThose abilities are granted by three protocols:\n\n```swift\n// Defines how a record encodes itself into the database\nprotocol EncodableRecord {\n    /// Defines the values persisted in the database\n    func encode(to container: inout PersistenceContainer) throws\n}\n\n// Adds persistence methods\nprotocol MutablePersistableRecord: TableRecord, EncodableRecord {\n    /// Optional method that lets your adopting type store its rowID upon\n    /// successful insertion. Don't call it directly: it is called for you.\n    mutating func didInsert(_ inserted: InsertionSuccess)\n}\n\n// Adds immutability\nprotocol PersistableRecord: MutablePersistableRecord {\n    /// Non-mutating version of the optional didInsert(_:)\n    func didInsert(_ inserted: InsertionSuccess)\n}\n```\n\nYes, three protocols instead of one. Here is how you pick one or the other:\n\n- **If your type is a class**, choose `PersistableRecord`. On top of that, implement `didInsert(_:)` if the database table has an auto-incremented primary key.\n\n- **If your type is a struct, and the database table has an auto-incremented primary key**, choose `MutablePersistableRecord`, and implement `didInsert(_:)`.\n\n- **Otherwise**, choose `PersistableRecord`, and ignore `didInsert(_:)`.\n\nThe `encode(to:)` method defines which [values](#values) (Bool, Int, String, Date, Swift enums, etc.) are assigned to database columns.\n\nThe optional `didInsert` method lets the adopting type store its rowID after successful insertion, and is only useful for tables that have an auto-incremented primary key. It is called from a protected dispatch queue, and serialized with all database updates.\n\nFor example:\n\n```swift\nextension Place: MutablePersistableRecord {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n    \n    /// The values persisted in the database\n    func encode(to container: inout PersistenceContainer) {\n        container[Columns.id] = id\n        container[Columns.title] = title\n        container[Columns.latitude] = coordinate.latitude\n        container[Columns.longitude] = coordinate.longitude\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n\nvar paris = Place(\n    id: nil,\n    title: \"Paris\",\n    coordinate: CLLocationCoordinate2D(latitude: 48.8534100, longitude: 2.3488000))\n\ntry paris.insert(db)\nparis.id   // some value\n```\n\nWhen your record type adopts the standard Encodable protocol, you don't have to provide the implementation for `encode(to:)`. See [Codable Records] for more information:\n\n```swift\n// That's all\nstruct Player: Encodable, MutablePersistableRecord {\n    var id: Int64?\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n\n### Persistence Methods\n\nTypes that adopt the [PersistableRecord] protocol are given methods that insert, update, and delete:\n\n```swift\n// INSERT\ntry place.insert(db)\nlet insertedPlace = try place.inserted(db) // non-mutating\n\n// UPDATE\ntry place.update(db)\ntry place.update(db, columns: [\"title\"])\n\n// Maybe UPDATE\ntry place.updateChanges(db, from: otherPlace)\ntry place.updateChanges(db) { $0.isFavorite = true }\n\n// INSERT or UPDATE\ntry place.save(db)\nlet savedPlace = place.saved(db) // non-mutating\n\n// UPSERT\ntry place.upsert(db)\nlet insertedPlace = place.upsertAndFetch(db)\n\n// DELETE\ntry place.delete(db)\n\n// EXISTENCE CHECK\nlet exists = try place.exists(db)\n```\n\nSee [Upsert](#upsert) below for more information about upserts.\n\n**The [TableRecord] protocol comes with batch operations**:\n\n```swift\n// UPDATE\ntry Place.updateAll(db, ...)\n\n// DELETE\ntry Place.deleteAll(db)\ntry Place.deleteAll(db, ids:...)\ntry Place.deleteAll(db, keys:...)\ntry Place.deleteOne(db, id:...)\ntry Place.deleteOne(db, key:...)\n```\n\nFor more information about batch updates, see [Update Requests](#update-requests).\n\n- All persistence methods can throw a [DatabaseError](#error-handling).\n\n- `update` and `updateChanges` throw [RecordError] if the database does not contain any row for the primary key of the record.\n\n- `save` makes sure your values are stored in the database. It performs an UPDATE if the record has a non-null primary key, and then, if no row was modified, an INSERT. It directly performs an INSERT if the record has no primary key, or a null primary key.\n\n- `delete` and `deleteOne` returns whether a database row was deleted or not. `deleteAll` returns the number of deleted rows. `updateAll` returns the number of updated rows. `updateChanges` returns whether a database row was updated or not.\n\n**All primary keys are supported**, including composite primary keys that span several columns, and the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html).\n\n**To customize persistence methods**, you provide [Persistence Callbacks], described below. Do not attempt at overriding the ready-made persistence methods.\n\n### Upsert\n\n[UPSERT](https://www.sqlite.org/lang_UPSERT.html) is an SQLite feature that causes an INSERT to behave as an UPDATE or a no-op if the INSERT would violate a uniqueness constraint (primary key or unique index).\n\n> **Note**: Upsert apis are available from SQLite 3.35.0+: iOS 15.0+, macOS 12.0+, tvOS 15.0+, watchOS 8.0+, or with a [custom SQLite build] or [SQLCipher](#encryption).\n>\n> **Note**: With regard to [persistence callbacks](#available-callbacks), an upsert behaves exactly like an insert. In particular: the `aroundInsert(_:)` and `didInsert(_:)` callbacks reports the rowid of the inserted or updated row; `willUpdate`, `aroundUpdate`, `didUpdate` are not called.\n\n[PersistableRecord] provides three upsert methods:\n\n- `upsert(_:)`\n    \n    Inserts or updates a record.\n    \n    The upsert behavior is triggered by a violation of any uniqueness constraint on the table (primary key or unique index). In case of conflict, all columns but the primary key are overwritten with the inserted values:\n    \n    ```swift\n    struct Player: Encodable, PersistableRecord {\n        var id: Int64\n        var name: String\n        var score: Int\n    }\n    \n    // INSERT INTO player (id, name, score)\n    // VALUES (1, 'Arthur', 1000)\n    // ON CONFLICT DO UPDATE SET\n    //   name = excluded.name,\n    //   score = excluded.score\n    let player = Player(id: 1, name: \"Arthur\", score: 1000)\n    try player.upsert(db)\n    ```\n\n- `upsertAndFetch(_:onConflict:doUpdate:)` (requires [FetchableRecord] conformance)\n\n    Inserts or updates a record, and returns the upserted record.\n    \n    The `onConflict` and `doUpdate` arguments let you further control the upsert behavior. Make sure you check the [SQLite UPSERT documentation](https://www.sqlite.org/lang_UPSERT.html) for detailed information.\n    \n    - `onConflict`: the \"conflict target\" is the array of columns in the uniqueness constraint (primary key or unique index) that triggers the upsert.\n        \n        If empty (the default), all uniqueness constraint are considered.\n    \n    - `doUpdate`: a closure that returns columns assignments to perform in case of conflict. Other columns are overwritten with the inserted values.\n        \n        By default, all inserted columns but the primary key and the conflict target are overwritten.\n    \n    In the example below, we upsert the new vocabulary word \"jovial\". It is inserted if that word is not already in the dictionary. Otherwise, `count` is incremented, `isTainted` is not overwritten, and `kind` is overwritten:\n    \n    ```swift\n    // CREATE TABLE vocabulary(\n    //   word TEXT NOT NULL PRIMARY KEY,\n    //   kind TEXT NOT NULL,\n    //   isTainted BOOLEAN DEFAULT 0,\n    //   count INT DEFAULT 1))\n    struct Vocabulary: Encodable, PersistableRecord {\n        var word: String\n        var kind: String\n        var isTainted: Bool\n    }\n    \n    // INSERT INTO vocabulary(word, kind, isTainted)\n    // VALUES('jovial', 'adjective', 0)\n    // ON CONFLICT(word) DO UPDATE SET \\\n    //   count = count + 1,   -- on conflict, count is incremented\n    //   kind = excluded.kind -- on conflict, kind is overwritten\n    // RETURNING *\n    let vocabulary = Vocabulary(word: \"jovial\", kind: \"adjective\", isTainted: false)\n    let upserted = try vocabulary.upsertAndFetch(\n        db, onConflict: [\"word\"],\n        doUpdate: { _ in\n            [Column(\"count\") += 1,            // on conflict, count is incremented\n             Column(\"isTainted\").noOverwrite] // on conflict, isTainted is NOT overwritten\n        })\n    ```\n    \n    The `doUpdate` closure accepts an `excluded` TableAlias argument that refers to the inserted values that trigger the conflict. You can use it to specify an explicit overwrite, or to perform a computation. In the next example, the upsert keeps the maximum date in case of conflict:\n    \n    ```swift\n    // INSERT INTO message(id, text, date)\n    // VALUES(...)\n    // ON CONFLICT DO UPDATE SET \\\n    //   text = excluded.text,\n    //   date = MAX(date, excluded.date)\n    // RETURNING *\n    let upserted = try message.upsertAndFetch(doUpdate: { excluded in\n        // keep the maximum date in case of conflict\n        [Column(\"date\").set(to: max(Column(\"date\"), excluded[\"date\"]))]\n    })\n    ```\n\n- `upsertAndFetch(_:as:onConflict:doUpdate:)` (does not require [FetchableRecord] conformance)\n\n    This method is identical to `upsertAndFetch(_:onConflict:doUpdate:)` described above, but you can provide a distinct [FetchableRecord] record type as a result, in order to specify the returned columns.\n\n### Persistence Methods and the `RETURNING` clause\n\nSQLite is able to return values from a inserted, updated, or deleted row, with the [`RETURNING` clause](https://www.sqlite.org/lang_returning.html).\n\n> **Note**: Support for the `RETURNING` clause is available from SQLite 3.35.0+: iOS 15.0+, macOS 12.0+, tvOS 15.0+, watchOS 8.0+, or with a [custom SQLite build] or [SQLCipher](#encryption).\n\nThe `RETURNING` clause helps dealing with database features such as auto-incremented ids, default values, and [generated columns](https://sqlite.org/gencol.html). You can, for example, insert a few columns and fetch the default or generated ones in one step.\n\nGRDB uses the `RETURNING` clause in all persistence methods that contain `AndFetch` in their name.\n\nFor example, given a database table with an auto-incremented primary key and a default score:\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player(\n          id INTEGER PRIMARY KEY AUTOINCREMENT,\n          name TEXT NOT NULL,\n          score INTEGER NOT NULL DEFAULT 1000)\n        \"\"\")\n}\n```\n\nYou can define a record type with full database information, and another partial record type that deals with a subset of columns:\n\n```swift\n// A player with full database information\nstruct Player: Codable, PersistableRecord, FetchableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// A partial player\nstruct PartialPlayer: Encodable, PersistableRecord {\n    static let databaseTableName = \"player\"\n    var name: String\n    \n    typealias Columns = Player.Columns\n}\n```\n\nAnd now you can get a full player by inserting a partial one:\n\n```swift\ntry dbQueue.write { db in\n    let partialPlayer = PartialPlayer(name: \"Alice\")\n    \n    // INSERT INTO player (name) VALUES ('Alice') RETURNING *\n    let player = try partialPlayer.insertAndFetch(db, as: Player.self)\n    print(player.id)    // The inserted id\n    print(player.name)  // The inserted name\n    print(player.score) // The default score\n}\n```\n\nFor extra precision, you can select only the columns you need, and fetch the desired value from the provided prepared [`Statement`]:\n\n```swift\ntry dbQueue.write { db in\n    let partialPlayer = PartialPlayer(name: \"Alice\")\n    \n    // INSERT INTO player (name) VALUES ('Alice') RETURNING score\n    let score = try partialPlayer.insertAndFetch(db) { statement in\n        try Int.fetchOne(statement)\n    } select: {\n        [$0.score]\n    }\n    print(score) // Prints 1000, the default score\n}\n```\n\nThere are other similar persistence methods, such as `upsertAndFetch`, `saveAndFetch`, `updateAndFetch`, `updateChangesAndFetch`, etc. They all behave like `upsert`, `save`, `update`, `updateChanges`, except that they return saved values. For example:\n\n```swift\n// Save and return the saved player\nlet savedPlayer = try player.saveAndFetch(db)\n```\n\nSee [Persistence Methods], [Upsert](#upsert), and [`updateChanges` methods](#the-updatechanges-methods) for more information.\n\n**Batch operations** can return updated or deleted values:\n\n> **Warning**: Make sure you check the [documentation of the `RETURNING` clause](https://www.sqlite.org/lang_returning.html#limitations_and_caveats), which describes important limitations and caveats for batch operations.\n\n```swift\nlet request = Player.filter(...)...\n\n// Fetch all deleted players\n// DELETE FROM player RETURNING *\nlet deletedPlayers = try request.deleteAndFetchAll(db) // [Player]\n\n// Fetch a selection of columns from the deleted rows\n// DELETE FROM player RETURNING name\nlet statement = try request.deleteAndFetchStatement(db) { [$0.name] }\nlet deletedNames = try String.fetchSet(statement)\n\n// Fetch all updated players\n// UPDATE player SET score = score + 10 RETURNING *\nlet updatedPlayers = try request.updateAndFetchAll(db) { [$0.score += 10] } // [Player]\n\n// Fetch a selection of columns from the updated rows\n// UPDATE player SET score = score + 10 RETURNING score\nlet statement = try request.updateAndFetchStatement(db) {\n    [$0.score += 10]\n} select: {\n    [$0.score]\n}\nlet updatedScores = try Int.fetchAll(statement)\n```\n\n\n### Persistence Callbacks\n\nYour custom type may want to perform extra work when the persistence methods are invoked.\n\nTo this end, your record type can implement **persistence callbacks**. Callbacks are methods that get called at certain moments of a record's life cycle. With callbacks it is possible to write code that will run whenever an record is inserted, updated, or deleted.\n\nIn order to use a callback method, you need to provide its implementation. For example, a frequently used callback is `didInsert`, in the case of auto-incremented database ids:\n\n```swift\nstruct Player: MutablePersistableRecord {\n    var id: Int64?\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n\ntry dbQueue.write { db in\n    var player = Player(id: nil, ...)\n    try player.insert(db)\n    print(player.id) // didInsert was called: prints some non-nil id\n}\n```\n\nCallbacks can also help implementing record validation:\n\n```swift\nstruct Link: PersistableRecord {\n    var url: URL\n    \n    func willSave(_ db: Database) throws {\n        if url.host == nil {\n            throw ValidationError(\"url must be absolute.\")\n        }\n    }\n}\n\ntry link.insert(db) // Calls the willSave callback\ntry link.update(db) // Calls the willSave callback\ntry link.save(db)   // Calls the willSave callback\ntry link.upsert(db) // Calls the willSave callback\n```\n\n#### Available Callbacks\n\nHere is a list with all the available [persistence callbacks], listed in the same order in which they will get called during the respective operations:\n\n- Inserting a record (all `record.insert` and `record.upsert` methods)\n    - `willSave`\n    - `aroundSave`\n    - `willInsert`\n    - `aroundInsert`\n    - `didInsert`\n    - `didSave`\n    \n- Updating a record (all `record.update` methods)\n    - `willSave`\n    - `aroundSave`\n    - `willUpdate`\n    - `aroundUpdate`\n    - `didUpdate`\n    - `didSave`\n    \n- Deleting a record (only the `record.delete(_:)` method)\n    - `willDelete`\n    - `aroundDelete`\n    - `didDelete`\n\nFor detailed information about each callback, check the [reference](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/mutablepersistablerecord/).\n\nIn the `MutablePersistableRecord` protocol, `willInsert` and `didInsert` are mutating methods. In `PersistableRecord`, they are not mutating.\n\n> **Note**: The `record.save(_:)` method performs an UPDATE if the record has a non-null primary key, and then, if no row was modified, an INSERT. It directly performs an INSERT if the record has no primary key, or a null primary key. It triggers update and/or insert callbacks accordingly.\n>\n> **Warning**: Callbacks are only invoked from persistence methods called on record instances. Callbacks are not invoked when you call a type method, perform a batch operations, or execute raw SQL.\n>\n> **Warning**: When a `did***` callback is invoked, do not assume that the change is actually persisted on disk, because the database may still be inside an uncommitted transaction. When you need to handle transaction completions, use the [afterNextTransaction(onCommit:onRollback:)](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)). For example:\n>\n> ```swift\n> struct PictureFile: PersistableRecord {\n>     var path: String\n>     \n>     func willDelete(_ db: Database) {\n>         db.afterNextTransaction { _ in\n>             try? deleteFileOnDisk()\n>         }\n>     }\n> }\n> ```\n\n\n## Identifiable Records\n\n**When a record type maps a table with a single-column primary key, it is recommended to have it adopt the standard [Identifiable] protocol.**\n\n```swift\nstruct Player: Identifiable, FetchableRecord, PersistableRecord {\n    var id: Int64 // fulfills the Identifiable requirement\n    var name: String\n    var score: Int\n}\n```\n\nWhen `id` has a [database-compatible type](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible) (Int64, Int, String, UUID, ...), the `Identifiable` conformance unlocks type-safe record and request methods:\n\n```swift\nlet player = try Player.find(db, id: 1)               // Player\nlet player = try Player.fetchOne(db, id: 1)           // Player?\nlet players = try Player.fetchAll(db, ids: [1, 2, 3]) // [Player]\nlet players = try Player.fetchSet(db, ids: [1, 2, 3]) // Set<Player>\n\nlet request = Player.filter(id: 1)\nlet request = Player.filter(ids: [1, 2, 3])\n\ntry Player.deleteOne(db, id: 1)\ntry Player.deleteAll(db, ids: [1, 2, 3])\n```\n\n> **Note**: Not all record types can be made `Identifiable`, and not all tables have a single-column primary key. GRDB provides other methods that deal with primary and unique keys, but they won't check the type of their arguments:\n> \n> ```swift\n> // Available on non-Identifiable types\n> try Player.fetchOne(db, key: 1)\n> try Player.fetchOne(db, key: [\"email\": \"arthur@example.com\"])\n> try Country.fetchAll(db, keys: [\"FR\", \"US\"])\n> try Citizenship.fetchOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n> \n> let request = Player.filter(key: 1)\n> let request = Player.filter(keys: [1, 2, 3])\n> \n> try Player.deleteOne(db, key: 1)\n> try Player.deleteAll(db, keys: [1, 2, 3])\n> ```\n\n> **Note**: It is not recommended to use `Identifiable` on record types that use an auto-incremented primary key:\n>\n> ```swift\n> // AVOID declaring Identifiable conformance when key is auto-incremented\n> struct Player {\n>     var id: Int64? // Not an id suitable for Identifiable\n>     var name: String\n>     var score: Int\n> }\n> \n> extension Player: FetchableRecord, MutablePersistableRecord {\n>     // Update auto-incremented id upon successful insertion\n>     mutating func didInsert(_ inserted: InsertionSuccess) {\n>         id = inserted.rowID\n>     }\n> }\n> ```\n>\n> For a detailed rationale, please see [issue #1435](https://github.com/groue/GRDB.swift/issues/1435#issuecomment-1740857712).\n\nSome database tables have a single-column primary key which is not called \"id\":\n\n```swift\ntry db.create(table: \"country\") { t in\n    t.primaryKey(\"isoCode\", .text)\n    t.column(\"name\", .text).notNull()\n    t.column(\"population\", .integer).notNull()\n}\n```\n\nIn this case, `Identifiable` conformance can be achieved, for example, by returning the primary key column from the `id` property:\n\n```swift\nstruct Country: Identifiable, FetchableRecord, PersistableRecord {\n    var isoCode: String\n    var name: String\n    var population: Int\n    \n    // Fulfill the Identifiable requirement\n    var id: String { isoCode }\n}\n\nlet france = try dbQueue.read { db in\n    try Country.fetchOne(db, id: \"FR\")\n}\n```\n\n\n## Codable Records\n\nRecord types that adopt an archival protocol ([Codable, Encodable or Decodable](https://developer.apple.com/documentation/foundation/archives_and_serialization/encoding_and_decoding_custom_types)) get free database support just by declaring conformance to the desired [record protocols](#record-protocols-overview):\n\n```swift\n// Declare a record...\nstruct Player: Codable, FetchableRecord, PersistableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// ...and there you go:\ntry dbQueue.write { db in\n    try Player(id: 1, name: \"Arthur\", score: 100).insert(db)\n    let players = try Player.order(\\.score.desc).fetchAll(db)\n}\n```\n\nCodable records encode and decode their properties according to their own implementation of the Encodable and Decodable protocols. Yet databases have specific requirements:\n\n- Properties are always coded according to their preferred database representation, when they have one (all [values](#values) that adopt the [`DatabaseValueConvertible`] protocol).\n- You can customize the encoding and decoding of dates and uuids.\n- Complex properties (arrays, dictionaries, nested structs, etc.) are stored as JSON.\n\nFor more information about Codable records, see:\n\n- [JSON Columns]\n- [Column Names Coding Strategies]\n- [Data, Date, and UUID Coding Strategies]\n- [The userInfo Dictionary]\n- [Tip: Derive Columns from Coding Keys](#tip-derive-columns-from-coding-keys)\n\n> :bulb: **Tip**: see the [Demo Applications] for sample code that uses Codable records.\n\n\n### JSON Columns\n\nWhen a [Codable record](#codable-records) contains a property that is not a simple [value](#values) (Bool, Int, String, Date, Swift enums, etc.), that value is encoded and decoded as a **JSON string**. For example:\n\n```swift\nenum AchievementColor: String, Codable {\n    case bronze, silver, gold\n}\n\nstruct Achievement: Codable {\n    var name: String\n    var color: AchievementColor\n}\n\nstruct Player: Codable, FetchableRecord, PersistableRecord {\n    var name: String\n    var score: Int\n    var achievements: [Achievement] // stored in a JSON column\n}\n\ntry dbQueue.write { db in\n    // INSERT INTO player (name, score, achievements)\n    // VALUES (\n    //   'Arthur',\n    //   100,\n    //   '[{\"color\":\"gold\",\"name\":\"Use Codable Records\"}]')\n    let achievement = Achievement(name: \"Use Codable Records\", color: .gold)\n    let player = Player(name: \"Arthur\", score: 100, achievements: [achievement])\n    try player.insert(db)\n}\n```\n\nGRDB uses the standard [JSONDecoder](https://developer.apple.com/documentation/foundation/jsondecoder) and [JSONEncoder](https://developer.apple.com/documentation/foundation/jsonencoder) from Foundation. By default, Data values are handled with the `.base64` strategy, Date with the `.millisecondsSince1970` strategy, and non conforming floats with the `.throw` strategy.\n\nYou can customize the JSON format by implementing those methods:\n\n```swift\nprotocol FetchableRecord {\n    static func databaseJSONDecoder(for column: String) -> JSONDecoder\n}\n\nprotocol EncodableRecord {\n    static func databaseJSONEncoder(for column: String) -> JSONEncoder\n}\n```\n\n> :bulb: **Tip**: Make sure you set the JSONEncoder `sortedKeys` option. This option makes sure that the JSON output is stable. This stability is required for [Record Comparison] to work as expected, and database observation tools such as [ValueObservation] to accurately recognize changed records.\n\n\n### Column Names Coding Strategies\n\nBy default, [Codable Records] store their values into database columns that match their coding keys: the `teamID` property is stored into the `teamID` column.\n\nThis behavior can be overridden, so that you can, for example, store the `teamID` property into the `team_id` column:\n\n```swift\nprotocol FetchableRecord {\n    static var databaseColumnDecodingStrategy: DatabaseColumnDecodingStrategy { get }\n}\n\nprotocol EncodableRecord {\n    static var databaseColumnEncodingStrategy: DatabaseColumnEncodingStrategy { get }\n}\n```\n\nSee [DatabaseColumnDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasecolumndecodingstrategy) and [DatabaseColumnEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasecolumnencodingstrategy/) to learn about all available strategies.\n\n\n### Data, Date, and UUID Coding Strategies\n\nBy default, [Codable Records] encode and decode their Data properties as blobs, and Date and UUID properties as described in the general [Date and DateComponents](#date-and-datecomponents) and [UUID](#uuid) chapters.\n\nTo sum up: dates encode themselves in the \"YYYY-MM-DD HH:MM:SS.SSS\" format, in the UTC time zone, and decode a variety of date formats and timestamps. UUIDs encode themselves as 16-bytes data blobs, and decode both 16-bytes data blobs and strings such as \"E621E1F8-C36C-495A-93FC-0C247A3E6E5F\".\n\nThose behaviors can be overridden:\n\n```swift\nprotocol FetchableRecord {\n    static func databaseDataDecodingStrategy(for column: String) -> DatabaseDataDecodingStrategy\n    static func databaseDateDecodingStrategy(for column: String) -> DatabaseDateDecodingStrategy\n}\n\nprotocol EncodableRecord {\n    static func databaseDataEncodingStrategy(for column: String) -> DatabaseDataEncodingStrategy\n    static func databaseDateEncodingStrategy(for column: String) -> DatabaseDateEncodingStrategy\n    static func databaseUUIDEncodingStrategy(for column: String) -> DatabaseUUIDEncodingStrategy\n}\n```\n\nSee [DatabaseDataDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedatadecodingstrategy/), [DatabaseDateDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedatedecodingstrategy/), [DatabaseDataEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedataencodingstrategy/), [DatabaseDateEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedateencodingstrategy/), and [DatabaseUUIDEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseuuidencodingstrategy/) to learn about all available strategies.\n\nThere is no customization of uuid decoding, because UUID can already decode all its encoded variants (16-bytes blobs and uuid strings, both uppercase and lowercase).\n\nCustomized coding strategies apply:\n\n- When encoding and decoding database rows to and from records (fetching and persistence methods).\n- In requests by single-column primary key: `fetchOne(_:id:)`, `filter(id:)`, `deleteAll(_:keys:)`, etc.\n\n*They do not apply* in other requests based on data, date, or uuid values.\n\nSo make sure that those are properly encoded in your requests. For example:\n\n```swift\nstruct Player: Codable, FetchableRecord, PersistableRecord, Identifiable {\n    // UUIDs are stored as strings\n    static func databaseUUIDEncodingStrategy(for column: String) -> DatabaseUUIDEncodingStrategy {\n        .uppercaseString\n    }\n    \n    var id: UUID\n    ...\n}\n\ntry dbQueue.write { db in\n    let uuid = UUID()\n    let player = Player(id: uuid, ...)\n    \n    // OK: inserts a player in the database, with a string uuid\n    try player.insert(db)\n    \n    // OK: performs a string-based query, finds the inserted player\n    _ = try Player.filter(id: uuid).fetchOne(db)\n\n    // NOT OK: performs a blob-based query, fails to find the inserted player\n    _ = try Player.filter { $0.id == uuid }.fetchOne(db)\n    \n    // OK: performs a string-based query, finds the inserted player\n    _ = try Player.filter { $0.id == uuid.uuidString }.fetchOne(db)\n}\n```\n\n\n### The userInfo Dictionary\n\nYour [Codable Records] can be stored in the database, but they may also have other purposes. In this case, you may need to customize their implementations of `Decodable.init(from:)` and `Encodable.encode(to:)`, depending on the context.\n\nThe standard way to provide such context is the `userInfo` dictionary. Implement those properties:\n\n```swift\nprotocol FetchableRecord {\n    static var databaseDecodingUserInfo: [CodingUserInfoKey: Any] { get }\n}\n\nprotocol EncodableRecord {\n    static var databaseEncodingUserInfo: [CodingUserInfoKey: Any] { get }\n}\n```\n\nFor example, here is a Player type that customizes its decoding:\n\n```swift\n// A key that holds a decoder's name\nlet decoderName = CodingUserInfoKey(rawValue: \"decoderName\")!\n\nstruct Player: FetchableRecord, Decodable {\n    init(from decoder: Decoder) throws {\n        // Print the decoder name\n        let decoderName = decoder.userInfo[decoderName] as? String\n        print(\"Decoded from \\(decoderName ?? \"unknown decoder\")\")\n        ...\n    }\n}\n```\n\nYou can have a specific decoding from JSON...\n\n```swift\n// prints \"Decoded from JSON\"\nlet decoder = JSONDecoder()\ndecoder.userInfo = [decoderName: \"JSON\"]\nlet player = try decoder.decode(Player.self, from: jsonData)\n```\n\n... and another one from database rows:\n\n```swift\nextension Player: FetchableRecord {\n    static var databaseDecodingUserInfo: [CodingUserInfoKey: Any] {\n        [decoderName: \"database row\"]\n    }\n}\n\n// prints \"Decoded from database row\"\nlet player = try Player.fetchOne(db, ...)\n```\n\n> **Note**: make sure the `databaseDecodingUserInfo` and `databaseEncodingUserInfo` properties are explicitly declared as `[CodingUserInfoKey: Any]`. If they are not, the Swift compiler may silently miss the protocol requirement, resulting in sticky empty userInfo.\n\n\n### Tip: Derive Columns from Coding Keys\n\nCodable types are granted with a [CodingKeys](https://developer.apple.com/documentation/foundation/archives_and_serialization/encoding_and_decoding_custom_types) enum. You can use them to safely define database columns:\n\n```swift\nstruct Player: Codable {\n    var id: Int64\n    var name: String\n    var score: Int\n}\n\nextension Player: FetchableRecord, PersistableRecord {\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n```\n\nSee the [query interface](#the-query-interface) and [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices) for further information.\n\n\n## Record Comparison\n\n**Records that adopt the [EncodableRecord] protocol can compare against other records, or against previous versions of themselves.**\n\nThis helps avoiding costly UPDATE statements when a record has not been edited.\n\n- [The `updateChanges` Methods](#the-updatechanges-methods)\n- [The `databaseEquals` Method](#the-databaseequals-method)\n- [The `databaseChanges` and `hasDatabaseChanges` Methods](#the-databasechanges-and-hasdatabasechanges-methods)\n\n\n### The `updateChanges` Methods\n\nThe `updateChanges` methods perform a database update of the changed columns only (and does nothing if record has no change).\n\n- `updateChanges(_:from:)`\n\n    This method lets you compare two records:\n\n    ```swift\n    if let oldPlayer = try Player.fetchOne(db, id: 42) {\n        var newPlayer = oldPlayer\n        newPlayer.score = 100\n        if try newPlayer.updateChanges(db, from: oldPlayer) {\n            print(\"player was modified, and updated in the database\")\n        } else {\n            print(\"player was not modified, and database was not hit\")\n        }\n    }\n    ```\n\n- `updateChanges(_:modify:)`\n    \n    This method lets you update a record in place:\n    \n    ```swift\n    if var player = try Player.fetchOne(db, id: 42) {\n        let modified = try player.updateChanges(db) {\n            $0.score = 100\n        }\n        if modified {\n            print(\"player was modified, and updated in the database\")\n        } else {\n            print(\"player was not modified, and database was not hit\")\n        }\n    }\n    ```\n\n### The `databaseEquals` Method\n\nThis method returns whether two records have the same database representation:\n\n```swift\nlet oldPlayer: Player = ...\nvar newPlayer: Player = ...\nif newPlayer.databaseEquals(oldPlayer) == false {\n    try newPlayer.save(db)\n}\n```\n\n> **Note**: The comparison is performed on the database representation of records. As long as your record type adopts the EncodableRecord protocol, you don't need to care about Equatable.\n\n\n### The `databaseChanges` and `hasDatabaseChanges` Methods\n\n`databaseChanges(from:)` returns a dictionary of differences between two records:\n\n```swift\nlet oldPlayer = Player(id: 1, name: \"Arthur\", score: 100)\nlet newPlayer = Player(id: 1, name: \"Arthur\", score: 1000)\nfor (column, oldValue) in try newPlayer.databaseChanges(from: oldPlayer) {\n    print(\"\\(column) was \\(oldValue)\")\n}\n// prints \"score was 100\"\n```\n\nFor an efficient algorithm which synchronizes the content of a database table with a JSON payload, check [groue/SortedDifference](https://github.com/groue/SortedDifference).\n\n\n## Record Customization Options\n\nGRDB records come with many default behaviors, that are designed to fit most situations. Many of those defaults can be customized for your specific needs:\n\n- [Persistence Callbacks]: define what happens when you call a persistence method such as `player.insert(db)`\n- [Conflict Resolution]: Run `INSERT OR REPLACE` queries, and generally define what happens when a persistence method violates a unique index.\n- [Columns Selected by a Request]: define which columns are selected by requests such as `Player.fetchAll(db)`.\n- [Beyond FetchableRecord]: the FetchableRecord protocol is not the end of the story.\n\n[Codable Records] have a few extra options:\n\n- [JSON Columns]: control the format of JSON columns.\n- [Column Names Coding Strategies]: control how coding keys are turned into column names\n- [Date and UUID Coding Strategies]: control the format of Date and UUID properties in your Codable records.\n- [The userInfo Dictionary]: adapt your Codable implementation for the database.\n\n\n### Conflict Resolution\n\n**Insertions and updates can create conflicts**: for example, a query may attempt to insert a duplicate row that violates a unique index.\n\nThose conflicts normally end with an error. Yet SQLite let you alter the default behavior, and handle conflicts with specific policies. For example, the `INSERT OR REPLACE` statement handles conflicts with the \"replace\" policy which replaces the conflicting row instead of throwing an error.\n\nThe [five different policies](https://www.sqlite.org/lang_conflict.html) are: abort (the default), replace, rollback, fail, and ignore.\n\n**SQLite let you specify conflict policies at two different places:**\n\n- In the definition of the database table:\n    \n    ```swift\n    // CREATE TABLE player (\n    //     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    //     email TEXT UNIQUE ON CONFLICT REPLACE\n    // )\n    try db.create(table: \"player\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"email\", .text).unique(onConflict: .replace) // <--\n    }\n    \n    // Despite the unique index on email, both inserts succeed.\n    // The second insert replaces the first row:\n    try db.execute(sql: \"INSERT INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    try db.execute(sql: \"INSERT INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    ```\n    \n- In each modification query:\n    \n    ```swift\n    // CREATE TABLE player (\n    //     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    //     email TEXT UNIQUE\n    // )\n    try db.create(table: \"player\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"email\", .text).unique()\n    }\n    \n    // Again, despite the unique index on email, both inserts succeed.\n    try db.execute(sql: \"INSERT OR REPLACE INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    try db.execute(sql: \"INSERT OR REPLACE INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    ```\n\nWhen you want to handle conflicts at the query level, specify a custom `persistenceConflictPolicy` in your type that adopts the PersistableRecord protocol. It will alter the INSERT and UPDATE queries run by the `insert`, `update` and `save` [persistence methods]:\n\n```swift\nprotocol MutablePersistableRecord {\n    /// The policy that handles SQLite conflicts when records are\n    /// inserted or updated.\n    ///\n    /// This property is optional: its default value uses the ABORT\n    /// policy for both insertions and updates, so that GRDB generate\n    /// regular INSERT and UPDATE queries.\n    static var persistenceConflictPolicy: PersistenceConflictPolicy { get }\n}\n\nstruct Player : MutablePersistableRecord {\n    static let persistenceConflictPolicy = PersistenceConflictPolicy(\n        insert: .replace,\n        update: .replace)\n}\n\n// INSERT OR REPLACE INTO player (...) VALUES (...)\ntry player.insert(db)\n```\n\n> **Note**: If you specify the `ignore` policy for inserts, the [`didInsert` callback](#persistence-callbacks) will be called with some random id in case of failed insert. You can detect failed insertions with `insertAndFetch`:\n>     \n> ```swift\n> // How to detect failed `INSERT OR IGNORE`:\n> // INSERT OR IGNORE INTO player ... RETURNING *\n> do {\n>     let insertedPlayer = try player.insertAndFetch(db) {\n>     // Successful insertion\n> catch RecordError.recordNotFound {\n>     // Failed insertion due to IGNORE policy\n> }\n> ```\n>\n> **Note**: The `replace` policy may have to delete rows so that inserts and updates can succeed. Those deletions are not reported to [transaction observers](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactionobserver) (this might change in a future release of SQLite).\n\n### Beyond FetchableRecord\n\n**Some GRDB users eventually discover that the [FetchableRecord] protocol does not fit all situations.** Use cases that are not well handled by FetchableRecord include:\n\n- Your application needs polymorphic row decoding: it decodes some type or another, depending on the values contained in a database row.\n\n- Your application needs to decode rows with a context: each decoded value should be initialized with some extra value that does not come from the database.\n\nSince those use cases are not well handled by FetchableRecord, don't try to implement them on top of this protocol: you'll just fight the framework.\n\n\n## Examples of Record Definitions\n\nWe will show below how to declare a record type for the following database table:\n\n```swift\ntry dbQueue.write { db in\n    try db.create(table: \"place\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"title\", .text).notNull()\n        t.column(\"isFavorite\", .boolean).notNull().defaults(to: false)\n        t.column(\"longitude\", .double).notNull()\n        t.column(\"latitude\", .double).notNull()\n    }\n}\n```\n\nEach one of the three examples below is correct. You will pick one or the other depending on your personal preferences and the requirements of your application:\n\n<details>\n  <summary>Define a Codable struct, and adopt the record protocols you need</summary>\n\nThis is the shortest way to define a record type.\n\nSee the [Record Protocols Overview](#record-protocols-overview), and [Codable Records] for more information.\n\n```swift\nstruct Place: Codable {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    private var latitude: CLLocationDegrees\n    private var longitude: CLLocationDegrees\n    \n    var coordinate: CLLocationCoordinate2D {\n        get {\n            CLLocationCoordinate2D(\n                latitude: latitude,\n                longitude: longitude)\n        }\n        set {\n            latitude = newValue.latitude\n            longitude = newValue.longitude\n        }\n    }\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let title = Column(CodingKeys.title)\n        static let isFavorite = Column(CodingKeys.isFavorite)\n        static let latitude = Column(CodingKeys.latitude)\n        static let longitude = Column(CodingKeys.longitude)\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord { }\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n<details>\n  <summary>Define a plain struct, and adopt the record protocols you need</summary>\n\nSee the [Record Protocols Overview](#record-protocols-overview) for more information.\n    \n```swift\nstruct Place {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    var coordinate: CLLocationCoordinate2D\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let isFavorite = Column(\"isFavorite\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord {\n    /// Creates a record from a database row\n    init(row: Row) {\n        id = row[Columns.id]\n        title = row[Columns.title]\n        isFavorite = row[Columns.isFavorite]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[Columns.latitude],\n            longitude: row[Columns.longitude])\n    }\n}\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    /// The values persisted in the database\n    func encode(to container: inout PersistenceContainer) {\n        container[Columns.id] = id\n        container[Columns.title] = title\n        container[Columns.isFavorite] = isFavorite\n        container[Columns.latitude] = coordinate.latitude\n        container[Columns.longitude] = coordinate.longitude\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n<details>\n  <summary>Define a plain struct optimized for fetching performance</summary>\n\nThis struct derives its persistence methods from the standard Encodable protocol (see [Codable Records]), but performs optimized row decoding by accessing database columns with numeric indexes.\n\nSee the [Record Protocols Overview](#record-protocols-overview) for more information.\n    \n```swift\nstruct Place: Encodable {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    private var latitude: CLLocationDegrees\n    private var longitude: CLLocationDegrees\n    \n    var coordinate: CLLocationCoordinate2D {\n        get {\n            CLLocationCoordinate2D(\n                latitude: latitude,\n                longitude: longitude)\n        }\n        set {\n            latitude = newValue.latitude\n            longitude = newValue.longitude\n        }\n    }\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let title = Column(CodingKeys.title)\n        static let isFavorite = Column(CodingKeys.isFavorite)\n        static let latitude = Column(CodingKeys.latitude)\n        static let longitude = Column(CodingKeys.longitude)\n    }\n    \n    /// Arrange the selected columns and lock their order\n    static var databaseSelection: [any SQLSelectable] {\n        [\n            Columns.id,\n            Columns.title,\n            Columns.favorite,\n            Columns.latitude,\n            Columns.longitude,\n        ]\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord {\n    /// Creates a record from a database row\n    init(row: Row) {\n        // For high performance, use numeric indexes that match the\n        // order of Place.databaseSelection\n        id = row[0]\n        title = row[1]\n        isFavorite = row[2]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[3],\n            longitude: row[4])\n    }\n}\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n\nThe Query Interface\n===================\n\n**The query interface lets you write pure Swift instead of SQL:**\n\n```swift\ntry dbQueue.write { db in\n    // Update database schema\n    try db.create(table: \"player\") { t in ... }\n    \n    // Fetch records\n    let bestPlayers = try Player\n        .order(\\.score.desc)\n        .limit(10)\n        .fetchAll(db)\n    \n    // Count\n    let count = try Player\n        .filter { $0.score >= 1000 }\n        .fetchCount(db)\n    \n    // Batch update\n    try Player\n        .filter { $0.team == \"Reds\" }\n        .updateAll(db) { $0.score += 100 }\n    \n    // Batch delete\n    try Player\n        .filter { $0.score == 0 }\n        .deleteAll(db)\n}\n```\n\nYou need to open a [database connection] before you can query the database.\n\nPlease bear in mind that the query interface can not generate all possible SQL queries. You may also *prefer* writing SQL, and this is just OK. From little snippets to full queries, your SQL skills are welcome:\n\n```swift\ntry dbQueue.write { db in\n    // Update database schema (with SQL)\n    try db.execute(sql: \"CREATE TABLE player (...)\")\n    \n    // Fetch records (with SQL)\n    let bestPlayers = try Player.fetchAll(db, sql: \"\"\"\n        SELECT * FROM player ORDER BY score DESC LIMIT 10\n        \"\"\")\n    \n    // Count (with an SQL snippet)\n    let minScore = 1000\n    let count = try Player\n        .filter(sql: \"score >= ?\", arguments: [minScore])\n        .fetchCount(db)\n    \n    // Update (with SQL)\n    try db.execute(sql: \"UPDATE player SET score = score + 100 WHERE team = 'Reds'\")\n    \n    // Delete (with SQL)\n    try db.execute(sql: \"DELETE FROM player WHERE score = 0\")\n}\n```\n\nSo don't miss the [SQL API](#sqlite-api).\n\n> **Note**: the generated SQL may change between GRDB releases, without notice: don't have your application rely on any specific SQL output.\n\n- [The Database Schema](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema)\n- [Requests](#requests)\n- [Expressions](#expressions)\n    - [SQL Operators](#sql-operators)\n    - [SQL Functions](#sql-functions)\n- [Embedding SQL in Query Interface Requests]\n- [Fetching from Requests]\n- [Fetching by Key](#fetching-by-key)\n- [Testing for Record Existence](#testing-for-record-existence)\n- [Fetching Aggregated Values](#fetching-aggregated-values)\n- [Delete Requests](#delete-requests)\n- [Update Requests](#update-requests)\n- [Custom Requests](#custom-requests)\n- :blue_book: [Associations and Joins](Documentation/AssociationsBasics.md)\n- :blue_book: [Common Table Expressions]\n- :blue_book: [Query Interface Organization]\n\n## Requests\n\nüìñ [`QueryInterfaceRequest`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest), [`Table`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/table)\n\n**The query interface requests** let you fetch values from the database:\n\n```swift\nlet request = Player.filter { $0.email != nil }.order(\\.name)\nlet players = try request.fetchAll(db)  // [Player]\nlet count = try request.fetchCount(db)  // Int\n```\n\nQuery interface requests usually start from **a type** that adopts the `TableRecord` protocol:\n\n```swift\nstruct Player: TableRecord { ... }\n\n// The request for all players:\nlet request = Player.all()\nlet players = try request.fetchAll(db) // [Player]\n```\n\nWhen you can not use a record type, use `Table`:\n\n```swift\n// The request for all rows from the player table:\nlet table = Table(\"player\")\nlet request = table.all()\nlet rows = try request.fetchAll(db)    // [Row]\n\n// The request for all players from the player table:\nlet table = Table<Player>(\"player\")\nlet request = table.all()\nlet players = try request.fetchAll(db) // [Player]\n```\n\n> **Note**: all examples in the documentation below use a record type, but you can always substitute a `Table` instead.\n\nNext, declare the table **columns** that you want to use for filtering, or sorting, in a nested type named `Columns`:\n\n```swift\nextension Player {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let name = Column(\"name\")\n    }\n}\n```\n\nWhen `Player` is `Codable`, you'll prefer defining columns from coding keys:\n\n```swift\nextension Player {\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n    }\n}\n```\n\nYou can now build requests with the following methods: `all`, `none`, `select`, `distinct`, `filter`, `matching`, `group`, `having`, `order`, `reversed`, `limit`, `joining`, `including`, `with`. All those methods return another request, which you can further refine by applying another method: `Player.select(...).filter(...).order(...)`.\n\n- [`all()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord/all()), [`none()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord/none()): the requests for all rows, or no row.\n\n    ```swift\n    // SELECT * FROM player\n    Player.all()\n    ```\n    \n    By default, all columns are selected. See [Columns Selected by a Request].\n\n- [`select(...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/selectionrequest/select(_:)-ruzy) and [`select(..., as:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/select(_:as:)-58954) define the selected columns. See [Columns Selected by a Request].\n    \n    ```swift\n    // SELECT name FROM player\n    Player.select(\\.name, as: String.self)\n    ```\n\n- [`selectID()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/selectID()) is available on [Identifiable Records]. It supports all tables that have a single-column primary key:\n\n    ```swift\n    // SELECT id FROM player\n    Player.selectID()\n    \n    // SELECT id FROM player WHERE name IS NOT NULL\n    Player.filter { $0.name != nil }.selectID()\n    ```\n\n- [`annotated(with: expression...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/selectionrequest/annotated(with:)-1satx) extends the selection.\n\n    ```swift\n    // SELECT *, (score + bonus) AS total FROM player\n    Player.annotated { ($0.score + $0.bonus).forKey(\"total\") }\n    ```\n\n- [`annotated(with: aggregate)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/annotated(with:)-74xfs) extends the selection with [association aggregates](Documentation/AssociationsBasics.md#association-aggregates).\n    \n    ```swift\n    // SELECT team.*, COUNT(DISTINCT player.id) AS playerCount\n    // FROM team\n    // LEFT JOIN player ON player.teamId = team.id\n    // GROUP BY team.id\n    Team.annotated(with: Team.players.count)\n    ```\n\n- [`annotated(withRequired: association)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/annotated(withrequired:)) and [`annotated(withOptional: association)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/annotated(withoptional:)) extends the selection with [Associations].\n    \n    ```swift\n    // SELECT player.*, team.color\n    // FROM player\n    // JOIN team ON team.id = player.teamId\n    Player.annotated(withRequired: Player.team.select(\\.color))\n    ```\n\n- [`distinct()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/distinct()) performs uniquing.\n    \n    ```swift\n    // SELECT DISTINCT name FROM player\n    Player.select(\\.name, as: String.self).distinct()\n    ```\n\n- [`filter(expression)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/filteredrequest/filter(_:)-6xr3d) applies conditions.\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (1, 2, 3)\n    Player.filter { [1,2,3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE (name IS NOT NULL) AND (height > 1.75)\n    Player.filter { $0.name != nil && $0.height > 1.75 }\n    ```\n\n- [`filter(id:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(id:)) and [`filter(ids:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(ids:)) are type-safe methods available on [Identifiable Records]:\n    \n    ```swift\n    // SELECT * FROM player WHERE id = 1\n    Player.filter(id: 1)\n    \n    // SELECT * FROM country WHERE isoCode IN ('FR', 'US')\n    Country.filter(ids: [\"FR\", \"US\"])\n    ```\n    \n- [`filter(key:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(key:)-1p9sq) and [`filter(keys:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(keys:)-6ggt1) apply conditions on primary and unique keys:\n    \n    ```swift\n    // SELECT * FROM player WHERE id = 1\n    Player.filter(key: 1)\n    \n    // SELECT * FROM country WHERE isoCode IN ('FR', 'US')\n    Country.filter(keys: [\"FR\", \"US\"])\n    \n    // SELECT * FROM citizenship WHERE citizenId = 1 AND countryCode = 'FR'\n    Citizenship.filter(key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n    \n    // SELECT * FROM player WHERE email = 'arthur@example.com'\n    Player.filter(key: [\"email\": \"arthur@example.com\"])\n    ```\n\n- `matching(pattern)` ([FTS3](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/matching(_:)-3s3zr), [FTS5](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/matching(_:)-7c1e8)) performs [full-text search](Documentation/FullTextSearch.md).\n    \n    ```swift\n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    let pattern = FTS3Pattern(matchingAllTokensIn: \"SQLite database\")\n    Document.matching(pattern)\n    ```\n    \n    When the pattern is nil, no row will match.\n\n- [`group(expression, ...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/aggregatingrequest/group(_:)-2g7br) groups rows.\n    \n    ```swift\n    // SELECT name, MAX(score) FROM player GROUP BY name\n    Player\n        .select { [$0.name, max($0.score)] }\n        .group(\\.name)\n    ```\n\n- [`having(expression)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/aggregatingrequest/having(_:)-2oggh) applies conditions on grouped rows.\n    \n    ```swift\n    // SELECT team, MAX(score) FROM player GROUP BY team HAVING MIN(score) >= 1000\n    Player\n        .select { [$0.team, max($0.score)] }\n        .group(\\.team)\n        .having { min($0.score) >= 1000 }\n    ```\n\n- [`having(aggregate)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/having(_:)) applies conditions on grouped rows, according to an [association aggregate](Documentation/AssociationsBasics.md#association-aggregates).\n    \n    ```swift\n    // SELECT team.*\n    // FROM team\n    // LEFT JOIN player ON player.teamId = team.id\n    // GROUP BY team.id\n    // HAVING COUNT(DISTINCT player.id) >= 5\n    Team.having(Team.players.count >= 5)\n    ```\n\n- [`order(ordering, ...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/orderedrequest/order(_:)-9d0hr) sorts.\n    \n    ```swift\n    // SELECT * FROM player ORDER BY name\n    Player.order(\\.name)\n    \n    // SELECT * FROM player ORDER BY score DESC\n    Player.order(\\.score.desc)\n    \n    // SELECT * FROM player ORDER BY score DESC, name\n    Player.order { [$0.score.desc, $0.name] }\n    ```\n    \n    SQLite considers NULL values to be smaller than any other values for sorting purposes. Hence, NULLs naturally appear at the beginning of an ascending ordering and at the end of a descending ordering. With a [custom SQLite build], this can be changed using `.ascNullsLast` and `.descNullsFirst`:\n    \n    ```swift\n    // SELECT * FROM player ORDER BY score ASC NULLS LAST\n    Player.order(\\.name.ascNullsLast)\n    ```\n    \n    Each `order` call clears any previous ordering:\n    \n    ```swift\n    // SELECT * FROM player ORDER BY name\n    Player.order(\\.score).order(\\.name)\n    ```\n\n- [`reversed()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/orderedrequest/reversed()) reverses the eventual orderings.\n    \n    ```swift\n    // SELECT * FROM player ORDER BY score ASC, name DESC\n    Player.order { [$0.score.desc, $0.name] }.reversed()\n    ```\n    \n    If no ordering was already specified, this method has no effect:\n    \n    ```swift\n    // SELECT * FROM player\n    Player.all().reversed()\n    ```\n\n- [`limit(limit, offset: offset)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/limit(_:offset:)) limits and pages results.\n    \n    ```swift\n    // SELECT * FROM player LIMIT 5\n    Player.limit(5)\n    \n    // SELECT * FROM player LIMIT 5 OFFSET 10\n    Player.limit(5, offset: 10)\n    ```\n\n- [`joining(required:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/joining(required:)), [`joining(optional:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/joining(optional:)), [`including(required:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(required:)), [`including(optional:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(optional:)), and [`including(all:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(all:)) fetch and join records through [Associations].\n    \n    ```swift\n    // SELECT player.*, team.*\n    // FROM player\n    // JOIN team ON team.id = player.teamId\n    Player.including(required: Player.team)\n    ```\n\n- [`with(cte)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/with(_:)) embeds a [common table expression]:\n    \n    ```swift\n    // WITH ... SELECT * FROM player\n    let cte = CommonTableExpression(...)\n    Player.with(cte)\n    ```\n\n- Other requests that involve the primary key:\n    \n    - [`selectPrimaryKey(as:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/selectprimarykey(as:)) selects the primary key.\n    \n        ```swift\n        // SELECT id FROM player\n        Player.selectPrimaryKey(as: Int64.self)    // QueryInterfaceRequest<Int64>\n        \n        // SELECT code FROM country\n        Country.selectPrimaryKey(as: String.self)  // QueryInterfaceRequest<String>\n        \n        // SELECT citizenId, countryCode FROM citizenship\n        Citizenship.selectPrimaryKey(as: Row.self) // QueryInterfaceRequest<Row>\n        ```\n        \n    - [`orderByPrimaryKey()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/orderbyprimarykey()) sorts by primary key.\n        \n        ```swift\n        // SELECT * FROM player ORDER BY id\n        Player.orderByPrimaryKey()\n        \n        // SELECT * FROM country ORDER BY code\n        Country.orderByPrimaryKey()\n        \n        // SELECT * FROM citizenship ORDER BY citizenId, countryCode\n        Citizenship.orderByPrimaryKey()\n        ```\n    \n    - [`groupByPrimaryKey()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/groupbyprimarykey()) groups rows by primary key.\n\n\nYou can refine requests by chaining those methods:\n\n```swift\n// SELECT * FROM player WHERE (email IS NOT NULL) ORDER BY name\nPlayer.order(\\.name).filter { $0.email != nil }\n```\n\nThe `select`, `order`, `group`, and `limit` methods ignore and replace previously applied selection, orderings, grouping, and limits. On the opposite, `filter`, `matching`, and `having` methods extend the query:\n\n```swift\nPlayer                          // SELECT * FROM player\n    .filter { $0.name != nil }  // WHERE (name IS NOT NULL)\n    .filter { $0.email != nil } //        AND (email IS NOT NULL)\n    .order(\\.name)              // - ignored -\n    .reversed()                 // - ignored -\n    .order(\\.score)             // ORDER BY score\n    .limit(20, offset: 40)      // - ignored -\n    .limit(10)                  // LIMIT 10\n```\n\n\nRaw SQL snippets are also accepted, with eventual [arguments](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments):\n\n```swift\n// SELECT DATE(creationDate), COUNT(*) FROM player WHERE name = 'Arthur' GROUP BY date(creationDate)\nPlayer\n    .select(sql: \"DATE(creationDate), COUNT(*)\")\n    .filter(sql: \"name = ?\", arguments: [\"Arthur\"])\n    .group(sql: \"DATE(creationDate)\")\n```\n\n\n### Columns Selected by a Request\n\nBy default, query interface requests select all columns:\n\n```swift\n// SELECT * FROM player\nstruct Player: TableRecord { ... }\nlet request = Player.all()\n\n// SELECT * FROM player\nlet table = Table(\"player\")\nlet request = table.all()\n```\n\n**The selection can be changed for each individual requests, or in the case of record-based requests, for all requests built from this record type.**\n\nThe `select(...)` and `select(..., as:)` methods change the selection of a single request (see [Fetching from Requests] for detailed information):\n\n```swift\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\nlet request = Player.select({ max($0.score) }, as: Int.self)\nlet maxScore = try request.fetchOne(db)      // Int?\n```\n\nThe default selection for a record type is controlled by the `databaseSelection` property. For example:\n\n```swift\n// Select a limited set of columns\nstruct RestrictedPlayer: TableRecord {\n    static let databaseTableName = \"player\"\n    \n    enum Columns {\n        static let id = Column(\"id\")\n        static let name = Column(\"name\")\n    }\n    \n    static var databaseSelection: [any SQLSelectable] {\n        [Columns.id, Columns.name]\n    }\n}\n\n// SELECT id, name FROM player\nlet request = RestrictedPlayer.all()\n```\n\n```swift\n// Select all but a few columns\nstruct Player : TableRecord {\n    static var databaseSelection: [any SQLSelectable] { \n        [.allColumns(excluding: [\"generatedColumn\"])]\n    }\n}\n\n// SELECT id, name FROM player\nlet request = RestrictedPlayer.all()\n```\n\n```swift\n// Select all columns and more\nstruct ExtendedPlayer : TableRecord {\n    static let databaseTableName = \"player\"\n    static var databaseSelection: [any SQLSelectable] {\n        [.allColumns, .rowID]\n    }\n}\n\n// SELECT *, rowid FROM player\nlet request = ExtendedPlayer.all()\n```\n\n> **Note**: make sure the `databaseSelection` property is explicitly declared as `[any SQLSelectable]`. If it is not, the Swift compiler may silently miss the protocol requirement, resulting in sticky `SELECT *` requests. To verify your setup, see the [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql) FAQ.\n\n\n## Expressions\n\nFeed [requests](#requests) with SQL expressions built from your Swift code:\n\n\n### SQL Operators\n\nüìñ [`SQLSpecificExpressible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlspecificexpressible)\n\nGRDB comes with a Swift version of many SQLite [built-in operators](https://sqlite.org/lang_expr.html#operators), listed below. But not all: see [Embedding SQL in Query Interface Requests] for a way to add support for missing SQL operators.\n\n- `=`, `<>`, `<`, `<=`, `>`, `>=`, `IS`, `IS NOT`\n    \n    Comparison operators are based on the Swift operators `==`, `!=`, `===`, `!==`, `<`, `<=`, `>`, `>=`:\n    \n    ```swift\n    // SELECT * FROM player WHERE (name = 'Arthur')\n    Player.filter { $0.name == \"Arthur\" }\n    \n    // SELECT * FROM player WHERE (name IS NULL)\n    Player.filter { $0.name == nil }\n    \n    // SELECT * FROM player WHERE (score IS 1000)\n    Player.filter { $0.score === 1000 }\n    \n    // SELECT * FROM rectangle WHERE width < height\n    Rectangle.filter { $0.width < $0.height }\n    ```\n    \n    Subqueries are supported:\n    \n    ```swift\n    // SELECT * FROM player WHERE score = (SELECT max(score) FROM player)\n    let maximumScore = Player.select { max($0.score) }\n    Player.filter { $0.score == maximumScore }\n    \n    // SELECT * FROM player WHERE score = (SELECT max(score) FROM player)\n    let maximumScore = SQLRequest(\"SELECT max(score) FROM player\")\n    Player.filter { $0.score == maximumScore }\n    ```\n    \n    > **Note**: SQLite string comparison, by default, is case-sensitive and not Unicode-aware. See [string comparison](#string-comparison) if you need more control.\n\n- `*`, `/`, `+`, `-`\n    \n    SQLite arithmetic operators are derived from their Swift equivalent:\n    \n    ```swift\n    // SELECT ((temperature * 1.8) + 32) AS fahrenheit FROM planet\n    Planet.select { ($0.temperature * 1.8 + 32).forKey(\"fahrenheit\") }\n    ```\n    \n    > **Note**: an expression like `nameColumn + \"rrr\"` will be interpreted by SQLite as a numerical addition (with funny results), not as a string concatenation. See the `concat` operator below.\n    \n    When you want to join a sequence of expressions with the `+` or `*` operator, use `joined(operator:)`:\n    \n    ```swift\n    // SELECT score + bonus + 1000 FROM player\n    Player.select {\n        [$0.score, $0.bonus, 1000.databaseValue].joined(operator: .add)\n    }\n    ```\n    \n    Note in the example above how you concatenate raw values: `1000.databaseValue`. A plain `1000` would not compile.\n    \n    When the sequence is empty, `joined(operator: .add)` returns 0, and `joined(operator: .multiply)` returns 1.\n\n- `&`, `|`, `~`, `<<`, `>>`\n    \n    Bitwise operations (bitwise and, or, not, left shift, right shift) are derived from their Swift equivalent:\n    \n    ```swift\n    // SELECT mask & 2 AS isRocky FROM planet\n    Planet.select { ($0.mask & 2).forKey(\"isRocky\") }\n    ```\n\n- `||`\n    \n    Concatenate several strings:\n    \n    ```swift\n    // SELECT firstName || ' ' || lastName FROM player\n    Player.select {\n        [$0.firstName, \" \".databaseValue, $0.lastName].joined(operator: .concat)\n    }\n    ```\n    \n    Note in the example above how you concatenate raw strings: `\" \".databaseValue`. A plain `\" \"` would not compile.\n    \n    When the sequence is empty, `joined(operator: .concat)` returns the empty string.\n\n- `AND`, `OR`, `NOT`\n    \n    The SQL logical operators are derived from the Swift `&&`, `||` and `!`:\n    \n    ```swift\n    // SELECT * FROM player WHERE ((NOT isVerified) OR (score < 1000))\n    Player.filter { !$0.isVerified || $0.score < 1000 }\n    ```\n    \n    When you want to join a sequence of expressions with the `AND` or `OR` operator, use `joined(operator:)`:\n    \n    ```swift\n    // SELECT * FROM player WHERE (isVerified AND (score >= 1000) AND (name IS NOT NULL))\n    Player.filter {\n        [$0.isVerified, $0.score >= 1000, $0.name != nil].joined(operator: .and)\n    }\n    ```\n    \n    When the sequence is empty, `joined(operator: .and)` returns true, and `joined(operator: .or)` returns false:\n\n- `BETWEEN`, `IN`, `NOT IN`\n    \n    To check inclusion in a Swift sequence (array, set, range‚Ä¶), call the `contains` method:\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (1, 2, 3)\n    Player.filter { [1, 2, 3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE id NOT IN (1, 2, 3)\n    Player.filter { ![1, 2, 3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE score BETWEEN 0 AND 1000\n    Player.filter { (0...1000).contains($0.score) }\n    \n    // SELECT * FROM player WHERE (score >= 0) AND (score < 1000)\n    Player.filter { (0..<1000).contains($0.score) }\n    \n    // SELECT * FROM player WHERE initial BETWEEN 'A' AND 'N'\n    Player.filter { (\"A\"...\"N\").contains($0.initial) }\n    \n    // SELECT * FROM player WHERE (initial >= 'A') AND (initial < 'N')\n    Player.filter { (\"A\"..<\"N\").contains($0.initial) }\n    ```\n    \n    To check inclusion inside a subquery, call the `contains` method as well:\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (SELECT playerId FROM playerSelection)\n    let selectedPlayerIds = PlayerSelection.select(\\.playerId)\n    Player.filter { selectedPlayerIds.contains($0.id) }\n    \n    // SELECT * FROM player WHERE id IN (SELECT playerId FROM playerSelection)\n    let selectedPlayerIds = SQLRequest(\"SELECT playerId FROM playerSelection\")\n    Player.filter { selectedPlayerIds.contains($0.id) }\n    ```\n    \n    To check inclusion inside a [common table expression], call the `contains` method as well:\n    \n    ```swift\n    // WITH selectedName AS (...)\n    // SELECT * FROM player WHERE name IN selectedName\n    let cte = CommonTableExpression(named: \"selectedName\", ...)\n    Player\n        .with(cte)\n        .filter { cte.contains($0.name) }\n    ```\n    \n    > **Note**: SQLite string comparison, by default, is case-sensitive and not Unicode-aware. See [string comparison](#string-comparison) if you need more control.\n\n- `EXISTS`, `NOT EXISTS`\n    \n    To check if a subquery would return rows, call the `exists` method:\n    \n    ```swift\n    // Teams that have at least one other player\n    //\n    //  SELECT * FROM team\n    //  WHERE EXISTS (SELECT * FROM player WHERE teamId = team.id)\n    let teamAlias = TableAlias<Team>()\n    let player = Player.filter { $0.teamId == teamAlias.id }\n    let teams = Team.aliased(teamAlias).filter(player.exists())\n    \n    // Teams that have no player\n    //\n    //  SELECT * FROM team\n    //  WHERE NOT EXISTS (SELECT * FROM player WHERE teamId = team.id)\n    let teams = Team.aliased(teamAlias).filter(!player.exists())\n    ```\n    \n    In the above example, you use a `TableAlias` in order to let a subquery refer to a column from another table.\n    \n    In the next example, which involves the same table twice, the table alias requires an explicit disambiguation with `TableAlias(name:)`:\n    \n    ```swift    \n    // Players who coach at least one other player\n    //\n    //  SELECT coach.* FROM player coach\n    //  WHERE EXISTS (SELECT * FROM player WHERE coachId = coach.id)\n    let coachAlias = TableAlias<Player>(name: \"coach\")\n    let coachedPlayer = Player.filter { $0.coachId == coachAlias.id }\n    let coaches = Player.aliased(coachAlias).filter(coachedPlayer.exists())\n    ```\n    \n    Finally, subqueries can also be expressed as SQL, with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT coach.* FROM player coach\n    // WHERE EXISTS (SELECT * FROM player WHERE coachId = coach.id)\n    let coachedPlayer = SQLRequest(\"SELECT * FROM player WHERE coachId = \\(coachAlias.id)\")\n    let coaches = Player.aliased(coachAlias).filter(coachedPlayer.exists())\n    ```\n    \n- `LIKE`\n    \n    The SQLite LIKE operator is available as the `like` method:\n    \n    ```swift\n    // SELECT * FROM player WHERE (email LIKE '%@example.com')\n    Player.filter { $0.email.like(\"%@example.com\") }\n    \n    // SELECT * FROM book WHERE (title LIKE '%10\\%%' ESCAPE '\\')\n    Player.filter { $0.email.like(\"%10\\\\%%\", escape: \"\\\\\") }\n    ```\n    \n    > **Note**: the SQLite LIKE operator is case-insensitive but not Unicode-aware. For example, the expression `'a' LIKE 'A'` is true but `'√¶' LIKE '√Ü'` is false.\n\n- `MATCH`\n    \n    The full-text MATCH operator is available through [FTS3Pattern](Documentation/FullTextSearch.md#fts3pattern) (for FTS3 and FTS4 tables) and [FTS5Pattern](Documentation/FullTextSearch.md#fts5pattern) (for FTS5):\n    \n    FTS3 and FTS4:\n    \n    ```swift\n    let pattern = FTS3Pattern(matchingAllTokensIn: \"SQLite database\")\n    \n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    Document.matching(pattern)\n    \n    // SELECT * FROM document WHERE content MATCH 'sqlite database'\n    Document.filter { $0.content.match(pattern) }\n    ```\n    \n    FTS5:\n    \n    ```swift\n    let pattern = FTS5Pattern(matchingAllTokensIn: \"SQLite database\")\n    \n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    Document.matching(pattern)\n    ```\n- `AS`\n    \n    To give an alias to an expression, use the `forKey` method:\n    \n    ```swift\n    // SELECT (score + bonus) AS total\n    // FROM player\n    Player.select { ($0.score + $0.bonus).forKey(\"total\") }\n    ```\n    \n    If you need to refer to this aliased column in another place of the request, use a detached column:\n    \n    ```swift\n    // SELECT (score + bonus) AS total\n    // FROM player \n    // ORDER BY total\n    Player\n        .select { ($0.score + $0.bonus).forKey(\"total\") }\n        .order(Column(\"total\").detached)\n    ```\n    \n    The detached column `Column(\"total\").detached` is not considered as a part of the \"player\" table, so it is always rendered as `total` in the generated SQL, even when the request involves other tables via an [association](Documentation/AssociationsBasics.md) or a [common table expression].\n\n\n### SQL Functions\n\nüìñ [`SQLSpecificExpressible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlspecificexpressible)\n\nGRDB comes with a Swift version of many SQLite [built-in functions](https://sqlite.org/lang_corefunc.html), listed below. But not all: see [Embedding SQL in Query Interface Requests] for a way to add support for missing SQL functions.\n\n- `ABS`, `AVG`, `COALESCE`, `COUNT`, `DATETIME`, `JULIANDAY`, `LENGTH`, `MAX`, `MIN`, `SUM`, `TOTAL`:\n    \n    Those are based on the `abs`, `average`, `coalesce`, `count`, `dateTime`, `julianDay`, `length`, `max`, `min`, `sum`, and `total` Swift functions:\n    \n    ```swift\n    // SELECT MIN(score), MAX(score) FROM player\n    Player.select { [min($0.score), max($0.score)] }\n    \n    // SELECT COUNT(name) FROM player\n    Player.select { count($0.name) }\n    \n    // SELECT COUNT(DISTINCT name) FROM player\n    Player.select { count(distinct: $0.name) }\n    \n    // SELECT JULIANDAY(date, 'start of year') FROM game\n    Game.select { julianDay($0.date, .startOfYear) }\n    ```\n    \n    For more information about the functions `dateTime` and `julianDay`, see [Date And Time Functions](https://www.sqlite.org/lang_datefunc.html).\n\n- `CAST`\n\n    Use the `cast` Swift function:\n    \n    ```swift\n    // SELECT (CAST(wins AS REAL) / games) AS successRate FROM player\n    Player.select { (cast($0.wins, as: .real) / $0.games).forKey(\"successRate\") }\n    ```\n    \n    See [CAST expressions](https://www.sqlite.org/lang_expr.html#castexpr) for more information about SQLite conversions.\n\n- `IFNULL`\n    \n    Use the Swift `??` operator:\n    \n    ```swift\n    // SELECT IFNULL(name, 'Anonymous') FROM player\n    Player.select { $0.name ?? \"Anonymous\" }\n    \n    // SELECT IFNULL(name, email) FROM player\n    Player.select { $0.name ?? $0.email }\n    ```\n\n- `LOWER`, `UPPER`\n    \n    The query interface does not give access to those SQLite functions. Nothing against them, but they are not unicode aware.\n    \n    Instead, GRDB extends SQLite with SQL functions that call the Swift built-in string functions `capitalized`, `lowercased`, `uppercased`, `localizedCapitalized`, `localizedLowercased` and `localizedUppercased`:\n    \n    ```swift\n    Player.select { $0.name.uppercased() }\n    ```\n    \n    > **Note**: When *comparing* strings, you'd rather use a [collation](#string-comparison):\n    >\n    > ```swift\n    > let name: String = ...\n    >\n    > // Not recommended\n    > Player.filter { $0.name.uppercased() == name.uppercased() }\n    >\n    > // Better\n    > Player.filter { $0.name.collating(.caseInsensitiveCompare) == name }\n    > ```\n\n- Custom SQL functions and aggregates\n    \n    You can apply your own [custom SQL functions and aggregates](#custom-functions-):\n    \n    ```swift\n    let myFunction = DatabaseFunction(\"myFunction\", ...)\n    \n    // SELECT myFunction(name) FROM player\n    Player.select { myFunction($0.name) }\n    ```\n\n## Embedding SQL in Query Interface Requests\n\nYou will sometimes want to extend your query interface requests with SQL snippets. This can happen because GRDB does not provide a Swift interface for some SQL function or operator, or because you want to use an SQLite construct that GRDB does not support.\n\nSupport for extensibility is large, but not unlimited. All the SQL queries built by the query interface request have the shape below. _If you need something else, you'll have to use [raw SQL requests](#sqlite-api)._\n\n```sql\nWITH ...     -- 1\nSELECT ...   -- 2\nFROM ...     -- 3\nJOIN ...     -- 4\nWHERE ...    -- 5\nGROUP BY ... -- 6\nHAVING ...   -- 7\nORDER BY ... -- 8\nLIMIT ...    -- 9\n```\n\n1. `WITH ...`: see [Common Table Expressions].\n\n2. `SELECT ...`\n\n    The selection can be provided as raw SQL:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let request = Player.select(sql: \"IFNULL(name, 'O''Brien'), score\")\n    \n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select(sql: \"IFNULL(name, ?), score\", arguments: [suffix])\n    ```\n\n    The selection can be provided with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select(literal: \"IFNULL(name, \\(defaultName)), score\")\n    ```\n    \n    The selection can be provided with a mix of Swift and [SQL Interpolation]:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien') AS displayName, score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select {\n        let displayName: SQL = \"IFNULL(\\($0.name), \\(defaultName)) AS displayName\"\n        return [displayName, $0.score]\n    }\n    ```\n    \n    When the custom SQL snippet should behave as a full-fledged expression, with support for the `+` Swift operator, the `forKey` aliasing method, and all other [SQL Operators](#sql-operators), build an _expression literal_ with the `SQL.sqlExpression` method:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien') AS displayName, score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select {\n        let displayName = SQL(\"IFNULL(\\($0.name), \\(defaultName))\").sqlExpression\n        return [displayName.forKey(\"displayName\"), $0.score]\n    }\n    ```\n    \n    Such expression literals allow you to build a reusable support library of SQL functions or operators that are missing from the query interface. For example, you can define a Swift `date` function:\n    \n    ```swift\n    func date(_ value: some SQLSpecificExpressible) -> SQLExpression {\n        SQL(\"DATE(\\(value))\").sqlExpression\n    }\n    \n    // SELECT * FROM \"player\" WHERE DATE(\"createdAt\") = '2020-01-23'\n    let request = Player.filter { date($0.createdAt) == \"2020-01-23\" }\n    ```\n    \n    See the [Query Interface Organization] for more information about `SQLSpecificExpressible` and `SQLExpression`.\n    \n3. `FROM ...`: only one table is supported here. You can not customize this SQL part.\n\n4. `JOIN ...`: joins are fully controlled by [Associations]. You can not customize this SQL part.\n\n5. `WHERE ...`\n    \n    The WHERE clause can be provided as raw SQL:\n    \n    ```swift\n    // SELECT * FROM player WHERE score >= 1000\n    let request = Player.filter(sql: \"score >= 1000\")\n    \n    // SELECT * FROM player WHERE score >= 1000\n    let minScore = 1000\n    let request = Player.filter(sql: \"score >= ?\", arguments: [minScore])\n    ```\n\n    The WHERE clause can be provided with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT * FROM player WHERE score >= 1000\n    let minScore = 1000\n    let request = Player.filter(literal: \"score >= \\(minScore)\")\n    ```\n    \n    The WHERE clause can be provided with a mix of Swift and [SQL Interpolation]:\n    \n    ```swift\n    // SELECT * FROM player WHERE (score >= 1000) AND (team = 'red')\n    let minScore = 1000\n    let request = Player.filter { \n        let scoreCondition: SQL = \"\\($0.score) >= \\(minScore)\"\n        return scoreCondition && $0.team == \"red\"\n    }\n    ```\n    \n    See `SELECT ...` above for more SQL Interpolation examples.\n    \n6. `GROUP BY ...`\n\n    The GROUP BY clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n7. `HAVING ...`\n\n    The HAVING clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n8. `ORDER BY ...`\n\n    The ORDER BY clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n    In order to support the `desc` and `asc` query interface operators, and the `reversed()` query interface method, you must provide your orderings as _expression literals_ with the `SQL.sqlExpression` method:\n    \n    ```swift\n    // SELECT * FROM \"player\" \n    // ORDER BY (score + bonus) ASC, name DESC\n    let request = Player\n        .order {\n            let total = SQL(\"(\\($0.score) + \\($0.bonus))\").sqlExpression\n            return [total.desc, $0.name]\n        }\n        .reversed()\n    ```\n    \n9. `LIMIT ...`: use the `limit(_:offset:)` method. You can not customize this SQL part.\n\n\n## Fetching from Requests\n\nOnce you have a request, you can fetch the records at the origin of the request:\n\n```swift\n// Some request based on `Player`\nlet request = Player.filter { ... }... // QueryInterfaceRequest<Player>\n\n// Fetch players:\ntry request.fetchCursor(db) // A Cursor of Player\ntry request.fetchAll(db)    // [Player]\ntry request.fetchSet(db)    // Set<Player>\ntry request.fetchOne(db)    // Player?\n```\n\nFor example:\n\n```swift\nlet allPlayers = try Player.fetchAll(db)                            // [Player]\nlet arthur = try Player.filter { $0.name == \"Arthur\" }.fetchOne(db) // Player?\n```\n\nSee [fetching methods](#fetching-methods) for information about the `fetchCursor`, `fetchAll`, `fetchSet` and `fetchOne` methods.\n\n**You sometimes want to fetch other values**.\n\nThe simplest way is to use the request as an argument to a fetching method of the desired type:\n\n```swift\n// Fetch an Int\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\n// Fetch a Row\nlet request = Player.select { [min($0.score), max($0.score)] }\nlet row = try Row.fetchOne(db, request)!     // Row\nlet minScore = row[0] as Int?\nlet maxScore = row[1] as Int?\n```\n\nYou can also change the request so that it knows the type it has to fetch:\n\n- With `asRequest(of:)`, useful when you use [Associations]:\n    \n    ```swift\n    struct BookInfo: FetchableRecord, Decodable {\n        var book: Book\n        var author: Author\n    }\n    \n    // A request of BookInfo\n    let request = Book\n        .including(required: Book.author)\n        .asRequest(of: BookInfo.self)\n    \n    let bookInfos = try dbQueue.read { db in\n        try request.fetchAll(db) // [BookInfo]\n    }\n    ```\n    \n- With `select(..., as:)`, which is handy when you change the selection:\n    \n    ```swift\n    // A request of Int\n    let request = Player.select({ max($0.score) }, as: Int.self)\n    \n    let maxScore = try dbQueue.read { db in\n        try request.fetchOne(db) // Int?\n    }\n    ```\n\n\n## Fetching by Key\n\n**Fetching records according to their primary key** is a common task.\n\n[Identifiable Records] can use the type-safe methods `find(_:id:)`, `fetchOne(_:id:)`, `fetchAll(_:ids:)` and `fetchSet(_:ids:)`:\n\n```swift\ntry Player.find(db, id: 1)                   // Player\ntry Player.fetchOne(db, id: 1)               // Player?\ntry Country.fetchAll(db, ids: [\"FR\", \"US\"])  // [Countries]\n```\n\nAll record types can use `find(_:key:)`, `fetchOne(_:key:)`, `fetchAll(_:keys:)` and `fetchSet(_:keys:)` that apply conditions on primary and unique keys:\n\n```swift\ntry Player.find(db, key: 1)                  // Player\ntry Player.fetchOne(db, key: 1)              // Player?\ntry Country.fetchAll(db, keys: [\"FR\", \"US\"]) // [Country]\ntry Player.fetchOne(db, key: [\"email\": \"arthur@example.com\"])            // Player?\ntry Citizenship.fetchOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"]) // Citizenship?\n```\n\nWhen the table has no explicit primary key, GRDB uses the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html):\n\n```swift\n// SELECT * FROM document WHERE rowid = 1\ntry Document.fetchOne(db, key: 1)            // Document?\n```\n\n**When you want to build a request and plan to fetch from it later**, use a `filter` method:\n\n```swift\nlet request = Player.filter(id: 1)\nlet request = Country.filter(ids: [\"FR\", \"US\"])\nlet request = Player.filter(key: [\"email\": \"arthur@example.com\"])\nlet request = Citizenship.filter(key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\n\n## Testing for Record Existence\n\n**You can check if a request has matching rows in the database.**\n\n```swift\n// Some request based on `Player`\nlet request = Player.filter { ... }...\n\n// Check for player existence:\nlet noSuchPlayer = try request.isEmpty(db) // Bool\n```\n\nYou should check for emptiness instead of counting:\n\n```swift\n// Correct\nlet noSuchPlayer = try request.fetchCount(db) == 0\n// Even better\nlet noSuchPlayer = try request.isEmpty(db)\n```\n\n**You can also check if a given primary or unique key exists in the database.**\n\n[Identifiable Records] can use the type-safe method `exists(_:id:)`:\n\n```swift\ntry Player.exists(db, id: 1)\ntry Country.exists(db, id: \"FR\")\n```\n\nAll record types can use `exists(_:key:)` that can check primary and unique keys:\n\n```swift\ntry Player.exists(db, key: 1)\ntry Country.exists(db, key: \"FR\")\ntry Player.exists(db, key: [\"email\": \"arthur@example.com\"])\ntry Citizenship.exists(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\nYou should check for key existence instead of fetching a record and checking for nil:\n\n```swift\n// Correct\nlet playerExists = try Player.fetchOne(db, id: 1) != nil\n// Even better\nlet playerExists = try Player.exists(db, id: 1)\n```\n\n\n## Fetching Aggregated Values\n\n**Requests can count.** The `fetchCount()` method returns the number of rows that would be returned by a fetch request:\n\n```swift\n// SELECT COUNT(*) FROM player\nlet count = try Player.fetchCount(db) // Int\n\n// SELECT COUNT(*) FROM player WHERE email IS NOT NULL\nlet count = try Player.filter { $0.email != nil }.fetchCount(db)\n\n// SELECT COUNT(DISTINCT name) FROM player\nlet count = try Player.select(\\.name).distinct().fetchCount(db)\n\n// SELECT COUNT(*) FROM (SELECT DISTINCT name, score FROM player)\nlet count = try Player.select { [$0.name, $0.score] }.distinct().fetchCount(db)\n```\n\n\n**Other aggregated values** can also be selected and fetched (see [SQL Functions](#sql-functions)):\n\n```swift\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\nlet request = Player.select { [min($0.score), max($0.score)] }\nlet row = try Row.fetchOne(db, request)!     // Row\nlet minScore = row[0] as Int?\nlet maxScore = row[1] as Int?\n```\n\n\n## Delete Requests\n\n**Requests can delete records**, with the `deleteAll()` method:\n\n```swift\n// DELETE FROM player\ntry Player.deleteAll(db)\n\n// DELETE FROM player WHERE team = 'Reds'\ntry Player\n    .filter { $0.team == \"Reds\" }\n    .deleteAll(db)\n\n// DELETE FROM player ORDER BY score LIMIT 10\ntry Player\n    .order(\\.score)\n    .limit(10)\n    .deleteAll(db)\n```\n\n> **Note** Deletion methods are available on types that adopt the [TableRecord] protocol, and `Table`:\n>\n> ```swift\n> struct Player: TableRecord { ... }\n> try Player.deleteAll(db)          // Fine\n> try Table(\"player\").deleteAll(db) // Just as fine\n> ```\n\n**Deleting records according to their primary key** is a common task.\n\n[Identifiable Records] can use the type-safe methods `deleteOne(_:id:)` and `deleteAll(_:ids:)`:\n\n```swift\ntry Player.deleteOne(db, id: 1)\ntry Country.deleteAll(db, ids: [\"FR\", \"US\"])\n```\n\nAll record types can use `deleteOne(_:key:)` and `deleteAll(_:keys:)` that apply conditions on primary and unique keys:\n\n```swift\ntry Player.deleteOne(db, key: 1)\ntry Country.deleteAll(db, keys: [\"FR\", \"US\"])\ntry Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\ntry Citizenship.deleteOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\nWhen the table has no explicit primary key, GRDB uses the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html):\n\n```swift\n// DELETE FROM document WHERE rowid = 1\ntry Document.deleteOne(db, id: 1)             // Document?\n```\n\n\n## Update Requests\n\n**Requests can batch update records**. The `updateAll()` method accepts *column assignments* defined with the `set(to:)` method:\n\n```swift\n// UPDATE player SET score = 0, isHealthy = 1, bonus = NULL\ntry Player.updateAll(db) { [\n    $0.score.set(to: 0), \n    $0.isHealthy.set(to: true), \n    $0.bonus.set(to: nil),\n] }\n\n// UPDATE player SET score = 0 WHERE team = 'Reds'\ntry Player\n    .filter { $0.team == \"Reds\" }\n    .updateAll(db) { $0.score.set(to: 0) }\n\n// UPDATE player SET isGreat = 1 ORDER BY score DESC LIMIT 10\ntry Player\n    .order(\\.score.desc)\n    .limit(10)\n    .updateAll(db) { $0.isGreat.set(to: true) }\n\n// UPDATE country SET population = 67848156 WHERE id = 'FR'\ntry Country\n    .filter(id: \"FR\")\n    .updateAll(db) { $0.population.set(to: 67_848_156) }\n```\n\nColumn assignments accept any expression:\n\n```swift\n// UPDATE player SET score = score + (bonus * 2)\ntry Player.updateAll(db) {\n    $0.score.set(to: $0.score + $0.bonus * 2)\n}\n```\n\nAs a convenience, you can also use the `+=`, `-=`, `*=`, or `/=` operators:\n\n```swift\n// UPDATE player SET score = score + (bonus * 2)\ntry Player.updateAll(db) { $0.score += $0.bonus * 2 }\n```\n\nDefault [Conflict Resolution] rules apply, and you may also provide a specific one:\n\n```swift\n// UPDATE OR IGNORE player SET ...\ntry Player.updateAll(db, onConflict: .ignore) { /* assignments... */ }\n```\n\n> **Note** The `updateAll` method is available on types that adopt the [TableRecord] protocol, and `Table`:\n>\n> ```swift\n> struct Player: TableRecord { ... }\n> try Player.updateAll(db, ...)          // Fine\n> try Table(\"player\").updateAll(db, ...) // Just as fine\n> ```\n\n\n## Custom Requests\n\nUntil now, we have seen [requests](#requests) created from any type that adopts the [TableRecord] protocol:\n\n```swift\nlet request = Player.all()  // QueryInterfaceRequest<Player>\n```\n\nThose requests of type `QueryInterfaceRequest` can fetch and count:\n\n```swift\ntry request.fetchCursor(db) // A Cursor of Player\ntry request.fetchAll(db)    // [Player]\ntry request.fetchSet(db)    // Set<Player>\ntry request.fetchOne(db)    // Player?\ntry request.fetchCount(db)  // Int\n```\n\n**When the query interface can not generate the SQL you need**, you can still fallback to [raw SQL](#fetch-queries):\n\n```swift\n// Custom SQL is always welcome\ntry Player.fetchAll(db, sql: \"SELECT ...\")   // [Player]\n```\n\nBut you may prefer to bring some elegance back in, and build custom requests:\n\n```swift\n// No custom SQL in sight\ntry Player.customRequest().fetchAll(db) // [Player]\n```\n\n**To build custom requests**, you can use one of the built-in requests or derive requests from other requests.\n\n- [SQLRequest] is a fetch request built from raw SQL. For example:\n    \n    ```swift\n    extension Player {\n        static func filter(color: Color) -> SQLRequest<Player> {\n            SQLRequest<Player>(\n                sql: \"SELECT * FROM player WHERE color = ?\"\n                arguments: [color])\n        }\n    }\n    \n    // [Player]\n    try Player.filter(color: .red).fetchAll(db)\n    ```\n    \n    SQLRequest supports [SQL Interpolation]:\n    \n    ```swift\n    extension Player {\n        static func filter(color: Color) -> SQLRequest<Player> {\n            \"SELECT * FROM player WHERE color = \\(color)\"\n        }\n    }\n    ```\n    \n- The [`asRequest(of:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/asrequest(of:)) method changes the type fetched by the request. It is useful, for example, when you use [Associations]:\n\n    ```swift\n    struct BookInfo: FetchableRecord, Decodable {\n        var book: Book\n        var author: Author\n    }\n    \n    let request = Book\n        .including(required: Book.author)\n        .asRequest(of: BookInfo.self)\n    \n    // [BookInfo]\n    try request.fetchAll(db)\n    ```\n\n- The [`adapted(_:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/fetchrequest/adapted(_:)) method eases the consumption of complex rows with row adapters. See [`RowAdapter`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter) and [`splittingRowAdapters(columnCounts:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/splittingrowadapters(columncounts:)) for a sample code that uses `adapted(_:)`.\n\n\nEncryption\n==========\n\n**GRDB can encrypt your database with [SQLCipher](http://sqlcipher.net) v3.4+.**\n\nUse [CocoaPods](http://cocoapods.org/), and specify in your `Podfile`:\n\n```ruby\n# GRDB with SQLCipher 4\npod 'GRDB.swift/SQLCipher'\npod 'SQLCipher', '~> 4.0'\n\n# GRDB with SQLCipher 3\npod 'GRDB.swift/SQLCipher'\npod 'SQLCipher', '~> 3.4'\n```\n\nMake sure you remove any existing `pod 'GRDB.swift'` from your Podfile. `GRDB.swift/SQLCipher` must be the only active GRDB pod in your whole project, or you will face linker or runtime errors, due to the conflicts between SQLCipher and the system SQLite.\n\n- [Creating or Opening an Encrypted Database](#creating-or-opening-an-encrypted-database)\n- [Changing the Passphrase of an Encrypted Database](#changing-the-passphrase-of-an-encrypted-database)\n- [Exporting a Database to an Encrypted Database](#exporting-a-database-to-an-encrypted-database)\n- [Security Considerations](#security-considerations)\n\n\n### Creating or Opening an Encrypted Database\n\n**You create and open an encrypted database** by providing a passphrase to your [database connection]:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nIt is also in `prepareDatabase` that you perform other [SQLCipher configuration steps](https://www.zetetic.net/sqlcipher/sqlcipher-api/) that must happen early in the lifetime of a SQLCipher connection. For example:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n    try db.execute(sql: \"PRAGMA cipher_page_size = ...\")\n    try db.execute(sql: \"PRAGMA kdf_iter = ...\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nWhen you want to open an existing SQLCipher 3 database with SQLCipher 4, you may want to run the `cipher_compatibility` pragma:\n\n```swift\n// Open an SQLCipher 3 database with SQLCipher 4\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n    try db.execute(sql: \"PRAGMA cipher_compatibility = 3\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nSee [SQLCipher 4.0.0 Release](https://www.zetetic.net/blog/2018/11/30/sqlcipher-400-release/) and [Upgrading to SQLCipher 4](https://discuss.zetetic.net/t/upgrading-to-sqlcipher-4/3283) for more information.\n\n\n### Changing the Passphrase of an Encrypted Database\n\n**You can change the passphrase** of an already encrypted database.\n\nWhen you use a [database queue](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue), open the database with the old passphrase, and then apply the new passphrase:\n\n```swift\ntry dbQueue.write { db in\n    try db.changePassphrase(\"newSecret\")\n}\n```\n\nWhen you use a [database pool](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool), make sure that no concurrent read can happen by changing the passphrase within the `barrierWriteWithoutTransaction` block. You must also ensure all future reads open a new database connection by calling the `invalidateReadOnlyConnections` method:\n\n```swift\ntry dbPool.barrierWriteWithoutTransaction { db in\n    try db.changePassphrase(\"newSecret\")\n    dbPool.invalidateReadOnlyConnections()\n}\n```\n\n> **Note**: When an application wants to keep on using a database queue or pool after the passphrase has changed, it is responsible for providing the correct passphrase to the `usePassphrase` method called in the database preparation function. Consider:\n>\n> ```swift\n> // WRONG: this won't work across a passphrase change\n> let passphrase = try getPassphrase()\n> var config = Configuration()\n> config.prepareDatabase { db in\n>     try db.usePassphrase(passphrase)\n> }\n>\n> // CORRECT: get the latest passphrase when it is needed\n> var config = Configuration()\n> config.prepareDatabase { db in\n>     let passphrase = try getPassphrase()\n>     try db.usePassphrase(passphrase)\n> }\n> ```\n\n> **Note**: The `DatabasePool.barrierWriteWithoutTransaction` method does not prevent [database snapshots](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasesnapshot) from accessing the database during the passphrase change, or after the new passphrase has been applied to the database. Those database accesses may throw errors. Applications should provide their own mechanism for invalidating open snapshots before the passphrase is changed.\n\n> **Note**: Instead of changing the passphrase \"in place\" as described here, you can also export the database in a new encrypted database that uses the new passphrase. See [Exporting a Database to an Encrypted Database](#exporting-a-database-to-an-encrypted-database).\n\n\n### Exporting a Database to an Encrypted Database\n\nProviding a passphrase won't encrypt a clear-text database that already exists, though. SQLCipher can't do that, and you will get an error instead: `SQLite error 26: file is encrypted or is not a database`.\n\nInstead, create a new encrypted database, at a distinct location, and export the content of the existing database. This can both encrypt a clear-text database, or change the passphrase of an encrypted database.\n\nThe technique to do that is [documented](https://discuss.zetetic.net/t/how-to-encrypt-a-plaintext-sqlite-database-to-use-sqlcipher-and-avoid-file-is-encrypted-or-is-not-a-database-errors/868/1) by SQLCipher.\n\nWith GRDB, it gives:\n\n```swift\n// The existing database\nlet existingDBQueue = try DatabaseQueue(path: \"/path/to/existing.db\")\n\n// The new encrypted database, at some distinct location:\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n}\nlet newDBQueue = try DatabaseQueue(path: \"/path/to/new.db\", configuration: config)\n\ntry existingDBQueue.inDatabase { db in\n    try db.execute(\n        sql: \"\"\"\n            ATTACH DATABASE ? AS encrypted KEY ?;\n            SELECT sqlcipher_export('encrypted');\n            DETACH DATABASE encrypted;\n            \"\"\",\n        arguments: [newDBQueue.path, \"secret\"])\n}\n\n// Now the export is completed, and the existing database can be deleted.\n```\n\n\n### Security Considerations\n\n#### Managing the lifetime of the passphrase string\n\nIt is recommended to avoid keeping the passphrase in memory longer than necessary. To do this, make sure you load the passphrase from the `prepareDatabase` method:\n\n```swift\n// NOT RECOMMENDED: this keeps the passphrase in memory longer than necessary\nlet passphrase = try getPassphrase()\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(passphrase)\n}\n\n// RECOMMENDED: only load the passphrase when it is needed\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    let passphrase = try getPassphrase()\n    try db.usePassphrase(passphrase)\n}\n```\n\nThis technique helps manages the lifetime of the passphrase, although keep in mind that the content of a String may remain intact in memory long after the object has been released.\n\nFor even better control over the lifetime of the passphrase in memory, use a Data object which natively provides the `resetBytes` function.\n\n```swift\n// RECOMMENDED: only load the passphrase when it is needed and reset its content immediately after use\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    var passphraseData = try getPassphraseData() // Data\n    defer {\n        passphraseData.resetBytes(in: 0..<passphraseData.count)\n    }\n    try db.usePassphrase(passphraseData)\n}\n```\n\nSome demanding users will want to go further, and manage the lifetime of the raw passphrase bytes. See below.\n\n\n#### Managing the lifetime of the passphrase bytes\n\nGRDB offers convenience methods for providing the database passphrases as Swift strings: `usePassphrase(_:)` and `changePassphrase(_:)`. Those methods don't keep the passphrase String in memory longer than necessary. But they are as secure as the standard String type: the lifetime of actual passphrase bytes in memory is not under control.\n\nWhen you want to precisely manage the passphrase bytes, talk directly to SQLCipher, using its raw C functions.\n\nFor example:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    ... // Carefully load passphrase bytes\n    let code = sqlite3_key(db.sqliteConnection, /* passphrase bytes */)\n    ... // Carefully dispose passphrase bytes\n    guard code == SQLITE_OK else {\n        throw DatabaseError(\n            resultCode: ResultCode(rawValue: code), \n            message: db.lastErrorMessage)\n    }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\n#### Passphrase availability vs. Database availability\n\nWhen the passphrase is securely stored in the system keychain, your application can protect it using the [`kSecAttrAccessible`](https://developer.apple.com/documentation/security/ksecattraccessible) attribute.\n\nSuch protection prevents GRDB from creating SQLite connections when the passphrase is not available:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    let passphrase = try loadPassphraseFromSystemKeychain()\n    try db.usePassphrase(passphrase)\n}\n\n// Success if and only if the passphrase is available\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nFor the same reason, [database pools], which open SQLite connections on demand, may fail at any time as soon as the passphrase becomes unavailable:\n\n```swift\n// Success if and only if the passphrase is available\nlet dbPool = try DatabasePool(path: dbPath, configuration: config)\n\n// May fail if passphrase has turned unavailable\ntry dbPool.read { ... }\n\n// May trigger value observation failure if passphrase has turned unavailable\ntry dbPool.write { ... }\n```\n\nBecause DatabasePool maintains a pool of long-lived SQLite connections, some database accesses will use an existing connection, and succeed. And some other database accesses will fail, as soon as the pool wants to open a new connection. It is impossible to predict which accesses will succeed or fail.\n\nFor the same reason, a database queue, which also maintains a long-lived SQLite connection, will remain available even after the passphrase has turned unavailable.\n\nApplications are thus responsible for protecting database accesses when the passphrase is unavailable. To this end, they can use [Data Protection](https://developer.apple.com/documentation/uikit/protecting_the_user_s_privacy/encrypting_your_app_s_files). They can also destroy their instances of database queue or pool when the passphrase becomes unavailable.\n\n\n## Backup\n\n**You can backup (copy) a database into another.**\n\nBackups can for example help you copying an in-memory database to and from a database file when you implement NSDocument subclasses.\n\n```swift\nlet source: DatabaseQueue = ...      // or DatabasePool\nlet destination: DatabaseQueue = ... // or DatabasePool\ntry source.backup(to: destination)\n```\n\nThe `backup` method blocks the current thread until the destination database contains the same contents as the source database.\n\nWhen the source is a [database pool](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool), concurrent writes can happen during the backup. Those writes may, or may not, be reflected in the backup, but they won't trigger any error.\n\n`Database` has an analogous `backup` method.\n\n```swift\nlet source: DatabaseQueue = ...      // or DatabasePool\nlet destination: DatabaseQueue = ... // or DatabasePool\ntry source.write { sourceDb in\n    try destination.barrierWriteWithoutTransaction { destDb in\n        try sourceDb.backup(to: destDb)\n    }\n}\n```\n\nThis method allows for the choice of source and destination `Database` handles with which to backup the database.\n\n### Backup Progress Reporting\n\nThe `backup` methods take optional `pagesPerStep` and `progress` parameters. Together these parameters can be used to track a database backup in progress and abort an incomplete backup.\n\nWhen `pagesPerStep` is provided, the database backup is performed in _steps_. At each step, no more than `pagesPerStep` database pages are copied from the source to the destination. The backup proceeds one step at a time until all pages have been copied.\n\nWhen a `progress` callback is provided, `progress` is called after every backup step, including the last. Even if a non-default `pagesPerStep` is specified or the backup is otherwise completed in a single step, the `progress` callback will be called.\n\n```swift\ntry source.backup(\n    to: destination,\n    pagesPerStep: ...)\n    { backupProgress in\n       print(\"Database backup progress:\", backupProgress)\n    }\n```\n\n### Aborting an Incomplete Backup\n\nIf a call to `progress` throws when `backupProgress.isComplete == false`, the backup will be aborted and the error rethrown. However, if a call to `progress` throws when `backupProgress.isComplete == true`, the backup is unaffected and the error is silently ignored.\n\n> **Warning**: Passing non-default values of `pagesPerStep` or `progress` to the backup methods is an advanced API intended to provide additional capabilities to expert users. GRDB's backup API provides a faithful, low-level wrapper to the underlying SQLite online backup API. GRDB's documentation is not a comprehensive substitute for the official SQLite [documentation of their backup API](https://www.sqlite.org/c3ref/backup_finish.html).\n\n## Interrupt a Database\n\n**The `interrupt()` method** causes any pending database operation to abort and return at its earliest opportunity.\n\nIt can be called from any thread.\n\n```swift\ndbQueue.interrupt()\ndbPool.interrupt()\n```\n\nA call to `interrupt()` that occurs when there are no running SQL statements is a no-op and has no effect on SQL statements that are started after `interrupt()` returns.\n\nA database operation that is interrupted will throw a DatabaseError with code `SQLITE_INTERRUPT`. If the interrupted SQL operation is an INSERT, UPDATE, or DELETE that is inside an explicit transaction, then the entire transaction will be rolled back automatically. If the rolled back transaction was started by a transaction-wrapping method such as `DatabaseWriter.write` or `Database.inTransaction`, then all database accesses will throw a DatabaseError with code `SQLITE_ABORT` until the wrapping method returns.\n\nFor example:\n\n```swift\ntry dbQueue.write { db in\n    try Player(...).insert(db)     // throws SQLITE_INTERRUPT\n    try Player(...).insert(db)     // not executed\n}                                  // throws SQLITE_INTERRUPT\n\ntry dbQueue.write { db in\n    do {\n        try Player(...).insert(db) // throws SQLITE_INTERRUPT\n    } catch { }\n}                                  // throws SQLITE_ABORT\n\ntry dbQueue.write { db in\n    do {\n        try Player(...).insert(db) // throws SQLITE_INTERRUPT\n    } catch { }\n    try Player(...).insert(db)     // throws SQLITE_ABORT\n}                                  // throws SQLITE_ABORT\n```\n\nYou can catch both `SQLITE_INTERRUPT` and `SQLITE_ABORT` errors:\n\n```swift\ndo {\n    try dbPool.write { db in ... }\n} catch DatabaseError.SQLITE_INTERRUPT, DatabaseError.SQLITE_ABORT {\n    // Oops, the database was interrupted.\n}\n```\n\nFor more information, see [Interrupt A Long-Running Query](https://www.sqlite.org/c3ref/interrupt.html).\n\n\n## Avoiding SQL Injection\n\nSQL injection is a technique that lets an attacker nuke your database.\n\n> ![XKCD: Exploits of a Mom](https://imgs.xkcd.com/comics/exploits_of_a_mom.png)\n>\n> https://xkcd.com/327/\n\nHere is an example of code that is vulnerable to SQL injection:\n\n```swift\n// BAD BAD BAD\nlet id = 1\nlet name = textField.text\ntry dbQueue.write { db in\n    try db.execute(sql: \"UPDATE students SET name = '\\(name)' WHERE id = \\(id)\")\n}\n```\n\nIf the user enters a funny string like `Robert'; DROP TABLE students; --`, SQLite will see the following SQL, and drop your database table instead of updating a name as intended:\n\n```sql\nUPDATE students SET name = 'Robert';\nDROP TABLE students;\n--' WHERE id = 1\n```\n\nTo avoid those problems, **never embed raw values in your SQL queries**. The only correct technique is to provide [arguments](#executing-updates) to your raw SQL queries:\n\n```swift\nlet name = textField.text\ntry dbQueue.write { db in\n    // Good\n    try db.execute(\n        sql: \"UPDATE students SET name = ? WHERE id = ?\",\n        arguments: [name, id])\n    \n    // Just as good\n    try db.execute(\n        sql: \"UPDATE students SET name = :name WHERE id = :id\",\n        arguments: [\"name\": name, \"id\": id])\n}\n```\n\nWhen you use [records](#records) and the [query interface](#the-query-interface), GRDB always prevents SQL injection for you:\n\n```swift\nlet id = 1\nlet name = textField.text\ntry dbQueue.write { db in\n    if var student = try Student.fetchOne(db, id: id) {\n        student.name = name\n        try student.update(db)\n    }\n}\n```\n\n\n## Error Handling\n\nGRDB can throw [DatabaseError](#databaseerror), [RecordError], [RowDecodingError], or crash your program with a [fatal error](#fatal-errors).\n\nConsidering that a local database is not some JSON loaded from a remote server, GRDB focuses on **trusted databases**. Dealing with [untrusted databases](#how-to-deal-with-untrusted-inputs) requires extra care.\n\n- [DatabaseError](#databaseerror)\n- [RecordError]\n- [RowDecodingError]\n- [Fatal Errors](#fatal-errors)\n- [How to Deal with Untrusted Inputs](#how-to-deal-with-untrusted-inputs)\n- [Error Log](#error-log)\n\n\n### DatabaseError\n\nüìñ [`DatabaseError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseerror)\n\n**DatabaseError** are thrown on SQLite errors:\n\n```swift\ndo {\n    try Pet(masterId: 1, name: \"Bobby\").insert(db)\n} catch let error as DatabaseError {\n    // The SQLite error code: 19 (SQLITE_CONSTRAINT)\n    error.resultCode\n    \n    // The extended error code: 787 (SQLITE_CONSTRAINT_FOREIGNKEY)\n    error.extendedResultCode\n    \n    // The eventual SQLite message: FOREIGN KEY constraint failed\n    error.message\n    \n    // The eventual erroneous SQL query\n    // \"INSERT INTO pet (masterId, name) VALUES (?, ?)\"\n    error.sql\n    \n    // The eventual SQL arguments\n    // [1, \"Bobby\"]\n    error.arguments\n    \n    // Full error description\n    // > SQLite error 19: FOREIGN KEY constraint failed -\n    // > while executing `INSERT INTO pet (masterId, name) VALUES (?, ?)`\n    error.description\n}\n```\n\nIf you want to see statement arguments in the error description, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n**SQLite uses [results codes](https://www.sqlite.org/rescode.html) to distinguish between various errors**.\n\nYou can catch a DatabaseError and match on result codes:\n\n```swift\ndo {\n    try ...\n} catch let error as DatabaseError {\n    switch error {\n    case DatabaseError.SQLITE_CONSTRAINT_FOREIGNKEY:\n        // foreign key constraint error\n    case DatabaseError.SQLITE_CONSTRAINT:\n        // any other constraint error\n    default:\n        // any other database error\n    }\n}\n```\n\nYou can also directly match errors on result codes:\n\n```swift\ndo {\n    try ...\n} catch DatabaseError.SQLITE_CONSTRAINT_FOREIGNKEY {\n    // foreign key constraint error\n} catch DatabaseError.SQLITE_CONSTRAINT {\n    // any other constraint error\n} catch {\n    // any other database error\n}\n```\n\nEach DatabaseError has two codes: an `extendedResultCode` (see [extended result code](https://www.sqlite.org/rescode.html#extended_result_code_list)), and a less precise `resultCode` (see [primary result code](https://www.sqlite.org/rescode.html#primary_result_code_list)). Extended result codes are refinements of primary result codes, as `SQLITE_CONSTRAINT_FOREIGNKEY` is to `SQLITE_CONSTRAINT`, for example.\n\n> **Warning**: SQLite has progressively introduced extended result codes across its versions. The [SQLite release notes](http://www.sqlite.org/changes.html) are unfortunately not quite clear about that: write your handling of extended result codes with care.\n\n\n### RecordError\n\nüìñ [`RecordError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recorderror)\n\n**RecordError** is thrown by the [PersistableRecord] protocol when the `update` method could not find any row to update:\n\n```swift\ndo {\n    try player.update(db)\n} catch let RecordError.recordNotFound(databaseTableName: table, key: key) {\n    print(\"Key \\(key) was not found in table \\(table).\")\n}\n```\n\n**RecordError** is also thrown by the [FetchableRecord] protocol when the `find` method does not find any record:\n\n```swift\ndo {\n    let player = try Player.find(db, id: 42)\n} catch let RecordError.recordNotFound(databaseTableName: table, key: key) {\n    print(\"Key \\(key) was not found in table \\(table).\")\n}\n```\n\n\n### RowDecodingError\n\nüìñ [`RowDecodingError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowdecodingerror)\n\n**RowDecodingError** is thrown when the application can not decode a value from a database row. For example:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT NULL AS name\")!\n// RowDecodingError: could not decode String from database value NULL.\nlet name = try row.decode(String.self, forColumn: \"name\")\n```\n\n### Fatal Errors\n\n**Fatal errors notify that the program, or the database, has to be changed.**\n\nThey uncover programmer errors, false assumptions, and prevent misuses. Here are a few examples:\n\n- **The code asks for a non-optional value, when the database contains NULL:**\n    \n    ```swift\n    // fatal error: could not convert NULL to String.\n    let name: String = row[\"name\"]\n    ```\n    \n    Solution: fix the contents of the database, use [NOT NULL constraints](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/columndefinition/notnull(onconflict:)), or load an optional:\n    \n    ```swift\n    let name: String? = row[\"name\"]\n    ```\n\n- **Conversion from database value to Swift type fails:**\n    \n    ```swift\n    // fatal error: could not convert \"Mom‚Äôs birthday\" to Date.\n    let date: Date = row[\"date\"]\n    \n    // fatal error: could not convert \"\" to URL.\n    let url: URL = row[\"url\"]\n    ```\n    \n    Solution: fix the contents of the database, or use [DatabaseValue](#databasevalue) to handle all possible cases:\n    \n    ```swift\n    let dbValue: DatabaseValue = row[\"date\"]\n    if dbValue.isNull {\n        // Handle NULL\n    } else if let date = Date.fromDatabaseValue(dbValue) {\n        // Handle valid date\n    } else {\n        // Handle invalid date\n    }\n    ```\n\n- **The database can't guarantee that the code does what it says:**\n\n    ```swift\n    // fatal error: table player has no unique index on column email\n    try Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\n    ```\n    \n    Solution: add a unique index to the player.email column, or use the `deleteAll` method to make it clear that you may delete more than one row:\n    \n    ```swift\n    try Player.filter { $0.email == \"arthur@example.com\" }.deleteAll(db)\n    ```\n\n- **Database connections are not reentrant:**\n    \n    ```swift\n    // fatal error: Database methods are not reentrant.\n    dbQueue.write { db in\n        dbQueue.write { db in\n            ...\n        }\n    }\n    ```\n    \n    Solution: avoid reentrancy, and instead pass a database connection along.\n\n\n### How to Deal with Untrusted Inputs\n\nLet's consider the code below:\n\n```swift\nlet sql = \"SELECT ...\"\n\n// Some untrusted arguments for the query\nlet arguments: [String: Any] = ...\nlet rows = try Row.fetchCursor(db, sql: sql, arguments: StatementArguments(arguments))\n\nwhile let row = try rows.next() {\n    // Some untrusted database value:\n    let date: Date? = row[0]\n}\n```\n\nIt has two opportunities to throw fatal errors:\n\n- **Untrusted arguments**: The dictionary may contain values that do not conform to the [DatabaseValueConvertible protocol](#values), or may miss keys required by the statement.\n- **Untrusted database content**: The row may contain a non-null value that can't be turned into a date.\n\nIn such a situation, you can still avoid fatal errors by exposing and handling each failure point, one level down in the GRDB API:\n\n```swift\n// Untrusted arguments\nif let arguments = StatementArguments(arguments) {\n    let statement = try db.makeStatement(sql: sql)\n    try statement.setArguments(arguments)\n    \n    var cursor = try Row.fetchCursor(statement)\n    while let row = try iterator.next() {\n        // Untrusted database content\n        let dbValue: DatabaseValue = row[0]\n        if dbValue.isNull {\n            // Handle NULL\n        if let date = Date.fromDatabaseValue(dbValue) {\n            // Handle valid date\n        } else {\n            // Handle invalid date\n        }\n    }\n}\n```\n\nSee [`Statement`] and [DatabaseValue](#databasevalue) for more information.\n\n\n### Error Log\n\n**SQLite can be configured to invoke a callback function containing an error code and a terse error message whenever anomalies occur.**\n\nThis global error callback must be configured early in the lifetime of your application:\n\n```swift\nDatabase.logError = { (resultCode, message) in\n    NSLog(\"%@\", \"SQLite error \\(resultCode): \\(message)\")\n}\n```\n\n> **Warning**: Database.logError must be set before any database connection is opened. This includes the connections that your application opens with GRDB, but also connections opened by other tools, such as third-party libraries. Setting it after a connection has been opened is an SQLite misuse, and has no effect.\n\nSee [The Error And Warning Log](https://sqlite.org/errlog.html) for more information.\n\n\n## Unicode\n\nSQLite lets you store unicode strings in the database.\n\nHowever, SQLite does not provide any unicode-aware string transformations or comparisons.\n\n\n### Unicode functions\n\nThe `UPPER` and `LOWER` built-in SQLite functions are not unicode-aware:\n\n```swift\n// \"J√©R√¥ME\"\ntry String.fetchOne(db, sql: \"SELECT UPPER('J√©r√¥me')\")\n```\n\nGRDB extends SQLite with [SQL functions](#custom-sql-functions-and-aggregates) that call the Swift built-in string functions `capitalized`, `lowercased`, `uppercased`, `localizedCapitalized`, `localizedLowercased` and `localizedUppercased`:\n\n```swift\n// \"J√âR√îME\"\nlet uppercased = DatabaseFunction.uppercase\ntry String.fetchOne(db, sql: \"SELECT \\(uppercased.name)('J√©r√¥me')\")\n```\n\nThose unicode-aware string functions are also readily available in the [query interface](#sql-functions):\n\n```swift\nPlayer.select { $0.name.uppercased }\n```\n\n\n### String Comparison\n\nSQLite compares strings in many occasions: when you sort rows according to a string column, or when you use a comparison operator such as `=` and `<=`.\n\nThe comparison result comes from a *collating function*, or *collation*. SQLite comes with three built-in collations that do not support Unicode: [binary, nocase, and rtrim](https://www.sqlite.org/datatype3.html#collation).\n\nGRDB comes with five extra collations that leverage unicode-aware comparisons based on the standard Swift String comparison functions and operators:\n\n- `unicodeCompare` (uses the built-in `<=` and `==` Swift operators)\n- `caseInsensitiveCompare`\n- `localizedCaseInsensitiveCompare`\n- `localizedCompare`\n- `localizedStandardCompare`\n\nA collation can be applied to a table column. All comparisons involving this column will then automatically trigger the comparison function:\n    \n```swift\ntry db.create(table: \"player\") { t in\n    // Guarantees case-insensitive email unicity\n    t.column(\"email\", .text).unique().collate(.nocase)\n    \n    // Sort names in a localized case insensitive way\n    t.column(\"name\", .text).collate(.localizedCaseInsensitiveCompare)\n}\n\n// Players are sorted in a localized case insensitive way:\nlet players = try Player.order(\\.name).fetchAll(db)\n```\n\n> **Warning**: SQLite *requires* host applications to provide the definition of any collation other than binary, nocase and rtrim. When a database file has to be shared or migrated to another SQLite library of platform (such as the Android version of your application), make sure you provide a compatible collation.\n\nIf you can't or don't want to define the comparison behavior of a column (see warning above), you can still use an explicit collation in SQL requests and in the [query interface](#the-query-interface):\n\n```swift\nlet collation = DatabaseCollation.localizedCaseInsensitiveCompare\nlet players = try Player.fetchAll(db,\n    sql: \"SELECT * FROM player ORDER BY name COLLATE \\(collation.name))\")\nlet players = try Player.order { $0.name.collating(collation) }.fetchAll(db)\n```\n\n\n**You can also define your own collations**:\n\n```swift\nlet collation = DatabaseCollation(\"customCollation\") { (lhs, rhs) -> NSComparisonResult in\n    // return the comparison of lhs and rhs strings.\n}\n\n// Make the collation available to a database connection\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(collation: collation)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\n\n\n## Memory Management\n\nBoth SQLite and GRDB use non-essential memory that help them perform better.\n\nYou can reclaim this memory with the `releaseMemory` method:\n\n```swift\n// Release as much memory as possible.\ndbQueue.releaseMemory()\ndbPool.releaseMemory()\n```\n\nThis method blocks the current thread until all current database accesses are completed, and the memory collected.\n\n> **Warning**: If `DatabasePool.releaseMemory()` is called while a long read is performed concurrently, then no other read access will be possible until this long read has completed, and the memory has been released. If this does not suit your application needs, look for the asynchronous options below:\n\nYou can release memory in an asynchronous way as well:\n\n```swift\n// On a DatabaseQueue\ndbQueue.asyncWriteWithoutTransaction { db in\n    db.releaseMemory()\n}\n\n// On a DatabasePool\ndbPool.releaseMemoryEventually()\n```\n\n`DatabasePool.releaseMemoryEventually()` does not block the current thread, and does not prevent concurrent database accesses. In exchange for this convenience, you don't know when memory has been freed.\n\n\n### Memory Management on iOS\n\n**The iOS operating system likes applications that do not consume much memory.**\n\n[Database queues] and [pools](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool) automatically free non-essential memory when the application receives a memory warning, and when the application enters background.\n\nYou can opt out of this automatic memory management:\n\n```swift\nvar config = Configuration()\nconfig.automaticMemoryManagement = false\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config) // or DatabasePool\n```\n\nFAQ\n===\n\n**[FAQ: Opening Connections](#faq-opening-connections)**\n\n- [How do I create a database in my application?](#how-do-i-create-a-database-in-my-application)\n- [How do I open a database stored as a resource of my application?](#how-do-i-open-a-database-stored-as-a-resource-of-my-application)\n- [How do I close a database connection?](#how-do-i-close-a-database-connection)\n\n**[FAQ: SQL](#faq-sql)**\n\n- [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql)\n\n**[FAQ: General](#faq-general)**\n\n- [How do I monitor the duration of database statements execution?](#how-do-i-monitor-the-duration-of-database-statements-execution)\n- [What Are Experimental Features?](#what-are-experimental-features)\n- [Does GRDB support library evolution and ABI stability?](#does-grdb-support-library-evolution-and-abi-stability)\n\n**[FAQ: Associations](#faq-associations)**\n\n- [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record)\n- [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record)\n- [How do I select only one column of an associated record?](#how-do-i-select-only-one-column-of-an-associated-record)\n\n**[FAQ: ValueObservation](#faq-valueobservation)**\n\n- [Why is ValueObservation not publishing value changes?](#why-is-valueobservation-not-publishing-value-changes)\n\n**[FAQ: Errors](#faq-errors)**\n\n- [Generic parameter 'T' could not be inferred](#generic-parameter-t-could-not-be-inferred)\n- [Mutation of captured var in concurrently-executing code](#mutation-of-captured-var-in-concurrently-executing-code)\n- [SQLite error 1 \"no such column\"](#sqlite-error-1-no-such-column)\n- [SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"](#sqlite-error-10-disk-io-error-sqlite-error-23-not-authorized)\n- [SQLite error 21 \"wrong number of statement arguments\" with LIKE queries](#sqlite-error-21-wrong-number-of-statement-arguments-with-like-queries)\n\n\n## FAQ: Opening Connections\n\n- :arrow_up: [FAQ]\n- [How do I create a database in my application?](#how-do-i-create-a-database-in-my-application)\n- [How do I open a database stored as a resource of my application?](#how-do-i-open-a-database-stored-as-a-resource-of-my-application)\n- [How do I close a database connection?](#how-do-i-close-a-database-connection)\n\n### How do I create a database in my application?\n\nFirst choose a proper location for the database file. Document-based applications will let the user pick a location. Apps that use the database as a global storage will prefer the Application Support directory.\n\nThe sample code below creates or opens a database file inside its dedicated directory (a [recommended practice](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections)). On the first run, a new empty database file is created. On subsequent runs, the database file already exists, so it just opens a connection:\n\n```swift\n// HOW TO create an empty database, or open an existing database file\n\n// Create the \"Application Support/MyDatabase\" directory\nlet fileManager = FileManager.default\nlet appSupportURL = try fileManager.url(\n    for: .applicationSupportDirectory, in: .userDomainMask,\n    appropriateFor: nil, create: true) \nlet directoryURL = appSupportURL.appendingPathComponent(\"MyDatabase\", isDirectory: true)\ntry fileManager.createDirectory(at: directoryURL, withIntermediateDirectories: true)\n\n// Open or create the database\nlet databaseURL = directoryURL.appendingPathComponent(\"db.sqlite\")\nlet dbQueue = try DatabaseQueue(path: databaseURL.path)\n```\n\n### How do I open a database stored as a resource of my application?\n\nOpen a read-only connection to your resource:\n\n```swift\n// HOW TO open a read-only connection to a database resource\n\n// Get the path to the database resource.\nif let dbPath = Bundle.main.path(forResource: \"db\", ofType: \"sqlite\") {\n    // If the resource exists, open a read-only connection.\n    // Writes are disallowed because resources can not be modified. \n    var config = Configuration()\n    config.readonly = true\n    let dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n} else {\n    // The database resource can not be found.\n    // Fix your setup, or report the problem to the user. \n}\n```\n\n### How do I close a database connection?\n\nDatabase connections are automatically closed when `DatabaseQueue` or `DatabasePool` instances are deinitialized.\n\nIf the correct execution of your program depends on precise database closing, perform an explicit call to [`close()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasereader/close()). This method may fail and create zombie connections, so please check its detailed documentation.\n\n## FAQ: SQL\n\n- :arrow_up: [FAQ]\n- [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql)\n\n### How do I print a request as SQL?\n\nWhen you want to debug a request that does not deliver the expected results, you may want to print the SQL that is actually executed.\n\nYou can compile the request into a prepared [`Statement`]:\n\n```swift\ntry dbQueue.read { db in\n    let request = Player.filter { $0.email == \"arthur@example.com\" }\n    let statement = try request.makePreparedRequest(db).statement\n    print(statement) // SELECT * FROM player WHERE email = ?\n    print(statement.arguments) // [\"arthur@example.com\"]\n}\n```\n\nAnother option is to setup a tracing function that prints out the executed SQL requests. For example, provide a tracing function when you connect to the database:\n\n```swift\n// Prints all SQL statements\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace { print($0) }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // Prints \"SELECT * FROM player WHERE email = ?\"\n    let players = try Player.filter { $0.email == \"arthur@example.com\" }.fetchAll(db)\n}\n```\n\nIf you want to see statement arguments such as `'arthur@example.com'` in the logged statements, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n> **Note**: the generated SQL may change between GRDB releases, without notice: don't have your application rely on any specific SQL output.\n\n\n## FAQ: General\n\n- :arrow_up: [FAQ]\n- [How do I monitor the duration of database statements execution?](#how-do-i-monitor-the-duration-of-database-statements-execution)\n- [What Are Experimental Features?](#what-are-experimental-features)\n- [Does GRDB support library evolution and ABI stability?](#does-grdb-support-library-evolution-and-abi-stability)\n\n### How do I monitor the duration of database statements execution?\n\nUse the `trace(options:_:)` method, with the `.profile` option:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace(options: .profile) { event in\n        // Prints all SQL statements with their duration\n        print(event)\n        \n        // Access to detailed profiling information\n        if case let .profile(statement, duration) = event, duration > 0.5 {\n            print(\"Slow query: \\(statement.sql)\")\n        }\n    }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    let players = try Player.filter { $0.email == \"arthur@example.com\" }.fetchAll(db)\n    // Prints \"0.003s SELECT * FROM player WHERE email = ?\"\n}\n```\n\nIf you want to see statement arguments such as `'arthur@example.com'` in the logged statements, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n### What Are Experimental Features?\n\nSince GRDB 1.0, all backwards compatibility guarantees of [semantic versioning](http://semver.org) apply: no breaking change will happen until the next major version of the library.\n\nThere is an exception, though: *experimental features*, marked with the \"**:fire: EXPERIMENTAL**\" badge. Those are advanced features that are too young, or lack user feedback. They are not stabilized yet.\n\nThose experimental features are not protected by semantic versioning, and may break between two minor releases of the library. To help them becoming stable, [your feedback](https://github.com/groue/GRDB.swift/issues) is greatly appreciated.\n\n### Does GRDB support library evolution and ABI stability?\n\nNo, GRDB does not support library evolution and ABI stability. The only promise is API stability according to [semantic versioning](http://semver.org), with an exception for [experimental features](#what-are-experimental-features).\n\nYet, GRDB can be built with the \"Build Libraries for Distribution\" Xcode option (`BUILD_LIBRARY_FOR_DISTRIBUTION`), so that you can build binary frameworks at your convenience.\n\n## FAQ: Associations\n\n- :arrow_up: [FAQ]\n- [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record)\n- [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record)\n- [How do I select only one column of an associated record?](#how-do-i-select-only-one-column-of-an-associated-record)\n\n### How do I filter records and only keep those that are associated to another record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to only fetch books that have an author, and discard anonymous books.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: TableRecord {\n    ...\n}\n```\n\nAnd then we can write our request and only fetch books that have an author, discarding anonymous ones:\n\n```swift\nlet books: [Book] = try dbQueue.read { db in\n    // SELECT book.* FROM book \n    // JOIN author ON author.id = book.authorID\n    let request = Book.joining(required: Book.author)\n    return try request.fetchAll(db)\n}\n```\n\nNote how this request does not use the `filter` method. Indeed, we don't have any condition to express on any column. Instead, we just need to \"require that a book can be joined to its author\".\n\nSee [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record) below for the opposite question.\n\n\n### How do I filter records and only keep those that are NOT associated to another record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to only fetch anonymous books that do not have any author.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: TableRecord {\n    ...\n}\n```\n\nAnd then we can write our request and only fetch anonymous books that don't have any author:\n\n```swift\nlet books: [Book] = try dbQueue.read { db in\n    // SELECT book.* FROM book\n    // LEFT JOIN author ON author.id = book.authorID\n    // WHERE author.id IS NULL\n    let authorAlias = TableAlias<Author>()\n    let request = Book\n        .joining(optional: Book.author.aliased(authorAlias))\n        .filter(!authorAlias.exists)\n    return try request.fetchAll(db)\n}\n```\n\nThis request uses a TableAlias in order to be able to filter on the eventual associated author. We make sure that the `Author.primaryKey` is nil, which is another way to say it does not exist: the book has no author.\n\nSee [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record) above for the opposite question.\n\n\n### How do I select only one column of an associated record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to fetch all books with their author name, but not the full associated author records.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: Decodable, TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: Decodable, TableRecord {\n    ...\n    enum Columns {\n        static let name = Column(CodingKeys.name)\n    }\n}\n```\n\nAnd then we can write our request and the ad-hoc record that decodes it:\n\n```swift\nstruct BookInfo: Decodable, FetchableRecord {\n    var book: Book\n    var authorName: String? // nil when the book is anonymous\n    \n    static func all() -> QueryInterfaceRequest<BookInfo> {\n        // SELECT book.*, author.name AS authorName\n        // FROM book\n        // LEFT JOIN author ON author.id = book.authorID\n        return Book\n            .annotated(withOptional: Book.author.select { \n                $0.name.forKey(CodingKeys.authorName)\n            })\n            .asRequest(of: BookInfo.self)\n    }\n}\n\nlet bookInfos: [BookInfo] = try dbQueue.read { db in\n    BookInfo.all().fetchAll(db)\n}\n```\n\nBy defining the request as a static method of BookInfo, you have access to the private `CodingKeys.authorName`, and a compiler-checked SQL column name.\n\nBy using the `annotated(withOptional:)` method, you append the author name to the top-level selection that can be decoded by the ad-hoc record.\n\nBy using `asRequest(of:)`, you enhance the type-safety of your request.\n\n\n## FAQ: ValueObservation\n\n- :arrow_up: [FAQ]\n- [Why is ValueObservation not publishing value changes?](#why-is-valueobservation-not-publishing-value-changes)\n\n### Why is ValueObservation not publishing value changes?\n\nSometimes it looks that a [ValueObservation] does not notify the changes you expect.\n\nThere may be four possible reasons for this:\n\n1. The expected changes were not committed into the database.\n2. The expected changes were committed into the database, but were quickly overwritten.\n3. The observation was stopped.\n4. The observation does not track the expected database region.\n\nTo answer the first two questions, look at SQL statements executed by the database. This is done when you open the database connection:\n\n```swift\n// Prints all SQL statements\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace { print(\"SQL: \\($0)\") }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nIf, after that, you are convinced that the expected changes were committed into the database, and not overwritten soon after, trace observation events:\n\n```swift\nlet observation = ValueObservation\n    .tracking { db in ... }\n    .print() // <- trace observation events\nlet cancellable = observation.start(...)\n```\n\nLook at the observation logs which start with `cancel` or `failure`: maybe the observation was cancelled by your app, or did fail with an error.\n\nLook at the observation logs which start with `value`: make sure, again, that the expected value was not actually notified, then overwritten.\n\nFinally, look at the observation logs which start with `tracked region`. Does the printed database region cover the expected changes?\n\nFor example:\n\n- `empty`: The empty region, which tracks nothing and never triggers the observation.\n- `player(*)`: The full `player` table\n- `player(id,name)`: The `id` and `name` columns of the `player` table\n- `player(id,name)[1]`: The `id` and `name` columns of the row with id 1 in the `player` table\n- `player(*),team(*)`: Both the full `player` and `team` tables\n\nIf you happen to use the `ValueObservation.trackingConstantRegion(_:)` method and see a mismatch between the tracked region and your expectation, then change the definition of your observation by using `tracking(_:)`. You should witness that the logs which start with `tracked region` now evolve in order to include the expected changes, and that you get the expected notifications.\n\nIf after all those steps (thanks you!), your observation is still failing you, please [open an issue](https://github.com/groue/GRDB.swift/issues/new) and provide a [minimal reproducible example](https://stackoverflow.com/help/minimal-reproducible-example)!\n\n\n## FAQ: Errors\n\n- :arrow_up: [FAQ]\n- [Generic parameter 'T' could not be inferred](#generic-parameter-t-could-not-be-inferred)\n- [Mutation of captured var in concurrently-executing code](#mutation-of-captured-var-in-concurrently-executing-code)\n- [SQLite error 1 \"no such column\"](#sqlite-error-1-no-such-column)\n- [SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"](#sqlite-error-10-disk-io-error-sqlite-error-23-not-authorized)\n- [SQLite error 21 \"wrong number of statement arguments\" with LIKE queries](#sqlite-error-21-wrong-number-of-statement-arguments-with-like-queries)\n\n### Generic parameter 'T' could not be inferred\n    \nYou may get this error when using the `read` and `write` methods of database queues and pools:\n\n```swift\n// Generic parameter 'T' could not be inferred\nlet string = try dbQueue.read { db in\n    let result = try String.fetchOne(db, ...)\n    return result\n}\n```\n\nThis is a limitation of the Swift compiler.\n\nThe general workaround is to explicitly declare the type of the closure result:\n\n```swift\n// General Workaround\nlet string = try dbQueue.read { db -> String? in\n    let result = try String.fetchOne(db, ...)\n    return result\n}\n```\n\nYou can also, when possible, write a single-line closure:\n\n```swift\n// Single-line closure workaround:\nlet string = try dbQueue.read { db in\n    try String.fetchOne(db, ...)\n}\n```\n\n\n### Mutation of captured var in concurrently-executing code\n\nThe `insert` and `save` [persistence methods](#persistablerecord-protocol) can trigger a compiler error in async contexts:\n\n```swift\nvar player = Player(id: nil, name: \"Arthur\")\ntry await dbWriter.write { db in\n    // Error: Mutation of captured var 'player' in concurrently-executing code\n    try player.insert(db)\n}\nprint(player.id) // A non-nil id\n```\n\nWhen this happens, prefer the `inserted` and `saved` methods instead:\n\n```swift\n// OK\nvar player = Player(id: nil, name: \"Arthur\")\nplayer = try await dbWriter.write { [player] db in\n    return try player.inserted(db)\n}\nprint(player.id) // A non-nil id\n```\n\n\n### SQLite error 1 \"no such column\"\n\nThis error message is self-explanatory: do check for misspelled or non-existing column names.\n\nHowever, sometimes this error only happens when an app runs on a recent operating system (iOS 14+, Big Sur+, etc.) The error does not happen with previous ones.\n\nWhen this is the case, there are two possible explanations:\n\n1. Maybe a column name is *really* misspelled or missing from the database schema.\n    \n    To find it, check the SQL statement that comes with the [DatabaseError](#databaseerror).\n\n2. Maybe the application is using the character `\"` instead of the single quote `'` as the delimiter for string literals in raw SQL queries. Recent versions of SQLite have learned to tell about this deviation from the SQL standard, and this is why you are seeing this error. \n    \n    For example: this is not standard SQL: `UPDATE player SET name = \"Arthur\"`.\n    \n    The standard version is: `UPDATE player SET name = 'Arthur'`.\n    \n    It just happens that old versions of SQLite used to accept the former, non-standard version. Newer versions are able to reject it with an error.\n    \n    The fix is to change the SQL statements run by the application: replace `\"` with `'` in your string literals.\n    \n    It may also be time to learn about statement arguments and [SQL injection](#avoiding-sql-injection):\n    \n    ```swift\n    let name: String = ...\n    \n    // NOT STANDARD (double quote)\n    try db.execute(sql: \"\"\"\n        UPDATE player SET name = \"\\(name)\"\n        \"\"\")\n    \n    // STANDARD, BUT STILL NOT RECOMMENDED (single quote)\n    try db.execute(sql: \"UPDATE player SET name = '\\(name)'\")\n    \n    // STANDARD, AND RECOMMENDED (statement arguments)\n    try db.execute(sql: \"UPDATE player SET name = ?\", arguments: [name])\n    \n    // STANDARD, AND RECOMMENDED (SQL interpolation)\n    try db.execute(literal: \"UPDATE player SET name = \\(name)\")\n    ```\n    \nFor more information, see [Double-quoted String Literals Are Accepted](https://sqlite.org/quirks.html#double_quoted_string_literals_are_accepted), and [Configuration.acceptsDoubleQuotedStringLiterals](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration/acceptsdoublequotedstringliterals).\n    \n\n\n### SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"\n\nThose errors may be the sign that SQLite can't access the database due to [data protection](https://developer.apple.com/documentation/uikit/protecting_the_user_s_privacy/encrypting_your_app_s_files).\n\nWhen your application should be able to run in the background on a locked device, it has to catch this error, and, for example, wait for [UIApplicationDelegate.applicationProtectedDataDidBecomeAvailable(_:)](https://developer.apple.com/reference/uikit/uiapplicationdelegate/1623044-applicationprotecteddatadidbecom) or [UIApplicationProtectedDataDidBecomeAvailable](https://developer.apple.com/reference/uikit/uiapplicationprotecteddatadidbecomeavailable) notification and retry the failed database operation.\n\n```swift\ndo {\n    try ...\n} catch DatabaseError.SQLITE_IOERR, DatabaseError.SQLITE_AUTH {\n    // Handle possible data protection error\n}\n```\n\nThis error can also be prevented altogether by using a more relaxed [file protection](https://developer.apple.com/reference/foundation/filemanager/1653059-file_protection_values).\n\n\n### SQLite error 21 \"wrong number of statement arguments\" with LIKE queries\n\nYou may get the error \"wrong number of statement arguments\" when executing a LIKE query similar to:\n\n```swift\nlet name = textField.text\nlet players = try dbQueue.read { db in\n    try Player.fetchAll(db, sql: \"SELECT * FROM player WHERE name LIKE '%?%'\", arguments: [name])\n}\n```\n\nThe problem lies in the `'%?%'` pattern.\n\nSQLite only interprets `?` as a parameter when it is a placeholder for a whole value (int, double, string, blob, null). In this incorrect query, `?` is just a character in the `'%?%'` string: it is not a query parameter, and is not processed in any way. See [https://www.sqlite.org/lang_expr.html#varparam](https://www.sqlite.org/lang_expr.html#varparam) for more information about SQLite parameters.\n\nTo fix the error, you can feed the request with the pattern itself, instead of the name:\n\n```swift\nlet name = textField.text\nlet players: [Player] = try dbQueue.read { db in\n    let pattern = \"%\\(name)%\"\n    return try Player.fetchAll(db, sql: \"SELECT * FROM player WHERE name LIKE ?\", arguments: [pattern])\n}\n```\n\n\nSample Code\n===========\n\n- The [Documentation](#documentation) is full of GRDB snippets.\n- [Demo Applications]\n- Open `GRDB.xcworkspace`: it contains GRDB-enabled playgrounds to play with.\n- [groue/SortedDifference](https://github.com/groue/SortedDifference): How to synchronize a database table with a JSON payload\n\n\n---\n\n**Thanks**\n\n- [Pierlis](http://pierlis.com), where we write great software.\n- [@alextrob](https://github.com/alextrob), [@alexwlchan](https://github.com/alexwlchan), [@bellebethcooper](https://github.com/bellebethcooper), [@bfad](https://github.com/bfad), [@cfilipov](https://github.com/cfilipov), [@charlesmchen-signal](https://github.com/charlesmchen-signal), [@Chiliec](https://github.com/Chiliec), [@chrisballinger](https://github.com/chrisballinger), [@darrenclark](https://github.com/darrenclark), [@davidkraus](https://github.com/davidkraus), [@eburns-vmware](https://github.com/eburns-vmware), [@felixscheinost](https://github.com/felixscheinost), [@fpillet](https://github.com/fpillet), [@gcox](https://github.com/gcox), [@GetToSet](https://github.com/GetToSet), [@gjeck](https://github.com/gjeck), [@guidedways](https://github.com/guidedways), [@gusrota](https://github.com/gusrota), [@haikusw](https://github.com/haikusw), [@hartbit](https://github.com/hartbit), [@holsety](https://github.com/holsety), [@jroselightricks](https://github.com/jroselightricks), [@kdubb](https://github.com/kdubb), [@kluufger](https://github.com/kluufger), [@KyleLeneau](https://github.com/KyleLeneau), [@layoutSubviews](https://github.com/layoutSubviews), [@mallman](https://github.com/mallman), [@MartinP7r](https://github.com/MartinP7r), [@Marus](https://github.com/Marus), [@mattgallagher](https://github.com/mattgallagher), [@MaxDesiatov](https://github.com/MaxDesiatov), [@michaelkirk-signal](https://github.com/michaelkirk-signal), [@mtancock](https://github.com/mtancock), [@pakko972](https://github.com/pakko972), [@peter-ss](https://github.com/peter-ss), [@pierlo](https://github.com/pierlo), [@pocketpixels](https://github.com/pocketpixels), [@pp5x](https://github.com/pp5x), [@professordeng](https://github.com/professordeng), [@robcas3](https://github.com/robcas3), [@runhum](https://github.com/runhum), [@sberrevoets](https://github.com/sberrevoets), [@schveiguy](https://github.com/schveiguy), [@SD10](https://github.com/SD10), [@sobri909](https://github.com/sobri909), [@sroddy](https://github.com/sroddy), [@steipete](https://github.com/steipete), [@swiftlyfalling](https://github.com/swiftlyfalling), [@Timac](https://github.com/Timac), [@tternes](https://github.com/tternes), [@valexa](https://github.com/valexa), [@wuyuehyang](https://github.com/wuyuehyang), [@ZevEisenberg](https://github.com/ZevEisenberg), and [@zmeyc](https://github.com/zmeyc) for their contributions, help, and feedback on GRDB.\n- [@aymerick](https://github.com/aymerick) and [@kali](https://github.com/kali) because SQL.\n- [ccgus/fmdb](https://github.com/ccgus/fmdb) for its excellency.\n\n---\n\n[URIs don't change: people change them.](https://www.w3.org/Provider/Style/URI)\n\n#### Adding support for missing SQL functions or operators\n\nThis chapter was renamed to [Embedding SQL in Query Interface Requests].\n\n#### Advanced DatabasePool\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### After Commit Hook\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)).\n\n#### Asynchronous APIs\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Changes Tracking\n\nThis chapter has been renamed [Record Comparison].\n\n#### Concurrency\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Custom Value Types\n\nCustom Value Types conform to the [`DatabaseValueConvertible`] protocol.\n\n#### Customized Decoding of Database Rows\n\nThis chapter has been renamed [Beyond FetchableRecord].\n\n#### Customizing the Persistence Methods\n\nThis chapter was replaced with [Persistence Callbacks].\n\n#### Database Changes Observation\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseobservation).\n\n#### Database Configuration\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration).\n\n#### Database Queues\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue).\n\n#### Database Pools\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool).\n\n#### Database Snapshots\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### DatabaseWriter and DatabaseReader Protocols\n\nThis chapter was removed. See the references of [DatabaseReader](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasereader) and [DatabaseWriter](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasewriter).\n\n#### Date and UUID Coding Strategies\n\nThis chapter has been renamed [Data, Date, and UUID Coding Strategies].\n\n#### Dealing with External Connections\n\nThis chapter has been superseded by the [Sharing a Database] guide.\n\n#### Differences between Database Queues and Pools\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Enabling FTS5 Support\n\nFTS5 is enabled by default since GRDB 6.7.0.\n\n#### FetchedRecordsController\n\nFetchedRecordsController has been removed in GRDB 5.\n\nThe [Database Observation] chapter describes the other ways to observe the database.\n\n#### Full-Text Search\n\nThis chapter has [moved](Documentation/FullTextSearch.md).\n\n#### Guarantees and Rules\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Joined Queries Support\n\nThis chapter was replaced with the documentation of [splittingRowAdapters(columnCounts:)](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/splittingrowadapters(columncounts:)).\n\n#### List of Record Methods\n\nSee [Records and the Query Interface](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterface).\n\n#### Migrations\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/migrations).\n\n#### NSNumber and NSDecimalNumber\n\nThis chapter has [moved](#nsnumber-nsdecimalnumber-and-decimal).\n\n#### Persistable Protocol\n\nThis protocol has been renamed [PersistableRecord] in GRDB 3.0.\n\n#### PersistenceError\n\nThis error was renamed to [RecordError].\n\n#### Prepared Statements\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement).\n\n#### Record Class\n\nThe [`Record`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/record) class is a legacy GRDB type. Since GRDB 7, it is not recommended to define record types by subclassing the `Record` class.\n\n#### Row Adapters\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter).\n\n#### RowConvertible Protocol\n\nThis protocol has been renamed [FetchableRecord] in GRDB 3.0.\n\n#### TableMapping Protocol\n\nThis protocol has been renamed [TableRecord] in GRDB 3.0.\n\n#### Transactions and Savepoints\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactions).\n\n#### Transaction Hook\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)).\n\n#### TransactionObserver Protocol\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactionobserver).\n\n#### Unsafe Concurrency APIs\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### ValueObservation\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/valueobservation).\n\n#### ValueObservation and DatabaseRegionObservation\n\nThis chapter has been superseded by [ValueObservation] and [DatabaseRegionObservation].\n\n[Associations]: Documentation/AssociationsBasics.md\n[Beyond FetchableRecord]: #beyond-fetchablerecord\n[Identifiable Records]: #identifiable-records\n[Codable Records]: #codable-records\n[Columns Selected by a Request]: #columns-selected-by-a-request\n[common table expression]: Documentation/CommonTableExpressions.md\n[Common Table Expressions]: Documentation/CommonTableExpressions.md\n[Conflict Resolution]: #conflict-resolution\n[Column Names Coding Strategies]: #column-names-coding-strategies\n[Data, Date, and UUID Coding Strategies]: #data-date-and-uuid-coding-strategies\n[Fetching from Requests]: #fetching-from-requests\n[Embedding SQL in Query Interface Requests]: #embedding-sql-in-query-interface-requests\n[Full-Text Search]: Documentation/FullTextSearch.md\n[Migrations]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/migrations\n[The userInfo Dictionary]: #the-userinfo-dictionary\n[JSON Columns]: #json-columns\n[FetchableRecord]: #fetchablerecord-protocol\n[EncodableRecord]: #persistablerecord-protocol\n[PersistableRecord]: #persistablerecord-protocol\n[Record Comparison]: #record-comparison\n[Record Customization Options]: #record-customization-options\n[Persistence Callbacks]: #persistence-callbacks\n[persistence callbacks]: #persistence-callbacks\n[Record Timestamps and Transaction Date]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordtimestamps\n[TableRecord]: #tablerecord-protocol\n[ValueObservation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/valueobservation\n[DatabaseRegionObservation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseregionobservation\n[RxGRDB]: https://github.com/RxSwiftCommunity/RxGRDB\n[DatabaseRegion]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseregion\n[SQL Interpolation]: Documentation/SQLInterpolation.md\n[custom SQLite build]: Documentation/CustomSQLiteBuilds.md\n[Combine]: https://developer.apple.com/documentation/combine\n[Combine Support]: Documentation/Combine.md\n[Concurrency]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency\n[Demo Applications]: Documentation/DemoApps\n[Sharing a Database]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasesharing\n[FAQ]: #faq\n[Database Observation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseobservation\n[SQLRequest]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlrequest\n[SQL literal]: Documentation/SQLInterpolation.md#sql-literal\n[Identifiable]: https://developer.apple.com/documentation/swift/identifiable\n[Query Interface Organization]: Documentation/QueryInterfaceOrganization.md\n[Database Configuration]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration\n[Persistence Methods]: #persistence-methods\n[persistence methods]: #persistence-methods\n[Persistence Methods and the `RETURNING` clause]: #persistence-methods-and-the-returning-clause\n[RecordError]: #recorderror\n[RowDecodingError]: #rowdecodingerror\n[Transactions and Savepoints]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactions\n[`DatabaseQueue`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue\n[Database queues]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue\n[`DatabasePool`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool\n[database pools]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool\n[`DatabaseValueConvertible`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible\n[`StatementArguments`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments\n[Prepared Statements]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[prepared statements]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[`Statement`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[Database Connections]: #database-connections\n[Database connections]: #database-connections\n[database connection]: #database-connections\n",
      "stars_today": 2
    },
    {
      "id": 315822591,
      "name": "XcodesApp",
      "full_name": "XcodesOrg/XcodesApp",
      "description": "The easiest way to install and switch between multiple versions of Xcode - with a mouse click. ",
      "html_url": "https://github.com/XcodesOrg/XcodesApp",
      "stars": 8210,
      "forks": 363,
      "language": "Swift",
      "topics": [
        "combine",
        "hacktoberfest",
        "macos",
        "swift",
        "swiftui",
        "xcode",
        "xcode-releases"
      ],
      "created_at": "2020-11-25T03:51:02Z",
      "updated_at": "2026-01-22T16:10:35Z",
      "pushed_at": "2025-09-20T04:53:56Z",
      "open_issues": 193,
      "owner": {
        "login": "XcodesOrg",
        "avatar_url": "https://avatars.githubusercontent.com/u/96437613?v=4"
      },
      "readme": "<h1><img src=\"icon.png\" align=\"center\" width=50 height=50 /> <img src=\"IconDark.png\" align=\"center\" width=50 height=50 /> <img src=\"IconMono.png\" align=\"center\" width=50 height=50 /> Xcodes.app</h1>\n\nThe easiest way to install and switch between multiple versions of Xcode.\n\n_If you're looking for a command-line version of Xcodes.app, try [`xcodes`](https://github.com/XcodesOrg/xcodes)._\n\n![CI](https://github.com/XcodesOrg/XcodesApp/workflows/CI/badge.svg)\n\n![](screenshot_light.png#gh-light-mode-only)\n![](screenshot_dark.png#gh-dark-mode-only)\n\n### :tada: Announcement\n\nXcodesApp is now part of the `XcodesOrg` - [read more here](nextstep.md)\n\n## Features\n\n- List all available Xcode versions from [Xcode Releases'](https://xcodereleases.com) data or the Apple Developer website.\n- Install any Xcode version, **fully automated** from start to finish. Xcodes uses [`aria2`](https://aria2.github.io), which uses up to 16 connections to download 3-5x faster than URLSession.\n- Automatically resumes installs if network errors.\n- Apple ID required to download Xcode versions.\n- Just click a button to make a version active with `xcode-select`.\n- View release notes, OS compatibility, included SDKs and compilers from [Xcode Releases](https://xcodereleases.com).\n- Dark/Light Mode supported\n- Security Key Authentication supported \n- Support installing Platforms/Runtimes\n- Support installing Apple Silicon variants\n\n## Platforms/Runtimes\n\n- Xcodes supports downloading the Apple runtimes via the app. Simply click on the Platform, and Xcodes will install automatically for you.\n\n**Note: iOS 18+, tvOS 18+, watchOS 11+, visionOS 2+ requires that Xcode 16.1 Beta 3+ be installed and active.** \n\n## Apple Silicon Variants\n\nAs of Xcode 26, Apple provides Apple Silicon as well as Universal variants for Xcode versions as well as each runtime. Simply tap on which variant you want installed. To install the Apple Silicon runtime variant Xcode 26 is required to be active.\n\n## Experiments\n\n- Thanks to the wonderful work of [https://github.com/saagarjha/unxip](https://github.com/saagarjha/unxip), turn on the experiment to increase your unxipping time by up to 70%! More can be found on his repo, but bugs, high memory may occur if used.\n\n![](experiment_light.png#gh-light-mode-only)\n![](experiment_dark.png#gh-dark-mode-only)\n\n## Localization\n\nXcodes supports localization in several languages.\n\nThe following languages are supported because of the following community users!\n\n|||||\n|-|-|-|-|\n|French üá´üá∑ |[@dompepin](https://github.com/dompepin)|Italian üáÆüáπ |[gualtierofrigerio](https://github.com/gualtierofrigerio)|\n|Spanish üá™üá∏üá≤ |[@cesartru88](https://github.com/cesartru88)|Korean üá∞üá∑ |[@ryan-son](https://github.com/ryan-son)|\n|Russian üá∑üá∫ |[@alexmazlov](https://github.com/alexmazlov)|Turkish üáπüá∑ |[@egesucu](https://github.com/egesucu)|\n|Hindi üáÆüá≥ |[@KGurpreet](https://github.com/KGurpreet)|Chinese-Simplified üá®üá≥|[@megabitsenmzq](https://github.com/megabitsenmzq)|\n|Finnish üá´üáÆ |[@marcusziade](https://github.com/marcusziade)|Chinese-Traditional üáπüáº|[@itszero](https://github.com/itszero)|\n|Ukranian üá∫üá¶ |[@gelosi](https://github.com/gelosi)|Japanese üáØüáµ|[@tatsuz0u](https://github.com/tatsuz0u)|\n|German üá©üá™|[@drct](https://github.com/drct)|Dutch üá≥üá±|[@jfversluis](https://github/com/jfversluis)|\n|Brazilian Portuguese üáßüá∑|[@brunomunizaf](https://github.com/brunomunizaf)|Polish üáµüá±|[@jakex7](https://github.com/jakex7)|\n|Catalan|[@ferranabello](https://github.com/ferranabello)|Greek üá¨üá∑|[@alladinian](https://github.com/alladinian)\n|Thai üáπüá≠|[@neetrath](https://github.com/neetrath)|\n\nWant to add more languages? Simply create a PR with the updated strings file.\n\n## Installation\nv1.X - requires macOS 11 or newer\nv2.X - requires macOS 13\nv3.X - requires macOS 13 - architecture variants and updated icon.\n\n### Install with Homebrew\n\nDeveloper ID-signed and notarized release builds are available on Homebrew. These don't require Xcode to already be installed in order to use.\n\n```sh\nbrew install --cask xcodes\n```\n\n### Manually install\n\n1. Download the latest version [here](https://github.com/XcodesOrg/XcodesApp/releases/latest) using the **Xcodes.zip** asset. These are Developer ID-signed and notarized release builds and don't require Xcode to already be installed in order to use.\n2. Move the unzipped `Xcodes.app` to your `/Applications` directory\n\n## Support\n\nXcodes.app and CLI is updated, maintained with contributors like yourself. Even open source libraries and tools come with expenses. If you would like to support Xcodes or donate to the development and maintenance of the tool, it would be greatly appreciated. There is absolutely no obligation!\n\n<a href=\"https://opencollective.com/xcodesapp\" target=\"_blank\">\n\t\t\t\t<img src=\"https://opencollective.com/xcodesapp/donate/button@2x.png?color=blue\" class=\"buymeacoffee\" width=200 />\n</a>\n\n## Development\n\nYou'll need macOS 15.6 Ventura and Xcode 26 in order to build and run Xcodes.app.\n\n`Unxip` and `aria2` must be compiled as a universal binary\n```\n# compile for Intel\n swiftc -parse-as-library -O -target x86_64-apple-macos11 unxip.swift\n# compile for M1\n swiftc -parse-as-library -O -target arm64-apple-macos11 unxip.swift\n\n# combine for universal binary\n lipo -create -output unxip unxip_intel unxip_m1  \n# check it\n lipo -archs unxip\n```\n\n\n[`xcode-install`](https://github.com/xcpretty/xcode-install) and [fastlane/spaceship](https://github.com/fastlane/fastlane/tree/master/spaceship) both deserve credit for figuring out the hard parts of what makes this possible.\n\n\n<details>\n<summary>Releasing a new version</summary>\n\nFollow the steps below to build and release a new version of Xcodes.app. For any of the git steps, you can use your preferred tool, but please sign the tag.\n\n```sh\n# Update the version number in Xcode and commit the change, if necessary\n\n# Question: Did anything in XPCHelper change?\n# - com.xcodesorg.xcodesapp.Helper folder and HelperXPCShared\n# - if so, bump the version number in com.xcodesorg.xcodesapp.Helper target.\n# Note: you do not have to bump the version number if nothing has changed.\n# Note2: If you do bump the version, the end user, must re-install the XPCHelper and give permission again.\n\n# Increment the build number\nscripts/increment_build_number.sh\n\n# Commit the change\ngit add Xcodes/Resources/Info.plist\ngit commit -asm \"Increment build number\"\n\n# Tag the latest commit\n# Replace $VERSION and $BUILD below with the latest real values\ngit tag -asm \"v$VERSIONb$BUILD\" \"v$VERSIONb$BUILD\"\n\n# Push to origin\ngit push --follow-tags\n\n# Build the app\n# Make sure you have the Xcode Selected you want to build with\nscripts/package_release.sh\n\n# Notarize the app\n# Do this from the Product directory so the app is zipped without being nested inside Product\n# Create a app specific password on appleid.apple.com if you haven't already\n# xcrun notarytool store-credentials \"AC_PASSWORD\" \\\n#              --apple-id \"test@example.com\" \\\n#              --team-id \"teamid\" \\\n#               --password \"app specific password\"\n\npushd Product\n../scripts/notarize.sh Xcodes.zip <MYORG>\n\n# Sign the .zip for Sparkle, note the signature in the output for later\n# If you're warned about the signing key not being found, see the Xcodes 1Password vault for the key and installation instructions.\n../scripts/sign_update Xcodes.zip\npopd\n\n# Go to https://github.com/XcodesOrg/XcodesApp/releases\n# If there are uncategorized PRs, add the appropriate label and run the Release Drafter action manually\n# Edit the latest draft release\n# Set its tag to the tag you just pushed\n# Set its title to a string with the format \"$VERSION ($BUILD)\"\n# Polish the draft release notes, if necessary\n# Add the signature to the bottom of the release notes in a comment, like:\n<!-- sparkle:edSignature=$SIGNATURE -->\n# Attach the zip that was created in the Product directory to the release\n# Publish the release\n\nshasum -a 256 xcodes.zip\n# Update the [Homebrew Cask](https://github.com/XcodesOrg/homebrew-cask/blob/master/Casks/x/xcodes.rb).\n```\n</details>\n\n## Maintainers\n\n[Matt Kiazyk](https://github.com/mattkiazyk) - [Twitter](https://www.twitter.com/mattkiazyk)\n\n[Twitter](https://twitter.com/xcodesApp) | [GitHub](https://github.com/xcodesOrg) | [Mastadon](https://iosdev.space/@XcodesApp) |\n",
      "stars_today": 2
    },
    {
      "id": 170738310,
      "name": "wallet-core",
      "full_name": "trustwallet/wallet-core",
      "description": "Cross-platform, cross-blockchain wallet library.",
      "html_url": "https://github.com/trustwallet/wallet-core",
      "stars": 3431,
      "forks": 1899,
      "language": "C++",
      "topics": [
        "bitcoin",
        "blockchain",
        "cross-platform",
        "crypto",
        "cryptocurrency",
        "ethereum"
      ],
      "created_at": "2019-02-14T18:25:54Z",
      "updated_at": "2026-01-22T22:48:59Z",
      "pushed_at": "2026-01-22T16:40:06Z",
      "open_issues": 78,
      "owner": {
        "login": "trustwallet",
        "avatar_url": "https://avatars.githubusercontent.com/u/32179889?v=4"
      },
      "readme": "<img src=\"docs/banner.png\" align=\"center\" title=\"Trust logo\">\n\nTrust Wallet Core is an open-source, cross-platform, mobile-focused library\nimplementing low-level cryptographic wallet functionality for a high number of blockchains.\nIt is a core part of the popular [Trust Wallet](https://trustwallet.com), and some other projects.\nMost of the code is C++ with a set of strict C interfaces, and idiomatic interfaces for supported languages:\nSwift for iOS and Java (Kotlin) for Android.\n\n[![iOS CI](https://github.com/trustwallet/wallet-core/actions/workflows/ios-ci.yml/badge.svg)](https://github.com/trustwallet/wallet-core/actions/workflows/ios-ci.yml)\n[![Android CI](https://github.com/trustwallet/wallet-core/actions/workflows/android-ci.yml/badge.svg)](https://github.com/trustwallet/wallet-core/actions/workflows/android-ci.yml)\n[![Linux CI](https://github.com/trustwallet/wallet-core/actions/workflows/linux-ci.yml/badge.svg)](https://github.com/trustwallet/wallet-core/actions/workflows/linux-ci.yml)\n[![Rust CI](https://github.com/trustwallet/wallet-core/actions/workflows/linux-ci-rust.yml/badge.svg)](https://github.com/trustwallet/wallet-core/actions/workflows/linux-ci-rust.yml)\n[![Wasm CI](https://github.com/trustwallet/wallet-core/actions/workflows/wasm-ci.yml/badge.svg)](https://github.com/trustwallet/wallet-core/actions/workflows/wasm-ci.yml)\n[![Kotlin CI](https://github.com/trustwallet/wallet-core/actions/workflows/kotlin-ci.yml/badge.svg)](https://github.com/trustwallet/wallet-core/actions/workflows/kotlin-ci.yml)\n[![Docker CI](https://github.com/trustwallet/wallet-core/actions/workflows/docker.yml/badge.svg)](https://github.com/trustwallet/wallet-core/actions/workflows/docker.yml)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=TrustWallet_wallet-core&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=TrustWallet_wallet-core)\n\n[![Gitpod Ready-to-Code](https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod)](https://gitpod.io/#https://github.com/trustwallet/wallet-core)\n![GitHub](https://img.shields.io/github/license/TrustWallet/wallet-core.svg)\n![GitHub release (latest by date)](https://img.shields.io/github/v/release/trustwallet/wallet-core)\n![SPM](https://img.shields.io/badge/SPM-ready-blue)\n![Cocoapods](https://img.shields.io/cocoapods/v/TrustWalletCore.svg)\n\n# Documentation\n\nFor comprehensive documentation, see [developer.trustwallet.com](https://developer.trustwallet.com/wallet-core).\n\n# Audit Reports\n\nSecurity Audit reports can be found in the [audit](audit) directory.\n\n# Supported Blockchains\n\nWallet Core supports more than **130** blockchains: Bitcoin, Ethereum, BNB, Cosmos, Solana, and most major blockchain platforms.\nThe full list is [here](docs/registry.md).\n\n# Building\n\nFor build instructions, see [developer.trustwallet.com/wallet-core/building](https://developer.trustwallet.com/wallet-core/building).\n\n\n# Using from your project\n\nIf you want to use wallet core in your project follow these instructions.\n\n## Android\n\nAndroid releases are hosted on [GitHub packages](https://github.com/trustwallet/wallet-core/packages/700258), you need to add GitHub access token to install it. Please check out [this installation guide](https://developer.trustwallet.com/wallet-core/integration-guide/android-guide#adding-library-dependency) or `build.gradle` from our [android sample](https://github.com/trustwallet/wallet-core/blob/master/samples/android/build.gradle)\n\nDon't forget replacing the version in the code with latest: ![GitHub release (latest by date)](https://img.shields.io/github/v/release/trustwallet/wallet-core)\n\n## iOS\n\nWe currently support Swift Package Manager and CocoaPods (will discontinue in the future).\n\n### SPM\n\nDownload latest `Package.swift` from [GitHub Releases](https://github.com/trustwallet/wallet-core/releases) and put it in a local `WalletCore` folder.\n\nAdd this line to the `dependencies` parameter in your `Package.swift`:\n\n```swift\n.package(name: \"WalletCore\", path: \"../WalletCore\"),\n```\n\nOr add remote url + `master` branch, it points to recent (not always latest) binary release.\n\n```swift\n.package(name: \"WalletCore\", url: \"https://github.com/trustwallet/wallet-core\", .branchItem(\"master\")),\n```\n\nThen add libraries to target's `dependencies`:\n\n```swift\n.product(name: \"WalletCore\", package: \"WalletCore\"),\n.product(name: \"WalletCoreSwiftProtobuf\", package: \"WalletCore\"),\n```\n\n### CocoaPods\n\nAdd this line to your Podfile and run `pod install`:\n\n```ruby\npod 'TrustWalletCore'\n```\n\n## NPM (beta)\n\n```js\nnpm install @trustwallet/wallet-core\n```\n\n## Go (beta)\n\nPlease check out the [Go integration sample](https://github.com/trustwallet/wallet-core/tree/master/samples/go).\n\n## Kotlin Multipleplatform (beta)\n\nPlease check out the [Kotlin Multiplatform sample](https://github.com/trustwallet/wallet-core/tree/master/samples/kmp)\n\n# Projects\n\nProjects using Trust Wallet Core. Add yours too!\n\n[<img src=\"https://trustwallet.com/icon.svg\" alt=\"Trust Wallet\"/>](https://trustwallet.com)\n\n[Coinpaprika](https://coinpaprika.com/)\n| [crypto.com](https://crypto.com)\n| [Frontier](https://frontier.xyz/)\n| [Tokenary](https://tokenary.io/)\n| [MemesWallet](https://planetmemes.com/)\n| [xPortal](https://xportal.com/)\n| [Slingshot](https://slingshot.finance/)\n| [ECOIN Wallet](https://play.google.com/store/apps/details?id=org.ecoinwallet&pcampaignid=web_share)\n\n# Community\n\nThere are a few community-maintained projects that extend Wallet Core to some additional platforms and languages. Note this is not an endorsement, please do your own research before using them:\n\n- Flutter binding https://github.com/weishirongzhen/flutter_trust_wallet_core\n- Python binding https://github.com/phuang/wallet-core-python\n- Wallet Core on Windows https://github.com/kaetemi/wallet-core-windows\n\n# Contributing\n\nThe best way to submit feedback and report bugs related to WalletCore is to [open a GitHub issue](https://github.com/trustwallet/wallet-core/issues/new).\nIf the bug is not related to WalletCore but to the TrustWallet app, please [create a Customer Support ticket](https://support.trustwallet.com/en/support/tickets/new).\nIf you want to contribute code please see [Contributing](https://developer.trustwallet.com/wallet-core/contributing).\nIf you want to add support for a new blockchain also see [Adding Support for a New Blockchain](https://developer.trustwallet.com/wallet-core/newblockchain), make sure you have read the [requirements](https://developer.trustwallet.com/wallet-core/newblockchain#requirements) section.\n\nThanks to all the people who contribute.\n<a href=\"https://github.com/trustwallet/wallet-core/graphs/contributors\"><img src=\"https://opencollective.com/wallet-core/contributors.svg?width=890&button=false\" /></a>\n\n# Disclaimer\n\nThe Wallet Core project is led and managed by Trust Wallet with a large contributor community and actively used in several projects.  Our goal at Wallet Core is to give other wallets an easy way to add chain support.\n\nTrust Wallet products leverage wallet core, however, they may or may not leverage all the capabilities, features, and assets available in wallet core due to their own product requirements.\n\n# License\n\nTrust Wallet Core is available under the Apache 2.0 license. See the [LICENSE](LICENSE) file for more info.\n",
      "stars_today": 2
    },
    {
      "id": 143079594,
      "name": "swift-syntax",
      "full_name": "swiftlang/swift-syntax",
      "description": "A set of Swift libraries for parsing, inspecting, generating, and transforming Swift source code.",
      "html_url": "https://github.com/swiftlang/swift-syntax",
      "stars": 3602,
      "forks": 485,
      "language": "Swift",
      "topics": [],
      "created_at": "2018-07-31T23:19:58Z",
      "updated_at": "2026-01-22T06:07:24Z",
      "pushed_at": "2026-01-22T06:08:27Z",
      "open_issues": 152,
      "owner": {
        "login": "swiftlang",
        "avatar_url": "https://avatars.githubusercontent.com/u/42816656?v=4"
      },
      "readme": "# Swift Syntax\n\nThe swift-syntax package is a set of libraries that work on a source-accurate tree representation of Swift source code, called the SwiftSyntax tree. The SwiftSyntax tree forms the backbone of Swift‚Äôs macro system ‚Äì the macro expansion nodes are represented as SwiftSyntax nodes and a macro generates a SwiftSyntax tree to be inserted into the source file.\n\n## Documentation\n\nYou can read SwiftSyntax‚Äôs documentation on [swiftpackageindex.com](https://swiftpackageindex.com/swiftlang/swift-syntax/documentation).\n\nA great way to interactively explore the SwiftSyntax tree of a source file is https://swift-ast-explorer.com, developed by [@kishikawakatsumi](https://github.com/kishikawakatsumi).\n\nA set of example usages of swift-syntax can be found in [Examples](Examples).\n\n## Releases\n\nReleases of SwiftSyntax are aligned with corresponding language and tooling releases, for example the major version 509 of swift-syntax is aligned with Swift 5.9. \n \nTo depend on swift-syntax in a SwiftPM package, add the following to your `Package.swift`.\n\n\n```swift\ndependencies: [\n  .package(url: \"https://github.com/swiftlang/swift-syntax.git\", from: \"<#latest swift-syntax tag#>\"),\n],\n```\n \nTo add swift-syntax as a dependency of your Xcode project, go to the *Package Dependencies* tab of your Xcode project, click the plus button and search for https://github.com/swiftlang/swift-syntax.git.\n\n## Reporting Issues\n\nIf you should hit any issues while using SwiftSyntax, we appreciate bug reports on [GitHub Issue](https://github.com/swiftlang/swift-syntax/issues).\n\n## Contributing\n\nStart contributing to SwiftSyntax see [this guide](CONTRIBUTING.md) for more information.\n\n## Bazel\n\nSwiftSyntax provides an experimental [Bazel](https://bazel.build) build configuration, maintained by Keith Smiley. \nTo use it, you can pull the source archive from the relevant release tag\ninto your `MODULE.bazel` file (preferred and recommended) with `bazel_dep`. Bzlmod support was added starting release of `509.0.0` and above. All available versions can be found in the [Bazel Central Registry](https://registry.bazel.build/modules/swift-syntax)\n\n```python3\nbazel_dep(name = \"swift-syntax\", version = \"600.0.1\")\n```\n\nYou can also pull source archive with `WORKSPACE` but note that it is preferred to use `MODULE.bazel`. To use `WORKSPACE` and swift-syntax, you can use `http_archive` as such\n\n```python3\nhttp_archive(\n    name = \"SwiftSyntax\",\n    sha256 = \"f070fd44db9b33f430fd5b5d2700f1e2001c0028711859600e80cc975074fab0\",\n    strip_prefix = \"swift-syntax-509.1.0\",\n    url = \"https://github.com/apple/swift-syntax/archive/refs/tags/509.1.0.tar.gz\",\n)\n```\n\nand depend on the libraries you need from the\n[`BUILD.bazel`](BUILD.bazel) file. Each library also has an associated\n`Library_opt` target (such as `SwiftSyntax_opt`) which forces\nSwiftSyntax to always build with optimizations enabled. This may help\nlocal runtime performance at the cost of debuggability, and initial\nbuild time. Please tag any [issues](https://github.com/swiftlang/swift-syntax/issues) related to the Bazel configuration with the label \"Bazel\".\n\n## License\n\nPlease see [LICENSE](LICENSE.txt) for more information.\n",
      "stars_today": 2
    },
    {
      "id": 131297762,
      "name": "wireguard-android",
      "full_name": "WireGuard/wireguard-android",
      "description": "Mirror only. Official repository is at https://git.zx2c4.com/wireguard-android",
      "html_url": "https://github.com/WireGuard/wireguard-android",
      "stars": 1372,
      "forks": 481,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2018-04-27T13:07:23Z",
      "updated_at": "2026-01-22T16:31:35Z",
      "pushed_at": "2026-01-02T02:37:30Z",
      "open_issues": 8,
      "owner": {
        "login": "WireGuard",
        "avatar_url": "https://avatars.githubusercontent.com/u/13991055?v=4"
      },
      "readme": "# Android GUI for [WireGuard](https://www.wireguard.com/)\n\n**[Download from the Play Store](https://play.google.com/store/apps/details?id=com.wireguard.android)**\n\nThis is an Android GUI for [WireGuard](https://www.wireguard.com/). It [opportunistically uses the kernel implementation](https://git.zx2c4.com/android_kernel_wireguard/about/), and falls back to using the non-root [userspace implementation](https://git.zx2c4.com/wireguard-go/about/).\n\n## Building\n\n```\n$ git clone --recurse-submodules https://git.zx2c4.com/wireguard-android\n$ cd wireguard-android\n$ ./gradlew assembleRelease\n```\n\nmacOS users may need [flock(1)](https://github.com/discoteq/flock).\n\n## Embedding\n\nThe tunnel library is [on Maven Central](https://search.maven.org/artifact/com.wireguard.android/tunnel), alongside [extensive class library documentation](https://javadoc.io/doc/com.wireguard.android/tunnel).\n\n```\nimplementation 'com.wireguard.android:tunnel:$wireguardTunnelVersion'\n```\n\nThe library makes use of Java 8 features, so be sure to support those in your gradle configuration with [desugaring](https://developer.android.com/studio/write/java8-support#library-desugaring):\n\n```\ncompileOptions {\n    sourceCompatibility JavaVersion.VERSION_17\n    targetCompatibility JavaVersion.VERSION_17\n    coreLibraryDesugaringEnabled = true\n}\ndependencies {\n    coreLibraryDesugaring \"com.android.tools:desugar_jdk_libs:2.0.3\"\n}\n```\n\n## Translating\n\nPlease help us translate the app into several languages on [our translation platform](https://crowdin.com/project/WireGuard).\n",
      "stars_today": 2
    },
    {
      "id": 369991603,
      "name": "supabase-swift",
      "full_name": "supabase/supabase-swift",
      "description": "A Swift SDK for Supabase. Query your Supabase database, subscribe to realtime events, upload and download files, browse Swift examples, invoke postgres functions via rpc, invoke supabase edge functions, query pgvector. ",
      "html_url": "https://github.com/supabase/supabase-swift",
      "stars": 1156,
      "forks": 223,
      "language": "Swift",
      "topics": [
        "database",
        "ios",
        "supabase",
        "swift"
      ],
      "created_at": "2021-05-23T07:46:26Z",
      "updated_at": "2026-01-23T01:44:46Z",
      "pushed_at": "2026-01-22T12:02:27Z",
      "open_issues": 27,
      "owner": {
        "login": "supabase",
        "avatar_url": "https://avatars.githubusercontent.com/u/54469796?v=4"
      },
      "readme": "# supabase-swift\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fsupabase%2Fsupabase-swift%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/supabase/supabase-swift)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fsupabase%2Fsupabase-swift%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/supabase/supabase-swift)\n[![Coverage Status](https://coveralls.io/repos/github/supabase/supabase-swift/badge.svg?branch=main)](https://coveralls.io/github/supabase/supabase-swift?branch=main)\n\nSupabase SDK for Swift. Mirrors the design of [supabase-js](https://github.com/supabase/supabase-js/blob/master/README.md).\n\n* Documentation: [https://supabase.com/docs/reference/swift/introduction](https://supabase.com/docs/reference/swift/introduction)\n\n## Usage\n\n### Requirements\n- iOS 13.0+ / macOS 10.15+ / tvOS 13+ / watchOS 6+ / visionOS 1+\n- Xcode 15.3+\n- Swift 5.10+\n\n> [!IMPORTANT]\n> Check the [Support Policy](#support-policy) to learn when dropping Xcode, Swift, and platform versions will not be considered a **breaking change**.\n\n### Installation\nInstall the library using the Swift Package Manager.\n\n```swift\nlet package = Package(\n    ...\n    dependencies: [\n        ...\n        .package(\n            url: \"https://github.com/supabase/supabase-swift.git\",\n            from: \"2.0.0\"\n        ),\n    ],\n    targets: [\n        .target(\n            name: \"YourTargetName\",\n            dependencies: [\n                .product(name: \"Supabase\", package: \"supabase-swift\") // Add as a dependency\n            ]\n        )\n    ]\n)\n```\n\nIf you're using Xcode, [use this guide](https://developer.apple.com/documentation/swift_packages/adding_package_dependencies_to_your_app) to add `supabase-swift` to your project. Use `https://github.com/supabase-community/supabase-swift.git` for the url when Xcode asks.\n\nIf you don't want the full Supabase environment, you can also add individual packages, such as `Functions`, `Auth`, `Realtime`, `Storage`, or `PostgREST`.\n\nThen you're able to import the package and establish the connection with the database.\n\n```swift\n/// Create a single supabase client for interacting with your database\nlet client = SupabaseClient(\n    supabaseURL: URL(string: \"https://xyzcompany.supabase.co\")!,\n    supabaseKey: \"public-anon-key\"\n)\n```\n\n### Initialize with custom options\n\n```swift\nlet client = SupabaseClient(\n    supabaseURL: URL(string: \"https://xyzcompany.supabase.co\")!, \n    supabaseKey: \"public-anon-key\",\n    options: SupabaseClientOptions(\n        db: .init(\n            schema: \"public\"\n        ),\n        auth: .init(\n            storage: MyCustomLocalStorage(),\n            flowType: .pkce\n        ),\n        global: .init(\n            headers: [\"x-my-custom-header\": \"my-app-name\"],\n            session: URLSession.myCustomSession\n        )\n    )\n)\n```\n\nAdditional examples are available [here](https://github.com/supabase/supabase-swift/tree/main/Examples).\n\n## Support Policy\n\nThis document outlines the scope of support for Xcode, Swift, and the various platforms (iOS, macOS, tvOS, watchOS, and visionOS) in Supabase.\n\n### Xcode\nWe only support Xcode versions that are currently eligible for submitting apps to the App Store. Once a specific version of Xcode is no longer supported, its removal from Supabase **won't be treated as a breaking change** and will occur in a minor release.\n\n### Swift\nThe minimum supported Swift version corresponds to the minor version released with the oldest-supported Xcode version. When a Swift version reaches its end of support, it will be dropped from Supabase in a **minor release**, and **this won't be considered a breaking change**.\n\n### Platforms\nWe maintain support for the four latest major versions of each platform, including the current version.\n\nWhen a platform version is no longer supported, Supabase will drop it in a **minor release**, and **this won't count as a breaking change**. For instance, iOS 14 will no longer be supported after the release of iOS 18, allowing its removal in a minor update.\n\nFor macOS, the named yearly releases are treated as major versions for this policy, regardless of their version numbers.\n\n> [!IMPORTANT]\n> Android, Linux and Windows works but aren't supported, and may stop working on future versions of the library.\n\n## Contributing\n\n- Fork the repo on GitHub\n- Clone the project to your own machine\n- Commit changes to your own branch\n- Push your work back up to your fork\n- Submit a Pull request so that we can review your changes and merge\n\n## Sponsors\n\nWe are building the features of Firebase using enterprise-grade, open source products. We support existing communities wherever possible, and if the products don‚Äôt exist we build them and open source them ourselves. Thanks to these sponsors who are making the OSS ecosystem better for everyone.\n\n[![New Sponsor](https://user-images.githubusercontent.com/10214025/90518111-e74bbb00-e198-11ea-8f88-c9e3c1aa4b5b.png)](https://github.com/sponsors/supabase)\n",
      "stars_today": 2
    },
    {
      "id": 32578467,
      "name": "Charts",
      "full_name": "ChartsOrg/Charts",
      "description": "Beautiful charts for iOS/tvOS/OSX! The Apple side of the crossplatform MPAndroidChart.",
      "html_url": "https://github.com/ChartsOrg/Charts",
      "stars": 28008,
      "forks": 6042,
      "language": "Swift",
      "topics": [],
      "created_at": "2015-03-20T10:49:12Z",
      "updated_at": "2026-01-22T01:05:45Z",
      "pushed_at": "2025-05-13T04:45:38Z",
      "open_issues": 991,
      "owner": {
        "login": "ChartsOrg",
        "avatar_url": "https://avatars.githubusercontent.com/u/79675592?v=4"
      },
      "readme": "**Version 4.0.0**, synced to [MPAndroidChart #f6a398b](https://github.com/PhilJay/MPAndroidChart/commit/f6a398b)\n\n![alt tag](https://raw.github.com/danielgindi/Charts/master/Assets/feature_graphic.png)\n![Supported Platforms](https://img.shields.io/cocoapods/p/Charts.svg) [![Releases](https://img.shields.io/github/release/danielgindi/Charts.svg)](https://github.com/danielgindi/Charts/releases) [![Latest pod release](https://img.shields.io/cocoapods/v/Charts.svg)](http://cocoapods.org/pods/charts) [![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage) [![Build Status](https://travis-ci.org/danielgindi/Charts.svg?branch=master)](https://travis-ci.org/danielgindi/Charts) [![codecov](https://codecov.io/gh/danielgindi/Charts/branch/master/graph/badge.svg)](https://codecov.io/gh/danielgindi/Charts)\n[![Join the chat at https://gitter.im/danielgindi/Charts](https://badges.gitter.im/danielgindi/Charts.svg)](https://gitter.im/danielgindi/Charts?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n### Just a heads up: Charts 5.0 has some breaking changes. Charts has now been renamed DGCharts to prevent conflicts with Apple's new Swift Charts. Please read [the release/migration notes](https://github.com/danielgindi/Charts/releases/tag/5.0.0).\n\n### One more heads up: As Swift evolves, if you are not using the latest Swift compiler, you shouldn't check out the master branch. Instead, you should go to the release page and pick up whatever suits you.\n\n- Xcode 14 / Swift 5.7 (master branch)\n- iOS >= 12.0 (Use as an **Embedded** Framework)\n- tvOS >= 12.0\n- macOS >= 10.13\n\nOkay so there's this beautiful library called [MPAndroidChart](https://github.com/PhilJay/MPAndroidChart) by [Philipp Jahoda](https://www.linkedin.com/in/philippjahoda) which has become very popular amongst Android developers, but there was no decent solution to create charts for iOS.\n\nI've chosen to write it in `Swift` as it can be highly optimized by the compiler, and can be used in both `Swift` and `ObjC` project. The demo project is written in `ObjC` to demonstrate how it works.\n\n**An amazing feature** of this library now, for Android, iOS, tvOS and macOS, is the time it saves you when developing for both platforms, as the learning curve is singleton- it happens only once, and the code stays very similar so developers don't have to go around and re-invent the app to produce the same output with a different library. (And that's not even considering the fact that there's not really another good choice out there currently...)\n\n## Having trouble running the demo?\n\n- `ChartsDemo/ChartsDemo.xcodeproj` is the demo project for iOS/tvOS\n- `ChartsDemo-OSX/ChartsDemo-OSX.xcodeproj` is the demo project for macOS\n- Make sure you are running a supported version of Xcode.\n  - Usually it is specified here a few lines above.\n  - In most cases it will be the latest Xcode version.\n- Make sure that your project supports Swift 5.0\n- Optional: Run `carthage checkout` in the project folder, to fetch dependencies (i.e testing dependencies).\n  - If you don't have Carthage - you can get it [here](https://github.com/Carthage/Carthage/releases).\n\n## Usage\n\nIn order to correctly compile:\n\n1. Drag the `DGCharts.xcodeproj` to your project\n2. Go to your target's settings, hit the \"+\" under the \"Frameworks, Libraries, and Embedded Content\" section, and select the DGCharts.framework\n3. `@import DGCharts`\n4. When using Swift in an ObjC project:\n\n- You need to import your Bridging Header. Usually it is \"_YourProject-Swift.h_\", so in ChartsDemo it's \"_ChartsDemo-Swift.h_\". Do not try to actually include \"_ChartsDemo-Swift.h_\" in your project :-)\n- (Xcode 8.1 and earlier) Under \"Build Options\", mark \"Embedded Content Contains Swift Code\"\n- (Xcode 8.2+) Under \"Build Options\", mark \"Always Embed Swift Standard Libraries\"\n\n5. When using [Realm.io](https://realm.io/):\n   - Note that the Realm framework is not linked with Charts - it is only there for _optional_ bindings. Which means that you need to have the framework in your project, and in a compatible version to whatever is compiled with DGCharts. We will do our best to always compile against the latest version.\n   - You'll need to add `ChartsRealm` as a dependency too.\n\n## 3rd party tutorials\n\n#### Video tutorials\n\n- [Chart in Swift - Setting Up a Basic Line Chart Using iOS Charts(Alex Nagy)](https://www.youtube.com/watch?v=mWhwe_tLNE8&list=PL_csAAO9PQ8bjzg-wxEff1Fr0Y5W1hrum&index=5)\n- [Charts Framework in SwiftUI - Bar Chart (Stewart Lynch)](https://youtu.be/csd7pyfEXgw)\n\n#### Blog posts\n\n- [Using Realm and Charts with Swift 3 in iOS 10 (Sami Korpela)](https://medium.com/@skoli/using-realm-and-charts-with-swift-3-in-ios-10-40c42e3838c0#.2gyymwfh8)\n- [Creating a Line Chart in Swift 3 and iOS 10 (Osian Smith)](https://medium.com/@OsianSmith/creating-a-line-chart-in-swift-3-and-ios-10-2f647c95392e)\n- [Beginning Set-up and Example Using Charts with Swift 3](https://github.com/annalizhaz/ChartsForSwiftBasic)\n- [Creating a Radar Chart in Swift (David Piper)](https://medium.com/@HeyDaveTheDev/creating-a-radar-chart-in-swift-5791afcf92f0)\n- [Plotting in IOS using Charts framework with SwiftUI (Evgeny Basisty)](https://medium.com/@zzzzbh/plotting-in-ios-using-charts-framework-with-swiftui-222034a2bea6)\n- [Set Up a Basic Bar Chart Using iOS-Charts (Penny Huang)](https://medium.com/@penny-huang/swift-setting-up-a-basic-bar-chart-using-ios-charts-afd6aad96ac)\n- [iOS-Charts Tutorial: Highlight Selected Value With a Custom Marker (Penny Huang)](https://medium.com/@penny-huang/swift-ios-charts-tutorial-highlight-selected-value-with-a-custom-marker-30ccbf92aa1b)\n- [Drawing Charts in iOS Before SwiftUI (Gennady Stepanov)](https://medium.com/better-programming/drawing-charts-in-ios-before-swiftui-9f95b8612607)\n\nWant your tutorial to show here? Create a PR!\n\n## Troubleshooting\n\n#### Can't compile?\n\n- Please note the difference between installing a compiled framework from CocoaPods or Carthage, and copying the source code.\n- Please read the **Usage** section again.\n- Search in the issues\n- Try to politely ask in the issues section\n\n#### Other problems / feature requests\n\n- Search in the issues\n- Try to politely ask in the issues section\n\n## CocoaPods Install\n\nAdd `pod 'DGCharts'` to your Podfile. \"DGCharts\" is the name of the library.  \nFor [Realm](https://realm.io/) support, please add `pod 'ChartsRealm'` too.\n\n**Note:** ~~`pod 'ios-charts'`~~ is not the correct library, and refers to a different project by someone else.\n\n## Carthage Install\n\nDGCharts now include Carthage prebuilt binaries.\n\n```carthage\ngithub \"danielgindi/Charts\" == 5.1.0\ngithub \"danielgindi/Charts\" ~> 5.1.0\n```\n\nIn order to build the binaries for a new release, use `carthage build --no-skip-current && carthage archive Charts`.\n\n## Swift Package Manager Install\n\nSwift Package Manager\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/danielgindi/Charts.git\", .upToNextMajor(from: \"5.1.0\"))\n]\n```\n\n## 3rd party bindings\n\nXamarin (by @Flash3001): _iOS_ - [GitHub](https://github.com/Flash3001/iOSCharts.Xamarin)/[NuGet](https://www.nuget.org/packages/iOSCharts/). _Android_ - [GitHub](https://github.com/Flash3001/MPAndroidChart.Xamarin)/[NuGet](https://www.nuget.org/packages/MPAndroidChart/).\n\n## Help\n\nIf you like what you see here, and want to support the work being done in this repository, you could:\n\n- Contribute code, issues and pull requests\n- Let people know this library exists (:fire: spread the word :fire:)\n- [![Donate](https://www.paypalobjects.com/en_US/i/btn/btn_donate_LG.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=68UL6Y8KUPS96) (You can buy me a beer, or you can buy me dinner :-)\n\n**Note:** The author of [MPAndroidChart](https://github.com/PhilJay/MPAndroidChart) is the reason that this library exists, and is accepting [donations](https://github.com/PhilJay/MPAndroidChart#donations) on his page. He deserves them!\n\n## Questions & Issues\n\nIf you are having questions or problems, you should:\n\n- Make sure you are using the latest version of the library. Check the [**release-section**](https://github.com/danielgindi/Charts/releases).\n- Study the Android version's [**Documentation-Wiki**](https://github.com/PhilJay/MPAndroidChart/wiki)\n- Search or open questions on [**stackoverflow**](http://stackoverflow.com/questions/tagged/ios-charts) with the `ios-charts` tag\n- Search [**known issues**](https://github.com/danielgindi/Charts/issues) for your problem (open and closed)\n- Create new issues (please :fire: **search known issues before** :fire:, do not create duplicate issues)\n\n# Features\n\n**Core features:**\n\n- 8 different chart types\n- Scaling on both axes (with touch-gesture, axes separately or pinch-zoom)\n- Dragging / Panning (with touch-gesture)\n- Combined-Charts (line-, bar-, scatter-, candle-stick-, bubble-)\n- Dual (separate) Axes\n- Customizable Axes (both x- and y-axis)\n- Highlighting values (with customizable popup-views)\n- Save chart to camera-roll / export to PNG/JPEG\n- Predefined color templates\n- Legends (generated automatically, customizable)\n- Animations (build up animations, on both x- and y-axis)\n- Limit lines (providing additional information, maximums, ...)\n- Fully customizable (paints, typefaces, legends, colors, background, gestures, dashed lines, ...)\n- Plotting data directly from [**Realm.io**](https://realm.io) mobile database ([here](https://github.com/danielgindi/ChartsRealm))\n\n**Chart types:**\n\n_Screenshots are currently taken from the original repository, as they render exactly the same :-)_\n\n- **LineChart (with legend, simple design)**\n  ![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/simpledesign_linechart4.png)\n- **LineChart (with legend, simple design)**\n  ![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/simpledesign_linechart3.png)\n\n- **LineChart (cubic lines)**\n  ![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/cubiclinechart.png)\n\n- **LineChart (gradient fill)**\n  ![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/line_chart_gradient.png)\n\n- **Combined-Chart (bar- and linechart in this case)**\n  ![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/combined_chart.png)\n\n- **BarChart (with legend, simple design)**\n\n![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/simpledesign_barchart3.png)\n\n- **BarChart (grouped DataSets)**\n\n![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/groupedbarchart.png)\n\n- **Horizontal-BarChart**\n\n![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/horizontal_barchart.png)\n\n- **PieChart (with selection, ...)**\n\n![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/simpledesign_piechart1.png)\n\n- **ScatterChart** (with squares, triangles, circles, ... and more)\n\n![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/scatterchart.png)\n\n- **CandleStickChart** (for financial data)\n\n![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/candlestickchart.png)\n\n- **BubbleChart** (area covered by bubbles indicates the value)\n\n![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/bubblechart.png)\n\n- **RadarChart** (spider web chart)\n\n![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/radarchart.png)\n\n# Documentation\n\nCurrently there's no need for documentation for the iOS/tvOS/macOS version, as the API is **95% the same** as on Android.  \nYou can read the official [MPAndroidChart](https://github.com/PhilJay/MPAndroidChart) documentation here: [**Wiki**](https://github.com/PhilJay/MPAndroidChart/wiki)\n\nOr you can see the Charts Demo project in both Objective-C and Swift ([**ChartsDemo-iOS**](https://github.com/danielgindi/Charts/tree/master/ChartsDemo-iOS), as well as macOS [**ChartsDemo-macOS**](https://github.com/danielgindi/Charts/tree/master/ChartsDemo-macOS)) and learn the how-tos from it.\n\n# Special Thanks\n\nGoes to [@liuxuan30](https://github.com/liuxuan30), [@petester42](https://github.com/petester42) and [@AlBirdie](https://github.com/AlBirdie) for new features, bugfixes, and lots and lots of involvement in our open-sourced community! You guys are a huge help to all of those coming here with questions and issues, and I couldn't respond to all of those without you.\n\n### Our amazing sponsors\n\n[Debricked](https://debricked.com/): Use open source securely\n\n[![debricked](https://user-images.githubusercontent.com/4375169/73585544-25bfa800-44dd-11ea-9661-82519a125302.jpg)](https://debricked.com/)\n\n# License\n\nCopyright 2016 Daniel Cohen Gindi & Philipp Jahoda\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n",
      "stars_today": 1
    },
    {
      "id": 70198664,
      "name": "lottie-ios",
      "full_name": "airbnb/lottie-ios",
      "description": "An iOS library to natively render After Effects vector animations",
      "html_url": "https://github.com/airbnb/lottie-ios",
      "stars": 26626,
      "forks": 3828,
      "language": "Swift",
      "topics": [
        "animation",
        "bodymovin",
        "custom-transitions",
        "ios",
        "ios-animation",
        "ios-transition",
        "keyframes",
        "swift",
        "transition-animation"
      ],
      "created_at": "2016-10-06T22:38:38Z",
      "updated_at": "2026-01-21T16:38:32Z",
      "pushed_at": "2026-01-13T14:44:25Z",
      "open_issues": 44,
      "owner": {
        "login": "airbnb",
        "avatar_url": "https://avatars.githubusercontent.com/u/698437?v=4"
      },
      "readme": "# Lottie for iOS\n [![Version](https://img.shields.io/cocoapods/v/lottie-ios.svg?style=flat)](https://cocoapods.org/pods/lottie-ios) [![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage) [![SwiftPM](https://img.shields.io/badge/SPM-supported-DE5C43.svg?style=flat)](https://swift.org/package-manager/) [![License](https://img.shields.io/cocoapods/l/lottie-ios.svg?style=flat)](https://cocoapods.org/pods/lottie-ios) [![Platform](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/airbnb/lottie-ios) [![Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/airbnb/lottie-ios)\n\n**View documentation, FAQ, help, examples, and more at [airbnb.io/lottie](https://airbnb.io/lottie/)**\n\nLottie is a cross-platform library for iOS, macOS, tvOS, visionOS, [Android](https://github.com/airbnb/lottie-android), and [Web](https://github.com/airbnb/lottie-web) that natively renders vector-based animations and art in realtime with minimal code.\n\nLottie loads and renders animations and vectors exported in the bodymovin JSON format. Bodymovin JSON can be created and exported from After Effects with [bodymovin](https://github.com/bodymovin/bodymovin), Sketch with [Lottie Sketch Export](https://github.com/buba447/Lottie-Sketch-Export), and from [Haiku](https://www.haikuanimator.com).\n\nDesigners can create **and ship** beautiful animations without an engineer painstakingly recreating them by hand.\nSince the animations are backed by JSON, they are extremely small in size but can be large in complexity!\nAnimations can be played, resized, looped, sped up, slowed down, reversed, and even interactively scrubbed.\nLottie can play or loop just a portion of the animation as well, the possibilities are endless!\nAnimations can even be ***changed at runtime*** in various ways! Change the color, position, or any keyframable value!\n\nHere is just a small sampling of the power of Lottie\n\n![Example1](_Gifs/Examples1.gif)\n![Example2](_Gifs/Examples2.gif)\n\n<img src=\"_Gifs/Community 2_3.gif\" />\n\n![Example3](_Gifs/Examples3.gif)\n\n![Abcs](_Gifs/Examples4.gif)\n\n## Installing Lottie\nLottie supports [Swift Package Manager](https://www.swift.org/package-manager/), [CocoaPods](https://cocoapods.org/), and [Carthage](https://github.com/Carthage/Carthage) (Both dynamic and static).\n\n### Github Repo\n\nYou can pull the [Lottie Github Repo](https://github.com/airbnb/lottie-ios/) and include the `Lottie.xcodeproj` to build a dynamic or static library.\n\n### Swift Package Manager\n\nTo install Lottie using [Swift Package Manager](https://github.com/swiftlang/swift-package-manager) you can follow the [tutorial published by Apple](https://developer.apple.com/documentation/xcode/adding_package_dependencies_to_your_app) using the URL for the Lottie repo with the current version:\n\n1. In Xcode, select ‚ÄúFile‚Äù ‚Üí ‚ÄúAdd Packages...‚Äù\n1. Enter https://github.com/airbnb/lottie-spm.git\n\nor you can add the following dependency to your `Package.swift`:\n\n```swift\n.package(url: \"https://github.com/airbnb/lottie-spm.git\", from: \"4.5.2\")\n```\n\nWhen using Swift Package Manager we recommend using the [lottie-spm](https://github.com/airbnb/lottie-spm) repo instead of the main lottie-ios repo.  The main git repository for [lottie-ios](https://github.com/airbnb/lottie-ios) is somewhat large (300+ MB), and Swift Package Manager always downloads the full repository with all git history. The [lottie-spm](https://github.com/airbnb/lottie-spm) repo is much smaller (less than 500kb), so can be downloaded much more quickly. \n\nInstead of downloading the full git history of Lottie and building it from source, the lottie-spm repo just contains a pointer to the precompiled XCFramework included in the [latest lottie-ios release](https://github.com/airbnb/lottie-ios/releases/latest) (typically ~8MB). If you prefer to include Lottie source directly your project, you can directly depend on the main lottie-ios repo by referencing `https://github.com/airbnb/lottie-ios.git` instead.\n\n### CocoaPods\nAdd the pod to your Podfile:\n```ruby\npod 'lottie-ios'\n```\n\nAnd then run:\n```ruby\npod install\n```\nAfter installing the cocoapod into your project import Lottie with\n```swift\nimport Lottie\n```\n\n### Carthage\nAdd Lottie to your Cartfile:\n```\ngithub \"airbnb/lottie-ios\" \"master\"\n```\n\nAnd then run:\n```\ncarthage update\n```\nIn your application targets ‚ÄúGeneral‚Äù tab under the ‚ÄúLinked Frameworks and Libraries‚Äù section, drag and drop lottie-ios.framework from the Carthage/Build/iOS directory that `carthage update` produced.\n\n## Swift Version Support\n\nLottie supports Swift / Xcode versions back to the minimum version that is permitted by Apple for submissions to the App Store. You can see the most up-to-date information for which Swift versions Lottie supports on [Swift Package Index](https://swiftpackageindex.com/airbnb/lottie-ios):\n\n[![Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/airbnb/lottie-ios)\n\n## Privacy\n\nLottie does not collect any data. We provide this notice to help you fill out [App Privacy Details](https://developer.apple.com/app-store/app-privacy-details/). We additionally provide a [privacy manifest](https://github.com/airbnb/lottie-ios/blob/master/Sources/PrivacyInfo.xcprivacy) which can be included in your app.\n\n## Security\n\nWe distribute XCFramework bundles for each release on [GitHub](https://github.com/airbnb/lottie-ios/releases/latest). In Lottie 4.4.0 and later, these XCFramework bundles include a [code signature](https://developer.apple.com/documentation/xcode/verifying-the-origin-of-your-xcframeworks). These bundles are self-signed under the name \"Lottie iOS\" and have the following fingerprint:\n\n```\n89 2F 1B 43 04 7B 50 53 8F 2F 46 EA D9 29 00 DD 3D 48 11 F358 21 78 C0 61 A5 FB 20 F1 11 CB 26\n```\n\nIn Xcode you can verify this by selecting `Lottie.xcframework` and confirming that it shows the following information:\n\n![Code Signature in Xcode](_Gifs/code_signature.png)\n\n## Contributing\n\nWe always appreciate contributions from the community. To make changes to the project, you can clone the repo and open `Lottie.xcworkspace`. This workspace includes:\n - the Lottie framework (for iOS, macOS, and tvOS)\n - unit tests and snapshot tests (for iOS, must be run on an iPhone 8 simulator)\n - an Example iOS app that lets you browse and test over 100 sample animations included in the repo\n\nAll pull requests with new features or bug fixes that affect how animations render should include snapshot test cases that validate the included changes. \n  - To add a new sample animation to the snapshot testing suite, you can add the `.json` file to `Tests/Samples`. Re-run the snapshot tests to generate the new snapshot image files.\n  - To update existing snapshots after making changes, you can set `isRecording = true` in `SnapshotTests.swift` `setUp()` method and then re-run the snapshot tests.\n\nThe project also includes several helpful commands defined in our [Rakefile](https://github.com/airbnb/lottie-ios/blob/master/Rakefile). To use these, you need to install [Bundler](https://bundler.io/):\n\n```bash\n$ sudo gem install bundle\n$ bundle install\n```\n\nFor example, all Swift code should be formatted according to the [Airbnb Swift Style Guide](https://github.com/airbnb/swift). After making changes, you can reformat the code automatically using [SwiftFormat](https://github.com/nicklockwood/SwiftFormat) and [SwiftLint](https://github.com/realm/SwiftLint) by running `bundle exec rake format:swift`. Other helpful commands include:\n\n```bash\n$ bundle exec rake build:all # builds all targets for all platforms\n$ bundle exec rake build:package:iOS # builds the Lottie package for iOS\n$ bundle exec rake test:package # tests the Lottie package\n$ bundle exec rake format:swift # reformat Swift code based on the Airbnb Swift Style Guide\n```\n",
      "stars_today": 1
    },
    {
      "id": 3148979,
      "name": "spring-security",
      "full_name": "spring-projects/spring-security",
      "description": "Spring Security",
      "html_url": "https://github.com/spring-projects/spring-security",
      "stars": 9411,
      "forks": 6226,
      "language": "Java",
      "topics": [
        "framework",
        "java",
        "security",
        "spring",
        "spring-framework"
      ],
      "created_at": "2012-01-10T21:50:57Z",
      "updated_at": "2026-01-22T20:27:22Z",
      "pushed_at": "2026-01-22T20:27:11Z",
      "open_issues": 1332,
      "owner": {
        "login": "spring-projects",
        "avatar_url": "https://avatars.githubusercontent.com/u/317776?v=4"
      },
      "readme": "image::https://badges.gitter.im/Join%20Chat.svg[Gitter,link=https://gitter.im/spring-projects/spring-security?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge]\n\nimage:https://github.com/spring-projects/spring-security/actions/workflows/continuous-integration-workflow.yml/badge.svg?branch=main[\"Build Status\", link=\"https://github.com/spring-projects/spring-security/actions/workflows/continuous-integration-workflow.yml\"]\n\nimage:https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A[\"Revved up by Develocity\", link=\"https://ge.spring.io/scans?search.rootProjectNames=spring-security\"]\n\n= Spring Security\n\nSpring Security provides security services for the https://docs.spring.io[Spring IO Platform]. Spring Security 6.0 requires Spring 6.0 as\na minimum and also requires Java 17.\n\nFor a detailed list of features and access to the latest release, please visit https://spring.io/projects[Spring projects].\n\n== Code of Conduct\nPlease see our https://github.com/spring-projects/.github/blob/main/CODE_OF_CONDUCT.md[code of conduct]\n\n== Downloading Artifacts\nSee https://docs.spring.io/spring-security/reference/getting-spring-security.html[Getting Spring Security] for how to obtain Spring Security.\n\n== Documentation\nBe sure to read the https://docs.spring.io/spring-security/reference/[Spring Security Reference].\nExtensive JavaDoc for the Spring Security code is also available in the https://docs.spring.io/spring-security/site/docs/current/api/[Spring Security API Documentation].\n\nYou may also want to check out https://docs.spring.io/spring-security/reference/whats-new.html[what's new in the latest release].\n\n== Quick Start\nSee https://docs.spring.io/spring-security/reference/servlet/getting-started.html[Hello Spring Security] to get started with a \"Hello, World\" application.\n\n== Building from Source\nSpring Security uses a https://gradle.org[Gradle]-based build system.\nIn the instructions below, https://vimeo.com/34436402[`./gradlew`] is invoked from the root of the source tree and serves as\na cross-platform, self-contained bootstrap mechanism for the build.\n\n=== Prerequisites\nhttps://docs.github.com/en/get-started/quickstart/set-up-git[Git] and the https://www.oracle.com/java/technologies/downloads/#java17[JDK17 build].\n\nBe sure that your `JAVA_HOME` environment variable points to the `jdk-17` folder extracted from the JDK download.\n\n=== Check out sources\n[indent=0]\n----\ngit clone git@github.com:spring-projects/spring-security.git\n----\n\n=== Install all `spring-*.jar` into your local Maven repository.\n\n[indent=0]\n----\n./gradlew publishToMavenLocal\n----\n\n=== Compile and test; build all JARs, distribution zips, and docs\n\n[indent=0]\n----\n./gradlew build\n----\n\nThe reference docs are not currently included in the distribution zip.\nYou can build the reference docs for this branch by running the following command:\n\n----\n./gradlew :spring-security-docs:antora\n----\n\nThat command publishes the docs site to the `_docs/build/site_` directory.\nThe https://github.com/spring-projects/spring-security/tree/docs-build[playbook branch] describes how to build the reference docs in detail.\n\nDiscover more commands with `./gradlew tasks`.\n\n== Getting Support\nCheck out the https://stackoverflow.com/questions/tagged/spring-security[Spring Security tags on Stack Overflow].\nhttps://spring.io/support[Commercial support] is available too.\n\n== Contributing\nhttps://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request[Pull requests] are welcome; see the https://github.com/spring-projects/spring-security/blob/main/CONTRIBUTING.adoc[contributor guidelines] for details.\n\n== License\nSpring Security is Open Source software released under the\nhttps://www.apache.org/licenses/LICENSE-2.0.html[Apache 2.0 license].\n",
      "stars_today": 1
    },
    {
      "id": 24797553,
      "name": "SQLite.swift",
      "full_name": "stephencelis/SQLite.swift",
      "description": "A type-safe, Swift-language layer over SQLite3.",
      "html_url": "https://github.com/stephencelis/SQLite.swift",
      "stars": 10087,
      "forks": 1625,
      "language": "Swift",
      "topics": [
        "sqlite",
        "swift"
      ],
      "created_at": "2014-10-04T18:23:46Z",
      "updated_at": "2026-01-22T13:52:39Z",
      "pushed_at": "2026-01-22T13:52:32Z",
      "open_issues": 141,
      "owner": {
        "login": "stephencelis",
        "avatar_url": "https://avatars.githubusercontent.com/u/658?v=4"
      },
      "readme": "# SQLite.swift\n\n![Build Status][GitHubActionBadge] [![CocoaPods Version][CocoaPodsVersionBadge]][CocoaPodsVersionLink] [![Swift5 compatible][Swift5Badge]][Swift5Link] [![Platform][PlatformBadge]][PlatformLink] [![Carthage compatible][CartagheBadge]][CarthageLink] [![Join the chat at https://gitter.im/stephencelis/SQLite.swift][GitterBadge]][GitterLink]\n\nA type-safe, [Swift][]-language layer over [SQLite3][].\n\n[SQLite.swift][] provides compile-time confidence in SQL statement\nsyntax _and_ intent.\n\n## Features\n\n - A pure-Swift interface\n - A type-safe, optional-aware SQL expression builder\n - A flexible, chainable, lazy-executing query layer\n - Automatically-typed data access\n - A lightweight, uncomplicated query and parameter binding interface\n - Developer-friendly error handling and debugging\n - [Full-text search][] support\n - [Well-documented][See Documentation]\n - Extensively tested\n - [SQLCipher][] support via Swift Package Manager\n - [Schema query/migration][]\n - Works on [Linux](Documentation/Linux.md) (with some limitations)\n - Active support at\n   [StackOverflow](https://stackoverflow.com/questions/tagged/sqlite.swift),\n   and [Gitter Chat Room](https://gitter.im/stephencelis/SQLite.swift)\n   (_experimental_)\n\n[SQLCipher]: https://www.zetetic.net/sqlcipher/\n[Full-text search]: Documentation/Index.md#full-text-search\n[Schema query/migration]: Documentation/Index.md#querying-the-schema\n[See Documentation]: Documentation/Index.md#sqliteswift-documentation\n\n\n## Usage\n\n```swift\nimport SQLite\n\n// Wrap everything in a do...catch to handle errors\ndo {\n    let db = try Connection(\"path/to/db.sqlite3\")\n\n    let users = Table(\"users\")\n    let id = SQLite.Expression<Int64>(\"id\")\n    let name = SQLite.Expression<String?>(\"name\")\n    let email = SQLite.Expression<String>(\"email\")\n\n    try db.run(users.create { t in\n        t.column(id, primaryKey: true)\n        t.column(name)\n        t.column(email, unique: true)\n    })\n    // CREATE TABLE \"users\" (\n    //     \"id\" INTEGER PRIMARY KEY NOT NULL,\n    //     \"name\" TEXT,\n    //     \"email\" TEXT NOT NULL UNIQUE\n    // )\n\n    let insert = users.insert(name <- \"Alice\", email <- \"alice@mac.com\")\n    let rowid = try db.run(insert)\n    // INSERT INTO \"users\" (\"name\", \"email\") VALUES ('Alice', 'alice@mac.com')\n\n    for user in try db.prepare(users) {\n        print(\"id: \\(user[id]), name: \\(user[name]), email: \\(user[email])\")\n        // id: 1, name: Optional(\"Alice\"), email: alice@mac.com\n    }\n    // SELECT * FROM \"users\"\n\n    let alice = users.filter(id == rowid)\n\n    try db.run(alice.update(email <- email.replace(\"mac.com\", with: \"me.com\")))\n    // UPDATE \"users\" SET \"email\" = replace(\"email\", 'mac.com', 'me.com')\n    // WHERE (\"id\" = 1)\n\n    try db.run(alice.delete())\n    // DELETE FROM \"users\" WHERE (\"id\" = 1)\n\n    try db.scalar(users.count) // 0\n    // SELECT count(*) FROM \"users\"\n} catch {\n    print (error)\n}\n```\n\nNote that `Expression` should be written as `SQLite.Expression` to avoid\nconflicts with the `SwiftUI.Expression` if you are using SwiftUI too.\n\nSQLite.swift also works as a lightweight, Swift-friendly wrapper over the C\nAPI.\n\n```swift\n// Wrap everything in a do...catch to handle errors\ndo {\n    // ...\n\n    let stmt = try db.prepare(\"INSERT INTO users (email) VALUES (?)\")\n    for email in [\"betty@icloud.com\", \"cathy@icloud.com\"] {\n        try stmt.run(email)\n    }\n\n    db.totalChanges    // 3\n    db.changes         // 1\n    db.lastInsertRowid // 3\n\n    for row in try db.prepare(\"SELECT id, email FROM users\") {\n        print(\"id: \\(row[0]), email: \\(row[1])\")\n        // id: Optional(2), email: Optional(\"betty@icloud.com\")\n        // id: Optional(3), email: Optional(\"cathy@icloud.com\")\n    }\n\n    try db.scalar(\"SELECT count(*) FROM users\") // 2\n} catch {\n    print (error)\n}\n```\n\n[Read the documentation][See Documentation] or explore more,\ninteractively, from the Xcode project‚Äôs playground.\n\n![SQLite.playground Screen Shot](Documentation/Resources/playground@2x.png)\n\n## Installation\n\n### Swift Package Manager\n\nThe [Swift Package Manager][] is a tool for managing the distribution of\nSwift code.\n\n1. Add the following to your `Package.swift` file:\n\n  ```swift\n  dependencies: [\n      .package(url: \"https://github.com/stephencelis/SQLite.swift.git\", from: \"0.15.5\")\n  ]\n  ```\n\n2. Build your project:\n\n  ```sh\n  $ swift build\n  ```\n\nSee the [Tests/SPM](https://github.com/stephencelis/SQLite.swift/tree/master/Tests/SPM) folder for a small demo project which uses SPM.\n\n[Swift Package Manager]: https://swift.org/package-manager\n\n### Carthage\n\n[Carthage][] is a simple, decentralized dependency manager for Cocoa. To\ninstall SQLite.swift with Carthage:\n\n 1. Make sure Carthage is [installed][Carthage Installation].\n\n 2. Update your Cartfile to include the following:\n\n    ```ruby\n    github \"stephencelis/SQLite.swift\" ~> 0.15.5\n    ```\n\n 3. Run `carthage update` and\n    [add the appropriate framework][Carthage Usage].\n\n\n[Carthage]: https://github.com/Carthage/Carthage\n[Carthage Installation]: https://github.com/Carthage/Carthage#installing-carthage\n[Carthage Usage]: https://github.com/Carthage/Carthage#adding-frameworks-to-an-application\n\n\n### CocoaPods\n\n[CocoaPods][] is a dependency manager for Cocoa projects. To install\nSQLite.swift with CocoaPods:\n\n 1. Make sure CocoaPods is [installed][CocoaPods Installation].\n\n    ```sh\n    # Using the default Ruby install will require you to use sudo when\n    # installing and updating gems.\n    [sudo] gem install cocoapods\n    ```\n\n 2. Update your Podfile to include the following:\n\n    ```ruby\n    use_frameworks!\n\n    target 'YourAppTargetName' do\n        pod 'SQLite.swift', '~> 0.15.0'\n    end\n    ```\n\n 3. Run `pod install --repo-update`.\n\n[CocoaPods]: https://cocoapods.org\n[CocoaPods Installation]: https://guides.cocoapods.org/using/getting-started.html#getting-started\n\n### Manual\n\nTo install SQLite.swift as an Xcode sub-project:\n\n 1. Drag the **SQLite.xcodeproj** file into your own project.\n    ([Submodule][], clone, or [download][] the project first.)\n\n    ![Installation Screen Shot](Documentation/Resources/installation@2x.png)\n\n 2. In your target‚Äôs **General** tab, click the **+** button under **Linked\n    Frameworks and Libraries**.\n\n 3. Select the appropriate **SQLite.framework** for your platform.\n\n 4. **Add**.\n\nSome additional steps are required to install the application on an actual\ndevice:\n\n 5. In the **General** tab, click the **+** button under **Embedded\n    Binaries**.\n\n 6. Select the appropriate **SQLite.framework** for your platform.\n\n 7. **Add**.\n\n\n[Xcode]: https://developer.apple.com/xcode/downloads/\n[Submodule]: https://git-scm.com/book/en/Git-Tools-Submodules\n[download]: https://github.com/stephencelis/SQLite.swift/archive/master.zip\n\n\n## Communication\n\n[Read the contributing guidelines][]. The _TL;DR_ (but please; _R_):\n\n - Need **help** or have a **general question**? [Ask on Stack\n   Overflow][] (tag `sqlite.swift`).\n - Found a **bug** or have a **feature request**? [Open an issue][].\n - Want to **contribute**? [Submit a pull request][].\n\n[Read the contributing guidelines]: ./CONTRIBUTING.md#contributing\n[Ask on Stack Overflow]: https://stackoverflow.com/questions/tagged/sqlite.swift\n[Open an issue]: https://github.com/stephencelis/SQLite.swift/issues/new\n[Submit a pull request]: https://github.com/stephencelis/SQLite.swift/fork\n\n\n## Original author\n\n - [Stephen Celis](mailto:stephen@stephencelis.com)\n   ([@stephencelis](https://twitter.com/stephencelis))\n\n\n## License\n\nSQLite.swift is available under the MIT license. See [the LICENSE\nfile](./LICENSE.txt) for more information.\n\n## Related\n\nThese projects enhance or use SQLite.swift:\n\n - [SQLiteMigrationManager.swift][] (inspired by\n   [FMDBMigrationManager][])\n\n## Alternatives\n\nLooking for something else? Try another Swift wrapper (or [FMDB][]):\n\n - [GRDB](https://github.com/groue/GRDB.swift)\n - [SQLiteDB](https://github.com/FahimF/SQLiteDB)\n\n[Swift]: https://swift.org/\n[SQLite3]: https://www.sqlite.org\n[SQLite.swift]: https://github.com/stephencelis/SQLite.swift\n\n[GitHubActionBadge]: https://img.shields.io/github/actions/workflow/status/stephencelis/SQLite.swift/build.yml?branch=master\n\n[CocoaPodsVersionBadge]: https://img.shields.io/cocoapods/v/SQLite.swift.svg?style=flat\n[CocoaPodsVersionLink]: https://cocoapods.org/pods/SQLite.swift\n\n[PlatformBadge]: https://img.shields.io/cocoapods/p/SQLite.swift.svg?style=flat\n[PlatformLink]: https://cocoapods.org/pods/SQLite.swift\n\n[CartagheBadge]: https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat\n[CarthageLink]: https://github.com/Carthage/Carthage\n\n[GitterBadge]: https://badges.gitter.im/stephencelis/SQLite.swift.svg\n[GitterLink]: https://gitter.im/stephencelis/SQLite.swift\n\n[Swift5Badge]: https://img.shields.io/badge/swift-5-orange.svg?style=flat\n[Swift5Link]: https://developer.apple.com/swift/\n\n[SQLiteMigrationManager.swift]: https://github.com/garriguv/SQLiteMigrationManager.swift\n[FMDB]: https://github.com/ccgus/fmdb\n[FMDBMigrationManager]: https://github.com/layerhq/FMDBMigrationManager\n",
      "stars_today": 1
    },
    {
      "id": 17101828,
      "name": "swirl_courses",
      "full_name": "swirldev/swirl_courses",
      "description": ":mortar_board: A collection of interactive courses for the swirl R package.",
      "html_url": "https://github.com/swirldev/swirl_courses",
      "stars": 4522,
      "forks": 7241,
      "language": "R",
      "topics": [],
      "created_at": "2014-02-23T04:48:04Z",
      "updated_at": "2026-01-22T15:03:22Z",
      "pushed_at": "2024-01-10T17:38:19Z",
      "open_issues": 206,
      "owner": {
        "login": "swirldev",
        "avatar_url": "https://avatars.githubusercontent.com/u/5671732?v=4"
      },
      "readme": "# swirl courses\n\nThis is a collection of interactive courses for use with the [swirl R package](http://swirlstats.com). You'll find instructions for installing courses further down on this page. Some courses are still in development and we'd love to hear any [suggestions](https://github.com/swirldev/swirl_courses/issues/new) you have as you work through them.\n\nFor more information regarding swirl, visit [swirlstats.com](http://swirlstats.com) or the [swirl GitHub repository](https://github.com/swirldev/swirl). If you'd like to write your own interactive content, please visit the [Instructors page](http://swirlstats.com/instructors.html) of our website.\n\nHere are our current offerings, organized by level of difficulty:\n\n#### Beginner\n\n- **R Programming**: The basics of programming in R\n- [**R Programming E**](https://github.com/swirldev/R_Programming_E): Same as the original, but modified slightly for in-class use (see below ***)\n- [**The R Programming Environment**](https://swirlstats.com/scn/rpe.html)\n<!-- - **Data Analysis**: Basic ideas in statistics and data visualization -->\n<!-- - **Mathematical Biostatistics Boot Camp**: One- and two-sample t-tests, power, and sample size -->\n<!-- - **Open Intro**: A very basic introduction to statistics, data analysis, and data visualization -->\n\n\\*\\*\\* *R Programming E is identical to R Programming, except we've eliminated the prompts for Coursera credentials at the end of each lesson and instead give students the option to send an email to their instructor notifying them of completion. Admittedly, it's sort of a hack until we come up with a more robust solution for in-class use (i.e. an instructor \"dashboard\").*\n\n#### Intermediate\n\n- **Regression Models**: The basics of regression modeling in R\n- **Getting and Cleaning Data**: dplyr, tidyr, lubridate, oh my!\n\n#### Advanced\n\n- **Statistical Inference**: This intermediate to advanced level course closely follows the\n[Statistical Inference course](https://www.coursera.org/course/statinference) of the Johns Hopkins \n[Data Science Specialization](https://www.coursera.org/specialization/jhudatascience/1) on Coursera. It\nintroduces the student to basic concepts of statistical inference\nincluding probability, hypothesis testing, confidence intervals and\np-values. It concludes with an initiation to topics of particular\nrelevance to big data, issues of multiple testing and resampling.\n- [**Advanced R Programming**](https://swirlstats.com/scn/arp.html)\n\nSince our users come from a variety backgrounds, it's very hard to label material as **Beginner**, **Intermediate**, or **Advanced**. If you find something that is labelled **Beginner** to be challenging, please don't be discouraged. The first step of learning anything is to acknowledge that you are capable of understanding it. True understanding will come with time and practice.\n\n#### Course Authors\n\n- **Writing swirl Courses**: An interactive guides and example \n  for swirl course authors. The first group of lessons cover basics. The rest cover \n  special topics useful primarily as samples--points of departure for one's own material.\n  For more comprehensive documentation about writing your own swirl courses see http://swirlstats.com/swirlify/.\n\n## Install and run a course automatically from swirl\n\n**This is the preferred method of installing courses.** It automates the process by allowing you to do everything right from the R console.\n\n1) Make sure you have a recent version version of swirl:\n\n```\ninstall.packages(\"swirl\")\n```\n\n2) Enter the following from the R console, **substituting the name of the course** that you wish to install:\n\n```\nlibrary(swirl)\ninstall_course(\"Course Name Here\")\nswirl()\n```\n\nFor example, `install_course(\"R Programming\")` will install the R Programming course. **Please note that course names are case sensitive!**\n\nIf that doesn't work for you...\n\n## Install and run a course manually\n\nIf the automatic course installation method outlined above does not work for you, then there's a simple alternative.\n\n1. Find the course you want to install on the [Swirl Course network website](https://swirlstats.com/scn/title.html).\n2. Follow the manual installation instructions on the course page.\n\nIf that does not work for you, consider taking a look at the \n[legacy manual install instructions](https://github.com/swirldev/swirl_courses/wiki/Legacy-Manual-Install-Instructions-for-Swirl-Courses).\n\n## Uninstall a course\n\nIf you'd like to remove a course at any time, you can use `uninstall_course(\"Course Name Here\")`.\n\n## Using swirl in the classroom\n\nInstructors around the world are using swirl in their classrooms. We think this is awesome. If you're an instructor, please feel free to do the same -- free of charge. While your students may be paying to take your course or attend your institution, we simply ask that you don't charge people *directly* for the use of our software or instructional content.\n\nIf you are not sure about a particular use case, don't hesitate to post a\nquestion to our [Google Group](https://groups.google.com/forum/#!forum/swirl-discuss).\n",
      "stars_today": 1
    },
    {
      "id": 39799721,
      "name": "r4ds",
      "full_name": "hadley/r4ds",
      "description": "R for data science: a book",
      "html_url": "https://github.com/hadley/r4ds",
      "stars": 4977,
      "forks": 4405,
      "language": "R",
      "topics": [
        "book",
        "bookdown",
        "data-science",
        "r"
      ],
      "created_at": "2015-07-27T21:52:44Z",
      "updated_at": "2026-01-22T15:01:41Z",
      "pushed_at": "2026-01-16T04:04:49Z",
      "open_issues": 21,
      "owner": {
        "login": "hadley",
        "avatar_url": "https://avatars.githubusercontent.com/u/4196?v=4"
      },
      "readme": "# R for Data Science\n\n<!-- badges: start -->\n\n[![Render and deploy Book to Netlify](https://github.com/hadley/r4ds/actions/workflows/build_book.yaml/badge.svg)](https://github.com/hadley/r4ds/actions/workflows/build_book.yaml)\n\n<!-- badges: end -->\n\nThis repository contains the source of [R for Data Science](http://r4ds.hadley.nz) book.\nThe book is built using [Quarto](https://quarto.org/).\n\n## Images\n\n### Omnigraffle drawings\n\n-   Font: 12pt Guardian Sans Condensed / Ubuntu mono\n\n-   Export as 300 dpi png.\n\n-   Website font is 18 px = 13.5 pt, so scale dpi to match font sizes: 270 = 300 \\* 12 / 13.5.\n    (I also verified this empirically by screenshotting.)\n\n    ``` r\n    #| echo: FALSE\n    #| out.width: NULL\n    knitr::include_graphics(\"diagrams/transform.png\", dpi = 270)\n    ```\n\n### Screenshots\n\n-   Make sure you're using a light theme.\n    For small interface elements (eg. toolbars), zoom in twice.\n\n-   Screenshot with Cmd + Shift + 4.\n\n-   Don't need to set dpi:\n\n    ``` r\n    #| echo: FALSE\n    #| out.width: NULL\n    knitr::include_graphics(\"screenshots/rstudio-wg.png\")\n    ```\n\n### O'Reilly\n\nTo generate book for O'Reilly, build the book then:\n\n```{r}\n# pak::pak(\"hadley/htmlbook\")\nhtmlbook::convert_book()\n\nhtml <- list.files(\"oreilly\", pattern = \"[.]html$\", full.names = TRUE)\nfile.copy(html, \"../r-for-data-science-2e/\", overwrite = TRUE)\n\npngs <- list.files(\"oreilly\", pattern = \"[.]png$\", full.names = TRUE, recursive = TRUE)\ndest <- gsub(\"oreilly\", \"../r-for-data-science-2e/\", pngs)\nfs::dir_create(unique(dirname(dest)))\nfile.copy(pngs, dest, overwrite = TRUE)\n```\n\nThen commit and push to atlas.\n\n## Code of Conduct\n\nPlease note that r4ds uses a [Contributor Code of Conduct](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html).\nBy contributing to this book, you agree to abide by its terms.\n",
      "stars_today": 1
    },
    {
      "id": 158012967,
      "name": "argo-rollouts",
      "full_name": "argoproj/argo-rollouts",
      "description": "Progressive Delivery for Kubernetes",
      "html_url": "https://github.com/argoproj/argo-rollouts",
      "stars": 3365,
      "forks": 1079,
      "language": "Go",
      "topics": [
        "argo-rollouts",
        "argoproj",
        "bluegreen",
        "canary",
        "deployments",
        "experiments",
        "gitops",
        "hacktoberfest",
        "kubernetes",
        "progressive-delivery"
      ],
      "created_at": "2018-11-17T18:28:39Z",
      "updated_at": "2026-01-22T21:40:21Z",
      "pushed_at": "2026-01-22T00:42:18Z",
      "open_issues": 607,
      "owner": {
        "login": "argoproj",
        "avatar_url": "https://avatars.githubusercontent.com/u/30269780?v=4"
      },
      "readme": "\n# Argo Rollouts - Progressive Delivery for Kubernetes\n\n[![codecov](https://codecov.io/gh/argoproj/argo-rollouts/branch/master/graph/badge.svg)](https://codecov.io/gh/argoproj/argo-rollouts)\n[![slack](https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack)](https://argoproj.github.io/community/join-slack)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3834/badge)](https://bestpractices.coreinfrastructure.org/projects/3834)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-rollouts/badge)](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-rollouts)\n[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-rollouts)](https://artifacthub.io/packages/helm/argo/argo-rollouts)\n\n## What is Argo Rollouts?\n\nArgo Rollouts is a Kubernetes controller and set of CRDs which provide advanced deployment capabilities such as blue-green, canary, canary analysis, experimentation, and progressive delivery features to Kubernetes.\n\nArgo Rollouts (optionally) integrates with ingress controllers and service meshes, leveraging their traffic shaping abilities to gradually shift traffic to the new version during an update. Additionally, Rollouts can query and interpret metrics from various providers to verify key KPIs and drive automated promotion or rollback during an update.\n\n[![Argo Rollouts Demo](https://img.youtube.com/vi/hIL0E2gLkf8/0.jpg)](https://youtu.be/hIL0E2gLkf8)\n\n## Quick Start\n\n```bash\nkubectl create namespace argo-rollouts\nkubectl apply -n argo-rollouts -f https://github.com/argoproj/argo-rollouts/releases/latest/download/install.yaml\n```\n\nFollow the full [getting started guide](docs/getting-started.md) to walk through creating and then updating a rollout object.\n\n## Why Argo Rollouts?\n\nKubernetes Deployments provides the `RollingUpdate` strategy which provide a basic set of safety guarantees (readiness probes) during an update. However the rolling update strategy faces many limitations:\n\n* Few controls over the speed of the rollout\n* Inability to control traffic flow to the new version\n* Readiness probes are unsuitable for deeper, stress, or one-time checks\n* No ability to query external metrics to verify an update\n* Can halt the progression, but unable to automatically abort and rollback the update\n\nFor these reasons, in large scale high-volume production environments, a rolling update is often considered too risky of an update procedure since it provides no control over the blast radius, may rollout too aggressively, and provides no automated rollback upon failures.\n\n## Features\n\n* Blue-Green update strategy\n* Canary update strategy\n* Fine-grained, weighted traffic shifting\n* Automated rollbacks and promotions\n* Manual judgement\n* Customizable metric queries and analysis of business KPIs\n* Ingress controller integration: NGINX, ALB, Apache APISIX\n* Service Mesh integration: Istio, Linkerd, SMI\n* Metric provider integration: Prometheus, Wavefront, Kayenta, Web, Kubernetes Jobs, Datadog, New Relic, InfluxDB\n\n## Supported Traffic Shaping Integrations\n| Traffic Shaping Integration       | SetWeight                    | SetWeightExperiments        | SetMirror                  | SetHeader                  | Implemented As Plugin       |\n|-----------------------------------|------------------------------|-----------------------------|----------------------------|----------------------------|-----------------------------|\n| ALB Ingress Controller            | :white_check_mark: (stable)  | :white_check_mark: (stable) | :x:                        | :white_check_mark: (alpha) |                             |\n| Ambassador                        | :white_check_mark: (stable)  | :x:                         | :x:                        | :x:                        |                             |\n| Apache APISIX Ingress Controller  | :white_check_mark: (alpha)   | :x:                         | :x:                        | :white_check_mark: (alpha) |                             |\n| Istio                             | :white_check_mark: (stable)  | :white_check_mark: (stable) | :white_check_mark: (alpha) | :white_check_mark: (alpha) |                             |\n| Nginx Ingress Controller          | :white_check_mark: (stable)  | :x:                         | :x:                        | :x:                        |                             |\n| SMI                               | :white_check_mark: (stable)  | :white_check_mark: (stable) | :x:                        | :x:                        |                             |\n| Traefik                           | :white_check_mark: (stable)  | :x:                         | :x:                        | :x:                        |                             |\n| Contour                           | :white_check_mark: (beta)    | :x:                         | :x:                        | :x:                        | :heavy_check_mark:          |\n| Gateway API                       | :white_check_mark: (alpha)   | :x:                         | :x:                        | :x:                        | :heavy_check_mark:          |\n\n:white_check_mark: = Supported\n\n:x: = Not Supported\n\n:heavy_check_mark: = Yes\n\n## Documentation\n\nTo learn more about Argo Rollouts go to the [complete documentation](https://argo-rollouts.readthedocs.io/en/stable/).\n\n## Community\n\nYou can reach the Argo Rollouts community and developers via the following channels:\n\n* Q & A: [Github Discussions](https://github.com/argoproj/argo-rollouts/discussions)\n* Chat: [The #argo-rollouts Slack channel](https://argoproj.github.io/community/join-slack)\n* Contributors Office Hours: [Every Thursday](https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com) | [Agenda](https://docs.google.com/document/d/1xkoFkVviB70YBzSEa4bDnu-rUZ1sIFtwKKG1Uw8XsY8)\n* User Community meeting: [First Wednesday of each month](https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com) | [Agenda](https://docs.google.com/document/d/1ttgw98MO45Dq7ZUHpIiOIEfbyeitKHNfMjbY5dLLMKQ)\n\n## Who uses Argo Rollouts?\n\n[Official Argo Rollouts User List](https://github.com/argoproj/argo-rollouts/blob/master/USERS.md)\n\n## Community Blogs and Presentations\n\n* [Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo](https://github.com/terrytangyuan/awesome-argo)\n* [Automation of Everything - How To Combine Argo Events, Workflows & Pipelines, CD, and Rollouts](https://youtu.be/XNXJtxkUKeY)\n* [Argo Rollouts - Canary Deployments Made Easy In Kubernetes](https://youtu.be/84Ky0aPbHvY)\n* [How Intuit Does Canary and Blue Green Deployments](https://www.youtube.com/watch?v=yeVkTTO9nOA)\n* [Leveling Up Your CD: Unlocking Progressive Delivery on Kubernetes](https://www.youtube.com/watch?v=Nv0PPwbIEkY)\n* [Minimize failed deployments with Argo Rollouts and Smoke tests](https://codefresh.io/continuous-deployment/minimize-failed-deployments-argo-rollouts-smoke-tests/)\n* [Recover automatically from failed deployments with Argo Rollouts and Prometheus metrics](https://codefresh.io/continuous-deployment/recover-automatically-from-failed-deployments/)\n* [Kubernetes Blue-Green deployments with Argo Rollouts](https://www.youtube.com/watch?v=krDxDz4V4Tg)\n* [Kubernetes canary deployments with Argo Rollouts](https://www.youtube.com/watch?v=fviYWA2mcF8)\n* [GitOps with Argo CD and an Argo Rollouts canary release](https://www.youtube.com/watch?v=35Qimb_AZ8U)\n* [Multi-Stage Delivery with Keptn and Argo Rollouts](https://www.youtube.com/watch?v=w-E8FzTbN3g&t=1s)\n* [Gradual Code Releases Using an In-House Kubernetes Canary Controller on top of Argo Rollouts](https://doordash.engineering/2021/04/14/gradual-code-releases-using-an-in-house-kubernetes-canary-controller/)\n* [How Scalable is Argo-Rollouts: A Cloud Operator‚Äôs Perspective](https://www.youtube.com/watch?v=rCEhxJ2NSTI)\n* [Minimize Impact in Kubernetes Using Argo Rollouts](https://medium.com/@arielsimhon/minimize-impact-in-kubernetes-using-argo-rollouts-992fb9519969)\n* [Progressive Application Delivery with GitOps on Red Hat OpenShift](https://www.youtube.com/watch?v=DfeL7cdTx4c)\n* [Progressive delivery for Kubernetes Config Maps using Argo Rollouts](https://codefresh.io/blog/progressive-delivery-for-kubernetes-config-maps-using-argo-rollouts/)\n* [Multi-Service Progressive Delivery with Argo Rollouts](https://codefresh.io/blog/multi-service-progressive-delivery-with-argo-rollouts/)\n* [Progressive Delivery for Stateful Services Using Argo Rollouts](https://codefresh.io/blog/progressive-delivery-for-stateful-services-using-argo-rollouts/)\n",
      "stars_today": 1
    },
    {
      "id": 96496250,
      "name": "swift-snapshot-testing",
      "full_name": "pointfreeco/swift-snapshot-testing",
      "description": "üì∏ Delightful Swift snapshot testing.",
      "html_url": "https://github.com/pointfreeco/swift-snapshot-testing",
      "stars": 4113,
      "forks": 642,
      "language": "Swift",
      "topics": [
        "screenshot-testing",
        "snapshot-testing",
        "swift",
        "testing"
      ],
      "created_at": "2017-07-07T03:38:51Z",
      "updated_at": "2026-01-22T00:53:32Z",
      "pushed_at": "2025-11-17T17:51:33Z",
      "open_issues": 195,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# üì∏ SnapshotTesting\n\n[![CI](https://github.com/pointfreeco/swift-snapshot-testing/workflows/CI/badge.svg)](https://actions-badge.atrox.dev/pointfreeco/swift-snapshot-testing/goto)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](http://pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-snapshot-testing%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-snapshot-testing%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing)\n\nDelightful Swift snapshot testing.\n\n## Usage\n\nOnce [installed](#installation), _no additional configuration is required_. You can import the\n`SnapshotTesting` module and call the `assertSnapshot` function.\n\n``` swift\nimport SnapshotTesting\nimport Testing\n\n@MainActor\nstruct MyViewControllerTests {\n  @Test func myViewController() {\n    let vc = MyViewController()\n\n    assertSnapshot(of: vc, as: .image)\n  }\n}\n```\n\nWhen an assertion first runs, a snapshot is automatically recorded to disk and the test will fail,\nprinting out the file path of any newly-recorded reference.\n\n> ‚ùå failed - No reference was found on disk. Automatically recorded snapshot: ‚Ä¶\n>\n> open \"‚Ä¶/MyAppTests/\\_\\_Snapshots\\_\\_/MyViewControllerTests/testMyViewController.png\"\n>\n> Re-run \"testMyViewController\" to test against the newly-recorded snapshot.\n\nRepeat test runs will load this reference and compare it with the runtime value. If they don't\nmatch, the test will fail and describe the difference. Failures can be inspected from Xcode's Report\nNavigator or by inspecting the file URLs of the failure.\n\nYou can record a new reference by customizing snapshots inline with the assertion, or using the\n`withSnapshotTesting` tool:\n\n```swift\n// Record just this one snapshot\nassertSnapshot(of: vc, as: .image, record: .all)\n\n// Record all snapshots in a scope:\nwithSnapshotTesting(record: .all) {\n  assertSnapshot(of: vc1, as: .image)\n  assertSnapshot(of: vc2, as: .image)\n  assertSnapshot(of: vc3, as: .image)\n}\n\n// Record all snapshot failures in a Swift Testing suite:\n@Suite(.snapshots(record: .failed))\nstruct FeatureTests {}\n\n// Record all snapshot failures in an 'XCTestCase' subclass:\nclass FeatureTests: XCTestCase {\n  override func invokeTest() {\n    withSnapshotTesting(record: .failed) {\n      super.invokeTest()\n    }\n  }\n}\n```\n\n## Snapshot Anything\n\nWhile most snapshot testing libraries in the Swift community are limited to `UIImage`s of `UIView`s,\nSnapshotTesting can work with _any_ format of _any_ value on _any_ Swift platform!\n\nThe `assertSnapshot` function accepts a value and any snapshot strategy that value supports. This\nmeans that a view or view controller can be tested against an image representation _and_ against a\ntextual representation of its properties and subview hierarchy.\n\n``` swift\nassertSnapshot(of: vc, as: .image)\nassertSnapshot(of: vc, as: .recursiveDescription)\n```\n\nView testing is highly configurable. You can override trait collections (for specific size classes\nand content size categories) and generate device-agnostic snapshots, all from a single simulator.\n\n``` swift\nassertSnapshot(of: vc, as: .image(on: .iPhoneSe))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneSe))\n\nassertSnapshot(of: vc, as: .image(on: .iPhoneSe(.landscape)))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneSe(.landscape)))\n\nassertSnapshot(of: vc, as: .image(on: .iPhoneX))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneX))\n\nassertSnapshot(of: vc, as: .image(on: .iPadMini(.portrait)))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPadMini(.portrait)))\n```\n\n> **Warning**\n> Snapshots must be compared using the exact same simulator that originally took the reference to\n> avoid discrepancies between images.\n\nBetter yet, SnapshotTesting isn't limited to views and view controllers! There are a number of\navailable snapshot strategies to choose from.\n\nFor example, you can snapshot test URL requests (_e.g._, those that your API client prepares).\n\n``` swift\nassertSnapshot(of: urlRequest, as: .raw)\n// POST http://localhost:8080/account\n// Cookie: pf_session={\"userId\":\"1\"}\n//\n// email=blob%40pointfree.co&name=Blob\n```\n\nAnd you can snapshot test `Encodable` values against their JSON _and_ property list representations.\n\n``` swift\nassertSnapshot(of: user, as: .json)\n// {\n//   \"bio\" : \"Blobbed around the world.\",\n//   \"id\" : 1,\n//   \"name\" : \"Blobby\"\n// }\n\nassertSnapshot(of: user, as: .plist)\n// <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n// <!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\"\n//  \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n// <plist version=\"1.0\">\n// <dict>\n//   <key>bio</key>\n//   <string>Blobbed around the world.</string>\n//   <key>id</key>\n//   <integer>1</integer>\n//   <key>name</key>\n//   <string>Blobby</string>\n// </dict>\n// </plist>\n```\n\nIn fact, _any_ value can be snapshot-tested by default using its\n[mirror](https://developer.apple.com/documentation/swift/mirror)!\n\n``` swift\nassertSnapshot(of: user, as: .dump)\n// ‚ñø User\n//   - bio: \"Blobbed around the world.\"\n//   - id: 1\n//   - name: \"Blobby\"\n```\n\nIf your data can be represented as an image, text, or data, you can write a snapshot test for it!\n\n## Documentation\n\nThe latest documentation is available\n[here](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting).\n\n## Installation\n\n### Xcode\n\n> **Warning**\n> By default, Xcode will try to add the SnapshotTesting package to your project's main\n> application/framework target. Please ensure that SnapshotTesting is added to a _test_ target\n> instead, as documented in the last step, below.\n\n 1. From the **File** menu, navigate through **Swift Packages** and select\n    **Add Package Dependency‚Ä¶**.\n 2. Enter package repository URL: `https://github.com/pointfreeco/swift-snapshot-testing`.\n 3. Confirm the version and let Xcode resolve the package.\n 4. On the final dialog, update SnapshotTesting's **Add to Target** column to a test target that\n    will contain snapshot tests (if you have more than one test target, you can later add\n    SnapshotTesting to them by manually linking the library in its build phase).\n\n### Swift Package Manager\n\nIf you want to use SnapshotTesting in any other project that uses\n[SwiftPM](https://swift.org/package-manager/), add the package as a dependency in `Package.swift`:\n\n```swift\ndependencies: [\n  .package(\n    url: \"https://github.com/pointfreeco/swift-snapshot-testing\",\n    from: \"1.12.0\"\n  ),\n]\n```\n\nNext, add `SnapshotTesting` as a dependency of your test target:\n\n```swift\ntargets: [\n  .target(name: \"MyApp\"),\n  .testTarget(\n    name: \"MyAppTests\",\n    dependencies: [\n      \"MyApp\",\n      .product(name: \"SnapshotTesting\", package: \"swift-snapshot-testing\"),\n    ]\n  )\n]\n```\n\n## Features\n\n  - [**Dozens of snapshot strategies**][available-strategies]. Snapshot\n    testing isn't just for `UIView`s and `CALayer`s. Write snapshots against _any_ value.\n  - [**Write your own snapshot strategies**][defining-strategies].\n    If you can convert it to an image, string, data, or your own diffable format, you can snapshot\n    test it! Build your own snapshot strategies from scratch or transform existing ones.\n  - **No configuration required.** Don't fuss with scheme settings and environment variables.\n    Snapshots are automatically saved alongside your tests.\n  - **More hands-off.** New snapshots are recorded whether `isRecording` mode is `true` or not.\n  - **Subclass-free.** Assert from any XCTest case or Quick spec.\n  - **Device-agnostic snapshots.** Render views and view controllers for specific devices and trait\n    collections from a single simulator.\n  - **First-class Xcode support.** Image differences are captured as XCTest attachments. Text\n    differences are rendered in inline error messages.\n  - **Supports any platform that supports Swift.** Write snapshot tests for iOS, Linux, macOS, and\n    tvOS.\n  - **SceneKit, SpriteKit, and WebKit support.** Most snapshot testing libraries don't support these\n    view subclasses.\n  - **`Codable` support**. Snapshot encodable data structures into their JSON and property list\n    representations.\n  - **Custom diff tool integration**. Configure failure messages to print diff commands for\n    [Kaleidoscope](https://kaleidoscope.app) or your diff tool of choice.\n    ``` swift\n    SnapshotTesting.diffToolCommand = { \"ksdiff \\($0) \\($1)\" }\n    ```\n\n[available-strategies]: https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting/snapshotting\n[defining-strategies]: https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting/customstrategies\n\n## Plug-ins\n\n  - [AccessibilitySnapshot](https://github.com/cashapp/AccessibilitySnapshot) adds easy regression\n    testing for iOS accessibility.\n    \n  - [AccessibilitySnapshotColorBlindness](https://github.com/Sherlouk/AccessibilitySnapshotColorBlindness)\n    adds snapshot strategies for color blindness simulation on iOS views, view controllers and images.\n\n  - [GRDBSnapshotTesting](https://github.com/SebastianOsinski/GRDBSnapshotTesting) adds snapshot\n    strategy for testing SQLite database migrations made with [GRDB](https://github.com/groue/GRDB.swift).\n\n  - [Nimble-SnapshotTesting](https://github.com/tahirmt/Nimble-SnapshotTesting) adds \n    [Nimble](https://github.com/Quick/Nimble) matchers for SnapshotTesting to be used by Swift\n    Package Manager.\n\n  - [Prefire](https://github.com/BarredEwe/Prefire) generating Snapshot Tests via\n    [Swift Package Plugins](https://github.com/apple/swift-package-manager/blob/main/Documentation/Plugins.md)\n    using SwiftUI `Preview`\n  \n  - [PreviewSnapshots](https://github.com/doordash-oss/swiftui-preview-snapshots) share `View`\n    configurations between SwiftUI Previews and snapshot tests and generate several snapshots with a\n    single test assertion.\n\n  - [swift-html](https://github.com/pointfreeco/swift-html) is a Swift DSL for type-safe,\n    extensible, and transformable HTML documents and includes an `HtmlSnapshotTesting` module to\n    snapshot test its HTML documents.\n\n  - [swift-snapshot-testing-nimble](https://github.com/Killectro/swift-snapshot-testing-nimble) adds\n    [Nimble](https://github.com/Quick/Nimble) matchers for SnapshotTesting.\n\n  - [swift-snapshot-testing-stitch](https://github.com/Sherlouk/swift-snapshot-testing-stitch/) adds\n    the ability to stitch multiple UIView's or UIViewController's together in a single test.\n\n  - [SnapshotTestingDump](https://github.com/tahirmt/swift-snapshot-testing-dump) Adds support to\n    use [swift-custom-dump](https://github.com/pointfreeco/swift-custom-dump/) by using `customDump`\n    strategy for `Any`\n\n  - [SnapshotTestingHEIC](https://github.com/alexey1312/SnapshotTestingHEIC) adds image support\n  using the HEIC storage format which reduces file sizes in comparison to PNG.\n\n  - [SnapshotVision](https://github.com/gregersson/swift-snapshot-testing-vision) adds snapshot\n    strategy for text recognition on views and images. Uses Apples Vision framework.\n\nHave you written your own SnapshotTesting plug-in?\n[Add it here](https://github.com/pointfreeco/swift-snapshot-testing/edit/master/README.md) and\nsubmit a pull request!\n\n## Related Tools\n\n  - [`iOSSnapshotTestCase`](https://github.com/uber/ios-snapshot-test-case/) helped introduce screen\n    shot testing to a broad audience in the iOS community. Experience with it inspired the creation\n    of this library.\n\n  - [Jest](https://jestjs.io) brought generalized snapshot testing to the JavaScript community with\n    a polished user experience. Several features of this library (diffing, automatically capturing\n    new snapshots) were directly influenced.\n\n## Learn More\n\nSnapshotTesting was designed with [witness-oriented programming](https://www.pointfree.co/episodes/ep39-witness-oriented-library-design).\n\nThis concept (and more) are explored thoroughly in a series of episodes on\n[Point-Free](https://www.pointfree.co), a video series exploring functional programming and Swift\nhosted by [Brandon Williams](https://twitter.com/mbrandonw) and\n[Stephen Celis](https://twitter.com/stephencelis).\n\nWitness-oriented programming and the design of this library was explored in the following\n[Point-Free](https://www.pointfree.co) episodes:\n\n  - [Episode 33](https://www.pointfree.co/episodes/ep33-protocol-witnesses-part-1): Protocol Witnesses: Part 1\n  - [Episode 34](https://www.pointfree.co/episodes/ep34-protocol-witnesses-part-1): Protocol Witnesses: Part 2\n  - [Episode 35](https://www.pointfree.co/episodes/ep35-advanced-protocol-witnesses-part-1): Advanced Protocol Witnesses: Part 1\n  - [Episode 36](https://www.pointfree.co/episodes/ep36-advanced-protocol-witnesses-part-2): Advanced Protocol Witnesses: Part 2\n  - [Episode 37](https://www.pointfree.co/episodes/ep37-protocol-oriented-library-design-part-1): Protocol-Oriented Library Design: Part 1\n  - [Episode 38](https://www.pointfree.co/episodes/ep38-protocol-oriented-library-design-part-2): Protocol-Oriented Library Design: Part 2\n  - [Episode 39](https://www.pointfree.co/episodes/ep39-witness-oriented-library-design): Witness-Oriented Library Design\n  - [Episode 40](https://www.pointfree.co/episodes/ep40-async-functional-refactoring): Async Functional Refactoring\n  - [Episode 41](https://www.pointfree.co/episodes/ep41-a-tour-of-snapshot-testing): A Tour of Snapshot Testing üÜì\n\n<a href=\"https://www.pointfree.co/episodes/ep41-a-tour-of-snapshot-testing\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0041.jpeg\" width=\"480\">\n</a>\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n",
      "stars_today": 1
    },
    {
      "id": 35927665,
      "name": "seurat",
      "full_name": "satijalab/seurat",
      "description": "R toolkit for single cell genomics",
      "html_url": "https://github.com/satijalab/seurat",
      "stars": 2619,
      "forks": 977,
      "language": "R",
      "topics": [
        "cran",
        "human-cell-atlas",
        "single-cell-genomics",
        "single-cell-rna-seq"
      ],
      "created_at": "2015-05-20T05:23:02Z",
      "updated_at": "2026-01-22T14:08:40Z",
      "pushed_at": "2026-01-21T19:54:02Z",
      "open_issues": 314,
      "owner": {
        "login": "satijalab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8411851?v=4"
      },
      "readme": "[![CRAN Version](https://www.r-pkg.org/badges/version/Seurat)](https://cran.r-project.org/package=Seurat)\n[![CRAN Downloads](https://cranlogs.r-pkg.org/badges/Seurat)](https://cran.r-project.org/package=Seurat)\n\n\n# Seurat v5\n\nSeurat is an R toolkit for single cell genomics, developed and maintained by the Satija Lab at NYGC.\n\nWe are excited to release Seurat v5! This updates introduces new functionality for spatial, multimodal, and scalable single-cell analysis.\n\nSeurat v5 is backwards-compatible with previous versions, so that users will continue to be able to re-run existing workflows. \n\nInstructions, documentation, and tutorials can be found at:\n\n* https://satijalab.org/seurat\n\nSeurat is also hosted on GitHub, you can view and clone the repository at\n\n* https://github.com/satijalab/seurat\n\nSeurat has been successfully installed on Mac OS X, Linux, and Windows, using the devtools package to install directly from GitHub\n\nImprovements and new features will be added on a regular basis, please post on the [github page](https://github.com/satijalab/seurat) with any questions or if you would like to contribute\n\nFor a version history/changelog, please see the [NEWS file](https://github.com/satijalab/seurat/blob/master/NEWS.md).\n",
      "stars_today": 1
    },
    {
      "id": 190275430,
      "name": "hidapi",
      "full_name": "libusb/hidapi",
      "description": "A Simple cross-platform library for communicating with HID devices",
      "html_url": "https://github.com/libusb/hidapi",
      "stars": 2102,
      "forks": 453,
      "language": "C",
      "topics": [
        "android",
        "bluetooth",
        "bsd",
        "c",
        "hid",
        "hidapi",
        "hidapi-library",
        "hidraw",
        "i2c",
        "linux",
        "macos",
        "spi",
        "usb",
        "usb-hid",
        "windows"
      ],
      "created_at": "2019-06-04T20:36:19Z",
      "updated_at": "2026-01-22T17:51:38Z",
      "pushed_at": "2026-01-15T14:17:10Z",
      "open_issues": 59,
      "owner": {
        "login": "libusb",
        "avatar_url": "https://avatars.githubusercontent.com/u/4439549?v=4"
      },
      "readme": "## HIDAPI library for Windows, Linux, FreeBSD and macOS\n\n| CI instance          | Status |\n|----------------------|--------|\n| `Linux/macOS/Windows (master)` | [![GitHub Builds](https://github.com/libusb/hidapi/actions/workflows/builds.yml/badge.svg?branch=master)](https://github.com/libusb/hidapi/actions/workflows/builds.yml?query=branch%3Amaster) |\n| `Windows (master)` | [![Build status](https://ci.appveyor.com/api/projects/status/xfmr5fo8w0re8ded/branch/master?svg=true)](https://ci.appveyor.com/project/libusb/hidapi/branch/master) |\n| `BSD, last build (branch/PR)` | [![builds.sr.ht status](https://builds.sr.ht/~z3ntu/hidapi.svg)](https://builds.sr.ht/~z3ntu/hidapi) |\n| `Coverity Scan (last)` | [![Coverity Scan](https://scan.coverity.com/projects/583/badge.svg)](https://scan.coverity.com/projects/hidapi) |\n\nHIDAPI is a multi-platform library which allows an application to interface\nwith USB and Bluetooth HID-Class devices on Windows, Linux, FreeBSD, and macOS.\nHIDAPI can be either built as a shared library (`.so`, `.dll` or `.dylib`) or\ncan be embedded directly into a target application by adding a _single source_\nfile (per platform) and a single header.<br>\nSee [remarks](BUILD.md#embedding-hidapi-directly-into-your-source-tree) on embedding _directly_ into your build system.\n\nHIDAPI library was originally developed by Alan Ott ([signal11](https://github.com/signal11)).\n\nIt was moved to [libusb/hidapi](https://github.com/libusb/hidapi) on June 4th, 2019, in order to merge important bugfixes and continue development of the library.\n\n## Table of Contents\n\n* [About](#about)\n    * [Test GUI](#test-gui)\n    * [Console Test App](#console-test-app)\n* [What Does the API Look Like?](#what-does-the-api-look-like)\n* [License](#license)\n* [Installing HIDAPI](#installing-hidapi)\n* [Build from Source](#build-from-source)\n\n\n## About\n\n### HIDAPI has four back-ends:\n* Windows (using `hid.dll`)\n* Linux/hidraw (using the Kernel's hidraw driver)\n* libusb (using libusb-1.0 - Linux/BSD/other UNIX-like systems)\n* macOS (using IOHidManager)\n\nOn Linux, either the hidraw or the libusb back-end can be used. There are\ntradeoffs, and the functionality supported is slightly different. Both are\nbuilt by default. It is up to the application linking to hidapi to choose\nthe backend at link time by linking to either `libhidapi-libusb` or\n`libhidapi-hidraw`.\n\nNote that you will need to install an udev rule file with your application\nfor unprivileged users to be able to access HID devices with hidapi. Refer\nto the [69-hid.rules](udev/69-hid.rules) file in the `udev` directory\nfor an example.\n\n#### __Linux/hidraw__ (`linux/hid.c`):\n\nThis back-end uses the hidraw interface in the Linux kernel, and supports\nboth USB and Bluetooth HID devices. It requires kernel version at least 2.6.39\nto build. In addition, it will only communicate with devices which have hidraw\nnodes associated with them.\nKeyboards, mice, and some other devices which are blacklisted from having\nhidraw nodes will not work. Fortunately, for nearly all the uses of hidraw,\nthis is not a problem.\n\n#### __Linux/FreeBSD/libusb__ (`libusb/hid.c`):\n\nThis back-end uses libusb-1.0 to communicate directly to a USB device. This\nback-end will of course not work with Bluetooth devices.\n\n### Test GUI\n\nHIDAPI also comes with a Test GUI. The Test GUI is cross-platform and uses\nFox Toolkit <http://www.fox-toolkit.org>.  It will build on every platform\nwhich HIDAPI supports.  Since it relies on a 3rd party library, building it\nis optional but it is useful when debugging hardware.\n\nNOTE: Test GUI based on Fox Toolkit is not actively developed nor supported\nby HIDAPI team. It is kept as a historical artifact. It may even work sometime\nor on some platforms, but it is not going to get any new features or bugfixes.\n\nInstructions for installing Fox-Toolkit on each platform is not provided.\nMake sure to use Fox-Toolkit v1.6 if you choose to use it.\n\n### Console Test App\n\nIf you want to play around with your HID device before starting\nany development with HIDAPI and using a GUI app is not an option for you, you may try [`hidapitester`](https://github.com/todbot/hidapitester).\n\nThis app has a console interface for most of the features supported\nby HIDAPI library.\n\n## What Does the API Look Like?\n\nThe API provides the most commonly used HID functions including sending\nand receiving of input, output, and feature reports. The sample program,\nwhich communicates with a heavily hacked up version of the Microchip USB\nGeneric HID sample looks like this (with error checking removed for\nsimplicity):\n\n**Warning: Only run the code you understand, and only when it conforms to the\ndevice spec. Writing data (`hid_write`) at random to your HID devices can break them.**\n\n```c\n#include <stdio.h> // printf\n#include <wchar.h> // wchar_t\n\n#include <hidapi.h>\n\n#define MAX_STR 255\n\nint main(int argc, char* argv[])\n{\n\tint res;\n\tunsigned char buf[65];\n\twchar_t wstr[MAX_STR];\n\thid_device *handle;\n\tint i;\n\n\t// Initialize the hidapi library\n\tres = hid_init();\n\n\t// Open the device using the VID, PID,\n\t// and optionally the Serial number.\n\thandle = hid_open(0x4d8, 0x3f, NULL);\n\tif (!handle) {\n\t\tprintf(\"Unable to open device\\n\");\n\t\thid_exit();\n \t\treturn 1;\n\t}\n\n\t// Read the Manufacturer String\n\tres = hid_get_manufacturer_string(handle, wstr, MAX_STR);\n\tprintf(\"Manufacturer String: %ls\\n\", wstr);\n\n\t// Read the Product String\n\tres = hid_get_product_string(handle, wstr, MAX_STR);\n\tprintf(\"Product String: %ls\\n\", wstr);\n\n\t// Read the Serial Number String\n\tres = hid_get_serial_number_string(handle, wstr, MAX_STR);\n\tprintf(\"Serial Number String: (%d) %ls\\n\", wstr[0], wstr);\n\n\t// Read Indexed String 1\n\tres = hid_get_indexed_string(handle, 1, wstr, MAX_STR);\n\tprintf(\"Indexed String 1: %ls\\n\", wstr);\n\n\t// Toggle LED (cmd 0x80). The first byte is the report number (0x0).\n\tbuf[0] = 0x0;\n\tbuf[1] = 0x80;\n\tres = hid_write(handle, buf, 65);\n\n\t// Request state (cmd 0x81). The first byte is the report number (0x0).\n\tbuf[0] = 0x0;\n\tbuf[1] = 0x81;\n\tres = hid_write(handle, buf, 65);\n\n\t// Read requested state\n\tres = hid_read(handle, buf, 65);\n\n\t// Print out the returned buffer.\n\tfor (i = 0; i < 4; i++)\n\t\tprintf(\"buf[%d]: %d\\n\", i, buf[i]);\n\n\t// Close the device\n\thid_close(handle);\n\n\t// Finalize the hidapi library\n\tres = hid_exit();\n\n\treturn 0;\n}\n```\n\nYou can also use [hidtest/test.c](hidtest/test.c)\nas a starting point for your applications.\n\n\n## License\n\nHIDAPI may be used by one of three licenses as outlined in [LICENSE.txt](LICENSE.txt).\n\n## Installing HIDAPI\n\nIf you want to build your own application that uses HID devices with HIDAPI,\nyou need to get HIDAPI development package.\n\nDepending on what your development environment is, HIDAPI likely to be provided\nby your package manager.\n\nFor instance on Ubuntu, HIDAPI is available via APT:\n```sh\nsudo apt install libhidapi-dev\n```\n\nHIDAPI package name for other systems/package managers may differ.\nCheck the documentation/package list of your package manager.\n\n## Build from Source\n\nCheck [BUILD.md](BUILD.md) for details.\n",
      "stars_today": 1
    },
    {
      "id": 30017750,
      "name": "ComplexHeatmap",
      "full_name": "jokergoo/ComplexHeatmap",
      "description": "Make Complex Heatmaps ",
      "html_url": "https://github.com/jokergoo/ComplexHeatmap",
      "stars": 1460,
      "forks": 242,
      "language": "R",
      "topics": [
        "clustering",
        "complex-heatmaps",
        "heatmap"
      ],
      "created_at": "2015-01-29T11:45:58Z",
      "updated_at": "2026-01-22T03:15:30Z",
      "pushed_at": "2025-06-23T15:51:50Z",
      "open_issues": 227,
      "owner": {
        "login": "jokergoo",
        "avatar_url": "https://avatars.githubusercontent.com/u/449218?v=4"
      },
      "readme": "# Make Complex Heatmaps <a href=\"https://jokergoo.github.io/ComplexHeatmap-reference/book/\"><img src=\"https://jokergoo.github.io/ComplexHeatmap-reference/book/complexheatmap-cover.jpg\" width=240 align=\"right\" style=\"border:2px solid black;\" ></a>\n\n[![R-CMD-check](https://github.com/jokergoo/ComplexHeatmap/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/ComplexHeatmap/actions)\n[![codecov](https://img.shields.io/codecov/c/github/jokergoo/ComplexHeatmap.svg)](https://codecov.io/github/jokergoo/ComplexHeatmap) \n[![bioc](http://www.bioconductor.org/shields/downloads/devel/ComplexHeatmap.svg)](https://bioconductor.org/packages/stats/bioc/ComplexHeatmap/) \n[![bioc](http://www.bioconductor.org/shields/years-in-bioc/ComplexHeatmap.svg)](http://bioconductor.org/packages/devel/bioc/html/ComplexHeatmap.html)\n\n<img src=\"http://jokergoo.github.io/complexheatmap_logo.svg\" width=\"550\">\n\n\nComplex heatmaps are efficient to visualize associations between different\nsources of data sets and reveal potential patterns. Here the\n**ComplexHeatmap** package provides a highly flexible way to arrange multiple\nheatmaps and supports various annotation graphics.\n\nThe [**InteractiveComplexHeatmap**](https://github.com/jokergoo/InteractiveComplexHeatmap) package can directly export static complex heatmaps into an interactive Shiny app. Have a try!\n\n## Citation\n\nZuguang Gu, et al., [Complex heatmaps reveal patterns and correlations in multidimensional genomic data](http://bioinformatics.oxfordjournals.org/content/early/2016/05/20/bioinformatics.btw313.abstract), Bioinformatics, 2016.\n\nZuguang Gu. [Complex Heatmap Visualization](https://doi.org/10.1002/imt2.43), iMeta, 2022. \n\n\n## Install\n\n`ComplexHeatmap` is available on [Bioconductor](http://www.bioconductor.org/packages/devel/bioc/html/ComplexHeatmap.html), you can install it by:\n\n```r\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"ComplexHeatmap\")\n```\n\nIf you want the latest version, install it directly from GitHub:\n\n```r\nlibrary(devtools)\ninstall_github(\"jokergoo/ComplexHeatmap\")\n```\n\n## Usage\n\nMake a single heatmap:\n\n```r\nHeatmap(mat, ...)\n```\n\nA single Heatmap with column annotations:\n\n```r\nha = HeatmapAnnotation(df = anno1, anno_fun = anno2, ...)\nHeatmap(mat, ..., top_annotation = ha)\n```\n\nMake a list of heatmaps:\n\n```r\nHeatmap(mat1, ...) + Heatmap(mat2, ...)\n```\n\nMake a list of heatmaps and row annotations:\n\n```r\nha = HeatmapAnnotation(df = anno1, anno_fun = anno2, ..., which = \"row\")\nHeatmap(mat1, ...) + Heatmap(mat2, ...) + ha\n```\n\n## Documentation\n\nThe full documentations are available at https://jokergoo.github.io/ComplexHeatmap-reference/book/ and the website is at https://jokergoo.github.io/ComplexHeatmap.\n\n## Blog posts\n\nThere are following blog posts focusing on specific topics:\n\n- [Make 3D heatmap](https://jokergoo.github.io/2021/03/24/3d-heatmap/)\n- [Translate from pheatmap to ComplexHeatmap](https://jokergoo.github.io/2020/05/06/translate-from-pheatmap-to-complexheatmap/)\n- [Set cell width/height in the heatmap](https://jokergoo.github.io/2020/05/11/set-cell-width/height-in-the-heatmap/)\n- [Interactive ComplexHeatmap](https://jokergoo.github.io/2020/05/15/interactive-complexheatmap/)\n- [Word cloud as heatmap annotation](https://jokergoo.github.io/2020/05/31/word-cloud-as-heatmap-annotation/)\n- [Which heatmap function is faster?](https://jokergoo.github.io/2020/06/19/which-heatmap-function-is-faster/)\n- [Rasterization in ComplexHeatmap](https://jokergoo.github.io/2020/06/30/rasterization-in-complexheatmap/)\n- [Block annotation over several slices](https://jokergoo.github.io/2020/07/06/block-annotation-over-several-slices/)\n- [Integrate ComplexHeatmap with cowplot package](https://jokergoo.github.io/2020/07/14/integrate-complexheatmap-with-cowplot-package/)\n\n\n## Examples\n\n### Visualize Methylation Profile with Complex Annotations\n\n![complexheatmap_example4](https://user-images.githubusercontent.com/449218/47718635-2ec22980-dc49-11e8-9f01-37becb19e0d5.png)\n\n### Correlations between methylation, expression and other genomic features\n\n![complexheatmap_example3](https://user-images.githubusercontent.com/449218/47718636-2ec22980-dc49-11e8-8db0-1659c27dcf40.png)\n\n### Visualize Cell Heterogeneity from Single Cell RNASeq\n\n![complexheatmap_example2](https://user-images.githubusercontent.com/449218/47718637-2ec22980-dc49-11e8-925e-955c16cfa982.png)\n\n### Making Enhanced OncoPrint\n\n![complexheatmap_example1](https://user-images.githubusercontent.com/449218/47718638-2ec22980-dc49-11e8-845e-21e51d3b8e73.png)\n\n### UpSet plot\n\n<img src=\"https://user-images.githubusercontent.com/449218/102615477-48c76a80-4136-11eb-98d9-3c528844fbe8.png\" width=500 />\n\n### 3D heatmap\n\n![image](https://user-images.githubusercontent.com/449218/112284448-8c77c600-8c89-11eb-8d38-c5538900df20.png)\n\n\n\n## License\n\nMIT @ Zuguang Gu\n\n",
      "stars_today": 1
    },
    {
      "id": 452908115,
      "name": "nflverse-data",
      "full_name": "nflverse/nflverse-data",
      "description": "Automated nflverse data repository",
      "html_url": "https://github.com/nflverse/nflverse-data",
      "stars": 329,
      "forks": 34,
      "language": "R",
      "topics": [],
      "created_at": "2022-01-28T02:01:18Z",
      "updated_at": "2026-01-22T20:36:16Z",
      "pushed_at": "2026-01-18T10:33:20Z",
      "open_issues": 6,
      "owner": {
        "login": "nflverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/79467114?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# nflverse-data\n\n<!-- badges: start -->\n<!-- badges: end -->\n\nThis repository holds automated data releases for nflverse projects\n(i.e.¬†all of the data powered/scraped via GitHub Actions).\n\n## Usage\n\nYou can download data hosted here with the `{nflreadr}` package, or\nmanually download and access the\n[releases](https://github.com/nflverse/nflverse-data/releases) page.\nReleases are roughly organized along the [main\nfunctions](https://nflreadr.nflverse.com/reference/) of nflreadr.\n\n## Automation Status\n\nPlease see https://nflreadr.nflverse.com/articles/nflverse_data_schedule.html#automation-status for the status table. \n",
      "stars_today": 1
    },
    {
      "id": 261039251,
      "name": "swift-composable-architecture",
      "full_name": "pointfreeco/swift-composable-architecture",
      "description": "A library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind.",
      "html_url": "https://github.com/pointfreeco/swift-composable-architecture",
      "stars": 14270,
      "forks": 1628,
      "language": "Swift",
      "topics": [
        "architecture",
        "composition",
        "modularity",
        "swiftui",
        "testability",
        "uikit"
      ],
      "created_at": "2020-05-03T23:18:40Z",
      "updated_at": "2026-01-23T00:48:36Z",
      "pushed_at": "2025-12-30T21:38:44Z",
      "open_issues": 24,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# The Composable Architecture\n\n[![CI](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml/badge.svg)](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](https://www.pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n\nThe Composable Architecture (TCA, for short) is a library for building applications in a consistent \nand understandable way, with composition, testing, and ergonomics in mind. It can be used in \nSwiftUI, UIKit, and more, and on any Apple platform (iOS, macOS, iPadOS, visionOS, tvOS, and watchOS).\n\n* [What is the Composable Architecture?](#what-is-the-composable-architecture)\n* [Learn more](#learn-more)\n* [Examples](#examples)\n* [Basic usage](#basic-usage)\n* [Documentation](#documentation)\n* [FAQ](#faq)\n* [Community](#community)\n* [Installation](#installation)\n* [Translations](#translations)\n\n## What is the Composable Architecture?\n\nThis library provides a few core tools that can be used to build applications of varying purpose and \ncomplexity. It provides compelling stories that you can follow to solve many problems you encounter \nday-to-day when building applications, such as:\n\n* **State management**\n  <br> How to manage the state of your application using simple value types, and share state across \n  many screens so that mutations in one screen can be immediately observed in another screen.\n\n* **Composition**\n  <br> How to break down large features into smaller components that can be extracted to their own, \n  isolated modules and be easily glued back together to form the feature.\n\n* **Side effects**\n  <br> How to let certain parts of the application talk to the outside world in the most testable \n  and understandable way possible.\n\n* **Testing**\n  <br> How to not only test a feature built in the architecture, but also write integration tests \n  for features that have been composed of many parts, and write end-to-end tests to understand how \n  side effects influence your application. This allows you to make strong guarantees that your \n  business logic is running in the way you expect.\n\n* **Ergonomics**\n  <br> How to accomplish all of the above in a simple API with as few concepts and moving parts as \n  possible.\n\n## Learn More\n\nThe Composable Architecture was designed over the course of many episodes on \n[Point-Free][pointfreeco], a video series exploring advanced programming topics in the Swift language, \nhosted by [Brandon Williams][mbrandonw] and [Stephen Celis][stephencelis].\n\nYou can watch all of the episodes [here][tca-episode-collection], as well as a dedicated, [multipart\ntour][tca-tour] of the architecture from scratch.\n\n<a href=\"https://www.pointfree.co/collections/tours/composable-architecture-1-0\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0243.jpeg\" width=\"600\">\n</a>\n\n## Examples\n\n[![Screen shots of example applications](https://d3rccdn33rt8ze.cloudfront.net/composable-architecture/demos.png)](./Examples)\n\nThis repo comes with _lots_ of examples to demonstrate how to solve common and complex problems with \nthe Composable Architecture. Check out [this](./Examples) directory to see them all, including:\n\n* [Case Studies](./Examples/CaseStudies)\n  * Getting started\n  * Effects\n  * Navigation\n  * Higher-order reducers\n  * Reusable components\n* [Location manager](https://github.com/pointfreeco/composable-core-location/tree/main/Examples/LocationManager)\n* [Motion manager](https://github.com/pointfreeco/composable-core-motion/tree/main/Examples/MotionManager)\n* [Search](./Examples/Search)\n* [Speech Recognition](./Examples/SpeechRecognition)\n* [SyncUps app](./Examples/SyncUps)\n* [Tic-Tac-Toe](./Examples/TicTacToe)\n* [Todos](./Examples/Todos)\n* [Voice memos](./Examples/VoiceMemos)\n\nLooking for something more substantial? Check out the source code for [isowords][gh-isowords], an \niOS word search game built in SwiftUI and the Composable Architecture.\n\n## Basic Usage\n\n> [!Note] \n> For a step-by-step interactive tutorial, be sure to check out [Meet the Composable\n> Architecture][meet-tca].\n\nTo build a feature using the Composable Architecture you define some types and values that model \nyour domain:\n\n* **State**: A type that describes the data your feature needs to perform its logic and render its \nUI.\n* **Action**: A type that represents all of the actions that can happen in your feature, such as \nuser actions, notifications, event sources and more.\n* **Reducer**: A function that describes how to evolve the current state of the app to the next \nstate given an action. The reducer is also responsible for returning any effects that should be \nrun, such as API requests, which can be done by returning an `Effect` value.\n* **Store**: The runtime that actually drives your feature. You send all user actions to the store \nso that the store can run the reducer and effects, and you can observe state changes in the store \nso that you can update UI.\n\nThe benefits of doing this are that you will instantly unlock testability of your feature, and you \nwill be able to break large, complex features into smaller domains that can be glued together.\n\nAs a basic example, consider a UI that shows a number along with \"+\" and \"‚àí\" buttons that increment \nand decrement the number. To make things interesting, suppose there is also a button that when \ntapped makes an API request to fetch a random fact about that number and displays it in the view.\n\nTo implement this feature we create a new type that will house the domain and behavior of the \nfeature, and it will be annotated with the `@Reducer` macro:\n\n```swift\nimport ComposableArchitecture\n\n@Reducer\nstruct Feature {\n}\n```\n\nIn here we need to define a type for the feature's state, which consists of an integer for the \ncurrent count, as well as an optional string that represents the fact being presented:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable {\n    var count = 0\n    var numberFact: String?\n  }\n}\n```\n\n> [!Note] \n> We've applied the `@ObservableState` macro to `State` in order to take advantage of the\n> observation tools in the library.\n\nWe also need to define a type for the feature's actions. There are the obvious actions, such as \ntapping the decrement button, increment button, or fact button. But there are also some slightly \nnon-obvious ones, such as the action that occurs when we receive a response from the fact API \nrequest:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action {\n    case decrementButtonTapped\n    case incrementButtonTapped\n    case numberFactButtonTapped\n    case numberFactResponse(String)\n  }\n}\n```\n\nAnd then we implement the `body` property, which is responsible for composing the actual logic and \nbehavior for the feature. In it we can use the `Reduce` reducer to describe how to change the\ncurrent state to the next state, and what effects need to be executed. Some actions don't need to\nexecute effects, and they can return `.none` to represent that:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action { /* ... */ }\n\n  var body: some Reducer<State, Action> {\n    Reduce { state, action in\n      switch action {\n      case .decrementButtonTapped:\n        state.count -= 1\n        return .none\n\n      case .incrementButtonTapped:\n        state.count += 1\n        return .none\n\n      case .numberFactButtonTapped:\n        return .run { [count = state.count] send in\n          let (data, _) = try await URLSession.shared.data(\n            from: URL(string: \"http://numbersapi.com/\\(count)/trivia\")!\n          )\n          await send(\n            .numberFactResponse(String(decoding: data, as: UTF8.self))\n          )\n        }\n\n      case let .numberFactResponse(fact):\n        state.numberFact = fact\n        return .none\n      }\n    }\n  }\n}\n```\n\nAnd then finally we define the view that displays the feature. It holds onto a `StoreOf<Feature>` \nso that it can observe all changes to the state and re-render, and we can send all user actions to \nthe store so that state changes:\n\n```swift\nstruct FeatureView: View {\n  let store: StoreOf<Feature>\n\n  var body: some View {\n    Form {\n      Section {\n        Text(\"\\(store.count)\")\n        Button(\"Decrement\") { store.send(.decrementButtonTapped) }\n        Button(\"Increment\") { store.send(.incrementButtonTapped) }\n      }\n\n      Section {\n        Button(\"Number fact\") { store.send(.numberFactButtonTapped) }\n      }\n      \n      if let fact = store.numberFact {\n        Text(fact)\n      }\n    }\n  }\n}\n```\n\nIt is also straightforward to have a UIKit controller driven off of this store. You can observe\nstate changes in the store in `viewDidLoad`, and then populate the UI components with data from\nthe store. The code is a bit longer than the SwiftUI version, so we have collapsed it here:\n\n<details>\n  <summary>Click to expand!</summary>\n\n  ```swift\n  class FeatureViewController: UIViewController {\n    let store: StoreOf<Feature>\n\n    init(store: StoreOf<Feature>) {\n      self.store = store\n      super.init(nibName: nil, bundle: nil)\n    }\n\n    required init?(coder: NSCoder) {\n      fatalError(\"init(coder:) has not been implemented\")\n    }\n\n    override func viewDidLoad() {\n      super.viewDidLoad()\n\n      let countLabel = UILabel()\n      let decrementButton = UIButton()\n      let incrementButton = UIButton()\n      let factLabel = UILabel()\n      \n      // Omitted: Add subviews and set up constraints...\n      \n      observe { [weak self] in\n        guard let self \n        else { return }\n        \n        countLabel.text = \"\\(self.store.count)\"\n        factLabel.text = self.store.numberFact\n      }\n    }\n\n    @objc private func incrementButtonTapped() {\n      self.store.send(.incrementButtonTapped)\n    }\n    @objc private func decrementButtonTapped() {\n      self.store.send(.decrementButtonTapped)\n    }\n    @objc private func factButtonTapped() {\n      self.store.send(.numberFactButtonTapped)\n    }\n  }\n  ```\n</details>\n\nOnce we are ready to display this view, for example in the app's entry point, we can construct a \nstore. This can be done by specifying the initial state to start the application in, as well as \nthe reducer that will power the application:\n\n```swift\nimport ComposableArchitecture\n\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd that is enough to get something on the screen to play around with. It's definitely a few more \nsteps than if you were to do this in a vanilla SwiftUI way, but there are a few benefits. It gives \nus a consistent manner to apply state mutations, instead of scattering logic in some observable \nobjects and in various action closures of UI components. It also gives us a concise way of \nexpressing side effects. And we can immediately test this logic, including the effects, without \ndoing much additional work.\n\n### Testing\n\n> [!Note] \n> For more in-depth information on testing, see the dedicated [testing][testing-article] article. \n\nTo test use a `TestStore`, which can be created with the same information as the `Store`, but it \ndoes extra work to allow you to assert how your feature evolves as actions are sent:\n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature()\n  }\n}\n```\n\nOnce the test store is created we can use it to make an assertion of an entire user flow of steps. \nEach step of the way we need to prove that state changed how we expect. For example, we can \nsimulate the user flow of tapping on the increment and decrement buttons:\n\n```swift\n// Test that tapping on the increment/decrement buttons changes the count\nawait store.send(.incrementButtonTapped) {\n  $0.count = 1\n}\nawait store.send(.decrementButtonTapped) {\n  $0.count = 0\n}\n```\n\nFurther, if a step causes an effect to be executed, which feeds data back into the store, we must \nassert on that. For example, if we simulate the user tapping on the fact button we expect to \nreceive a fact response back with the fact, which then causes the `numberFact` state to be \npopulated:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = ???\n}\n```\n\nHowever, how do we know what fact is going to be sent back to us?\n\nCurrently our reducer is using an effect that reaches out into the real world to hit an API server, \nand that means we have no way to control its behavior. We are at the whims of our internet \nconnectivity and the availability of the API server in order to write this test.\n\nIt would be better for this dependency to be passed to the reducer so that we can use a live \ndependency when running the application on a device, but use a mocked dependency for tests. We can \ndo this by adding a property to the `Feature` reducer:\n\n```swift\n@Reducer\nstruct Feature {\n  let numberFact: (Int) async throws -> String\n  // ...\n}\n```\n\nThen we can use it in the `reduce` implementation:\n\n```swift\ncase .numberFactButtonTapped:\n  return .run { [count = state.count] send in \n    let fact = try await self.numberFact(count)\n    await send(.numberFactResponse(fact))\n  }\n```\n\nAnd in the entry point of the application we can provide a version of the dependency that actually \ninteracts with the real world API server:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature(\n            numberFact: { number in\n              let (data, _) = try await URLSession.shared.data(\n                from: URL(string: \"http://numbersapi.com/\\(number)\")!\n              )\n              return String(decoding: data, as: UTF8.self)\n            }\n          )\n        }\n      )\n    }\n  }\n}\n```\n\nBut in tests we can use a mock dependency that immediately returns a deterministic, predictable \nfact: \n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature(numberFact: { \"\\($0) is a good number Brent\" })\n  }\n}\n```\n\nWith that little bit of upfront work we can finish the test by simulating the user tapping on the \nfact button, and then receiving the response from the dependency to present the fact:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = \"0 is a good number Brent\"\n}\n```\n\nWe can also improve the ergonomics of using the `numberFact` dependency in our application. Over \ntime the application may evolve into many features, and some of those features may also want access \nto `numberFact`, and explicitly passing it through all layers can get annoying. There is a process \nyou can follow to ‚Äúregister‚Äù dependencies with the library, making them instantly available to any \nlayer in the application.\n\n> [!Note] \n> For more in-depth information on dependency management, see the dedicated\n> [dependencies][dependencies-article] article. \n\nWe can start by wrapping the number fact functionality in a new type:\n\n```swift\nstruct NumberFactClient {\n  var fetch: (Int) async throws -> String\n}\n```\n\nAnd then registering that type with the dependency management system by conforming the client to\nthe `DependencyKey` protocol, which requires you to specify the live value to use when running the\napplication in simulators or devices:\n\n```swift\nextension NumberFactClient: DependencyKey {\n  static let liveValue = Self(\n    fetch: { number in\n      let (data, _) = try await URLSession.shared\n        .data(from: URL(string: \"http://numbersapi.com/\\(number)\")!\n      )\n      return String(decoding: data, as: UTF8.self)\n    }\n  )\n}\n\nextension DependencyValues {\n  var numberFact: NumberFactClient {\n    get { self[NumberFactClient.self] }\n    set { self[NumberFactClient.self] = newValue }\n  }\n}\n```\n\nWith that little bit of upfront work done you can instantly start making use of the dependency in \nany feature by using the `@Dependency` property wrapper:\n\n```diff\n @Reducer\n struct Feature {\n-  let numberFact: (Int) async throws -> String\n+  @Dependency(\\.numberFact) var numberFact\n   \n   ‚Ä¶\n\n-  try await self.numberFact(count)\n+  try await self.numberFact.fetch(count)\n }\n```\n\nThis code works exactly as it did before, but you no longer have to explicitly pass the dependency \nwhen constructing the feature's reducer. When running the app in previews, the simulator or on a \ndevice, the live dependency will be provided to the reducer, and in tests the test dependency will \nbe provided.\n\nThis means the entry point to the application no longer needs to construct dependencies:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd the test store can be constructed without specifying any dependencies, but you can still \noverride any dependency you need to for the purpose of the test:\n\n```swift\nlet store = TestStore(initialState: Feature.State()) {\n  Feature()\n} withDependencies: {\n  $0.numberFact.fetch = { \"\\($0) is a good number Brent\" }\n}\n\n// ...\n```\n\nThat is the basics of building and testing a feature in the Composable Architecture. There are \n_a lot_ more things to be explored, such as composition, modularity, adaptability, and complex \neffects. The [Examples](./Examples) directory has a bunch of projects to explore to see more \nadvanced usages.\n\n## Documentation\n\nThe documentation for releases and `main` are available here:\n\n* [`main`](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture)\n* [1.x.x](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/~/documentation/composablearchitecture)\n\nThere are a number of articles in the documentation that you may find helpful as you become more \ncomfortable with the library:\n\n* [Getting started][getting-started-article]\n* [Dependencies][dependencies-article]\n* [Testing][testing-article]\n* [Navigation][navigation-article]\n* [Sharing state][sharing-state-article]\n* [Performance][performance-article]\n* [Concurrency][concurrency-article]\n* [Bindings][bindings-article]\n\n## FAQ\n\nWe have a [dedicated article][faq-article] for all of the most frequently asked questions and\ncomments people have concerning the library.\n\n## Community\n\nIf you want to discuss the Composable Architecture or have a question about how to use it to solve \na particular problem, there are a number of places you can discuss with fellow \n[Point-Free](http://www.pointfree.co) enthusiasts:\n\n* For long-form discussions, we recommend the [discussions][gh-discussions] tab of this repo.\n* For casual chat, we recommend the [Point-Free Community slack](http://pointfree.co/slack-invite).\n\n## Installation\n\nYou can add ComposableArchitecture to an Xcode project by adding it as a package dependency.\n\n  1. From the **File** menu, select **Add Package Dependencies...**\n  2. Enter \"https://github.com/pointfreeco/swift-composable-architecture\" into the package \n     repository URL text field\n  3. Depending on how your project is structured:\n      - If you have a single application target that needs access to the library, then add \n        **ComposableArchitecture** directly to your application.\n      - If you want to use this library from multiple Xcode targets, or mix Xcode targets and SPM \n        targets, you must create a shared framework that depends on **ComposableArchitecture** and \n        then depend on that framework in all of your targets. For an example of this, check out the \n        [Tic-Tac-Toe](./Examples/TicTacToe) demo application, which splits lots of features into \n        modules and consumes the static library in this fashion using the **tic-tac-toe** Swift \n        package.\n\n## Companion libraries\n\nThe Composable Architecture is built with extensibility in mind, and there are a number of\ncommunity-supported libraries available to enhance your applications:\n\n* [Composable Architecture Extras](https://github.com/Ryu0118/swift-composable-architecture-extras):\n  A companion library to the Composable Architecture.\n* [TCAComposer](https://github.com/mentalflux/tca-composer): A macro framework for generating\n  boiler-plate code in the Composable Architecture.\n* [TCACoordinators](https://github.com/johnpatrickmorgan/TCACoordinators): The coordinator pattern\n  in the Composable Architecture.\n\nIf you'd like to contribute a library, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link\nto it!\n\n## Translations\n\nThe following translations of this README have been contributed by members of the community:\n\n* [Arabic](https://gist.github.com/NorhanBoghdadi/1b98d55c02b683ddef7e05c2ebcccd47)\n* [French](https://gist.github.com/nikitamounier/0e93eb832cf389db12f9a69da030a2dc)\n* [Hindi](https://gist.github.com/akashsoni01/b358ee0b3b747167964ef6946123c88d)\n* [Indonesian](https://gist.github.com/wendyliga/792ea9ac5cc887f59de70a9e39cc7343)\n* [Italian](https://gist.github.com/Bellaposa/5114e6d4d55fdb1388e8186886d48958)\n* [Japanese](https://gist.github.com/Achoo-kr/2d0712deb77f78b3379551ac7baea3e4)\n* [Korean](https://gist.github.com/Achoo-kr/5d8936d12e71028fcc4a7c5e078ca038)\n* [Polish](https://gist.github.com/MarcelStarczyk/6b6153051f46912a665c32199f0d1d54)\n* [Portuguese](https://gist.github.com/SevioCorrea/2bbf337cd084a58c89f2f7f370626dc8)\n* [Russian](https://gist.github.com/SubvertDev/3317d0c3b35ed601be330d6fc0df5aba)\n* [Simplified Chinese](https://gist.github.com/sh3l6orrr/10c8f7c634a892a9c37214f3211242ad)\n* [Spanish](https://gist.github.com/pitt500/f5e32fccb575ce112ffea2827c7bf942)\n* [Turkish](https://gist.github.com/gokhanamal/93001244ef0c1cec58abeb1afc0de37c)\n* [Ukrainian](https://gist.github.com/barabashd/33b64676195ce41f4bb73c327ea512a8)\n\nIf you'd like to contribute a translation, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link \nto a [Gist](https://gist.github.com)!\n\n## Credits and thanks\n\nThe following people gave feedback on the library at its early stages and helped make the library \nwhat it is today:\n\nPaul Colton, Kaan Dedeoglu, Matt Diephouse, Josef Dole≈æal, Eimantas, Matthew Johnson, George \nKaimakas, Nikita Leonov, Christopher Liscio, Jeffrey Macko, Alejandro Martinez, Shai Mishali, Willis \nPlummer, Simon-Pierre Roy, Justin Price, Sven A. Schmidt, Kyle Sherman, Petr ≈†√≠ma, Jasdev Singh, \nMaxim Smirnov, Ryan Stone, Daniel Hollis Tavares, and all of the [Point-Free][pointfreeco] \nsubscribers üòÅ.\n\nSpecial thanks to [Chris Liscio](https://twitter.com/liscio) who helped us work through many strange \nSwiftUI quirks and helped refine the final API.\n\nAnd thanks to [Shai Mishali](https://github.com/freak4pc) and the\n[CombineCommunity](https://github.com/CombineCommunity/CombineExt/) project, from which we took \ntheir implementation of `Publishers.Create`, which we use in `Effect` to help bridge delegate and \ncallback-based APIs, making it much easier to interface with 3rd party frameworks.\n\n## Other libraries\n\nThe Composable Architecture was built on a foundation of ideas started by other libraries, in \nparticular [Elm](https://elm-lang.org) and [Redux](https://redux.js.org/).\n\nThere are also many architecture libraries in the Swift and iOS community. Each one of these has \ntheir own set of priorities and trade-offs that differ from the Composable Architecture.\n\n* [RIBs](https://github.com/uber/RIBs)\n* [Loop](https://github.com/ReactiveCocoa/Loop)\n* [ReSwift](https://github.com/ReSwift/ReSwift)\n* [Workflow](https://github.com/square/workflow)\n* [ReactorKit](https://github.com/ReactorKit/ReactorKit)\n* [RxFeedback](https://github.com/NoTests/RxFeedback.swift)\n* [Mobius.swift](https://github.com/spotify/mobius.swift)\n* <details>\n  <summary>And more</summary>\n\n  * [Fluxor](https://github.com/FluxorOrg/Fluxor)\n  * [PromisedArchitectureKit](https://github.com/RPallas92/PromisedArchitectureKit)\n  </details>\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n\n[pointfreeco]: https://www.pointfree.co\n[mbrandonw]: https://twitter.com/mbrandonw\n[stephencelis]: https://twitter.com/stephencelis\n[tca-episode-collection]: https://www.pointfree.co/collections/composable-architecture\n[tca-tour]: https://www.pointfree.co/collections/tours/composable-architecture-1-0\n[gh-isowords]: https://github.com/pointfreeco/isowords\n[gh-discussions]: https://github.com/pointfreeco/swift-composable-architecture/discussions\n[swift-forum]: https://forums.swift.org/c/related-projects/swift-composable-architecture\n[testing-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/testingtca\n[faq-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/faq\n[dependencies-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/dependencymanagement\n[getting-started-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/gettingstarted\n[navigation-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/navigation\n[performance-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/performance\n[concurrency-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/swiftconcurrency\n[bindings-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/bindings\n[sharing-state-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/sharingstate\n[meet-tca]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/tutorials/meetcomposablearchitecture\n",
      "stars_today": 0
    },
    {
      "id": 12499251,
      "name": "checkstyle",
      "full_name": "checkstyle/checkstyle",
      "description": "Checkstyle is a development tool to help programmers write Java code that adheres to a coding standard. By default it supports the Google Java Style Guide and Sun Code Conventions, but is highly configurable. It can be invoked with an ANT task and a command line program.",
      "html_url": "https://github.com/checkstyle/checkstyle",
      "stars": 8824,
      "forks": 3964,
      "language": "Java",
      "topics": [
        "code-quality",
        "command-line-tool",
        "hacktoberfest",
        "java",
        "static-analysis",
        "static-code-analysis"
      ],
      "created_at": "2013-08-31T02:05:05Z",
      "updated_at": "2026-01-22T13:20:16Z",
      "pushed_at": "2026-01-23T02:10:33Z",
      "open_issues": 964,
      "owner": {
        "login": "checkstyle",
        "avatar_url": "https://avatars.githubusercontent.com/u/5179750?v=4"
      },
      "readme": "# Checkstyle - Java Code Quality Tool\n\n![](https://raw.githubusercontent.com/checkstyle/resources/master/img/checkstyle-logos/checkstyle-logo-260x99.png)\n\n--------------------------\n\n*Checkstyle is a tool that ensures adherence to a code standard or a set of best practices.*\n\n[![][appveyor img]][appveyor]\n[![][circleci img]][circleci]\n[![][cirrusci img]][cirrusci]\n[![][coverage img]][coverage]\n[![][snyk img]][snyk]\n[![][semaphoreci img]][semaphoreci]\n[![][azure img]][azure]\n[![][error prone img]][error prone]\n[![][pitest img]][pitest]\n[![][checker framework img]][checker framework]\n[![][dependabot img]][dependabot]\n[![][release notes/version img]][release notes/version]\n[![][closed issues img]][closed issues]\n[![][link check img]][link check]\n[![][milestone img]][milestone]\n\n[![][mavenbadge img]][mavenbadge]\n\nThe latest release version can be found at\n[GitHub releases](https://github.com/checkstyle/checkstyle/releases/)\nor at [Maven repo](https://repo1.maven.org/maven2/com/puppycrawl/tools/checkstyle/).\n\nDocumentation is available in HTML format, see https://checkstyle.org/checks.html .\n\n## Table of Contents\n\n- [Quick Start](#quick-start)\n- [Contributing](#contributing)\n- [Feedback and Support](#feedback-and-support)\n- [Javadoc](#javadoc)\n- [Sponsor Checkstyle](#sponsor-checkstyle)\n- [Licensing](#licensing)\n\n## Quick Start\n\n- Download our [Latest Release](https://github.com/checkstyle/checkstyle/releases/) from GitHub\n  or Add Checkstyle to your build from [Maven Central](https://mvnrepository.com/artifact/com.puppycrawl.tools/checkstyle).\n- Read our Documentation for [usage](https://checkstyle.org/cmdline.html)\n  and [configuration](https://checkstyle.org/config.html).\n\n```bash\n$ cat config.xml\n<?xml version=\"1.0\"?>\n<!DOCTYPE module PUBLIC\n          \"-//Puppy Crawl//DTD Check Configuration 1.3//EN\"\n          \"https://checkstyle.org/dtds/configuration_1_3.dtd\">\n<module name=\"Checker\">\n  <module name=\"TreeWalker\">\n    <module name=\"FallThrough\"/>\n  </module>\n</module>\n\n$ cat Test.java\nclass Test {\n  public void foo() {\n    int i = 0;\n    while (i >= 0) {\n      switch (i) {\n        case 1:\n        case 2:\n          i++;\n        case 3: // violation 'fall from previous branch of the switch'\n          i++;\n      }\n    }\n  }\n}\n\n$ java -jar checkstyle-10.18.1-all.jar -c config.xml Test.java\nStarting audit...\n[ERROR] Test.java:9:9: Fall through from previous branch of switch statement [FallThrough]\nAudit done.\nCheckstyle ends with 1 errors.\n```\n\n## Contributing\n\nThanks for your interest in contributing to CheckStyle! Please see the\n[Contribution Guidelines](https://github.com/checkstyle/checkstyle/blob/master/.github/CONTRIBUTING.md)\nfor information on how to contribute to the project. This includes creating issues, submitting pull\nrequests, and setting up your development environment.\n\n## Build Instructions\n\nPlease see the [CheckStyle Documentation](https://checkstyle.org/contributing.html#Build) for\ninformation on how to build the project.\n\n## Feedback and Support\n\n- Visit our [Discussions Page](https://github.com/checkstyle/checkstyle/discussions), where you\n  can ask questions and discuss the project with other users and contributors. This is our\n  preferred method of communication for topics\n  like usage and configuration questions, debugging, and other feedback.\n- [Stack Overflow](https://stackoverflow.com/questions/tagged/checkstyle) is another place to\n  ask questions about Checkstyle usage.\n- If you are interested in contributing to the project, you can join our\n  [Discord Contributors Chat](https://discord.com/channels/845645228467159061/1216455699488313554)\n  [with invite link](https://discord.gg/FsUsYC2ura).\n- Our [Google Groups Forum](https://groups.google.com/forum/?hl=en#!forum/checkstyle) is a\n  mailing list for discussion and support; however, we may be slow to respond there.\n\n## Javadoc\n\nTake a look at our [javadoc](https://checkstyle.org/apidocs/index.html) to see\nour API documentation.\n\n## Sponsor Checkstyle\n\nCheckstyle is an open-source project that is developed and maintained by volunteers. If you\nfind Checkstyle useful, please consider sponsoring the project. Your support helps us to\nmaintain and improve Checkstyle.\n\n- [Liberapay](https://liberapay.com/checkstyle/)\n- [OpenCollective](https://opencollective.com/checkstyle/)\n\n[![][backers.opencollective img]][backers.opencollective]\n\n[![][sponsors.opencollective img]][sponsors.opencollective]\n\n## Licensing\n\nCheckstyle is licensed under the [GNU LGPL v2.1 License](LICENSE).\nCheckstyle uses libraries:\n\n- [ANTLR](https://www.antlr.org/)\n- [Apache Commons](https://commons.apache.org/)\n- [Google Guava](https://github.com/google/guava/)\n- [Picocli](https://github.com/remkop/picocli/)\n\n## Development Tools Powered by\n\n[![JetBrains logo.][jetbrains img]][jetbrains]\n\n[![JProfiler logo.][jprofiler img]][jprofiler]\n\n[jetbrains]:https://jb.gg/OpenSource\n[jetbrains img]:https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg\n\n[jprofiler]:https://www.ej-technologies.com/jprofiler\n[jprofiler img]:https://www.ej-technologies.com/images/product_banners/jprofiler_medium.png\n\n[appveyor]:https://ci.appveyor.com/project/checkstyle/checkstyle/history\n[appveyor img]:https://ci.appveyor.com/api/projects/status/rw6bw3dl9kph6ucc?svg=true\n\n[coverage]:https://codecov.io/github/checkstyle/checkstyle?branch=master\n[coverage img]:https://codecov.io/github/checkstyle/checkstyle/coverage.svg?branch=master\n\n[mavenbadge]:https://search.maven.org/search?q=g:%22com.puppycrawl.tools%22%20AND%20a:%22checkstyle%22\n[mavenbadge img]:https://img.shields.io/maven-central/v/com.puppycrawl.tools/checkstyle.svg?label=Maven%20Central\n\n[stackoverflow]:https://stackoverflow.com/questions/tagged/checkstyle\n[stackoverflow img]:https://img.shields.io/badge/stackoverflow-CHECKSTYLE-blue.svg\n\n[teamcity]:https://teamcity.jetbrains.com/viewType.html?buildTypeId=Checkstyle_IdeaInspectionsMaster\n[teamcity img]:https://teamcity.jetbrains.com/app/rest/builds/buildType:(id:Checkstyle_IdeaInspectionsMaster)/statusIcon\n\n[circleci]: https://circleci.com/gh/checkstyle/checkstyle/tree/master\n[circleci img]: https://circleci.com/gh/checkstyle/checkstyle/tree/master.svg?style=svg\n\n[cirrusci]: https://cirrus-ci.com/github/checkstyle/checkstyle\n[cirrusci img]: https://api.cirrus-ci.com/github/checkstyle/checkstyle.svg?branch=master\n\n[snyk]: https://snyk.io/test/github/checkstyle/checkstyle?targetFile=pom.xml\n[snyk img]: https://snyk.io/test/github/checkstyle/checkstyle/badge.svg\n\n[semaphoreci]: https://checkstyle.semaphoreci.com/projects/checkstyle\n[semaphoreci img]: https://checkstyle.semaphoreci.com/badges/checkstyle/branches/master.svg?style=shields\n\n[azure]:https://dev.azure.com/romanivanovjr/romanivanovjr/_build/latest?definitionId=1&branchName=master\n[azure img]:https://dev.azure.com/romanivanovjr/romanivanovjr/_apis/build/status/checkstyle.checkstyle?branchName=master\n\n[backers.opencollective]:https://opencollective.com/checkstyle/\n[backers.opencollective img]:https://opencollective.com/checkstyle/backers/badge.svg\n\n[sponsors.opencollective]:https://opencollective.com/checkstyle/\n[sponsors.opencollective img]:https://opencollective.com/checkstyle/sponsors/badge.svg\n\n[dependabot]:https://github.com/dependabot\n[dependabot img]:https://img.shields.io/badge/dependabot-025E8C?style=for-the-badge&logo=dependabot\n\n[closed issues]:https://github.com/checkstyle/checkstyle/actions/workflows/no-old-refs.yml\n[closed issues img]:https://github.com/checkstyle/checkstyle/actions/workflows/no-old-refs.yml/badge.svg\n\n[release notes/version]:https://github.com/checkstyle/checkstyle/actions/workflows/releasenotes-gen.yml\n[release notes/version img]:https://github.com/checkstyle/checkstyle/actions/workflows/releasenotes-gen.yml/badge.svg\n\n[link check]:https://github.com/checkstyle/checkstyle/actions/workflows/run-link-check.yml\n[link check img]:https://github.com/checkstyle/checkstyle/actions/workflows/run-link-check.yml/badge.svg\n\n[error prone]:https://github.com/checkstyle/checkstyle/actions/workflows/error-prone.yml\n[error prone img]:https://github.com/checkstyle/checkstyle/actions/workflows/error-prone.yml/badge.svg\n\n[pitest]:https://github.com/checkstyle/checkstyle/actions/workflows/pitest.yml\n[pitest img]:https://github.com/checkstyle/checkstyle/actions/workflows/pitest.yml/badge.svg\n\n[checker framework]:https://github.com/checkstyle/checkstyle/actions/workflows/checker-framework.yml\n[checker framework img]:https://github.com/checkstyle/checkstyle/actions/workflows/checker-framework.yml/badge.svg\n\n[milestone]:https://github.com/checkstyle/checkstyle/actions/workflows/set-milestone-on-referenced-issue.yml\n[milestone img]:https://github.com/checkstyle/checkstyle/actions/workflows/set-milestone-on-referenced-issue.yml/badge.svg\n",
      "stars_today": 0
    },
    {
      "id": 19438,
      "name": "ggplot2",
      "full_name": "tidyverse/ggplot2",
      "description": "An implementation of the Grammar of Graphics in R",
      "html_url": "https://github.com/tidyverse/ggplot2",
      "stars": 6866,
      "forks": 2116,
      "language": "R",
      "topics": [
        "data-visualisation",
        "r",
        "visualisation"
      ],
      "created_at": "2008-05-25T01:21:32Z",
      "updated_at": "2026-01-23T00:39:18Z",
      "pushed_at": "2025-12-18T13:22:01Z",
      "open_issues": 95,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# ggplot2 <a href=\"https://ggplot2.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" alt=\"ggplot2 website\" /></a>\n\n<!-- badges: start -->\n\n[![R-CMD-check](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml)\n[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/ggplot2)](https://cran.r-project.org/package=ggplot2)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/ggplot2/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/ggplot2)\n<!-- badges: end -->\n\n## Overview\n\nggplot2 is a system for declaratively creating graphics, based on [The\nGrammar of\nGraphics](https://link.springer.com/book/10.1007/0-387-28695-0). You\nprovide the data, tell ggplot2 how to map variables to aesthetics, what\ngraphical primitives to use, and it takes care of the details.\n\n## Installation\n\n``` r\n# The easiest way to get ggplot2 is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just ggplot2:\ninstall.packages(\"ggplot2\")\n\n# Or the development version from GitHub:\n# install.packages(\"pak\")\npak::pak(\"tidyverse/ggplot2\")\n```\n\n## Cheatsheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-visualization-cheatsheet-thumbs.png\" width=\"630\" height=\"252\" alt=\"ggplot2 cheatsheet\" /></a>\n\n## Usage\n\nIt‚Äôs hard to succinctly describe how ggplot2 works because it embodies a\ndeep philosophy of visualisation. However, in most cases you start with\n`ggplot()`, supply a dataset and aesthetic mapping (with `aes()`). You\nthen add on layers (like `geom_point()` or `geom_histogram()`), scales\n(like `scale_colour_brewer()`), faceting specifications (like\n`facet_wrap()`) and coordinate systems (like `coord_flip()`).\n\n``` r\nlibrary(ggplot2)\n\nggplot(mpg, aes(displ, hwy, colour = class)) +\n  geom_point()\n```\n\n<img src=\"man/figures/README-example-1.png\" alt=\"Scatterplot of engine displacement versus highway miles per gallon, for 234 cars coloured by 7 'types' of car. The displacement and miles per gallon are inversely correlated.\"  />\n\n## Lifecycle\n\n[![lifecycle](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n\nggplot2 is now 18 years old and is used by hundreds of thousands of\npeople to make millions of plots. That means, by-and-large, ggplot2\nitself changes relatively little. When we do make changes, they will be\ngenerally to add new functions or arguments rather than changing the\nbehaviour of existing functions, and if we do make changes to existing\nbehaviour we will do them for compelling reasons.\n\nIf you are looking for innovation, look to ggplot2‚Äôs rich ecosystem of\nextensions. See a community maintained list at\n<https://exts.ggplot2.tidyverse.org/gallery/>.\n\n## Learning ggplot2\n\nIf you are new to ggplot2 you are better off starting with a systematic\nintroduction, rather than trying to learn from reading individual\ndocumentation pages. Currently, there are several good places to start:\n\n1.  The [Data Visualization](https://r4ds.hadley.nz/data-visualize) and\n    [Communication](https://r4ds.hadley.nz/communication) chapters in [R\n    for Data Science](https://r4ds.hadley.nz). R for Data Science is\n    designed to give you a comprehensive introduction to the\n    [tidyverse](https://tidyverse.org/), and these two chapters will get\n    you up to speed with the essentials of ggplot2 as quickly as\n    possible.\n\n2.  If you‚Äôd like to take an online course, try [Data Visualization in R\n    With\n    ggplot2](https://learning.oreilly.com/videos/data-visualization-in/9781491963661/)\n    by Kara Woo.\n\n3.  If you‚Äôd like to follow a webinar, try [Plotting Anything with\n    ggplot2](https://youtu.be/h29g21z0a68) by Thomas Lin Pedersen.\n\n4.  If you want to dive into making common graphics as quickly as\n    possible, I recommend [The R Graphics\n    Cookbook](https://r-graphics.org) by Winston Chang. It provides a\n    set of recipes to solve common graphics problems.\n\n5.  If you‚Äôve mastered the basics and want to learn more, read [ggplot2:\n    Elegant Graphics for Data Analysis](https://ggplot2-book.org). It\n    describes the theoretical underpinnings of ggplot2 and shows you how\n    all the pieces fit together. This book helps you understand the\n    theory that underpins ggplot2, and will help you create new types of\n    graphics specifically tailored to your needs.\n\n6.  For articles about announcements and deep-dives you can visit the\n    [tidyverse blog](https://tidyverse.org/tags/ggplot2/).\n\n## Getting help\n\nThere are two main places to get help with ggplot2:\n\n1.  The [Posit Community](https://forum.posit.co/) (formerly RStudio\n    Community) is a friendly place to ask any questions about ggplot2.\n\n2.  [Stack\n    Overflow](https://stackoverflow.com/questions/tagged/ggplot2?sort=frequent&pageSize=50)\n    is a great source of answers to common ggplot2 questions. It is also\n    a great place to get help, once you have created a reproducible\n    example that illustrates your problem.\n",
      "stars_today": 0
    },
    {
      "id": 4729944,
      "name": "shiny",
      "full_name": "rstudio/shiny",
      "description": "Easy interactive web applications with R",
      "html_url": "https://github.com/rstudio/shiny",
      "stars": 5590,
      "forks": 1881,
      "language": "R",
      "topics": [
        "r",
        "reactive",
        "rstudio",
        "shiny",
        "web-app",
        "web-development"
      ],
      "created_at": "2012-06-20T18:45:11Z",
      "updated_at": "2026-01-21T16:16:25Z",
      "pushed_at": "2026-01-12T16:26:11Z",
      "open_issues": 870,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "# shiny <img src=\"man/figures/logo.png\" align=\"right\" width=120 height=139 alt=\"\" />\n\n<!-- badges: start -->\n[![CRAN](https://www.r-pkg.org/badges/version/shiny)](https://CRAN.R-project.org/package=shiny)\n[![R build status](https://github.com/rstudio/shiny/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/shiny/actions)\n[![RStudio community](https://img.shields.io/badge/community-shiny-blue?style=social&logo=rstudio&logoColor=75AADB)](https://forum.posit.co/new-topic?category=shiny&tags=shiny)\n\n<!-- badges: end -->\n\nEasily build rich and productive interactive web apps in R &mdash; no HTML/CSS/JavaScript required.\n\n## Features\n\n* An intuitive and extensible [reactive programming](https://en.wikipedia.org/wiki/Reactive_programming) model which makes it easy to transform existing R code into a \"live app\" where outputs automatically react to new user input.\n  * Compared to event-based programming, reactivity allows Shiny to do the minimum amount of work when input(s) change, and allows humans to more easily reason about complex [MVC logic](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller).\n* A prebuilt set of highly sophisticated, customizable, and easy-to-use widgets (e.g., plots, tables, sliders, dropdowns, date pickers, and more).\n* An attractive default look based on [Bootstrap](https://getbootstrap.com/) which can also be easily customized with the [bslib](https://github.com/rstudio/bslib) package or avoided entirely with more direct R bindings to HTML/CSS/JavaScript.\n* Seamless integration with [R Markdown](https://shiny.rstudio.com/articles/interactive-docs.html), making it easy to embed numerous applications natively within a larger dynamic document.\n* Tools for improving and monitoring performance, including native support for [async programming](https://posit.co/blog/shiny-1-1-0/), [caching](https://talks.cpsievert.me/20201117), [load testing](https://rstudio.github.io/shinyloadtest/), and more.\n* [Modules](https://shiny.rstudio.com/articles/modules.html): a framework for reducing code duplication and complexity.\n* An ability to [bookmark application state](https://shiny.rstudio.com/articles/bookmarking-state.html) and/or [generate code to reproduce output(s)](https://github.com/rstudio/shinymeta).\n* A rich ecosystem of extension packages for more [custom widgets](http://www.htmlwidgets.org/), [input validation](https://github.com/rstudio/shinyvalidate), [unit testing](https://github.com/rstudio/shinytest), and more.\n\n## Installation\n\nTo install the stable version from CRAN:\n\n```r\ninstall.packages(\"shiny\")\n```\n\n## Getting Started\n\nOnce installed, load the library and run an example:\n\n```r\nlibrary(shiny)\n# Launches an app, with the app's source code included\nrunExample(\"06_tabsets\")\n# Lists more prepackaged examples\nrunExample()\n```\n\nFor more examples and inspiration, check out the [Shiny User Gallery](https://shiny.rstudio.com/gallery/).\n\nFor help with learning fundamental Shiny programming concepts, check out the [Mastering Shiny](https://mastering-shiny.org/) book and the [Shiny Tutorial](https://shiny.rstudio.com/tutorial/). The former is currently more up-to-date with modern Shiny features, whereas the latter takes a deeper, more visual, dive into fundamental concepts.\n\n## Join the conversation\n\nIf you want to chat about Shiny, meet other developers, or help us decide what to work on next, [join us on Discord](https://discord.com/invite/yMGCamUMnS).\n\n## Getting Help\n\nTo ask a question about Shiny, please use the [RStudio Community website](https://forum.posit.co/new-topic?category=shiny&tags=shiny).\n\nFor bug reports, please use the [issue tracker](https://github.com/rstudio/shiny/issues) and also keep in mind that by [writing a good bug report](https://github.com/rstudio/shiny/wiki/Writing-Good-Bug-Reports), you're more likely to get help with your problem.\n\n## Contributing\n\nWe welcome contributions to the **shiny** package. Please see our [CONTRIBUTING.md](https://github.com/rstudio/shiny/blob/main/.github/CONTRIBUTING.md) file for detailed guidelines of how to contribute.\n\n## License\n\nThe shiny package as a whole is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.\n\n## R version support\n\nShiny is supported on the latest release version of R, as well as the previous four minor release versions of R. For example, if the latest release R version is 4.3, then that version is supported, as well as 4.2, 4.1, 4.0, 3.6.\n",
      "stars_today": 0
    },
    {
      "id": 6427813,
      "name": "dplyr",
      "full_name": "tidyverse/dplyr",
      "description": "dplyr: A grammar of data manipulation",
      "html_url": "https://github.com/tidyverse/dplyr",
      "stars": 4986,
      "forks": 2130,
      "language": "R",
      "topics": [
        "data-manipulation",
        "grammar",
        "r"
      ],
      "created_at": "2012-10-28T13:39:17Z",
      "updated_at": "2026-01-23T00:40:02Z",
      "pushed_at": "2026-01-22T19:21:00Z",
      "open_issues": 78,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# dplyr <a href=\"https://dplyr.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" /></a>\n\n<!-- badges: start -->\n\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/dplyr)](https://cran.r-project.org/package=dplyr)\n[![R-CMD-check](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/dplyr/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/dplyr)\n<!-- badges: end -->\n\n## Overview\n\ndplyr is a grammar of data manipulation, providing a consistent set of\nverbs that help you solve the most common data manipulation challenges:\n\n- `mutate()` adds new variables that are functions of existing variables\n- `select()` picks variables based on their names.\n- `filter()` picks cases based on their values.\n- `summarise()` reduces multiple values down to a single summary.\n- `arrange()` changes the ordering of the rows.\n\nThese all combine naturally with `group_by()` which allows you to\nperform any operation ‚Äúby group‚Äù. You can learn more about them in\n`vignette(\"dplyr\")`. As well as these single-table verbs, dplyr also\nprovides a variety of two-table verbs, which you can learn about in\n`vignette(\"two-table\")`.\n\nIf you are new to dplyr, the best place to start is the [data\ntransformation chapter](https://r4ds.hadley.nz/data-transform) in R for\nData Science.\n\n## Backends\n\nIn addition to data frames/tibbles, dplyr makes working with other\ncomputational backends accessible and efficient. Below is a list of\nalternative backends:\n\n- [arrow](https://arrow.apache.org/docs/r/) for larger-than-memory\n  datasets, including on remote cloud storage like AWS S3, using the\n  Apache Arrow C++ engine,\n  [Acero](https://arrow.apache.org/docs/cpp/acero/overview.html).\n\n- [dbplyr](https://dbplyr.tidyverse.org/) for data stored in a\n  relational database. Translates your dplyr code to SQL.\n\n- [dtplyr](https://dtplyr.tidyverse.org/) for large, in-memory datasets.\n  Translates your dplyr code to high performance\n  [data.table](https://rdatatable.gitlab.io/data.table/) code.\n\n- [duckplyr](https://duckplyr.tidyverse.org/) for large, in-memory\n  datasets. Translates your dplyr code to high performance\n  [duckdb](https://duckdb.org) queries with zero extra copies and an\n  automatic R fallback when translation isn‚Äôt possible.\n\n- [sparklyr](https://spark.posit.co/) for very large datasets stored in\n  [Apache Spark](https://spark.apache.org).\n\n## Installation\n\n``` r\n# The easiest way to get dplyr is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just dplyr:\ninstall.packages(\"dplyr\")\n```\n\n### Development version\n\nTo get a bug fix or to use a feature from the development version, you\ncan install the development version of dplyr from GitHub.\n\n``` r\n# install.packages(\"pak\")\npak::pak(\"tidyverse/dplyr\")\n```\n\n## Cheat Sheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-transformation-cheatsheet-thumbs.png\" width=\"630\" height=\"252\"/></a>\n\n## Usage\n\n``` r\nlibrary(dplyr)\n\nstarwars |>\n  filter(species == \"Droid\")\n#> # A tibble: 6 √ó 14\n#>   name   height  mass hair_color skin_color  eye_color birth_year sex   gender  \n#>   <chr>   <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr> <chr>   \n#> 1 C-3PO     167    75 <NA>       gold        yellow           112 none  masculi‚Ä¶\n#> 2 R2-D2      96    32 <NA>       white, blue red               33 none  masculi‚Ä¶\n#> 3 R5-D4      97    32 <NA>       white, red  red               NA none  masculi‚Ä¶\n#> 4 IG-88     200   140 none       metal       red               15 none  masculi‚Ä¶\n#> 5 R4-P17     96    NA none       silver, red red, blue         NA none  feminine\n#> # ‚Ñπ 1 more row\n#> # ‚Ñπ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  select(name, ends_with(\"color\"))\n#> # A tibble: 87 √ó 4\n#>   name           hair_color skin_color  eye_color\n#>   <chr>          <chr>      <chr>       <chr>    \n#> 1 Luke Skywalker blond      fair        blue     \n#> 2 C-3PO          <NA>       gold        yellow   \n#> 3 R2-D2          <NA>       white, blue red      \n#> 4 Darth Vader    none       white       yellow   \n#> 5 Leia Organa    brown      light       brown    \n#> # ‚Ñπ 82 more rows\n\nstarwars |>\n  mutate(name, bmi = mass / ((height / 100)^2)) |>\n  select(name:mass, bmi)\n#> # A tibble: 87 √ó 4\n#>   name           height  mass   bmi\n#>   <chr>           <int> <dbl> <dbl>\n#> 1 Luke Skywalker    172    77  26.0\n#> 2 C-3PO             167    75  26.9\n#> 3 R2-D2              96    32  34.7\n#> 4 Darth Vader       202   136  33.3\n#> 5 Leia Organa       150    49  21.8\n#> # ‚Ñπ 82 more rows\n\nstarwars |>\n  arrange(desc(mass))\n#> # A tibble: 87 √ó 14\n#>   name      height  mass hair_color skin_color eye_color birth_year sex   gender\n#>   <chr>      <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> \n#> 1 Jabba De‚Ä¶    175  1358 <NA>       green-tan‚Ä¶ orange         600   herm‚Ä¶ mascu‚Ä¶\n#> 2 Grievous     216   159 none       brown, wh‚Ä¶ green, y‚Ä¶       NA   male  mascu‚Ä¶\n#> 3 IG-88        200   140 none       metal      red             15   none  mascu‚Ä¶\n#> 4 Darth Va‚Ä¶    202   136 none       white      yellow          41.9 male  mascu‚Ä¶\n#> 5 Tarfful      234   136 brown      brown      blue            NA   male  mascu‚Ä¶\n#> # ‚Ñπ 82 more rows\n#> # ‚Ñπ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  group_by(species) |>\n  summarise(\n    n = n(),\n    mass = mean(mass, na.rm = TRUE)\n  ) |>\n  filter(\n    n > 1,\n    mass > 50\n  )\n#> # A tibble: 9 √ó 3\n#>   species      n  mass\n#>   <chr>    <int> <dbl>\n#> 1 Droid        6  69.8\n#> 2 Gungan       3  74  \n#> 3 Human       35  81.3\n#> 4 Kaminoan     2  88  \n#> 5 Mirialan     2  53.1\n#> # ‚Ñπ 4 more rows\n```\n\n## Getting help\n\nIf you encounter a clear bug, please file an issue with a minimal\nreproducible example on\n[GitHub](https://github.com/tidyverse/dplyr/issues). For questions and\nother discussion, please use [forum.posit.co](https://forum.posit.co/).\n\n## Code of conduct\n\nPlease note that this project is released with a [Contributor Code of\nConduct](https://dplyr.tidyverse.org/CODE_OF_CONDUCT). By participating\nin this project you agree to abide by its terms.\n",
      "stars_today": 0
    },
    {
      "id": 1368195,
      "name": "asio",
      "full_name": "chriskohlhoff/asio",
      "description": "Asio C++ Library",
      "html_url": "https://github.com/chriskohlhoff/asio",
      "stars": 5717,
      "forks": 1341,
      "language": "C++",
      "topics": [],
      "created_at": "2011-02-15T05:18:45Z",
      "updated_at": "2026-01-22T10:08:59Z",
      "pushed_at": "2025-11-30T09:48:48Z",
      "open_issues": 1044,
      "owner": {
        "login": "chriskohlhoff",
        "avatar_url": "https://avatars.githubusercontent.com/u/462538?v=4"
      },
      "readme": "asio version 1.36.0\nReleased Saturday, 16 August 2025.\n\nVisit https://think-async.com/ or see packaged doc/index.html for API\ndocumentation and a tutorial.\n",
      "stars_today": 0
    },
    {
      "id": 16146440,
      "name": "rmarkdown",
      "full_name": "rstudio/rmarkdown",
      "description": "Dynamic Documents for R",
      "html_url": "https://github.com/rstudio/rmarkdown",
      "stars": 3013,
      "forks": 996,
      "language": "R",
      "topics": [
        "literate-programming",
        "markdown",
        "pandoc",
        "r",
        "r-package",
        "rmarkdown"
      ],
      "created_at": "2014-01-22T17:25:19Z",
      "updated_at": "2026-01-21T15:22:20Z",
      "pushed_at": "2025-11-26T19:36:51Z",
      "open_issues": 264,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "# rmarkdown <a href=\"https://pkgs.rstudio.com/rmarkdown/\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" /></a>\n\n\n<!-- badges: start -->\n[![R-CMD-check](https://github.com/rstudio/rmarkdown/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/rmarkdown/actions/workflows/R-CMD-check.yaml)\n[![CRAN release](https://www.r-pkg.org/badges/version/rmarkdown)](https://cran.r-project.org/package=rmarkdown)\n[![Codecov test coverage](https://codecov.io/gh/rstudio/rmarkdown/branch/main/graph/badge.svg)](https://app.codecov.io/gh/rstudio/rmarkdown?branch=main)\n<!-- badges: end -->\n\n\nThe **rmarkdown** package helps you create dynamic analysis documents that combine code, rendered output (such as figures), and prose. You bring your data, code, and ideas, and R Markdown renders your content into a polished document that can be used to:\n\n- Do data science interactively within the RStudio IDE,\n\n- Reproduce your analyses,\n\n- Collaborate and share code with others, and\n\n- Communicate your results with others.\n\nR Markdown documents can be rendered to many output formats including HTML documents, PDFs, Word files, slideshows, and more, allowing you to focus on the content while R Markdown takes care of your presentation. \n\n## Books\n\n<a href=\"https://bookdown.org/yihui/rmarkdown/\"><img class=\"book\" src=\"https://bookdown.org/yihui/rmarkdown/images/cover.png\" alt=\"R Markdown: The Definitive Guide\" height=\"400\"></a>\n<a href=\"https://bookdown.org/yihui/rmarkdown-cookbook/\"><img class=\"book\" src=\"https://bookdown.org/yihui/rmarkdown-cookbook/images/cover.png\" alt=\"R Markdown Cookbook\" height=\"400\"></a>\n\nSee more about them in [Get Started](https://pkgs.rstudio.com/rmarkdown/articles/rmarkdown.html).\n\n## Installation\n\nThe easiest way to install the **rmarkdown** package is from within the [RStudio IDE](https://posit.co/download/rstudio-desktop/), but you don't need to explicitly install it or load it, as RStudio automatically does both when needed. A recent version of Pandoc (>= 1.12.3) is also required; RStudio also automatically includes this too so you do not need to download Pandoc if you plan to use rmarkdown from the RStudio IDE.\n\nIf you want to use the rmarkdown package outside of RStudio, you can install the package from CRAN as follows:\n\n```r\ninstall.packages(\"rmarkdown\")\n```\n\nIf you want to use the development version of the rmarkdown package (either with or without RStudio), you can install the package from GitHub via the [**pak** package](https://pak.r-lib.org):\n\n```r\n# install.packages(\"pak\")\npak::pak('rstudio/rmarkdown')\n```\n\nIf not using the RStudio IDE, you'll need to install a recent version of Pandoc (>= 1.12.3); see the [Pandoc installation instructions](https://pandoc.org/installing.html) for help.\n\n## Usage\n\nThe easiest way to make a new R Markdown document is from within RStudio. Go to _File > New File > R Markdown_. From the new file wizard, you may:\n\n+ Provide a document title (_optional but recommended_),\n+ Provide an author name (_optional but recommended_),\n+ Select a default output format- HTML is the recommended format for authoring, and you can switch the output format anytime (_required_), \n+ Click **OK** (_required_).\n\nOnce inside your new `.Rmd` file, you should see some boilerplate text that includes code chunks. Use the \"Knit\" button in the RStudio IDE to render the file and preview the output with a single click or use the keyboard shortcut Cmd/Ctrl + Shift + K. \n\nYou can also delete all the text below the YAML frontmatter and fill in your own `.Rmd` by:\n\n+ Adding code chunks (keyboard shortcut: `Ctrl + Alt + I`; OS X: `Cmd + Option + I`),\n+ Writing prose with [Markdown formatting](https://www.markdowntutorial.com/), and\n+ Running each code chunk interactively by clicking the ![The run button](https://rmarkdown.rstudio.com/images/notebook-run-chunk.png) icon within RStudio. \n\nYou can also click \"Knit to HTML\" again to render the full document with all code chunks. For more help getting started in R Markdown, please see the [R Markdown website](https://rmarkdown.rstudio.com/lesson-1.html) or use the **\"Get Started\"** links at the top of this page.\n\n## Getting help\n\nThere are two main places to get help:\n\n1. The [Posit community](https://forum.posit.co/c/quarto-r-markdown/10) is a friendly place to ask any questions about rmarkdown and the R Markdown family of packages.\n\n1. [Stack Overflow](https://stackoverflow.com/questions/tagged/r-markdown) is a great source of answers to common rmarkdown questions. It is also a great place to get help, once you have created a reproducible example that illustrates your problem.\n\n## Code of Conduct\n\nPlease note that the **rmarkdown** project is released with a [Contributor Code of Conduct](https://pkgs.rstudio.com/rmarkdown/CODE_OF_CONDUCT.html). By contributing to this project, you agree to abide by its terms.\n",
      "stars_today": 0
    },
    {
      "id": 45981801,
      "name": "SPIRV-Tools",
      "full_name": "KhronosGroup/SPIRV-Tools",
      "description": null,
      "html_url": "https://github.com/KhronosGroup/SPIRV-Tools",
      "stars": 1265,
      "forks": 649,
      "language": "C++",
      "topics": [],
      "created_at": "2015-11-11T12:56:25Z",
      "updated_at": "2026-01-22T19:45:24Z",
      "pushed_at": "2026-01-22T20:03:35Z",
      "open_issues": 441,
      "owner": {
        "login": "KhronosGroup",
        "avatar_url": "https://avatars.githubusercontent.com/u/1608701?v=4"
      },
      "readme": "# SPIR-V Tools\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/KhronosGroup/SPIRV-Tools/badge)](https://securityscorecards.dev/viewer/?uri=github.com/KhronosGroup/SPIRV-Tools)\n\nNEWS 2023-01-11: Development occurs on the `main` branch.\n\n## Overview\n\nThe SPIR-V Tools project provides an API and commands for processing SPIR-V\nmodules.\n\nThe project includes an assembler, binary module parser, disassembler,\nvalidator, and optimizer for SPIR-V. Except for the optimizer, all are based\non a common static library.  The library contains all of the implementation\ndetails, and is used in the standalone tools whilst also enabling integration\ninto other code bases directly. The optimizer implementation resides in its\nown library, which depends on the core library.\n\nThe interfaces have stabilized:\nWe don't anticipate making a breaking change for existing features.\n\nSPIR-V is defined by the Khronos Group Inc.\nSee the [SPIR-V Registry][spirv-registry] for the SPIR-V specification,\nheaders, and XML registry.\n\n## Downloads\n\nThe official releases for SPIRV-Tools can be found on LunarG's\n[SDK download page](https://vulkan.lunarg.com/sdk/home).\n\nFor convenience, here are also links to the latest builds (HEAD).\nThose are untested automated builds. Those are not official releases, nor\nare guaranteed to work. Official releases builds are in the Vulkan SDK.\n\n<img alt=\"Linux\" src=\"kokoro/img/linux.png\" width=\"20px\" height=\"20px\" hspace=\"2px\"/>[![Linux Build Status](https://storage.googleapis.com/spirv-tools/badges/build_status_linux_clang_release.svg)](https://storage.googleapis.com/spirv-tools/badges/build_link_linux_clang_release.html)\n<img alt=\"MacOS\" src=\"kokoro/img/macos.png\" width=\"20px\" height=\"20px\" hspace=\"2px\"/>[![MacOS Build Status](https://storage.googleapis.com/spirv-tools/badges/build_status_macos_clang_release.svg)](https://storage.googleapis.com/spirv-tools/badges/build_link_macos_clang_release.html)\n<img alt=\"Windows\" src=\"kokoro/img/windows.png\" width=\"20px\" height=\"20px\" hspace=\"2px\"/>[![Windows Build Status](https://storage.googleapis.com/spirv-tools/badges/build_status_windows_vs2022_release.svg)](https://storage.googleapis.com/spirv-tools/badges/build_link_windows_vs2022_release.html)\n\n[More downloads](docs/downloads.md)\n\n## Versioning SPIRV-Tools\n\nSee [`CHANGES`](CHANGES) for a high level summary of recent changes, by version.\n\nSPIRV-Tools project version numbers are of the form `v`*year*`.`*index* and with\nan optional `-dev` suffix to indicate work in progress.  For example, the\nfollowing versions are ordered from oldest to newest:\n\n* `v2016.0`\n* `v2016.1-dev`\n* `v2016.1`\n* `v2016.2-dev`\n* `v2016.2`\n\nUse the `--version` option on each command line tool to see the software\nversion.  An API call reports the software version as a C-style string.\n\n## Releases\n\nThe official releases for SPIRV-Tools can be found on LunarG's\n[SDK download page](https://vulkan.lunarg.com/sdk/home).\n\nYou can find either the prebuilt, and QA tested binaries, or download the\nSDK Config, which lists the commits to use to build the release from scratch.\n\nGitHub releases are deprecated, and we will not publish new releases until\nfurther notice.\n\n## Supported features\n\n### Assembler, binary parser, and disassembler\n\n* Support for SPIR-V 1.0, through 1.5\n  * Based on SPIR-V syntax described by JSON grammar files in the\n    [SPIRV-Headers](https://github.com/KhronosGroup/SPIRV-Headers) repository.\n  * Usually, support for a new version of SPIR-V is ready within days after\n    publication.\n* Support for extended instruction sets:\n  * GLSL std450 version 1.0 Rev 3\n  * OpenCL version 1.0 Rev 2\n* Assembler only does basic syntax checking.  No cross validation of\n  IDs or types is performed, except to check literal arguments to\n  `OpConstant`, `OpSpecConstant`, and `OpSwitch`.\n* Where tools expect binary input, a hex stream may be provided instead.  See\n  `spirv-dis --help`.\n\nSee [`docs/syntax.md`](docs/syntax.md) for the assembly language syntax.\n\n### Validator\n\nThe validator checks validation rules described by the SPIR-V specification.\n\nKhronos recommends that tools that create or transform SPIR-V modules use the\nvalidator to ensure their outputs are valid, and that tools that consume SPIR-V\nmodules optionally use the validator to protect themselves from bad inputs.\nThis is especially encouraged for debug and development scenarios.\n\nThe validator has one-sided error: it will only return an error when it has\nimplemented a rule check and the module violates that rule.\n\nThe validator is incomplete.\nSee the [CHANGES](CHANGES) file for reports on completed work, and\nthe [Validator\nsub-project](https://github.com/KhronosGroup/SPIRV-Tools/projects/1) for planned\nand in-progress work.\n\n*Note*: The validator checks some Universal Limits, from section 2.17 of the SPIR-V spec.\nThe validator will fail on a module that exceeds those minimum upper bound limits.\nThe validator has been parameterized to allow larger values, for use when targeting \na more-than-minimally-capable SPIR-V consumer.\n\nSee [`tools/val/val.cpp`](tools/val/val.cpp) or run `spirv-val --help` for the command-line help.\n\n### Optimizer\n\nThe optimizer is a collection of code transforms, or \"passes\".\nTransforms are written for a diverse set of reasons:\n\n* To restructure, simplify, or normalize the code for further processing.\n* To eliminate undesirable code.\n* To improve code quality in some metric such as size or performance.\n  **Note**: These transforms are not guaranteed to actually improve any\n  given metric. Users should always measure results for their own situation.\n\nAs of this writing, there are 67 transforms including examples such as:\n* Simplification\n  * Strip debug info\n  * Strip reflection info\n* Specialization Constants\n  * Set spec constant default value\n  * Freeze spec constant to default value\n  * Fold `OpSpecConstantOp` and `OpSpecConstantComposite`\n  * Unify constants\n  * Eliminate dead constant\n* Code Reduction\n  * Inline all function calls exhaustively\n  * Convert local access chains to inserts/extracts\n  * Eliminate local load/store in single block\n  * Eliminate local load/store with single store\n  * Eliminate local load/store with multiple stores\n  * Eliminate local extract from insert\n  * Eliminate dead instructions (aggressive)\n  * Eliminate dead branches\n  * Merge single successor / single predecessor block pairs\n  * Eliminate common uniform loads\n  * Remove duplicates: Capabilities, extended instruction imports, types, and\n    decorations.\n* Normalization\n  * Compact IDs\n  * Canonicalize IDs\n  * CFG cleanup\n  * Flatten decorations\n  * Merge returns\n  * Convert AMD-specific instructions to KHR instructions\n* Code improvement\n  * Conditional constant propagation\n  * If-conversion\n  * Loop fission\n  * Loop fusion\n  * Loop-invariant code motion\n  * Loop unroll\n* Other\n  * Graphics robust access\n  * Upgrade memory model to VulkanKHR\n\nAdditionally, certain sets of transformations have been packaged into\nhigher-level recipes.  These include:\n\n* Optimization for size (`spirv-opt -Os`)\n* Optimization for performance (`spirv-opt -O`)\n\nFor the latest list with detailed documentation, please refer to\n[`include/spirv-tools/optimizer.hpp`](include/spirv-tools/optimizer.hpp).\n\nFor suggestions on using the code reduction options, please refer to this [white paper](https://www.lunarg.com/shader-compiler-technologies/white-paper-spirv-opt/).\n\n\n### Linker\n\n*Note:* The linker is still under development.\n\nCurrent features:\n* Combine multiple SPIR-V binary modules together.\n* Combine into a library (exports are retained) or an executable (no symbols\n  are exported).\n\nSee the [CHANGES](CHANGES) file for reports on completed work, and the [General\nsub-project](https://github.com/KhronosGroup/SPIRV-Tools/projects/2) for\nplanned and in-progress work.\n\n\n### Reducer\n\n*Note:* The reducer is still under development.\n\nThe reducer simplifies and shrinks a SPIR-V module with respect to a\nuser-supplied *interestingness function*.  For example, given a large\nSPIR-V module that cause some SPIR-V compiler to fail with a given\nfatal error message, the reducer could be used to look for a smaller\nversion of the module that causes the compiler to fail with the same\nfatal error message.\n\nTo suggest an additional capability for the reducer, [file an\nissue](https://github.com/KhronosGroup/SPIRV-Tools/issues]) with\n\"Reducer:\" as the start of its title.\n\n\n### Fuzzer\n\n*Note:* The fuzzer is still under development.\n\nThe fuzzer applies semantics-preserving transformations to a SPIR-V binary\nmodule, to produce an equivalent module.  The original and transformed modules\nshould produce essentially identical results when executed on identical inputs:\ntheir results should differ only due to floating-point round-off, if at all.\nSignificant differences in results can pinpoint bugs in tools that process\nSPIR-V binaries, such as miscompilations.  This *metamorphic testing* approach\nis similar to the method used by the [GraphicsFuzz\nproject](https://github.com/google/graphicsfuzz) for fuzzing of GLSL shaders.\n\nTo suggest an additional capability for the fuzzer, [file an\nissue](https://github.com/KhronosGroup/SPIRV-Tools/issues]) with\n\"Fuzzer:\" as the start of its title.\n\n\n### Diff\n\n*Note:* The diff tool is still under development.\n\nThe diff tool takes two SPIR-V files, either in binary or text format and\nproduces a diff-style comparison between the two.  The instructions between the\nsrc and dst modules are matched as best as the tool can, and output is produced\n(in src id-space) that shows which instructions are removed in src, added in dst\nor modified between them.  The order of instructions are not retained.\n\nMatching instructions between two SPIR-V modules is not trivial, and thus a\nnumber of heuristics are applied in this tool.  In particular, without debug\ninformation, match functions is nontrivial as they can be reordered.  As such,\nthis tool is primarily useful to produce the diff of two SPIR-V modules derived\nfrom the same source, for example before and after a modification to the shader,\nbefore and after a transformation, or SPIR-V produced from different tools.\n\n\n### Extras\n\n* [Utility filters](#utility-filters)\n* Build target `spirv-tools-vimsyntax` generates file `spvasm.vim`.\n  Copy that file into your `$HOME/.vim/syntax` directory to get SPIR-V assembly syntax\n  highlighting in Vim.  This build target is not built by default.\n\n## Contributing\n\nThe SPIR-V Tools project is maintained by members of the The Khronos Group Inc.,\nand is hosted at https://github.com/KhronosGroup/SPIRV-Tools.\n\nConsider joining the `public_spirv_tools_dev@khronos.org` mailing list, via\n[https://www.khronos.org/spir/spirv-tools-mailing-list/](https://www.khronos.org/spir/spirv-tools-mailing-list/).\nThe mailing list is used to discuss development plans for the SPIRV-Tools as an open source project.\nOnce discussion is resolved,\nspecific work is tracked via issues and sometimes in one of the\n[projects][spirv-tools-projects].\n\n(To provide feedback on the SPIR-V _specification_, file an issue on the\n[SPIRV-Headers][spirv-headers] GitHub repository.)\n\nSee [`docs/projects.md`](docs/projects.md) to see how we use the\n[GitHub Project\nfeature](https://help.github.com/articles/tracking-the-progress-of-your-work-with-projects/)\nto organize planned and in-progress work.\n\nContributions via merge request are welcome. Changes should:\n* Be provided under the [Apache 2.0](#license).\n* You'll be prompted with a one-time \"click-through\"\n  [Khronos Open Source Contributor License Agreement][spirv-tools-cla]\n  (CLA) dialog as part of submitting your pull request or\n  other contribution to GitHub.\n* Include tests to cover updated functionality.\n* C++ code should follow the [Google C++ Style Guide][cpp-style-guide].\n* Code should be formatted with `clang-format`.\n  [kokoro/check-format/build.sh](kokoro/check-format/build.sh)\n  shows how to download it. Note that we currently use\n  `clang-format version 5.0.0` for SPIRV-Tools. Settings are defined by\n  the included [.clang-format](.clang-format) file.\n\nWe intend to maintain a linear history on the GitHub `main` branch.\n\n### Getting the source\n\nExample of getting sources, assuming SPIRV-Tools is configured as a standalone project:\n\n    git clone https://github.com/KhronosGroup/SPIRV-Tools.git   spirv-tools\n    cd spirv-tools\n\n    # Check out sources for dependencies, at versions known to work together,\n    # as listed in the DEPS file.\n    python3 utils/git-sync-deps\n\nFor some kinds of development, you may need the latest sources from the third-party projects:\n\n    git clone https://github.com/KhronosGroup/SPIRV-Headers.git spirv-tools/external/spirv-headers\n    git clone https://github.com/google/googletest.git          spirv-tools/external/googletest\n    git clone https://github.com/google/effcee.git              spirv-tools/external/effcee\n    git clone https://github.com/google/re2.git                 spirv-tools/external/re2\n    git clone https://github.com/abseil/abseil-cpp.git          spirv-tools/external/abseil_cpp\n    git clone https://github.com/microsoft/mimalloc.git         spirv-tools/external/mimalloc\n\n#### Dependency on Effcee\n\nSome tests depend on the [Effcee][effcee] library for stateful matching.\nEffcee itself depends on [RE2][re2], and RE2 depends on [Abseil][abseil-cpp].\n\n* If SPIRV-Tools is configured as part of a larger project that already uses\n  Effcee, then that project should include Effcee before SPIRV-Tools.\n* Otherwise, SPIRV-Tools expects Effcee sources to appear in `external/effcee`,\n  RE2 sources to appear in `external/re2`, and Abseil sources to appear in \n  `external/abseil_cpp`.\n\n#### Dependency on mimalloc\n\nSPIRV-Tools may be configured to use the [mimalloc][mimalloc] library to improve memory\nallocation performance.\n\nIn the CMake build, usage of mimalloc is controlled by the `SPIRV_TOOLS_USE_MIMALLOC`\noption. This variable defaults on `ON` when building for Windows and `OFF` when building\nfor other platforms. Enabling this option on non-Windows platforms is supported and is\nexpected to work normally, but this has not been tested as thoroughly and extensively as\nthe Windows version. In the future, the `SPIRV_TOOLS_USE_MIMALLOC` option may default to\n`ON` for non-Windows platforms as well.\n\nIn order to avoid unexpectedly changing allocation behavior of applications that link\nSPIRV-Tools libraries statically, mimalloc is disabled by default on static libraries.\nThe option 'SPIRV_TOOLS_USE_MIMALLOC_IN_STATIC_BUILD' can be used to force the usage of\nmimalloc on static libraries.\n\n*Note*: mimalloc is currently only supported when building with CMake. When using Bazel,\nmimalloc is not used.\n\n### Source code organization\n\n* `example`: demo code of using SPIRV-Tools APIs\n* `external/googletest`: Intended location for the\n  [googletest][googletest] sources, not provided\n* `external/effcee`: Location of [Effcee][effcee] sources, if the `effcee` library\n  is not already configured by an enclosing project.\n* `external/re2`: Location of [RE2][re2] sources, if the `re2` library is not already\n  configured by an enclosing project.\n  (The Effcee project already requires RE2.)\n* `external/abseil_cpp`: Location of [Abseil][abseil-cpp] sources, if Abseil is\n   not already configured by an enclosing project.\n  (The RE2 project already requires Abseil.)\n* `external/mimalloc`: Intended location for [mimalloc][mimalloc] sources, not provided\n* `include/`: API clients should add this directory to the include search path\n* `external/spirv-headers`: Intended location for\n  [SPIR-V headers][spirv-headers], not provided\n* `include/spirv-tools/libspirv.h`: C API public interface\n* `source/`: API implementation\n* `test/`: Tests, using the [googletest][googletest] framework\n* `tools/`: Command line executables\n\n### Tests\n\nThe project contains a number of tests, used to drive development\nand ensure correctness.  The tests are written using the\n[googletest][googletest] framework.  The `googletest`\nsource is not provided with this project.  There are two ways to enable\ntests:\n* If SPIR-V Tools is configured as part of an enclosing project, then the\n  enclosing project should configure `googletest` before configuring SPIR-V Tools.\n* If SPIR-V Tools is configured as a standalone project, then download the\n  `googletest` source into the `<spirv-dir>/external/googletest` directory before\n  configuring and building the project.\n\n## Build\n\n*Note*: Prebuilt binaries are available from the [downloads](docs/downloads.md) page.\n\nFirst [get the sources](#getting-the-source).\nThen build using CMake, Bazel, Android ndk-build, or the Emscripten SDK.\n\n### Build using CMake\nYou can build the project using [CMake][cmake]:\n\n```sh\ncd <spirv-dir>\nmkdir build && cd build\ncmake [-G <platform-generator>] <spirv-dir>\n```\n\nOnce the build files have been generated, build using the appropriate build\ncommand (e.g. `ninja`, `make`, `msbuild`, etc.; this depends on the platform\ngenerator used above), or use your IDE, or use CMake to run the appropriate build\ncommand for you:\n\n```sh\ncmake --build . [--config Debug]  # runs `make` or `ninja` or `msbuild` etc.\n```\n\n#### Note about the fuzzer\n\nThe SPIR-V fuzzer, `spirv-fuzz`, can only be built via CMake, and is disabled by\ndefault. To build it, clone protobuf and use the `SPIRV_BUILD_FUZZER` CMake\noption, like so:\n\n```sh\n# In <spirv-dir> (the SPIRV-Tools repo root):\ngit clone --depth=1 --branch v3.13.0.1 https://github.com/protocolbuffers/protobuf external/protobuf\n\n# In your build directory:\ncmake [-G <platform-generator>] <spirv-dir> -DSPIRV_BUILD_FUZZER=ON\ncmake --build . --config Debug\n```\n\nYou can also add `-DSPIRV_ENABLE_LONG_FUZZER_TESTS=ON` to build additional\nfuzzer tests.\n\n\n### Build using Bazel\nYou can also use [Bazel](https://bazel.build/) to build the project.\n\n```sh\nbazel build :all\n```\n\n### Build a node.js package using Emscripten\n\nThe SPIRV-Tools core library can be built to a WebAssembly [node.js](https://nodejs.org)\nmodule. The resulting `SpirvTools` WebAssembly module only exports methods to\nassemble and disassemble SPIR-V modules.\n\nFirst, make sure you have the [Emscripten SDK](https://emscripten.org).\nThen:\n\n```sh\ncd <spirv-dir>\n./source/wasm/build.sh\n```\n\nThe resulting node package, with JavaScript and TypeScript bindings, is\nwritten to `<spirv-dir>/out/web`.\n\nNote: This builds the package locally. It does *not* publish it to [npm](https://npmjs.org).\n\nTo test the result:\n\n```sh\nnode ./test/wasm/test.js\n```\n\n### Tools you'll need\n\nFor building and testing SPIRV-Tools, the following tools should be\ninstalled regardless of your OS:\n\n- [CMake](http://www.cmake.org/): if using CMake for generating compilation\ntargets, you need to install CMake Version 2.8.12 or later.\n- [Python 3](http://www.python.org/): for utility scripts and running the test\nsuite.\n- [Bazel](https://bazel.build/) (optional): if building the source with Bazel,\nyou need to install Bazel Version 7.4.0 on your machine. Other versions may\nalso work, but are not verified.\n- [Emscripten SDK](https://emscripten.org) (optional): if building the\n  WebAssembly module.\n\nSPIRV-Tools is regularly tested with the following compilers:\n\nOn Linux\n- GCC version 9.4\n- Clang version 10.0\n\nOn MacOS\n- AppleClang 15.0\n\nOn Windows\n- Visual Studio 2022\n\nNote: Other compilers or later versions may work, but they are not tested.\n\n### CMake options\n\nThe following CMake options are supported:\n\n* `SPIRV_BUILD_FUZZER={ON|OFF}`, default `OFF` - Build the spirv-fuzz tool.\n* `SPIRV_COLOR_TERMINAL={ON|OFF}`, default `ON` - Enables color console output.\n* `SPIRV_SKIP_TESTS={ON|OFF}`, default `OFF`- Build only the library and\n  the command line tools.  This will prevent the tests from being built.\n* `SPIRV_SKIP_EXECUTABLES={ON|OFF}`, default `OFF`- Build only the library, not\n  the command line tools and tests.\n* `SPIRV_USE_SANITIZER=<sanitizer>`, default is no sanitizing - On UNIX\n  platforms with an appropriate version of `clang` this option enables the use\n  of the sanitizers documented [here][clang-sanitizers].\n  This should only be used with a debug build.\n* `SPIRV_WARN_EVERYTHING={ON|OFF}`, default `OFF` - On UNIX platforms enable\n  more strict warnings.  The code might not compile with this option enabled.\n  For Clang, enables `-Weverything`.  For GCC, enables `-Wpedantic`.\n  See [`CMakeLists.txt`](CMakeLists.txt) for details.\n* `SPIRV_WERROR={ON|OFF}`, default `ON` - Forces a compilation error on any\n  warnings encountered by enabling the compiler-specific compiler front-end\n  option.  No compiler front-end options are enabled when this option is OFF.\n\nAdditionally, you can pass additional C preprocessor definitions to SPIRV-Tools\nvia setting `SPIRV_TOOLS_EXTRA_DEFINITIONS`. For example, by setting it to\n`/D_ITERATOR_DEBUG_LEVEL=0` on Windows, you can disable checked iterators and\niterator debugging.\n\n### Android ndk-build\n\nSPIR-V Tools supports building static libraries `libSPIRV-Tools.a` and\n`libSPIRV-Tools-opt.a` for Android.  Using the Android NDK r25c or later:\n\n```\ncd <spirv-dir>\n\nexport ANDROID_NDK=/path/to/your/ndk   # NDK r25c or later\n\nmkdir build && cd build\nmkdir libs\nmkdir app\n\n$ANDROID_NDK/ndk-build -C ../android_test     \\\n                      NDK_PROJECT_PATH=.      \\\n                      NDK_LIBS_OUT=`pwd`/libs \\\n                      NDK_APP_OUT=`pwd`/app\n```\n\n### Updating DEPS\n\nOccasionally the entries in [DEPS](DEPS) will need to be updated. This is done on\ndemand when there is a request to do this, often due to downstream breakages.\nTo update `DEPS`, run `utils/roll_deps.sh` and confirm that tests pass.\nThe script requires Chromium's\n[`depot_tools`](https://chromium.googlesource.com/chromium/tools/depot_tools).\n\n## Library\n\n### Usage\n\nThe internals of the library use C++17 features, and are exposed via both a C\nand C++ API.\n\nIn order to use the library from an application, the include path should point\nto `<spirv-dir>/include`, which will enable the application to include the\nheader `<spirv-dir>/include/spirv-tools/libspirv.h{|pp}` then linking against\nthe static library in `<spirv-build-dir>/source/libSPIRV-Tools.a` or\n`<spirv-build-dir>/source/SPIRV-Tools.lib`.\nFor optimization, the header file is\n`<spirv-dir>/include/spirv-tools/optimizer.hpp`, and the static library is\n`<spirv-build-dir>/source/libSPIRV-Tools-opt.a` or\n`<spirv-build-dir>/source/SPIRV-Tools-opt.lib`.\n\n* `SPIRV-Tools` CMake target: Creates the static library:\n  * `<spirv-build-dir>/source/libSPIRV-Tools.a` on Linux and OS X.\n  * `<spirv-build-dir>/source/libSPIRV-Tools.lib` on Windows.\n* `SPIRV-Tools-opt` CMake target: Creates the static library:\n  * `<spirv-build-dir>/source/libSPIRV-Tools-opt.a` on Linux and OS X.\n  * `<spirv-build-dir>/source/libSPIRV-Tools-opt.lib` on Windows.\n\n#### Entry points\n\nThe interfaces are still under development, and are expected to change.\n\nThere are five main entry points into the library in the C interface:\n\n* `spvTextToBinary`: An assembler, translating text to a binary SPIR-V module.\n* `spvBinaryToText`: A disassembler, translating a binary SPIR-V module to\n  text.\n* `spvBinaryParse`: The entry point to a binary parser API.  It issues callbacks\n  for the header and each parsed instruction.  The disassembler is implemented\n  as a client of `spvBinaryParse`.\n* `spvValidate` implements the validator functionality. *Incomplete*\n* `spvValidateBinary` implements the validator functionality. *Incomplete*\n\nThe C++ interface is comprised of three classes, `SpirvTools`, `Optimizer` and\n`Linker`, all in the `spvtools` namespace.\n* `SpirvTools` provides `Assemble`, `Disassemble`, and `Validate` methods.\n* `Optimizer` provides methods for registering and running optimization passes.\n* `Linker` provides methods for combining together multiple binaries.\n\n## Command line tools\n\nCommand line tools, which wrap the above library functions, are provided to\nassemble or disassemble shader files.  It's a convention to name SPIR-V\nassembly and binary files with suffix `.spvasm` and `.spv`, respectively.\n\n### Assembler tool\n\nThe assembler reads the assembly language text, and emits the binary form.\n\nThe standalone assembler is the executable called `spirv-as`, and is located in\n`<spirv-build-dir>/tools/spirv-as`.  The functionality of the assembler is implemented\nby the `spvTextToBinary` library function.\n\n* `spirv-as` - the standalone assembler\n  * `<spirv-dir>/tools/as`\n\nUse option `-h` to print help.\n\n### Disassembler tool\n\nThe disassembler reads the binary form, and emits assembly language text.\n\nThe standalone disassembler is the executable called `spirv-dis`, and is located in\n`<spirv-build-dir>/tools/spirv-dis`. The functionality of the disassembler is implemented\nby the `spvBinaryToText` library function.\n\n* `spirv-dis` - the standalone disassembler\n  * `<spirv-dir>/tools/dis`\n\nUse option `-h` to print help.\n\nThe output includes syntax colouring when printing to the standard output stream,\non Linux, Windows, and OS X.\n\n### Linker tool\n\nThe linker combines multiple SPIR-V binary modules together, resulting in a single\nbinary module as output.\n\nThis is a work in progress.\nThe linker does not support OpenCL program linking options related to math\nflags. (See section 5.6.5.2 in OpenCL 1.2)\n\n* `spirv-link` - the standalone linker\n  * `<spirv-dir>/tools/link`\n\n### Optimizer tool\n\nThe optimizer processes a SPIR-V binary module, applying transformations\nin the specified order.\n\nThis is a work in progress, with initially only few available transformations.\n\n* `spirv-opt` - the standalone optimizer\n  * `<spirv-dir>/tools/opt`\n\n### Validator tool\n\n*Warning:* This functionality is under development, and is incomplete.\n\nThe standalone validator is the executable called `spirv-val`, and is located in\n`<spirv-build-dir>/tools/spirv-val`. The functionality of the validator is implemented\nby the `spvValidate` library function.\n\nThe validator operates on the binary form.\n\n* `spirv-val` - the standalone validator\n  * `<spirv-dir>/tools/val`\n\n### Reducer tool\n\nThe reducer shrinks a SPIR-V binary module, guided by a user-supplied\n*interestingness test*.\n\nThis is a work in progress, with initially only shrinks a module in a few ways.\n\n* `spirv-reduce` - the standalone reducer\n  * `<spirv-dir>/tools/reduce`\n\nRun `spirv-reduce --help` to see how to specify interestingness.\n\n### Fuzzer tool\n\nThe fuzzer transforms a SPIR-V binary module into a semantically-equivalent\nSPIR-V binary module by applying transformations in a randomized fashion.\n\nThis is a work in progress, with initially only a few semantics-preserving\ntransformations.\n\n* `spirv-fuzz` - the standalone fuzzer\n  * `<spirv-dir>/tools/fuzz`\n\nRun `spirv-fuzz --help` for a detailed list of options.\n\n### Control flow dumper tool\n\nThe control flow dumper prints the control flow graph for a SPIR-V module as a\n[GraphViz](http://www.graphviz.org/) graph.\n\nThis is experimental.\n\n* `spirv-cfg` - the control flow graph dumper\n  * `<spirv-dir>/tools/cfg`\n\n### Diff tool\n\n*Warning:* This functionality is under development, and is incomplete.\n\nThe diff tool produces a diff-style comparison between two SPIR-V modules.\n\n* `spirv-diff` - the standalone diff tool\n  * `<spirv-dir>`/tools/diff`\n\n### Utility filters\n\n* `spirv-lesspipe.sh` - Automatically disassembles `.spv` binary files for the\n  `less` program, on compatible systems.  For example, set the `LESSOPEN`\n  environment variable as follows, assuming both `spirv-lesspipe.sh` and\n  `spirv-dis` are on your executable search path:\n  ```\n   export LESSOPEN='| spirv-lesspipe.sh \"%s\"'\n  ```\n  Then you page through a disassembled module as follows:\n  ```\n  less foo.spv\n  ```\n  * The `spirv-lesspipe.sh` script will pass through any extra arguments to\n    `spirv-dis`.  So, for example, you can turn off colours and friendly ID\n    naming as follows:\n    ```\n    export LESSOPEN='| spirv-lesspipe.sh \"%s\" --no-color --raw-id'\n    ```\n\n* [vim-spirv](https://github.com/kbenzie/vim-spirv) - A vim plugin which\n  supports automatic disassembly of `.spv` files using the `:edit` command and\n  assembly using the `:write` command. The plugin also provides additional\n  features which include; syntax highlighting; highlighting of all ID's matching\n  the ID under the cursor; and highlighting errors where the `Instruction`\n  operand of `OpExtInst` is used without an appropriate `OpExtInstImport`.\n\n* `50spirv-tools.el` - Automatically disassembles '.spv' binary files when\n  loaded into the emacs text editor, and re-assembles them when saved,\n  provided any modifications to the file are valid.  This functionality\n  must be explicitly requested by defining the symbol\n  SPIRV_TOOLS_INSTALL_EMACS_HELPERS as follows:\n  ```\n  cmake -DSPIRV_TOOLS_INSTALL_EMACS_HELPERS=true ...\n  ```\n\n  In addition, this helper is only installed if the directory /etc/emacs/site-start.d\n  exists, which is typically true if emacs is installed on the system.\n\n  Note that symbol IDs are not currently preserved through a load/edit/save operation.\n  This may change if the ability is added to spirv-as.\n\n\n### Tests\n\nTests are only built when googletest is found.\n\n#### Running test with CMake\n\nUse `ctest -j <num threads>` to run all the tests. To run tests using all threads:\n```shell\nctest -j$(nproc)\n```\n\nTo run a single test target, use `ctest [-j <N>] -R <test regex>`. For example,\nyou can run all `opt` tests with:\n```shell\nctest -R 'spirv-tools-test_opt'\n```\n\n#### Running test with Bazel\n\nUse `bazel test :all` to run all tests. This will run tests in parallel by default.\n\nTo run a single test target, specify `:my_test_target` instead of `:all`. Test target\nnames get printed when you run `bazel test :all`. For example, you can run\n`opt_def_use_test` with:\n\non linux:\n```shell\nbazel test --cxxopt=-std=c++17 :opt_def_use_test\n```\n\non windows:\n```shell\nbazel test --cxxopt=/std:c++17 :opt_def_use_test\n```\n\n## Future Work\n<a name=\"future\"></a>\n\n_See the [projects pages](https://github.com/KhronosGroup/SPIRV-Tools/projects)\nfor more information._\n\n### Assembler and disassembler\n\n* The disassembler could emit helpful annotations in comments.  For example:\n  * Use variable name information from debug instructions to annotate\n    key operations on variables.\n  * Show control flow information by annotating `OpLabel` instructions with\n    that basic block's predecessors.\n* Error messages could be improved.\n\n### Validator\n\nThis is a work in progress.\n\n### Linker\n\n* The linker could accept math transformations such as allowing MADs, or other\n  math flags passed at linking-time in OpenCL.\n* Linkage attributes can not be applied through a group.\n* Check decorations of linked functions attributes.\n* Remove dead instructions, such as OpName targeting imported symbols.\n\n## Licence\n<a name=\"license\"></a>\nFull license terms are in [LICENSE](LICENSE)\n```\nCopyright (c) 2015-2016 The Khronos Group Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n[spirv-tools-cla]: https://cla-assistant.io/KhronosGroup/SPIRV-Tools\n[spirv-tools-projects]: https://github.com/KhronosGroup/SPIRV-Tools/projects\n[spirv-tools-mailing-list]: https://www.khronos.org/spir/spirv-tools-mailing-list\n[spirv-registry]: https://www.khronos.org/registry/spir-v/\n[spirv-headers]: https://github.com/KhronosGroup/SPIRV-Headers\n[googletest]: https://github.com/google/googletest\n[googletest-pull-612]: https://github.com/google/googletest/pull/612\n[googletest-issue-610]: https://github.com/google/googletest/issues/610\n[effcee]: https://github.com/google/effcee\n[re2]: https://github.com/google/re2\n[abseil-cpp]: https://github.com/abseil/abseil-cpp\n[mimalloc]: https://github.com/microsoft/mimalloc\n[CMake]: https://cmake.org/\n[cpp-style-guide]: https://google.github.io/styleguide/cppguide.html\n[clang-sanitizers]: http://clang.llvm.org/docs/UsersManual.html#controlling-code-generation\n",
      "stars_today": 0
    },
    {
      "id": 45709704,
      "name": "sf",
      "full_name": "r-spatial/sf",
      "description": "Simple Features for R",
      "html_url": "https://github.com/r-spatial/sf",
      "stars": 1417,
      "forks": 300,
      "language": "R",
      "topics": [
        "gdal",
        "geos",
        "proj",
        "r",
        "r-package",
        "rstats",
        "spatial"
      ],
      "created_at": "2015-11-06T21:49:34Z",
      "updated_at": "2026-01-21T17:20:46Z",
      "pushed_at": "2026-01-22T21:29:46Z",
      "open_issues": 74,
      "owner": {
        "login": "r-spatial",
        "avatar_url": "https://avatars.githubusercontent.com/u/25086656?v=4"
      },
      "readme": "<!-- badges: start -->\n[![R-CMD-check](https://github.com/r-spatial/sf/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/r-spatial/sf/actions/workflows/R-CMD-check.yaml)\n[![tic-db](https://github.com/r-spatial/sf/actions/workflows/tic-db.yml/badge.svg)](https://github.com/r-spatial/sf/actions/workflows/tic-db.yml)\n[![Coverage Status](https://img.shields.io/codecov/c/github/r-spatial/sf/main.svg)](https://app.codecov.io/gh/r-spatial/sf)\n[![License](http://img.shields.io/badge/license-GPL%20%28%3E=%202%29-brightgreen.svg?style=flat)](http://www.gnu.org/licenses/gpl-2.0.html)\n[![CRAN](https://www.r-pkg.org/badges/version/sf)](https://cran.r-project.org/package=sf)\n[![cran checks](https://badges.cranchecks.info/worst/sf.svg)](https://cran.r-project.org/web/checks/check_results_sf.html)\n[![Downloads](https://cranlogs.r-pkg.org/badges/sf?color=brightgreen)](https://www.r-pkg.org/pkg/sf)\n[![status](https://tinyverse.netlify.app/badge/sf)](https://CRAN.R-project.org/package=sf)\n<!-- badges: end -->\n\n# Simple Features for R\n\n<a href=\"https://gist.github.com/edzer/f461a3a95570c4ab7edf3125c2f19d20\"><img align=\"right\" src=\"https://user-images.githubusercontent.com/520851/34887433-ce1d130e-f7c6-11e7-83fc-d60ad4fae6bd.gif\" /></a>\n\nA package that provides [simple features access](https://en.wikipedia.org/wiki/Simple_Features) for R. \n\n[Blogs, links](#blogs-presentations-vignettes-sp-sf-wiki) ‚Ä¢ [Cheatsheet](#cheatsheet) ‚Ä¢ [Installing](#installing)\n‚Ä¢ [Contributing](#contributing) ‚Ä¢ [Acknowledgment](#acknowledgment) ‚Ä¢ [How to cite](#how-to-cite)\n\nPackage sf:\n\n* represents simple features as records in a `data.frame` or `tibble` with a geometry list-column\n* represents natively in R all 17 simple feature types for all dimensions (XY, XYZ, XYM, XYZM)\n* interfaces to [GEOS](https://libgeos.org) for geometrical operations on projected coordinates, and (through R package [s2](https://cran.r-project.org/package=s2)) to [s2geometry](http://s2geometry.io/) for geometrical operations on ellipsoidal coordinates\n* interfaces to [GDAL](https://gdal.org/), supporting all driver options, `Date` and `POSIXct` and list-columns\n* interfaces to [PR√òJ](http://proj.org/) for coordinate reference system conversion and transformation\n* uses [well-known-binary](https://en.wikipedia.org/wiki/Well-known_text#Well-known_binary) serialisations written in C++/Rcpp for fast I/O with GDAL and GEOS \n* reads from and writes to spatial databases such as [PostGIS](http://postgis.net/) using [DBI](https://cran.r-project.org/package=DBI)\n* is extended by \n    * [lwgeom](https://github.com/r-spatial/lwgeom/) for selected liblwgeom/PostGIS functions\n    * [stars](https://github.com/r-spatial/stars/) for raster data, and raster or vector data cubes (spatial time series)\n    * [sfnetworks](https://luukvdmeer.github.io/sfnetworks/) for geospatial network data\n\n<a href=\"https://gist.github.com/edzer/442d74a5775abcd5068cf3e73b23687b\"><img align=\"left\" src=\"https://user-images.githubusercontent.com/520851/50280460-e35c1880-044c-11e9-9ed7-cc46754e49db.jpg\" /></a>\n\n(Illustration (c) 2018 by <a href=\"https://twitter.com/allison_horst/status/1071456081308614656\">Allison Horst</a>)\n\n## Books, journal articles, blogs, presentations, vignettes, sp-sf wiki\n\n* an open access [R Journal article](https://journal.r-project.org/archive/2018/RJ-2018-009/index.html) summarizes the package\n* two books: [Spatial Data Science: with applications in R](https://r-spatial.org/book/), [Geocomputation with R](https://r.geocompx.org/)\n* package vignettes: [first](https://r-spatial.github.io/sf/articles/sf1.html), [second](https://r-spatial.github.io/sf/articles/sf2.html), [third](https://r-spatial.github.io/sf/articles/sf3.html), [fourth](https://r-spatial.github.io/sf/articles/sf4.html), [fifth](https://r-spatial.github.io/sf/articles/sf5.html), [sixth](https://r-spatial.github.io/sf/articles/sf6.html), [seventh](https://r-spatial.github.io/sf/articles/sf7.html)\n* blog posts: [first](https://r-spatial.org/r/2016/02/15/simple-features-for-r.html), [second](https://r-spatial.org/r/2016/07/18/sf2.html), [third](https://r-spatial.org/r/2016/11/02/sfcran.html), [fourth](https://r-spatial.org/r/2017/01/12/newssf.html)\n* the original R Consortium ISC [proposal](PROPOSAL.md), the R Consortium [blog post](https://www.r-consortium.org/blog/2017/01/03/simple-features-now-on-cran)\n* presentations: [rstudio::conf 2018](https://edzer.github.io/rstudio_conf/#1) ([video](https://posit.co/resources/videos/tidy-spatial-data-analysis/)), [UseR! 2016](http://pebesma.staff.ifgi.de/pebesma_sfr.pdf)\n* wiki page describing [sp-sf migration](https://github.com/r-spatial/sf/wiki/Migrating)\n\n## Cheatsheet\n[CC 4.0](https://creativecommons.org/licenses/by/4.0/) BY [Ryan Garnett](https://github.com/ryangarnett)  \n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/sf.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/sf.png\" /></a>\n\n## Installing\n\nInstall either from CRAN with:\n```r\ninstall.packages(\"sf\")\n```\nThis will install binary packages on Windows and MacOS, unless you configured R such that it tries to install source packages; in that case, see below.\n\nInstall development versions from GitHub with:\n```r\nlibrary(remotes)\ninstall_github(\"r-spatial/sf\")\n```\n\n### Windows\n\nInstalling sf from source works under Windows when [Rtools](https://cran.r-project.org/bin/windows/Rtools/) is installed.\n\n### MacOS\n\nMacOS users are strongly encouraged to install the `sf` binary packages from CRAN, unless they are familiar with compilers, linking, C++ source code, and homebrew. If you experience that R tries to install `sf` from source (or otherwise your install fails but you don't understand what is going on) try again by explicitly installing the binary, using\n\n```r\ninstall.packages(\"sf\", type = \"binary\")\n```\n\nThe remainder of this section is for those who understand what source installs mean, and imply.\n\nPerhaps the easiest way of an install from source is to first install `gdal` using Homebrew. Recent versions of Homebrew include a full-featured up-to-date [gdal formula](https://github.com/Homebrew/homebrew-core/blob/master/Formula/g/gdal.rb), which installs `proj` and `gdal` at the same time:\n\n```\nbrew install pkg-config\nbrew install gdal\n```\n\nOnce gdal is installed, you may be able to install `sf` package from source in R. With the current version of `proj` on homebrew, installation requires additional configuration:\n\n```r\ninstall.packages(\"sf\", type = \"source\", configure.args = \"--with-proj-lib=$(brew --prefix)/lib/\")\n```\n\nOr the development version:\n\n```r\nlibrary(remotes)\ninstall_github(\"r-spatial/sf\", configure.args = \"--with-proj-lib=$(brew --prefix)/lib/\")\n```\n\nAlternatively, [these instructions](https://stat.ethz.ch/pipermail/r-sig-mac/2017-June/012429.html) explain how to install gdal using kyngchaos frameworks.\n\nFor Mac OS 11 Big Sur source install instruction, see [here](https://github.com/r-spatial/sf/issues/1536#issuecomment-727342736)\n\n### Linux\n\nFor Unix-alikes, GDAL (>= 2.0.1), GEOS (>= 3.4.0) and Proj.4 (>= 4.8.0) are required.\n\n#### Ubuntu\n\nDependencies for recent versions of Ubuntu (18.04 and later) are available in the official repositories; you can install them with:\n\n```sh\nsudo apt -y update && apt install -y libudunits2-dev libgdal-dev libgeos-dev libproj-dev libsqlite3-dev\n```\n\nHowever, to get more up-to-date versions of dependencies such as GDAL, GEOS and PROJ we recommend adding the [ubuntugis-unstable](http://ppa.launchpad.net/ubuntugis/ubuntugis-unstable/ubuntu/) PPA to the package repositories and installing them as follows:\n\n```sh\nsudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt update\nsudo apt install libudunits2-dev libgdal-dev libgeos-dev libproj-dev libsqlite3-dev\n```\n\nAdding this PPA is required for installing `sf` on older versions of Ubuntu (e.g. Xenial).\n\nAnother option, for advanced users, is to install dependencies from source; see e.g. an older [Travis](https://github.com/r-spatial/sf/blob/593ee48b34001fe3b383ea73ea57063ecf690732/.travis.yml) config file for hints.\n\n#### Fedora\nThe following command installs all required dependencies:\n```sh\nsudo dnf install gdal-devel proj-devel geos-devel sqlite-devel udunits2-devel\n```\n\n#### Arch\n\nGet gdal, proj, geos and podofo from the main repos, and udunits from the AUR:\n\n```\npacman -S gdal proj geos arrow podofo\nyay/pacaur/yaourt/whatever -S udunits\n```\n\n#### `renv` or `conda`\n\nThere are several reports that `sf` fails to install as a source package when R is used with `renv`, or when R is installed in a `conda` environment. If you experience this, please do not raise an issue here, but \n\n* try to sort this out with the `renv` developers or the `conda` maintainers, or\n* try to use binary installs of the `sf` package, e.g. from [r2u](https://github.com/eddelbuettel/r2u), or the Posit package manager\n\n#### Other\n\nTo install on Debian, the [rocker geospatial](https://github.com/rocker-org/geospatial) Dockerfiles may be helpful. Ubuntu Dockerfiles are found [here](https://github.com/r-spatial/sf/tree/main/inst/docker).\n\n### Multiple GDAL, GEOS and/or PROJ versions on your system\n\nIf you use dynamic linking (installation from source) and have multiple versions of these libraries installed (e.g. one from ubuntugis-unstable, another installed from source in `/usr/local/lib`) then this will in general not work, even when setting `LD_LIBRARY_PATH` manually. See [here](https://github.com/r-spatial/sf/issues/844) for the reason why. \n\n### lwgeom\n\nFunctions and methods that require `liblwgeom`, including ellipsoidal (not spherical or Euclidean) metrics (area, distances), are provide by and used from [lwgeom](https://github.com/r-spatial/lwgeom), which is also on [CRAN](https://cran.r-project.org/package=lwgeom).\n\n## Contributing\n\n* Contributions of all sorts are most welcome, issues and pull requests are the preferred ways of sharing them.\n* When contributing pull requests, please adhere to the package style (in package code use `=` rather than `<-`; don't change indentation; tab stops of 4 spaces are preferred).\n* This project is released with a [Contributor Code of Conduct](CONDUCT.md). By participating in this project, you agree to abide by its terms.\n\n## How to cite\n\nPackage `sf` can be cited as: \n\n* Edzer Pebesma, 2018.  Simple Features for R: Standardized Support\nfor Spatial Vector Data. The R Journal [10:1, 439-446.](https://journal.r-project.org/archive/2018/RJ-2018-009/index.html)\n\n* Pebesma, E.; Bivand, R. (2023). [Spatial Data Science: With Applications in R](https://r-spatial.org/book/) \n(1st ed.). 314 pages. [Chapman and Hall/CRC](https://doi.org/10.1201/9780429459016).\n\n## Acknowledgment\n\nThis project gratefully acknowledges financial [support](https://www.r-consortium.org/projects) from the\n\n<a href=\"https://r-consortium.org/all-projects/2016-group-1.html#simple-features-for-r\">\n<img src=\"https://r-consortium.org/images/RConsortium_Horizontal_Pantone.webp\" width=\"300\">\n</a>\n<!--\n<img src=\"http://pebesma.staff.ifgi.de/RConsortium_Horizontal_Pantone.png\" width=\"300\">\n-->\n\n",
      "stars_today": 0
    },
    {
      "id": 20360040,
      "name": "clusterProfiler",
      "full_name": "YuLab-SMU/clusterProfiler",
      "description": ":bar_chart: A universal enrichment tool for interpreting omics data",
      "html_url": "https://github.com/YuLab-SMU/clusterProfiler",
      "stars": 1156,
      "forks": 263,
      "language": "R",
      "topics": [
        "enrichment-analysis",
        "go",
        "gsea",
        "kegg",
        "rstats",
        "visualization"
      ],
      "created_at": "2014-05-31T16:34:32Z",
      "updated_at": "2026-01-22T06:05:51Z",
      "pushed_at": "2026-01-22T06:05:47Z",
      "open_issues": 361,
      "owner": {
        "login": "YuLab-SMU",
        "avatar_url": "https://avatars.githubusercontent.com/u/40430016?v=4"
      },
      "readme": "# clusterProfiler\n\n<img src=\"inst/sticker/clusterProfiler_hex.png\" height=\"200\" align=\"right\" />\n\n[![Project Status: Active - The project has reached a stable, usable\nstate and is being actively\ndeveloped.](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)\n[![](https://img.shields.io/badge/release%20version-4.18.4-green.svg)](https://www.bioconductor.org/packages/clusterProfiler)\n[![](https://img.shields.io/badge/devel%20version-4.19.4.006-green.svg)](https://github.com/guangchuangyu/clusterProfiler)\n[![Bioc](http://www.bioconductor.org/shields/years-in-bioc/clusterProfiler.svg)](https://www.bioconductor.org/packages/devel/bioc/html/clusterProfiler.html#since)\n\n[![platform](http://www.bioconductor.org/shields/availability/devel/clusterProfiler.svg)](https://www.bioconductor.org/packages/devel/bioc/html/clusterProfiler.html#archives)\n[![Build\nStatus](http://www.bioconductor.org/shields/build/devel/bioc/clusterProfiler.svg)](https://bioconductor.org/checkResults/devel/bioc-LATEST/clusterProfiler/)\n[![codecov](https://codecov.io/gh/GuangchuangYu/clusterProfiler/branch/master/graph/badge.svg)](https://codecov.io/gh/GuangchuangYu/clusterProfiler/)\n\n<!--\n[![Last-changedate](https://img.shields.io/badge/last%20change-2026--01--21-green.svg)](https://github.com/GuangchuangYu/clusterProfiler/commits/master)\n-->\n\n- [clusterProfiler](http://bioconductor.org/packages/clusterProfiler)\n  supports exploring functional characteristics of both coding and\n  non-coding genomics data for thousands of species with up-to-date gene\n  annotation.\n- It provides a universal interface for gene functional annotation from\n  a variety of sources and thus can be applied in diverse scenarios.\n- It provides a tidy interface to access, manipulate, and visualize\n  enrichment results to help users achieve efficient data interpretation\n- Datasets obtained from multiple treatments and time points can be\n  analyzed and compared in a single run, easily revealing functional\n  consensus and differences among distinct conditions\n\nFor details, please visit:\n\n- <https://yulab-smu.top/contribution-knowledge-mining/>\n- <https://yulab-smu.top/biomedical-knowledge-mining-book/>\n\n<img src=\"graphic-abstract-The-Innovation-2021.jpg\" width=\"890\"/>\n\n## :writing_hand: Authors\n\nGuangchuang YU <https://yulab-smu.top>\n\nSchool of Basic Medical Sciences, Southern Medical University\n\n------------------------------------------------------------------------\n\nIf you use\n[clusterProfiler](http://bioconductor.org/packages/clusterProfiler) in\npublished research, please cite the most appropriate paper(s) from this\nlist:\n\n1.  S Xu<sup>\\#</sup>, E Hu<sup>\\#</sup>, Y Cai<sup>\\#</sup>, Z\n    Xie<sup>\\#</sup>, X Luo<sup>\\#</sup>, L Zhan, W Tang, Q Wang, B Liu,\n    R Wang, W Xie, T Wu, L Xie, **G Yu**<sup>\\*</sup>. Using\n    clusterProfiler to characterise Multi-Omics Data. ***Nature\n    Protocols***. 2024, accepted. doi:\n    [10.1038/s41596-024-01020-z](https://doi.org/10.1038/s41596-024-01020-z)\n2.  T Wu<sup>\\#</sup>, E Hu<sup>\\#</sup>, S Xu, M Chen, P Guo, Z Dai, T\n    Feng, L Zhou, W Tang, L Zhan, X Fu, S Liu, X Bo<sup>\\*</sup>, **G\n    Yu**<sup>\\*</sup>. clusterProfiler 4.0: A universal enrichment tool\n    for interpreting omics data. ***The Innovation***. 2021,\n    2(3):100141. doi:\n    [10.1016/j.xinn.2021.100141](https://doi.org/10.1016/j.xinn.2021.100141)\n3.  **G Yu**<sup>\\*</sup>. Gene Ontology Semantic Similarity Analysis\n    Using GOSemSim. In: Kidder B. (eds) Stem Cell Transcriptional\n    Networks. ***Methods in Molecular Biology***. 2020, 2117:207-215.\n    Humana, New York, NY. doi:\n    [10.1007/978-1-0716-0301-7_11](https://doi.org/10.1007/978-1-0716-0301-7_11)\n4.  **G Yu**<sup>\\*</sup>. Using meshes for MeSH term enrichment and\n    semantic analyses. ***Bioinformatics***. 2018, 34(21):3766‚Äì3767.\n    doi:\n    [10.1093/bioinformatics/bty410](https://doi.org/10.1093/bioinformatics/bty410)\n5.  **G Yu**, QY He<sup>\\*</sup>. ReactomePA: an R/Bioconductor package\n    for reactome pathway analysis and visualization. ***Molecular\n    BioSystems***. 2016, 12(2):477-479. doi:\n    [10.1039/C5MB00663E](https://doi.org/10.1039/C5MB00663E)\n6.  **G Yu**<sup>\\*</sup>, LG Wang, and QY He<sup>\\*</sup>. ChIPseeker:\n    an R/Bioconductor package for ChIP peak annotation, comparison and\n    visualization. ***Bioinformatics***. 2015, 31(14):2382-2383. doi:\n    [10.1093/bioinformatics/btv145](https://doi.org/10.1093/bioinformatics/btv145)\n7.  **G Yu**<sup>\\*</sup>, LG Wang, GR Yan, QY He<sup>\\*</sup>. DOSE: an\n    R/Bioconductor package for Disease Ontology Semantic and Enrichment\n    analysis. ***Bioinformatics***. 2015, 31(4):608-609. doi:\n    [10.1093/bioinformatics/btu684](https://doi.org/10.1093/bioinformatics/btu684)\n8.  **G Yu**, LG Wang, Y Han and QY He<sup>\\*</sup>. clusterProfiler: an\n    R package for comparing biological themes among gene clusters.\n    ***OMICS: A Journal of Integrative Biology***. 2012, 16(5):284-287.\n    doi: [10.1089/omi.2011.0118](https://doi.org/10.1089/omi.2011.0118)\n9.  **G Yu**, F Li, Y Qin, X Bo<sup>\\*</sup>, Y Wu, S Wang<sup>\\*</sup>.\n    GOSemSim: an R package for measuring semantic similarity among GO\n    terms and gene products. ***Bioinformatics***. 2010, 26(7):976-978.\n    doi:\n    [10.1093/bioinformatics/btq064](https://doi.org/10.1093/bioinformatics/btq064)\n\n<!--\n&#10;\n&#10; r badge_custom(\"1st most cited paper\", \"in OMICS\", \"green\",\n  \"http://online.liebertpub.com/action/showMostCitedArticles?journalCode=omi\")`\n r badge_custom(\"ESI\", \"Highly Cited Paper\", \"green\")`\n r badge_doi(\"10.1089/omi.2011.0118\", \"green\")`\n&#10;\n------------------------------------------------------------------------\n&#10;### Citation\n&#10;\n&#10;\n<img src=\"https://guangchuangyu.github.io/software/citation_trend/clusterProfiler.png\" width=\"890\"/>\n&#10;\n### Download stats\n&#10;r badge_download_bioc(\"clusterProfiler\")\nr badge_bioc_download(\"clusterProfiler\", \"total\", \"blue\")\nr badge_bioc_download(\"clusterProfiler\", \"month\", \"blue\")\n&#10;\n<img src=\"https://guangchuangyu.github.io/software/dlstats/clusterProfiler.png\" width=\"890\"/>\n&#10;-->\n",
      "stars_today": 0
    },
    {
      "id": 159560389,
      "name": "renv",
      "full_name": "rstudio/renv",
      "description": "renv: Project environments for R.",
      "html_url": "https://github.com/rstudio/renv",
      "stars": 1126,
      "forks": 162,
      "language": "R",
      "topics": [],
      "created_at": "2018-11-28T20:25:39Z",
      "updated_at": "2026-01-23T01:23:09Z",
      "pushed_at": "2026-01-22T07:14:26Z",
      "open_issues": 211,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# renv <img src=\"man/figures/logo.svg\" align=\"right\" height=\"115\"/>\n\n<!-- badges: start -->\n\n[![Lifecycle:\nstable](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/renv)](https://CRAN.R-project.org/package=renv)\n[![R-CMD-check](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml)\n\n<!-- badges: end -->\n\n## Overview\n\nThe renv package[^1] helps you create **r**eproducible **env**ironments\nfor your R projects. Use renv to make your R projects more isolated,\nportable and reproducible.\n\n- **Isolated**: Installing a new or updated package for one project\n  won‚Äôt break your other projects, and vice versa. That‚Äôs because renv\n  gives each project its own private library.\n- **Portable**: Easily transport your projects from one computer to\n  another, even across different platforms. renv makes it easy to\n  install the packages your project depends on.\n- **Reproducible**: renv records the exact package versions you depend\n  on, and ensures those exact versions are the ones that get installed\n  wherever you go.\n\n## Installation\n\nInstall the latest version of renv from CRAN with:\n\n``` r\ninstall.packages(\"renv\")\n```\n\nAlternatively, install the development version from\n[r-universe](https://rstudio.r-universe.dev/renv) with:\n\n``` r\ninstall.packages(\"renv\", repos = \"https://rstudio.r-universe.dev\")\n```\n\n## Workflow\n\n<img src=\"vignettes/renv.png\" alt=\"A diagram showing the most important verbs and nouns of renv. Projects start with init(), which creates a project library using packages from the system library. snapshot() updates the lockfile using the packages installed in the project library, where restore() installs packages into the project library using the metadata from the lockfile, and status() compares the lockfile to the project library. You install and update packages from CRAN and GitHub using install() and update(), but because you'll need to do this for multiple projects, renv uses cache to make this fast.\" width=\"408\" style=\"display: block; margin: auto;\" />\n\nUse `renv::init()` to initialize renv in a new or existing project. This\nwill set up a **project library**, containing all the packages you‚Äôre\ncurrently using. The packages (and all the metadata needed to reinstall\nthem) are recorded into a **lockfile**, `renv.lock`, and a `.Rprofile`\nensures that the library is used every time you open that project.\n\nAs you continue to work on your project, you will install and upgrade\npackages, either using `install.packages()` and `update.packages()` or\n`renv::install()` and `renv::update()`. After you‚Äôve confirmed your code\nworks as expected, use `renv::snapshot()` to record the packages and\ntheir sources in the lockfile.\n\nLater, if you need to share your code with someone else or run your code\non new machine, your collaborator (or you) can call `renv::restore()` to\nreinstall the specific package versions recorded in the lockfile.\n\n## Learning more\n\nIf this is your first time using renv, we strongly recommend starting\nwith the [Introduction to\nrenv](https://rstudio.github.io/renv/articles/renv.html) vignette: this\nwill help you understand the most important verbs and nouns of renv.\n\nIf you have a question about renv, please first check the\n[FAQ](https://rstudio.github.io/renv/articles/faq.html) to see whether\nyour question has already been addressed. If it hasn‚Äôt, please feel free\nto ask on the [Posit Forum](https://forum.posit.co).\n\nIf you believe you‚Äôve found a bug in renv, please file a bug (and, if\npossible, a [reproducible example](https://reprex.tidyverse.org)) at\n<https://github.com/rstudio/renv/issues>.\n\n[^1]: Pronounced ‚ÄúR‚Äù ‚Äúenv‚Äù\n",
      "stars_today": 0
    },
    {
      "id": 259225467,
      "name": "CellChat",
      "full_name": "sqjin/CellChat",
      "description": "R toolkit for inference, visualization and analysis of cell-cell communication from single-cell data",
      "html_url": "https://github.com/sqjin/CellChat",
      "stars": 759,
      "forks": 167,
      "language": "R",
      "topics": [
        "cell-cell-communication",
        "cell-cell-interaction",
        "microenvironment",
        "single-cell-analysis"
      ],
      "created_at": "2020-04-27T06:28:33Z",
      "updated_at": "2026-01-21T05:58:36Z",
      "pushed_at": "2024-01-06T18:23:14Z",
      "open_issues": 455,
      "owner": {
        "login": "sqjin",
        "avatar_url": "https://avatars.githubusercontent.com/u/32399212?v=4"
      },
      "readme": "\n<p align=\"center\">\n  <img width=\"200\"  src=\"https://github.com/sqjin/CellChat/blob/master/CellChat_Logo.png\">\n</p>\n\n# CAUTION\nWe have updated CellChat to v2 and migrated CellChat to a new repository. This repository will be NOT updated and maintained any more. Please check the new repository [jinworks/CellChat](https://github.com/jinworks/CellChat) for the new updates, and the [CellChat v2 paper](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) for a comprehensive protocol of CellChat.  \n\n# About CellChat and CellChatDB\nCellChat is an R package designed for inference, analysis, and visualization of cell-cell communication from single-cell data. CellChat aims to enable users to identify and interpret cell-cell communication within an easily interpretable framework, with the emphasis of clear, attractive, and interpretable visualizations.  \n\nCellChatDB is a manually curated database of literature-supported ligand-receptor interactions in mutiple species, leading to a comprehensive recapitulation of known molecular interaction mechanisms including multi-subunit structure of ligand-receptor complexes and co-factors.\n\nIf you use CellChat in your research, please considering citing our papers: \n- [Suoqin Jin et al., CellChat for systematic analysis of cell-cell communication from single-cell and spatially resolved transcriptomics, bioRxiv 2023](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) [CellChat v2]\n- [Suoqin Jin et al., Inference and analysis of cell-cell communication using CellChat, Nature Communications 2021](https://www.nature.com/articles/s41467-021-21246-9) [CellChat v1]\n\n# Capabilities\nIn addition to infer the intercellular communication from any given single-cell data, CellChat provides functionality for further data exploration, analysis, and visualization. \n\n- It can quantitatively characterize and compare the inferred cell-cell communication networks using a systems approach by combining social network analysis, pattern recognition, and manifold learning approaches.\n- It provides an easy-to-use tool for extracting and visualizing high-order information of the inferred networks. For example, it allows ready prediction of major signaling inputs and outputs for all cell populations and how these populations and signals coordinate together for functions.\n- It enables comparative analysis of cell-cell communication across different conditions and identification of altered signaling and cell populations. \n- It provides several visualization outputs to facilitate intuitive user-guided data interpretation.\n\n<p align=\"center\">\n  <img width=\"700\"  src=\"https://github.com/sqjin/CellChat/blob/master/overview_CellChat.png\">\n</p>\n\n\n<p align=\"center\">\n  <a href=\"https://clustrmaps.com/site/1bpq2\">\n     <img width=\"200\"  src=\"https://clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=n&d=42WqeykSXznN_NSaBlpf6CtSXQxhqmIs6QusUsguFdY\" />\n   </a>\n</p>\n<p align=\"center\">\n  <a href=\"#\">\n     <img src=\"https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fsqjin%2FCellChat&labelColor=%233499cc&countColor=%2370c168\" />\n   </a>\n</p>\n\n\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 2188402,
      "name": "phyloseq",
      "full_name": "joey711/phyloseq",
      "description": "phyloseq is a set of classes, wrappers, and tools (in R) to make it easier to import, store, and analyze phylogenetic sequencing data; and to reproducibly share that data and analysis with others. See the phyloseq front page:",
      "html_url": "https://github.com/joey711/phyloseq",
      "stars": 635,
      "forks": 193,
      "language": "R",
      "topics": [],
      "created_at": "2011-08-11T00:16:34Z",
      "updated_at": "2026-01-12T16:12:10Z",
      "pushed_at": "2024-04-29T20:03:19Z",
      "open_issues": 765,
      "owner": {
        "login": "joey711",
        "avatar_url": "https://avatars.githubusercontent.com/u/841437?v=4"
      },
      "readme": "<link href=\"http://joey711.github.com/phyloseq/markdown.css\" rel=\"stylesheet\"></link>\n\n# [phyloseq](http://joey711.github.com/phyloseq/)\n\n[![Travis-CI Build Status](https://travis-ci.org/joey711/phyloseq.svg?branch=master)](https://travis-ci.org/joey711/phyloseq)\n\n![phyloseq](inst/extdata/phyloseq.png)\n\n## Quick Install\n\nIn R terminal:\n\n```\nif(!requireNamespace(\"BiocManager\")){\n  install.packages(\"BiocManager\")\n}\nBiocManager::install(\"phyloseq\")\n```\n\nSee [the phyloseq installation page](http://joey711.github.io/phyloseq/install.html)\nfor further details, examples.\n\n## Article on Improved Microbiome Analysis\n\nMcMurdie and Holmes (2014)\n[Waste Not, Want Not: Why Rarefying Microbiome Data is Statistically Inadmissible](http://dx.plos.org/10.1371/journal.pcbi.1003531)\n*PLoS Computational Biology*\n10(4): e1003531\n\nPresubmission versions ahead of acceptance (2013):\n[PDF version 2](http://arxiv.org/pdf/1310.0424v2.pdf),\n[PDF version 1](http://arxiv.org/pdf/1310.0424v1.pdf)\n\n\n## Peer-reviewed articles about phyloseq\n\nMcMurdie and Holmes (2014) [Shiny-phyloseq: Web Application for Interactive Microbiome Analysis with Provenance Tracking](http://bioinformatics.oxfordjournals.org/content/early/2014/10/02/bioinformatics.btu616).\n*Bioinformatics (Oxford, England)*\n31(2), 282‚Äì283.\n\nMcMurdie and Holmes (2013)\n[phyloseq: An R package for reproducible interactive analysis and graphics of microbiome census data](http://dx.plos.org/10.1371/journal.pone.0061217)\n*PLoS ONE* \n8(4):e61217\n\n## Other resources\n\nThe phyloseq project also has a number of supporting online resources,\nincluding (but probably not limited to)\n\n### [the phyloseq home page](http://joey711.github.com/phyloseq/)\n\n### [the phyloseq FAQ](https://www.bioconductor.org/packages/release/bioc/vignettes/phyloseq/inst/doc/phyloseq-FAQ.html)\nI recommend checking this page, and the issues tracker,\nbefore posting new issues.\n\n### [Bioconductor stable release](http://bioconductor.org/packages/release/bioc/html/phyloseq.html).\n\n### [the phyloseq Issue Tracker](https://github.com/joey711/phyloseq/issues)\nThis is the recommended location to post\n\n(1) feature requests\n(2) bug reports\n(3) theoretical considerations\n(4) other issues, feedback\n(5) ask for help\n\nSearch previous posts,\nand check [the phyloseq FAQ](https://www.bioconductor.org/packages/release/bioc/vignettes/phyloseq/inst/doc/phyloseq-FAQ.html)\nbefore posting a new issue.\n",
      "stars_today": 0
    },
    {
      "id": 53894616,
      "name": "infercnv",
      "full_name": "broadinstitute/infercnv",
      "description": "Inferring CNV from Single-Cell RNA-Seq",
      "html_url": "https://github.com/broadinstitute/infercnv",
      "stars": 650,
      "forks": 177,
      "language": "R",
      "topics": [],
      "created_at": "2016-03-14T21:53:54Z",
      "updated_at": "2026-01-20T07:04:11Z",
      "pushed_at": "2025-11-14T17:35:17Z",
      "open_issues": 236,
      "owner": {
        "login": "broadinstitute",
        "avatar_url": "https://avatars.githubusercontent.com/u/393552?v=4"
      },
      "readme": "\n***********************************************\n>InferCNV is no longer supported. Please explore alternatives such as InferCNA (https://jlaffy.github.io/infercna/)[https://jlaffy.github.io/infercna/], CopyKAT (https://github.com/navinlabcode/copykat)[https://github.com/navinlabcode/copykat], and Numbat (https://github.com/kharchenkolab/numbat)[https://github.com/kharchenkolab/numbat]\n***********************************************\n\n# Subclustering\n\nSubclustering resolution is one of the primary settings that will need to be adjusted in most runs to avoid oversplitting. The tutorial below explains how it works and details about it can also be found on the [wiki](https://github.com/broadinstitute/infercnv/wiki/infercnv-tumor-subclusters#tumor-subclustering-by-leiden-clustering-preferred).\n\n# Documentation\n### Full documentation\n\nVisit project [wiki](https://github.com/broadinstitute/inferCNV/wiki) for InferCNV documentation.\n\n\n### Infercnv video tutorial\n\nA **video** tutorial giving on overview of infercnv features and how to run an analysis can be found below **(click on the image)**:\n\n[![Tutorial: Running infercnv](http://img.youtube.com/vi/-qOcHAavZT8/0.jpg)](http://www.youtube.com/watch?v=-qOcHAavZT8 \"Tutorial: Running infercnv\")\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 28114218,
      "name": "dada2",
      "full_name": "benjjneb/dada2",
      "description": "Accurate sample inference from amplicon data with single nucleotide resolution",
      "html_url": "https://github.com/benjjneb/dada2",
      "stars": 533,
      "forks": 162,
      "language": "R",
      "topics": [
        "amplicon",
        "bioconductor",
        "bioinformatics",
        "metabarcoding",
        "metagenomics",
        "microbiome",
        "taxonomy"
      ],
      "created_at": "2014-12-17T00:53:58Z",
      "updated_at": "2026-01-21T20:29:00Z",
      "pushed_at": "2025-12-15T19:22:15Z",
      "open_issues": 193,
      "owner": {
        "login": "benjjneb",
        "avatar_url": "https://avatars.githubusercontent.com/u/5797204?v=4"
      },
      "readme": "\n[![Build Status](https://app.travis-ci.com/benjjneb/dada2.svg?branch=master)](https://app.travis-ci.com/benjjneb/dada2)\n\n# dada2\n\nExact sample inference from high-throughput amplicon data. Resolves real variants differing by as little as one nucleotide. Visit [the DADA2 website](https://benjjneb.github.io/dada2/index.html) for the most detailed and up-to-date documentation.\n\n### Installation\n\nThe dada2 package binaries are available through Bioconductor:\n\n```S\n## try http:// if https:// URLs are not supported\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"dada2\")\n```\n\nIn order to install dada2 from source (and get the latest and greatest new features) see our [installation from source instructions](https://benjjneb.github.io/dada2/dada-installation.html).\n\n### Documentation\n\nThe [tutorial walkthrough of the DADA2 pipeline on paired end Illumina Miseq data](https://benjjneb.github.io/dada2/tutorial.html). \n\nThe [dada2 R package manual](https://www.bioconductor.org/packages/3.6/bioc/manuals/dada2/man/dada2.pdf).\n\nFurther documentation is available on [the DADA2 front page](http://benjjneb.github.io/dada2/). \n\n### DADA2 Articles\n\n[DADA2: High resolution sample inference from Illumina amplicon data. Nature Methods, 2016.](http://dx.doi.org/10.1038/nmeth.3869) [(Open Access link.)](http://rdcu.be/ipGh)\n\n[Bioconductor workflow for microbiome data analysis: from raw reads to community analyses. F1000 Research, 2016.](https://f1000research.com/articles/5-1492)\n\n[Exact sequence variants should replace operational taxonomic units in marker-gene data analysis. ISMEJ, 2017.](http://dx.doi.org/10.1038/ismej.2017.119)\n\n[High-throughput amplicon sequencing of the full-length 16S rRNA gene with single-nucleotide resolution. Nucleic Acids Research, 2019.](http://dx.doi.org/10.1093/nar/gkz569)\n\n### Other Resources\n\nPlanned feature improvements are publicly catalogued at the main DADA2 development site on github, specifically on the \"Issues\" page for DADA2:\n\nhttps://github.com/benjjneb/dada2/issues\n\nIf the feature you are hoping for is not listed, you are welcome to add it as a feature request \"issue\" on this page. This request will be publicly available and listed on the page.\n\nBugs and difficulties in using DADA2 are also welcome on [the issue tracker](https://github.com/benjjneb/dada2/issues).\n",
      "stars_today": 0
    },
    {
      "id": 138660553,
      "name": "DoubletFinder",
      "full_name": "chris-mcginnis-ucsf/DoubletFinder",
      "description": "R package for detecting doublets in single-cell RNA sequencing data",
      "html_url": "https://github.com/chris-mcginnis-ucsf/DoubletFinder",
      "stars": 517,
      "forks": 123,
      "language": "R",
      "topics": [],
      "created_at": "2018-06-25T23:32:45Z",
      "updated_at": "2026-01-10T20:29:11Z",
      "pushed_at": "2025-03-21T11:20:52Z",
      "open_issues": 22,
      "owner": {
        "login": "chris-mcginnis-ucsf",
        "avatar_url": "https://avatars.githubusercontent.com/u/40582930?v=4"
      },
      "readme": "~~ Announcement (11/24/21) ~~\nI'm now a postdoc at Stanford and my UCSF email will be decommissioned soon. I also only check my github repos about once per month, so please reach out directly at cmcginni@stanford[dot]edu if you run into any issues. \n\n# DoubletFinder\n\nDoubletFinder is an R package that predicts doublets in single-cell RNA sequencing data. \n\nDoubletFinder is implemented to interface with Seurat >= 2.0 (https://satijalab.org/seurat/) \n\nDoubletFinder was published by Cell Systems in April, 2019: https://www.cell.com/cell-systems/fulltext/S2405-4712(19)30073-0\n\n## Updates\n\n(02/02/2025) Haibo Liu (Senior Bioinformatician at UMass, @haibol2016) added as maintainer after his much-needed improvement updates to the package.\n\n(11/21/2023) Made compatible with Seurat v5 and removed '_v3' flag from relevant function names.\n\n(03/31/2020) Internalized functions normally in 'modes' package to enable compatibility with R v3.6 and highger.\n\n(06/21/2019) Added parallelization to paramSweep_v3 (thanks NathanSkeen!) -- Note: progress no longer updated, but the process is much faster! Fixed bug with smaller datasets. Updated readme.\n\n(04/12/2019) Added SCTransform compatibilities to 'paramSweep_v3' and 'doubletFinder_v3'\n\n(04/08/2019) Added 'PCs' argument to 'doubletFinder', 'doubletFinder_v3', 'paramSweep', and 'paramSweep_v3' to avoid conflicts with dimension reduction preferences. Updated readme.\n\n(01/12/2019) Seurat V3 compatibility: 'doubletFinder_v3' and 'paramSweep_v3' functions added, other functions for parameter estimation remain compatible.  \n\n## DoubletFinder V2.0 (11/28/2018) \n\nNew Features:\n1. Increased computational efficiency during pANN computation\n2. Implemented strategy for determining optimal pK values for any scRNA-seq data using pN-pK parameter sweeps and mean-variance-normalized bimodality coefficient (BCmvn)\n3. Included vignette describing 'best-practices' for applying DoubletFinder to scRNA-seq data generated without sample multiplexing\n\n## Installation (in R/RStudio)\n\n```{r}\nremotes::install_github('chris-mcginnis-ucsf/DoubletFinder', force = TRUE)\n```\n\n## Dependencies\n\nDoubletFinder requires the following R packages: \n* Seurat (>= 2.0) \n* Matrix (1.2.14) \n* fields (9.6) \n* KernSmooth (2.23-15)\n* ROCR (1.0-7)\n* parallel (3.5.1)\n* NOTE: These package versions were used in the bioRxiv paper, but other versions may work, as well.\n\n## Frequently Asked Questions\n\nQuestion: What is my anticipated doublet rate? \nAnswer: This is dependent on your platform (10x, parse, etc.) and will vary with the number of input cells. It will not always be 7.5% as is used in the tutorial. This information is available in the user guides for each technology. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/76 and https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/156\n\nQuestion: Can I run DoubletFinder on merged data from multiple 10x lanes?\nAnswer: Technically yes but I would only do this if you were splitting the same sample across multiple lanes. You want to avoid instances where DoubletFinder is attempting to find doublets that do not actually exist in the data. I would also not advise running DF on integrated Seurat objects. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/101 \n\nQuestion: I see multiple potential pK values when visualizing BCmvn -- what should I do?\nAnswer: I would spot check the results in GEX space to see what makes the most sense given your understanding of the data. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/62 and https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/40\n\n# DoubletFinder Overview\n\nDoubletFinder can be broken up into 4 steps:\n\n(1) Generate artificial doublets from existing scRNA-seq data \n\n(2) Pre-process merged real-artificial data\n\n(3) Perform PCA and use the PC distance matrix to find each cell's proportion of artificial k nearest neighbors (pANN)\n\n(4) Rank order and threshold pANN values according to the expected number of doublets\n\n![alternativetext](DF.screenshots/DoubletFinderOverview.png)\n\nDoubletFinder takes the following arguments:\n\nseu ~ This is a fully-processed Seurat object (i.e., after NormalizeData, FindVariableGenes, ScaleData, RunPCA, and RunTSNE have all been run).\n\nPCs ~ The number of statistically-significant principal components, specified as a range (e.g., PCs = 1:10)\n\npN ~ This defines the number of generated artificial doublets, expressed as a proportion of the merged real-artificial data. Default is set to 25%, based on observation that DoubletFinder performance is largely pN-invariant (see McGinnis, Murrow and Gartner 2019, Cell Systems).\n\npK ~ This defines the PC neighborhood size used to compute pANN, expressed as a proportion of the merged real-artificial data. No default is set, as pK should be adjusted for each scRNA-seq dataset. Optimal pK values should be estimated using the strategy described below.\n\nnExp ~ This defines the pANN threshold used to make final doublet/singlet predictions. This value can best be estimated from cell loading densities into the 10X/Drop-Seq device, and adjusted according to the estimated proportion of homotypic doublets.\n\n## Application to Cell Hashing and Demuxlet data\n\nDoubletFinder successfully recapitulates ground-truth doublet classifications determined using antibody-barcode sample multiplexing (Cell Hashing) and SNP deconvolution (Demuxlet). DoubletFinder identifies false-negative Demuxlet classifications caused by doublets formed from cells with identical SNP profiles. DoubletFinder is insensitive to homotypic doublets -- i.e., doublets dervied from transcriptionally-similar cell states. \n\n![alternativetext](DF.screenshots/Results_Demux.png)\n![alternativetext](DF.screenshots/Results_Hashing.png)\n\n# 'Best-Practices' for scRNA-seq data generated without sample multiplexing\n\n## Input scRNA-seq Data\n\n* Do not apply DoubletFinder to aggregated scRNA-seq data representing multiple *distinct* samples (e.g., multiple 10X lanes). For example, if you run DoubletFinder on aggregated data representing WT and mutant cell lines sequenced across different 10X lanes, artificial doublets will be generated from WT and mutant cells, which cannot exist in your data. These artificial doublets will skew results. Notably, it is okay to run DoubletFinder on data generated by splitting a single sample across multiple 10X lanes. \n\n* Ensure that input data is cleared of low-quality cell clusters. There are a variety of ways to do this, but I usually use the following workflow:\n1. Manually threshold raw gene expression matrices according to RNA nUMIs (especially important when dealing with super-loaded 10X data because of the way CellRanger threholds data -- See Lun et al., 2019, Genome Biology.\n2. Pre-process data using standard workflow.\n3. Identify clusters with (A) low RNA UMIs, (B) High % mitochondrial reads, and/or (C) Uninformative marker genes.\n4. Remove clusters, pre-process again, and run DoubletFinder.\n\n## pK Selection\n\nROC analysis across pN-pK parameter sweeps for Cell Hashing and Demuxlet datasets demonstrate that DoubletFinder performance is largely invariant of pN value selection:\n\n![alternativetext](DF.screenshots/ParamSweep_Schematic.png)\n![alternativetext](DF.screenshots/ParamSweep_HeatMap.png)\n\nROC analysis across pN-pK parameter sweeps for simulated scRNA-seq data with (I) Variable numbers of cell states and (II) Variable magnitudes of transcriptional heterogeneity demonstrates that (I) Optimal pK value selection depends on the total number of cell states and (II) DoubletFinder performance suffers when applied to transcriptionally-homogenous data. Simulated data was generated using a strategy similar to as described in Wolock, Lopex & Klein 2019, Cell Systems.\n\n![alternativetext](DF.screenshots/Simulation_Schematic.png)\n![alternativetext](DF.screenshots/Results_Simulation.png)\n\nSimulated and sample-multiplexed data are unique in that ground-truth doublet classifications can be leveraged to characterize how DoubletFinder parameters must be 'fit' to distinct scRNA-seq datasets. However, doublets remain unknown in real-world contexts -- which is likely why you are interested in DoubletFinder, at all!\n\nTo maximize the accuracy of DoubletFinder predictions, we sought a ground-truth-agnostic metric that coincides with pK values that maximize AUC in Cell Hashing and Demuxlet data. Mean-variance normalized bimodality coefficient (BCmvn) achieves this goal, featuring a single, easily-discernible maximum at pK values that optimize AUC. \n\n![alternativetext](DF.screenshots/BCmvn.png)\n\nBCmvn distributions also feature a single maximum for scRNA-seq datasets generated without sample-multiplexing (e.g., Mouse pancreas, Byrnes et al., 2018, Nature Communcations; Mouse kidney, Park et al., 2018, Science), enabling pK selection.\n\n## Doublet Number Estimation\n\nDoubletFinder is sensitive to heterotypic doublets -- i.e., doublets formed from transcriptionally-distinct cell states -- but is insensitive to homotypic doublets -- i.e., doublets formed from transcriptionally-similar cell states. In our original manuscript, we suggested using DoubletFinder to predict the number of doublets expected from Poisson statistical estimates realting to the droplet microfluidics cell loading density. However, Poisson estimates are agnostic of homotypic doublets, and will thus invariably overestimate the number of *detectable* doublets.\n\nTo address this issue, we suggest users utilize literature-supported cell type annotations to model the proportion of homotypic doublets present in their data. As an example, we present an analysis of mouse kidney scRNA-seq data (Park et al., 2018, Science):\n\n![alternativetext](DF.screenshots/HomotypicAdjustment.png)\n\nNotably, it is conceivable that literature-suppoted cell type annotations may not accurately recapitulate the magnitude of transcriptional divergence necessary for DoubletFinder sensitivity. For example, nominally-homogenous cells (e.g., CD4+ T-cells) may exist along a spectrum of gene expression states (e.g., distinct anatomical locations, disease states, naive/Tregs/Th17 cells, etc.), and doublets formed by cell sub-types may be detectable by DoubletFinder. Thus, we consider doublet number estimates based on Poisson statistics with and without homotypic doublet proportion adjustment to 'bookend' the real detectable doublet rate. \n\n## Example code for 'real-world' applications\n\n```R\n## Pre-process Seurat object (standard) --------------------------------------------------------------------------------------\nseu_kidney <- CreateSeuratObject(kidney.data)\nseu_kidney <- NormalizeData(seu_kidney)\nseu_kidney <- FindVariableFeatures(seu_kidney, selection.method = \"vst\", nfeatures = 2000)\nseu_kidney <- ScaleData(seu_kidney)\nseu_kidney <- RunPCA(seu_kidney)\nseu_kidney <- RunUMAP(seu_kidney, dims = 1:10)\n\n## Pre-process Seurat object (sctransform) -----------------------------------------------------------------------------------\nseu_kidney <- CreateSeuratObject(kidney.data)\nseu_kidney <- SCTransform(seu_kidney)\nseu_kidney <- RunPCA(seu_kidney)\nseu_kidney <- RunUMAP(seu_kidney, dims = 1:10)\n\n## pK Identification (no ground-truth) ---------------------------------------------------------------------------------------\nsweep.res.list_kidney <- paramSweep(seu_kidney, PCs = 1:10, sct = FALSE)\nsweep.stats_kidney <- summarizeSweep(sweep.res.list_kidney, GT = FALSE)\nbcmvn_kidney <- find.pK(sweep.stats_kidney)\n\n## pK Identification (ground-truth) ------------------------------------------------------------------------------------------\nsweep.res.list_kidney <- paramSweep(seu_kidney, PCs = 1:10, sct = FALSE)\ngt.calls <- seu_kidney@meta.data[rownames(sweep.res.list_kidney[[1]]), \"GT\"].   ## GT is a vector containing \"Singlet\" and \"Doublet\" calls recorded using sample multiplexing classification and/or in silico geneotyping results \nsweep.stats_kidney <- summarizeSweep(sweep.res.list_kidney, GT = TRUE, GT.calls = gt.calls)\nbcmvn_kidney <- find.pK(sweep.stats_kidney)\n\n## Homotypic Doublet Proportion Estimate -------------------------------------------------------------------------------------\nhomotypic.prop <- modelHomotypic(annotations)           ## ex: annotations <- seu_kidney@meta.data$ClusteringResults\nnExp_poi <- round(0.075*nrow(seu_kidney@meta.data))  ## Assuming 7.5% doublet formation rate - tailor for your dataset\nnExp_poi.adj <- round(nExp_poi*(1-homotypic.prop))\n\n## Run DoubletFinder with varying classification stringencies ----------------------------------------------------------------\nseu_kidney <- doubletFinder(seu_kidney, PCs = 1:10, pN = 0.25, pK = 0.09, nExp = nExp_poi, reuse.pANN = NULL, sct = FALSE)\nseu_kidney <- doubletFinder(seu_kidney, PCs = 1:10, pN = 0.25, pK = 0.09, nExp = nExp_poi.adj, reuse.pANN = \"pANN_0.25_0.09_913\", sct = FALSE)\n```\n\n![alternativetext](DF.screenshots/DFkidney_low.vs.high.png)\n\n## Other Doublet Detection Methods\n[Scrublet (Py)](https://github.com/AllonKleinLab/scrublet)\n[DoubletDecon (R)](https://github.com/EDePasquale/DoubletDecon)\n[DoubletDetection (Py)](https://github.com/JonathanShor/DoubletDetection)\n[Solo (Py)](https://github.com/calico/solo)\n[scds (R)](https://github.com/kostkalab/scds)\n[scDblFinder (R)](https://github.com/plger/scDblFinder)\n\n## References\n\n1.\tStoeckius M, Zheng S, Houck-Loomis B, Hao S, Yeung BZ, Smibert P, Satija R. Cell Hashing with barcoded antibodies enables multiplexing and doublet detection for single cell genomics. Genome Biology. 2018. 19:224.\n\n2.  Kang HM, Subramaniam M, Targ S, Nguyen M, Maliskova L, McCarthy E, Wan E, Wong S, Byrnes L, Lanata CM, Gate RE, Mostafavi S, Marson A, Zaitlen N, Criswell LA, Ye JC. Multiplexed droplet single-cell RNA-sequencing using natural genetic variation. Nature Biotechnology. 2018. 36(1):89-94. \n\n3.  Wolock SL, Lopez R, Klein AM. Scrublet: Computational Identification of Cell Doublets in Single-Cell Transcriptomic Data. Cell Systems. 2019. 8(4):281-291.e9.\n\n4.  Park J, Shrestha R, Qiu C, Kondo A, Huang S, Werth M, Li M, Barasch J, Suszt√°k K. Single-cell transcriptomics of the mouse kidney reveals potential cellular targets of kidney disease. Science. 2018. 360(6390):758-63.\n\n5.  Byrnes LE, Wong DM, Subramaniam M, Meyer NP, Gilchrist CL, Knox SM, Tward AD, Ye CJ, Sneddon JB. Lineage dynamics of murine pancreatic development at single-cell resolution. Nature Communications. 2018; 9:3922.\n\n6.  Bais AS, Kostka D. scds: computational annotation of doublets in single-cell RNA sequencing data. Bioinformatics. 2020. 36(4):1150-8.\n\n7.  Bernstein NJ, Fong NL, Lam I, Roy MA, Hendrickson DG, Kelley DR. Solo: Doublet Identification in Single-Cell RNA-Seq via Semi-Supervised Deep Learning. Cell Systems. 2020. S2405-4712(20)30195-2.\n\n8.  DePasquale EAK, Schnell DJ, Van Camp PJ, Valiente-Alandi I, Blaxall BC, Grimes HL, Singh H, Salomonis N. DoubletDecon: Deconvoluting Doublets from Single-Cell RNA-Sequencing Data. Cell Reports. 2019. 29(6):1718-27.e8.\n",
      "stars_today": 0
    },
    {
      "id": 216123064,
      "name": "ArchR",
      "full_name": "GreenleafLab/ArchR",
      "description": "ArchR : Analysis of Regulatory Chromatin in R (www.ArchRProject.com)",
      "html_url": "https://github.com/GreenleafLab/ArchR",
      "stars": 444,
      "forks": 153,
      "language": "R",
      "topics": [],
      "created_at": "2019-10-18T23:35:41Z",
      "updated_at": "2026-01-21T06:31:12Z",
      "pushed_at": "2025-02-18T21:19:00Z",
      "open_issues": 177,
      "owner": {
        "login": "GreenleafLab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8398169?v=4"
      },
      "readme": "<p align=\"center\"><a href =\"https://www.archrproject.com\"><img src=\"Figures/ArchR_Logo_Integrated.png\" alt=\"\" width=\"350\"></a></p>\n<hr>\n\n[![Lifecycle: maturing](https://img.shields.io/badge/lifecycle-maturing-blue.svg)](https://www.tidyverse.org/lifecycle/#maturing)\n\n### ArchR has new features available for scATAC-seq Analysis\n\n**Paired scATAC-seq and scRNA-seq Analysis**\n\nArchR now supports paired scATAC-seq and scRNA-seq Analysis! <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See updates with importFeatureMatrix, addGeneExpressionMatrix, addIterativeLSI, addCombinedDims <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For a brief tutorial of these features : https://greenleaflab.github.io/ArchR_2020/Ex-Analyze-Multiome.html\n\n**Trajectory Analysis**\n\nArchR now directly supports both monocle3 and Slingshot based trajectory analysis! <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See updates with getMonocleTrajectories, addMonocleTrajectory, addSlingShotTrajectories <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For a brief tutorial of these features : https://greenleaflab.github.io/ArchR_2020/Ex-Analyze-Trajectory.html\n\nAdditionally ArchR now enables export of a peak matrix that is compatible with STREAM!<br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See updates with exportPeakMatrixForSTREAM <br />\n\n### ArchR is currently in Beta and will be in active development through the peer review process.\n\nArchR is a full-featured R package for processing and analyzing single-cell ATAC-seq data. ArchR provides the most extensive suite of scATAC-seq analysis tools of any software available. Additionally, ArchR excels in both speed and resource usage, making it possible to analyze 1 million cells in 8 hours on a MacBook Pro laptop.\n\n### For installation instructions and full documentation, visit www.ArchRProject.com.\n\n<hr>\n\n![](Figures/ArchR_Workflow_Horizontal.png)\n\n# Quick Installation of ArchR\nFor a full walk through of installation and frequently related issues please visit www.ArchRProject.com.\n\n**First, install devtools (for installing GitHub packages) if it isn't already installed:**\n``` r\nif (!requireNamespace(\"devtools\", quietly = TRUE)) install.packages(\"devtools\")\n```\n\n**Then, install BiocManager (for installing bioconductor packages) if it isn't already installed:**\n``` r\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\")\n```\n\n**Then, install ArchR:**\n``` r\ndevtools::install_github(\"GreenleafLab/ArchR\", ref=\"master\", repos = BiocManager::repositories())\n```\n\n**Lastly, install all of the ArchR dependencies that aren't installed by default:**\n``` r\nlibrary(ArchR)\nArchR::installExtraPackages()\n```\nIf any of these steps fails, you should identify the offending package and troubleshoot that individual installation before proceeding. Additionally, please see the ArchR website (www.ArchRProject.com) where we have installation troubleshooting tips.\n\n# Pre-compiled ArchR environment\nWe provide two methods in which a user can manage R dependencies.  \n\n### Using renv to manage dependencies\nThe first is by using renv to manage a project's dependencies. To utilize this, make sure that the renv package is installed and loaded.  Before you are ready to use `renv`, you must ensure that you are working on the same R version that we used for the provided renv environment. \nThe R versions we currently support are:\n```\n- R 4.4\n- R 4.1\n```\nSecondly, make sure that the renv package is installed and loaded.\n```\ninstall.packages(\"renv\")\nlibrary(renv)\n```\nSet a working directory for your project\n```\ndir.create(path = \"./<project_name>\", showWarnings = FALSE)\nsetwd(\"./<project_name>\")\n```\nThen, lets download the lock file for the current master branch of ArchR.\nFor R 4.4:\n```\ndownload.file(url = \"https://pub-9ae435458ecc412abbbc9420a502ec38.r2.dev/renv.lock\", destfile = \"./renv.lock\")\n```\nFor R 4.1:\n```\ndownload.file(url = \"https://pub-9ae435458ecc412abbbc9420a502ec38.r2.dev/renv_4_1.lock\", destfile = \"./renv.lock\")\n```\n\nNow, we can initiate our renv project environment, utilizing the renv.lock to bootstrap a new renv environment.\n```\nrenv::init()\n```\n\n### Using Docker to manage dependencies\nWe also provide Docker images, built off of `rocker/rstudio`, that already have ArchR and all dependencies pre-loaded.\n\nThe latest version can be found at:\n```\ngreenleaflab/archr:latest\n```\nand other versions, including images built with differing R versions, can be found at:\n```\nhttps://hub.docker.com/r/greenleaflab/archr/tags\n```\n\nTo utilize these images, the user can first install Docker as mentioned in their [documentation](https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository)\n\nFollowing, create a container using the following command:\n```\ndocker image pull greenleaflab/archr:latest\ndocker run -it --rm -v <your_workspace>:/workspace -p <your_port_of_interest>:8787\n```\nThis will spin up a container that has Rstudio turned on by default. Rstudio can be accessed through:\n```\nlocalhost:<your_port_of_interest>\n```\nIf you would like an interactive bash console instead, the following command can instead be called:\n```\ndocker run -it --rm -v <your_workspace>:/workspace -p <your_port_of_interest>:8787 bash\n```\n\n# Issues using ArchR?\n\nArchR is currently in __beta__. We expect there to be bumps in the road. If you think you have found a bug, please first install the latest version of ArchR via\n``` r\ndevtools::install_github(\"GreenleafLab/ArchR\", ref=\"master\", repos = BiocManager::repositories())\n```\nIf this does not fix your problem, please [report an issue on Github](https://github.com/GreenleafLab/ArchR/issues) with the __Bug Report__ form.\n\nIf you have questions about ArchR usage, please refer to the [the searchable full user's manual](https://www.archrproject.com/bookdown/index.html), [the FAQ section](https://www.archrproject.com/articles/Articles/faq.html), and the [publication](https://greenleaf.stanford.edu/assets/pdf/). If you think the documentation on this website or in the function annotations is unclear, please [submit an issue on Github](https://github.com/GreenleafLab/ArchR/issues) with the __Documentation Request__ form. If there is a feature that you think is missing from ArchR _and you have already searched the user's manual_, [submit an issue on Github](https://github.com/GreenleafLab/ArchR/issues) with the __Feature Request__ form. If none of these options help, [send us an email](mailto:archr.devs@gmail.com). We will do our best to respond to questions that are not otherwise answered in the documentation.\n\n\n",
      "stars_today": 0
    },
    {
      "id": 53515475,
      "name": "sonic-swss",
      "full_name": "sonic-net/sonic-swss",
      "description": "SONiC Switch State Service (SwSS)",
      "html_url": "https://github.com/sonic-net/sonic-swss",
      "stars": 209,
      "forks": 666,
      "language": "C++",
      "topics": [
        "hacktoberfest",
        "sonic"
      ],
      "created_at": "2016-03-09T17:01:09Z",
      "updated_at": "2026-01-21T18:19:09Z",
      "pushed_at": "2026-01-22T23:37:45Z",
      "open_issues": 633,
      "owner": {
        "login": "sonic-net",
        "avatar_url": "https://avatars.githubusercontent.com/u/102750714?v=4"
      },
      "readme": "*static analysis:*\n\n[![Total alerts](https://img.shields.io/lgtm/alerts/g/sonic-net/sonic-swss.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/sonic-net/sonic-swss/alerts/)\n[![Language grade: Python](https://img.shields.io/lgtm/grade/python/g/sonic-net/sonic-swss.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/sonic-net/sonic-swss/context:python)\n[![Language grade: C/C++](https://img.shields.io/lgtm/grade/cpp/g/sonic-net/sonic-swss.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/sonic-net/sonic-swss/context:cpp)\n\n*sonic-swss builds:*\n\n[![master build](https://dev.azure.com/mssonic/build/_apis/build/status/Azure.sonic-swss?branchName=master&label=master)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=15&branchName=master)\n[![202205 build](https://dev.azure.com/mssonic/build/_apis/build/status/Azure.sonic-swss?branchName=202205&label=202205)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=15&branchName=202205)\n[![202111 build](https://dev.azure.com/mssonic/build/_apis/build/status/Azure.sonic-swss?branchName=202111&label=202111)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=15&branchName=202111)\n[![202106 build](https://dev.azure.com/mssonic/build/_apis/build/status/Azure.sonic-swss?branchName=202106&label=202106)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=15&branchName=202106)\n[![202012 build](https://dev.azure.com/mssonic/build/_apis/build/status/Azure.sonic-swss?branchName=202012&label=202012)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=15&branchName=202012)\n[![201911 build](https://dev.azure.com/mssonic/build/_apis/build/status/Azure.sonic-swss?branchName=201911&label=201911)](https://dev.azure.com/mssonic/build/_build/latest?definitionId=15&branchName=201911)\n\n\n# SONiC - SWitch State Service - SWSS\n\n## Description\nThe SWitch State Service (SWSS) is a collection of software that provides a database interface for communication with and state representation of network applications and network switch hardware.\n\n## Getting Started\n\n### Prerequisites\n\nInstall the following dependencies:\n```\nsudo apt install redis-server\nsudo apt install libhiredis0.14\nsudo apt install libzmq5 libzmq3-dev\nsudo apt install libboost-serialization1.74.0\nsudo apt install libboost1.71-dev\nsudo apt install libasan6\n```\n**Note:** If your are using Ubuntu 18.04, install `libhiredis0.13` instead.\n\nVisit the [official sonic-buildimage Azure pipeline for the VS platform](https://dev.azure.com/mssonic/build/_build?definitionId=142&view=branches) and choose the branch that matches the sonic-swss branch you are trying to build or install. Then select the latest successful build.\nFrom the Summary tab, access build artifacts.\n<img width=\"1048\" alt=\"image\" src=\"https://github.com/user-attachments/assets/faa6f08d-788b-4801-8439-3f31a52efaa1\">\nDownload the folder `sonic-buildimage.vs/target/debs/{your host machine's Debian code name}`. You can check the Debian code name of your machine by running `cat /etc/debian_version`.\n<img width=\"1022\" alt=\"image\" src=\"https://github.com/user-attachments/assets/1ad750eb-252c-4913-b14f-91b5533a1295\">\nExtract the downloaded zip file using `unzip sonic-buildimage.vs.zip`. Then navigate to `sonic-buildimage.vs/target/debs/{Debian code name}/` and install the following Debian packages:\n```\nsudo dpkg -i libdashapi_1.0.0_amd64.deb libnl-3-200_3.5.0-1_amd64.deb libnl-3-dev_3.5.0-1_amd64.deb libnl-cli-3-200_3.5.0-1_amd64.deb libnl-cli-3-dev_3.5.0-1_amd64.deb libnl-genl-3-200_3.5.0-1_amd64.deb libnl-genl-3-dev_3.5.0-1_amd64.deb libnl-nf-3-200_3.5.0-1_amd64.deb libnl-nf-3-dev_3.5.0-1_amd64.deb libnl-route-3-200_3.5.0-1_amd64.deb libnl-route-3-dev_3.5.0-1_amd64.deb libprotobuf32_3.21.12-3_amd64.deb libsaimetadata_1.0.0_amd64.deb  libsaimetadata-dev_1.0.0_amd64.deb libsairedis_1.0.0_amd64.deb libsairedis-dev_1.0.0_amd64.deb libsaivs_1.0.0_amd64.deb libsaivs-dev_1.0.0_amd64.deb  libswsscommon_1.0.0_amd64.deb libswsscommon-dev_1.0.0_amd64.deb libteam5_1.31-1_amd64.deb libteamdctl0_1.31-1_amd64.deb libyang_1.0.73_amd64.deb libyang-dev_1.0.73_amd64.deb python3-swsscommon_1.0.0_amd64.deb\n```\n**Note:** You can also [build these packages yourself (for the VS platform)](https://github.com/sonic-net/sonic-buildimage/blob/master/README.md).\n\nNow, you can either directly install the SONiC SWSS package or you can build it from source and then install it. To install the SONiC SWSS package that is already in `sonic-buildimage.vs/target/debs/{Debian code name}/`, simply run the following command:\n```\nsudo dpkg -i swss_1.0.0_amd64.deb\n```\n\n#### Install from Source\n\nInstall build dependencies:\n```\nsudo apt install libtool\nsudo apt install autoconf automake\nsudo apt install dh-exec\nsudo apt install nlohmann-json3-dev\nsudo apt install libgmock-dev\n```\n\nClone the `sonic-swss` repository on your host machine: `git clone https://github.com/sonic-net/sonic-swss.git`.\n\nMake sure that SAI header files exist in `/usr/include/sai`. Since you have already installed `libsairedis-dev`, `libsaimetadata-dev`, and `libsaivs-dev`, this should already be the case. If you have compiled `libsairedis` yourself, make sure that the SAI header files are copied to `/usr/include/sai`.\n\nYou can compile and install from source using:\n```\n./autogen.sh\n./configure\nmake && sudo make install\n```\n**Note:** This will NOT run the mock tests located under `tests/mock_tests`.\n\nYou can also build a debian package using:\n```\n./autogen.sh\nfakeroot debian/rules binary\n```\n## Common issues\n\n#### Cannot find `libboost-serialization1.74.0`\n\nUnfortunately, `libboost-serialization1.74.0` is not officially supported on Ubuntu 20.04 (focal) even though it is supported on Debian 11 (bullseye). Therefore, you must build this package from source. You can use a script similar to [this one](https://github.com/ulikoehler/deb-buildscripts/blob/master/deb-boost.sh), but you only need to create a package for the Boost serialization library. You should also make sure that the generated package is named `libboost-serialization1.74.0`. After the package is created, you can install it by running `sudo dpkg -i libboost-serialization1.74.0_1.74.0_amd64.deb`.\n\n#### Dependency issue when installing `libzmq3-dev`\n\nIf you cannot install `libzmq3-dev` because of dependency issues, please check the version of `libkrb5` packages installed on your host machine:\n```\n    sudo dpkg -l | grep \"libkrb5\"\n```\nIf the version is not `1.17-6ubuntu4.7`, then you need to install the correct version:\n\n    sudo apt install libkrb5support0=1.17-6ubuntu4.7\n    sudo apt install libzmq3-dev\n\n**Warning:** This may remove many packages that are already installed on your system. Please take note of what is being removed.\n\n**Note:** Do NOT install `*krb5*` packages that are located in the `sonic-buildimage.vs` folder that you downloaded. These packages have a higher version and will cause dependency issues.\n\n#### Dependency issues when installing some package\n\nIf you run into dependency issues during the installation of a package, you can run `sudo apt -f install` to fix the issue. But note that if `apt` is unable to fix the dependency problem, it will attempt to remove the broken package(s).\n\n#### Too many open files\n\nIf you get a C++ exception with the description \"Too many open files\" during the mock tests, you should check the maximum number of open files that are permitted on your system:\n```\nulimit -a | grep \"open files\"\n```\nYou can increase it by executing this command: `ulimit -n 8192`. Feel free to change `8192`. This value worked fine for me.\n\n**Note:** This change is only valid for the current terminal session. If you want a persistent change, append `ulimit -n 8192` to `~/.bashrc`.\n\n## Need Help?\n\nFor general questions, setup help, or troubleshooting:\n- [sonicproject on Google Groups](https://groups.google.com/g/sonicproject)\n\nFor bug reports or feature requests, please open an Issue.\n\n## Contribution guide\n\nSee the [contributors guide](https://github.com/sonic-net/SONiC/wiki/Becoming-a-contributor) for information about how to contribute.\n\n### GitHub Workflow\n\nWe're following basic GitHub Flow. If you have no idea what we're talking about, check out [GitHub's official guide](https://guides.github.com/introduction/flow/). Note that merge is only performed by the repository maintainer.\n\nGuide for performing commits:\n\n* Isolate each commit to one component/bugfix/issue/feature\n* Use a standard commit message format:\n\n>     [component/folder touched]: Description intent of your changes\n>\n>     [List of changes]\n>\n> \t  Signed-off-by: Your Name your@email.com\n\nFor example:\n\n>     swss-common: Stabilize the ConsumerTable\n>\n>     * Fixing autoreconf\n>     * Fixing unit-tests by adding checkers and initialize the DB before start\n>     * Adding the ability to select from multiple channels\n>     * Health-Monitor - The idea of the patch is that if something went wrong with the notification channel,\n>       we will have the option to know about it (Query the LLEN table length).\n>\n>       Signed-off-by: user@dev.null\n\n\n* Each developer should fork this repository and [add the team as a Contributor](https://help.github.com/articles/adding-collaborators-to-a-personal-repository)\n* Push your changes to your private fork and do \"pull-request\" to this repository\n* Use a pull request to do code review\n* Use issues to keep track of what is going on\n\n",
      "stars_today": 0
    },
    {
      "id": 167440342,
      "name": "monocle3",
      "full_name": "cole-trapnell-lab/monocle3",
      "description": null,
      "html_url": "https://github.com/cole-trapnell-lab/monocle3",
      "stars": 433,
      "forks": 115,
      "language": "R",
      "topics": [
        "single-cell-rna-seq"
      ],
      "created_at": "2019-01-24T21:26:18Z",
      "updated_at": "2026-01-20T19:15:46Z",
      "pushed_at": "2026-01-08T18:32:17Z",
      "open_issues": 260,
      "owner": {
        "login": "cole-trapnell-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8060918?v=4"
      },
      "readme": "MONOCLE 3\n=======================\n\nMonocle 3 is an analysis toolkit for single-cell RNA-Seq experiments.  To use this package, you will need the R statistical computing environment (version 3.0 or later) and several packages available through Bioconductor and CRAN.\n\nDetails on how to install and use Monocle 3 are available on our website:\n\nhttp://cole-trapnell-lab.github.io/monocle3/\n\n## Monocle3 with BPCells counts matrix support\n\nThis development branch version of Monocle3 adds the ability to store the counts matrix on-disk using the BPCells package. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as in previous versions. In order to store the matrix on-disk, you must set the matrix_control list value `matrix_class=\"BPCells\"` in the affected commands. For example, to load a MatrixMarket file as an on-disk matrix, use the command\n\n```\ncds <- load_mm_data(mat_path=<path_to_mtx_file>,\n                    feature_anno_path=<path_to_feature_anno_file>,\n                    cell_anno_path=<path_to_cell_anno_file>,\n                    matrix_control=list(matrix_class='BPCells'))\n```\n\n### Install Monocle3 with BPCells\n\nYou must install BPCells from Github before you can install this Monocle3 version, and BPCells requires an HDF5 object library for installation. After installing the HDF5 library, you install BPCells using the command\n\n```\nremotes::install_github(\"bnprks/BPCells/r\")\n```\n\nThe [BPCells Github site](https://github.com/bnprks/BPCells)  has additional information.\n\nSome Linux distributions provide the HDF5 library as an option. The\nBPCells site has information about installing the HDF5 library on various operating systems.\n\nI used Homebrew to install an HDF5 library on MacOS. I seemed to need to install the pkg-config package as well, and add a pkg-config configuration file for HDF5. Homebrew installed pkg-config in '/opt/homebrew' so I added the hdf5.pc file in\n\n> /opt/homebrew/lib/pkgconfig/hdf5.pc\n\nwith the contents\n\n```\nprefix=/opt/homebrew/Cellar/hdf5/1.12.2_2\nexec_prefix=${prefix}\nincludedir=${prefix}/include\nlibdir=/opt/homebrew/Cellar/hdf5/1.12.2_2/lib\n  \nName: hdf5\nDescription: HDF5\nURL: xx\nVersion: 1.12.2_2\nCflags: -I${includedir}\nLibs: -L${libdir} -lhdf5\n```\n\nYou may need to update the version strings in your hdf5.pc file.\n\nMonocle3 no longer uses the terra package, so it does not need to be installed.\n\n### Notes\n\n- Monocle3 can use the BPCells package to store the feature-cell counts matrix on-disk rather than in-memory, which enables analysis of considerably larger data sets than before. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as it has in the past. To store the counts matrix on-disk, use the parameter `matrix_control=list(matrix_class=\"BPCells\")` when you make the CDS or convert the counts matrix using one of the functions\n  - `load_mm_data()`\n  - `load_mtx_data()`\n  - `load_cellranger_data()`\n  - `load_a549()`\n  - `load_worm_embryo()`\n  - `load_worm_l2()`\n  - `convert_counts_matrix()`\n\n  For example, to convert a dgCMatrix counts matrix to a BPCells on-disk matrix in an existing CDS, use the command `cds <- convert_counts_matrix(cds, matrix_control=list(matrix_class=\"BPCells\"))`.\n- BPCells stores the count matrix information in directories with names similar to `monocle.bpcells.20230830.4c4b1bebe4b4.tmp`. Monocle3 tries to remove those directories when you quit R. Please do not remove them while Monocle3 is running because doing so eliminates the count matrix data. You *can* remove them after quitting R if Monocle3 fails to remove them.\n- The method `new_cell_data_set()` accepts a BPCells on-disk counts matrix.\n- The functions `save_monocle_objects()` and `load_monocle_objects()` store and load BPCells on-disk matrices when the CDS counts matrix is an on-disk BPCells matrix.\n- The Monocle3 `saveRDS()` function warns the user to use `save_monocle_objects()` when saving a CDS with a BPCells on-disk counts matrix. If you insist on using the `saveRDS()` function, the BPCells on-disk matrix directory will not be stored and you will be unable to load it with the `readRDS()` function.\n- The function `combine_cds()` combines CDSes with mixes of dgCMatrix and BPCells on-disk counts matrices into a BPCells on-disk counts matrix. When called with the `matrix_control=list(matrix_class=\"BPCells\")` parameter, `combine_cds()` combines CDSes with all dgCMatrix counts matrices into a BPCells on-disk counts matrix.\n- Note that when the counts matrix is stored as a BPCells on-disk matrix, the `new_cell_data_set()` method stores a second BPCells on-disk copy of the matrix in the CDS assays slot with the name `counts_row_order`. The `counts_row_order` matrix is used by Monocle3 when the counts matrix is accessed intensively by row. The reason is that, by default, BPCells stores the matrix as a one-dimensional vector in column-major order, as does R. As a result, column access is fast and row access is slow. We use BPCell's ability to also store and access matrices in row-major order, which gives fast row access. However, this means that the two copies of the counts matrix must have the same count values. If you replace or change the CDS's counts matrix, you must also update the `counts_row_order` matrix, which you can do using the function `set_cds_row_order_matrix()`.\n  - The CDS assays slot is a named list where the standard, column-major order, matrix is called `counts` and the BPCells row-major order matrix is called `counts_row_order`.\n  - The `counts` matrix getter and setter methods are `counts(cds)` and `counts(cds)<-`.\n  - The Monocle3 setter warns about re-setting the BPCells `counts_row_order` matrix, unless called with the parameter `bpcells_warn=FALSE`.\n  - The `counts_row_order` getter method is called `counts_row_order`.\n  - There is no corresponding `counts_row_order` setter method\n- By default, the BPCells on-disk matrix is stored in a directory that is created where R is started. You can change the directory location using the `matrix_path` value in the `matrix_control` parameter.\n- For more information about the `matrix_control` values, see the help document for the function `set_matrix_control()`.\n- I tested this version using BPCells counts matrices on the examples in the Monocle3 documentation although I did not try all of the plotting functions.\n\n",
      "stars_today": 0
    },
    {
      "id": 185880527,
      "name": "signac",
      "full_name": "stuart-lab/signac",
      "description": "R toolkit for the analysis of single-cell chromatin data",
      "html_url": "https://github.com/stuart-lab/signac",
      "stars": 402,
      "forks": 100,
      "language": "R",
      "topics": [
        "atac",
        "bioinformatics",
        "single-cell"
      ],
      "created_at": "2019-05-09T22:32:26Z",
      "updated_at": "2026-01-21T11:18:24Z",
      "pushed_at": "2026-01-20T08:57:03Z",
      "open_issues": 19,
      "owner": {
        "login": "stuart-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/102445397?v=4"
      },
      "readme": "# Signac <img align=\"right\" src=\"man/figures/logo.svg\" style=\"height:100px;\" />\n\n[![R-CMD-check](https://github.com/stuart-lab/signac/workflows/R-CMD-check/badge.svg)](https://github.com/stuart-lab/signac/actions)\n[![CRAN\nVersion](https://www.r-pkg.org/badges/version/Signac)](https://cran.r-project.org/package=Signac)\n[![CRAN\nDownloads](https://cranlogs.r-pkg.org/badges/Signac)](https://cran.r-project.org/package=Signac)\n\n## Overview\n\nSignac is a comprehensive R package for the analysis of single-cell\nchromatin data. Signac includes functions for quality control,\nnormalization, dimension reduction, clustering, differential activity,\nand more.\n\nDocumentation and tutorials can be found at\n<https://stuartlab.org/signac/>\n\n## Installation\n\nTo install the latest release of Signac from CRAN:\n\n``` r\nsetRepositories(ind=1:3) # needed to automatically install Bioconductor dependencies\ninstall.packages(\"Signac\")\n```\n\nTo release the latest develop version from GitHub:\n\n``` r\nif (!requireNamespace(\"remotes\", quietly = TRUE))\n    install.packages(\"remotes\")\nremotes::install_github(\"stuart-lab/signac\", ref = \"develop\")\n```\n\n## Release notes\n\nFor a changelog please see the [NEWS\nfile](https://github.com/stuart-lab/signac/blob/develop/NEWS.md), also\navailable on the [Signac\nwebsite](https://stuartlab.org/signac/news/index.html).\n\n## Contributing\n\nWe welcome contributions to the Signac package. Please see the\n[contribution guide](https://github.com/stuart-lab/signac/blob/develop/CONTRIBUTING.md)\nfor more information.\n\n## Getting help\n\nIf you encounter a bug or have a feature request, please open an\n[issue](https://github.com/stuart-lab/signac/issues).\n\nIf you would like to discuss questions related to single-cell analysis,\nyou can open a\n[discussion](https://github.com/stuart-lab/signac/discussions).\n\n## Citing Signac\n\nIf you use the Signac package in your work please cite [Stuart et\nal. 2021](https://doi.org/10.1038/s41592-021-01282-5)\n\n```\n@ARTICLE{signac,\n  title     = \"Single-cell chromatin state analysis with Signac\",\n  author    = \"Stuart, Tim and Srivastava, Avi and Madad, Shaista and Lareau,\n               Caleb A and Satija, Rahul\",\n  journal   = \"Nat. Methods\",\n  publisher = \"Nature Publishing Group\",\n  pages     = \"1--9\",\n  month     =  nov,\n  year      =  2021,\n  url       = \"https://www.nature.com/articles/s41592-021-01282-5\",\n  language  = \"en\"\n}\n```\n\n## Related packages\n\n-   [Seurat](https://github.com/satijalab/seurat)\n-   [SeuratObject](https://github.com/satijalab/seurat-object)\n-   [SeuratDisk](https://github.com/mojaveazure/seurat-disk)\n-   [SeuratData](https://github.com/satijalab/seurat-data)\n-   [SeuratWrappers](https://github.com/satijalab/seurat-wrappers)\n-   [Azimuth](https://github.com/satijalab/azimuth)\n",
      "stars_today": 0
    },
    {
      "id": 6857384,
      "name": "pecan",
      "full_name": "PecanProject/pecan",
      "description": "The Predictive Ecosystem Analyzer (PEcAn) is an integrated ecological bioinformatics toolbox.",
      "html_url": "https://github.com/PecanProject/pecan",
      "stars": 225,
      "forks": 286,
      "language": "R",
      "topics": [
        "bayesian",
        "cyberinfrastructure",
        "data-assimilation",
        "data-science",
        "ecosystem-model",
        "ecosystem-science",
        "forecasting",
        "meta-analysis",
        "national-science-foundation",
        "pecan",
        "plants",
        "r"
      ],
      "created_at": "2012-11-25T23:48:26Z",
      "updated_at": "2026-01-20T20:09:25Z",
      "pushed_at": "2026-01-20T20:09:12Z",
      "open_issues": 463,
      "owner": {
        "login": "PecanProject",
        "avatar_url": "https://avatars.githubusercontent.com/u/2879854?v=4"
      },
      "readme": "[![GitHub Actions CI](https://github.com/PecanProject/pecan/workflows/CI/badge.svg)](https://github.com/PecanProject/pecan/actions)\n[![Slack](https://img.shields.io/badge/slack-login-green.svg)](https://pecanproject.slack.com/)\n[![Slack](https://img.shields.io/badge/slack-join_chat-green.svg)](https://join.slack.com/t/pecanproject/shared_invite/enQtMzkyODUyMjQyNTgzLWEzOTM1ZjhmYWUxNzYwYzkxMWVlODAyZWQwYjliYzA0MDA0MjE4YmMyOTFhMjYyMjYzN2FjODE4N2Y4YWFhZmQ)\n[![DOI](https://zenodo.org/badge/4469/PecanProject/pecan.svg)](https://zenodo.org/badge/latestdoi/4469/PecanProject/pecan)\n\n## Our Vision\n\n#### Ecosystem science, policy, and management informed by the best available data and models\n\n## Our Mission\n\n#### Develop and promote accessible tools for reproducible ecosystem modeling and forecasting\n\n## What is PEcAn?\n\nThe Predictive Ecosystem Analyzer (PEcAn) (see [pecanproject.org](http://pecanproject.org)) is an integrated ecological bioinformatics toolbox (Dietze et al 2013, LeBauer et al, 2013) that consists of: 1) a scientific workflow system to manage the immense amounts of publicly-available environmental data and 2) a Bayesian data assimilation system to synthesize this information within state-of-the-art ecosystems models. This project is motivated by the fact that many of the most pressing questions about global change are not necessarily limited by the need to collect new data as much as by our ability to synthesize existing data. This project seeks to improve this ability by developing a accessibe framework for integrating multiple data sources in a sensible manner.\n\nThe PEcAn workflow system allows ecosystem modeling to be more reproducible, automated, and transparent in terms of operations applied to data, and thus ultimately more comprehensible to both peers and the public. It reduces the redundancy of effort among modeling groups, facilitate collaboration, and makes models more accessible the rest of the research community.\n\nPEcAn is not itself an ecosystem model, and it can be used to with a variety of different ecosystem models; integrating a model involves writing a wrapper to convert inputs and outputs to and from the standards used by PEcAn. Currently, PEcAn supports over a dozen ecosystem models, with more being added all the time (see the _models_ folder for the most up-to-date list)\n\n## Documentation\n\nPEcAn documentation is available for both the [latest stable development](https://pecanproject.github.io/pecan-documentation/develop/) branch and the [latest release](https://pecanproject.github.io/pecan-documentation/latest/). Documentation for [earlier releases](https://pecanproject.github.io/documentation/) is also available.\n\nPackage-level reference documentation for PEcAn modules is generated using [pkgdown](https://pkgdown.r-lib.org/) and can be found [here](https://pecanproject.github.io/package-documentation/develop/)\n\n## Getting Started\n\nSee our [\"Tutorials Page\"](https://pecanproject.github.io/tutorials/) that provides self-guided tutorials, links to vignettes, and an overview presentation.\n\n### Notebook-based tutorials\n\nThe **recommended** way to get started with PEcAn is through the notebook-based tutorials. These provide reproducible, end-to-end examples of PEcAn workflows using rendered **Quarto** notebooks.\n\nCurrent tutorials include:\n- [Running a PEcAn workflow](https://pecanproject.github.io/pecan-documentation/develop/rendered-demo-notebooks/run_pecan.html)\n- [Uncertainty analysis tutorial](https://pecanproject.github.io/pecan-documentation/develop/rendered-demo-notebooks/uncertainty.html)\n\n### Installation\n\nComplete instructions on how to install PEcAn can be found in the [documentation here](https://pecanproject.github.io/pecan-documentation/develop/pecan-manual-setup.html). To get PEcAn up and running you can use one of the following methods:\n\n1. Use [Docker](https://pecanproject.github.io/pecan-documentation/develop/install-docker.html#install-docker). This is recommended, especially for development and production deployment.\n2. Install all of the PEcAn R packages on your own Linux or MacOS computer or server. This can be done by [installing from r-universe](https://pecanproject.github.io/pecan-documentation/develop/r-universe.html):\n\n```R\n# Enable repository from pecanproject\noptions(repos = c(\n  pecanproject = 'https://pecanproject.r-universe.dev',\n  CRAN = 'https://cloud.r-project.org'))\n# Download and install PEcAn.all in R\ninstall.packages('PEcAn.all')\n```\n\nSome functionalities will be limited without also installing the Postgres database ([BETYdb](https://pecanproject.github.io/pecan-documentation/develop/osinstall.html#install-bety)), though we are making steady progress toward removing this dependency.\n\n### Website\n\nVisit our [webpage](https://pecanproject.github.io) to keep up with latest news, version, and information about the PEcAn Project\n\n#### Web Interface demo (legacy)\n\nThe PEcAn web interface is considered a legacy interface and is **no longer** the recommended entry point for new users.\n\nNotebook-based tutorials provide reproducible, up-to-date examples of PEcAn workflows and are the recommended starting point for learning and exploration.\n\n## Publications\n\n* LeBauer, D.S., D. Wang, K. Richter, C. Davidson, and M.C. Dietze (2013). Facilitating feedbacks between field measurements and ecosystem models. Ecological Monographs. [doi:10.1890/12-0137.1](https://doi.org/10.1890/12-0137.1)\n* Wang, D, D.S. LeBauer, and M.C. Dietze (2013). Predicting yields of short-rotation hybrid poplar (Populus spp.) for the contiguous US through model-data synthesis. Ecological Applications [doi:10.1890/12-0854.1](https://doi.org/10.1890/12-0854.1)\n* Dietze, M.C., D.S LeBauer, and R. Kooper (2013). On improving the communication between models and data. Plant, Cell, & Environment [doi:10.1111/pce.12043](https://doi.org/10.1111/pce.12043)\n* Dietze, Michael C., Shawn P. Serbin, Carl Davidson, Ankur R. Desai, Xiaohui Feng, Ryan Kelly, Rob Kooper et al. \"A quantitative assessment of a terrestrial biosphere model's data needs across North American biomes.\" Journal of Geophysical Research: Biogeosciences 119, no. 3 (2014): 286-300.\n* Viskari, Toni, Brady Hardiman, Ankur R. Desai, and Michael C. Dietze. \"Model-data assimilation of multiple phenological observations to constrain and predict leaf area index.\" (2015) [doi:10.1890/14-0497.1](https://doi.org/10.1890/14-0497.1)\n* Shiklomanov. A, MC Dietze, T Viskari, PA Townsend, SP Serbin. 2016 \"Quantifying the influences of spectral resolution on uncertainty in leaf trait estimates through a Bayesian approach to RTM inversion\" Remote Sensing of the Environment 183: 226-238\n* LeBauer, David, Rob Kooper, Patrick Mulrooney, Scott Rohde, Dan Wang, Stephen P. Long, and Michael C. Dietze. \"BETYdb: a yield, trait, and ecosystem service database applied to second‚Äêgeneration bioenergy feedstock production.\" GCB Bioenergy (2017).\n\nA extensive list of publications that apply PEcAn or are informed by our work on [Google Scholar](https://scholar.google.com/citations?hl=en&user=HWhxBY4AAAAJ).\n\n## Acknowledgements\n\nThe PEcAn project is supported by the National Science Foundation (ABI #1062547, ABI #1458021, DIBBS #1261582, ARC #1023477, EF #1318164, EF #1241894, EF #1241891), NASA Terrestrial Ecosystems, the Energy Biosciences Institute, Department of Energy (ARPA-E awards #DE-AR0000594 and DE-AR0000598), and an Amazon AWS in Education Grant.\n\nAny opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation, NASA, or other federal agencies. PEcAn is a collaboration among research groups at the Department of Earth And Environment at Boston University, the Carl Woese Institute for Genomic Biology at the University of Illinois, the Image Spatial Data Analysis group at the National Center for Supercomputing Applications, the Department of Atmospheric & Oceanic Sciences at the University Wisconsin-Madison, and the Terrestrial Ecosystem Science & Technology group at Brookhaven National Lab.\n\nBETYdb is a product of the Energy Biosciences Institute at the University of Illinois at Urbana-Champaign. We gratefully acknowledge the great effort of other researchers who generously made their own data available for further study.\n\n## License\n\nUniversity of Illinois/NCSA Open Source License\n\nCopyright (c) 2012, University of Illinois, NCSA.  All rights reserved.\n\nPEcAn project\n<www.pecanproject.org>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the  \"Software\"), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\n* Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\n* Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\n* Neither the names of University of Illinois, NCSA, nor the names of its contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON INFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n## Activities\n\n![Alt](https://repobeats.axiom.co/api/embed/9d39b0af80fbfa979e349a529c05f21bbac9f858.svg \"Repobeats analytics image\")\n",
      "stars_today": 0
    }
  ],
  "created_at": "2026-01-23T02:12:21.826083312Z"
}