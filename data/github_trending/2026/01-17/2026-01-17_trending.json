{
  "date": "2026-01-17",
  "name": "trending",
  "repositories": [
    {
      "id": 1028492186,
      "name": "eigent",
      "full_name": "eigent-ai/eigent",
      "description": "Eigent: The Open Source Cowork Desktop to Unlock Your Exceptional Productivity.",
      "html_url": "https://github.com/eigent-ai/eigent",
      "stars": 7518,
      "forks": 809,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-07-29T15:56:02Z",
      "updated_at": "2026-01-17T01:03:32Z",
      "pushed_at": "2026-01-17T00:41:34Z",
      "open_issues": 140,
      "owner": {
        "login": "eigent-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/163795819?v=4"
      },
      "readme": "<div align=\"center\"><a name=\"readme-top\"></a>\n\n[![][image-head]][eigent-site]\n\n[![][image-seperator]][eigent-site]\n\n### Eigent: The Open Source Cowork Desktop to Unlock Your Exceptional Productivity\n\n<!-- SHIELD GROUP -->\n\n[![][download-shield]][eigent-download]\n[![][github-star]][eigent-github]\n[![][social-x-shield]][social-x-link]\n[![][discord-image]][discord-url]<br>\n[![Reddit][reddit-image]][reddit-url]\n[![Wechat][wechat-image]][wechat-url]\n[![][sponsor-shield]][sponsor-link]\n[![][built-with-camel]][camel-github]\n[![][join-us-image]][join-us]\n\n</div>\n\n<hr/>\n<div align=\"center\">\n\n**English** ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](./README_CN.md) ¬∑ [Êó•Êú¨Ë™û](./README_JA.md) ¬∑ [Official Site][eigent-site] ¬∑ [Documents][docs-site] ¬∑ [Feedback][github-issue-link]\n\n</div>\n<br/>\n\n**Eigent**¬†is the open source cowork desktop application, empowering you to build, manage, and deploy a custom AI workforce that can turn your most complex workflows into automated tasks. \n\nBuilt on [CAMEL-AI][camel-site]'s acclaimed open-source project, our system introduces a **Multi-Agent Workforce** that **boosts productivity** through parallel execution, customization, and privacy protection.\n\n### ‚≠ê 100% Open Source - ü•á Local Deployment - üèÜ MCP Integration\n\n- ‚úÖ **Zero Setup** - No technical configuration required\n- ‚úÖ **Multi-Agent Coordination** - Handle complex multi-agent workflows\n- ‚úÖ **Enterprise Feature** - SSO/Access control\n- ‚úÖ **Local Deploymen**t\n- ‚úÖ **Open Source**\n- ‚úÖ **Custom Model Support**\n- ‚úÖ **MCP Integration**\n\n<br/>\n\n[![][image-join-us]][join-us]\n\n<details>\n<summary><kbd>Table of contents</kbd></summary>\n\n#### TOC\n\n- [üöÄ Getting Started](#-getting-started)\n  - [üè† Local Deployment (Recommended)](#-local-deployment-recommended)\n  - [‚ö° Quick Start (Cloud-Connected)](#-quick-start-cloud-connected)\n  - [üè¢ Enterprise](#-enterprise)\n  - [‚òÅÔ∏è Cloud Version](#Ô∏è-cloud-version)\n- [‚ú® Key features](#-key-features)\n  - [üè≠ Workforce](#-workforce)\n  - [üß† Comprehensive Model Support](#-comprehensive-model-support)\n  - [üîå MCP Tools Integration (MCP)](#-mcp-tools-integration-mcp)\n  - [‚úã Human-in-the-Loop](#-human-in-the-loop)\n  - [üëê 100% Open Source](#-100-open-source)\n- [üß© Use Cases](#-use-cases)\n- [üõ†Ô∏è Tech Stack](#-tech-stack)\n  - [Backend](#backend)\n  - [Frontend](#frontend)\n- [üåü¬†Staying ahead](#staying-ahead)\n- [üó∫Ô∏è Roadmap](#-roadmap)\n- [üìñ¬†Contributing](#-contributing)\n  - [Main Contributors](#main-contributors)\n  - [Distinguished amabssador](#distinguished-amabssador)\n- [Ecosystem](#ecosystem)\n- [üìÑ¬†Open Source License](#-open-source-license)\n- [üåê¬†Community & contact](#-community--contact)\n\n####\n\n<br/>\n\n</details>\n\n## **üöÄ Getting Started**\n\n> **üîì Build in Public** ‚Äî Eigent is **100% open source** from day one. Every feature, every commit, every decision is transparent. We believe the best AI tools should be built openly with the community, not behind closed doors.\n\n### üè† Local Deployment (Recommended)\n\nThe recommended way to run Eigent ‚Äî fully standalone with complete control over your data, no cloud account required.\n\nüëâ **[Full Local Deployment Guide](./server/README_EN.md)**\n\nThis setup includes:\n- Local backend server with full API\n- Local model integration (vLLM, Ollama, LM Studio, etc.)\n- Complete isolation from cloud services\n- Zero external dependencies\n\n### ‚ö° Quick Start (Cloud-Connected)\n\nFor a quick preview using our cloud backend ‚Äî get started in seconds:\n\n#### Prerequisites\n\n- Node.js (version 18-22) and npm\n\n#### Steps\n\n```bash\ngit clone https://github.com/eigent-ai/eigent.git\ncd eigent\nnpm install\nnpm run dev\n```\n\n> Note: This mode connects to Eigent cloud services and requires account registration. For a fully standalone experience, use [Local Deployment](#-local-deployment-recommended) instead.\n\n### üè¢ Enterprise\n\nFor organizations requiring maximum security, customization, and control:\n\n- **Exclusive Features** (like SSO & custom development)\n- **Scalable Enterprise Deployment**\n- **Negotiated SLAs** & implementation services\n\nüìß For further details, please contact us at [info@eigent.ai](mailto:info@eigent.ai).\n\n### ‚òÅÔ∏è Cloud Version\n\nFor teams who prefer managed infrastructure, we also offer a cloud platform. The fastest way to experience Eigent's multi-agent AI capabilities without setup complexity. We'll host the models, APIs, and cloud storage, ensuring Eigent runs flawlessly.\n\n- **Instant Access** - Start building multi-agent workflows in minutes.\n- **Managed Infrastructure** - We handle scaling, updates, and maintenance.\n- **Premium Support** - Subscribe and get priority assistance from our engineering team.\n\n<br/>\n\n[![image-public-beta]][eigent-download]\n\n<div align=\"right\">\n<a href=\"https://www.eigent.ai/download\">Get started at Eigent.ai ‚Üí</a>\n</div>\n\n## **‚ú® Key features**\nUnlock the full potential of exceptional productivity with Eigent‚Äôs powerful features‚Äîbuilt for seamless integration, smarter task execution, and boundless automation.\n\n### üè≠ Workforce \nEmploys a team of specialized AI agents that collaborate to solve complex tasks. Eigent dynamically breaks down tasks and activates multiple agents to work¬†**in parallel.**\n\nEigent pre-defined the following agent workers:\n\n- **Developer Agent:**¬†Writes and executes code, runs terminal commands.\n- **Browser Agent:**¬†Searches the web and extracts content.\n- **Document Agent:**¬†Creates and manages documents.\n- **Multi-Modal Agent:**¬†Processes images and audio.\n\n![Workforce](https://eigent-ai.github.io/.github/assets/gif/feature_dynamic_workforce.gif)\n\n<br/>\n\n### üß† Comprehensive Model Support\nDeploy Eigent locally with your preferred models. \n\n![Model](https://eigent-ai.github.io/.github/assets/gif/feature_local_model.gif)\n\n<br/>\n\n### üîå MCP Tools Integration (MCP)\nEigent comes with massive built-in¬†**Model Context Protocol (MCP)**¬†tools (for web browsing, code execution, Notion, Google suite, Slack etc.), and also lets you¬†**install your own tools**. Equip agents with exactly the right tools for your scenarios ‚Äì even integrate internal APIs or custom functions ‚Äì to enhance their capabilities.\n\n![MCP](https://eigent-ai.github.io/.github/assets/gif/feature_add_mcps.gif)\n\n<br/>\n\n### ‚úã Human-in-the-Loop\nIf a task gets stuck or encounters uncertainty, Eigent will automatically request human input. \n\n![Human-in-the-loop](https://eigent-ai.github.io/.github/assets/gif/feature_human_in_the_loop.gif)\n\n<br/>\n\n### üëê 100% Open Source\nEigent is completely open-sourced. You can download, inspect, and modify the code, ensuring transparency and fostering a community-driven ecosystem for multi-agent innovation.\n\n![Opensource][image-opensource]\n\n<br/>\n\n## üß© Use Cases\n\n### 1. Palm Springs Tennis Trip Itinerary with Slack Summary [Replay ‚ñ∂Ô∏è](https://www.eigent.ai/download?share_token=IjE[REDACTED_SECRET]__1753435151337-7113)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>We are two tennis fans and want to go see the tennis tournament ... <kbd></summary>\n<br>\nWe are two tennis fans and want to go see the tennis tournament in Palm Springs 2026. I live in SF - please prepare a detailed itinerary with flights, hotels, things to do for 3 days - around the time semifinal/finals are happening. We like hiking, vegan food and spas. Our budget is $5K. The itinerary should be a detailed timeline of time, activity, cost, other details and if applicable a link to buy tickets/make reservations etc. for the item. Some preferences .Spa access would be nice but not necessary. When you finish this task, please generate a html report about this trip; write a summary of this plan and send text summary and report html link to slack #tennis-trip-sf channel.\n</details>\n\n<br>\n\n### 2. Generate Q2 Report from CSV Bank Data [Replay ‚ñ∂Ô∏è](https://www.eigent.ai/download?share_token=IjE[REDACTED_SECRET]__1753526891808-8739)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>Please help me prepare a Q2 financial statement based on my bank ... <kbd></summary>\n<br>\nPlease help me prepare a Q2 financial statement based on my bank transfer record file bank_transacation.csv in my desktop to a html report with chart to investors how much we have spent.\n</details>\n\n<br>\n\n### 3. UK Healthcare Market Research Report Automation [Replay ‚ñ∂Ô∏è](https://www.eigent.ai/download?share_token=IjE3NTMzOTM1NTg3OTctODcwNyI.aIey-Q.Jh9QXzYrRYarY0kz_qsgoj3ewX0__1753393558797-8707)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>Analyze the UK healthcare industry to support the planning ... <kbd></summary>\n<br>\nAnalyze the UK healthcare industry to support the planning of my next company. Provide a comprehensive market overview, including current trends, growth projections, and relevant regulations. Identify the top 5‚Äì10 major opportunities, gaps, or underserved segments within the market. Present all findings in a well-structured, professional HTML report. Then send a message to slack #eigentr-product-test channel when this task is done to align the report content with my teammates.\n</details>\n\n<br>\n\n### 4. German Electric Skateboard Market Feasibility [Replay ‚ñ∂Ô∏è](https://www.eigent.ai/download?share_token=Ij[REDACTED_SECRET]__1753652826787-696)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>We are a company that produces high-end electric skateboards ... <kbd></summary>\n<br>\nWe are a company that produces high-end electric skateboards, and we are considering entering the German market. Please prepare a detailed market entry feasibility report for me. The report needs to cover the following aspects:\n1. Market Size & Regulations: Research the market size, annual growth rate, key players, and market share for Personal Light Electric Vehicles (PLEVs) in Germany. Simultaneously, provide a detailed breakdown and summary of German laws and regulations concerning the use of electric skateboards on public roads, including certification requirements (such as ABE certification) and insurance policies.\n2. Consumer Profile: Analyze the profile of potential German consumers, including their age, income level, primary usage scenarios (commuting, recreation), key purchasing decision drivers (price, performance, brand, design), and the channels they typically use to gather information (forums, social media, offline retail stores).\n3. Channels & Distribution: Investigate Germany‚Äôs mainstream online electronics sales platforms (e.g., Amazon.de, MediaMarkt.de) and high-end sporting goods offline retail chains. List the top 5 potential online and offline distribution partners and find the contact information for their purchasing departments, if possible.\n4. Costing & Pricing: Based on the product cost structure in my Product_Cost.csv file on my desktop, and taking into account German customs duties, Value Added Tax (VAT), logistics and warehousing costs, and potential marketing expenses, estimate a Manufacturer‚Äôs Suggested Retail Price (MSRP) and analyze its competitiveness in the market.\n5. Comprehensive Report & Presentation: Summarize all research findings into an HTML report file. The content should include data charts, key findings, and a final market entry strategy recommendation (Recommended / Not Recommended / Recommended with Conditions).\n</details>\n\n<br>\n\n### 5. SEO Audit for Workforce Multiagent Launch [Replay ‚ñ∂Ô∏è](https://www.eigent.ai/download?share_token=IjE[REDACTED_SECRET]__1753699971144-5696)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>To support the launch of our new Workforce Multiagent product ... <kbd></summary>\n<br>\nTo support the launch of our new Workforce Multiagent product, please run a thorough SEO audit on our official website (https://www.camel-ai.org/) and deliver a detailed optimization report with actionable recommendations.\n</details>\n\n<br>\n\n### 6. Identify Duplicate Files in Downloads [Replay ‚ñ∂Ô∏è](https://www.eigent.ai/download?share_token=Ij[REDACTED_SECRET]__1753760388171-248)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>I have a folder named mydocs inside my Documents directory ... <kbd></summary>\n<br>\nI have a folder named mydocs inside my Documents directory. Please scan it and identify all files that are exact or near duplicates ‚Äî including those with identical content, file size, or format (even if file names or extensions differ). List them clearly, grouped by similarity.\n</details>\n\n<br>\n\n### 7. Add Signature to PDF [Replay ‚ñ∂Ô∏è](https://www.eigent.ai/download?share_token=IjE[REDACTED_SECRET]__1754095483452-5661)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>Please add this signature image to the Signature Areas in the PDF ... <kbd></summary>\n<br>\nPlease add this signature image to the Signature Areas in the PDF. You could install the CLI tool ‚Äòtesseract‚Äô (needed for reliable location of ‚ÄòSignature Areas‚Äô via OCR) to help finish this task.\n</details>\n\n<br>\n\n## üõ†Ô∏è Tech Stack\n\n### Backend\n- **Framework:**¬†FastAPI\n- **Package Manager:**¬†uv\n- **Async Server:**¬†Uvicorn\n- **Authentication:**¬†OAuth 2.0,  Passlib.\n- **Multi-agent framework:** CAMEL\n    \n### Frontend\n\n- **Framework:**¬†React\n- **Desktop App Framework:**¬†Electron\n- **Language:**¬†TypeScript\n- **UI:**¬†Tailwind CSS, Radix UI, Lucide React, Framer Motion\n- **State Management:**¬†Zustand\n- **Flow Editor:**¬†React Flow\n\n## üåü¬†Staying ahead\n\n> \\[!IMPORTANT]\n>\n> **Star Eigent**, You will receive all release notifications from GitHub without any delay \\~ ‚≠êÔ∏è\n\n![][image-star-us]\n\n## üó∫Ô∏è Roadmap\n\n| Topics                   | Issues   | Discord Channel |\n| ------------------------ | -- |-- |\n| **Context Engineering** | - Prompt caching<br> - System prompt optimize<br> - Toolkit docstring optimize<br> - Context compression | [**Join Discord ‚Üí**](https://discord.gg/D2e3rBWD) |\n| **Multi-modal Enhancement** | - More accurate image understanding when using browser<br> - Advanced video generation | [**Join Discord ‚Üí**](https://discord.gg/kyapNCeJ) |\n| **Multi-agent system** | - Workforce support fixed workflow<br> - Workforce support multi-round conversion | [**Join Discord ‚Üí**](https://discord.gg/bFRmPuDB) |\n| **Browser Toolkit** | - BrowseCamp integration<br> - Benchmark improvement<br> - Forbid repeated page visiting<br> - Automatic cache button clicking | [**Join Discord ‚Üí**](https://discord.gg/NF73ze5v) |\n| **Document Toolkit** | - Support dynamic file editing | [**Join Discord ‚Üí**](https://discord.gg/4yAWJxYr) |\n| **Terminal Toolkit** | - Benchmark improvement<br> - Terminal-Bench integration | [**Join Discord ‚Üí**](https://discord.gg/FjQfnsrV) |\n| **Environment & RL** | - Environment design<br> - Data-generation<br> - RL framework integration (VERL, TRL, OpenRLHF) | [**Join Discord ‚Üí**](https://discord.gg/MaVZXEn8) |\n\n\n## [ü§ù Contributing][contribution-link]\n\nWe believe in building trust and embracing all forms of open-source collaborations. Your creative contributions help drive the innovation of `Eigent`. Explore our GitHub issues and projects to dive in and show us what you‚Äôve got ü§ù‚ù§Ô∏è [Contribution Guideline][contribution-link]\n\n\n## Contributors\n\n<a href=\"https://github.com/eigent-ai/eigent/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=eigent-ai/eigent\" />\n</a>\n\nMade with [contrib.rocks](https://contrib.rocks).\n\n<br>\n\n## [‚ù§Ô∏è Sponsor][sponsor-link]\n\nEigent is built on top of [CAMEL-AI.org][camel-ai-org-github]'s research and infrastructures. [Sponsoring CAMEL-AI.org][sponsor-link] will make `Eigent` better.\n\n## **üìÑ¬†Open Source License**\n\nThis repository is licensed under the [Apache License 2.0](LICENSE).\n\n## üåê Community & Contact\nFor more information please contact info@eigent.ai\n\n- **GitHub Issues:** Report bugs, request features, and track development. [Submit an issue][github-issue-link]\n\n- **Discord:** Get real-time support, chat with the community, and stay updated. [Join us](https://discord.camel-ai.org/)\n\n- **X (Twitter):** Follow for updates, AI insights, and key announcements. [Follow us][social-x-link]\n\n- **WeChat Community:** Scan the QR code below to add our WeChat assistant, and join our WeChat community group.\n\n<div align=\"center\">\n  <img src=\"./src/assets/wechat_qr.jpg\" width=\"200\" style=\"display: inline-block; margin: 10px;\">\n</div>\n\n\n\n<!-- LINK GROUP -->\n<!-- Social -->\n[discord-url]: https://discord.camel-ai.org/\n[discord-image]: https://img.shields.io/discord/1082486657678311454?logo=discord&labelColor=%20%235462eb&logoColor=%20%23f5f5f5&color=%20%235462eb\n\n[built-with-camel]:https://img.shields.io/badge/-Built--with--CAMEL-4C19E8.svg?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQ4IiBoZWlnaHQ9IjI3MiIgdmlld0JveD0iMCAwIDI0OCAyNzIiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+CjxwYXRoIGQ9Ik04LjgzMTE3IDE4LjU4NjVMMCAzMC44MjY3QzUuNDY2OTIgMzUuMDQzMiAxNS4xMzkxIDM4LjgyNTggMjQuODExNCAzNi4yOTU5QzMwLjY5ODggNDAuOTM0MSAzOS42NzAyIDQwLjIzMTMgNDQuMTU1OSA0MC4wOTA4QzQzLjQ1NSA0Ny4zOTk0IDQyLjQ3MzcgNzAuOTU1OCA0NC4xNTU5IDEwNi43MTJDNDUuODM4IDE0Mi40NjggNzEuNzcwOCAxNjYuODY4IDg0LjUyNjkgMTc0LjU5OEw3Ni4wMDAyIDIyMEw4NC41MjY5IDI3MkgxMDguOTE4TDk4LjAwMDIgMjIwTDEwOC45MTggMTc0LjU5OEwxMjkuOTQ0IDI3MkgxNTQuNzU2TDEzNC4xNSAxNzQuNTk4SDE4Ny4xMzdMMTY2LjUzMSAyNzJIMTkxLjc2M0wyMTIuMzY5IDE3NC41OThMMjI2IDIyMEwyMTIuMzY5IDI3MkgyMzcuNjAxTDI0OC4wMDEgMjIwTDIzNy4xOCAxNzQuNTk4QzIzOS4yODMgMTY5LjExNyAyNDAuNDAxIDE2Ni45NzYgMjQxLjgwNiAxNjEuMTA1QzI0OS4zNzUgMTI5LjQ4MSAyMzUuMDc3IDEwMy45MDEgMjI2LjY2NyA5NC40ODRMMjA2LjQ4MSA3My44MjNDMTk3LjY1IDY0Ljk2ODMgMTgyLjUxMSA2NC41NDY3IDE3Mi44MzkgNzIuNTU4MUMxNjUuNzI4IDc4LjQ0NzcgMTYxLjcwMSA3OC43NzI3IDE1NC43NTYgNzIuNTU4MUMxNTEuODEyIDcwLjAyODEgMTQ0LjUzNSA2MS40ODg5IDEzNC45OTEgNTMuNTgzN0MxMjUuMzE5IDQ1LjU3MjMgMTA4LjQ5NyA0OC45NDU1IDEwMi4xODkgNTUuNjkxOUw3My41OTMxIDg0LjM2NDRWNy42MjM0OUw3OS4xMjczIDBDNjAuOTA0MiAzLjY1NDMzIDIzLjgwMjEgOS41NjMwOSAxOS43NjUgMTAuNTc1MUMxNS43Mjc5IDExLjU4NyAxMC43OTM3IDE2LjMzNzcgOC44MzExNyAxOC41ODY1WiIgZmlsbD0id2hpdGUiLz4KPHBhdGggZD0iTTQzLjIwMzggMTguNzE4N0w0OS4wOTEyIDEzLjA0OTNMNTQuOTc4NyAxOC43MTg3TDQ5LjA5MTIgMjQuODI0Mkw0My4yMDM4IDE4LjcxODdaIiBmaWxsPSIjNEMxOUU4Ii8+Cjwvc3ZnPgo=\n\n[eigent-github]: https://github.com/eigent-ai/eigent\n[github-star]: https://img.shields.io/github/stars/eigent-ai?color=F5F4F0&labelColor=gray&style=plastic&logo=github\n[camel-ai-org-github]: https://github.com/camel-ai\n\n[camel-github]: https://github.com/camel-ai/camel\n[eigent-github]: https://github.com/eigent-ai/eigent\n[contribution-link]: https://github.com/eigent-ai/eigent/blob/main/CONTRIBUTING.md\n\n[social-x-link]: https://x.com/Eigent_AI\n[social-x-shield]: https://img.shields.io/badge/-%40Eigent_AI-white?labelColor=gray&logo=x&logoColor=white&style=plastic\n\n[reddit-url]: https://www.reddit.com/r/CamelAI/\n[reddit-image]: https://img.shields.io/reddit/subreddit-subscribers/CamelAI?style=plastic&logo=reddit&label=r%2FCAMEL&labelColor=white\n\n[wechat-url]: https://ghli.org/camel/wechat.png\n[wechat-image]: https://img.shields.io/badge/WeChat-CamelAIOrg-brightgreen?logo=wechat&logoColor=white\n\n[sponsor-link]: https://github.com/sponsors/camel-ai\n[sponsor-shield]: https://img.shields.io/badge/-Sponsor%20CAMEL--AI-1d1d1d?logo=github&logoColor=white&style=plastic\n\n[eigent-download]: https://www.eigent.ai/download\n[download-shield]: https://img.shields.io/badge/Download%20Eigent-363AF5?style=plastic\n\n[join-us]:https://eigent-ai.notion.site/eigent-ai-careers\n[join-us-image]:https://img.shields.io/badge/Join%20Us-yellow?style=plastic\n\n<!-- camel & eigent -->\n[camel-site]: https://www.camel-ai.org\n[eigent-site]: https://www.eigent.ai\n[docs-site]: https://docs.eigent.ai\n[github-issue-link]: https://github.com/eigent-ai/eigent/issues\n\n<!-- marketing -->\n[image-seperator]: https://eigent-ai.github.io/.github/assets/seperator.png \n[image-head]: https://eigent-ai.github.io/.github/assets/head.png \n[image-public-beta]: https://eigent-ai.github.io/.github/assets/banner.png\n[image-star-us]: https://eigent-ai.github.io/.github/assets/star-us.gif\n[image-opensource]: https://eigent-ai.github.io/.github/assets/opensource.png\n[image-wechat]: https://eigent-ai.github.io/.github/assets/wechat.png\n[image-join-us]: https://camel-ai.github.io/camel_asset/graphics/join_us.png\n\n<!-- feature -->\n[image-workforce]: https://eigent-ai.github.io/.github/assets/feature_dynamic_workforce.gif\n[image-human-in-the-loop]: https://eigent-ai.github.io/.github/assets/feature_human_in_the_loop.gif\n[image-customise-workers]: https://eigent-ai.github.io/.github/assets/feature_customise_workers.gif\n[image-add-mcps]: https://eigent-ai.github.io/.github/assets/feature_add_mcps.gif\n[image-local-model]: https://eigent-ai.github.io/.github/assets/feature_local_model.gif\n",
      "stars_today": 2179
    },
    {
      "id": 648629873,
      "name": "puck",
      "full_name": "puckeditor/puck",
      "description": "The visual editor for React",
      "html_url": "https://github.com/puckeditor/puck",
      "stars": 11049,
      "forks": 771,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2023-06-02T12:23:41Z",
      "updated_at": "2026-01-17T00:59:43Z",
      "pushed_at": "2026-01-15T14:22:42Z",
      "open_issues": 177,
      "owner": {
        "login": "puckeditor",
        "avatar_url": "https://avatars.githubusercontent.com/u/153829377?v=4"
      },
      "readme": "<br /><br /><br />\n\n<div align=\"center\">\n\n<a href=\"https://puckeditor.com?utm_source=readme&utm_medium=code&utm_campaign=repo&utm_contents=logo\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://res.cloudinary.com/die3nptcg/image/upload/Puck_Logo_White_RGB_j2rwgg.svg\" height=\"100px\" aria-label=\"Puck logo\">\n    <img src=\"https://res.cloudinary.com/die3nptcg/image/upload/Puck_Logo_Black_RGB_dqsjag.svg\" height=\"100px\" aria-label=\"Puck logo\">\n  </picture>\n</a>\n\n_The visual editor for React_\n\n[Documentation](https://puckeditor.com/docs?utm_source=readme&utm_medium=code&utm_campaign=repo&utm_contents=docs_link) ‚Ä¢ [Demo](https://demo.puckeditor.com/edit?utm_source=readme&utm_medium=code&utm_campaign=repo&utm_contents=demo_link) ‚Ä¢ [Discord](https://discord.gg/V9mDAhuxyZ) ‚Ä¢ [Contributing](https://github.com/puckeditor/puck/blob/main/CONTRIBUTING.md)\n\n‚≠êÔ∏è Enjoying Puck? Please [leave a star](https://github.com/puckeditor/puck)!\n\n<br />\n\n[![GIF showing a page being created in the Puck Editor, with components being added, arranged, and customized in real time](https://github.com/user-attachments/assets/25e1ae25-ca5e-450f-afa0-01816830b731)](https://demo.puckeditor.com/edit)\n\n</div>\n\n## What is Puck?\n\nPuck is a modular, open-source visual editor for React.js. You can use Puck to build custom drag-and-drop experiences with your own application and React components.\n\nBecause Puck is just a React component, it plays well with all React.js environments, including Next.js. You own your data and there‚Äôs no vendor lock-in.\n\nPuck is also [licensed under MIT](https://github.com/puckeditor/puck?tab=MIT-1-ov-file#readme), making it suitable for both internal systems and commercial applications.\n\n## Quick start\n\nInstall the package:\n\n```sh\nnpm i @puckeditor/core --save # or npx create-puck-app my-app\n```\n\nRender the editor:\n\n```jsx\n// Editor.jsx\nimport { Puck } from \"@puckeditor/core\";\nimport \"@puckeditor/core/puck.css\";\n\n// Create Puck component config\nconst config = {\n  components: {\n    HeadingBlock: {\n      fields: {\n        children: {\n          type: \"text\",\n        },\n      },\n      render: ({ children }) => {\n        return <h1>{children}</h1>;\n      },\n    },\n  },\n};\n\n// Describe the initial data\nconst initialData = {};\n\n// Save the data to your database\nconst save = (data) => {};\n\n// Render Puck editor\nexport function Editor() {\n  return <Puck config={config} data={initialData} onPublish={save} />;\n}\n```\n\nRender the page:\n\n```jsx\n// Page.jsx\nimport { Render } from \"@puckeditor/core\";\nimport \"@puckeditor/core/puck.css\";\n\nexport function Page() {\n  return <Render config={config} data={data} />;\n}\n```\n\n## Recipes\n\nUse `create-puck-app` to quickly spin up a a pre-configured app based on our provided [recipes](https://github.com/puckeditor/puck/tree/main/recipes):\n\n```sh\nnpx create-puck-app my-app\n```\n\nAvailable recipes include:\n\n- [**next**](https://github.com/puckeditor/puck/tree/main/recipes/next): Next.js example, using App Router and static page generation\n- [**remix**](https://github.com/puckeditor/puck/tree/main/recipes/remix): Remix Run v2 example, using dynamic routes at root-level\n- [**react-router**](https://github.com/puckeditor/puck/tree/main/recipes/react-router): React Router v7 app example, using dynamic routes to create pages at any level\n\n## Community\n\n- [Discord server](https://discord.gg/D9e4E3MQVZ) for discussions\n- [awesome-puck](https://github.com/puckeditor/awesome-puck) community repo for plugins, custom fields & more\n\n## Get support\n\nIf you have any questions about Puck, please open a [GitHub issue](https://github.com/puckeditor/puck/issues) or join us on [Discord](https://discord.gg/D9e4E3MQVZ).\n\nOr [book a discovery call](https://app.cal.com/chrisvxd/puck-enquiry/) for hands-on support and consultancy.\n\n## License\n\nMIT ¬© [The Puck Contributors](https://github.com/puckeditor/puck/graphs/contributors)\n",
      "stars_today": 504
    },
    {
      "id": 931888694,
      "name": "Handy",
      "full_name": "cjpais/Handy",
      "description": "A free, open source, and extensible speech-to-text application that works completely offline.",
      "html_url": "https://github.com/cjpais/Handy",
      "stars": 11824,
      "forks": 780,
      "language": "TypeScript",
      "topics": [
        "accessibility",
        "cross-platform",
        "speech-to-text",
        "tauri-v2"
      ],
      "created_at": "2025-02-13T02:42:29Z",
      "updated_at": "2026-01-17T00:59:44Z",
      "pushed_at": "2026-01-15T01:58:30Z",
      "open_issues": 85,
      "owner": {
        "login": "cjpais",
        "avatar_url": "https://avatars.githubusercontent.com/u/1559480?v=4"
      },
      "readme": "# Handy\n\n[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&logo=discord&logoColor=white)](https://discord.com/invite/WVBeWsNXK4)\n\n**A free, open source, and extensible speech-to-text application that works completely offline.**\n\nHandy is a cross-platform desktop application built with Tauri (Rust + React/TypeScript) that provides simple, privacy-focused speech transcription. Press a shortcut, speak, and have your words appear in any text field‚Äîall without sending your voice to the cloud.\n\n## Why Handy?\n\nHandy was created to fill the gap for a truly open source, extensible speech-to-text tool. As stated on [handy.computer](https://handy.computer):\n\n- **Free**: Accessibility tooling belongs in everyone's hands, not behind a paywall\n- **Open Source**: Together we can build further. Extend Handy for yourself and contribute to something bigger\n- **Private**: Your voice stays on your computer. Get transcriptions without sending audio to the cloud\n- **Simple**: One tool, one job. Transcribe what you say and put it into a text box\n\nHandy isn't trying to be the best speech-to-text app‚Äîit's trying to be the most forkable one.\n\n## How It Works\n\n1. **Press** a configurable keyboard shortcut to start/stop recording (or use push-to-talk mode)\n2. **Speak** your words while the shortcut is active\n3. **Release** and Handy processes your speech using Whisper\n4. **Get** your transcribed text pasted directly into whatever app you're using\n\nThe process is entirely local:\n\n- Silence is filtered using VAD (Voice Activity Detection) with Silero\n- Transcription uses your choice of models:\n  - **Whisper models** (Small/Medium/Turbo/Large) with GPU acceleration when available\n  - **Parakeet V3** - CPU-optimized model with excellent performance and automatic language detection\n- Works on Windows, macOS, and Linux\n\n## Quick Start\n\n### Installation\n\n1. Download the latest release from the [releases page](https://github.com/cjpais/Handy/releases) or the [website](https://handy.computer)\n2. Install the application following platform-specific instructions\n3. Launch Handy and grant necessary system permissions (microphone, accessibility)\n4. Configure your preferred keyboard shortcuts in Settings\n5. Start transcribing!\n\n### Development Setup\n\nFor detailed build instructions including platform-specific requirements, see [BUILD.md](BUILD.md).\n\n## Architecture\n\nHandy is built as a Tauri application combining:\n\n- **Frontend**: React + TypeScript with Tailwind CSS for the settings UI\n- **Backend**: Rust for system integration, audio processing, and ML inference\n- **Core Libraries**:\n  - `whisper-rs`: Local speech recognition with Whisper models\n  - `transcription-rs`: CPU-optimized speech recognition with Parakeet models\n  - `cpal`: Cross-platform audio I/O\n  - `vad-rs`: Voice Activity Detection\n  - `rdev`: Global keyboard shortcuts and system events\n  - `rubato`: Audio resampling\n\n### Debug Mode\n\nHandy includes an advanced debug mode for development and troubleshooting. Access it by pressing:\n\n- **macOS**: `Cmd+Shift+D`\n- **Windows/Linux**: `Ctrl+Shift+D`\n\n## Known Issues & Current Limitations\n\nThis project is actively being developed and has some [known issues](https://github.com/cjpais/Handy/issues). We believe in transparency about the current state:\n\n### Major Issues (Help Wanted)\n\n**Whisper Model Crashes:**\n\n- Whisper models crash on certain system configurations (Windows and Linux)\n- Does not affect all systems - issue is configuration-dependent\n  - If you experience crashes and are a developer, please help to fix and provide debug logs!\n\n**Wayland Support (Linux):**\n\n- Limited support for Wayland display server\n- Requires [`wtype`](https://github.com/atx/wtype) or [`dotool`](https://sr.ht/~geb/dotool/) for text input to work correctly (see [Linux Notes](#linux-notes) below for installation)\n\n### Linux Notes\n\n**Text Input Tools:**\n\nFor reliable text input on Linux, install the appropriate tool for your display server:\n\n| Display Server | Recommended Tool | Install Command                                    |\n| -------------- | ---------------- | -------------------------------------------------- |\n| X11            | `xdotool`        | `sudo apt install xdotool`                         |\n| Wayland        | `wtype`          | `sudo apt install wtype`                           |\n| Both           | `dotool`         | `sudo apt install dotool` (requires `input` group) |\n\n- **X11**: Install `xdotool` for both direct typing and clipboard paste shortcuts\n- **Wayland**: Install `wtype` (preferred) or `dotool` for text input to work correctly\n- **dotool setup**: Requires adding your user to the `input` group: `sudo usermod -aG input $USER` (then log out and back in)\n\nWithout these tools, Handy falls back to enigo which may have limited compatibility, especially on Wayland.\n\n**Other Notes:**\n\n- The recording overlay is disabled by default on Linux (`Overlay Position: None`) because certain compositors treat it as the active window. When the overlay is visible it can steal focus, which prevents Handy from pasting back into the application that triggered transcription. If you enable the overlay anyway, be aware that clipboard-based pasting might fail or end up in the wrong window.\n- If you are having trouble with the app, running with the environment variable `WEBKIT_DISABLE_DMABUF_RENDERER=1` may help\n- You can manage global shortcuts outside of Handy and still control the app via signals. Sending `SIGUSR2` to the Handy process toggles recording on/off, which lets Wayland window managers or other hotkey daemons keep ownership of keybindings. Example (Sway):\n\n  ```ini\n  bindsym $mod+o exec pkill -USR2 -n handy\n  ```\n\n  `pkill` here simply delivers the signal‚Äîit does not terminate the process.\n\n### Platform Support\n\n- **macOS (both Intel and Apple Silicon)**\n- **x64 Windows**\n- **x64 Linux**\n\n### System Requirements/Recommendations\n\nThe following are recommendations for running Handy on your own machine. If you don't meet the system requirements, the performance of the application may be degraded. We are working on improving the performance across all kinds of computers and hardware.\n\n**For Whisper Models:**\n\n- **macOS**: M series Mac, Intel Mac\n- **Windows**: Intel, AMD, or NVIDIA GPU\n- **Linux**: Intel, AMD, or NVIDIA GPU\n  - Ubuntu 22.04, 24.04\n\n**For Parakeet V3 Model:**\n\n- **CPU-only operation** - runs on a wide variety of hardware\n- **Minimum**: Intel Skylake (6th gen) or equivalent AMD processors\n- **Performance**: ~5x real-time speed on mid-range hardware (tested on i5)\n- **Automatic language detection** - no manual language selection required\n\n## Roadmap & Active Development\n\nWe're actively working on several features and improvements. Contributions and feedback are welcome!\n\n### In Progress\n\n**Debug Logging:**\n\n- Adding debug logging to a file to help diagnose issues\n\n**macOS Keyboard Improvements:**\n\n- Support for Globe key as transcription trigger\n- A rewrite of global shortcut handling for MacOS, and potentially other OS's too.\n\n**Opt-in Analytics:**\n\n- Collect anonymous usage data to help improve Handy\n- Privacy-first approach with clear opt-in\n\n**Settings Refactoring:**\n\n- Cleanup and refactor settings system which is becoming bloated and messy\n- Implement better abstractions for settings management\n\n**Tauri Commands Cleanup:**\n\n- Abstract and organize Tauri command patterns\n- Investigate tauri-specta for improved type safety and organization\n\n## Troubleshooting\n\n### Manual Model Installation (For Proxy Users or Network Restrictions)\n\nIf you're behind a proxy, firewall, or in a restricted network environment where Handy cannot download models automatically, you can manually download and install them. The URLs are publicly accessible from any browser.\n\n#### Step 1: Find Your App Data Directory\n\n1. Open Handy settings\n2. Navigate to the **About** section\n3. Copy the \"App Data Directory\" path shown there, or use the shortcuts:\n   - **macOS**: `Cmd+Shift+D` to open debug menu\n   - **Windows/Linux**: `Ctrl+Shift+D` to open debug menu\n\nThe typical paths are:\n\n- **macOS**: `~/Library/Application Support/com.pais.handy/`\n- **Windows**: `C:\\Users\\{username}\\AppData\\Roaming\\com.pais.handy\\`\n- **Linux**: `~/.config/com.pais.handy/`\n\n#### Step 2: Create Models Directory\n\nInside your app data directory, create a `models` folder if it doesn't already exist:\n\n```bash\n# macOS/Linux\nmkdir -p ~/Library/Application\\ Support/com.pais.handy/models\n\n# Windows (PowerShell)\nNew-Item -ItemType Directory -Force -Path \"$env:APPDATA\\com.pais.handy\\models\"\n```\n\n#### Step 3: Download Model Files\n\nDownload the models you want from below\n\n**Whisper Models (single .bin files):**\n\n- Small (487 MB): `https://blob.handy.computer/ggml-small.bin`\n- Medium (492 MB): `https://blob.handy.computer/whisper-medium-q4_1.bin`\n- Turbo (1600 MB): `https://blob.handy.computer/ggml-large-v3-turbo.bin`\n- Large (1100 MB): `https://blob.handy.computer/ggml-large-v3-q5_0.bin`\n\n**Parakeet Models (compressed archives):**\n\n- V2 (473 MB): `https://blob.handy.computer/parakeet-v2-int8.tar.gz`\n- V3 (478 MB): `https://blob.handy.computer/parakeet-v3-int8.tar.gz`\n\n#### Step 4: Install Models\n\n**For Whisper Models (.bin files):**\n\nSimply place the `.bin` file directly into the `models` directory:\n\n```\n{app_data_dir}/models/\n‚îú‚îÄ‚îÄ ggml-small.bin\n‚îú‚îÄ‚îÄ whisper-medium-q4_1.bin\n‚îú‚îÄ‚îÄ ggml-large-v3-turbo.bin\n‚îî‚îÄ‚îÄ ggml-large-v3-q5_0.bin\n```\n\n**For Parakeet Models (.tar.gz archives):**\n\n1. Extract the `.tar.gz` file\n2. Place the **extracted directory** into the `models` folder\n3. The directory must be named exactly as follows:\n   - **Parakeet V2**: `parakeet-tdt-0.6b-v2-int8`\n   - **Parakeet V3**: `parakeet-tdt-0.6b-v3-int8`\n\nFinal structure should look like:\n\n```\n{app_data_dir}/models/\n‚îú‚îÄ‚îÄ parakeet-tdt-0.6b-v2-int8/     (directory with model files inside)\n‚îÇ   ‚îú‚îÄ‚îÄ (model files)\n‚îÇ   ‚îî‚îÄ‚îÄ (config files)\n‚îî‚îÄ‚îÄ parakeet-tdt-0.6b-v3-int8/     (directory with model files inside)\n    ‚îú‚îÄ‚îÄ (model files)\n    ‚îî‚îÄ‚îÄ (config files)\n```\n\n**Important Notes:**\n\n- For Parakeet models, the extracted directory name **must** match exactly as shown above\n- Do not rename the `.bin` files for Whisper models‚Äîuse the exact filenames from the download URLs\n- After placing the files, restart Handy to detect the new models\n\n#### Step 5: Verify Installation\n\n1. Restart Handy\n2. Open Settings ‚Üí Models\n3. Your manually installed models should now appear as \"Downloaded\"\n4. Select the model you want to use and test transcription\n\n### How to Contribute\n\n1. **Check existing issues** at [github.com/cjpais/Handy/issues](https://github.com/cjpais/Handy/issues)\n2. **Fork the repository** and create a feature branch\n3. **Test thoroughly** on your target platform\n4. **Submit a pull request** with clear description of changes\n5. **Join the discussion** - reach out at [contact@handy.computer](mailto:contact@handy.computer)\n\nThe goal is to create both a useful tool and a foundation for others to build upon‚Äîa well-patterned, simple codebase that serves the community.\n\n## Sponsors\n\n<div align=\"center\">\n  We're grateful for the support of our sponsors who help make Handy possible:\n  <br><br>\n  <a href=\"https://wordcab.com\">\n    <img src=\"sponsor-images/wordcab.png\" alt=\"Wordcab\" width=\"120\" height=\"120\">\n  </a>\n  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n  <a href=\"https://github.com/epicenter-so/epicenter\">\n    <img src=\"sponsor-images/epicenter.png\" alt=\"Epicenter\" width=\"120\" height=\"120\">\n  </a>\n</div>\n\n## Related Projects\n\n- **[Handy CLI](https://github.com/cjpais/handy-cli)** - The original Python command-line version\n- **[handy.computer](https://handy.computer)** - Project website with demos and documentation\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- **Whisper** by OpenAI for the speech recognition model\n- **whisper.cpp and ggml** for amazing cross-platform whisper inference/acceleration\n- **Silero** for great lightweight VAD\n- **Tauri** team for the excellent Rust-based app framework\n- **Community contributors** helping make Handy better\n\n---\n\n_\"Your search for the right speech-to-text tool can end here‚Äînot because Handy is perfect, but because you can make it perfect for you.\"_\n",
      "stars_today": 405
    },
    {
      "id": 1031912724,
      "name": "cc-switch",
      "full_name": "farion1231/cc-switch",
      "description": "A cross-platform desktop All-in-One assistant tool for Claude Code, Codex & Gemini CLI.",
      "html_url": "https://github.com/farion1231/cc-switch",
      "stars": 11771,
      "forks": 767,
      "language": "Rust",
      "topics": [
        "ai-tools",
        "claude-code",
        "codex",
        "deepseek-v3",
        "desktop-app",
        "kimi-k2-thiking",
        "mcp",
        "minimax",
        "open-source",
        "provider-management",
        "qwen-coder",
        "rust",
        "tauri",
        "typescript",
        "wsl-support"
      ],
      "created_at": "2025-08-04T14:16:16Z",
      "updated_at": "2026-01-17T00:21:09Z",
      "pushed_at": "2026-01-16T19:55:49Z",
      "open_issues": 109,
      "owner": {
        "login": "farion1231",
        "avatar_url": "https://avatars.githubusercontent.com/u/44939412?v=4"
      },
      "readme": "<div align=\"center\">\n\n# All-in-One Assistant for Claude Code, Codex & Gemini CLI\n\n[![Version](https://img.shields.io/badge/version-3.9.1-blue.svg)](https://github.com/farion1231/cc-switch/releases)\n[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/farion1231/cc-switch/releases)\n[![Built with Tauri](https://img.shields.io/badge/built%20with-Tauri%202-orange.svg)](https://tauri.app/)\n[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total)](https://github.com/farion1231/cc-switch/releases/latest)\n\n<a href=\"https://trendshift.io/repositories/15372\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/15372\" alt=\"farion1231%2Fcc-switch | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\nEnglish | [‰∏≠Êñá](README_ZH.md) | [Êó•Êú¨Ë™û](README_JA.md) | [Changelog](CHANGELOG.md)\n\n</div>\n\n## ‚ù§Ô∏èSponsor\n\n[![Zhipu GLM](assets/partners/banners/glm-en.jpg)](https://z.ai/subscribe?ic=8JVLJQFSKB)\n\nThis project is sponsored by Z.ai, supporting us with their GLM CODING PLAN.GLM CODING PLAN is a subscription service designed for AI coding, starting at just $3/month. It provides access to their flagship GLM-4.6 model across 10+ popular AI coding tools (Claude Code, Cline, Roo Code, etc.), offering developers top-tier, fast, and stable coding experiences.Get 10% OFF the GLM CODING PLAN with [this link](https://z.ai/subscribe?ic=8JVLJQFSKB)!\n\n---\n\n<table>\n<tr>\n<td width=\"180\"><a href=\"https://www.packyapi.com/register?aff=cc-switch\"><img src=\"assets/partners/logos/packycode.png\" alt=\"PackyCode\" width=\"150\"></a></td>\n<td>Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using <a href=\"https://www.packyapi.com/register?aff=cc-switch\">this link</a> and enter the \"cc-switch\" promo code during recharge to get 10% off.</td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://aigocode.com/invite/CC-SWITCH\"><img src=\"assets/partners/logos/aigocode.png\" alt=\"AIGoCode\" width=\"150\"></a></td>\n<td>Thanks to AIGoCode for sponsoring this project! AIGoCode is an all-in-one platform that integrates Claude Code, Codex, and the latest Gemini models, providing you with stable, efficient, and highly cost-effective AI coding services. The platform offers flexible subscription plans, zero risk of account suspension, direct access with no VPN required, and lightning-fast responses. AIGoCode has prepared a special benefit for CC Switch users: if you register via <a href=\"https://aigocode.com/invite/CC-SWITCH\">this link</a>, you'll receive an extra 10% bonus credit on your first top-up!</td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://www.dmxapi.cn/register?aff=bUHu\"><img src=\"assets/partners/logos/dmx-en.jpg\" alt=\"DMXAPI\" width=\"150\"></a></td>\n<td>Thanks to DMXAPI for sponsoring this project! DMXAPI provides global large model API services to 200+ enterprise users. One API key for all global models. Features include: instant invoicing, unlimited concurrency, starting from $0.15, 24/7 technical support. GPT/Claude/Gemini all at 32% off, domestic models 20-50% off, Claude Code exclusive models at 66% off! <a href=\"https://www.dmxapi.cn/register?aff=bUHu\">Register here</a></td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://cubence.com/signup?code=CCSWITCH&source=ccs\"><img src=\"assets/partners/logos/cubence.png\" alt=\"Cubence\" width=\"150\"></a></td>\n<td>Thanks to Cubence for sponsoring this project! Cubence is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more with flexible billing options including pay-as-you-go and monthly plans. Cubence provides special discounts for CC Switch users: register using <a href=\"https://cubence.com/signup?code=CCSWITCH&source=ccs\">this link</a> and enter the \"CCSWITCH\" promo code during recharge to get 10% off every top-up!</td>\n</tr>\n\n</table>\n\n## Screenshots\n\n|                  Main Interface                   |                  Add Provider                  |\n| :-----------------------------------------------: | :--------------------------------------------: |\n| ![Main Interface](assets/screenshots/main-en.png) | ![Add Provider](assets/screenshots/add-en.png) |\n\n## Features\n\n### Current Version: v3.9.1 | [Full Changelog](CHANGELOG.md) | [Release Notes](docs/release-note-v3.9.0-en.md)\n\n**v3.8.0 Major Update (2025-11-28)**\n\n**Persistence Architecture Upgrade & Brand New UI**\n\n- **SQLite + JSON Dual-layer Architecture**\n  - Migrated from JSON file storage to SQLite + JSON dual-layer structure\n  - Syncable data (providers, MCP, Prompts, Skills) stored in SQLite\n  - Device-level data (window state, local paths) stored in JSON\n  - Lays the foundation for future cloud sync functionality\n  - Schema version management for database migrations\n\n- **Brand New User Interface**\n  - Completely redesigned interface layout\n  - Unified component styles and smoother animations\n  - Optimized visual hierarchy\n  - Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility\n\n- **Japanese Language Support**\n  - Added Japanese interface support (now supports Chinese/English/Japanese)\n\n- **Auto Launch on Startup**\n  - One-click enable/disable in settings\n  - Platform-native APIs (Registry/LaunchAgent/XDG autostart)\n\n- **Skills Recursive Scanning**\n  - Support for multi-level directory structures\n  - Allow same-named skills from different repositories\n\n- **Critical Bug Fixes**\n  - Fixed custom endpoints lost when updating providers\n  - Fixed Gemini configuration write issues\n  - Fixed Linux WebKitGTK rendering issues\n\n**v3.7.0 Highlights**\n\n**Six Core Features, 18,000+ Lines of New Code**\n\n- **Gemini CLI Integration**\n  - Third supported AI CLI (Claude Code / Codex / Gemini)\n  - Dual-file configuration support (`.env` + `settings.json`)\n  - Complete MCP server management\n  - Presets: Google Official (OAuth) / PackyCode / Custom\n\n- **Claude Skills Management System**\n  - Auto-scan skills from GitHub repositories (3 pre-configured curated repos)\n  - One-click install/uninstall to `~/.claude/skills/`\n  - Custom repository support + subdirectory scanning\n  - Complete lifecycle management (discover/install/update)\n\n- **Prompts Management System**\n  - Multi-preset system prompt management (unlimited presets, quick switching)\n  - Cross-app support (Claude: `CLAUDE.md` / Codex: `AGENTS.md` / Gemini: `GEMINI.md`)\n  - Markdown editor (CodeMirror 6 + real-time preview)\n  - Smart backfill protection, preserves manual modifications\n\n- **MCP v3.7.0 Unified Architecture**\n  - Single panel manages MCP servers across three applications\n  - New SSE (Server-Sent Events) transport type\n  - Smart JSON parser + Codex TOML format auto-correction\n  - Unified import/export + bidirectional sync\n\n- **Deep Link Protocol**\n  - `ccswitch://` protocol registration (all platforms)\n  - One-click import provider configs via shared links\n  - Security validation + lifecycle integration\n\n- **Environment Variable Conflict Detection**\n  - Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)\n  - Visual conflict indicators + resolution suggestions\n  - Override warnings + backup before changes\n\n**Core Capabilities**\n\n- **Provider Management**: One-click switching between Claude Code, Codex, and Gemini API configurations\n- **Speed Testing**: Measure API endpoint latency with visual quality indicators\n- **Import/Export**: Backup and restore configs with auto-rotation (keep 10 most recent)\n- **i18n Support**: Complete Chinese/English localization (UI, errors, tray)\n- **Claude Plugin Sync**: One-click apply/restore Claude plugin configurations\n\n**v3.6 Highlights**\n\n- Provider duplication & drag-and-drop sorting\n- Multi-endpoint management & custom config directory (cloud sync ready)\n- Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)\n- WSL environment support with auto-sync on directory change\n- 100% hooks test coverage & complete architecture refactoring\n\n**System Features**\n\n- System tray with quick switching\n- Single instance daemon\n- Built-in auto-updater\n- Atomic writes with rollback protection\n\n## Download & Installation\n\n### System Requirements\n\n- **Windows**: Windows 10 and above\n- **macOS**: macOS 10.15 (Catalina) and above\n- **Linux**: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions\n\n### Windows Users\n\nDownload the latest `CC-Switch-v{version}-Windows.msi` installer or `CC-Switch-v{version}-Windows-Portable.zip` portable version from the [Releases](../../releases) page.\n\n### macOS Users\n\n**Method 1: Install via Homebrew (Recommended)**\n\n```bash\nbrew tap farion1231/ccswitch\nbrew install --cask cc-switch\n```\n\nUpdate:\n\n```bash\nbrew upgrade --cask cc-switch\n```\n\n**Method 2: Manual Download**\n\nDownload `CC-Switch-v{version}-macOS.zip` from the [Releases](../../releases) page and extract to use.\n\n> **Note**: Since the author doesn't have an Apple Developer account, you may see an \"unidentified developer\" warning on first launch. Please close it first, then go to \"System Settings\" ‚Üí \"Privacy & Security\" ‚Üí click \"Open Anyway\", and you'll be able to open it normally afterwards.\n\n### ArchLinux Áî®Êà∑\n\n**Install via paru (Recommended)**\n\n```bash\nparu -S cc-switch-bin\n```\n\n### Linux Users\n\nDownload the latest Linux build from the [Releases](../../releases) page:\n\n- `CC-Switch-v{version}-Linux.deb` (Debian/Ubuntu)\n- `CC-Switch-v{version}-Linux.rpm` (Fedora/RHEL/openSUSE)\n- `CC-Switch-v{version}-Linux.AppImage` (Universal)\n- `CC-Switch-v{version}-Linux.flatpak` (Flatpak)\n\nFlatpak install & run:\n\n```bash\nflatpak install --user ./CC-Switch-v{version}-Linux.flatpak\nflatpak run com.ccswitch.desktop\n```\n\n## Quick Start\n\n### Basic Usage\n\n1. **Add Provider**: Click \"Add Provider\" ‚Üí Choose preset or create custom configuration\n2. **Switch Provider**:\n   - Main UI: Select provider ‚Üí Click \"Enable\"\n   - System Tray: Click provider name directly (instant effect)\n3. **Takes Effect**: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes\n4. **Back to Official**: Select the \"Official Login\" preset (Claude/Codex) or \"Google Official\" preset (Gemini), restart the corresponding client, then follow its login/OAuth flow\n\n### MCP Management\n\n- **Location**: Click \"MCP\" button in top-right corner\n- **Add Server**:\n  - Use built-in templates (mcp-fetch, mcp-filesystem, etc.)\n  - Support stdio / http / sse transport types\n  - Configure independent MCP servers for different apps\n- **Enable/Disable**: Toggle switches to control which servers sync to live config\n- **Sync**: Enabled servers auto-sync to each app's live files\n- **Import/Export**: Import existing MCP servers from Claude/Codex/Gemini config files\n\n### Skills Management (v3.7.0 New)\n\n- **Location**: Click \"Skills\" button in top-right corner\n- **Discover Skills**:\n  - Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)\n  - Add custom repositories (supports subdirectory scanning)\n- **Install Skills**: Click \"Install\" to one-click install to `~/.claude/skills/`\n- **Uninstall Skills**: Click \"Uninstall\" to safely remove and clean up state\n- **Manage Repositories**: Add/remove custom GitHub repositories\n\n### Prompts Management (v3.7.0 New)\n\n- **Location**: Click \"Prompts\" button in top-right corner\n- **Create Presets**:\n  - Create unlimited system prompt presets\n  - Use Markdown editor to write prompts (syntax highlighting + real-time preview)\n- **Switch Presets**: Select preset ‚Üí Click \"Activate\" to apply immediately\n- **Sync Mechanism**:\n  - Claude: `~/.claude/CLAUDE.md`\n  - Codex: `~/.codex/AGENTS.md`\n  - Gemini: `~/.gemini/GEMINI.md`\n- **Protection Mechanism**: Auto-save current prompt content before switching, preserves manual modifications\n\n### Configuration Files\n\n**Claude Code**\n\n- Live config: `~/.claude/settings.json` (or `claude.json`)\n- API key field: `env.ANTHROPIC_AUTH_TOKEN` or `env.ANTHROPIC_API_KEY`\n- MCP servers: `~/.claude.json` ‚Üí `mcpServers`\n\n**Codex**\n\n- Live config: `~/.codex/auth.json` (required) + `config.toml` (optional)\n- API key field: `OPENAI_API_KEY` in `auth.json`\n- MCP servers: `~/.codex/config.toml` ‚Üí `[mcp_servers]` tables\n\n**Gemini**\n\n- Live config: `~/.gemini/.env` (API key) + `~/.gemini/settings.json` (auth mode)\n- API key field: `GEMINI_API_KEY` or `GOOGLE_GEMINI_API_KEY` in `.env`\n- Environment variables: Support `GOOGLE_GEMINI_BASE_URL`, `GEMINI_MODEL`, etc.\n- MCP servers: `~/.gemini/settings.json` ‚Üí `mcpServers`\n- Tray quick switch: Each provider switch rewrites `~/.gemini/.env`, no need to restart Gemini CLI\n\n**CC Switch Storage (v3.8.0 New Architecture)**\n\n- Database (SSOT): `~/.cc-switch/cc-switch.db` (SQLite, stores providers, MCP, Prompts, Skills)\n- Local settings: `~/.cc-switch/settings.json` (device-level settings)\n- Backups: `~/.cc-switch/backups/` (auto-rotate, keep 10)\n\n### Cloud Sync Setup\n\n1. Go to Settings ‚Üí \"Custom Configuration Directory\"\n2. Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)\n3. Restart app to apply\n4. Repeat on other devices to enable cross-device sync\n\n> **Note**: First launch auto-imports existing Claude/Codex configs as default provider.\n\n## Architecture Overview\n\n### Design Principles\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                    Frontend (React + TS)                    ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ  ‚îÇ Components  ‚îÇ  ‚îÇ    Hooks     ‚îÇ  ‚îÇ  TanStack Query  ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ   (UI)      ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Logic) ‚îÇ‚îÄ‚îÄ‚îÇ   (Cache/Sync)   ‚îÇ    ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                         ‚îÇ Tauri IPC\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                  Backend (Tauri + Rust)                     ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ  ‚îÇ  Commands   ‚îÇ  ‚îÇ   Services   ‚îÇ  ‚îÇ  Models/Config   ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ (API Layer) ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Layer) ‚îÇ‚îÄ‚îÄ‚îÇ     (Data)       ‚îÇ    ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**Core Design Patterns**\n\n- **SSOT** (Single Source of Truth): All data stored in `~/.cc-switch/cc-switch.db` (SQLite)\n- **Dual-layer Storage**: SQLite for syncable data, JSON for device-level settings\n- **Dual-way Sync**: Write to live files on switch, backfill from live when editing active provider\n- **Atomic Writes**: Temp file + rename pattern prevents config corruption\n- **Concurrency Safe**: Mutex-protected database connection avoids race conditions\n- **Layered Architecture**: Clear separation (Commands ‚Üí Services ‚Üí DAO ‚Üí Database)\n\n**Key Components**\n\n- **ProviderService**: Provider CRUD, switching, backfill, sorting\n- **McpService**: MCP server management, import/export, live file sync\n- **ConfigService**: Config import/export, backup rotation\n- **SpeedtestService**: API endpoint latency measurement\n\n**v3.6 Refactoring**\n\n- Backend: 5-phase refactoring (error handling ‚Üí command split ‚Üí tests ‚Üí services ‚Üí concurrency)\n- Frontend: 4-stage refactoring (test infra ‚Üí hooks ‚Üí components ‚Üí cleanup)\n- Testing: 100% hooks coverage + integration tests (vitest + MSW)\n\n## Development\n\n### Environment Requirements\n\n- Node.js 18+\n- pnpm 8+\n- Rust 1.85+\n- Tauri CLI 2.8+\n\n### Development Commands\n\n```bash\n# Install dependencies\npnpm install\n\n# Dev mode (hot reload)\npnpm dev\n\n# Type check\npnpm typecheck\n\n# Format code\npnpm format\n\n# Check code format\npnpm format:check\n\n# Run frontend unit tests\npnpm test:unit\n\n# Run tests in watch mode (recommended for development)\npnpm test:unit:watch\n\n# Build application\npnpm build\n\n# Build debug version\npnpm tauri build --debug\n```\n\n### Rust Backend Development\n\n```bash\ncd src-tauri\n\n# Format Rust code\ncargo fmt\n\n# Run clippy checks\ncargo clippy\n\n# Run backend tests\ncargo test\n\n# Run specific tests\ncargo test test_name\n\n# Run tests with test-hooks feature\ncargo test --features test-hooks\n```\n\n### Testing Guide (v3.6 New)\n\n**Frontend Testing**:\n\n- Uses **vitest** as test framework\n- Uses **MSW (Mock Service Worker)** to mock Tauri API calls\n- Uses **@testing-library/react** for component testing\n\n**Test Coverage**:\n\n- Hooks unit tests (100% coverage)\n  - `useProviderActions` - Provider operations\n  - `useMcpActions` - MCP management\n  - `useSettings` series - Settings management\n  - `useImportExport` - Import/export\n- Integration tests\n  - App main application flow\n  - SettingsDialog complete interaction\n  - MCP panel functionality\n\n**Running Tests**:\n\n```bash\n# Run all tests\npnpm test:unit\n\n# Watch mode (auto re-run)\npnpm test:unit:watch\n\n# With coverage report\npnpm test:unit --coverage\n```\n\n## Tech Stack\n\n**Frontend**: React 18 ¬∑ TypeScript ¬∑ Vite ¬∑ TailwindCSS 4 ¬∑ TanStack Query v5 ¬∑ react-i18next ¬∑ react-hook-form ¬∑ zod ¬∑ shadcn/ui ¬∑ @dnd-kit\n\n**Backend**: Tauri 2.8 ¬∑ Rust ¬∑ serde ¬∑ tokio ¬∑ thiserror ¬∑ tauri-plugin-updater/process/dialog/store/log\n\n**Testing**: vitest ¬∑ MSW ¬∑ @testing-library/react\n\n## Project Structure\n\n```\n‚îú‚îÄ‚îÄ src/                      # Frontend (React + TypeScript)\n‚îÇ   ‚îú‚îÄ‚îÄ components/           # UI components (providers/settings/mcp/ui)\n‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Custom hooks (business logic)\n‚îÇ   ‚îú‚îÄ‚îÄ lib/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/              # Tauri API wrapper (type-safe)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query/            # TanStack Query config\n‚îÇ   ‚îú‚îÄ‚îÄ i18n/locales/         # Translations (zh/en)\n‚îÇ   ‚îú‚îÄ‚îÄ config/               # Presets (providers/mcp)\n‚îÇ   ‚îî‚îÄ‚îÄ types/                # TypeScript definitions\n‚îú‚îÄ‚îÄ src-tauri/                # Backend (Rust)\n‚îÇ   ‚îî‚îÄ‚îÄ src/\n‚îÇ       ‚îú‚îÄ‚îÄ commands/         # Tauri command layer (by domain)\n‚îÇ       ‚îú‚îÄ‚îÄ services/         # Business logic layer\n‚îÇ       ‚îú‚îÄ‚îÄ app_config.rs     # Config data models\n‚îÇ       ‚îú‚îÄ‚îÄ provider.rs       # Provider domain models\n‚îÇ       ‚îú‚îÄ‚îÄ mcp.rs            # MCP sync & validation\n‚îÇ       ‚îî‚îÄ‚îÄ lib.rs            # App entry & tray menu\n‚îú‚îÄ‚îÄ tests/                    # Frontend tests\n‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Unit tests\n‚îÇ   ‚îî‚îÄ‚îÄ components/           # Integration tests\n‚îî‚îÄ‚îÄ assets/                   # Screenshots & partner resources\n```\n\n## Changelog\n\nSee [CHANGELOG.md](CHANGELOG.md) for version update details.\n\n## Legacy Electron Version\n\n[Releases](../../releases) retains v2.0.3 legacy Electron version\n\nIf you need legacy Electron code, you can pull the electron-legacy branch\n\n## Contributing\n\nIssues and suggestions are welcome!\n\nBefore submitting PRs, please ensure:\n\n- Pass type check: `pnpm typecheck`\n- Pass format check: `pnpm format:check`\n- Pass unit tests: `pnpm test:unit`\n- üí° For new features, please open an issue for discussion before submitting a PR\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=farion1231/cc-switch&type=Date)](https://www.star-history.com/#farion1231/cc-switch&Date)\n\n## License\n\nMIT ¬© Jason Young\n",
      "stars_today": 280
    },
    {
      "id": 914139037,
      "name": "SpotiFLAC",
      "full_name": "afkarxyz/SpotiFLAC",
      "description": "Get Spotify tracks in true FLAC from Tidal, Qobuz & Amazon Music ‚Äî no account required.",
      "html_url": "https://github.com/afkarxyz/SpotiFLAC",
      "stars": 3258,
      "forks": 174,
      "language": "TypeScript",
      "topics": [
        "spotify",
        "spotify-downloader",
        "wails"
      ],
      "created_at": "2025-01-09T02:43:06Z",
      "updated_at": "2026-01-17T01:01:07Z",
      "pushed_at": "2026-01-15T13:03:49Z",
      "open_issues": 25,
      "owner": {
        "login": "afkarxyz",
        "avatar_url": "https://avatars.githubusercontent.com/u/173781715?v=4"
      },
      "readme": "[![GitHub All Releases](https://img.shields.io/github/downloads/afkarxyz/SpotiFLAC/total?style=for-the-badge)](https://github.com/afkarxyz/SpotiFLAC/releases)\n\n<!-- ![Maintenance](https://maintenance.afkarxyz.fun?v=3) -->\n\n![Image](https://github.com/user-attachments/assets/a6e92fdd-2944-45c1-83e8-e23a26c827af)\n\n<div align=\"center\">\n\nGet Spotify tracks in true FLAC from Tidal, Qobuz & Amazon Music ‚Äî no account required.\n\n![Windows](https://img.shields.io/badge/Windows-10%2B-0078D6?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI1MTIiIGhlaWdodD0iNTEyIiB2aWV3Qm94PSIwIDAgMjAgMjAiPjxwYXRoIGZpbGw9IiNmZmZmZmYiIGZpbGwtcnVsZT0iZXZlbm9kZCIgZD0iTTIwIDEwLjg3M1YyMEw4LjQ3OSAxOC41MzdsLjAwMS03LjY2NEgyMFptLTEzLjEyIDBsLS4wMDEgNy40NjFMMCAxNy40NjF2LTYuNTg4aDYuODhaTTIwIDkuMjczSDguNDhsLS4wMDEtNy44MUwyMCAwdjkuMjczWk02Ljg3OSAxLjY2NmwuMDAxIDcuNjA3SDBWMi41MzlsNi44NzktLjg3M1oiLz48L3N2Zz4=)\n![macOS](https://img.shields.io/badge/macOS-10.13%2B-000000?style=for-the-badge&logo=apple&logoColor=white)\n![Linux](https://img.shields.io/badge/Linux-Any-FCC624?style=for-the-badge&logo=linux&logoColor=white)\n\n<a href=\"https://trendshift.io/repositories/15737\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/15737\" alt=\"afkarxyz%2FSpotiFLAC | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n</div>\n\n### [Download](https://github.com/afkarxyz/SpotiFLAC/releases)\n\n## Screenshot\n\n![Image](https://github.com/user-attachments/assets/eba25a4a-0eb9-4d88-9646-80c7658a7de6)\n\n## Other projects\n\n### [SpotiDownloader](https://github.com/afkarxyz/SpotiDownloader) \nGet Spotify tracks in MP3 and FLAC via the spotidownloader.com API.\n\n### [SpotubeDL](https://spotubedl.com)\nDownload Spotify Tracks, Albums, Playlists as MP3/OGG/Opus with High Quality.\n\n### [SpotiFLAC (Mobile)](https://github.com/zarzet/SpotiFLAC-Mobile)\nSpotiFLAC for Android & iOS ‚Äî maintained by [@zarzet](https://github.com/zarzet)\n\n## FAQ (Frequently Asked Questions)\n\n### Is this software free?\n\n_Yes. This software is completely free.\nYou do not need an account, login, or subscription.\nAll you need is an internet connection._\n\n### Can using this software get my Spotify account suspended or banned?\n\n_No.\nThis software has no connection to your Spotify account.\nSpotify data is obtained through reverse engineering of the Spotify Web Player, not through user authentication._\n\n### Where does the audio come from?\n\n_The audio is fetched using third-party APIs._\n\n### Why does metadata fetching sometimes fail?\n\n_This usually happens because your IP address has been rate-limited.\nYou can wait and try again later, or use a VPN to bypass the rate limit._\n\n### Why does Windows Defender or antivirus flag or delete the file?\n\n_This is a false positive.\nIt likely happens because the executable is compressed using UPX._\n\n_If you are concerned, you can fork the repository and build the software yourself from source._\n\n### Want to support the project?\n\n_If this software is useful and brings you value,\nconsider supporting the project by buying me a coffee.\nYour support helps keep development going._\n\n[![Ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/afkarxyz)\n\n## Disclaimer\n\nThis project is for **educational and private use only**. The developer does not condone or encourage copyright infringement.\n\n**SpotiFLAC** is a third-party tool and is not affiliated with, endorsed by, or connected to Spotify, Tidal, Qobuz, Amazon Music, or any other streaming service.\n\nYou are solely responsible for:\n1. Ensuring your use of this software complies with your local laws.\n2. Reading and adhering to the Terms of Service of the respective platforms.\n3. Any legal consequences resulting from the misuse of this tool.\n\nThe software is provided \"as is\", without warranty of any kind. The author assumes no liability for any bans, damages, or legal issues arising from its use.\n\n## API Credits\n\n- **Tidal**: [hifi-api](https://github.com/binimum/hifi-api)\n- **Qobuz**: [dabmusic.xyz](https://dabmusic.xyz), [squid.wtf](https://squid.wtf)\n- **Amazon Music**: [doubledouble.top](https://doubledouble.top), [lucida.to](https://lucida.to)\n\n> [!TIP]\n>\n> **Star Us**, You will receive all release notifications from GitHub without any delay ~\n",
      "stars_today": 255
    },
    {
      "id": 615869301,
      "name": "LocalAI",
      "full_name": "mudler/LocalAI",
      "description": ":robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, MCP, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference",
      "html_url": "https://github.com/mudler/LocalAI",
      "stars": 42089,
      "forks": 3444,
      "language": "Go",
      "topics": [
        "ai",
        "api",
        "audio-generation",
        "decentralized",
        "distributed",
        "gemma",
        "image-generation",
        "libp2p",
        "llama",
        "llm",
        "mamba",
        "mcp",
        "mistral",
        "musicgen",
        "object-detection",
        "rerank",
        "rwkv",
        "stable-diffusion",
        "text-generation",
        "tts"
      ],
      "created_at": "2023-03-18T22:58:02Z",
      "updated_at": "2026-01-16T23:57:02Z",
      "pushed_at": "2026-01-16T22:20:59Z",
      "open_issues": 155,
      "owner": {
        "login": "mudler",
        "avatar_url": "https://avatars.githubusercontent.com/u/2420543?v=4"
      },
      "readme": "<h1 align=\"center\">\n  <br>\n  <img width=\"300\" src=\"./core/http/static/logo.png\"> <br>\n<br>\n</h1>\n\n<p align=\"center\">\n<a href=\"https://github.com/go-skynet/LocalAI/fork\" target=\"blank\">\n<img src=\"https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge\" alt=\"LocalAI forks\"/>\n</a>\n<a href=\"https://github.com/go-skynet/LocalAI/stargazers\" target=\"blank\">\n<img src=\"https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge\" alt=\"LocalAI stars\"/>\n</a>\n<a href=\"https://github.com/go-skynet/LocalAI/pulls\" target=\"blank\">\n<img src=\"https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge\" alt=\"LocalAI pull-requests\"/>\n</a>\n<a href='https://github.com/go-skynet/LocalAI/releases'>\n<img src='https://img.shields.io/github/release/go-skynet/LocalAI?&label=Latest&style=for-the-badge'>\n</a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://hub.docker.com/r/localai/localai\" target=\"blank\">\n<img src=\"https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker\" alt=\"LocalAI Docker hub\"/>\n</a>\n<a href=\"https://quay.io/repository/go-skynet/local-ai?tab=tags&tag=latest\" target=\"blank\">\n<img src=\"https://img.shields.io/badge/quay.io-images-important.svg?\" alt=\"LocalAI Quay.io\"/>\n</a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://twitter.com/LocalAI_API\" target=\"blank\">\n<img src=\"https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&logo=X&logoColor=white&label=LocalAI_API\" alt=\"Follow LocalAI_API\"/>\n</a>\n<a href=\"https://discord.gg/uJAeKSAGDy\" target=\"blank\">\n<img src=\"https://img.shields.io/badge/dynamic/json?color=blue&label=Discord&style=for-the-badge&query=approximate_member_count&url=https%3A%2F%2Fdiscordapp.com%2Fapi%2Finvites%2FuJAeKSAGDy%3Fwith_counts%3Dtrue&logo=discord\" alt=\"Join LocalAI Discord Community\"/>\n</a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/5539\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/5539\" alt=\"mudler%2FLocalAI | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n> :bulb: Get help - [‚ùìFAQ](https://localai.io/faq/) [üí≠Discussions](https://github.com/go-skynet/LocalAI/discussions) [:speech_balloon: Discord](https://discord.gg/uJAeKSAGDy) [:book: Documentation website](https://localai.io/)\n>\n> [üíª Quickstart](https://localai.io/basics/getting_started/) [üñºÔ∏è Models](https://models.localai.io/) [üöÄ Roadmap](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap) [üõ´ Examples](https://github.com/mudler/LocalAI-examples) Try on \n[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white)](https://t.me/localaiofficial_bot)\n\n[![tests](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml)[![Build and Release](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml)[![build container images](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml)[![Bump dependencies](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml)[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai)](https://artifacthub.io/packages/search?repo=localai)\n\n**LocalAI** is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by [Ettore Di Giacinto](https://github.com/mudler).\n\n\n## üìöüÜï Local Stack Family\n\nüÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:\n\n<table>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <a href=\"https://github.com/mudler/LocalAGI\">\n        <img src=\"https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png\" width=\"300\" alt=\"LocalAGI Logo\">\n      </a>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <h3><a href=\"https://github.com/mudler/LocalAGI\">LocalAGI</a></h3>\n      <p>A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI's Responses API, enhanced with advanced agentic capabilities.</p>\n    </td>\n  </tr>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <a href=\"https://github.com/mudler/LocalRecall\">\n        <img src=\"https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png\" width=\"300\" alt=\"LocalRecall Logo\">\n      </a>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <h3><a href=\"https://github.com/mudler/LocalRecall\">LocalRecall</a></h3>\n      <p>A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.</p>\n    </td>\n  </tr>\n</table>\n\n## Screenshots / Video\n\n### Youtube video\n\n<h1 align=\"center\">\n  <br>\n  <a href=\"https://www.youtube.com/watch?v=PDqYhB9nNHA\" target=\"_blank\"> <img width=\"300\" src=\"https://img.youtube.com/vi/PDqYhB9nNHA/0.jpg\"> </a><br>\n<br>\n</h1>\n\n\n### Screenshots\n\n| Talk Interface | Generate Audio |\n| --- | --- |\n| ![Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk](./docs/assets/images/screenshots/screenshot_tts.png) | ![Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low](./docs/assets/images/screenshots/screenshot_tts.png) |\n\n| Models Overview | Generate Images |\n| --- | --- |\n| ![Screenshot 2025-03-31 at 12-01-20 LocalAI - Models](./docs/assets/images/screenshots/screenshot_gallery.png) | ![Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev](./docs/assets/images/screenshots/screenshot_image.png) |\n\n| Chat Interface | Home |\n| --- | --- |\n| ![Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5](./docs/assets/images/screenshots/screenshot_chat.png) | ![Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)](./docs/assets/images/screenshots/screenshot_home.png) |\n\n| Login | Swarm |\n| --- | --- |\n|![Screenshot 2025-03-31 at 12-09-59 ](./docs/assets/images/screenshots/screenshot_login.png) | ![Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard](./docs/assets/images/screenshots/screenshot_p2p.png) |\n\n## üíª Quickstart\n\n> ‚ö†Ô∏è **Note:** The `install.sh` script is currently experiencing issues due to the heavy changes currently undergoing in LocalAI and may produce broken or misconfigured installations. Please use Docker installation (see below) or manual binary installation until [issue #8032](https://github.com/mudler/LocalAI/issues/8032) is resolved.\n\nRun the installer script:\n\n```bash\n# Basic installation\ncurl https://localai.io/install.sh | sh\n```\n\nFor more installation options, see [Installer Options](https://localai.io/installation/).\n\n### macOS Download:\n\n<a href=\"https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg\">\n  <img src=\"https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&logo=apple&logoColor=white\" alt=\"Download LocalAI for macOS\"/>\n</a>\n\n> Note: the DMGs are not signed by Apple as quarantined. See https://github.com/mudler/LocalAI/issues/6268 for a workaround, fix is tracked here: https://github.com/mudler/LocalAI/issues/6244\n\n### Containers (Docker, podman, ...)\n\n> **üí° Docker Run vs Docker Start**\n> \n> - `docker run` creates and starts a new container. If a container with the same name already exists, this command will fail.\n> - `docker start` starts an existing container that was previously created with `docker run`.\n> \n> If you've already run LocalAI before and want to start it again, use: `docker start -i local-ai`\n\n#### CPU only image:\n\n```bash\ndocker run -ti --name local-ai -p 8080:8080 localai/localai:latest\n```\n\n#### NVIDIA GPU Images:\n\n```bash\n# CUDA 13.0\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-13\n\n# CUDA 12.0\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12\n\n# NVIDIA Jetson (L4T) ARM64\n# CUDA 12 (for Nvidia AGX Orin and similar platforms)\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64\n\n# CUDA 13 (for Nvidia DGX Spark)\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64-cuda-13\n```\n\n#### AMD GPU Images (ROCm):\n\n```bash\ndocker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas\n```\n\n#### Intel GPU Images (oneAPI):\n\n```bash\ndocker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel\n```\n\n#### Vulkan GPU Images:\n\n```bash\ndocker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan\n```\n\n#### AIO Images (pre-downloaded models):\n\n```bash\n# CPU version\ndocker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu\n\n# NVIDIA CUDA 13 version\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-13\n\n# NVIDIA CUDA 12 version\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12\n\n# Intel GPU version\ndocker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel\n\n# AMD GPU version\ndocker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas\n```\n\nFor more information about the AIO images and pre-downloaded models, see [Container Documentation](https://localai.io/basics/container/).\n\nTo load models:\n\n```bash\n# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)\nlocal-ai run llama-3.2-1b-instruct:q4_k_m\n# Start LocalAI with the phi-2 model directly from huggingface\nlocal-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf\n# Install and run a model from the Ollama OCI registry\nlocal-ai run ollama://gemma:2b\n# Run a model from a configuration file\nlocal-ai run https://gist.githubusercontent.com/.../phi-2.yaml\n# Install and run a model from a standard OCI registry (e.g., Docker Hub)\nlocal-ai run oci://localai/phi-2:latest\n```\n\n> ‚ö° **Automatic Backend Detection**: When you install models from the gallery or YAML files, LocalAI automatically detects your system's GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see [GPU Acceleration](https://localai.io/features/gpu-acceleration/#automatic-backend-detection).\n\nFor more information, see [üíª Getting started](https://localai.io/basics/getting_started/index.html), if you are interested in our roadmap items and future enhancements, you can see the [Issues labeled as Roadmap here](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)\n\n## üì∞ Latest project news\n\n- December 2025: [Dynamic Memory Resource reclaimer](https://github.com/mudler/LocalAI/pull/7583), [Automatic fitting of models to multiple GPUS(llama.cpp)](https://github.com/mudler/LocalAI/pull/7584), [Added Vibevoice backend](https://github.com/mudler/LocalAI/pull/7494)\n- November 2025: Major improvements to the UX. Among these: [Import models via URL](https://github.com/mudler/LocalAI/pull/7245) and [Multiple chats and history](https://github.com/mudler/LocalAI/pull/7325)\n- October 2025: üîå [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) support added for agentic capabilities with external tools\n- September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.\n- August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with `development` suffix in the gallery ): https://github.com/mudler/LocalAI/pull/6049 https://github.com/mudler/LocalAI/pull/6119 https://github.com/mudler/LocalAI/pull/6121 https://github.com/mudler/LocalAI/pull/6060\n- July/August 2025: üîç [Object Detection](https://localai.io/features/object-detection/) added to the API featuring [rf-detr](https://github.com/roboflow/rf-detr)\n- July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. [Read the release notes](https://github.com/mudler/LocalAI/releases/tag/v3.2.0)\n- June 2025: [Backend management](https://github.com/mudler/LocalAI/pull/5607) has been added. Attention: extras images are going to be deprecated from the next release! Read [the backend management PR](https://github.com/mudler/LocalAI/pull/5607).\n- May 2025: [Audio input](https://github.com/mudler/LocalAI/pull/5466) and [Reranking](https://github.com/mudler/LocalAI/pull/5396) in llama.cpp backend, [Realtime API](https://github.com/mudler/LocalAI/pull/5392),  Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).\n- May 2025: Important: image name changes [See release](https://github.com/mudler/LocalAI/releases/tag/v2.29.0)\n- Apr 2025: Rebrand, WebUI enhancements\n- Apr 2025: [LocalAGI](https://github.com/mudler/LocalAGI) and [LocalRecall](https://github.com/mudler/LocalRecall) join the LocalAI family stack.\n- Apr 2025: WebUI overhaul, AIO images updates\n- Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images\n- Jan 2025: LocalAI model release: https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3, SANA support in diffusers: https://github.com/mudler/LocalAI/pull/4603\n- Dec 2024: stablediffusion.cpp backend (ggml) added ( https://github.com/mudler/LocalAI/pull/4289 )\n- Nov 2024: Bark.cpp backend added ( https://github.com/mudler/LocalAI/pull/4287 )\n- Nov 2024: Voice activity detection models (**VAD**) added to the API: https://github.com/mudler/LocalAI/pull/4204\n- Oct 2024: examples moved to [LocalAI-examples](https://github.com/mudler/LocalAI-examples)\n- Aug 2024:  üÜï FLUX-1, [P2P Explorer](https://explorer.localai.io)\n- July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: https://github.com/mudler/LocalAI/pull/2723. P2P Global community pools: https://github.com/mudler/LocalAI/issues/3113\n- May 2024: üî•üî• Decentralized P2P llama.cpp:  https://github.com/mudler/LocalAI/pull/2343 (peer2peer llama.cpp!) üëâ Docs  https://localai.io/features/distribute/\n- May 2024: üî•üî• Distributed inferencing: https://github.com/mudler/LocalAI/pull/2324\n- April 2024: Reranker API: https://github.com/mudler/LocalAI/pull/2121\n\nRoadmap items: [List of issues](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)\n\n## üöÄ [Features](https://localai.io/features/)\n\n- üß© [Backend Gallery](https://localai.io/backends/): Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.\n- üìñ [Text generation with GPTs](https://localai.io/features/text-generation/) (`llama.cpp`, `transformers`, `vllm` ... [:book: and more](https://localai.io/model-compatibility/index.html#model-compatibility-table))\n- üó£ [Text to Audio](https://localai.io/features/text-to-audio/)\n- üîà [Audio to Text](https://localai.io/features/audio-to-text/) (Audio transcription with `whisper.cpp`)\n- üé® [Image generation](https://localai.io/features/image-generation)\n- üî• [OpenAI-alike tools API](https://localai.io/features/openai-functions/) \n- üß† [Embeddings generation for vector databases](https://localai.io/features/embeddings/)\n- ‚úçÔ∏è [Constrained grammars](https://localai.io/features/constrained_grammars/)\n- üñºÔ∏è [Download Models directly from Huggingface ](https://localai.io/models/)\n- ü•Ω [Vision API](https://localai.io/features/gpt-vision/)\n- üîç [Object Detection](https://localai.io/features/object-detection/)\n- üìà [Reranker API](https://localai.io/features/reranker/)\n- üÜïüñß [P2P Inferencing](https://localai.io/features/distribute/)\n- üÜïüîå [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) - Agentic capabilities with external tools and [LocalAGI's Agentic capabilities](https://github.com/mudler/LocalAGI)\n- üîä Voice activity detection (Silero-VAD support)\n- üåç Integrated WebUI!\n\n## üß© Supported Backends & Acceleration\n\nLocalAI supports a comprehensive range of AI backends with multiple acceleration options:\n\n### Text Generation & Language Models\n| Backend | Description | Acceleration Support |\n|---------|-------------|---------------------|\n| **llama.cpp** | LLM inference in C/C++ | CUDA 12/13, ROCm, Intel SYCL, Vulkan, Metal, CPU |\n| **vLLM** | Fast LLM inference with PagedAttention | CUDA 12/13, ROCm, Intel |\n| **transformers** | HuggingFace transformers framework | CUDA 12/13, ROCm, Intel, CPU |\n| **exllama2** | GPTQ inference library | CUDA 12/13 |\n| **MLX** | Apple Silicon LLM inference | Metal (M1/M2/M3+) |\n| **MLX-VLM** | Apple Silicon Vision-Language Models | Metal (M1/M2/M3+) |\n\n### Audio & Speech Processing\n| Backend | Description | Acceleration Support |\n|---------|-------------|---------------------|\n| **whisper.cpp** | OpenAI Whisper in C/C++ | CUDA 12/13, ROCm, Intel SYCL, Vulkan, CPU |\n| **faster-whisper** | Fast Whisper with CTranslate2 | CUDA 12/13, ROCm, Intel, CPU |\n| **bark** | Text-to-audio generation | CUDA 12/13, ROCm, Intel |\n| **bark-cpp** | C++ implementation of Bark | CUDA, Metal, CPU |\n| **coqui** | Advanced TTS with 1100+ languages | CUDA 12/13, ROCm, Intel, CPU |\n| **kokoro** | Lightweight TTS model | CUDA 12/13, ROCm, Intel, CPU |\n| **chatterbox** | Production-grade TTS | CUDA 12/13, CPU |\n| **piper** | Fast neural TTS system | CPU |\n| **kitten-tts** | Kitten TTS models | CPU |\n| **silero-vad** | Voice Activity Detection | CPU |\n| **neutts** | Text-to-speech with voice cloning | CUDA 12/13, ROCm, CPU |\n| **vibevoice** | Real-time TTS with voice cloning | CUDA 12/13, ROCm, Intel, CPU |\n| **pocket-tts** | Lightweight CPU-based TTS | CUDA 12/13, ROCm, Intel, CPU |\n\n### Image & Video Generation\n| Backend | Description | Acceleration Support |\n|---------|-------------|---------------------|\n| **stablediffusion.cpp** | Stable Diffusion in C/C++ | CUDA 12/13, Intel SYCL, Vulkan, CPU |\n| **diffusers** | HuggingFace diffusion models | CUDA 12/13, ROCm, Intel, Metal, CPU |\n\n### Specialized AI Tasks\n| Backend | Description | Acceleration Support |\n|---------|-------------|---------------------|\n| **rfdetr** | Real-time object detection | CUDA 12/13, Intel, CPU |\n| **rerankers** | Document reranking API | CUDA 12/13, ROCm, Intel, CPU |\n| **local-store** | Vector database | CPU |\n| **huggingface** | HuggingFace API integration | API-based |\n\n### Hardware Acceleration Matrix\n\n| Acceleration Type | Supported Backends | Hardware Support |\n|-------------------|-------------------|------------------|\n| **NVIDIA CUDA 12** | All CUDA-compatible backends | Nvidia hardware |\n| **NVIDIA CUDA 13** | All CUDA-compatible backends | Nvidia hardware |\n| **AMD ROCm** | llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts, vibevoice, pocket-tts | AMD Graphics |\n| **Intel oneAPI** | llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark, vibevoice, pocket-tts | Intel Arc, Intel iGPUs |\n| **Apple Metal** | llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp | Apple M1/M2/M3+ |\n| **Vulkan** | llama.cpp, whisper, stablediffusion | Cross-platform GPUs |\n| **NVIDIA Jetson (CUDA 12)** | llama.cpp, whisper, stablediffusion, diffusers, rfdetr | ARM64 embedded AI (AGX Orin, etc.) |\n| **NVIDIA Jetson (CUDA 13)** | llama.cpp, whisper, stablediffusion, diffusers, rfdetr | ARM64 embedded AI (DGX Spark) |\n| **CPU Optimized** | All backends | AVX/AVX2/AVX512, quantization support |\n\n### üîó Community and integrations\n\nBuild and deploy custom containers:\n- https://github.com/sozercan/aikit\n\nWebUIs:\n- https://github.com/Jirubizu/localai-admin\n- https://github.com/go-skynet/LocalAI-frontend\n- QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) https://github.com/reid41/QA-Pilot\n\nAgentic Libraries:\n- https://github.com/mudler/cogito\n\nMCPs:\n- https://github.com/mudler/MCPs\n\nModel galleries\n- https://github.com/go-skynet/model-gallery\n\nVoice:\n- https://github.com/richiejp/VoxInput\n\nOther:\n- Helm chart https://github.com/go-skynet/helm-charts\n- VSCode extension https://github.com/badgooooor/localai-vscode-plugin\n- Langchain: https://python.langchain.com/docs/integrations/providers/localai/\n- Terminal utility https://github.com/djcopley/ShellOracle\n- Local Smart assistant https://github.com/mudler/LocalAGI\n- Home Assistant https://github.com/sammcj/homeassistant-localai / https://github.com/drndos/hass-openai-custom-conversation / https://github.com/valentinfrlch/ha-gpt4vision\n- Discord bot https://github.com/mudler/LocalAGI/tree/main/examples/discord\n- Slack bot https://github.com/mudler/LocalAGI/tree/main/examples/slack\n- Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) https://github.com/reid41/shell-pilot\n- Telegram bot https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot\n- Another Telegram Bot https://github.com/JackBekket/Hellper\n- Auto-documentation https://github.com/JackBekket/Reflexia\n- Github bot which answer on issues, with code and documentation as context https://github.com/JackBekket/GitHelper\n- Github Actions: https://github.com/marketplace/actions/start-localai\n- Examples: https://github.com/mudler/LocalAI/tree/master/examples/\n  \n\n### üîó Resources\n\n- [LLM finetuning guide](https://localai.io/docs/advanced/fine-tuning/)\n- [How to build locally](https://localai.io/basics/build/index.html)\n- [How to install in Kubernetes](https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes)\n- [Projects integrating LocalAI](https://localai.io/docs/integrations/)\n- [How tos section](https://io.midori-ai.xyz/howtos/) (curated by our community)\n\n## :book: üé• [Media, Blogs, Social](https://localai.io/basics/news/#media-blogs-social)\n\n- [Run Visual studio code with LocalAI (SUSE)](https://www.suse.com/c/running-ai-locally/)\n- üÜï [Run LocalAI on Jetson Nano Devkit](https://mudler.pm/posts/local-ai-jetson-nano-devkit/)\n- [Run LocalAI on AWS EKS with Pulumi](https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/)\n- [Run LocalAI on AWS](https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance)\n- [Create a slackbot for teams and OSS projects that answer to documentation](https://mudler.pm/posts/smart-slackbot-for-teams/)\n- [LocalAI meets k8sgpt](https://www.youtube.com/watch?v=PKrDNuJ_dfE)\n- [Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All](https://mudler.pm/posts/localai-question-answering/)\n- [Tutorial to use k8sgpt with LocalAI](https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65)\n\n## Citation\n\nIf you utilize this repository, data in a downstream project, please consider citing it with:\n\n```\n@misc{localai,\n  author = {Ettore Di Giacinto},\n  title = {LocalAI: The free, Open source OpenAI alternative},\n  year = {2023},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/go-skynet/LocalAI}},\n```\n\n## ‚ù§Ô∏è Sponsors\n\n> Do you find LocalAI useful?\n\nSupport the project by becoming [a backer or sponsor](https://github.com/sponsors/mudler). Your logo will show up here with a link to your website.\n\nA huge thank you to our generous sponsors who support this project covering CI expenses, and our [Sponsor list](https://github.com/sponsors/mudler):\n\n<p align=\"center\">\n  <a href=\"https://www.spectrocloud.com/\" target=\"blank\">\n    <img height=\"200\" src=\"https://github.com/user-attachments/assets/72eab1dd-8b93-4fc0-9ade-84db49f24962\">\n  </a>\n  <a href=\"https://www.premai.io/\" target=\"blank\">\n    <img height=\"200\" src=\"https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6\"> <br>\n  </a>\n</p>\n\n### Individual sponsors\n\nA special thanks to individual sponsors that contributed to the project, a full list is in [Github](https://github.com/sponsors/mudler) and [buymeacoffee](https://buymeacoffee.com/mudler), a special shout out goes to [drikster80](https://github.com/drikster80) for being generous. Thank you everyone!\n\n## üåü Star history\n\n[![LocalAI Star history Chart](https://api.star-history.com/svg?repos=go-skynet/LocalAI&type=Date)](https://star-history.com/#go-skynet/LocalAI&Date)\n\n## üìñ License\n\nLocalAI is a community-driven project created by [Ettore Di Giacinto](https://github.com/mudler/).\n\nMIT - Author Ettore Di Giacinto <mudler@localai.io>\n\n## üôá Acknowledgements\n\nLocalAI couldn't have been built without the help of great software already available from the community. Thank you!\n\n- [llama.cpp](https://github.com/ggerganov/llama.cpp)\n- https://github.com/tatsu-lab/stanford_alpaca\n- https://github.com/cornelk/llama-go for the initial ideas\n- https://github.com/antimatter15/alpaca.cpp\n- https://github.com/EdVince/Stable-Diffusion-NCNN\n- https://github.com/ggerganov/whisper.cpp\n- https://github.com/rhasspy/piper\n\n## ü§ó Contributors\n\nThis is a community project, a special thanks to our contributors! ü§ó\n<a href=\"https://github.com/go-skynet/LocalAI/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=go-skynet/LocalAI\" />\n</a>\n",
      "stars_today": 254
    },
    {
      "id": 327859577,
      "name": "juicefs",
      "full_name": "juicedata/juicefs",
      "description": "JuiceFS is a distributed POSIX file system built on top of Redis and S3.",
      "html_url": "https://github.com/juicedata/juicefs",
      "stars": 12978,
      "forks": 1142,
      "language": "Go",
      "topics": [
        "bigdata",
        "cloud-native",
        "distributed-systems",
        "filesystem",
        "go",
        "golang",
        "hdfs",
        "object-storage",
        "posix",
        "redis",
        "s3",
        "storage"
      ],
      "created_at": "2021-01-08T09:39:46Z",
      "updated_at": "2026-01-17T01:01:27Z",
      "pushed_at": "2026-01-16T16:51:53Z",
      "open_issues": 157,
      "owner": {
        "login": "juicedata",
        "avatar_url": "https://avatars.githubusercontent.com/u/27241737?v=4"
      },
      "readme": "<p align=\"center\"><a href=\"https://github.com/juicedata/juicefs\"><img alt=\"JuiceFS Logo\" src=\"docs/en/images/juicefs-logo-new.svg\" width=\"50%\" /></a></p>\n<p align=\"center\">\n    <a href=\"https://github.com/juicedata/juicefs/releases/latest\"><img alt=\"Latest Stable Release\" src=\"https://img.shields.io/github/v/release/juicedata/juicefs\" /></a>\n    <a href=\"https://github.com/juicedata/juicefs/actions/workflows/unittests.yml\"><img alt=\"GitHub Workflow Status\" src=\"https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/unittests.yml?branch=main&label=Unit%20Testing\" /></a>\n    <a href=\"https://github.com/juicedata/juicefs/actions/workflows/integrationtests.yml\"><img alt=\"GitHub Workflow Status\" src=\"https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/integrationtests.yml?branch=main&label=Integration%20Testing\" /></a>\n    <a href=\"https://goreportcard.com/report/github.com/juicedata/juicefs\"><img alt=\"Go Report\" src=\"https://goreportcard.com/badge/github.com/juicedata/juicefs\" /></a>\n    <a href=\"https://juicefs.com/docs/community/introduction\"><img alt=\"English doc\" src=\"https://img.shields.io/badge/docs-Doc%20Center-brightgreen\" /></a>\n    <a href=\"https://go.juicefs.com/slack\"><img alt=\"Join Slack\" src=\"https://badgen.net/badge/Slack/Join%20JuiceFS/0abd59?icon=slack\" /></a>\n</p>\n\n**JuiceFS** is a high-performance [POSIX](https://en.wikipedia.org/wiki/POSIX) file system released under Apache License 2.0, particularly designed for the cloud-native environment. The data, stored via JuiceFS, will be persisted in Object Storage _(e.g. Amazon S3)_, and the corresponding metadata can be persisted in various compatible database engines such as Redis, MySQL, and TiKV based on the scenarios and requirements.\n\nWith JuiceFS, massive cloud storage can be directly connected to big data, machine learning, artificial intelligence, and various application platforms in production environments. Without modifying code, the massive cloud storage can be used as efficiently as local storage.\n\nüìñ **Document**: [Quick Start Guide](https://juicefs.com/docs/community/quick_start_guide)\n\n## Highlighted Features\n\n1. **Fully POSIX-compatible**: Use as a local file system, seamlessly docking with existing applications without breaking business workflow.\n2. **Fully Hadoop-compatible**: JuiceFS' [Hadoop Java SDK](https://juicefs.com/docs/community/hadoop_java_sdk) is compatible with Hadoop 2.x and Hadoop 3.x as well as a variety of components in the Hadoop ecosystems.\n3. **S3-compatible**:  JuiceFS' [S3 Gateway](https://juicefs.com/docs/community/s3_gateway) provides an S3-compatible interface.\n4. **Cloud Native**: A [Kubernetes CSI Driver](https://juicefs.com/docs/community/how_to_use_on_kubernetes) is provided for easily using JuiceFS in Kubernetes.\n5. **Shareable**: JuiceFS is a shared file storage that can be read and written by thousands of clients.\n6. **Strong Consistency**: The confirmed modification will be immediately visible on all the servers mounted with the same file system.\n7. **Outstanding Performance**: The latency can be as low as a few milliseconds, and the throughput can be expanded nearly unlimitedly _(depending on the size of the Object Storage)_. [Test results](https://juicefs.com/docs/community/benchmark)\n8. **Data Encryption**: Supports data encryption in transit and at rest (please refer to [the guide](https://juicefs.com/docs/community/security/encrypt) for more information).\n9. **Global File Locks**: JuiceFS supports both BSD locks (flock) and POSIX record locks (fcntl).\n10. **Data Compression**: JuiceFS supports [LZ4](https://lz4.github.io/lz4) or [Zstandard](https://facebook.github.io/zstd) to compress all your data.\n\n---\n\n[Architecture](#architecture) | [Getting Started](#getting-started) | [Advanced Topics](#advanced-topics) | [POSIX Compatibility](#posix-compatibility) | [Performance Benchmark](#performance-benchmark) | [Supported Object Storage](#supported-object-storage) | [Who is using](#who-is-using) | [Roadmap](#roadmap) | [Reporting Issues](#reporting-issues) | [Contributing](#contributing) | [Community](#community) | [Usage Tracking](#usage-tracking) | [License](#license) | [Credits](#credits) | [FAQ](#faq)\n\n---\n\n## Architecture\n\nJuiceFS consists of three parts:\n\n1. **JuiceFS Client**: Coordinates Object Storage and metadata storage engine as well as implementation of file system interfaces such as POSIX, Hadoop, Kubernetes, and S3 gateway.\n2. **Data Storage**: Stores data, with supports of a variety of data storage media, e.g., local disk, public or private cloud Object Storage, and HDFS.\n3. **Metadata Engine**: Stores the corresponding metadata that contains information of file name, file size, permission group, creation and modification time and directory structure, etc., with supports of different metadata engines, e.g., Redis, MySQL, SQLite and TiKV.\n\n![JuiceFS Architecture](docs/en/images/juicefs-arch-new.png)\n\nJuiceFS can store the metadata of file system on different metadata engines, like Redis, which is a fast, open-source, in-memory key-value data storage, particularly suitable for storing metadata; meanwhile, all the data will be stored in Object Storage through JuiceFS client. [Learn more](https://juicefs.com/docs/community/architecture)\n\n![data-structure-diagram](docs/en/images/data-structure-diagram.svg)\n\nEach file stored in JuiceFS is split into **\"Chunk\"** s at a fixed size with the default upper limit of 64 MiB. Each Chunk is composed of one or more **\"Slice\"**(s), and the length of the slice varies depending on how the file is written. Each slice is composed of size-fixed **\"Block\"** s, which are 4 MiB by default. These blocks will be stored in Object Storage in the end; at the same time, the metadata information of the file and its Chunks, Slices, and Blocks will be stored in metadata engines via JuiceFS. [Learn more](https://juicefs.com/docs/community/architecture/#how-juicefs-store-files)\n\n![How JuiceFS stores your files](docs/en/images/how-juicefs-stores-files.svg)\n\nWhen using JuiceFS, files will eventually be split into Chunks, Slices and Blocks and stored in Object Storage. Therefore, the source files stored in JuiceFS cannot be found in the file browser of the Object Storage platform; instead, there are only a chunks directory and a bunch of digitally numbered directories and files in the bucket. Don't panic! This is just the secret of the high-performance operation of JuiceFS!\n\n## Getting Started\n\nBefore you begin, make sure you have:\n\n1. One supported metadata engine, see [How to Set Up Metadata Engine](https://juicefs.com/docs/community/databases_for_metadata)\n2. One supported Object Storage for storing data blocks, see [Supported Object Storage](https://juicefs.com/docs/community/how_to_setup_object_storage)\n3. [JuiceFS Client](https://juicefs.com/docs/community/installation) downloaded and installed\n\nPlease refer to [Quick Start Guide](https://juicefs.com/docs/community/quick_start_guide) to start using JuiceFS right away!\n\n### Command Reference\n\nCheck out all the command line options in [command reference](https://juicefs.com/docs/community/command_reference).\n\n### Containers\n\nJuiceFS can be used as a persistent volume for Docker and Podman, please check [here](https://juicefs.com/docs/community/juicefs_on_docker) for details.\n\n### Kubernetes\n\nIt is also very easy to use JuiceFS on Kubernetes. Please find more information [here](https://juicefs.com/docs/community/how_to_use_on_kubernetes).\n\n### Hadoop Java SDK\n\nIf you wanna use JuiceFS in Hadoop, check [Hadoop Java SDK](https://juicefs.com/docs/community/hadoop_java_sdk).\n\n## Advanced Topics\n\n- [Redis Best Practices](https://juicefs.com/docs/community/redis_best_practices)\n- [How to Setup Object Storage](https://juicefs.com/docs/community/how_to_setup_object_storage)\n- [Cache](https://juicefs.com/docs/community/cache)\n- [Fault Diagnosis and Analysis](https://juicefs.com/docs/community/fault_diagnosis_and_analysis)\n- [FUSE Mount Options](https://juicefs.com/docs/community/fuse_mount_options)\n- [Using JuiceFS on Windows](https://juicefs.com/docs/community/installation#windows)\n- [S3 Gateway](https://juicefs.com/docs/community/s3_gateway)\n\nPlease refer to [JuiceFS Document Center](https://juicefs.com/docs/community/introduction) for more information.\n\n## POSIX Compatibility\n\nJuiceFS has passed all of the compatibility tests (8813 in total) in the latest [pjdfstest](https://github.com/pjd/pjdfstest) .\n\n```\nAll tests successful.\n\nTest Summary Report\n-------------------\n/root/soft/pjdfstest/tests/chown/00.t          (Wstat: 0 Tests: 1323 Failed: 0)\n  TODO passed:   693, 697, 708-709, 714-715, 729, 733\nFiles=235, Tests=8813, 233 wallclock secs ( 2.77 usr  0.38 sys +  2.57 cusr  3.93 csys =  9.65 CPU)\nResult: PASS\n```\n\nAside from the POSIX features covered by pjdfstest, JuiceFS also provides:\n\n- **Close-to-open consistency**. Once a file is written _and_ closed, it is guaranteed to view the written data in the following opens and reads from any client. Within the same mount point, all the written data can be read immediately.\n- Rename and all other metadata operations are atomic, which are guaranteed by supported metadata engine transaction.\n- Opened files remain accessible after unlink from same mount point.\n- Mmap (tested with FSx).\n- Fallocate with punch hole support.\n- Extended attributes (xattr).\n- BSD locks (flock).\n- POSIX record locks (fcntl).\n\n## Performance Benchmark\n\n### Basic benchmark\n\nJuiceFS provides a subcommand that can run a few basic benchmarks to help you understand how it works in your environment:\n\n![JuiceFS Bench](docs/en/images/juicefs-bench.png)\n\n### Throughput\n\nA sequential read/write benchmark has also been performed on JuiceFS, [EFS](https://aws.amazon.com/efs) and [S3FS](https://github.com/s3fs-fuse/s3fs-fuse) by [fio](https://github.com/axboe/fio).\n\n![Sequential Read Write Benchmark](docs/en/images/sequential-read-write-benchmark.svg)\n\nAbove result figure shows that JuiceFS can provide 10X more throughput than the other two (see [more details](https://juicefs.com/docs/community/fio)).\n\n### Metadata IOPS\n\nA simple mdtest benchmark has been performed on JuiceFS, [EFS](https://aws.amazon.com/efs) and [S3FS](https://github.com/s3fs-fuse/s3fs-fuse) by [mdtest](https://github.com/hpc/ior).\n\n![Metadata Benchmark](docs/en/images/metadata-benchmark.svg)\n\nThe result shows that JuiceFS can provide significantly more metadata IOPS than the other two (see [more details](https://juicefs.com/docs/community/mdtest)).\n\n### Analyze performance\n\nSee [Real-Time Performance Monitoring](https://juicefs.com/docs/community/fault_diagnosis_and_analysis#performance-monitor) if you encountered performance issues.\n\n## Supported Object Storage\n\n- Amazon S3 _(and other S3 compatible Object Storage services)_\n- Google Cloud Storage\n- Azure Blob Storage\n- Alibaba Cloud Object Storage Service (OSS)\n- Tencent Cloud Object Storage (COS)\n- Qiniu Cloud Object Storage (Kodo)\n- QingStor Object Storage\n- Ceph RGW\n- MinIO\n- Local disk\n- Redis\n- ...\n\nJuiceFS supports numerous Object Storage services. [Learn more](https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage).\n\n## Who is using\n\nJuiceFS is production ready and used by thousands of machines in production. A list of users has been assembled and documented [here](https://juicefs.com/docs/community/adopters). In addition JuiceFS has several collaborative projects that integrate with other open source projects, which we have documented [here](https://juicefs.com/docs/community/integrations). If you are also using JuiceFS, please feel free to let us know, and you are welcome to share your specific experience with everyone.\n\nThe storage format is stable, and will be supported by all future releases.\n\n## Roadmap\n\n- Gateway Optimization\n- Resumable Sync\n- Read-ahead Optimization\n- Optimization for Large-scale Scenarios\n- Snapshots\n\n## Reporting Issues\n\nWe use [GitHub Issues](https://github.com/juicedata/juicefs/issues) to track community reported issues. You can also [contact](#community) the community for any questions.\n\n## Contributing\n\nThank you for your contribution! Please refer to the [JuiceFS Contributing Guide](https://juicefs.com/docs/community/development/contributing_guide) for more information.\n\n## Community\n\nWelcome to join the [Discussions](https://github.com/juicedata/juicefs/discussions) and the [Slack channel](https://go.juicefs.com/slack) to connect with JuiceFS team members and other users.\n\n## Usage Tracking\n\nJuiceFS collects **anonymous** usage data by default to help us better understand how the community is using JuiceFS. Only core metrics (e.g. version number) will be reported, and user data and any other sensitive data will not be included. The related code can be viewed [here](pkg/usage/usage.go).\n\nYou could also disable reporting easily by command line option `--no-usage-report`:\n\n```bash\njuicefs mount --no-usage-report\n```\n\n## License\n\nJuiceFS is open-sourced under Apache License 2.0, see [LICENSE](LICENSE).\n\n## Credits\n\nThe design of JuiceFS was inspired by [Google File System](https://research.google/pubs/pub51), [HDFS](https://hadoop.apache.org) and [MooseFS](https://moosefs.com). Thanks for their great work!\n\n## FAQ\n\n### Why doesn't JuiceFS support XXX Object Storage?\n\nJuiceFS supports many Object Storage services. Please check out [this list](https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage) first. If the Object Storage you want to use is compatible with S3, you could treat it as S3. Otherwise, try reporting any issue.\n\n### Can I use Redis Cluster as metadata engine?\n\nYes. Since [v1.0.0 Beta3](https://github.com/juicedata/juicefs/releases/tag/v1.0.0-beta3) JuiceFS supports the use of [Redis Cluster](https://redis.io/docs/manual/scaling) as the metadata engine, but it should be noted that Redis Cluster requires that the keys of all operations in a transaction must be in the same hash slot, so a JuiceFS file system can only use one hash slot.\n\nSee [\"Redis Best Practices\"](https://juicefs.com/docs/community/redis_best_practices) for more information.\n\n### What's the difference between JuiceFS and XXX?\n\nSee [\"Comparison with Others\"](https://juicefs.com/docs/community/comparison/juicefs_vs_alluxio) for more information.\n\nFor more FAQs, please see the [full list](https://juicefs.com/docs/community/faq).\n\n## Stargazers over time\n\n[![Star History Chart](https://api.star-history.com/svg?repos=juicedata/juicefs&type=Date)](https://star-history.com/#juicedata/juicefs&Date)\n",
      "stars_today": 235
    },
    {
      "id": 501045649,
      "name": "waveterm",
      "full_name": "wavetermdev/waveterm",
      "description": "An open-source, cross-platform terminal for seamless workflows",
      "html_url": "https://github.com/wavetermdev/waveterm",
      "stars": 16575,
      "forks": 716,
      "language": "Go",
      "topics": [
        "command-line",
        "developer-tools",
        "linux",
        "macos",
        "productivity",
        "terminal",
        "terminal-emulators",
        "windows"
      ],
      "created_at": "2022-06-08T00:26:00Z",
      "updated_at": "2026-01-17T00:45:05Z",
      "pushed_at": "2026-01-17T00:54:45Z",
      "open_issues": 430,
      "owner": {
        "login": "wavetermdev",
        "avatar_url": "https://avatars.githubusercontent.com/u/120279640?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://www.waveterm.dev\">\n\t<picture>\n\t\t<source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/wave-dark.png\">\n\t\t<source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/wave-light.png\">\n\t\t<img alt=\"Wave Terminal Logo\" src=\"./assets/wave-light.png\" width=\"240\">\n\t</picture>\n  </a>\n  <br/>\n</p>\n\n# Wave Terminal\n\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield)\n\nWave is an open-source terminal that combines traditional terminal features with graphical capabilities like file previews, web browsing, and AI assistance. It runs on MacOS, Linux, and Windows.\n\nModern development involves constantly switching between terminals and browsers - checking documentation, previewing files, monitoring systems, and using AI tools. Wave brings these graphical tools directly into the terminal, letting you control them from the command line. This means you can stay in your terminal workflow while still having access to the visual interfaces you need.\n\n![WaveTerm Screenshot](./assets/wave-screenshot.webp)\n\n## Key Features\n\n- Flexible drag & drop interface to organize terminal blocks, editors, web browsers, and AI assistants\n- Built-in editor for seamlessly editing remote files with syntax highlighting and modern editor features\n- Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)\n- Quick full-screen toggle for any block - expand terminals, editors, and previews for better visibility, then instantly return to multi-block view\n- Wave AI - Context-aware terminal assistant that reads your terminal output, analyzes widgets, and performs file operations\n- AI chat widget with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)\n- Command Blocks for isolating and monitoring individual commands with auto-close options\n- One-click remote connections with full terminal and file system access\n- Secure secret storage using native system backends - store API keys and credentials locally, access them across SSH sessions\n- Rich customization including tab themes, terminal styles, and background images\n- Powerful `wsh` command system for managing your workspace from the CLI and sharing data between terminal sessions\n- Connected file management with `wsh file` - seamlessly copy and sync files between local, remote SSH hosts, Wave filesystem, and S3\n\n## Wave AI\n\nWave AI is your context-aware terminal assistant with access to your workspace:\n\n- **Terminal Context**: Reads terminal output and scrollback for debugging and analysis\n- **File Operations**: Read, write, and edit files with automatic backups and user approval\n- **CLI Integration**: Use `wsh ai` to pipe output or attach files directly from the command line\n- **Free Beta**: Included AI credits while we refine the experience\n- **Coming Soon**: Command execution (with approval), local model support, and alternate AI providers (BYOK)\n\nLearn more in our [Wave AI documentation](https://docs.waveterm.dev/waveai).\n\n## Installation\n\nWave Terminal works on macOS, Linux, and Windows.\n\nPlatform-specific installation instructions can be found [here](https://docs.waveterm.dev/gettingstarted).\n\nYou can also install Wave Terminal directly from: [www.waveterm.dev/download](https://www.waveterm.dev/download).\n\n### Minimum requirements\n\nWave Terminal runs on the following platforms:\n\n- macOS 11 or later (arm64, x64)\n- Windows 10 1809 or later (x64)\n- Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)\n\nThe WSH helper runs on the following platforms:\n\n- macOS 11 or later (arm64, x64)\n- Windows 10 or later (arm64, x64)\n- Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)\n\n## Roadmap\n\nWave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it [here](./ROADMAP.md).\n\nWant to provide input to our future releases? Connect with us on [Discord](https://discord.gg/XfvZ334gwU) or open a [Feature Request](https://github.com/wavetermdev/waveterm/issues/new/choose)!\n\n## Links\n\n- Homepage &mdash; https://www.waveterm.dev\n- Download Page &mdash; https://www.waveterm.dev/download\n- Documentation &mdash; https://docs.waveterm.dev\n- Legacy Documentation &mdash; https://legacydocs.waveterm.dev\n- Blog &mdash; https://blog.waveterm.dev\n- X &mdash; https://x.com/wavetermdev\n- Discord Community &mdash; https://discord.gg/XfvZ334gwU\n\n## Building from Source\n\nSee [Building Wave Terminal](BUILD.md).\n\n## Contributing\n\nWave uses GitHub Issues for issue tracking.\n\nFind more information in our [Contributions Guide](CONTRIBUTING.md), which includes:\n\n- [Ways to contribute](CONTRIBUTING.md#contributing-to-wave-terminal)\n- [Contribution guidelines](CONTRIBUTING.md#before-you-start)\n\n## License\n\nWave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see [here](./ACKNOWLEDGEMENTS.md).\n",
      "stars_today": 220
    },
    {
      "id": 1020834440,
      "name": "Acontext",
      "full_name": "memodb-io/Acontext",
      "description": "Data platform for context engineering. Context data platform that stores, observes and learns. Join the community‚ù§Ô∏è: https://discord.acontext.io",
      "html_url": "https://github.com/memodb-io/Acontext",
      "stars": 2627,
      "forks": 239,
      "language": "Go",
      "topics": [
        "agent",
        "agent-development-kit",
        "agent-observability",
        "ai-agent",
        "anthropic",
        "context-data-platform",
        "context-engineering",
        "data-platform",
        "llm",
        "llm-observability",
        "llmops",
        "memory",
        "openai",
        "self-evolving",
        "self-learning"
      ],
      "created_at": "2025-07-16T13:15:48Z",
      "updated_at": "2026-01-17T00:48:23Z",
      "pushed_at": "2026-01-16T19:59:51Z",
      "open_issues": 21,
      "owner": {
        "login": "memodb-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/180244457?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://discord.acontext.io\">\n      <img alt=\"Show Acontext header banner\" src=\"./assets/Acontext-header-banner.png\">\n  </a>\n  <p>\n    <h4>Context Data Platform for Building Cloud-native AI Agents</h4>\n  </p>\n  <p align=\"center\">\n    <a href=\"https://pypi.org/project/acontext/\"><img src=\"https://img.shields.io/pypi/v/acontext.svg\"></a>\n    <a href=\"https://www.npmjs.com/package/@acontext/acontext\"><img src=\"https://img.shields.io/npm/v/@acontext/acontext.svg?logo=npm&logoColor=fff&style=flat&labelColor=2C2C2C&color=28CF8D\"></a>\n    <a href=\"https://github.com/memodb-io/acontext/actions/workflows/core-test.yaml\"><img src=\"https://github.com/memodb-io/acontext/actions/workflows/core-test.yaml/badge.svg\"></a>\n    <a href=\"https://github.com/memodb-io/acontext/actions/workflows/api-test.yaml\"><img src=\"https://github.com/memodb-io/acontext/actions/workflows/api-test.yaml/badge.svg\"></a>\n    <a href=\"https://github.com/memodb-io/acontext/actions/workflows/cli-test.yaml\"><img src=\"https://github.com/memodb-io/acontext/actions/workflows/cli-test.yaml/badge.svg\"></a>\n  </p>\n  <p align=\"center\">\n    <a href=\"https://x.com/acontext_io\"><img src=\"https://img.shields.io/twitter/follow/acontext_io?style=social\" alt=\"Twitter Follow\"></a>\n    <a href=\"https://discord.acontext.io\"><img src=\"https://img.shields.io/badge/dynamic/json?label=Acontext&style=flat&query=approximate_member_count&url=https%3A%2F%2Fdiscord.com%2Fapi%2Fv10%2Finvites%2FSG9xJcqVBu%3Fwith_counts%3Dtrue&logo=discord&logoColor=white&suffix=+members&color=36393f&labelColor=5765F2\" alt=\"Acontext Discord\"></a>\n  </p>\n  <div align=\"center\">\n    <!-- Keep these links. Translations will automatically update with the README. -->\n    <a href=\"./readme/de/README.md\">Deutsch</a> | \n    <a href=\"./readme/es/README.md\">Espa√±ol</a> | \n    <a href=\"./readme/fr/README.md\">Fran√ßais</a> | \n    <a href=\"./readme/ja/README.md\">Êó•Êú¨Ë™û</a> | \n    <a href=\"./readme/ko/README.md\">ÌïúÍµ≠Ïñ¥</a> | \n    <a href=\"./readme/pt/README.md\">Portugu√™s</a> | \n    <a href=\"./readme/ru/README.md\">–†—É—Å—Å–∫–∏–π</a> | \n    <a href=\"./readme/zh/README.md\">‰∏≠Êñá</a>\n  </div>\n  <br/>\n</div>\n\n\n*Everyone is telling you how to use their agents. But what if YOU need to build an agent for 100,000 users, how would you start?*\n\n**üì¶ Problem 1: 99% of your DB is just LLM messages.** \n\n> Poor schema design makes your most valuable data expensive and slow. Acontext handles context storage and retrieval via PG, Redis, and S3. \n>\n> ChatGPT, Gemini, Anthropic, images, audio, files... we've got you covered.\n\n**‚è∞ Problem 2: Long-running agents are a nightmare.** \n\n> You know context engineering, but you're always writing it from scratch. Acontext comes with built-in context editing methods and a todo agent out of the box.\n>\n> Managing agent state? Piece of cake.\n\n**üëÄ Problem 3: You can't see how your agent is doing.** \n\n> How satisfied are your users, really? Acontext tracks tasks per session and shows you your agent's actual success rate. \n>\n> Stop obsessing over token costs, improve the agent first.\n\n**üß† Problem 4: Your agent is hit or miss.**\n\n> Can it learn from its wins? Acontext's experience agent remembers successful runs and turns them into reusable tool-use SOPs.\n>\n> Consistency is everything.\n\n\n\nTo solve those problems at once, Acontext becomes the **Context Data Platform**:\n\n<div align=\"center\">\n    <picture>\n      <img alt=\"Acontext Learning\" src=\"./assets/acontext-components.jpg\" width=\"100%\">\n    </picture>\n  <p>Context Data Platform that Store, Observe and Learn</p>\n</div>\n\n\n# üí° Core Features\n\n- **Context Engineering**\n  - [Session](https://docs.acontext.io/store/messages/multi-provider): unified message storage for any llm, any modal.\n  - [Disk](https://docs.acontext.io/store/disk): save/download artifacts with file path.\n  - [Context Editing](https://docs.acontext.io/store/editing) - manage your context window in one api.\n\n<div align=\"center\">\n    <picture>\n      <img alt=\"Acontext Learning\" src=\"./assets/acontext-context-engineering.png\" width=\"80%\">\n    </picture>\n  <p>Context Engineering in Acontext</p>\n</div>\n\n- **Observe agent tasks and user feedback**\n  - [Task](https://docs.acontext.io/observe/agent_tasks): collect agent's working status, progress and preferences in near real-time.\n- **Agent self-learning**\n  - [Experience](https://docs.acontext.io/learn/advance/experience-agent): let agent learn SOPs for each user.\n- **View everything in one [dashboard](https://docs.acontext.io/observe/dashboard)**\n\n<div align=\"center\">\n    <picture>\n      <img alt=\"Dashboard\" src=\"./docs/images/dashboard/BI.png\" width=\"80%\">\n    </picture>\n  <p>Dashboard of Agent Success Rate and Other Metrics</p>\n</div>\n\n\n\n# üèóÔ∏è How it works?\n\n<details>\n<summary>click to open</summary>\n\n```mermaid\ngraph TB\n    subgraph \"Client Layer\"\n        PY[\"pip install acontext\"]\n        TS[\"npm i @acontext/acontext\"]\n    end\n    \n    subgraph \"Acontext Backend\"\n      subgraph \" \"\n          API[\"API<br/>localhost:8029\"]\n          CORE[\"Core\"]\n          API -->|FastAPI & MQ| CORE\n      end\n      \n      subgraph \" \"\n          Infrastructure[\"Infrastructures\"]\n          PG[\"PostgreSQL\"]\n          S3[\"S3\"]\n          REDIS[\"Redis\"]\n          MQ[\"RabbitMQ\"]\n      end\n    end\n    \n    subgraph \"Dashboard\"\n        UI[\"Web Dashboard<br/>localhost:3000\"]\n    end\n    \n    PY -->|RESTFUL API| API\n    TS -->|RESTFUL API| API\n    UI -->|RESTFUL API| API\n    API --> Infrastructure\n    CORE --> Infrastructure\n\n    Infrastructure --> PG\n    Infrastructure --> S3\n    Infrastructure --> REDIS\n    Infrastructure --> MQ\n    \n    \n    style PY fill:#3776ab,stroke:#fff,stroke-width:2px,color:#fff\n    style TS fill:#3178c6,stroke:#fff,stroke-width:2px,color:#fff\n    style API fill:#00add8,stroke:#fff,stroke-width:2px,color:#fff\n    style CORE fill:#ffd43b,stroke:#333,stroke-width:2px,color:#333\n    style UI fill:#000,stroke:#fff,stroke-width:2px,color:#fff\n    style PG fill:#336791,stroke:#fff,stroke-width:2px,color:#fff\n    style S3 fill:#ff9900,stroke:#fff,stroke-width:2px,color:#fff\n    style REDIS fill:#dc382d,stroke:#fff,stroke-width:2px,color:#fff\n    style MQ fill:#ff6600,stroke:#fff,stroke-width:2px,color:#fff\n```\n\n## How They Work Together\n\n```txt\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ User ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ Your Agent ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   Session    ‚îÇ    ‚îÇ Artifact Disk ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ                  ‚îÇ # if enable\n                  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                  ‚îÇ         ‚îÇ Observed Tasks  ‚îÇ\n                  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ                  ‚îÇ # if enable\n                  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                  ‚îÇ         ‚îÇ   Learn Skills  ‚îÇ\n                  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                      Search skills\n```\n\n\n\n## Data Structures\n\n<details>\n<summary>üìñ Task Structure</summary>\n\n```json\n{\n  \"task_description\": \"Star https://github.com/memodb-io/Acontext\",\n  \"progresses\": [\n    \"I have navigated to Acontext repo\",\n    \"Tried to Star but a pop-up required me to login\",\n    ...\n  ],\n  \"user_preferences\": [\n    \"user wants to use outlook email to login\"\n  ]\n}\n```\n</details>\n\n\n\n<details>\n<summary>üìñ Skill Structure</summary>\n\n\n```json\n{\n    \"use_when\": \"star a repo on github.com\",\n    \"preferences\": \"use user's outlook account\",\n    \"tool_sops\": [\n        {\"tool_name\": \"goto\", \"action\": \"goto github.com\"},\n        {\"tool_name\": \"click\", \"action\": \"find login button if any. login first\"},\n        ...\n    ]\n}\n```\n\n</details>\n\n\n\n<details>\n<summary>üìñ Space Structure</summary>\n\n```txt\n/\n‚îî‚îÄ‚îÄ github/ (folder)\n    ‚îî‚îÄ‚îÄ GTM (page)\n        ‚îú‚îÄ‚îÄ find_trending_repos (sop)\n        ‚îî‚îÄ‚îÄ find_contributor_emails (sop)\n    ‚îî‚îÄ‚îÄ basic_ops (page)\n        ‚îú‚îÄ‚îÄ create_repo (sop)\n        ‚îî‚îÄ‚îÄ delete_repo (sop)\n    ...\n```\n</details>\n\n</details>\n\n\n\n\n\n# üöÄ Connect to Acontext\n\n1. Go to [Acontext.io](https://acontext.io), claim your free credits.\n2. Go through a one-click onboarding to get your API Key: `sk-ac-xxx`\n\n<div align=\"center\">\n    <picture>\n      <img alt=\"Dashboard\" src=\"./assets/onboard.png\" width=\"80%\">\n    </picture>\n</div>\n\n\n\n\n<details>\n<summary>üíª Self-host Acontext</summary>\n\nWe have an `acontext-cli` to help you do quick proof-of-concept. Download it first in your terminal:\n\n```bash\ncurl -fsSL https://install.acontext.io | sh\n```\n\nYou should have [docker](https://www.docker.com/get-started/) installed and an OpenAI API Key to start an Acontext backend on your computer:\n\n```bash\nmkdir acontext_server && cd acontext_server\nacontext docker up\n```\n\n> [!IMPORTANT]\n>\n> Make sure your LLM has the ability to [call tools](https://platform.openai.com/docs/guides/function-calling). By default, Acontext will use `gpt-4.1`.\n\n`acontext docker up` will create/use  `.env` and `config.yaml` for Acontext, and create a `db` folder to persist data.\n\n\n\nOnce it's done, you can access the following endpoints:\n\n- Acontext API Base URL: http://localhost:8029/api/v1\n- Acontext Dashboard: http://localhost:3000/\n\n</details>\n\n\n\n\n\n\n# üßê Use Acontext to build Agent\n\nDownload end-to-end scripts with `acontext`:\n\n**Python**\n\n```bash\nacontext create my-proj --template-path \"python/openai-basic\"\n```\n\n> More examples on Python:\n>\n> - `python/openai-agent-basic`: self-learning agent in openai agent sdk.\n> - `python/agno-basic`: self-learning agent in agno framework.\n> - `python/openai-agent-artifacts`: agent that can edit and download artifacts.\n\n**Typescript**\n\n```bash\nacontext create my-proj --template-path \"typescript/openai-basic\"\n```\n\n> More examples on Typescript:\n>\n> - `typescript/vercel-ai-basic`: self-learning agent in @vercel/ai-sdk\n\n\n\n> [!NOTE]\n>\n> Check our example repo for more templates: [Acontext-Examples](https://github.com/memodb-io/Acontext-Examples).\n>\n> We're cooking more full-stack Agent Applications! [Tell us what you want!](https://discord.acontext.io)\n\n\n\n## Step-by-step Quickstart\n\n<details>\n<summary>click to open</summary>\n\n\nWe're maintaining Python [![pypi](https://img.shields.io/pypi/v/acontext.svg)](https://pypi.org/project/acontext/) and Typescript [![npm](https://img.shields.io/npm/v/@acontext/acontext.svg?logo=npm&logoColor=fff&style=flat&labelColor=2C2C2C&color=28CF8D)](https://www.npmjs.com/package/@acontext/acontext) SDKs. The snippets below are using Python.\n\n## Install SDKs\n\n```\npip install acontext # for Python\nnpm i @acontext/acontext # for Typescript\n```\n\n\n\n## Initialize Client\n\n```python\nimport os\nfrom acontext import AcontextClient\n\nclient = AcontextClient(\n    api_key=os.getenv(\"ACONTEXT_API_KEY\"),\n)\n\n# If you're using self-hosted Acontext:\n# client = AcontextClient(\n#     base_url=\"http://localhost:8029/api/v1\",\n#     api_key=\"sk-ac-your-root-api-bearer-token\",\n# )\n```\n\n> [üìñ async client doc](https://docs.acontext.io/settings/core)\n\n\n\n## Store\n\nAcontext can manage agent sessions and artifacts.\n\n### Save Messages [üìñ](https://docs.acontext.io/api-reference/session/store-message-to-session)\n\nAcontext offers persistent storage for message data. When you call `session.store_message`, Acontext will persist the message and start to monitor this session:\n\n<details>\n<summary>Code Snippet</summary>\n\n```python\nsession = client.sessions.create()\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"I need to write a landing page of iPhone 15 pro max\"},\n    {\n        \"role\": \"assistant\",\n        \"content\": \"Sure, my plan is below:\\n1. Search for the latest news about iPhone 15 pro max\\n2. Init Next.js project for the landing page\\n3. Deploy the landing page to the website\",\n    }\n]\n\n# Save messages\nfor msg in messages:\n    client.sessions.store_message(session_id=session.id, blob=msg, format=\"openai\")\n```\n\n> [üìñ](https://docs.acontext.io/store/messages/multi-modal) We also support multi-modal message storage and anthropic SDK.\n\n\n</details>\n\n### Load Messages [üìñ](https://docs.acontext.io/api-reference/session/get-messages-from-session)\n\nObtain your session messages using `sessions.get_messages`\n\n<details>\n<summary>Code Snippet</summary>\n\n```python\nr = client.sessions.get_messages(session.id)\nnew_msg = r.items\n\nnew_msg.append({\"role\": \"user\", \"content\": \"How are you doing?\"})\nr = openai_client.chat.completions.create(model=\"gpt-4.1\", messages=new_msg)\nprint(r.choices[0].message.content)\nclient.sessions.store_message(session_id=session.id, blob=r.choices[0].message)\n```\n\n</details>\n\n<div align=\"center\">\n    <picture>\n      <img alt=\"Session\" src=\"./docs/images/dashboard/message_viewer.png\" width=\"100%\">\n    </picture>\n  <p>You can view sessions in your local Dashboard</p>\n</div>\n\n\n### Artifacts [üìñ](https://docs.acontext.io/store/disk)\n\nCreate a disk for your agent to store and read artifacts using file paths:\n\n<details>\n<summary>Code Snippet</summary>\n\n```python\nfrom acontext import FileUpload\n\ndisk = client.disks.create()\n\nfile = FileUpload(\n    filename=\"todo.md\",\n    content=b\"# Sprint Plan\\n\\n## Goals\\n- Complete user authentication\\n- Fix critical bugs\"\n)\nartifact = client.disks.artifacts.upsert(\n    disk.id,\n    file=file,\n    file_path=\"/todo/\"\n)\n\n\nprint(client.disks.artifacts.list(\n    disk.id,\n    path=\"/todo/\"\n))\n\nresult = client.disks.artifacts.get(\n    disk.id,\n    file_path=\"/todo/\",\n    filename=\"todo.md\",\n    with_public_url=True,\n    with_content=True\n)\nprint(f\"‚úì File content: {result.content.raw}\")\nprint(f\"‚úì Download URL: {result.public_url}\")        \n```\n</details>\n\n\n\n<div align=\"center\">\n    <picture>\n      <img alt=\"Artifacts\" src=\"./docs/images/dashboard/artifact_viewer.png\" width=\"100%\">\n    </picture>\n  <p>You can view artifacts in your local Dashboard</p>\n</div>\n\n\n\n## Observe [üìñ](https://docs.acontext.io/observe)\n\nFor every session, Acontext will **automatically** launch a background agent to track the task progress and user feedback. **It's like a background TODO agent**. Acontext will use it to observe your daily agent success rate.\n\nYou can use the SDK to retrieve the current state of the agent session, for Context Engineering like Reduction and Compression. \n\n<details>\n<summary>Full Script</summary>\n\n```python\nfrom acontext import AcontextClient\n\n# Initialize client\nclient = AcontextClient(\n    base_url=\"http://localhost:8029/api/v1\", api_key=\"sk-ac-your-root-api-bearer-token\"\n)\n\n# Create a project and session\nsession = client.sessions.create()\n\n# Conversation messages\nmessages = [\n    {\"role\": \"user\", \"content\": \"I need to write a landing page of iPhone 15 pro max\"},\n    {\n        \"role\": \"assistant\",\n        \"content\": \"Sure, my plan is below:\\n1. Search for the latest news about iPhone 15 pro max\\n2. Init Next.js project for the landing page\\n3. Deploy the landing page to the website\",\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"That sounds good. Let's first collect the message and report to me before any landing page coding.\",\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"Sure, I will first collect the message then report to you before any landing page coding.\",\n      \t\"tool_calls\": [\n            {\n                \"id\": \"call_001\",\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"search_news\",\n                    \"arguments\": \"{\\\"query\\\": \\\"iPhone news\\\"}\"\n                }\n            }\n        ]\n    },\n]\n\n# Store messages in a loop\nfor msg in messages:\n    client.sessions.store_message(session_id=session.id, blob=msg, format=\"openai\")\n\n# Wait for task extraction to complete\nclient.sessions.flush(session.id)\n\n# Display extracted tasks\ntasks_response = client.sessions.get_tasks(session.id)\nprint(tasks_response)\nfor task in tasks_response.items:\n    print(f\"\\nTask #{task.order}:\")\n    print(f\"  ID: {task.id}\")\n    print(f\"  Title: {task.data.task_description}\")\n    print(f\"  Status: {task.status}\")\n\n    # Show progress updates if available\n    if task.data.progresses:\n        print(f\"  Progress updates: {len(task.data.progresses)}\")\n        for progress in task.data.progresses:\n            print(f\"    - {progress}\")\n\n    # Show user preferences if available\n    if task.data.user_preferences:\n        print(\"  User preferences:\")\n        for pref in task.data.user_preferences:\n            print(f\"    - {pref}\")\n\n```\n> `flush` is a blocking call, it will wait for the task extraction to complete.\n> You don't need to call it in production, Acontext has a [buffer mechanism](https://docs.acontext.io/observe/buffer) to ensure the task extraction is completed right on time.\n\n</details>\n\nExample Task Return:\n\n```txt\nTask #1:\n  Title: Search for the latest news about iPhone 15 Pro Max and report findings to the user before any landing page coding.\n  Status: success\n  Progress updates: 2\n    - I confirmed that the first step will be reporting before moving on to landing page development.\n    - I have already collected all the iPhone 15 pro max info and reported to the user, waiting for approval for next step.\n  User preferences:\n    - user expects a report on latest news about iPhone 15 pro max before any coding work on the landing page.\n\nTask #2:\n  Title: Initialize a Next.js project for the iPhone 15 Pro Max landing page.\n  Status: pending\n\nTask #3:\n  Title: Deploy the completed landing page to the website.\n  Status: pending\n```\n\n\n\nYou can view the session tasks' statuses in the Dashboard:\n\n<div align=\"center\">\n    <picture>\n      <img alt=\"Acontext Learning\" src=\"./docs/images/dashboard/session_task_viewer.png\" width=\"100%\">\n    </picture>\n  <p>A Task Demo</p>\n</div>\n\n\n\n## Self-learning\n\nAcontext can gather a bunch of sessions and learn skills (SOPs) on how to call tools for certain tasks.\n\n### Learn Skills to a `Space` [üìñ](https://docs.acontext.io/learn/skill-space)\n\n<div align=\"center\">\n    <picture>\n      <img alt=\"A Space Demo\" src=\"./assets/acontext_dataflow.png\" width=\"100%\">\n    </picture>\n  <p>How self-learning works?</p>\n</div>\n\nA `Space` can store skills, and memories in a Notion-like system. You first need to connect a session to `Space` to enable the learning process:\n\n```python\n# Step 1: Create a Space for skill learning\nspace = client.spaces.create()\nprint(f\"Created Space: {space.id}\")\n\n# Step 2: Create a session attached to the space\nsession = client.sessions.create(space_id=space.id)\n\n# ... push the agent working context\n```\n\nThe learning happens in the background and is not real-time (delay around 10-30s). \n\nWhat Acontext will do in the background:\n\n```mermaid\ngraph LR\n    A[Task Completed] --> B[Task Extraction]\n    B --> C{Space Connected?}\n    C -->|Yes| D[Queue for Learning]\n    C -->|No| E[Skip Learning]\n    D --> F[Extract SOP]\n    F --> G{Hard Enough?}\n    G -->|No - Too Simple| H[Skip Learning]\n    G -->|Yes - Complex| I[Store as Skill Block]\n    I --> J[Available for Future Sessions]\n```\n\nEventually, SOP blocks with tool-call pattern will be saved to `Space`. You can view every `Space` in the Dashboard:\n\n<div align=\"center\">\n    <picture>\n      <img alt=\"A Space Demo\" src=\"./docs/images/dashboard/skill_viewer.png\" width=\"100%\">\n    </picture>\n  <p>A Space Demo</p>\n</div>\n\n\n\n\n### Search Skills from a `Space` [üìñ](https://docs.acontext.io/learn/search-skills)\n\nTo search skills from a `Space` and use them in the next session:\n\n```python\nresult = client.spaces.experience_search(\n    space_id=space.id,\n    query=\"I need to implement authentication\",\n  \tmode=\"fast\"\n)\n```\n\nAcontext supports `fast` and `agentic` modes for search. The former uses embeddings to match skills. The latter uses an Experience Agent to explore the entire `Space` and tries to cover every skill needed.\n\nThe return is a list of sop blocks, which look like below:\n\n```json\n{\n    \"use_when\": \"star a github repo\",\n    \"preferences\": \"use personal account. star but not fork\",\n    \"tool_sops\": [\n        {\"tool_name\": \"goto\", \"action\": \"goto the user given github repo url\"},\n        {\"tool_name\": \"click\", \"action\": \"find login button if any, and start to login first\"},\n        ...\n    ]\n}\n```\n\n</details>\n\n\n\n\n\n\n\n# üîç Document\n\nTo understand what Acontext can do better, please view [our docs](https://docs.acontext.io/)\n\n\n\n# ‚ù§Ô∏è Stay Updated\n\nStar Acontext on Github to support and receive instant notifications \n\n![click_star](./assets/star_acontext.gif)\n\n\n\n# ü§ù Stay Together\n\nJoin the community for support and discussions:\n\n-   [Discuss with Builders on Acontext Discord](https://discord.acontext.io) üëª \n-  [Follow Acontext on X](https://x.com/acontext_io) ùïè \n\n\n\n# üåü Contributing\n\n- Check our [roadmap.md](./ROADMAP.md) first.\n- Read [contributing.md](./CONTRIBUTING.md)\n\n\n\n# üìë LICENSE\n\nThis project is currently licensed under [Apache License 2.0](LICENSE).\n\n\n\n# ü•á Badges\n\n![Made with Acontext](./assets/badge-made-with-acontext.svg) ![Made with Acontext (dark)](./assets/badge-made-with-acontext-dark.svg)\n\n```md\n[![Made with Acontext](https://assets.memodb.io/Acontext/badge-made-with-acontext.svg)](https://acontext.io)\n\n[![Made with Acontext](https://assets.memodb.io/Acontext/badge-made-with-acontext-dark.svg)](https://acontext.io)\n```",
      "stars_today": 190
    },
    {
      "id": 1033778670,
      "name": "AionUi",
      "full_name": "iOfficeAI/AionUi",
      "description": "Free, local, open-source Cowork for Gemini CLI, Claude Code, Codex, Opencode, Qwen Code, Goose Cli, Auggie, and more | üåü Star if you like it!",
      "html_url": "https://github.com/iOfficeAI/AionUi",
      "stars": 4293,
      "forks": 354,
      "language": "TypeScript",
      "topics": [
        "acp",
        "ai",
        "ai-agent",
        "banana",
        "chat",
        "chatbot",
        "claude-code",
        "codex",
        "cowork",
        "gemini",
        "gemini-cli",
        "gemini-pro",
        "llm",
        "multi-agent",
        "nano-banana",
        "office",
        "opencode",
        "qwen-code",
        "skills",
        "webui"
      ],
      "created_at": "2025-08-07T10:29:51Z",
      "updated_at": "2026-01-17T01:03:17Z",
      "pushed_at": "2026-01-16T06:03:47Z",
      "open_issues": 19,
      "owner": {
        "login": "iOfficeAI",
        "avatar_url": "https://avatars.githubusercontent.com/u/145246968?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"./resources/aionui-banner-1 copy.png\" alt=\"AionUi - Cowork with Your CLI AI Agent\" width=\"100%\">\n</p>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/github/v/release/iOfficeAI/AionUi?style=flat-square&color=32CD32\" alt=\"Version\">\n  &nbsp;\n  <img src=\"https://img.shields.io/badge/license-Apache--2.0-32CD32?style=flat-square&logo=apache&logoColor=white\" alt=\"License\">\n  &nbsp;\n  <img src=\"https://img.shields.io/badge/platform-macOS%20%7C%20Windows%20%7C%20Linux-6C757D?style=flat-square&logo=linux&logoColor=white\" alt=\"Platform\">\n</p>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/15423\" target=\"_blank\">\n    <img src=\"https://trendshift.io/api/badge/repositories/15423\" alt=\"GitHub Trending\" height=\"80\">\n  </a>\n</p>\n\n---\n\n<p align=\"center\">\n  <strong>üöÄ Cowork with Your AI, Gemini CLI, Claude Code, Codex, Qwen Code, Goose CLI, Auggie, and more</strong><br>\n  <em>User-friendly | Visual graphical interface | Multi-model support | Local data security</em>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/iOfficeAI/AionUi/releases\">\n    <img src=\"https://img.shields.io/badge/‚¨áÔ∏è%20Download%20Now-Latest%20Release-32CD32?style=for-the-badge&logo=github&logoColor=white\" alt=\"Download Latest Release\" height=\"50\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <strong>English</strong> | <a href=\"./readme_ch.md\">ÁÆÄ‰Ωì‰∏≠Êñá</a> | <a href=\"./readme_jp.md\">Êó•Êú¨Ë™û</a> | <a href=\"https://www.aionui.com\" target=\"_blank\">Official Website</a> | <a href=\"https://twitter.com/AionUI\" target=\"_blank\">Twitter</a>\n</p>\n\n<p align=\"center\">\n  <strong>üí¨ Community:</strong> <a href=\"https://discord.gg/g6u66vV9\" target=\"_blank\">Discord (English)</a> | <a href=\"./resources/wechat.jpg\" target=\"_blank\">ÂæÆ‰ø° (‰∏≠ÊñáÁæ§)</a>\n</p>\n\n---\n\n## üìã Quick Navigation\n\n<p align=\"center\">\n\n[‚ú® What Can AionUi Do?](#‚ú®-what-can-aionui-do) ¬∑\n[ü§î Why Choose AionUi?](#ü§î-why-choose-aionui) ¬∑\n[‚ú® Core Features](#‚ú®-core-features) ¬∑\n[üöÄ Quick Start](#üöÄ-quick-start) ¬∑\n[üìñ Detailed Usage Guide](#üìñ-detailed-usage-guide) ¬∑\n[üí¨ Community](#ü§ù-community--support)\n\n</p>\n\n---\n\n## ‚ú® What Can AionUi Do?\n\n<p align=\"center\">\n  <img src=\"./resources/offica-ai BANNER-function copy.png\" alt=\"AionUi - Cowork with Your CLI AI Agent\" width=\"800\">\n</p>\n\n### ü§ñ **Multi-Agent Mode - Cowork for Your Command-Line AI Tools, Unified Graphical Interface**\n\n_If you have installed command-line tools like Gemini CLI, Claude Code, CodeX, Qwen Code, Goose AI, Augment Code, AionUi can automatically detect them and provide a unified graphical interface_\n\n- ‚úÖ **Auto Detection + Unified Interface** - Automatically recognizes local CLI tools, provides a unified graphical interface, say goodbye to command line\n- ‚úÖ **Local Storage + Multi-Session** - Conversations saved locally, supports multiple parallel sessions, each session with independent context\n\n<p align=\"center\">\n  <img src=\"./resources/acp home page.gif\" alt=\"Multi-Agent Mode Demo\" width=\"800\">\n</p>\n\n---\n\n### üìÅ **Smart File Management (AI Cowork)**\n\n_Batch renaming, automatic organization, smart classification, file merging_\n\n- **Auto Organize**: Intelligently identify content and auto-classify, keeping folders tidy.\n- **Efficient Batch**: One-click rename, merge files, say goodbye to tedious manual tasks.\n\n<p align=\"center\">\n  <img src=\"./resources/aionui sort file.gif\" alt=\"Smart File Management Demo\" width=\"800\">\n</p>\n\n---\n\n### üìÑ **Preview Panel - Quickly View AI-Generated Results**\n\n_Supports 9+ formats of visual preview (PDF, Word, Excel, PPT, code, Markdown, images, HTML, Diff, etc.)_\n\n- ‚úÖ **View Results Instantly** - After AI generates files, view preview immediately without switching apps\n- ‚úÖ **Real-time Tracking + Editable** - Automatically tracks file changes, editor and preview sync intelligently; supports real-time editing of Markdown, code, HTML, WYSIWYG\n\n<p align=\"center\">\n  <img src=\"./resources/preview.gif\" alt=\"Preview Panel Demo\" width=\"800\">\n</p>\n\n---\n\n### üé® **AI Image Generation & Editing**\n\n_Intelligent image generation, editing, and recognition, powered by Gemini_\n\n<p align=\"center\">\n  <img src=\"./resources/Image_Generation.gif\" alt=\"AI Image Generation Demo\" width=\"800\">\n</p>\n\n---\n\n### üí¨ **Multi-Task Parallel Processing**\n\n_Open multiple conversations, tasks don't get mixed up, independent memory, double efficiency_\n\n<p align=\"center\">\n  <img src=\"./resources/multichat-side-by-side.gif\" alt=\"Conversation Management Demo\" width=\"800\">\n</p>\n\n---\n\n### üåê **Access Anywhere - WebUI Mode**\n\n_Remotely control your AI tools - Access AionUi from any device on the network! Securely control local Gemini CLI, Claude Code, Codex, and other tools, data never leaves your device_\n\n```bash\n# Basic startup\nAionUi --webui\n\n# Remote access (accessible from other devices on the local network)\nAionUi --webui --remote\n```\n\n> üí° **Need detailed configuration guide?** Check out the [WebUI Configuration Tutorial](https://github.com/iOfficeAI/AionUi/wiki/WebUI-Configuration-Guide) - includes complete startup commands for all platforms\n\n<p align=\"center\">\n  <img src=\"./resources/webui banner.png\" alt=\"WebUI Remote Access Demo\" width=\"800\">\n</p>\n\n---\n\n## ü§î Why Choose AionUi?\n\n**Just like Claude Cowork makes Claude Code easier to use, AionUi is the Cowork platform for all your command-line AI tools**\n\nGemini CLI, Claude Code, Codex, Qwen Code are powerful, but share common pain points: conversations can't be saved, single-session limitations, cumbersome file operations, and only support a single model.\n\nAionUi provides unified **Cowork capabilities** for these command-line tools:\n\n- üéØ **Unified Platform** - One interface to manage all command-line AI tools, no switching needed\n- üöÄ **Multi-Tool Support** - Not only supports Claude Code, but also Gemini CLI, Codex, Qwen Code, and more\n- üåê **Cross-Platform** - Full platform support for macOS, Windows, Linux (Claude Cowork currently only macOS)\n- üîÑ **Multi-Model Switching** - Flexibly switch between different models in the same interface, meeting different task requirements\n- üìÑ **Real-time Preview** - Visual preview for 9+ formats, immediately view the effects of AI-generated files\n- üíæ **Local Data Security** - All conversations and files saved locally, data never leaves your device\n\n---\n\n### ‚ùì Quick Q&A\n\n<details>\n<summary><strong>Q: Why is AionUi a great replacement for Claude Cowork?</strong></summary>\nA: AionUi is a **free and open-source** **Multi-AI Agent Desktop**. Compared to the official Cowork which only runs on macOS and is locked to Claude, AionUi is its **full-model, cross-platform enhanced version**, deeply covering **AI Office Automation** scenarios.\n\n| Dimension     | Claude Cowork        | AionUi (This Project)                       |\n| :------------ | :------------------- | :------------------------------------------ |\n| OS            | macOS Only           | üçè macOS / ü™ü Windows / üêß Linux            |\n| Model Support | Claude Only          | ü§ñ Gemini, Claude, DeepSeek, OpenAI, Ollama |\n| Interaction   | GUI                  | üñ•Ô∏è Full GUI + WebUI Remote Access           |\n| Cost          | Subscription $100/mo | üÜì Completely Free & Open Source            |\n\n**Deep AI Office Scenario Support:**\n\n- **File Management**: Intelligently organize messy local folders and batch rename with one click.\n- **Data Processing**: Deeply analyze and automatically beautify Excel reports.\n- **Document Generation**: Automatically write and format PPT, Word, and Markdown documents.\n- **Instant Preview**: Built-in 9+ format preview panels, making AI office collaboration results instantly visible.\n</details>\n\n<details>\n<summary><strong>Q: What can I do with AionUi?</strong></summary>\nA: It can be your **private Cowork workspace**. You can let it help you batch organize folders, deeply beautify Excel, and preview web code in real-time. It's your best graphical choice for exploring office automation workflows and enhancing your experience with Claude Code or Gemini CLI.\n</details>\n\n<details>\n<summary><strong>Q: Is AionUi ready to use out of the box?</strong></summary>\nA: Yes! After installation, you can directly use Google account login, AionUi will automatically associate with Gemini CLI, no additional configuration needed to start using.\n</details>\n\n<details>\n<summary><strong>Q: Is it free?</strong></summary>\nA: AionUi is completely free and open source, but using AI models requires corresponding API Keys.\n</details>\n\n<details>\n<summary><strong>Q: Which AI models are supported?</strong></summary>\nA: Supports mainstream models like Gemini, OpenAI, Claude, Qwen, as well as local models like Ollama, LM Studio.\n\nYou can also run multiple AI Agents simultaneously (such as Gemini CLI, Claude Code, Qwen Code, etc.), see the configuration guide for details.\n\n</details>\n\n<details>\n<summary><strong>Q: Is my data secure?</strong></summary>\nA: All conversation data is stored in a local SQLite database and will not be uploaded to any server.\n</details>\n\n---\n\n## ‚ú® Core Features\n\n### üí¨ **Multi-Session Chat**\n\n- **Multi-Session + Independent Context** - Open multiple chats simultaneously, each session has independent context memory, no confusion\n- **Local Storage** - All conversations are saved locally and will not be lost\n\n### ü§ñ **Multi-Model Support**\n\n- **Multi-Platform Support** - Supports mainstream models like Gemini, OpenAI, Claude, Qwen, flexible switching\n- **Local Model Support** - Supports local model deployment like Ollama, LM Studio, select Custom platform and set local API address (e.g., `http://localhost:11434/v1`) to connect\n- **Gemini 3 Subscription Optimization** - Automatically identifies subscribed users, recommends advanced models\n\n### üóÇÔ∏è **File Management**\n\n- **File Tree Browsing + Drag & Drop Upload** - Browse files like folders, support drag and drop files or folders for one-click import\n- **Smart Organization** - You can let AI help organize folders, automatic classification\n\n### üìÑ **Preview Panel - Give AI Agent a Display**\n\n- **9+ Format Preview** - Supports PDF, Word, Excel, PPT, code, Markdown, images, etc., view results immediately after AI generation\n- **Real-time Tracking + Editable** - Automatically tracks file changes, supports real-time editing and debugging of Markdown, code, HTML\n\n### üé® **AI Image Generation & Editing**\n\n- **Intelligent Image Generation** - Supports multiple image generation models like Gemini 2.5 Flash Image Preview, Nano, Banana\n- **Image Recognition & Editing** - AI-driven image analysis and editing features\n\n### üåê **WebUI Remote Access**\n\n- **Cross-Device Access** - Access from any device on the network via browser, supports mobile devices\n- **Local Data Security** - All data stored locally in SQLite database, suitable for server deployment\n\n### üé® **Personalized Interface Customization**\n\n_Customize with your own CSS code, make your interface match your preferences_\n\n<p align=\"center\">\n  <img src=\"./resources/css with skin.gif\" alt=\"CSS Custom Interface Demo\" width=\"800\">\n</p>\n\n- **Fully Customizable** - Freely customize interface colors, styles, layout through CSS code, create your exclusive experience\n\n---\n\n## üìñ Detailed Usage Guide\n\n<details>\n<summary><strong>üìñ Expand to View Complete Usage Guide</strong></summary>\n\n### üöÄ Quick Start\n\n- [üìñ Complete Installation Guide](https://github.com/iOfficeAI/AionUi/wiki/Getting-Started) - Detailed steps from download to configuration\n- [‚öôÔ∏è LLM Configuration Guide](https://github.com/iOfficeAI/AionUi/wiki/LLM-Configuration) - Multi-platform AI model configuration\n- [ü§ñ Multi-Agent Mode Setup](https://github.com/iOfficeAI/AionUi/wiki/ACP-Setup) - Integrate terminal AI agents\n- [üîå MCP Tool Configuration](https://github.com/iOfficeAI/AionUi/wiki/MCP-Configuration-Guide) - Model Context Protocol server setup\n- [üé® Image Generation Configuration](https://github.com/iOfficeAI/AionUi/wiki/AionUi-Image-Generation-Tool-Model-Configuration-Guide) - AI image generation setup tutorial\n- [üåê WebUI Configuration Guide](https://github.com/iOfficeAI/AionUi/wiki/WebUI-Configuration-Guide) - Complete WebUI setup and configuration tutorial\n\n### üéØ Use Cases\n\n- [üìÅ File Management](https://github.com/iOfficeAI/AionUi/wiki/file-management) - Smart file organization\n- [üìä Excel Processing](https://github.com/iOfficeAI/AionUi/wiki/excel-processing) - AI-driven data processing\n- [üé® Image Generation](https://github.com/iOfficeAI/AionUi/wiki/AionUi-Image-Generation-Tool-Model-Configuration-Guide) - AI image creation\n- [üìö More Use Cases](https://github.com/iOfficeAI/AionUi/wiki/Use-Cases-Overview)\n\n### ‚ùì Support & Help\n\n- [‚ùì FAQ](https://github.com/iOfficeAI/AionUi/wiki/FAQ) - Questions and troubleshooting\n- [üîß Configuration & Usage Tutorials](https://github.com/iOfficeAI/AionUi/wiki/Configuration-Guides) - Complete configuration documentation\n\n</details>\n\n---\n\n## üöÄ Quick Start\n\n### üíª System Requirements\n\n- **macOS**: 10.15 or higher\n- **Windows**: Windows 10 or higher\n- **Linux**: Ubuntu 18.04+ / Debian 10+ / Fedora 32+\n- **Memory**: Recommended 4GB or more\n- **Storage**: At least 500MB available space\n\n### üì• Download\n\n<p>\n  <a href=\"https://github.com/iOfficeAI/AionUi/releases\">\n    <img src=\"https://img.shields.io/badge/Download-Latest%20Release-32CD32?style=for-the-badge&logo=github&logoColor=white\" alt=\"Download Latest Release\" height=\"50\">\n  </a>\n</p>\n\n### üîß Simple Installation\n\n1. **Download and install** AionUi application\n2. **Configure AI service** - Support Google account login or API Key authentication\n3. **Start using** - Immediately experience modern AI chat interface\n\n> üí° **Need detailed configuration guide?** Check out our [Complete Installation Tutorial](https://github.com/iOfficeAI/AionUi/wiki/Getting-Started)\n\n---\n\n## ü§ù Community & Support\n\n### üí¨ Community\n\n**üí° Your ideas matter!** We highly value every user's suggestions and feedback. Whether it's feature ideas, user experience, or issues you encounter, feel free to contact us anytime!\n\n<p align=\"center\">\n  <a href=\"https://x.com/AionUi\" target=\"_blank\">\n    <img src=\"./resources/contactus-x.png\" alt=\"Contact Us on X\" width=\"600\">\n  </a>\n</p>\n\n- [üí¨ GitHub Discussions](https://github.com/iOfficeAI/AionUi/discussions) - **Share ideas, make suggestions, exchange usage tips**\n- [üêõ Report Issues](https://github.com/iOfficeAI/AionUi/issues) - Report bugs or feature requests\n- [üì¶ Release Updates](https://github.com/iOfficeAI/AionUi/releases) - Get the latest version\n- [üí¨ Discord Community](https://discord.gg/g6u66vV9) - **Join our English community on Discord**\n- [üí¨ ÂæÆ‰ø° (‰∏≠ÊñáÁæ§)](./resources/wechat.jpg) - **Click to view QR code**\n\n### ü§ù Contributing\n\nWelcome to submit Issues and Pull Requests!\n\n1. Fork this project\n2. Create a feature branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n---\n\n## üìÑ License\n\nThis project is licensed under [Apache-2.0](LICENSE).\n\n---\n\n## üë• Contributors\n\nThanks to all developers who have contributed to AionUi!\n\n<p align=\"center\">\n  <a href=\"https://github.com/iOfficeAI/AionUi/graphs/contributors\">\n    <img src=\"https://contrib.rocks/image?repo=iOfficeAI/AionUi&max=20\" alt=\"Contributors\" />\n  </a>\n</p>\n\n## üìä Star History\n\n<p align=\"center\">\n  <a href=\"https://www.star-history.com/#iOfficeAI/aionui&Date\" target=\"_blank\">\n    <img src=\"https://api.star-history.com/svg?repos=iOfficeAI/aionui&type=Date\" alt=\"GitHub Star Trends\" width=\"600\">\n  </a>\n</p>\n\n<div align=\"center\">\n\n**‚≠ê If you like it, give us a star**\n\n[Report Bug](https://github.com/iOfficeAI/AionUi/issues) ¬∑ [Request Feature](https://github.com/iOfficeAI/AionUi/issues)\n\n</div>\n",
      "stars_today": 174
    },
    {
      "id": 1024118326,
      "name": "WeKnora",
      "full_name": "Tencent/WeKnora",
      "description": "LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.",
      "html_url": "https://github.com/Tencent/WeKnora",
      "stars": 12001,
      "forks": 1324,
      "language": "Go",
      "topics": [
        "agent",
        "agentic",
        "ai",
        "chatbot",
        "chatbots",
        "embeddings",
        "evaluation",
        "generative-ai",
        "golang",
        "knowledge-base",
        "llm",
        "multi-tenant",
        "multimodel",
        "ollama",
        "openai",
        "question-answering",
        "rag",
        "reranking",
        "semantic-search",
        "vector-search"
      ],
      "created_at": "2025-07-22T08:01:23Z",
      "updated_at": "2026-01-17T00:38:01Z",
      "pushed_at": "2026-01-16T08:50:54Z",
      "open_issues": 80,
      "owner": {
        "login": "Tencent",
        "avatar_url": "https://avatars.githubusercontent.com/u/18461506?v=4"
      },
      "readme": "<p align=\"center\">\n  <picture>\n    <img src=\"./docs/images/logo.png\" alt=\"WeKnora Logo\" height=\"120\"/>\n  </picture>\n</p>\n\n<p align=\"center\">\n  <picture>\n    <a href=\"https://trendshift.io/repositories/15289\" target=\"_blank\">\n      <img src=\"https://trendshift.io/api/badge/repositories/15289\" alt=\"Tencent%2FWeKnora | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/>\n    </a>\n  </picture>\n</p>\n<p align=\"center\">\n    <a href=\"https://weknora.weixin.qq.com\" target=\"_blank\">\n        <img alt=\"ÂÆòÊñπÁΩëÁ´ô\" src=\"https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99\">\n    </a>\n    <a href=\"https://chatbot.weixin.qq.com\" target=\"_blank\">\n        <img alt=\"ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞\" src=\"https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725\">\n    </a>\n    <a href=\"https://github.com/Tencent/WeKnora/blob/main/LICENSE\">\n        <img src=\"https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&color=2e6cc4\" alt=\"License\">\n    </a>\n    <a href=\"./CHANGELOG.md\">\n        <img alt=\"Version\" src=\"https://img.shields.io/badge/version-0.2.10-2e6cc4?labelColor=d4eaf7\">\n    </a>\n</p>\n\n<p align=\"center\">\n| <b>English</b> | <a href=\"./README_CN.md\"><b>ÁÆÄ‰Ωì‰∏≠Êñá</b></a> | <a href=\"./README_JA.md\"><b>Êó•Êú¨Ë™û</b></a> |\n</p>\n\n<p align=\"center\">\n  <h4 align=\"center\">\n\n  [Overview](#-overview) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Key Features](#-key-features) ‚Ä¢ [Getting Started](#-getting-started) ‚Ä¢ [API Reference](#-api-reference) ‚Ä¢ [Developer Guide](#-developer-guide)\n  \n  </h4>\n</p>\n\n# üí° WeKnora - LLM-Powered Document Understanding & Retrieval Framework\n\n## üìå Overview\n\n[**WeKnora**](https://weknora.weixin.qq.com) is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents. \n\nIt adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the **RAG (Retrieval-Augmented Generation)** paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.\n\n**Website:** https://weknora.weixin.qq.com\n\n## ‚ú® Latest Updates\n\n**v0.2.0 Highlights:**\n\n- ü§ñ **Agent Mode**: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection\n- üìö **Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry\n- ‚öôÔ∏è **Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior\n- üåê **Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine\n- üîå **MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods\n- üé® **New UI**: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade\n- ‚ö° **Infrastructure Upgrade**: Introduced MQ async task management, support for automatic database migration, and fast development mode\n\n## üîí Security Notice\n\n**Important:** Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:\n\n- Deploy WeKnora services in internal/private network environments rather than public internet\n- Avoid exposing the service directly to public networks to prevent potential information leakage\n- Configure proper firewall rules and access controls for your deployment environment\n- Regularly update to the latest version for security patches and improvements\n\n## üèóÔ∏è Architecture\n\n![weknora-architecture.png](./docs/images/architecture.png)\n\nWeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.\n\n## üéØ Key Features\n\n- **ü§ñ Agent Mode**: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection\n- **üîç Precise Understanding**: Structured content extraction from PDFs, Word documents, images and more into unified semantic views\n- **üß† Intelligent Reasoning**: Leverages LLMs to understand document context and user intent for accurate Q&A and multi-turn conversations\n- **üìö Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities\n- **üîß Flexible Extension**: All components from parsing and embedding to retrieval and generation are decoupled for easy customization\n- **‚ö° Efficient Retrieval**: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support\n- **üåê Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine\n- **üîå MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods\n- **‚öôÔ∏è Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior\n- **üéØ User-Friendly**: Intuitive web interface and standardized APIs for zero technical barriers\n- **üîí Secure & Controlled**: Support for local deployment and private cloud, ensuring complete data sovereignty\n\n## üìä Application Scenarios\n\n| Scenario | Applications | Core Value |\n|---------|----------|----------|\n| **Enterprise Knowledge Management** | Internal document retrieval, policy Q&A, operation manual search | Improve knowledge discovery efficiency, reduce training costs |\n| **Academic Research Analysis** | Paper retrieval, research report analysis, scholarly material organization | Accelerate literature review, assist research decisions |\n| **Product Technical Support** | Product manual Q&A, technical documentation search, troubleshooting | Enhance customer service quality, reduce support burden |\n| **Legal & Compliance Review** | Contract clause retrieval, regulatory policy search, case analysis | Improve compliance efficiency, reduce legal risks |\n| **Medical Knowledge Assistance** | Medical literature retrieval, treatment guideline search, case analysis | Support clinical decisions, improve diagnosis quality |\n\n## üß© Feature Matrix\n\n| Module | Support                                                                        | Description                                                                                                                                                        |\n|---------|--------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Agent Mode | ‚úÖ ReACT Agent Mode                                                             | Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations               |\n| Knowledge Base Types | ‚úÖ FAQ / Document                                                               | Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry                                       |\n| Document Formats | ‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)                    | Support for structured and unstructured documents with text extraction from images                                                                                 |\n| Model Management | ‚úÖ Centralized configuration, built-in model sharing                            | Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models                                   |\n| Embedding Models | ‚úÖ Local models, BGE / GTE APIs, etc.                                           | Customizable embedding models, compatible with local deployment and cloud vector generation APIs                                                                   |\n| Vector DB Integration | ‚úÖ PostgreSQL (pgvector), Elasticsearch                                         | Support for mainstream vector index backends, flexible switching for different retrieval scenarios                                                                 |\n| Retrieval Strategies | ‚úÖ BM25 / Dense Retrieval / GraphRAG                                            | Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines                                        |\n| LLM Integration | ‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching  | Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration                                                     |\n| Conversation Strategy | ‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration | Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior |\n| Web Search | ‚úÖ Extensible search engines, DuckDuckGo / Google                               | Support for extensible web search engines with built-in DuckDuckGo search engine                                                                                   |\n| MCP Tools | ‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE                                | Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods                                      |\n| QA Capabilities | ‚úÖ Context-aware, multi-turn dialogue, prompt templates                         | Support for complex semantic modeling, instruction control and chain-of-thought Q&A with configurable prompts and context windows                                  |\n| E2E Testing | ‚úÖ Retrieval+generation process visualization and metric evaluation             | End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics                                                            |\n| Deployment Modes | ‚úÖ Support for local deployment / Docker images                                 | Meets private, offline deployment and flexible operation requirements, with fast development mode support                                                          |\n| User Interfaces | ‚úÖ Web UI + RESTful API                                                         | Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display                                              |\n| Task Management | ‚úÖ MQ async tasks, automatic database migration                                 | MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades                                            |\n\n## üöÄ Getting Started\n\n### üõ† Prerequisites\n\nMake sure the following tools are installed on your system:\n\n* [Docker](https://www.docker.com/)\n* [Docker Compose](https://docs.docker.com/compose/)\n* [Git](https://git-scm.com/)\n\n### üì¶ Installation\n\n#### ‚ë† Clone the repository\n\n```bash\n# Clone the main repository\ngit clone https://github.com/Tencent/WeKnora.git\ncd WeKnora\n```\n\n#### ‚ë° Configure environment variables\n\n```bash\n# Copy example env file\ncp .env.example .env\n\n# Edit .env and set required values\n# All variables are documented in the .env.example comments\n```\n\n#### ‚ë¢ Start the services (include Ollama)\n\nCheck the images that need to be started in the .env file.\n\n```bash\n./scripts/start_all.sh\n```\n\nor\n\n```bash\nmake start-all\n```\n\n#### ‚ë¢.0 Start ollama services (Optional)\n\n```bash\nollama serve > /dev/null 2>&1 &\n```\n\n#### ‚ë¢.1 Activate different combinations of features\n\n- Minimum core services\n```bash\ndocker compose up -d\n```\n\n- All features enabled\n```bash\ndocker-compose --profile full up -d\n```\n\n- Tracing logs required\n```bash\ndocker-compose --profile jaeger up -d\n```\n\n- Neo4j knowledge graph required\n```bash\ndocker-compose --profile neo4j up -d\n```\n\n- Minio file storage service required\n```bash\ndocker-compose --profile minio up -d\n```\n\n- Multiple options combination\n```bash\ndocker-compose --profile neo4j --profile minio up -d\n```\n\n#### ‚ë£ Stop the services\n\n```bash\n./scripts/start_all.sh --stop\n# Or\nmake stop-all\n```\n\n### üåê Access Services\n\nOnce started, services will be available at:\n\n* Web UI: `http://localhost`\n* Backend API: `http://localhost:8080`\n* Jaeger Tracing: `http://localhost:16686`\n\n### üîå Using WeChat Dialog Open Platform\n\nWeKnora serves as the core technology framework for the [WeChat Dialog Open Platform](https://chatbot.weixin.qq.com), providing a more convenient usage approach:\n\n- **Zero-code Deployment**: Simply upload knowledge to quickly deploy intelligent Q&A services within the WeChat ecosystem, achieving an \"ask and answer\" experience\n- **Efficient Question Management**: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers\n- **WeChat Ecosystem Integration**: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences\n\n### üîó Access WeKnora via MCP Server\n\n#### 1Ô∏è‚É£ Clone the repository\n```\ngit clone https://github.com/Tencent/WeKnora\n```\n\n#### 2Ô∏è‚É£ Configure MCP Server\n> It is recommended to directly refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for configuration.\n\nConfigure the MCP client to connect to the server:\n```json\n{\n  \"mcpServers\": {\n    \"weknora\": {\n      \"args\": [\n        \"path/to/WeKnora/mcp-server/run_server.py\"\n      ],\n      \"command\": \"python\",\n      \"env\":{\n        \"WEKNORA_API_KEY\":\"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk\",\n        \"WEKNORA_BASE_URL\":\"http(s)://your-weknora-address/api/v1\"\n      }\n    }\n  }\n}\n```\n\nRun directly using stdio command:\n```\npip install weknora-mcp-server\npython -m weknora-mcp-server\n```\n\n## üîß Initialization Configuration Guide\n\nTo help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows:\nIf this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.\n\n### ‚ë† Stop the services\n\n```bash\n./scripts/start_all.sh --stop\n```\n\n### ‚ë° Clear existing data tables (recommended when no important data exists)\n\n```bash\nmake clean-db\n```\n\n### ‚ë¢ Compile and start services\n\n```bash\n./scripts/start_all.sh\n```\n\n### ‚ë£ Access Web UI\n\nhttp://localhost\n\nOn your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.\n\n## üì± Interface Showcase\n\n### Web UI Interface\n\n<table>\n  <tr>\n    <td><b>Knowledge Base Management</b><br/><img src=\"./docs/images/knowledgebases.png\" alt=\"Knowledge Base Management\"></td>\n    <td><b>Conversation Settings</b><br/><img src=\"./docs/images/settings.png\" alt=\"Conversation Settings\"></td>\n  </tr>\n  <tr>\n    <td colspan=\"2\"><b>Agent Mode Tool Call Process</b><br/><img src=\"./docs/images/agent-qa.png\" alt=\"Agent Mode Tool Call Process\"></td>\n  </tr>\n</table>\n\n**Knowledge Base Management:** Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.\n\n**Agent Mode:** Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.\n\n**Conversation Strategy:** Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.\n\n### Document Knowledge Graph\n\nWeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.\n\nFor detailed configuration, please refer to the [Knowledge Graph Configuration Guide](./docs/KnowledgeGraph.md).\n\n### MCP Server\n\nPlease refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for the necessary setup.\n\n## üìò API Reference\n\nTroubleshooting FAQ: [Troubleshooting FAQ](./docs/QA.md)\n\nDetailed API documentation is available at: [API Docs](./docs/api/README.md)\n\n## üß≠ Developer Guide\n\n### ‚ö° Fast Development Mode (Recommended)\n\nIf you need to frequently modify code, **you don't need to rebuild Docker images every time**! Use fast development mode:\n\n```bash\n# Method 1: Using Make commands (Recommended)\nmake dev-start      # Start infrastructure\nmake dev-app        # Start backend (new terminal)\nmake dev-frontend   # Start frontend (new terminal)\n\n# Method 2: One-click start\n./scripts/quick-dev.sh\n\n# Method 3: Using scripts\n./scripts/dev.sh start     # Start infrastructure\n./scripts/dev.sh app       # Start backend (new terminal)\n./scripts/dev.sh frontend  # Start frontend (new terminal)\n```\n\n**Development Advantages:**\n- ‚úÖ Frontend modifications auto hot-reload (no restart needed)\n- ‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)\n- ‚úÖ No need to rebuild Docker images\n- ‚úÖ Support IDE breakpoint debugging\n\n**Detailed Documentation:** [Development Environment Quick Start](./docs/ÂºÄÂèëÊåáÂçó.md)\n\n### üìÅ Directory Structure\n\n```\nWeKnora/\n‚îú‚îÄ‚îÄ client/      # go client\n‚îú‚îÄ‚îÄ cmd/         # Main entry point\n‚îú‚îÄ‚îÄ config/      # Configuration files\n‚îú‚îÄ‚îÄ docker/      # docker images files\n‚îú‚îÄ‚îÄ docreader/   # Document parsing app\n‚îú‚îÄ‚îÄ docs/        # Project documentation\n‚îú‚îÄ‚îÄ frontend/    # Frontend app\n‚îú‚îÄ‚îÄ internal/    # Core business logic\n‚îú‚îÄ‚îÄ mcp-server/  # MCP server\n‚îú‚îÄ‚îÄ migrations/  # DB migration scripts\n‚îî‚îÄ‚îÄ scripts/     # Shell scripts\n```\n\n## ü§ù Contributing\n\nWe welcome community contributions! For suggestions, bugs, or feature requests, please submit an [Issue](https://github.com/Tencent/WeKnora/issues) or directly create a Pull Request.\n\n### üéØ How to Contribute\n\n- üêõ **Bug Fixes**: Discover and fix system defects\n- ‚ú® **New Features**: Propose and implement new capabilities\n- üìö **Documentation**: Improve project documentation\n- üß™ **Test Cases**: Write unit and integration tests\n- üé® **UI/UX Enhancements**: Improve user interface and experience\n\n### üìã Contribution Process\n\n1. **Fork the project** to your GitHub account\n2. **Create a feature branch** `git checkout -b feature/amazing-feature`\n3. **Commit changes** `git commit -m 'Add amazing feature'`\n4. **Push branch** `git push origin feature/amazing-feature`\n5. **Create a Pull Request** with detailed description of changes\n\n### üé® Code Standards\n\n- Follow [Go Code Review Comments](https://github.com/golang/go/wiki/CodeReviewComments)\n- Format code using `gofmt`\n- Add necessary unit tests\n- Update relevant documentation\n\n### üìù Commit Guidelines\n\nUse [Conventional Commits](https://www.conventionalcommits.org/) standard:\n\n```\nfeat: Add document batch upload functionality\nfix: Resolve vector retrieval precision issue\ndocs: Update API documentation\ntest: Add retrieval engine test cases\nrefactor: Restructure document parsing module\n```\n\n## üë• Contributors\n\nThanks to these excellent contributors:\n\n[![Contributors](https://contrib.rocks/image?repo=Tencent/WeKnora)](https://github.com/Tencent/WeKnora/graphs/contributors)\n\n## üìÑ License\n\nThis project is licensed under the [MIT License](./LICENSE).\nYou are free to use, modify, and distribute the code with proper attribution.\n\n## üìà Project Statistics\n\n<a href=\"https://www.star-history.com/#Tencent/WeKnora&type=date&legend=top-left\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=Tencent/WeKnora&type=date&theme=dark&legend=top-left\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=Tencent/WeKnora&type=date&legend=top-left\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=Tencent/WeKnora&type=date&legend=top-left\" />\n </picture>\n</a>\n",
      "stars_today": 173
    },
    {
      "id": 191820100,
      "name": "mediapipe",
      "full_name": "google-ai-edge/mediapipe",
      "description": "Cross-platform, customizable ML solutions for live and streaming media.",
      "html_url": "https://github.com/google-ai-edge/mediapipe",
      "stars": 33299,
      "forks": 5744,
      "language": "C++",
      "topics": [
        "android",
        "audio-processing",
        "c-plus-plus",
        "calculator",
        "computer-vision",
        "deep-learning",
        "framework",
        "graph-based",
        "graph-framework",
        "inference",
        "machine-learning",
        "mediapipe",
        "mobile-development",
        "perception",
        "pipeline-framework",
        "stream-processing",
        "video-processing"
      ],
      "created_at": "2019-06-13T19:16:41Z",
      "updated_at": "2026-01-17T00:39:41Z",
      "pushed_at": "2026-01-16T21:18:02Z",
      "open_issues": 617,
      "owner": {
        "login": "google-ai-edge",
        "avatar_url": "https://avatars.githubusercontent.com/u/150697620?v=4"
      },
      "readme": "---\nlayout: forward\ntarget: https://developers.google.com/mediapipe\ntitle: Home\nnav_order: 1\n---\n\n----\n\n**Attention:** *We have moved to\n[https://developers.google.com/mediapipe](https://developers.google.com/mediapipe)\nas the primary developer documentation site for MediaPipe as of April 3, 2023.*\n\n![MediaPipe](https://developers.google.com/static/mediapipe/images/home/hero_01_1920.png)\n\n**Attention**: MediaPipe Solutions Preview is an early release. [Learn\nmore](https://developers.google.com/mediapipe/solutions/about#notice).\n\n**On-device machine learning for everyone**\n\nDelight your customers with innovative machine learning features. MediaPipe\ncontains everything that you need to customize and deploy to mobile (Android,\niOS), web, desktop, edge devices, and IoT, effortlessly.\n\n*   [See demos](https://goo.gle/mediapipe-studio)\n*   [Learn more](https://developers.google.com/mediapipe/solutions)\n\n## Get started\n\nYou can get started with MediaPipe Solutions by by checking out any of the\ndeveloper guides for\n[vision](https://developers.google.com/mediapipe/solutions/vision/object_detector),\n[text](https://developers.google.com/mediapipe/solutions/text/text_classifier),\nand\n[audio](https://developers.google.com/mediapipe/solutions/audio/audio_classifier)\ntasks. If you need help setting up a development environment for use with\nMediaPipe Tasks, check out the setup guides for\n[Android](https://developers.google.com/mediapipe/solutions/setup_android), [web\napps](https://developers.google.com/mediapipe/solutions/setup_web), and\n[Python](https://developers.google.com/mediapipe/solutions/setup_python).\n\n## Solutions\n\nMediaPipe Solutions provides a suite of libraries and tools for you to quickly\napply artificial intelligence (AI) and machine learning (ML) techniques in your\napplications. You can plug these solutions into your applications immediately,\ncustomize them to your needs, and use them across multiple development\nplatforms. MediaPipe Solutions is part of the MediaPipe [open source\nproject](https://github.com/google/mediapipe), so you can further customize the\nsolutions code to meet your application needs.\n\nThese libraries and resources provide the core functionality for each MediaPipe\nSolution:\n\n*   **MediaPipe Tasks**: Cross-platform APIs and libraries for deploying\n    solutions. [Learn\n    more](https://developers.google.com/mediapipe/solutions/tasks).\n*   **MediaPipe models**: Pre-trained, ready-to-run models for use with each\n    solution.\n\nThese tools let you customize and evaluate solutions:\n\n*   **MediaPipe Model Maker**: Customize models for solutions with your data.\n    [Learn more](https://developers.google.com/mediapipe/solutions/model_maker).\n*   **MediaPipe Studio**: Visualize, evaluate, and benchmark solutions in your\n    browser. [Learn\n    more](https://developers.google.com/mediapipe/solutions/studio).\n\n### Legacy solutions\n\nWe have ended support for [these MediaPipe Legacy Solutions](https://developers.google.com/mediapipe/solutions/guide#legacy)\nas of March 1, 2023. All other MediaPipe Legacy Solutions will be upgraded to\na new MediaPipe Solution. See the [Solutions guide](https://developers.google.com/mediapipe/solutions/guide#legacy)\nfor details. The [code repository](https://github.com/google/mediapipe/tree/master/mediapipe)\nand prebuilt binaries for all MediaPipe Legacy Solutions will continue to be\nprovided on an as-is basis.\n\nFor more on the legacy solutions, see the [documentation](https://github.com/google/mediapipe/tree/master/docs/solutions).\n\n## Framework\n\nTo start using MediaPipe Framework, [install MediaPipe\nFramework](https://developers.google.com/mediapipe/framework/getting_started/install)\nand start building example applications in C++, Android, and iOS.\n\n[MediaPipe Framework](https://developers.google.com/mediapipe/framework) is the\nlow-level component used to build efficient on-device machine learning\npipelines, similar to the premade MediaPipe Solutions.\n\nBefore using MediaPipe Framework, familiarize yourself with the following key\n[Framework\nconcepts](https://developers.google.com/mediapipe/framework/framework_concepts/overview.md):\n\n*   [Packets](https://developers.google.com/mediapipe/framework/framework_concepts/packets.md)\n*   [Graphs](https://developers.google.com/mediapipe/framework/framework_concepts/graphs.md)\n*   [Calculators](https://developers.google.com/mediapipe/framework/framework_concepts/calculators.md)\n\n## Community\n\n*   [Slack community](https://mediapipe.page.link/joinslack) for MediaPipe\n    users.\n*   [Discuss](https://groups.google.com/forum/#!forum/mediapipe) - General\n    community discussion around MediaPipe.\n*   [Awesome MediaPipe](https://mediapipe.page.link/awesome-mediapipe) - A\n    curated list of awesome MediaPipe related frameworks, libraries and\n    software.\n\n## Contributing\n\nWe welcome contributions. Please follow these\n[guidelines](https://github.com/google/mediapipe/blob/master/CONTRIBUTING.md).\n\nWe use GitHub issues for tracking requests and bugs. Please post questions to\nthe MediaPipe Stack Overflow with a `mediapipe` tag.\n\n## Resources\n\n### Publications\n\n*   [Bringing artworks to life with AR](https://developers.googleblog.com/2021/07/bringing-artworks-to-life-with-ar.html)\n    in Google Developers Blog\n*   [Prosthesis control via Mirru App using MediaPipe hand tracking](https://developers.googleblog.com/2021/05/control-your-mirru-prosthesis-with-mediapipe-hand-tracking.html)\n    in Google Developers Blog\n*   [SignAll SDK: Sign language interface using MediaPipe is now available for\n    developers](https://developers.googleblog.com/2021/04/signall-sdk-sign-language-interface-using-mediapipe-now-available.html)\n    in Google Developers Blog\n*   [MediaPipe Holistic - Simultaneous Face, Hand and Pose Prediction, on\n    Device](https://ai.googleblog.com/2020/12/mediapipe-holistic-simultaneous-face.html)\n    in Google AI Blog\n*   [Background Features in Google Meet, Powered by Web ML](https://ai.googleblog.com/2020/10/background-features-in-google-meet.html)\n    in Google AI Blog\n*   [MediaPipe 3D Face Transform](https://developers.googleblog.com/2020/09/mediapipe-3d-face-transform.html)\n    in Google Developers Blog\n*   [Instant Motion Tracking With MediaPipe](https://developers.googleblog.com/2020/08/instant-motion-tracking-with-mediapipe.html)\n    in Google Developers Blog\n*   [BlazePose - On-device Real-time Body Pose Tracking](https://ai.googleblog.com/2020/08/on-device-real-time-body-pose-tracking.html)\n    in Google AI Blog\n*   [MediaPipe Iris: Real-time Eye Tracking and Depth Estimation](https://ai.googleblog.com/2020/08/mediapipe-iris-real-time-iris-tracking.html)\n    in Google AI Blog\n*   [MediaPipe KNIFT: Template-based feature matching](https://developers.googleblog.com/2020/04/mediapipe-knift-template-based-feature-matching.html)\n    in Google Developers Blog\n*   [Alfred Camera: Smart camera features using MediaPipe](https://developers.googleblog.com/2020/03/alfred-camera-smart-camera-features-using-mediapipe.html)\n    in Google Developers Blog\n*   [Real-Time 3D Object Detection on Mobile Devices with MediaPipe](https://ai.googleblog.com/2020/03/real-time-3d-object-detection-on-mobile.html)\n    in Google AI Blog\n*   [AutoFlip: An Open Source Framework for Intelligent Video Reframing](https://ai.googleblog.com/2020/02/autoflip-open-source-framework-for.html)\n    in Google AI Blog\n*   [MediaPipe on the Web](https://developers.googleblog.com/2020/01/mediapipe-on-web.html)\n    in Google Developers Blog\n*   [Object Detection and Tracking using MediaPipe](https://developers.googleblog.com/2019/12/object-detection-and-tracking-using-mediapipe.html)\n    in Google Developers Blog\n*   [On-Device, Real-Time Hand Tracking with MediaPipe](https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html)\n    in Google AI Blog\n*   [MediaPipe: A Framework for Building Perception Pipelines](https://arxiv.org/abs/1906.08172)\n\n### Videos\n\n*   [YouTube Channel](https://www.youtube.com/c/MediaPipe)\n",
      "stars_today": 170
    },
    {
      "id": 955620917,
      "name": "context7",
      "full_name": "upstash/context7",
      "description": "Context7 MCP Server -- Up-to-date code documentation for LLMs and AI code editors",
      "html_url": "https://github.com/upstash/context7",
      "stars": 42216,
      "forks": 2051,
      "language": "TypeScript",
      "topics": [
        "llm",
        "mcp",
        "mcp-server",
        "vibe-coding"
      ],
      "created_at": "2025-03-26T23:40:39Z",
      "updated_at": "2026-01-17T00:59:50Z",
      "pushed_at": "2026-01-16T17:25:29Z",
      "open_issues": 87,
      "owner": {
        "login": "upstash",
        "avatar_url": "https://avatars.githubusercontent.com/u/74989412?v=4"
      },
      "readme": "![Cover](https://github.com/upstash/context7/blob/master/public/cover.png?raw=true)\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=context7&config=eyJ1cmwiOiJodHRwczovL21jcC5jb250ZXh0Ny5jb20vbWNwIn0%3D)\n\n# Context7 MCP - Up-to-date Code Docs For Any Prompt\n\n[![Website](https://img.shields.io/badge/Website-context7.com-blue)](https://context7.com) [![smithery badge](https://smithery.ai/badge/@upstash/context7-mcp)](https://smithery.ai/server/@upstash/context7-mcp) [![NPM Version](https://img.shields.io/npm/v/%40upstash%2Fcontext7-mcp?color=red)](https://www.npmjs.com/package/@upstash/context7-mcp) [![MIT licensed](https://img.shields.io/npm/l/%40upstash%2Fcontext7-mcp)](./LICENSE)\n\n[![ÁπÅÈ´î‰∏≠Êñá](https://img.shields.io/badge/docs-ÁπÅÈ´î‰∏≠Êñá-yellow)](./i18n/README.zh-TW.md) [![ÁÆÄ‰Ωì‰∏≠Êñá](https://img.shields.io/badge/docs-ÁÆÄ‰Ωì‰∏≠Êñá-yellow)](./i18n/README.zh-CN.md) [![Êó•Êú¨Ë™û](https://img.shields.io/badge/docs-Êó•Êú¨Ë™û-b7003a)](./i18n/README.ja.md) [![ÌïúÍµ≠Ïñ¥ Î¨∏ÏÑú](https://img.shields.io/badge/docs-ÌïúÍµ≠Ïñ¥-green)](./i18n/README.ko.md) [![Documentaci√≥n en Espa√±ol](https://img.shields.io/badge/docs-Espa√±ol-orange)](./i18n/README.es.md) [![Documentation en Fran√ßais](https://img.shields.io/badge/docs-Fran√ßais-blue)](./i18n/README.fr.md) [![Documenta√ß√£o em Portugu√™s (Brasil)](<https://img.shields.io/badge/docs-Portugu√™s%20(Brasil)-purple>)](./i18n/README.pt-BR.md) [![Documentazione in italiano](https://img.shields.io/badge/docs-Italian-red)](./i18n/README.it.md) [![Dokumentasi Bahasa Indonesia](https://img.shields.io/badge/docs-Bahasa%20Indonesia-pink)](./i18n/README.id-ID.md) [![Dokumentation auf Deutsch](https://img.shields.io/badge/docs-Deutsch-darkgreen)](./i18n/README.de.md) [![–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ](https://img.shields.io/badge/docs-–†—É—Å—Å–∫–∏–π-darkblue)](./i18n/README.ru.md) [![–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è](https://img.shields.io/badge/docs-–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞-lightblue)](./i18n/README.uk.md) [![T√ºrk√ße Dok√ºman](https://img.shields.io/badge/docs-T√ºrk√ße-blue)](./i18n/README.tr.md) [![Arabic Documentation](https://img.shields.io/badge/docs-Arabic-white)](./i18n/README.ar.md) [![Ti·∫øng Vi·ªát](https://img.shields.io/badge/docs-Ti·∫øng%20Vi·ªát-red)](./i18n/README.vi.md)\n\n## ‚ùå Without Context7\n\nLLMs rely on outdated or generic information about the libraries you use. You get:\n\n- ‚ùå Code examples are outdated and based on year-old training data\n- ‚ùå Hallucinated APIs that don't even exist\n- ‚ùå Generic answers for old package versions\n\n## ‚úÖ With Context7\n\nContext7 MCP pulls up-to-date, version-specific documentation and code examples straight from the source ‚Äî and places them directly into your prompt.\n\nAdd `use context7` to your prompt (or [set up a rule](#add-a-rule) to auto-invoke):\n\n```txt\nCreate a Next.js middleware that checks for a valid JWT in cookies\nand redirects unauthenticated users to `/login`. use context7\n```\n\n```txt\nConfigure a Cloudflare Worker script to cache\nJSON API responses for five minutes. use context7\n```\n\nContext7 fetches up-to-date code examples and documentation right into your LLM's context. No tab-switching, no hallucinated APIs that don't exist, no outdated code generation.\n\n## Installation\n\n> [!NOTE]\n> **API Key Recommended**: Get a free API key at [context7.com/dashboard](https://context7.com/dashboard) for higher rate limits.\n\n<details>\n<summary><b>Install in Cursor</b></summary>\n\nGo to: `Settings` -> `Cursor Settings` -> `MCP` -> `Add new global MCP server`\n\nPasting the following configuration into your Cursor `~/.cursor/mcp.json` file is the recommended approach. You may also install in a specific project by creating `.cursor/mcp.json` in your project folder. See [Cursor MCP docs](https://docs.cursor.com/context/model-context-protocol) for more info.\n\n> Since Cursor 1.0, you can click the install button below for instant one-click installation.\n\n#### Cursor Remote Server Connection\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=context7&config=eyJ1cmwiOiJodHRwczovL21jcC5jb250ZXh0Ny5jb20vbWNwIn0%3D)\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\n#### Cursor Local Server Connection\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=context7&config=eyJjb21tYW5kIjoibnB4IC15IEB1cHN0YXNoL2NvbnRleHQ3LW1jcCJ9)\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in Claude Code</b></summary>\n\nRun this command. See [Claude Code MCP docs](https://code.claude.com/docs/en/mcp) for more info.\n\n#### Claude Code Local Server Connection\n\n```sh\nclaude mcp add context7 -- npx -y @upstash/context7-mcp --api-key YOUR_API_KEY\n```\n\n#### Claude Code Remote Server Connection\n\n```sh\nclaude mcp add --header \"CONTEXT7_API_KEY: YOUR_API_KEY\" --transport http context7 https://mcp.context7.com/mcp\n```\n\n</details>\n\n<details>\n<summary><b>Install in Opencode</b></summary>\n\nAdd this to your Opencode configuration file. See [Opencode MCP docs](https://opencode.ai/docs/mcp-servers) for more info.\n\n#### Opencode Remote Server Connection\n\n```json\n\"mcp\": {\n  \"context7\": {\n    \"type\": \"remote\",\n    \"url\": \"https://mcp.context7.com/mcp\",\n    \"headers\": {\n      \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n    },\n    \"enabled\": true\n  }\n}\n```\n\n#### Opencode Local Server Connection\n\n```json\n{\n  \"mcp\": {\n    \"context7\": {\n      \"type\": \"local\",\n      \"command\": [\"npx\", \"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"],\n      \"enabled\": true\n    }\n  }\n}\n```\n\n</details>\n\n**[Other IDEs and Clients ‚Üí](https://context7.com/docs/resources/all-clients)**\n\n<details>\n<summary><b>OAuth Authentication</b></summary>\n\nContext7 MCP server supports OAuth 2.0 authentication for MCP clients that implement the [MCP OAuth specification](https://modelcontextprotocol.io/specification/2025-03-26/basic/authorization).\n\nTo use OAuth, change the endpoint from `/mcp` to `/mcp/oauth` in your client configuration:\n\n```diff\n- \"url\": \"https://mcp.context7.com/mcp\"\n+ \"url\": \"https://mcp.context7.com/mcp/oauth\"\n```\n\nOAuth is only available for remote HTTP connections. For local MCP connections using stdio transport, use API key authentication instead.\n\n</details>\n\n## Important Tips\n\n### Add a Rule\n\nTo avoid typing `use context7` in every prompt, add a rule to your MCP client to automatically invoke Context7 for code-related questions:\n\n- **Cursor**: `Cursor Settings > Rules`\n- **Claude Code**: `CLAUDE.md`\n- Or the equivalent in your MCP client\n\n**Example rule:**\n\n```txt\nAlways use Context7 MCP when I need library/API documentation, code generation, setup or configuration steps without me having to explicitly ask.\n```\n\n### Use Library Id\n\nIf you already know exactly which library you want to use, add its Context7 ID to your prompt. That way, Context7 MCP server can skip the library-matching step and directly continue with retrieving docs.\n\n```txt\nImplement basic authentication with Supabase. use library /supabase/supabase for API and docs.\n```\n\nThe slash syntax tells the MCP tool exactly which library to load docs for.\n\n### Specify a Version\n\nTo get documentation for a specific library version, just mention the version in your prompt:\n\n```txt\nHow do I set up Next.js 14 middleware? use context7\n```\n\nContext7 will automatically match the appropriate version.\n\n## Available Tools\n\nContext7 MCP provides the following tools that LLMs can use:\n\n- `resolve-library-id`: Resolves a general library name into a Context7-compatible library ID.\n  - `query` (required): The user's question or task (used to rank results by relevance)\n  - `libraryName` (required): The name of the library to search for\n\n- `query-docs`: Retrieves documentation for a library using a Context7-compatible library ID.\n  - `libraryId` (required): Exact Context7-compatible library ID (e.g., `/mongodb/docs`, `/vercel/next.js`)\n  - `query` (required): The question or task to get relevant documentation for\n\n## More Documentation\n\n- [More MCP Clients](https://context7.com/docs/resources/all-clients) - Installation for 30+ clients\n- [Adding Libraries](https://context7.com/docs/adding-libraries) - Submit your library to Context7\n- [Troubleshooting](https://context7.com/docs/resources/troubleshooting) - Common issues and solutions\n- [API Reference](https://context7.com/docs/api-guide) - REST API documentation\n- [Developer Guide](https://context7.com/docs/resources/developer) - Run Context7 MCP locally\n\n## Disclaimer\n\n1- Context7 projects are community-contributed and while we strive to maintain high quality, we cannot guarantee the accuracy, completeness, or security of all library documentation. Projects listed in Context7 are developed and maintained by their respective owners, not by Context7. If you encounter any suspicious, inappropriate, or potentially harmful content, please use the \"Report\" button on the project page to notify us immediately. We take all reports seriously and will review flagged content promptly to maintain the integrity and safety of our platform. By using Context7, you acknowledge that you do so at your own discretion and risk.\n\n2- This repository hosts the MCP server‚Äôs source code. The supporting components ‚Äî API backend, parsing engine, and crawling engine ‚Äî are private and not part of this repository.\n\n## ü§ù Connect with Us\n\nStay updated and join our community:\n\n- üì¢ Follow us on [X](https://x.com/context7ai) for the latest news and updates\n- üåê Visit our [Website](https://context7.com)\n- üí¨ Join our [Discord Community](https://upstash.com/discord)\n\n## üì∫ Context7 In Media\n\n- [Better Stack: \"Free Tool Makes Cursor 10x Smarter\"](https://youtu.be/52FC3qObp9E)\n- [Cole Medin: \"This is Hands Down the BEST MCP Server for AI Coding Assistants\"](https://www.youtube.com/watch?v=G7gK8H6u7Rs)\n- [Income Stream Surfers: \"Context7 + SequentialThinking MCPs: Is This AGI?\"](https://www.youtube.com/watch?v=-ggvzyLpK6o)\n- [Julian Goldie SEO: \"Context7: New MCP AI Agent Update\"](https://www.youtube.com/watch?v=CTZm6fBYisc)\n- [JeredBlu: \"Context 7 MCP: Get Documentation Instantly + VS Code Setup\"](https://www.youtube.com/watch?v=-ls0D-rtET4)\n- [Income Stream Surfers: \"Context7: The New MCP Server That Will CHANGE AI Coding\"](https://www.youtube.com/watch?v=PS-2Azb-C3M)\n- [AICodeKing: \"Context7 + Cline & RooCode: This MCP Server Makes CLINE 100X MORE EFFECTIVE!\"](https://www.youtube.com/watch?v=qZfENAPMnyo)\n- [Sean Kochel: \"5 MCP Servers For Vibe Coding Glory (Just Plug-In & Go)\"](https://www.youtube.com/watch?v=LqTQi8qexJM)\n\n## ‚≠ê Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=upstash/context7&type=Date)](https://www.star-history.com/#upstash/context7&Date)\n\n## üìÑ License\n\nMIT\n",
      "stars_today": 139
    },
    {
      "id": 48109239,
      "name": "cilium",
      "full_name": "cilium/cilium",
      "description": "eBPF-based Networking, Security, and Observability",
      "html_url": "https://github.com/cilium/cilium",
      "stars": 23440,
      "forks": 3540,
      "language": "Go",
      "topics": [
        "bpf",
        "cncf",
        "cni",
        "containers",
        "ebpf",
        "k8s",
        "kernel",
        "kubernetes",
        "kubernetes-networking",
        "loadbalancing",
        "monitoring",
        "networking",
        "observability",
        "security",
        "troubleshooting",
        "xdp"
      ],
      "created_at": "2015-12-16T12:33:31Z",
      "updated_at": "2026-01-17T00:15:47Z",
      "pushed_at": "2026-01-16T19:15:39Z",
      "open_issues": 980,
      "owner": {
        "login": "cilium",
        "avatar_url": "https://avatars.githubusercontent.com/u/21054566?v=4"
      },
      "readme": ".. raw:: html\n\n   <picture>\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://cdn.jsdelivr.net/gh/cilium/cilium@main/Documentation/images/logo.png\" width=\"350\" alt=\"Cilium Logo\">\n      <img src=\"https://cdn.jsdelivr.net/gh/cilium/cilium@main/Documentation/images/logo-dark.png\" width=\"350\" alt=\"Cilium Logo\">\n   </picture>\n\n|cii| |go-report| |clomonitor| |artifacthub| |slack| |go-doc| |rtd| |apache| |bsd| |gpl| |fossa| |gateway-api| |codespaces|\n\nCilium is a networking, observability, and security solution with an eBPF-based\ndataplane. It provides a simple flat Layer 3 network with the ability to span\nmultiple clusters in either a native routing or overlay mode. It is L7-protocol\naware and can enforce network policies on L3-L7 using an identity based security\nmodel that is decoupled from network addressing.\n\nCilium implements distributed load balancing for traffic between pods and to\nexternal services, and is able to fully replace kube-proxy, using efficient\nhash tables in eBPF allowing for almost unlimited scale. It also supports\nadvanced functionality like integrated ingress and egress gateway, bandwidth\nmanagement and service mesh, and provides deep network and security visibility and monitoring.\n\nA new Linux kernel technology called eBPF_ is at the foundation of Cilium. It\nsupports dynamic insertion of eBPF bytecode into the Linux kernel at various\nintegration points such as: network IO, application sockets, and tracepoints to\nimplement security, networking and visibility logic. eBPF is highly efficient\nand flexible. To learn more about eBPF, visit `eBPF.io`_.\n\n.. image:: Documentation/images/cilium-overview.png\n   :alt: Overview of Cilium features for networking, observability, service mesh, and runtime security\n\n.. raw:: html\n\n   <a href=\"https://cncf.io/\">\n      <picture>\n         <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/cncf/artwork/blob/main/other/cncf-member/graduated/color/cncf-graduated-color.svg\" />\n         <img src=\"https://github.com/cncf/artwork/blob/main/other/cncf-member/graduated/white/cncf-graduated-white.svg\" alt=\"CNCF Graduated Project\" height=\"80\" />\n      </picture>\n   </a>\n   <a href=\"https://ebpf.io/\">\n      <picture>\n         <source media=\"(prefers-color-scheme: light)\" srcset=\".github/assets/ebpf-horizontal.svg\" />\n         <img src=\".github/assets/ebpf-horizontal-dark-back.svg\" alt=\"eBPF Logo\" height=\"80\" align=\"right\" />\n      </picture>\n   </a>\n\nStable Releases\n===============\n\nThe Cilium community maintains minor stable releases for the last three minor\nCilium versions. Older Cilium stable versions from minor releases prior to that\nare considered EOL.\n\nFor upgrades to new minor releases please consult the `Cilium Upgrade Guide`_.\n\nListed below are the actively maintained release branches along with their latest\npatch release, corresponding image pull tags and their release notes:\n\n+---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+\n| `v1.18 <https://github.com/cilium/cilium/tree/v1.18>`__ | 2026-01-13 | ``quay.io/cilium/cilium:v1.18.6``  | `Release Notes <https://github.com/cilium/cilium/releases/tag/v1.18.6>`__  |\n+---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+\n| `v1.17 <https://github.com/cilium/cilium/tree/v1.17>`__ | 2026-01-13 | ``quay.io/cilium/cilium:v1.17.12`` | `Release Notes <https://github.com/cilium/cilium/releases/tag/v1.17.12>`__ |\n+---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+\n| `v1.16 <https://github.com/cilium/cilium/tree/v1.16>`__ | 2026-01-13 | ``quay.io/cilium/cilium:v1.16.19`` | `Release Notes <https://github.com/cilium/cilium/releases/tag/v1.16.19>`__ |\n+---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+\n\nArchitectures\n-------------\n\nCilium images are distributed for AMD64 and AArch64 architectures.\n\nSoftware Bill of Materials\n--------------------------\n\nStarting with Cilium version 1.13.0, all images include a Software Bill of\nMaterials (SBOM). The SBOM is generated in `SPDX`_ format. More information\non this is available on `Cilium SBOM`_.\n\n.. _`SPDX`: https://spdx.dev/\n.. _`Cilium SBOM`: https://docs.cilium.io/en/latest/configuration/sbom/\n\nDevelopment\n===========\n\nFor development and testing purpose, the Cilium community publishes snapshots,\nearly release candidates (RC) and CI container images build from the `main\nbranch <https://github.com/cilium/cilium/commits/main>`_. These images are\nnot for use in production.\n\nFor testing upgrades to new development releases please consult the latest\ndevelopment build of the `Cilium Upgrade Guide`_.\n\nListed below are branches for testing along with their snapshots or RC releases,\ncorresponding image pull tags and their release notes where applicable:\n\n+----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+\n| `main <https://github.com/cilium/cilium/commits/main>`__                   | daily      | ``quay.io/cilium/cilium-ci:latest``     | N/A                                                                             |\n+----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+\n| `v1.19.0-rc.0 <https://github.com/cilium/cilium/commits/v1.19.0-rc.0>`__   | 2026-01-15 | ``quay.io/cilium/cilium:v1.19.0-rc.0``  | `Release Notes <https://github.com/cilium/cilium/releases/tag/v1.19.0-rc.0>`__  |\n+----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+\n\nFunctionality Overview\n======================\n\n.. begin-functionality-overview\n\nCNI (Container Network Interface)\n---------------------------------\n\n`Cilium as a CNI plugin <https://cilium.io/use-cases/cni/>`_ provides a\nfast, scalable, and secure networking layer for Kubernetes clusters. Built\non eBPF, it offers several deployment options:\n\n* **Overlay networking:** encapsulation-based virtual network spanning all\n  hosts with support for VXLAN and Geneve. It works on almost any network\n  infrastructure as the only requirement is IP connectivity between hosts\n  which is typically already given.\n\n* **Native routing mode:** Use of the regular routing table of the Linux\n  host. The network is required to be capable of routing the IP addresses\n  of the application containers. It integrates with cloud routers, routing\n  daemons, and IPv6-native infrastructure.\n\n* **Flexible routing options:** Cilium can automate route learning and\n  advertisement in common topologies such as using L2 neighbor discovery\n  when nodes share a layer 2 domain, or BGP when routing across layer 3\n  boundaries.\n\nEach mode is designed for maximum interoperability with existing\ninfrastructure while minimizing operational burden.\n\nLoad Balancing\n--------------\n\nCilium implements distributed load balancing for traffic between application\ncontainers and to/from external services. The load balancing is implemented\nin eBPF using efficient hashtables enabling high service density and low\nlatency at scale.\n\n* **East-west load balancing** rewrites service connections at the socket\n  level (``connect()``), avoiding the overhead of per-packet NAT and fully\n  `replacing kube-proxy <https://cilium.io/use-cases/kube-proxy/>`_.\n\n* **North-south load balancing** supports XDP for high-throughput scenarios\n  and `layer 4 load balancing <https://cilium.io/use-cases/load-balancer/>`_\n  including Direct Server Return (DSR), and Maglev consistent hashing.\n\nCluster Mesh\n------------\n\nCilium `Cluster Mesh <https://cilium.io/use-cases/cluster-mesh/>`_ enables\nsecure, seamless connectivity across multiple Kubernetes clusters. For\noperators running hybrid or multi-cloud environments, Cluster Mesh ensures\na consistent security and connectivity experience.\n\n* **Global service discovery**: Workloads across clusters can discover and\n  connect to services as if they were local. This enables fault tolerance,\n  like automatically failing over to backends in another cluster, and\n  exposes shared services like logging, auth, or databases across\n  environments.\n\n* **Unified identity model:** Security policies are enforced based on\n  identity, not IP address, across all clusters.\n\nNetwork Policy\n--------------\n\nCilium `Network Policy <https://cilium.io/use-cases/network-policy/>`_\nprovides identity-aware enforcement across L3-L7. Typical container\nfirewalls secure workloads by filtering on source IP addresses and\ndestination ports. This concept requires the firewalls on all servers to be\nmanipulated whenever a container is started anywhere in the cluster.\n\nIn order to avoid this situation which limits scale, Cilium assigns a\nsecurity identity to groups of application containers which share identical\nsecurity policies. The identity is then associated with all network packets\nemitted by the application containers, allowing to validate the identity at\nthe receiving node.\n\n* **Identity-based security** removes reliance on brittle IP addresses.\n\n* **L3/L4 policies** restrict traffic based on labels, protocols, and ports.\n\n* **DNS-based policies:** Allow or deny traffic to FQDNs or wildcard domains\n   (e.g., ``api.example.com``, ``*.trusted.com``). This is especially useful\n   for securing egress traffic to third-party services.\n\n* **L7-aware policies** allow filtering by HTTP method, URL path, gRPC call,\n  and more:\n\n  * Example: Allow only GET requests to ``/public/.*``.\n\n  * Enforce the presence of headers like ``X-Token: [0-9]+``.\n\nCIDR-based egress and ingress policies are also supported for controlling\naccess to external IPs, ideal for integrating with legacy systems or\nregulatory boundaries.\n\nService Mesh\n------------\n\nWith Cilium `Service Mesh <https://cilium.io/use-cases/service-mesh/>`_,\noperators gain the benefits of fine-grained traffic control, encryption, observability,\naccess control, without the cost and complexity of traditional proxy-based\ndesigns. Key features include:\n\n* **Mutual authentication** with automatic identity-based encryption between\n  workloads using IPSec or WireGuard.\n\n* **L7-aware policy enforcement** for security and compliance.\n\n* **Deep integration with the Kubernetes Gateway API :** Acts as a\n  `Gateway API <https://cilium.io/use-cases/gateway-api/>`_ compliant data\n  plane, allowing you to declaratively manage ingress, traffic splitting, and\n  routing behavior using Kubernetes-native CRDs.\n\nObservability and Troubleshooting\n---------------------------------\n\nObservability is built into Cilium from the ground up, providing rich\nvisibility that helps operators diagnose and understand system behavior\nincluding:\n\n* **Hubble**: A fully integrated observability platform that offers\n  real-time service maps, flow visibility with identity and label metadata,\n  and DNS-aware filtering and protocol-specific insights\n\n* **Metrics and alerting**: Integration with Prometheus, Grafana, and other\n  monitoring systems.\n\n* **Drop reasons and audit trails**: Get actionable insights into why traffic\n  was dropped, including policy or port violations and issues like failed\n  DNS lookups.\n\n.. end-functionality-overview\n\nGetting Started\n===============\n\n* `Why Cilium?`_\n* `Getting Started`_\n* `Architecture and Concepts`_\n* `Installing Cilium`_\n* `Frequently Asked Questions`_\n* Contributing_\n\nCommunity\n=========\n\nSlack\n-----\n\nJoin the Cilium `Slack channel <https://slack.cilium.io>`_ to chat with\nCilium developers and other Cilium users. This is a good place to learn about\nCilium, ask questions, and share your experiences.\n\nSpecial Interest Groups (SIG)\n-----------------------------\n\nSee `Special Interest groups\n<https://github.com/cilium/community/blob/main/sigs.yaml>`_ for a list of all SIGs and their meeting times.\n\nDeveloper meetings\n------------------\nThe Cilium developer community hangs out on Zoom to chat. Everybody is welcome.\n\n* Weekly, Wednesday,\n  5:00 pm `Europe/Zurich time <https://time.is/Canton_of_Zurich>`__ (CET/CEST),\n  usually equivalent to 8:00 am PT, or 11:00 am ET. `Meeting Notes and Zoom Info`_\n* Third Wednesday of each month, 9:00 am `Japan time <https://time.is/Tokyo>`__ (JST). `APAC Meeting Notes and Zoom Info`_\n\neBPF & Cilium Office Hours livestream\n-------------------------------------\nWe host a weekly community `YouTube livestream called eCHO <https://www.youtube.com/channel/UCJFUxkVQTBJh3LD1wYBWvuQ>`_ which (very loosely!) stands for eBPF & Cilium Office Hours. Join us live, catch up with past episodes, or head over to the `eCHO repo <https://github.com/isovalent/eCHO>`_ and let us know your ideas for topics we should cover.\n\nGovernance\n----------\nThe Cilium project is governed by a group of `Maintainers and Committers <https://raw.githubusercontent.com/cilium/cilium/main/MAINTAINERS.md>`__.\nHow they are selected and govern is outlined in our `governance document <https://github.com/cilium/community/blob/main/GOVERNANCE.md>`__.\n\nAdopters\n--------\nA list of adopters of the Cilium project who are deploying it in production, and of their use cases,\ncan be found in file `USERS.md <https://github.com/cilium/cilium/blob/main/USERS.md>`__.\n\nLicense\n=======\n\n.. _apache-license: LICENSE\n.. _bsd-license: bpf/LICENSE.BSD-2-Clause\n.. _gpl-license: bpf/LICENSE.GPL-2.0\n\nThe Cilium user space components are licensed under the\n`Apache License, Version 2.0 <apache-license_>`__.\nThe BPF code templates are dual-licensed under the\n`General Public License, Version 2.0 (only) <gpl-license_>`__\nand the `2-Clause BSD License <bsd-license_>`__\n(you can use the terms of either license, at your option).\n\n.. _`Cilium Upgrade Guide`: https://docs.cilium.io/en/stable/operations/upgrade/\n.. _`Why Cilium?`: https://docs.cilium.io/en/stable/overview/intro\n.. _`Getting Started`: https://docs.cilium.io/en/stable/#getting-started\n.. _`Architecture and Concepts`: https://docs.cilium.io/en/stable/overview/component-overview/\n.. _`Installing Cilium`: https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/\n.. _`Frequently Asked Questions`: https://github.com/cilium/cilium/issues?utf8=%E2%9C%93&q=is%3Aissue+label%3Akind%2Fquestion+\n.. _Contributing: https://docs.cilium.io/en/stable/contributing/development/\n.. _Prerequisites: https://docs.cilium.io/en/stable/operations/system_requirements/\n.. _`eBPF`: https://ebpf.io\n.. _`eBPF.io`: https://ebpf.io\n.. _`Meeting Notes and Zoom Info`: https://docs.google.com/document/d/1Y_4chDk4rznD6UgXPlPvn3Dc7l-ZutGajUv1eF0VDwQ/edit#\n.. _`APAC Meeting Notes and Zoom Info`: https://docs.google.com/document/d/1egv4qLydr0geP-GjQexYKm4tz3_tHy-LCBjVQcXcT5M/edit#\n\n.. |go-report| image:: https://goreportcard.com/badge/github.com/cilium/cilium\n    :alt: Go Report Card\n    :target: https://goreportcard.com/report/github.com/cilium/cilium\n\n.. |go-doc| image:: https://godoc.org/github.com/cilium/cilium?status.svg\n    :alt: GoDoc\n    :target: https://godoc.org/github.com/cilium/cilium\n\n.. |rtd| image:: https://readthedocs.org/projects/docs/badge/?version=latest\n    :alt: Read the Docs\n    :target: https://docs.cilium.io/\n\n.. |apache| image:: https://img.shields.io/badge/license-Apache-blue.svg\n    :alt: Apache licensed\n    :target: apache-license_\n\n.. |bsd| image:: https://img.shields.io/badge/license-BSD-blue.svg\n    :alt: BSD licensed\n    :target: bsd-license_\n\n.. |gpl| image:: https://img.shields.io/badge/license-GPL-blue.svg\n    :alt: GPL licensed\n    :target: gpl-license_\n\n.. |slack| image:: https://img.shields.io/badge/slack-cilium-brightgreen.svg?logo=slack\n    :alt: Join the Cilium slack channel\n    :target: https://slack.cilium.io\n\n.. |cii| image:: https://bestpractices.coreinfrastructure.org/projects/1269/badge\n    :alt: CII Best Practices\n    :target: https://bestpractices.coreinfrastructure.org/projects/1269\n\n.. |clomonitor| image:: https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/cilium/badge\n    :alt: CLOMonitor\n    :target: https://clomonitor.io/projects/cncf/cilium\n\n.. |artifacthub| image:: https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/cilium\n    :alt: Artifact Hub\n    :target: https://artifacthub.io/packages/helm/cilium/cilium\n\n.. |fossa| image:: https://app.fossa.com/api/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git.svg?type=shield\n    :alt: FOSSA Status\n    :target: https://app.fossa.com/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git?ref=badge_shield\n\n.. |gateway-api| image:: https://img.shields.io/badge/Gateway%20API%20Conformance%20v1.2.0-Cilium-green\n    :alt: Gateway API Status\n    :target: https://github.com/kubernetes-sigs/gateway-api/tree/main/conformance/reports/v1.2.0/cilium-cilium\n\n.. |codespaces| image:: https://img.shields.io/badge/Open_in_GitHub_Codespaces-gray?logo=github\n    :alt: Github Codespaces\n    :target: https://github.com/codespaces/new?hide_repo_select=true&ref=master&repo=48109239&machine=standardLinux32gb&location=WestEurope\n",
      "stars_today": 128
    },
    {
      "id": 965415649,
      "name": "codex",
      "full_name": "openai/codex",
      "description": "Lightweight coding agent that runs in your terminal",
      "html_url": "https://github.com/openai/codex",
      "stars": 56337,
      "forks": 7261,
      "language": "Rust",
      "topics": [],
      "created_at": "2025-04-13T05:37:54Z",
      "updated_at": "2026-01-17T00:52:19Z",
      "pushed_at": "2026-01-17T00:37:32Z",
      "open_issues": 892,
      "owner": {
        "login": "openai",
        "avatar_url": "https://avatars.githubusercontent.com/u/14957082?v=4"
      },
      "readme": "<p align=\"center\"><code>npm i -g @openai/codex</code><br />or <code>brew install --cask codex</code></p>\n<p align=\"center\"><strong>Codex CLI</strong> is a coding agent from OpenAI that runs locally on your computer.\n<p align=\"center\">\n  <img src=\"./.github/codex-cli-splash.png\" alt=\"Codex CLI splash\" width=\"80%\" />\n</p>\n</br>\nIf you want Codex in your code editor (VS Code, Cursor, Windsurf), <a href=\"https://developers.openai.com/codex/ide\">install in your IDE.</a>\n</br>If you are looking for the <em>cloud-based agent</em> from OpenAI, <strong>Codex Web</strong>, go to <a href=\"https://chatgpt.com/codex\">chatgpt.com/codex</a>.</p>\n\n---\n\n## Quickstart\n\n### Installing and running Codex CLI\n\nInstall globally with your preferred package manager:\n\n```shell\n# Install using npm\nnpm install -g @openai/codex\n```\n\n```shell\n# Install using Homebrew\nbrew install --cask codex\n```\n\nThen simply run `codex` to get started.\n\n<details>\n<summary>You can also go to the <a href=\"https://github.com/openai/codex/releases/latest\">latest GitHub Release</a> and download the appropriate binary for your platform.</summary>\n\nEach GitHub Release contains many executables, but in practice, you likely want one of these:\n\n- macOS\n  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`\n  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`\n- Linux\n  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`\n  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`\n\nEach archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.\n\n</details>\n\n### Using Codex with your ChatGPT plan\n\nRun `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what's included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).\n\nYou can also use Codex with an API key, but this requires [additional setup](https://developers.openai.com/codex/auth#sign-in-with-an-api-key).\n\n## Docs\n\n- [**Codex Documentation**](https://developers.openai.com/codex)\n- [**Contributing**](./docs/contributing.md)\n- [**Installing & building**](./docs/install.md)\n- [**Open source fund**](./docs/open-source-fund.md)\n\nThis repository is licensed under the [Apache-2.0 License](LICENSE).\n",
      "stars_today": 119
    },
    {
      "id": 1040906383,
      "name": "agents.md",
      "full_name": "agentsmd/agents.md",
      "description": "AGENTS.md ‚Äî a simple, open format for guiding coding agents",
      "html_url": "https://github.com/agentsmd/agents.md",
      "stars": 15365,
      "forks": 1068,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-08-19T17:22:54Z",
      "updated_at": "2026-01-17T00:56:21Z",
      "pushed_at": "2025-12-19T20:06:52Z",
      "open_issues": 105,
      "owner": {
        "login": "agentsmd",
        "avatar_url": "https://avatars.githubusercontent.com/u/247225942?v=4"
      },
      "readme": "# AGENTS.md\n\n![AGENTS.md logo](./public/og.png)\n\n[AGENTS.md](https://agents.md) is a simple, open format for guiding coding agents.\n\nThink of AGENTS.md as a README for agents: a dedicated, predictable place\nto provide context and instructions to help AI coding agents work on your project.\n\nBelow is a minimal example of an AGENTS.md file:\n\n```markdown\n# Sample AGENTS.md file\n\n## Dev environment tips\n- Use `pnpm dlx turbo run where <project_name>` to jump to a package instead of scanning with `ls`.\n- Run `pnpm install --filter <project_name>` to add the package to your workspace so Vite, ESLint, and TypeScript can see it.\n- Use `pnpm create vite@latest <project_name> -- --template react-ts` to spin up a new React + Vite package with TypeScript checks ready.\n- Check the name field inside each package's package.json to confirm the right name‚Äîskip the top-level one.\n\n## Testing instructions\n- Find the CI plan in the .github/workflows folder.\n- Run `pnpm turbo run test --filter <project_name>` to run every check defined for that package.\n- From the package root you can just call `pnpm test`. The commit should pass all tests before you merge.\n- To focus on one step, add the Vitest pattern: `pnpm vitest run -t \"<test name>\"`.\n- Fix any test or type errors until the whole suite is green.\n- After moving files or changing imports, run `pnpm lint --filter <project_name>` to be sure ESLint and TypeScript rules still pass.\n- Add or update tests for the code you change, even if nobody asked.\n\n## PR instructions\n- Title format: [<project_name>] <Title>\n- Always run `pnpm lint` and `pnpm test` before committing.\n```\n\n## Website\n\nThis repository also includes a basic Next.js website hosted at https://agents.md/\nthat explains the project‚Äôs goals in a simple way, and featuring some examples.\n\n### Running the app locally\n1. Install dependencies:\n   ```bash\n   pnpm install\n   ```\n2. Start the development server:\n   ```bash\n   pnpm run dev\n   ```\n3. Open your browser and go to http://localhost:3000\n",
      "stars_today": 97
    },
    {
      "id": 699532645,
      "name": "uv",
      "full_name": "astral-sh/uv",
      "description": "An extremely fast Python package and project manager, written in Rust.",
      "html_url": "https://github.com/astral-sh/uv",
      "stars": 77107,
      "forks": 2450,
      "language": "Rust",
      "topics": [
        "packaging",
        "python",
        "resolver",
        "uv"
      ],
      "created_at": "2023-10-02T20:24:11Z",
      "updated_at": "2026-01-16T23:40:15Z",
      "pushed_at": "2026-01-16T22:38:02Z",
      "open_issues": 2551,
      "owner": {
        "login": "astral-sh",
        "avatar_url": "https://avatars.githubusercontent.com/u/115962839?v=4"
      },
      "readme": "# uv\n\n[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)\n[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)\n[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)\n[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)\n[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)\n[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/astral-sh)\n\nAn extremely fast Python package and project manager, written in Rust.\n\n<p align=\"center\">\n  <picture align=\"center\">\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d\">\n    <img alt=\"Shows a bar chart with benchmark results.\" src=\"https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d\">\n  </picture>\n</p>\n\n<p align=\"center\">\n  <i>Installing <a href=\"https://trio.readthedocs.io/\">Trio</a>'s dependencies with a warm cache.</i>\n</p>\n\n## Highlights\n\n- A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`, and\n  more.\n- [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.\n- Provides [comprehensive project management](#projects), with a\n  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).\n- [Runs scripts](#scripts), with support for\n  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).\n- [Installs and manages](#python-versions) Python versions.\n- [Runs and installs](#tools) tools published as Python packages.\n- Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a familiar\n  CLI.\n- Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for\n  scalable projects.\n- Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for\n  dependency deduplication.\n- Installable without Rust or Python via `curl` or `pip`.\n- Supports macOS, Linux, and Windows.\n\nuv is backed by [Astral](https://astral.sh), the creators of\n[Ruff](https://github.com/astral-sh/ruff) and [ty](https://github.com/astral-sh/ty).\n\n## Installation\n\nInstall uv with our standalone installers:\n\n```bash\n# On macOS and Linux.\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n```bash\n# On Windows.\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\nOr, from [PyPI](https://pypi.org/project/uv/):\n\n```bash\n# With pip.\npip install uv\n```\n\n```bash\n# Or pipx.\npipx install uv\n```\n\nIf installed via the standalone installer, uv can update itself to the latest version:\n\n```bash\nuv self update\n```\n\nSee the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for\ndetails and alternative installation methods.\n\n## Documentation\n\nuv's documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).\n\nAdditionally, the command line reference documentation can be viewed with `uv help`.\n\n## Features\n\n### Projects\n\nuv manages project dependencies and environments, with support for lockfiles, workspaces, and more,\nsimilar to `rye` or `poetry`:\n\n```console\n$ uv init example\nInitialized project `example` at `/home/user/example`\n\n$ cd example\n\n$ uv add ruff\nCreating virtual environment at: .venv\nResolved 2 packages in 170ms\n   Built example @ file:///home/user/example\nPrepared 2 packages in 627ms\nInstalled 2 packages in 1ms\n + example==0.1.0 (from file:///home/user/example)\n + ruff==0.5.0\n\n$ uv run ruff check\nAll checks passed!\n\n$ uv lock\nResolved 2 packages in 0.33ms\n\n$ uv sync\nResolved 2 packages in 0.70ms\nAudited 1 package in 0.02ms\n```\n\nSee the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.\n\nuv also supports building and publishing projects, even if they're not managed with uv. See the\n[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.\n\n### Scripts\n\nuv manages dependencies and environments for single-file scripts.\n\nCreate a new script and add inline metadata declaring its dependencies:\n\n```console\n$ echo 'import requests; print(requests.get(\"https://astral.sh\"))' > example.py\n\n$ uv add --script example.py requests\nUpdated `example.py`\n```\n\nThen, run the script in an isolated virtual environment:\n\n```console\n$ uv run example.py\nReading inline script metadata from: example.py\nInstalled 5 packages in 12ms\n<Response [200]>\n```\n\nSee the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.\n\n### Tools\n\nuv executes and installs command-line tools provided by Python packages, similar to `pipx`.\n\nRun a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):\n\n```console\n$ uvx pycowsay 'hello world!'\nResolved 1 package in 167ms\nInstalled 1 package in 9ms\n + pycowsay==0.0.0.2\n  \"\"\"\n\n  ------------\n< hello world! >\n  ------------\n   \\   ^__^\n    \\  (oo)\\_______\n       (__)\\       )\\/\\\n           ||----w |\n           ||     ||\n```\n\nInstall a tool with `uv tool install`:\n\n```console\n$ uv tool install ruff\nResolved 1 package in 6ms\nInstalled 1 package in 2ms\n + ruff==0.5.0\nInstalled 1 executable: ruff\n\n$ ruff --version\nruff 0.5.0\n```\n\nSee the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.\n\n### Python versions\n\nuv installs Python and allows quickly switching between versions.\n\nInstall multiple Python versions:\n\n```console\n$ uv python install 3.12 3.13 3.14\nInstalled 3 versions in 972ms\n + cpython-3.12.12-macos-aarch64-none (python3.12)\n + cpython-3.13.9-macos-aarch64-none (python3.13)\n + cpython-3.14.0-macos-aarch64-none (python3.14)\n\n```\n\nDownload Python versions as needed:\n\n```console\n$ uv venv --python 3.12.0\nUsing Python 3.12.0\nCreating virtual environment at: .venv\nActivate with: source .venv/bin/activate\n\n$ uv run --python pypy@3.8 -- python --version\nPython 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)\n[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>>>\n```\n\nUse a specific Python version in the current directory:\n\n```console\n$ uv python pin 3.11\nPinned `.python-version` to `3.11`\n```\n\nSee the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get\nstarted.\n\n### The pip interface\n\nuv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.\n\nuv extends their interfaces with advanced features, such as dependency version overrides,\nplatform-independent resolutions, reproducible resolutions, alternative resolution strategies, and\nmore.\n\nMigrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the\n`uv pip` interface.\n\nCompile requirements into a platform-independent requirements file:\n\n```console\n$ uv pip compile docs/requirements.in \\\n   --universal \\\n   --output-file docs/requirements.txt\nResolved 43 packages in 12ms\n```\n\nCreate a virtual environment:\n\n```console\n$ uv venv\nUsing Python 3.12.3\nCreating virtual environment at: .venv\nActivate with: source .venv/bin/activate\n```\n\nInstall the locked requirements:\n\n```console\n$ uv pip sync docs/requirements.txt\nResolved 43 packages in 11ms\nInstalled 43 packages in 208ms\n + babel==2.15.0\n + black==24.4.2\n + certifi==2024.7.4\n ...\n```\n\nSee the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.\n\n## Contributing\n\nWe are passionate about supporting contributors of all levels of experience and would love to see\nyou get involved in the project. See the\n[contributing guide](https://github.com/astral-sh/uv?tab=contributing-ov-file#contributing) to get\nstarted.\n\n## FAQ\n\n#### How do you pronounce uv?\n\nIt's pronounced as \"you - vee\" ([`/juÀê viÀê/`](https://en.wikipedia.org/wiki/Help:IPA/English#Key))\n\n#### How should I stylize uv?\n\nJust \"uv\", please. See the [style guide](./STYLE.md#styling-uv) for details.\n\n#### What platforms does uv support?\n\nSee uv's [platform support](https://docs.astral.sh/uv/reference/platforms/) document.\n\n#### Is uv ready for production?\n\nYes, uv is stable and widely used in production. See uv's\n[versioning policy](https://docs.astral.sh/uv/reference/versioning/) document for details.\n\n## Acknowledgements\n\nuv's dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We're\ngrateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for\ntheir support.\n\nuv's Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).\n\nSome of uv's optimizations are inspired by the great work we've seen in [pnpm](https://pnpm.io/),\n[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We've also\nlearned a lot from Nathaniel J. Smith's [Posy](https://github.com/njsmith/posy) and adapted its\n[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)\nfor Windows support.\n\n## License\n\nuv is licensed under either of\n\n- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or\n  <https://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <https://opensource.org/licenses/MIT>)\n\nat your option.\n\nUnless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv\nby you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any\nadditional terms or conditions.\n\n<div align=\"center\">\n  <a target=\"_blank\" href=\"https://astral.sh\" style=\"background:none\">\n    <img src=\"https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg\" alt=\"Made by Astral\">\n  </a>\n</div>\n",
      "stars_today": 83
    },
    {
      "id": 722597620,
      "name": "rustfs",
      "full_name": "rustfs/rustfs",
      "description": "üöÄ2.3x faster than MinIO for 4KB object payloads. RustFS is an open-source, S3-compatible high-performance object storage system supporting migration and coexistence with other S3-compatible platforms such as MinIO and Ceph.",
      "html_url": "https://github.com/rustfs/rustfs",
      "stars": 19858,
      "forks": 854,
      "language": "Rust",
      "topics": [
        "amazon-s3",
        "bigdata",
        "cloud-native",
        "filesystem",
        "minio",
        "object-storage",
        "objectstorage",
        "rust",
        "s3"
      ],
      "created_at": "2023-11-23T13:45:10Z",
      "updated_at": "2026-01-16T23:31:37Z",
      "pushed_at": "2026-01-16T18:53:25Z",
      "open_issues": 68,
      "owner": {
        "login": "rustfs",
        "avatar_url": "https://avatars.githubusercontent.com/u/151849438?v=4"
      },
      "readme": "[![RustFS](https://rustfs.com/images/rustfs-github.png)](https://rustfs.com)\n\n<p align=\"center\">RustFS is a high-performance, distributed object storage system built in Rust.</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/rustfs/rustfs/actions/workflows/ci.yml\"><img alt=\"CI\" src=\"https://github.com/rustfs/rustfs/actions/workflows/ci.yml/badge.svg\" /></a>\n  <a href=\"https://github.com/rustfs/rustfs/actions/workflows/docker.yml\"><img alt=\"Build and Push Docker Images\" src=\"https://github.com/rustfs/rustfs/actions/workflows/docker.yml/badge.svg\" /></a>\n  <img alt=\"GitHub commit activity\" src=\"https://img.shields.io/github/commit-activity/m/rustfs/rustfs\"/>\n  <img alt=\"Github Last Commit\" src=\"https://img.shields.io/github/last-commit/rustfs/rustfs\"/>\n  <a href=\"https://hellogithub.com/repository/rustfs/rustfs\" target=\"_blank\"><img src=\"https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=b95bcb72bdc340b68f16fdf6790b7d5b&claim_uid=MsbvjYeLDKAH457&theme=small\" alt=\"FeaturedÔΩúHelloGitHub\" /></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/14181\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/14181\" alt=\"rustfs%2Frustfs | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n\n<p align=\"center\">\n  <a href=\"https://docs.rustfs.com/installation/\">Getting Started</a>\n  ¬∑ <a href=\"https://docs.rustfs.com/\">Docs</a>\n  ¬∑ <a href=\"https://github.com/rustfs/rustfs/issues\">Bug reports</a>\n  ¬∑ <a href=\"https://github.com/rustfs/rustfs/discussions\">Discussions</a>\n</p>\n\n<p align=\"center\">\nEnglish | <a href=\"https://github.com/rustfs/rustfs/blob/main/README_ZH.md\">ÁÆÄ‰Ωì‰∏≠Êñá</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=de\">Deutsch</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=es\">Espa√±ol</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=fr\">fran√ßais</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=ja\">Êó•Êú¨Ë™û</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=ko\">ÌïúÍµ≠Ïñ¥</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=pt\">Portuguese</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n</p>\n\nRustFS is a high-performance, distributed object storage system built in Rust‚Äîone of the most loved programming languages worldwide. RustFS combines the simplicity of MinIO with the memory safety and raw performance of Rust. It offers full S3 compatibility, is completely open-source, and is optimized for data lakes, AI, and big data workloads.\n\nUnlike other storage systems, RustFS is released under the permissible Apache 2.0 license, avoiding the restrictions of AGPL. With Rust as its foundation, RustFS delivers superior speed and secure distributed features for next-generation object storage.\n\n## Feature & Status\n\n- **High Performance**: Built with Rust to ensure maximum speed and resource efficiency.\n- **Distributed Architecture**: Scalable and fault-tolerant design suitable for large-scale deployments.\n- **S3 Compatibility**: Seamless integration with existing S3-compatible applications and tools.\n- **Data Lake Support**: Optimized for high-throughput big data and AI workloads.\n- **Open Source**: Licensed under Apache 2.0, encouraging unrestricted community contributions and commercial usage.\n- **User-Friendly**: Designed with simplicity in mind for easy deployment and management.\n\n| Feature | Status | Feature | Status |\n| :--- | :--- | :--- | :--- |\n| **S3 Core Features** | ‚úÖ Available | **Bitrot Protection** | ‚úÖ Available |\n| **Upload / Download** | ‚úÖ Available | **Single Node Mode** | ‚úÖ Available |\n| **Versioning** | ‚úÖ Available |  **Bucket Replication** | ‚úÖ Available |\n| **Logging** | ‚úÖ Available |  **Lifecycle Management** | üöß Under Testing |\n| **Event Notifications** | ‚úÖ Available |  **Distributed Mode** | üöß Under Testing |\n| **K8s Helm Charts** | ‚úÖ Available |   **RustFS KMS** | üöß Under Testing | \n\n\n\n\n## RustFS vs MinIO Performance\n\n**Stress Test Environment:**\n\n| Type    | Parameter | Remark                                                   |\n|---------|-----------|----------------------------------------------------------|\n| CPU     | 2 Core    | Intel Xeon (Sapphire Rapids) Platinum 8475B, 2.7/3.2 GHz |\n| Memory  | 4GB       |                                                          |\n| Network | 15Gbps    |                                                          |\n| Drive   | 40GB x 4  | IOPS 3800 / Drive                                        |\n\n<https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a>\n\n### RustFS vs Other Object Storage\n\n| Feature | RustFS | Other Object Storage |\n| :--- | :--- | :--- |\n| **Console Experience** | **Powerful Console**<br>Comprehensive management interface. | **Basic / Limited Console**<br>Often overly simple or lacking critical features. |\n| **Language & Safety** | **Rust-based**<br>Memory safety by design. | **Go or C-based**<br>Potential for memory GC pauses or leaks. |\n| **Data Sovereignty** | **No Telemetry / Full Compliance**<br>Guards against unauthorized cross-border data egress. Compliant with GDPR (EU/UK), CCPA (US), and APPI (Japan). | **Potential Risk**<br>Possible legal exposure and unwanted data telemetry. |\n| **Licensing** | **Permissive Apache 2.0**<br>Business-friendly, no \"poison pill\" clauses. | **Restrictive AGPL v3**<br>Risk of license traps and intellectual property pollution. |\n| **Compatibility** | **100% S3 Compatible**<br>Works with any cloud provider or client, anywhere. | **Variable Compatibility**<br>May lack support for local cloud vendors or specific APIs. |\n| **Edge & IoT** | **Strong Edge Support**<br>Ideal for secure, innovative edge devices. | **Weak Edge Support**<br>Often too heavy for edge gateways. |\n| **Risk Profile** | **Enterprise Risk Mitigation**<br>Clear IP rights and safe for commercial use. | **Legal Risks**<br>Intellectual property ambiguity and usage restrictions. |\n\n\n## Staying ahead\n\nStar RustFS on GitHub and be instantly notified of new releases.\n\n<img src=\"https://github.com/user-attachments/assets/7ee40bb4-3e46-4eac-b0d0-5fbeb85ff8f3\" />\n\n## Quickstart\n\nTo get started with RustFS, follow these steps:\n\n### 1. One-click Installation (Option 1)\n\n  ```bash\n  curl -O https://rustfs.com/install_rustfs.sh && bash install_rustfs.sh\n````\n\n### 2\\. Docker Quick Start (Option 2)\n\nThe RustFS container runs as a non-root user `rustfs` (UID `10001`). If you run Docker with `-v` to mount a host directory, please ensure the host directory owner is set to `10001`, otherwise you will encounter permission denied errors.\n\n```bash\n # Create data and logs directories\n mkdir -p data logs\n\n # Change the owner of these directories\n chown -R 10001:10001 data logs\n\n # Using latest version\n docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:latest\n\n # Using specific version\n docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:1.0.0-alpha.76\n```\n\nYou can also use Docker Compose. Using the `docker-compose.yml` file in the root directory:\n\n```bash\ndocker compose --profile observability up -d\n```\n\n**NOTE**: We recommend reviewing the `docker-compose.yaml` file before running. It defines several services including Grafana, Prometheus, and Jaeger, which are helpful for RustFS observability. If you wish to start Redis or Nginx containers, you can specify the corresponding profiles.\n\n### 3\\. Build from Source (Option 3) - Advanced Users\n\nFor developers who want to build RustFS Docker images from source with multi-architecture support:\n\n```bash\n# Build multi-architecture images locally\n./docker-buildx.sh --build-arg RELEASE=latest\n\n# Build and push to registry\n./docker-buildx.sh --push\n\n# Build specific version\n./docker-buildx.sh --release v1.0.0 --push\n\n# Build for custom registry\n./docker-buildx.sh --registry your-registry.com --namespace yourname --push\n```\n\nThe `docker-buildx.sh` script supports:\n\\- **Multi-architecture builds**: `linux/amd64`, `linux/arm64`\n\\- **Automatic version detection**: Uses git tags or commit hashes\n\\- **Registry flexibility**: Supports Docker Hub, GitHub Container Registry, etc.\n\\- **Build optimization**: Includes caching and parallel builds\n\nYou can also use Make targets for convenience:\n\n```bash\nmake docker-buildx                    # Build locally\nmake docker-buildx-push               # Build and push\nmake docker-buildx-version VERSION=v1.0.0  # Build specific version\nmake help-docker                      # Show all Docker-related commands\n```\n\n> **Heads-up (macOS cross-compilation)**: macOS keeps the default `ulimit -n` at 256, so `cargo zigbuild` or `./build-rustfs.sh --platform ...` may fail with `ProcessFdQuotaExceeded` when targeting Linux. The build script attempts to raise the limit automatically, but if you still see the warning, run `ulimit -n 4096` (or higher) in your shell before building.\n\n### 4\\. Build with Helm Chart (Option 4) - Cloud Native\n\nFollow the instructions in the [Helm Chart README](https://charts.rustfs.com/) to install RustFS on a Kubernetes cluster.\n\n### 5\\. Nix Flake (Option 5)\n\nIf you have [Nix with flakes enabled](https://nixos.wiki/wiki/Flakes#Enable_flakes):\n\n```bash\n# Run directly without installing\nnix run github:rustfs/rustfs\n\n# Build the binary\nnix build github:rustfs/rustfs\n./result/bin/rustfs --help\n\n# Or from a local checkout\nnix build\nnix run\n```\n\n-----\n\n### Accessing RustFS\n\n5.  **Access the Console**: Open your web browser and navigate to `http://localhost:9001` to access the RustFS console.\n      * Default credentials: `rustfsadmin` / `rustfsadmin`\n6.  **Create a Bucket**: Use the console to create a new bucket for your objects.\n7.  **Upload Objects**: You can upload files directly through the console or use S3-compatible APIs/clients to interact with your RustFS instance.\n\n**NOTE**: To access the RustFS instance via `https`, please refer to the [TLS Configuration Docs](https://docs.rustfs.com/integration/tls-configured.html).\n\n## Documentation\n\nFor detailed documentation, including configuration options, API references, and advanced usage, please visit our [Documentation](https://docs.rustfs.com).\n\n## Getting Help\n\nIf you have any questions or need assistance:\n\n  - Check the [FAQ](https://github.com/rustfs/rustfs/discussions/categories/q-a) for common issues and solutions.\n  - Join our [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) to ask questions and share your experiences.\n  - Open an issue on our [GitHub Issues](https://github.com/rustfs/rustfs/issues) page for bug reports or feature requests.\n\n## Links\n\n  - [Documentation](https://docs.rustfs.com) - The manual you should read\n  - [Changelog](https://github.com/rustfs/rustfs/releases) - What we broke and fixed\n  - [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) - Where the community lives\n\n## Contact\n\n  - **Bugs**: [GitHub Issues](https://github.com/rustfs/rustfs/issues)\n  - **Business**: [hello@rustfs.com](mailto:hello@rustfs.com)\n  - **Jobs**: [jobs@rustfs.com](mailto:jobs@rustfs.com)\n  - **General Discussion**: [GitHub Discussions](https://github.com/rustfs/rustfs/discussions)\n  - **Contributing**: [CONTRIBUTING.md](CONTRIBUTING.md)\n\n## Contributors\n\nRustFS is a community-driven project, and we appreciate all contributions. Check out the [Contributors](https://github.com/rustfs/rustfs/graphs/contributors) page to see the amazing people who have helped make RustFS better.\n\n<a href=\"https://github.com/rustfs/rustfs/graphs/contributors\">\n<img src=\"https://opencollective.com/rustfs/contributors.svg?width=890&limit=500&button=false\" alt=\"Contributors\" />\n</a>\n\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=rustfs/rustfs&type=date&legend=top-left)](https://www.star-history.com/#rustfs/rustfs&type=date&legend=top-left)\n\n## License\n\n[Apache 2.0](https://opensource.org/licenses/Apache-2.0)\n\n**RustFS** is a trademark of RustFS, Inc. All other trademarks are the property of their respective owners.\n\n",
      "stars_today": 78
    },
    {
      "id": 382496361,
      "name": "uptime-kuma",
      "full_name": "louislam/uptime-kuma",
      "description": "A fancy self-hosted monitoring tool",
      "html_url": "https://github.com/louislam/uptime-kuma",
      "stars": 81483,
      "forks": 7269,
      "language": "JavaScript",
      "topics": [
        "docker",
        "monitor",
        "monitoring",
        "responsive",
        "self-hosted",
        "selfhosted",
        "single-page-app",
        "socket-io",
        "uptime",
        "uptime-monitoring",
        "webapp",
        "websocket"
      ],
      "created_at": "2021-07-03T01:02:42Z",
      "updated_at": "2026-01-17T00:53:54Z",
      "pushed_at": "2026-01-16T04:47:04Z",
      "open_issues": 708,
      "owner": {
        "login": "louislam",
        "avatar_url": "https://avatars.githubusercontent.com/u/1336778?v=4"
      },
      "readme": "<div align=\"center\" width=\"100%\">\n    <img src=\"./public/icon.svg\" width=\"128\" alt=\"Uptime Kuma Logo\" />\n</div>\n\n# Uptime Kuma\n\nUptime Kuma is an easy-to-use self-hosted monitoring tool.\n\n<a target=\"_blank\" href=\"https://github.com/louislam/uptime-kuma\"><img src=\"https://img.shields.io/github/stars/louislam/uptime-kuma?style=flat\" /></a> <a target=\"_blank\" href=\"https://hub.docker.com/r/louislam/uptime-kuma\"><img src=\"https://img.shields.io/docker/pulls/louislam/uptime-kuma\" /></a> <a target=\"_blank\" href=\"https://hub.docker.com/r/louislam/uptime-kuma\"><img src=\"https://img.shields.io/docker/v/louislam/uptime-kuma/2?label=docker%20image%20ver.\" /></a> <a target=\"_blank\" href=\"https://github.com/louislam/uptime-kuma\"><img src=\"https://img.shields.io/github/last-commit/louislam/uptime-kuma\" /></a> <a target=\"_blank\" href=\"https://opencollective.com/uptime-kuma\"><img src=\"https://opencollective.com/uptime-kuma/total/badge.svg?label=Open%20Collective%20Backers&color=brightgreen\" /></a>\n[![GitHub Sponsors](https://img.shields.io/github/sponsors/louislam?label=GitHub%20Sponsors)](https://github.com/sponsors/louislam) <a href=\"https://weblate.kuma.pet/projects/uptime-kuma/uptime-kuma/\">\n<img src=\"https://weblate.kuma.pet/widgets/uptime-kuma/-/svg-badge.svg\" alt=\"Translation status\" />\n</a>\n\n<img src=\"https://user-images.githubusercontent.com/1336778/212262296-e6205815-ad62-488c-83ec-a5b0d0689f7c.jpg\" width=\"700\" alt=\"Uptime Kuma Dashboard Screenshot\" />\n\n## ü•î Live Demo\n\nTry it!\n\nDemo Server (Location: Frankfurt - Germany): <https://demo.kuma.pet/start-demo>\n\nIt is a temporary live demo, all data will be deleted after 10 minutes. Sponsored by [Uptime Kuma Sponsors](https://github.com/louislam/uptime-kuma#%EF%B8%8F-sponsors).\n\n## ‚≠ê Features\n\n- Monitoring uptime for HTTP(s) / TCP / HTTP(s) Keyword / HTTP(s) Json Query / Websocket / Ping / DNS Record / Push / Steam Game Server / Docker Containers\n- Fancy, Reactive, Fast UI/UX\n- Notifications via Telegram, Discord, Gotify, Slack, Pushover, Email (SMTP), and [90+ notification services, click here for the full list](https://github.com/louislam/uptime-kuma/tree/master/src/components/notifications)\n- 20-second intervals\n- [Multi Languages](https://github.com/louislam/uptime-kuma/tree/master/src/lang)\n- Multiple status pages\n- Map status pages to specific domains\n- Ping chart\n- Certificate info\n- Proxy support\n- 2FA support\n\n## üîß How to Install\n\n### üê≥ Docker Compose\n\n```bash\nmkdir uptime-kuma\ncd uptime-kuma\ncurl -o compose.yaml https://raw.githubusercontent.com/louislam/uptime-kuma/master/compose.yaml\ndocker compose up -d\n```\n\nUptime Kuma is now running on all network interfaces (e.g. http://localhost:3001 or http://your-ip:3001).\n\n> [!WARNING]\n> File Systems like **NFS** (Network File System) are **NOT** supported. Please map to a local directory or volume.\n\n### üê≥ Docker Command\n\n```bash\ndocker run -d --restart=always -p 3001:3001 -v uptime-kuma:/app/data --name uptime-kuma louislam/uptime-kuma:2\n```\n\nUptime Kuma is now running on all network interfaces (e.g. http://localhost:3001 or http://your-ip:3001).\n\nIf you want to limit exposure to localhost only:\n\n```bash\ndocker run ... -p 127.0.0.1:3001:3001 ...\n```\n\n### üí™üèª Non-Docker\n\nRequirements:\n\n- Platform\n  - ‚úÖ Major Linux distros such as Debian, Ubuntu, Fedora and ArchLinux etc.\n  - ‚úÖ Windows 10 (x64), Windows Server 2012 R2 (x64) or higher\n  - ‚ùå FreeBSD / OpenBSD / NetBSD\n  - ‚ùå Replit / Heroku\n- [Node.js](https://nodejs.org/en/download/) >= 20.4\n- [Git](https://git-scm.com/downloads)\n- [pm2](https://pm2.keymetrics.io/) - For running Uptime Kuma in the background\n\n```bash\ngit clone https://github.com/louislam/uptime-kuma.git\ncd uptime-kuma\nnpm run setup\n\n# Option 1. Try it\nnode server/server.js\n\n# (Recommended) Option 2. Run in the background using PM2\n# Install PM2 if you don't have it:\nnpm install pm2 -g && pm2 install pm2-logrotate\n\n# Start Server\npm2 start server/server.js --name uptime-kuma\n```\n\nUptime Kuma is now running on all network interfaces (e.g. http://localhost:3001 or http://your-ip:3001).\n\nMore useful PM2 Commands\n\n```bash\n# If you want to see the current console output\npm2 monit\n\n# If you want to add it to startup\npm2 startup && pm2 save\n```\n\n### Advanced Installation\n\nIf you need more options or need to browse via a reverse proxy, please read:\n\n<https://github.com/louislam/uptime-kuma/wiki/%F0%9F%94%A7-How-to-Install>\n\n## üÜô How to Update\n\nPlease read:\n\n<https://github.com/louislam/uptime-kuma/wiki/%F0%9F%86%99-How-to-Update>\n\n## üÜï What's Next?\n\nI will assign requests/issues to the next milestone.\n\n<https://github.com/louislam/uptime-kuma/milestones>\n\n## ‚ù§Ô∏è Sponsors\n\nThank you so much! (GitHub Sponsors will be updated manually. OpenCollective sponsors will be updated automatically, the list will be cached by GitHub though. It may need some time to be updated)\n\n<img src=\"https://uptime.kuma.pet/sponsors?v=6\" alt=\"Uptime Kuma Sponsors\" />\n\n## üñº More Screenshots\n\nLight Mode:\n\n<img src=\"https://uptime.kuma.pet/img/light.jpg\" width=\"512\" alt=\"Uptime Kuma Light Mode Screenshot of how the Dashboard looks\" />\n\nStatus Page:\n\n<img src=\"https://user-images.githubusercontent.com/1336778/134628766-a3fe0981-0926-4285-ab46-891a21c3e4cb.png\" width=\"512\" alt=\"Uptime Kuma Status Page Screenshot\" />\n\nSettings Page:\n\n<img src=\"https://louislam.net/uptimekuma/2.jpg\" width=\"400\" alt=\"Uptime Kuma Settings Page Screenshot\" />\n\nTelegram Notification Sample:\n\n<img src=\"https://louislam.net/uptimekuma/3.jpg\" width=\"400\" alt=\"Uptime Kuma Telegram Notification Sample Screenshot\" />\n\n## Motivation\n\n- I was looking for a self-hosted monitoring tool like \"Uptime Robot\", but it is hard to find a suitable one. One of the closest ones is statping. Unfortunately, it is not stable and no longer maintained.\n- Wanted to build a fancy UI.\n- Learn Vue 3 and vite.js.\n- Show the power of Bootstrap 5.\n- Try to use WebSocket with SPA instead of a REST API.\n- Deploy my first Docker image to Docker Hub.\n\nIf you love this project, please consider giving it a ‚≠ê.\n\n## üó£Ô∏è Discussion / Ask for Help\n\n‚ö†Ô∏è For any general or technical questions, please don't send me an email, as I am unable to provide support in that manner. I will not respond if you ask questions there.\n\nI recommend using Google, GitHub Issues, or Uptime Kuma's subreddit for finding answers to your question. If you cannot find the information you need, feel free to ask:\n\n- [GitHub Issues](https://github.com/louislam/uptime-kuma/issues)\n- [Subreddit (r/UptimeKuma)](https://www.reddit.com/r/UptimeKuma/)\n\nMy Reddit account: [u/louislamlam](https://reddit.com/u/louislamlam)\nYou can mention me if you ask a question on the subreddit.\n\n## Contributions\n\n### Create Pull Requests\n\nPull requests are awesome.\nTo keep reviews fast and effective, please make sure you‚Äôve [read our pull request guidelines](https://github.com/louislam/uptime-kuma/blob/master/CONTRIBUTING.md#can-i-create-a-pull-request-for-uptime-kuma).\n\n### Test Pull Requests\n\nThere are a lot of pull requests right now, but I don't have time to test them all.\n\nIf you want to help, you can check this:\n<https://github.com/louislam/uptime-kuma/wiki/Test-Pull-Requests>\n\n### Test Beta Version\n\nCheck out the latest beta release here: <https://github.com/louislam/uptime-kuma/releases>\n\n### Bug Reports / Feature Requests\n\nIf you want to report a bug or request a new feature, feel free to open a [new issue](https://github.com/louislam/uptime-kuma/issues).\n\n### Translations\n\nIf you want to translate Uptime Kuma into your language, please visit [Weblate Readme](https://github.com/louislam/uptime-kuma/blob/master/src/lang/README.md).\n\n### Spelling & Grammar\n\nFeel free to correct the grammar in the documentation or code.\nMy mother language is not English and my grammar is not that great.\n",
      "stars_today": 76
    },
    {
      "id": 997890921,
      "name": "n8n-mcp",
      "full_name": "czlonkowski/n8n-mcp",
      "description": "A MCP for Claude Desktop / Claude Code / Windsurf / Cursor to build n8n workflows for you ",
      "html_url": "https://github.com/czlonkowski/n8n-mcp",
      "stars": 11796,
      "forks": 2175,
      "language": "TypeScript",
      "topics": [
        "mcp",
        "mcp-server",
        "n8n",
        "workflows"
      ],
      "created_at": "2025-06-07T12:15:57Z",
      "updated_at": "2026-01-17T00:53:08Z",
      "pushed_at": "2026-01-13T16:57:52Z",
      "open_issues": 67,
      "owner": {
        "login": "czlonkowski",
        "avatar_url": "https://avatars.githubusercontent.com/u/56956555?v=4"
      },
      "readme": "# n8n-MCP\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![GitHub stars](https://img.shields.io/github/stars/czlonkowski/n8n-mcp?style=social)](https://github.com/czlonkowski/n8n-mcp)\n[![npm version](https://img.shields.io/npm/v/n8n-mcp.svg)](https://www.npmjs.com/package/n8n-mcp)\n[![codecov](https://codecov.io/gh/czlonkowski/n8n-mcp/graph/badge.svg?token=YOUR_TOKEN)](https://codecov.io/gh/czlonkowski/n8n-mcp)\n[![Tests](https://img.shields.io/badge/tests-3336%20passing-brightgreen.svg)](https://github.com/czlonkowski/n8n-mcp/actions)\n[![n8n version](https://img.shields.io/badge/n8n-2.3.3-orange.svg)](https://github.com/n8n-io/n8n)\n[![Docker](https://img.shields.io/badge/docker-ghcr.io%2Fczlonkowski%2Fn8n--mcp-green.svg)](https://github.com/czlonkowski/n8n-mcp/pkgs/container/n8n-mcp)\n[![Deploy on Railway](https://railway.com/button.svg)](https://railway.com/deploy/n8n-mcp?referralCode=n8n-mcp)\n\nA Model Context Protocol (MCP) server that provides AI assistants with comprehensive access to n8n node documentation, properties, and operations. Deploy in minutes to give Claude and other AI assistants deep knowledge about n8n's 1,084 workflow automation nodes (537 core + 547 community).\n\n## Overview\n\nn8n-MCP serves as a bridge between n8n's workflow automation platform and AI models, enabling them to understand and work with n8n nodes effectively. It provides structured access to:\n\n- üìö **1,084 n8n nodes** - 537 core nodes + 547 community nodes (301 verified)\n- üîß **Node properties** - 99% coverage with detailed schemas\n- ‚ö° **Node operations** - 63.6% coverage of available actions\n- üìÑ **Documentation** - 87% coverage from official n8n docs (including AI nodes)\n- ü§ñ **AI tools** - 265 AI-capable tool variants detected with full documentation\n- üí° **Real-world examples** - 2,646 pre-extracted configurations from popular templates\n- üéØ **Template library** - 2,709 workflow templates with 100% metadata coverage\n- üåê **Community nodes** - Search verified community integrations with `source` filter (NEW!)\n\n\n## ‚ö†Ô∏è Important Safety Warning\n\n**NEVER edit your production workflows directly with AI!** Always:\n- üîÑ **Make a copy** of your workflow before using AI tools\n- üß™ **Test in development** environment first\n- üíæ **Export backups** of important workflows\n- ‚ö° **Validate changes** before deploying to production\n\nAI results can be unpredictable. Protect your work!\n\n## üöÄ Quick Start\n\n### Option 1: Hosted Service (Easiest - No Setup!) ‚òÅÔ∏è\n\n**The fastest way to try n8n-MCP** - no installation, no configuration:\n\nüëâ **[dashboard.n8n-mcp.com](https://dashboard.n8n-mcp.com)**\n\n- ‚úÖ **Free tier**: 100 tool calls/day\n- ‚úÖ **Instant access**: Start building workflows immediately\n- ‚úÖ **Always up-to-date**: Latest n8n nodes and templates\n- ‚úÖ **No infrastructure**: We handle everything\n\nJust sign up, get your API key, and connect your MCP client. \n\n---\n\n## üè† Self-Hosting Options\n\nPrefer to run n8n-MCP yourself? Choose your deployment method:\n\n### Option A: npx (Quick Local Setup) üöÄ\n\nGet n8n-MCP running in minutes:\n\n[![n8n-mcp Video Quickstart Guide](./thumbnail.png)](https://youtu.be/5CccjiLLyaY?si=Z62SBGlw9G34IQnQ&t=343)\n\n**Prerequisites:** [Node.js](https://nodejs.org/) installed on your system\n\n```bash\n# Run directly with npx (no installation needed!)\nnpx n8n-mcp\n```\n\nAdd to Claude Desktop config:\n\n> ‚ö†Ô∏è **Important**: The `MCP_MODE: \"stdio\"` environment variable is **required** for Claude Desktop. Without it, you will see JSON parsing errors like `\"Unexpected token...\"` in the UI. This variable ensures that only JSON-RPC messages are sent to stdout, preventing debug logs from interfering with the protocol.\n\n**Basic configuration (documentation tools only):**\n```json\n{\n  \"mcpServers\": {\n    \"n8n-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"n8n-mcp\"],\n      \"env\": {\n        \"MCP_MODE\": \"stdio\",\n        \"LOG_LEVEL\": \"error\",\n        \"DISABLE_CONSOLE_OUTPUT\": \"true\"\n      }\n    }\n  }\n}\n```\n\n**Full configuration (with n8n management tools):**\n```json\n{\n  \"mcpServers\": {\n    \"n8n-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"n8n-mcp\"],\n      \"env\": {\n        \"MCP_MODE\": \"stdio\",\n        \"LOG_LEVEL\": \"error\",\n        \"DISABLE_CONSOLE_OUTPUT\": \"true\",\n        \"N8N_API_URL\": \"https://your-n8n-instance.com\",\n        \"N8N_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n```\n\n> **Note**: npx will download and run the latest version automatically. The package includes a pre-built database with all n8n node information.\n\n**Configuration file locations:**\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n- **Linux**: `~/.config/Claude/claude_desktop_config.json`\n\n**Restart Claude Desktop after updating configuration** - That's it! üéâ\n\n### Option B: Docker (Isolated & Reproducible) üê≥\n\n**Prerequisites:** Docker installed on your system\n\n<details>\n<summary><strong>üì¶ Install Docker</strong> (click to expand)</summary>\n\n**macOS:**\n```bash\n# Using Homebrew\nbrew install --cask docker\n\n# Or download from https://www.docker.com/products/docker-desktop/\n```\n\n**Linux (Ubuntu/Debian):**\n```bash\n# Update package index\nsudo apt-get update\n\n# Install Docker\nsudo apt-get install docker.io\n\n# Start Docker service\nsudo systemctl start docker\nsudo systemctl enable docker\n\n# Add your user to docker group (optional, to run without sudo)\nsudo usermod -aG docker $USER\n# Log out and back in for this to take effect\n```\n\n**Windows:**\n```bash\n# Option 1: Using winget (Windows Package Manager)\nwinget install Docker.DockerDesktop\n\n# Option 2: Using Chocolatey\nchoco install docker-desktop\n\n# Option 3: Download installer from https://www.docker.com/products/docker-desktop/\n```\n\n**Verify installation:**\n```bash\ndocker --version\n```\n</details>\n\n```bash\n# Pull the Docker image (~280MB, no n8n dependencies!)\ndocker pull ghcr.io/czlonkowski/n8n-mcp:latest\n```\n\n> **‚ö° Ultra-optimized:** Our Docker image is 82% smaller than typical n8n images because it contains NO n8n dependencies - just the runtime MCP server with a pre-built database!\n\nAdd to Claude Desktop config:\n\n**Basic configuration (documentation tools only):**\n```json\n{\n  \"mcpServers\": {\n    \"n8n-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--init\",\n        \"-e\", \"MCP_MODE=stdio\",\n        \"-e\", \"LOG_LEVEL=error\",\n        \"-e\", \"DISABLE_CONSOLE_OUTPUT=true\",\n        \"ghcr.io/czlonkowski/n8n-mcp:latest\"\n      ]\n    }\n  }\n}\n```\n\n**Full configuration (with n8n management tools):**\n```json\n{\n  \"mcpServers\": {\n    \"n8n-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--init\",\n        \"-e\", \"MCP_MODE=stdio\",\n        \"-e\", \"LOG_LEVEL=error\",\n        \"-e\", \"DISABLE_CONSOLE_OUTPUT=true\",\n        \"-e\", \"N8N_API_URL=https://your-n8n-instance.com\",\n        \"-e\", \"N8N_API_KEY=your-api-key\",\n        \"ghcr.io/czlonkowski/n8n-mcp:latest\"\n      ]\n    }\n  }\n}\n```\n\n>üí° Tip: If you're running n8n locally on the same machine (e.g., via Docker), use http://host.docker.internal:5678 as the N8N_API_URL.\n\n> **Note**: The n8n API credentials are optional. Without them, you'll have access to all documentation and validation tools. With them, you'll additionally get workflow management capabilities (create, update, execute workflows).\n\n### üè† Local n8n Instance Configuration\n\nIf you're running n8n locally (e.g., `http://localhost:5678` or Docker), you need to allow localhost webhooks:\n\n```json\n{\n  \"mcpServers\": {\n    \"n8n-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"-i\", \"--rm\", \"--init\",\n        \"-e\", \"MCP_MODE=stdio\",\n        \"-e\", \"LOG_LEVEL=error\",\n        \"-e\", \"DISABLE_CONSOLE_OUTPUT=true\",\n        \"-e\", \"N8N_API_URL=http://host.docker.internal:5678\",\n        \"-e\", \"N8N_API_KEY=your-api-key\",\n        \"-e\", \"WEBHOOK_SECURITY_MODE=moderate\",\n        \"ghcr.io/czlonkowski/n8n-mcp:latest\"\n      ]\n    }\n  }\n}\n```\n\n> ‚ö†Ô∏è **Important:** Set `WEBHOOK_SECURITY_MODE=moderate` to allow webhooks to your local n8n instance. This is safe for local development while still blocking private networks and cloud metadata.\n\n**Important:** The `-i` flag is required for MCP stdio communication.\n\n> üîß If you encounter any issues with Docker, check our [Docker Troubleshooting Guide](./docs/DOCKER_TROUBLESHOOTING.md).\n\n**Configuration file locations:**\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n- **Linux**: `~/.config/Claude/claude_desktop_config.json`\n\n**Restart Claude Desktop after updating configuration** - That's it! üéâ\n\n## üîê Privacy & Telemetry\n\nn8n-mcp collects anonymous usage statistics to improve the tool. [View our privacy policy](./PRIVACY.md).\n\n### Opting Out\n\n**For npx users:**\n```bash\nnpx n8n-mcp telemetry disable\n```\n\n**For Docker users:**\nAdd the following environment variable to your Docker configuration:\n```json\n\"-e\", \"N8N_MCP_TELEMETRY_DISABLED=true\"\n```\n\nExample in Claude Desktop config:\n```json\n{\n  \"mcpServers\": {\n    \"n8n-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--init\",\n        \"-e\", \"MCP_MODE=stdio\",\n        \"-e\", \"LOG_LEVEL=error\",\n        \"-e\", \"N8N_MCP_TELEMETRY_DISABLED=true\",\n        \"ghcr.io/czlonkowski/n8n-mcp:latest\"\n      ]\n    }\n  }\n}\n```\n\n**For docker-compose users:**\nSet in your environment file or docker-compose.yml:\n```yaml\nenvironment:\n  N8N_MCP_TELEMETRY_DISABLED: \"true\"\n```\n\n## ‚öôÔ∏è Database & Memory Configuration\n\n### Database Adapters\n\nn8n-mcp uses SQLite for storing node documentation. Two adapters are available:\n\n1. **better-sqlite3** (Default in Docker)\n   - Native C++ bindings for best performance\n   - Direct disk writes (no memory overhead)\n   - **Now enabled by default** in Docker images (v2.20.2+)\n   - Memory usage: ~100-120 MB stable\n\n2. **sql.js** (Fallback)\n   - Pure JavaScript implementation\n   - In-memory database with periodic saves\n   - Used when better-sqlite3 compilation fails\n   - Memory usage: ~150-200 MB stable\n\n### Memory Optimization (sql.js)\n\nIf using sql.js fallback, you can configure the save interval to balance between data safety and memory efficiency:\n\n**Environment Variable:**\n```bash\nSQLJS_SAVE_INTERVAL_MS=5000  # Default: 5000ms (5 seconds)\n```\n\n**Usage:**\n- Controls how long to wait after database changes before saving to disk\n- Lower values = more frequent saves = higher memory churn\n- Higher values = less frequent saves = lower memory usage\n- Minimum: 100ms\n- Recommended: 5000-10000ms for production\n\n**Docker Configuration:**\n```json\n{\n  \"mcpServers\": {\n    \"n8n-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--init\",\n        \"-e\", \"SQLJS_SAVE_INTERVAL_MS=10000\",\n        \"ghcr.io/czlonkowski/n8n-mcp:latest\"\n      ]\n    }\n  }\n}\n```\n\n**docker-compose:**\n```yaml\nenvironment:\n  SQLJS_SAVE_INTERVAL_MS: \"10000\"\n```\n\n## üíñ Support This Project\n\n<div align=\"center\">\n  <a href=\"https://github.com/sponsors/czlonkowski\">\n    <img src=\"https://img.shields.io/badge/Sponsor-‚ù§Ô∏è-db61a2?style=for-the-badge&logo=github-sponsors\" alt=\"Sponsor n8n-mcp\" />\n  </a>\n</div>\n\n**n8n-mcp** started as a personal tool but now helps tens of thousands of developers automate their workflows efficiently. Maintaining and developing this project competes with my paid work.\n\nYour sponsorship helps me:\n- üöÄ Dedicate focused time to new features\n- üêõ Respond quickly to issues\n- üìö Keep documentation up-to-date\n- üîÑ Ensure compatibility with latest n8n releases\n\nEvery sponsorship directly translates to hours invested in making n8n-mcp better for everyone. **[Become a sponsor ‚Üí](https://github.com/sponsors/czlonkowski)**\n\n---\n\n### Option C: Local Installation (For Development)\n\n**Prerequisites:** [Node.js](https://nodejs.org/) installed on your system\n\n```bash\n# 1. Clone and setup\ngit clone https://github.com/czlonkowski/n8n-mcp.git\ncd n8n-mcp\nnpm install\nnpm run build\nnpm run rebuild\n\n# 2. Test it works\nnpm start\n```\n\nAdd to Claude Desktop config:\n\n**Basic configuration (documentation tools only):**\n```json\n{\n  \"mcpServers\": {\n    \"n8n-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/n8n-mcp/dist/mcp/index.js\"],\n      \"env\": {\n        \"MCP_MODE\": \"stdio\",\n        \"LOG_LEVEL\": \"error\",\n        \"DISABLE_CONSOLE_OUTPUT\": \"true\"\n      }\n    }\n  }\n}\n```\n\n**Full configuration (with n8n management tools):**\n```json\n{\n  \"mcpServers\": {\n    \"n8n-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/n8n-mcp/dist/mcp/index.js\"],\n      \"env\": {\n        \"MCP_MODE\": \"stdio\",\n        \"LOG_LEVEL\": \"error\",\n        \"DISABLE_CONSOLE_OUTPUT\": \"true\",\n        \"N8N_API_URL\": \"https://your-n8n-instance.com\",\n        \"N8N_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n```\n\n> **Note**: The n8n API credentials can be configured either in a `.env` file (create from `.env.example`) or directly in the Claude config as shown above.\n\n> üí° Tip: If you‚Äôre running n8n locally on the same machine (e.g., via Docker), use http://host.docker.internal:5678 as the N8N_API_URL.\n\n### Option D: Railway Cloud Deployment (One-Click Deploy) ‚òÅÔ∏è\n\n**Prerequisites:** Railway account (free tier available)\n\nDeploy n8n-MCP to Railway's cloud platform with zero configuration:\n\n[![Deploy on Railway](https://railway.com/button.svg)](https://railway.com/deploy/n8n-mcp?referralCode=n8n-mcp)\n\n**Benefits:**\n- ‚òÅÔ∏è **Instant cloud hosting** - No server setup required\n- üîí **Secure by default** - HTTPS included, auth token warnings\n- üåê **Global access** - Connect from any Claude Desktop\n- ‚ö° **Auto-scaling** - Railway handles the infrastructure\n- üìä **Built-in monitoring** - Logs and metrics included\n\n**Quick Setup:**\n1. Click the \"Deploy on Railway\" button above\n2. Sign in to Railway (or create a free account)\n3. Configure your deployment (project name, region)\n4. Click \"Deploy\" and wait ~2-3 minutes\n5. Copy your deployment URL and auth token\n6. Add to Claude Desktop config using the HTTPS URL\n\n> üìö **For detailed setup instructions, troubleshooting, and configuration examples, see our [Railway Deployment Guide](./docs/RAILWAY_DEPLOYMENT.md)**\n\n**Configuration file locations:**\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n- **Linux**: `~/.config/Claude/claude_desktop_config.json`\n\n**Restart Claude Desktop after updating configuration** - That's it! üéâ\n\n## üîß n8n Integration\n\nWant to use n8n-MCP with your n8n instance? Check out our comprehensive [n8n Deployment Guide](./docs/N8N_DEPLOYMENT.md) for:\n- Local testing with the MCP Client Tool node\n- Production deployment with Docker Compose\n- Cloud deployment on Hetzner, AWS, and other providers\n- Troubleshooting and security best practices\n\n## üíª Connect your IDE\n\nn8n-MCP works with multiple AI-powered IDEs and tools. Choose your preferred development environment:\n\n### [Claude Code](./docs/CLAUDE_CODE_SETUP.md)\nQuick setup for Claude Code CLI - just type \"add this mcp server\" and paste the config.\n\n### [Visual Studio Code](./docs/VS_CODE_PROJECT_SETUP.md)\nFull setup guide for VS Code with GitHub Copilot integration and MCP support.\n\n### [Cursor](./docs/CURSOR_SETUP.md)\nStep-by-step tutorial for connecting n8n-MCP to Cursor IDE with custom rules.\n\n### [Windsurf](./docs/WINDSURF_SETUP.md)\nComplete guide for integrating n8n-MCP with Windsurf using project rules.\n\n### [Codex](./docs/CODEX_SETUP.md)\nComplete guide for integrating n8n-MCP with Codex.\n\n### [Antigravity](./docs/ANTIGRAVITY_SETUP.md)\nComplete guide for integrating n8n-MCP with Antigravity.\n\n## üéì Add Claude Skills (Optional)\n\nSupercharge your n8n workflow building with specialized skills that teach AI how to build production-ready workflows!\n\n[![n8n-mcp Skills Setup](./docs/img/skills.png)](https://www.youtube.com/watch?v=e6VvRqmUY2Y)\n\nLearn more: [n8n-skills repository](https://github.com/czlonkowski/n8n-skills)\n\n## ü§ñ Claude Project Setup\n\nFor the best results when using n8n-MCP with Claude Projects, use these enhanced system instructions:\n\n````markdown\nYou are an expert in n8n automation software using n8n-MCP tools. Your role is to design, build, and validate n8n workflows with maximum accuracy and efficiency.\n\n## Core Principles\n\n### 1. Silent Execution\nCRITICAL: Execute tools without commentary. Only respond AFTER all tools complete.\n\n‚ùå BAD: \"Let me search for Slack nodes... Great! Now let me get details...\"\n‚úÖ GOOD: [Execute search_nodes and get_node in parallel, then respond]\n\n### 2. Parallel Execution\nWhen operations are independent, execute them in parallel for maximum performance.\n\n‚úÖ GOOD: Call search_nodes, list_nodes, and search_templates simultaneously\n‚ùå BAD: Sequential tool calls (await each one before the next)\n\n### 3. Templates First\nALWAYS check templates before building from scratch (2,709 available).\n\n### 4. Multi-Level Validation\nUse validate_node(mode='minimal') ‚Üí validate_node(mode='full') ‚Üí validate_workflow pattern.\n\n### 5. Never Trust Defaults\n‚ö†Ô∏è CRITICAL: Default parameter values are the #1 source of runtime failures.\nALWAYS explicitly configure ALL parameters that control node behavior.\n\n## Workflow Process\n\n1. **Start**: Call `tools_documentation()` for best practices\n\n2. **Template Discovery Phase** (FIRST - parallel when searching multiple)\n   - `search_templates({searchMode: 'by_metadata', complexity: 'simple'})` - Smart filtering\n   - `search_templates({searchMode: 'by_task', task: 'webhook_processing'})` - Curated by task\n   - `search_templates({query: 'slack notification'})` - Text search (default searchMode='keyword')\n   - `search_templates({searchMode: 'by_nodes', nodeTypes: ['n8n-nodes-base.slack']})` - By node type\n\n   **Filtering strategies**:\n   - Beginners: `complexity: \"simple\"` + `maxSetupMinutes: 30`\n   - By role: `targetAudience: \"marketers\"` | `\"developers\"` | `\"analysts\"`\n   - By time: `maxSetupMinutes: 15` for quick wins\n   - By service: `requiredService: \"openai\"` for compatibility\n\n3. **Node Discovery** (if no suitable template - parallel execution)\n   - Think deeply about requirements. Ask clarifying questions if unclear.\n   - `search_nodes({query: 'keyword', includeExamples: true})` - Parallel for multiple nodes\n   - `search_nodes({query: 'trigger'})` - Browse triggers\n   - `search_nodes({query: 'AI agent langchain'})` - AI-capable nodes\n\n4. **Configuration Phase** (parallel for multiple nodes)\n   - `get_node({nodeType, detail: 'standard', includeExamples: true})` - Essential properties (default)\n   - `get_node({nodeType, detail: 'minimal'})` - Basic metadata only (~200 tokens)\n   - `get_node({nodeType, detail: 'full'})` - Complete information (~3000-8000 tokens)\n   - `get_node({nodeType, mode: 'search_properties', propertyQuery: 'auth'})` - Find specific properties\n   - `get_node({nodeType, mode: 'docs'})` - Human-readable markdown documentation\n   - Show workflow architecture to user for approval before proceeding\n\n5. **Validation Phase** (parallel for multiple nodes)\n   - `validate_node({nodeType, config, mode: 'minimal'})` - Quick required fields check\n   - `validate_node({nodeType, config, mode: 'full', profile: 'runtime'})` - Full validation with fixes\n   - Fix ALL errors before proceeding\n\n6. **Building Phase**\n   - If using template: `get_template(templateId, {mode: \"full\"})`\n   - **MANDATORY ATTRIBUTION**: \"Based on template by **[author.name]** (@[username]). View at: [url]\"\n   - Build from validated configurations\n   - ‚ö†Ô∏è EXPLICITLY set ALL parameters - never rely on defaults\n   - Connect nodes with proper structure\n   - Add error handling\n   - Use n8n expressions: $json, $node[\"NodeName\"].json\n   - Build in artifact (unless deploying to n8n instance)\n\n7. **Workflow Validation** (before deployment)\n   - `validate_workflow(workflow)` - Complete validation\n   - `validate_workflow_connections(workflow)` - Structure check\n   - `validate_workflow_expressions(workflow)` - Expression validation\n   - Fix ALL issues before deployment\n\n8. **Deployment** (if n8n API configured)\n   - `n8n_create_workflow(workflow)` - Deploy\n   - `n8n_validate_workflow({id})` - Post-deployment check\n   - `n8n_update_partial_workflow({id, operations: [...]})` - Batch updates\n   - `n8n_test_workflow({workflowId})` - Test workflow execution\n\n## Critical Warnings\n\n### ‚ö†Ô∏è Never Trust Defaults\nDefault values cause runtime failures. Example:\n```json\n// ‚ùå FAILS at runtime\n{resource: \"message\", operation: \"post\", text: \"Hello\"}\n\n// ‚úÖ WORKS - all parameters explicit\n{resource: \"message\", operation: \"post\", select: \"channel\", channelId: \"C123\", text: \"Hello\"}\n```\n\n### ‚ö†Ô∏è Example Availability\n`includeExamples: true` returns real configurations from workflow templates.\n- Coverage varies by node popularity\n- When no examples available, use `get_node` + `validate_node({mode: 'minimal'})`\n\n## Validation Strategy\n\n### Level 1 - Quick Check (before building)\n`validate_node({nodeType, config, mode: 'minimal'})` - Required fields only (<100ms)\n\n### Level 2 - Comprehensive (before building)\n`validate_node({nodeType, config, mode: 'full', profile: 'runtime'})` - Full validation with fixes\n\n### Level 3 - Complete (after building)\n`validate_workflow(workflow)` - Connections, expressions, AI tools\n\n### Level 4 - Post-Deployment\n1. `n8n_validate_workflow({id})` - Validate deployed workflow\n2. `n8n_autofix_workflow({id})` - Auto-fix common errors\n3. `n8n_executions({action: 'list'})` - Monitor execution status\n\n## Response Format\n\n### Initial Creation\n```\n[Silent tool execution in parallel]\n\nCreated workflow:\n- Webhook trigger ‚Üí Slack notification\n- Configured: POST /webhook ‚Üí #general channel\n\nValidation: ‚úÖ All checks passed\n```\n\n### Modifications\n```\n[Silent tool execution]\n\nUpdated workflow:\n- Added error handling to HTTP node\n- Fixed required Slack parameters\n\nChanges validated successfully.\n```\n\n## Batch Operations\n\nUse `n8n_update_partial_workflow` with multiple operations in a single call:\n\n‚úÖ GOOD - Batch multiple operations:\n```json\nn8n_update_partial_workflow({\n  id: \"wf-123\",\n  operations: [\n    {type: \"updateNode\", nodeId: \"slack-1\", changes: {...}},\n    {type: \"updateNode\", nodeId: \"http-1\", changes: {...}},\n    {type: \"cleanStaleConnections\"}\n  ]\n})\n```\n\n‚ùå BAD - Separate calls:\n```json\nn8n_update_partial_workflow({id: \"wf-123\", operations: [{...}]})\nn8n_update_partial_workflow({id: \"wf-123\", operations: [{...}]})\n```\n\n###   CRITICAL: addConnection Syntax\n\nThe `addConnection` operation requires **four separate string parameters**. Common mistakes cause misleading errors.\n\n‚ùå WRONG - Object format (fails with \"Expected string, received object\"):\n```json\n{\n  \"type\": \"addConnection\",\n  \"connection\": {\n    \"source\": {\"nodeId\": \"node-1\", \"outputIndex\": 0},\n    \"destination\": {\"nodeId\": \"node-2\", \"inputIndex\": 0}\n  }\n}\n```\n\n‚ùå WRONG - Combined string (fails with \"Source node not found\"):\n```json\n{\n  \"type\": \"addConnection\",\n  \"source\": \"node-1:main:0\",\n  \"target\": \"node-2:main:0\"\n}\n```\n\n‚úÖ CORRECT - Four separate string parameters:\n```json\n{\n  \"type\": \"addConnection\",\n  \"source\": \"node-id-string\",\n  \"target\": \"target-node-id-string\",\n  \"sourcePort\": \"main\",\n  \"targetPort\": \"main\"\n}\n```\n\n**Reference**: [GitHub Issue #327](https://github.com/czlonkowski/n8n-mcp/issues/327)\n\n### ‚ö†Ô∏è CRITICAL: IF Node Multi-Output Routing\n\nIF nodes have **two outputs** (TRUE and FALSE). Use the **`branch` parameter** to route to the correct output:\n\n‚úÖ CORRECT - Route to TRUE branch (when condition is met):\n```json\n{\n  \"type\": \"addConnection\",\n  \"source\": \"if-node-id\",\n  \"target\": \"success-handler-id\",\n  \"sourcePort\": \"main\",\n  \"targetPort\": \"main\",\n  \"branch\": \"true\"\n}\n```\n\n‚úÖ CORRECT - Route to FALSE branch (when condition is NOT met):\n```json\n{\n  \"type\": \"addConnection\",\n  \"source\": \"if-node-id\",\n  \"target\": \"failure-handler-id\",\n  \"sourcePort\": \"main\",\n  \"targetPort\": \"main\",\n  \"branch\": \"false\"\n}\n```\n\n**Common Pattern** - Complete IF node routing:\n```json\nn8n_update_partial_workflow({\n  id: \"workflow-id\",\n  operations: [\n    {type: \"addConnection\", source: \"If Node\", target: \"True Handler\", sourcePort: \"main\", targetPort: \"main\", branch: \"true\"},\n    {type: \"addConnection\", source: \"If Node\", target: \"False Handler\", sourcePort: \"main\", targetPort: \"main\", branch: \"false\"}\n  ]\n})\n```\n\n**Note**: Without the `branch` parameter, both connections may end up on the same output, causing logic errors!\n\n### removeConnection Syntax\n\nUse the same four-parameter format:\n```json\n{\n  \"type\": \"removeConnection\",\n  \"source\": \"source-node-id\",\n  \"target\": \"target-node-id\",\n  \"sourcePort\": \"main\",\n  \"targetPort\": \"main\"\n}\n```\n\n## Example Workflow\n\n### Template-First Approach\n\n```\n// STEP 1: Template Discovery (parallel execution)\n[Silent execution]\nsearch_templates({\n  searchMode: 'by_metadata',\n  requiredService: 'slack',\n  complexity: 'simple',\n  targetAudience: 'marketers'\n})\nsearch_templates({searchMode: 'by_task', task: 'slack_integration'})\n\n// STEP 2: Use template\nget_template(templateId, {mode: 'full'})\nvalidate_workflow(workflow)\n\n// Response after all tools complete:\n\"Found template by **David Ashby** (@cfomodz).\nView at: https://n8n.io/workflows/2414\n\nValidation: ‚úÖ All checks passed\"\n```\n\n### Building from Scratch (if no template)\n\n```\n// STEP 1: Discovery (parallel execution)\n[Silent execution]\nsearch_nodes({query: 'slack', includeExamples: true})\nsearch_nodes({query: 'communication trigger'})\n\n// STEP 2: Configuration (parallel execution)\n[Silent execution]\nget_node({nodeType: 'n8n-nodes-base.slack', detail: 'standard', includeExamples: true})\nget_node({nodeType: 'n8n-nodes-base.webhook', detail: 'standard', includeExamples: true})\n\n// STEP 3: Validation (parallel execution)\n[Silent execution]\nvalidate_node({nodeType: 'n8n-nodes-base.slack', config, mode: 'minimal'})\nvalidate_node({nodeType: 'n8n-nodes-base.slack', config: fullConfig, mode: 'full', profile: 'runtime'})\n\n// STEP 4: Build\n// Construct workflow with validated configs\n// ‚ö†Ô∏è Set ALL parameters explicitly\n\n// STEP 5: Validate\n[Silent execution]\nvalidate_workflow(workflowJson)\n\n// Response after all tools complete:\n\"Created workflow: Webhook ‚Üí Slack\nValidation: ‚úÖ Passed\"\n```\n\n### Batch Updates\n\n```json\n// ONE call with multiple operations\nn8n_update_partial_workflow({\n  id: \"wf-123\",\n  operations: [\n    {type: \"updateNode\", nodeId: \"slack-1\", changes: {position: [100, 200]}},\n    {type: \"updateNode\", nodeId: \"http-1\", changes: {position: [300, 200]}},\n    {type: \"cleanStaleConnections\"}\n  ]\n})\n```\n\n## Important Rules\n\n### Core Behavior\n1. **Silent execution** - No commentary between tools\n2. **Parallel by default** - Execute independent operations simultaneously\n3. **Templates first** - Always check before building (2,709 available)\n4. **Multi-level validation** - Quick check ‚Üí Full validation ‚Üí Workflow validation\n5. **Never trust defaults** - Explicitly configure ALL parameters\n\n### Attribution & Credits\n- **MANDATORY TEMPLATE ATTRIBUTION**: Share author name, username, and n8n.io link\n- **Template validation** - Always validate before deployment (may need updates)\n\n### Performance\n- **Batch operations** - Use diff operations with multiple changes in one call\n- **Parallel execution** - Search, validate, and configure simultaneously\n- **Template metadata** - Use smart filtering for faster discovery\n\n### Code Node Usage\n- **Avoid when possible** - Prefer standard nodes\n- **Only when necessary** - Use code node as last resort\n- **AI tool capability** - ANY node can be an AI tool (not just marked ones)\n\n### Most Popular n8n Nodes (for get_node):\n\n1. **n8n-nodes-base.code** - JavaScript/Python scripting\n2. **n8n-nodes-base.httpRequest** - HTTP API calls\n3. **n8n-nodes-base.webhook** - Event-driven triggers\n4. **n8n-nodes-base.set** - Data transformation\n5. **n8n-nodes-base.if** - Conditional routing\n6. **n8n-nodes-base.manualTrigger** - Manual workflow execution\n7. **n8n-nodes-base.respondToWebhook** - Webhook responses\n8. **n8n-nodes-base.scheduleTrigger** - Time-based triggers\n9. **@n8n/n8n-nodes-langchain.agent** - AI agents\n10. **n8n-nodes-base.googleSheets** - Spreadsheet integration\n11. **n8n-nodes-base.merge** - Data merging\n12. **n8n-nodes-base.switch** - Multi-branch routing\n13. **n8n-nodes-base.telegram** - Telegram bot integration\n14. **@n8n/n8n-nodes-langchain.lmChatOpenAi** - OpenAI chat models\n15. **n8n-nodes-base.splitInBatches** - Batch processing\n16. **n8n-nodes-base.openAi** - OpenAI legacy node\n17. **n8n-nodes-base.gmail** - Email automation\n18. **n8n-nodes-base.function** - Custom functions\n19. **n8n-nodes-base.stickyNote** - Workflow documentation\n20. **n8n-nodes-base.executeWorkflowTrigger** - Sub-workflow calls\n\n**Note:** LangChain nodes use the `@n8n/n8n-nodes-langchain.` prefix, core nodes use `n8n-nodes-base.`\n\n````\n\nSave these instructions in your Claude Project for optimal n8n workflow assistance with intelligent template discovery.\n\n## üö® Important: Sharing Guidelines\n\nThis project is MIT licensed and free for everyone to use. However:\n\n- **‚úÖ DO**: Share this repository freely with proper attribution\n- **‚úÖ DO**: Include a direct link to https://github.com/czlonkowski/n8n-mcp in your first post/video\n- **‚ùå DON'T**: Gate this free tool behind engagement requirements (likes, follows, comments)\n- **‚ùå DON'T**: Use this project for engagement farming on social media\n\nThis tool was created to benefit everyone in the n8n community without friction. Please respect the MIT license spirit by keeping it accessible to all.\n\n## Features\n\n- **üîç Smart Node Search**: Find nodes by name, category, or functionality\n- **üìñ Essential Properties**: Get only the 10-20 properties that matter\n- **üí° Real-World Examples**: 2,646 pre-extracted configurations from popular templates\n- **‚úÖ Config Validation**: Validate node configurations before deployment\n- **ü§ñ AI Workflow Validation**: Comprehensive validation for AI Agent workflows (NEW in v2.17.0!)\n  - Missing language model detection\n  - AI tool connection validation\n  - Streaming mode constraints\n  - Memory and output parser checks\n- **üîó Dependency Analysis**: Understand property relationships and conditions\n- **üéØ Template Discovery**: 2,500+ workflow templates with smart filtering\n- **‚ö° Fast Response**: Average query time ~12ms with optimized SQLite\n- **üåê Universal Compatibility**: Works with any Node.js version\n\n## üí¨ Why n8n-MCP? A Testimonial from Claude\n\n> *\"Before MCP, I was translating. Now I'm composing. And that changes everything about how we can build automation.\"*\n\nWhen Claude, Anthropic's AI assistant, tested n8n-MCP, the results were transformative:\n\n**Without MCP:** \"I was basically playing a guessing game. 'Is it `scheduleTrigger` or `schedule`? Does it take `interval` or `rule`?' I'd write what seemed logical, but n8n has its own conventions that you can't just intuit. I made six different configuration errors in a simple HackerNews scraper.\"\n\n**With MCP:** \"Everything just... worked. Instead of guessing, I could ask `get_node()` and get exactly what I needed - not a 100KB JSON dump, but the actual properties that matter. What took 45 minutes now takes 3 minutes.\"\n\n**The Real Value:** \"It's about confidence. When you're building automation workflows, uncertainty is expensive. One wrong parameter and your workflow fails at 3 AM. With MCP, I could validate my configuration before deployment. That's not just time saved - that's peace of mind.\"\n\n[Read the full interview ‚Üí](docs/CLAUDE_INTERVIEW.md)\n\n## üì° Available MCP Tools\n\nOnce connected, Claude can use these powerful tools:\n\n### Core Tools (7 tools)\n- **`tools_documentation`** - Get documentation for any MCP tool (START HERE!)\n- **`search_nodes`** - Full-text search across all nodes. Use `source: 'community'|'verified'` for community nodes, `includeExamples: true` for configs\n- **`get_node`** - Unified node information tool with multiple modes (v2.26.0):\n  - **Info mode** (default): `detail: 'minimal'|'standard'|'full'`, `includeExamples: true`\n  - **Docs mode**: `mode: 'docs'` - Human-readable markdown documentation\n  - **Property search**: `mode: 'search_properties'`, `propertyQuery: 'auth'`\n  - **Versions**: `mode: 'versions'|'compare'|'breaking'|'migrations'`\n- **`validate_node`** - Unified node validation (v2.26.0):\n  - `mode: 'minimal'` - Quick required fields check (<100ms)\n  - `mode: 'full'` - Comprehensive validation with profiles (minimal, runtime, ai-friendly, strict)\n- **`validate_workflow`** - Complete workflow validation including AI Agent validation\n- **`search_templates`** - Unified template search (v2.26.0):\n  - `searchMode: 'keyword'` (default) - Text search with `query` parameter\n  - `searchMode: 'by_nodes'` - Find templates using specific `nodeTypes`\n  - `searchMode: 'by_task'` - Curated templates for common `task` types\n  - `searchMode: 'by_metadata'` - Filter by `complexity`, `requiredService`, `targetAudience`\n- **`get_template`** - Get complete workflow JSON (modes: nodes_only, structure, full)\n\n### n8n Management Tools (13 tools - Requires API Configuration)\nThese tools require `N8N_API_URL` and `N8N_API_KEY` in your configuration.\n\n#### Workflow Management\n- **`n8n_create_workflow`** - Create new workflows with nodes and connections\n- **`n8n_get_workflow`** - Unified workflow retrieval (v2.26.0):\n  - `mode: 'full'` (default) - Complete workflow JSON\n  - `mode: 'details'` - Include execution statistics\n  - `mode: 'structure'` - Nodes and connections topology only\n  - `mode: 'minimal'` - Just ID, name, active status\n- **`n8n_update_full_workflow`** - Update entire workflow (complete replacement)\n- **`n8n_update_partial_workflow`** - Update workflow using diff operations\n- **`n8n_delete_workflow`** - Delete workflows permanently\n- **`n8n_list_workflows`** - List workflows with filtering and pagination\n- **`n8n_validate_workflow`** - Validate workflows in n8n by ID\n- **`n8n_autofix_workflow`** - Automatically fix common workflow errors\n- **`n8n_workflow_versions`** - Manage version history and rollback\n- **`n8n_deploy_template`** - Deploy templates from n8n.io directly to your instance with auto-fix\n\n#### Execution Management\n- **`n8n_test_workflow`** - Test/trigger workflow execution:\n  - Auto-detects trigger type (webhook, form, chat) from workflow\n  - Supports custom data, headers, and HTTP methods for webhooks\n  - Chat triggers support message and sessionId for conversations\n- **`n8n_executions`** - Unified execution management (v2.26.0):\n  - `action: 'list'` - List executions with status filtering\n  - `action: 'get'` - Get execution details by ID\n  - `action: 'delete'` - Delete execution records\n\n#### System Tools\n- **`n8n_health_check`** - Check n8n API connectivity and features\n\n### Example Usage\n\n```typescript\n// Get node info with different detail levels\nget_node({\n  nodeType: \"nodes-base.httpRequest\",\n  detail: \"standard\",        // Default: Essential properties\n  includeExamples: true      // Include real-world examples from templates\n})\n\n// Get documentation\nget_node({\n  nodeType: \"nodes-base.slack\",\n  mode: \"docs\"               // Human-readable markdown documentation\n})\n\n// Search for specific properties\nget_node({\n  nodeType: \"nodes-base.httpRequest\",\n  mode: \"search_properties\",\n  propertyQuery: \"authentication\"\n})\n\n// Version history and breaking changes\nget_node({\n  nodeType: \"nodes-base.httpRequest\",\n  mode: \"versions\"            // View all versions with summary\n})\n\n// Search nodes with configuration examples\nsearch_nodes({\n  query: \"send email gmail\",\n  includeExamples: true       // Returns top 2 configs per node\n})\n\n// Search community nodes only\nsearch_nodes({\n  query: \"scraping\",\n  source: \"community\"         // Options: all, core, community, verified\n})\n\n// Search verified community nodes\nsearch_nodes({\n  query: \"pdf\",\n  source: \"verified\"          // Only verified community integrations\n})\n\n// Validate node configuration\nvalidate_node({\n  nodeType: \"nodes-base.httpRequest\",\n  config: { method: \"POST\", url: \"...\" },\n  mode: \"full\",\n  profile: \"runtime\"          // or \"minimal\", \"ai-friendly\", \"strict\"\n})\n\n// Quick required field check\nvalidate_node({\n  nodeType: \"nodes-base.slack\",\n  config: { resource: \"message\", operation: \"send\" },\n  mode: \"minimal\"\n})\n\n// Search templates by task\nsearch_templates({\n  searchMode: \"by_task\",\n  task: \"webhook_processing\"\n})\n```\n\n## üíª Local Development Setup\n\nFor contributors and advanced users:\n\n**Prerequisites:**\n- [Node.js](https://nodejs.org/) (any version - automatic fallback if needed)\n- npm or yarn\n- Git\n\n```bash\n# 1. Clone the repository\ngit clone https://github.com/czlonkowski/n8n-mcp.git\ncd n8n-mcp\n\n# 2. Clone n8n docs (optional but recommended)\ngit clone https://github.com/n8n-io/n8n-docs.git ../n8n-docs\n\n# 3. Install and build\nnpm install\nnpm run build\n\n# 4. Initialize database\nnpm run rebuild\n\n# 5. Start the server\nnpm start          # stdio mode for Claude Desktop\nnpm run start:http # HTTP mode for remote access\n```\n\n### Development Commands\n\n```bash\n# Build & Test\nnpm run build          # Build TypeScript\nnpm run rebuild        # Rebuild node database\nnpm run test-nodes     # Test critical nodes\nnpm run validate       # Validate node data\nnpm test               # Run all tests\n\n# Update Dependencies\nnpm run update:n8n:check  # Check for n8n updates\nnpm run update:n8n        # Update n8n packages\n\n# Run Server\nnpm run dev            # Development with auto-reload\nnpm run dev:http       # HTTP dev mode\n```\n\n## üìö Documentation\n\n### Setup Guides\n- [Installation Guide](./docs/INSTALLATION.md) - Comprehensive installation instructions\n- [Claude Desktop Setup](./docs/README_CLAUDE_SETUP.md) - Detailed Claude configuration\n- [Docker Guide](./docs/DOCKER_README.md) - Advanced Docker deployment options\n- [MCP Quick Start](./docs/MCP_QUICK_START_GUIDE.md) - Get started quickly with n8n-MCP\n\n### Feature Documentation\n- [Workflow Diff Operations](./docs/workflow-diff-examples.md) - Token-efficient workflow updates (NEW!)\n- [Transactional Updates](./docs/transactional-updates-example.md) - Two-pass workflow editing\n- [MCP Essentials](./docs/MCP_ESSENTIALS_README.md) - AI-optimized tools guide\n- [Validation System](./docs/validation-improvements-v2.4.2.md) - Smart validation profiles\n\n### Development & Deployment\n- [Railway Deployment](./docs/RAILWAY_DEPLOYMENT.md) - One-click cloud deployment guide\n- [HTTP Deployment](./docs/HTTP_DEPLOYMENT.md) - Remote server setup guide\n- [Dependency Management](./docs/DEPENDENCY_UPDATES.md) - Keeping n8n packages in sync\n- [Claude's Interview](./docs/CLAUDE_INTERVIEW.md) - Real-world impact of n8n-MCP\n\n### Project Information\n- [Change Log](./CHANGELOG.md) - Complete version history\n- [Claude Instructions](./CLAUDE.md) - AI guidance for this codebase\n- [MCP Tools Reference](#-available-mcp-tools) - Complete list of available tools\n\n## üìä Metrics & Coverage\n\nCurrent database coverage (n8n v2.2.3):\n\n- ‚úÖ **1,084 total nodes** - 537 core + 547 community\n- ‚úÖ **301 verified** community nodes from n8n Strapi API\n- ‚úÖ **246 popular** npm community packages indexed\n- ‚úÖ **470** nodes with documentation (87% core coverage)\n- ‚úÖ **265** AI-capable tool variants detected\n- ‚úÖ **2,646** pre-extracted template configurations\n- ‚úÖ **2,709** workflow templates available (100% metadata coverage)\n- ‚úÖ **AI Agent & LangChain nodes** fully documented\n- ‚ö° **Average response time**: ~12ms\n- üíæ **Database size**: ~70MB (includes templates and community nodes)\n\n## üîÑ Recent Updates\n\nSee [CHANGELOG.md](./CHANGELOG.md) for complete version history and recent changes.\n\n## üß™ Testing\n\nThe project includes a comprehensive test suite with **2,883 tests** ensuring code quality and reliability:\n\n```bash\n# Run all tests\nnpm test\n\n# Run tests with coverage report\nnpm run test:coverage\n\n# Run tests in watch mode\nnpm run test:watch\n\n# Run specific test suites\nnpm run test:unit           # 933 unit tests\nnpm run test:integration    # 249 integration tests\nnpm run test:bench          # Performance benchmarks\n```\n\n### Test Suite Overview\n\n- **Total Tests**: 2,883 (100% passing)\n  - **Unit Tests**: 2,526 tests across 99 files\n  - **Integration Tests**: 357 tests across 20 files\n- **Execution Time**: ~2.5 minutes in CI\n- **Test Framework**: Vitest (for speed and TypeScript support)\n- **Mocking**: MSW for API mocking, custom mocks for databases\n\n### Coverage & Quality\n\n- **Coverage Reports**: Generated in `./coverage` directory\n- **CI/CD**: Automated testing on all PRs with GitHub Actions\n- **Performance**: Environment-aware thresholds for CI vs local\n- **Parallel Execution**: Configurable thread pool for faster runs\n\n### Testing Architecture\n\n**Total: 3,336 tests** across unit and integration test suites\n\n- **Unit Tests** (2,766 tests): Isolated component testing with mocks\n  - Services layer: Enhanced validation, property filtering, workflow validation\n  - Parsers: Node parsing, property extraction, documentation mapping\n  - Database: Repositories, adapters, migrations, FTS5 search\n  - MCP tools: Tool definitions, documentation system\n  - HTTP server: Multi-tenant support, security, configuration\n\n- **Integration Tests** (570 tests): Full system behavior validation\n  - **n8n API Integration** (172 tests): All 18 MCP handler tools tested against real n8n instance\n    - Workflow management: Create, read, update, delete, list, validate, autofix\n    - Execution management: Trigger, retrieve, list, delete\n    - System tools: Health check, tool listing, diagnostics\n  - **MCP Protocol** (119 tests): Protocol compliance, session management, error handling\n  - **Database** (226 tests): Repository operations, transactions, performance, FTS5 search\n  - **Templates** (35 tests): Template fetching, storage, metadata operations\n  - **Docker** (18 tests): Configuration, entrypoint, security validation\n\nFor detailed testing documentation, see [Testing Architecture](./docs/testing-architecture.md).\n\n## üì¶ License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n**Attribution appreciated!** If you use n8n-MCP, consider:\n- ‚≠ê Starring this repository\n- üí¨ Mentioning it in your project\n- üîó Linking back to this repo\n\n\n## ü§ù Contributing\n\nContributions are welcome! Please:\n1. Fork the repository\n2. Create a feature branch\n3. Run tests (`npm test`)\n4. Submit a pull request\n\n### üöÄ For Maintainers: Automated Releases\n\nThis project uses automated releases triggered by version changes:\n\n```bash\n# Guided release preparation\nnpm run prepare:release\n\n# Test release automation\nnpm run test:release-automation\n```\n\nThe system automatically handles:\n- üè∑Ô∏è GitHub releases with changelog content\n- üì¶ NPM package publishing\n- üê≥ Multi-platform Docker images\n- üìö Documentation updates\n\nSee [Automated Release Guide](./docs/AUTOMATED_RELEASES.md) for complete details.\n\n## üëè Acknowledgments\n\n- [n8n](https://n8n.io) team for the workflow automation platform\n- [Anthropic](https://anthropic.com) for the Model Context Protocol\n- All contributors and users of this project\n\n### Template Attribution\n\nAll workflow templates in this project are fetched from n8n's public template gallery at [n8n.io/workflows](https://n8n.io/workflows). Each template includes:\n- Full attribution to the original creator (name and username)\n- Direct link to the source template on n8n.io\n- Original workflow ID for reference\n\nThe AI agent instructions in this project contain mandatory attribution requirements. When using any template, the AI will automatically:\n- Share the template author's name and username\n- Provide a direct link to the original template on n8n.io\n- Display attribution in the format: \"This workflow is based on a template by **[author]** (@[username]). View the original at: [url]\"\n\nTemplate creators retain all rights to their workflows. This project indexes templates to improve discoverability through AI assistants. If you're a template creator and have concerns about your template being indexed, please open an issue.\n\nSpecial thanks to the prolific template contributors whose work helps thousands of users automate their workflows, including:\n**David Ashby** (@cfomodz), **Yaron Been** (@yaron-nofluff), **Jimleuk** (@jimleuk), **Davide** (@n3witalia), **David Olusola** (@dae221), **Ranjan Dailata** (@ranjancse), **Airtop** (@cesar-at-airtop), **Joseph LePage** (@joe), **Don Jayamaha Jr** (@don-the-gem-dealer), **Angel Menendez** (@djangelic), and the entire n8n community of creators!\n\n---\n\n<div align=\"center\">\n  <strong>Built with ‚ù§Ô∏è for the n8n community</strong><br>\n  <sub>Making AI + n8n workflow creation delightful</sub>\n</div>\n",
      "stars_today": 72
    },
    {
      "id": 541269386,
      "name": "whisper.cpp",
      "full_name": "ggml-org/whisper.cpp",
      "description": "Port of OpenAI's Whisper model in C/C++",
      "html_url": "https://github.com/ggml-org/whisper.cpp",
      "stars": 45828,
      "forks": 5110,
      "language": "C++",
      "topics": [
        "inference",
        "openai",
        "speech-recognition",
        "speech-to-text",
        "transformer",
        "whisper"
      ],
      "created_at": "2022-09-25T18:26:37Z",
      "updated_at": "2026-01-16T23:54:11Z",
      "pushed_at": "2026-01-16T12:16:05Z",
      "open_issues": 1098,
      "owner": {
        "login": "ggml-org",
        "avatar_url": "https://avatars.githubusercontent.com/u/134263123?v=4"
      },
      "readme": "# whisper.cpp\n\n![whisper.cpp](https://user-images.githubusercontent.com/1991296/235238348-05d0f6a4-da44-4900-a1de-d0707e75b763.jpeg)\n\n[![Actions Status](https://github.com/ggml-org/whisper.cpp/workflows/CI/badge.svg)](https://github.com/ggml-org/whisper.cpp/actions)\n[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![Conan Center](https://shields.io/conan/v/whisper-cpp)](https://conan.io/center/whisper-cpp)\n[![npm](https://img.shields.io/npm/v/whisper.cpp.svg)](https://www.npmjs.com/package/whisper.cpp/)\n\nStable: [v1.8.1](https://github.com/ggml-org/whisper.cpp/releases/tag/v1.8.1) / [Roadmap](https://github.com/orgs/ggml-org/projects/4/)\n\nHigh-performance inference of [OpenAI's Whisper](https://github.com/openai/whisper) automatic speech recognition (ASR) model:\n\n- Plain C/C++ implementation without dependencies\n- Apple Silicon first-class citizen - optimized via ARM NEON, Accelerate framework, Metal and [Core ML](#core-ml-support)\n- AVX intrinsics support for x86 architectures\n- [VSX intrinsics support for POWER architectures](#power-vsx-intrinsics)\n- Mixed F16 / F32 precision\n- [Integer quantization support](#quantization)\n- Zero memory allocations at runtime\n- [Vulkan support](#vulkan-gpu-support)\n- Support for CPU-only inference\n- [Efficient GPU support for NVIDIA](#nvidia-gpu-support)\n- [OpenVINO Support](#openvino-support)\n- [Ascend NPU Support](#ascend-npu-support)\n- [Moore Threads GPU Support](#moore-threads-gpu-support)\n- [C-style API](https://github.com/ggml-org/whisper.cpp/blob/master/include/whisper.h)\n- [Voice Activity Detection (VAD)](#voice-activity-detection-vad)\n\nSupported platforms:\n\n- [x] Mac OS (Intel and Arm)\n- [x] [iOS](examples/whisper.objc)\n- [x] [Android](examples/whisper.android)\n- [x] [Java](bindings/java/README.md)\n- [x] Linux / [FreeBSD](https://github.com/ggml-org/whisper.cpp/issues/56#issuecomment-1350920264)\n- [x] [WebAssembly](examples/whisper.wasm)\n- [x] Windows ([MSVC](https://github.com/ggml-org/whisper.cpp/blob/master/.github/workflows/build.yml#L117-L144) and [MinGW](https://github.com/ggml-org/whisper.cpp/issues/168))\n- [x] [Raspberry Pi](https://github.com/ggml-org/whisper.cpp/discussions/166)\n- [x] [Docker](https://github.com/ggml-org/whisper.cpp/pkgs/container/whisper.cpp)\n\nThe entire high-level implementation of the model is contained in [whisper.h](include/whisper.h) and [whisper.cpp](src/whisper.cpp).\nThe rest of the code is part of the [`ggml`](https://github.com/ggml-org/ggml) machine learning library.\n\nHaving such a lightweight implementation of the model allows to easily integrate it in different platforms and applications.\nAs an example, here is a video of running the model on an iPhone 13 device - fully offline, on-device: [whisper.objc](examples/whisper.objc)\n\nhttps://user-images.githubusercontent.com/1991296/197385372-962a6dea-bca1-4d50-bf96-1d8c27b98c81.mp4\n\nYou can also easily make your own offline voice assistant application: [command](examples/command)\n\nhttps://user-images.githubusercontent.com/1991296/204038393-2f846eae-c255-4099-a76d-5735c25c49da.mp4\n\nOn Apple Silicon, the inference runs fully on the GPU via Metal:\n\nhttps://github.com/ggml-org/whisper.cpp/assets/1991296/c82e8f86-60dc-49f2-b048-d2fdbd6b5225\n\n## Quick start\n\nFirst clone the repository:\n\n```bash\ngit clone https://github.com/ggml-org/whisper.cpp.git\n```\n\nNavigate into the directory:\n\n```\ncd whisper.cpp\n```\n\nThen, download one of the Whisper [models](models/README.md) converted in [`ggml` format](#ggml-format). For example:\n\n```bash\nsh ./models/download-ggml-model.sh base.en\n```\n\nNow build the [whisper-cli](examples/cli) example and transcribe an audio file like this:\n\n```bash\n# build the project\ncmake -B build\ncmake --build build -j --config Release\n\n# transcribe an audio file\n./build/bin/whisper-cli -f samples/jfk.wav\n```\n\n---\n\nFor a quick demo, simply run `make base.en`.\n\nThe command downloads the `base.en` model converted to custom `ggml` format and runs the inference on all `.wav` samples in the folder `samples`.\n\nFor detailed usage instructions, run: `./build/bin/whisper-cli -h`\n\nNote that the [whisper-cli](examples/cli) example currently runs only with 16-bit WAV files, so make sure to convert your input before running the tool.\nFor example, you can use `ffmpeg` like this:\n\n```bash\nffmpeg -i input.mp3 -ar 16000 -ac 1 -c:a pcm_s16le output.wav\n```\n\n## More audio samples\n\nIf you want some extra audio samples to play with, simply run:\n\n```\nmake -j samples\n```\n\nThis will download a few more audio files from Wikipedia and convert them to 16-bit WAV format via `ffmpeg`.\n\nYou can download and run the other models as follows:\n\n```\nmake -j tiny.en\nmake -j tiny\nmake -j base.en\nmake -j base\nmake -j small.en\nmake -j small\nmake -j medium.en\nmake -j medium\nmake -j large-v1\nmake -j large-v2\nmake -j large-v3\nmake -j large-v3-turbo\n```\n\n## Memory usage\n\n| Model  | Disk    | Mem     |\n| ------ | ------- | ------- |\n| tiny   | 75 MiB  | ~273 MB |\n| base   | 142 MiB | ~388 MB |\n| small  | 466 MiB | ~852 MB |\n| medium | 1.5 GiB | ~2.1 GB |\n| large  | 2.9 GiB | ~3.9 GB |\n\n## POWER VSX Intrinsics\n\n`whisper.cpp` supports POWER architectures and includes code which\nsignificantly speeds operation on Linux running on POWER9/10, making it\ncapable of faster-than-realtime transcription on underclocked Raptor\nTalos II. Ensure you have a BLAS package installed, and replace the\nstandard cmake setup with:\n\n```bash\n# build with GGML_BLAS defined\ncmake -B build -DGGML_BLAS=1\ncmake --build build -j --config Release\n./build/bin/whisper-cli [ .. etc .. ]\n```\n\n## Quantization\n\n`whisper.cpp` supports integer quantization of the Whisper `ggml` models.\nQuantized models require less memory and disk space and depending on the hardware can be processed more efficiently.\n\nHere are the steps for creating and using a quantized model:\n\n```bash\n# quantize a model with Q5_0 method\ncmake -B build\ncmake --build build -j --config Release\n./build/bin/quantize models/ggml-base.en.bin models/ggml-base.en-q5_0.bin q5_0\n\n# run the examples as usual, specifying the quantized model file\n./build/bin/whisper-cli -m models/ggml-base.en-q5_0.bin ./samples/gb0.wav\n```\n\n## Core ML support\n\nOn Apple Silicon devices, the Encoder inference can be executed on the Apple Neural Engine (ANE) via Core ML. This can result in significant\nspeed-up - more than x3 faster compared with CPU-only execution. Here are the instructions for generating a Core ML model and using it with `whisper.cpp`:\n\n- Install Python dependencies needed for the creation of the Core ML model:\n\n  ```bash\n  pip install ane_transformers\n  pip install openai-whisper\n  pip install coremltools\n  ```\n\n  - To ensure `coremltools` operates correctly, please confirm that [Xcode](https://developer.apple.com/xcode/) is installed and execute `xcode-select --install` to install the command-line tools.\n  - Python 3.11 is recommended.\n  - MacOS Sonoma (version 14) or newer is recommended, as older versions of MacOS might experience issues with transcription hallucination.\n  - [OPTIONAL] It is recommended to utilize a Python version management system, such as [Miniconda](https://docs.conda.io/en/latest/miniconda.html) for this step:\n    - To create an environment, use: `conda create -n py311-whisper python=3.11 -y`\n    - To activate the environment, use: `conda activate py311-whisper`\n\n- Generate a Core ML model. For example, to generate a `base.en` model, use:\n\n  ```bash\n  ./models/generate-coreml-model.sh base.en\n  ```\n\n  This will generate the folder `models/ggml-base.en-encoder.mlmodelc`\n\n- Build `whisper.cpp` with Core ML support:\n\n  ```bash\n  # using CMake\n  cmake -B build -DWHISPER_COREML=1\n  cmake --build build -j --config Release\n  ```\n\n- Run the examples as usual. For example:\n\n  ```text\n  $ ./build/bin/whisper-cli -m models/ggml-base.en.bin -f samples/jfk.wav\n\n  ...\n\n  whisper_init_state: loading Core ML model from 'models/ggml-base.en-encoder.mlmodelc'\n  whisper_init_state: first run on a device may take a while ...\n  whisper_init_state: Core ML model loaded\n\n  system_info: n_threads = 4 / 10 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | COREML = 1 |\n\n  ...\n  ```\n\n  The first run on a device is slow, since the ANE service compiles the Core ML model to some device-specific format.\n  Next runs are faster.\n\nFor more information about the Core ML implementation please refer to PR [#566](https://github.com/ggml-org/whisper.cpp/pull/566).\n\n## OpenVINO support\n\nOn platforms that support [OpenVINO](https://github.com/openvinotoolkit/openvino), the Encoder inference can be executed\non OpenVINO-supported devices including x86 CPUs and Intel GPUs (integrated & discrete).\n\nThis can result in significant speedup in encoder performance. Here are the instructions for generating the OpenVINO model and using it with `whisper.cpp`:\n\n- First, setup python virtual env. and install python dependencies. Python 3.10 is recommended.\n\n  Windows:\n\n  ```powershell\n  cd models\n  python -m venv openvino_conv_env\n  openvino_conv_env\\Scripts\\activate\n  python -m pip install --upgrade pip\n  pip install -r requirements-openvino.txt\n  ```\n\n  Linux and macOS:\n\n  ```bash\n  cd models\n  python3 -m venv openvino_conv_env\n  source openvino_conv_env/bin/activate\n  python -m pip install --upgrade pip\n  pip install -r requirements-openvino.txt\n  ```\n\n- Generate an OpenVINO encoder model. For example, to generate a `base.en` model, use:\n\n  ```\n  python convert-whisper-to-openvino.py --model base.en\n  ```\n\n  This will produce ggml-base.en-encoder-openvino.xml/.bin IR model files. It's recommended to relocate these to the same folder as `ggml` models, as that\n  is the default location that the OpenVINO extension will search at runtime.\n\n- Build `whisper.cpp` with OpenVINO support:\n\n  Download OpenVINO package from [release page](https://github.com/openvinotoolkit/openvino/releases). The recommended version to use is [2024.6.0](https://github.com/openvinotoolkit/openvino/releases/tag/2024.6.0). Ready to use Binaries of the required libraries can be found in the [OpenVino Archives](https://storage.openvinotoolkit.org/repositories/openvino/packages/2024.6/)\n\n  After downloading & extracting package onto your development system, set up required environment by sourcing setupvars script. For example:\n\n  Linux:\n\n  ```bash\n  source /path/to/l_openvino_toolkit_ubuntu22_2023.0.0.10926.b4452d56304_x86_64/setupvars.sh\n  ```\n\n  Windows (cmd):\n\n  ```powershell\n  C:\\Path\\To\\w_openvino_toolkit_windows_2023.0.0.10926.b4452d56304_x86_64\\setupvars.bat\n  ```\n\n  And then build the project using cmake:\n\n  ```bash\n  cmake -B build -DWHISPER_OPENVINO=1\n  cmake --build build -j --config Release\n  ```\n\n- Run the examples as usual. For example:\n\n  ```text\n  $ ./build/bin/whisper-cli -m models/ggml-base.en.bin -f samples/jfk.wav\n\n  ...\n\n  whisper_ctx_init_openvino_encoder: loading OpenVINO model from 'models/ggml-base.en-encoder-openvino.xml'\n  whisper_ctx_init_openvino_encoder: first run on a device may take a while ...\n  whisper_openvino_init: path_model = models/ggml-base.en-encoder-openvino.xml, device = GPU, cache_dir = models/ggml-base.en-encoder-openvino-cache\n  whisper_ctx_init_openvino_encoder: OpenVINO model loaded\n\n  system_info: n_threads = 4 / 8 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | COREML = 0 | OPENVINO = 1 |\n\n  ...\n  ```\n\n  The first time run on an OpenVINO device is slow, since the OpenVINO framework will compile the IR (Intermediate Representation) model to a device-specific 'blob'. This device-specific blob will get\n  cached for the next run.\n\nFor more information about the OpenVINO implementation please refer to PR [#1037](https://github.com/ggml-org/whisper.cpp/pull/1037).\n\n## NVIDIA GPU support\n\nWith NVIDIA cards the processing of the models is done efficiently on the GPU via cuBLAS and custom CUDA kernels.\nFirst, make sure you have installed `cuda`: https://developer.nvidia.com/cuda-downloads\n\nNow build `whisper.cpp` with CUDA support:\n\n```\ncmake -B build -DGGML_CUDA=1\ncmake --build build -j --config Release\n```\n\nor for newer NVIDIA GPU's (RTX 5000 series):\n```\ncmake -B build -DGGML_CUDA=1 -DCMAKE_CUDA_ARCHITECTURES=\"86\"\ncmake --build build -j --config Release\n```\n\n## Vulkan GPU support\nCross-vendor solution which allows you to accelerate workload on your GPU.\nFirst, make sure your graphics card driver provides support for Vulkan API.\n\nNow build `whisper.cpp` with Vulkan support:\n```\ncmake -B build -DGGML_VULKAN=1\ncmake --build build -j --config Release\n```\n\n## BLAS CPU support via OpenBLAS\n\nEncoder processing can be accelerated on the CPU via OpenBLAS.\nFirst, make sure you have installed `openblas`: https://www.openblas.net/\n\nNow build `whisper.cpp` with OpenBLAS support:\n\n```\ncmake -B build -DGGML_BLAS=1\ncmake --build build -j --config Release\n```\n\n## Ascend NPU support\n\nAscend NPU provides inference acceleration via [`CANN`](https://www.hiascend.com/en/software/cann) and AI cores.\n\nFirst, check if your Ascend NPU device is supported:\n\n**Verified devices**\n| Ascend NPU                    | Status  |\n|:-----------------------------:|:-------:|\n| Atlas 300T A2                 | Support |\n| Atlas 300I Duo                | Support |\n\nThen, make sure you have installed [`CANN toolkit`](https://www.hiascend.com/en/software/cann/community) . The lasted version of CANN is recommanded.\n\nNow build `whisper.cpp` with CANN support:\n\n```\ncmake -B build -DGGML_CANN=1\ncmake --build build -j --config Release\n```\n\nRun the inference examples as usual, for example:\n\n```\n./build/bin/whisper-cli -f samples/jfk.wav -m models/ggml-base.en.bin -t 8\n```\n\n*Notes:*\n\n- If you have trouble with Ascend NPU device, please create a issue with **[CANN]** prefix/tag.\n- If you run successfully with your Ascend NPU device, please help update the table `Verified devices`.\n\n## Moore Threads GPU support\n\nWith Moore Threads cards the processing of the models is done efficiently on the GPU via muBLAS and custom MUSA kernels.\nFirst, make sure you have installed `MUSA SDK rc4.2.0`: https://developer.mthreads.com/sdk/download/musa?equipment=&os=&driverVersion=&version=4.2.0\n\nNow build `whisper.cpp` with MUSA support:\n\n```\ncmake -B build -DGGML_MUSA=1\ncmake --build build -j --config Release\n```\n\nor specify the architecture for your Moore Threads GPU. For example, if you have a MTT S80 GPU, you can specify the architecture as follows:\n\n```\ncmake -B build -DGGML_MUSA=1 -DMUSA_ARCHITECTURES=\"21\"\ncmake --build build -j --config Release\n```\n\n## FFmpeg support (Linux only)\n\nIf you want to support more audio formats (such as Opus and AAC), you can turn on the `WHISPER_FFMPEG` build flag to enable FFmpeg integration.\n\nFirst, you need to install required libraries:\n\n```bash\n# Debian/Ubuntu\nsudo apt install libavcodec-dev libavformat-dev libavutil-dev\n\n# RHEL/Fedora\nsudo dnf install libavcodec-free-devel libavformat-free-devel libavutil-free-devel\n```\n\nThen you can build the project as follows:\n\n```bash\ncmake -B build -D WHISPER_FFMPEG=yes\ncmake --build build\n```\n\nRun the following example to confirm it's working:\n\n```bash\n# Convert an audio file to Opus format\nffmpeg -i samples/jfk.wav jfk.opus\n\n# Transcribe the audio file\n./build/bin/whisper-cli --model models/ggml-base.en.bin --file jfk.opus\n```\n\n## Docker\n\n### Prerequisites\n\n- Docker must be installed and running on your system.\n- Create a folder to store big models & intermediate files (ex. /whisper/models)\n\n### Images\n\nWe have two Docker images available for this project:\n\n1. `ghcr.io/ggml-org/whisper.cpp:main`: This image includes the main executable file as well as `curl` and `ffmpeg`. (platforms: `linux/amd64`, `linux/arm64`)\n2. `ghcr.io/ggml-org/whisper.cpp:main-cuda`: Same as `main` but compiled with CUDA support. (platforms: `linux/amd64`)\n3. `ghcr.io/ggml-org/whisper.cpp:main-musa`: Same as `main` but compiled with MUSA support. (platforms: `linux/amd64`)\n\n### Usage\n\n```shell\n# download model and persist it in a local folder\ndocker run -it --rm \\\n  -v path/to/models:/models \\\n  whisper.cpp:main \"./models/download-ggml-model.sh base /models\"\n# transcribe an audio file\ndocker run -it --rm \\\n  -v path/to/models:/models \\\n  -v path/to/audios:/audios \\\n  whisper.cpp:main \"whisper-cli -m /models/ggml-base.bin -f /audios/jfk.wav\"\n# transcribe an audio file in samples folder\ndocker run -it --rm \\\n  -v path/to/models:/models \\\n  whisper.cpp:main \"whisper-cli -m /models/ggml-base.bin -f ./samples/jfk.wav\"\n```\n\n## Installing with Conan\n\nYou can install pre-built binaries for whisper.cpp or build it from source using [Conan](https://conan.io/). Use the following command:\n\n```\nconan install --requires=\"whisper-cpp/[*]\" --build=missing\n```\n\nFor detailed instructions on how to use Conan, please refer to the [Conan documentation](https://docs.conan.io/2/).\n\n## Limitations\n\n- Inference only\n\n## Real-time audio input example\n\nThis is a naive example of performing real-time inference on audio from your microphone.\nThe [stream](examples/stream) tool samples the audio every half a second and runs the transcription continuously.\nMore info is available in [issue #10](https://github.com/ggml-org/whisper.cpp/issues/10).\nYou will need to have [sdl2](https://wiki.libsdl.org/SDL2/Installation) installed for it to work properly.\n\n```bash\ncmake -B build -DWHISPER_SDL2=ON\ncmake --build build -j --config Release\n./build/bin/whisper-stream -m ./models/ggml-base.en.bin -t 8 --step 500 --length 5000\n```\n\nhttps://user-images.githubusercontent.com/1991296/194935793-76afede7-cfa8-48d8-a80f-28ba83be7d09.mp4\n\n## Confidence color-coding\n\nAdding the `--print-colors` argument will print the transcribed text using an experimental color coding strategy\nto highlight words with high or low confidence:\n\n```bash\n./build/bin/whisper-cli -m models/ggml-base.en.bin -f samples/gb0.wav --print-colors\n```\n\n<img width=\"965\" alt=\"image\" src=\"https://user-images.githubusercontent.com/1991296/197356445-311c8643-9397-4e5e-b46e-0b4b4daa2530.png\">\n\n## Controlling the length of the generated text segments (experimental)\n\nFor example, to limit the line length to a maximum of 16 characters, simply add `-ml 16`:\n\n```text\n$ ./build/bin/whisper-cli -m ./models/ggml-base.en.bin -f ./samples/jfk.wav -ml 16\n\nwhisper_model_load: loading model from './models/ggml-base.en.bin'\n...\nsystem_info: n_threads = 4 / 10 | AVX2 = 0 | AVX512 = 0 | NEON = 1 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 |\n\nmain: processing './samples/jfk.wav' (176000 samples, 11.0 sec), 4 threads, 1 processors, lang = en, task = transcribe, timestamps = 1 ...\n\n[00:00:00.000 --> 00:00:00.850]   And so my\n[00:00:00.850 --> 00:00:01.590]   fellow\n[00:00:01.590 --> 00:00:04.140]   Americans, ask\n[00:00:04.140 --> 00:00:05.660]   not what your\n[00:00:05.660 --> 00:00:06.840]   country can do\n[00:00:06.840 --> 00:00:08.430]   for you, ask\n[00:00:08.430 --> 00:00:09.440]   what you can do\n[00:00:09.440 --> 00:00:10.020]   for your\n[00:00:10.020 --> 00:00:11.000]   country.\n```\n\n## Word-level timestamp (experimental)\n\nThe `--max-len` argument can be used to obtain word-level timestamps. Simply use `-ml 1`:\n\n```text\n$ ./build/bin/whisper-cli -m ./models/ggml-base.en.bin -f ./samples/jfk.wav -ml 1\n\nwhisper_model_load: loading model from './models/ggml-base.en.bin'\n...\nsystem_info: n_threads = 4 / 10 | AVX2 = 0 | AVX512 = 0 | NEON = 1 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 |\n\nmain: processing './samples/jfk.wav' (176000 samples, 11.0 sec), 4 threads, 1 processors, lang = en, task = transcribe, timestamps = 1 ...\n\n[00:00:00.000 --> 00:00:00.320]\n[00:00:00.320 --> 00:00:00.370]   And\n[00:00:00.370 --> 00:00:00.690]   so\n[00:00:00.690 --> 00:00:00.850]   my\n[00:00:00.850 --> 00:00:01.590]   fellow\n[00:00:01.590 --> 00:00:02.850]   Americans\n[00:00:02.850 --> 00:00:03.300]  ,\n[00:00:03.300 --> 00:00:04.140]   ask\n[00:00:04.140 --> 00:00:04.990]   not\n[00:00:04.990 --> 00:00:05.410]   what\n[00:00:05.410 --> 00:00:05.660]   your\n[00:00:05.660 --> 00:00:06.260]   country\n[00:00:06.260 --> 00:00:06.600]   can\n[00:00:06.600 --> 00:00:06.840]   do\n[00:00:06.840 --> 00:00:07.010]   for\n[00:00:07.010 --> 00:00:08.170]   you\n[00:00:08.170 --> 00:00:08.190]  ,\n[00:00:08.190 --> 00:00:08.430]   ask\n[00:00:08.430 --> 00:00:08.910]   what\n[00:00:08.910 --> 00:00:09.040]   you\n[00:00:09.040 --> 00:00:09.320]   can\n[00:00:09.320 --> 00:00:09.440]   do\n[00:00:09.440 --> 00:00:09.760]   for\n[00:00:09.760 --> 00:00:10.020]   your\n[00:00:10.020 --> 00:00:10.510]   country\n[00:00:10.510 --> 00:00:11.000]  .\n```\n\n## Speaker segmentation via tinydiarize (experimental)\n\nMore information about this approach is available here: https://github.com/ggml-org/whisper.cpp/pull/1058\n\nSample usage:\n\n```py\n# download a tinydiarize compatible model\n./models/download-ggml-model.sh small.en-tdrz\n\n# run as usual, adding the \"-tdrz\" command-line argument\n./build/bin/whisper-cli -f ./samples/a13.wav -m ./models/ggml-small.en-tdrz.bin -tdrz\n...\nmain: processing './samples/a13.wav' (480000 samples, 30.0 sec), 4 threads, 1 processors, lang = en, task = transcribe, tdrz = 1, timestamps = 1 ...\n...\n[00:00:00.000 --> 00:00:03.800]   Okay Houston, we've had a problem here. [SPEAKER_TURN]\n[00:00:03.800 --> 00:00:06.200]   This is Houston. Say again please. [SPEAKER_TURN]\n[00:00:06.200 --> 00:00:08.260]   Uh Houston we've had a problem.\n[00:00:08.260 --> 00:00:11.320]   We've had a main beam up on a volt. [SPEAKER_TURN]\n[00:00:11.320 --> 00:00:13.820]   Roger main beam interval. [SPEAKER_TURN]\n[00:00:13.820 --> 00:00:15.100]   Uh uh [SPEAKER_TURN]\n[00:00:15.100 --> 00:00:18.020]   So okay stand, by thirteen we're looking at it. [SPEAKER_TURN]\n[00:00:18.020 --> 00:00:25.740]   Okay uh right now uh Houston the uh voltage is uh is looking good um.\n[00:00:27.620 --> 00:00:29.940]   And we had a a pretty large bank or so.\n```\n\n## Karaoke-style movie generation (experimental)\n\nThe [whisper-cli](examples/cli) example provides support for output of karaoke-style movies, where the\ncurrently pronounced word is highlighted. Use the `-owts` argument and run the generated bash script.\nThis requires to have `ffmpeg` installed.\n\nHere are a few _\"typical\"_ examples:\n\n```bash\n./build/bin/whisper-cli -m ./models/ggml-base.en.bin -f ./samples/jfk.wav -owts\nsource ./samples/jfk.wav.wts\nffplay ./samples/jfk.wav.mp4\n```\n\nhttps://user-images.githubusercontent.com/1991296/199337465-dbee4b5e-9aeb-48a3-b1c6-323ac4db5b2c.mp4\n\n---\n\n```bash\n./build/bin/whisper-cli -m ./models/ggml-base.en.bin -f ./samples/mm0.wav -owts\nsource ./samples/mm0.wav.wts\nffplay ./samples/mm0.wav.mp4\n```\n\nhttps://user-images.githubusercontent.com/1991296/199337504-cc8fd233-0cb7-4920-95f9-4227de3570aa.mp4\n\n---\n\n```bash\n./build/bin/whisper-cli -m ./models/ggml-base.en.bin -f ./samples/gb0.wav -owts\nsource ./samples/gb0.wav.wts\nffplay ./samples/gb0.wav.mp4\n```\n\nhttps://user-images.githubusercontent.com/1991296/199337538-b7b0c7a3-2753-4a88-a0cd-f28a317987ba.mp4\n\n---\n\n## Video comparison of different models\n\nUse the [scripts/bench-wts.sh](https://github.com/ggml-org/whisper.cpp/blob/master/scripts/bench-wts.sh) script to generate a video in the following format:\n\n```bash\n./scripts/bench-wts.sh samples/jfk.wav\nffplay ./samples/jfk.wav.all.mp4\n```\n\nhttps://user-images.githubusercontent.com/1991296/223206245-2d36d903-cf8e-4f09-8c3b-eb9f9c39d6fc.mp4\n\n---\n\n## Benchmarks\n\nIn order to have an objective comparison of the performance of the inference across different system configurations,\nuse the [whisper-bench](examples/bench) tool. The tool simply runs the Encoder part of the model and prints how much time it\ntook to execute it. The results are summarized in the following Github issue:\n\n[Benchmark results](https://github.com/ggml-org/whisper.cpp/issues/89)\n\nAdditionally a script to run whisper.cpp with different models and audio files is provided [bench.py](scripts/bench.py).\n\nYou can run it with the following command, by default it will run against any standard model in the models folder.\n\n```bash\npython3 scripts/bench.py -f samples/jfk.wav -t 2,4,8 -p 1,2\n```\n\nIt is written in python with the intention of being easy to modify and extend for your benchmarking use case.\n\nIt outputs a csv file with the results of the benchmarking.\n\n## `ggml` format\n\nThe original models are converted to a custom binary format. This allows to pack everything needed into a single file:\n\n- model parameters\n- mel filters\n- vocabulary\n- weights\n\nYou can download the converted models using the [models/download-ggml-model.sh](models/download-ggml-model.sh) script\nor manually from here:\n\n- https://huggingface.co/ggerganov/whisper.cpp\n\nFor more details, see the conversion script [models/convert-pt-to-ggml.py](models/convert-pt-to-ggml.py) or [models/README.md](models/README.md).\n\n## [Bindings](https://github.com/ggml-org/whisper.cpp/discussions/categories/bindings)\n\n- [x] Rust: [tazz4843/whisper-rs](https://github.com/tazz4843/whisper-rs) | [#310](https://github.com/ggml-org/whisper.cpp/discussions/310)\n- [x] JavaScript: [bindings/javascript](bindings/javascript) | [#309](https://github.com/ggml-org/whisper.cpp/discussions/309)\n  - React Native (iOS / Android): [whisper.rn](https://github.com/mybigday/whisper.rn)\n- [x] Go: [bindings/go](bindings/go) | [#312](https://github.com/ggml-org/whisper.cpp/discussions/312)\n- [x] Java:\n  - [GiviMAD/whisper-jni](https://github.com/GiviMAD/whisper-jni)\n- [x] Ruby: [bindings/ruby](bindings/ruby) | [#507](https://github.com/ggml-org/whisper.cpp/discussions/507)\n- [x] Objective-C / Swift: [ggml-org/whisper.spm](https://github.com/ggml-org/whisper.spm) | [#313](https://github.com/ggml-org/whisper.cpp/discussions/313)\n  - [exPHAT/SwiftWhisper](https://github.com/exPHAT/SwiftWhisper)\n- [x] .NET: | [#422](https://github.com/ggml-org/whisper.cpp/discussions/422)\n  - [sandrohanea/whisper.net](https://github.com/sandrohanea/whisper.net)\n  - [NickDarvey/whisper](https://github.com/NickDarvey/whisper)\n- [x] Python: | [#9](https://github.com/ggml-org/whisper.cpp/issues/9)\n  - [stlukey/whispercpp.py](https://github.com/stlukey/whispercpp.py) (Cython)\n  - [AIWintermuteAI/whispercpp](https://github.com/AIWintermuteAI/whispercpp) (Updated fork of aarnphm/whispercpp)\n  - [aarnphm/whispercpp](https://github.com/aarnphm/whispercpp) (Pybind11)\n  - [abdeladim-s/pywhispercpp](https://github.com/abdeladim-s/pywhispercpp) (Pybind11)\n- [x] R: [bnosac/audio.whisper](https://github.com/bnosac/audio.whisper)\n- [x] Unity: [macoron/whisper.unity](https://github.com/Macoron/whisper.unity)\n\n## XCFramework\nThe XCFramework is a precompiled version of the library for iOS, visionOS, tvOS,\nand macOS. It can be used in Swift projects without the need to compile the\nlibrary from source. For example, the v1.7.5 version of the XCFramework can be\nused as follows:\n\n```swift\n// swift-tools-version: 5.10\n// The swift-tools-version declares the minimum version of Swift required to build this package.\n\nimport PackageDescription\n\nlet package = Package(\n    name: \"Whisper\",\n    targets: [\n        .executableTarget(\n            name: \"Whisper\",\n            dependencies: [\n                \"WhisperFramework\"\n            ]),\n        .binaryTarget(\n            name: \"WhisperFramework\",\n            url: \"https://github.com/ggml-org/whisper.cpp/releases/download/v1.7.5/whisper-v1.7.5-xcframework.zip\",\n            checksum: \"c7faeb328620d6012e130f3d705c51a6ea6c995605f2df50f6e1ad68c59c6c4a\"\n        )\n    ]\n)\n```\n\n## Voice Activity Detection (VAD)\nSupport for Voice Activity Detection (VAD) can be enabled using the `--vad`\nargument to `whisper-cli`. In addition to this option a VAD model is also\nrequired.\n\nThe way this works is that first the audio samples are passed through\nthe VAD model which will detect speech segments. Using this information the\nonly the speech segments that are detected are extracted from the original audio\ninput and passed to whisper for processing. This reduces the amount of audio\ndata that needs to be processed by whisper and can significantly speed up the\ntranscription process.\n\nThe following VAD models are currently supported:\n\n### Silero-VAD\n[Silero-vad](https://github.com/snakers4/silero-vad) is a lightweight VAD model\nwritten in Python that is fast and accurate.\n\nModels can be downloaded by running the following command on Linux or MacOS:\n```console\n$ ./models/download-vad-model.sh silero-v6.2.0\nDownloading ggml model silero-v6.2.0 from 'https://huggingface.co/ggml-org/whisper-vad' ...\nggml-silero-v6.2.0.bin        100%[==============================================>] 864.35K  --.-KB/s    in 0.04s\nDone! Model 'silero-v6.2.0' saved in '/path/models/ggml-silero-v6.2.0.bin'\nYou can now use it like this:\n\n  $ ./build/bin/whisper-cli -vm /path/models/ggml-silero-v6.2.0.bin --vad -f samples/jfk.wav -m models/ggml-base.en.bin\n\n```\nAnd the following command on Windows:\n```console\n> .\\models\\download-vad-model.cmd silero-v6.2.0\nDownloading vad model silero-v6.2.0...\nDone! Model silero-v6.2.0 saved in C:\\Users\\danie\\work\\ai\\whisper.cpp\\ggml-silero-v6.2.0.bin\nYou can now use it like this:\n\nC:\\path\\build\\bin\\Release\\whisper-cli.exe -vm C:\\path\\ggml-silero-v6.2.0.bin --vad -m models/ggml-base.en.bin -f samples\\jfk.wav\n\n```\n\nTo see a list of all available models, run the above commands without any\narguments.\n\nThis model can be also be converted manually to ggml using the following command:\n```console\n$ python3 -m venv venv && source venv/bin/activate\n$ (venv) pip install silero-vad\n$ (venv) $ python models/convert-silero-vad-to-ggml.py --output models/silero.bin\nSaving GGML Silero-VAD model to models/silero-v6.2.0-ggml.bin\n```\nAnd it can then be used with whisper as follows:\n```console\n$ ./build/bin/whisper-cli \\\n   --file ./samples/jfk.wav \\\n   --model ./models/ggml-base.en.bin \\\n   --vad \\\n   --vad-model ./models/silero-v6.2.0-ggml.bin\n```\n\n### VAD Options\n\n* --vad-threshold: Threshold probability for speech detection. A probability\nfor a speech segment/frame above this threshold will be considered as speech.\n\n* --vad-min-speech-duration-ms: Minimum speech duration in milliseconds. Speech\nsegments shorter than this value will be discarded to filter out brief noise or\nfalse positives.\n\n* --vad-min-silence-duration-ms: Minimum silence duration in milliseconds. Silence\nperiods must be at least this long to end a speech segment. Shorter silence\nperiods will be ignored and included as part of the speech.\n\n* --vad-max-speech-duration-s: Maximum speech duration in seconds. Speech segments\nlonger than this will be automatically split into multiple segments at silence\npoints exceeding 98ms to prevent excessively long segments.\n\n* --vad-speech-pad-ms: Speech padding in milliseconds. Adds this amount of padding\nbefore and after each detected speech segment to avoid cutting off speech edges.\n\n* --vad-samples-overlap: Amount of audio to extend from each speech segment into\nthe next one, in seconds (e.g., 0.10 = 100ms overlap). This ensures speech isn't\ncut off abruptly between segments when they're concatenated together.\n\n## Examples\n\nThere are various examples of using the library for different projects in the [examples](examples) folder.\nSome of the examples are even ported to run in the browser using WebAssembly. Check them out!\n\n| Example                                             | Web                                   | Description                                                                                                                     |\n| --------------------------------------------------- | ------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |\n| [whisper-cli](examples/cli)                         | [whisper.wasm](examples/whisper.wasm) | Tool for translating and transcribing audio using Whisper                                                                       |\n| [whisper-bench](examples/bench)                     | [bench.wasm](examples/bench.wasm)     | Benchmark the performance of Whisper on your machine                                                                            |\n| [whisper-stream](examples/stream)                   | [stream.wasm](examples/stream.wasm)   | Real-time transcription of raw microphone capture                                                                               |\n| [whisper-command](examples/command)                 | [command.wasm](examples/command.wasm) | Basic voice assistant example for receiving voice commands from the mic                                                         |\n| [whisper-server](examples/server)                   |                                       | HTTP transcription server with OAI-like API                                                                                     |\n| [whisper-talk-llama](examples/talk-llama)           |                                       | Talk with a LLaMA bot                                                                                                           |\n| [whisper.objc](examples/whisper.objc)               |                                       | iOS mobile application using whisper.cpp                                                                                        |\n| [whisper.swiftui](examples/whisper.swiftui)         |                                       | SwiftUI iOS / macOS application using whisper.cpp                                                                               |\n| [whisper.android](examples/whisper.android)         |                                       | Android mobile application using whisper.cpp                                                                                    |\n| [whisper.nvim](examples/whisper.nvim)               |                                       | Speech-to-text plugin for Neovim                                                                                                |\n| [generate-karaoke.sh](examples/generate-karaoke.sh) |                                       | Helper script to easily [generate a karaoke video](https://youtu.be/uj7hVta4blM) of raw audio capture                           |\n| [livestream.sh](examples/livestream.sh)             |                                       | [Livestream audio transcription](https://github.com/ggml-org/whisper.cpp/issues/185)                                            |\n| [yt-wsp.sh](examples/yt-wsp.sh)                     |                                       | Download + transcribe and/or translate any VOD [(original)](https://gist.github.com/DaniruKun/96f763ec1a037cc92fe1a059b643b818) |\n| [wchess](examples/wchess)                           | [wchess.wasm](examples/wchess)        | Voice-controlled chess                                                                                                          |\n\n## [Discussions](https://github.com/ggml-org/whisper.cpp/discussions)\n\nIf you have any kind of feedback about this project feel free to use the Discussions section and open a new topic.\nYou can use the [Show and tell](https://github.com/ggml-org/whisper.cpp/discussions/categories/show-and-tell) category\nto share your own projects that use `whisper.cpp`. If you have a question, make sure to check the\n[Frequently asked questions (#126)](https://github.com/ggml-org/whisper.cpp/discussions/126) discussion.\n",
      "stars_today": 60
    },
    {
      "id": 1013830656,
      "name": "bitchat",
      "full_name": "permissionlesstech/bitchat",
      "description": "bluetooth mesh chat, IRC vibes",
      "html_url": "https://github.com/permissionlesstech/bitchat",
      "stars": 24068,
      "forks": 2256,
      "language": "Swift",
      "topics": [],
      "created_at": "2025-07-04T14:34:38Z",
      "updated_at": "2026-01-17T00:38:55Z",
      "pushed_at": "2026-01-16T18:42:12Z",
      "open_issues": 217,
      "owner": {
        "login": "permissionlesstech",
        "avatar_url": "https://avatars.githubusercontent.com/u/220183803?v=4"
      },
      "readme": "<img width=\"256\" height=\"256\" alt=\"icon_128x128@2x\" src=\"https://github.com/user-attachments/assets/90133f83-b4f6-41c6-aab9-25d0859d2a47\" />\n\n## bitchat\n\nA decentralized peer-to-peer messaging app with dual transport architecture: local Bluetooth mesh networks for offline communication and internet-based Nostr protocol for global reach. No accounts, no phone numbers, no central servers. It's the side-groupchat.\n\n[bitchat.free](http://bitchat.free)\n\nüì≤ [App Store](https://apps.apple.com/us/app/bitchat-mesh/id6748219622)\n\n## License\n\nThis project is released into the public domain. See the [LICENSE](LICENSE) file for details.\n\n## Features\n\n- **Dual Transport Architecture**: Bluetooth mesh for offline + Nostr protocol for internet-based messaging\n- **Location-Based Channels**: Geographic chat rooms using geohash coordinates over global Nostr relays\n- **Intelligent Message Routing**: Automatically chooses best transport (Bluetooth ‚Üí Nostr fallback)\n- **Decentralized Mesh Network**: Automatic peer discovery and multi-hop message relay over Bluetooth LE\n- **Privacy First**: No accounts, no phone numbers, no persistent identifiers\n- **Private Message End-to-End Encryption**: [Noise Protocol](https://noiseprotocol.org) for mesh, NIP-17 for Nostr\n- **IRC-Style Commands**: Familiar `/slap`, `/msg`, `/who` style interface\n- **Universal App**: Native support for iOS and macOS\n- **Emergency Wipe**: Triple-tap to instantly clear all data\n- **Performance Optimizations**: LZ4 message compression, adaptive battery modes, and optimized networking\n\n## [Technical Architecture](https://deepwiki.com/permissionlesstech/bitchat)\n\nBitChat uses a **hybrid messaging architecture** with two complementary transport layers:\n\n### Bluetooth Mesh Network (Offline)\n\n- **Local Communication**: Direct peer-to-peer within Bluetooth range\n- **Multi-hop Relay**: Messages route through nearby devices (max 7 hops)\n- **No Internet Required**: Works completely offline in disaster scenarios\n- **Noise Protocol Encryption**: End-to-end encryption with forward secrecy\n- **Binary Protocol**: Compact packet format optimized for Bluetooth LE constraints\n- **Automatic Discovery**: Peer discovery and connection management\n- **Adaptive Power**: Battery-optimized duty cycling\n\n### Nostr Protocol (Internet)\n\n- **Global Reach**: Connect with users worldwide via internet relays\n- **Location Channels**: Geographic chat rooms using geohash coordinates\n- **290+ Relay Network**: Distributed across the globe for reliability\n- **NIP-17 Encryption**: Gift-wrapped private messages for internet privacy\n- **Ephemeral Keys**: Fresh cryptographic identity per geohash area\n\n### Channel Types\n\n#### `mesh #bluetooth`\n\n- **Transport**: Bluetooth Low Energy mesh network\n- **Scope**: Local devices within multi-hop range\n- **Internet**: Not required\n- **Use Case**: Offline communication, protests, disasters, remote areas\n\n#### Location Channels (`block #dr5rsj7`, `neighborhood #dr5rs`, `country #dr`)\n\n- **Transport**: Nostr protocol over internet\n- **Scope**: Geographic areas defined by geohash precision\n  - `block` (7 chars): City block level\n  - `neighborhood` (6 chars): District/neighborhood\n  - `city` (5 chars): City level\n  - `province` (4 chars): State/province\n  - `region` (2 chars): Country/large region\n- **Internet**: Required (connects to Nostr relays)\n- **Use Case**: Location-based community chat, local events, regional discussions\n\n### Direct Message Routing\n\nPrivate messages use **intelligent transport selection**:\n\n1. **Bluetooth First** (preferred when available)\n\n   - Direct connection with established Noise session\n   - Fastest and most private option\n\n2. **Nostr Fallback** (when Bluetooth unavailable)\n\n   - Uses recipient's Nostr public key\n   - NIP-17 gift-wrapping for privacy\n   - Routes through global relay network\n\n3. **Smart Queuing** (when neither available)\n   - Messages queued until transport becomes available\n   - Automatic delivery when connection established\n\nFor detailed protocol documentation, see the [Technical Whitepaper](WHITEPAPER.md).\n\n## Setup\n\n### Option 1: Using Xcode\n\n   ```bash\n   cd bitchat\n   open bitchat.xcodeproj\n   ```\n\n   To run on a device there're a few steps to prepare the code:\n   - Clone the local configs: `cp Configs/Local.xcconfig.example Configs/Local.xcconfig`\n   - Add your Developer Team ID into the newly created `Configs/Local.xcconfig`\n      - Bundle ID would be set to `chat.bitchat.<team_id>` (unless you set to something else)\n   - Entitlements need to be updated manually (TODO: Automate):\n      - Search and replace `group.chat.bitchat` with `group.<your_bundle_id>` (e.g. `group.chat.bitchat.ABC123`)\n\n### Option 2: Using `just`\n\n   ```bash\n   brew install just\n   ```\n\nWant to try this on macos: `just run` will set it up and run from source.\nRun `just clean` afterwards to restore things to original state for mobile app building and development.\n\n## Localization\n\n- Base app resources live under `bitchat/Localization/Base.lproj/`. Add new copy to `Localizable.strings` and plural rules to `Localizable.stringsdict`.\n- Share extension strings are separate in `bitchatShareExtension/Localization/Base.lproj/Localizable.strings`.\n- Prefer keys that describe intent (`app_info.features.offline.title`) and reuse existing ones where possible.\n- Run `xcodebuild -project bitchat.xcodeproj -scheme \"bitchat (macOS)\" -configuration Debug CODE_SIGNING_ALLOWED=NO build` to compile-check any localization updates.\n",
      "stars_today": 59
    },
    {
      "id": 868811259,
      "name": "prek",
      "full_name": "j178/prek",
      "description": "‚ö° Better `pre-commit`, re-engineered in Rust",
      "html_url": "https://github.com/j178/prek",
      "stars": 3570,
      "forks": 106,
      "language": "Rust",
      "topics": [
        "git",
        "git-hooks",
        "pre-commit"
      ],
      "created_at": "2024-10-07T08:21:29Z",
      "updated_at": "2026-01-17T00:22:12Z",
      "pushed_at": "2026-01-16T13:14:40Z",
      "open_issues": 70,
      "owner": {
        "login": "j178",
        "avatar_url": "https://avatars.githubusercontent.com/u/10510431?v=4"
      },
      "readme": "<div align=\"center\">\n\n<h1>\n  <img width=\"180\" alt=\"prek\" src=\"https://raw.githubusercontent.com/j178/prek/master/docs/assets/logo.webp\" />\n  <br/>prek\n</h1>\n\n[![prek](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/j178/prek/master/docs/assets/badge-v0.json)](https://github.com/j178/prek)\n[![codecov](https://codecov.io/github/j178/prek/graph/badge.svg?token=MP6TY24F43)](https://codecov.io/github/j178/prek)\n[![GitHub Downloads](https://img.shields.io/github/downloads/j178/prek/total?logo=github)](https://github.com/j178/prek/releases)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/prek?logo=python)](https://pepy.tech/projects/prek)\n[![Discord](https://img.shields.io/discord/1403581202102878289?logo=discord)](https://discord.gg/3NRJUqJz86)\n\n</div>\n\n<!-- description:start -->\n[pre-commit](https://pre-commit.com/) is a framework to run hooks written in many languages, and it manages the\nlanguage toolchain and dependencies for running the hooks.\n\n*prek* is a reimagined version of pre-commit, built in Rust.\nIt is designed to be a faster, dependency-free and drop-in alternative for it,\nwhile also providing some additional long-requested features.\n<!-- description:end -->\n\n> [!NOTE]\n> Although prek is pretty new, it‚Äôs already powering real‚Äëworld projects like [Apache Airflow](https://github.com/apache/airflow), [FastAPI](https://github.com/fastapi/fastapi), and more projects are picking it up‚Äîsee [Who is using prek?](#who-is-using-prek). If you‚Äôre looking for an alternative to `pre-commit`, please give it a try‚Äîwe‚Äôd love your feedback!\n>\n> Please note that some subcommands and languages are still missing for full drop‚Äëin parity with `pre-commit`. Track the remaining gaps here: [TODO](https://prek.j178.dev/todo/).\n\n<!-- features:start -->\n## Features\n\n- üöÄ A single binary with no dependencies, does not require Python or any other runtime.\n- ‚ö° [Faster](https://prek.j178.dev/benchmark/) than `pre-commit` and more efficient in disk space usage.\n- üîÑ Fully compatible with the original pre-commit configurations and hooks.\n- üèóÔ∏è Built-in support for monorepos (i.e. [workspace mode](https://prek.j178.dev/workspace/)).\n- üêç Integration with [`uv`](https://github.com/astral-sh/uv) for managing Python virtual environments and dependencies.\n- üõ†Ô∏è Improved toolchain installations for Python, Node.js, Go, Rust and Ruby, shared between hooks.\n- üì¶ [Built-in](https://prek.j178.dev/builtin/) Rust-native implementation of some common hooks.\n<!-- features:end -->\n\n## Table of contents\n\n- [Installation](#installation)\n- [Quick start](#quick-start)\n- [Why prek?](#why-prek)\n- [Who is using prek?](#who-is-using-prek)\n- [Acknowledgements](#acknowledgements)\n\n## Installation\n\n<details>\n<summary>Standalone installer</summary>\n\nprek provides a standalone installer script to download and install the tool,\n\nOn Linux and macOS:\n\n<!-- linux-standalone-install:start -->\n```bash\ncurl --proto '=https' --tlsv1.2 -LsSf https://github.com/j178/prek/releases/download/v0.2.29/prek-installer.sh | sh\n```\n<!-- linux-standalone-install:end -->\n\nOn Windows:\n\n<!-- windows-standalone-install:start -->\n```powershell\npowershell -ExecutionPolicy ByPass -c \"irm https://github.com/j178/prek/releases/download/v0.2.29/prek-installer.ps1 | iex\"\n```\n<!-- windows-standalone-install:end -->\n\n</details>\n\n<details>\n<summary>PyPI</summary>\n\n<!-- pypi-install:start -->\nprek is published as Python binary wheel to PyPI, you can install it using `pip`, `uv` (recommended), or `pipx`:\n\n```bash\n# Using uv (recommended)\nuv tool install prek\n\n# Using uvx (install and run in one command)\nuvx prek\n\n# Adding prek to the project dev-dependencies\nuv add --dev prek\n\n# Using pip\npip install prek\n\n# Using pipx\npipx install prek\n```\n<!-- pypi-install:end -->\n\n</details>\n\n<details>\n<summary>Homebrew</summary>\n\n<!-- homebrew-install:start -->\n```bash\nbrew install prek\n```\n<!-- homebrew-install:end -->\n\n</details>\n\n<details>\n<summary>mise</summary>\n\n<!-- mise-install:start -->\nTo use prek with [mise](https://mise.jdx.dev) ([v2025.8.11](https://github.com/jdx/mise/releases/tag/v2025.8.11) or later):\n\n```bash\nmise use prek\n```\n<!-- mise-install:end -->\n\n</details>\n\n<details>\n<summary>Cargo binstall</summary>\n\n<!-- cargo-binstall:start -->\nInstall pre-compiled binaries from GitHub using [cargo-binstall](https://github.com/cargo-bins/cargo-binstall):\n\n```bash\ncargo binstall prek\n```\n<!-- cargo-binstall:end -->\n\n</details>\n\n<details>\n<summary>Cargo</summary>\n\n<!-- cargo-install:start -->\nBuild from source using Cargo (Rust 1.89+ is required):\n\n```bash\ncargo install --locked prek\n```\n<!-- cargo-install:end -->\n\n</details>\n\n<details>\n<summary>npmjs</summary>\n\n<!-- npmjs-install:start -->\nprek is published as a Node.js package, you can install it using `npm`, `pnpm`, or `npx`:\n\n```bash\n# Using npm\nnpm add -D @j178/prek\n\n# Using pnpm\npnpm add -D @j178/prek\n\n# Using npx\nnpx @j178/prek --version\n\n# or install globally\nnpm install -g @j178/prek\n\n# then use `prek` command\nprek --version\n```\n<!-- npmjs-install:end -->\n\n</details>\n\n<details>\n<summary>Nix</summary>\n\n<!-- nix-install:start -->\nprek is available via [Nixpkgs](https://search.nixos.org/packages?channel=unstable&show=prek&query=prek).\n\n```shell\n# Choose what's appropriate for your use case.\n# One-off in a shell:\nnix-shell -p prek\n\n# NixOS or non-NixOS without flakes:\nnix-env -iA nixos.prek\n\n# Non-NixOS with flakes:\nnix profile install nixpkgs#prek\n```\n<!-- nix-install:end -->\n\n</details>\n\n<details>\n<summary>Conda</summary>\n\n<!-- conda-forge-install:start -->\nprek is available as `prek` via [conda-forge](https://anaconda.org/conda-forge/prek).\n\n```shell\nconda install conda-forge::prek\n```\n<!-- conda-forge-install:end -->\n\n</details>\n\n<details>\n<summary>Scoop (Windows)</summary>\n\n<!-- scoop-install:start -->\nprek is available via [Scoop](https://scoop.sh/#/apps?q=prek).\n\n```powershell\nscoop install main/prek\n```\n<!-- scoop-install:end -->\n</details>\n\n<details>\n<summary>MacPorts</summary>\n\n<!-- macports-install:start -->\nprek is available via [MacPorts](https://ports.macports.org/port/prek/).\n\n```bash\nsudo port install prek\n```\n<!-- macports-install:end -->\n</details>\n\n<details>\n<summary>GitHub Releases</summary>\n\n<!-- pre-built-binaries:start -->\nPre-built binaries are available for download from the [GitHub releases](https://github.com/j178/prek/releases) page.\n<!-- pre-built-binaries:end -->\n\n</details>\n\n<details>\n<summary>GitHub Actions</summary>\n\n<!-- github-actions:start -->\nprek can be used in GitHub Actions via the [j178/prek-action](https://github.com/j178/prek-action) repository.\n\nExample workflow:\n\n```yaml\nname: Prek checks\non: [push, pull_request]\n\njobs:\n  prek:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v6\n      - uses: j178/prek-action@v1\n```\n\nThis action installs prek and runs `prek run --all-files` on your repository.\n\nprek is also available via [`taiki-e/install-action`](https://github.com/taiki-e/install-action) for installing various tools.\n<!-- github-actions:end -->\n</details>\n\n<!-- self-update:start -->\nIf installed via the standalone installer, prek can update itself to the latest version:\n\n```bash\nprek self update\n```\n<!-- self-update:end -->\n\n## Quick start\n\n- **I already use pre-commit:** follow the short migration checklist in the [quickstart guide](https://prek.j178.dev/quickstart/#already-using-pre-commit) to swap in `prek` safely.\n- **I'm new to pre-commit-style tools:** learn the basics‚Äîcreating a config, running hooks, and installing git hooks‚Äîin the [beginner quickstart walkthrough](https://prek.j178.dev/quickstart/#new-to-pre-commit-style-workflows).\n\n<!-- why:start -->\n## Why prek?\n\n### prek is faster\n\n- It is [multiple times faster](https://prek.j178.dev/benchmark/) than `pre-commit` and takes up half the disk space.\n- It redesigned how hook environments and toolchains are managed, they are all shared between hooks, which reduces the disk space usage and speeds up the installation process.\n- Repositories are cloned in parallel, and hooks are installed in parallel if their dependencies are disjoint.\n- Hooks can run in parallel by priority (hooks with the same [`priority`](https://prek.j178.dev/configuration/#priority) may run concurrently), reducing end-to-end runtime.\n- It uses [`uv`](https://github.com/astral-sh/uv) for creating Python virtualenvs and installing dependencies, which is known for its speed and efficiency.\n- It implements some common hooks in Rust, [built in prek](https://prek.j178.dev/builtin/), which are faster than their Python counterparts.\n- It supports `repo: builtin` for offline, zero-setup hooks, which is not available in `pre-commit`.\n\n### prek provides a better user experience\n\n- No need to install Python or any other runtime, just download a single binary.\n- No hassle with your Python version or virtual environments, prek automatically installs the required Python version and creates a virtual environment for you.\n- Built-in support for [workspaces](https://prek.j178.dev/workspace/) (or monorepos), each subproject can have its own `.pre-commit-config.yaml` file.\n- [`prek run`](https://prek.j178.dev/cli/#prek-run) has some nifty improvements over `pre-commit run`, such as:\n  - `prek run --directory <dir>` runs hooks for files in the specified directory, no need to use `git ls-files -- <dir> | xargs pre-commit run --files` anymore.\n  - `prek run --last-commit` runs hooks for files changed in the last commit.\n  - `prek run [HOOK] [HOOK]` selects and runs multiple hooks.\n- [`prek list`](https://prek.j178.dev/cli/#prek-list) command lists all available hooks, their ids, and descriptions, providing a better overview of the configured hooks.\n- [`prek auto-update`](https://prek.j178.dev/cli/#prek-auto-update) supports `--cooldown-days` to mitigate open source supply chain attacks.\n- prek provides shell completions for `prek run <hook_id>` command, making it easier to run specific hooks without remembering their ids.\n\nFor more detailed improvements prek offers, take a look at [Difference from pre-commit](https://prek.j178.dev/diff/).\n\n## Who is using prek?\n\nprek is pretty new, but it is already being used or recommend by some projects and organizations:\n\n- [apache/airflow](https://github.com/apache/airflow/issues/44995)\n- [python/cpython](https://github.com/python/cpython/issues/143148)\n- [pdm-project/pdm](https://github.com/pdm-project/pdm/pull/3593)\n- [fastapi/fastapi](https://github.com/fastapi/fastapi/pull/14572)\n- [fastapi/typer](https://github.com/fastapi/typer/pull/1453)\n- [fastapi/asyncer](https://github.com/fastapi/asyncer/pull/437)\n- [astral-sh/ruff](https://github.com/astral-sh/ruff/pull/22505)\n- [astral-sh/ty](https://github.com/astral-sh/ty/pull/2469)\n- [home-assistant/core](https://github.com/home-assistant/core/pull/160427)\n- [DetachHead/basedpyright](https://github.com/DetachHead/basedpyright/pull/1413)\n- [OpenLineage/OpenLineage](https://github.com/OpenLineage/OpenLineage/pull/3965)\n- [authlib/authlib](https://github.com/authlib/authlib/pull/804)\n- [django/djangoproject.com](https://github.com/django/djangoproject.com/pull/2252)\n- [Future-House/paper-qa](https://github.com/Future-House/paper-qa/pull/1098)\n- [requests-cache/requests-cache](https://github.com/requests-cache/requests-cache/pull/1116)\n- [Goldziher/kreuzberg](https://github.com/Goldziher/kreuzberg/pull/142)\n- [python-attrs/attrs](https://github.com/python-attrs/attrs/commit/c95b177682e76a63478d29d040f9cb36a8d31915)\n- [jlowin/fastmcp](https://github.com/jlowin/fastmcp/pull/2309)\n- [apache/iceberg-python](https://github.com/apache/iceberg-python/pull/2533)\n- [jcrist/msgspec](https://github.com/jcrist/msgspec/pull/918)\n- [python-humanize/humanize](https://github.com/python-humanize/humanize/pull/276)\n- [MoonshotAI/kimi-cli](https://github.com/MoonshotAI/kimi-cli/pull/535)\n- [ZhuoZhuoCrayon/throttled-py](https://github.com/ZhuoZhuoCrayon/throttled-py/pull/119)\n\n<!-- why:end -->\n\n## Acknowledgements\n\nThis project is heavily inspired by the original [pre-commit](https://pre-commit.com/) tool, and it wouldn't be possible without the hard work\nof the maintainers and contributors of that project.\n\nAnd a special thanks to the [Astral](https://github.com/astral-sh) team for their remarkable projects, particularly [uv](https://github.com/astral-sh/uv),\nfrom which I've learned a lot on how to write efficient and idiomatic Rust code.\n",
      "stars_today": 59
    },
    {
      "id": 836976013,
      "name": "clash-party",
      "full_name": "mihomo-party-org/clash-party",
      "description": ":electron: Another Mihomo GUI. ",
      "html_url": "https://github.com/mihomo-party-org/clash-party",
      "stars": 19990,
      "forks": 1621,
      "language": "TypeScript",
      "topics": [
        "clash",
        "clash-meta",
        "electron",
        "mihomo"
      ],
      "created_at": "2024-08-02T00:38:23Z",
      "updated_at": "2026-01-16T21:06:41Z",
      "pushed_at": "2026-01-15T16:47:33Z",
      "open_issues": 250,
      "owner": {
        "login": "mihomo-party-org",
        "avatar_url": "https://avatars.githubusercontent.com/u/181477152?v=4"
      },
      "readme": "<h3 align=\"center\">\n  <img height='48px' src='./images/icon-white.png#gh-dark-mode-only'>\n  <img height='48px' src='./images/icon-black.png#gh-light-mode-only'>\n</h3>\n\n<h3 align=\"center\">Another <a href=\"https://github.com/MetaCubeX/mihomo\">Mihomo</a> GUI</h3>\n\n<p align=\"center\">\n  <a href=\"https://github.com/mihomo-party-org/clash-party/releases\">\n    <img src=\"https://img.shields.io/github/release/mihomo-party-org/clash-party/all.svg\">\n  </a>\n  <a href=\"https://t.me/mihomo_party_group\">\n    <img src=\"https://img.shields.io/badge/Telegram-Group-blue?logo=telegram\">\n  </a>\n</p>\n<div align='center'>\n<img width='90%' src=\"./images/preview.jpg\">\n</div>\n\n### Êú¨È°πÁõÆËÆ§ËØÅÁ®≥ÂÆöÊú∫Âú∫Êé®ËçêÔºö‚Äú[ÁãóÁãóÂä†ÈÄü](https://party.dginv.click/#/register?code=ARdo0mXx)‚Äù\n\n##### [ÁãóÁãóÂä†ÈÄü ‚Äî‚Äî ÊäÄÊúØÊµÅÊú∫Âú∫ Doggygo VPN](https://party.dginv.click/#/register?code=ARdo0mXx)\n\n- È´òÊÄßËÉΩÊµ∑Â§ñÊú∫Âú∫ÔºåÁ®≥ÂÆöÈ¶ñÈÄâÔºåÊµ∑Â§ñÂõ¢ÈòüÔºåÊó†Ë∑ëË∑ØÈ£éÈô©\n- Clash Party‰∏ìÂ±û8Êäò‰ºòÊÉ†Á†ÅÔºöpartyÔºå‰ªÖÊúâ500‰ªΩ\n- Party‰∏ìÂ±ûÈìæÊé•Ê≥®ÂÜåÈÄÅ 3 Â§©ÔºåÊØèÂ§© 1G ÊµÅÈáè [ÂÖçË¥πËØïÁî®](https://party.dginv.click/#/register?code=ARdo0mXx)\n- ‰ºòÊÉ†Â•óÈ§êÊØèÊúà‰ªÖÈúÄ 15.8 ÂÖÉÔºå160G ÊµÅÈáèÔºåÂπ¥‰ªò 8 Êäò\n- ÂÖ®ÁêÉÈ¶ñÂÆ∂ÊîØÊåÅHysteria1/2 ÂçèËÆÆÔºåÈõÜÁæ§Ë¥üËΩΩÂùáË°°ËÆæËÆ°ÔºåÈ´òÈÄü‰∏ìÁ∫øÔºåÂü∫‰∫éÊúÄÊñ∞UDP quicÊäÄÊúØÔºåÊûÅ‰ΩéÂª∂ËøüÔºåÊó†ËßÜÊôöÈ´òÂ≥∞Ôºå4K ÁßíÂºÄÔºåÈÖçÂêàClash PartyÈ£üÁî®Êõ¥ÁúÅÂøÉÔºÅ\n- Ëß£ÈîÅÊµÅÂ™í‰ΩìÂèä ChatGPT\n- ÂÆòÁΩëÔºö[https://ÁãóÁãóÂä†ÈÄü.com](https://party.dginv.click/#/register?code=ARdo0mXx)\n\n### ÁâπÊÄß\n\n- [x] ‰∏ÄÈîÆ Smart Core ËßÑÂàôË¶ÜÂÜôÔºåÂü∫‰∫é AI Ê®°ÂûãËá™Âä®ÈÄâÊã©ÊúÄ‰ºòËäÇÁÇπ ËØ¶ÁªÜ‰ªãÁªçËØ∑Áúã [ËøôÈáå](https://clashparty.org/docs/guide/smart-core)\n- [x] ÂºÄÁÆ±Âç≥Áî®ÔºåÊó†ÈúÄÊúçÂä°Ê®°ÂºèÁöÑ Tun\n- [x] Â§öÁßçÈÖçËâ≤‰∏ªÈ¢òÂèØÈÄâÔºåUI ÁÑïÁÑ∂‰∏ÄÊñ∞\n- [x] ÊîØÊåÅÂ§ßÈÉ®ÂàÜ Mihomo(Clash Meta) Â∏∏Áî®ÈÖçÁΩÆ‰øÆÊîπ\n- [x] ÂÜÖÁΩÆ SmartÂÜÖÊ†∏ ‰∏é Mihomo(Clash Meta) ÂÜÖÊ†∏\n- [x] ÈÄöËøá WebDAV ‰∏ÄÈîÆÂ§á‰ªΩÂíåÊÅ¢Â§çÈÖçÁΩÆ\n- [x] Âº∫Â§ßÁöÑË¶ÜÂÜôÂäüËÉΩÔºå‰ªªÊÑè‰øÆËÆ¢ÈÖçÁΩÆÊñá‰ª∂\n- [x] Ê∑±Â∫¶ÈõÜÊàê Sub-StoreÔºåËΩªÊùæÁÆ°ÁêÜËÆ¢ÈòÖ\n\n### ÂÆâË£Ö/‰ΩøÁî®ÊåáÂçóËßÅ [ÂÆòÊñπÊñáÊ°£](https://clashparty.org)\n",
      "stars_today": 54
    },
    {
      "id": 187961907,
      "name": "legado",
      "full_name": "gedoor/legado",
      "description": "Legado 3.0 Book Reader with powerful controls & full functions‚ù§Ô∏èÈòÖËØª3.0, ÈòÖËØªÊòØ‰∏ÄÊ¨æÂèØ‰ª•Ëá™ÂÆö‰πâÊù•Ê∫êÈòÖËØªÁΩëÁªúÂÜÖÂÆπÁöÑÂ∑•ÂÖ∑Ôºå‰∏∫ÂπøÂ§ßÁΩëÁªúÊñáÂ≠¶Áà±Â•ΩËÄÖÊèê‰æõ‰∏ÄÁßçÊñπ‰æø„ÄÅÂø´Êç∑ËàíÈÄÇÁöÑËØïËØª‰ΩìÈ™å„ÄÇ",
      "html_url": "https://github.com/gedoor/legado",
      "stars": 43284,
      "forks": 4850,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2019-05-22T04:18:58Z",
      "updated_at": "2026-01-17T00:24:11Z",
      "pushed_at": "2026-01-16T07:15:24Z",
      "open_issues": 81,
      "owner": {
        "login": "gedoor",
        "avatar_url": "https://avatars.githubusercontent.com/u/22701807?v=4"
      },
      "readme": "# [English](English.md) [‰∏≠Êñá](README.md)\n\n[![icon_android](https://github.com/gedoor/gedoor.github.io/blob/master/static/img/legado/icon_android.png)](https://play.google.com/store/apps/details?id=io.legado.play.release)\n<a href=\"https://jb.gg/OpenSourceSupport\" target=\"_blank\">\n<img width=\"24\" height=\"24\" src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jb_beam.svg?_gl=1*135yekd*_ga*OTY4Mjg4NDYzLjE2Mzk0NTE3MzQ.*_ga_9J976DJZ68*MTY2OTE2MzM5Ny4xMy4wLjE2NjkxNjMzOTcuNjAuMC4w&_ga=2.257292110.451256242.1669085120-968288463.1639451734\" alt=\"idea\"/>\n</a>\n\n<div align=\"center\">\n<img width=\"125\" height=\"125\" src=\"https://github.com/gedoor/legado/raw/master/app/src/main/res/mipmap-xxxhdpi/ic_launcher.png\" alt=\"legado\"/>  \n  \nLegado / ÂºÄÊ∫êÈòÖËØª\n<br>\n<a href=\"https://gedoor.github.io\" target=\"_blank\">gedoor.github.io</a> / <a href=\"https://www.legado.top/\" target=\"_blank\">legado.top</a>\n<br>\nLegado is a free and open source novel reader for Android.\n</div>\n\n[![](https://img.shields.io/badge/-Contents:-696969.svg)](#contents) [![](https://img.shields.io/badge/-Function-F5F5F5.svg)](#Function-‰∏ªË¶ÅÂäüËÉΩ-) [![](https://img.shields.io/badge/-Community-F5F5F5.svg)](#Community-‰∫§ÊµÅÁ§æÂå∫-) [![](https://img.shields.io/badge/-API-F5F5F5.svg)](#API-) [![](https://img.shields.io/badge/-Other-F5F5F5.svg)](#Other-ÂÖ∂‰ªñ-) [![](https://img.shields.io/badge/-Grateful-F5F5F5.svg)](#Grateful-ÊÑüË∞¢-) [![](https://img.shields.io/badge/-Interface-F5F5F5.svg)](#Interface-ÁïåÈù¢-)\n\n>Êñ∞Áî®Êà∑Ôºü\n>\n>ËΩØ‰ª∂‰∏çÊèê‰æõÂÜÖÂÆπÔºåÈúÄË¶ÅÊÇ®Ëá™Â∑±ÊâãÂä®Ê∑ªÂä†Ôºå‰æãÂ¶ÇÂØºÂÖ•‰π¶Ê∫êÁ≠â„ÄÇ\n>ÁúãÁúã [ÂÆòÊñπÂ∏ÆÂä©ÊñáÊ°£](https://www.yuque.com/legado/wiki)Ôºå‰πüËÆ∏ÈáåÈù¢Â∞±Êúâ‰Ω†Ë¶ÅÁöÑÁ≠îÊ°à„ÄÇ\n\n# Function-‰∏ªË¶ÅÂäüËÉΩ [![](https://img.shields.io/badge/-Function-F5F5F5.svg)](#Function-‰∏ªË¶ÅÂäüËÉΩ-)\n[English](English.md)\n\n<details><summary>‰∏≠Êñá</summary>\n1.Ëá™ÂÆö‰πâ‰π¶Ê∫êÔºåËá™Â∑±ËÆæÁΩÆËßÑÂàôÔºåÊäìÂèñÁΩëÈ°µÊï∞ÊçÆÔºåËßÑÂàôÁÆÄÂçïÊòìÊáÇÔºåËΩØ‰ª∂ÂÜÖÊúâËßÑÂàôËØ¥Êòé„ÄÇ<br>\n2.ÂàóË°®‰π¶Êû∂ÔºåÁΩëÊ†º‰π¶Êû∂Ëá™Áî±ÂàáÊç¢„ÄÇ<br>\n3.‰π¶Ê∫êËßÑÂàôÊîØÊåÅÊêúÁ¥¢ÂèäÂèëÁé∞ÔºåÊâÄÊúâÊâæ‰π¶Áúã‰π¶ÂäüËÉΩÂÖ®ÈÉ®Ëá™ÂÆö‰πâÔºåÊâæ‰π¶Êõ¥Êñπ‰æø„ÄÇ<br>\n4.ËÆ¢ÈòÖÂÜÖÂÆπ,ÂèØ‰ª•ËÆ¢ÈòÖÊÉ≥ÁúãÁöÑ‰ªª‰ΩïÂÜÖÂÆπ,Áúã‰Ω†ÊÉ≥Áúã<br>\n5.ÊîØÊåÅÊõøÊç¢ÂáÄÂåñÔºåÂéªÈô§ÂπøÂëäÊõøÊç¢ÂÜÖÂÆπÂæàÊñπ‰æø„ÄÇ<br>\n6.ÊîØÊåÅÊú¨Âú∞TXT„ÄÅEPUBÈòÖËØªÔºåÊâãÂä®ÊµèËßàÔºåÊô∫ËÉΩÊâ´Êèè„ÄÇ<br>\n7.ÊîØÊåÅÈ´òÂ∫¶Ëá™ÂÆö‰πâÈòÖËØªÁïåÈù¢ÔºåÂàáÊç¢Â≠ó‰Ωì„ÄÅÈ¢úËâ≤„ÄÅËÉåÊôØ„ÄÅË°åË∑ù„ÄÅÊÆµË∑ù„ÄÅÂä†Á≤ó„ÄÅÁÆÄÁπÅËΩ¨Êç¢Á≠â„ÄÇ<br>\n8.ÊîØÊåÅÂ§öÁßçÁøªÈ°µÊ®°ÂºèÔºåË¶ÜÁõñ„ÄÅ‰ªøÁúü„ÄÅÊªëÂä®„ÄÅÊªöÂä®Á≠â„ÄÇ<br>\n9.ËΩØ‰ª∂ÂºÄÊ∫êÔºåÊåÅÁª≠‰ºòÂåñÔºåÊó†ÂπøÂëä„ÄÇ\n</details>\n\n<a href=\"#readme\">\n    <img src=\"https://img.shields.io/badge/-ËøîÂõûÈ°∂ÈÉ®-orange.svg\" alt=\"#\" align=\"right\">\n</a>\n\n# Community-‰∫§ÊµÅÁ§æÂå∫ [![](https://img.shields.io/badge/-Community-F5F5F5.svg)](#Community-‰∫§ÊµÅÁ§æÂå∫-)\n\n#### Telegram\n[![Telegram-group](https://img.shields.io/badge/Telegram-%E7%BE%A4%E7%BB%84-blue)](https://t.me/yueduguanfang) [![Telegram-channel](https://img.shields.io/badge/Telegram-%E9%A2%91%E9%81%93-blue)](https://t.me/legado_channels)\n\n#### Discord\n[![Discord](https://img.shields.io/discord/560731361414086666?color=%235865f2&label=Discord)](https://discord.gg/VtUfRyzRXn)\n\n#### Other\nhttps://www.yuque.com/legado/wiki/community\n\n<a href=\"#readme\">\n    <img src=\"https://img.shields.io/badge/-ËøîÂõûÈ°∂ÈÉ®-orange.svg\" alt=\"#\" align=\"right\">\n</a>\n\n# API [![](https://img.shields.io/badge/-API-F5F5F5.svg)](#API-)\n* ÈòÖËØª3.0 Êèê‰æõ‰∫Ü2ÁßçÊñπÂºèÁöÑAPIÔºö`WebÊñπÂºè`Âíå`Content ProviderÊñπÂºè`„ÄÇÊÇ®ÂèØ‰ª•Âú®[ËøôÈáå](api.md)Ê†πÊçÆÈúÄË¶ÅËá™Ë°åË∞ÉÁî®„ÄÇ \n* ÂèØÈÄöËøáurlÂî§Ëµ∑ÈòÖËØªËøõË°å‰∏ÄÈîÆÂØºÂÖ•,urlÊ†ºÂºè: legado://import/{path}?src={url}\n* pathÁ±ªÂûã: bookSource,rssSource,replaceRule,textTocRule,httpTTS,theme,readConfig,dictRule,[addToBookshelf](/app/src/main/java/io/legado/app/ui/association/AddToBookshelfDialog.kt)\n* pathÁ±ªÂûãËß£Èáä: ‰π¶Ê∫ê,ËÆ¢ÈòÖÊ∫ê,ÊõøÊç¢ËßÑÂàô,Êú¨Âú∞txtÂ∞èËØ¥ÁõÆÂΩïËßÑÂàô,Âú®Á∫øÊúóËØªÂºïÊìé,‰∏ªÈ¢ò,ÈòÖËØªÊéíÁâà,Ê∑ªÂä†Âà∞‰π¶Êû∂\n\n<a href=\"#readme\">\n    <img src=\"https://img.shields.io/badge/-ËøîÂõûÈ°∂ÈÉ®-orange.svg\" alt=\"#\" align=\"right\">\n</a>\n\n# Other-ÂÖ∂‰ªñ [![](https://img.shields.io/badge/-Other-F5F5F5.svg)](#Other-ÂÖ∂‰ªñ-)\n##### ÂÖçË¥£Â£∞Êòé\nhttps://gedoor.github.io/Disclaimer\n\n##### ÈòÖËØª3.0\n* [‰π¶Ê∫êËßÑÂàô](https://mgz0227.github.io/The-tutorial-of-Legado/)\n* [Êõ¥Êñ∞Êó•Âøó](/app/src/main/assets/updateLog.md)\n* [Â∏ÆÂä©ÊñáÊ°£](/app/src/main/assets/web/help/md/appHelp.md)\n* [webÁ´Ø‰π¶Êû∂](https://github.com/gedoor/legado_web_bookshelf)\n* [webÁ´ØÊ∫êÁºñËæë](https://github.com/gedoor/legado_web_source_editor)\n\n<a href=\"#readme\">\n    <img src=\"https://img.shields.io/badge/-ËøîÂõûÈ°∂ÈÉ®-orange.svg\" alt=\"#\" align=\"right\">\n</a>\n\n# Grateful-ÊÑüË∞¢ [![](https://img.shields.io/badge/-Grateful-F5F5F5.svg)](#Grateful-ÊÑüË∞¢-)\n> * org.jsoup:jsoup\n> * cn.wanghaomiao:JsoupXpath\n> * com.jayway.jsonpath:json-path\n> * com.github.gedoor:rhino-android\n> * com.squareup.okhttp3:okhttp\n> * com.github.bumptech.glide:glide\n> * org.nanohttpd:nanohttpd\n> * org.nanohttpd:nanohttpd-websocket\n> * cn.bingoogolapple:bga-qrcode-zxing\n> * com.jaredrummler:colorpicker\n> * org.apache.commons:commons-text\n> * io.noties.markwon:core\n> * io.noties.markwon:image-glide\n> * com.hankcs:hanlp\n> * com.positiondev.epublib:epublib-core\n<a href=\"#readme\">\n    <img src=\"https://img.shields.io/badge/-ËøîÂõûÈ°∂ÈÉ®-orange.svg\" alt=\"#\" align=\"right\">\n</a>\n\n# Interface-ÁïåÈù¢ [![](https://img.shields.io/badge/-Interface-F5F5F5.svg)](#Interface-ÁïåÈù¢-)\n<img src=\"https://github.com/gedoor/gedoor.github.io/blob/master/static/img/legado/%E9%98%85%E8%AF%BB%E7%AE%80%E4%BB%8B1.jpg\" width=\"270\"><img src=\"https://github.com/gedoor/gedoor.github.io/blob/master/static/img/legado/%E9%98%85%E8%AF%BB%E7%AE%80%E4%BB%8B2.jpg\" width=\"270\"><img src=\"https://github.com/gedoor/gedoor.github.io/blob/master/static/img/legado/%E9%98%85%E8%AF%BB%E7%AE%80%E4%BB%8B3.jpg\" width=\"270\">\n<img src=\"https://github.com/gedoor/gedoor.github.io/blob/master/static/img/legado/%E9%98%85%E8%AF%BB%E7%AE%80%E4%BB%8B4.jpg\" width=\"270\"><img src=\"https://github.com/gedoor/gedoor.github.io/blob/master/static/img/legado/%E9%98%85%E8%AF%BB%E7%AE%80%E4%BB%8B5.jpg\" width=\"270\"><img src=\"https://github.com/gedoor/gedoor.github.io/blob/master/static/img/legado/%E9%98%85%E8%AF%BB%E7%AE%80%E4%BB%8B6.jpg\" width=\"270\">\n\n<a href=\"#readme\">\n    <img src=\"https://img.shields.io/badge/-ËøîÂõûÈ°∂ÈÉ®-orange.svg\" alt=\"#\" align=\"right\">\n</a>\n",
      "stars_today": 46
    },
    {
      "id": 904534974,
      "name": "go-stock",
      "full_name": "ArvinLovegood/go-stock",
      "description": "ü¶Ñü¶Ñü¶ÑAIËµãËÉΩËÇ°Á•®ÂàÜÊûêÔºöAIÂä†ÊåÅÁöÑËÇ°Á•®ÂàÜÊûê/ÈÄâËÇ°Â∑•ÂÖ∑„ÄÇËÇ°Á•®Ë°åÊÉÖËé∑ÂèñÔºåAIÁÉ≠ÁÇπËµÑËÆØÂàÜÊûêÔºåAIËµÑÈáë/Ë¥¢Âä°ÂàÜÊûêÔºåÊ∂®Ë∑åÊä•Ë≠¶Êé®ÈÄÅ„ÄÇÊîØÊåÅAËÇ°ÔºåÊ∏ØËÇ°ÔºåÁæéËÇ°„ÄÇÊîØÊåÅÂ∏ÇÂú∫Êï¥‰Ωì/‰∏™ËÇ°ÊÉÖÁª™ÂàÜÊûêÔºåAIËæÖÂä©ÈÄâËÇ°Á≠â„ÄÇÊï∞ÊçÆÂÖ®ÈÉ®‰øùÁïôÂú®Êú¨Âú∞„ÄÇÊîØÊåÅDeepSeekÔºåOpenAIÔºå OllamaÔºåLMStudioÔºåAnythingLLMÔºåÁ°ÖÂü∫ÊµÅÂä®ÔºåÁÅ´Â±±ÊñπËàüÔºåÈòøÈáå‰∫ëÁôæÁÇºÁ≠âÂπ≥Âè∞ÊàñÊ®°Âûã„ÄÇ",
      "html_url": "https://github.com/ArvinLovegood/go-stock",
      "stars": 3860,
      "forks": 630,
      "language": "Go",
      "topics": [
        "anythingllm",
        "deepseek",
        "golang",
        "lmstudio",
        "naiveui",
        "ollama",
        "openai",
        "stock",
        "wails"
      ],
      "created_at": "2024-12-17T04:46:28Z",
      "updated_at": "2026-01-17T00:15:59Z",
      "pushed_at": "2026-01-16T11:33:10Z",
      "open_issues": 20,
      "owner": {
        "login": "ArvinLovegood",
        "avatar_url": "https://avatars.githubusercontent.com/u/7401917?v=4"
      },
      "readme": "# go-stock : Âü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑAIËµãËÉΩËÇ°Á•®ÂàÜÊûêÂ∑•ÂÖ∑\n## ![go-stock](./build/appicon.png)\n![GitHub Release](https://img.shields.io/github/v/release/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases&link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases)\n[![GitHub Repo stars](https://img.shields.io/github/stars/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock)](https://github.com/ArvinLovegood/go-stock)\n[![star](https://gitee.com/arvinlovegood_admin/go-stock/badge/star.svg?theme=dark)](https://gitee.com/arvinlovegood_admin/go-stock)\n\n[//]: # ([![star]&#40;https://gitcode.com/ArvinLovegood/go-stock/star/badge.svg&#41;]&#40;https://gitcode.com/ArvinLovegood/go-stock&#41;)\n\n### üåüÂÖ¨‰ºóÂè∑\n![Êâ´Á†Å_ÊêúÁ¥¢ËÅîÂêà‰º†Êí≠Ê†∑Âºè-ÁôΩËâ≤Áâà.png](build/screenshot/%E6%89%AB%E7%A0%81_%E6%90%9C%E7%B4%A2%E8%81%94%E5%90%88%E4%BC%A0%E6%92%AD%E6%A0%B7%E5%BC%8F-%E7%99%BD%E8%89%B2%E7%89%88.png)\n\n### üìà ‰∫§ÊµÅÁæ§\n\n[//]: # (- QQ‰∫§ÊµÅÁæ§2Ôºö[ÁÇπÂáªÈìæÊé•Âä†ÂÖ•Áæ§ËÅä„Äêgo-stock‰∫§ÊµÅÁæ§2„ÄëÔºö892666282]&#40;https://qm.qq.com/q/5mYiy6Yxh0&#41;)\n- QQ‰∫§ÊµÅÁæ§Ôºö[ÁÇπÂáªÈìæÊé•Âä†ÂÖ•Áæ§ËÅä„Äêgo-stock‰∫§ÊµÅÁæ§„ÄëÔºö491605333(ÂÆöÊúüÊ∏ÖÁêÜÔºåÈöèÁºòÂÖ•Áæ§)](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=0YQ8qD3exahsD4YLNhzQTWe5ssstWC89&authKey=usOMMRFtIQDC%2FYcatHYapcxQbJ7PwXPHK9OypTXWzNjAq%2FRVvQu9bj2lRgb%2BSZ3p&noverify=0&group_code=491605333)\n\n###  ‚ú® ÁÆÄ‰ªã\n- Êú¨È°πÁõÆÂü∫‰∫éWailsÂíåNaiveUIÂºÄÂèëÔºåÁªìÂêàAIÂ§ßÊ®°ÂûãÊûÑÂª∫ÁöÑËÇ°Á•®ÂàÜÊûêÂ∑•ÂÖ∑„ÄÇ\n- ÁõÆÂâçÂ∑≤ÊîØÊåÅAËÇ°ÔºåÊ∏ØËÇ°ÔºåÁæéËÇ°ÔºåÊú™Êù•ËÆ°ÂàíÂä†ÂÖ•Âü∫ÈáëÔºåETFÁ≠âÊîØÊåÅ„ÄÇ\n- ÊîØÊåÅÂ∏ÇÂú∫Êï¥‰Ωì/‰∏™ËÇ°ÊÉÖÁª™ÂàÜÊûêÔºåKÁ∫øÊäÄÊúØÊåáÊ†áÂàÜÊûêÁ≠âÂäüËÉΩ„ÄÇ\n- Êú¨È°πÁõÆ‰ªÖ‰æõÂ®±‰πêÔºå‰∏çÂñúÂãøÂñ∑ÔºåAIÂàÜÊûêËÇ°Á•®ÁªìÊûú‰ªÖ‰æõÂ≠¶‰π†Á†îÁ©∂ÔºåÊäïËµÑÊúâÈ£éÈô©ÔºåËØ∑Ë∞®ÊÖé‰ΩøÁî®„ÄÇ\n- ÂºÄÂèëÁéØÂ¢É‰∏ªË¶ÅÂü∫‰∫éWindows10+ÔºåÂÖ∂‰ªñÂπ≥Âè∞Êú™ÊµãËØïÊàñÂäüËÉΩÂèóÈôê„ÄÇ\n\n### üì¶ Á´ãÂç≥‰ΩìÈ™å\n[//]: # (- ÂÆâË£ÖÁâàÔºö[go-stock-amd64-installer.exe]&#40;https://github.com/ArvinLovegood/go-stock/releases&#41;)\n- ÁªøËâ≤ÁâàÔºö[go-stock-windows-amd64.exe](https://github.com/ArvinLovegood/go-stock/releases)\n- MACOSÁªøËâ≤ÁâàÔºö[go-stock-darwin-universal](https://github.com/ArvinLovegood/go-stock/releases)\n\n[//]: # (- MACOSÂÆâË£ÖÁâàÔºö[go-stock-darwin-universal.pkg]&#40;https://github.com/ArvinLovegood/go-stock/releases&#41;)\n\n\n### üí¨ ÊîØÊåÅÂ§ßÊ®°Âûã/Âπ≥Âè∞\n| Ê®°Âûã | Áä∂ÊÄÅ | Â§áÊ≥®                                                                                                                                                                                                                                                                |\n| --- | --- |-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [OpenAI](https://platform.openai.com/) | ‚úÖ | ÂèØÊé•ÂÖ•‰ªª‰Ωï OpenAI Êé•Âè£Ê†ºÂºèÊ®°Âûã                                                                                                                                                                                                                                               |\n| [Ollama](https://ollama.com/) | ‚úÖ | Êú¨Âú∞Â§ßÊ®°ÂûãËøêË°åÂπ≥Âè∞                                                                                                                                                                                                                                                         |\n| [LMStudio](https://lmstudio.ai/) | ‚úÖ | Êú¨Âú∞Â§ßÊ®°ÂûãËøêË°åÂπ≥Âè∞                                                                                                                                                                                                                                                         |\n| [AnythingLLM](https://anythingllm.com/) | ‚úÖ | Êú¨Âú∞Áü•ËØÜÂ∫ì                                                                                                                                                                                                                                                             |\n| [DeepSeek](https://www.deepseek.com/) | ‚úÖ | deepseek-reasoner,deepseek-chat                                                                                                                                                                                                                                   |\n| [Â§ßÊ®°ÂûãËÅöÂêàÂπ≥Âè∞](https://cloud.siliconflow.cn/i/foufCerk) | ‚úÖ | Â¶ÇÔºö[Á°ÖÂü∫ÊµÅÂä®](https://cloud.siliconflow.cn/i/foufCerk)Ôºå[ÁÅ´Â±±ÊñπËàü](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&ac=DSASUQY5&rc=IJSE43PZ) |\n\n### <span style=\"color: #568DF4;\">ÂêÑ‰Ωç‰∫≤Áà±ÁöÑÊúãÂèã‰ª¨ÔºåÂ¶ÇÊûúÊÇ®ÂØπËøô‰∏™È°πÁõÆÊÑüÂÖ¥Ë∂£ÔºåËØ∑ÂÖàÁªôÊàë‰∏Ä‰∏™<i style=\"color: #EA2626;\">star</i>ÂêßÔºåË∞¢Ë∞¢ÔºÅ</span>üíï\n[//]: # (- ‰ºò‰∫ëÊô∫ÁÆóÔºàby UCloudÔºâÔºö‰∏áÂç°ËßÑÊ®°4090ÂÖçË¥πÁî®10Â∞èÊó∂ÔºåÊñ∞‰∫∫Ê≥®ÂÜåÂè¶Â¢û50‰∏átokensÔºåÊµ∑ÈáèÁÉ≠Èó®Ê∫êÈ°πÁõÆÈïúÂÉè‰∏ÄÈîÆÈÉ®ÁΩ≤Ôºå[Ê≥®ÂÜåÈìæÊé•]&#40;https://www.compshare.cn/image-community?ytag=GPU_YY-gh_gostock&#41;)\n- ÁÅ´Â±±ÊñπËàüÔºöÊñ∞Áî®Êà∑ÊØè‰∏™Ê®°ÂûãÊ≥®ÂÜåÂç≥ÈÄÅ50‰∏átokensÔºå[Ê≥®ÂÜåÈìæÊé•](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&ac=DSASUQY5&rc=IJSE43PZ)\n- Á°ÖÂü∫ÊµÅÂä®(siliconflow)ÔºåÊ≥®ÂÜåÂç≥ÈÄÅ2000‰∏áTokensÔºå[Ê≥®ÂÜåÈìæÊé•](https://cloud.siliconflow.cn/i/foufCerk)\n- TushareÂ§ßÊï∞ÊçÆÂºÄÊîæÁ§æÂå∫,ÂÖçË¥πÊèê‰æõÂêÑÁ±ªÈáëËûçÊï∞ÊçÆ,Âä©ÂäõË°å‰∏öÂíåÈáèÂåñÁ†îÁ©∂(Ê≥®ÊÑèÔºöTushareÂè™ÈúÄË¶Å120ÁßØÂàÜÂç≥ÂèØÔºåÊ≥®ÂÜåÂÆåÊàê‰∏™‰∫∫ËµÑÊñôË°•ÂÖÖÂç≥ÂèØÂæó120ÁßØÂàÜÔºÅÔºÅÔºÅ)Ôºå[Ê≥®ÂÜåÈìæÊé•](https://tushare.pro/register?reg=701944)\n- ËΩØ‰ª∂Âø´ÈÄüËø≠‰ª£ÂºÄÂèë‰∏≠,ËØ∑Â§ßÂÆ∂‰ºòÂÖàÊµãËØïÂíå‰ΩøÁî®ÊúÄÊñ∞ÂèëÂ∏ÉÁöÑÁâàÊú¨„ÄÇ\n- Ê¨¢ËøéÂ§ßÂÆ∂ÊèêÂá∫ÂÆùË¥µÁöÑÂª∫ËÆÆÔºåÊ¨¢ËøéÊèêissue,PR„ÄÇÂΩìÁÑ∂Êõ¥Ê¨¢Ëøé[ËµûÂä©Êàë](#ÈÉΩÂàíÂà∞Ëøô‰∫ÜÂ¶ÇÊûúÊàëÁöÑÈ°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ËØ∑ËµûÂä©ÊàëÂêß)„ÄÇüíï\n\n\n### ÊîØÊåÅÂºÄÊ∫êüíïËÆ°Âàí\n| ËµûÂä©ËÆ°Âàí\t                           | ËµûÂä©Á≠âÁ∫ß\t          | ÊùÉÁõäËØ¥Êòé                                                   |\n|:--------------------------------|----------------|:-------------------------------------------------------|\n| ÊØèÊúà 0 RMB\t                       | vip0\t          | üåü ÂÖ®ÈÉ®ÂäüËÉΩ,ËΩØ‰ª∂Ëá™Âä®Êõ¥Êñ∞(‰ªéGitHub‰∏ãËΩΩ),Ëá™Ë°åËß£ÂÜ≥githubÂπ≥Âè∞ÁΩëÁªúÈóÆÈ¢ò„ÄÇ            |\n| ÊØèÊúàËµûÂä© 18.8 RMB<br>ÊØèÂπ¥ËµûÂä© 120 RMB\t\t | vip1\t          | üíï ÂÖ®ÈÉ®ÂäüËÉΩ,ËΩØ‰ª∂Ëá™Âä®Êõ¥Êñ∞(‰ªéCDN‰∏ãËΩΩ),Êõ¥Êñ∞Âø´ÈÄü‰æøÊç∑„ÄÇAIÈÖçÁΩÆÊåáÂØºÔºåÊèêÁ§∫ËØçÂèÇËÄÉÁ≠â            |\n| ÊØèÊúàËµûÂä© 28.8 RMB<br>ÊØèÂπ¥ËµûÂä© 240 RMB\t\t | vip2\t          | üíï üíï vip1ÂÖ®ÈÉ®ÂäüËÉΩ,Ëµ†ÈÄÅÁ°ÖÂü∫ÊµÅÂä®AIÂàÜÊûêÊúçÂä°,ÂêØÂä®Êó∂Ëá™Âä®ÂêåÊ≠•ÊúÄËøë24Â∞èÊó∂Â∏ÇÂú∫ËµÑËÆØ(ÂåÖÊã¨Â§ñÂ™íÁÆÄËÆØ)  |\n| ÊØèÊúàËµûÂä© X RMB\t\t\t                   | vipX\t          | üß© Êõ¥Â§öËÆ°ÂàíÔºåËßÜgo-stockÂºÄÊ∫êÈ°πÁõÆÂèëÂ±ïÊÉÖÂÜµËÄåÂÆö...(ÊâøÊé•GitHubÈ°πÁõÆREADMEÂπøÂëäÊé®Âπøüíñ) |\n\n## üß© ÈáçÂ§ßÂäüËÉΩÂºÄÂèëËÆ°Âàí\n| ÂäüËÉΩËØ¥Êòé            | Áä∂ÊÄÅ | Â§áÊ≥®                                                                                                       |\n|-----------------|----|----------------------------------------------------------------------------------------------------------|\n| ËÇ°Á•®ÂàÜÊûêÁü•ËØÜÂ∫ì         | üöß | Êú™Êù•ËÆ°Âàí                                                                                                     |\n| AiÊô∫ËÉΩÈÄâËÇ°          | ‚úÖ | AiÊô∫ËÉΩÈÄâËÇ°ÂäüËÉΩ(Â∏ÇÂú∫Ë°åÊÉÖ-„ÄãAIÊÄªÁªì/AIÊô∫ËÉΩ‰ΩìÂäüËÉΩ)                                                                             |\n| ETFÊîØÊåÅ           | üöß | ETFÊï∞ÊçÆÊîØÊåÅ (ÁõÆÂâçÂèØ‰ª•Êü•ÁúãÂáÄÂÄºÂíå‰º∞ÂÄº)                                                                                    |\n| ÁæéËÇ°ÊîØÊåÅ            | ‚úÖ  | ÁæéËÇ°Êï∞ÊçÆÊîØÊåÅ                                                                                                   |\n| Ê∏ØËÇ°ÊîØÊåÅ            | ‚úÖ  | Ê∏ØËÇ°Êï∞ÊçÆÊîØÊåÅ                                                                                                   |\n| Â§öËΩÆÂØπËØù            | ‚úÖ  | AIÂàÜÊûêÂêéÂèØÁªßÁª≠ÂØπËØùÊèêÈóÆ                                                                                             |\n| Ëá™ÂÆö‰πâAIÂàÜÊûêÊèêÈóÆÊ®°Êùø     | ‚úÖ  | ÂèØÈÖçÁΩÆÁöÑÊèêÈóÆÊ®°Êùø [v2025.2.12.7-alpha](https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha) |\n| ‰∏çÂÜçÂº∫Âà∂‰æùËµñChromeÊµèËßàÂô® | ‚úÖ  | ÈªòËÆ§‰ΩøÁî®edgeÊµèËßàÂô®ÊäìÂèñÊñ∞ÈóªËµÑËÆØ                                                                                        |\n\n## üëÄ Êõ¥Êñ∞Êó•Âøó\n### 2025.12.16 Êñ∞Â¢ûAIÊÄùËÄÉÊ®°Âºè‰∏éÁÉ≠Èó®ÈÄâËÇ°Á≠ñÁï•ÂäüËÉΩ\n### 2025.11.21 Êñ∞Â¢ûÂ∏¶È¢ëÁéáÊùÉÈáçÁöÑÊÉÖÊÑüÂàÜÊûêÂäüËÉΩ\n### 2025.10.30 Ê∑ªÂä†AIÊô∫ËÉΩ‰ΩìÂäüËÉΩÂºÄÂÖ≥(ÈªòËÆ§ÂÖ≥Èó≠ÔºåÂõ†‰∏∫‰ΩøÁî®‰ΩìÈ™å‰∏çÁêÜÊÉ≥)ÔºåÁßªÈô§È°µÈù¢Ê∞¥Âç∞\n### 2025.09.27 Ê∑ªÂä†Êú∫ÊûÑ/Âà∏ÂïÜÁöÑÁ†îÁ©∂Êä•ÂëäAIÂ∑•ÂÖ∑ÂáΩÊï∞\n### 2025.08.09 Ê∑ªÂä†AIÊô∫ËÉΩ‰ΩìËÅäÂ§©ÂäüËÉΩ\n### 2025.07.08 ÂÆûÁé∞ËΩØ‰ª∂Ëá™Âä®Êõ¥Êñ∞ÂäüËÉΩ\n### 2025.07.07 Âç°ÁâáÊ∑ªÂä†Ëø∑‰Ω†ÂàÜÊó∂Âõæ\n### 2025.07.05 MacOsÊîØÊåÅ\n### 2025.07.01 AIÂàÜÊûêÈõÜÊàêÂ∑•ÂÖ∑ÂáΩÊï∞ÔºåAIÂàÜÊûêÂ∞ÜÊõ¥Âä†Êô∫ËÉΩ\n### 2025.06.30 Ê∑ªÂä†ÊåáÊ†áÈÄâËÇ°ÂäüËÉΩ\n### 2025.06.27 Ê∑ªÂä†Ë¥¢ÁªèÊó•ÂéÜÂíåÈáçÂ§ß‰∫ã‰ª∂Êó∂Èó¥ËΩ¥ÂäüËÉΩ\n### 2025.06.25 Ê∑ªÂä†ÁÉ≠Èó®ËÇ°Á•®„ÄÅ‰∫ã‰ª∂ÂíåËØùÈ¢òÂäüËÉΩ\n### 2025.06.18 Êõ¥Êñ∞ÂÜÖÁΩÆËÇ°Á•®Âü∫Á°ÄÊï∞ÊçÆ,ËΩØ‰ª∂ÂÜÖÂÆûÊó∂Â∏ÇÂú∫ËµÑËÆØ‰ø°ÊÅØÊèêÈÜíÔºåÊ∑ªÂä†Ë°å‰∏öÁ†îÁ©∂ÂäüËÉΩ\n### 2025.06.15 Ê∑ªÂä†ÂÖ¨Âè∏ÂÖ¨Âëä‰ø°ÊÅØÊêúÁ¥¢/Êü•ÁúãÂäüËÉΩ\n### 2025.06.15 Ê∑ªÂä†‰∏™ËÇ°Á†îÊä•Âà∞ÂºπÂá∫ËèúÂçï\n### 2025.06.13 Ê∑ªÂä†‰∏™ËÇ°Á†îÊä•ÂäüËÉΩ\n### 2025.06.12 Ê∑ªÂä†ÈæôËôéÊ¶úÂäüËÉΩÔºåÊñ∞Â¢ûË°å‰∏öÊéíÂêçÂàÜÁ±ª\n### 2025.05.30 ‰ºòÂåñËÇ°Á•®ÂàÜÊó∂ÂõæÊòæÁ§∫\n### 2025.05.20 ‰øÆÂ§çË¥¢ËÅîÁ§æÁîµÊä•Ëé∑ÂèñÈóÆÈ¢ò\n### 2025.05.16 ‰ºòÂåñËµÑÈáëË∂ãÂäøÂõæË°®ÁªÑ‰ª∂\n### 2025.05.15 ÈáçÊûÑÂ∫îÁî®Âä†ËΩΩÂíåÊï∞ÊçÆÂàùÂßãÂåñÈÄªËæëÔºåÊ∑ªÂä†ËÇ°Á•®ËµÑÈáëË∂ãÂäøÂäüËÉΩÔºåËµÑÈáëË∂ãÂäøÂõæË°®Â¢ûÂä†‰∏ªÂäõÂΩìÊó•ÂáÄÊµÅÂÖ•Êï∞ÊçÆÂπ∂‰ºòÂåñÂ±ïÁ§∫ÊïàÊûú\n### 2025.05.14 Ê∑ªÂä†‰∏™ËÇ°ËµÑÈáëÊµÅÂêëÂäüËÉΩÔºåÊéíË°åÊ¶úÂ¢ûÂä†ËÇ°Á•®Ë°åÊÉÖKÁ∫øÂõæÂºπÁ™ó\n### 2025.05.13 Ê∑ªÂä†Ë°å‰∏öÊéíÂêçÂäüËÉΩ\n### 2025.05.09 Ê∑ªÂä†AËÇ°ÁõòÂè£Êï∞ÊçÆËß£ÊûêÂíåÂ±ïÁ§∫ÂäüËÉΩ\n### 2025.05.07 ‰ºòÂåñÂàÜÊó∂ÂõæÁöÑÂ±ïÁ§∫\n### 2025.04.29 Ë°•ÂÖ®Ê∏ØËÇ°/ÁæéËÇ°Âü∫Á°ÄÊï∞ÊçÆÔºå‰ºòÂåñÊ∏ØËÇ°ËÇ°‰ª∑Âª∂ËøüÈóÆÈ¢òÔºå‰ºòÂåñÂàùÂßãÂåñÈÄªËæë\n### 2025.04.25 Â∏ÇÂú∫ËµÑËÆØÊîØÊåÅAIÂàÜÊûêÂíåÊÄªÁªìÔºöËÆ©AIÂ∏Æ‰Ω†ËØªÂ∏ÇÂú∫ÔºÅ\n### 2025.04.24 Êñ∞Â¢ûÂ∏ÇÂú∫Ë°åÊÉÖÊ®°ÂùóÔºöÂç≥Êó∂ÊéåÊè°ÂÖ®ÁêÉÂ∏ÇÂú∫Ë°åÊÉÖËµÑËÆØ/Âä®ÊÄÅÔºå‰ªéÊ≠§ÂÜç‰πü‰∏çÁî®ÂÅ∑Êë∏ÂéªÂêÑÂ§ßË¥¢ÁªèÁΩëÁ´ôÂï¶„ÄÇgo-stock‰∏ÄÈîÆÂ∏Æ‰Ω†ÊêûÂÆöÔºÅ\n### 2025.04.22 ‰ºòÂåñKÁ∫øÂõæÂ±ïÁ§∫ÔºåÊîØÊåÅÊãâ‰º∏ÊîæÂ§ßÔºåÁúãÂæóÊõ¥ËàíÊúçÂï¶ÔºÅ\n### 2025.04.21 Ê∏ØËÇ°ÔºåÁæéËÇ°KÁ∫øÊï∞ÊçÆËé∑Âèñ‰ºòÂåñ\n### 2025.04.01 ‰ºòÂåñÈÉ®ÂàÜËÆæÁΩÆÈÄâÈ°πÔºåÈÅøÂÖçÈáçÂêØËΩØ‰ª∂\n### 2025.03.31 ‰ºòÂåñÊï∞ÊçÆÁà¨Âèñ\n### 2025.03.30 AIËá™Âä®ÂÆöÊó∂ÂàÜÊûêÂäüËÉΩ\n### 2025.03.29 Â§öÊèêÁ§∫ËØçÊ®°ÊùøÁÆ°ÁêÜÔºåAIÂàÜÊûêÊó∂ÊîØÊåÅÈÄâÊã©‰∏çÂêåÊèêÁ§∫ËØçÊ®°Êùø\n### 2025.03.28 AIÂàÜÊûêÁªìÊûú‰øùÂ≠ò‰∏∫markdownÊñá‰ª∂Êó∂ÔºåÊîØÊåÅ‰øùÂ≠ò‰ΩçÁΩÆÁõÆÂΩïÈÄâÊã©\n### 2025.03.15 Ëá™ÂÆö‰πâÁà¨Ëô´‰ΩøÁî®ÁöÑÊµèËßàÂô®Ë∑ØÂæÑÈÖçÁΩÆ\n### 2025.03.14 ‰ºòÂåñÁºñËØëÊûÑÂª∫ÔºåÂ§ßÂπÖÂáèÂ∞ëÁºñËØëÂêéÁöÑÁ®ãÂ∫èÊñá‰ª∂Â§ßÂ∞è\n### 2025.03.09 Âü∫Èáë‰º∞ÂÄºÂíåÂáÄÂÄºÁõëÊéßÊü•Áúã\n### 2025.03.06 È°πÁõÆÁ§æÂå∫ÂàÜ‰∫´ÂäüËÉΩ\n### 2025.02.28 ÁæéËÇ°Êï∞ÊçÆÊîØÊåÅ\n### 2025.02.23 ÂºπÂπïÂäüËÉΩÔºåÁõØÁõò‰∏çÂÜçÂ≠§ÂçïÔºåÊó†ËÅäÂàí‰∏™Ê∞¥ÔºÅüòé\n### 2025.02.22 Ê∏ØËÇ°Êï∞ÊçÆÊîØÊåÅ(ÁõÆÂâçÊúâÂª∂Ëøü)\n\n### 2025.02.16 AIÂàÜÊûêÂêéÂèØÁªßÁª≠ÂØπËØùÊèêÈóÆ\n- [v2025.2.16.1-alpha](https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.16.1-alpha)\n\n### 2025.02.12 ÂèØÈÖçÁΩÆÁöÑÊèêÈóÆÊ®°Êùø\n- [v2025.2.12.7-alpha](https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha)\n\n\n## ü¶Ñ ÈáçÂ§ßÊõ¥Êñ∞\n### BIG NEWS !!! ÈáçÂ§ßÊõ¥Êñ∞ÔºÅÔºÅÔºÅ\n- 2025.11.21 Êñ∞Â¢ûÂ∏¶È¢ëÁéáÊùÉÈáçÁöÑÊÉÖÊÑüÂàÜÊûêÂäüËÉΩ\n![img_1.png](build/screenshot/img15.png)\n- 2025.04.25 Â∏ÇÂú∫ËµÑËÆØÊîØÊåÅAIÂàÜÊûêÂíåÊÄªÁªìÔºöËÆ©AIÂ∏Æ‰Ω†ËØªÂ∏ÇÂú∫ÔºÅ\n![img.png](img.png)\n- 2025.04.24 Êñ∞Â¢ûÂ∏ÇÂú∫Ë°åÊÉÖÊ®°ÂùóÔºöÂç≥Êó∂ÊéåÊè°ÂÖ®ÁêÉÂ∏ÇÂú∫Ë°åÊÉÖËµÑËÆØ/Âä®ÊÄÅÔºå‰ªéÊ≠§ÂÜç‰πü‰∏çÁî®ÂÅ∑Êë∏ÂéªÂêÑÂ§ßË¥¢ÁªèÁΩëÁ´ôÂï¶„ÄÇgo-stock‰∏ÄÈîÆÂ∏Æ‰Ω†ÊêûÂÆöÔºÅ\n![img.png](build/screenshot/img13.png)\n![img_13.png](build/screenshot/img_13.png)\n- ![img_14.png](build/screenshot/img_14.png)\n- 2025.01.17 Êñ∞Â¢ûAIÂ§ßÊ®°ÂûãÂàÜÊûêËÇ°Á•®ÂäüËÉΩ\n  ![img_5.png](build/screenshot/img.png)\n## üì∏ ÂäüËÉΩÊà™Âõæ\n![img_1.png](build/screenshot/img_6.png)\n### ËÆæÁΩÆ\n![img_12.png](build/screenshot/img_4.png)\n### ÊàêÊú¨ËÆæÁΩÆ\n![img.png](build/screenshot/img_7.png)\n### Êó•K\n![img_12.png](build/screenshot/img_12.png)\n### ÂàÜÊó∂\n![img_3.png](build/screenshot/img_9.png)\n### ÈíâÈíâÊä•Ë≠¶ÈÄöÁü•\n![img_4.png](build/screenshot/img_5.png)\n### AIÂàÜÊûêËÇ°Á•®\n![img_5.png](build/screenshot/img.png)\n### ÁâàÊú¨‰ø°ÊÅØÊèêÁ§∫\n![img_11.png](build/screenshot/img_11.png)\n\n## üíï ÊÑüË∞¢‰ª•‰∏ãÈ°πÁõÆ\n- [NaiveUI](https://www.naiveui.com/)\n- [Wails](https://wails.io/)\n- [Vue](https://vuejs.org/)\n- [Vite](https://vitejs.dev/)\n- [Tushare](https://tushare.pro/register?reg=701944)\n\n## üòò ËµûÂä©Êàë\n### ÈÉΩÂàíÂà∞Ëøô‰∫ÜÔºåÂ¶ÇÊûúÊàëÁöÑÈ°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑ËµûÂä©ÊàëÂêßÔºÅüòäüòäüòä\n| ÊîØ‰ªòÂÆù | ÂæÆ‰ø°  |\n|-----|-----| \n| ![alipay.jpg](build/screenshot/alipay.jpg)  | ![wxpay.jpg](build/screenshot/wxpay.jpg) |\n\n\n## ‚≠ê Star History\n[![Star History Chart](https://api.star-history.com/svg?repos=ArvinLovegood/go-stock&type=Date)](https://star-history.com/#ArvinLovegood/go-stock&Date)\n## ü§ñ Áä∂ÊÄÅ\n![Alt](https://repobeats.axiom.co/api/embed/40b07d415a42c2264a18c4fe1b6f182ff1470687.svg \"Repobeats analytics image\")\n\n## üê≥ ÂÖ≥‰∫éÊäÄÊúØÊîØÊåÅÁî≥Êòé\n- Êú¨ËΩØ‰ª∂Âü∫‰∫éÂºÄÊ∫êÊäÄÊúØÊûÑÂª∫Ôºå‰ΩøÁî®Wails„ÄÅNaiveUI„ÄÅVue„ÄÅAIÂ§ßÊ®°ÂûãÁ≠âÂºÄÊ∫êÈ°πÁõÆ„ÄÇ ÊäÄÊúØ‰∏äÂ¶ÇÊúâÈóÆÈ¢òÔºåÂèØ‰ª•ÂÖàÂêëÂØπÂ∫îÁöÑÂºÄÊ∫êÁ§æÂå∫ËØ∑Ê±ÇÂ∏ÆÂä©„ÄÇ\n- ÂºÄÊ∫ê‰∏çÊòìÔºåÊú¨‰∫∫Á≤æÂäõÂíåÊó∂Èó¥ÊúâÈôêÔºåÂ¶ÇÈúÄ‰∏ÄÂØπ‰∏ÄÊäÄÊúØÊîØÊåÅÔºåËØ∑ÂÖàËµûÂä©„ÄÇËÅîÁ≥ªQQ(Â§áÊ≥® ÊäÄÊúØÊîØÊåÅ)Ôºö506808970\n\n[//]: # (<img src=\"./build/wx.jpg\" width=\"301px\" height=\"402px\" alt=\"ArvinLovegood\">)\n\n\n| ÊäÄÊúØÊîØÊåÅÊñπÂºè                          | ËµûÂä©(ÂÖÉ) | \n|:--------------------------------|:-----:|\n| Âä† QQÔºö506808970                  | 100/Ê¨° |\n| ÈïøÊúüÊäÄÊúØÊîØÊåÅÔºà‰∏çÈôêÊ¨°Êï∞ÔºåÊñ∞ÂäüËÉΩ‰ºòÂÖà‰ΩìÈ™åÁ≠âÔºâ           | 5000  |                  \n\n\n\n## License\n[Apache License 2.0](LICENSE)\n\n",
      "stars_today": 42
    },
    {
      "id": 875661263,
      "name": "VoiceInk",
      "full_name": "Beingpax/VoiceInk",
      "description": "Voice-to-text app for macOS to transcribe what you say to text almost instantly",
      "html_url": "https://github.com/Beingpax/VoiceInk",
      "stars": 3265,
      "forks": 404,
      "language": "Swift",
      "topics": [
        "macos",
        "macos-app",
        "swift"
      ],
      "created_at": "2024-10-20T15:11:17Z",
      "updated_at": "2026-01-17T00:36:06Z",
      "pushed_at": "2026-01-13T05:13:46Z",
      "open_issues": 176,
      "owner": {
        "login": "Beingpax",
        "avatar_url": "https://avatars.githubusercontent.com/u/101010368?v=4"
      },
      "readme": "<div align=\"center\">\n  <img src=\"VoiceInk/Assets.xcassets/AppIcon.appiconset/256-mac.png\" width=\"180\" height=\"180\" />\n  <h1>VoiceInk</h1>\n  <p>Voice to text app for macOS to transcribe what you say to text almost instantly</p>\n\n  [![License](https://img.shields.io/badge/License-GPL%20v3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n  ![Platform](https://img.shields.io/badge/platform-macOS%2014.0%2B-brightgreen)\n  [![GitHub release (latest by date)](https://img.shields.io/github/v/release/Beingpax/VoiceInk)](https://github.com/Beingpax/VoiceInk/releases)\n  ![GitHub all releases](https://img.shields.io/github/downloads/Beingpax/VoiceInk/total)\n  ![GitHub stars](https://img.shields.io/github/stars/Beingpax/VoiceInk?style=social)\n  <p>\n    <a href=\"https://tryvoiceink.com\">Website</a> ‚Ä¢\n    <a href=\"https://www.youtube.com/@tryvoiceink\">YouTube</a>\n  </p>\n\n  <a href=\"https://tryvoiceink.com\">\n    <img src=\"https://img.shields.io/badge/Download%20Now-Latest%20Version-blue?style=for-the-badge&logo=apple\" alt=\"Download VoiceInk\" width=\"250\"/>\n  </a>\n</div>\n\n---\n\nVoiceInk is a native macOS application that transcribes what you say to text almost instantly. You can find all the information and download the app from [here](https://tryvoiceink.com). \n\n![VoiceInk Mac App](https://github.com/user-attachments/assets/12367379-83e7-48a6-b52c-4488a6a04bba)\n\nAfter dedicating the past 5 months to developing this app, I've decided to open source it for the greater good. \n\nMy goal is to make it **the most efficient and privacy-focused voice-to-text solution for macOS** that is a joy to use. While the source code is now open for experienced developers to build and contribute, purchasing a license helps support continued development and gives you access to automatic updates, priority support, and upcoming features.\n\n## Features\n\n- üéôÔ∏è **Accurate Transcription**: Local AI models that transcribe your voice to text with 99% accuracy, almost instantly\n- üîí **Privacy First**: 100% offline processing ensures your data never leaves your device\n- ‚ö° **Power Mode**: Intelligent app detection automatically applies your perfect pre-configured settings based on the app/ URL you're on\n- üß† **Context Aware**: Smart AI that understands your screen content and adapts to the context\n- üéØ **Global Shortcuts**: Configurable keyboard shortcuts for quick recording and push-to-talk functionality\n- üìù **Personal Dictionary**: Train the AI to understand your unique terminology with custom words, industry terms, and smart text replacements\n- üîÑ **Smart Modes**: Instantly switch between AI-powered modes optimized for different writing styles and contexts\n- ü§ñ **AI Assistant**: Built-in voice assistant mode for a quick chatGPT like conversational assistant\n\n## Get Started\n\n### Download\nGet the latest version with a free trial from [tryvoiceink.com](https://tryvoiceink.com). Your purchase helps me work on VoiceInk full-time and continuously improve it with new features and updates.\n\n#### Homebrew\nAlternatively, you can install VoiceInk via `brew`:\n\n```shell\nbrew install --cask voiceink\n```\n\n### Build from Source\nAs an open-source project, you can build VoiceInk yourself by following the instructions in [BUILDING.md](BUILDING.md). However, the compiled version includes additional benefits like automatic updates, priority support via Discord and email, and helps fund ongoing development.\n\n## Requirements\n\n- macOS 14.0 or later\n\n## Documentation\n\n- [Building from Source](BUILDING.md) - Detailed instructions for building the project\n- [Contributing Guidelines](CONTRIBUTING.md) - How to contribute to VoiceInk\n- [Code of Conduct](CODE_OF_CONDUCT.md) - Our community standards\n\n## Contributing\n\nWe welcome contributions! However, please note that all contributions should align with the project's goals and vision. Before starting work on any feature or fix:\n\n1. Read our [Contributing Guidelines](CONTRIBUTING.md)\n2. Open an issue to discuss your proposed changes\n3. Wait for maintainer feedback\n\nFor build instructions, see our [Building Guide](BUILDING.md).\n\n## License\n\nThis project is licensed under the GNU General Public License v3.0 - see the [LICENSE](LICENSE) file for details.\n\n## Support\n\nIf you encounter any issues or have questions, please:\n1. Check the existing issues in the GitHub repository\n2. Create a new issue if your problem isn't already reported\n3. Provide as much detail as possible about your environment and the problem\n\n## Acknowledgments\n\n### Core Technology\n- [whisper.cpp](https://github.com/ggerganov/whisper.cpp) - High-performance inference of OpenAI's Whisper model\n- [FluidAudio](https://github.com/FluidInference/FluidAudio) - Used for Parakeet model implementation\n\n### Essential Dependencies\n- [Sparkle](https://github.com/sparkle-project/Sparkle) - Keeping VoiceInk up to date\n- [KeyboardShortcuts](https://github.com/sindresorhus/KeyboardShortcuts) - User-customizable keyboard shortcuts\n- [LaunchAtLogin](https://github.com/sindresorhus/LaunchAtLogin) - Launch at login functionality\n- [MediaRemoteAdapter](https://github.com/ejbills/mediaremote-adapter) - Media playback control during recording\n- [Zip](https://github.com/marmelroy/Zip) - File compression and decompression utilities\n- [SelectedTextKit](https://github.com/tisfeng/SelectedTextKit) - A modern macOS library for getting selected text\n- [Swift Atomics](https://github.com/apple/swift-atomics) - Low-level atomic operations for thread-safe concurrent programming\n\n\n---\n\nMade with ‚ù§Ô∏è by Pax\n",
      "stars_today": 41
    },
    {
      "id": 25135037,
      "name": "deskflow",
      "full_name": "deskflow/deskflow",
      "description": "Share a single keyboard and mouse between multiple computers.",
      "html_url": "https://github.com/deskflow/deskflow",
      "stars": 23197,
      "forks": 4394,
      "language": "C++",
      "topics": [
        "keyboard",
        "keyboard-emulation",
        "mouse",
        "mouse-emulation",
        "network"
      ],
      "created_at": "2014-10-12T23:18:57Z",
      "updated_at": "2026-01-17T00:52:18Z",
      "pushed_at": "2026-01-16T11:35:40Z",
      "open_issues": 205,
      "owner": {
        "login": "deskflow",
        "avatar_url": "https://avatars.githubusercontent.com/u/181782356?v=4"
      },
      "readme": "<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/deskflow/deskflow-artwork/blob/main/logo/deskflow-logo-dark-200px.png?raw=true\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/deskflow/deskflow-artwork/blob/main/logo/deskflow-logo-light-200px.png?raw=true\">\n  <img alt=\"Deskflow\" src=\"https://github.com/user-attachments/assets/f005b958-24df-4f4a-9bfd-4f834dae59d6\">\n</picture>\n\n**Deskflow** is a free and open source keyboard and mouse sharing app.\nUse the keyboard, mouse, or trackpad of one computer to control nearby computers,\nand work seamlessly between them.\nIt's like a software KVM (but without the video).\nTLS encryption is enabled by default. Wayland is supported. Clipboard sharing is supported.\n\n> [!TIP]\n>\n> **Chat with us**\n>\n> - Main discussion on Matrix: [`#deskflow:matrix.org`](https://matrix.to/#/#deskflow:matrix.org) ([Matrix clients](https://matrix.org/ecosystem/clients/))\n> - Discussion also happens on IRC: `#deskflow` or `#deskflow-dev` on [Libera Chat](https://libera.chat/)\n> - Start a [new discussion](https://github.com/deskflow/deskflow/discussions) on our GitHub project.\n\n## Download\n\n[![Downloads: Stable Release](https://img.shields.io/github/downloads/deskflow/deskflow/latest/total?style=for-the-badge&logo=github&label=Download%20Stable)](https://github.com/deskflow/deskflow/releases/latest)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[![Downloads: Continuous Build](https://img.shields.io/github/downloads/deskflow/deskflow/continuous/total?style=for-the-badge&logo=github&label=Download%20Continuous)](https://github.com/deskflow/deskflow/releases/continuous)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[![Download From Flathub](https://img.shields.io/flathub/downloads/org.deskflow.deskflow?style=for-the-badge&logo=flathub&label=Download%20from%20flathub)](https://flathub.org/apps/org.deskflow.deskflow)\n\n> [!NOTE]\n> On Windows, you will need to install the\n> [Microsoft Visual C++ Redistributable](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170#latest-microsoft-visual-c-redistributable-version).  \n> Download latest: [`vc_redist.x64.exe`](https://aka.ms/vs/17/release/vc_redist.x64.exe) [`vc_redist.arm64.exe`](https://aka.ms/vs/17/release/vc_redist.arm64.exe)\n\n> [!TIP]\n> For macOS users, the easiest way to install and stay up to date is to use [Homebrew](https://brew.sh) with our [homebrew-tap](https://github.com/deskflow/homebrew-tap).\n> macOS reports unsigned apps as damaged. This occurs because we do not use an Apple certificate for notarization. Clear the quarantine attribute to run the app: `xattr -c Deskflow.app`\n\nTo use Deskflow, download one of our [packages](https://github.com/deskflow/deskflow/releases), install `deskflow` (from your package repository), or [build it](https://github.com/deskflow/deskflow/wiki/Building) from source.\n\n## Stats\n\n[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/deskflow/deskflow?logo=github)](https://github.com/deskflow/deskflow/commits/master/)\n[![GitHub top language](https://img.shields.io/github/languages/top/deskflow/deskflow?logo=github)](https://github.com/deskflow/deskflow/commits/master/)\n[![GitHub License](https://img.shields.io/github/license/deskflow/deskflow?logo=github)](LICENSE)\n[![REUSE status](https://api.reuse.software/badge/github.com/deskflow/deskflow)](https://api.reuse.software/info/github.com/deskflow/deskflow)\n\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=deskflow_deskflow&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=deskflow_deskflow)\n[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=deskflow_deskflow&metric=coverage)](https://sonarcloud.io/summary/new_code?id=deskflow_deskflow)\n[![Code Smells](https://sonarcloud.io/api/project_badges/measure?project=deskflow_deskflow&metric=code_smells)](https://sonarcloud.io/summary/new_code?id=deskflow_deskflow)\n[![Vulnerabilities](https://sonarcloud.io/api/project_badges/measure?project=deskflow_deskflow&metric=vulnerabilities)](https://sonarcloud.io/summary/new_code?id=deskflow_deskflow)\n\n[![CI](https://github.com/deskflow/deskflow/actions/workflows/continuous-integration.yml/badge.svg)](https://github.com/deskflow/deskflow/actions/workflows/continuous-integration.yml)\n[![CodeQL Analysis](https://github.com/deskflow/deskflow/actions/workflows/codeql-analysis.yml/badge.svg)](https://github.com/deskflow/deskflow/actions/workflows/codeql-analysis.yml)\n[![SonarCloud Analysis](https://github.com/deskflow/deskflow/actions/workflows/sonarcloud-analysis.yml/badge.svg)](https://github.com/deskflow/deskflow/actions/workflows/sonarcloud-analysis.yml)\n\n## Contribute\n\n[![Good first issues](https://img.shields.io/github/issues/deskflow/deskflow/good%20first%20issue?label=good%20first%20issues&color=%2344cc11)](https://github.com/deskflow/deskflow/labels/good%20first%20issue) [![Open bounty issues](https://img.shields.io/github/issues/deskflow/deskflow/%F0%9F%92%8E%20bounty?label=üíé%20open%20bounty%20issues&color=%2344cc11)](https://github.com/deskflow/deskflow/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22%F0%9F%92%8E%20bounty%22) [![Rewarded bounties](https://img.shields.io/github/issues-search/deskflow/deskflow?query=label%3A%22%F0%9F%92%B0%20rewarded%22&label=%F0%9F%92%B0%20rewarded%20bounties&color=yellow)](https://github.com/deskflow/deskflow/issues?q=label%3A%22%F0%9F%92%B0%20rewarded%22%20sort%3Aupdated-desc)\n\nThere are many ways to contribute to the Deskflow project.\n\nWe're a friendly, active, and welcoming community focused on building a great app.\n\nRead our [Contributing](https://github.com/deskflow/deskflow/wiki/Contributing) page to get started.\n\nFor instructions on building Deskflow, use the wiki page: [Building](https://github.com/deskflow/deskflow/wiki/Building)\n\n## Operating Systems\n\nWe support all major operating systems, including Windows, macOS, Linux, and Unix-like BSD-derived.\n\nWindows 10 v1809 or higher is required.\n\nmacOS 13 or higher is requried to use our CI builds for Apple Silicon machines. macOS 12 or higher is required for Intel macs or local builds.\n\nLinux requires libei 1.3+ and libportal 0.8+ for the server/client. Additionally, Qt 6.7+ is required for the GUI.\nLinux users with systems not meeting these requirements should use flatpak in place of a native package.\n\nWe officially support FreeBSD, and would also like to support: OpenBSD, NetBSD, DragonFly, Solaris.\n\n## Repology\n\nRepology monitors a huge number of package repositories and other sources comparing package\nversions across them and gathering other information.\n\n[![Repology](https://repology.org/badge/vertical-allrepos/deskflow.svg?exclude_unsupported=1)](https://repology.org/project/deskflow/versions)\n\n**Note:** We are working with package maintainers to have our new package name adopted.\n\n## Installing on macOS\n\nWhen you install Deskflow on macOS, you need to allow accessibility access (Privacy & Security) to both the `Deskflow` app and the `deskflow` process.\n\nIf using Sequoia, you may also need to allow `Deskflow` under Local Network‚Äç settings (Privacy & Security).\nWhen prompted by the OS, go to the settings and enable the access.\n\nIf you are upgrading and you already have `Deskflow` or `deskflow`\non the allowed list you will need to manually remove them before accessibility access can be granted to the new version.\n\nmacOS users who download directly from releases may need to run `xattr -c /Applications/Deskflow.app` after copying the app to the `Applications` dir.\n\nIt is recommend to install Deskflow using [Homebrew](https://brew.sh) from our [homebrew-tap](https://github.com/deskflow/homebrew-tap)\n\nTo add our tap, run:\n\n```\nbrew tap deskflow/tap\n```\n\nThen install either:\n\n- Stable: `brew install deskflow`\n- Continuous: `brew install deskflow-dev`\n\n## Similar Projects\n\nIn the open source developer community, similar projects collaborate for the improvement of all\nmouse and keyboard sharing tools. We aim for idea sharing and interoperability.\n\n- [**Lan Mouse**](https://github.com/feschber/lan-mouse) -\n  Rust implementation with the goal of having native front-ends and interoperability with\n  Deskflow/Synergy.\n- [**Synergy**](https://symless.com/synergy) -\n  Downstream commercial fork. Synergy sponsors Deskflow with financial support and contributes code ([learn more](https://github.com/deskflow/deskflow/wiki/Relationship-with-Synergy)).\n- [**Input Leap**](https://github.com/input-leap/input-leap) -\n  Inactive Deskflow/Synergy-derivative with the goal continuing Barrier development (now a dead fork).\n\n## FAQ\n\n### Is Deskflow compatible with Synergy, Input Leap, or Barrier?\n\nYes, Deskflow has network compatibility with all forks:\n\n- Requires Deskflow >= v1.17.0.96\n- Deskflow will _just work_ with Input Leap and Barrier (server or client).\n- Connecting a Deskflow client to a Synergy 1 server will also _just work_.\n- To connect a Synergy 1 client, you need to select the Synergy protocol in the Deskflow server settings.\n\n_Note:_ Only Synergy 1 is compatible with Deskflow (Synergy 3 is not yet compatible).\n\n### Is Deskflow compatible with Lan Mouse?\n\nWe would love to see compatibility with Lan Mouse. This may be quite an effort as currently the way they handle the generated input is very different.\n\n### If I want to solve issues in Deskflow do I need to contribute to a fork?\n\nWe welcome PRs (pull requests) from the community. If you'd like to make a change, please feel\nfree to [start a discussion](https://github.com/deskflow/deskflow/discussions) or\n[open a PR](https://github.com/deskflow/deskflow/wiki/Contributing).\n\n### Is clipboard sharing supported?\n\nAbsolutely. The clipboard-sharing feature is a cornerstone feature of the product and we are\ncommitted to maintaining and improving that feature.\n\n### Is Wayland for Linux supported?\n\nYes! Wayland (the Linux display server protocol aimed to become the successor of the X Window\nSystem) is an important platform for us.\nThe [`libei`](https://gitlab.freedesktop.org/libinput/libei) and\n[`libportal`](https://github.com/flatpak/libportal) libraries enable\nWayland support for Deskflow. We would like to give special thanks to Peter Hutterer,\nwho is the author of `libei`, a major contributor to `libportal`, and the author of the Wayland\nimplementation in Deskflow. Others such as Olivier Fourdan and Povilas Kanapickas helped with the\nWayland implementation.\n\nSome features _may_ be unavailable or broken on Wayland. Please see the [known Wayland issues](https://github.com/deskflow/deskflow/discussions/7499).\n\n### Where did it all start?\n\nDeskflow was first created as Synergy in 2001 by Chris Schoeneman.\nRead about the [history of the project](https://github.com/deskflow/deskflow/wiki/History) on our\nwiki.\n\n## Meow'Dib (our mascot)\n\n![Meow'Dib](https://github.com/user-attachments/assets/726f695c-3dfb-4abd-875d-ed658f6c610f)\n\n## Deskflow Contributors\n\n[![Sponsored by Synergy](https://raw.githubusercontent.com/deskflow/deskflow-artwork/b2c72a3e60a42dee793bd47efc275b5ee0bdaa5f/misc/synergy-sponsor.svg)](https://symless.com/synergy)\n\n[Synergy](https://symless.com/synergy) sponsors the Deskflow project by contributing code and providing financial support ([learn more](https://github.com/deskflow/deskflow/wiki/Relationship-with-Synergy)).\n\nDeskflow is made by possible by these contributors.\n\n <a href = \"https://github.com/deskflow/deskflow/graphs/contributors\">\n   <img src = \"https://contrib.rocks/image?repo=deskflow/deskflow\"/>\n </a>\n\n## License\n\nThis project is licensed under [GPL-2.0](LICENSE) with an [OpenSSL exception](LICENSES/LicenseRef-OpenSSL-Exception.txt).\n",
      "stars_today": 39
    },
    {
      "id": 464415161,
      "name": "lago",
      "full_name": "getlago/lago",
      "description": "Open Source Metering and Usage Based Billing API ‚≠êÔ∏è Consumption tracking, Subscription management, Pricing iterations, Payment orchestration & Revenue analytics",
      "html_url": "https://github.com/getlago/lago",
      "stars": 9113,
      "forks": 518,
      "language": "Go",
      "topics": [
        "analytics",
        "billing",
        "clickhouse",
        "events",
        "fintech",
        "go",
        "ingestion",
        "invoices",
        "metering",
        "open-source",
        "payments",
        "pricing",
        "pricing-data-science",
        "react",
        "ruby",
        "self-hosted",
        "subscriptions",
        "usage-based-billing"
      ],
      "created_at": "2022-02-28T09:22:45Z",
      "updated_at": "2026-01-16T23:30:45Z",
      "pushed_at": "2026-01-15T13:22:44Z",
      "open_issues": 24,
      "owner": {
        "login": "getlago",
        "avatar_url": "https://avatars.githubusercontent.com/u/75492405?v=4"
      },
      "readme": "<!-- PROJECT LOGO -->\n<p align=\"center\">\n  <a href=\"https://github.com/getlago/lago\">\n    <img src=\"https://uploads-ssl.webflow.com/635119506e36baf5c267fecd/635b6df0ee8effaa54c1fa42_banner-open-graph.jpg\" alt=\"Lago\">\n  </a>\n\n  <h1 align=\"center\">Lago</h2>\n\n  <p align=\"center\">\n    Open Source Metering & Usage-Based Billing\n    <br />\n    <br />\n    The best alternative to Chargebee, Recurly or Stripe Billing.\n    <br />\n    For usage-based, subscription-based, and all the nuances of pricing in between.\n    <br />\n    <br />\n    <a href=\"https://www.getlago.com/slack\">Slack</a>\n    ¬∑\n    <a href=\"https://getlago.com\">Website</a>\n    ¬∑\n    <a href=\"https://github.com/getlago/lago/issues\">Issues</a>\n    ¬∑\n    <a href=\"https://getlago.canny.io/\">Roadmap</a>\n  </p>\n</p>\n<p align=\"center\">\n    <a href=\"https://www.producthunt.com/posts/lago?utm_source=badge-top-post-badge&utm_medium=badge&utm_souce=badge-lago\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=386328&theme=light&period=monthly\" alt=\"Lago - Open&#0045;source&#0032;alternative&#0032;to&#0032;Stripe&#0032;Billing&#0032;and&#0032;Chargebee | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" />\n    </a>\n</p>\n<p align=\"center\">\n    <a href=\"https://www.producthunt.com/posts/lago?utm_source=badge-top-post-topic-badge&utm_medium=badge&utm_souce=badge-lago\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=386328&theme=light&period=monthly&topic_id=267\" alt=\"Lago - Open&#0045;source&#0032;alternative&#0032;to&#0032;Stripe&#0032;Billing&#0032;and&#0032;Chargebee | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n</p>\n\n<p align=\"center\">\n   <a href=\"https://www.getlago.com/slack\"><img src=\"https://img.shields.io/badge/Lago%20Slack%20Community-lago.slack.com-%234A154B\" alt=\"Join Lago on Slack\"></a>\n   <a href=\"https://github.com/getlago/lago/stargazers\"><img src=\"https://img.shields.io/github/stars/getlago/lago\" alt=\"Github Stars\"></a>\n   <a href=\"https://news.ycombinator.com/item?id=31424450\"><img src=\"https://img.shields.io/badge/Hacker%20News-777-%23FF6600\" alt=\"Hacker News\"></a>\n   <a href=\"https://github.com/getlago/lago/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/license-AGPLv3-purple\" alt=\"License\"></a>\n   <a href=\"https://twitter.com/getlago\"><img src=\"https://img.shields.io/twitter/follow/getlago?style=flat\"></a>\n   <a href=\"https://www.ycombinator.com\"><img src=\"https://img.shields.io/badge/Backed%20by-Y%20Combinator-%23f26625\"></a>\n</p>\n\n<!-- ABOUT THE PROJECT -->\n## The programmable API for usage-based billing\n[![Lago Billing System Presentation](https://img.youtube.com/vi/dXnoMRetsr4/0.jpg)](https://www.youtube.com/watch?v=dXnoMRetsr4)\n\n### The problem: Billing systems are still a nightmare for engineers\n![Billing nightmare](https://uploads-ssl.webflow.com/6244531a40ad7ef5475ad9b3/62827b2f6fa52239b0db0fa4_Blog%20Post%20Image%20Standalone.png)\nEngineers be like‚Ä¶\n\nRead more first-hand experiences from Qonto, Algolia, Pleo, Segment, or the 350+. Hackernews comments [here](https://news.ycombinator.com/item?id=31424450).\n\n**The Solution:** Lago, the open-source billing API for product-led SaaS\n- Event-based: if you can track it, you can charge for it;\n- Built for product-led growth companies;\n- Hybrid pricing: subscription and usage;\n- Hybrid go-to-market motion: self-serve and sales-led.\n\n**Open-source, open architecture:**\n- Composable: connect Lago to any of your internal systems or tools (i.e. any payment gateway, CRM, CPQ, accounting software);\n- Pricing: we‚Äôre not rent seekers, we‚Äôre not asking for a % of your revenue. Our self-hosted version is free. Our cloud version is priced like a SaaS;\n- Privacy: your data never has to leave your infrastructure.\n\n## ‚ú® Features\n- **[Usage metering](https://www.getlago.com/products/metering)**: Lago's event-based architecture provides a solid foundation for building a fair pricing model that scales with your business.\n- **[Price plans](https://www.getlago.com/products/plans)**: Lago supports all pricing models. Create pay-as-you-go and hybrid plans in no time with our intuitive user interface or API.\n- **[Coupons](https://www.getlago.com/products/coupons)**: Create engaging marketing campaigns and increase conversion with coupons that customers can redeem to get a discount.\n- **[Add-ons](https://www.getlago.com/products/add-on)**: Why wait until the end of the billing cycle to get paid? Lago allows you to create one-time charges that are invoiced on the fly.\n- **[Invoicing](https://www.getlago.com/products/invoicing)**: Depending on the configuration of your plans, Lago automatically calculates what each customer owes you and generates invoices.\n- **[Prepaid credits](https://www.getlago.com/products/prepaid-credits)**: Unlock recurring revenue opportunities for pay-as-you-go pricing models with Lago's prepaid credit features.\n\n## üìö Documentation\n- **[Development Environment](./docs/dev_environment.md)**: Learn how to set up and run Lago locally for development\n- **[Architecture](./docs/architecture.md)**: Understand Lago's technical architecture and flows\n\n## üîî Stay up to date\nLago launched its v0.1 on June 2nd, 2022. Lots of new features are coming, and are generally released on a bi-weekly basis. Watch updates of this repository to be notified of future updates.\n\n[Check out our public roadmap](https://getlago.canny.io/)\n\n## üîñ License\nDistributed under the AGPLv3 License. Read more [here](https://www.getlago.com/blog/open-source-licensing-and-why-lago-chose-agplv3).\n\n## Current Releases\n\n| Project            | Release Badge                                                                                       |\n|--------------------|-----------------------------------------------------------------------------------------------------|\n| **Lago**           | [![Lago Release](https://img.shields.io/github/v/release/getlago/lago)](https://github.com/getlago/lago/releases) |\n| **Lago API**     | [![Lago API Release](https://img.shields.io/github/v/release/getlago/lago-api)](https://github.com/getlago/lago-api/releases) |\n| **Lago front**     | [![Lago front Testing Release](https://img.shields.io/github/v/release/getlago/lago-front)](https://github.com/getlago/lago-front/releases) |\n| **Lago Go Client**     | [![Lago Go Client Testing Release](https://img.shields.io/github/v/release/getlago/lago-go-client)](https://github.com/getlago/lago-go-client/releases) |\n| **lago-gotenberg**     | [![lago-gotenberg Release](https://img.shields.io/github/v/release/getlago/lago-gotenberg)](https://github.com/getlago/lago-gotenberg/releases) |\n| **Lago JavaScript Client**     | [![Lago JavaScript Client Release](https://img.shields.io/github/v/release/getlago/lago-javascript-client)](https://github.com/getlago/lago-javascript-client/releases) |\n| **Lago OpenAPI**     | [![Lago OpenAPI Release](https://img.shields.io/github/v/release/getlago/lago-openapi)](https://github.com/getlago/lago-openapi/releases) |\n| **Lago Python Client**     | [![Lago Python Client Release](https://img.shields.io/github/v/release/getlago/lago-python-client)](https://github.com/getlago/lago-python-client/releases) |\n| **Lago Ruby Client**     | [![Lago Ruby Client Release](https://img.shields.io/github/v/release/getlago/lago-ruby-client)](https://github.com/getlago/lago-ruby-client/releases) |\n\n\n## üíª Deploy locally\n\n### Requirements\n1. Install Docker on your machine;\n2. Make sure Docker Compose is installed and available (it should be the case if you have chosen to install Docker via Docker Desktop); and\n3. Make sure Git is installed on your machine.\n\n### Run the app\nTo start using Lago, run the following commands in a shell:\n\n\n#### On a fresh install\n```bash\n# Get the code\ngit clone --depth 1 https://github.com/getlago/lago.git\n\n# Go to Lago folder\ncd lago\n\n# Set up environment configuration\necho \"LAGO_RSA_PRIVATE_KEY=\\\"`openssl genrsa 2048 | openssl base64 -A`\\\"\" >> .env\nsource .env\n\n# Start all the components\ndocker compose up\n```\n\n#### After an update\n\n```bash\ndocker compose up\n```\n\nYou can now open your browser and go to http://localhost to connect to the application. Lago's API is exposed at http://localhost:3000.\n\nNote that if our docker server is not at http://localhost, the following env variables must be set: `LAGO_API_URL`. This may be on the command line or in your .env file. For example:\n\n```\nLAGO_API_URL=\"http://192.168.122.71:3000\"\nLAGO_FRONT_URL=\"http://192.168.122.71\"\n```\n\n### Find your API key\nYour API Key can be found directly in the UI:\n\n1. Access the **Developer** section from the sidebar;\n2. The first tab of this section is related to your **API keys**; and\n3. Click the **Copy** button to copy it to clipboard.\n\n### Analytics and tracking\nPlease note that Lago, by default, tracks basic actions performed on your self-hosted instance. If you do not disable tracking, you may receive specific communications or product updates. However, rest assured that Lago will not collect any personal information about your customers or financial information about your invoices.\n\nIf you would like to know more about Lago's analytics or remove the entire tracking, please refer to [this page](https://doc.getlago.com/guide/self-hosted/tracking-analytics) for comprehensive information.\n\n### Version, environment variables and components\nDocker images are always updated to the last stable version in the docker-compose.yml file. You can use a different tag if needed by checking the releases list.\n\nLago uses the following environment variables to configure the components of the application. You can override them to customise your setup. Take a closer look are our [documentation](https://doc.getlago.com/docs/guide/self-hosting/docker#configuration).\n\n## ‚òÅÔ∏è Use our cloud-based product\nContact our team at hello@getlago.com to get started with Lago Cloud. More information on [our website](https://www.getlago.com/pricing).\n\n## üöÄ Getting the most out of Lago\n- See the [documentation](https://doc.getlago.com) to learn more about all the features;\n- Use our [templates](https://getlago.com/docs/templates/introduction) to get inspiration and learn how to reproduce Algolia‚Äôs, Segment‚Äôs and Klaviyo‚Äôs pricing models;\n- Join our [Slack community](https://www.getlago.com/slack) if you need help, or want to chat, we‚Äôre here to help;\n- Contribute on GitHub: read our [guidelines](https://github.com/getlago/lago/blob/main/CONTRIBUTING.md);\n- Follow us on [Twitter](https://twitter.com/GetLago) for the latest news;\n- You can email us as well: hello@getlago.com.\n\n## üßë‚Äçüíª Contributions and development environment\n\nYou can follow this [guide](./docs/dev_environment.md) to set up a Lago development environment on your machine. This guide is intended for people willing to contribute to Lago. If you want to try Lago on your local system, we recommend that you take a look at Lago's public documentation.\n\nYou can contribute by following our [guidelines](https://github.com/getlago/lago/blob/main/CONTRIBUTING.md).\n\n## üí° Philosophy\nB2B SaaS has evolved, but billing has not yet.\n\n### 1- We‚Äôre not in the ‚Äúsubscription economy‚Äù anymore. And we won‚Äôt go ‚Äúfull usage-based pricing‚Äù quite yet\nPricings are now mostly hybrid: they include a usage-based component (i.e. ‚Äúif you use more you pay more‚Äù) and a subscription component (i.e. a recurring fee for basic usage).\n\nNot all software companies will go full ‚Äúusage-based‚Äù like Snowflake for instance. This model is the new standard for cloud infrastructure products. However, in other areas of SaaS, users want to know beforehand how much they will pay to control their spending and software companies want to be able to predict recurring revenues.\n\n### 2- Go-to-market is not either bottom-up or top-down anymore\nSaaS used to be either self-service (SMBs) or sales-led (Enterprises).\nGo-to-market now mixes the self-service (all customers access the same price plans) and sales-led (customers get a custom quote from a sales representative) motions.\nA typical journey involves an individual contributor in a company who tests a new tool, puts their corporate credit card in, and starts spreading the use of the tool within the organization. At that point, the VP or head of department might want to upgrade to a custom plan tailored to the needs of the whole organization.\nAs a result, billing needs to be flexible, automated, and transparent enough to embrace this hybrid go-to-market motion as well.\n\n### 3- The ‚Äúrent seeker‚Äù pricing of current billing solutions needs to stop\nWhy do payment companies take a cut on revenues?\nBecause the higher the amount, the higher the risk for them (e.g. fraud, disputes, etc.).\n\nWhy did billing companies adopt the same pricing structure? We‚Äôre not able to provide an answer that makes sense. It‚Äôs been said on the internet that they did this because they could (read more [here](https://news.ycombinator.com/item?id=16766846)).\n\n### One last thing‚Ä¶\nLago is agnostic and we aim at being as transparent as possible, so we won‚Äôt nudge or lock you into using a specific tool in exchange for using our billing API ([learn more](https://www.gmass.co/blog/negotiating-stripe-fees/)).\n",
      "stars_today": 38
    },
    {
      "id": 677376114,
      "name": "Metrolist",
      "full_name": "mostafaalagamy/Metrolist",
      "description": "YouTube Music client for Android",
      "html_url": "https://github.com/mostafaalagamy/Metrolist",
      "stars": 5840,
      "forks": 296,
      "language": "Kotlin",
      "topics": [
        "android",
        "innertube",
        "material-design",
        "material-ui",
        "material3",
        "music",
        "music-player",
        "musicplayer",
        "newpipe",
        "newpipe-extractor",
        "youtube",
        "youtube-music",
        "ytmusic"
      ],
      "created_at": "2023-08-11T12:19:23Z",
      "updated_at": "2026-01-16T23:01:44Z",
      "pushed_at": "2026-01-17T01:03:05Z",
      "open_issues": 574,
      "owner": {
        "login": "mostafaalagamy",
        "avatar_url": "https://avatars.githubusercontent.com/u/80542861?v=4"
      },
      "readme": "<div align=\"center\">\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/icon.png\" width=\"160\" height=\"160\" style=\"display: block; margin: 0 auto\"/>\n<h1>Metrolist</h1>\n<p>YouTube Music client for Android</p>\n\n<div style=\"padding: 16px; margin: 16px 0; background-color: #FFFBE5; border-left: 6px solid #FFC107; border-radius: 4px;\">\n<h2 style=\"margin: 0;\"><strong>‚ö†Warning</strong></h2>\nIf you're in a region where YouTube Music is not supported, you won't be able to use this app <strong>unless</strong> you have a proxy or VPN to connect to a YTM-supported region.\n</div>\n\n<h1>Screenshots</h1>\n\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_1.png\" width=\"30%\" />\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_2.png\" width=\"30%\" />\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_3.png\" width=\"30%\" />\n\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_4.png\" width=\"30%\" />\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_5.png\" width=\"30%\" />\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_6.png\" width=\"30%\" />\n\n<div align=\"center\">\n<h1>Release numbers</h1>\n</div>\n\n[![Latest release](https://img.shields.io/github/v/release/mostafaalagamy/Metrolist?style=for-the-badge)](https://github.com/mostafaalagamy/Metrolist/releases)\n[![GitHub license](https://img.shields.io/github/license/mostafaalagamy/metrolist?style=for-the-badge)](https://github.com/mostafaalagamy/Metrolist/blob/main/LICENSE)\n[![Downloads](https://img.shields.io/github/downloads/mostafaalagamy/Metrolist/total?style=for-the-badge)](https://github.com/mostafaalagamy/Metrolist/releases)\n</div>\n\n<div align=\"center\">\n<h1>Table of Contents</h1>\n</div>\n\n- [Features](#features)\n- [Download Now](#download-now)\n- [FAQ](#faq)\n- [Development Setup](#development-setup)\n- [Translations](#translations)\n- [Support Me](#support-me)\n- [Join our community](#join-our-community)\n- [Contributors](#thanks-to-all-contributors) \n\n<div align=\"center\">\n<h1>Features</h1>\n</div>\n\n- Play any song or video from YT Music\n- Background playback \n- Personalized quick picks \n- Library management \n- Download and cache songs for offline playback\n- Search for songs, albums, artists, videos and playlists\n- Live lyrics \n- YouTube Music account login support\n- Syncing of songs, artists, albums and playlists, from and to your account\n- Skip silence \n- Import playlists \n- Audio normalization \n- Adjust tempo/pitch \n- Local playlist management\n- Reorder songs in playlist or queue \n- Light - Dark - black - Dynamic theme\n- Sleep timer\n- Material 3 \n- etc.\n\n<div align=\"center\">\n<h1>Download Now</h1>\n\n<table>\n<tr>\n<td align=\"center\">\n<a href=\"https://github.com/mostafaalagamy/Metrolist/releases/latest/download/Metrolist.apk\"><img src=\"https://github.com/machiav3lli/oandbackupx/blob/034b226cea5c1b30eb4f6a6f313e4dadcbb0ece4/badge_github.png\" alt=\"Get it on GitHub\" height=\"82\"></a><br/>\n<a href=\"https://www.openapk.net/metrolist/com.metrolist.music/\"><img src=\"https://www.openapk.net/images/openapk-badge.png\" alt=\"Get it on OpenAPK\" height=\"80\"></a>\n</td>\n<td align=\"center\">\n<a href=\"https://apps.obtainium.imranr.dev/redirect?r=obtainium://add/https://github.com/mostafaalagamy/Metrolist/\"><img src=\"https://github.com/ImranR98/Obtainium/blob/main/assets/graphics/badge_obtainium.png\" alt=\"Get it on Obtainium\" height=\"50\"></a>\n</td>\n<td align=\"center\">\n<a href=\"https://apt.izzysoft.de/fdroid/index/apk/com.metrolist.music\"><img src=\"https://gitlab.com/IzzyOnDroid/repo/-/raw/master/assets/IzzyOnDroid.png\" alt=\"Get it on IzzyOnDroid\" height=\"80\"></a><br/>\n<a href=\"https://belberi.com/metrolist/?fbclid=PAY2xjawJP5dlleHRuA2FlbQIxMAABpjSk1oBp4e8aSV4nfX2dfunQObTlMWIkN-aVA9CSq36pnmkHsvfoYTjhHg_aem_9o9OGbQuZ2PjJTArq21UDA\"><img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/belberi_github.png\" alt=\"Get it on Belberi\" height=\"82\"></a>\n</td>\n</tr>\n</table>\n\n</div>\n\n<div align=\"center\">\n<h1>Translations</h1>\n\n[![Translation status](https://img.shields.io/weblate/progress/metrolist?style=for-the-badge)](https://hosted.weblate.org/engage/metrolist/)\n\nWe use Weblate to translate Metrolist. For more details or to get started, visit our [Weblate page](https://hosted.weblate.org/projects/Metrolist/).\n\n<a href=\"https://hosted.weblate.org/projects/Metrolist/\">\n<img src=\"https://hosted.weblate.org/widget/Metrolist/horizontal-auto.svg\" alt=\"Translation status\" />\n</a>\n\nThank you very much for helping to make Metrolist accessible to many people worldwide.\n</div>\n\n<div align=\"center\">\n<h1>FAQ</h1>\n</div>\n\n### Q: Why Metrolist isn't showing in Android Auto?\n\n1. Go to Android Auto's settings and tap multiple times on the version in the bottom to enable\n   developer settings\n2. In the three dots menu at the top-right of the screen, click \"Developer settings\"\n3. Enable \"Unknown sources\"\n\n<div align=\"center\">\n<h1>Development Setup</h1>\n</div>\n\n### GitHub Secrets Configuration\n\nThis project uses GitHub Secrets to securely store API keys for building releases. To set up the secrets:\n\n1. Go to your GitHub repository settings\n2. Navigate to **Settings** ‚Üí **Secrets and variables** ‚Üí **Actions**\n3. Add the following repository secrets:\n   - `LASTFM_API_KEY`: Your LastFM API key\n   - `LASTFM_SECRET`: Your LastFM secret key\n\n4. Get your LastFM API credentials from: https://www.last.fm/api/account/create\n\n**Note:** These secrets are automatically injected into the build process via GitHub Actions and are not visible in the source code.\n\n<div align=\"center\">\n<h1>Support Me</h1>\n\nIf you'd like to support my work, send a Monero (XMR) donation to this address:\n\n44XjSELSWcgJTZiCKzjpCQWyXhokrH9RqH3rpp35FkSKi57T25hniHWHQNhLeXyFn3DDYqufmfRB1iEtENerZpJc7xJCcqt\n\nOr scan this QR code:\n\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/assets/XMR.png\" alt=\"QR Code\" width=\"200\" height=\"200\" />\n\nOr other\n\n<a href=\"https://www.buymeacoffee.com/mostafaalagamy\">\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/assets/buymeacoffee.png?raw=true\" alt=\"Buy Me a Coffee\" width=\"150\" height=\"150\" />\n</a>\n\n<div align=\"center\">\n<h1>Join our community</h1>\n\n[![Discord](https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&logo=discord&logoColor=white&labelColor=1c1917)](https://dsc.gg/metrolist)\n[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white&labelColor=1c1917)](https://t.me/metrolistapp)\n</div>\n\n<div align=\"center\">\n<h1>Special thanks</h1>\n\n**InnerTune**\n[Zion Huang](https://github.com/z-huang) ‚Ä¢ [Malopieds](https://github.com/Malopieds)\n\n**OuterTune**\n[Davide Garberi](https://github.com/DD3Boh) ‚Ä¢ [Michael Zh](https://github.com/mikooomich)\n\nCredits:\n\n[**Kizzy**](https://github.com/dead8309/Kizzy) ‚Äì for the Discord Rich Presence implementation and inspiration.\n\n[**Better Lyrics**](https://better-lyrics.boidu.dev) ‚Äì for beautiful time-synced lyrics with word-by-word highlighting, and seamless YouTube Music integration.\n\n[**SimpMusic Lyrics**](https://github.com/maxrave-dev/SimpMusic) ‚Äì for providing lyrics data through the SimpMusic Lyrics API.\n\nThe open-source community for tools, libraries, and APIs that make this project possible.\n\n<sub>Thank you to all the amazing developers who made this project possible!</sub>\n\n</div>\n\n<div align=\"center\">\n<h1>Thanks to all contributors</h1>\n\n<a href = \"https://github.com/mostafaalagamy/Metrolist/graphs/contributors\">\n<img src = \"https://contrib.rocks/image?repo=mostafaalagamy/Metrolist\" width=\"600\"/>\n</a>\n\n</div>\n\n<div align=\"center\">\n<h1>Disclaimer</h1>\n</div>\n\nThis project and its contents are not affiliated with, funded, authorized, endorsed by, or in any way associated with YouTube, Google LLC, Metrolist Group LLC or any of its affiliates and subsidiaries.\n\nAny trademark, service mark, trade name, or other intellectual property rights used in this project are owned by the respective owners.\n\n**Made with ‚ù§Ô∏è by [Mo Agamy](https://github.com/mostafaalagamy)**\n",
      "stars_today": 34
    },
    {
      "id": 53305197,
      "name": "go-concurrency-exercises",
      "full_name": "loong/go-concurrency-exercises",
      "description": "Hands on exercises with real-life examples to study and practice Go concurrency patterns. Test-cases are provided to verify your answers.",
      "html_url": "https://github.com/loong/go-concurrency-exercises",
      "stars": 1779,
      "forks": 532,
      "language": "Go",
      "topics": [],
      "created_at": "2016-03-07T07:34:57Z",
      "updated_at": "2026-01-16T23:29:09Z",
      "pushed_at": "2024-09-23T09:40:48Z",
      "open_issues": 10,
      "owner": {
        "login": "loong",
        "avatar_url": "https://avatars.githubusercontent.com/u/1732217?v=4"
      },
      "readme": "# Go Concurrency Exercises [![Build Status](https://travis-ci.org/loong/go-concurrency-exercises.svg?branch=main)](https://travis-ci.org/loong/go-concurrency-exercises) [![Go Report Card](https://goreportcard.com/badge/github.com/loong/go-concurrency-exercises)](https://goreportcard.com/report/github.com/loong/go-concurrency-exercises)\nExercises for Golang's concurrency patterns.\n\n## Why\nThe Go community has plenty resources to read about go's concurrency model and how to use it effectively. But *who actually wants to read all this*!? This repo tries to teach concurrency patterns by following the 'learning by doing' approach.\n\n![Image of excited gopher](https://golang.org/doc/gopher/pkg.png)\n\n## How to take this challenge\n1. *Only edit `main.go`* to solve the problem. Do not touch any of the other files.\n2. If you find a `*_test.go` file, you can test the correctness of your solution with `go test`\n3. If you get stuck, join us on [Discord](https://discord.com/invite/golang) or [Slack](https://invite.slack.golangbridge.org/)! Surely there are people who are happy to give you some code reviews (if not, find me via `@loong` ;) )\n\n## Overview\n| # | Name of the Challenge + URL           | \n| - |:-------------|\n| 0 | [Limit your Crawler](https://github.com/loong/go-concurrency-exercises/tree/main/0-limit-crawler) |\n| 1 | [Producer-Consumer](https://github.com/loong/go-concurrency-exercises/tree/main/1-producer-consumer)  |\n| 2 | [Race Condition in Caching Cache](https://github.com/loong/go-concurrency-exercises/tree/main/2-race-in-cache#race-condition-in-caching-szenario)  |\n| 3 | [Limit Service Time for Free-tier Users](https://github.com/loong/go-concurrency-exercises/tree/main/3-limit-service-time)  |\n| 4 | [Graceful SIGINT Killing](https://github.com/loong/go-concurrency-exercises/tree/main/4-graceful-sigint)  |\n| 5 | [Clean Inactive Sessions to Prevent Memory Overflow](https://github.com/loong/go-concurrency-exercises/tree/main/5-session-cleaner)  |\n\n## License\n\n```\n DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE \n                    Version 2, December 2004 \n\n Copyleft from 2017 Long Hoang\n\n Everyone is permitted to copy and distribute verbatim or modified \n copies of this license document, and changing it is allowed as long \n as the name is changed.\n\n            DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE \n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION \n\n  0. You just DO WHAT THE FUCK YOU WANT TO.\n```\n",
      "stars_today": 32
    },
    {
      "id": 478710402,
      "name": "ImageToolbox",
      "full_name": "T8RIN/ImageToolbox",
      "description": "üñºÔ∏è Image Toolbox is a powerful app for advanced image manipulation. It offers dozens of features, from basic tools like crop and draw to filters, OCR, and a wide range of image processing options",
      "html_url": "https://github.com/T8RIN/ImageToolbox",
      "stars": 11285,
      "forks": 493,
      "language": "Kotlin",
      "topics": [
        "ai",
        "android",
        "background-removal",
        "crop",
        "edit-photo",
        "exif",
        "f-droid",
        "filter-image",
        "image-manipulation",
        "jetpack-compose",
        "jxl",
        "kotlin",
        "material-you",
        "ocr-recognition",
        "pdf",
        "photo-collage",
        "photo-editor",
        "psd",
        "qrcode-scanner",
        "upscaling"
      ],
      "created_at": "2022-04-06T20:06:28Z",
      "updated_at": "2026-01-17T00:46:58Z",
      "pushed_at": "2026-01-16T23:14:03Z",
      "open_issues": 14,
      "owner": {
        "login": "T8RIN",
        "avatar_url": "https://avatars.githubusercontent.com/u/52178347?v=4"
      },
      "readme": "<div align=\"center\">\n</br>\n<img src=\"./fastlane/metadata/android/en-US/images/logo/logo.png\" width=\"200\" />\n\n</div>\n\n<div align=\"center\">\n\n# Image Toolbox\n\n</div>\n\n</br>\n\n<p align=\"center\">\n  <img alt=\"API\" src=\"https://img.shields.io/badge/Api%2023+-50f270?logo=android&logoColor=black&style=for-the-badge\"/></a>\n  <img alt=\"Kotlin\" src=\"https://img.shields.io/badge/Kotlin-a503fc?logo=kotlin&logoColor=white&style=for-the-badge\"/></a>\n  <img alt=\"Jetpack Compose\" src=\"https://img.shields.io/static/v1?style=for-the-badge&message=Jetpack+Compose&color=4285F4&logo=Jetpack+Compose&logoColor=FFFFFF&label=\"/></a> \n    <img alt=\"material\" src=\"https://custom-icon-badges.demolab.com/badge/material%20you-lightblue?style=for-the-badge&logoColor=333&logo=material-you\"/></a>\n  </br>\n  </br>\n  \n <img src=\"https://img.shields.io/badge/236.8K-aeff4d?style=for-the-badge&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI%2BCiAgICA8cGF0aCBkPSJNMTIuODksM0wxNC44NSwzLjRMMTEuMTEsMjFMOS4xNSwyMC42TDEyLjg5LDNNMTkuNTksMTJMMTYsOC40MVY1LjU4TDIyLjQyLDEyTDE2LDE4LjQxVjE1LjU4TDE5LjU5LDEyTTEuNTgsMTJMOCw1LjU4VjguNDFMNC40MSwxMkw4LDE1LjU4VjE4LjQxTDEuNTgsMTJaIgogICAgICAgIGZpbGw9IndoaXRlIiAvPgo8L3N2Zz4%3D&label=Lines%20of%20code&labelColor=4b731a\"/>\n\n<img src=\"https://img.shields.io/github/commits-since/t8rin/ImageResizer/v1.0?color=palegreen&label=Commits&style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCI+PHRpdGxlPnNvdXJjZS1jb21taXQ8L3RpdGxlPjxwYXRoIGQ9Ik0xNywxMkMxNywxNC40MiAxNS4yOCwxNi40NCAxMywxNi45VjIxSDExVjE2LjlDOC43MiwxNi40NCA3LDE0LjQyIDcsMTJDNyw5LjU4IDguNzIsNy41NiAxMSw3LjFWM0gxM1Y3LjFDMTUuMjgsNy41NiAxNyw5LjU4IDE3LDEyTTEyLDlBMywzIDAgMCwwIDksMTJBMywzIDAgMCwwIDEyLDE1QTMsMyAwIDAsMCAxNSwxMkEzLDMgMCAwLDAgMTIsOVoiIGZpbGw9IndoaXRlIiAvPjwvc3ZnPg==&labelColor=07ab4e\">\n \n<img src=\"https://img.shields.io/github/languages/code-size/t8rin/imageresizer?style=for-the-badge&color=8ce2ff&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCI+PHRpdGxlPndlaWdodDwvdGl0bGU+PHBhdGggZD0iTTEyLDNBNCw0IDAgMCwxIDE2LDdDMTYsNy43MyAxNS44MSw4LjQxIDE1LjQ2LDlIMThDMTguOTUsOSAxOS43NSw5LjY3IDE5Ljk1LDEwLjU2QzIxLjk2LDE4LjU3IDIyLDE4Ljc4IDIyLDE5QTIsMiAwIDAsMSAyMCwyMUg0QTIsMiAwIDAsMSAyLDE5QzIsMTguNzggMi4wNCwxOC41NyA0LjA1LDEwLjU2QzQuMjUsOS42NyA1LjA1LDkgNiw5SDguNTRDOC4xOSw4LjQxIDgsNy43MyA4LDdBNCw0IDAgMCwxIDEyLDNNMTIsNUEyLDIgMCAwLDAgMTAsN0EyLDIgMCAwLDAgMTIsOUEyLDIgMCAwLDAgMTQsN0EyLDIgMCAwLDAgMTIsNVoiIGZpbGw9IndoaXRlIiAvPjwvc3ZnPg==&labelColor=0782ab\">\n \n</br>\n</br>\n\n<a href=\"https://hits.sh/github.com/t8rin/ImageResizer/\">\n\n  <img src=\"https://hits.sh/github.com/t8rin/ImageResizer.svg?style=for-the-badge&label=Page%20Views&extraCount=7500&color=ff3f6f&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGNsYXNzPSJzdmctaWNvbiIgc3R5bGU9IndpZHRoOiAxZW07IGhlaWdodDogMWVtO3ZlcnRpY2FsLWFsaWduOiBtaWRkbGU7ZmlsbDojZmZmZmZmO292ZXJmbG93OiBoaWRkZW47IiB2aWV3Qm94PSIwIDAgMTAyNCAxMDI0IiB2ZXJzaW9uPSIxLjEiPjxwYXRoIGQ9Ik01MTIgMzg0YTEyOCAxMjggMCAwIDAtMTI4IDEyOCAxMjggMTI4IDAgMCAwIDEyOCAxMjggMTI4IDEyOCAwIDAgMCAxMjgtMTI4IDEyOCAxMjggMCAwIDAtMTI4LTEyOG0wIDM0MS4zMzMzMzNhMjEzLjMzMzMzMyAyMTMuMzMzMzMzIDAgMCAxLTIxMy4zMzMzMzMtMjEzLjMzMzMzMyAyMTMuMzMzMzMzIDIxMy4zMzMzMzMgMCAwIDEgMjEzLjMzMzMzMy0yMTMuMzMzMzMzIDIxMy4zMzMzMzMgMjEzLjMzMzMzMyAwIDAgMSAyMTMuMzMzMzMzIDIxMy4zMzMzMzMgMjEzLjMzMzMzMyAyMTMuMzMzMzMzIDAgMCAxLTIxMy4zMzMzMzMgMjEzLjMzMzMzM20wLTUzMy4zMzMzMzNDMjk4LjY2NjY2NyAxOTIgMTE2LjQ4IDMyNC42OTMzMzMgNDIuNjY2NjY3IDUxMmM3My44MTMzMzMgMTg3LjMwNjY2NyAyNTYgMzIwIDQ2OS4zMzMzMzMgMzIwczM5NS41Mi0xMzIuNjkzMzMzIDQ2OS4zMzMzMzMtMzIwYy03My44MTMzMzMtMTg3LjMwNjY2Ny0yNTYtMzIwLTQ2OS4zMzMzMzMtMzIweiIgZmlsbD0iIi8%2BPC9zdmc%2B&labelColor=870b2a\"/>\n  \n</a>\n  \n<a href=\"https://github.com/t8rin/ImageResizer/releases\">\n  \n  <img src=\"https://img.shields.io/github/downloads/t8rin/ImageResizer/total?color=ff9500&style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCI+PHRpdGxlPmRvd25sb2FkPC90aXRsZT48cGF0aCBkPSJNNSwyMEgxOVYxOEg1TTE5LDlIMTVWM0g5VjlINUwxMiwxNkwxOSw5WiIgZmlsbD0id2hpdGUiIC8+PC9zdmc+&labelColor=a6660d\"/>\n  \n</a>\n  \n<a href=\"https://github.com/t8rin/ImageResizer/stargazers\">\n  \n  <img src=\"https://img.shields.io/github/stars/t8rin/imageresizer?color=ffff00&style=for-the-badge&labelColor=a1a116&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCI+PHRpdGxlPnN0YXI8L3RpdGxlPjxwYXRoIGQ9Ik0xMiwxNy4yN0wxOC4xOCwyMUwxNi41NCwxMy45N0wyMiw5LjI0TDE0LjgxLDguNjJMMTIsMkw5LjE5LDguNjJMMiw5LjI0TDcuNDUsMTMuOTdMNS44MiwyMUwxMiwxNy4yN1oiIGZpbGw9IndoaXRlIiAvPjwvc3ZnPg==\"/>\n  \n</a>\n  \n</br>\n\n<a href=\"https://github.com/t8rin/imageresizer/releases/latest\">\n\n  <img src=\"https://img.shields.io/github/v/release/t8rin/imageresizer?color=a1168e&include_prereleases&logo=github&style=for-the-badge&labelColor=700f63\"/>\n  \n</a>\n\n<a href=\"https://play.google.com/store/apps/details?id=ru.tech.imageresizershrinker\">\n\n  <img src=\"https://img.shields.io/endpoint?color=a1168e&logo=google-play&style=for-the-badge&label=Play%20store&url=https%3A%2F%2Fplay.cuzi.workers.dev%2Fplay%3Fi%3Dru.tech.imageresizershrinker%26l%3DAndroid%26m%3D%24version&labelColor=700f63\"/>\n  \n</a>\n\n<a href=\"https://f-droid.org/packages/ru.tech.imageresizershrinker\">\n\n  <img src=\"https://img.shields.io/f-droid/v/ru.tech.imageresizershrinker?color=a1168e&include_prereleases&logo=FDROID&style=for-the-badge&labelColor=700f63\"/>\n  \n</a>\n\n</br>\n</br>\n\n<img src=\"https://wakatime.com/badge/user/7fa5ec35-3afd-4c14-984e-6ea7daf545c7.svg?style=social\" style=\"height: 28px;\"/>\n\n</br>\n</br>\n\n  <a href=\"https://hellogithub.com/repository/4c5f2fae4eb545ab87cad9ffd19870ca\" target=\"_blank\">\n    <img src=\"https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=4c5f2fae4eb545ab87cad9ffd19870ca&claim_uid=ubtZe5aXVz0n2QA&theme=dark\" alt=\"FeaturedÔΩúHelloGitHub\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" />\n  </a>\n  \n\n</p>\n\n<div align=\"center\">\n\n\n# üó∫Ô∏è Project Overview\n\nImageToolbox is a versatile image editing tool designed for efficient photo manipulation. It allows\nusers to crop, apply filters, edit EXIF data, erase backgrounds, and even convert images to PDFs.\nIdeal for both photographers and developers, the tool offers a simple interface with powerful\ncapabilities.\n\n</div>\n\n<p align=\"middle\">\n    <img src=\"./fastlane/metadata/android/en-US/images/banner/banner1.png\" width=\"99%\" />\n    <img src=\"./fastlane/metadata/android/en-US/images/phoneScreenshots/01.png\" width=\"13%\" />\n    <img src=\"./fastlane/metadata/android/en-US/images/phoneScreenshots/02.png\" width=\"13%\" />\n    <img src=\"./fastlane/metadata/android/en-US/images/phoneScreenshots/03.png\" width=\"13%\" />\n    <img src=\"./fastlane/metadata/android/en-US/images/phoneScreenshots/04.png\" width=\"13%\" />\n    <img src=\"./fastlane/metadata/android/en-US/images/phoneScreenshots/05.png\" width=\"13%\" />\n    <img src=\"./fastlane/metadata/android/en-US/images/phoneScreenshots/06.png\" width=\"13%\" />\n    <img src=\"./fastlane/metadata/android/en-US/images/phoneScreenshots/07.png\" width=\"13%\" />\n</p>\n\n<div align=\"center\">\n\n# üìî Wiki\nCheck out Image Toolbox [Wiki](https://github.com/T8RIN/ImageToolbox/wiki) for FAQ and useful info\n</br>\n</br>\n\n# ‚úàÔ∏è Telegram Links\n\n</br>\n\n  [![ImageToolbox Chat](https://img.shields.io/endpoint?&style=for-the-badge&colorA=246732&colorB=A2FFB0&logo=telegram&logoColor=A2FFB0&label=ImageToolbox%20Chat&url=https://tg.sumanjay.workers.dev/t8rin_imagetoolbox)](https://t.me/t8rin_imagetoolbox)\n[![CI Telegram](https://img.shields.io/endpoint?&style=for-the-badge&colorA=29626B&colorB=B5DFE8&logo=telegram&logoColor=B5DFE8&url=https://tg.sumanjay.workers.dev/t8rin_imagetoolbox_ci)](https://t.me/t8rin_imagetoolbox_ci)\n\n\n  </br>\n  </br>\n  Join our chat where you can discuss anything you want and also look into the CI channel where I post betas and announcements\n  </br>\n\n# ‚òï Buy me a coffee\n\nThis application is completely free, but if you want to support the project development, you can\nsend a donation to the crypto wallets below\n\n| </br> ![Bitcoin](https://img.shields.io/badge/Bitcoin-EAB300?style=for-the-badge&logo=Bitcoin%20SV&logoColor=white) <br/> <br/> -> `18QFWMREkjzQa4yetfYsN5Ua51UubKmJut` <- <br/> <br/> | </br> ![Tether](https://img.shields.io/badge/USDT%20(TRC20)-168363?style=for-the-badge&logo=tether&logoColor=white) <br/> <br/> -> `TVdw6fP8dYsYA6HgQiSYNijBqPJ3k5BbYo` <- <br/> <br/> |\n|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n\n# üì≤ Download\n\nGo to the [Releases](https://github.com/t8rin/imageresizer/releases/latest) and the download latest\napk\nor click one of the badges below.\n\n</br>\n\n<p align=\"middle\">\n    <a href=\"https://play.google.com/store/apps/details?id=ru.tech.imageresizershrinker\"><img alt=\"Google Play\" src=\"./fastlane/metadata/android/en-US/images/buttons/gplay.svg\" height=\"60\"></a>\n    <a href=\"https://f-droid.org/packages/ru.tech.imageresizershrinker\"><img alt=\"F-Droid\" src=\"./fastlane/metadata/android/en-US/images/buttons/fdroid.svg\" height=\"60\"/></a>\n    <a href=\"https://github.com/t8rin/imageresizer/releases/latest\"><img alt=\"GitHub\" src=\"./fastlane/metadata/android/en-US/images/buttons/github.svg\" height=\"60\"/></a>\n    <a href=\"https://apps.obtainium.imranr.dev/redirect?r=obtainium://app/%7B%22id%22%3A%22ru.tech.imageresizershrinker%22%2C%22url%22%3A%22https%3A%2F%2Fgithub.com%2FT8RIN%2FImageToolbox%22%2C%22author%22%3A%22T8RIN%22%2C%22name%22%3A%22Image%20Toolbox%22%2C%22preferredApkIndex%22%3A1%2C%22additionalSettings%22%3A%22%7B%5C%22includePrereleases%5C%22%3Afalse%2C%5C%22fallbackToOlderReleases%5C%22%3Atrue%2C%5C%22filterReleaseTitlesByRegEx%5C%22%3A%5C%22%5C%22%2C%5C%22filterReleaseNotesByRegEx%5C%22%3A%5C%22%5C%22%2C%5C%22verifyLatestTag%5C%22%3Afalse%2C%5C%22dontSortReleasesList%5C%22%3Afalse%2C%5C%22useLatestAssetDateAsReleaseDate%5C%22%3Afalse%2C%5C%22trackOnly%5C%22%3Afalse%2C%5C%22versionExtractionRegEx%5C%22%3A%5C%22%5C%22%2C%5C%22matchGroupToUse%5C%22%3A%5C%22%5C%22%2C%5C%22versionDetection%5C%22%3Atrue%2C%5C%22releaseDateAsVersion%5C%22%3Afalse%2C%5C%22useVersionCodeAsOSVersion%5C%22%3Afalse%2C%5C%22apkFilterRegEx%5C%22%3A%5C%22%5C%22%2C%5C%22invertAPKFilter%5C%22%3Afalse%2C%5C%22autoApkFilterByArch%5C%22%3Atrue%2C%5C%22appName%5C%22%3A%5C%22Image%20Toolbox%5C%22%2C%5C%22shizukuPretendToBeGooglePlay%5C%22%3Afalse%2C%5C%22exemptFromBackgroundUpdates%5C%22%3Afalse%2C%5C%22skipUpdateNotifications%5C%22%3Afalse%2C%5C%22about%5C%22%3A%5C%22Image%20Toolbox%20is%20an%20powerful%20picture%20editor%2C%20which%20can%20crop%2C%20apply%20filters%2C%20add%20some%20drawing%2C%20erase%20background%2C%20edit%20EXIF%20or%20even%20create%20PDF%20file.%5C%22%2C%5C%22appAuthor%5C%22%3A%5C%22T8RIN%5C%22%7D%22%7D\"><img alt=\"Obtainium\" src=\"./fastlane/metadata/android/en-US/images/buttons/obtainium.svg\" height=\"60\"/></a>\n    <a href=\"https://apps.obtainium.imranr.dev/redirect?r=obtainium://app/%7B%22id%22%3A%22ru.tech.imageresizershrinker%22%2C%22url%22%3A%22https%3A%2F%2Fgithub.com%2FT8RIN%2FImageToolbox%22%2C%22author%22%3A%22T8RIN%22%2C%22name%22%3A%22Image%20Toolbox%22%2C%22preferredApkIndex%22%3A1%2C%22additionalSettings%22%3A%22%7B%5C%22includePrereleases%5C%22%3Atrue%2C%5C%22fallbackToOlderReleases%5C%22%3Atrue%2C%5C%22filterReleaseTitlesByRegEx%5C%22%3A%5C%22%5C%22%2C%5C%22filterReleaseNotesByRegEx%5C%22%3A%5C%22%5C%22%2C%5C%22verifyLatestTag%5C%22%3Afalse%2C%5C%22dontSortReleasesList%5C%22%3Afalse%2C%5C%22useLatestAssetDateAsReleaseDate%5C%22%3Afalse%2C%5C%22trackOnly%5C%22%3Afalse%2C%5C%22versionExtractionRegEx%5C%22%3A%5C%22%5C%22%2C%5C%22matchGroupToUse%5C%22%3A%5C%22%5C%22%2C%5C%22versionDetection%5C%22%3Atrue%2C%5C%22releaseDateAsVersion%5C%22%3Afalse%2C%5C%22useVersionCodeAsOSVersion%5C%22%3Afalse%2C%5C%22apkFilterRegEx%5C%22%3A%5C%22%5C%22%2C%5C%22invertAPKFilter%5C%22%3Afalse%2C%5C%22autoApkFilterByArch%5C%22%3Atrue%2C%5C%22appName%5C%22%3A%5C%22Image%20Toolbox%5C%22%2C%5C%22shizukuPretendToBeGooglePlay%5C%22%3Afalse%2C%5C%22exemptFromBackgroundUpdates%5C%22%3Afalse%2C%5C%22skipUpdateNotifications%5C%22%3Afalse%2C%5C%22about%5C%22%3A%5C%22Image%20Toolbox%20is%20an%20powerful%20picture%20editor%2C%20which%20can%20crop%2C%20apply%20filters%2C%20add%20some%20drawing%2C%20erase%20background%2C%20edit%20EXIF%20or%20even%20create%20PDF%20file.%5C%22%2C%5C%22appAuthor%5C%22%3A%5C%22T8RIN%5C%22%7D%22%7D\"><img alt=\"Obtainium (Pre-release)\" src=\"./fastlane/metadata/android/en-US/images/buttons/obtainium-pre-release.svg\" height=\"60\"/></a>\n\n</p>\n</div>\n\n# üíª Installation Instructions\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/yourusername/ImageToolbox.git\n   ```\n2. Install dependencies using your preferred package manager (e.g., Gradle).\n3. Build the project:\n   bash ./gradlew build\n4. Run the application:\n   bash ./gradlew run\n\n# ‚öîÔ∏è FOSS vs MARKET\n\n|       **Feature**       |      **FOSS**      |     **Market**     |\n|:-----------------------:|:------------------:|:------------------:|\n|       QR Scanner        |       Zxing        |       MlKit        |\n| Auto Background Remover |        ONNX        |       MlKit        |\n|    Document Scanner     |       OpenCV       |       MlKit        |\n|        Analytics        |        :x:         | :white_check_mark: |\n|       Crashlytics       |        :x:         | :white_check_mark: |\n|    Other Google deps    |        :x:         | :white_check_mark: |\n|   All Other Features    | :white_check_mark: | :white_check_mark: |\n\n# ‚ú® Features\n\n- Batch processing\n- Applying filter chains (More than 310 various filters)\n\n  <details>\n  <summary>Available filters</summary>\n  <br>\n\n    - [x] Saturation\n    - [x] Contrast\n    - [x] Brightness\n    - [x] Exposure\n    - [x] RGB\n    - [x] Hue\n    - [x] White Balance\n    - [x] Monochrome\n    - [x] Black and White\n    - [x] False Color\n    - [x] Sharpen\n    - [x] Gamma\n    - [x] Highlights and Shadows\n    - [x] Haze\n    - [x] Sepia Tone\n    - [x] Color Inversion\n    - [x] Solarize\n    - [x] Vibrance\n    - [x] Luminance Threshold\n    - [x] Pixellate\n    - [x] Halftone\n    - [x] Crosshatch\n    - [x] Sobel Edge Detection\n    - [x] Sketch Filter\n    - [x] Toon Filter\n    - [x] SmoothToon Filter\n    - [x] CGA Colorspace Filter\n    - [x] Posterize\n    - [x] Convolution 3x3\n    - [x] Emboss Filter\n    - [x] Laplacian\n    - [x] Kuwahara Filter\n    - [x] Vignette\n    - [x] Gaussian Blur\n    - [x] Box Blur\n    - [x] Stack Blur\n    - [x] Fast Blur\n    - [x] Bilaterial Blur\n    - [x] Zoom Blur\n    - [x] Median Blur\n    - [x] Pixelation\n    - [x] Enhanced Pixelation\n    - [x] Stroke Pixelation\n    - [x] Circle Pixelation\n    - [x] Enhanced Circle Pixelation\n    - [x] Diamond Pixelation\n    - [x] Enhanced Diamond Pixelation\n    - [x] Swirl Distortion\n    - [x] Bulge Distortion\n    - [x] Sphere Refraction\n    - [x] Glass Sphere Refraction\n    - [x] Dilation\n    - [x] Non Maximum Suppression\n    - [x] Opacity\n    - [x] Weak Pixel Inclusion Filter\n    - [x] Color Matrix 4x4\n    - [x] Lookup\n    - [x] Color Replacement\n    - [x] Color Removance\n    - [x] Bayer Two Dithering\n    - [x] Bayer Three Dithering\n    - [x] Bayer Four Dithering\n    - [x] Bayer Eight Dithering\n    - [x] Floyd Steinberg Dithering\n    - [x] Jarvis Judice Ninke Dithering\n    - [x] Sierra Dithering\n    - [x] Two Row Sierra Dithering\n    - [x] Sierra Lite Dithering\n    - [x] Atkinson Dithering\n    - [x] Stucki Dithering\n    - [x] Burkes Dithering\n    - [x] False Floyd Steinberg Dithering\n    - [x] Left To Right Dithering\n    - [x] Random Dithering\n    - [x] Simple Threshold Dithering\n    - [x] Quantizier\n    - [x] Glitch Effect\n    - [x] Enhanced Glitch Effect\n    - [x] Anaglyph\n    - [x] Noise\n    - [x] Tent Blur\n    - [x] Side Fade\n    - [x] Erode\n    - [x] Anisotropic Diffusion\n    - [x] Horizontal Wind Stagger\n    - [x] Fast Bilaterial Blur\n    - [x] Poisson Blur\n    - [x] Logarithmic Tone Mapping\n    - [x] Aces Filmic Tone Mapping\n    - [x] Crystallize\n    - [x] Fractal Glass\n    - [x] Marble\n    - [x] Oil\n    - [x] Water Effect\n    - [x] Hable Filmic Tone Mapping\n    - [x] Aces Hill Tone Mapping\n    - [x] Hejl Burgess Tone Mapping\n    - [x] Perlin Distortion\n    - [x] Grayscale\n    - [x] Dehaze\n    - [x] Color Matrix 3x3\n    - [x] Achromatomaly\n    - [x] Achromatopsia\n    - [x] Browni\n    - [x] CodaChrome\n    - [x] Cool\n    - [x] Deutaromaly\n    - [x] Deutaronotopia\n    - [x] Night Vision\n    - [x] Polaroid\n    - [x] Protanopia\n    - [x] Protonomaly\n    - [x] Tritanopia\n    - [x] Tritonomaly\n    - [x] Vintage\n    - [x] Warm\n    - [x] Grain\n    - [x] Unsharp\n    - [x] Pastel\n    - [x] Orange Haze\n    - [x] Pink Dream\n    - [x] Golden Hour\n    - [x] Hot Summer\n    - [x] Purple Mist\n    - [x] Sunrise\n    - [x] Colorful Swirl\n    - [x] Soft Spring Light\n    - [x] Autumn Tones\n    - [x] Lavender Dream\n    - [x] Cyberpunk\n    - [x] Lemonade Light\n    - [x] Spectral Fire\n    - [x] Night Magic\n    - [x] Fantasy Landscape\n    - [x] Color Explosion\n    - [x] Electric Gradient\n    - [x] Caramel Darkness\n    - [x] Futuristic Gradient\n    - [x] Green Sun\n    - [x] Rainbow World\n    - [x] Deep Purple\n    - [x] Space Portal\n    - [x] Red Swirl\n    - [x] Digital Code\n    - [x] Bokeh\n    - [x] Neon\n    - [x] Old Tv\n    - [x] Shuffle Blur\n    - [x] Mobius\n    - [x] Uchimura\n    - [x] Aldridge\n    - [x] Drago\n    - [x] Color Anomaly\n    - [x] Quantizier\n    - [x] Ring Blur\n    - [x] Cross Blur\n    - [x] Circle Blur\n    - [x] Star Blur\n    - [x] Motion Blur\n    - [x] Fast Gaussian Blur 2D\n    - [x] Fast Gaussian Blur 3D\n    - [x] Fast Gaussian Blur 4D\n    - [x] Equalize Histogram\n    - [x] Equalize Histogram HSV\n    - [x] Equalize Histogram Pixelation\n    - [x] Equalize Histogram Adaptive\n    - [x] Equalize Histogram Adaptive LUV\n    - [x] Equalize Histogram Adaptive LAB\n    - [x] Equalize Histogram Adaptive HSV\n    - [x] Equalize Histogram Adaptive HSL\n    - [x] Clahe\n    - [x] Clahe LUV\n    - [x] Clahe LAB\n    - [x] Clahe HSL\n    - [x] Clahe HSV\n    - [x] Crop To Content\n    - [x] Linear Box Blur\n    - [x] Linear Tent Blur\n    - [x] Linear Gaussian Box Blur\n    - [x] Linear Stack Blur\n    - [x] Gaussian Box Blur\n    - [x] Linear Fast Gaussian Next\n    - [x] LinearFast Gaussian\n    - [x] Linear Gaussian\n    - [x] Low Poly\n    - [x] Sand Painting\n    - [x] Palette Transfer\n    - [x] Enhanced Oil\n    - [x] Simple Old TV\n    - [x] HDR\n    - [x] Simple Sketch\n    - [x] Gotham\n    - [x] Color Poster\n    - [x] Tri Tone\n    - [x] Clahe Oklch\n    - [x] Clahe Jzazbz\n    - [x] Clahe Oklab\n    - [x] Yililoma Dithering\n    - [x] Clustered 2x2 Dithering\n    - [x] Clustered 4x4 Dithering\n    - [x] Clustered8x8 Dithering\n    - [x] Polka Dot\n    - [x] LUT 512\\*512\n    - [x] Amatorka\n    - [x] Miss Etikate\n    - [x] Soft Elegance\n    - [x] Soft Elegance Variant\n    - [x] Bleach Bypass\n    - [x] Candlelight\n    - [x] Drop Blues\n    - [x] Edgy Amber\n    - [x] Fall Colors\n    - [x] Film Stock 50\n    - [x] Foggy Night\n    - [x] Kodak\n    - [x] Palette Transfer Variant\n    - [x] 3D LUT (.cube / .CUBE)\n    - [x] Pop Art\n    - [x] Celluloid\n    - [x] Coffee\n    - [x] Golden Forest\n    - [x] Greenish\n    - [x] Retro Yellow\n    - [x] Auto Crop\n    - [x] Opening\n    - [x] Closing\n    - [x] Morphological Gradient\n    - [x] Top Hat\n    - [x] Black Hat\n    - [x] Enhanced Zoom Blur\n    - [x] Simple Sobel\n    - [x] Simple Laplacian\n    - [x] Auto Red Eyes remover\n    - [x] Tone Curves \n    - [x] Mirror\n    - [x] Kaleidoscope  \n    - [x] Channel Mix  \n    - [x] Color Halftone  \n    - [x] Contour  \n    - [x] Voronoi Crystallize  \n    - [x] Despeckle  \n    - [x] Diffuse  \n    - [x] DoG  \n    - [x] Equalize  \n    - [x] Glow  \n    - [x] Offset  \n    - [x] Pinch  \n    - [x] Pointillize  \n    - [x] Polar Coordinates  \n    - [x] Reduce Noise  \n    - [x] Simple Solarize  \n    - [x] Weave  \n    - [x] Twirl  \n    - [x] Rubber Stamp  \n    - [x] Smear  \n    - [x] Sphere Lens Distortion  \n    - [x] Arc  \n    - [x] Sparkle\n    - [x] ASCII\n    - [x] Moire\n    - [x] Autumn\n    - [x] Bone\n    - [x] Jet\n    - [x] Winter\n    - [x] Rainbow\n    - [x] Ocean\n    - [x] Summer\n    - [x] Spring\n    - [x] Cool Variant \n    - [x] Hsv\n    - [x] Pink\n    - [x] Hot\n    - [x] Parula\n    - [x] Magma\n    - [x] Inferno\n    - [x] Plasma\n    - [x] Viridis\n    - [x] Cividis\n    - [x] Twilight\n    - [x] Twilight Shifted\n    - [x] Deskew\n    - [x] Auto Perspective\n    - [x] Crop Or Perspective\n    - [x] Turbo\n    - [x] Deep Green \n    - [x] Lens Correction\n    - [x] Seam Carving\n    - [x] Error Level Analysis\n    - [x] Luminance Gradient\n    - [x] Average Distance\n    - [x] Copy Move Detection\n    - [x] Simple Weave Pixelization\n    - [x] Staggered Pixelization\n    - [x] Cross Pixelization\n    - [x] Micro Macro Pixelization\n    - [x] Orbital Pixelization\n    - [x] Vortex Pixelization\n    - [x] Pulse Grid Pixelization\n    - [x] Nucleus Pixelization\n    - [x] Radial Weave Pixelization\n    - [x] Border Frame\n    - [x] Glitch Variant\n    - [x] VHS\n    - [x] Block Glitch\n    - [x] Crt Curvature\n    - [x] Pixel Melt\n\n\n  </details>\n\n- Custom Filters Creation by Template filters\n    - You can create filter from any filter chain\n    - Share created filters by QR code\n    - Scan filters from the app to get them on your device\n- Files encryption and decryption with 100+ different algorithms available\n- Adding Stickers and Text (Markup Layers Mode)\n- Extract Text From Images (OCR)\n    - 120+ languages\n    - 3 Type of data: Fast, Standard, Best\n    - Segmentation Mode Selection\n    - Engine Mode Selection\n    - Custom Tesseract options entering\n    - Multiple languages at the same time\n    - Reading from batch of images to file\n    - Placing in EXIF metadata of batch images\n- EXIF metadata editing/deleting\n- Loading images from internet\n- Image Stitching\n- Image Stacking\n- Image Splitting\n- Background Removal\n    - By drawing\n  - Automatically (MlKit, U2NetP, U2Net, RMBG, InSPyReNet, BiRefNet, ISNet)\n- Watermarking\n    - Repeating Text\n    - Image\n    - Stamp\n    - Timestamp\n    - Digital (Steganography)\n- Drawing on Image/Background\n    - Pen\n    - Flood Fil\n    - Spray\n    - Neon\n    - Highlighter\n    - Privacy Blur\n    - Pixelation Paint\n    - Text\n    - Image Brush\n    - Filter Brush\n    - Spot Healing (with ability to download AI model for generative inpainting)\n    - Pointing Arrow\n    - Line\n    - Double Pointing Arrow\n    - Line Pointing Arrow\n    - Double Line Pointing Arrow\n    - Outlined Rect\n    - Outlined Oval\n    - Outlined Triangle\n    - Outlined Polygon\n    - Outlined Star\n    - Rect\n    - Oval\n    - Triangle\n    - Polygon\n    - Star\n    - Lasso\n    - Line Style\n        - Dashed\n        - Dot Dashed\n        - Zigzag\n        - Stamped\n- Image Resizing\n    - Width changing\n    - Height changing\n    - Adaptive resize\n    - Resize retaining aspect ratio\n    - Resize by given limits\n    - Center Crop with\n        - Background color changing\n        - Background blur drawing\n    - Different Scaling Algorithms\n\n      <details>\n      <summary>Available methods</summary>\n      <br>\n\n      - Bilinear\n      - Nearest Neighbour\n      - Cubic\n      - Mitchell-Netravalli\n      - Catmull-Rom\n      - Hermite\n      - B-Spline\n      - Hann\n      - Bicubic\n      - Hamming\n      - Hanning\n      - Blackman\n      - Welch\n      - Quadric\n      - Gaussian\n      - Sphinx\n      - Bartlett\n      - Robidoux\n      - Robidoux Sharp\n      - Spline 16\n      - Spline 36\n      - Spline 64\n      - Kaiser\n      - Bartlett-Hann\n      - Box\n      - Bohman\n      - Lanczos 2\n      - Lanczos 3\n      - Lanczos 4\n      - Lanczos 2 Jinc\n      - Lanczos 3 Jinc\n      - Lanczos 4 Jinc\n      - Ewa Hanning\n      - Ewa Robidoux\n      - Ewa Blackman\n      - Ewa Quadric\n      - Ewa Robidoux Sharp\n      - Ewa Lanczos 3 Jinc\n      - Ginseng\n      - Ginseng EWA\n      - Lanczos Sharp EWA\n      - Lanczos 4 Sharpest EWA\n      - Lanczos Soft EWA\n      - Haasn Soft\n      - Lagrange 2\n      - Lagrange 3\n      - Lanczos 6\n      - Lanczos 6 Jinc\n\n      </details>\n\n    - Different Scale Color Spaces\n        - Linear\n        - sRGB\n        - LAB\n        - LUV\n        - Sigmoidal\n        - XYZ\n        - F32 Gamma 2.2\n        - F32 Gamma 2.8\n        - F32 Rec.709\n        - F32 sRGB\n        - LCH\n        - Oklab sRGB\n        - Oklab Rec.709\n        - Oklab Gamma 2.2\n        - Oklab Gamma 2.8\n        - Jzazbz sRGB\n        - Jzazbz Rec.709\n        - Jzazbz Gamma 2.2\n        - Jzazbz Gamma 2.8\n- GIF conversion\n    - GIF to images\n    - Images to GIF\n    - GIF to WEBP\n- WEBP conversion\n    - WEBP to images\n    - Images to WEBP\n- APNG conversion\n    - APNG to images\n    - Images to APNG\n- JXL transcoding\n    - JXL to JPEG\n    - JPEG to JXL\n- Animated JXL conversion\n    - Images to JXL\n    - JXL to Images\n    - APNG to JXL\n    - GIF to JXL\n- PDF tools\n    - PDF to images\n    - Images to PDF\n    - PDF previewing\n- Document Scanning\n- AI tools (81 ready to use models available)\n    - Upscale\n    - Remove BG\n    - DeJPEG\n    - DeNoise\n    - Colorize\n    - Artifacts\n    - Enhance\n    - Anime\n    - Scans\n- Barcodes\n    - Scanning\n    - Creating & Parsing common types\n      - Plain\n      - Url\n      - WiFi\n      - Email\n      - Geolocation\n      - Phone\n      - SMS\n      - Contact (vCard)\n      - Calendar event\n    - Sharing as images\n    - 13 formats available\n      - QR CODE\n      - AZTEC\n      - CODABAR\n      - CODE 39\n      - CODE 93\n      - CODE 128\n      - DATA MATRIX\n      - EAN 8\n      - EAN 13\n      - ITF\n      - PDF 417\n      - UPC A\n      - UPC E\n- Collage Creation\n    - From 2 to 10 images\n    - More than 180 various collage layouts\n- Image Shrinking\n    - Quality compressing\n    - Preset shrinking\n    - Reducing size by given weight (in KB)\n- Cropping\n    - Regular crop\n    - Free rotation crop\n    - Free corners crop (can be used as Perspective Correction)\n    - Crop by aspect ratio\n    - Crop with shape mask\n        \n        <details>\n          <summary>List of shapes</summary>\n          <br/>\n          \n        - Rounded Corners\n        - Cut Corners\n        - Oval\n        - Squircle\n        - Octagon\n        - Rounded Pentagon\n        - Clover\n        - Material Star\n        - Kotlin Logo\n        - Small Material Star\n        - Heart\n        - Shuriken\n        - Explosion\n        - Bookmark\n        - Pill\n        - Burger\n        - Shield\n        - Droplet\n        - Arrow\n        - Egg\n        - Map\n        - Enhanced Heart\n        - Star\n        - Image Mask\n        - <details>\n          <summary>Additional Shapes</summary>\n          </br>\n        \n          ![image](./fastlane/metadata/android/en-US/images/banner/banner_shapes.png)\n\n          </details>\n        \n        </details>\n\n\n- Image Cutting (can be used as batch crop)         \n- Tracing raster images to SVG\n- Format Conversion\n    - HEIF\n    - HEIC\n    - AVIF\n    - WEBP\n    - JPEG\n    - JPG\n    - PNG Lossless\n    - PNG Lossy\n    - MozJpeg\n    - Jpegli\n    - JXL\n    - JP2\n    - J2K\n    - TIFF\n    - TIF\n    - QOI\n    - ICO\n    - SVG, DNG, PSD, GIF to static raster images\n    - Telegram sticker PNG format\n- Files to Zip\n- Comparing images\n    - Slide\n    - Toggle Tap\n    - Transparency\n    - Side By Side\n    - Pixel By Pixel (7 Methods)\n        - SSIM\n        - AE\n        - MAE\n        - NCC\n        - PSNR\n        - RMSE\n- Color Utils\n    - Palette generation\n        - Material You Scheme\n        - Simple Colors\n    - Import/Export palette across 41 format\n      - ACB\n      - ACO\n      - ACT  \n      - Android Xml  \n      - ASE\n      - Basic Xml  \n      - Corel Painter  \n      - Corel Draw  \n      - Scribus Xml  \n      - Corel Palette  \n      - CSV\n      - DCP\n      - Gimp\n      - Hex Rgba  \n      - Image  \n      - Json  \n      - Open Office  \n      - Paint Net  \n      - Paint Shop Pro  \n      - Rgba  \n      - Rgb  \n      - Riff  \n      - Sketch  \n      - SKP\n      - SVG  \n      - Swift  \n      - Kotlin  \n      - Corel Draw V3  \n      - CLF\n      - Swatches  \n      - Autodesk Color Book  \n      - Simple Palette  \n      - Swatchbooker  \n      - Afpalette  \n      - Xara  \n      - Koffice\n      - KPL\n      - HPL\n      - Skencil  \n      - Vga 24Bit  \n      - Vga 18Bit  \n    - Picking color from image\n    - Gradient creation (Mesh gradients too)\n    - Overlaying image with gradient\n    - Mixing\n    - Conversion\n    - Harmonies\n    - Shading\n    - Tone Curves applying\n- Histograms\n    - RGB\n    - Brightness\n    - Camera Like RGB\n- Image source selection\n- Additional Features\n    - Base64 Decode/Encode\n    - Rotating\n    - Flipping\n    - Perlin Noise Generation\n    - Previewing SVG, DNG, PSD, DJVU and almost all types of images\n    - Saving to any specific folder\n    - Long press on save to choose one time output folder\n    - Randomizing output filename\n    - Using image cheksum as filename\n    - Checksum Tools with ability to calculate and compare hashes\n    - 64 different hashing algorithms\n    - Audio files Album Cover export\n    - Embedded media picker\n    - Wallpapers Export\n    - Ascii Art\n\n**And More!**\n\n#\n\n<img src=\"./fastlane/metadata/android/en-US/images/banner/banner2.png\" width=\"99%\" />\n\n# üåü UI tweaks\n\n- Selecting Emoji for top app bar\n- Ability to use Pixel like switch instead of Material You\n- Secure Mode for app\n- Maximum brightness for selected screens\n- In app language changing\n- Enabling or Disabling confetti\n- Custom app color scheme\n    - Different palette styles\n    - Predefined schemes\n    - Color inversion\n    - Contrast adjusting\n- Controlling borders thickness\n- Enabling and disabling each existing shadow\n- Haptics controls\n- Light/Dark mode\n- AMOLED mode\n- Monet implementation (Dynamic colors) even for Android versions less than 12\n  by [Dynamic Theme](https://github.com/T8RIN/DynamicTheme)\n- Image based color scheme\n- Icons Background shape selection\n    - Rounded Corners\n    - Cut Corners\n    - Oval\n    - Squircle\n    - Octagon\n    - Rounded Pentagon\n    - Clover\n    - Material Star\n    - Small Material Star\n    - Heart\n    - Enhanced Heart\n- Custom fonts\n\n  <details>\n  <summary>Preinstalled fonts</summary>\n  <br>\n\n    - Montserrat\n    - Comfortaa\n    - Caveat\n    - Handjet\n    - Jura\n    - Podkova\n    - Tektur\n    - YsabeauSC\n    - DejaVu\n    - BadScript\n    - RuslanDisplay\n    - Catterdale\n    - FRM32\n    - Tokeely Brookings\n    - Nunito\n    - Nothing\n    - WOPR Tweaked\n    - Alegreya Sans\n    - Minecraft Gnu\n    - Granite Fixed\n    - Nokia Pixel\n    - Ztivalia\n    - Axotrel\n    - Lcd Octagon\n    - Lcd Moving\n    - Unisource\n\n  </details>\n\n- Ability to import any font (OTF/TTF) to further use\n- In app font scale changing\n- Changing between options list and grouped view\n- Confetti Type selection\n    - Default\n    - Festive\n    - Explode\n    - Rain\n    - Side\n    - Corners\n    - ImageToolbox\n- Switch Type selection:\n    - Material You\n    - Compose\n    - Pixel\n    - Fluent\n    - Cupertino\n    - Liquid Glas\n    - HyperOS\n- Slider Type Selection:\n    - Fancy\n    - Material You\n    - Material\n    - HyperOS\n- Main screen layout customization\n\n(Yes, the app supports dynamic coloring based on wallpapers for every android version)\n\n# üìö Tech stack & Open-source libraries\n\n- Minimum SDK level 23\n\n- [Kotlin](https://kotlinlang.org/) based\n\n- [Image Toolbox Libs](https://github.com/T8RIN/ImageToolboxLibs) - set of essential libraries for\n  Image Toolbox.\n\n- [Dynamic Theme](https://github.com/T8RIN/DynamicTheme) - library, which allows you to easily\n  implement custom color theming.\n\n- [Modal Sheet](https://github.com/T8RIN/ModalSheet) - modal bottom sheet that follows M3\n  guidelines.\n\n- [Coroutines](https://github.com/Kotlin/kotlinx.coroutines) for asynchronous work.\n\n- [Flow](https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines.flow/)\n  to emit values from data layer reactively.\n\n- [Accompanist](https://github.com/google/accompanist) to expand jetpack compose opportunities.\n\n- [Decompose](https://github.com/arkivanov/Decompose) - KMP lifecycle-aware business logic\n  components (aka BLoCs) with routing (navigation) and pluggable UI\n\n- [Hilt](https://dagger.dev/hilt/) for dependency injection.\n\n- [Coil](https://github.com/coil-kt/coil) for loading images.\n\n- [Konfetti](https://github.com/DanielMartinus/Konfetti) to establish beautiful particle system.\n\n- Jetpack\n\n    - [Compose](https://developer.android.com/jetpack/compose) - Modern Declarative UI style\n      framework based on composable functions.\n\n    - [Material You Kit](https://developer.android.com/jetpack/androidx/releases/compose-material3) -\n      Material 3 powerful UI components.\n\n    - [Data Store](https://developer.android.com/jetpack/androidx/releases/datastore) - Store data\n      asynchronously, consistently, and transactionally.\n\n    - [Lifecycle](https://developer.android.com/jetpack/androidx/releases/lifecycle) - Observe\n      Android lifecycles and handle UI states upon the lifecycle changes.\n\n    - [Exif Interface](https://developer.android.com/jetpack/androidx/releases/exifinterface) - Read\n      and write image file EXIF tags.\n\n- [GPU Image](https://github.com/cats-oss/android-gpuimage) for creating and applying filters to the\n  images.\n\n- [SmartToolFactory](https://github.com/SmartToolFactory) provides a bunch of helpful libraries.\n\n- [AVIF Coder](https://github.com/awxkee/avif-coder)\n  and [JXL Coder](https://github.com/awxkee/jxl-coder) libraries which provide avif, heic, heif and\n  jxl support.\n\n- [Aire](https://github.com/awxkee/aire) and [Trickle](https://github.com/T8RIN/Trickle) for\n  creating and applying filters to the images on CPU\n  using native cpp code.\n\n\n# üìê App Architecture\n\nSee Modules Graph at [ARCHITECTURE.md](https://github.com/T8RIN/ImageToolbox/blob/master/ARCHITECTURE.md)\n\n<div align=\"center\">\n\n#\n\n<img src=\"./fastlane/metadata/android/en-US/images/banner/banner3.png\" width=\"99%\" />\n\n# üåê Translation\n\nYou can help translate Image Toolbox into your language\non [Hosted Weblate](https://hosted.weblate.org/engage/image-resizer/)\n\n[![–°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞](https://hosted.weblate.org/widgets/image-resizer/-/horizontal-auto.svg)](https://hosted.weblate.org/engage/image-resizer/)\n</br>\n[![Translation status](https://hosted.weblate.org/widgets/image-resizer/-/image-resizer/287x66-black.png)](https://hosted.weblate.org/engage/image-resizer/)\n\n# ‚ù§Ô∏è Find this repository useful?\n\nSupport it by joining **[stargazers](https://github.com/t8rin/ImageToolbox/stargazers)** for this\nrepository. :star: <br>\nAnd **[follow](https://github.com/t8rin)** me for my next creations! ü§©\n\n# ‚≠ê Star History\n\n<a href=\"https://star-history.com/#T8RIN/ImageToolbox&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=T8RIN/ImageToolbox&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=T8RIN/ImageToolbox&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=T8RIN/ImageToolbox&type=Date\" />\n </picture>\n</a>\n\n![](https://repobeats.axiom.co/api/embed/c62092c6ec0d00e67496223d50e39f48a582c532.svg)\n\n# üì¢ Contributors\n\n<a href=\"https://github.com/t8rin/imageresizer/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=t8rin/Imageresizer\" />\n</a>\n\n# üîí Signing Certificate Hashes\n\nSHA-256: `20d7689de0874f00015ea3e31fa067c15c03457d362d41d5e793db3a864fa534`\n\nSHA-1: `d69eacb30eeae804e8b72d2384c3c616b1906785`\n\nMD5: `db6f6b76c503d31099e4754e676353cf`\n\nFor more info, see [wiki](https://github.com/T8RIN/ImageToolbox/wiki/FAQ#how-can-i-verify-my-download-of-imagetoolbox-is-legitimate)\n\n# ‚öñÔ∏è License\n\n```xml\nDesigned and developed by 2023 T8RIN\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");you may not use this file except in compliance with the License.You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.\n```\n",
      "stars_today": 31
    },
    {
      "id": 189285554,
      "name": "stats",
      "full_name": "exelban/stats",
      "description": "macOS system monitor in your menu bar",
      "html_url": "https://github.com/exelban/stats",
      "stars": 35819,
      "forks": 1144,
      "language": "Swift",
      "topics": [
        "battery",
        "bluetooth",
        "clock",
        "cpu",
        "disk",
        "fans",
        "gpu",
        "macos",
        "menubar",
        "monitor",
        "network",
        "sensors",
        "stats",
        "temperature"
      ],
      "created_at": "2019-05-29T19:24:56Z",
      "updated_at": "2026-01-17T00:09:57Z",
      "pushed_at": "2026-01-11T14:45:42Z",
      "open_issues": 30,
      "owner": {
        "login": "exelban",
        "avatar_url": "https://avatars.githubusercontent.com/u/13332412?v=4"
      },
      "readme": "<div align=\"center\" markdown=\"1\">\n <sup>Special thanks to:</sup>\n <br><br>\n <a href=\"https://go.warp.dev/stats\">\n  <img width=\"400\" alt=\"Warp sponsorship\" src=\"https://github.com/user-attachments/assets/67ff3655-983d-43cf-9e99-51ce76afa3e7\"/>\n </a>\n <br><br>\n <a href=\"https://go.warp.dev/stats\">Warp is built for coding with multiple AI agents</a>\n</div>\n\n---\n\n# Stats\n\n<a href=\"https://github.com/exelban/stats/releases\"><p align=\"center\"><img src=\"https://github.com/exelban/stats/raw/master/Stats/Supporting%20Files/Assets.xcassets/AppIcon.appiconset/icon_256x256.png\" width=\"120\"></p></a>\n\n[![Stats](https://serhiy.s3.eu-central-1.amazonaws.com/Github_repo/stats/menus%3Fv2.3.2.png?v1)](https://github.com/exelban/stats/releases)\n[![Stats](https://serhiy.s3.eu-central-1.amazonaws.com/Github_repo/stats/popups%3Fv2.3.2.png?v3)](https://github.com/exelban/stats/releases)\n\nmacOS system monitor in your menu bar\n\n## Installation\n### Manual\nYou can download the latest version [here](https://github.com/exelban/stats/releases/latest/download/Stats.dmg).\nThis will download a file called `Stats.dmg`. Open it and move the app to the application folder.\n\n### Homebrew\nTo install it using Homebrew, open the Terminal app and type:\n```bash\nbrew install stats\n```\n\n### Legacy version\nLegacy version for older systems could be found [here](https://mac-stats.com/downloads).\n\n## Requirements\nStats is supported on the released macOS version starting from macOS 10.15 (Catalina).\n\n## Features\nStats is an application that allows you to monitor your macOS system.\n\n - CPU utilization\n - GPU utilization\n - Memory usage\n - Disk utilization\n - Network usage\n - Battery level\n - Fan's control (not maintained)\n - Sensors information (Temperature/Voltage/Power)\n - Bluetooth devices\n - Multiple time zone clock\n\n## FAQs\n\n### How do you change the order of the menu bar icons?\nmacOS decides the order of the menu bar items not `Stats` - it may change after the first reboot after installing Stats.\n\nTo change the order of any menu bar icon - macOS Mojave (version 10.14) and up.\n\n1. Hold down ‚åò (command key).\n2. Drag the icon to the desired position on the menu bar.\n3. Release ‚åò (command key)\n\n### How to reduce energy impact or CPU usage of Stats?\nStats tries to be efficient as it's possible. But reading some data periodically is not a cheap task. Each module has its own \"price\". So, if you want to reduce energy impact from the Stats you need to disable some Stats modules. The most inefficient modules are Sensors and Bluetooth. Disabling these modules could reduce CPU usage and power efficiency by up to 50% in some cases.\n\n### Fan control\nFan control is in legacy mode. It does not receive any updates or fixes. It's not dropped from the app just because in the old Macs it works pretty acceptable. I'm open to accepting fixed or improvements (via PR) for this feature in case someone would like to help with that. But have no option and time to provide support for this feature.\n\n### Sensors show incorrect CPU/GPU core count\nCPU/GPU sensors are simply thermal zones (sensors) on the CPU/GPU. They have no relation to the number of cores or specific cores.\nFor example, a CPU is typically divided into two clusters: efficiency and performance. Each cluster contains multiple temperature sensors, and Stats simply displays these sensors. However, \"CPU Efficient Core 1\" does not represent the temperature of a single efficient core‚Äîit only indicates one of the temperature sensors within the efficiency core cluster.\nAdditionally, with each new SoC, Apple changes the sensor keys. As a result, it takes time to determine which SMC values correspond to the appropriate sensors. If anyone knows how to accurately match the sensors for Apple Silicon, please contact me.\n\n### App crash ‚Äì what to do?\nFirst, ensure that you are using the latest version of Stats. There is a high chance that a fix preventing the crash has already been released. If you are already running the latest version, check the open issues. Only if none of the existing issues address your problem should you open a new issue.\n\n### Why my issue was closed without any response?\nMost probably because it's a duplicated issue and there is an answer to the question, report, or proposition. Please use a search by closed issues to get an answer.\nSo, if your issue was closed without any response, most probably it already has a response.\n\n### External API\nStats uses some external APIs, such as:\n\n- https://api.mac-stats.com ‚Äì For update checks and retrieving the public IP address\n- https://api.github.com ‚Äì Fallback for update checks\n\nBoth of these APIs are used to check for updates. Additionally, an external request is required to obtain the public IP address. I do not want to use any third-party providers for retrieving the public IP address, so I use my own server for this purpose.\n\nIf you have concerns about these requests, you have a few options:\n\n- propose a PR that allows these features to work without an external server\n- block both of these servers using any network filtering app (if you're reading this, you're likely using something like Little Snitch, so you can easily do this). In this case do not expect to receive any updates or see your public IP in the network module.\n\n\n## Supported languages\n- English\n- Polski\n- –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞\n- –†—É—Å—Å–∫–∏–π\n- ‰∏≠Êñá (ÁÆÄ‰Ωì) (thanks to [chenguokai](https://github.com/chenguokai), [Tai-Zhou](https://github.com/Tai-Zhou), and [Jerry](https://github.com/Jerry23011))\n- T√ºrk√ße (thanks to [yusufozgul](https://github.com/yusufozgul) and [setanarut](https://github.com/setanarut))\n- ÌïúÍµ≠Ïñ¥ (thanks to [escapeanaemia](https://github.com/escapeanaemia) and [iamhslee](https://github.com/iamhslee))\n- German (thanks to [natterstefan](https://github.com/natterstefan) and [aneitel](https://github.com/aneitel))\n- ‰∏≠Êñá (ÁπÅÈ´î) (thanks to [iamch15542](https://github.com/iamch15542) and [jrthsr700tmax](https://github.com/jrthsr700tmax))\n- Spanish (thanks to [jcconca](https://github.com/jcconca))\n- Vietnamese (thanks to [HXD.VN](https://github.com/xuandung38))\n- French (thanks to [RomainLt](https://github.com/RomainLt))\n- Italian (thanks to [gmcinalli](https://github.com/gmcinalli))\n- Portuguese (Brazil) (thanks to [marcelochaves95](https://github.com/marcelochaves95) and [pedroserigatto](https://github.com/pedroserigatto))\n- Norwegian Bokm√•l (thanks to [rubjo](https://github.com/rubjo))\n- Êó•Êú¨Ë™û (thanks to [treastrain](https://github.com/treastrain))\n- Portuguese (Portugal) (thanks to [AdamModus](https://github.com/AdamModus))\n- Czech (thanks to [mpl75](https://github.com/mpl75))\n- Magyar (thanks to [moriczr](https://github.com/moriczr))\n- Bulgarian (thanks to [zbrox](https://github.com/zbrox))\n- Romanian (thanks to [razluta](https://github.com/razluta))\n- Dutch (thanks to [ngohungphuc](https://github.com/ngohungphuc))\n- Hrvatski (thanks to [milotype](https://github.com/milotype))\n- Danish (thanks to [casperes1996](https://github.com/casperes1996) and [aleksanderbl29](https://github.com/aleksanderbl29))\n- Catalan (thanks to [davidalonso](https://github.com/davidalonso))\n- Indonesian (thanks to [yooody](https://github.com/yooody))\n- Hebrew (thanks to [BadSugar](https://github.com/BadSugar))\n- Slovenian (thanks to [zigapovhe](https://github.com/zigapovhe))\n- Greek (thanks to [sudoxcess](https://github.com/sudoxcess) and [vaionicle](https://github.com/vaionicle))\n- Persian (thanks to [ShawnAlisson](https://github.com/ShawnAlisson))\n- Slovensk√Ω (thanks to [martinbernat](https://github.com/martinbernat))\n- Thai (thanks to [apiphoomchu](https://github.com/apiphoomchu))\n- Estonian (thanks to [postylem](https://github.com/postylem))\n- Hindi (thanks to [patiljignesh](https://github.com/patiljignesh))\n- Finnish (thanks to [eightscrow](https://github.com/eightscrow))\n\nYou can help by adding a new language or improving the existing translation.\n\n## License\n[MIT License](https://github.com/exelban/stats/blob/master/LICENSE)\n",
      "stars_today": 30
    },
    {
      "id": 359952601,
      "name": "pgvector",
      "full_name": "pgvector/pgvector",
      "description": "Open-source vector similarity search for Postgres",
      "html_url": "https://github.com/pgvector/pgvector",
      "stars": 19300,
      "forks": 1027,
      "language": "C",
      "topics": [
        "approximate-nearest-neighbor-search",
        "nearest-neighbor-search"
      ],
      "created_at": "2021-04-20T21:13:52Z",
      "updated_at": "2026-01-16T22:58:00Z",
      "pushed_at": "2026-01-16T04:46:05Z",
      "open_issues": 13,
      "owner": {
        "login": "pgvector",
        "avatar_url": "https://avatars.githubusercontent.com/u/98363230?v=4"
      },
      "readme": "# pgvector\n\nOpen-source vector similarity search for Postgres\n\nStore your vectors with the rest of your data. Supports:\n\n- exact and approximate nearest neighbor search\n- single-precision, half-precision, binary, and sparse vectors\n- L2 distance, inner product, cosine distance, L1 distance, Hamming distance, and Jaccard distance\n- any [language](#languages) with a Postgres client\n\nPlus [ACID](https://en.wikipedia.org/wiki/ACID) compliance, point-in-time recovery, JOINs, and all of the other [great features](https://www.postgresql.org/about/) of Postgres\n\n[![Build Status](https://github.com/pgvector/pgvector/actions/workflows/build.yml/badge.svg)](https://github.com/pgvector/pgvector/actions)\n\n## Installation\n\n### Linux and Mac\n\nCompile and install the extension (supports Postgres 13+)\n\n```sh\ncd /tmp\ngit clone --branch v0.8.1 https://github.com/pgvector/pgvector.git\ncd pgvector\nmake\nmake install # may need sudo\n```\n\nSee the [installation notes](#installation-notes---linux-and-mac) if you run into issues\n\nYou can also install it with [Docker](#docker), [Homebrew](#homebrew), [PGXN](#pgxn), [APT](#apt), [Yum](#yum), [pkg](#pkg), [APK](#apk), or [conda-forge](#conda-forge), and it comes preinstalled with [Postgres.app](#postgresapp) and many [hosted providers](#hosted-postgres). There are also instructions for [GitHub Actions](https://github.com/pgvector/setup-pgvector).\n\n### Windows\n\nEnsure [C++ support in Visual Studio](https://learn.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-170#download-and-install-the-tools) is installed and run `x64 Native Tools Command Prompt for VS [version]` as administrator. Then use `nmake` to build:\n\n```cmd\nset \"PGROOT=C:\\Program Files\\PostgreSQL\\18\"\ncd %TEMP%\ngit clone --branch v0.8.1 https://github.com/pgvector/pgvector.git\ncd pgvector\nnmake /F Makefile.win\nnmake /F Makefile.win install\n```\n\nSee the [installation notes](#installation-notes---windows) if you run into issues\n\nYou can also install it with [Docker](#docker) or [conda-forge](#conda-forge).\n\n## Getting Started\n\nEnable the extension (do this once in each database where you want to use it)\n\n```tsql\nCREATE EXTENSION vector;\n```\n\nCreate a vector column with 3 dimensions\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding vector(3));\n```\n\nInsert vectors\n\n```sql\nINSERT INTO items (embedding) VALUES ('[1,2,3]'), ('[4,5,6]');\n```\n\nGet the nearest neighbors by L2 distance\n\n```sql\nSELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\nAlso supports inner product (`<#>`), cosine distance (`<=>`), and L1 distance (`<+>`)\n\nNote: `<#>` returns the negative inner product since Postgres only supports `ASC` order index scans on operators\n\n## Storing\n\nCreate a new table with a vector column\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding vector(3));\n```\n\nOr add a vector column to an existing table\n\n```sql\nALTER TABLE items ADD COLUMN embedding vector(3);\n```\n\nAlso supports [half-precision](#half-precision-vectors), [binary](#binary-vectors), and [sparse](#sparse-vectors) vectors\n\nInsert vectors\n\n```sql\nINSERT INTO items (embedding) VALUES ('[1,2,3]'), ('[4,5,6]');\n```\n\nOr load vectors in bulk using `COPY` ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/loading/example.py))\n\n```sql\nCOPY items (embedding) FROM STDIN WITH (FORMAT BINARY);\n```\n\nUpsert vectors\n\n```sql\nINSERT INTO items (id, embedding) VALUES (1, '[1,2,3]'), (2, '[4,5,6]')\n    ON CONFLICT (id) DO UPDATE SET embedding = EXCLUDED.embedding;\n```\n\nUpdate vectors\n\n```sql\nUPDATE items SET embedding = '[1,2,3]' WHERE id = 1;\n```\n\nDelete vectors\n\n```sql\nDELETE FROM items WHERE id = 1;\n```\n\n## Querying\n\nGet the nearest neighbors to a vector\n\n```sql\nSELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\nSupported distance functions are:\n\n- `<->` - L2 distance\n- `<#>` - (negative) inner product\n- `<=>` - cosine distance\n- `<+>` - L1 distance\n- `<~>` - Hamming distance (binary vectors)\n- `<%>` - Jaccard distance (binary vectors)\n\nGet the nearest neighbors to a row\n\n```sql\nSELECT * FROM items WHERE id != 1 ORDER BY embedding <-> (SELECT embedding FROM items WHERE id = 1) LIMIT 5;\n```\n\nGet rows within a certain distance\n\n```sql\nSELECT * FROM items WHERE embedding <-> '[3,1,2]' < 5;\n```\n\nNote: Combine with `ORDER BY` and `LIMIT` to use an index\n\n#### Distances\n\nGet the distance\n\n```sql\nSELECT embedding <-> '[3,1,2]' AS distance FROM items;\n```\n\nFor inner product, multiply by -1 (since `<#>` returns the negative inner product)\n\n```tsql\nSELECT (embedding <#> '[3,1,2]') * -1 AS inner_product FROM items;\n```\n\nFor cosine similarity, use 1 - cosine distance\n\n```sql\nSELECT 1 - (embedding <=> '[3,1,2]') AS cosine_similarity FROM items;\n```\n\n#### Aggregates\n\nAverage vectors\n\n```sql\nSELECT AVG(embedding) FROM items;\n```\n\nAverage groups of vectors\n\n```sql\nSELECT category_id, AVG(embedding) FROM items GROUP BY category_id;\n```\n\n## Indexing\n\nBy default, pgvector performs exact nearest neighbor search, which provides perfect recall.\n\nYou can add an index to use approximate nearest neighbor search, which trades some recall for speed. Unlike typical indexes, you will see different results for queries after adding an approximate index.\n\nSupported index types are:\n\n- [HNSW](#hnsw)\n- [IVFFlat](#ivfflat)\n\n## HNSW\n\nAn HNSW index creates a multilayer graph. It has better query performance than IVFFlat (in terms of speed-recall tradeoff), but has slower build times and uses more memory. Also, an index can be created without any data in the table since there isn‚Äôt a training step like IVFFlat.\n\nAdd an index for each distance function you want to use.\n\nL2 distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops);\n```\n\nNote: Use `halfvec_l2_ops` for `halfvec` and `sparsevec_l2_ops` for `sparsevec` (and similar with the other distance functions)\n\nInner product\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_ip_ops);\n```\n\nCosine distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_cosine_ops);\n```\n\nL1 distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l1_ops);\n```\n\nHamming distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding bit_hamming_ops);\n```\n\nJaccard distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding bit_jaccard_ops);\n```\n\nSupported types are:\n\n- `vector` - up to 2,000 dimensions\n- `halfvec` - up to 4,000 dimensions\n- `bit` - up to 64,000 dimensions\n- `sparsevec` - up to 1,000 non-zero elements\n\n### Index Options\n\nSpecify HNSW parameters\n\n- `m` - the max number of connections per layer (16 by default)\n- `ef_construction` - the size of the dynamic candidate list for constructing the graph (64 by default)\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops) WITH (m = 16, ef_construction = 64);\n```\n\nA higher value of `ef_construction` provides better recall at the cost of index build time / insert speed.\n\n### Query Options\n\nSpecify the size of the dynamic candidate list for search (40 by default)\n\n```sql\nSET hnsw.ef_search = 100;\n```\n\nA higher value provides better recall at the cost of speed.\n\nUse `SET LOCAL` inside a transaction to set it for a single query\n\n```sql\nBEGIN;\nSET LOCAL hnsw.ef_search = 100;\nSELECT ...\nCOMMIT;\n```\n\n### Index Build Time\n\nIndexes build significantly faster when the graph fits into `maintenance_work_mem`\n\n```sql\nSET maintenance_work_mem = '8GB';\n```\n\nA notice is shown when the graph no longer fits\n\n```text\nNOTICE:  hnsw graph no longer fits into maintenance_work_mem after 100000 tuples\nDETAIL:  Building will take significantly more time.\nHINT:  Increase maintenance_work_mem to speed up builds.\n```\n\nNote: Do not set `maintenance_work_mem` so high that it exhausts the memory on the server\n\nLike other index types, it‚Äôs faster to create an index after loading your initial data\n\nYou can also speed up index creation by increasing the number of parallel workers (2 by default)\n\n```sql\nSET max_parallel_maintenance_workers = 7; -- plus leader\n```\n\nFor a large number of workers, you may need to increase `max_parallel_workers` (8 by default)\n\nThe [index options](#index-options) also have a significant impact on build time (use the defaults unless seeing low recall)\n\n### Indexing Progress\n\nCheck [indexing progress](https://www.postgresql.org/docs/current/progress-reporting.html#CREATE-INDEX-PROGRESS-REPORTING)\n\n```sql\nSELECT phase, round(100.0 * blocks_done / nullif(blocks_total, 0), 1) AS \"%\" FROM pg_stat_progress_create_index;\n```\n\nThe phases for HNSW are:\n\n1. `initializing`\n2. `loading tuples`\n\n## IVFFlat\n\nAn IVFFlat index divides vectors into lists, and then searches a subset of those lists that are closest to the query vector. It has faster build times and uses less memory than HNSW, but has lower query performance (in terms of speed-recall tradeoff).\n\nThree keys to achieving good recall are:\n\n1. Create the index *after* the table has some data\n2. Choose an appropriate number of lists - a good place to start is `rows / 1000` for up to 1M rows and `sqrt(rows)` for over 1M rows\n3. When querying, specify an appropriate number of [probes](#query-options) (higher is better for recall, lower is better for speed) - a good place to start is `sqrt(lists)`\n\nAdd an index for each distance function you want to use.\n\nL2 distance\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_l2_ops) WITH (lists = 100);\n```\n\nNote: Use `halfvec_l2_ops` for `halfvec` (and similar with the other distance functions)\n\nInner product\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_ip_ops) WITH (lists = 100);\n```\n\nCosine distance\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);\n```\n\nHamming distance\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding bit_hamming_ops) WITH (lists = 100);\n```\n\nSupported types are:\n\n- `vector` - up to 2,000 dimensions\n- `halfvec` - up to 4,000 dimensions\n- `bit` - up to 64,000 dimensions\n\n### Query Options\n\nSpecify the number of probes (1 by default)\n\n```sql\nSET ivfflat.probes = 10;\n```\n\nA higher value provides better recall at the cost of speed, and it can be set to the number of lists for exact nearest neighbor search (at which point the planner won‚Äôt use the index)\n\nUse `SET LOCAL` inside a transaction to set it for a single query\n\n```sql\nBEGIN;\nSET LOCAL ivfflat.probes = 10;\nSELECT ...\nCOMMIT;\n```\n\n### Index Build Time\n\nSpeed up index creation on large tables by increasing the number of parallel workers (2 by default)\n\n```sql\nSET max_parallel_maintenance_workers = 7; -- plus leader\n```\n\nFor a large number of workers, you may also need to increase `max_parallel_workers` (8 by default)\n\n### Indexing Progress\n\nCheck [indexing progress](https://www.postgresql.org/docs/current/progress-reporting.html#CREATE-INDEX-PROGRESS-REPORTING)\n\n```sql\nSELECT phase, round(100.0 * tuples_done / nullif(tuples_total, 0), 1) AS \"%\" FROM pg_stat_progress_create_index;\n```\n\nThe phases for IVFFlat are:\n\n1. `initializing`\n2. `performing k-means`\n3. `assigning tuples`\n4. `loading tuples`\n\nNote: `%` is only populated during the `loading tuples` phase\n\n## Filtering\n\nThere are a few ways to index nearest neighbor queries with a `WHERE` clause.\n\n```sql\nSELECT * FROM items WHERE category_id = 123 ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\nA good place to start is creating an index on the filter column. This can provide fast, exact nearest neighbor search in many cases. Postgres has a number of [index types](https://www.postgresql.org/docs/current/indexes-types.html) for this: B-tree (default), hash, GiST, SP-GiST, GIN, and BRIN.\n\n```sql\nCREATE INDEX ON items (category_id);\n```\n\nFor multiple columns, consider a [multicolumn index](https://www.postgresql.org/docs/current/indexes-multicolumn.html).\n\n```sql\nCREATE INDEX ON items (location_id, category_id);\n```\n\nExact indexes work well for conditions that match a low percentage of rows. Otherwise, [approximate indexes](#indexing) can work better.\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops);\n```\n\nWith approximate indexes, filtering is applied *after* the index is scanned. If a condition matches 10% of rows, with HNSW and the default `hnsw.ef_search` of 40, only 4 rows will match on average. For more rows, increase `hnsw.ef_search`.\n\n```sql\nSET hnsw.ef_search = 200;\n```\n\nStarting with 0.8.0, you can enable [iterative index scans](#iterative-index-scans), which will automatically scan more of the index when needed.\n\n```sql\nSET hnsw.iterative_scan = strict_order;\n```\n\nIf filtering by only a few distinct values, consider [partial indexing](https://www.postgresql.org/docs/current/indexes-partial.html).\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops) WHERE (category_id = 123);\n```\n\nIf filtering by many different values, consider [partitioning](https://www.postgresql.org/docs/current/ddl-partitioning.html).\n\n```sql\nCREATE TABLE items (embedding vector(3), category_id int) PARTITION BY LIST(category_id);\n```\n\n## Iterative Index Scans\n\nWith approximate indexes, queries with filtering can return less results since filtering is applied *after* the index is scanned. Starting with 0.8.0, you can enable iterative index scans, which will automatically scan more of the index until enough results are found (or it reaches `hnsw.max_scan_tuples` or `ivfflat.max_probes`).\n\nIterative scans can use strict or relaxed ordering.\n\nStrict ensures results are in the exact order by distance\n\n```sql\nSET hnsw.iterative_scan = strict_order;\n```\n\nRelaxed allows results to be slightly out of order by distance, but provides better recall\n\n```sql\nSET hnsw.iterative_scan = relaxed_order;\n# or\nSET ivfflat.iterative_scan = relaxed_order;\n```\n\nWith relaxed ordering, you can use a [materialized CTE](https://www.postgresql.org/docs/current/queries-with.html#QUERIES-WITH-CTE-MATERIALIZATION) to get strict ordering\n\n```sql\nWITH relaxed_results AS MATERIALIZED (\n    SELECT id, embedding <-> '[1,2,3]' AS distance FROM items WHERE category_id = 123 ORDER BY distance LIMIT 5\n) SELECT * FROM relaxed_results ORDER BY distance + 0;\n```\n\nNote: `+ 0` is needed for Postgres 17+\n\nFor queries that filter by distance, use a materialized CTE and place the distance filter outside of it for best performance (due to the [current behavior](https://www.postgresql.org/message-id/flat/CAOdR5yGUoMQ6j7M5hNUXrySzaqZVGf_Ne%2B8fwZMRKTFxU1nbJg%40mail.gmail.com) of the Postgres executor)\n\n```sql\nWITH nearest_results AS MATERIALIZED (\n    SELECT id, embedding <-> '[1,2,3]' AS distance FROM items ORDER BY distance LIMIT 5\n) SELECT * FROM nearest_results WHERE distance < 5 ORDER BY distance;\n```\n\nNote: Place any other filters inside the CTE\n\n### Iterative Scan Options\n\nSince scanning a large portion of an approximate index is expensive, there are options to control when a scan ends.\n\n#### HNSW\n\nSpecify the max number of tuples to visit (20,000 by default)\n\n```sql\nSET hnsw.max_scan_tuples = 20000;\n```\n\nNote: This is approximate and does not affect the initial scan\n\nSpecify the max amount of memory to use, as a multiple of `work_mem` (1 by default)\n\n```sql\nSET hnsw.scan_mem_multiplier = 2;\n```\n\nNote: Try increasing this if increasing `hnsw.max_scan_tuples` does not improve recall\n\n#### IVFFlat\n\nSpecify the max number of probes\n\n```sql\nSET ivfflat.max_probes = 100;\n```\n\nNote: If this is lower than `ivfflat.probes`, `ivfflat.probes` will be used\n\n## Half-Precision Vectors\n\nUse the `halfvec` type to store half-precision vectors\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding halfvec(3));\n```\n\n## Half-Precision Indexing\n\nIndex vectors at half precision for smaller indexes\n\n```sql\nCREATE INDEX ON items USING hnsw ((embedding::halfvec(3)) halfvec_l2_ops);\n```\n\nGet the nearest neighbors\n\n```sql\nSELECT * FROM items ORDER BY embedding::halfvec(3) <-> '[1,2,3]' LIMIT 5;\n```\n\n## Binary Vectors\n\nUse the `bit` type to store binary vectors ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/imagehash/example.py))\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding bit(3));\nINSERT INTO items (embedding) VALUES ('000'), ('111');\n```\n\nGet the nearest neighbors by Hamming distance\n\n```sql\nSELECT * FROM items ORDER BY embedding <~> '101' LIMIT 5;\n```\n\nAlso supports Jaccard distance (`<%>`)\n\n## Binary Quantization\n\nUse expression indexing for binary quantization\n\n```sql\nCREATE INDEX ON items USING hnsw ((binary_quantize(embedding)::bit(3)) bit_hamming_ops);\n```\n\nGet the nearest neighbors by Hamming distance\n\n```sql\nSELECT * FROM items ORDER BY binary_quantize(embedding)::bit(3) <~> binary_quantize('[1,-2,3]') LIMIT 5;\n```\n\nRe-rank by the original vectors for better recall\n\n```sql\nSELECT * FROM (\n    SELECT * FROM items ORDER BY binary_quantize(embedding)::bit(3) <~> binary_quantize('[1,-2,3]') LIMIT 20\n) ORDER BY embedding <=> '[1,-2,3]' LIMIT 5;\n```\n\n## Sparse Vectors\n\nUse the `sparsevec` type to store sparse vectors\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding sparsevec(5));\n```\n\nInsert vectors\n\n```sql\nINSERT INTO items (embedding) VALUES ('{1:1,3:2,5:3}/5'), ('{1:4,3:5,5:6}/5');\n```\n\nThe format is `{index1:value1,index2:value2}/dimensions` and indices start at 1 like SQL arrays\n\nGet the nearest neighbors by L2 distance\n\n```sql\nSELECT * FROM items ORDER BY embedding <-> '{1:3,3:1,5:2}/5' LIMIT 5;\n```\n\n## Hybrid Search\n\nUse together with Postgres [full-text search](https://www.postgresql.org/docs/current/textsearch-intro.html) for hybrid search.\n\n```sql\nSELECT id, content FROM items, plainto_tsquery('hello search') query\n    WHERE textsearch @@ query ORDER BY ts_rank_cd(textsearch, query) DESC LIMIT 5;\n```\n\nYou can use [Reciprocal Rank Fusion](https://github.com/pgvector/pgvector-python/blob/master/examples/hybrid_search/rrf.py) or a [cross-encoder](https://github.com/pgvector/pgvector-python/blob/master/examples/hybrid_search/cross_encoder.py) to combine results.\n\n## Indexing Subvectors\n\nUse expression indexing to index subvectors\n\n```sql\nCREATE INDEX ON items USING hnsw ((subvector(embedding, 1, 3)::vector(3)) vector_cosine_ops);\n```\n\nGet the nearest neighbors by cosine distance\n\n```sql\nSELECT * FROM items ORDER BY subvector(embedding, 1, 3)::vector(3) <=> subvector('[1,2,3,4,5]'::vector, 1, 3) LIMIT 5;\n```\n\nRe-rank by the full vectors for better recall\n\n```sql\nSELECT * FROM (\n    SELECT * FROM items ORDER BY subvector(embedding, 1, 3)::vector(3) <=> subvector('[1,2,3,4,5]'::vector, 1, 3) LIMIT 20\n) ORDER BY embedding <=> '[1,2,3,4,5]' LIMIT 5;\n```\n\n## Performance\n\n### Tuning\n\nUse a tool like [PgTune](https://pgtune.leopard.in.ua/) to set initial values for Postgres server parameters. For instance, `shared_buffers` should typically be 25% of the server‚Äôs memory. You can find the config file with:\n\n```sql\nSHOW config_file;\n```\n\nAnd check individual settings with:\n\n```sql\nSHOW shared_buffers;\n```\n\nBe sure to restart Postgres for changes to take effect.\n\n### Loading\n\nUse `COPY` for bulk loading data ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/loading/example.py)).\n\n```sql\nCOPY items (embedding) FROM STDIN WITH (FORMAT BINARY);\n```\n\nAdd any indexes *after* loading the initial data for best performance.\n\n### Indexing\n\nSee index build time for [HNSW](#index-build-time) and [IVFFlat](#index-build-time-1).\n\nIn production environments, create indexes concurrently to avoid blocking writes.\n\n```sql\nCREATE INDEX CONCURRENTLY ...\n```\n\n### Querying\n\nUse `EXPLAIN (ANALYZE, BUFFERS)` to debug performance.\n\n```sql\nEXPLAIN (ANALYZE, BUFFERS) SELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\n#### Exact Search\n\nTo speed up queries without an index, increase `max_parallel_workers_per_gather`.\n\n```sql\nSET max_parallel_workers_per_gather = 4;\n```\n\nIf vectors are normalized to length 1 (like [OpenAI embeddings](https://platform.openai.com/docs/guides/embeddings/which-distance-function-should-i-use)), use inner product for best performance.\n\n```tsql\nSELECT * FROM items ORDER BY embedding <#> '[3,1,2]' LIMIT 5;\n```\n\n#### Approximate Search\n\nTo speed up queries with an IVFFlat index, increase the number of inverted lists (at the expense of recall).\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_l2_ops) WITH (lists = 1000);\n```\n\n### Vacuuming\n\nVacuuming can take a while for HNSW indexes. Speed it up by reindexing first.\n\n```sql\nREINDEX INDEX CONCURRENTLY index_name;\nVACUUM table_name;\n```\n\n## Monitoring\n\nMonitor performance with [pg_stat_statements](https://www.postgresql.org/docs/current/pgstatstatements.html) (be sure to add it to `shared_preload_libraries`).\n\n```sql\nCREATE EXTENSION pg_stat_statements;\n```\n\nGet the most time-consuming queries with:\n\n```sql\nSELECT query, calls, ROUND((total_plan_time + total_exec_time) / calls) AS avg_time_ms,\n    ROUND((total_plan_time + total_exec_time) / 60000) AS total_time_min\n    FROM pg_stat_statements ORDER BY total_plan_time + total_exec_time DESC LIMIT 20;\n```\n\nMonitor recall by comparing results from approximate search with exact search.\n\n```sql\nBEGIN;\nSET LOCAL enable_indexscan = off; -- use exact search\nSELECT ...\nCOMMIT;\n```\n\n## Scaling\n\nScale pgvector the same way you scale Postgres.\n\nScale vertically by increasing memory, CPU, and storage on a single instance. Use existing tools to [tune parameters](#tuning) and [monitor performance](#monitoring).\n\nScale horizontally with [replicas](https://www.postgresql.org/docs/current/hot-standby.html), or use [Citus](https://github.com/citusdata/citus) or another approach for sharding ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/citus/example.py)).\n\n## Languages\n\nUse pgvector from any language with a Postgres client. You can even generate and store vectors in one language and query them in another.\n\nLanguage | Libraries / Examples\n--- | ---\nAda | [pgvector-ada](https://github.com/pgvector/pgvector-ada)\nAlgol | [pgvector-algol](https://github.com/pgvector/pgvector-algol)\nC | [pgvector-c](https://github.com/pgvector/pgvector-c)\nC++ | [pgvector-cpp](https://github.com/pgvector/pgvector-cpp)\nC#, F#, Visual Basic | [pgvector-dotnet](https://github.com/pgvector/pgvector-dotnet)\nCOBOL | [pgvector-cobol](https://github.com/pgvector/pgvector-cobol)\nCrystal | [pgvector-crystal](https://github.com/pgvector/pgvector-crystal)\nD | [pgvector-d](https://github.com/pgvector/pgvector-d)\nDart | [pgvector-dart](https://github.com/pgvector/pgvector-dart)\nElixir | [pgvector-elixir](https://github.com/pgvector/pgvector-elixir)\nErlang | [pgvector-erlang](https://github.com/pgvector/pgvector-erlang)\nFortran | [pgvector-fortran](https://github.com/pgvector/pgvector-fortran)\nGleam | [pgvector-gleam](https://github.com/pgvector/pgvector-gleam)\nGo | [pgvector-go](https://github.com/pgvector/pgvector-go)\nHaskell | [pgvector-haskell](https://github.com/pgvector/pgvector-haskell)\nJava, Kotlin, Groovy, Scala | [pgvector-java](https://github.com/pgvector/pgvector-java)\nJavaScript, TypeScript | [pgvector-node](https://github.com/pgvector/pgvector-node)\nJulia | [Pgvector.jl](https://github.com/pgvector/Pgvector.jl)\nLisp | [pgvector-lisp](https://github.com/pgvector/pgvector-lisp)\nLua | [pgvector-lua](https://github.com/pgvector/pgvector-lua)\nNim | [pgvector-nim](https://github.com/pgvector/pgvector-nim)\nOCaml | [pgvector-ocaml](https://github.com/pgvector/pgvector-ocaml)\nPascal | [pgvector-pascal](https://github.com/pgvector/pgvector-pascal)\nPerl | [pgvector-perl](https://github.com/pgvector/pgvector-perl)\nPHP | [pgvector-php](https://github.com/pgvector/pgvector-php)\nProlog | [pgvector-prolog](https://github.com/pgvector/pgvector-prolog)\nPython | [pgvector-python](https://github.com/pgvector/pgvector-python)\nR | [pgvector-r](https://github.com/pgvector/pgvector-r)\nRacket | [pgvector-racket](https://github.com/pgvector/pgvector-racket)\nRaku | [pgvector-raku](https://github.com/pgvector/pgvector-raku)\nRuby | [pgvector-ruby](https://github.com/pgvector/pgvector-ruby), [Neighbor](https://github.com/ankane/neighbor)\nRust | [pgvector-rust](https://github.com/pgvector/pgvector-rust)\nSwift | [pgvector-swift](https://github.com/pgvector/pgvector-swift)\nTcl | [pgvector-tcl](https://github.com/pgvector/pgvector-tcl)\nZig | [pgvector-zig](https://github.com/pgvector/pgvector-zig)\n\n## Frequently Asked Questions\n\n#### How many vectors can be stored in a single table?\n\nA non-partitioned table has a limit of 32 TB by default in Postgres. A partitioned table can have thousands of partitions of that size.\n\n#### Is replication supported?\n\nYes, pgvector uses the write-ahead log (WAL), which allows for replication and point-in-time recovery.\n\n#### What if I want to index vectors with more than 2,000 dimensions?\n\nYou can use [half-precision vectors](#half-precision-vectors) or [half-precision indexing](#half-precision-indexing) to index up to 4,000 dimensions or [binary quantization](#binary-quantization) to index up to 64,000 dimensions. Other options are [indexing subvectors](#indexing-subvectors) (for models that support it) or [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction).\n\n#### Can I store vectors with different dimensions in the same column?\n\nYou can use `vector` as the type (instead of `vector(n)`).\n\n```sql\nCREATE TABLE embeddings (model_id bigint, item_id bigint, embedding vector, PRIMARY KEY (model_id, item_id));\n```\n\nHowever, you can only create indexes on rows with the same number of dimensions (using [expression](https://www.postgresql.org/docs/current/indexes-expressional.html) and [partial](https://www.postgresql.org/docs/current/indexes-partial.html) indexing):\n\n```sql\nCREATE INDEX ON embeddings USING hnsw ((embedding::vector(3)) vector_l2_ops) WHERE (model_id = 123);\n```\n\nand query with:\n\n```sql\nSELECT * FROM embeddings WHERE model_id = 123 ORDER BY embedding::vector(3) <-> '[3,1,2]' LIMIT 5;\n```\n\n#### Can I store vectors with more precision?\n\nYou can use the `double precision[]` or `numeric[]` type to store vectors with more precision.\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding double precision[]);\n\n-- use {} instead of [] for Postgres arrays\nINSERT INTO items (embedding) VALUES ('{1,2,3}'), ('{4,5,6}');\n```\n\nOptionally, add a [check constraint](https://www.postgresql.org/docs/current/ddl-constraints.html) to ensure data can be converted to the `vector` type and has the expected dimensions.\n\n```sql\nALTER TABLE items ADD CHECK (vector_dims(embedding::vector) = 3);\n```\n\nUse [expression indexing](https://www.postgresql.org/docs/current/indexes-expressional.html) to index (at a lower precision):\n\n```sql\nCREATE INDEX ON items USING hnsw ((embedding::vector(3)) vector_l2_ops);\n```\n\nand query with:\n\n```sql\nSELECT * FROM items ORDER BY embedding::vector(3) <-> '[3,1,2]' LIMIT 5;\n```\n\n#### Do indexes need to fit into memory?\n\nNo, but like other index types, you‚Äôll likely see better performance if they do. You can get the size of an index with:\n\n```sql\nSELECT pg_size_pretty(pg_relation_size('index_name'));\n```\n\n## Troubleshooting\n\n#### Why isn‚Äôt a query using an index?\n\nThe query needs to have an `ORDER BY` and `LIMIT`, and the `ORDER BY` must be the result of a distance operator (not an expression) in ascending order.\n\n```sql\n-- index\nORDER BY embedding <=> '[3,1,2]' LIMIT 5;\n\n-- no index\nORDER BY 1 - (embedding <=> '[3,1,2]') DESC LIMIT 5;\n```\n\nYou can encourage the planner to use an index for a query with:\n\n```sql\nBEGIN;\nSET LOCAL enable_seqscan = off;\nSELECT ...\nCOMMIT;\n```\n\nAlso, if the table is small, a table scan may be faster.\n\n#### Why isn‚Äôt a query using a parallel table scan?\n\nThe planner doesn‚Äôt consider [out-of-line storage](https://www.postgresql.org/docs/current/storage-toast.html) in cost estimates, which can make a serial scan look cheaper. You can reduce the cost of a parallel scan for a query with:\n\n```sql\nBEGIN;\nSET LOCAL min_parallel_table_scan_size = 1;\nSET LOCAL parallel_setup_cost = 1;\nSELECT ...\nCOMMIT;\n```\n\nor choose to store vectors inline:\n\n```sql\nALTER TABLE items ALTER COLUMN embedding SET STORAGE PLAIN;\n```\n\n#### Why are there less results for a query after adding an HNSW index?\n\nResults are limited by the size of the dynamic candidate list (`hnsw.ef_search`), which is 40 by default. There may be even less results due to dead tuples or filtering conditions in the query. Enabling [iterative index scans](#iterative-index-scans) can help address this.\n\nAlso, note that `NULL` vectors are not indexed (as well as zero vectors for cosine distance).\n\n#### Why are there less results for a query after adding an IVFFlat index?\n\nThe index was likely created with too little data for the number of lists. Drop the index until the table has more data.\n\n```sql\nDROP INDEX index_name;\n```\n\nResults can also be limited by the number of probes (`ivfflat.probes`). Enabling [iterative index scans](#iterative-index-scans) can address this.\n\nAlso, note that `NULL` vectors are not indexed (as well as zero vectors for cosine distance).\n\n## Reference\n\n- [Vector](#vector-type)\n- [Halfvec](#halfvec-type)\n- [Bit](#bit-type)\n- [Sparsevec](#sparsevec-type)\n\n### Vector Type\n\nEach vector takes `4 * dimensions + 8` bytes of storage. Each element is a single-precision floating-point number (like the `real` type in Postgres), and all elements must be finite (no `NaN`, `Infinity` or `-Infinity`). Vectors can have up to 16,000 dimensions.\n\n### Vector Operators\n\nOperator | Description | Added\n--- | --- | ---\n\\+ | element-wise addition |\n\\- | element-wise subtraction |\n\\* | element-wise multiplication | 0.5.0\n\\|\\| | concatenate | 0.7.0\n<-> | Euclidean distance |\n<#> | negative inner product |\n<=> | cosine distance |\n<+> | taxicab distance | 0.7.0\n\n### Vector Functions\n\nFunction | Description | Added\n--- | --- | ---\nbinary_quantize(vector) ‚Üí bit | binary quantize | 0.7.0\ncosine_distance(vector, vector) ‚Üí double precision | cosine distance |\ninner_product(vector, vector) ‚Üí double precision | inner product |\nl1_distance(vector, vector) ‚Üí double precision | taxicab distance | 0.5.0\nl2_distance(vector, vector) ‚Üí double precision | Euclidean distance |\nl2_normalize(vector) ‚Üí vector | Normalize with Euclidean norm | 0.7.0\nsubvector(vector, integer, integer) ‚Üí vector | subvector | 0.7.0\nvector_dims(vector) ‚Üí integer | number of dimensions |\nvector_norm(vector) ‚Üí double precision | Euclidean norm |\n\n### Vector Aggregate Functions\n\nFunction | Description | Added\n--- | --- | ---\navg(vector) ‚Üí vector | average |\nsum(vector) ‚Üí vector | sum | 0.5.0\n\n### Halfvec Type\n\nEach half vector takes `2 * dimensions + 8` bytes of storage. Each element is a half-precision floating-point number, and all elements must be finite (no `NaN`, `Infinity` or `-Infinity`). Half vectors can have up to 16,000 dimensions.\n\n### Halfvec Operators\n\nOperator | Description | Added\n--- | --- | ---\n\\+ | element-wise addition | 0.7.0\n\\- | element-wise subtraction | 0.7.0\n\\* | element-wise multiplication | 0.7.0\n\\|\\| | concatenate | 0.7.0\n<-> | Euclidean distance | 0.7.0\n<#> | negative inner product | 0.7.0\n<=> | cosine distance | 0.7.0\n<+> | taxicab distance | 0.7.0\n\n### Halfvec Functions\n\nFunction | Description | Added\n--- | --- | ---\nbinary_quantize(halfvec) ‚Üí bit | binary quantize | 0.7.0\ncosine_distance(halfvec, halfvec) ‚Üí double precision | cosine distance | 0.7.0\ninner_product(halfvec, halfvec) ‚Üí double precision | inner product | 0.7.0\nl1_distance(halfvec, halfvec) ‚Üí double precision | taxicab distance | 0.7.0\nl2_distance(halfvec, halfvec) ‚Üí double precision | Euclidean distance | 0.7.0\nl2_norm(halfvec) ‚Üí double precision | Euclidean norm | 0.7.0\nl2_normalize(halfvec) ‚Üí halfvec | Normalize with Euclidean norm | 0.7.0\nsubvector(halfvec, integer, integer) ‚Üí halfvec | subvector | 0.7.0\nvector_dims(halfvec) ‚Üí integer | number of dimensions | 0.7.0\n\n### Halfvec Aggregate Functions\n\nFunction | Description | Added\n--- | --- | ---\navg(halfvec) ‚Üí halfvec | average | 0.7.0\nsum(halfvec) ‚Üí halfvec | sum | 0.7.0\n\n### Bit Type\n\nEach bit vector takes `dimensions / 8 + 8` bytes of storage. See the [Postgres docs](https://www.postgresql.org/docs/current/datatype-bit.html) for more info.\n\n### Bit Operators\n\nOperator | Description | Added\n--- | --- | ---\n<~> | Hamming distance | 0.7.0\n<%> | Jaccard distance | 0.7.0\n\n### Bit Functions\n\nFunction | Description | Added\n--- | --- | ---\nhamming_distance(bit, bit) ‚Üí double precision | Hamming distance | 0.7.0\njaccard_distance(bit, bit) ‚Üí double precision | Jaccard distance | 0.7.0\n\n### Sparsevec Type\n\nEach sparse vector takes `8 * non-zero elements + 16` bytes of storage. Each element is a single-precision floating-point number, and all elements must be finite (no `NaN`, `Infinity` or `-Infinity`). Sparse vectors can have up to 16,000 non-zero elements.\n\n### Sparsevec Operators\n\nOperator | Description | Added\n--- | --- | ---\n<-> | Euclidean distance | 0.7.0\n<#> | negative inner product | 0.7.0\n<=> | cosine distance | 0.7.0\n<+> | taxicab distance | 0.7.0\n\n### Sparsevec Functions\n\nFunction | Description | Added\n--- | --- | ---\ncosine_distance(sparsevec, sparsevec) ‚Üí double precision | cosine distance | 0.7.0\ninner_product(sparsevec, sparsevec) ‚Üí double precision | inner product | 0.7.0\nl1_distance(sparsevec, sparsevec) ‚Üí double precision | taxicab distance | 0.7.0\nl2_distance(sparsevec, sparsevec) ‚Üí double precision | Euclidean distance | 0.7.0\nl2_norm(sparsevec) ‚Üí double precision | Euclidean norm | 0.7.0\nl2_normalize(sparsevec) ‚Üí sparsevec | Normalize with Euclidean norm | 0.7.0\n\n## Installation Notes - Linux and Mac\n\n### Postgres Location\n\nIf your machine has multiple Postgres installations, specify the path to [pg_config](https://www.postgresql.org/docs/current/app-pgconfig.html) with:\n\n```sh\nexport PG_CONFIG=/Library/PostgreSQL/18/bin/pg_config\n```\n\nThen re-run the installation instructions (run `make clean` before `make` if needed). If `sudo` is needed for `make install`, use:\n\n```sh\nsudo --preserve-env=PG_CONFIG make install\n```\n\nA few common paths on Mac are:\n\n- EDB installer - `/Library/PostgreSQL/18/bin/pg_config`\n- Homebrew (arm64) - `/opt/homebrew/opt/postgresql@18/bin/pg_config`\n- Homebrew (x86-64) - `/usr/local/opt/postgresql@18/bin/pg_config`\n\nNote: Replace `18` with your Postgres server version\n\n### Missing Header\n\nIf compilation fails with `fatal error: postgres.h: No such file or directory`, make sure Postgres development files are installed on the server.\n\nFor Ubuntu and Debian, use:\n\n```sh\nsudo apt install postgresql-server-dev-18\n```\n\nNote: Replace `18` with your Postgres server version\n\n### Missing SDK\n\nIf compilation fails and the output includes `warning: no such sysroot directory` on Mac, your Postgres installation points to a path that no longer exists.\n\n```sh\npg_config --cppflags\n```\n\nReinstall Postgres to fix this.\n\n### Portability\n\nBy default, pgvector compiles with `-march=native` on some platforms for best performance. However, this can lead to `Illegal instruction` errors if trying to run the compiled extension on a different machine.\n\nTo compile for portability, use:\n\n```sh\nmake OPTFLAGS=\"\"\n```\n\n## Installation Notes - Windows\n\n### Missing Header\n\nIf compilation fails with `Cannot open include file: 'postgres.h': No such file or directory`, make sure `PGROOT` is correct.\n\n### Mismatched Architecture\n\nIf compilation fails with `error C2196: case value '4' already used`, make sure you‚Äôre using the `x64 Native Tools Command Prompt`. Then run `nmake /F Makefile.win clean` and re-run the installation instructions.\n\n### Missing Symbol\n\nIf linking fails with `unresolved external symbol float_to_shortest_decimal_bufn` with Postgres 17.0-17.2, upgrade to Postgres 17.3+.\n\n### Permissions\n\nIf installation fails with `Access is denied`, re-run the installation instructions as an administrator.\n\n## Additional Installation Methods\n\n### Docker\n\nGet the [Docker image](https://hub.docker.com/r/pgvector/pgvector) with:\n\n```sh\ndocker pull pgvector/pgvector:pg18-trixie\n```\n\nThis adds pgvector to the [Postgres image](https://hub.docker.com/_/postgres) (replace `18` with your Postgres server version, and run it the same way).\n\nSupported tags are:\n\n- `pg18-trixie`, `0.8.1-pg18-trixie`\n- `pg18-bookworm`, `0.8.1-pg18-bookworm`, `pg18`, `0.8.1-pg18`\n- `pg17-trixie`, `0.8.1-pg17-trixie`\n- `pg17-bookworm`, `0.8.1-pg17-bookworm`, `pg17`, `0.8.1-pg17`\n- `pg16-trixie`, `0.8.1-pg16-trixie`\n- `pg16-bookworm`, `0.8.1-pg16-bookworm`, `pg16`, `0.8.1-pg16`\n- `pg15-trixie`, `0.8.1-pg15-trixie`\n- `pg15-bookworm`, `0.8.1-pg15-bookworm`, `pg15`, `0.8.1-pg15`\n- `pg14-trixie`, `0.8.1-pg14-trixie`\n- `pg14-bookworm`, `0.8.1-pg14-bookworm`, `pg14`, `0.8.1-pg14`\n- `pg13-trixie`, `0.8.1-pg13-trixie`\n- `pg13-bookworm`, `0.8.1-pg13-bookworm`, `pg13`, `0.8.1-pg13`\n\nYou can also build the image manually:\n\n```sh\ngit clone --branch v0.8.1 https://github.com/pgvector/pgvector.git\ncd pgvector\ndocker build --pull --build-arg PG_MAJOR=18 -t myuser/pgvector .\n```\n\nIf you increase `maintenance_work_mem`, make sure `--shm-size` is at least that size to avoid an error with parallel HNSW index builds.\n\n```sh\ndocker run --shm-size=1g ...\n```\n\n### Homebrew\n\nWith Homebrew Postgres, you can use:\n\n```sh\nbrew install pgvector\n```\n\nNote: This only adds it to the `postgresql@18` and `postgresql@17` formulas\n\n### PGXN\n\nInstall from the [PostgreSQL Extension Network](https://pgxn.org/dist/vector) with:\n\n```sh\npgxn install vector\n```\n\n### APT\n\nDebian and Ubuntu packages are available from the [PostgreSQL APT Repository](https://wiki.postgresql.org/wiki/Apt). Follow the [setup instructions](https://wiki.postgresql.org/wiki/Apt#Quickstart) and run:\n\n```sh\nsudo apt install postgresql-18-pgvector\n```\n\nNote: Replace `18` with your Postgres server version\n\n### Yum\n\nRPM packages are available from the [PostgreSQL Yum Repository](https://yum.postgresql.org/). Follow the [setup instructions](https://www.postgresql.org/download/linux/redhat/) for your distribution and run:\n\n```sh\nsudo yum install pgvector_18\n# or\nsudo dnf install pgvector_18\n```\n\nNote: Replace `18` with your Postgres server version\n\n### pkg\n\nInstall the FreeBSD package with:\n\n```sh\npkg install postgresql17-pgvector\n```\n\nor the port with:\n\n```sh\ncd /usr/ports/databases/pgvector\nmake install\n```\n\n### APK\n\nInstall the Alpine package with:\n\n```sh\napk add postgresql-pgvector\n```\n\n### conda-forge\n\nWith Conda Postgres, install from [conda-forge](https://anaconda.org/conda-forge/pgvector) with:\n\n```sh\nconda install -c conda-forge pgvector\n```\n\nThis method is [community-maintained](https://github.com/conda-forge/pgvector-feedstock) by [@mmcauliffe](https://github.com/mmcauliffe)\n\n### Postgres.app\n\nDownload the [latest release](https://postgresapp.com/downloads.html) with Postgres 15+.\n\n## Hosted Postgres\n\npgvector is available on [these providers](https://github.com/pgvector/pgvector/issues/54).\n\n## Upgrading\n\n[Install](#installation) the latest version (use the same method as the original installation). Then in each database you want to upgrade, run:\n\n```sql\nALTER EXTENSION vector UPDATE;\n```\n\nYou can check the version in the current database with:\n\n```sql\nSELECT extversion FROM pg_extension WHERE extname = 'vector';\n```\n\n## Thanks\n\nThanks to:\n\n- [PASE: PostgreSQL Ultra-High-Dimensional Approximate Nearest Neighbor Search Extension](https://dl.acm.org/doi/pdf/10.1145/3318464.3386131)\n- [Faiss: A Library for Efficient Similarity Search and Clustering of Dense Vectors](https://github.com/facebookresearch/faiss)\n- [Using the Triangle Inequality to Accelerate k-means](https://cdn.aaai.org/ICML/2003/ICML03-022.pdf)\n- [k-means++: The Advantage of Careful Seeding](https://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf)\n- [Concept Decompositions for Large Sparse Text Data using Clustering](https://www.cs.utexas.edu/users/inderjit/public_papers/concept_mlj.pdf)\n- [Efficient and Robust Approximate Nearest Neighbor Search using Hierarchical Navigable Small World Graphs](https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf)\n\n## History\n\nView the [changelog](https://github.com/pgvector/pgvector/blob/master/CHANGELOG.md)\n\n## Contributing\n\nEveryone is encouraged to help improve this project. Here are a few ways you can help:\n\n- [Report bugs](https://github.com/pgvector/pgvector/issues)\n- Fix bugs and [submit pull requests](https://github.com/pgvector/pgvector/pulls)\n- Write, clarify, or fix documentation\n- Suggest or add new features\n\nTo get started with development:\n\n```sh\ngit clone https://github.com/pgvector/pgvector.git\ncd pgvector\nmake\nmake install\n```\n\nTo run all tests:\n\n```sh\nmake installcheck        # regression tests\nmake prove_installcheck  # TAP tests\n```\n\nTo run single tests:\n\n```sh\nmake installcheck REGRESS=functions                            # regression test\nmake prove_installcheck PROVE_TESTS=test/t/001_ivfflat_wal.pl  # TAP test\n```\n\nTo enable assertions:\n\n```sh\nmake clean && PG_CFLAGS=\"-DUSE_ASSERT_CHECKING\" make && make install\n```\n\nTo enable benchmarking:\n\n```sh\nmake clean && PG_CFLAGS=\"-DIVFFLAT_BENCH\" make && make install\n```\n\nTo show memory usage:\n\n```sh\nmake clean && PG_CFLAGS=\"-DHNSW_MEMORY -DIVFFLAT_MEMORY\" make && make install\n```\n\nTo get k-means metrics:\n\n```sh\nmake clean && PG_CFLAGS=\"-DIVFFLAT_KMEANS_DEBUG\" make && make install\n```\n\nResources for contributors\n\n- [Extension Building Infrastructure](https://www.postgresql.org/docs/current/extend-pgxs.html)\n- [Index Access Method Interface Definition](https://www.postgresql.org/docs/current/indexam.html)\n- [Generic WAL Records](https://www.postgresql.org/docs/current/generic-wal.html)\n",
      "stars_today": 29
    },
    {
      "id": 1015044525,
      "name": "VictoriaLogs",
      "full_name": "VictoriaMetrics/VictoriaLogs",
      "description": "Fast and easy to use database for logs, which can efficiently handle terabytes of logs",
      "html_url": "https://github.com/VictoriaMetrics/VictoriaLogs",
      "stars": 1324,
      "forks": 81,
      "language": "Go",
      "topics": [
        "elasticsearch",
        "grafana",
        "kubernetes",
        "logs",
        "loki",
        "observability",
        "opentelemetry",
        "siem"
      ],
      "created_at": "2025-07-06T22:56:52Z",
      "updated_at": "2026-01-17T00:48:15Z",
      "pushed_at": "2026-01-16T16:37:10Z",
      "open_issues": 161,
      "owner": {
        "login": "VictoriaMetrics",
        "avatar_url": "https://avatars.githubusercontent.com/u/43720803?v=4"
      },
      "readme": "# VictoriaLogs\n\n[![Latest Release](https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaLogs?sort=semver&label=&logo=github&labelColor=gray&color=gray&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs%2Freleases%2Flatest)](https://github.com/VictoriaMetrics/VictoriaLogs/releases)\n![Docker Pulls](https://img.shields.io/docker/pulls/victoriametrics/victoria-logs?label=&logo=docker&logoColor=white&labelColor=2496ED&color=2496ED&link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-logs)\n[![Go Report](https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaLogs?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs)](https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaLogs)\n[![Build Status](https://github.com/VictoriaMetrics/VictoriaLogs/actions/workflows/main.yml/badge.svg?branch=master&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs%2Factions)](https://github.com/VictoriaMetrics/VictoriaLogs/actions/workflows/main.yml)\n[![codecov](https://codecov.io/gh/VictoriaMetrics/VictoriaLogs/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaLogs)](https://app.codecov.io/gh/VictoriaMetrics/VictoriaLogs)\n[![License](https://img.shields.io/github/license/VictoriaMetrics/VictoriaLogs?labelColor=green&label=&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs%2Fblob%2Fmaster%2FLICENSE)](https://github.com/VictoriaMetrics/VictoriaLogs/blob/master/LICENSE)\n![Slack](https://img.shields.io/badge/Join-4A154B?logo=slack&link=https%3A%2F%2Fslack.victoriametrics.com)\n[![X](https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&label=Follow&color=black&logo=x&labelColor=black&link=https%3A%2F%2Fx.com%2FVictoriaMetrics)](https://x.com/VictoriaMetrics/)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&label=Join&labelColor=red&logoColor=white&logo=reddit&link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics)](https://www.reddit.com/r/VictoriaMetrics/)\n\nVictoriaLogs is a fast easy to use database for logs.\n\nHere are some resources and information about VictoriaLogs:\n\n- Playgrounds: [playground for the built-in web UI](https://play-vmlogs.victoriametrics.com/), [playground for Grafana plugin for VictoriaLogs](https://play-grafana.victoriametrics.com/d/be5zidev72m80f/k8s-logs-via-victorialogs)\n- [Documentation](https://docs.victoriametrics.com/victorialogs/)\n- Available: [Binary releases](https://github.com/VictoriaMetrics/VictoriaLogs/releases/latest), docker images [Docker Hub](https://hub.docker.com/r/victoriametrics/victoria-logs/) and [Quay](https://quay.io/repository/victoriametrics/victoria-logs), [Source code](https://github.com/VictoriaMetrics/VictoriaLogs)\n- Deployment types: [Single-node version](https://docs.victoriametrics.com/victorialogs/), [Cluster version](https://docs.victoriametrics.com/victorialogs/cluster/)\n- Changelog: [CHANGELOG](https://docs.victoriametrics.com/victorialogs/changelog/), and [How to upgrade](https://docs.victoriametrics.com/victorialogs/#upgrading)\n- Community: [Slack](https://slack.victoriametrics.com/), [X (Twitter)](https://x.com/VictoriaMetrics), [LinkedIn](https://www.linkedin.com/company/victoriametrics/), [YouTube](https://www.youtube.com/@VictoriaMetrics)\n\nBoth the single-node and the cluster versions of VictoriaLogs are open source and free to use.\n\n## Community and contributions\n\nFeel free asking any questions regarding VictoriaLogs:\n\n* [Slack Inviter](https://slack.victoriametrics.com/) and [Slack channel](https://victoriametrics.slack.com/)\n* [X (Twitter)](https://x.com/VictoriaMetrics/)\n* [Linkedin](https://www.linkedin.com/company/victoriametrics/)\n* [Reddit](https://www.reddit.com/r/VictoriaMetrics/)\n* [Telegram-en](https://t.me/VictoriaMetrics_en)\n* [Telegram-ru](https://t.me/VictoriaLogs_ru)\n* [Mastodon](https://mastodon.social/@victoriametrics/)\n\nIf you like VictoriaLogs and want to contribute, then please [read these docs](https://docs.victoriametrics.com/victoriametrics/contributing/).\n\nThank you for your cooperation!\n",
      "stars_today": 29
    },
    {
      "id": 531380835,
      "name": "sherpa-onnx",
      "full_name": "k2-fsa/sherpa-onnx",
      "description": "Speech-to-text, text-to-speech, speaker diarization, speech enhancement, source separation, and VAD using next-gen Kaldi with onnxruntime without Internet connection. Support embedded systems, Android, iOS, HarmonyOS, Raspberry Pi, RISC-V, RK NPU, Axera NPU, Ascend NPU, x86_64 servers, websocket server/client, support 12 programming languages",
      "html_url": "https://github.com/k2-fsa/sherpa-onnx",
      "stars": 9792,
      "forks": 1103,
      "language": "C++",
      "topics": [
        "aarch64",
        "android",
        "arm32",
        "asr",
        "cpp",
        "csharp",
        "dotnet",
        "ios",
        "lazarus",
        "linux",
        "macos",
        "mfc",
        "object-pascal",
        "onnx",
        "raspberry-pi",
        "risc-v",
        "speech-to-text",
        "text-to-speech",
        "vits",
        "windows"
      ],
      "created_at": "2022-09-01T05:47:33Z",
      "updated_at": "2026-01-17T00:51:30Z",
      "pushed_at": "2026-01-16T01:38:58Z",
      "open_issues": 510,
      "owner": {
        "login": "k2-fsa",
        "avatar_url": "https://avatars.githubusercontent.com/u/71431748?v=4"
      },
      "readme": " ### Supported functions\n\n|Speech recognition| [Speech synthesis][tts-url] | [Source separation][ss-url] |\n|------------------|------------------|-------------------|\n|   ‚úîÔ∏è              |         ‚úîÔ∏è        |       ‚úîÔ∏è           |\n\n|Speaker identification| [Speaker diarization][sd-url] | Speaker verification |\n|----------------------|-------------------- |------------------------|\n|   ‚úîÔ∏è                  |         ‚úîÔ∏è           |            ‚úîÔ∏è           |\n\n| [Spoken Language identification][slid-url] | [Audio tagging][at-url] | [Voice activity detection][vad-url] |\n|--------------------------------|---------------|--------------------------|\n|                 ‚úîÔ∏è              |          ‚úîÔ∏è    |                ‚úîÔ∏è         |\n\n| [Keyword spotting][kws-url] | [Add punctuation][punct-url] | [Speech enhancement][se-url] |\n|------------------|-----------------|--------------------|\n|     ‚úîÔ∏è            |       ‚úîÔ∏è         |      ‚úîÔ∏è             |\n\n\n### Supported platforms\n\n|Architecture| Android | iOS     | Windows    | macOS | linux | HarmonyOS |\n|------------|---------|---------|------------|-------|-------|-----------|\n|   x64      |  ‚úîÔ∏è      |         |   ‚úîÔ∏è      | ‚úîÔ∏è    |  ‚úîÔ∏è    |   ‚úîÔ∏è   |\n|   x86      |  ‚úîÔ∏è      |         |   ‚úîÔ∏è      |       |        |        |\n|   arm64    |  ‚úîÔ∏è      | ‚úîÔ∏è      |   ‚úîÔ∏è      | ‚úîÔ∏è    |  ‚úîÔ∏è    |   ‚úîÔ∏è   |\n|   arm32    |  ‚úîÔ∏è      |         |           |       |  ‚úîÔ∏è    |   ‚úîÔ∏è   |\n|   riscv64  |          |         |           |       |  ‚úîÔ∏è    |        |\n\n### Supported programming languages\n\n| 1. C++ | 2. C  | 3. Python | 4. JavaScript |\n|--------|-------|-----------|---------------|\n|   ‚úîÔ∏è    | ‚úîÔ∏è     | ‚úîÔ∏è         |    ‚úîÔ∏è          |\n\n|5. Java | 6. C# | 7. Kotlin | 8. Swift |\n|--------|-------|-----------|----------|\n| ‚úîÔ∏è      |  ‚úîÔ∏è    | ‚úîÔ∏è         |  ‚úîÔ∏è       |\n\n| 9. Go | 10. Dart | 11. Rust | 12. Pascal |\n|-------|----------|----------|------------|\n| ‚úîÔ∏è     |  ‚úîÔ∏è       |   ‚úîÔ∏è      |    ‚úîÔ∏è       |\n\nFor Rust support, please see [sherpa-rs][sherpa-rs]\n\nIt also supports WebAssembly.\n\n### Supported NPUs\n\n| [1. Rockchip NPU (RKNN)][rknpu-doc] | [2. Qualcomm NPU (QNN)][qnn-doc]  | [3. Ascend NPU][ascend-doc] |\n|-------------------------------------|-----------------------------------|-----------------------------|\n|     ‚úîÔ∏è                              |                  ‚úîÔ∏è               |     ‚úîÔ∏è                      |\n\n| [4. Axera NPU][axera-npu] |\n|---------------------------|\n|     ‚úîÔ∏è                    |\n\n[Join our discord](https://discord.gg/fJdxzg2VbG)\n\n\n## Introduction\n\nThis repository supports running the following functions **locally**\n\n  - Speech-to-text (i.e., ASR); both streaming and non-streaming are supported\n  - Text-to-speech (i.e., TTS)\n  - Speaker diarization\n  - Speaker identification\n  - Speaker verification\n  - Spoken language identification\n  - Audio tagging\n  - VAD (e.g., [silero-vad][silero-vad])\n  - Speech enhancement (e.g., [gtcrn][gtcrn])\n  - Keyword spotting\n  - Source separation (e.g., [spleeter][spleeter], [UVR][UVR])\n\non the following platforms and operating systems:\n\n  - x86, ``x86_64``, 32-bit ARM, 64-bit ARM (arm64, aarch64), RISC-V (riscv64), **RK NPU**, **Ascend NPU**\n  - Linux, macOS, Windows, openKylin\n  - Android, WearOS\n  - iOS\n  - HarmonyOS\n  - NodeJS\n  - WebAssembly\n  - [NVIDIA Jetson Orin NX][NVIDIA Jetson Orin NX] (Support running on both CPU and GPU)\n  - [NVIDIA Jetson Nano B01][NVIDIA Jetson Nano B01] (Support running on both CPU and GPU)\n  - [Raspberry Pi][Raspberry Pi]\n  - [RV1126][RV1126]\n  - [LicheePi4A][LicheePi4A]\n  - [VisionFive 2][VisionFive 2]\n  - [Êó≠Êó•X3Ê¥æ][Êó≠Êó•X3Ê¥æ]\n  - [Áà±ËäØÊ¥æ][Áà±ËäØÊ¥æ]\n  - [RK3588][RK3588]\n  - etc\n\nwith the following APIs\n\n  - C++, C, Python, Go, ``C#``\n  - Java, Kotlin, JavaScript\n  - Swift, Rust\n  - Dart, Object Pascal\n\n### Links for Huggingface Spaces\n\n<details>\n<summary>You can visit the following Huggingface spaces to try sherpa-onnx without\ninstalling anything. All you need is a browser.</summary>\n\n| Description                                           | URL                                     | ‰∏≠ÂõΩÈïúÂÉè                               |\n|-------------------------------------------------------|-----------------------------------------|----------------------------------------|\n| Speaker diarization                                   | [Click me][hf-space-speaker-diarization]| [ÈïúÂÉè][hf-space-speaker-diarization-cn]|\n| Speech recognition                                    | [Click me][hf-space-asr]                | [ÈïúÂÉè][hf-space-asr-cn]                |\n| Speech recognition with [Whisper][Whisper]            | [Click me][hf-space-asr-whisper]        | [ÈïúÂÉè][hf-space-asr-whisper-cn]        |\n| Speech synthesis                                      | [Click me][hf-space-tts]                | [ÈïúÂÉè][hf-space-tts-cn]                |\n| Generate subtitles                                    | [Click me][hf-space-subtitle]           | [ÈïúÂÉè][hf-space-subtitle-cn]           |\n| Audio tagging                                         | [Click me][hf-space-audio-tagging]      | [ÈïúÂÉè][hf-space-audio-tagging-cn]      |\n| Source separation                                     | [Click me][hf-space-source-separation]  | [ÈïúÂÉè][hf-space-source-separation-cn]  |\n| Spoken language identification with [Whisper][Whisper]| [Click me][hf-space-slid-whisper]       | [ÈïúÂÉè][hf-space-slid-whisper-cn]       |\n\nWe also have spaces built using WebAssembly. They are listed below:\n\n| Description                                                                              | Huggingface space| ModelScope space|\n|------------------------------------------------------------------------------------------|------------------|-----------------|\n|Voice activity detection with [silero-vad][silero-vad]                                    | [Click me][wasm-hf-vad]|[Âú∞ÂùÄ][wasm-ms-vad]|\n|Real-time speech recognition (Chinese + English) with Zipformer                           | [Click me][wasm-hf-streaming-asr-zh-en-zipformer]|[Âú∞ÂùÄ][wasm-hf-streaming-asr-zh-en-zipformer]|\n|Real-time speech recognition (Chinese + English) with Paraformer                          |[Click me][wasm-hf-streaming-asr-zh-en-paraformer]| [Âú∞ÂùÄ][wasm-ms-streaming-asr-zh-en-paraformer]|\n|Real-time speech recognition (Chinese + English + Cantonese) with [Paraformer-large][Paraformer-large]|[Click me][wasm-hf-streaming-asr-zh-en-yue-paraformer]| [Âú∞ÂùÄ][wasm-ms-streaming-asr-zh-en-yue-paraformer]|\n|Real-time speech recognition (English) |[Click me][wasm-hf-streaming-asr-en-zipformer]    |[Âú∞ÂùÄ][wasm-ms-streaming-asr-en-zipformer]|\n|VAD + speech recognition (Chinese) with [Zipformer CTC](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/icefall/zipformer.html#sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03-chinese)|[Click me][wasm-hf-vad-asr-zh-zipformer-ctc-07-03]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-zipformer-ctc-07-03]|\n|VAD + speech recognition (Chinese + English + Korean + Japanese + Cantonese) with [SenseVoice][SenseVoice]|[Click me][wasm-hf-vad-asr-zh-en-ko-ja-yue-sense-voice]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-en-ko-ja-yue-sense-voice]|\n|VAD + speech recognition (English) with [Whisper][Whisper] tiny.en|[Click me][wasm-hf-vad-asr-en-whisper-tiny-en]| [Âú∞ÂùÄ][wasm-ms-vad-asr-en-whisper-tiny-en]|\n|VAD + speech recognition (English) with [Moonshine tiny][Moonshine tiny]|[Click me][wasm-hf-vad-asr-en-moonshine-tiny-en]| [Âú∞ÂùÄ][wasm-ms-vad-asr-en-moonshine-tiny-en]|\n|VAD + speech recognition (English) with Zipformer trained with [GigaSpeech][GigaSpeech]    |[Click me][wasm-hf-vad-asr-en-zipformer-gigaspeech]| [Âú∞ÂùÄ][wasm-ms-vad-asr-en-zipformer-gigaspeech]|\n|VAD + speech recognition (Chinese) with Zipformer trained with [WenetSpeech][WenetSpeech]  |[Click me][wasm-hf-vad-asr-zh-zipformer-wenetspeech]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-zipformer-wenetspeech]|\n|VAD + speech recognition (Japanese) with Zipformer trained with [ReazonSpeech][ReazonSpeech]|[Click me][wasm-hf-vad-asr-ja-zipformer-reazonspeech]| [Âú∞ÂùÄ][wasm-ms-vad-asr-ja-zipformer-reazonspeech]|\n|VAD + speech recognition (Thai) with Zipformer trained with [GigaSpeech2][GigaSpeech2]      |[Click me][wasm-hf-vad-asr-th-zipformer-gigaspeech2]| [Âú∞ÂùÄ][wasm-ms-vad-asr-th-zipformer-gigaspeech2]|\n|VAD + speech recognition (Chinese Â§öÁßçÊñπË®Ä) with a [TeleSpeech-ASR][TeleSpeech-ASR] CTC model|[Click me][wasm-hf-vad-asr-zh-telespeech]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-telespeech]|\n|VAD + speech recognition (English + Chinese, ÂèäÂ§öÁßç‰∏≠ÊñáÊñπË®Ä) with Paraformer-large          |[Click me][wasm-hf-vad-asr-zh-en-paraformer-large]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-en-paraformer-large]|\n|VAD + speech recognition (English + Chinese, ÂèäÂ§öÁßç‰∏≠ÊñáÊñπË®Ä) with Paraformer-small          |[Click me][wasm-hf-vad-asr-zh-en-paraformer-small]| [Âú∞ÂùÄ][wasm-ms-vad-asr-zh-en-paraformer-small]|\n|VAD + speech recognition (Â§öËØ≠ÁßçÂèäÂ§öÁßç‰∏≠ÊñáÊñπË®Ä) with [Dolphin][Dolphin]-base          |[Click me][wasm-hf-vad-asr-multi-lang-dolphin-base]| [Âú∞ÂùÄ][wasm-ms-vad-asr-multi-lang-dolphin-base]|\n|Speech synthesis (Piper, English)                                                                  |[Click me][wasm-hf-tts-piper-en]| [Âú∞ÂùÄ][wasm-ms-tts-piper-en]|\n|Speech synthesis (Piper, German)                                                                   |[Click me][wasm-hf-tts-piper-de]| [Âú∞ÂùÄ][wasm-ms-tts-piper-de]|\n|Speech synthesis (Matcha, Chinese)                                                                  |[Click me][wasm-hf-tts-matcha-zh]| [Âú∞ÂùÄ][wasm-ms-tts-matcha-zh]|\n|Speech synthesis (Matcha, English)                                                                  |[Click me][wasm-hf-tts-matcha-en]| [Âú∞ÂùÄ][wasm-ms-tts-matcha-en]|\n|Speech synthesis (Matcha, Chinese+English)                                                          |[Click me][wasm-hf-tts-matcha-zh-en]| [Âú∞ÂùÄ][wasm-ms-tts-matcha-zh-en]|\n|Speaker diarization                                                                         |[Click me][wasm-hf-speaker-diarization]|[Âú∞ÂùÄ][wasm-ms-speaker-diarization]|\n\n</details>\n\n### Links for pre-built Android APKs\n\n<details>\n\n<summary>You can find pre-built Android APKs for this repository in the following table</summary>\n\n| Description                            | URL                                | ‰∏≠ÂõΩÁî®Êà∑                          |\n|----------------------------------------|------------------------------------|-----------------------------------|\n| Speaker diarization                    | [Address][apk-speaker-diarization] | [ÁÇπÊ≠§][apk-speaker-diarization-cn]|\n| Streaming speech recognition           | [Address][apk-streaming-asr]       | [ÁÇπÊ≠§][apk-streaming-asr-cn]      |\n| Simulated-streaming speech recognition | [Address][apk-simula-streaming-asr]| [ÁÇπÊ≠§][apk-simula-streaming-asr-cn]|\n| Text-to-speech                         | [Address][apk-tts]                 | [ÁÇπÊ≠§][apk-tts-cn]                |\n| Voice activity detection (VAD)         | [Address][apk-vad]                 | [ÁÇπÊ≠§][apk-vad-cn]                |\n| VAD + non-streaming speech recognition | [Address][apk-vad-asr]             | [ÁÇπÊ≠§][apk-vad-asr-cn]            |\n| Two-pass speech recognition            | [Address][apk-2pass]               | [ÁÇπÊ≠§][apk-2pass-cn]              |\n| Audio tagging                          | [Address][apk-at]                  | [ÁÇπÊ≠§][apk-at-cn]                 |\n| Audio tagging (WearOS)                 | [Address][apk-at-wearos]           | [ÁÇπÊ≠§][apk-at-wearos-cn]          |\n| Speaker identification                 | [Address][apk-sid]                 | [ÁÇπÊ≠§][apk-sid-cn]                |\n| Spoken language identification         | [Address][apk-slid]                | [ÁÇπÊ≠§][apk-slid-cn]               |\n| Keyword spotting                       | [Address][apk-kws]                 | [ÁÇπÊ≠§][apk-kws-cn]                |\n\n</details>\n\n### Links for pre-built Flutter APPs\n\n<details>\n\n#### Real-time speech recognition\n\n| Description                    | URL                                 | ‰∏≠ÂõΩÁî®Êà∑                            |\n|--------------------------------|-------------------------------------|-------------------------------------|\n| Streaming speech recognition   | [Address][apk-flutter-streaming-asr]| [ÁÇπÊ≠§][apk-flutter-streaming-asr-cn]|\n\n#### Text-to-speech\n\n| Description                              | URL                                | ‰∏≠ÂõΩÁî®Êà∑                           |\n|------------------------------------------|------------------------------------|------------------------------------|\n| Android (arm64-v8a, armeabi-v7a, x86_64) | [Address][flutter-tts-android]     | [ÁÇπÊ≠§][flutter-tts-android-cn]     |\n| Linux (x64)                              | [Address][flutter-tts-linux]       | [ÁÇπÊ≠§][flutter-tts-linux-cn]       |\n| macOS (x64)                              | [Address][flutter-tts-macos-x64]   | [ÁÇπÊ≠§][flutter-tts-macos-x64-cn] |\n| macOS (arm64)                            | [Address][flutter-tts-macos-arm64] | [ÁÇπÊ≠§][flutter-tts-macos-arm64-cn]   |\n| Windows (x64)                            | [Address][flutter-tts-win-x64]     | [ÁÇπÊ≠§][flutter-tts-win-x64-cn]     |\n\n> Note: You need to build from source for iOS.\n\n</details>\n\n### Links for pre-built Lazarus APPs\n\n<details>\n\n#### Generating subtitles\n\n| Description                    | URL                        | ‰∏≠ÂõΩÁî®Êà∑                   |\n|--------------------------------|----------------------------|----------------------------|\n| Generate subtitles (ÁîüÊàêÂ≠óÂπï)  | [Address][lazarus-subtitle]| [ÁÇπÊ≠§][lazarus-subtitle-cn]|\n\n</details>\n\n### Links for pre-trained models\n\n<details>\n\n| Description                                 | URL                                                                                   |\n|---------------------------------------------|---------------------------------------------------------------------------------------|\n| Speech recognition (speech to text, ASR)    | [Address][asr-models]                                                                 |\n| Text-to-speech (TTS)                        | [Address][tts-models]                                                                 |\n| VAD                                         | [Address][vad-models]                                                                 |\n| Keyword spotting                            | [Address][kws-models]                                                                 |\n| Audio tagging                               | [Address][at-models]                                                                  |\n| Speaker identification (Speaker ID)         | [Address][sid-models]                                                                 |\n| Spoken language identification (Language ID)| See multi-lingual [Whisper][Whisper] ASR models from  [Speech recognition][asr-models]|\n| Punctuation                                 | [Address][punct-models]                                                               |\n| Speaker segmentation                        | [Address][speaker-segmentation-models]                                                |\n| Speech enhancement                          | [Address][speech-enhancement-models]                                                  |\n| Source separation                           | [Address][source-separation-models]                                                  |\n\n</details>\n\n#### Some pre-trained ASR models (Streaming)\n\n<details>\n\nPlease see\n\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-paraformer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-ctc/index.html>\n\nfor more models. The following table lists only **SOME** of them.\n\n\n|Name | Supported Languages| Description|\n|-----|-----|----|\n|[sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20][sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20]| Chinese, English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english)|\n|[sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16][sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16]| Chinese, English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16-bilingual-chinese-english)|\n|[sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23][sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23]|Chinese| Suitable for Cortex A7 CPU. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-zh-14m-2023-02-23)|\n|[sherpa-onnx-streaming-zipformer-en-20M-2023-02-17][sherpa-onnx-streaming-zipformer-en-20M-2023-02-17]|English|Suitable for Cortex A7 CPU. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-en-20m-2023-02-17)|\n|[sherpa-onnx-streaming-zipformer-korean-2024-06-16][sherpa-onnx-streaming-zipformer-korean-2024-06-16]|Korean| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-korean-2024-06-16-korean)|\n|[sherpa-onnx-streaming-zipformer-fr-2023-04-14][sherpa-onnx-streaming-zipformer-fr-2023-04-14]|French| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#shaojieli-sherpa-onnx-streaming-zipformer-fr-2023-04-14-french)|\n\n</details>\n\n\n#### Some pre-trained ASR models (Non-Streaming)\n\n<details>\n\nPlease see\n\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-paraformer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/telespeech/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/whisper/index.html>\n\nfor more models. The following table lists only **SOME** of them.\n\n|Name | Supported Languages| Description|\n|-----|-----|----|\n|[sherpa-onnx-nemo-parakeet-tdt-0.6b-v2-int8](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-parakeet-tdt-0-6b-v2-int8-english)| English | It is converted from <https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2>|\n|[Whisper tiny.en](https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-whisper-tiny.en.tar.bz2)|English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/whisper/tiny.en.html)|\n|[Moonshine tiny][Moonshine tiny]|English|See [also](https://github.com/usefulsensors/moonshine)|\n|[sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/icefall/zipformer.html#sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03-chinese)|Chinese| A Zipformer CTC model|\n|[sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17][sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17]|Chinese, Cantonese, English, Korean, Japanese| ÊîØÊåÅÂ§öÁßç‰∏≠ÊñáÊñπË®Ä. See [also](https://k2-fsa.github.io/sherpa/onnx/sense-voice/index.html)|\n|[sherpa-onnx-paraformer-zh-2024-03-09][sherpa-onnx-paraformer-zh-2024-03-09]|Chinese, English| ‰πüÊîØÊåÅÂ§öÁßç‰∏≠ÊñáÊñπË®Ä. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2024-03-09-chinese-english)|\n|[sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01][sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01]|Japanese|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01-japanese)|\n|[sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24][sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24]|Russian|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24-russian)|\n|[sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24][sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24]|Russian| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/nemo/russian.html#sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24)|\n|[sherpa-onnx-zipformer-ru-2024-09-18][sherpa-onnx-zipformer-ru-2024-09-18]|Russian|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-ru-2024-09-18-russian)|\n|[sherpa-onnx-zipformer-korean-2024-06-24][sherpa-onnx-zipformer-korean-2024-06-24]|Korean|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-korean-2024-06-24-korean)|\n|[sherpa-onnx-zipformer-thai-2024-06-20][sherpa-onnx-zipformer-thai-2024-06-20]|Thai| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-thai-2024-06-20-thai)|\n|[sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04][sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04]|Chinese| ÊîØÊåÅÂ§öÁßçÊñπË®Ä. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/telespeech/models.html#sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04)|\n\n</details>\n\n### Useful links\n\n- Documentation: https://k2-fsa.github.io/sherpa/onnx/\n- Bilibili ÊºîÁ§∫ËßÜÈ¢ë: https://search.bilibili.com/all?keyword=%E6%96%B0%E4%B8%80%E4%BB%A3Kaldi\n\n### How to reach us\n\nPlease see\nhttps://k2-fsa.github.io/sherpa/social-groups.html\nfor Êñ∞‰∏Ä‰ª£ Kaldi **ÂæÆ‰ø°‰∫§ÊµÅÁæ§** and **QQ ‰∫§ÊµÅÁæ§**.\n\n## Projects using sherpa-onnx\n\n### [BreezeApp](https://github.com/mtkresearch/BreezeApp) from [MediaTek Research](https://github.com/mtkresearch)\n\n> BreezeAPP is a mobile AI application developed for both Android and iOS platforms.\n> Users can download it directly from the App Store and enjoy a variety of features\n> offline, including speech-to-text, text-to-speech, text-based chatbot interactions,\n> and image question-answering\n\n  - [Download APK for BreezeAPP](https://huggingface.co/MediaTek-Research/BreezeApp/resolve/main/BreezeApp.apk)\n  - [APK ‰∏≠ÂõΩÈïúÂÉè](https://hf-mirror.com/MediaTek-Research/BreezeApp/blob/main/BreezeApp.apk)\n\n| 1 | 2 | 3 |\n|---|---|---|\n|![](https://github.com/user-attachments/assets/1cdbc057-b893-4de6-9e9c-f1d7dfd1d992)|![](https://github.com/user-attachments/assets/d77cd98e-b057-442f-860d-d5befd5c769b)|![](https://github.com/user-attachments/assets/57e546bf-3d39-45b9-b392-b48ca4fb3c58)|\n\n### [Open-LLM-VTuber](https://github.com/t41372/Open-LLM-VTuber)\n\nTalk to any LLM with hands-free voice interaction, voice interruption, and Live2D taking\nface running locally across platforms\n\nSee also <https://github.com/t41372/Open-LLM-VTuber/pull/50>\n\n### [voiceapi](https://github.com/ruzhila/voiceapi)\n\n<details>\n  <summary>Streaming ASR and TTS based on FastAPI</summary>\n\n\nIt shows how to use the ASR and TTS Python APIs with FastAPI.\n</details>\n\n### [ËÖæËÆØ‰ºöËÆÆÊë∏È±ºÂ∑•ÂÖ∑ TMSpeech](https://github.com/jxlpzqc/TMSpeech)\n\nUses streaming ASR in C# with graphical user interface.\n\nVideo demo in Chinese: [„ÄêÂºÄÊ∫ê„ÄëWindowsÂÆûÊó∂Â≠óÂπïËΩØ‰ª∂ÔºàÁΩëËØæ/ÂºÄ‰ºöÂøÖÂ§áÔºâ](https://www.bilibili.com/video/BV1rX4y1p7Nx)\n\n### [lol‰∫íÂä®Âä©Êâã](https://github.com/l1veIn/lol-wom-electron)\n\nIt uses the JavaScript API of sherpa-onnx along with [Electron](https://electronjs.org/)\n\nVideo demo in Chinese: [ÁàÜ‰∫ÜÔºÅÁÇ´Á•ûÊïô‰Ω†ÂºÄÊâìÂ≠óÊåÇÔºÅÁúüÊ≠£ÂΩ±ÂìçËÉúÁéáÁöÑËã±ÈõÑËÅîÁõüÂ∑•ÂÖ∑ÔºÅËã±ÈõÑËÅîÁõüÁöÑÊúÄÂêé‰∏ÄÂùóÊãºÂõæÔºÅÂíåÊ∏∏Êàè‰∏≠ÁöÑÊØè‰∏™‰∫∫Êó†ÈöúÁ¢çÊ≤üÈÄöÔºÅ](https://www.bilibili.com/video/BV142tje9E74)\n\n### [Sherpa-ONNX ËØ≠Èü≥ËØÜÂà´ÊúçÂä°Âô®](https://github.com/hfyydd/sherpa-onnx-server)\n\nA server based on nodejs providing Restful API for speech recognition.\n\n### [QSmartAssistant](https://github.com/xinhecuican/QSmartAssistant)\n\n‰∏Ä‰∏™Ê®°ÂùóÂåñÔºåÂÖ®ËøáÁ®ãÂèØÁ¶ªÁ∫øÔºå‰ΩéÂç†Áî®ÁéáÁöÑÂØπËØùÊú∫Âô®‰∫∫/Êô∫ËÉΩÈü≥ÁÆ±\n\nIt uses QT. Both [ASR](https://github.com/xinhecuican/QSmartAssistant/blob/master/doc/%E5%AE%89%E8%A3%85.md#asr)\nand [TTS](https://github.com/xinhecuican/QSmartAssistant/blob/master/doc/%E5%AE%89%E8%A3%85.md#tts)\nare used.\n\n### [Flutter-EasySpeechRecognition](https://github.com/Jason-chen-coder/Flutter-EasySpeechRecognition)\n\nIt extends [./flutter-examples/streaming_asr](./flutter-examples/streaming_asr) by\ndownloading models inside the app to reduce the size of the app.\n\nNote: [[Team B] Sherpa AI backend](https://github.com/umgc/spring2025/pull/82) also uses\nsherpa-onnx in a Flutter APP.\n\n### [sherpa-onnx-unity](https://github.com/xue-fei/sherpa-onnx-unity)\n\nsherpa-onnx in Unity. See also [#1695](https://github.com/k2-fsa/sherpa-onnx/issues/1695),\n[#1892](https://github.com/k2-fsa/sherpa-onnx/issues/1892), and [#1859](https://github.com/k2-fsa/sherpa-onnx/issues/1859)\n\n### [xiaozhi-esp32-server](https://github.com/xinnan-tech/xiaozhi-esp32-server)\n\nÊú¨È°πÁõÆ‰∏∫xiaozhi-esp32Êèê‰æõÂêéÁ´ØÊúçÂä°ÔºåÂ∏ÆÂä©ÊÇ®Âø´ÈÄüÊê≠Âª∫ESP32ËÆæÂ§áÊéßÂà∂ÊúçÂä°Âô®\nBackend service for xiaozhi-esp32, helps you quickly build an ESP32 device control server.\n\nSee also\n\n  - [ASRÊñ∞Â¢ûËΩªÈáèÁ∫ßsherpa-onnx-asr](https://github.com/xinnan-tech/xiaozhi-esp32-server/issues/315)\n  - [feat: ASRÂ¢ûÂä†sherpa-onnxÊ®°Âûã](https://github.com/xinnan-tech/xiaozhi-esp32-server/pull/379)\n\n### [KaithemAutomation](https://github.com/EternityForest/KaithemAutomation)\n\nPure Python, GUI-focused home automation/consumer grade SCADA.\n\nIt uses TTS from sherpa-onnx. See also [‚ú® Speak command that uses the new globally configured TTS model.](https://github.com/EternityForest/KaithemAutomation/commit/8e64d2b138725e426532f7d66bb69dd0b4f53693)\n\n### [Open-XiaoAI KWS](https://github.com/idootop/open-xiaoai-kws)\n\nEnable custom wake word for XiaoAi Speakers. ËÆ©Â∞èÁà±Èü≥ÁÆ±ÊîØÊåÅËá™ÂÆö‰πâÂî§ÈÜíËØç„ÄÇ\n\nVideo demo in Chinese: [Â∞èÁà±ÂêåÂ≠¶ÂêØÂä®ÔΩûÀ∂‚ïπÍá¥‚ïπÀ∂ÔºÅ](https://www.bilibili.com/video/BV1YfVUz5EMj)\n\n### [C++ WebSocket ASR Server](https://github.com/mawwalker/stt-server)\n\nIt provides a WebSocket server based on C++ for ASR using sherpa-onnx.\n\n### [Go WebSocket Server](https://github.com/bbeyondllove/asr_server)\n\nIt provides a WebSocket server based on the Go programming language for sherpa-onnx.\n\n### [Making robot Paimon, Ep10 \"The AI Part 1\"](https://www.youtube.com/watch?v=KxPKkwxGWZs)\n\nIt is a [YouTube video](https://www.youtube.com/watch?v=KxPKkwxGWZs),\nshowing how the author tried to use AI so he can have a conversation with Paimon.\n\nIt uses sherpa-onnx for speech-to-text and text-to-speech.\n|1|\n|---|\n|![](https://github.com/user-attachments/assets/f6eea2d5-1807-42cb-9160-be8da2971e1f)|\n\n### [TtsReader - Desktop application](https://github.com/ys-pro-duction/TtsReader)\n\nA desktop text-to-speech application built using Kotlin Multiplatform.\n\n### [MentraOS](https://github.com/Mentra-Community/MentraOS)\n\n> Smart glasses OS, with dozens of built-in apps. Users get AI assistant, notifications,\n> translation, screen mirror, captions, and more. Devs get to write 1 app that runs on\n> any pair of smart glasses.\n\nIt uses sherpa-onnx for real-time speech recognition on iOS and Android devices.\nSee also <https://github.com/Mentra-Community/MentraOS/pull/861>\n\nIt uses Swift for iOS and Java for Android.\n\n### [flet_sherpa_onnx](https://github.com/SamYuan1990/flet_sherpa_onnx)\n\nFlet ASR/STT component based on sherpa-onnx.\nExample [a chat box agent](https://github.com/SamYuan1990/i18n-agent-action)\n\n### [achatbot-go](https://github.com/ai-bot-pro/achatbot-go)\n\na multimodal chatbot based on go with sherpa-onnx's speech lib api.\n\n[sherpa-rs]: https://github.com/thewh1teagle/sherpa-rs\n[silero-vad]: https://github.com/snakers4/silero-vad\n[Raspberry Pi]: https://www.raspberrypi.com/\n[RV1126]: https://www.rock-chips.com/uploads/pdf/2022.8.26/191/RV1126%20Brief%20Datasheet.pdf\n[LicheePi4A]: https://sipeed.com/licheepi4a\n[VisionFive 2]: https://www.starfivetech.com/en/site/boards\n[Êó≠Êó•X3Ê¥æ]: https://developer.horizon.ai/api/v1/fileData/documents_pi/index.html\n[Áà±ËäØÊ¥æ]: https://wiki.sipeed.com/hardware/zh/maixIII/ax-pi/axpi.html\n[hf-space-speaker-diarization]: https://huggingface.co/spaces/k2-fsa/speaker-diarization\n[hf-space-speaker-diarization-cn]: https://hf.qhduan.com/spaces/k2-fsa/speaker-diarization\n[hf-space-asr]: https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition\n[hf-space-asr-cn]: https://hf.qhduan.com/spaces/k2-fsa/automatic-speech-recognition\n[Whisper]: https://github.com/openai/whisper\n[hf-space-asr-whisper]: https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition-with-whisper\n[hf-space-asr-whisper-cn]: https://hf.qhduan.com/spaces/k2-fsa/automatic-speech-recognition-with-whisper\n[hf-space-tts]: https://huggingface.co/spaces/k2-fsa/text-to-speech\n[hf-space-tts-cn]: https://hf.qhduan.com/spaces/k2-fsa/text-to-speech\n[hf-space-subtitle]: https://huggingface.co/spaces/k2-fsa/generate-subtitles-for-videos\n[hf-space-subtitle-cn]: https://hf.qhduan.com/spaces/k2-fsa/generate-subtitles-for-videos\n[hf-space-audio-tagging]: https://huggingface.co/spaces/k2-fsa/audio-tagging\n[hf-space-audio-tagging-cn]: https://hf.qhduan.com/spaces/k2-fsa/audio-tagging\n[hf-space-source-separation]: https://huggingface.co/spaces/k2-fsa/source-separation\n[hf-space-source-separation-cn]: https://hf.qhduan.com/spaces/k2-fsa/source-separation\n[hf-space-slid-whisper]: https://huggingface.co/spaces/k2-fsa/spoken-language-identification\n[hf-space-slid-whisper-cn]: https://hf.qhduan.com/spaces/k2-fsa/spoken-language-identification\n[wasm-hf-vad]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-sherpa-onnx\n[wasm-ms-vad]: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-sherpa-onnx\n[wasm-hf-streaming-asr-zh-en-zipformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en\n[wasm-ms-streaming-asr-zh-en-zipformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en\n[wasm-hf-streaming-asr-zh-en-paraformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en-paraformer\n[wasm-ms-streaming-asr-zh-en-paraformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en-paraformer\n[Paraformer-large]: https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary\n[wasm-hf-streaming-asr-zh-en-yue-paraformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-cantonese-en-paraformer\n[wasm-ms-streaming-asr-zh-en-yue-paraformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-cantonese-en-paraformer\n[wasm-hf-streaming-asr-en-zipformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-en\n[wasm-ms-streaming-asr-en-zipformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-en\n[SenseVoice]: https://github.com/FunAudioLLM/SenseVoice\n[wasm-hf-vad-asr-zh-zipformer-ctc-07-03]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-ctc\n[wasm-ms-vad-asr-zh-zipformer-ctc-07-03]: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-ctc/summary\n[wasm-hf-vad-asr-zh-en-ko-ja-yue-sense-voice]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-ja-ko-cantonese-sense-voice\n[wasm-ms-vad-asr-zh-en-ko-ja-yue-sense-voice]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-zh-en-jp-ko-cantonese-sense-voice\n[wasm-hf-vad-asr-en-whisper-tiny-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-whisper-tiny\n[wasm-ms-vad-asr-en-whisper-tiny-en]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-en-whisper-tiny\n[wasm-hf-vad-asr-en-moonshine-tiny-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-moonshine-tiny\n[wasm-ms-vad-asr-en-moonshine-tiny-en]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-en-moonshine-tiny\n[wasm-hf-vad-asr-en-zipformer-gigaspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-zipformer-gigaspeech\n[wasm-ms-vad-asr-en-zipformer-gigaspeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-zipformer-gigaspeech\n[wasm-hf-vad-asr-zh-zipformer-wenetspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-wenetspeech\n[wasm-ms-vad-asr-zh-zipformer-wenetspeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-wenetspeech\n[reazonspeech]: https://research.reazon.jp/_static/reazonspeech_nlp2023.pdf\n[wasm-hf-vad-asr-ja-zipformer-reazonspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-ja-zipformer\n[wasm-ms-vad-asr-ja-zipformer-reazonspeech]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-ja-zipformer\n[gigaspeech2]: https://github.com/speechcolab/gigaspeech2\n[wasm-hf-vad-asr-th-zipformer-gigaspeech2]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-th-zipformer\n[wasm-ms-vad-asr-th-zipformer-gigaspeech2]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-th-zipformer\n[telespeech-asr]: https://github.com/tele-ai/telespeech-asr\n[wasm-hf-vad-asr-zh-telespeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-telespeech\n[wasm-ms-vad-asr-zh-telespeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-telespeech\n[wasm-hf-vad-asr-zh-en-paraformer-large]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer\n[wasm-ms-vad-asr-zh-en-paraformer-large]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer\n[wasm-hf-vad-asr-zh-en-paraformer-small]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer-small\n[wasm-ms-vad-asr-zh-en-paraformer-small]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer-small\n[dolphin]: https://github.com/dataoceanai/dolphin\n[wasm-ms-vad-asr-multi-lang-dolphin-base]: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-multi-lang-dophin-ctc\n[wasm-hf-vad-asr-multi-lang-dolphin-base]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-multi-lang-dophin-ctc\n\n[wasm-hf-tts-matcha-zh-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-zh-en-tts-matcha\n[wasm-hf-tts-matcha-zh]: https://huggingface.co/spaces/k2-fsa/web-assembly-zh-tts-matcha\n[wasm-ms-tts-matcha-zh-en]: https://modelscope.cn/studios/csukuangfj/web-assembly-zh-en-tts-matcha\n[wasm-ms-tts-matcha-zh]: https://modelscope.cn/studios/csukuangfj/web-assembly-zh-tts-matcha\n[wasm-hf-tts-matcha-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-en-tts-matcha\n[wasm-ms-tts-matcha-en]: https://modelscope.cn/studios/csukuangfj/web-assembly-en-tts-matcha\n[wasm-hf-tts-piper-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-tts-sherpa-onnx-en\n[wasm-ms-tts-piper-en]: https://modelscope.cn/studios/k2-fsa/web-assembly-tts-sherpa-onnx-en\n[wasm-hf-tts-piper-de]: https://huggingface.co/spaces/k2-fsa/web-assembly-tts-sherpa-onnx-de\n[wasm-ms-tts-piper-de]: https://modelscope.cn/studios/k2-fsa/web-assembly-tts-sherpa-onnx-de\n[wasm-hf-speaker-diarization]: https://huggingface.co/spaces/k2-fsa/web-assembly-speaker-diarization-sherpa-onnx\n[wasm-ms-speaker-diarization]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-speaker-diarization-sherpa-onnx\n[apk-speaker-diarization]: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/apk.html\n[apk-speaker-diarization-cn]: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/apk-cn.html\n[apk-streaming-asr]: https://k2-fsa.github.io/sherpa/onnx/android/apk.html\n[apk-streaming-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/android/apk-cn.html\n[apk-simula-streaming-asr]: https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr.html\n[apk-simula-streaming-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr-cn.html\n[apk-tts]: https://k2-fsa.github.io/sherpa/onnx/tts/apk-engine.html\n[apk-tts-cn]: https://k2-fsa.github.io/sherpa/onnx/tts/apk-engine-cn.html\n[apk-vad]: https://k2-fsa.github.io/sherpa/onnx/vad/apk.html\n[apk-vad-cn]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-cn.html\n[apk-vad-asr]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-asr.html\n[apk-vad-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-asr-cn.html\n[apk-2pass]: https://k2-fsa.github.io/sherpa/onnx/android/apk-2pass.html\n[apk-2pass-cn]: https://k2-fsa.github.io/sherpa/onnx/android/apk-2pass-cn.html\n[apk-at]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk.html\n[apk-at-cn]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-cn.html\n[apk-at-wearos]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-wearos.html\n[apk-at-wearos-cn]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-wearos-cn.html\n[apk-sid]: https://k2-fsa.github.io/sherpa/onnx/speaker-identification/apk.html\n[apk-sid-cn]: https://k2-fsa.github.io/sherpa/onnx/speaker-identification/apk-cn.html\n[apk-slid]: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/apk.html\n[apk-slid-cn]: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/apk-cn.html\n[apk-kws]: https://k2-fsa.github.io/sherpa/onnx/kws/apk.html\n[apk-kws-cn]: https://k2-fsa.github.io/sherpa/onnx/kws/apk-cn.html\n[apk-flutter-streaming-asr]: https://k2-fsa.github.io/sherpa/onnx/flutter/asr/app.html\n[apk-flutter-streaming-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/asr/app-cn.html\n[flutter-tts-android]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-android.html\n[flutter-tts-android-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-android-cn.html\n[flutter-tts-linux]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-linux.html\n[flutter-tts-linux-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-linux-cn.html\n[flutter-tts-macos-x64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-x64.html\n[flutter-tts-macos-arm64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-arm64-cn.html\n[flutter-tts-macos-arm64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-arm64.html\n[flutter-tts-macos-x64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-x64-cn.html\n[flutter-tts-win-x64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-win.html\n[flutter-tts-win-x64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-win-cn.html\n[lazarus-subtitle]: https://k2-fsa.github.io/sherpa/onnx/lazarus/download-generated-subtitles.html\n[lazarus-subtitle-cn]: https://k2-fsa.github.io/sherpa/onnx/lazarus/download-generated-subtitles-cn.html\n[asr-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/asr-models\n[tts-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/tts-models\n[vad-models]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx\n[kws-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/kws-models\n[at-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/audio-tagging-models\n[sid-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-recongition-models\n[slid-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-recongition-models\n[punct-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/punctuation-models\n[speaker-segmentation-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-segmentation-models\n[GigaSpeech]: https://github.com/SpeechColab/GigaSpeech\n[WenetSpeech]: https://github.com/wenet-e2e/WenetSpeech\n[sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20.tar.bz2\n[sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16.tar.bz2\n[sherpa-onnx-streaming-zipformer-korean-2024-06-16]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-korean-2024-06-16.tar.bz2\n[sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23.tar.bz2\n[sherpa-onnx-streaming-zipformer-en-20M-2023-02-17]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-en-20M-2023-02-17.tar.bz2\n[sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01.tar.bz2\n[sherpa-onnx-zipformer-ru-2024-09-18]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ru-2024-09-18.tar.bz2\n[sherpa-onnx-zipformer-korean-2024-06-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-korean-2024-06-24.tar.bz2\n[sherpa-onnx-zipformer-thai-2024-06-20]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-thai-2024-06-20.tar.bz2\n[sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24.tar.bz2\n[sherpa-onnx-paraformer-zh-2024-03-09]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-paraformer-zh-2024-03-09.tar.bz2\n[sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24.tar.bz2\n[sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04.tar.bz2\n[sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17.tar.bz2\n[sherpa-onnx-streaming-zipformer-fr-2023-04-14]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-fr-2023-04-14.tar.bz2\n[Moonshine tiny]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-moonshine-tiny-en-int8.tar.bz2\n[NVIDIA Jetson Orin NX]: https://developer.download.nvidia.com/assets/embedded/secure/jetson/orin_nx/docs/Jetson_Orin_NX_DS-10712-001_v0.5.pdf?RCPGu9Q6OVAOv7a7vgtwc9-BLScXRIWq6cSLuditMALECJ_dOj27DgnqAPGVnT2VpiNpQan9SyFy-9zRykR58CokzbXwjSA7Gj819e91AXPrWkGZR3oS1VLxiDEpJa_Y0lr7UT-N4GnXtb8NlUkP4GkCkkF_FQivGPrAucCUywL481GH_WpP_p7ziHU1Wg==&t=eyJscyI6ImdzZW8iLCJsc2QiOiJodHRwczovL3d3dy5nb29nbGUuY29tLmhrLyJ9\n[NVIDIA Jetson Nano B01]: https://www.seeedstudio.com/blog/2020/01/16/new-revision-of-jetson-nano-dev-kit-now-supports-new-jetson-nano-module/\n[speech-enhancement-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speech-enhancement-models\n[source-separation-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/source-separation-models\n[RK3588]: https://www.rock-chips.com/uploads/pdf/2022.8.26/192/RK3588%20Brief%20Datasheet.pdf\n[spleeter]: https://github.com/deezer/spleeter\n[UVR]: https://github.com/Anjok07/ultimatevocalremovergui\n[gtcrn]: https://github.com/Xiaobin-Rong/gtcrn\n[tts-url]: https://k2-fsa.github.io/sherpa/onnx/tts/all-in-one.html\n[ss-url]: https://k2-fsa.github.io/sherpa/onnx/source-separation/index.html\n[sd-url]: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/index.html\n[slid-url]: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/index.html\n[at-url]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/index.html\n[vad-url]: https://k2-fsa.github.io/sherpa/onnx/vad/index.html\n[kws-url]: https://k2-fsa.github.io/sherpa/onnx/kws/index.html\n[punct-url]: https://k2-fsa.github.io/sherpa/onnx/punctuation/index.html\n[se-url]: https://k2-fsa.github.io/sherpa/onnx/speech-enhancement/index.html\n[rknpu-doc]: https://k2-fsa.github.io/sherpa/onnx/rknn/index.html\n[qnn-doc]: https://k2-fsa.github.io/sherpa/onnx/qnn/index.html\n[ascend-doc]: https://k2-fsa.github.io/sherpa/onnx/ascend/index.html\n[axera-npu]: https://axera-tech.com/Skill/166.html\n",
      "stars_today": 26
    },
    {
      "id": 993475914,
      "name": "container",
      "full_name": "apple/container",
      "description": "A tool for creating and running Linux containers using lightweight virtual machines on a Mac. It is written in Swift, and optimized for Apple silicon. ",
      "html_url": "https://github.com/apple/container",
      "stars": 23301,
      "forks": 586,
      "language": "Swift",
      "topics": [],
      "created_at": "2025-05-30T21:26:05Z",
      "updated_at": "2026-01-17T00:26:18Z",
      "pushed_at": "2026-01-17T00:26:14Z",
      "open_issues": 244,
      "owner": {
        "login": "apple",
        "avatar_url": "https://avatars.githubusercontent.com/u/10639145?v=4"
      },
      "readme": "# `container`\n\n`container` is a tool that you can use to create and run Linux containers as lightweight virtual machines on your Mac. It's written in Swift, and optimized for Apple silicon.\n\nThe tool consumes and produces [OCI-compatible container images](https://github.com/opencontainers/image-spec), so you can pull and run images from any standard container registry. You can push images that you build to those registries as well, and run the images in any other OCI-compatible application.\n\n`container` uses the [Containerization](https://github.com/apple/containerization) Swift package for low level container, image, and process management.\n\n![introductory movie showing some basic commands](./docs/assets/landing-movie.gif)\n\n## Get started\n\n### Requirements\n\nYou need a Mac with Apple silicon to run `container`. To build it, see the [BUILDING](./BUILDING.md) document.\n\n`container` is supported on macOS 26, since it takes advantage of new features and enhancements to virtualization and networking in this release. We do not support older versions of macOS and the `container` maintainers typically will not address issues that cannot be reproduced on the macOS 26.\n\n### Install or upgrade\n\nIf you're upgrading, first stop and uninstall your existing `container` (the `-k` flag keeps your user data, while `-d` removes it):\n\n```bash\ncontainer system stop\n/usr/local/bin/uninstall-container.sh -k\n```\n\nDownload the latest signed installer package for `container` from the [GitHub release page](https://github.com/apple/container/releases).\n\nTo install the tool, double-click the package file and follow the instructions. Enter your administrator password when prompted, to give the installer permission to place the installed files under `/usr/local`.\n\nStart the system service with:\n\n```bash\ncontainer system start\n```\n\n### Uninstall\n\nUse the `uninstall-container.sh` script (installed to `/usr/local/bin`) to remove `container` from your system. To remove your user data along with the tool, run:\n\n```bash\n/usr/local/bin/uninstall-container.sh -d\n```\n\nTo retain your user data so that it is available should you reinstall later, run:\n\n```bash\n/usr/local/bin/uninstall-container.sh -k\n```\n\n## Next steps\n\n- Take [a guided tour of `container`](./docs/tutorial.md) by building, running, and publishing a simple web server image.\n- Learn how to [use various `container` features](./docs/how-to.md).\n- Read a brief description and [technical overview](./docs/technical-overview.md) of `container`.\n- Browse the [full command reference](./docs/command-reference.md).\n- [Build and run](./BUILDING.md) `container` on your own development system.\n- View the project [API documentation](https://apple.github.io/container/documentation/).\n\n## Contributing\n\nContributions to `container` are welcomed and encouraged. Please see our [main contributing guide](https://github.com/apple/containerization/blob/main/CONTRIBUTING.md) for more information.\n\n## Project Status\n\nThe container project is currently under active development. Its stability, both for consuming the project as a Swift package and the `container` tool, is only guaranteed within patch versions, such as between 0.1.1 and 0.1.2. Minor version number releases may include breaking changes until we achieve a 1.0.0 release.\n",
      "stars_today": 24
    },
    {
      "id": 11171548,
      "name": "json",
      "full_name": "nlohmann/json",
      "description": "JSON for Modern C++",
      "html_url": "https://github.com/nlohmann/json",
      "stars": 48570,
      "forks": 7293,
      "language": "C++",
      "topics": [
        "bson",
        "cbor",
        "header-only",
        "json",
        "json-diff",
        "json-merge-patch",
        "json-parser",
        "json-patch",
        "json-pointer",
        "json-serialization",
        "messagepack",
        "msgpack",
        "rfc-6901",
        "rfc-6902",
        "rfc-7049",
        "rfc-7159",
        "rfc-8259",
        "stl-containers",
        "ubjson"
      ],
      "created_at": "2013-07-04T08:47:49Z",
      "updated_at": "2026-01-16T23:30:53Z",
      "pushed_at": "2026-01-13T16:19:39Z",
      "open_issues": 97,
      "owner": {
        "login": "nlohmann",
        "avatar_url": "https://avatars.githubusercontent.com/u/159488?v=4"
      },
      "readme": "[![JSON for Modern C++](docs/mkdocs/docs/images/json.gif)](https://github.com/nlohmann/json/releases)\n\n[![Build Status](https://ci.appveyor.com/api/projects/status/1acb366xfyg3qybk/branch/develop?svg=true)](https://ci.appveyor.com/project/nlohmann/json)\n[![Ubuntu](https://github.com/nlohmann/json/workflows/Ubuntu/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AUbuntu)\n[![macOS](https://github.com/nlohmann/json/workflows/macOS/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AmacOS)\n[![Windows](https://github.com/nlohmann/json/workflows/Windows/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AWindows)\n[![Coverage Status](https://coveralls.io/repos/github/nlohmann/json/badge.svg?branch=develop)](https://coveralls.io/github/nlohmann/json?branch=develop)\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/5550/badge.svg)](https://scan.coverity.com/projects/nlohmann-json)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/e0d1a9d5d6fd46fcb655c4cb930bb3e8)](https://app.codacy.com/gh/nlohmann/json/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n[![Cirrus CI](https://api.cirrus-ci.com/github/nlohmann/json.svg)](https://cirrus-ci.com/github/nlohmann/json)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/json.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:json)\n[![Try online](https://img.shields.io/badge/try-online-blue.svg)](https://wandbox.org/permlink/1mp10JbaANo6FUc7)\n[![Documentation](https://img.shields.io/badge/docs-mkdocs-blue.svg)](https://json.nlohmann.me)\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/nlohmann/json/master/LICENSE.MIT)\n[![GitHub Releases](https://img.shields.io/github/release/nlohmann/json.svg)](https://github.com/nlohmann/json/releases)\n[![Packaging status](https://repology.org/badge/tiny-repos/nlohmann-json.svg)](https://repology.org/project/nlohmann-json/versions)\n[![GitHub Downloads](https://img.shields.io/github/downloads/nlohmann/json/total)](https://github.com/nlohmann/json/releases)\n[![GitHub Issues](https://img.shields.io/github/issues/nlohmann/json.svg)](https://github.com/nlohmann/json/issues)\n[![Average time to resolve an issue](https://isitmaintained.com/badge/resolution/nlohmann/json.svg)](https://isitmaintained.com/project/nlohmann/json \"Average time to resolve an issue\")\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/289/badge)](https://bestpractices.coreinfrastructure.org/projects/289)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/nlohmann/json/badge)](https://scorecard.dev/viewer/?uri=github.com/nlohmann/json)\n[![Backup Status](https://app.cloudback.it/badge/nlohmann/json)](https://cloudback.it)\n[![GitHub Sponsors](https://img.shields.io/badge/GitHub-Sponsors-ff69b4)](https://github.com/sponsors/nlohmann)\n[![REUSE status](https://api.reuse.software/badge/github.com/nlohmann/json)](https://api.reuse.software/info/github.com/nlohmann/json)\n[![Discord](https://img.shields.io/discord/1003743314341793913)](https://discord.gg/6mrGXKvX7y)\n\n- [Design goals](#design-goals)\n- [Sponsors](#sponsors)\n- [Support](#support) ([documentation](https://json.nlohmann.me), [FAQ](https://json.nlohmann.me/home/faq/), [discussions](https://github.com/nlohmann/json/discussions), [API](https://json.nlohmann.me/api/basic_json/), [bug issues](https://github.com/nlohmann/json/issues))\n- [Quick reference](#quick-reference)\n- [Examples](#examples)\n  - [Read JSON from a file](#read-json-from-a-file)\n  - [Creating `json` objects from JSON literals](#creating-json-objects-from-json-literals)\n  - [JSON as a first-class data type](#json-as-a-first-class-data-type)\n  - [Serialization / Deserialization](#serialization--deserialization)\n  - [STL-like access](#stl-like-access)\n  - [Conversion from STL containers](#conversion-from-stl-containers)\n  - [JSON Pointer and JSON Patch](#json-pointer-and-json-patch)\n  - [JSON Merge Patch](#json-merge-patch)\n  - [Implicit conversions](#implicit-conversions)\n  - [Conversions to/from arbitrary types](#arbitrary-types-conversions)\n  - [Specializing enum conversion](#specializing-enum-conversion)\n  - [Binary formats (BSON, CBOR, MessagePack, UBJSON, and BJData)](#binary-formats-bson-cbor-messagepack-ubjson-and-bjdata)\n- [Customers](#customers)\n- [Supported compilers](#supported-compilers)\n- [Integration](#integration)\n  - [CMake](#cmake)\n  - [Package Managers](#package-managers)\n  - [Pkg-config](#pkg-config)\n- [License](#license)\n- [Contact](#contact)\n- [Thanks](#thanks)\n- [Used third-party tools](#used-third-party-tools)\n- [Notes](#notes)\n- [Execute unit tests](#execute-unit-tests)\n\n## Design goals\n\nThere are myriads of [JSON](https://json.org) libraries out there, and each may even have its reason to exist. Our class had these design goals:\n\n- **Intuitive syntax**. In languages such as Python, JSON feels like a first-class data type. We used all the operator magic of modern C++ to achieve the same feeling in your code. Check out the [examples below](#examples) and you'll know what I mean.\n\n- **Trivial integration**. Our whole code consists of a single header file [`json.hpp`](https://github.com/nlohmann/json/blob/develop/single_include/nlohmann/json.hpp). That's it. No library, no subproject, no dependencies, no complex build system. The class is written in vanilla C++11. All in all, everything should require no adjustment of your compiler flags or project settings. The library is also included in all popular [package managers](https://json.nlohmann.me/integration/package_managers/).\n\n- **Serious testing**. Our code is heavily [unit-tested](https://github.com/nlohmann/json/tree/develop/tests/src) and covers [100%](https://coveralls.io/r/nlohmann/json) of the code, including all exceptional behavior. Furthermore, we checked with [Valgrind](https://valgrind.org) and the [Clang Sanitizers](https://clang.llvm.org/docs/index.html) that there are no memory leaks. [Google OSS-Fuzz](https://github.com/google/oss-fuzz/tree/master/projects/json) additionally runs fuzz tests against all parsers 24/7, effectively executing billions of tests so far. To maintain high quality, the project is following the [Core Infrastructure Initiative (CII) best practices](https://bestpractices.coreinfrastructure.org/projects/289). See the [quality assurance](https://json.nlohmann.me/community/quality_assurance) overview documentation.\n\nOther aspects were not so important to us:\n\n- **Memory efficiency**. Each JSON object has an overhead of one pointer (the maximal size of a union) and one enumeration element (1 byte). The default generalization uses the following C++ data types: `std::string` for strings, `int64_t`, `uint64_t` or `double` for numbers, `std::map` for objects, `std::vector` for arrays, and `bool` for Booleans. However, you can template the generalized class `basic_json` to your needs.\n\n- **Speed**. There are certainly [faster JSON libraries](https://github.com/miloyip/nativejson-benchmark#parsing-time) out there. However, if your goal is to speed up your development by adding JSON support with a single header, then this library is the way to go. If you know how to use a `std::vector` or `std::map`, you are already set.\n\nSee the [contribution guidelines](https://github.com/nlohmann/json/blob/master/.github/CONTRIBUTING.md#please-dont) for more information.\n\n## Sponsors\n\nYou can sponsor this library at [GitHub Sponsors](https://github.com/sponsors/nlohmann).\n\n### :raising_hand: Priority Sponsor\n\n- [Martti Laine](https://github.com/codeclown)\n- [Paul Harrington](https://github.com/phrrngtn)\n\n### :label: Named Sponsors\n\n- [Michael Hartmann](https://github.com/reFX-Mike)\n- [Stefan Hagen](https://github.com/sthagen)\n- [Steve Sperandeo](https://github.com/homer6)\n- [Robert Jefe Lindst√§dt](https://github.com/eljefedelrodeodeljefe)\n- [Steve Wagner](https://github.com/ciroque)\n- [Lion Yang](https://github.com/LionNatsu)\n\n### Further support\n\nThe development of the library is further supported by JetBrains by providing free access to their IDE tools.\n\n[![JetBrains logo.](https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg)](https://jb.gg/OpenSourceSupport)\n\nThanks everyone!\n\n## Support\n\n:question: If you have a **question**, please check if it is already answered in the [**FAQ**](https://json.nlohmann.me/home/faq/) or the [**Q&A**](https://github.com/nlohmann/json/discussions/categories/q-a) section. If not, please [**ask a new question**](https://github.com/nlohmann/json/discussions/new) there.\n\n:books: If you want to **learn more** about how to use the library, check out the rest of the [**README**](#examples), have a look at [**code examples**](https://github.com/nlohmann/json/tree/develop/docs/mkdocs/docs/examples), or browse through the [**help pages**](https://json.nlohmann.me).\n\n:construction: If you want to understand the **API** better, check out the [**API Reference**](https://json.nlohmann.me/api/basic_json/) or have a look at the [quick reference](#quick-reference) below.\n\n:bug: If you found a **bug**, please check the [**FAQ**](https://json.nlohmann.me/home/faq/) if it is a known issue or the result of a design decision. Please also have a look at the [**issue list**](https://github.com/nlohmann/json/issues) before you [**create a new issue**](https://github.com/nlohmann/json/issues/new/choose). Please provide as much information as possible to help us understand and reproduce your issue.\n\nThere is also a [**docset**](https://github.com/Kapeli/Dash-User-Contributions/tree/master/docsets/JSON_for_Modern_C%2B%2B) for the documentation browsers [Dash](https://kapeli.com/dash), [Velocity](https://velocity.silverlakesoftware.com), and [Zeal](https://zealdocs.org) that contains the full [documentation](https://json.nlohmann.me) as an offline resource.\n\n## Quick reference\n\n- **Constructors** [basic_json](https://json.nlohmann.me/api/basic_json/basic_json), [array](https://json.nlohmann.me/api/basic_json/array), [binary](https://json.nlohmann.me/api/basic_json/binary), [object](https://json.nlohmann.me/api/basic_json/object)\n- **Object inspection**: [type](https://json.nlohmann.me/api/basic_json/type), [operator value_t](https://json.nlohmann.me/api/basic_json/operator_value_t), [type_name](https://json.nlohmann.me/api/basic_json/type_name), [is_primitive](https://json.nlohmann.me/api/basic_json/is_primitive), [is_structured](https://json.nlohmann.me/api/basic_json/is_structured), [is_null](https://json.nlohmann.me/api/basic_json/is_null), [is_boolean](https://json.nlohmann.me/api/basic_json/is_boolean), [is_number](https://json.nlohmann.me/api/basic_json/is_number), [is_number_integer](https://json.nlohmann.me/api/basic_json/is_number_integer), [is_number_unsigned](https://json.nlohmann.me/api/basic_json/is_number_unsigned), [is_number_float](https://json.nlohmann.me/api/basic_json/is_number_float), [is_object](https://json.nlohmann.me/api/basic_json/is_object), [is_array](https://json.nlohmann.me/api/basic_json/is_array), [is_string](https://json.nlohmann.me/api/basic_json/is_string), [is_binary](https://json.nlohmann.me/api/basic_json/is_binary), [is_discarded](https://json.nlohmann.me/api/basic_json/is_discarded)\n- **Value access**; [get](https://json.nlohmann.me/api/basic_json/get), [get_to](https://json.nlohmann.me/api/basic_json/get_to), [get_ptr](https://json.nlohmann.me/api/basic_json/get_ptr), [get_ref](https://json.nlohmann.me/api/basic_json/get_ref), [operator ValueType](https://json.nlohmann.me/api/basic_json/operator_ValueType), [get_binary](https://json.nlohmann.me/api/basic_json/get_binary)\n- **Element access**: [at](https://json.nlohmann.me/api/basic_json/at), [operator[]](https://json.nlohmann.me/api/basic_json/operator[]), [value](https://json.nlohmann.me/api/basic_json/value), [front](https://json.nlohmann.me/api/basic_json/front), [back](https://json.nlohmann.me/api/basic_json/back)\n- **Lookup**: [find](https://json.nlohmann.me/api/basic_json/find), [count](https://json.nlohmann.me/api/basic_json/count), [contains](https://json.nlohmann.me/api/basic_json/contains)\n- **Iterators**: [begin](https://json.nlohmann.me/api/basic_json/begin), [cbegin](https://json.nlohmann.me/api/basic_json/cbegin), [end](https://json.nlohmann.me/api/basic_json/end), [cend](https://json.nlohmann.me/api/basic_json/cend), [rbegin](https://json.nlohmann.me/api/basic_json/rbegin), [rend](https://json.nlohmann.me/api/basic_json/rend), [crbegin](https://json.nlohmann.me/api/basic_json/crbegin), [crend](https://json.nlohmann.me/api/basic_json/crend), [items](https://json.nlohmann.me/api/basic_json/items)\n- **Capacity**: [empty](https://json.nlohmann.me/api/basic_json/empty), [size](https://json.nlohmann.me/api/basic_json/size), [max_size](https://json.nlohmann.me/api/basic_json/max_size)\n- **Modifiers**: [clear](https://json.nlohmann.me/api/basic_json/clear), [push_back](https://json.nlohmann.me/api/basic_json/push_back), [operator+=](https://json.nlohmann.me/api/basic_json/operator+=), [emplace_back](https://json.nlohmann.me/api/basic_json/emplace_back), [emplace](https://json.nlohmann.me/api/basic_json/emplace), [erase](https://json.nlohmann.me/api/basic_json/erase), [insert](https://json.nlohmann.me/api/basic_json/insert), [update](https://json.nlohmann.me/api/basic_json/update), [swap](https://json.nlohmann.me/api/basic_json/swap)\n- **Lexicographical comparison operators**: [operator==](https://json.nlohmann.me/api/basic_json/operator_eq), [operator!=](https://json.nlohmann.me/api/basic_json/operator_ne), [operator<](https://json.nlohmann.me/api/basic_json/operator_lt), [operator>](https://json.nlohmann.me/api/basic_json/operator_gt), [operator<=](https://json.nlohmann.me/api/basic_json/operator_le), [operator>=](https://json.nlohmann.me/api/basic_json/operator_ge), [operator<=>](https://json.nlohmann.me/api/basic_json/operator_spaceship)\n- **Serialization / Dumping**: [dump](https://json.nlohmann.me/api/basic_json/dump)\n- **Deserialization / Parsing**: [parse](https://json.nlohmann.me/api/basic_json/parse), [accept](https://json.nlohmann.me/api/basic_json/accept), [sax_parse](https://json.nlohmann.me/api/basic_json/sax_parse)\n- **JSON Pointer functions**: [flatten](https://json.nlohmann.me/api/basic_json/flatten), [unflatten](https://json.nlohmann.me/api/basic_json/unflatten)\n- **JSON Patch functions**: [patch](https://json.nlohmann.me/api/basic_json/patch), [patch_inplace](https://json.nlohmann.me/api/basic_json/patch_inplace), [diff](https://json.nlohmann.me/api/basic_json/diff), [merge_patch](https://json.nlohmann.me/api/basic_json/merge_patch)\n- **Static functions**: [meta](https://json.nlohmann.me/api/basic_json/meta), [get_allocator](https://json.nlohmann.me/api/basic_json/get_allocator)\n- **Binary formats**: [from_bjdata](https://json.nlohmann.me/api/basic_json/from_bjdata), [from_bson](https://json.nlohmann.me/api/basic_json/from_bson), [from_cbor](https://json.nlohmann.me/api/basic_json/from_cbor), [from_msgpack](https://json.nlohmann.me/api/basic_json/from_msgpack), [from_ubjson](https://json.nlohmann.me/api/basic_json/from_ubjson), [to_bjdata](https://json.nlohmann.me/api/basic_json/to_bjdata), [to_bson](https://json.nlohmann.me/api/basic_json/to_bson), [to_cbor](https://json.nlohmann.me/api/basic_json/to_cbor), [to_msgpack](https://json.nlohmann.me/api/basic_json/to_msgpack), [to_ubjson](https://json.nlohmann.me/api/basic_json/to_ubjson)\n- **Non-member functions**: [operator<<](https://json.nlohmann.me/api/operator_ltlt/), [operator>>](https://json.nlohmann.me/api/operator_gtgt/), [to_string](https://json.nlohmann.me/api/basic_json/to_string)\n- **Literals**: [operator\"\"_json](https://json.nlohmann.me/api/operator_literal_json)\n- **Helper classes**: [std::hash&lt;basic_json&gt;](https://json.nlohmann.me/api/basic_json/std_hash), [std::swap&lt;basic_json&gt;](https://json.nlohmann.me/api/basic_json/std_swap)\n\n[**Full API documentation**](https://json.nlohmann.me/api/basic_json/)\n\n## Examples\n\nHere are some examples to give you an idea how to use the class.\n\nBesides the examples below, you may want to:\n\n‚Üí Check the [documentation](https://json.nlohmann.me/)\\\n‚Üí Browse the [standalone example files](https://github.com/nlohmann/json/tree/develop/docs/mkdocs/docs/examples)\\\n‚Üí Read the full [API Documentation](https://json.nlohmann.me/api/basic_json/) with self-contained examples for every function\n\n### Read JSON from a file\n\nThe `json` class provides an API for manipulating a JSON value. To create a `json` object by reading a JSON file:\n\n```cpp\n#include <fstream>\n#include <nlohmann/json.hpp>\nusing json = nlohmann::json;\n\n// ...\n\nstd::ifstream f(\"example.json\");\njson data = json::parse(f);\n```\n\nIf using modules (enabled with `NLOHMANN_JSON_BUILD_MODULES`), this example becomes:\n```cpp\nimport std;\nimport nlohmann.json;\n\nusing json = nlohmann::json;\n\n// ...\n\nstd::ifstream f(\"example.json\");\njson data = json::parse(f);\n```\n\n### Creating `json` objects from JSON literals\n\nAssume you want to create hard-code this literal JSON value in a file, as a `json` object:\n\n```json\n{\n  \"pi\": 3.141,\n  \"happy\": true\n}\n```\n\nThere are various options:\n\n```cpp\n// Using (raw) string literals and json::parse\njson ex1 = json::parse(R\"(\n  {\n    \"pi\": 3.141,\n    \"happy\": true\n  }\n)\");\n\n// Using user-defined (raw) string literals\nusing namespace nlohmann::literals;\njson ex2 = R\"(\n  {\n    \"pi\": 3.141,\n    \"happy\": true\n  }\n)\"_json;\n\n// Using initializer lists\njson ex3 = {\n  {\"happy\", true},\n  {\"pi\", 3.141},\n};\n```\n\n### JSON as a first-class data type\n\nHere are some examples to give you an idea how to use the class.\n\nAssume you want to create the JSON object\n\n```json\n{\n  \"pi\": 3.141,\n  \"happy\": true,\n  \"name\": \"Niels\",\n  \"nothing\": null,\n  \"answer\": {\n    \"everything\": 42\n  },\n  \"list\": [1, 0, 2],\n  \"object\": {\n    \"currency\": \"USD\",\n    \"value\": 42.99\n  }\n}\n```\n\nWith this library, you could write:\n\n```cpp\n// create an empty structure (null)\njson j;\n\n// add a number stored as double (note the implicit conversion of j to an object)\nj[\"pi\"] = 3.141;\n\n// add a Boolean stored as bool\nj[\"happy\"] = true;\n\n// add a string stored as std::string\nj[\"name\"] = \"Niels\";\n\n// add another null object by passing nullptr\nj[\"nothing\"] = nullptr;\n\n// add an object inside the object\nj[\"answer\"][\"everything\"] = 42;\n\n// add an array stored as std::vector (using an initializer list)\nj[\"list\"] = { 1, 0, 2 };\n\n// add another object (using an initializer list of pairs)\nj[\"object\"] = { {\"currency\", \"USD\"}, {\"value\", 42.99} };\n\n// instead, you could also write (which looks very similar to the JSON above)\njson j2 = {\n  {\"pi\", 3.141},\n  {\"happy\", true},\n  {\"name\", \"Niels\"},\n  {\"nothing\", nullptr},\n  {\"answer\", {\n    {\"everything\", 42}\n  }},\n  {\"list\", {1, 0, 2}},\n  {\"object\", {\n    {\"currency\", \"USD\"},\n    {\"value\", 42.99}\n  }}\n};\n```\n\nNote that in all these cases, you never need to \"tell\" the compiler which JSON value type you want to use. If you want to be explicit or express some edge cases, the functions [`json::array()`](https://json.nlohmann.me/api/basic_json/array/) and [`json::object()`](https://json.nlohmann.me/api/basic_json/object/) will help:\n\n```cpp\n// a way to express the empty array []\njson empty_array_explicit = json::array();\n\n// ways to express the empty object {}\njson empty_object_implicit = json({});\njson empty_object_explicit = json::object();\n\n// a way to express an _array_ of key/value pairs [[\"currency\", \"USD\"], [\"value\", 42.99]]\njson array_not_object = json::array({ {\"currency\", \"USD\"}, {\"value\", 42.99} });\n```\n\n### Serialization / Deserialization\n\n#### To/from strings\n\nYou can create a JSON value (deserialization) by appending `_json` to a string literal:\n\n```cpp\n// create object from string literal\njson j = \"{ \\\"happy\\\": true, \\\"pi\\\": 3.141 }\"_json;\n\n// or even nicer with a raw string literal\nauto j2 = R\"(\n  {\n    \"happy\": true,\n    \"pi\": 3.141\n  }\n)\"_json;\n```\n\nNote that without appending the `_json` suffix, the passed string literal is not parsed, but just used as JSON string\nvalue. That is, `json j = \"{ \\\"happy\\\": true, \\\"pi\\\": 3.141 }\"` would just store the string\n`\"{ \"happy\": true, \"pi\": 3.141 }\"` rather than parsing the actual object.\n\nThe string literal should be brought into scope with `using namespace nlohmann::literals;`\n(see [`json::parse()`](https://json.nlohmann.me/api/operator_literal_json/)).\n\nThe above example can also be expressed explicitly using [`json::parse()`](https://json.nlohmann.me/api/basic_json/parse/):\n\n```cpp\n// parse explicitly\nauto j3 = json::parse(R\"({\"happy\": true, \"pi\": 3.141})\");\n```\n\nYou can also get a string representation of a JSON value (serialize):\n\n```cpp\n// explicit conversion to string\nstd::string s = j.dump();    // {\"happy\":true,\"pi\":3.141}\n\n// serialization with pretty printing\n// pass in the amount of spaces to indent\nstd::cout << j.dump(4) << std::endl;\n// {\n//     \"happy\": true,\n//     \"pi\": 3.141\n// }\n```\n\nNote the difference between serialization and assignment:\n\n```cpp\n// store a string in a JSON value\njson j_string = \"this is a string\";\n\n// retrieve the string value\nauto cpp_string = j_string.get<std::string>();\n// retrieve the string value (alternative when a variable already exists)\nstd::string cpp_string2;\nj_string.get_to(cpp_string2);\n\n// retrieve the serialized value (explicit JSON serialization)\nstd::string serialized_string = j_string.dump();\n\n// output of original string\nstd::cout << cpp_string << \" == \" << cpp_string2 << \" == \" << j_string.get<std::string>() << '\\n';\n// output of serialized value\nstd::cout << j_string << \" == \" << serialized_string << std::endl;\n```\n\n[`.dump()`](https://json.nlohmann.me/api/basic_json/dump/) returns the originally stored string value.\n\nNote the library only supports UTF-8. When you store strings with different encodings in the library, calling [`dump()`](https://json.nlohmann.me/api/basic_json/dump/) may throw an exception unless `json::error_handler_t::replace` or `json::error_handler_t::ignore` are used as error handlers.\n\n#### To/from streams (e.g., files, string streams)\n\nYou can also use streams to serialize and deserialize:\n\n```cpp\n// deserialize from standard input\njson j;\nstd::cin >> j;\n\n// serialize to standard output\nstd::cout << j;\n\n// the setw manipulator was overloaded to set the indentation for pretty printing\nstd::cout << std::setw(4) << j << std::endl;\n```\n\nThese operators work for any subclasses of `std::istream` or `std::ostream`. Here is the same example with files:\n\n```cpp\n// read a JSON file\nstd::ifstream i(\"file.json\");\njson j;\ni >> j;\n\n// write prettified JSON to another file\nstd::ofstream o(\"pretty.json\");\no << std::setw(4) << j << std::endl;\n```\n\nPlease note that setting the exception bit for `failbit` is inappropriate for this use case. It will result in program termination due to the `noexcept` specifier in use.\n\n#### Read from iterator range\n\nYou can also parse JSON from an iterator range; that is, from any container accessible by iterators whose `value_type` is an integral type of 1, 2, or 4 bytes, which will be interpreted as UTF-8, UTF-16, and UTF-32 respectively. For instance, a `std::vector<std::uint8_t>`, or a `std::list<std::uint16_t>`:\n\n```cpp\nstd::vector<std::uint8_t> v = {'t', 'r', 'u', 'e'};\njson j = json::parse(v.begin(), v.end());\n```\n\nYou may leave the iterators for the range [begin, end):\n\n```cpp\nstd::vector<std::uint8_t> v = {'t', 'r', 'u', 'e'};\njson j = json::parse(v);\n```\n\n#### Custom data source\n\nSince the parse function accepts arbitrary iterator ranges, you can provide your own data sources by implementing the `LegacyInputIterator` concept.\n\n```cpp\nstruct MyContainer {\n  void advance();\n  const char& get_current();\n};\n\nstruct MyIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = char;\n    using pointer = const char*;\n    using reference = const char&;\n    using iterator_category = std::input_iterator_tag;\n\n    MyIterator& operator++() {\n        target->advance();\n        return *this;\n    }\n\n    bool operator!=(const MyIterator& rhs) const {\n        return rhs.target != target;\n    }\n\n    reference operator*() const {\n        return target->get_current();\n    }\n\n    MyContainer* target = nullptr;\n};\n\nMyIterator begin(MyContainer& tgt) {\n    return MyIterator{&tgt};\n}\n\nMyIterator end(const MyContainer&) {\n    return {};\n}\n\nvoid foo() {\n    MyContainer c;\n    json j = json::parse(c);\n}\n```\n\n#### SAX interface\n\nThe library uses a SAX-like interface with the following functions:\n\n```cpp\n// called when null is parsed\nbool null();\n\n// called when a boolean is parsed; value is passed\nbool boolean(bool val);\n\n// called when a signed or unsigned integer number is parsed; value is passed\nbool number_integer(number_integer_t val);\nbool number_unsigned(number_unsigned_t val);\n\n// called when a floating-point number is parsed; value and original string is passed\nbool number_float(number_float_t val, const string_t& s);\n\n// called when a string is parsed; value is passed and can be safely moved away\nbool string(string_t& val);\n// called when a binary value is parsed; value is passed and can be safely moved away\nbool binary(binary_t& val);\n\n// called when an object or array begins or ends, resp. The number of elements is passed (or -1 if not known)\nbool start_object(std::size_t elements);\nbool end_object();\nbool start_array(std::size_t elements);\nbool end_array();\n// called when an object key is parsed; value is passed and can be safely moved away\nbool key(string_t& val);\n\n// called when a parse error occurs; byte position, the last token, and an exception is passed\nbool parse_error(std::size_t position, const std::string& last_token, const detail::exception& ex);\n```\n\nThe return value of each function determines whether parsing should proceed.\n\nTo implement your own SAX handler, proceed as follows:\n\n1. Implement the SAX interface in a class. You can use class `nlohmann::json_sax<json>` as base class, but you can also use any class where the functions described above are implemented and public.\n2. Create an object of your SAX interface class, e.g. `my_sax`.\n3. Call `bool json::sax_parse(input, &my_sax)`; where the first parameter can be any input like a string or an input stream and the second parameter is a pointer to your SAX interface.\n\nNote the `sax_parse` function only returns a `bool` indicating the result of the last executed SAX event. It does not return a  `json` value - it is up to you to decide what to do with the SAX events. Furthermore, no exceptions are thrown in case of a parse error -- it is up to you what to do with the exception object passed to your `parse_error` implementation. Internally, the SAX interface is used for the DOM parser (class `json_sax_dom_parser`) as well as the acceptor (`json_sax_acceptor`), see file [`json_sax.hpp`](https://github.com/nlohmann/json/blob/develop/include/nlohmann/detail/input/json_sax.hpp).\n\n### STL-like access\n\nWe designed the JSON class to behave just like an STL container. In fact, it satisfies the [**ReversibleContainer**](https://en.cppreference.com/w/cpp/named_req/ReversibleContainer) requirement.\n\n```cpp\n// create an array using push_back\njson j;\nj.push_back(\"foo\");\nj.push_back(1);\nj.push_back(true);\n\n// also use emplace_back\nj.emplace_back(1.78);\n\n// iterate the array\nfor (json::iterator it = j.begin(); it != j.end(); ++it) {\n  std::cout << *it << '\\n';\n}\n\n// range-based for\nfor (auto& element : j) {\n  std::cout << element << '\\n';\n}\n\n// getter/setter\nconst auto tmp = j[0].get<std::string>();\nj[1] = 42;\nbool foo = j.at(2);\n\n// comparison\nj == R\"([\"foo\", 1, true, 1.78])\"_json;  // true\n\n// other stuff\nj.size();     // 4 entries\nj.empty();    // false\nj.type();     // json::value_t::array\nj.clear();    // the array is empty again\n\n// convenience type checkers\nj.is_null();\nj.is_boolean();\nj.is_number();\nj.is_object();\nj.is_array();\nj.is_string();\n\n// create an object\njson o;\no[\"foo\"] = 23;\no[\"bar\"] = false;\no[\"baz\"] = 3.141;\n\n// also use emplace\no.emplace(\"weather\", \"sunny\");\n\n// special iterator member functions for objects\nfor (json::iterator it = o.begin(); it != o.end(); ++it) {\n  std::cout << it.key() << \" : \" << it.value() << \"\\n\";\n}\n\n// the same code as range for\nfor (auto& el : o.items()) {\n  std::cout << el.key() << \" : \" << el.value() << \"\\n\";\n}\n\n// even easier with structured bindings (C++17)\nfor (auto& [key, value] : o.items()) {\n  std::cout << key << \" : \" << value << \"\\n\";\n}\n\n// find an entry\nif (o.contains(\"foo\")) {\n  // there is an entry with key \"foo\"\n}\n\n// or via find and an iterator\nif (o.find(\"foo\") != o.end()) {\n  // there is an entry with key \"foo\"\n}\n\n// or simpler using count()\nint foo_present = o.count(\"foo\"); // 1\nint fob_present = o.count(\"fob\"); // 0\n\n// delete an entry\no.erase(\"foo\");\n```\n\n### Conversion from STL containers\n\nAny sequence container (`std::array`, `std::vector`, `std::deque`, `std::forward_list`, `std::list`) whose values can be used to construct JSON values (e.g., integers, floating point numbers, Booleans, string types, or again STL containers described in this section) can be used to create a JSON array. The same holds for similar associative containers (`std::set`, `std::multiset`, `std::unordered_set`, `std::unordered_multiset`), but in these cases the order of the elements of the array depends on how the elements are ordered in the respective STL container.\n\n```cpp\nstd::vector<int> c_vector {1, 2, 3, 4};\njson j_vec(c_vector);\n// [1, 2, 3, 4]\n\nstd::deque<double> c_deque {1.2, 2.3, 3.4, 5.6};\njson j_deque(c_deque);\n// [1.2, 2.3, 3.4, 5.6]\n\nstd::list<bool> c_list {true, true, false, true};\njson j_list(c_list);\n// [true, true, false, true]\n\nstd::forward_list<int64_t> c_flist {12345678909876, 23456789098765, 34567890987654, 45678909876543};\njson j_flist(c_flist);\n// [12345678909876, 23456789098765, 34567890987654, 45678909876543]\n\nstd::array<unsigned long, 4> c_array {{1, 2, 3, 4}};\njson j_array(c_array);\n// [1, 2, 3, 4]\n\nstd::set<std::string> c_set {\"one\", \"two\", \"three\", \"four\", \"one\"};\njson j_set(c_set); // only one entry for \"one\" is used\n// [\"four\", \"one\", \"three\", \"two\"]\n\nstd::unordered_set<std::string> c_uset {\"one\", \"two\", \"three\", \"four\", \"one\"};\njson j_uset(c_uset); // only one entry for \"one\" is used\n// maybe [\"two\", \"three\", \"four\", \"one\"]\n\nstd::multiset<std::string> c_mset {\"one\", \"two\", \"one\", \"four\"};\njson j_mset(c_mset); // both entries for \"one\" are used\n// maybe [\"one\", \"two\", \"one\", \"four\"]\n\nstd::unordered_multiset<std::string> c_umset {\"one\", \"two\", \"one\", \"four\"};\njson j_umset(c_umset); // both entries for \"one\" are used\n// maybe [\"one\", \"two\", \"one\", \"four\"]\n```\n\nLikewise, any associative key-value containers (`std::map`, `std::multimap`, `std::unordered_map`, `std::unordered_multimap`) whose keys can construct an `std::string` and whose values can be used to construct JSON values (see examples above) can be used to create a JSON object. Note that in case of multimaps, only one key is used in the JSON object and the value depends on the internal order of the STL container.\n\n```cpp\nstd::map<std::string, int> c_map { {\"one\", 1}, {\"two\", 2}, {\"three\", 3} };\njson j_map(c_map);\n// {\"one\": 1, \"three\": 3, \"two\": 2 }\n\nstd::unordered_map<const char*, double> c_umap { {\"one\", 1.2}, {\"two\", 2.3}, {\"three\", 3.4} };\njson j_umap(c_umap);\n// {\"one\": 1.2, \"two\": 2.3, \"three\": 3.4}\n\nstd::multimap<std::string, bool> c_mmap { {\"one\", true}, {\"two\", true}, {\"three\", false}, {\"three\", true} };\njson j_mmap(c_mmap); // only one entry for key \"three\" is used\n// maybe {\"one\": true, \"two\": true, \"three\": true}\n\nstd::unordered_multimap<std::string, bool> c_ummap { {\"one\", true}, {\"two\", true}, {\"three\", false}, {\"three\", true} };\njson j_ummap(c_ummap); // only one entry for key \"three\" is used\n// maybe {\"one\": true, \"two\": true, \"three\": true}\n```\n\n### JSON Pointer and JSON Patch\n\nThe library supports **JSON Pointer** ([RFC 6901](https://tools.ietf.org/html/rfc6901)) as an alternative means to address structured values. On top of this, **JSON Patch** ([RFC 6902](https://tools.ietf.org/html/rfc6902)) allows describing differences between two JSON values -- effectively allowing patch and diff operations known from Unix.\n\n```cpp\n// a JSON value\njson j_original = R\"({\n  \"baz\": [\"one\", \"two\", \"three\"],\n  \"foo\": \"bar\"\n})\"_json;\n\n// access members with a JSON pointer (RFC 6901)\nj_original[\"/baz/1\"_json_pointer];\n// \"two\"\n\n// a JSON patch (RFC 6902)\njson j_patch = R\"([\n  { \"op\": \"replace\", \"path\": \"/baz\", \"value\": \"boo\" },\n  { \"op\": \"add\", \"path\": \"/hello\", \"value\": [\"world\"] },\n  { \"op\": \"remove\", \"path\": \"/foo\"}\n])\"_json;\n\n// apply the patch\njson j_result = j_original.patch(j_patch);\n// {\n//    \"baz\": \"boo\",\n//    \"hello\": [\"world\"]\n// }\n\n// calculate a JSON patch from two JSON values\njson::diff(j_result, j_original);\n// [\n//   { \"op\":\" replace\", \"path\": \"/baz\", \"value\": [\"one\", \"two\", \"three\"] },\n//   { \"op\": \"remove\",\"path\": \"/hello\" },\n//   { \"op\": \"add\", \"path\": \"/foo\", \"value\": \"bar\" }\n// ]\n```\n\n### JSON Merge Patch\n\nThe library supports **JSON Merge Patch** ([RFC 7386](https://tools.ietf.org/html/rfc7386)) as a patch format. Instead of using JSON Pointer (see above) to specify values to be manipulated, it describes the changes using a syntax that closely mimics the document being modified.\n\n```cpp\n// a JSON value\njson j_document = R\"({\n  \"a\": \"b\",\n  \"c\": {\n    \"d\": \"e\",\n    \"f\": \"g\"\n  }\n})\"_json;\n\n// a patch\njson j_patch = R\"({\n  \"a\":\"z\",\n  \"c\": {\n    \"f\": null\n  }\n})\"_json;\n\n// apply the patch\nj_document.merge_patch(j_patch);\n// {\n//  \"a\": \"z\",\n//  \"c\": {\n//    \"d\": \"e\"\n//  }\n// }\n```\n\n### Implicit conversions\n\nSupported types can be implicitly converted to JSON values.\n\nIt is recommended to **NOT USE** implicit conversions **FROM** a JSON value.\nYou can find more details about this recommendation [here](https://www.github.com/nlohmann/json/issues/958).\nYou can switch off implicit conversions by defining `JSON_USE_IMPLICIT_CONVERSIONS` to `0` before including the `json.hpp` header. When using CMake, you can also achieve this by setting the option `JSON_ImplicitConversions` to `OFF`.\n\n```cpp\n// strings\nstd::string s1 = \"Hello, world!\";\njson js = s1;\nauto s2 = js.get<std::string>();\n// NOT RECOMMENDED\nstd::string s3 = js;\nstd::string s4;\ns4 = js;\n\n// Booleans\nbool b1 = true;\njson jb = b1;\nauto b2 = jb.get<bool>();\n// NOT RECOMMENDED\nbool b3 = jb;\nbool b4;\nb4 = jb;\n\n// numbers\nint i = 42;\njson jn = i;\nauto f = jn.get<double>();\n// NOT RECOMMENDED\ndouble f2 = jb;\ndouble f3;\nf3 = jb;\n\n// etc.\n```\n\nNote that `char` types are not automatically converted to JSON strings, but to integer numbers. A conversion to a string must be specified explicitly:\n\n```cpp\nchar ch = 'A';                       // ASCII value 65\njson j_default = ch;                 // stores integer number 65\njson j_string = std::string(1, ch);  // stores string \"A\"\n```\n\n### Arbitrary types conversions\n\nEvery type can be serialized in JSON, not just STL containers and scalar types. Usually, you would do something along those lines:\n\n```cpp\nnamespace ns {\n    // a simple struct to model a person\n    struct person {\n        std::string name;\n        std::string address;\n        int age;\n    };\n}\n\nns::person p = {\"Ned Flanders\", \"744 Evergreen Terrace\", 60};\n\n// convert to JSON: copy each value into the JSON object\njson j;\nj[\"name\"] = p.name;\nj[\"address\"] = p.address;\nj[\"age\"] = p.age;\n\n// ...\n\n// convert from JSON: copy each value from the JSON object\nns::person p {\n    j[\"name\"].get<std::string>(),\n    j[\"address\"].get<std::string>(),\n    j[\"age\"].get<int>()\n};\n```\n\nIt works, but that's quite a lot of boilerplate... Fortunately, there's a better way:\n\n```cpp\n// create a person\nns::person p {\"Ned Flanders\", \"744 Evergreen Terrace\", 60};\n\n// conversion: person -> json\njson j = p;\n\nstd::cout << j << std::endl;\n// {\"address\":\"744 Evergreen Terrace\",\"age\":60,\"name\":\"Ned Flanders\"}\n\n// conversion: json -> person\nauto p2 = j.get<ns::person>();\n\n// that's it\nassert(p == p2);\n```\n\n#### Basic usage\n\nTo make this work with one of your types, you only need to provide two functions:\n\n```cpp\nusing json = nlohmann::json;\n\nnamespace ns {\n    void to_json(json& j, const person& p) {\n        j = json{{\"name\", p.name}, {\"address\", p.address}, {\"age\", p.age}};\n    }\n\n    void from_json(const json& j, person& p) {\n        j.at(\"name\").get_to(p.name);\n        j.at(\"address\").get_to(p.address);\n        j.at(\"age\").get_to(p.age);\n    }\n} // namespace ns\n```\n\nThat's all! When calling the `json` constructor with your type, your custom `to_json` method will be automatically called.\nLikewise, when calling `get<your_type>()` or `get_to(your_type&)`, the `from_json` method will be called.\n\nSome important things:\n\n- Those methods **MUST** be in your type's namespace (which can be the global namespace), or the library will not be able to locate them (in this example, they are in namespace `ns`, where `person` is defined).\n- Those methods **MUST** be available (e.g., proper headers must be included) everywhere you use these conversions. Look at [issue 1108](https://github.com/nlohmann/json/issues/1108) for errors that may occur otherwise.\n- When using `get<your_type>()`, `your_type` **MUST** be [DefaultConstructible](https://en.cppreference.com/w/cpp/named_req/DefaultConstructible). (There is a way to bypass this requirement described later.)\n- In function `from_json`, use function [`at()`](https://json.nlohmann.me/api/basic_json/at/) to access the object values rather than `operator[]`. In case a key does not exist, `at` throws an exception that you can handle, whereas `operator[]` exhibits undefined behavior.\n- You do not need to add serializers or deserializers for STL types like `std::vector`: the library already implements these.\n\n#### Simplify your life with macros\n\nIf you just want to serialize/deserialize some structs, the `to_json`/`from_json` functions can be a lot of boilerplate. There are [**several macros**](https://json.nlohmann.me/features/arbitrary_types/#simplify-your-life-with-macros) to make your life easier as long as you (1) want to use a JSON object as serialization and (2) want to use the member variable names as object keys in that object.\n\nWhich macro to choose depends on whether private member variables need to be accessed, a deserialization is needed, missing values should yield an error or should be replaced by default values, and if derived classes are used. See [this overview to choose the right one for your use case](https://json.nlohmann.me/api/macros/#serializationdeserialization-macros).\n\n##### Example usage of macros\n\nThe `to_json`/`from_json` functions for the `person` struct above can be created with [`NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`](https://json.nlohmann.me/api/macros/nlohmann_define_type_non_intrusive/). In all macros, the first parameter is the name of the class/struct, and all remaining parameters name the members.\n\n```cpp\nnamespace ns {\n    NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE(person, name, address, age)\n}\n```\n\nHere is another example with private members, where [`NLOHMANN_DEFINE_TYPE_INTRUSIVE`](https://json.nlohmann.me/api/macros/nlohmann_define_type_intrusive/) is needed:\n\n```cpp\nnamespace ns {\n    class address {\n      private:\n        std::string street;\n        int housenumber;\n        int postcode;\n  \n      public:\n        NLOHMANN_DEFINE_TYPE_INTRUSIVE(address, street, housenumber, postcode)\n    };\n}\n```\n\n#### How do I convert third-party types?\n\nThis requires a bit more advanced technique. But first, let's see how this conversion mechanism works:\n\nThe library uses **JSON Serializers** to convert types to JSON.\nThe default serializer for `nlohmann::json` is `nlohmann::adl_serializer` (ADL means [Argument-Dependent Lookup](https://en.cppreference.com/w/cpp/language/adl)).\n\nIt is implemented like this (simplified):\n\n```cpp\ntemplate <typename T>\nstruct adl_serializer {\n    static void to_json(json& j, const T& value) {\n        // calls the \"to_json\" method in T's namespace\n    }\n\n    static void from_json(const json& j, T& value) {\n        // same thing, but with the \"from_json\" method\n    }\n};\n```\n\nThis serializer works fine when you have control over the type's namespace. However, what about `boost::optional` or `std::filesystem::path` (C++17)? Hijacking the `boost` namespace is pretty bad, and it's illegal to add something other than template specializations to `std`...\n\nTo solve this, you need to add a specialization of `adl_serializer` to the `nlohmann` namespace, here's an example:\n\n```cpp\n// partial specialization (full specialization works too)\nnamespace nlohmann {\n    template <typename T>\n    struct adl_serializer<boost::optional<T>> {\n        static void to_json(json& j, const boost::optional<T>& opt) {\n            if (opt == boost::none) {\n                j = nullptr;\n            } else {\n              j = *opt; // this will call adl_serializer<T>::to_json which will\n                        // find the free function to_json in T's namespace!\n            }\n        }\n\n        static void from_json(const json& j, boost::optional<T>& opt) {\n            if (j.is_null()) {\n                opt = boost::none;\n            } else {\n                opt = j.get<T>(); // same as above, but with\n                                  // adl_serializer<T>::from_json\n            }\n        }\n    };\n}\n```\n\n#### How can I use `get()` for non-default constructible/non-copyable types?\n\nThere is a way if your type is [MoveConstructible](https://en.cppreference.com/w/cpp/named_req/MoveConstructible). You will need to specialize the `adl_serializer` as well, but with a special `from_json` overload:\n\n```cpp\nstruct move_only_type {\n    move_only_type() = delete;\n    move_only_type(int ii): i(ii) {}\n    move_only_type(const move_only_type&) = delete;\n    move_only_type(move_only_type&&) = default;\n\n    int i;\n};\n\nnamespace nlohmann {\n    template <>\n    struct adl_serializer<move_only_type> {\n        // note: the return type is no longer 'void', and the method only takes\n        // one argument\n        static move_only_type from_json(const json& j) {\n            return {j.get<int>()};\n        }\n\n        // Here's the catch! You must provide a to_json method! Otherwise, you\n        // will not be able to convert move_only_type to json, since you fully\n        // specialized adl_serializer on that type\n        static void to_json(json& j, move_only_type t) {\n            j = t.i;\n        }\n    };\n}\n```\n\n#### Can I write my own serializer? (Advanced use)\n\nYes. You might want to take a look at [`unit-udt.cpp`](https://github.com/nlohmann/json/blob/develop/tests/src/unit-udt.cpp) in the test suite, to see a few examples.\n\nIf you write your own serializer, you'll need to do a few things:\n\n- use a different `basic_json` alias than `nlohmann::json` (the last template parameter of `basic_json` is the `JSONSerializer`)\n- use your `basic_json` alias (or a template parameter) in all your `to_json`/`from_json` methods\n- use `nlohmann::to_json` and `nlohmann::from_json` when you need ADL\n\nHere is an example, without simplifications, that only accepts types with a size <= 32, and uses ADL.\n\n```cpp\n// You should use void as a second template argument\n// if you don't need compile-time checks on T\ntemplate<typename T, typename SFINAE = typename std::enable_if<sizeof(T) <= 32>::type>\nstruct less_than_32_serializer {\n    template <typename BasicJsonType>\n    static void to_json(BasicJsonType& j, T value) {\n        // we want to use ADL, and call the correct to_json overload\n        using nlohmann::to_json; // this method is called by adl_serializer,\n                                 // this is where the magic happens\n        to_json(j, value);\n    }\n\n    template <typename BasicJsonType>\n    static void from_json(const BasicJsonType& j, T& value) {\n        // same thing here\n        using nlohmann::from_json;\n        from_json(j, value);\n    }\n};\n```\n\nBe **very** careful when reimplementing your serializer, you can stack overflow if you don't pay attention:\n\n```cpp\ntemplate <typename T, void>\nstruct bad_serializer\n{\n    template <typename BasicJsonType>\n    static void to_json(BasicJsonType& j, const T& value) {\n      // this calls BasicJsonType::json_serializer<T>::to_json(j, value)\n      // if BasicJsonType::json_serializer == bad_serializer ... oops!\n      j = value;\n    }\n\n    template <typename BasicJsonType>\n    static void to_json(const BasicJsonType& j, T& value) {\n      // this calls BasicJsonType::json_serializer<T>::from_json(j, value)\n      // if BasicJsonType::json_serializer == bad_serializer ... oops!\n      value = j.get<T>(); // oops!\n    }\n};\n```\n\n### Specializing enum conversion\n\nBy default, enum values are serialized to JSON as integers. In some cases, this could result in undesired behavior. If an enum is modified or re-ordered after data has been serialized to JSON, the later deserialized JSON data may be undefined or a different enum value than was originally intended.\n\nIt is possible to more precisely specify how a given enum is mapped to and from JSON as shown below:\n\n```cpp\n// example enum type declaration\nenum TaskState {\n    TS_STOPPED,\n    TS_RUNNING,\n    TS_COMPLETED,\n    TS_INVALID=-1,\n};\n\n// map TaskState values to JSON as strings\nNLOHMANN_JSON_SERIALIZE_ENUM( TaskState, {\n    {TS_INVALID, nullptr},\n    {TS_STOPPED, \"stopped\"},\n    {TS_RUNNING, \"running\"},\n    {TS_COMPLETED, \"completed\"},\n})\n```\n\nThe `NLOHMANN_JSON_SERIALIZE_ENUM()` macro declares a set of `to_json()` / `from_json()` functions for type `TaskState` while avoiding repetition and boilerplate serialization code.\n\n**Usage:**\n\n```cpp\n// enum to JSON as string\njson j = TS_STOPPED;\nassert(j == \"stopped\");\n\n// json string to enum\njson j3 = \"running\";\nassert(j3.get<TaskState>() == TS_RUNNING);\n\n// undefined json value to enum (where the first map entry above is the default)\njson jPi = 3.14;\nassert(jPi.get<TaskState>() == TS_INVALID);\n```\n\nJust as in [Arbitrary Type Conversions](#arbitrary-types-conversions) above,\n\n- `NLOHMANN_JSON_SERIALIZE_ENUM()` MUST be declared in your enum type's namespace (which can be the global namespace), or the library will not be able to locate it, and it will default to integer serialization.\n- It MUST be available (e.g., proper headers must be included) everywhere you use the conversions.\n\nOther Important points:\n\n- When using `get<ENUM_TYPE>()`, undefined JSON values will default to the first pair specified in your map. Select this default pair carefully.\n- If an enum or JSON value is specified more than once in your map, the first matching occurrence from the top of the map will be returned when converting to or from JSON.\n\n### Binary formats (BSON, CBOR, MessagePack, UBJSON, and BJData)\n\nThough JSON is a ubiquitous data format, it is not a very compact format suitable for data exchange, for instance over a network. Hence, the library supports [BSON](https://bsonspec.org) (Binary JSON), [CBOR](https://cbor.io) (Concise Binary Object Representation), [MessagePack](https://msgpack.org), [UBJSON](https://ubjson.org) (Universal Binary JSON Specification) and [BJData](https://neurojson.org/bjdata) (Binary JData) to efficiently encode JSON values to byte vectors and to decode such vectors.\n\n```cpp\n// create a JSON value\njson j = R\"({\"compact\": true, \"schema\": 0})\"_json;\n\n// serialize to BSON\nstd::vector<std::uint8_t> v_bson = json::to_bson(j);\n\n// 0x1B, 0x00, 0x00, 0x00, 0x08, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0x00, 0x01, 0x10, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n\n// roundtrip\njson j_from_bson = json::from_bson(v_bson);\n\n// serialize to CBOR\nstd::vector<std::uint8_t> v_cbor = json::to_cbor(j);\n\n// 0xA2, 0x67, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0xF5, 0x66, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00\n\n// roundtrip\njson j_from_cbor = json::from_cbor(v_cbor);\n\n// serialize to MessagePack\nstd::vector<std::uint8_t> v_msgpack = json::to_msgpack(j);\n\n// 0x82, 0xA7, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0xC3, 0xA6, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00\n\n// roundtrip\njson j_from_msgpack = json::from_msgpack(v_msgpack);\n\n// serialize to UBJSON\nstd::vector<std::uint8_t> v_ubjson = json::to_ubjson(j);\n\n// 0x7B, 0x69, 0x07, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0x54, 0x69, 0x06, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x69, 0x00, 0x7D\n\n// roundtrip\njson j_from_ubjson = json::from_ubjson(v_ubjson);\n```\n\nThe library also supports binary types from BSON, CBOR (byte strings), and MessagePack (bin, ext, fixext). They are stored by default as `std::vector<std::uint8_t>` to be processed outside the library.\n\n```cpp\n// CBOR byte string with payload 0xCAFE\nstd::vector<std::uint8_t> v = {0x42, 0xCA, 0xFE};\n\n// read value\njson j = json::from_cbor(v);\n\n// the JSON value has type binary\nj.is_binary(); // true\n\n// get reference to stored binary value\nauto& binary = j.get_binary();\n\n// the binary value has no subtype (CBOR has no binary subtypes)\nbinary.has_subtype(); // false\n\n// access std::vector<std::uint8_t> member functions\nbinary.size(); // 2\nbinary[0]; // 0xCA\nbinary[1]; // 0xFE\n\n// set subtype to 0x10\nbinary.set_subtype(0x10);\n\n// serialize to MessagePack\nauto cbor = json::to_msgpack(j); // 0xD5 (fixext2), 0x10, 0xCA, 0xFE\n```\n\n## Customers\n\nThe library is used in multiple projects, applications, operating systems, etc. The list below is not exhaustive, but the result of an internet search. If you know further customers of the library, please let me know, see [contact](#contact).\n\n[![logos of customers using the library](docs/mkdocs/docs/images/customers.png)](https://json.nlohmann.me/home/customers/)\n\n## Supported compilers\n\nThough it's 2026 already, the support for C++11 is still a bit sparse. Currently, the following compilers are known to work:\n\n- GCC 4.8 - 14.2 (and possibly later)\n- Clang 3.4 - 21.0 (and possibly later)\n- Apple Clang 9.1 - 16.0 (and possibly later)\n- Intel C++ Compiler 17.0.2 (and possibly later)\n- Nvidia CUDA Compiler 11.0.221 (and possibly later)\n- Microsoft Visual C++ 2015 / Build Tools 14.0.25123.0 (and possibly later)\n- Microsoft Visual C++ 2017 / Build Tools 15.5.180.51428 (and possibly later)\n- Microsoft Visual C++ 2019 / Build Tools 16.3.1+1def00d3d (and possibly later)\n- Microsoft Visual C++ 2022 / Build Tools 19.30.30709.0 (and possibly later)\n\nI would be happy to learn about other compilers/versions.\n\nPlease note:\n\n- GCC 4.8 has a bug [57824](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=57824): multiline raw strings cannot be the arguments to macros. Don't use multiline raw strings directly in macros with this compiler.\n- Android defaults to using very old compilers and C++ libraries. To fix this, add the following to your `Application.mk`. This will switch to the LLVM C++ library, the Clang compiler, and enable C++11 and other features disabled by default.\n\n    ```makefile\n    APP_STL := c++_shared\n    NDK_TOOLCHAIN_VERSION := clang3.6\n    APP_CPPFLAGS += -frtti -fexceptions\n    ```\n\n    The code compiles successfully with [Android NDK](https://developer.android.com/ndk/index.html?hl=ml), Revision 9 - 11 (and possibly later) and [CrystaX's Android NDK](https://www.crystax.net/en/android/ndk) version 10.\n\n- For GCC running on MinGW or Android SDK, the error `'to_string' is not a member of 'std'` (or similarly, for `strtod` or `strtof`) may occur. Note this is not an issue with the code, but rather with the compiler itself. On Android, see above to build with a newer environment.  For MinGW, please refer to [this site](https://tehsausage.com/mingw-to-string) and [this discussion](https://github.com/nlohmann/json/issues/136) for information on how to fix this bug. For Android NDK using `APP_STL := gnustl_static`, please refer to [this discussion](https://github.com/nlohmann/json/issues/219).\n\n- Unsupported versions of GCC and Clang are rejected by `#error` directives. This can be switched off by defining `JSON_SKIP_UNSUPPORTED_COMPILER_CHECK`. Note that you can expect no support in this case.\n\nSee the page [quality assurance](https://json.nlohmann.me/community/quality_assurance) on the compilers used to check the library in the CI.\n\n## Integration\n\n[`json.hpp`](https://github.com/nlohmann/json/blob/develop/single_include/nlohmann/json.hpp) is the single required file in `single_include/nlohmann` or [released here](https://github.com/nlohmann/json/releases). You need to add\n\n```cpp\n#include <nlohmann/json.hpp>\n\n// for convenience\nusing json = nlohmann::json;\n```\n\nto the files you want to process JSON and set the necessary switches to enable C++11 (e.g., `-std=c++11` for GCC and Clang).\n\nYou can further use file [`include/nlohmann/json_fwd.hpp`](https://github.com/nlohmann/json/blob/develop/include/nlohmann/json_fwd.hpp) for forward-declarations. The installation of `json_fwd.hpp` (as part of cmake's install step) can be achieved by setting `-DJSON_MultipleHeaders=ON`.\n\n### CMake\n\nYou can also use the `nlohmann_json::nlohmann_json` interface target in CMake.  This target populates the appropriate usage requirements for `INTERFACE_INCLUDE_DIRECTORIES` to point to the appropriate include directories and `INTERFACE_COMPILE_FEATURES` for the necessary C++11 flags.\n\n#### External\n\nTo use this library from a CMake project, you can locate it directly with `find_package()` and use the namespaced imported target from the generated package configuration:\n\n```cmake\n# CMakeLists.txt\nfind_package(nlohmann_json 3.12.0 REQUIRED)\n...\nadd_library(foo ...)\n...\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\nThe package configuration file, `nlohmann_jsonConfig.cmake`, can be used either from an install tree or directly out of the build tree.\n\n#### Embedded\n\nTo embed the library directly into an existing CMake project, place the entire source tree in a subdirectory and call `add_subdirectory()` in your `CMakeLists.txt` file:\n\n```cmake\n# Typically you don't care so much for a third party library's tests to be\n# run from your own project's code.\nset(JSON_BuildTests OFF CACHE INTERNAL \"\")\n\n# If you only include this third party in PRIVATE source files, you do not\n# need to install it when your main project gets installed.\n# set(JSON_Install OFF CACHE INTERNAL \"\")\n\n# Don't use include(nlohmann_json/CMakeLists.txt) since that carries with it\n# unintended consequences that will break the build.  It's generally\n# discouraged (although not necessarily well documented as such) to use\n# include(...) for pulling in other CMake projects anyways.\nadd_subdirectory(nlohmann_json)\n...\nadd_library(foo ...)\n...\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n##### Embedded (FetchContent)\n\nSince CMake v3.11,\n[FetchContent](https://cmake.org/cmake/help/v3.11/module/FetchContent.html) can\nbe used to automatically download a release as a dependency at configure time.\n\nExample:\n\n```cmake\ninclude(FetchContent)\n\nFetchContent_Declare(json URL https://github.com/nlohmann/json/releases/download/v3.12.0/json.tar.xz)\nFetchContent_MakeAvailable(json)\n\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n**Note**: It is recommended to use the URL approach described above, which is supported as of version 3.10.0. See\n<https://json.nlohmann.me/integration/cmake/#fetchcontent> for more information.\n\n#### Supporting Both\n\nTo allow your project to support either an externally supplied or an embedded JSON library, you can use a pattern akin to the following:\n\n``` cmake\n# Top level CMakeLists.txt\nproject(FOO)\n...\noption(FOO_USE_EXTERNAL_JSON \"Use an external JSON library\" OFF)\n...\nadd_subdirectory(thirdparty)\n...\nadd_library(foo ...)\n...\n# Note that the namespaced target will always be available regardless of the\n# import method\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n```cmake\n# thirdparty/CMakeLists.txt\n...\nif(FOO_USE_EXTERNAL_JSON)\n  find_package(nlohmann_json 3.12.0 REQUIRED)\nelse()\n  set(JSON_BuildTests OFF CACHE INTERNAL \"\")\n  add_subdirectory(nlohmann_json)\nendif()\n...\n```\n\n`thirdparty/nlohmann_json` is then a complete copy of this source tree.\n\n### Package Managers\n\nUse your favorite [**package manager**](https://json.nlohmann.me/integration/package_managers/) to use the library.\n\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/homebrew.svg\" height=\"20\">&nbsp;[**Homebrew**](https://json.nlohmann.me/integration/package_managers/#homebrew) `nlohmann-json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/meson.svg\" height=\"20\">&nbsp;[**Meson**](https://json.nlohmann.me/integration/package_managers/#meson) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/bazel.svg\" height=\"20\">&nbsp;[**Bazel**](https://json.nlohmann.me/integration/package_managers/#bazel) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/conan.svg\" height=\"20\">&nbsp;[**Conan**](https://json.nlohmann.me/integration/package_managers/#conan) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/spack.svg\" height=\"20\">&nbsp;[**Spack**](https://json.nlohmann.me/integration/package_managers/#spack) `nlohmann-json`\n- [**Hunter**](https://json.nlohmann.me/integration/package_managers/#hunter) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/vcpkg.png\" height=\"20\">&nbsp;[**vcpkg**](https://json.nlohmann.me/integration/package_managers/#vcpkg) `nlohmann-json`\n- [**cget**](https://json.nlohmann.me/integration/package_managers/#cget) `nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/swift.svg\" height=\"20\">&nbsp;[**Swift Package Manager**](https://json.nlohmann.me/integration/package_managers/#swift-package-manager) `nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/nuget.svg\" height=\"20\">&nbsp;[**Nuget**](https://json.nlohmann.me/integration/package_managers/#nuget) `nlohmann.json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/conda.svg\" height=\"20\">&nbsp;[**Conda**](https://json.nlohmann.me/integration/package_managers/#conda) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/macports.svg\" height=\"20\">&nbsp;[**MacPorts**](https://json.nlohmann.me/integration/package_managers/#macports) `nlohmann-json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/CPM.png\" height=\"20\">&nbsp;[**cpm.cmake**](https://json.nlohmann.me/integration/package_managers/#cpmcmake) `gh:nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/xmake.svg\" height=\"20\">&nbsp;[**xmake**](https://json.nlohmann.me/integration/package_managers/#xmake) `nlohmann_json`\n\nThe library is part of many package managers. See the [**documentation**](https://json.nlohmann.me/integration/package_managers/) for detailed descriptions and examples.\n\n### Pkg-config\n\nIf you are using bare Makefiles, you can use `pkg-config` to generate the include flags that point to where the library is installed:\n\n```sh\npkg-config nlohmann_json --cflags\n```\n\n## License\n\n<img align=\"right\" src=\"https://149753425.v2.pressablecdn.com/wp-content/uploads/2009/06/OSIApproved_100X125.png\" alt=\"OSI approved license\">\n\nThe class is licensed under the [MIT License](https://opensource.org/licenses/MIT):\n\nCopyright &copy; 2013-2026 [Niels Lohmann](https://nlohmann.me)\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n* * *\n\n- The class contains the UTF-8 Decoder from Bjoern Hoehrmann which is licensed under the [MIT License](https://opensource.org/licenses/MIT) (see above). Copyright &copy; 2008-2009 [Bj√∂rn Hoehrmann](https://bjoern.hoehrmann.de/) <bjoern@hoehrmann.de>\n- The class contains a slightly modified version of the Grisu2 algorithm from Florian Loitsch which is licensed under the [MIT License](https://opensource.org/licenses/MIT) (see above). Copyright &copy; 2009 [Florian Loitsch](https://florian.loitsch.com/)\n- The class contains a copy of [Hedley](https://nemequ.github.io/hedley/) from Evan Nemerson which is licensed as [CC0-1.0](https://creativecommons.org/publicdomain/zero/1.0/).\n- The class contains parts of [Google Abseil](https://github.com/abseil/abseil-cpp) which is licensed under the [Apache 2.0 License](https://opensource.org/licenses/Apache-2.0).\n\n<img align=\"right\" src=\"https://git.fsfe.org/reuse/reuse-ci/raw/branch/master/reuse-horizontal.png\" alt=\"REUSE Software\">\n\nThe library is compliant to version 3.3 of the [**REUSE specification**](https://reuse.software):\n\n- Every source file contains an SPDX copyright header.\n- The full text of all licenses used in the repository can be found in the `LICENSES` folder.\n- File `.reuse/dep5` contains an overview of all files' copyrights and licenses.\n- Run `pipx run reuse lint` to verify the project's REUSE compliance and `pipx run reuse spdx` to generate a SPDX SBOM.\n\n## Contact\n\nIf you have questions regarding the library, I would like to invite you to [open an issue at GitHub](https://github.com/nlohmann/json/issues/new/choose). Please describe your request, problem, or question as detailed as possible, and also mention the version of the library you are using as well as the version of your compiler and operating system. Opening an issue at GitHub allows other users and contributors to this library to collaborate. For instance, I have little experience with MSVC, and most issues in this regard have been solved by a growing community. If you have a look at the [closed issues](https://github.com/nlohmann/json/issues?q=is%3Aissue+is%3Aclosed), you will see that we react quite timely in most cases.\n\nOnly if your request would contain confidential information, please [send me an email](mailto:mail@nlohmann.me). For encrypted messages, please use [this key](https://keybase.io/nlohmann/pgp_keys.asc).\n\n## Security\n\n[Commits by Niels Lohmann](https://github.com/nlohmann/json/commits) and [releases](https://github.com/nlohmann/json/releases) are signed with this [PGP Key](https://keybase.io/nlohmann/pgp_keys.asc?fingerprint=797167ae41c0a6d9232e48457f3cea63ae251b69).\n\n## Thanks\n\nI deeply appreciate the help of the following people.\n\n<img src=\"https://raw.githubusercontent.com/nlohmann/json/develop/docs/avatars.png\" align=\"right\" alt=\"GitHub avatars of the contributors\">\n\n1. [Teemperor](https://github.com/Teemperor) implemented CMake support and lcov integration, realized escape and Unicode handling in the string parser, and fixed the JSON serialization.\n2. [elliotgoodrich](https://github.com/elliotgoodrich) fixed an issue with double deletion in the iterator classes.\n3. [kirkshoop](https://github.com/kirkshoop) made the iterators of the class composable to other libraries.\n4. [wancw](https://github.com/wanwc) fixed a bug that hindered the class to compile with Clang.\n5. Tomas √Öblad found a bug in the iterator implementation.\n6. [Joshua C. Randall](https://github.com/jrandall) fixed a bug in the floating-point serialization.\n7. [Aaron Burghardt](https://github.com/aburgh) implemented code to parse streams incrementally. Furthermore, he greatly improved the parser class by allowing the definition of a filter function to discard undesired elements while parsing.\n8. [Daniel Kopeƒçek](https://github.com/dkopecek) fixed a bug in the compilation with GCC 5.0.\n9. [Florian Weber](https://github.com/Florianjw) fixed a bug in and improved the performance of the comparison operators.\n10. [Eric Cornelius](https://github.com/EricMCornelius) pointed out a bug in the handling with NaN and infinity values. He also improved the performance of the string escaping.\n11. [ÊòìÊÄùÈæô](https://github.com/likebeta) implemented a conversion from anonymous enums.\n12. [kepkin](https://github.com/kepkin) patiently pushed forward the support for Microsoft Visual Studio.\n13. [gregmarr](https://github.com/gregmarr) simplified the implementation of reverse iterators and helped with numerous hints and improvements. In particular, he pushed forward the implementation of user-defined types.\n14. [Caio Luppi](https://github.com/caiovlp) fixed a bug in the Unicode handling.\n15. [dariomt](https://github.com/dariomt) fixed some typos in the examples.\n16. [Daniel Frey](https://github.com/d-frey) cleaned up some pointers and implemented exception-safe memory allocation.\n17. [Colin Hirsch](https://github.com/ColinH) took care of a small namespace issue.\n18. [Huu Nguyen](https://github.com/whoshuu) corrected a variable name in the documentation.\n19. [Silverweed](https://github.com/silverweed) overloaded `parse()` to accept an rvalue reference.\n20. [dariomt](https://github.com/dariomt) fixed a subtlety in MSVC type support and implemented the `get_ref()` function to get a reference to stored values.\n21. [ZahlGraf](https://github.com/ZahlGraf) added a workaround that allows compilation using Android NDK.\n22. [whackashoe](https://github.com/whackashoe) replaced a function that was marked as unsafe by Visual Studio.\n23. [406345](https://github.com/406345) fixed two small warnings.\n24. [Glen Fernandes](https://github.com/glenfe) noted a potential portability problem in the `has_mapped_type` function.\n25. [Corbin Hughes](https://github.com/nibroc) fixed some typos in the contribution guidelines.\n26. [twelsby](https://github.com/twelsby) fixed the array subscript operator, an issue that failed the MSVC build, and floating-point parsing/dumping. He further added support for unsigned integer numbers and implemented better roundtrip support for parsed numbers.\n27. [Volker Diels-Grabsch](https://github.com/vog) fixed a link in the README file.\n28. [msm-](https://github.com/msm-) added support for American Fuzzy Lop.\n29. [Annihil](https://github.com/Annihil) fixed an example in the README file.\n30. [Themercee](https://github.com/Themercee) noted a wrong URL in the README file.\n31. [Lv Zheng](https://github.com/lv-zheng) fixed a namespace issue with `int64_t` and `uint64_t`.\n32. [abc100m](https://github.com/abc100m) analyzed the issues with GCC 4.8 and proposed a [partial solution](https://github.com/nlohmann/json/pull/212).\n33. [zewt](https://github.com/zewt) added useful notes to the README file about Android.\n34. [R√≥bert M√°rki](https://github.com/robertmrk) added a fix to use move iterators and improved the integration via CMake.\n35. [Chris Kitching](https://github.com/ChrisKitching) cleaned up the CMake files.\n36. [Tom Needham](https://github.com/06needhamt) fixed a subtle bug with MSVC 2015 which was also proposed by [Michael K.](https://github.com/Epidal).\n37. [M√°rio Feroldi](https://github.com/thelostt) fixed a small typo.\n38. [duncanwerner](https://github.com/duncanwerner) found a really embarrassing performance regression in the 2.0.0 release.\n39. [Damien](https://github.com/dtoma) fixed one of the last conversion warnings.\n40. [Thomas Braun](https://github.com/t-b) fixed a warning in a test case and adjusted MSVC calls in the CI.\n41. [Th√©o DELRIEU](https://github.com/theodelrieu) patiently and constructively oversaw the long way toward [iterator-range parsing](https://github.com/nlohmann/json/issues/290). He also implemented the magic behind the serialization/deserialization of user-defined types and split the single header file into smaller chunks.\n42. [Stefan](https://github.com/5tefan) fixed a minor issue in the documentation.\n43. [Vasil Dimov](https://github.com/vasild) fixed the documentation regarding conversions from `std::multiset`.\n44. [ChristophJud](https://github.com/ChristophJud) overworked the CMake files to ease project inclusion.\n45. [Vladimir Petrigo](https://github.com/vpetrigo) made a SFINAE hack more readable and added Visual Studio 17 to the build matrix.\n46. [Denis Andrejew](https://github.com/seeekr) fixed a grammar issue in the README file.\n47. [Pierre-Antoine Lacaze](https://github.com/palacaze) found a subtle bug in the `dump()` function.\n48. [TurpentineDistillery](https://github.com/TurpentineDistillery) pointed to [`std::locale::classic()`](https://en.cppreference.com/w/cpp/locale/locale/classic) to avoid too much locale joggling, found some nice performance improvements in the parser, improved the benchmarking code, and realized locale-independent number parsing and printing.\n49. [cgzones](https://github.com/cgzones) had an idea how to fix the Coverity scan.\n50. [Jared Grubb](https://github.com/jaredgrubb) silenced a nasty documentation warning.\n51. [Yixin Zhang](https://github.com/qwename) fixed an integer overflow check.\n52. [Bosswestfalen](https://github.com/Bosswestfalen) merged two iterator classes into a smaller one.\n53. [Daniel599](https://github.com/Daniel599) helped to get Travis to execute the tests with Clang's sanitizers.\n54. [Jonathan Lee](https://github.com/vjon) fixed an example in the README file.\n55. [gnzlbg](https://github.com/gnzlbg) supported the implementation of user-defined types.\n56. [Alexej Harm](https://github.com/qis) helped to get the user-defined types working with Visual Studio.\n57. [Jared Grubb](https://github.com/jaredgrubb) supported the implementation of user-defined types.\n58. [EnricoBilla](https://github.com/EnricoBilla) noted a typo in an example.\n59. [Martin Ho≈ôe≈àovsk√Ω](https://github.com/horenmar) found a way for a 2x speedup for the compilation time of the test suite.\n60. [ukhegg](https://github.com/ukhegg) found proposed an improvement for the examples section.\n61. [rswanson-ihi](https://github.com/rswanson-ihi) noted a typo in the README.\n62. [Mihai Stan](https://github.com/stanmihai4) fixed a bug in the comparison with `nullptr`s.\n63. [Tushar Maheshwari](https://github.com/tusharpm) added [cotire](https://github.com/sakra/cotire) support to speed up the compilation.\n64. [TedLyngmo](https://github.com/TedLyngmo) noted a typo in the README, removed unnecessary bit arithmetic, and fixed some `-Weffc++` warnings.\n65. [Krzysztof Wo≈õ](https://github.com/krzysztofwos) made exceptions more visible.\n66. [ftillier](https://github.com/ftillier) fixed a compiler warning.\n67. [tinloaf](https://github.com/tinloaf) made sure all pushed warnings are properly popped.\n68. [Fytch](https://github.com/Fytch) found a bug in the documentation.\n69. [Jay Sistar](https://github.com/Type1J) implemented a Meson build description.\n70. [Henry Lee](https://github.com/HenryRLee) fixed a warning in ICC and improved the iterator implementation.\n71. [Vincent Thiery](https://github.com/vthiery) maintains a package for the Conan package manager.\n72. [Steffen](https://github.com/koemeet) fixed a potential issue with MSVC and `std::min`.\n73. [Mike Tzou](https://github.com/Chocobo1) fixed some typos.\n74. [amrcode](https://github.com/amrcode) noted misleading documentation about comparison of floats.\n75. [Oleg Endo](https://github.com/olegendo) reduced the memory consumption by replacing `<iostream>` with `<iosfwd>`.\n76. [dan-42](https://github.com/dan-42) cleaned up the CMake files to simplify including/reusing of the library.\n77. [Nikita Ofitserov](https://github.com/himikof) allowed for moving values from initializer lists.\n78. [Greg Hurrell](https://github.com/wincent) fixed a typo.\n79. [Dmitry Kukovinets](https://github.com/DmitryKuk) fixed a typo.\n80. [kbthomp1](https://github.com/kbthomp1) fixed an issue related to the Intel OSX compiler.\n81. [Markus Werle](https://github.com/daixtrose) fixed a typo.\n82. [WebProdPP](https://github.com/WebProdPP) fixed a subtle error in a precondition check.\n83. [Alex](https://github.com/leha-bot) noted an error in a code sample.\n84. [Tom de Geus](https://github.com/tdegeus) reported some warnings with ICC and helped to fix them.\n85. [Perry Kundert](https://github.com/pjkundert) simplified reading from input streams.\n86. [Sonu Lohani](https://github.com/sonulohani) fixed a small compilation error.\n87. [Jamie Seward](https://github.com/jseward) fixed all MSVC warnings.\n88. [Nate Vargas](https://github.com/eld00d) added a Doxygen tag file.\n89. [pvleuven](https://github.com/pvleuven) helped to fix a warning in ICC.\n90. [Pavel](https://github.com/crea7or) helped to fix some warnings in MSVC.\n91. [Jamie Seward](https://github.com/jseward) avoided unnecessary string copies in `find()` and `count()`.\n92. [Mitja](https://github.com/Itja) fixed some typos.\n93. [Jorrit Wronski](https://github.com/jowr) updated the Hunter package links.\n94. [Matthias M√∂ller](https://github.com/TinyTinni) added a `.natvis` for the MSVC debug view.\n95. [bogemic](https://github.com/bogemic) fixed some C++17 deprecation warnings.\n96. [Eren Okka](https://github.com/erengy) fixed some MSVC warnings.\n97. [abolz](https://github.com/abolz) integrated the Grisu2 algorithm for proper floating-point formatting, allowing more roundtrip checks to succeed.\n98. [Vadim Evard](https://github.com/Pipeliner) fixed a Markdown issue in the README.\n99. [zerodefect](https://github.com/zerodefect) fixed a compiler warning.\n100. [Kert](https://github.com/kaidokert) allowed to template the string type in the serialization and added the possibility to override the exceptional behavior.\n101. [mark-99](https://github.com/mark-99) helped fix an ICC error.\n102. [Patrik Huber](https://github.com/patrikhuber) fixed links in the README file.\n103. [johnfb](https://github.com/johnfb) found a bug in the implementation of CBOR's indefinite length strings.\n104. [Paul Fultz II](https://github.com/pfultz2) added a note on the cget package manager.\n105. [Wilson Lin](https://github.com/wla80) made the integration section of the README more concise.\n106. [RalfBielig](https://github.com/ralfbielig) detected and fixed a memory leak in the parser callback.\n107. [agrianius](https://github.com/agrianius) allowed dumping JSON to an alternative string type.\n108. [Kevin Tonon](https://github.com/ktonon) overworked the C++11 compiler checks in CMake.\n109. [Axel Huebl](https://github.com/ax3l) simplified a CMake check and added support for the [Spack package manager](https://spack.io).\n110. [Carlos O'Ryan](https://github.com/coryan) fixed a typo.\n111. [James Upjohn](https://github.com/jammehcow) fixed a version number in the compilers section.\n112. [Chuck Atkins](https://github.com/chuckatkins) adjusted the CMake files to the CMake packaging guidelines and provided documentation for the CMake integration.\n113. [Jan Sch√∂ppach](https://github.com/dns13) fixed a typo.\n114. [martin-mfg](https://github.com/martin-mfg) fixed a typo.\n115. [Matthias M√∂ller](https://github.com/TinyTinni) removed the dependency from `std::stringstream`.\n116. [agrianius](https://github.com/agrianius) added code to use alternative string implementations.\n117. [Daniel599](https://github.com/Daniel599) allowed to use more algorithms with the `items()` function.\n118. [Julius Rakow](https://github.com/jrakow) fixed the Meson include directory and fixed the links to [cppreference.com](https://cppreference.com).\n119. [Sonu Lohani](https://github.com/sonulohani) fixed the compilation with MSVC 2015 in debug mode.\n120. [grembo](https://github.com/grembo) fixed the test suite and re-enabled several test cases.\n121. [Hyeon Kim](https://github.com/simnalamburt) introduced the macro `JSON_INTERNAL_CATCH` to control the exception handling inside the library.\n122. [thyu](https://github.com/thyu) fixed a compiler warning.\n123. [David Guthrie](https://github.com/LEgregius) fixed a subtle compilation error with Clang 3.4.2.\n124. [Dennis Fischer](https://github.com/dennisfischer) allowed to call `find_package` without installing the library.\n125. [Hyeon Kim](https://github.com/simnalamburt) fixed an issue with a double macro definition.\n126. [Ben Berman](https://github.com/rivertam) made some error messages more understandable.\n127. [zakalibit](https://github.com/zakalibit) fixed a compilation problem with the Intel C++ compiler.\n128. [mandreyel](https://github.com/mandreyel) fixed a compilation problem.\n129. [Kostiantyn Ponomarenko](https://github.com/koponomarenko) added version and license information to the Meson build file.\n130. [Henry Schreiner](https://github.com/henryiii) added support for GCC 4.8.\n131. [knilch](https://github.com/knilch0r) made sure the test suite does not stall when run in the wrong directory.\n132. [Antonio Borondo](https://github.com/antonioborondo) fixed an MSVC 2017 warning.\n133. [Dan Gendreau](https://github.com/dgendreau) implemented the `NLOHMANN_JSON_SERIALIZE_ENUM` macro to quickly define an enum/JSON mapping.\n134. [efp](https://github.com/efp) added line and column information to parse errors.\n135. [julian-becker](https://github.com/julian-becker) added BSON support.\n136. [Pratik Chowdhury](https://github.com/pratikpc) added support for structured bindings.\n137. [David Avedissian](https://github.com/davedissian) added support for Clang 5.0.1 (PS4 version).\n138. [Jonathan Dumaresq](https://github.com/dumarjo) implemented an input adapter to read from `FILE*`.\n139. [kjpus](https://github.com/kjpus) fixed a link in the documentation.\n140. [Manvendra Singh](https://github.com/manu-chroma) fixed a typo in the documentation.\n141. [ziggurat29](https://github.com/ziggurat29) fixed an MSVC warning.\n142. [Sylvain Corlay](https://github.com/SylvainCorlay) added code to avoid an issue with MSVC.\n143. [mefyl](https://github.com/mefyl) fixed a bug when JSON was parsed from an input stream.\n144. [Millian Poquet](https://github.com/mpoquet) allowed to install the library via Meson.\n145. [Michael Behrns-Miller](https://github.com/moodboom) found an issue with a missing namespace.\n146. [Nasztanovics Ferenc](https://github.com/naszta) fixed a compilation issue with libc 2.12.\n147. [Andreas Schwab](https://github.com/andreas-schwab) fixed the endian conversion.\n148. [Mark-Dunning](https://github.com/Mark-Dunning) fixed a warning in MSVC.\n149. [Gareth Sylvester-Bradley](https://github.com/garethsb-sony) added `operator/` for JSON Pointers.\n150. [John-Mark](https://github.com/johnmarkwayve) noted a missing header.\n151. [Vitaly Zaitsev](https://github.com/xvitaly) fixed compilation with GCC 9.0.\n152. [Laurent Stacul](https://github.com/stac47) fixed compilation with GCC 9.0.\n153. [Ivor Wanders](https://github.com/iwanders) helped to reduce the CMake requirement to version 3.1.\n154. [njlr](https://github.com/njlr) updated the Buckaroo instructions.\n155. [Lion](https://github.com/lieff) fixed a compilation issue with GCC 7 on CentOS.\n156. [Isaac Nickaein](https://github.com/nickaein) improved the integer serialization performance and implemented the `contains()` function.\n157. [past-due](https://github.com/past-due) suppressed an unfixable warning.\n158. [Elvis Oric](https://github.com/elvisoric) improved Meson support.\n159. [Matƒõj Plch](https://github.com/Afforix) fixed an example in the README.\n160. [Mark Beckwith](https://github.com/wythe) fixed a typo.\n161. [scinart](https://github.com/scinart) fixed a bug in the serializer.\n162. [Patrick Boettcher](https://github.com/pboettch) implemented `push_back()` and `pop_back()` for JSON Pointers.\n163. [Bruno Oliveira](https://github.com/nicoddemus) added support for Conda.\n164. [Michele Caini](https://github.com/skypjack) fixed links in the README.\n165. [Hani](https://github.com/hnkb) documented how to install the library with NuGet.\n166. [Mark Beckwith](https://github.com/wythe) fixed a typo.\n167. [yann-morin-1998](https://github.com/yann-morin-1998) helped to reduce the CMake requirement to version 3.1.\n168. [Konstantin Podsvirov](https://github.com/podsvirov) maintains a package for the MSYS2 software distro.\n169. [remyabel](https://github.com/remyabel) added GNUInstallDirs to the CMake files.\n170. [Taylor Howard](https://github.com/taylorhoward92) fixed a unit test.\n171. [Gabe Ron](https://github.com/Macr0Nerd) implemented the `to_string` method.\n172. [Watal M. Iwasaki](https://github.com/heavywatal) fixed a Clang warning.\n173. [Viktor Kirilov](https://github.com/onqtam) switched the unit tests from [Catch](https://github.com/philsquared/Catch) to [doctest](https://github.com/onqtam/doctest)\n174. [Juncheng E](https://github.com/ejcjason) fixed a typo.\n175. [tete17](https://github.com/tete17) fixed a bug in the `contains` function.\n176. [Xav83](https://github.com/Xav83) fixed some cppcheck warnings.\n177. [0xflotus](https://github.com/0xflotus) fixed some typos.\n178. [Christian Deneke](https://github.com/chris0x44) added a const version of `json_pointer::back`.\n179. [Julien Hamaide](https://github.com/crazyjul) made the `items()` function work with custom string types.\n180. [Evan Nemerson](https://github.com/nemequ) updated fixed a bug in Hedley and updated this library accordingly.\n181. [Florian Pigorsch](https://github.com/flopp) fixed a lot of typos.\n182. [Camille B√©gu√©](https://github.com/cbegue) fixed an issue in the conversion from  `std::pair` and `std::tuple` to `json`.\n183. [Anthony VH](https://github.com/AnthonyVH) fixed a compile error in an enum deserialization.\n184. [Yuriy Vountesmery](https://github.com/ua-code-dragon) noted a subtle bug in a preprocessor check.\n185. [Chen](https://github.com/dota17) fixed numerous issues in the library.\n186. [Antony Kellermann](https://github.com/aokellermann) added a CI step for GCC 10.1.\n187. [Alex](https://github.com/gistrec) fixed an MSVC warning.\n188. [Rainer](https://github.com/rvjr) proposed an improvement in the floating-point serialization in CBOR.\n189. [Francois Chabot](https://github.com/FrancoisChabot) made performance improvements in the input adapters.\n190. [Arthur Sonzogni](https://github.com/ArthurSonzogni) documented how the library can be included via `FetchContent`.\n191. [Rimas Miseviƒçius](https://github.com/rmisev) fixed an error message.\n192. [Alexander Myasnikov](https://github.com/alexandermyasnikov) fixed some examples and a link in the README.\n193. [Hubert Chathi](https://github.com/uhoreg) made CMake's version config file architecture-independent.\n194. [OmnipotentEntity](https://github.com/OmnipotentEntity) implemented the binary values for CBOR, MessagePack, BSON, and UBJSON.\n195. [ArtemSarmini](https://github.com/ArtemSarmini) fixed a compilation issue with GCC 10 and fixed a leak.\n196. [Evgenii Sopov](https://github.com/sea-kg) integrated the library to the wsjcpp package manager.\n197. [Sergey Linev](https://github.com/linev) fixed a compiler warning.\n198. [Miguel Magalh√£es](https://github.com/magamig) fixed the year in the copyright.\n199. [Gareth Sylvester-Bradley](https://github.com/garethsb-sony) fixed a compilation issue with MSVC.\n200. [Alexander ‚Äúweej‚Äù Jones](https://github.com/alex-weej) fixed an example in the README.\n201. [Antoine C≈ìur](https://github.com/Coeur) fixed some typos in the documentation.\n202. [jothepro](https://github.com/jothepro) updated links to the Hunter package.\n203. [Dave Lee](https://github.com/kastiglione) fixed a link in the README.\n204. [Jo√´l Lamotte](https://github.com/Klaim) added instruction for using Build2's package manager.\n205. [Paul Jurczak](https://github.com/pauljurczak) fixed an example in the README.\n206. [Sonu Lohani](https://github.com/sonulohani) fixed a warning.\n207. [Carlos Gomes Martinho](https://github.com/gocarlos) updated the Conan package source.\n208. [Konstantin Podsvirov](https://github.com/podsvirov) fixed the MSYS2 package documentation.\n209. [Tridacnid](https://github.com/Tridacnid) improved the CMake tests.\n210. [Michael](https://github.com/MBalszun) fixed MSVC warnings.\n211. [Quentin Barbarat](https://github.com/quentin-dev) fixed an example in the documentation.\n212. [XyFreak](https://github.com/XyFreak) fixed a compiler warning.\n213. [TotalCaesar659](https://github.com/TotalCaesar659) fixed links in the README.\n214. [Tanuj Garg](https://github.com/tanuj208) improved the fuzzer coverage for UBSAN input.\n215. [AODQ](https://github.com/AODQ) fixed a compiler warning.\n216. [jwittbrodt](https://github.com/jwittbrodt) made `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE` inline.\n217. [pfeatherstone](https://github.com/pfeatherstone) improved the upper bound of arguments of the `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`/`NLOHMANN_DEFINE_TYPE_INTRUSIVE` macros.\n218. [Jan Proch√°zka](https://github.com/jprochazk) fixed a bug in the CBOR parser for binary and string values.\n219. [T0b1-iOS](https://github.com/T0b1-iOS) fixed a bug in the new hash implementation.\n220. [Matthew Bauer](https://github.com/matthewbauer) adjusted the CBOR writer to create tags for binary subtypes.\n221. [gatopeich](https://github.com/gatopeich) implemented an ordered map container for `nlohmann::ordered_json`.\n222. [√ârico Nogueira Rolim](https://github.com/ericonr) added support for pkg-config.\n223. [KonanM](https://github.com/KonanM) proposed an implementation for the `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`/`NLOHMANN_DEFINE_TYPE_INTRUSIVE` macros.\n224. [Guillaume Racicot](https://github.com/gracicot) implemented `string_view` support and allowed C++20 support.\n225. [Alex Reinking](https://github.com/alexreinking) improved CMake support for `FetchContent`.\n226. [Hannes Domani](https://github.com/ssbssa) provided a GDB pretty printer.\n227. Lars Wirzenius reviewed the README file.\n228. [Jun Jie](https://github.com/ongjunjie) fixed a compiler path in the CMake scripts.\n229. [Ronak Buch](https://github.com/rbuch) fixed typos in the documentation.\n230. [Alexander Karzhenkov](https://github.com/karzhenkov) fixed a move constructor and the Travis builds.\n231. [Leonardo Lima](https://github.com/leozz37) added CPM.Cmake support.\n232. [Joseph Blackman](https://github.com/jbzdarkid) fixed a warning.\n233. [Yaroslav](https://github.com/YarikTH) updated doctest and implemented unit tests.\n234. [Martin Stump](https://github.com/globberwops) fixed a bug in the CMake files.\n235. [Jaakko Moisio](https://github.com/jasujm) fixed a bug in the input adapters.\n236. [bl-ue](https://github.com/bl-ue) fixed some Markdown issues in the README file.\n237. [William A. Wieselquist](https://github.com/wawiesel) fixed an example from the README.\n238. [abbaswasim](https://github.com/abbaswasim) fixed an example from the README.\n239. [Remy Jette](https://github.com/remyjette) fixed a warning.\n240. [Fraser](https://github.com/frasermarlow) fixed the documentation.\n241. [Ben Beasley](https://github.com/musicinmybrain) updated doctest.\n242. [Doron Behar](https://github.com/doronbehar) fixed pkg-config.pc.\n243. [raduteo](https://github.com/raduteo) fixed a warning.\n244. [David Pfahler](https://github.com/theShmoo) added the possibility to compile the library without I/O support.\n245. [Morten Fyhn Amundsen](https://github.com/mortenfyhn) fixed a typo.\n246. [jpl-mac](https://github.com/jpl-mac) allowed treating the library as a system header in CMake.\n247. [Jason Dsouza](https://github.com/jasmcaus) fixed the indentation of the CMake file.\n248. [offa](https://github.com/offa) added a link to Conan Center to the documentation.\n249. [TotalCaesar659](https://github.com/TotalCaesar659) updated the links in the documentation to use HTTPS.\n250. [Rafail Giavrimis](https://github.com/grafail) fixed the Google Benchmark default branch.\n251. [Louis Dionne](https://github.com/ldionne) fixed a conversion operator.\n252. [justanotheranonymoususer](https://github.com/justanotheranonymoususer) made the examples in the README more consistent.\n253. [Finkman](https://github.com/Finkman) suppressed some `-Wfloat-equal` warnings.\n254. [Ferry Huberts](https://github.com/fhuberts) fixed `-Wswitch-enum` warnings.\n255. [Arseniy Terekhin](https://github.com/senyai) made the GDB pretty-printer robust against unset variable names.\n256. [Amir Masoud Abdol](https://github.com/amirmasoudabdol) updated the Homebrew command as nlohmann/json is now in homebrew-core.\n257. [Hallot](https://github.com/Hallot) fixed some `-Wextra-semi-stmt warnings`.\n258. [Giovanni Cerretani](https://github.com/gcerretani) fixed `-Wunused` warnings on `JSON_DIAGNOSTICS`.\n259. [Bogdan Popescu](https://github.com/Kapeli) hosts the [docset](https://github.com/Kapeli/Dash-User-Contributions/tree/master/docsets/JSON_for_Modern_C%2B%2B) for offline documentation viewers.\n260. [Carl Smedstad](https://github.com/carlsmedstad) fixed an assertion error when using `JSON_DIAGNOSTICS`.\n261. [miikka75](https://github.com/miikka75) provided an important fix to compile C++17 code with Clang 9.\n262. [Maarten Becker](https://github.com/kernie) fixed a warning for shadowed variables.\n263. [Cristi V√Æjdea](https://github.com/axnsan12) fixed typos in the `operator[]` documentation.\n264. [Alex Beregszaszi](https://github.com/axic) fixed spelling mistakes in comments.\n265. [Dirk Stolle](https://github.com/striezel) fixed typos in documentation.\n266. [Daniel Albuschat](https://github.com/daniel-kun) corrected the parameter name in the `parse` documentation.\n267. [Prince Mendiratta](https://github.com/Prince-Mendiratta) fixed a link to the FAQ.\n268. [Florian Albrechtskirchinger](https://github.com/falbrechtskirchinger) implemented `std::string_view` support for object keys and made dozens of other improvements.\n269. [Qianqian Fang](https://github.com/fangq) implemented the Binary JData (BJData) format.\n270. [pketelsen](https://github.com/pketelsen) added macros `NLOHMANN_DEFINE_TYPE_INTRUSIVE_WITH_DEFAULT` and `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE_WITH_DEFAULT`.\n271. [DarkZeros](https://github.com/DarkZeros) adjusted to code to not clash with Arduino defines.\n272. [flagarde](https://github.com/flagarde) fixed the output of `meta()` for MSVC.\n273. [Giovanni Cerretani](https://github.com/gcerretani) fixed a check for `std::filesystem`.\n274. [Dimitris Apostolou](https://github.com/rex4539) fixed a typo.\n275. [Ferry Huberts](https://github.com/fhuberts) fixed a typo.\n276. [Michael Nosthoff](https://github.com/heinemml) fixed a typo.\n277. [JungHoon Lee](https://github.com/jhnlee) fixed a typo.\n278. [Faruk D.](https://github.com/fdiblen) fixed the CITATION.CFF file.\n279. [Andrea Cocito](https://github.com/puffetto) added a clarification on macro usage to the documentation.\n280. [Krzysiek Karbowiak](https://github.com/kkarbowiak) refactored the tests to use `CHECK_THROWS_WITH_AS`.\n281. [Chaoqi Zhang](https://github.com/prncoprs) fixed a typo.\n282. [ivanovmp](https://github.com/ivanovmp) fixed a whitespace error.\n283. [KsaNL](https://github.com/KsaNL) fixed a build error when including `<windows.h>`.\n284. [Andrea Pappacoda](https://github.com/Tachi107) moved `.pc` and `.cmake` files to `share` directory.\n285. [Wolf Vollprecht](https://github.com/wolfv) added the `patch_inplace` function.\n286. [Jake Zimmerman](https://github.com/jez) highlighted common usage patterns in the README file.\n287. [NN](https://github.com/NN---) added the Visual Studio output directory to `.gitignore`.\n288. [Romain Reignier](https://github.com/romainreignier) improved the performance of the vector output adapter.\n289. [Mike](https://github.com/Mike-Leo-Smith) fixed the `std::iterator_traits`.\n290. [Richard Hoz√°k](https://github.com/zxey) added macro `JSON_NO_ENUM` to disable default enum conversions.\n291. [vakokako](https://github.com/vakokako) fixed tests when compiling with C++20.\n292. [Alexander ‚Äúweej‚Äù Jones](https://github.com/alexweej) fixed an example in the README.\n293. [Eli Schwartz](https://github.com/eli-schwartz) added more files to the `include.zip` archive.\n294. [Kevin Lu](https://github.com/kevinlul) fixed a compilation issue when typedefs with certain names were present.\n295. [Trevor Hickey](https://github.com/luxe) improved the description of an example.\n296. [Jef LeCompte](https://github.com/jef) updated the year in the README file.\n297. [Alexandre Hamez](https://github.com/ahamez) fixed a warning.\n298. [Maninderpal Badhan](https://github.com/mbadhan) fixed a typo.\n299. [kevin--](https://github.com/kevin--) added a note to an example in the README file.\n300. [I](https://github.com/wx257osn2) fixed a typo.\n301. [Gregorio Litenstein](https://github.com/Lord-Kamina) fixed the Clang detection.\n302. [Andreas Smas](https://github.com/andoma) added a Doozer badge.\n303. [WanCW](https://github.com/wancw) fixed the string conversion with Clang.\n304. [zhaohuaxishi](https://github.com/zhaohuaxishi) fixed a Doxygen error.\n305. [emvivre](https://github.com/emvivre) removed an invalid parameter from CMake.\n306. [Tobias Hermann](https://github.com/Dobiasd) fixed a link in the README file.\n307. [Michael](https://github.com/traits) fixed a warning.\n308. [Ryan Mulder](https://github.com/ryanjmulder) added `ensure_ascii` to the `dump` function.\n309. [Muri Nicanor](https://github.com/murinicanor) fixed the `sed` discovery in the Makefile.\n310. [David Avedissian](https://github.com/dgavedissian) implemented SFINAE-friendly `iterator_traits`.\n311. [AQNOUCH Mohammed](https://github.com/aqnouch) fixed a typo in the README.\n312. [Gareth Sylvester-Bradley](https://github.com/garethsb) added `operator/=` and `operator/` to construct JSON pointers.\n313. [Michael Macnair](https://github.com/mykter) added support for afl-fuzz testing.\n314. [Berkus Decker](https://github.com/berkus) fixed a typo in the README.\n315. [Illia Polishchuk](https://github.com/effolkronium) improved the CMake testing.\n316. [Ikko Ashimine](https://github.com/eltociear) fixed a typo.\n317. [Raphael Grimm](https://github.com/barcode) added the possibility to define a custom base class.\n318. [tocic](https://github.com/tocic) fixed typos in the documentation.\n319. [Vertexwahn](https://github.com/Vertexwahn) added Bazel build support.\n320. [Dirk Stolle](https://github.com/striezel) fixed typos in the documentation.\n321. [DavidKorczynski](https://github.com/DavidKorczynski) added a CIFuzz CI GitHub action.\n322. [Finkman](https://github.com/Finkman) fixed the debug pretty-printer.\n323. [Florian Segginger](https://github.com/floriansegginger) bumped the years in the README.\n324. [haadfida](https://github.com/haadfida) cleaned up the badges of used services.\n325. [Arsen Arsenoviƒá](https://github.com/ArsenArsen) fixed a build error.\n326. [theevilone45](https://github.com/theevilone45) fixed a typo in a CMake file.\n327. [Sergei Trofimovich](https://github.com/trofi) fixed the custom allocator support.\n328. [Joyce](https://github.com/joycebrum) fixed some security issues in the GitHub workflows.\n329. [Nicolas Jakob](https://github.com/njakob) add vcpkg version badge.\n330. [Tomerkm](https://github.com/Tomerkm) added tests.\n331. [No.](https://github.com/tusooa) fixed the use of `get<>` calls.\n332. [taro](https://github.com/tarolling) fixed a typo in the `CODEOWNERS` file.\n333. [Ikko Eltociear Ashimine](https://github.com/eltociear) fixed a typo.\n334. [Felix Yan](https://github.com/felixonmars) fixed a typo in the README.\n335. [HO-COOH](https://github.com/HO-COOH) fixed a parenthesis in the documentation.\n336. [Ivor Wanders](https://github.com/iwanders) fixed the examples to catch exception by `const&`.\n337. [miny1233](https://github.com/miny1233) fixed a parenthesis in the documentation.\n338. [tomalakgeretkal](https://github.com/tomalakgeretkal) fixed a compilation error.\n339. [alferov](https://github.com/ALF-ONE) fixed a compilation error.\n340. [Craig Scott](https://github.com/craigscott-crascit) fixed a deprecation warning in CMake.\n341. [Vyacheslav Zhdanovskiy](https://github.com/ZeronSix) added macros for serialization-only types.\n342. [Mathieu Westphal](https://github.com/mwestphal) fixed typos.\n343. [scribam](https://github.com/scribam) fixed the MinGW workflow.\n344. [Aleksei Sapitskii](https://github.com/aleksproger) added support for Apple's Swift Package Manager.\n345. [Benjamin Buch](https://github.com/bebuch) fixed the installation path in CMake.\n346. [Colby Haskell](https://github.com/colbychaskell) clarified the parse error message in case a file cannot be opened.\n347. [Juan Carlos Arevalo Baeza](https://github.com/TheJCAB) fixed the enum conversion.\n348. [alferov](https://github.com/ALF-ONE) fixed a version in the documentation.\n349. [ss](https://github.com/serge-s) fixed the amalgamation call.\n350. [AniketDhemare](https://github.com/AniketDhemare) fixed a version in the documentation.\n351. [Philip M√ºller](https://github.com/philip-paul-mueller) fixed an example.\n352. [Leila Shcheglova](https://github.com/LeilaShcheglova) fixed a warning in a test.\n353. [Alex Prabhat Bara](https://github.com/alexprabhat99) fixed a function name in the documentation.\n354. [laterlaugh](https://github.com/laterlaugh) fixed some typos.\n355. [Yuanhao Jia](https://github.com/MrJia1997) fixed the GDB pretty printer.\n356. [Fallen_Breath](https://github.com/Fallen-Breath) fixed an example for JSON Pointer.\n357. [Nikhil Idiculla](https://github.com/tsnl) fixed some typos.\n358. [Griffin Myers](https://github.com/gmyers18) updated the Natvis file.\n359. [thetimr](https://github.com/thetimr) fixed a typo in the documentation.\n360. [Balazs Erseki](https://github.com/zerocukor287) fixed a URL in the contribution guidelines.\n361. [Niccol√≤ Iardella](https://github.com/rotolof) added `NLOHMANN_DEFINE_DERIVED_TYPE_*` macros.\n362. [Borislav Stanimirov](https://github.com/iboB) allowed overriding the CMake target name.\n363. [Captain Crutches](https://github.com/captaincrutches) made `iterator_proxy_value` a `std::forward_iterator`.\n364. [Fredrik Sandhei](https://github.com/fsandhei) added type conversion support for `std::optional`.\n365. [jh96](https://github.com/jordan-hoang) added exceptions when `nullptr` is passed to `parse`.\n366. [Stuart Gorman](https://github.com/StuartGorman) fixed number parsing when `EINTR` set in `errno`.\n367. [Dylan Baker](https://github.com/dcbaker) generated a pkg-config file that follows the pkg-config conventions.\n368. [Tianyi Chen](https://github.com/TianyiChen) optimized the binary `get_number` implementation.\n369. [peng-wang-cn](https://github.com/peng-wang-cn) added type conversion support for multidimensional arrays.\n370. [Einars Netlis-Galejs](https://github.com/EinarsNG) added `ONLY_SERIALIZE` for `NLOHMANN_DEFINE_DERIVED_TYPE_*` macros.\n371. [Marcel](https://github.com/mering) removed `alwayslink=True` Bazel flag.\n372. [Harinath Nampally](https://github.com/hnampally) added diagnostic positions to exceptions.\n373. [Nissim Armand Ben Danan](https://github.com/NissimBendanan) fixed `NLOHMANN_DEFINE_TYPE_INTRUSIVE_WITH_DEFAULT` with an empty JSON instance.\n374. [Michael Valladolid](https://github.com/codenut) added support for BSON uint64 serialization/deserialization.\n375. [Nikhil](https://github.com/nikhilreddydev) updated the documentation.\n376. [Neboj≈°a Cvetkoviƒá](https://github.com/nebkat) added support for BJDATA optimized binary array type.\n377. [Sushrut Shringarputale](https://github.com/sushshring) added support for diagnostic positions. \n378. [kimci86](https://github.com/kimci86) templated to `NLOHMANN_DEFINE_TYPE` macros to also support `ordered_json`.\n379. [Richard Topchii](https://github.com/richardtop) added support for VisionOS in the Swift Package Manager.\n380. [Robert Chisholm](https://github.com/Robadob) fixed a typo.\n381. [zjyhjqs](https://github.com/zjyhjqs) added CPack support.\n382. [bitFiedler](https://github.com/bitFiedler) made GDB pretty printer work with Python 3.8.\n383. [Gianfranco Costamagna](https://github.com/LocutusOfBorg) fixed a compiler warning.\n384. [risa2000](https://github.com/risa2000) made `std::filesystem::path` conversion to/from UTF-8 encoded string explicit.\n\nThanks a lot for helping out! Please [let me know](mailto:mail@nlohmann.me) if I forgot someone.\n\n## Used third-party tools\n\nThe library itself consists of a single header file licensed under the MIT license. However, it is built, tested, documented, and whatnot using a lot of third-party tools and services. Thanks a lot!\n\n- [**amalgamate.py - Amalgamate C source and header files**](https://github.com/edlund/amalgamate) to create a single header file\n- [**American fuzzy lop**](https://lcamtuf.coredump.cx/afl/) for fuzz testing\n- [**AppVeyor**](https://www.appveyor.com) for [continuous integration](https://ci.appveyor.com/project/nlohmann/json) on Windows\n- [**Artistic Style**](http://astyle.sourceforge.net) for automatic source code indentation\n- [**Clang**](https://clang.llvm.org) for compilation with code sanitizers\n- [**CMake**](https://cmake.org) for build automation\n- [**Codacy**](https://www.codacy.com) for further [code analysis](https://app.codacy.com/gh/nlohmann/json/dashboard)\n- [**Coveralls**](https://coveralls.io) to measure [code coverage](https://coveralls.io/github/nlohmann/json)\n- [**Coverity Scan**](https://scan.coverity.com) for [static analysis](https://scan.coverity.com/projects/nlohmann-json)\n- [**cppcheck**](http://cppcheck.sourceforge.net) for static analysis\n- [**doctest**](https://github.com/onqtam/doctest) for the unit tests\n- [**GitHub Changelog Generator**](https://github.com/skywinder/github-changelog-generator) to generate the [ChangeLog](https://github.com/nlohmann/json/blob/develop/ChangeLog.md)\n- [**Google Benchmark**](https://github.com/google/benchmark) to implement the benchmarks\n- [**Hedley**](https://nemequ.github.io/hedley/) to avoid re-inventing several compiler-agnostic feature macros\n- [**lcov**](https://github.com/linux-test-project/lcov) to process coverage information and create an HTML view\n- [**libFuzzer**](https://llvm.org/docs/LibFuzzer.html) to implement fuzz testing for OSS-Fuzz\n- [**Material for MkDocs**](https://squidfunk.github.io/mkdocs-material/) for the style of the documentation site\n- [**MkDocs**](https://www.mkdocs.org) for the documentation site\n- [**OSS-Fuzz**](https://github.com/google/oss-fuzz) for continuous fuzz testing of the library ([project repository](https://github.com/google/oss-fuzz/tree/master/projects/json))\n- [**Probot**](https://probot.github.io) for automating maintainer tasks such as closing stale issues, requesting missing information, or detecting toxic comments.\n- [**Valgrind**](https://valgrind.org) to check for correct memory management\n\n## Notes\n\n### Character encoding\n\nThe library supports **Unicode input** as follows:\n\n- Only **UTF-8** encoded input is supported, which is the default encoding for JSON according to [RFC 8259](https://tools.ietf.org/html/rfc8259.html#section-8.1).\n- `std::u16string` and `std::u32string` can be parsed, assuming UTF-16 and UTF-32 encoding, respectively. These encodings are not supported when reading from files or other input containers.\n- Other encodings such as Latin-1 or ISO 8859-1 are **not** supported and will yield parse or serialization errors.\n- [Unicode noncharacters](https://www.unicode.org/faq/private_use.html#nonchar1) will not be replaced by the library.\n- Invalid surrogates (e.g., incomplete pairs such as `\\uDEAD`) will yield parse errors.\n- The strings stored in the library are UTF-8 encoded. When using the default string type (`std::string`), note that its length/size functions return the number of stored bytes rather than the number of characters or glyphs.\n- When you store strings with different encodings in the library, calling [`dump()`](https://json.nlohmann.me/api/basic_json/dump/) may throw an exception unless `json::error_handler_t::replace` or `json::error_handler_t::ignore` are used as error handlers.\n- To store wide strings (e.g., `std::wstring`), you need to convert them to a UTF-8 encoded `std::string` before, see [an example](https://json.nlohmann.me/home/faq/#wide-string-handling).\n\n### Comments in JSON\n\nThis library does not support comments by default. It does so for three reasons:\n\n1. Comments are not part of the [JSON specification](https://tools.ietf.org/html/rfc8259). You may argue that `//` or `/* */` are allowed in JavaScript, but JSON is not JavaScript.\n2. This was not an oversight: Douglas Crockford [wrote on this](https://plus.google.com/118095276221607585885/posts/RK8qyGVaGSr) in May 2012:\n  \n    > I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability.  I know that the lack of comments makes some people sad, but it shouldn't.\n    >\n    > Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.\n  \n3. It is dangerous for interoperability if some libraries would add comment support while others don't. Please check [The Harmful Consequences of the Robustness Principle](https://tools.ietf.org/html/draft-iab-protocol-maintenance-01) on this.\n\nHowever, you can set set parameter `ignore_comments` to true in the `parse` function to ignore `//` or `/* */` comments. Comments will then be treated as whitespace.\n\n### Trailing commas\n\nThe JSON specification does not allow trailing commas in arrays and objects, and hence this library is treating them as parsing errors by default.\n\nLike comments, you can set parameter `ignore_trailing_commas` to true in the `parse` function to ignore trailing commas in arrays and objects. Note that a single comma as the only content of the array or object (`[,]` or `{,}`) is not allowed, and multiple trailing commas (`[1,,]`) are not allowed either.\n\nThis library does not add trailing commas when serializing JSON data.\n\nFor more information, see [JSON With Commas and Comments (JWCC)](https://nigeltao.github.io/blog/2021/json-with-commas-comments.html).\n\n### Order of object keys\n\nBy default, the library does not preserve the **insertion order of object elements**. This is standards-compliant, as the [JSON standard](https://tools.ietf.org/html/rfc8259.html) defines objects as \"an unordered collection of zero or more name/value pairs\".\n\nIf you do want to preserve the insertion order, you can try the type [`nlohmann::ordered_json`](https://github.com/nlohmann/json/issues/2179). Alternatively, you can use a more sophisticated ordered map like [`tsl::ordered_map`](https://github.com/Tessil/ordered-map) ([integration](https://github.com/nlohmann/json/issues/546#issuecomment-304447518)) or [`nlohmann::fifo_map`](https://github.com/nlohmann/fifo_map) ([integration](https://github.com/nlohmann/json/issues/485#issuecomment-333652309)).\n\nSee the [**documentation on object order**](https://json.nlohmann.me/features/object_order/) for more information.\n\n### Memory Release\n\nWe checked with Valgrind and the Address Sanitizer (ASAN) that there are no memory leaks.\n\nIf you find that a parsing program with this library does not release memory, please consider the following case, and it may be unrelated to this library.\n\n**Your program is compiled with glibc.** There is a tunable threshold that glibc uses to decide whether to actually return memory to the system or whether to cache it for later reuse. If in your program you make lots of small allocations and those small allocations are not a contiguous block and are presumably below the threshold, then they will not get returned to the OS.\nHere is a related issue [#1924](https://github.com/nlohmann/json/issues/1924).\n\n### Further notes\n\n- The code contains numerous debug **assertions** which can be switched off by defining the preprocessor macro `NDEBUG`, see the [documentation of `assert`](https://en.cppreference.com/w/cpp/error/assert). In particular, note [`operator[]`](https://json.nlohmann.me/api/basic_json/operator%5B%5D/) implements **unchecked access** for const objects: If the given key is not present, the behavior is undefined (think of a dereferenced null pointer) and yields an [assertion failure](https://github.com/nlohmann/json/issues/289) if assertions are switched on. If you are not sure whether an element in an object exists, use checked access with the [`at()` function](https://json.nlohmann.me/api/basic_json/at/). Furthermore, you can define `JSON_ASSERT(x)` to replace calls to `assert(x)`. See the [**documentation on runtime assertions**](https://json.nlohmann.me/features/assertions/) for more information.\n- As the exact number type is not defined in the [JSON specification](https://tools.ietf.org/html/rfc8259.html), this library tries to choose the best fitting C++ number type automatically. As a result, the type `double` may be used to store numbers which may yield [**floating-point exceptions**](https://github.com/nlohmann/json/issues/181) in certain rare situations if floating-point exceptions have been unmasked in the calling code. These exceptions are not caused by the library and need to be fixed in the calling code, such as by re-masking the exceptions prior to calling library functions.\n- The code can be compiled without C++ **runtime type identification** features; that is, you can use the `-fno-rtti` compiler flag.\n- **Exceptions** are used widely within the library. They can, however, be switched off with either using the compiler flag `-fno-exceptions` or by defining the symbol `JSON_NOEXCEPTION`. In this case, exceptions are replaced by `abort()` calls. You can further control this behavior by defining `JSON_THROW_USER` (overriding `throw`), `JSON_TRY_USER` (overriding `try`), and `JSON_CATCH_USER` (overriding `catch`). Note that `JSON_THROW_USER` should leave the current scope (e.g., by throwing or aborting), as continuing after it may yield undefined behavior. Note the explanatory [`what()`](https://en.cppreference.com/w/cpp/error/exception/what) string of exceptions is not available for MSVC if exceptions are disabled, see [#2824](https://github.com/nlohmann/json/discussions/2824). See the [**documentation of exceptions**](https://json.nlohmann.me/home/exceptions/) for more information.\n\n## Execute unit tests\n\nTo compile and run the tests, you need to execute\n\n```shell\nmkdir build\ncd build\ncmake .. -DJSON_BuildTests=On\ncmake --build .\nctest --output-on-failure\n```\n\nNote that during the `ctest` stage, several JSON test files are downloaded from an [external repository](https://github.com/nlohmann/json_test_data). If policies forbid downloading artifacts during testing, you can download the files yourself and pass the directory with the test files via `-DJSON_TestDataDirectory=path` to CMake. Then, no Internet connectivity is required. See [issue #2189](https://github.com/nlohmann/json/issues/2189) for more information.\n\nIf the testdata is not found, several test suites will fail like this:\n\n```\n===============================================================================\njson/tests/src/make_test_data_available.hpp:21:\nTEST CASE:  check test suite is downloaded\n\njson/tests/src/make_test_data_available.hpp:23: FATAL ERROR: REQUIRE( utils::check_testsuite_downloaded() ) is NOT correct!\n  values: REQUIRE( false )\n  logged: Test data not found in 'json/cmake-build-debug/json_test_data'.\n          Please execute target 'download_test_data' before running this test suite.\n          See <https://github.com/nlohmann/json#execute-unit-tests> for more information.\n\n===============================================================================\n```\n\nIn case you have downloaded the library rather than checked out the code via Git, test `cmake_fetch_content_configure` will fail. Please execute `ctest -LE git_required` to skip these tests. See [issue #2189](https://github.com/nlohmann/json/issues/2189) for more information.\n\nSome tests are requiring network to be properly execute. They are labeled as `git_required`. Please execute `ctest -LE git_required` to skip these tests. See [issue #4851](https://github.com/nlohmann/json/issues/4851) for more information.\n\nSome tests change the installed files and hence make the whole process not reproducible. Please execute `ctest -LE not_reproducible` to skip these tests. See [issue #2324](https://github.com/nlohmann/json/issues/2324) for more information. Furthermore, assertions must be switched off to ensure reproducible builds (see [discussion 4494](https://github.com/nlohmann/json/discussions/4494)).\n\nNote you need to call `cmake -LE \"not_reproducible|git_required\"` to exclude both labels. See [issue #2596](https://github.com/nlohmann/json/issues/2596) for more information.\n\nAs Intel compilers use unsafe floating point optimization by default, the unit tests may fail. Use flag [`/fp:precise`](https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/2021-8/fp-model-fp.html) then.\n",
      "stars_today": 22
    },
    {
      "id": 60246359,
      "name": "ClickHouse",
      "full_name": "ClickHouse/ClickHouse",
      "description": "ClickHouse¬Æ is a real-time analytics database management system",
      "html_url": "https://github.com/ClickHouse/ClickHouse",
      "stars": 45231,
      "forks": 7983,
      "language": "C++",
      "topics": [
        "ai",
        "analytics",
        "big-data",
        "clickhouse",
        "cloud-native",
        "cpp",
        "database",
        "dbms",
        "distributed",
        "embedded",
        "hacktoberfest",
        "lakehouse",
        "mpp",
        "olap",
        "rust",
        "self-hosted",
        "sql"
      ],
      "created_at": "2016-06-02T08:28:18Z",
      "updated_at": "2026-01-17T01:01:12Z",
      "pushed_at": "2026-01-17T00:42:55Z",
      "open_issues": 5629,
      "owner": {
        "login": "ClickHouse",
        "avatar_url": "https://avatars.githubusercontent.com/u/54801242?v=4"
      },
      "readme": "<div align=center>\n\n[![Website](https://img.shields.io/website?up_message=AVAILABLE&down_message=DOWN&url=https%3A%2F%2Fclickhouse.com&style=for-the-badge)](https://clickhouse.com)\n[![Apache 2.0 License](https://img.shields.io/badge/license-Apache%202.0-blueviolet?style=for-the-badge)](https://www.apache.org/licenses/LICENSE-2.0)\n\n<picture align=center>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/ClickHouse/clickhouse-docs/assets/9611008/4ef9c104-2d3f-4646-b186-507358d2fe28\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/ClickHouse/clickhouse-docs/assets/9611008/b001dc7b-5a45-4dcd-9275-e03beb7f9177\">\n    <img alt=\"The ClickHouse company logo.\" src=\"https://github.com/ClickHouse/clickhouse-docs/assets/9611008/b001dc7b-5a45-4dcd-9275-e03beb7f9177\">\n</picture>\n\n<h4>ClickHouse¬Æ is an open-source column-oriented database management system that allows generating analytical data reports in real-time.</h4>\n\n</div>\n\n## How To Install (Linux, macOS, FreeBSD)\n\n```\ncurl https://clickhouse.com/ | sh\n```\n\n## Useful Links\n\n* [Official website](https://clickhouse.com/) has a quick high-level overview of ClickHouse on the main page.\n* [ClickHouse Cloud](https://clickhouse.cloud) ClickHouse as a service, built by the creators and maintainers.\n* [Tutorial](https://clickhouse.com/docs/getting_started/tutorial/) shows how to set up and query a small ClickHouse cluster.\n* [Documentation](https://clickhouse.com/docs/) provides more in-depth information.\n* [YouTube channel](https://www.youtube.com/c/ClickHouseDB) has a lot of content about ClickHouse in video format.\n* [ClickHouse Theater](https://presentations.clickhouse.com/) contains presentations and videos about ClickHouse.\n* [Slack](https://clickhouse.com/slack) and [Telegram](https://telegram.me/clickhouse_en) allow chatting with ClickHouse users in real-time.\n* [Blog](https://clickhouse.com/blog/) contains various ClickHouse-related articles, as well as announcements and reports about events.\n* [Bluesky](https://bsky.app/profile/clickhouse.com) and [X](https://x.com/ClickHouseDB) for short news.\n* [Code Browser (github.dev)](https://github.dev/ClickHouse/ClickHouse) with syntax highlighting, powered by github.dev.\n* [Contacts](https://clickhouse.com/company/contact) can help to get your questions answered if there are any.\n\n## Monthly Release & Community Call\n\nClickHouse release 25.12, 2025-12-18. [Presentation](https://presentations.clickhouse.com/2025-release-25.12/), [Video](https://www.youtube.com/watch?v=UdxLygnjsRY)\n\nWatch all release presentations and videos at [ClickHouse Theater](https://presentations.clickhouse.com/) and [YouTube Playlist](https://www.youtube.com/playlist?list=PL0Z2YDlm0b3jAlSy1JxyP8zluvXaN3nxU).\n\n## Upcoming Events\n\nKeep an eye out for upcoming meetups and events around the world.\nSomewhere else you want us to be?\nPlease feel free to reach out to tyler `<at>` clickhouse `<dot>` com.\nYou can also peruse [ClickHouse Events](https://clickhouse.com/company/news-events) for a list of all upcoming trainings, meetups, speaking engagements, etc.\n\nUpcoming meetups\n* [Iceberg Meetup Menlo Park](https://luma.com/abggijbh) - January 21st, 2026\n* [Data & AI Paris Meetup](https://luma.com/3szhmv9h) - January 22nd, 2026\n* [Iceberg Meetup New York](https://luma.com/ifxnj82q) - January 23rd, 2026\n* [New York Meetup](https://luma.com/iicnlq41) - January 26th, 2026\n* [Singapore Meetup](https://www.meetup.com/clickhouse-singapore-meetup-group/events/312801791/) - January 27th, 2026\n* [ClickHouse France Meetup](https://www.meetup.com/clickhouse-france-user-group/events/312295018/) - January 28th, 2026\n* [Seoul Meetup](https://www.meetup.com/clickhouse-seoul-user-group/events/312679894/) - January 29th, 2026\n* [Iceberg Meetup Brussels](https://luma.com/yx3lhqu9) - January 30th, 2026\n* [ClickHouse Dinner at FOSDEM](https://luma.com/czvs584m) - January 31st, 2026\n* [ClickHouse Barcelona Meetup](https://www.meetup.com/clickhouse-barcelona-user-group/events/312714616/) - February 5th, 2026\n* [ClickHouse London Meetup](https://www.meetup.com/clickhouse-london-user-group/events/312314505/) - February 10th, 2026\n* [AI Night San Francisco](https://luma.com/j2ck1sbz)- February 11th, 2026\n* [Toronto Meetup](https://luma.com/8p8unbnw) - February 19th, 2026\n* [Seattle Meetup](https://luma.com/jsctpwoa) - February 26th, 2026\n* [LA Meetup](https://luma.com/wbkqmaqk) - March 6th, 2026\n\nRecent meetups\n* [Gurgaon/Delhi Meetup](https://www.meetup.com/clickhouse-delhi-user-group/events/312621832/) - January 10th, 2026\n* [Tel Aviv Meetup](https://www.meetup.com/clickhouse-meetup-israel/events/311868191) - December 29, 2025\n* [Tokyo Meetup](https://www.meetup.com/clickhouse-tokyo-user-group/events/311974739/) - December 15, 2025\n* [Jakarta Meetup](https://www.meetup.com/clickhouse-indonesia-user-group/events/311988089/) - December 9, 2025\n* [San Francisco Meetup](https://www.meetup.com/clickhouse-silicon-valley-meetup-group/events/312075592) - December 8, 2025\n* [New York Meetup](https://www.meetup.com/clickhouse-new-york-user-group/events/312080179/) - December 8, 2025\n\n\n\n## Recent Recordings\n\n* **Recent Meetup Videos**: [Meetup Playlist](https://www.youtube.com/playlist?list=PL0Z2YDlm0b3iNDUzpY1S3L_iV4nARda_U) Whenever possible recordings of the ClickHouse Community Meetups are edited and presented as individual talks. \n\n## Interested in joining ClickHouse and making it your full-time job?\n\nClickHouse is a nice DBMS, and it's a good place to work.\n\nCheck out our **current openings** here: https://clickhouse.com/company/careers\n\nEmail: careers@clickhouse.com!\n",
      "stars_today": 22
    },
    {
      "id": 709589487,
      "name": "awesome-system-design-resources",
      "full_name": "ashishps1/awesome-system-design-resources",
      "description": "Learn System Design concepts and prepare for interviews using free resources.",
      "html_url": "https://github.com/ashishps1/awesome-system-design-resources",
      "stars": 29064,
      "forks": 6659,
      "language": "Java",
      "topics": [
        "awesome",
        "backend",
        "computer-science",
        "distributed-systems",
        "high-level-design",
        "hld",
        "interview",
        "interview-questions",
        "scalability",
        "system-design"
      ],
      "created_at": "2023-10-25T01:50:42Z",
      "updated_at": "2026-01-16T23:42:51Z",
      "pushed_at": "2026-01-11T14:54:34Z",
      "open_issues": 7,
      "owner": {
        "login": "ashishps1",
        "avatar_url": "https://avatars.githubusercontent.com/u/8646889?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"diagrams/system-design-github-logo.png\" width=\"350\" height=\"200\">\n</p>\n\nThis repository contains free resources to learn System Design concepts and prepare for interviews.\n\nüëâ Subscribe to my [AlgoMaster Newsletter](https://bit.ly/amghsd) and get a **FREE System Design Interview Handbook** in your inbox.\n\n‚úÖ If you are new to System Design, start here: [System Design was HARD until I Learned these 30 Concepts](https://blog.algomaster.io/p/30-system-design-concepts)\n\n## ‚öôÔ∏è Core Concepts\n- [Scalability](https://algomaster.io/learn/system-design/scalability)\n- [Availability](https://algomaster.io/learn/system-design/availability)\n- [Reliability](https://algomaster.io/learn/system-design/reliability)\n- [CAP Theorem](https://blog.algomaster.io/p/cap-theorem-explained)\n- [Consistent Hashing](https://blog.algomaster.io/p/consistent-hashing-explained)\n- [SPOF](https://blog.algomaster.io/p/system-design-how-to-avoid-single-point-of-failures)\n- [Failover](https://www.druva.com/glossary/what-is-a-failover-definition-and-related-faqs)\n- [Fault Tolerance](https://www.cockroachlabs.com/blog/what-is-fault-tolerance/)\n\n## üåê Networking Fundamentals\n- [OSI Model](https://algomaster.io/learn/system-design/osi)\n- [IP Addresses](https://algomaster.io/learn/system-design/ip-address)\n- [Domain Name System (DNS)](https://blog.algomaster.io/p/how-dns-actually-works)\n- [Proxy vs Reverse Proxy](https://blog.algomaster.io/p/proxy-vs-reverse-proxy-explained)\n- [HTTP/HTTPS](https://algomaster.io/learn/system-design/http-https)\n- [TCP vs UDP](https://algomaster.io/learn/system-design/tcp-vs-udp)\n- [Load Balancing](https://blog.algomaster.io/p/load-balancing-algorithms-explained-with-code)\n- [Checksums](https://algomaster.io/learn/system-design/checksums)\n\n## üîå API Fundamentals\n- [APIs](https://algomaster.io/learn/system-design/what-is-an-api)\n- [API Gateway](https://blog.algomaster.io/p/what-is-an-api-gateway)\n- [REST vs GraphQL](https://blog.algomaster.io/p/rest-vs-graphql)\n- [WebSockets](https://blog.algomaster.io/p/websockets)\n- [Webhooks](https://algomaster.io/learn/system-design/webhooks)\n- [Idempotency](https://algomaster.io/learn/system-design/idempotency)\n- [Rate limiting](https://blog.algomaster.io/p/rate-limiting-algorithms-explained-with-code)\n- [API Design](https://abdulrwahab.medium.com/api-architecture-best-practices-for-designing-rest-apis-bf907025f5f)\n\n## üóÑÔ∏è Database Fundamentals\n- [ACID Transactions](https://algomaster.io/learn/system-design/acid-transactions)\n- [SQL vs NoSQL](https://algomaster.io/learn/system-design/sql-vs-nosql)\n- [Database Indexes](https://algomaster.io/learn/system-design/indexing)\n- [Database Sharding](https://algomaster.io/learn/system-design/sharding)\n- [Data Replication](https://redis.com/blog/what-is-data-replication/)\n- [Database Scaling](https://blog.algomaster.io/p/system-design-how-to-scale-a-database)\n- [Databases Types](https://blog.algomaster.io/p/15-types-of-databases)\n- [Bloom Filters](https://algomaster.io/learn/system-design/bloom-filters)\n- [Database Architectures](https://www.mongodb.com/developer/products/mongodb/active-active-application-architectures/)\n\n## ‚ö° Caching Fundamentals\n- [Caching 101](https://algomaster.io/learn/system-design/what-is-caching)\n- [Caching Strategies](https://algomaster.io/learn/system-design/caching-strategies)\n- [Cache Eviction Policies](https://blog.algomaster.io/p/7-cache-eviction-strategies)\n- [Distributed Caching](https://blog.algomaster.io/p/distributed-caching)\n- [Content Delivery Network (CDN)](https://algomaster.io/learn/system-design/content-delivery-network-cdn)\n\n## üîÑ Asynchronous Communication\n- [Pub/Sub](https://algomaster.io/learn/system-design/pub-sub)\n- [Message Queues](https://algomaster.io/learn/system-design/message-queues)\n- [Change Data Capture (CDC)](https://algomaster.io/learn/system-design/change-data-capture-cdc)\n\n## üß© Distributed System and Microservices\n- [HeartBeats](https://blog.algomaster.io/p/heartbeats-in-distributed-systems)\n- [Service Discovery](https://blog.algomaster.io/p/service-discovery-in-distributed-systems)\n- [Consensus Algorithms](https://medium.com/@sourabhatta1819/consensus-in-distributed-system-ac79f8ba2b8c)\n- [Distributed Locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)\n- [Microservices Guidelines](https://newsletter.systemdesign.one/p/netflix-microservices) \n- [Gossip Protocol](http://highscalability.com/blog/2023/7/16/gossip-protocol-explained.html)\n- [Circuit Breaker](https://medium.com/geekculture/design-patterns-for-microservices-circuit-breaker-pattern-276249ffab33)\n- [Disaster Recovery](https://cloud.google.com/learn/what-is-disaster-recovery)\n- [Distributed Tracing](https://www.dynatrace.com/news/blog/what-is-distributed-tracing/)\n\n## üñáÔ∏è Architectural Patterns\n- [Client-Server Architecture](https://algomaster.io/learn/system-design/client-server-architecture)\n- [Microservices Architecture](https://medium.com/hashmapinc/the-what-why-and-how-of-a-microservices-architecture-4179579423a9)\n- [Serverless Architecture](https://blog.algomaster.io/p/2edeb23b-cfa5-4b24-845e-3f6f7a39d162)\n- [Event-Driven Architecture](https://www.confluent.io/learn/event-driven-architecture/)\n- [Peer-to-Peer (P2P) Architecture](https://www.spiceworks.com/tech/networking/articles/what-is-peer-to-peer/)\n\n## ‚öñÔ∏è System Design Tradeoffs\n- [Top 15 Tradeoffs](https://blog.algomaster.io/p/system-design-top-15-trade-offs)\n- [Vertical vs Horizontal Scaling](https://algomaster.io/learn/system-design/vertical-vs-horizontal-scaling)\n- [Concurrency vs Parallelism](https://blog.algomaster.io/p/concurrency-vs-parallelism)\n- [Long Polling vs WebSockets](https://blog.algomaster.io/p/long-polling-vs-websockets)\n- [Batch vs Stream Processing](https://blog.algomaster.io/p/batch-processing-vs-stream-processing)\n- [Stateful vs Stateless Design](https://blog.algomaster.io/p/stateful-vs-stateless-architecture)\n- [Strong vs Eventual Consistency](https://blog.algomaster.io/p/strong-vs-eventual-consistency)\n- [Read-Through vs Write-Through Cache](https://blog.algomaster.io/p/59cae60d-9717-4e20-a59e-759e370db4e5)\n- [Push vs Pull Architecture](https://blog.algomaster.io/p/af5fe2fe-9a4f-4708-af43-184945a243af)\n- [REST vs RPC](https://blog.algomaster.io/p/106604fb-b746-41de-88fb-60e932b2ff68)\n- [Synchronous vs. asynchronous communications](https://blog.algomaster.io/p/aec1cebf-6060-45a7-8e00-47364ca70761)\n- [Latency vs Throughput](https://aws.amazon.com/compare/the-difference-between-throughput-and-latency/)\n\n## ‚úÖ [How to Answer a System Design Interview Problem](https://algomaster.io/learn/system-design-interviews/answering-framework)\n\n## üíª System Design Interview Problems\n### Easy\n- [Design URL Shortener like TinyURL](https://algomaster.io/learn/system-design-interviews/design-url-shortener)\n- [Design Autocomplete for Search Engines](https://algomaster.io/learn/system-design-interviews/design-instagram)\n- [Design Load Balancer](https://algomaster.io/learn/system-design-interviews/design-load-balancer)\n- [Design Content Delivery Network (CDN)](https://www.youtube.com/watch?v=8zX0rue2Hic)\n- [Design Parking Garage](https://www.youtube.com/watch?v=NtMvNh0WFVM)\n- [Design Vending Machine](https://www.youtube.com/watch?v=D0kDMUgo27c)\n- [Design Distributed Key-Value Store](https://www.youtube.com/watch?v=rnZmdmlR-2M)\n- [Design Distributed Cache](https://www.youtube.com/watch?v=iuqZvajTOyA)\n- [Design Authentication System](https://www.youtube.com/watch?v=uj_4vxm9u90)\n- [Design Unified Payments Interface (UPI)](https://www.youtube.com/watch?v=QpLy0_c_RXk)\n### Medium\n- [Design WhatsApp](https://algomaster.io/learn/system-design-interviews/design-whatsapp)\n- [Design Spotify](https://algomaster.io/learn/system-design-interviews/design-spotify)\n- [Design Instagram](https://algomaster.io/learn/system-design-interviews/design-instagram)\n- [Design Notification Service](https://algomaster.io/learn/system-design-interviews/design-notification-service)\n- [Design Distributed Job Scheduler](https://blog.algomaster.io/p/design-a-distributed-job-scheduler)\n- [Design Tinder](https://www.youtube.com/watch?v=tndzLznxq40)\n- [Design Facebook](https://www.youtube.com/watch?v=9-hjBGxuiEs)\n- [Design Twitter](https://www.youtube.com/watch?v=wYk0xPP_P_8)\n- [Design Reddit](https://www.youtube.com/watch?v=KYExYE_9nIY)\n- [Design Netflix](https://www.youtube.com/watch?v=psQzyFfsUGU)\n- [Design Youtube](https://www.youtube.com/watch?v=jPKTo1iGQiE)\n- [Design Google Search](https://www.youtube.com/watch?v=CeGtqouT8eA)\n- [Design E-commerce Store like Amazon](https://www.youtube.com/watch?v=EpASu_1dUdE)\n- [Design TikTok](https://www.youtube.com/watch?v=Z-0g_aJL5Fw)\n- [Design Shopify](https://www.youtube.com/watch?v=lEL4F_0J3l8)\n- [Design Airbnb](https://www.youtube.com/watch?v=YyOXt2MEkv4)\n- [Design Rate Limiter](https://www.youtube.com/watch?v=mhUQe4BKZXs)\n- [Design Distributed Message Queue like Kafka](https://www.youtube.com/watch?v=iJLL-KPqBpM)\n- [Design Flight Booking System](https://www.youtube.com/watch?v=qsGcfVGvFSs)\n- [Design Online Code Editor](https://www.youtube.com/watch?v=07jkn4jUtso)\n- [Design an Analytics Platform (Metrics & Logging)](https://www.youtube.com/watch?v=kIcq1_pBQSY)\n- [Design Payment System](https://www.youtube.com/watch?v=olfaBgJrUBI)\n- [Design a Digital Wallet](https://www.youtube.com/watch?v=4ijjIUeq6hE)\n### Hard\n- [Design Location Based Service like Yelp](https://www.youtube.com/watch?v=M4lR_Va97cQ)\n- [Design Uber](https://www.youtube.com/watch?v=umWABit-wbk)\n- [Design Food Delivery App like Doordash](https://www.youtube.com/watch?v=iRhSAR3ldTw)\n- [Design Google Docs](https://www.youtube.com/watch?v=2auwirNBvGg)\n- [Design Google Maps](https://www.youtube.com/watch?v=jk3yvVfNvds)\n- [Design Zoom](https://www.youtube.com/watch?v=G32ThJakeHk)\n- [Design Distributed Counter](https://systemdesign.one/distributed-counter-system-design/)\n- [Design File Sharing System like Dropbox](https://www.youtube.com/watch?v=U0xTu6E2CT8)\n- [Design Ticket Booking System like BookMyShow](https://www.youtube.com/watch?v=lBAwJgoO3Ek)\n- [Design Distributed Web Crawler](https://www.youtube.com/watch?v=BKZxZwUgL3Y)\n- [Design Code Deployment System](https://www.youtube.com/watch?v=q0KGYwNbf-0)\n- [Design Distributed Cloud Storage like S3](https://www.youtube.com/watch?v=UmWtcgC96X8)\n- [Design Distributed Locking Service](https://www.youtube.com/watch?v=v7x75aN9liM)\n- [Design Slack](https://systemdesign.one/slack-architecture/)\n- [Design Live Comments](https://systemdesign.one/live-comment-system-design/)\n\n## üìá Courses\n- [System Design Fundamentals](https://algomaster.io/learn/system-design/course-introduction)\n- [System Design Interviews](https://algomaster.io/learn/system-design-interviews/introduction)\n\n## üì© Newsletters\n- [AlgoMaster Newsletter](https://blog.algomaster.io/)\n\n## üìö Books\n- [Designing Data-Intensive Applications](https://www.amazon.in/dp/9352135245)\n\n## üì∫ YouTube Channels\n- [Tech Dummies Narendra L](https://www.youtube.com/@TechDummiesNarendraL)\n- [Gaurav Sen](https://www.youtube.com/@gkcs)\n- [codeKarle](https://www.youtube.com/@codeKarle)\n- [ByteByteGo](https://www.youtube.com/@ByteByteGo)\n- [System Design Interview](https://www.youtube.com/@SystemDesignInterview)\n- [sudoCODE](https://www.youtube.com/@sudocode)\n- [Success in Tech](https://www.youtube.com/@SuccessinTech/videos)\n\n## üìú Must-Read Engineering Articles\n- [How Discord stores trillions of messages](https://discord.com/blog/how-discord-stores-trillions-of-messages)\n- [Building In-Video Search at Netflix](https://netflixtechblog.com/building-in-video-search-936766f0017c)\n- [How Canva scaled Media uploads from Zero to 50 Million per Day](https://www.canva.dev/blog/engineering/from-zero-to-50-million-uploads-per-day-scaling-media-at-canva/)\n- [How Airbnb avoids double payments in a Distributed Payments System](https://medium.com/airbnb-engineering/avoiding-double-payments-in-a-distributed-payments-system-2981f6b070bb)\n- [Stripe‚Äôs payments APIs - The first 10 years](https://stripe.com/blog/payment-api-design)\n- [Real time messaging at Slack](https://slack.engineering/real-time-messaging/)\n\n## üóûÔ∏è Must-Read Distributed Systems Papers\n- [Paxos: The Part-Time Parliament](https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf)\n- [MapReduce: Simplified Data Processing on Large Clusters](https://research.google.com/archive/mapreduce-osdi04.pdf)\n- [The Google File System](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf)\n- [Dynamo: Amazon‚Äôs Highly Available Key-value Store](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)\n- [Kafka: a Distributed Messaging System for Log Processing](https://notes.stephenholiday.com/Kafka.pdf)\n- [Spanner: Google‚Äôs Globally-Distributed Database](https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf)\n- [Bigtable: A Distributed Storage System for Structured Data](https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf)\n- [ZooKeeper: Wait-free coordination for Internet-scale systems](https://www.usenix.org/legacy/event/usenix10/tech/full_papers/Hunt.pdf)\n- [The Log-Structured Merge-Tree (LSM-Tree)](https://www.cs.umb.edu/~poneil/lsmtree.pdf)\n- [The Chubby lock service for loosely-coupled distributed systems](https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf)\n\n---\n\n<p align=\"center\">\n  <i>If you find this resource helpful, please give it a star ‚≠êÔ∏è and share it with others!</i>\n</p>\n",
      "stars_today": 22
    },
    {
      "id": 850267588,
      "name": "xiaozhi-esp32",
      "full_name": "78/xiaozhi-esp32",
      "description": "An MCP-based chatbot | ‰∏Ä‰∏™Âü∫‰∫éMCPÁöÑËÅäÂ§©Êú∫Âô®‰∫∫",
      "html_url": "https://github.com/78/xiaozhi-esp32",
      "stars": 23272,
      "forks": 4895,
      "language": "C++",
      "topics": [
        "chatbot",
        "esp32",
        "mcp"
      ],
      "created_at": "2024-08-31T10:08:16Z",
      "updated_at": "2026-01-17T00:11:28Z",
      "pushed_at": "2026-01-15T11:14:42Z",
      "open_issues": 482,
      "owner": {
        "login": "78",
        "avatar_url": "https://avatars.githubusercontent.com/u/4488133?v=4"
      },
      "readme": "# An MCP-based Chatbot\n\n(English | [‰∏≠Êñá](README_zh.md) | [Êó•Êú¨Ë™û](README_ja.md))\n\n## Introduction\n\nüëâ [Human: Give AI a camera vs AI: Instantly finds out the owner hasn't washed hair for three days„Äêbilibili„Äë](https://www.bilibili.com/video/BV1bpjgzKEhd/)\n\nüëâ [Handcraft your AI girlfriend, beginner's guide„Äêbilibili„Äë](https://www.bilibili.com/video/BV1XnmFYLEJN/)\n\nAs a voice interaction entry, the XiaoZhi AI chatbot leverages the AI capabilities of large models like Qwen / DeepSeek, and achieves multi-terminal control via the MCP protocol.\n\n<img src=\"docs/mcp-based-graph.jpg\" alt=\"Control everything via MCP\" width=\"320\">\n\n## Version Notes\n\nThe current v2 version is incompatible with the v1 partition table, so it is not possible to upgrade from v1 to v2 via OTA. For partition table details, see [partitions/v2/README.md](partitions/v2/README.md).\n\nAll hardware running v1 can be upgraded to v2 by manually flashing the firmware.\n\nThe stable version of v1 is 1.9.2. You can switch to v1 by running `git checkout v1`. The v1 branch will be maintained until February 2026.\n\n### Features Implemented\n\n- Wi-Fi / ML307 Cat.1 4G\n- Offline voice wake-up [ESP-SR](https://github.com/espressif/esp-sr)\n- Supports two communication protocols ([Websocket](docs/websocket.md) or MQTT+UDP)\n- Uses OPUS audio codec\n- Voice interaction based on streaming ASR + LLM + TTS architecture\n- Speaker recognition, identifies the current speaker [3D Speaker](https://github.com/modelscope/3D-Speaker)\n- OLED / LCD display, supports emoji display\n- Battery display and power management\n- Multi-language support (Chinese, English, Japanese)\n- Supports ESP32-C3, ESP32-S3, ESP32-P4 chip platforms\n- Device-side MCP for device control (Speaker, LED, Servo, GPIO, etc.)\n- Cloud-side MCP to extend large model capabilities (smart home control, PC desktop operation, knowledge search, email, etc.)\n- Customizable wake words, fonts, emojis, and chat backgrounds with online web-based editing ([Custom Assets Generator](https://github.com/78/xiaozhi-assets-generator))\n\n## Hardware\n\n### Breadboard DIY Practice\n\nSee the Feishu document tutorial:\n\nüëâ [\"XiaoZhi AI Chatbot Encyclopedia\"](https://ccnphfhqs21z.feishu.cn/wiki/F5krwD16viZoF0kKkvDcrZNYnhb?from=from_copylink)\n\nBreadboard demo:\n\n![Breadboard Demo](docs/v1/wiring2.jpg)\n\n### Supports 70+ Open Source Hardware (Partial List)\n\n- <a href=\"https://oshwhub.com/li-chuang-kai-fa-ban/li-chuang-shi-zhan-pai-esp32-s3-kai-fa-ban\" target=\"_blank\" title=\"LiChuang ESP32-S3 Development Board\">LiChuang ESP32-S3 Development Board</a>\n- <a href=\"https://github.com/espressif/esp-box\" target=\"_blank\" title=\"Espressif ESP32-S3-BOX3\">Espressif ESP32-S3-BOX3</a>\n- <a href=\"https://docs.m5stack.com/zh_CN/core/CoreS3\" target=\"_blank\" title=\"M5Stack CoreS3\">M5Stack CoreS3</a>\n- <a href=\"https://docs.m5stack.com/en/atom/Atomic%20Echo%20Base\" target=\"_blank\" title=\"AtomS3R + Echo Base\">M5Stack AtomS3R + Echo Base</a>\n- <a href=\"https://gf.bilibili.com/item/detail/1108782064\" target=\"_blank\" title=\"Magic Button 2.4\">Magic Button 2.4</a>\n- <a href=\"https://www.waveshare.net/shop/ESP32-S3-Touch-AMOLED-1.8.htm\" target=\"_blank\" title=\"Waveshare ESP32-S3-Touch-AMOLED-1.8\">Waveshare ESP32-S3-Touch-AMOLED-1.8</a>\n- <a href=\"https://github.com/Xinyuan-LilyGO/T-Circle-S3\" target=\"_blank\" title=\"LILYGO T-Circle-S3\">LILYGO T-Circle-S3</a>\n- <a href=\"https://oshwhub.com/tenclass01/xmini_c3\" target=\"_blank\" title=\"XiaGe Mini C3\">XiaGe Mini C3</a>\n- <a href=\"https://oshwhub.com/movecall/cuican-ai-pendant-lights-up-y\" target=\"_blank\" title=\"Movecall CuiCan ESP32S3\">CuiCan AI Pendant</a>\n- <a href=\"https://github.com/WMnologo/xingzhi-ai\" target=\"_blank\" title=\"WMnologo-Xingzhi-1.54\">WMnologo-Xingzhi-1.54TFT</a>\n- <a href=\"https://www.seeedstudio.com/SenseCAP-Watcher-W1-A-p-5979.html\" target=\"_blank\" title=\"SenseCAP Watcher\">SenseCAP Watcher</a>\n- <a href=\"https://www.bilibili.com/video/BV1BHJtz6E2S/\" target=\"_blank\" title=\"ESP-HI Low Cost Robot Dog\">ESP-HI Low Cost Robot Dog</a>\n\n<div style=\"display: flex; justify-content: space-between;\">\n  <a href=\"docs/v1/lichuang-s3.jpg\" target=\"_blank\" title=\"LiChuang ESP32-S3 Development Board\">\n    <img src=\"docs/v1/lichuang-s3.jpg\" width=\"240\" />\n  </a>\n  <a href=\"docs/v1/espbox3.jpg\" target=\"_blank\" title=\"Espressif ESP32-S3-BOX3\">\n    <img src=\"docs/v1/espbox3.jpg\" width=\"240\" />\n  </a>\n  <a href=\"docs/v1/m5cores3.jpg\" target=\"_blank\" title=\"M5Stack CoreS3\">\n    <img src=\"docs/v1/m5cores3.jpg\" width=\"240\" />\n  </a>\n  <a href=\"docs/v1/atoms3r.jpg\" target=\"_blank\" title=\"AtomS3R + Echo Base\">\n    <img src=\"docs/v1/atoms3r.jpg\" width=\"240\" />\n  </a>\n  <a href=\"docs/v1/magiclick.jpg\" target=\"_blank\" title=\"Magic Button 2.4\">\n    <img src=\"docs/v1/magiclick.jpg\" width=\"240\" />\n  </a>\n  <a href=\"docs/v1/waveshare.jpg\" target=\"_blank\" title=\"Waveshare ESP32-S3-Touch-AMOLED-1.8\">\n    <img src=\"docs/v1/waveshare.jpg\" width=\"240\" />\n  </a>\n  <a href=\"docs/v1/lilygo-t-circle-s3.jpg\" target=\"_blank\" title=\"LILYGO T-Circle-S3\">\n    <img src=\"docs/v1/lilygo-t-circle-s3.jpg\" width=\"240\" />\n  </a>\n  <a href=\"docs/v1/xmini-c3.jpg\" target=\"_blank\" title=\"XiaGe Mini C3\">\n    <img src=\"docs/v1/xmini-c3.jpg\" width=\"240\" />\n  </a>\n  <a href=\"docs/v1/movecall-cuican-esp32s3.jpg\" target=\"_blank\" title=\"CuiCan\">\n    <img src=\"docs/v1/movecall-cuican-esp32s3.jpg\" width=\"240\" />\n  </a>\n  <a href=\"docs/v1/wmnologo_xingzhi_1.54.jpg\" target=\"_blank\" title=\"WMnologo-Xingzhi-1.54\">\n    <img src=\"docs/v1/wmnologo_xingzhi_1.54.jpg\" width=\"240\" />\n  </a>\n  <a href=\"docs/v1/sensecap_watcher.jpg\" target=\"_blank\" title=\"SenseCAP Watcher\">\n    <img src=\"docs/v1/sensecap_watcher.jpg\" width=\"240\" />\n  </a>\n  <a href=\"docs/v1/esp-hi.jpg\" target=\"_blank\" title=\"ESP-HI Low Cost Robot Dog\">\n    <img src=\"docs/v1/esp-hi.jpg\" width=\"240\" />\n  </a>\n</div>\n\n## Software\n\n### Firmware Flashing\n\nFor beginners, it is recommended to use the firmware that can be flashed without setting up a development environment.\n\nThe firmware connects to the official [xiaozhi.me](https://xiaozhi.me) server by default. Personal users can register an account to use the Qwen real-time model for free.\n\nüëâ [Beginner's Firmware Flashing Guide](https://ccnphfhqs21z.feishu.cn/wiki/Zpz4wXBtdimBrLk25WdcXzxcnNS)\n\n### Development Environment\n\n- Cursor or VSCode\n- Install ESP-IDF plugin, select SDK version 5.4 or above\n- Linux is better than Windows for faster compilation and fewer driver issues\n- This project uses Google C++ code style, please ensure compliance when submitting code\n\n### Developer Documentation\n\n- [Custom Board Guide](docs/custom-board.md) - Learn how to create custom boards for XiaoZhi AI\n- [MCP Protocol IoT Control Usage](docs/mcp-usage.md) - Learn how to control IoT devices via MCP protocol\n- [MCP Protocol Interaction Flow](docs/mcp-protocol.md) - Device-side MCP protocol implementation\n- [MQTT + UDP Hybrid Communication Protocol Document](docs/mqtt-udp.md)\n- [A detailed WebSocket communication protocol document](docs/websocket.md)\n\n## Large Model Configuration\n\nIf you already have a XiaoZhi AI chatbot device and have connected to the official server, you can log in to the [xiaozhi.me](https://xiaozhi.me) console for configuration.\n\nüëâ [Backend Operation Video Tutorial (Old Interface)](https://www.bilibili.com/video/BV1jUCUY2EKM/)\n\n## Related Open Source Projects\n\nFor server deployment on personal computers, refer to the following open-source projects:\n\n- [xinnan-tech/xiaozhi-esp32-server](https://github.com/xinnan-tech/xiaozhi-esp32-server) Python server\n- [joey-zhou/xiaozhi-esp32-server-java](https://github.com/joey-zhou/xiaozhi-esp32-server-java) Java server\n- [AnimeAIChat/xiaozhi-server-go](https://github.com/AnimeAIChat/xiaozhi-server-go) Golang server\n\nOther client projects using the XiaoZhi communication protocol:\n\n- [huangjunsen0406/py-xiaozhi](https://github.com/huangjunsen0406/py-xiaozhi) Python client\n- [TOM88812/xiaozhi-android-client](https://github.com/TOM88812/xiaozhi-android-client) Android client\n- [100askTeam/xiaozhi-linux](http://github.com/100askTeam/xiaozhi-linux) Linux client by 100ask\n- [78/xiaozhi-sf32](https://github.com/78/xiaozhi-sf32) Bluetooth chip firmware by Sichuan\n- [QuecPython/solution-xiaozhiAI](https://github.com/QuecPython/solution-xiaozhiAI) QuecPython firmware by Quectel\n\nCustom Assets Tools:\n\n- [78/xiaozhi-assets-generator](https://github.com/78/xiaozhi-assets-generator) Custom Assets Generator (Wake words, fonts, emojis, backgrounds)\n\n## About the Project\n\nThis is an open-source ESP32 project, released under the MIT license, allowing anyone to use it for free, including for commercial purposes.\n\nWe hope this project helps everyone understand AI hardware development and apply rapidly evolving large language models to real hardware devices.\n\nIf you have any ideas or suggestions, please feel free to raise Issues or join the QQ group: 1011329060\n\n## Star History\n\n<a href=\"https://star-history.com/#78/xiaozhi-esp32&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=78/xiaozhi-esp32&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=78/xiaozhi-esp32&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=78/xiaozhi-esp32&type=Date\" />\n </picture>\n</a> \n",
      "stars_today": 22
    },
    {
      "id": 546206616,
      "name": "chroma",
      "full_name": "chroma-core/chroma",
      "description": "Open-source search and retrieval database for AI applications.",
      "html_url": "https://github.com/chroma-core/chroma",
      "stars": 25503,
      "forks": 2002,
      "language": "Rust",
      "topics": [
        "ai",
        "database",
        "document-retrieval",
        "embeddings",
        "llm",
        "llms",
        "rag",
        "rust",
        "rust-lang",
        "vector-database"
      ],
      "created_at": "2022-10-05T17:58:44Z",
      "updated_at": "2026-01-16T22:53:12Z",
      "pushed_at": "2026-01-17T00:05:24Z",
      "open_issues": 480,
      "owner": {
        "login": "chroma-core",
        "avatar_url": "https://avatars.githubusercontent.com/u/105881770?v=4"
      },
      "readme": "![Chroma](./docs/docs.trychroma.com/public/chroma-wordmark-color.png#gh-light-mode-only)\n![Chroma](./docs/docs.trychroma.com/public/chroma-wordmark-white.png#gh-dark-mode-only)\n\n<p align=\"center\">\n    <b>Chroma - the open-source embedding database</b>. <br />\n    The fastest way to build Python or JavaScript LLM apps with memory!\n</p>\n\n<p align=\"center\">\n  <a href=\"https://discord.gg/MMeYNTmh3x\" target=\"_blank\">\n      <img src=\"https://img.shields.io/discord/1073293645303795742?cacheSeconds=3600\" alt=\"Discord\">\n  </a> |\n  <a href=\"https://github.com/chroma-core/chroma/blob/master/LICENSE\" target=\"_blank\">\n      <img src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg\" alt=\"License\">\n  </a> |\n  <a href=\"https://docs.trychroma.com/\" target=\"_blank\">\n      Docs\n  </a> |\n  <a href=\"https://www.trychroma.com/\" target=\"_blank\">\n      Homepage\n  </a>\n</p>\n\n```bash\npip install chromadb # python client\n# for javascript, npm install chromadb!\n# for client-server mode, chroma run --path /chroma_db_path\n```\n\n## Chroma Cloud\n\nOur hosted service, Chroma Cloud, powers serverless vector and full-text search. It's extremely fast, cost-effective, scalable and painless. Create a DB and try it out in under 30 seconds with $5 of free credits.\n\n[Get started with Chroma Cloud](https://trychroma.com/signup)\n\n## API\n\nThe core API is only 4 functions (run our [üí° Google Colab](https://colab.research.google.com/drive/1QEzFyqnoFxq7LUGyP1vzR4iLt9PpCDXv?usp=sharing)):\n\n```python\nimport chromadb\n# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\nclient = chromadb.Client()\n\n# Create collection. get_collection, get_or_create_collection, delete_collection also available!\ncollection = client.create_collection(\"all-my-documents\")\n\n# Add docs to the collection. Can also update and delete. Row-based API coming soon!\ncollection.add(\n    documents=[\"This is document1\", \"This is document2\"], # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n    metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"}], # filter on these!\n    ids=[\"doc1\", \"doc2\"], # unique for each doc\n)\n\n# Query/search 2 most similar results. You can also .get by id\nresults = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n    # where_document={\"$contains\":\"search_string\"}  # optional filter\n)\n```\n\nLearn about all features on our [Docs](https://docs.trychroma.com)\n\n## Features\n- __Simple__: Fully-typed, fully-tested, fully-documented == happiness\n- __Integrations__: [`ü¶úÔ∏èüîó LangChain`](https://blog.langchain.dev/langchain-chroma/) (python and js), [`ü¶ô LlamaIndex`](https://twitter.com/atroyn/status/1628557389762007040) and more soon\n- __Dev, Test, Prod__: the same API that runs in your python notebook, scales to your cluster\n- __Feature-rich__: Queries, filtering, regex and more\n- __Free & Open Source__: Apache 2.0 Licensed\n\n## Use case: ChatGPT for ______\n\nFor example, the `\"Chat your data\"` use case:\n1. Add documents to your database. You can pass in your own embeddings, embedding function, or let Chroma embed them for you.\n2. Query relevant documents with natural language.\n3. Compose documents into the context window of an LLM like `GPT4` for additional summarization or analysis.\n\n## Embeddings?\n\nWhat are embeddings?\n\n- [Read the guide from OpenAI](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)\n- __Literal__: Embedding something turns it from image/text/audio into a list of numbers. üñºÔ∏è or üìÑ => `[1.2, 2.1, ....]`. This process makes documents \"understandable\" to a machine learning model.\n- __By analogy__: An embedding represents the essence of a document. This enables documents and queries with the same essence to be \"near\" each other and therefore easy to find.\n- __Technical__: An embedding is the latent-space position of a document at a layer of a deep neural network. For models trained specifically to embed data, this is the last layer.\n- __A small example__: If you search your photos for \"famous bridge in San Francisco\". By embedding this query and comparing it to the embeddings of your photos and their metadata - it should return photos of the Golden Gate Bridge.\n\nEmbeddings databases (also known as **vector databases**) store embeddings and allow you to search by nearest neighbors rather than by substrings like a traditional database. By default, Chroma uses [Sentence Transformers](https://docs.trychroma.com/guides/embeddings#default:-all-minilm-l6-v2) to embed for you but you can also use OpenAI embeddings, Cohere (multilingual) embeddings, or your own.\n\n## Get involved\n\nChroma is a rapidly developing project. We welcome PR contributors and ideas for how to improve the project.\n- [Join the conversation on Discord](https://discord.gg/MMeYNTmh3x) - `#contributing` channel\n- [Review the üõ£Ô∏è Roadmap and contribute your ideas](https://docs.trychroma.com/roadmap)\n- [Grab an issue and open a PR](https://github.com/chroma-core/chroma/issues) - [`Good first issue tag`](https://github.com/chroma-core/chroma/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22)\n- [Read our contributing guide](https://docs.trychroma.com/contributing)\n\n**Release Cadence**\nWe currently release new tagged versions of the `pypi` and `npm` packages on Mondays. Hotfixes go out at any time during the week.\n\n## License\n\n[Apache 2.0](./LICENSE)\n",
      "stars_today": 22
    },
    {
      "id": 11125589,
      "name": "keycloak",
      "full_name": "keycloak/keycloak",
      "description": "Open Source Identity and Access Management For Modern Applications and Services",
      "html_url": "https://github.com/keycloak/keycloak",
      "stars": 32271,
      "forks": 7966,
      "language": "Java",
      "topics": [
        "keycloak",
        "oidc",
        "saml"
      ],
      "created_at": "2013-07-02T13:38:51Z",
      "updated_at": "2026-01-17T00:41:15Z",
      "pushed_at": "2026-01-17T00:17:13Z",
      "open_issues": 2477,
      "owner": {
        "login": "keycloak",
        "avatar_url": "https://avatars.githubusercontent.com/u/4921466?v=4"
      },
      "readme": "![Keycloak](https://github.com/keycloak/keycloak-misc/blob/main/logo/logo.svg)\n\n![GitHub Release](https://img.shields.io/github/v/release/keycloak/keycloak?label=latest%20release)\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/6818/badge)](https://bestpractices.coreinfrastructure.org/projects/6818)\n[![CLOMonitor](https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/keycloak/badge)](https://clomonitor.io/projects/cncf/keycloak)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/keycloak/keycloak/badge)](https://securityscorecards.dev/viewer/?uri=github.com/keycloak/keycloak)\n[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/keycloak-operator)](https://artifacthub.io/packages/olm/community-operators/keycloak-operator)\n![GitHub Repo stars](https://img.shields.io/github/stars/keycloak/keycloak?style=flat)\n![GitHub commit activity](https://img.shields.io/github/commit-activity/m/keycloak/keycloak)\n[![Translation status](https://hosted.weblate.org/widget/keycloak/svg-badge.svg)](docs/translation.md)\n\n# Open Source Identity and Access Management\n\nAdd authentication to applications and secure services with minimum effort. No need to deal with storing users or authenticating users.\n\nKeycloak provides user federation, strong authentication, user management, fine-grained authorization, and more.\n\n\n## Help and Documentation\n\n* [Documentation](https://www.keycloak.org/documentation.html)\n* [User Mailing List](https://groups.google.com/d/forum/keycloak-user) - Mailing list for help and general questions about Keycloak\n* Join¬†[#keycloak](https://cloud-native.slack.com/archives/C056HC17KK9) for general questions, or¬†[#keycloak-dev](https://cloud-native.slack.com/archives/C056XU905S6)¬†on Slack for design and development discussions, by creating an account at¬†[https://slack.cncf.io/](https://slack.cncf.io/).\n\n\n## Reporting Security Vulnerabilities\n\nIf you have found a security vulnerability, please look at the [instructions on how to properly report it](https://github.com/keycloak/keycloak/security/policy).\n\n\n## Reporting an issue\n\nIf you believe you have discovered a defect in Keycloak, please open [an issue](https://github.com/keycloak/keycloak/issues).\nPlease remember to provide a good summary, description as well as steps to reproduce the issue.\n\n\n## Getting started\n\nTo run Keycloak, download the distribution from our [website](https://www.keycloak.org/downloads.html). Unzip and run:\n\n    bin/kc.[sh|bat] start-dev\n\nAlternatively, you can use the Docker image by running:\n\n    docker run quay.io/keycloak/keycloak start-dev\n    \nFor more details refer to the [Keycloak Documentation](https://www.keycloak.org/documentation.html).\n\n\n## Building from Source\n\nTo build from source, refer to the [building and working with the code base](docs/building.md) guide.\n\n\n### Testing\n\nTo run tests, refer to the [running tests](docs/tests.md) guide.\n\n\n### Writing Tests\n\nTo write tests, refer to the [writing tests](docs/tests-development.md) guide.\n\n\n## Contributing\n\nBefore contributing to Keycloak, please read our [contributing guidelines](CONTRIBUTING.md). Participation in the Keycloak project is governed by the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/main/code-of-conduct.md).\n\nJoining a [community meeting](https://www.keycloak.org/community) is a great way to get involved and help shape the future of Keycloak.\n\n## Other Keycloak Projects\n\n* [Keycloak](https://github.com/keycloak/keycloak) - Keycloak Server and Java adapters\n* [Keycloak QuickStarts](https://github.com/keycloak/keycloak-quickstarts) - QuickStarts for getting started with Keycloak\n* [Keycloak Node.js Connect](https://github.com/keycloak/keycloak-nodejs-connect) - Node.js adapter for Keycloak\n\n\n## License\n\n* [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
      "stars_today": 21
    },
    {
      "id": 607441698,
      "name": "lancedb",
      "full_name": "lancedb/lancedb",
      "description": "Developer-friendly OSS embedded retrieval library for multimodal AI. Search More; Manage Less.",
      "html_url": "https://github.com/lancedb/lancedb",
      "stars": 8522,
      "forks": 708,
      "language": "Rust",
      "topics": [
        "approximate-nearest-neighbor-search",
        "image-search",
        "nearest-neighbor-search",
        "recommender-system",
        "search-engine",
        "semantic-search",
        "similarity-search",
        "vector-database"
      ],
      "created_at": "2023-02-28T01:15:17Z",
      "updated_at": "2026-01-17T00:29:27Z",
      "pushed_at": "2026-01-15T17:46:55Z",
      "open_issues": 536,
      "owner": {
        "login": "lancedb",
        "avatar_url": "https://avatars.githubusercontent.com/u/108903835?v=4"
      },
      "readme": "<a href=\"https://cloud.lancedb.com\" target=\"_blank\">\n  <img src=\"https://github.com/user-attachments/assets/92dad0a2-2a37-4ce1-b783-0d1b4f30a00c\" alt=\"LanceDB Cloud Public Beta\" width=\"100%\" style=\"max-width: 100%;\">\n</a>\n<div align=\"center\">\n\n[![LanceDB](docs/src/assets/hero-header.png)](https://lancedb.com)\n[![Website](https://img.shields.io/badge/-Website-100000?style=for-the-badge&labelColor=645cfb&color=645cfb)](https://lancedb.com/)\n[![Blog](https://img.shields.io/badge/Blog-100000?style=for-the-badge&labelColor=645cfb&color=645cfb)](https://blog.lancedb.com/)\n[![Discord](https://img.shields.io/badge/-Discord-100000?style=for-the-badge&logo=discord&logoColor=white&labelColor=645cfb&color=645cfb)](https://discord.gg/zMM32dvNtd)\n[![Twitter](https://img.shields.io/badge/-Twitter-100000?style=for-the-badge&logo=x&logoColor=white&labelColor=645cfb&color=645cfb)](https://twitter.com/lancedb)\n[![LinkedIn](https://img.shields.io/badge/-LinkedIn-100000?style=for-the-badge&logo=linkedin&logoColor=white&labelColor=645cfb&color=645cfb)](https://www.linkedin.com/company/lancedb/)\n\n\n<img src=\"docs/src/assets/lancedb.png\" alt=\"LanceDB\" width=\"50%\">\n\n# **The Multimodal AI Lakehouse**\n\n[**How to Install** ](#how-to-install) ‚ú¶ [**Detailed Documentation**](https://lancedb.com/docs) ‚ú¶ [**Tutorials and Recipes**](https://github.com/lancedb/vectordb-recipes/tree/main) ‚ú¶  [**Contributors**](#contributors) \n\n**The ultimate multimodal data platform for AI/ML applications.** \n\nLanceDB is designed for fast, scalable, and production-ready vector search. It is built on top of the Lance columnar format. You can store, index, and search over petabytes of multimodal data and vectors with ease. \nLanceDB is a central location where developers can build, train and analyze their AI workloads.\n\n</div>\n\n<br>\n\n## **Demo: Multimodal Search by Keyword, Vector or with SQL**\n<img max-width=\"750px\" alt=\"LanceDB Multimodal Search\" src=\"https://github.com/lancedb/lancedb/assets/917119/09c5afc5-7816-4687-bae4-f2ca194426ec\">\n\n## **Star LanceDB to get updates!**\n\n<details>\n<summary>‚≠ê Click here ‚≠ê  to see how fast we're growing!</summary>\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=lancedb/lancedb&theme=dark&type=Date\">\n  <img width=\"100%\" src=\"https://api.star-history.com/svg?repos=lancedb/lancedb&theme=dark&type=Date\">\n</picture>\n</details>\n\n## **Key Features**:\n\n- **Fast Vector Search**: Search billions of vectors in milliseconds with state-of-the-art indexing.\n- **Comprehensive Search**: Support for vector similarity search, full-text search and SQL.\n- **Multimodal Support**: Store, query and filter vectors, metadata and multimodal data (text, images, videos, point clouds, and more).\n- **Advanced Features**: Zero-copy, automatic versioning, manage versions of your data without needing extra infrastructure. GPU support in building vector index.\n\n### **Products**:\n- **Open Source & Local**: 100% open source, runs locally or in your cloud. No vendor lock-in.\n- **Cloud and Enterprise**: Production-scale vector search with no servers to manage. Complete data sovereignty and security.\n\n### **Ecosystem**:\n- **Columnar Storage**: Built on the Lance columnar format for efficient storage and analytics.\n- **Seamless Integration**: Python, Node.js, Rust, and REST APIs for easy integration. Native Python and Javascript/Typescript support.\n- **Rich Ecosystem**: Integrations with [**LangChain** ü¶úÔ∏èüîó](https://python.langchain.com/docs/integrations/vectorstores/lancedb/), [**LlamaIndex** ü¶ô](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/LanceDBIndexDemo.html), Apache-Arrow, Pandas, Polars, DuckDB and more on the way.\n\n## **How to Install**:\n\nFollow the [Quickstart](https://lancedb.com/docs/quickstart/) doc to set up LanceDB locally. \n\n**API & SDK:** We also support Python, Typescript and Rust SDKs\n\n| Interface | Documentation |\n|-----------|---------------|\n| Python SDK | https://lancedb.github.io/lancedb/python/python/ |\n| Typescript SDK | https://lancedb.github.io/lancedb/js/globals/ |\n| Rust SDK | https://docs.rs/lancedb/latest/lancedb/index.html |\n| REST API | https://docs.lancedb.com/api-reference/introduction |\n\n## **Join Us and Contribute**\n\nWe welcome contributions from everyone! Whether you're a developer, researcher, or just someone who wants to help out. \n\nIf you have any suggestions or feature requests, please feel free to open an issue on GitHub or discuss it on our [**Discord**](https://discord.gg/G5DcmnZWKB) server.\n\n[**Check out the GitHub Issues**](https://github.com/lancedb/lancedb/issues) if you would like to work on the features that are planned for the future. If you have any suggestions or feature requests, please feel free to open an issue on GitHub. \n\n## **Contributors**\n\n<a href=\"https://github.com/lancedb/lancedb/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=lancedb/lancedb\" />\n</a>\n\n\n## **Stay in Touch With Us**\n<div align=\"center\">\n\n</br>\n\n[![Website](https://img.shields.io/badge/-Website-100000?style=for-the-badge&labelColor=645cfb&color=645cfb)](https://lancedb.com/)\n[![Blog](https://img.shields.io/badge/Blog-100000?style=for-the-badge&labelColor=645cfb&color=645cfb)](https://blog.lancedb.com/)\n[![Discord](https://img.shields.io/badge/-Discord-100000?style=for-the-badge&logo=discord&logoColor=white&labelColor=645cfb&color=645cfb)](https://discord.gg/zMM32dvNtd)\n[![Twitter](https://img.shields.io/badge/-Twitter-100000?style=for-the-badge&logo=x&logoColor=white&labelColor=645cfb&color=645cfb)](https://twitter.com/lancedb)\n[![LinkedIn](https://img.shields.io/badge/-LinkedIn-100000?style=for-the-badge&logo=linkedin&logoColor=white&labelColor=645cfb&color=645cfb)](https://www.linkedin.com/company/lancedb/)\n\n</div>\n",
      "stars_today": 21
    },
    {
      "id": 767183985,
      "name": "azahar",
      "full_name": "azahar-emu/azahar",
      "description": "An open-source 3DS emulator project based on Citra.",
      "html_url": "https://github.com/azahar-emu/azahar",
      "stars": 6239,
      "forks": 388,
      "language": "C++",
      "topics": [],
      "created_at": "2024-03-04T21:08:59Z",
      "updated_at": "2026-01-16T23:49:05Z",
      "pushed_at": "2026-01-15T11:46:18Z",
      "open_issues": 309,
      "owner": {
        "login": "azahar-emu",
        "avatar_url": "https://avatars.githubusercontent.com/u/188636407?v=4"
      },
      "readme": "![Azahar Emulator](https://azahar-emu.org/resources/images/logo/azahar-name-and-logo.svg)\n\n![GitHub Release](https://img.shields.io/github/v/release/azahar-emu/azahar?label=Current%20Release)\n![GitHub Downloads](https://img.shields.io/github/downloads/azahar-emu/azahar/total?logo=github&label=GitHub%20Downloads)\n![Google Play Downloads](https://playbadges.pavi2410.com/badge/downloads?id=io.github.lime3ds.android&pretty&label=Play%20Store%20Downloads)\n![Flathub Downloads](https://img.shields.io/flathub/downloads/org.azahar_emu.Azahar?logo=flathub&label=Flathub%20Downloads)\n![CI Build Status](https://github.com/azahar-emu/azahar/actions/workflows/build.yml/badge.svg)\n\n<b>Azahar</b> is an open-source 3DS emulator project based on Citra.\n\nIt was created from the merging of PabloMK7's Citra fork and the Lime3DS project, both of which emerged shortly after Citra was taken down.\n\nThe goal of this project is to be the de-facto platform for future development.\n\n# Installation\n\n### Windows\n\nAzahar is available as both an installer and a zip archive.\n\nDownload the latest release in your preferred format from the [Releases](https://github.com/azahar-emu/azahar/releases) page.\n\nIf you are unsure of whether you want to use MSVC or MSYS2, use MSYS2.\n\n---\n\n### MacOS\n\nTo download a build that will work on all Macs, you can download the `macos-universal` build on the [Releases](https://github.com/azahar-emu/azahar/releases) page.\n\nAlternatively, if you wish to download a build specifically for your Mac, you can choose either:\n\n- `macos-arm64` for Apple Silicon Macs\n- `macos-x86_64` for Intel Macs\n\n---\n\n### Android\n\nThere are two variants of Azahar available on Android, those being the Vanilla and Google Play builds.\n\nThe Vanilla build is technically superior, as it uses an alternative method of file management which is faster, but isn't permitted on the Google Play store.\n\nFor most users, we currently recommended downloading Azahar on Android via the Google Play Store for ease of accessibility:\n\n<a href='https://play.google.com/store/apps/details?id=io.github.lime3ds.android'><img width='180' alt='Get it on Google Play' src='https://raw.githubusercontent.com/pioug/google-play-badges/06ccd9252af1501613da2ca28eaffe31307a4e6d/svg/English.svg'/></a>\n\nAlternatively, you can install the app using Obtainium, allowing you to use the Vanilla variant:\n1. Download and install Obtainium from [here](https://github.com/ImranR98/Obtainium/releases) (use the file named `app-release.apk`)\n2. Open Obtainium and click 'Add App'\n3. Type `https://github.com/azahar-emu/azahar` into the 'App Source URL' section\n4. Click 'Add'\n5. Click 'Install', and select the preferred variant\n\nIf you wish, you can also simply install the latest APK from the [Releases](https://github.com/azahar-emu/azahar/releases) page.\n\nKeep in mind that you will not recieve automatic updates when installing via the APK.\n\n---\n\n### Linux\n\nThe recommended format for using Azahar on Linux is the Flatpak available on Flathub:\n\n<a href='https://flathub.org/apps/org.azahar_emu.Azahar'><img width='180' alt='Download on Flathub' src='https://dl.flathub.org/assets/badges/flathub-badge-en.png'/></a>\n\nAzahar is also available as an AppImage on the [Releases](https://github.com/azahar-emu/azahar/releases) page.\n\nThere are two variants of the AppImage available, those being `azahar.AppImage` and `azahar-wayland.AppImage`.\n\nIf you are unsure of which variant to use, we recommend using the default `azahar.AppImage`. This is because of upstream issues in the Wayland ecosystem which may cause problems when running the emulator (e.g. [#1162](https://github.com/azahar-emu/azahar/issues/1162)).\n\nUnless you explicitly require native Wayland support (e.g. you are running a system with no Xwayland), the non-Wayland variant is recommended.\n\nThe Flatpak build of Azahar also has native Wayland support disabled by default. If you require native Wayland support, it can be enabled using [Flatseal](https://flathub.org/en/apps/com.github.tchx84.Flatseal).\n\n# Build instructions\n\nPlease refer this repository's [wiki](https://github.com/azahar-emu/azahar/wiki/Building-From-Source) for build instructions\n\n# How can I contribute?\n\n### Pull requests\n\nIf you want to implement a change and have the technical capability to do so, we would be happy to accept your contributions.\n\nIf you are contributing a new feature, it is highly suggested that you first make a Feature Request issue to discuss the addition before writing any code. This is to ensure that your time isn't wasted working on a feature which isn't deemed appropriate for the project.\n\nAfter creating a pull request, please don't repeatedly merge `master` into your branch. A maintainer will update the branch for you if/ when it is appropriate to do so.\n\n### Language translations\n\nAdditionally, we are accepting language translations on [Transifex](https://app.transifex.com/azahar/azahar). If you know a non-english language listed on our Transifex page, please feel free to contribute.\n\n> [!NOTE]\n> We are not currently accepting new languages for translation. Please do not request for new languages or language variants to be added.\n\n### Compatibility reports\n\nEven if you don't wish to contribute code or translations, you can help the project by reporting game compatibility data to our compatibility list.\n\nTo do so, simply read https://github.com/azahar-emu/compatibility-list/blob/master/CONTRIBUTING.md and follow the instructions.\n\nContributing compatibility data helps more accurately reflect the current capabilities of the emulator, so it would be highly appreciated if you could go through the reporting process after completing a game.\n\n# Minimum requirements\n\nBelow are the minimum requirements to run Azahar:\n\n### Desktop\n\n```\nOperating System: Windows 10 (64-bit), MacOS 13.4 (Ventura), or modern 64-bit Linux\nCPU: x86-64/ARM64 CPU (Windows for ARM not supported).\n     Single core performance higher than 1,800 on Passmark.\n     SSE4.2 required on x86_64.\nGPU: OpenGL 4.3 or Vulkan 1.1 support\nMemory: 2GB of RAM. 4GB is recommended\n```\n### Android\n\n```\nOperating System: Android 10.0+ (64-bit)\nCPU: Snapdragon 835 SoC or better\nGPU: OpenGL ES 3.2 or Vulkan 1.1 support\nMemory: 2GB of RAM. 4GB is recommended\n```\n\n# What's next?\n\nWe share public roadmaps for upcoming releases in the form of GitHub milestones.\n\nYou can find these at https://github.com/azahar-emu/azahar/milestones.\n\n# Join the conversation\n\nWe have a community Discord server where you can chat about the project, keep up to date with the latest announcements, or coordinate emulator development.\n\nJoin at https://discord.gg/4ZjMpAp3M6\n",
      "stars_today": 21
    },
    {
      "id": 51868010,
      "name": "bubblewrap",
      "full_name": "containers/bubblewrap",
      "description": "Low-level unprivileged sandboxing tool used by Flatpak and similar projects",
      "html_url": "https://github.com/containers/bubblewrap",
      "stars": 5464,
      "forks": 273,
      "language": "C",
      "topics": [
        "linux-containers",
        "user-namespaces"
      ],
      "created_at": "2016-02-16T20:36:10Z",
      "updated_at": "2026-01-17T00:30:08Z",
      "pushed_at": "2025-08-04T14:30:38Z",
      "open_issues": 177,
      "owner": {
        "login": "containers",
        "avatar_url": "https://avatars.githubusercontent.com/u/5874934?v=4"
      },
      "readme": "Bubblewrap\n==========\n\nMany container runtime tools like `systemd-nspawn`, `docker`,\netc. focus on providing infrastructure for system administrators and\norchestration tools (e.g. Kubernetes) to run containers.\n\nThese tools are not suitable to give to unprivileged users, because it\nis trivial to turn such access into a fully privileged root shell\non the host.\n\nUser namespaces\n---------------\n\nThere is an effort in the Linux kernel called\n[user namespaces](https://www.google.com/search?q=user+namespaces+site%3Ahttps%3A%2F%2Flwn.net)\nwhich attempts to allow unprivileged users to use container features.\nWhile significant progress has been made, there are\n[still concerns](https://lwn.net/Articles/673597/) about it, and\nit is not available to unprivileged users in several production distributions\nsuch as CentOS/Red Hat Enterprise Linux 7, Debian Jessie, etc.\n\nSee for example\n[CVE-2016-3135](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3135)\nwhich is a local root vulnerability introduced by userns.\n[This March 2016 post](https://lkml.org/lkml/2016/3/9/555) has some\nmore discussion.\n\nBubblewrap could be viewed as setuid implementation of a *subset* of\nuser namespaces.  Emphasis on subset - specifically relevant to the\nabove CVE, bubblewrap does not allow control over iptables.\n\nThe original bubblewrap code existed before user namespaces - it inherits code from\n[xdg-app helper](https://cgit.freedesktop.org/xdg-app/xdg-app/tree/common/xdg-app-helper.c?id=4c3bf179e2e4a2a298cd1db1d045adaf3f564532)\nwhich in turn distantly derives from\n[linux-user-chroot](https://git.gnome.org/browse/linux-user-chroot).\n\nSystem security\n---------------\n\nThe maintainers of this tool believe that it does not, even when used\nin combination with typical software installed on that distribution,\nallow privilege escalation.  It may increase the ability of a logged\nin user to perform denial of service attacks, however.\n\nIn particular, bubblewrap uses `PR_SET_NO_NEW_PRIVS` to turn off\nsetuid binaries, which is the [traditional way](https://en.wikipedia.org/wiki/Chroot#Limitations) to get out of things\nlike chroots.\n\nSandbox security\n----------------\n\nbubblewrap is a tool for constructing sandbox environments.\nbubblewrap is not a complete, ready-made sandbox with a specific security\npolicy.\n\nSome of bubblewrap's use-cases want a security boundary between the sandbox\nand the real system; other use-cases want the ability to change the layout of\nthe filesystem for processes inside the sandbox, but do not aim to be a\nsecurity boundary.\nAs a result, the level of protection between the sandboxed processes and\nthe host system is entirely determined by the arguments passed to\nbubblewrap.\n\nWhatever program constructs the command-line arguments for bubblewrap\n(often a larger framework like Flatpak, libgnome-desktop, sandwine\nor an ad-hoc script) is responsible for defining its own security model,\nand choosing appropriate bubblewrap command-line arguments to implement\nthat security model.\n\nSome aspects of sandbox security that require particular care are described\nin the [Limitations](#limitations) section below.\n\nUsers\n-----\n\nThis program can be shared by all container tools which perform\nnon-root operation, such as:\n\n - [Flatpak](https://www.flatpak.org)\n - [rpm-ostree unprivileged](https://github.com/projectatomic/rpm-ostree/pull/209)\n - [bwrap-oci](https://github.com/projectatomic/bwrap-oci)\n\nWe would also like to see this be available in Kubernetes/OpenShift\nclusters.  Having the ability for unprivileged users to use container\nfeatures would make it significantly easier to do interactive\ndebugging scenarios and the like.\n\nInstallation\n------------\n\nbubblewrap is available in the package repositories of the most Linux distributions\nand can be installed from there.\n\nIf you need to build bubblewrap from source, you can do this with meson:\n\n```sh\nmeson _builddir\nmeson compile -C _builddir\nmeson test -C _builddir\nmeson install -C _builddir\n```\n\nUsage\n-----\n\nbubblewrap works by creating a new, completely empty, mount\nnamespace where the root is on a tmpfs that is invisible from the\nhost, and will be automatically cleaned up when the last process\nexits. You can then use commandline options to construct the root\nfilesystem and process environment and command to run in the\nnamespace.\n\nThere's a larger [demo script](./demos/bubblewrap-shell.sh) in the\nsource code, but here's a trimmed down version which runs\na new shell reusing the host's `/usr`.\n\n```\nbwrap \\\n    --ro-bind /usr /usr \\\n    --symlink usr/lib64 /lib64 \\\n    --proc /proc \\\n    --dev /dev \\\n    --unshare-pid \\\n    --new-session \\\n    bash\n```\n\nThis is an incomplete example, but useful for purposes of\nillustration.  More often, rather than creating a container using the\nhost's filesystem tree, you want to target a chroot.  There, rather\nthan creating the symlink `lib64 -> usr/lib64` in the tmpfs, you might\nhave already created it in the target rootfs.\n\nSandboxing\n----------\n\nThe goal of bubblewrap is to run an application in a sandbox, where it\nhas restricted access to parts of the operating system or user data\nsuch as the home directory.\n\nbubblewrap always creates a new mount namespace, and the user can specify\nexactly what parts of the filesystem should be visible in the sandbox.\nAny such directories you specify mounted `nodev` by default, and can be made readonly.\n\nAdditionally you can use these kernel features:\n\nUser namespaces ([CLONE_NEWUSER](https://linux.die.net/man/2/clone)): This hides all but the current uid and gid from the\nsandbox. You can also change what the value of uid/gid should be in the sandbox.\n\nIPC namespaces ([CLONE_NEWIPC](https://linux.die.net/man/2/clone)): The sandbox will get its own copy of all the\ndifferent forms of IPCs, like SysV shared memory and semaphores.\n\nPID namespaces ([CLONE_NEWPID](https://linux.die.net/man/2/clone)): The sandbox will not see any processes outside the sandbox. Additionally, bubblewrap will run a trivial pid1 inside your container to handle the requirements of reaping children in the sandbox. This avoids what is known now as the [Docker pid 1 problem](https://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/).\n\n\nNetwork namespaces ([CLONE_NEWNET](https://linux.die.net/man/2/clone)): The sandbox will not see the network. Instead it will have its own network namespace with only a loopback device.\n\nUTS namespace ([CLONE_NEWUTS](https://linux.die.net/man/2/clone)): The sandbox will have its own hostname.\n\nSeccomp filters: You can pass in seccomp filters that limit which syscalls can be done in the sandbox. For more information, see [Seccomp](https://en.wikipedia.org/wiki/Seccomp).\n\nLimitations\n-----------\n\nAs noted in the [Sandbox security](#sandbox-security) section above,\nthe level of protection between the sandboxed processes and the host system\nis entirely determined by the arguments passed to bubblewrap.\nSome aspects that require special care are noted here.\n\n- If you are not filtering out `TIOCSTI` commands using seccomp filters,\nargument `--new-session` is needed to protect against out-of-sandbox\ncommand execution\n(see [CVE-2017-5226](https://github.com/containers/bubblewrap/issues/142)).\n\n- Everything mounted into the sandbox can potentially be used to escalate\nprivileges.\nFor example, if you bind a D-Bus socket into the sandbox, it can be used to\nexecute commands via systemd. You can use\n[xdg-dbus-proxy](https://github.com/flatpak/xdg-dbus-proxy) to filter\nD-Bus communication.\n\n- Some applications deploy their own sandboxing mechanisms, and these can be\nrestricted by the constraints imposed by bubblewrap's sandboxing.\nFor example, some web browsers which configure their child proccesses via\nseccomp to not have access to the filesystem. If you limit the syscalls and\ndon't allow the seccomp syscall, a browser cannot apply these restrictions.\nSimilarly, if these rules were compiled into a file that is not available in\nthe sandbox, the browser cannot load these rules from this file and cannot\napply these restrictions.\n\nRelated project comparison: Firejail\n------------------------------------\n\n[Firejail](https://github.com/netblue30/firejail/tree/HEAD/src/firejail)\nis similar to Flatpak before bubblewrap was split out in that it combines\na setuid tool with a lot of desktop-specific sandboxing features.  For\nexample, Firejail knows about Pulseaudio, whereas bubblewrap does not.\n\nThe bubblewrap authors believe it's much easier to audit a small\nsetuid program, and keep features such as Pulseaudio filtering as an\nunprivileged process, as now occurs in Flatpak.\n\nAlso, @cgwalters thinks trying to\n[whitelist file paths](https://github.com/netblue30/firejail/blob/37a5a3545ef6d8d03dad8bbd888f53e13274c9e5/src/firejail/fs_whitelist.c#L176)\nis a bad idea given the myriad ways users have to manipulate paths,\nand the myriad ways in which system administrators may configure a\nsystem.  The bubblewrap approach is to only retain a few specific\nLinux capabilities such as `CAP_SYS_ADMIN`, but to always access the\nfilesystem as the invoking uid.  This entirely closes\n[TOCTTOU attacks](https://cwe.mitre.org/data/definitions/367.html) and\nsuch.\n\nRelated project comparison: Sandstorm.io\n----------------------------------------\n\n[Sandstorm.io](https://sandstorm.io/) requires unprivileged user\nnamespaces to set up its sandbox, though it could easily be adapted\nto operate in a setuid mode as well. @cgwalters believes their code is\nfairly good, but it could still make sense to unify on bubblewrap.\nHowever, @kentonv (of Sandstorm) feels that while this makes sense\nin principle, the switching cost outweighs the practical benefits for\nnow. This decision could be re-evaluated in the future, but it is not\nbeing actively pursued today.\n\nRelated project comparison: runc/binctr\n----------------------------------------\n\n[runC](https://github.com/opencontainers/runc) is currently working on\nsupporting [rootless containers](https://github.com/opencontainers/runc/pull/774),\nwithout needing `setuid` or any other privileges during installation of\nrunC (using unprivileged user namespaces rather than `setuid`),\ncreation, and management of containers. However, the standard mode of\nusing runC is similar to [systemd nspawn](https://www.freedesktop.org/software/systemd/man/systemd-nspawn.html)\nin that it is tooling intended to be invoked by root.\n\nThe bubblewrap authors believe that runc and systemd-nspawn are not\ndesigned to be made setuid, and are distant from supporting such a mode.\nHowever with rootless containers, runC will be able to fulfill certain usecases\nthat bubblewrap supports (with the added benefit of being a standardised and\ncomplete OCI runtime).\n\n[binctr](https://github.com/jfrazelle/binctr) is just a wrapper for\nrunC, so inherits all of its design tradeoffs.\n\nWhat's with the name?!\n----------------------\n\nThe name bubblewrap was chosen to convey that this\ntool runs as the parent of the application (so wraps it in some sense) and creates\na protective layer (the sandbox) around it.\n\n![](bubblewrap.jpg)\n\n(Bubblewrap cat by [dancing_stupidity](https://www.flickr.com/photos/27549668@N03/))\n",
      "stars_today": 21
    },
    {
      "id": 132464395,
      "name": "JavaGuide",
      "full_name": "Snailclimb/JavaGuide",
      "description": "Java Â≠¶‰π†&Èù¢ËØïÊåáÂçóÔºàGo„ÄÅPython ÂêéÁ´ØÈù¢ËØïÈÄöÁî®,ËÆ°ÁÆóÊú∫Âü∫Á°ÄÈù¢ËØïÊÄªÁªìÔºâ„ÄÇÂáÜÂ§áÂêéÁ´ØÊäÄÊúØÈù¢ËØïÔºåÈ¶ñÈÄâ JavaGuideÔºÅ",
      "html_url": "https://github.com/Snailclimb/JavaGuide",
      "stars": 153480,
      "forks": 46101,
      "language": "Java",
      "topics": [
        "algorithms",
        "distributed-systems",
        "interview",
        "java",
        "jvm",
        "mysql",
        "redis",
        "redisson",
        "spring",
        "system",
        "system-design",
        "zookeeper"
      ],
      "created_at": "2018-05-07T13:27:00Z",
      "updated_at": "2026-01-16T18:24:56Z",
      "pushed_at": "2026-01-16T13:43:56Z",
      "open_issues": 74,
      "owner": {
        "login": "Snailclimb",
        "avatar_url": "https://avatars.githubusercontent.com/u/29880145?v=4"
      },
      "readme": "- Êé®ËçêÂú®Á∫øÈòÖËØªÔºà‰ΩìÈ™åÊõ¥Â•ΩÔºåÈÄüÂ∫¶Êõ¥Âø´ÔºâÔºö[javaguide.cn](https://javaguide.cn/)\n- Èù¢ËØïÁ™ÅÂáªÁâàÊú¨ÔºàÂè™‰øùÁïôÈáçÁÇπÔºåÈôÑÂ∏¶Á≤æÁæé PDF ‰∏ãËΩΩÔºâÔºö[interview.javaguide.cn](https://interview.javaguide.cn/)\n\n<div align=\"center\">\n\n[![logo](https://oss.javaguide.cn/github/javaguide/csdn/1c00413c65d1995993bf2b0daf7b4f03.png)](https://github.com/Snailclimb/JavaGuide)\n\n[GitHub](https://github.com/Snailclimb/JavaGuide) | [Gitee](https://gitee.com/SnailClimb/JavaGuide)\n\n<a href=\"https://trendshift.io/repositories/1319\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/1319\" alt=\"Snailclimb%2FJavaGuide | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n</div>\n\n> - **ÂÆûÊàòÈ°πÁõÆ**Ôºö\n>   - [‚≠êAI Êô∫ËÉΩÈù¢ËØïËæÖÂä©Âπ≥Âè∞ + RAG Áü•ËØÜÂ∫ì](https://javaguide.cn/zhuanlan/interview-guide.html)ÔºöÂü∫‰∫é Spring Boot 4.0 + Java 21 + Spring AI 2.0 ÂºÄÂèë„ÄÇÈùûÂ∏∏ÈÄÇÂêà‰Ωú‰∏∫Â≠¶‰π†ÂíåÁÆÄÂéÜÈ°πÁõÆÔºåÂ≠¶‰π†Èó®Êßõ‰ΩéÔºåÂ∏ÆÂä©ÊèêÂçáÊ±ÇËÅåÁ´û‰∫âÂäõÔºåÊòØ‰∏ªÊâìÂ∞±‰∏öÁöÑÂÆûÊàòÈ°πÁõÆ„ÄÇ\n>   - [ÊâãÂÜô RPC Ê°ÜÊû∂](https://javaguide.cn/zhuanlan/handwritten-rpc-framework.html)Ôºö‰ªéÈõ∂ÂºÄÂßãÂü∫‰∫é Netty+Kyro+Zookeeper ÂÆûÁé∞‰∏Ä‰∏™ÁÆÄÊòìÁöÑ RPC Ê°ÜÊû∂„ÄÇÈ∫ªÈõÄËôΩÂ∞è‰∫îËÑè‰ø±ÂÖ®ÔºåÈ°πÁõÆ‰ª£Á†ÅÊ≥®ÈáäËØ¶ÁªÜÔºåÁªìÊûÑÊ∏ÖÊô∞„ÄÇ\n> - **Èù¢ËØïËµÑÊñôË°•ÂÖÖ**Ôºö\n>   - [„ÄäJava Èù¢ËØïÊåáÂåó„Äã](https://javaguide.cn/zhuanlan/java-mian-shi-zhi-bei.html)ÔºöÂõõÂπ¥ÊâìÁ£®ÔºåÂíå [JavaGuide ÂºÄÊ∫êÁâà](https://javaguide.cn/)ÁöÑÂÜÖÂÆπ‰∫íË°•ÔºåÂ∏¶‰Ω†‰ªéÈõ∂ÂºÄÂßãÁ≥ªÁªüÂáÜÂ§áÈù¢ËØïÔºÅ\n>   - [„ÄäÂêéÁ´ØÈù¢ËØïÈ´òÈ¢ëÁ≥ªÁªüËÆæËÆ°&Âú∫ÊôØÈ¢ò„Äã](https://javaguide.cn/zhuanlan/back-end-interview-high-frequency-system-design-and-scenario-questions.html)Ôºö30+ ÈÅìÈ´òÈ¢ëÁ≥ªÁªüËÆæËÆ°ÂíåÂú∫ÊôØÈù¢ËØïÔºåÂä©‰Ω†Â∫îÂØπÂΩì‰∏ã‰∏≠Â§ßÂéÇÈù¢ËØïË∂ãÂäø„ÄÇ\n> - **‰ΩøÁî®Âª∫ËÆÆ** ÔºöÊúâÊ∞¥Âπ≥ÁöÑÈù¢ËØïÂÆòÈÉΩÊòØÈ°∫ÁùÄÈ°πÁõÆÁªèÂéÜÊåñÊéòÊäÄÊúØÈóÆÈ¢ò„ÄÇ‰∏ÄÂÆö‰∏çË¶ÅÊ≠ªËÆ∞Á°¨ËÉåÊäÄÊúØÂÖ´ËÇ°ÊñáÔºÅËØ¶ÁªÜÁöÑÂ≠¶‰π†Âª∫ËÆÆËØ∑ÂèÇËÄÉÔºö[JavaGuide ‰ΩøÁî®Âª∫ËÆÆ](https://javaguide.cn/javaguide/use-suggestion.html)„ÄÇ\n> - **Ê±Ç‰∏™ Star**ÔºöÂ¶ÇÊûúËßâÂæó JavaGuide ÁöÑÂÜÖÂÆπÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÁöÑËØùÔºåËøòËØ∑ÁÇπ‰∏™ÂÖçË¥πÁöÑ StarÔºåËøôÊòØÂØπÊàëÊúÄÂ§ßÁöÑÈºìÂä±ÔºåÊÑüË∞¢ÂêÑ‰Ωç‰∏ÄËµ∑ÂêåË°åÔºåÂÖ±ÂãâÔºÅ‰º†ÈÄÅÈó®Ôºö[GitHub](https://github.com/Snailclimb/JavaGuide) | [Gitee](https://gitee.com/SnailClimb/JavaGuide)„ÄÇ\n> - **ËΩ¨ËΩΩÈ°ªÁü•**Ôºö‰ª•‰∏ãÊâÄÊúâÊñáÁ´†Â¶ÇÈùûÊñáÈ¶ñËØ¥Êòé‰∏∫ËΩ¨ËΩΩÁöÜ‰∏∫ JavaGuide ÂéüÂàõÔºåËΩ¨ËΩΩËØ∑Âú®ÊñáÈ¶ñÊ≥®ÊòéÂá∫Â§Ñ„ÄÇÂ¶ÇÂèëÁé∞ÊÅ∂ÊÑèÊäÑË¢≠/Êê¨ËøêÔºå‰ºöÂä®Áî®Ê≥ïÂæãÊ≠¶Âô®Áª¥Êä§Ëá™Â∑±ÁöÑÊùÉÁõä„ÄÇËÆ©Êàë‰ª¨‰∏ÄËµ∑Áª¥Êä§‰∏Ä‰∏™ËâØÂ•ΩÁöÑÊäÄÊúØÂàõ‰ΩúÁéØÂ¢ÉÔºÅ\n\n<!-- #region home -->\n\n## Èù¢ËØïÁ™ÅÂáªÁâàÊú¨\n\nÂæàÂ§öÂêåÂ≠¶Êúâ‚Äú‰∏¥Êó∂Á™ÅÂáªÈù¢ËØï‚ÄùÁöÑÈúÄÊ±ÇÔºåÊâÄ‰ª•Êàë‰∏ìÈó®ÂÅö‰∫Ü‰∏Ä‰∏™ [JavaGuide Èù¢ËØïÁ™ÅÂáªÁâà](https://interview.javaguide.cn/home.html)ÔºöÂú® [JavaGuide](https://javaguide.cn/home.html) ÂéüÊúâÂÜÖÂÆπÂü∫Á°Ä‰∏äÂÅö‰∫ÜÂ§ßÂπÖÁ≤æÁÆÄÔºåÂè™‰øùÁïôÈ´òÈ¢ëÂøÖËÄÉÈáçÁÇπÔºåÂπ∂‰∏ÄÁõ¥ÊåÅÁª≠Êõ¥Êñ∞„ÄÇ\n\nÂú®Ëøô‰∫õ‚ÄúÁ≤æÁÆÄÂêéÁöÑÈáçÁÇπ‚ÄùÈáåÔºåÊàëÂèàÈ¢ùÂ§ñÁî® ‚≠êÔ∏è Ê†áÂá∫‰∫Ü**ÈáçÁÇπ‰∏≠ÁöÑÈáçÁÇπ**ÔºåÊñπ‰æø‰Ω†‰ºòÂÖàÊµèËßà„ÄÅÂø´ÈÄüËÆ∞ÂøÜ„ÄÇ\n\nÂêåÊó∂Êèê‰æõ‰∫ÆËâ≤ÔºàÁôΩÂ§©ÔºâÂíåÊöóËâ≤ÔºàÂ§úÈó¥ÔºâPDFÔºå**ÈúÄË¶ÅÊâìÂç∞ÁöÑÂêåÂ≠¶ËÆ∞ÂæóÈÄâ‰∫ÆËâ≤ÁâàÊú¨**ÔºåÁ∫∏Ë¥®ÈòÖËØª‰ΩìÈ™å‰ºöÊõ¥Â•Ω„ÄÇ\n\nÂ¶ÇÊûú‰Ω†**Êó∂Èó¥ÊØîËæÉÂÖÖË£ï**ÔºåÊõ¥Êé®ËçêÁõ¥Êé•Âú® [JavaGuide ÂÆòÁΩë](https://javaguide.cn/) ‰∏ä**Á≥ªÁªüÂ≠¶‰π†**ÔºöÂÜÖÂÆπÊØîÁ™ÅÂáªÁâàÊõ¥ÂÖ®Èù¢„ÄÅÊõ¥Ê∑±ÂÖ•ÔºåÊõ¥ÈÄÇÂêàÊâìÂü∫Á°ÄÂíåÈïøÊúüÊèêÂçá„ÄÇ\n\n**Á™ÅÂáªÁâàÊú¨ÁΩëÁ´ôÂÖ•Âè£**Ôºö[interview.javaguide.cn](https://interview.javaguide.cn/)\n\nÂØπÂ∫îÁöÑ PDF ÁâàÊú¨ÔºåÂèØ‰ª•Áõ¥Êé•Âú®ÂÖ¨‰ºóÂè∑ÂêéÂè∞ÂõûÂ§ç‚Äú**PDF**‚ÄùËé∑ÂèñÔºö\n\n<img src=\"https://oss.javaguide.cn/github/javaguide/gongzhonghao-javaguide.png\" alt=\"JavaGuide ÂÖ¨‰ºóÂè∑\"  style=\"zoom: 43%; display: block; margin: 0 auto;\" />\n\n## Java\n\n### Âü∫Á°Ä\n\n**Áü•ËØÜÁÇπ/Èù¢ËØïÈ¢òÊÄªÁªì** : (ÂøÖÁúã:+1: )Ôºö\n\n- [Java Âü∫Á°ÄÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ä)](./docs/java/basis/java-basic-questions-01.md)\n- [Java Âü∫Á°ÄÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏≠)](./docs/java/basis/java-basic-questions-02.md)\n- [Java Âü∫Á°ÄÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ã)](./docs/java/basis/java-basic-questions-03.md)\n\n**ÈáçË¶ÅÁü•ËØÜÁÇπËØ¶Ëß£**Ôºö\n\n- [‰∏∫‰ªÄ‰πà Java ‰∏≠Âè™ÊúâÂÄº‰º†ÈÄíÔºü](./docs/java/basis/why-there-only-value-passing-in-java.md)\n- [Java Â∫èÂàóÂåñËØ¶Ëß£](./docs/java/basis/serialization.md)\n- [Ê≥õÂûã&ÈÄöÈÖçÁ¨¶ËØ¶Ëß£](./docs/java/basis/generics-and-wildcards.md)\n- [Java ÂèçÂ∞ÑÊú∫Âà∂ËØ¶Ëß£](./docs/java/basis/reflection.md)\n- [Java ‰ª£ÁêÜÊ®°ÂºèËØ¶Ëß£](./docs/java/basis/proxy.md)\n- [BigDecimal ËØ¶Ëß£](./docs/java/basis/bigdecimal.md)\n- [Java È≠îÊ≥ïÁ±ª Unsafe ËØ¶Ëß£](./docs/java/basis/unsafe.md)\n- [Java SPI Êú∫Âà∂ËØ¶Ëß£](./docs/java/basis/spi.md)\n- [Java ËØ≠Ê≥ïÁ≥ñËØ¶Ëß£](./docs/java/basis/syntactic-sugar.md)\n\n### ÈõÜÂêà\n\n**Áü•ËØÜÁÇπ/Èù¢ËØïÈ¢òÊÄªÁªì**Ôºö\n\n- [Java ÈõÜÂêàÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ä)](./docs/java/collection/java-collection-questions-01.md) (ÂøÖÁúã :+1:)\n- [Java ÈõÜÂêàÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ã)](./docs/java/collection/java-collection-questions-02.md) (ÂøÖÁúã :+1:)\n- [Java ÂÆπÂô®‰ΩøÁî®Ê≥®ÊÑè‰∫ãÈ°πÊÄªÁªì](./docs/java/collection/java-collection-precautions-for-use.md)\n\n**Ê∫êÁ†ÅÂàÜÊûê**Ôºö\n\n- [ArrayList Ê†∏ÂøÉÊ∫êÁ†Å+Êâ©ÂÆπÊú∫Âà∂ÂàÜÊûê](./docs/java/collection/arraylist-source-code.md)\n- [LinkedList Ê†∏ÂøÉÊ∫êÁ†ÅÂàÜÊûê](./docs/java/collection/linkedlist-source-code.md)\n- [HashMap Ê†∏ÂøÉÊ∫êÁ†Å+Â∫ïÂ±ÇÊï∞ÊçÆÁªìÊûÑÂàÜÊûê](./docs/java/collection/hashmap-source-code.md)\n- [ConcurrentHashMap Ê†∏ÂøÉÊ∫êÁ†Å+Â∫ïÂ±ÇÊï∞ÊçÆÁªìÊûÑÂàÜÊûê](./docs/java/collection/concurrent-hash-map-source-code.md)\n- [LinkedHashMap Ê†∏ÂøÉÊ∫êÁ†ÅÂàÜÊûê](./docs/java/collection/linkedhashmap-source-code.md)\n- [CopyOnWriteArrayList Ê†∏ÂøÉÊ∫êÁ†ÅÂàÜÊûê](./docs/java/collection/copyonwritearraylist-source-code.md)\n- [ArrayBlockingQueue Ê†∏ÂøÉÊ∫êÁ†ÅÂàÜÊûê](./docs/java/collection/arrayblockingqueue-source-code.md)\n- [PriorityQueue Ê†∏ÂøÉÊ∫êÁ†ÅÂàÜÊûê](./docs/java/collection/priorityqueue-source-code.md)\n- [DelayQueue Ê†∏ÂøÉÊ∫êÁ†ÅÂàÜÊûê](./docs/java/collection/delayqueue-source-code.md)\n\n### IO\n\n- [IO Âü∫Á°ÄÁü•ËØÜÊÄªÁªì](./docs/java/io/io-basis.md)\n- [IO ËÆæËÆ°Ê®°ÂºèÊÄªÁªì](./docs/java/io/io-design-patterns.md)\n- [IO Ê®°ÂûãËØ¶Ëß£](./docs/java/io/io-model.md)\n- [NIO Ê†∏ÂøÉÁü•ËØÜÊÄªÁªì](./docs/java/io/nio-basis.md)\n\n### Âπ∂Âèë\n\n**Áü•ËØÜÁÇπ/Èù¢ËØïÈ¢òÊÄªÁªì** : (ÂøÖÁúã :+1:)\n\n- [Java Âπ∂ÂèëÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªìÔºà‰∏äÔºâ](./docs/java/concurrent/java-concurrent-questions-01.md)\n- [Java Âπ∂ÂèëÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªìÔºà‰∏≠Ôºâ](./docs/java/concurrent/java-concurrent-questions-02.md)\n- [Java Âπ∂ÂèëÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªìÔºà‰∏ãÔºâ](./docs/java/concurrent/java-concurrent-questions-03.md)\n\n**ÈáçË¶ÅÁü•ËØÜÁÇπËØ¶Ëß£**Ôºö\n\n- [‰πêËßÇÈîÅÂíåÊÇ≤ËßÇÈîÅËØ¶Ëß£](./docs/java/concurrent/optimistic-lock-and-pessimistic-lock.md)\n- [CAS ËØ¶Ëß£](./docs/java/concurrent/cas.md)\n- [JMMÔºàJava ÂÜÖÂ≠òÊ®°ÂûãÔºâËØ¶Ëß£](./docs/java/concurrent/jmm.md)\n- **Á∫øÁ®ãÊ±†**Ôºö[Java Á∫øÁ®ãÊ±†ËØ¶Ëß£](./docs/java/concurrent/java-thread-pool-summary.md)„ÄÅ[Java Á∫øÁ®ãÊ±†ÊúÄ‰Ω≥ÂÆûË∑µ](./docs/java/concurrent/java-thread-pool-best-practices.md)\n- [ThreadLocal ËØ¶Ëß£](./docs/java/concurrent/threadlocal.md)\n- [Java Âπ∂ÂèëÂÆπÂô®ÊÄªÁªì](./docs/java/concurrent/java-concurrent-collections.md)\n- [Atomic ÂéüÂ≠êÁ±ªÊÄªÁªì](./docs/java/concurrent/atomic-classes.md)\n- [AQS ËØ¶Ëß£](./docs/java/concurrent/aqs.md)\n- [CompletableFuture ËØ¶Ëß£](./docs/java/concurrent/completablefuture-intro.md)\n\n### JVM (ÂøÖÁúã :+1:)\n\nJVM ËøôÈÉ®ÂàÜÂÜÖÂÆπ‰∏ªË¶ÅÂèÇËÄÉ [JVM ËôöÊãüÊú∫ËßÑËåÉ-Java8](https://docs.oracle.com/javase/specs/jvms/se8/html/index.html) ÂíåÂë®ÂøóÊòéËÄÅÂ∏àÁöÑ[„ÄäÊ∑±ÂÖ•ÁêÜËß£ Java ËôöÊãüÊú∫ÔºàÁ¨¨ 3 ÁâàÔºâ„Äã](https://book.douban.com/subject/34907497/) ÔºàÂº∫ÁÉàÂª∫ËÆÆÈòÖËØªÂ§öÈÅçÔºÅÔºâ„ÄÇ\n\n- **[Java ÂÜÖÂ≠òÂå∫Âüü](./docs/java/jvm/memory-area.md)**\n- **[JVM ÂûÉÂúæÂõûÊî∂](./docs/java/jvm/jvm-garbage-collection.md)**\n- [Á±ªÊñá‰ª∂ÁªìÊûÑ](./docs/java/jvm/class-file-structure.md)\n- **[Á±ªÂä†ËΩΩËøáÁ®ã](./docs/java/jvm/class-loading-process.md)**\n- [Á±ªÂä†ËΩΩÂô®](./docs/java/jvm/classloader.md)\n- [„ÄêÂæÖÂÆåÊàê„ÄëÊúÄÈáçË¶ÅÁöÑ JVM ÂèÇÊï∞ÊÄªÁªìÔºàÁøªËØëÂÆåÂñÑ‰∫Ü‰∏ÄÂçäÔºâ](./docs/java/jvm/jvm-parameters-intro.md)\n- [„ÄêÂä†È§ê„ÄëÂ§ßÁôΩËØùÂ∏¶‰Ω†ËÆ§ËØÜ JVM](./docs/java/jvm/jvm-intro.md)\n- [JDK ÁõëÊéßÂíåÊïÖÈöúÂ§ÑÁêÜÂ∑•ÂÖ∑](./docs/java/jvm/jdk-monitoring-and-troubleshooting-tools.md)\n\n### Êñ∞ÁâπÊÄß\n\n- **Java 8**Ôºö[Java 8 Êñ∞ÁâπÊÄßÊÄªÁªìÔºàÁøªËØëÔºâ](./docs/java/new-features/java8-tutorial-translate.md)„ÄÅ[Java8 Â∏∏Áî®Êñ∞ÁâπÊÄßÊÄªÁªì](./docs/java/new-features/java8-common-new-features.md)\n- [Java 9 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java9.md)\n- [Java 10 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java10.md)\n- [Java 11 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java11.md)\n- [Java 12 & 13 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java12-13.md)\n- [Java 14 & 15 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java14-15.md)\n- [Java 16 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java16.md)\n- [Java 17 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java17.md)\n- [Java 18 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java18.md)\n- [Java 19 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java19.md)\n- [Java 20 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java20.md)\n- [Java 21 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java21.md)\n- [Java 22 & 23 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java22-23.md)\n- [Java 24 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java24.md)\n- [Java 25 Êñ∞ÁâπÊÄßÊ¶ÇËßà](./docs/java/new-features/java25.md)\n\n## ËÆ°ÁÆóÊú∫Âü∫Á°Ä\n\n### Êìç‰ΩúÁ≥ªÁªü\n\n- [Êìç‰ΩúÁ≥ªÁªüÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ä)](./docs/cs-basics/operating-system/operating-system-basic-questions-01.md)\n- [Êìç‰ΩúÁ≥ªÁªüÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ã)](./docs/cs-basics/operating-system/operating-system-basic-questions-02.md)\n- **Linux**Ôºö\n  - [ÂêéÁ´ØÁ®ãÂ∫èÂëòÂøÖÂ§áÁöÑ Linux Âü∫Á°ÄÁü•ËØÜÊÄªÁªì](./docs/cs-basics/operating-system/linux-intro.md)\n  - [Shell ÁºñÁ®ãÂü∫Á°ÄÁü•ËØÜÊÄªÁªì](./docs/cs-basics/operating-system/shell-intro.md)\n\n### ÁΩëÁªú\n\n**Áü•ËØÜÁÇπ/Èù¢ËØïÈ¢òÊÄªÁªì**Ôºö\n\n- [ËÆ°ÁÆóÊú∫ÁΩëÁªúÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ä)](./docs/cs-basics/network/other-network-questions.md)\n- [ËÆ°ÁÆóÊú∫ÁΩëÁªúÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ã)](./docs/cs-basics/network/other-network-questions2.md)\n- [Ë∞¢Â∏å‰ªÅËÄÅÂ∏àÁöÑ„ÄäËÆ°ÁÆóÊú∫ÁΩëÁªú„ÄãÂÜÖÂÆπÊÄªÁªìÔºàË°•ÂÖÖÔºâ](./docs/cs-basics/network/computer-network-xiexiren-summary.md)\n\n**ÈáçË¶ÅÁü•ËØÜÁÇπËØ¶Ëß£**Ôºö\n\n- [OSI Âíå TCP/IP ÁΩëÁªúÂàÜÂ±ÇÊ®°ÂûãËØ¶Ëß£ÔºàÂü∫Á°ÄÔºâ](./docs/cs-basics/network/osi-and-tcp-ip-model.md)\n- [Â∫îÁî®Â±ÇÂ∏∏ËßÅÂçèËÆÆÊÄªÁªìÔºàÂ∫îÁî®Â±ÇÔºâ](./docs/cs-basics/network/application-layer-protocol.md)\n- [HTTP vs HTTPSÔºàÂ∫îÁî®Â±ÇÔºâ](./docs/cs-basics/network/http-vs-https.md)\n- [HTTP 1.0 vs HTTP 1.1ÔºàÂ∫îÁî®Â±ÇÔºâ](./docs/cs-basics/network/http1.0-vs-http1.1.md)\n- [HTTP Â∏∏ËßÅÁä∂ÊÄÅÁ†ÅÔºàÂ∫îÁî®Â±ÇÔºâ](./docs/cs-basics/network/http-status-codes.md)\n- [DNS ÂüüÂêçÁ≥ªÁªüËØ¶Ëß£ÔºàÂ∫îÁî®Â±ÇÔºâ](./docs/cs-basics/network/dns.md)\n- [TCP ‰∏âÊ¨°Êè°ÊâãÂíåÂõõÊ¨°Êå•ÊâãÔºà‰º†ËæìÂ±ÇÔºâ](./docs/cs-basics/network/tcp-connection-and-disconnection.md)\n- [TCP ‰º†ËæìÂèØÈù†ÊÄß‰øùÈöúÔºà‰º†ËæìÂ±ÇÔºâ](./docs/cs-basics/network/tcp-reliability-guarantee.md)\n- [ARP ÂçèËÆÆËØ¶Ëß£(ÁΩëÁªúÂ±Ç)](./docs/cs-basics/network/arp.md)\n- [NAT ÂçèËÆÆËØ¶Ëß£(ÁΩëÁªúÂ±Ç)](./docs/cs-basics/network/nat.md)\n- [ÁΩëÁªúÊîªÂáªÂ∏∏ËßÅÊâãÊÆµÊÄªÁªìÔºàÂÆâÂÖ®Ôºâ](./docs/cs-basics/network/network-attack-means.md)\n\n### Êï∞ÊçÆÁªìÊûÑ\n\n**ÂõæËß£Êï∞ÊçÆÁªìÊûÑÔºö**\n\n- [Á∫øÊÄßÊï∞ÊçÆÁªìÊûÑ :Êï∞ÁªÑ„ÄÅÈìæË°®„ÄÅÊ†à„ÄÅÈòüÂàó](./docs/cs-basics/data-structure/linear-data-structure.md)\n- [Âõæ](./docs/cs-basics/data-structure/graph.md)\n- [Â†Ü](./docs/cs-basics/data-structure/heap.md)\n- [Ê†ë](./docs/cs-basics/data-structure/tree.md)ÔºöÈáçÁÇπÂÖ≥Ê≥®[Á∫¢ÈªëÊ†ë](./docs/cs-basics/data-structure/red-black-tree.md)„ÄÅB-ÔºåB+ÔºåB\\*Ê†ë„ÄÅLSM Ê†ë\n\nÂÖ∂‰ªñÂ∏∏Áî®Êï∞ÊçÆÁªìÊûÑÔºö\n\n- [Â∏ÉÈöÜËøáÊª§Âô®](./docs/cs-basics/data-structure/bloom-filter.md)\n\n### ÁÆóÊ≥ï\n\nÁÆóÊ≥ïËøôÈÉ®ÂàÜÂÜÖÂÆπÈùûÂ∏∏ÈáçË¶ÅÔºåÂ¶ÇÊûú‰Ω†‰∏çÁü•ÈÅìÂ¶Ç‰ΩïÂ≠¶‰π†ÁÆóÊ≥ïÁöÑËØùÔºåÂèØ‰ª•Áúã‰∏ãÊàëÂÜôÁöÑÔºö\n\n- [ÁÆóÊ≥ïÂ≠¶‰π†‰π¶Á±ç+ËµÑÊ∫êÊé®Ëçê](https://www.zhihu.com/question/323359308/answer/1545320858) „ÄÇ\n- [Â¶Ç‰ΩïÂà∑ Leetcode?](https://www.zhihu.com/question/31092580/answer/1534887374)\n\n**Â∏∏ËßÅÁÆóÊ≥ïÈóÆÈ¢òÊÄªÁªì**Ôºö\n\n- [Âá†ÈÅìÂ∏∏ËßÅÁöÑÂ≠óÁ¨¶‰∏≤ÁÆóÊ≥ïÈ¢òÊÄªÁªì](./docs/cs-basics/algorithms/string-algorithm-problems.md)\n- [Âá†ÈÅìÂ∏∏ËßÅÁöÑÈìæË°®ÁÆóÊ≥ïÈ¢òÊÄªÁªì](./docs/cs-basics/algorithms/linkedlist-algorithm-problems.md)\n- [ÂâëÊåá offer ÈÉ®ÂàÜÁºñÁ®ãÈ¢ò](./docs/cs-basics/algorithms/the-sword-refers-to-offer.md)\n- [ÂçÅÂ§ßÁªèÂÖ∏ÊéíÂ∫èÁÆóÊ≥ï](./docs/cs-basics/algorithms/10-classical-sorting-algorithms.md)\n\nÂè¶Â§ñÔºå[GeeksforGeeks](https://www.geeksforgeeks.org/fundamentals-of-algorithms/) Ëøô‰∏™ÁΩëÁ´ôÊÄªÁªì‰∫ÜÂ∏∏ËßÅÁöÑÁÆóÊ≥ï ÔºåÊØîËæÉÂÖ®Èù¢Á≥ªÁªü„ÄÇ\n\n## Êï∞ÊçÆÂ∫ì\n\n### Âü∫Á°Ä\n\n- [Êï∞ÊçÆÂ∫ìÂü∫Á°ÄÁü•ËØÜÊÄªÁªì](./docs/database/basis.md)\n- [NoSQL Âü∫Á°ÄÁü•ËØÜÊÄªÁªì](./docs/database/nosql.md)\n- [Â≠óÁ¨¶ÈõÜËØ¶Ëß£](./docs/database/character-set.md)\n- SQL :\n  - [SQL ËØ≠Ê≥ïÂü∫Á°ÄÁü•ËØÜÊÄªÁªì](./docs/database/sql/sql-syntax-summary.md)\n  - [SQL Â∏∏ËßÅÈù¢ËØïÈ¢òÊÄªÁªì](./docs/database/sql/sql-questions-01.md)\n\n### MySQL\n\n**Áü•ËØÜÁÇπ/Èù¢ËØïÈ¢òÊÄªÁªìÔºö**\n\n- **[MySQL Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](./docs/database/mysql/mysql-questions-01.md)** (ÂøÖÁúã :+1:)\n- [MySQL È´òÊÄßËÉΩ‰ºòÂåñËßÑËåÉÂª∫ËÆÆÊÄªÁªì](./docs/database/mysql/mysql-high-performance-optimization-specification-recommendations.md)\n\n**ÈáçË¶ÅÁü•ËØÜÁÇπÔºö**\n\n- [MySQL Á¥¢ÂºïËØ¶Ëß£](./docs/database/mysql/mysql-index.md)\n- [MySQL ‰∫ãÂä°ÈöîÁ¶ªÁ∫ßÂà´ÂõæÊñáËØ¶Ëß£)](./docs/database/mysql/transaction-isolation-level.md)\n- [MySQL ‰∏âÂ§ßÊó•Âøó(binlog„ÄÅredo log Âíå undo log)ËØ¶Ëß£](./docs/database/mysql/mysql-logs.md)\n- [InnoDB Â≠òÂÇ®ÂºïÊìéÂØπ MVCC ÁöÑÂÆûÁé∞](./docs/database/mysql/innodb-implementation-of-mvcc.md)\n- [SQL ËØ≠Âè•Âú® MySQL ‰∏≠ÁöÑÊâßË°åËøáÁ®ã](./docs/database/mysql/how-sql-executed-in-mysql.md)\n- [MySQL Êü•ËØ¢ÁºìÂ≠òËØ¶Ëß£](./docs/database/mysql/mysql-query-cache.md)\n- [MySQL ÊâßË°åËÆ°ÂàíÂàÜÊûê](./docs/database/mysql/mysql-query-execution-plan.md)\n- [MySQL Ëá™Â¢û‰∏ªÈîÆ‰∏ÄÂÆöÊòØËøûÁª≠ÁöÑÂêó](./docs/database/mysql/mysql-auto-increment-primary-key-continuous.md)\n- [MySQL Êó∂Èó¥Á±ªÂûãÊï∞ÊçÆÂ≠òÂÇ®Âª∫ËÆÆ](./docs/database/mysql/some-thoughts-on-database-storage-time.md)\n- [MySQL ÈöêÂºèËΩ¨Êç¢ÈÄ†ÊàêÁ¥¢ÂºïÂ§±Êïà](./docs/database/mysql/index-invalidation-caused-by-implicit-conversion.md)\n\n### Redis\n\n**Áü•ËØÜÁÇπ/Èù¢ËØïÈ¢òÊÄªÁªì** : (ÂøÖÁúã:+1: )Ôºö\n\n- [Redis Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ä)](./docs/database/redis/redis-questions-01.md)\n- [Redis Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ã)](./docs/database/redis/redis-questions-02.md)\n\n**ÈáçË¶ÅÁü•ËØÜÁÇπÔºö**\n\n- [3 ÁßçÂ∏∏Áî®ÁöÑÁºìÂ≠òËØªÂÜôÁ≠ñÁï•ËØ¶Ëß£](./docs/database/redis/3-commonly-used-cache-read-and-write-strategies.md)\n- [Redis 5 ÁßçÂü∫Êú¨Êï∞ÊçÆÁªìÊûÑËØ¶Ëß£](./docs/database/redis/redis-data-structures-01.md)\n- [Redis 3 ÁßçÁâπÊÆäÊï∞ÊçÆÁªìÊûÑËØ¶Ëß£](./docs/database/redis/redis-data-structures-02.md)\n- [Redis ÊåÅ‰πÖÂåñÊú∫Âà∂ËØ¶Ëß£](./docs/database/redis/redis-persistence.md)\n- [Redis ÂÜÖÂ≠òÁ¢éÁâáËØ¶Ëß£](./docs/database/redis/redis-memory-fragmentation.md)\n- [Redis Â∏∏ËßÅÈòªÂ°ûÂéüÂõ†ÊÄªÁªì](./docs/database/redis/redis-common-blocking-problems-summary.md)\n- [Redis ÈõÜÁæ§ËØ¶Ëß£](./docs/database/redis/redis-cluster.md)\n\n### MongoDB\n\n- [MongoDB Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ä)](./docs/database/mongodb/mongodb-questions-01.md)\n- [MongoDB Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì(‰∏ã)](./docs/database/mongodb/mongodb-questions-02.md)\n\n## ÊêúÁ¥¢ÂºïÊìé\n\n[Elasticsearch Â∏∏ËßÅÈù¢ËØïÈ¢òÊÄªÁªì(‰ªòË¥π)](./docs/database/elasticsearch/elasticsearch-questions-01.md)\n\n![JavaGuide ÂÆòÊñπÂÖ¨‰ºóÂè∑](https://oss.javaguide.cn/github/javaguide/gongzhonghaoxuanchuan.png)\n\n## ÂºÄÂèëÂ∑•ÂÖ∑\n\n### Maven\n\n- [Maven Ê†∏ÂøÉÊ¶ÇÂøµÊÄªÁªì](./docs/tools/maven/maven-core-concepts.md)\n- [Maven ÊúÄ‰Ω≥ÂÆûË∑µ](./docs/tools/maven/maven-best-practices.md)\n\n### Gradle\n\n[Gradle Ê†∏ÂøÉÊ¶ÇÂøµÊÄªÁªì](./docs/tools/gradle/gradle-core-concepts.md)ÔºàÂèØÈÄâÔºåÁõÆÂâçÂõΩÂÜÖËøòÊòØ‰ΩøÁî® Maven ÊôÆÈÅç‰∏Ä‰∫õÔºâ\n\n### Docker\n\n- [Docker Ê†∏ÂøÉÊ¶ÇÂøµÊÄªÁªì](./docs/tools/docker/docker-intro.md)\n- [Docker ÂÆûÊàò](./docs/tools/docker/docker-in-action.md)\n\n### Git\n\n- [Git Ê†∏ÂøÉÊ¶ÇÂøµÊÄªÁªì](./docs/tools/git/git-intro.md)\n- [GitHub ÂÆûÁî®Â∞èÊäÄÂ∑ßÊÄªÁªì](./docs/tools/git/github-tips.md)\n\n## Á≥ªÁªüËÆæËÆ°\n\n- [Á≥ªÁªüËÆæËÆ°Â∏∏ËßÅÈù¢ËØïÈ¢òÊÄªÁªì](./docs/system-design/system-design-questions.md)\n- [ËÆæËÆ°Ê®°ÂºèÂ∏∏ËßÅÈù¢ËØïÈ¢òÊÄªÁªì](./docs/system-design/design-pattern.md)\n\n### Âü∫Á°Ä\n\n- [RestFul API ÁÆÄÊòéÊïôÁ®ã](./docs/system-design/basis/RESTfulAPI.md)\n- [ËΩØ‰ª∂Â∑•Á®ãÁÆÄÊòéÊïôÁ®ã](./docs/system-design/basis/software-engineering.md)\n- [‰ª£Á†ÅÂëΩÂêçÊåáÂçó](./docs/system-design/basis/naming.md)\n- [‰ª£Á†ÅÈáçÊûÑÊåáÂçó](./docs/system-design/basis/refactoring.md)\n- [ÂçïÂÖÉÊµãËØïÊåáÂçó](./docs/system-design/basis/unit-test.md)\n\n### Â∏∏Áî®Ê°ÜÊû∂\n\n#### Spring/SpringBoot (ÂøÖÁúã :+1:)\n\n**Áü•ËØÜÁÇπ/Èù¢ËØïÈ¢òÊÄªÁªì** :\n\n- [Spring Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](./docs/system-design/framework/spring/spring-knowledge-and-questions-summary.md)\n- [SpringBoot Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](./docs/system-design/framework/spring/springboot-knowledge-and-questions-summary.md)\n- [Spring/Spring Boot Â∏∏Áî®Ê≥®Ëß£ÊÄªÁªì](./docs/system-design/framework/spring/spring-common-annotations.md)\n- [SpringBoot ÂÖ•Èó®ÊåáÂçó](https://github.com/Snailclimb/springboot-guide)\n\n**ÈáçË¶ÅÁü•ËØÜÁÇπËØ¶Ëß£**Ôºö\n\n- [IoC & AOPËØ¶Ëß£ÔºàÂø´ÈÄüÊêûÊáÇÔºâ](./docs/system-design/framework/spring/ioc-and-aop.md)\n- [Spring ‰∫ãÂä°ËØ¶Ëß£](./docs/system-design/framework/spring/spring-transaction.md)\n- [Spring ‰∏≠ÁöÑËÆæËÆ°Ê®°ÂºèËØ¶Ëß£](./docs/system-design/framework/spring/spring-design-patterns-summary.md)\n- [SpringBoot Ëá™Âä®Ë£ÖÈÖçÂéüÁêÜËØ¶Ëß£](./docs/system-design/framework/spring/spring-boot-auto-assembly-principles.md)\n\n#### MyBatis\n\n[MyBatis Â∏∏ËßÅÈù¢ËØïÈ¢òÊÄªÁªì](./docs/system-design/framework/mybatis/mybatis-interview.md)\n\n### ÂÆâÂÖ®\n\n#### ËÆ§ËØÅÊéàÊùÉ\n\n- [ËÆ§ËØÅÊéàÊùÉÂü∫Á°ÄÊ¶ÇÂøµËØ¶Ëß£](./docs/system-design/security/basis-of-authority-certification.md)\n- [JWT Âü∫Á°ÄÊ¶ÇÂøµËØ¶Ëß£](./docs/system-design/security/jwt-intro.md)\n- [JWT ‰ºòÁº∫ÁÇπÂàÜÊûê‰ª•ÂèäÂ∏∏ËßÅÈóÆÈ¢òËß£ÂÜ≥ÊñπÊ°à](./docs/system-design/security/advantages-and-disadvantages-of-jwt.md)\n- [SSO ÂçïÁÇπÁôªÂΩïËØ¶Ëß£](./docs/system-design/security/sso-intro.md)\n- [ÊùÉÈôêÁ≥ªÁªüËÆæËÆ°ËØ¶Ëß£](./docs/system-design/security/design-of-authority-system.md)\n\n#### Êï∞ÊçÆÂÆâÂÖ®\n\n- [Â∏∏ËßÅÂä†ÂØÜÁÆóÊ≥ïÊÄªÁªì](./docs/system-design/security/encryption-algorithms.md)\n- [ÊïèÊÑüËØçËøáÊª§ÊñπÊ°àÊÄªÁªì](./docs/system-design/security/sentive-words-filter.md)\n- [Êï∞ÊçÆËÑ±ÊïèÊñπÊ°àÊÄªÁªì](./docs/system-design/security/data-desensitization.md)\n- [‰∏∫‰ªÄ‰πàÂâçÂêéÁ´ØÈÉΩË¶ÅÂÅöÊï∞ÊçÆÊ†°È™å](./docs/system-design/security/data-validation.md)\n\n### ÂÆöÊó∂‰ªªÂä°\n\n[Java ÂÆöÊó∂‰ªªÂä°ËØ¶Ëß£](./docs/system-design/schedule-task.md)\n\n### Web ÂÆûÊó∂Ê∂àÊÅØÊé®ÈÄÅ\n\n[Web ÂÆûÊó∂Ê∂àÊÅØÊé®ÈÄÅËØ¶Ëß£](./docs/system-design/web-real-time-message-push.md)\n\n## ÂàÜÂ∏ÉÂºè\n\n### ÁêÜËÆ∫&ÁÆóÊ≥ï&ÂçèËÆÆ\n\n- [CAP ÁêÜËÆ∫Âíå BASE ÁêÜËÆ∫Ëß£ËØª](https://javaguide.cn/distributed-system/protocol/cap-and-base-theorem.html)\n- [Paxos ÁÆóÊ≥ïËß£ËØª](https://javaguide.cn/distributed-system/protocol/paxos-algorithm.html)\n- [Raft ÁÆóÊ≥ïËß£ËØª](https://javaguide.cn/distributed-system/protocol/raft-algorithm.html)\n- [Gossip ÂçèËÆÆËØ¶Ëß£](https://javaguide.cn/distributed-system/protocol/gossip-protocl.html)\n- [‰∏ÄËá¥ÊÄßÂìàÂ∏åÁÆóÊ≥ïËØ¶Ëß£](https://javaguide.cn/distributed-system/protocol/consistent-hashing.html)\n\n### RPC\n\n- [RPC Âü∫Á°ÄÁü•ËØÜÊÄªÁªì](https://javaguide.cn/distributed-system/rpc/rpc-intro.html)\n- [Dubbo Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](https://javaguide.cn/distributed-system/rpc/dubbo.html)\n\n### ZooKeeper\n\n> Ëøô‰∏§ÁØáÊñáÁ´†ÂèØËÉΩÊúâÂÜÖÂÆπÈáçÂêàÈÉ®ÂàÜÔºåÊé®ËçêÈÉΩÁúã‰∏ÄÈÅç„ÄÇ\n\n- [ZooKeeper Áõ∏ÂÖ≥Ê¶ÇÂøµÊÄªÁªì(ÂÖ•Èó®)](https://javaguide.cn/distributed-system/distributed-process-coordination/zookeeper/zookeeper-intro.html)\n- [ZooKeeper Áõ∏ÂÖ≥Ê¶ÇÂøµÊÄªÁªì(ËøõÈò∂)](https://javaguide.cn/distributed-system/distributed-process-coordination/zookeeper/zookeeper-plus.html)\n\n### API ÁΩëÂÖ≥\n\n- [API ÁΩëÂÖ≥Âü∫Á°ÄÁü•ËØÜÊÄªÁªì](https://javaguide.cn/distributed-system/api-gateway.html)\n- [Spring Cloud Gateway Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](./docs/distributed-system/spring-cloud-gateway-questions.md)\n\n### ÂàÜÂ∏ÉÂºè ID\n\n- [ÂàÜÂ∏ÉÂºèID‰ªãÁªç&ÂÆûÁé∞ÊñπÊ°àÊÄªÁªì](https://javaguide.cn/distributed-system/distributed-id.html)\n- [ÂàÜÂ∏ÉÂºè ID ËÆæËÆ°ÊåáÂçó](https://javaguide.cn/distributed-system/distributed-id-design.html)\n\n### ÂàÜÂ∏ÉÂºèÈîÅ\n\n- [ÂàÜÂ∏ÉÂºèÈîÅ‰ªãÁªç](https://javaguide.cn/distributed-system/distributed-lock.html)\n- [ÂàÜÂ∏ÉÂºèÈîÅÂ∏∏ËßÅÂÆûÁé∞ÊñπÊ°àÊÄªÁªì](https://javaguide.cn/distributed-system/distributed-lock-implementations.html)\n\n### ÂàÜÂ∏ÉÂºè‰∫ãÂä°\n\n[ÂàÜÂ∏ÉÂºè‰∫ãÂä°Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](https://javaguide.cn/distributed-system/distributed-transaction.html)\n\n### ÂàÜÂ∏ÉÂºèÈÖçÁΩÆ‰∏≠ÂøÉ\n\n[ÂàÜÂ∏ÉÂºèÈÖçÁΩÆ‰∏≠ÂøÉÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](./docs/distributed-system/distributed-configuration-center.md)\n\n## È´òÊÄßËÉΩ\n\n### Êï∞ÊçÆÂ∫ì‰ºòÂåñ\n\n- [Êï∞ÊçÆÂ∫ìËØªÂÜôÂàÜÁ¶ªÂíåÂàÜÂ∫ìÂàÜË°®](./docs/high-performance/read-and-write-separation-and-library-subtable.md)\n- [Êï∞ÊçÆÂÜ∑ÁÉ≠ÂàÜÁ¶ª](./docs/high-performance/data-cold-hot-separation.md)\n- [Â∏∏ËßÅ SQL ‰ºòÂåñÊâãÊÆµÊÄªÁªì](./docs/high-performance/sql-optimization.md)\n- [Ê∑±Â∫¶ÂàÜÈ°µ‰ªãÁªçÂèä‰ºòÂåñÂª∫ËÆÆ](./docs/high-performance/deep-pagination-optimization.md)\n\n### Ë¥üËΩΩÂùáË°°\n\n[Ë¥üËΩΩÂùáË°°Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](./docs/high-performance/load-balancing.md)\n\n### CDN\n\n[CDNÔºàÂÜÖÂÆπÂàÜÂèëÁΩëÁªúÔºâÂ∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](./docs/high-performance/cdn.md)\n\n### Ê∂àÊÅØÈòüÂàó\n\n- [Ê∂àÊÅØÈòüÂàóÂü∫Á°ÄÁü•ËØÜÊÄªÁªì](./docs/high-performance/message-queue/message-queue.md)\n- [Disruptor Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](./docs/high-performance/message-queue/disruptor-questions.md)\n- [RabbitMQ Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](./docs/high-performance/message-queue/rabbitmq-questions.md)\n- [RocketMQ Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](./docs/high-performance/message-queue/rocketmq-questions.md)\n- [Kafka Â∏∏ËßÅÁü•ËØÜÁÇπ&Èù¢ËØïÈ¢òÊÄªÁªì](./docs/high-performance/message-queue/kafka-questions-01.md)\n\n## È´òÂèØÁî®\n\n[È´òÂèØÁî®Á≥ªÁªüËÆæËÆ°ÊåáÂçó](./docs/high-availability/high-availability-system-design.md)\n\n### ÂÜó‰ΩôËÆæËÆ°\n\n[ÂÜó‰ΩôËÆæËÆ°ËØ¶Ëß£](./docs/high-availability/redundancy.md)\n\n### ÈôêÊµÅ\n\n[ÊúçÂä°ÈôêÊµÅËØ¶Ëß£](./docs/high-availability/limit-request.md)\n\n### ÈôçÁ∫ß&ÁÜîÊñ≠\n\n[ÈôçÁ∫ß&ÁÜîÊñ≠ËØ¶Ëß£](./docs/high-availability/fallback-and-circuit-breaker.md)\n\n### Ë∂ÖÊó∂&ÈáçËØï\n\n[Ë∂ÖÊó∂&ÈáçËØïËØ¶Ëß£](./docs/high-availability/timeout-and-retry.md)\n\n### ÈõÜÁæ§\n\nÁõ∏ÂêåÁöÑÊúçÂä°ÈÉ®ÁΩ≤Â§ö‰ªΩÔºåÈÅøÂÖçÂçïÁÇπÊïÖÈöú„ÄÇ\n\n### ÁÅæÂ§áËÆæËÆ°ÂíåÂºÇÂú∞Â§öÊ¥ª\n\n**ÁÅæÂ§á** = ÂÆπÁÅæ + Â§á‰ªΩ„ÄÇ\n\n- **Â§á‰ªΩ**ÔºöÂ∞ÜÁ≥ªÁªüÊâÄ‰∫ßÁîüÁöÑÊâÄÊúâÈáçË¶ÅÊï∞ÊçÆÂ§öÂ§á‰ªΩÂá†‰ªΩ„ÄÇ\n- **ÂÆπÁÅæ**ÔºöÂú®ÂºÇÂú∞Âª∫Á´ã‰∏§‰∏™ÂÆåÂÖ®Áõ∏ÂêåÁöÑÁ≥ªÁªü„ÄÇÂΩìÊüê‰∏™Âú∞ÊñπÁöÑÁ≥ªÁªüÁ™ÅÁÑ∂ÊåÇÊéâÔºåÊï¥‰∏™Â∫îÁî®Á≥ªÁªüÂèØ‰ª•ÂàáÊç¢Âà∞Âè¶‰∏Ä‰∏™ÔºåËøôÊ†∑Á≥ªÁªüÂ∞±ÂèØ‰ª•Ê≠£Â∏∏Êèê‰æõÊúçÂä°‰∫Ü„ÄÇ\n\n**ÂºÇÂú∞Â§öÊ¥ª** ÊèèËø∞ÁöÑÊòØÂ∞ÜÊúçÂä°ÈÉ®ÁΩ≤Âú®ÂºÇÂú∞Âπ∂‰∏îÊúçÂä°ÂêåÊó∂ÂØπÂ§ñÊèê‰æõÊúçÂä°„ÄÇÂíå‰º†ÁªüÁöÑÁÅæÂ§áËÆæËÆ°ÁöÑÊúÄ‰∏ªË¶ÅÂå∫Âà´Âú®‰∫é‚ÄúÂ§öÊ¥ª‚ÄùÔºåÂç≥ÊâÄÊúâÁ´ôÁÇπÈÉΩÊòØÂêåÊó∂Âú®ÂØπÂ§ñÊèê‰æõÊúçÂä°ÁöÑ„ÄÇÂºÇÂú∞Â§öÊ¥ªÊòØ‰∏∫‰∫ÜÂ∫îÂØπÁ™ÅÂèëÁä∂ÂÜµÊØîÂ¶ÇÁÅ´ÁÅæ„ÄÅÂú∞ÈúáÁ≠âËá™ÁÑ∂ÊàñËÄÖ‰∫∫‰∏∫ÁÅæÂÆ≥„ÄÇ\n\n## Star Ë∂ãÂäø\n\n![Stars](https://api.star-history.com/svg?repos=Snailclimb/JavaGuide&type=Date)\n\n## ÂÖ¨‰ºóÂè∑\n\nÂ¶ÇÊûúÂ§ßÂÆ∂ÊÉ≥Ë¶ÅÂÆûÊó∂ÂÖ≥Ê≥®ÊàëÊõ¥Êñ∞ÁöÑÊñáÁ´†‰ª•ÂèäÂàÜ‰∫´ÁöÑÂπ≤Ë¥ßÁöÑËØùÔºåÂèØ‰ª•ÂÖ≥Ê≥®ÊàëÁöÑÂÖ¨‰ºóÂè∑„ÄÇ\n\n<img src=\"https://oss.javaguide.cn/github/javaguide/gongzhonghao-javaguide.png\" alt=\"JavaGuide ÂÖ¨‰ºóÂè∑\"  style=\"zoom: 43%; display: block; margin: 0 auto;\" />\n\n<!-- #endregion home -->\n",
      "stars_today": 20
    },
    {
      "id": 27193779,
      "name": "node",
      "full_name": "nodejs/node",
      "description": "Node.js JavaScript runtime ‚ú®üê¢üöÄ‚ú®",
      "html_url": "https://github.com/nodejs/node",
      "stars": 115235,
      "forks": 34396,
      "language": "JavaScript",
      "topics": [
        "javascript",
        "js",
        "linux",
        "macos",
        "mit",
        "node",
        "nodejs",
        "runtime",
        "windows"
      ],
      "created_at": "2014-11-26T19:57:11Z",
      "updated_at": "2026-01-17T00:50:50Z",
      "pushed_at": "2026-01-16T22:00:45Z",
      "open_issues": 2433,
      "owner": {
        "login": "nodejs",
        "avatar_url": "https://avatars.githubusercontent.com/u/9950313?v=4"
      },
      "readme": "# Node.js\n\nNode.js is an open-source, cross-platform JavaScript runtime environment.\n\nFor information on using Node.js, see the [Node.js website][].\n\nThe Node.js project uses an [open governance model](./GOVERNANCE.md). The\n[OpenJS Foundation][] provides support for the project.\n\nContributors are expected to act in a collaborative manner to move\nthe project forward. We encourage the constructive exchange of contrary\nopinions and compromise. The [TSC](./GOVERNANCE.md#technical-steering-committee)\nreserves the right to limit or block contributors who repeatedly act in ways\nthat discourage, exhaust, or otherwise negatively affect other participants.\n\n**This project has a [Code of Conduct][].**\n\n## Table of contents\n\n* [Support](#support)\n* [Release types](#release-types)\n  * [Download](#download)\n    * [Current and LTS releases](#current-and-lts-releases)\n    * [Nightly releases](#nightly-releases)\n    * [API documentation](#api-documentation)\n  * [Verifying binaries](#verifying-binaries)\n* [Building Node.js](#building-nodejs)\n* [Security](#security)\n* [Contributing to Node.js](#contributing-to-nodejs)\n* [Current project team members](#current-project-team-members)\n  * [TSC (Technical Steering Committee)](#tsc-technical-steering-committee)\n  * [Collaborators](#collaborators)\n  * [Triagers](#triagers)\n  * [Release keys](#release-keys)\n* [License](#license)\n\n## Support\n\nLooking for help? Check out the\n[instructions for getting support](.github/SUPPORT.md).\n\n## Release types\n\n* **Current**: Under active development. Code for the Current release is in the\n  branch for its major version number (for example,\n  [v22.x](https://github.com/nodejs/node/tree/v22.x)). Node.js releases a new\n  major version every 6 months, allowing for breaking changes. This happens in\n  April and October every year. Releases appearing each October have a support\n  life of 8 months. Releases appearing each April convert to LTS (see below)\n  each October.\n* **LTS**: Releases that receive Long Term Support, with a focus on stability\n  and security. Every even-numbered major version will become an LTS release.\n  LTS releases receive 12 months of _Active LTS_ support and a further 18 months\n  of _Maintenance_. LTS release lines have alphabetically-ordered code names,\n  beginning with v4 Argon. There are no breaking changes or feature additions,\n  except in some special circumstances.\n* **Nightly**: Code from the Current branch built every 24-hours when there are\n  changes. Use with caution.\n\nCurrent and LTS releases follow [semantic versioning](https://semver.org). A\nmember of the Release Team [signs](#release-keys) each Current and LTS release.\nFor more information, see the\n[Release README](https://github.com/nodejs/Release#readme).\n\n### Download\n\nBinaries, installers, and source tarballs are available at\n<https://nodejs.org/en/download/>.\n\n#### Current and LTS releases\n\n<https://nodejs.org/download/release/>\n\nThe [latest](https://nodejs.org/download/release/latest/) directory is an\nalias for the latest Current release. The latest-_codename_ directory is an\nalias for the latest release from an LTS line. For example, the\n[latest-hydrogen](https://nodejs.org/download/release/latest-hydrogen/)\ndirectory contains the latest Hydrogen (Node.js 18) release.\n\n#### Nightly releases\n\n<https://nodejs.org/download/nightly/>\n\nEach directory and filename includes the version (e.g., `v22.0.0`),\nfollowed by the UTC date (e.g., `20240424` for April 24, 2024),\nand the short commit SHA of the HEAD of the release (e.g., `ddd0a9e494`).\nFor instance, a full directory name might look like `v22.0.0-nightly20240424ddd0a9e494`.\n\n#### API documentation\n\nDocumentation for the latest Current release is at <https://nodejs.org/api/>.\nVersion-specific documentation is available in each release directory in the\n_docs_ subdirectory. Version-specific documentation is also at\n<https://nodejs.org/download/docs/>.\n\n### Verifying binaries\n\nDownload directories contain a `SHASUMS256.txt.asc` file with SHA checksums for the\nfiles and the releaser PGP signature.\n\nYou can get a trusted keyring from nodejs/release-keys, e.g. using `curl`:\n\n```bash\ncurl -fsLo \"/path/to/nodejs-keyring.kbx\" \"https://github.com/nodejs/release-keys/raw/HEAD/gpg/pubring.kbx\"\n```\n\nAlternatively, you can import the releaser keys in your default keyring, see\n[Release keys](#release-keys) for commands to how to do that.\n\nThen, you can verify the files you've downloaded locally\n(if you're using your default keyring, pass `--keyring=\"${GNUPGHOME:-~/.gnupg}/pubring.kbx\"`):\n\n```bash\ncurl -fsO \"https://nodejs.org/dist/${VERSION}/SHASUMS256.txt.asc\" \\\n&& gpgv --keyring=\"/path/to/nodejs-keyring.kbx\" --output SHASUMS256.txt < SHASUMS256.txt.asc \\\n&& shasum --check SHASUMS256.txt --ignore-missing\n```\n\n## Building Node.js\n\nSee [BUILDING.md](BUILDING.md) for instructions on how to build Node.js from\nsource and a list of supported platforms.\n\n## Security\n\nFor information on reporting security vulnerabilities in Node.js, see\n[SECURITY.md](./SECURITY.md).\n\n## Contributing to Node.js\n\n* [Contributing to the project][]\n* [Working Groups][]\n* [Strategic initiatives][]\n* [Technical values and prioritization][]\n\n## Current project team members\n\nFor information about the governance of the Node.js project, see\n[GOVERNANCE.md](./GOVERNANCE.md).\n\n<!-- node-core-utils and find-inactive-tsc.mjs depend on the format of the TSC\n     list. If the format changes, those utilities need to be tested and\n     updated. -->\n\n### TSC (Technical Steering Committee)\n\n#### TSC voting members\n\n<!--lint disable prohibited-strings-->\n\n* [aduh95](https://github.com/aduh95) -\n  **Antoine du Hamel** <<duhamelantoine1995@gmail.com>> (he/him)\n* [anonrig](https://github.com/anonrig) -\n  **Yagiz Nizipli** <<yagiz@nizipli.com>> (he/him)\n* [benjamingr](https://github.com/benjamingr) -\n  **Benjamin Gruenbaum** <<benjamingr@gmail.com>>\n* [BridgeAR](https://github.com/BridgeAR) -\n  **Ruben Bridgewater** <<ruben@bridgewater.de>> (he/him)\n* [gireeshpunathil](https://github.com/gireeshpunathil) -\n  **Gireesh Punathil** <<gpunathi@in.ibm.com>> (he/him)\n* [jasnell](https://github.com/jasnell) -\n  **James M Snell** <<jasnell@gmail.com>> (he/him)\n* [joyeecheung](https://github.com/joyeecheung) -\n  **Joyee Cheung** <<joyeec9h3@gmail.com>> (she/her)\n* [legendecas](https://github.com/legendecas) -\n  **Chengzhong Wu** <<legendecas@gmail.com>> (he/him)\n* [marco-ippolito](https://github.com/marco-ippolito) -\n  **Marco Ippolito** <<marcoippolito54@gmail.com>> (he/him)\n* [mcollina](https://github.com/mcollina) -\n  **Matteo Collina** <<matteo.collina@gmail.com>> (he/him)\n* [panva](https://github.com/panva) -\n  **Filip Skokan** <<panva.ip@gmail.com>> (he/him)\n* [RafaelGSS](https://github.com/RafaelGSS) -\n  **Rafael Gonzaga** <<rafael.nunu@hotmail.com>> (he/him)\n* [RaisinTen](https://github.com/RaisinTen) -\n  **Darshan Sen** <<raisinten@gmail.com>> (he/him)\n* [richardlau](https://github.com/richardlau) -\n  **Richard Lau** <<richard.lau@ibm.com>>\n* [ronag](https://github.com/ronag) -\n  **Robert Nagy** <<ronagy@icloud.com>>\n* [ruyadorno](https://github.com/ruyadorno) -\n  **Ruy Adorno** <<ruy@vlt.sh>> (he/him)\n* [ShogunPanda](https://github.com/ShogunPanda) -\n  **Paolo Insogna** <<paolo@cowtech.it>> (he/him)\n* [targos](https://github.com/targos) -\n  **Micha√´l Zasso** <<targos@protonmail.com>> (he/him)\n* [tniessen](https://github.com/tniessen) -\n  **Tobias Nie√üen** <<tniessen@tnie.de>> (he/him)\n\n#### TSC regular members\n\n* [BethGriggs](https://github.com/BethGriggs) -\n  **Beth Griggs** <<bethanyngriggs@gmail.com>> (she/her)\n* [bnoordhuis](https://github.com/bnoordhuis) -\n  **Ben Noordhuis** <<info@bnoordhuis.nl>>\n* [cjihrig](https://github.com/cjihrig) -\n  **Colin Ihrig** <<cjihrig@gmail.com>> (he/him)\n* [codebytere](https://github.com/codebytere) -\n  **Shelley Vohr** <<shelley.vohr@gmail.com>> (she/her)\n* [GeoffreyBooth](https://github.com/GeoffreyBooth) -\n  **Geoffrey Booth** <<webadmin@geoffreybooth.com>> (he/him)\n* [MoLow](https://github.com/MoLow) -\n  **Moshe Atlow** <<moshe@atlow.co.il>> (he/him)\n* [Trott](https://github.com/Trott) -\n  **Rich Trott** <<rtrott@gmail.com>> (he/him)\n\n<details>\n\n<summary>TSC emeriti members</summary>\n\n#### TSC emeriti members\n\n* [addaleax](https://github.com/addaleax) -\n  **Anna Henningsen** <<anna@addaleax.net>> (she/her)\n* [apapirovski](https://github.com/apapirovski) -\n  **Anatoli Papirovski** <<apapirovski@mac.com>> (he/him)\n* [ChALkeR](https://github.com/ChALkeR) -\n  **–°–∫–æ–≤–æ—Ä–æ–¥–∞ –ù–∏–∫–∏—Ç–∞ –ê–Ω–¥—Ä–µ–µ–≤–∏—á** <<chalkerx@gmail.com>> (he/him)\n* [chrisdickinson](https://github.com/chrisdickinson) -\n  **Chris Dickinson** <<christopher.s.dickinson@gmail.com>>\n* [danbev](https://github.com/danbev) -\n  **Daniel Bevenius** <<daniel.bevenius@gmail.com>> (he/him)\n* [danielleadams](https://github.com/danielleadams) -\n  **Danielle Adams** <<adamzdanielle@gmail.com>> (she/her)\n* [evanlucas](https://github.com/evanlucas) -\n  **Evan Lucas** <<evanlucas@me.com>> (he/him)\n* [fhinkel](https://github.com/fhinkel) -\n  **Franziska Hinkelmann** <<franziska.hinkelmann@gmail.com>> (she/her)\n* [Fishrock123](https://github.com/Fishrock123) -\n  **Jeremiah Senkpiel** <<fishrock123@rocketmail.com>> (he/they)\n* [gabrielschulhof](https://github.com/gabrielschulhof) -\n  **Gabriel Schulhof** <<gabrielschulhof@gmail.com>>\n* [gibfahn](https://github.com/gibfahn) -\n  **Gibson Fahnestock** <<gibfahn@gmail.com>> (he/him)\n* [indutny](https://github.com/indutny) -\n  **Fedor Indutny** <<fedor@indutny.com>>\n* [isaacs](https://github.com/isaacs) -\n  **Isaac Z. Schlueter** <<i@izs.me>>\n* [joshgav](https://github.com/joshgav) -\n  **Josh Gavant** <<josh.gavant@outlook.com>>\n* [mhdawson](https://github.com/mhdawson) -\n  **Michael Dawson** <<midawson@redhat.com>> (he/him)\n* [mmarchini](https://github.com/mmarchini) -\n  **Mary Marchini** <<oss@mmarchini.me>> (she/her)\n* [mscdex](https://github.com/mscdex) -\n  **Brian White** <<mscdex@mscdex.net>>\n* [MylesBorins](https://github.com/MylesBorins) -\n  **Myles Borins** <<myles.borins@gmail.com>> (he/him)\n* [nebrius](https://github.com/nebrius) -\n  **Bryan Hughes** <<bryan@nebri.us>>\n* [ofrobots](https://github.com/ofrobots) -\n  **Ali Ijaz Sheikh** <<ofrobots@google.com>> (he/him)\n* [orangemocha](https://github.com/orangemocha) -\n  **Alexis Campailla** <<orangemocha@nodejs.org>>\n* [piscisaureus](https://github.com/piscisaureus) -\n  **Bert Belder** <<bertbelder@gmail.com>>\n* [rvagg](https://github.com/rvagg) -\n  **Rod Vagg** <<r@va.gg>>\n* [sam-github](https://github.com/sam-github) -\n  **Sam Roberts** <<vieuxtech@gmail.com>>\n* [shigeki](https://github.com/shigeki) -\n  **Shigeki Ohtsu** <<ohtsu@ohtsu.org>> (he/him)\n* [thefourtheye](https://github.com/thefourtheye) -\n  **Sakthipriyan Vairamani** <<thechargingvolcano@gmail.com>> (he/him)\n* [TimothyGu](https://github.com/TimothyGu) -\n  **Tiancheng \"Timothy\" Gu** <<timothygu99@gmail.com>> (he/him)\n* [trevnorris](https://github.com/trevnorris) -\n  **Trevor Norris** <<trev.norris@gmail.com>>\n\n</details>\n\n<!-- node-core-utils and find-inactive-collaborators.mjs depend on the format\n     of the collaborator list. If the format changes, those utilities need to be\n     tested and updated. -->\n\n### Collaborators\n\n* [abmusse](https://github.com/abmusse) -\n  **Abdirahim Musse** <<abdirahim.musse@ibm.com>>\n* [addaleax](https://github.com/addaleax) -\n  **Anna Henningsen** <<anna@addaleax.net>> (she/her)\n* [Aditi-1400](https://github.com/Aditi-1400) -\n  **Aditi Singh** <<aditisingh1400@gmail.com>> (she/her)\n* [aduh95](https://github.com/aduh95) -\n  **Antoine du Hamel** <<duhamelantoine1995@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/aduh95)\n* [anonrig](https://github.com/anonrig) -\n  **Yagiz Nizipli** <<yagiz@nizipli.com>> (he/him) - [Support me](https://github.com/sponsors/anonrig)\n* [atlowChemi](https://github.com/atlowChemi) -\n  **Chemi Atlow** <<chemi@atlow.co.il>> (he/him)\n* [avivkeller](https://github.com/avivkeller) -\n  **Aviv Keller** <<me@aviv.sh>> (he/him) - [Support me](https://github.com/sponsors/avivkeller)\n* [Ayase-252](https://github.com/Ayase-252) -\n  **Qingyu Deng** <<i@ayase-lab.com>>\n* [bengl](https://github.com/bengl) -\n  **Bryan English** <<bryan@bryanenglish.com>> (he/him)\n* [benjamingr](https://github.com/benjamingr) -\n  **Benjamin Gruenbaum** <<benjamingr@gmail.com>>\n* [BethGriggs](https://github.com/BethGriggs) -\n  **Beth Griggs** <<bethanyngriggs@gmail.com>> (she/her)\n* [bnb](https://github.com/bnb) -\n  **Tierney Cyren** <<hello@bnb.im>> (they/them)\n* [bnoordhuis](https://github.com/bnoordhuis) -\n  **Ben Noordhuis** <<info@bnoordhuis.nl>>\n* [BridgeAR](https://github.com/BridgeAR) -\n  **Ruben Bridgewater** <<ruben@bridgewater.de>> (he/him)\n* [cclauss](https://github.com/cclauss) -\n  **Christian Clauss** <<cclauss@me.com>> (he/him)\n* [cjihrig](https://github.com/cjihrig) -\n  **Colin Ihrig** <<cjihrig@gmail.com>> (he/him)\n* [codebytere](https://github.com/codebytere) -\n  **Shelley Vohr** <<shelley.vohr@gmail.com>> (she/her)\n* [cola119](https://github.com/cola119) -\n  **Kohei Ueno** <<kohei.ueno119@gmail.com>> (he/him)\n* [daeyeon](https://github.com/daeyeon) -\n  **Daeyeon Jeong** <<daeyeon.dev@gmail.com>> (he/him)\n* [dario-piotrowicz](https://github.com/dario-piotrowicz) -\n  **Dario Piotrowicz** <<dario.piotrowicz@gmail.com>> (he/him)\n* [debadree25](https://github.com/debadree25) -\n  **Debadree Chatterjee** <<debadree333@gmail.com>> (he/him)\n* [deokjinkim](https://github.com/deokjinkim) -\n  **Deokjin Kim** <<deokjin81.kim@gmail.com>> (he/him)\n* [edsadr](https://github.com/edsadr) -\n  **Adrian Estrada** <<edsadr@gmail.com>> (he/him)\n* [ErickWendel](https://github.com/ErickWendel) -\n  **Erick Wendel** <<erick.workspace@gmail.com>> (he/him)\n* [Ethan-Arrowood](https://github.com/Ethan-Arrowood) -\n  **Ethan Arrowood** <<ethan@arrowood.dev>> (he/him)\n* [fhinkel](https://github.com/fhinkel) -\n  **Franziska Hinkelmann** <<franziska.hinkelmann@gmail.com>> (she/her)\n* [Flarna](https://github.com/Flarna) -\n  **Gerhard St√∂bich** <<deb2001-github@yahoo.de>> (he/they)\n* [gabrielschulhof](https://github.com/gabrielschulhof) -\n  **Gabriel Schulhof** <<gabrielschulhof@gmail.com>>\n* [geeksilva97](https://github.com/geeksilva97) -\n  **Edy Silva** <<edigleyssonsilva@gmail.com>> (he/him)\n* [gengjiawen](https://github.com/gengjiawen) -\n  **Jiawen Geng** <<technicalcute@gmail.com>>\n* [GeoffreyBooth](https://github.com/GeoffreyBooth) -\n  **Geoffrey Booth** <<webadmin@geoffreybooth.com>> (he/him)\n* [gireeshpunathil](https://github.com/gireeshpunathil) -\n  **Gireesh Punathil** <<gpunathi@in.ibm.com>> (he/him)\n* [gurgunday](https://github.com/gurgunday) -\n  **G√ºrg√ºn Dayƒ±oƒülu** <<hey@gurgun.day>> (he/him)\n* [guybedford](https://github.com/guybedford) -\n  **Guy Bedford** <<guybedford@gmail.com>> (he/him)\n* [H4ad](https://github.com/H4ad) -\n  **Vin√≠cius Louren√ßo Claro Cardoso** <<contact@viniciusl.com.br>> (he/him)\n* [HarshithaKP](https://github.com/HarshithaKP) -\n  **Harshitha K P** <<harshitha014@gmail.com>> (she/her)\n* [himself65](https://github.com/himself65) -\n  **Zeyu \"Alex\" Yang** <<himself65@outlook.com>> (he/him)\n* [hybrist](https://github.com/hybrist) -\n  **Jan Martin** <<jan.krems@gmail.com>> (he/him)\n* [IlyasShabi](https://github.com/IlyasShabi) -\n  **Ilyas Shabi** <<ilyasshabi94@gmail.com>> (he/him)\n* [islandryu](https://github.com/islandryu) -\n  **Ryuhei Shima** <<shimaryuhei@gmail.com>> (he/him)\n* [jakecastelli](https://github.com/jakecastelli) -\n  **Jake Yuesong Li** <<jake.yuesong@gmail.com>> (he/him)\n* [JakobJingleheimer](https://github.com/JakobJingleheimer) -\n  **Jacob Smith** <<jacob@frende.me>> (he/him)\n* [jasnell](https://github.com/jasnell) -\n  **James M Snell** <<jasnell@gmail.com>> (he/him)\n* [jazelly](https://github.com/jazelly) -\n  **Jason Zhang** <<xzha4350@gmail.com>> (he/him)\n* [JonasBa](https://github.com/JonasBa) -\n  **Jonas Badalic** <<jonas.badalic@gmail.com>> (he/him)\n* [joyeecheung](https://github.com/joyeecheung) -\n  **Joyee Cheung** <<joyeec9h3@gmail.com>> (she/her)\n* [juanarbol](https://github.com/juanarbol) -\n  **Juan Jos√© Arboleda** <<soyjuanarbol@gmail.com>> (he/him)\n* [JungMinu](https://github.com/JungMinu) -\n  **Minwoo Jung** <<nodecorelab@gmail.com>> (he/him)\n* [KhafraDev](https://github.com/KhafraDev) -\n  **Matthew Aitken** <<maitken033380023@gmail.com>> (he/him)\n* [legendecas](https://github.com/legendecas) -\n  **Chengzhong Wu** <<legendecas@gmail.com>> (he/him)\n* [lemire](https://github.com/lemire) -\n  **Daniel Lemire** <<daniel@lemire.me>>\n* [LiviaMedeiros](https://github.com/LiviaMedeiros) -\n  **LiviaMedeiros** <<livia@cirno.name>>\n* [ljharb](https://github.com/ljharb) -\n  **Jordan Harband** <<ljharb@gmail.com>>\n* [lpinca](https://github.com/lpinca) -\n  **Luigi Pinca** <<luigipinca@gmail.com>> (he/him)\n* [Lxxyx](https://github.com/Lxxyx) -\n  **Zijian Liu** <<lxxyxzj@gmail.com>> (he/him)\n* [marco-ippolito](https://github.com/marco-ippolito) -\n  **Marco Ippolito** <<marcoippolito54@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/marco-ippolito)\n* [marsonya](https://github.com/marsonya) -\n  **Akhil Marsonya** <<akhil.marsonya27@gmail.com>> (he/him)\n* [MattiasBuelens](https://github.com/MattiasBuelens) -\n  **Mattias Buelens** <<mattias@buelens.com>> (he/him)\n* [mcollina](https://github.com/mcollina) -\n  **Matteo Collina** <<matteo.collina@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/mcollina)\n* [meixg](https://github.com/meixg) -\n  **Xuguang Mei** <<meixuguang@gmail.com>> (he/him)\n* [mhdawson](https://github.com/mhdawson) -\n  **Michael Dawson** <<midawson@redhat.com>> (he/him)\n* [MoLow](https://github.com/MoLow) -\n  **Moshe Atlow** <<moshe@atlow.co.il>> (he/him)\n* [MrJithil](https://github.com/MrJithil) -\n  **Jithil P Ponnan** <<jithil@outlook.com>> (he/him)\n* [ovflowd](https://github.com/ovflowd) -\n  **Claudio Wunder** <<cwunder@gnome.org>> (he/they)\n* [panva](https://github.com/panva) -\n  **Filip Skokan** <<panva.ip@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/panva)\n* [pimterry](https://github.com/pimterry) -\n  **Tim Perry** <<pimterry@gmail.com>> (he/him)\n* [pmarchini](https://github.com/pmarchini) -\n  **Pietro Marchini** <<pietro.marchini94@gmail.com>> (he/him)\n* [puskin](https://github.com/puskin) -\n  **Giovanni Bucci** <<github@puskin.it>> (he/him)\n* [Qard](https://github.com/Qard) -\n  **Stephen Belanger** <<admin@stephenbelanger.com>> (he/him)\n* [RafaelGSS](https://github.com/RafaelGSS) -\n  **Rafael Gonzaga** <<rafael.nunu@hotmail.com>> (he/him) - [Support me](https://github.com/sponsors/RafaelGSS)\n* [RaisinTen](https://github.com/RaisinTen) -\n  **Darshan Sen** <<raisinten@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/RaisinTen)\n* [Renegade334](https://github.com/Renegade334) -\n  **Ren√©** <<contact.9a5d6388@renegade334.me.uk>>\n* [richardlau](https://github.com/richardlau) -\n  **Richard Lau** <<richard.lau@ibm.com>>\n* [rluvaton](https://github.com/rluvaton) -\n  **Raz Luvaton** <<rluvaton@gmail.com>> (he/him)\n* [ronag](https://github.com/ronag) -\n  **Robert Nagy** <<ronagy@icloud.com>>\n* [ruyadorno](https://github.com/ruyadorno) -\n  **Ruy Adorno** <<ruy@vlt.sh>> (he/him)\n* [santigimeno](https://github.com/santigimeno) -\n  **Santiago Gimeno** <<santiago.gimeno@gmail.com>>\n* [ShogunPanda](https://github.com/ShogunPanda) -\n  **Paolo Insogna** <<paolo@cowtech.it>> (he/him)\n* [srl295](https://github.com/srl295) -\n  **Steven R Loomis** <<srl295@gmail.com>>\n* [StefanStojanovic](https://github.com/StefanStojanovic) -\n  **Stefan Stojanovic** <<stefan.stojanovic@janeasystems.com>> (he/him)\n* [sxa](https://github.com/sxa) -\n  **Stewart X Addison** <<sxa@redhat.com>> (he/him)\n* [targos](https://github.com/targos) -\n  **Micha√´l Zasso** <<targos@protonmail.com>> (he/him)\n* [theanarkh](https://github.com/theanarkh) -\n  **theanarkh** <<theratliter@gmail.com>> (he/him)\n* [tniessen](https://github.com/tniessen) -\n  **Tobias Nie√üen** <<tniessen@tnie.de>> (he/him)\n* [trivikr](https://github.com/trivikr) -\n  **Trivikram Kamat** <<trivikr.dev@gmail.com>>\n* [Trott](https://github.com/Trott) -\n  **Rich Trott** <<rtrott@gmail.com>> (he/him)\n* [UlisesGascon](https://github.com/UlisesGascon) -\n  **Ulises Gasc√≥n** <<ulisesgascongonzalez@gmail.com>> (he/him)\n* [vmoroz](https://github.com/vmoroz) -\n  **Vladimir Morozov** <<vmorozov@microsoft.com>> (he/him)\n* [VoltrexKeyva](https://github.com/VoltrexKeyva) -\n  **Mohammed Keyvanzadeh** <<mohammadkeyvanzade94@gmail.com>> (he/him)\n* [watilde](https://github.com/watilde) -\n  **Daijiro Wachi** <<daijiro.wachi@gmail.com>> (he/him)\n* [zcbenz](https://github.com/zcbenz) -\n  **Cheng Zhao** <<zcbenz@gmail.com>> (he/him)\n* [ZYSzys](https://github.com/ZYSzys) -\n  **Yongsheng Zhang** <<zyszys98@gmail.com>> (he/him)\n\n<details>\n\n<summary>Emeriti</summary>\n\n<!-- find-inactive-collaborators.mjs depends on the format of the emeriti list.\n     If the format changes, those utilities need to be tested and updated. -->\n\n### Collaborator emeriti\n\n* [ak239](https://github.com/ak239) -\n  **Aleksei Koziatinskii** <<ak239spb@gmail.com>>\n* [andrasq](https://github.com/andrasq) -\n  **Andras** <<andras@kinvey.com>>\n* [AndreasMadsen](https://github.com/AndreasMadsen) -\n  **Andreas Madsen** <<amwebdk@gmail.com>> (he/him)\n* [AnnaMag](https://github.com/AnnaMag) -\n  **Anna M. Kedzierska** <<anna.m.kedzierska@gmail.com>>\n* [antsmartian](https://github.com/antsmartian) -\n  **Anto Aravinth** <<anto.aravinth.cse@gmail.com>> (he/him)\n* [apapirovski](https://github.com/apapirovski) -\n  **Anatoli Papirovski** <<apapirovski@mac.com>> (he/him)\n* [aqrln](https://github.com/aqrln) -\n  **Alexey Orlenko** <<eaglexrlnk@gmail.com>> (he/him)\n* [AshCripps](https://github.com/AshCripps) -\n  **Ash Cripps** <<email@ashleycripps.co.uk>>\n* [bcoe](https://github.com/bcoe) -\n  **Ben Coe** <<bencoe@gmail.com>> (he/him)\n* [bmeck](https://github.com/bmeck) -\n  **Bradley Farias** <<bradley.meck@gmail.com>>\n* [bmeurer](https://github.com/bmeurer) -\n  **Benedikt Meurer** <<benedikt.meurer@gmail.com>>\n* [boneskull](https://github.com/boneskull) -\n  **Christopher Hiller** <<boneskull@boneskull.com>> (he/him)\n* [brendanashworth](https://github.com/brendanashworth) -\n  **Brendan Ashworth** <<brendan.ashworth@me.com>>\n* [bzoz](https://github.com/bzoz) -\n  **Bartosz Sosnowski** <<bartosz@janeasystems.com>>\n* [calvinmetcalf](https://github.com/calvinmetcalf) -\n  **Calvin Metcalf** <<calvin.metcalf@gmail.com>>\n* [ChALkeR](https://github.com/ChALkeR) -\n  **–°–∫–æ–≤–æ—Ä–æ–¥–∞ –ù–∏–∫–∏—Ç–∞ –ê–Ω–¥—Ä–µ–µ–≤–∏—á** <<chalkerx@gmail.com>> (he/him)\n* [chrisdickinson](https://github.com/chrisdickinson) -\n  **Chris Dickinson** <<christopher.s.dickinson@gmail.com>>\n* [claudiorodriguez](https://github.com/claudiorodriguez) -\n  **Claudio Rodriguez** <<cjrodr@yahoo.com>>\n* [danbev](https://github.com/danbev) -\n  **Daniel Bevenius** <<daniel.bevenius@gmail.com>> (he/him)\n* [danielleadams](https://github.com/danielleadams) -\n  **Danielle Adams** <<adamzdanielle@gmail.com>> (she/her)\n* [DavidCai1111](https://github.com/DavidCai1111) -\n  **David Cai** <<davidcai1993@yahoo.com>> (he/him)\n* [davisjam](https://github.com/davisjam) -\n  **Jamie Davis** <<davisjam@vt.edu>> (he/him)\n* [devnexen](https://github.com/devnexen) -\n  **David Carlier** <<devnexen@gmail.com>>\n* [devsnek](https://github.com/devsnek) -\n  **Gus Caplan** <<me@gus.host>> (they/them)\n* [digitalinfinity](https://github.com/digitalinfinity) -\n  **Hitesh Kanwathirtha** <<digitalinfinity@gmail.com>> (he/him)\n* [dmabupt](https://github.com/dmabupt) -\n  **Xu Meng** <<dmabupt@gmail.com>> (he/him)\n* [dnlup](https://github.com/dnlup) -\n  **dnlup** <<dnlup.dev@gmail.com>>\n* [eljefedelrodeodeljefe](https://github.com/eljefedelrodeodeljefe) -\n  **Robert Jefe Lindstaedt** <<robert.lindstaedt@gmail.com>>\n* [estliberitas](https://github.com/estliberitas) -\n  **Alexander Makarenko** <<estliberitas@gmail.com>>\n* [eugeneo](https://github.com/eugeneo) -\n  **Eugene Ostroukhov** <<eostroukhov@google.com>>\n* [evanlucas](https://github.com/evanlucas) -\n  **Evan Lucas** <<evanlucas@me.com>> (he/him)\n* [F3n67u](https://github.com/F3n67u) -\n  **Feng Yu** <<F3n67u@outlook.com>> (he/him)\n* [firedfox](https://github.com/firedfox) -\n  **Daniel Wang** <<wangyang0123@gmail.com>>\n* [Fishrock123](https://github.com/Fishrock123) -\n  **Jeremiah Senkpiel** <<fishrock123@rocketmail.com>> (he/they)\n* [gdams](https://github.com/gdams) -\n  **George Adams** <<gadams@microsoft.com>> (he/him)\n* [geek](https://github.com/geek) -\n  **Wyatt Preul** <<wpreul@gmail.com>>\n* [gibfahn](https://github.com/gibfahn) -\n  **Gibson Fahnestock** <<gibfahn@gmail.com>> (he/him)\n* [glentiki](https://github.com/glentiki) -\n  **Glen Keane** <<glenkeane.94@gmail.com>> (he/him)\n* [hashseed](https://github.com/hashseed) -\n  **Yang Guo** <<yangguo@chromium.org>> (he/him)\n* [hiroppy](https://github.com/hiroppy) -\n  **Yuta Hiroto** <<hello@hiroppy.me>> (he/him)\n* [iansu](https://github.com/iansu) -\n  **Ian Sutherland** <<ian@iansutherland.ca>>\n* [iarna](https://github.com/iarna) -\n  **Rebecca Turner** <<me@re-becca.org>>\n* [imran-iq](https://github.com/imran-iq) -\n  **Imran Iqbal** <<imran@imraniqbal.org>>\n* [imyller](https://github.com/imyller) -\n  **Ilkka Myller** <<ilkka.myller@nodefield.com>>\n* [indutny](https://github.com/indutny) -\n  **Fedor Indutny** <<fedor@indutny.com>>\n* [isaacs](https://github.com/isaacs) -\n  **Isaac Z. Schlueter** <<i@izs.me>>\n* [italoacasas](https://github.com/italoacasas) -\n  **Italo A. Casas** <<me@italoacasas.com>> (he/him)\n* [JacksonTian](https://github.com/JacksonTian) -\n  **Jackson Tian** <<shyvo1987@gmail.com>>\n* [jasongin](https://github.com/jasongin) -\n  **Jason Ginchereau** <<jasongin@microsoft.com>>\n* [jbergstroem](https://github.com/jbergstroem) -\n  **Johan Bergstr√∂m** <<bugs@bergstroem.nu>>\n* [jdalton](https://github.com/jdalton) -\n  **John-David Dalton** <<john.david.dalton@gmail.com>>\n* [jhamhader](https://github.com/jhamhader) -\n  **Yuval Brik** <<yuval@brik.org.il>>\n* [joaocgreis](https://github.com/joaocgreis) -\n  **Jo√£o Reis** <<reis@janeasystems.com>>\n* [joesepi](https://github.com/joesepi) -\n  **Joe Sepi** <<sepi@joesepi.com>> (he/him)\n* [joshgav](https://github.com/joshgav) -\n  **Josh Gavant** <<josh.gavant@outlook.com>>\n* [julianduque](https://github.com/julianduque) -\n  **Julian Duque** <<julianduquej@gmail.com>> (he/him)\n* [kfarnung](https://github.com/kfarnung) -\n  **Kyle Farnung** <<kfarnung@microsoft.com>> (he/him)\n* [kunalspathak](https://github.com/kunalspathak) -\n  **Kunal Pathak** <<kunal.pathak@microsoft.com>>\n* [kuriyosh](https://github.com/kuriyosh) -\n  **Yoshiki Kurihara** <<yosyos0306@gmail.com>> (he/him)\n* [kvakil](https://github.com/kvakil) -\n  **Keyhan Vakil** <<kvakil@sylph.kvakil.me>>\n* [lance](https://github.com/lance) -\n  **Lance Ball** <<lball@redhat.com>> (he/him)\n* [Leko](https://github.com/Leko) -\n  **Shingo Inoue** <<leko.noor@gmail.com>> (he/him)\n* [Linkgoron](https://github.com/Linkgoron) -\n  **Nitzan Uziely** <<linkgoron@gmail.com>>\n* [lucamaraschi](https://github.com/lucamaraschi) -\n  **Luca Maraschi** <<luca.maraschi@gmail.com>> (he/him)\n* [lukekarrys](https://github.com/lukekarrys) -\n  **Luke Karrys** <<luke@lukekarrys.com>> (he/him)\n* [lundibundi](https://github.com/lundibundi) -\n  **Denys Otrishko** <<shishugi@gmail.com>> (he/him)\n* [lxe](https://github.com/lxe) -\n  **Aleksey Smolenchuk** <<lxe@lxe.co>>\n* [maclover7](https://github.com/maclover7) -\n  **Jon Moss** <<me@jonathanmoss.me>> (he/him)\n* [mafintosh](https://github.com/mafintosh) -\n  **Mathias Buus** <<mathiasbuus@gmail.com>> (he/him)\n* [matthewloring](https://github.com/matthewloring) -\n  **Matthew Loring** <<mattloring@google.com>>\n* [Mesteery](https://github.com/Mesteery) -\n  **Mestery** <<mestery@protonmail.com>> (he/him)\n* [micnic](https://github.com/micnic) -\n  **Nicu Micleu»ôanu** <<micnic90@gmail.com>> (he/him)\n* [mikeal](https://github.com/mikeal) -\n  **Mikeal Rogers** <<mikeal.rogers@gmail.com>>\n* [miladfarca](https://github.com/miladfarca) -\n  **Milad Fa** <<mfarazma@redhat.com>> (he/him)\n* [mildsunrise](https://github.com/mildsunrise) -\n  **Alba Mendez** <<me@alba.sh>> (she/her)\n* [misterdjules](https://github.com/misterdjules) -\n  **Julien Gilli** <<jgilli@netflix.com>>\n* [mmarchini](https://github.com/mmarchini) -\n  **Mary Marchini** <<oss@mmarchini.me>> (she/her)\n* [monsanto](https://github.com/monsanto) -\n  **Christopher Monsanto** <<chris@monsan.to>>\n* [MoonBall](https://github.com/MoonBall) -\n  **Chen Gang** <<gangc.cxy@foxmail.com>>\n* [mscdex](https://github.com/mscdex) -\n  **Brian White** <<mscdex@mscdex.net>>\n* [MylesBorins](https://github.com/MylesBorins) -\n  **Myles Borins** <<myles.borins@gmail.com>> (he/him)\n* [not-an-aardvark](https://github.com/not-an-aardvark) -\n  **Teddy Katz** <<teddy.katz@gmail.com>> (he/him)\n* [ofrobots](https://github.com/ofrobots) -\n  **Ali Ijaz Sheikh** <<ofrobots@google.com>> (he/him)\n* [Olegas](https://github.com/Olegas) -\n  **Oleg Elifantiev** <<oleg@elifantiev.ru>>\n* [orangemocha](https://github.com/orangemocha) -\n  **Alexis Campailla** <<orangemocha@nodejs.org>>\n* [othiym23](https://github.com/othiym23) -\n  **Forrest L Norvell** <<ogd@aoaioxxysz.net>> (they/them/themself)\n* [oyyd](https://github.com/oyyd) -\n  **Ouyang Yadong** <<oyydoibh@gmail.com>> (he/him)\n* [petkaantonov](https://github.com/petkaantonov) -\n  **Petka Antonov** <<petka_antonov@hotmail.com>>\n* [phillipj](https://github.com/phillipj) -\n  **Phillip Johnsen** <<johphi@gmail.com>>\n* [piscisaureus](https://github.com/piscisaureus) -\n  **Bert Belder** <<bertbelder@gmail.com>>\n* [pmq20](https://github.com/pmq20) -\n  **Minqi Pan** <<pmq2001@gmail.com>>\n* [PoojaDurgad](https://github.com/PoojaDurgad) -\n  **Pooja D P** <<Pooja.D.P@ibm.com>> (she/her)\n* [princejwesley](https://github.com/princejwesley) -\n  **Prince John Wesley** <<princejohnwesley@gmail.com>>\n* [psmarshall](https://github.com/psmarshall) -\n  **Peter Marshall** <<petermarshall@chromium.org>> (he/him)\n* [puzpuzpuz](https://github.com/puzpuzpuz) -\n  **Andrey Pechkurov** <<apechkurov@gmail.com>> (he/him)\n* [refack](https://github.com/refack) -\n  **Refael Ackermann (◊®◊§◊ê◊ú ◊§◊ú◊ó◊ô)** <<refack@gmail.com>> (he/him/◊î◊ï◊ê/◊ê◊™◊î)\n* [rexagod](https://github.com/rexagod) -\n  **Pranshu Srivastava** <<rexagod@gmail.com>> (he/him)\n* [rickyes](https://github.com/rickyes) -\n  **Ricky Zhou** <<0x19951125@gmail.com>> (he/him)\n* [rlidwka](https://github.com/rlidwka) -\n  **Alex Kocharin** <<alex@kocharin.ru>>\n* [rmg](https://github.com/rmg) -\n  **Ryan Graham** <<r.m.graham@gmail.com>>\n* [robertkowalski](https://github.com/robertkowalski) -\n  **Robert Kowalski** <<rok@kowalski.gd>>\n* [romankl](https://github.com/romankl) -\n  **Roman Klauke** <<romaaan.git@gmail.com>>\n* [ronkorving](https://github.com/ronkorving) -\n  **Ron Korving** <<ron@ronkorving.nl>>\n* [RReverser](https://github.com/RReverser) -\n  **Ingvar Stepanyan** <<me@rreverser.com>>\n* [rubys](https://github.com/rubys) -\n  **Sam Ruby** <<rubys@intertwingly.net>>\n* [rvagg](https://github.com/rvagg) -\n  **Rod Vagg** <<rod@vagg.org>>\n* [ryzokuken](https://github.com/ryzokuken) -\n  **Ujjwal Sharma** <<ryzokuken@disroot.org>> (he/him)\n* [saghul](https://github.com/saghul) -\n  **Sa√∫l Ibarra Corretg√©** <<s@saghul.net>>\n* [sam-github](https://github.com/sam-github) -\n  **Sam Roberts** <<vieuxtech@gmail.com>>\n* [sebdeckers](https://github.com/sebdeckers) -\n  **Sebastiaan Deckers** <<sebdeckers83@gmail.com>>\n* [seishun](https://github.com/seishun) -\n  **Nikolai Vavilov** <<vvnicholas@gmail.com>>\n* [shigeki](https://github.com/shigeki) -\n  **Shigeki Ohtsu** <<ohtsu@ohtsu.org>> (he/him)\n* [shisama](https://github.com/shisama) -\n  **Masashi Hirano** <<shisama07@gmail.com>> (he/him)\n* [silverwind](https://github.com/silverwind) -\n  **Roman Reiss** <<me@silverwind.io>>\n* [starkwang](https://github.com/starkwang) -\n  **Weijia Wang** <<starkwang@126.com>>\n* [stefanmb](https://github.com/stefanmb) -\n  **Stefan Budeanu** <<stefan@budeanu.com>>\n* [tellnes](https://github.com/tellnes) -\n  **Christian Tellnes** <<christian@tellnes.no>>\n* [thefourtheye](https://github.com/thefourtheye) -\n  **Sakthipriyan Vairamani** <<thechargingvolcano@gmail.com>> (he/him)\n* [thlorenz](https://github.com/thlorenz) -\n  **Thorsten Lorenz** <<thlorenz@gmx.de>>\n* [TimothyGu](https://github.com/TimothyGu) -\n  **Tiancheng \"Timothy\" Gu** <<timothygu99@gmail.com>> (he/him)\n* [trevnorris](https://github.com/trevnorris) -\n  **Trevor Norris** <<trev.norris@gmail.com>>\n* [tunniclm](https://github.com/tunniclm) -\n  **Mike Tunnicliffe** <<m.j.tunnicliffe@gmail.com>>\n* [vdeturckheim](https://github.com/vdeturckheim) -\n  **Vladimir de Turckheim** <<vlad2t@hotmail.com>> (he/him)\n* [vkurchatkin](https://github.com/vkurchatkin) -\n  **Vladimir Kurchatkin** <<vladimir.kurchatkin@gmail.com>>\n* [vsemozhetbyt](https://github.com/vsemozhetbyt) -\n  **Vse Mozhet Byt** <<vsemozhetbyt@gmail.com>> (he/him)\n* [watson](https://github.com/watson) -\n  **Thomas Watson** <<w@tson.dk>>\n* [whitlockjc](https://github.com/whitlockjc) -\n  **Jeremy Whitlock** <<jwhitlock@apache.org>>\n* [XadillaX](https://github.com/XadillaX) -\n  **Khaidi Chu** <<i@2333.moe>> (he/him)\n* [yashLadha](https://github.com/yashLadha) -\n  **Yash Ladha** <<yash@yashladha.in>> (he/him)\n* [yhwang](https://github.com/yhwang) -\n  **Yihong Wang** <<yh.wang@ibm.com>>\n* [yorkie](https://github.com/yorkie) -\n  **Yorkie Liu** <<yorkiefixer@gmail.com>>\n* [yosuke-furukawa](https://github.com/yosuke-furukawa) -\n  **Yosuke Furukawa** <<yosuke.furukawa@gmail.com>>\n\n</details>\n\n<!--lint enable prohibited-strings-->\n\nCollaborators follow the [Collaborator Guide](./doc/contributing/collaborator-guide.md) in\nmaintaining the Node.js project.\n\n### Triagers\n\n* [1ilsang](https://github.com/1ilsang) -\n  **Sangchul Lee** <<1ilsang.dev@gmail.com>> (he/him)\n* [atlowChemi](https://github.com/atlowChemi) -\n  **Chemi Atlow** <<chemi@atlow.co.il>> (he/him)\n* [Ayase-252](https://github.com/Ayase-252) -\n  **Qingyu Deng** <<i@ayase-lab.com>>\n* [bjohansebas](https://github.com/bjohansebas) -\n  **Sebastian Beltran** <<bjohansebas@gmail.com>>\n* [bmuenzenmeyer](https://github.com/bmuenzenmeyer) -\n  **Brian Muenzenmeyer** <<brian.muenzenmeyer@gmail.com>> (he/him)\n* [CanadaHonk](https://github.com/CanadaHonk) -\n  **Oliver Medhurst** <<honk@goose.icu>> (they/them)\n* [daeyeon](https://github.com/daeyeon) -\n  **Daeyeon Jeong** <<daeyeon.dev@gmail.com>> (he/him)\n* [gireeshpunathil](https://github.com/gireeshpunathil) -\n  **Gireesh Punathil** <<gpunathi@in.ibm.com>> (he/him)\n* [gurgunday](https://github.com/gurgunday) -\n  **G√ºrg√ºn Dayƒ±oƒülu** <<hey@gurgun.day>>\n* [haramj](https://github.com/haramj) -\n  **Haram Jeong** <<haramj.dev@gmail.com>>\n* [HBSPS](https://github.com/HBSPS) -\n  **Wiyeong Seo** <<hbsps.dev@gmail.com>>\n* [iam-frankqiu](https://github.com/iam-frankqiu) -\n  **Frank Qiu** <<iam.frankqiu@gmail.com>> (he/him)\n* [KevinEady](https://github.com/KevinEady) -\n  **Kevin Eady** <<kevin.c.eady@gmail.com>> (he/him)\n* [marsonya](https://github.com/marsonya) -\n  **Akhil Marsonya** <<akhil.marsonya27@gmail.com>> (he/him)\n* [meixg](https://github.com/meixg) -\n  **Xuguang Mei** <<meixuguang@gmail.com>> (he/him)\n* [milesguicent](https://github.com/milesguicent) -\n  **Miles Guicent** <<guicent@pm.me>> (he/him)\n* [preveen-stack](https://github.com/preveen-stack) -\n  **Preveen Padmanabhan** <<wide4head@gmail.com>> (he/him)\n* [RaisinTen](https://github.com/RaisinTen) -\n  **Darshan Sen** <<raisinten@gmail.com>> (he/him)\n* [VoltrexKeyva](https://github.com/VoltrexKeyva) -\n  **Mohammed Keyvanzadeh** <<mohammadkeyvanzade94@gmail.com>> (he/him)\n\nTriagers follow the [Triage Guide](./doc/contributing/issues.md#triaging-a-bug-report) when\nresponding to new issues.\n\n### Release keys\n\nPrimary GPG keys for Node.js Releasers (some Releasers sign with subkeys):\n\n* **Antoine du Hamel** <<duhamelantoine1995@gmail.com>>\n  `5BE8A3F6C8A5C01D106C0AD820B1A390B168D356`\n* **Juan Jos√© Arboleda** <<soyjuanarbol@gmail.com>>\n  `DD792F5973C6DE52C432CBDAC77ABFA00DDBF2B7`\n* **Marco Ippolito** <<marcoippolito54@gmail.com>>\n  `CC68F5A3106FF448322E48ED27F5E38D5B0A215F`\n* **Micha√´l Zasso** <<targos@protonmail.com>>\n  `8FCCA13FEF1D0C2E91008E09770F7A9A5AE15600`\n* **Rafael Gonzaga** <<rafael.nunu@hotmail.com>>\n  `890C08DB8579162FEE0DF9DB8BEAB4DFCF555EF4`\n* **Richard Lau** <<richard.lau@ibm.com>>\n  `C82FA3AE1CBEDC6BE46B9360C43CEC45C17AB93C`\n* **Ruy Adorno** <<ruyadorno@hotmail.com>>\n  `108F52B48DB57BB0CC439B2997B01419BD92F80A`\n* **Ulises Gasc√≥n** <<ulisesgascongonzalez@gmail.com>>\n  `A363A499291CBBC940DD62E41F10027AF002F8B0`\n\nYou can use the keyring the project maintains at\n<https://github.com/nodejs/release-keys/raw/refs/heads/main/gpg-only-active-keys/pubring.kbx>.\nAlternatively, you can import them from a public key server. Have in mind that\nthe project cannot guarantee the availability of the server nor the keys on\nthat server.\n\n```bash\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 5BE8A3F6C8A5C01D106C0AD820B1A390B168D356 # Antoine du Hamel\ngpg --keyserver hkps://keys.openpgp.org --recv-keys DD792F5973C6DE52C432CBDAC77ABFA00DDBF2B7 # Juan Jos√© Arboleda\ngpg --keyserver hkps://keys.openpgp.org --recv-keys CC68F5A3106FF448322E48ED27F5E38D5B0A215F # Marco Ippolito\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 8FCCA13FEF1D0C2E91008E09770F7A9A5AE15600 # Micha√´l Zasso\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 890C08DB8579162FEE0DF9DB8BEAB4DFCF555EF4 # Rafael Gonzaga\ngpg --keyserver hkps://keys.openpgp.org --recv-keys C82FA3AE1CBEDC6BE46B9360C43CEC45C17AB93C # Richard Lau\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 108F52B48DB57BB0CC439B2997B01419BD92F80A # Ruy Adorno\ngpg --keyserver hkps://keys.openpgp.org --recv-keys A363A499291CBBC940DD62E41F10027AF002F8B0 # Ulises Gasc√≥n\n```\n\nSee [Verifying binaries](#verifying-binaries) for how to use these keys to\nverify a downloaded file.\n\n<details>\n\n<summary>Other keys used to sign some previous releases</summary>\n\n* **Antoine du Hamel** <<duhamelantoine1995@gmail.com>>\n  `C0D6248439F1D5604AAFFB4021D900FFDB233756`\n* **Beth Griggs** <<bethanyngriggs@gmail.com>>\n  `4ED778F539E3634C779C87C6D7062848A1AB005C`\n* **Bryan English** <<bryan@bryanenglish.com>>\n  `141F07595B7B3FFE74309A937405533BE57C7D57`\n* **Chris Dickinson** <<christopher.s.dickinson@gmail.com>>\n  `9554F04D7259F04124DE6B476D5A82AC7E37093B`\n* **Colin Ihrig** <<cjihrig@gmail.com>>\n  `94AE36675C464D64BAFA68DD7434390BDBE9B9C5`\n* **Danielle Adams** <<adamzdanielle@gmail.com>>\n  `1C050899334244A8AF75E53792EF661D867B9DFA`\n  `74F12602B6F1C4E913FAA37AD3A89613643B6201`\n* **Evan Lucas** <<evanlucas@me.com>>\n  `B9AE9905FFD7803F25714661B63B535A4C206CA9`\n* **Gibson Fahnestock** <<gibfahn@gmail.com>>\n  `77984A986EBC2AA786BC0F66B01FBB92821C587A`\n* **Isaac Z. Schlueter** <<i@izs.me>>\n  `93C7E9E91B49E432C2F75674B0A78B0A6C481CF6`\n* **Italo A. Casas** <<me@italoacasas.com>>\n  `56730D5401028683275BD23C23EFEFE93C4CFFFE`\n* **James M Snell** <<jasnell@keybase.io>>\n  `71DCFD284A79C3B38668286BC97EC7A07EDE3FC1`\n* **Jeremiah Senkpiel** <<fishrock@keybase.io>>\n  `FD3A5288F042B6850C66B31F09FE44734EB7990E`\n* **Juan Jos√© Arboleda** <<soyjuanarbol@gmail.com>>\n  `61FC681DFB92A079F1685E77973F295594EC4689`\n* **Julien Gilli** <<jgilli@fastmail.fm>>\n  `114F43EE0176B71C7BC219DD50A3051F888C628D`\n* **Myles Borins** <<myles.borins@gmail.com>>\n  `C4F0DFFF4E8C1A8236409D08E73BC641CC11F4C8`\n* **Rod Vagg** <<rod@vagg.org>>\n  `DD8F2338BAE7501E3DD5AC78C273792F7D83545D`\n* **Ruben Bridgewater** <<ruben@bridgewater.de>>\n  `A48C2BEE680E841632CD4E44F07496B3EB3C1762`\n* **Shelley Vohr** <<shelley.vohr@gmail.com>>\n  `B9E2F5981AA6E0CD28160D9FF13993A75599653C`\n* **Timothy J Fontaine** <<tjfontaine@gmail.com>>\n  `7937DFD2AB06298B2293C3187D33FF9D0246406D`\n\nThe project maintains a keyring able to verify all past releases of Node.js at\n<https://github.com/nodejs/release-keys/raw/refs/heads/main/gpg/pubring.kbx>.\n\n</details>\n\n### Security release stewards\n\nWhen possible, the commitment to take slots in the\nsecurity release steward rotation is made by companies in order\nto ensure individuals who act as security stewards have the\nsupport and recognition from their employer to be able to\nprioritize security releases. Security release stewards manage security\nreleases on a rotation basis as outlined in the\n[security release process](./doc/contributing/security-release-process.md).\n\n* [Datadog](https://www.datadoghq.com/)\n  * [bengl](https://github.com/bengl) -\n    **Bryan English** <<bryan@bryanenglish.com>> (he/him)\n* [HeroDevs](https://www.herodevs.com/)\n  * [marco-ippolito](https://github.com/marco-ippolito) -\n    **Marco Ippolito** <<marcoippolito54@gmail.com>> (he/him)\n* [NodeSource](https://nodesource.com/)\n  * [juanarbol](https://github.com/juanarbol) -\n    **Juan Jos√© Arboleda** <<soyjuanarbol@gmail.com>> (he/him)\n  * [RafaelGSS](https://github.com/RafaelGSS) -\n    **Rafael Gonzaga** <<rafael.nunu@hotmail.com>> (he/him)\n* [Platformatic](https://platformatic.dev/)\n  * [mcollina](https://github.com/mcollina) -\n    **Matteo Collina** <<matteo.collina@gmail.com>> (he/him)\n* [Red Hat](https://redhat.com) / [IBM](https://ibm.com)\n  * [joesepi](https://github.com/joesepi) -\n    **Joe Sepi** <<joesepi@ibm.com>> (he/him)\n  * [mhdawson](https://github.com/mhdawson) -\n    **Michael Dawson** <<midawson@redhat.com>> (he/him)\n\n## License\n\nNode.js is licensed under the [MIT License](https://opensource.org/licenses/MIT).\n\nThis project also depends on external libraries that may use different open-source\nlicenses. For a complete list of included licenses, please see the\n[LICENSE](https://github.com/nodejs/node/blob/main/LICENSE) file.\n\nIf you are contributing documentation or source changes, please ensure your\nadditions comply with the project‚Äôs license guidelines.\n\n[Code of Conduct]: https://github.com/nodejs/admin/blob/HEAD/CODE_OF_CONDUCT.md\n[Contributing to the project]: CONTRIBUTING.md\n[Node.js website]: https://nodejs.org/\n[OpenJS Foundation]: https://openjsf.org/\n[Strategic initiatives]: doc/contributing/strategic-initiatives.md\n[Technical values and prioritization]: doc/contributing/technical-values.md\n[Working Groups]: https://github.com/nodejs/TSC/blob/HEAD/WORKING_GROUPS.md\n",
      "stars_today": 20
    },
    {
      "id": 268424739,
      "name": "helix",
      "full_name": "helix-editor/helix",
      "description": "A post-modern modal text editor.",
      "html_url": "https://github.com/helix-editor/helix",
      "stars": 42450,
      "forks": 3261,
      "language": "Rust",
      "topics": [
        "kakoune",
        "rust",
        "text-editor",
        "vim"
      ],
      "created_at": "2020-06-01T04:26:56Z",
      "updated_at": "2026-01-17T00:06:03Z",
      "pushed_at": "2026-01-14T05:07:41Z",
      "open_issues": 1420,
      "owner": {
        "login": "helix-editor",
        "avatar_url": "https://avatars.githubusercontent.com/u/66235900?v=4"
      },
      "readme": "<div align=\"center\">\n\n<h1>\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"logo_dark.svg\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"logo_light.svg\">\n  <img alt=\"Helix\" height=\"128\" src=\"logo_light.svg\">\n</picture>\n</h1>\n\n[![Build status](https://github.com/helix-editor/helix/actions/workflows/build.yml/badge.svg)](https://github.com/helix-editor/helix/actions)\n[![GitHub Release](https://img.shields.io/github/v/release/helix-editor/helix)](https://github.com/helix-editor/helix/releases/latest)\n[![Documentation](https://shields.io/badge/-documentation-452859)](https://docs.helix-editor.com/)\n[![GitHub contributors](https://img.shields.io/github/contributors/helix-editor/helix)](https://github.com/helix-editor/helix/graphs/contributors)\n[![Matrix Space](https://img.shields.io/matrix/helix-community:matrix.org)](https://matrix.to/#/#helix-community:matrix.org)\n\n</div>\n\n![Screenshot](./screenshot.png)\n\nA [Kakoune](https://github.com/mawww/kakoune) / [Neovim](https://github.com/neovim/neovim) inspired editor, written in Rust.\n\nThe editing model is very heavily based on Kakoune; during development I found\nmyself agreeing with most of Kakoune's design decisions.\n\nFor more information, see the [website](https://helix-editor.com) or\n[documentation](https://docs.helix-editor.com/).\n\nAll shortcuts/keymaps can be found [in the documentation on the website](https://docs.helix-editor.com/keymap.html).\n\n[Troubleshooting](https://github.com/helix-editor/helix/wiki/Troubleshooting)\n\n# Features\n\n- Vim-like modal editing\n- Multiple selections\n- Built-in language server support\n- Smart, incremental syntax highlighting and code editing via tree-sitter\n\nAlthough it's primarily a terminal-based editor, I am interested in exploring\na custom renderer (similar to Emacs) using wgpu.\n\nNote: Only certain languages have indentation definitions at the moment. Check\n`runtime/queries/<lang>/` for `indents.scm`.\n\n# Installation\n\n[Installation documentation](https://docs.helix-editor.com/install.html).\n\n[![Packaging status](https://repology.org/badge/vertical-allrepos/helix-editor.svg?exclude_unsupported=1)](https://repology.org/project/helix-editor/versions)\n\n# Contributing\n\nContributing guidelines can be found [here](./docs/CONTRIBUTING.md).\n\n# Getting help\n\nYour question might already be answered on the [FAQ](https://github.com/helix-editor/helix/wiki/FAQ).\n\nDiscuss the project on the community [Matrix Space](https://matrix.to/#/#helix-community:matrix.org) (make sure to join `#helix-editor:matrix.org` if you're on a client that doesn't support Matrix Spaces yet).\n\n# Credits\n\nThanks to [@jakenvac](https://github.com/jakenvac) for designing the logo!\n",
      "stars_today": 20
    },
    {
      "id": 92443980,
      "name": "drawio-desktop",
      "full_name": "jgraph/drawio-desktop",
      "description": "Official electron build of draw.io",
      "html_url": "https://github.com/jgraph/drawio-desktop",
      "stars": 58996,
      "forks": 5567,
      "language": "JavaScript",
      "topics": [
        "diagram-editor",
        "electron-app",
        "graphics",
        "javascript-applications"
      ],
      "created_at": "2017-05-25T20:58:42Z",
      "updated_at": "2026-01-17T00:38:09Z",
      "pushed_at": "2026-01-16T13:58:57Z",
      "open_issues": 50,
      "owner": {
        "login": "jgraph",
        "avatar_url": "https://avatars.githubusercontent.com/u/1769238?v=4"
      },
      "readme": "About\n----- \n\n**drawio-desktop** is a diagramming desktop app based on [Electron](https://electronjs.org/) that wraps the [core draw.io editor](https://github.com/jgraph/drawio).\n\nDownload built binaries from the [releases section](https://github.com/jgraph/drawio-desktop/releases).\n\n**Can I use this app for free?** Yes, under the apache 2.0 license. If you don't change the code and accept it is provided \"as-is\", you can use it for any purpose.\n\nSecurity\n--------\n\ndraw.io Desktop is designed to be completely isolated from the Internet, apart from the update process. This checks github.com at startup for a newer version and downloads it from an AWS S3 bucket owned by Github. All JavaScript files are self-contained, the Content Security Policy forbids running remotely loaded JavaScript.\n\nNo diagram data is ever sent externally, nor do we send any analytics about app usage externally. There is a Content Security Policy in place on the web part of the interface to ensure external transmission cannot happen, even by accident.\n\nSecurity and isolating the app are the primarily objectives of draw.io desktop. If you ask for anything that involves external connections enabled in the app by default, the answer will be no.\n\nSupport\n-------\n\nSupport is provided on a reasonable business constraints basis, but without anything contractually binding. All support is provided via this repo. There is no private ticketing support for non-paying users.\n\nPurchasing draw.io for Confluence or Jira does not entitle you to commercial support for draw.io desktop.\n\nDeveloping\n----------\n\n**draw.io** is a git submodule of **drawio-desktop**. To get both you need to clone recursively:\n\n`git clone --recursive https://github.com/jgraph/drawio-desktop.git`\n\nTo run this:\n1. `npm install` (in the root directory of this repo)\n2. [internal use only] export DRAWIO_ENV=dev if you want to develop/debug in dev mode.\n3. `npm start` _in the root directory of this repo_ runs the app. For debugging, use `npm start --enable-logging`.\n\nNote: If a symlink is used to refer to drawio repo (instead of the submodule), then symlink the `node_modules` directory inside `drawio/src/main/webapp` also.\n\nTo release:\n1. Update the draw.io sub-module and push the change. Add version tag before pushing to origin.\n2. Wait for the builds to complete (https://travis-ci.org/jgraph/drawio-desktop and https://ci.appveyor.com/project/davidjgraph/drawio-desktop)\n3. Go to https://github.com/jgraph/drawio-desktop/releases, edit the preview release.\n4. Download the windows exe and windows portable, sign them using `signtool sign /a /tr http://rfc3161timestamp.globalsign.com/advanced /td SHA256 c:/path/to/your/file.exe`\n5. Re-upload signed file as `draw.io-windows-installer-x.y.z.exe` and `draw.io-windows-no-installer-x.y.z.exe`\n6. Add release notes\n7. Publish release\n\n*Note*: In Windows release, when using both x64 and is32 as arch, the result is one big file with both archs. This is why we split them.\n\nLocal Storage and Session Storage is stored in the AppData folder:\n\n- macOS: `~/Library/Application Support/draw.io`\n- Windows: `C:\\Users\\<USER-NAME>\\AppData\\Roaming\\draw.io\\`\n\nNot open-contribution\n---------------------\n\ndraw.io is closed to contributions (unless a maintainer permits it, which is extremely rare).\n\nThe level of complexity of this project means that even simple changes \ncan break a _lot_ of other moving parts. The amount of testing required \nis far more than it first seems. If we were to receive a PR, we'd have \nto basically throw it away and write it how we want it to be implemented.\n\nWe are grateful for community involvement, bug reports, & feature requests. We do\nnot wish to come off as anything but welcoming, however, we've\nmade the decision to keep this project closed to contributions for \nthe long term viability of the project.\n",
      "stars_today": 19
    },
    {
      "id": 1016267036,
      "name": "bitchat-android",
      "full_name": "permissionlesstech/bitchat-android",
      "description": "bluetooth mesh chat, IRC vibes",
      "html_url": "https://github.com/permissionlesstech/bitchat-android",
      "stars": 4392,
      "forks": 621,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2025-07-08T18:36:23Z",
      "updated_at": "2026-01-17T00:58:45Z",
      "pushed_at": "2026-01-16T17:50:09Z",
      "open_issues": 216,
      "owner": {
        "login": "permissionlesstech",
        "avatar_url": "https://avatars.githubusercontent.com/u/220183803?v=4"
      },
      "readme": "<p align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/188c42f8-d249-4a72-b27a-e2b4f10a00a8\" alt=\"Bitchat Android Logo\" width=\"480\">\n</p>\n\n> [!WARNING]\n> This software has not received external security review and may contain vulnerabilities and may not necessarily meet its stated security goals. Do not use it for sensitive use cases, and do not rely on its security until it has been reviewed. Work in progress.\n\n# bitchat for Android\n\nA secure, decentralized, peer-to-peer messaging app that works over Bluetooth mesh networks. No internet required for mesh chats, no servers, no phone numbers - just pure encrypted communication. Bitchat also supports geohash channels, which use an internet connection to connect you with others in your geographic area.\n\nThis is the **Android port** of the original [bitchat iOS app](https://github.com/jackjackbits/bitchat), maintaining 100% protocol compatibility for cross-platform communication.\n\n## Install bitchat\n\nYou can download the latest version of bitchat for Android from the [GitHub Releases page](https://github.com/permissionlesstech/bitchat-android/releases).\n\nOr you can:\n\n[<img alt=\"Get it on Google Play\" height=\"60\" src=\"https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png\"/>](https://play.google.com/store/apps/details?id=com.bitchat.droid)\n\n**Instructions:**\n\n1.  **Download the APK:** On your Android device, navigate to the link above and download the latest `.apk` file. Open it.\n2.  **Allow Unknown Sources:** On some devices, before you can install the APK, you may need to enable \"Install from unknown sources\" in your device's settings. This is typically found under **Settings > Security** or **Settings > Apps & notifications > Special app access**.\n3.  **Install:** Open the downloaded `.apk` file to begin the installation.\n\n## License\n\nThis project is released into the public domain. See the [LICENSE](LICENSE.md) file for details.\n\n## Features\n\n- **‚úÖ Cross-Platform Compatible**: Full protocol compatibility with iOS bitchat\n- **‚úÖ Decentralized Mesh Network**: Automatic peer discovery and multi-hop message relay over Bluetooth LE\n- **‚úÖ End-to-End Encryption**: X25519 key exchange + AES-256-GCM for private messages\n- **‚úÖ Channel-Based Chats**: Topic-based group messaging with optional password protection\n- **‚úÖ Store & Forward**: Messages cached for offline peers and delivered when they reconnect\n- **‚úÖ Privacy First**: No accounts, no phone numbers, no persistent identifiers\n- **‚úÖ IRC-Style Commands**: Familiar `/join`, `/msg`, `/who` style interface\n- **‚úÖ Message Retention**: Optional channel-wide message saving controlled by channel owners\n- **‚úÖ Emergency Wipe**: Triple-tap logo to instantly clear all data\n- **‚úÖ Modern Android UI**: Jetpack Compose with Material Design 3\n- **‚úÖ Dark/Light Themes**: Terminal-inspired aesthetic matching iOS version\n- **‚úÖ Battery Optimization**: Adaptive scanning and power management\n\n## Android Setup\n\n### Prerequisites\n\n- **Android Studio**: Arctic Fox (2020.3.1) or newer\n- **Android SDK**: API level 26 (Android 8.0) or higher\n- **Kotlin**: 1.8.0 or newer\n- **Gradle**: 7.0 or newer\n\n### Build Instructions\n\n1. **Clone the repository:**\n   ```bash\n   git clone https://github.com/permissionlesstech/bitchat-android.git\n   cd bitchat-android\n   ```\n\n2. **Open in Android Studio:**\n   ```bash\n   # Open Android Studio and select \"Open an Existing Project\"\n   # Navigate to the bitchat-android directory\n   ```\n\n3. **Build the project:**\n   ```bash\n   ./gradlew build\n   ```\n\n4. **Install on device:**\n   ```bash\n   ./gradlew installDebug\n   ```\n\n### Development Build\n\nFor development builds with debugging enabled:\n\n```bash\n./gradlew assembleDebug\nadb install -r app/build/outputs/apk/debug/app-debug.apk\n```\n\n### Release Build\n\nFor production releases:\n\n```bash\n./gradlew assembleRelease\n```\n\n## Android-Specific Requirements\n\n### Permissions\n\nThe app requires the following permissions (automatically requested):\n\n- **Bluetooth**: Core BLE functionality\n- **Location**: Required for BLE scanning on Android\n- **Network**: Expand your mesh through public internet relays\n- **Notifications**: Message alerts and background updates\n\n### Hardware Requirements\n\n- **Bluetooth LE (BLE)**: Required for mesh networking\n- **Android 8.0+**: API level 26 minimum\n- **RAM**: 2GB recommended for optimal performance\n\n## Usage\n\n### Basic Commands\n\n- `/j #channel` - Join or create a channel\n- `/m @name message` - Send a private message\n- `/w` - List online users\n- `/channels` - Show all discovered channels\n- `/block @name` - Block a peer from messaging you\n- `/block` - List all blocked peers\n- `/unblock @name` - Unblock a peer\n- `/clear` - Clear chat messages\n- `/pass [password]` - Set/change channel password (owner only)\n- `/transfer @name` - Transfer channel ownership\n- `/save` - Toggle message retention for channel (owner only)\n\n### Getting Started\n\n1. **Install the app** on your Android device (requires Android 8.0+)\n2. **Grant permissions** for Bluetooth and location when prompted\n3. **Launch bitchat** - it will auto-start mesh networking\n4. **Set your nickname** or use the auto-generated one\n5. **Connect automatically** to nearby iOS and Android bitchat users\n6. **Join a channel** with `/j #general` or start chatting in public\n7. **Messages relay** through the mesh network to reach distant peers\n\n### Android UI Features\n\n- **Jetpack Compose UI**: Modern Material Design 3 interface\n- **Dark/Light Themes**: Terminal-inspired aesthetic matching iOS\n- **Haptic Feedback**: Vibrations for interactions and notifications\n- **Adaptive Layout**: Optimized for various Android screen sizes\n- **Message Status**: Real-time delivery and read receipts\n- **RSSI Indicators**: Signal strength colors for each peer\n\n### Channel Features\n\n- **Password Protection**: Channel owners can set passwords with `/pass`\n- **Message Retention**: Owners can enable mandatory message saving with `/save`\n- **@ Mentions**: Use `@nickname` to mention users (with autocomplete)\n- **Ownership Transfer**: Pass control to trusted users with `/transfer`\n\n## Security & Privacy\n\n### Encryption\n- **Private Messages**: X25519 key exchange + AES-256-GCM encryption\n- **Channel Messages**: Argon2id password derivation + AES-256-GCM\n- **Digital Signatures**: Ed25519 for message authenticity\n- **Forward Secrecy**: New key pairs generated each session\n\n### Privacy Features\n- **No Registration**: No accounts, emails, or phone numbers required\n- **Ephemeral by Default**: Messages exist only in device memory\n- **Cover Traffic**: Random delays and dummy messages prevent traffic analysis\n- **Emergency Wipe**: Triple-tap logo to instantly clear all data\n- **Bundled Tor Support**: Built-in Tor network integration for enhanced privacy when internet connectivity is available\n\n## Performance & Efficiency\n\n### Message Compression\n- **LZ4 Compression**: Automatic compression for messages >100 bytes\n- **30-70% bandwidth savings** on typical text messages\n- **Smart compression**: Skips already-compressed data\n\n### Battery Optimization\n- **Adaptive Power Modes**: Automatically adjusts based on battery level\n  - Performance mode: Full features when charging or >60% battery\n  - Balanced mode: Default operation (30-60% battery)\n  - Power saver: Reduced scanning when <30% battery\n  - Ultra-low power: Emergency mode when <10% battery\n- **Background efficiency**: Automatic power saving when app backgrounded\n- **Configurable scanning**: Duty cycle adapts to battery state\n\n### Network Efficiency\n- **Optimized Bloom filters**: Faster duplicate detection with less memory\n- **Message aggregation**: Batches small messages to reduce transmissions\n- **Adaptive connection limits**: Adjusts peer connections based on power mode\n\n## Technical Architecture\n\n### Binary Protocol\nbitchat uses an efficient binary protocol optimized for Bluetooth LE:\n- Compact packet format with 1-byte type field\n- TTL-based message routing (max 7 hops)\n- Automatic fragmentation for large messages\n- Message deduplication via unique IDs\n\n### Mesh Networking\n- Each device acts as both client and peripheral\n- Automatic peer discovery and connection management\n- Store-and-forward for offline message delivery\n- Adaptive duty cycling for battery optimization\n\n### Android-Specific Optimizations\n- **Coroutine Architecture**: Asynchronous operations for mesh networking\n- **Kotlin Coroutines**: Thread-safe concurrent mesh operations\n- **EncryptedSharedPreferences**: Secure storage for user settings\n- **Lifecycle-Aware**: Proper handling of Android app lifecycle\n- **Battery Optimization**: Foreground service and adaptive scanning\n\n## Android Technical Architecture\n\n### Core Components\n\n1. **BitchatApplication.kt**: Application-level initialization and dependency injection\n2. **MainActivity.kt**: Main activity handling permissions and UI hosting\n3. **ChatViewModel.kt**: MVVM pattern managing app state and business logic\n4. **BluetoothMeshService.kt**: Core BLE mesh networking (central + peripheral roles)\n5. **EncryptionService.kt**: Cryptographic operations using BouncyCastle\n6. **BinaryProtocol.kt**: Binary packet encoding/decoding matching iOS format\n7. **ChatScreen.kt**: Jetpack Compose UI with Material Design 3\n\n### Dependencies\n\n- **Jetpack Compose**: Modern declarative UI\n- **BouncyCastle**: Cryptographic operations (X25519, Ed25519, AES-GCM)\n- **Nordic BLE Library**: Reliable Bluetooth LE operations\n- **Kotlin Coroutines**: Asynchronous programming\n- **LZ4**: Message compression (when enabled)\n- **EncryptedSharedPreferences**: Secure local storage\n\n### Binary Protocol Compatibility\n\nThe Android implementation maintains 100% binary protocol compatibility with iOS:\n- **Header Format**: Identical 13-byte header structure\n- **Packet Types**: Same message types and routing logic\n- **Encryption**: Identical cryptographic algorithms and key exchange\n- **UUIDs**: Same Bluetooth service and characteristic identifiers\n- **Fragmentation**: Compatible message fragmentation for large content\n\n## Publishing to Google Play\n\n### Preparation\n\n1. **Update version information:**\n   ```kotlin\n   // In app/build.gradle.kts\n   defaultConfig {\n       versionCode = 2  // Increment for each release\n       versionName = \"1.1.0\"  // User-visible version\n   }\n   ```\n\n2. **Create a signed release build:**\n   ```bash\n   ./gradlew assembleRelease\n   ```\n\n3. **Generate app bundle (recommended for Play Store):**\n   ```bash\n   ./gradlew bundleRelease\n   ```\n\n### Play Store Requirements\n\n- **Target API**: Latest Android API (currently 34)\n- **Privacy Policy**: Required for apps requesting sensitive permissions\n- **App Permissions**: Justify Bluetooth and location usage\n- **Content Rating**: Complete questionnaire for age-appropriate content\n\n### Distribution\n\n- **Google Play Store**: Main distribution channel\n- **F-Droid**: For open-source distribution\n- **Direct APK**: For testing and development\n\n## Cross-Platform Communication\n\nThis Android port enables seamless communication with the original iOS bitchat app:\n\n- **iPhone ‚Üî Android**: Full bidirectional messaging\n- **Mixed Groups**: iOS and Android users in same channels\n- **Feature Parity**: All commands and encryption work across platforms\n- **Protocol Sync**: Identical message format and routing behavior\n\n**iOS Version**: For iPhone/iPad users, get the original bitchat at [github.com/jackjackbits/bitchat](https://github.com/jackjackbits/bitchat)\n\n## Contributing\n\nContributions are welcome! Key areas for enhancement:\n\n1. **Performance**: Battery optimization and connection reliability\n2. **UI/UX**: Additional Material Design 3 features\n3. **Security**: Enhanced cryptographic features\n4. **Testing**: Unit and integration test coverage\n5. **Documentation**: API documentation and development guides\n\n## Support & Issues\n\n- **Bug Reports**: [Create an issue](../../issues) with device info and logs\n- **Feature Requests**: [Start a discussion](https://github.com/orgs/permissionlesstech/discussions)\n- **Security Issues**: Email security concerns privately\n- **iOS Compatibility**: Cross-reference with [original iOS repo](https://github.com/jackjackbits/bitchat)\n\nFor iOS-specific issues, please refer to the [original iOS bitchat repository](https://github.com/jackjackbits/bitchat).\n",
      "stars_today": 19
    },
    {
      "id": 1023959202,
      "name": "runanywhere-sdks",
      "full_name": "RunanywhereAI/runanywhere-sdks",
      "description": "Production ready toolkit to run AI locally",
      "html_url": "https://github.com/RunanywhereAI/runanywhere-sdks",
      "stars": 3744,
      "forks": 111,
      "language": "Kotlin",
      "topics": [
        "agent-framework",
        "android",
        "apple-intelligence",
        "edge",
        "edge-ai",
        "foundational-models",
        "inference",
        "ios",
        "kotlin",
        "llamacpp",
        "llm",
        "multimodal",
        "ollama",
        "on-device-ai",
        "privacy",
        "swift",
        "voice-ai",
        "voice-assistant"
      ],
      "created_at": "2025-07-22T01:23:34Z",
      "updated_at": "2026-01-16T21:56:38Z",
      "pushed_at": "2026-01-16T10:04:29Z",
      "open_issues": 21,
      "owner": {
        "login": "RunanywhereAI",
        "avatar_url": "https://avatars.githubusercontent.com/u/220821781?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"examples/logo.svg\" alt=\"RunAnywhere Logo\" width=\"140\"/>\n</p>\n\n<h1 align=\"center\">RunAnywhere</h1>\n\n<p align=\"center\">\n  <strong>On-device AI for mobile apps.</strong><br/>\n  Run LLMs, speech-to-text, and text-to-speech locally‚Äîprivate, offline, fast.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://apps.apple.com/us/app/runanywhere/id6756506307\">\n    <img src=\"https://img.shields.io/badge/App_Store-Download-0D96F6?style=for-the-badge&logo=apple&logoColor=white\" alt=\"Download on App Store\" />\n  </a>\n  &nbsp;\n  <a href=\"https://play.google.com/store/apps/details?id=com.runanywhere.runanywhereai\">\n    <img src=\"https://img.shields.io/badge/Google_Play-Download-34A853?style=for-the-badge&logo=google-play&logoColor=white\" alt=\"Get it on Google Play\" />\n  </a>\n  &nbsp;\n  <a href=\"https://www.youtube.com/watch?v=GG100ijJHl4\">\n    <img src=\"https://img.shields.io/badge/YouTube-Watch_Demo-FF0000?style=for-the-badge&logo=youtube&logoColor=white\" alt=\"Watch Demo\" />\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/RunanywhereAI/runanywhere-sdks/stargazers\"><img src=\"https://img.shields.io/github/stars/RunanywhereAI/runanywhere-sdks?style=flat-square\" alt=\"GitHub Stars\" /></a>\n  <a href=\"LICENSE\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue?style=flat-square\" alt=\"License\" /></a>\n  <a href=\"https://discord.gg/N359FBbDVd\"><img src=\"https://img.shields.io/discord/1234567890?style=flat-square&logo=discord&logoColor=white&label=Discord\" alt=\"Discord\" /></a>\n</p>\n\n<p align=\"center\">\n  <img src=\"docs/screenshots/main-screenshot.jpg\" alt=\"Chat\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/chat-interface.png\" alt=\"Analytics\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/quiz-flow.png\" alt=\"Structured Output\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/voice-ai.png\" alt=\"Voice AI\" width=\"180\"/>\n</p>\n\n---\n\n## What is RunAnywhere?\n\nRunAnywhere lets you add AI features to your mobile app that run entirely on-device:\n\n- **LLM Chat** ‚Äî Llama, Mistral, Qwen, SmolLM, and more\n- **Speech-to-Text** ‚Äî Whisper-powered transcription\n- **Text-to-Speech** ‚Äî Neural voice synthesis\n- **Voice Assistant** ‚Äî Full STT ‚Üí LLM ‚Üí TTS pipeline\n\nNo cloud. No latency. No data leaves the device.\n\n---\n\n## SDKs\n\n| Platform | Status | Installation | Documentation |\n|----------|--------|--------------|---------------|\n| **Swift** (iOS/macOS) | Stable | [Swift Package Manager](#swift-ios--macos) | [docs.runanywhere.ai/swift](https://docs.runanywhere.ai/swift/introduction) |\n| **Kotlin** (Android) | Stable | [Gradle](#kotlin-android) | [docs.runanywhere.ai/kotlin](https://docs.runanywhere.ai/kotlin/introduction) |\n| **React Native** | Beta | [npm](#react-native) | [docs.runanywhere.ai/react-native](https://docs.runanywhere.ai/react-native/introduction) |\n| **Flutter** | Beta | [pub.dev](#flutter) | [docs.runanywhere.ai/flutter](https://docs.runanywhere.ai/flutter/introduction) |\n\n---\n\n## Quick Start\n\n### Swift (iOS / macOS)\n\n```swift\nimport RunAnywhere\nimport LlamaCPPRuntime\n\n// 1. Initialize\nLlamaCPP.register()\ntry RunAnywhere.initialize()\n\n// 2. Load a model\ntry await RunAnywhere.downloadModel(\"smollm2-360m\")\ntry await RunAnywhere.loadModel(\"smollm2-360m\")\n\n// 3. Generate\nlet response = try await RunAnywhere.chat(\"What is the capital of France?\")\nprint(response) // \"Paris is the capital of France.\"\n```\n\n**Install via Swift Package Manager:**\n\n```\nhttps://github.com/RunanywhereAI/runanywhere-sdks\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/swift/introduction) ¬∑ [Source code](sdk/runanywhere-swift/)\n\n---\n\n### Kotlin (Android)\n\n```kotlin\nimport com.runanywhere.sdk.public.RunAnywhere\nimport com.runanywhere.sdk.public.extensions.*\n\n// 1. Initialize\nLlamaCPP.register()\nRunAnywhere.initialize(environment = SDKEnvironment.DEVELOPMENT)\n\n// 2. Load a model\nRunAnywhere.downloadModel(\"smollm2-360m\").collect { println(\"${it.progress * 100}%\") }\nRunAnywhere.loadLLMModel(\"smollm2-360m\")\n\n// 3. Generate\nval response = RunAnywhere.chat(\"What is the capital of France?\")\nprintln(response) // \"Paris is the capital of France.\"\n```\n\n**Install via Gradle:**\n\n```kotlin\ndependencies {\n    implementation(\"com.runanywhere.sdk:runanywhere-kotlin:0.1.4\")\n    implementation(\"com.runanywhere.sdk:runanywhere-core-llamacpp:0.1.4\")\n}\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/kotlin/introduction) ¬∑ [Source code](sdk/runanywhere-kotlin/)\n\n---\n\n### React Native\n\n```typescript\nimport { RunAnywhere, SDKEnvironment } from '@runanywhere/core';\nimport { LlamaCPP } from '@runanywhere/llamacpp';\n\n// 1. Initialize\nawait RunAnywhere.initialize({ environment: SDKEnvironment.Development });\nLlamaCPP.register();\n\n// 2. Load a model\nawait RunAnywhere.downloadModel('smollm2-360m');\nawait RunAnywhere.loadModel(modelPath);\n\n// 3. Generate\nconst response = await RunAnywhere.chat('What is the capital of France?');\nconsole.log(response); // \"Paris is the capital of France.\"\n```\n\n**Install via npm:**\n\n```bash\nnpm install @runanywhere/core @runanywhere/llamacpp\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/react-native/introduction) ¬∑ [Source code](sdk/runanywhere-react-native/)\n\n---\n\n### Flutter\n\n```dart\nimport 'package:runanywhere/runanywhere.dart';\nimport 'package:runanywhere_llamacpp/runanywhere_llamacpp.dart';\n\n// 1. Initialize\nawait RunAnywhere.initialize();\nawait LlamaCpp.register();\n\n// 2. Load a model\nawait RunAnywhere.downloadModel('smollm2-360m');\nawait RunAnywhere.loadModel('smollm2-360m');\n\n// 3. Generate\nfinal response = await RunAnywhere.chat('What is the capital of France?');\nprint(response); // \"Paris is the capital of France.\"\n```\n\n**Install via pub.dev:**\n\n```yaml\ndependencies:\n  runanywhere: ^0.15.11\n  runanywhere_llamacpp: ^0.15.11\n```\n\n[Full documentation ‚Üí](https://docs.runanywhere.ai/flutter/introduction) ¬∑ [Source code](sdk/runanywhere-flutter/)\n\n---\n\n## Sample Apps\n\nFull-featured demo applications demonstrating SDK capabilities:\n\n| Platform | Source Code | Download |\n|----------|-------------|----------|\n| iOS | [examples/ios/RunAnywhereAI](examples/ios/RunAnywhereAI/) | [App Store](https://apps.apple.com/us/app/runanywhere/id6756506307) |\n| Android | [examples/android/RunAnywhereAI](examples/android/RunAnywhereAI/) | [Google Play](https://play.google.com/store/apps/details?id=com.runanywhere.runanywhereai) |\n| React Native | [examples/react-native/RunAnywhereAI](examples/react-native/RunAnywhereAI/) | Build from source |\n| Flutter | [examples/flutter/RunAnywhereAI](examples/flutter/RunAnywhereAI/) | Build from source |\n\n---\n\n## Features\n\n| Feature | iOS | Android | React Native | Flutter |\n|---------|-----|---------|--------------|---------|\n| LLM Text Generation | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Streaming | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Speech-to-Text | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Text-to-Speech | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Voice Assistant Pipeline | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Model Download + Progress | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Structured Output (JSON) | ‚úÖ | ‚úÖ | üîú | üîú |\n| Apple Foundation Models | ‚úÖ | ‚Äî | ‚Äî | ‚Äî |\n\n---\n\n## Supported Models\n\n### LLM (GGUF format via llama.cpp)\n\n| Model | Size | RAM Required | Use Case |\n|-------|------|--------------|----------|\n| SmolLM2 360M | ~400MB | 500MB | Fast, lightweight |\n| Qwen 2.5 0.5B | ~500MB | 600MB | Multilingual |\n| Llama 3.2 1B | ~1GB | 1.2GB | Balanced |\n| Mistral 7B Q4 | ~4GB | 5GB | High quality |\n\n### Speech-to-Text (Whisper via ONNX)\n\n| Model | Size | Languages |\n|-------|------|-----------|\n| Whisper Tiny | ~75MB | English |\n| Whisper Base | ~150MB | Multilingual |\n\n### Text-to-Speech (Piper via ONNX)\n\n| Voice | Size | Language |\n|-------|------|----------|\n| Piper US English | ~65MB | English (US) |\n| Piper British English | ~65MB | English (UK) |\n\n---\n\n## Repository Structure\n\n```\nrunanywhere-sdks/\n‚îú‚îÄ‚îÄ sdk/\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-swift/          # iOS/macOS SDK\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-kotlin/         # Android SDK\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-react-native/   # React Native SDK\n‚îÇ   ‚îú‚îÄ‚îÄ runanywhere-flutter/        # Flutter SDK\n‚îÇ   ‚îî‚îÄ‚îÄ runanywhere-commons/        # Shared C++ core\n‚îÇ\n‚îú‚îÄ‚îÄ examples/\n‚îÇ   ‚îú‚îÄ‚îÄ ios/RunAnywhereAI/          # iOS sample app\n‚îÇ   ‚îú‚îÄ‚îÄ android/RunAnywhereAI/      # Android sample app\n‚îÇ   ‚îú‚îÄ‚îÄ react-native/RunAnywhereAI/ # React Native sample app\n‚îÇ   ‚îî‚îÄ‚îÄ flutter/RunAnywhereAI/      # Flutter sample app\n‚îÇ\n‚îî‚îÄ‚îÄ docs/                           # Documentation\n```\n\n---\n\n## Requirements\n\n| Platform | Minimum | Recommended |\n|----------|---------|-------------|\n| iOS | 17.0+ | 17.0+ |\n| macOS | 14.0+ | 14.0+ |\n| Android | API 24 (7.0) | API 28+ |\n| React Native | 0.74+ | 0.76+ |\n| Flutter | 3.10+ | 3.24+ |\n\n**Memory:** 2GB minimum, 4GB+ recommended for larger models\n\n---\n\n## Contributing\n\nWe welcome contributions. See our [Contributing Guide](CONTRIBUTING.md) for details.\n\n```bash\n# Clone the repo\ngit clone https://github.com/RunanywhereAI/runanywhere-sdks.git\n\n# Set up a specific SDK (example: Swift)\ncd runanywhere-sdks/sdk/runanywhere-swift\n./scripts/build-swift.sh --setup\n\n# Run the sample app\ncd ../../examples/ios/RunAnywhereAI\nopen RunAnywhereAI.xcodeproj\n```\n\n---\n\n## Support\n\n- **Discord:** [Join our community](https://discord.gg/N359FBbDVd)\n- **GitHub Issues:** [Report bugs or request features](https://github.com/RunanywhereAI/runanywhere-sdks/issues)\n- **Email:** founders@runanywhere.ai\n- **Twitter:** [@RunanywhereAI](https://twitter.com/RunanywhereAI)\n\n---\n\n## License\n\nApache 2.0 ‚Äî see [LICENSE](LICENSE) for details.\n",
      "stars_today": 19
    },
    {
      "id": 306829688,
      "name": "nocobase",
      "full_name": "nocobase/nocobase",
      "description": "NocoBase is the most extensible AI-powered no-code/low-code platform for building business applications and enterprise solutions.",
      "html_url": "https://github.com/nocobase/nocobase",
      "stars": 21195,
      "forks": 2384,
      "language": "TypeScript",
      "topics": [
        "admin-dashboard",
        "airtable",
        "app-builder",
        "crm",
        "crud",
        "developer-tools",
        "erp",
        "internal-tool",
        "internal-tools",
        "low-code",
        "low-code-development-platform",
        "lowcode",
        "no-code",
        "no-code-platform",
        "nocode",
        "project-management",
        "salesforce",
        "self-hosted",
        "web-application",
        "workflows"
      ],
      "created_at": "2020-10-24T07:27:48Z",
      "updated_at": "2026-01-17T00:10:55Z",
      "pushed_at": "2026-01-16T16:56:29Z",
      "open_issues": 285,
      "owner": {
        "login": "nocobase",
        "avatar_url": "https://avatars.githubusercontent.com/u/66196787?v=4"
      },
      "readme": "English | [‰∏≠Êñá](./README.zh-CN.md) | [Êó•Êú¨Ë™û](./README.ja-JP.md)\n\nhttps://github.com/user-attachments/assets/4d11a87b-00e2-48f3-9bf7-389d21072d13\n\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/4112\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/4112\" alt=\"nocobase%2Fnocobase | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n<a href=\"https://www.producthunt.com/posts/nocobase?embed=true&utm_source=badge-top-post-topic-badge&utm_medium=badge&utm_souce=badge-nocobase\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=456520&theme=light&period=weekly&topic_id=267\" alt=\"NocoBase - Scalability&#0045;first&#0044;&#0032;open&#0045;source&#0032;no&#0045;code&#0032;platform | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n</p>\n\n## What is NocoBase\n\nNocoBase is the most extensible AI-powered no-code platform.   \nTotal control. Infinite extensibility. AI collaboration.  \nEnable your team to adapt quickly and cut costs dramatically.  \nNo years of development. No millions wasted.  \nDeploy NocoBase in minutes ‚Äî and take control of everything.\n\nHomepage:  \nhttps://www.nocobase.com/  \n\nOnline Demo:  \nhttps://demo.nocobase.com/new\n\nDocuments:  \nhttps://docs.nocobase.com/\n\nForum:  \nhttps://forum.nocobase.com/\n\nUse Cases:  \nhttps://www.nocobase.com/en/blog/tags/customer-stories\n\n## Release Notes\n\nOur [blog](https://www.nocobase.com/en/blog/timeline) is regularly updated with release notes and provides a weekly summary.\n\n## Distinctive features\n\n### 1. Data model-driven, not form/table‚Äìdriven\n\nInstead of being constrained by forms or tables, NocoBase adopts a data model‚Äìdriven approach, separating data structure from user interface to unlock unlimited possibilities.\n\n- UI and data structure are fully decoupled\n- Multiple blocks and actions can be created for the same table or record in any quantity or form\n- Supports the main database, external databases, and third-party APIs as data sources\n\n![model](https://static-docs.nocobase.com/model.png)\n\n### 2. AI employees, integrated into your business systems\nUnlike standalone AI demos, NocoBase allows you to embed AI capabilities seamlessly into your interfaces, workflows, and data context, making AI truly useful in real business scenarios.\n\n- Define AI employees for roles such as translator, analyst, researcher, or assistant\n- Seamless AI‚Äìhuman collaboration in interfaces and workflows\n- Ensure AI usage is secure, transparent, and customizable for your business needs\n\n![AI-employee](https://static-docs.nocobase.com/ai-employee-home.png)\n\n### 3. What you see is what you get, incredibly easy to use\n\nWhile enabling the development of complex business systems, NocoBase keeps the experience simple and intuitive.\n\n- One-click switch between usage mode and configuration mode\n- Pages serve as a canvas to arrange blocks and actions, similar to Notion\n- Configuration mode is designed for ordinary users, not just programmers\n\n![wysiwyg](https://static-docs.nocobase.com/wysiwyg.gif)\n\n### 4. Everything is a plugin, designed for extension\nAdding more no-code features will never cover every business case. NocoBase is built for extension through its plugin-based microkernel architecture.\n\n- All functionalities are plugins, similar to WordPress\n- Plugins are ready to use upon installation\n- Pages, blocks, actions, APIs, and data sources can all be extended through custom plugins\n\n![plugins](https://static-docs.nocobase.com/plugins.png)\n\n## Installation\n\nNocoBase supports three installation methods:\n\n- <a target=\"_blank\" href=\"https://docs.nocobase.com/welcome/getting-started/installation/docker-compose\">Installing With Docker (üëçRecommended)</a>\n\n  Suitable for no-code scenarios, no code to write. When upgrading, just download the latest image and reboot.\n\n- <a target=\"_blank\" href=\"https://docs.nocobase.com/welcome/getting-started/installation/create-nocobase-app\">Installing from create-nocobase-app CLI</a>\n\n  The business code of the project is completely independent and supports low-code development.\n\n- <a target=\"_blank\" href=\"https://docs.nocobase.com/welcome/getting-started/installation/git-clone\">Installing from Git source code</a>\n\n  If you want to experience the latest unreleased version, or want to participate in the contribution, you need to make changes and debug on the source code, it is recommended to choose this installation method, which requires a high level of development skills, and if the code has been updated, you can git pull the latest code.\n\n## How NocoBase works\n\nhttps://github.com/user-attachments/assets/8d183b44-9bb5-4792-b08f-bc08fe8dfaaf\n",
      "stars_today": 17
    },
    {
      "id": 150954997,
      "name": "VictoriaMetrics",
      "full_name": "VictoriaMetrics/VictoriaMetrics",
      "description": "VictoriaMetrics: fast, cost-effective monitoring solution and time series database",
      "html_url": "https://github.com/VictoriaMetrics/VictoriaMetrics",
      "stars": 16042,
      "forks": 1539,
      "language": "Go",
      "topics": [
        "database",
        "grafana",
        "graphite",
        "influxdb",
        "kubernetes",
        "monitoring",
        "observability",
        "opentelemetry",
        "opentsdb",
        "prometheus",
        "promql",
        "thanos",
        "tsdb"
      ],
      "created_at": "2018-09-30T09:58:01Z",
      "updated_at": "2026-01-17T00:35:13Z",
      "pushed_at": "2026-01-16T20:08:09Z",
      "open_issues": 766,
      "owner": {
        "login": "VictoriaMetrics",
        "avatar_url": "https://avatars.githubusercontent.com/u/43720803?v=4"
      },
      "readme": "# VictoriaMetrics\n\n[![Latest Release](https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaMetrics?sort=semver&label=&filter=!*-victorialogs&logo=github&labelColor=gray&color=gray&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Freleases%2Flatest)](https://github.com/VictoriaMetrics/VictoriaMetrics/releases)\n![Docker Pulls](https://img.shields.io/docker/pulls/victoriametrics/victoria-metrics?label=&logo=docker&logoColor=white&labelColor=2496ED&color=2496ED&link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-metrics)\n[![Go Report](https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaMetrics?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics)](https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaMetrics)\n[![Build Status](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml/badge.svg?branch=master&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Factions)](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml)\n[![codecov](https://codecov.io/gh/VictoriaMetrics/VictoriaMetrics/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaMetrics)](https://app.codecov.io/gh/VictoriaMetrics/VictoriaMetrics)\n[![License](https://img.shields.io/github/license/VictoriaMetrics/VictoriaMetrics?labelColor=green&label=&link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Fblob%2Fmaster%2FLICENSE)](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/LICENSE)\n![Slack](https://img.shields.io/badge/Join-4A154B?logo=slack&link=https%3A%2F%2Fslack.victoriametrics.com)\n[![X](https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&label=Follow&color=black&logo=x&labelColor=black&link=https%3A%2F%2Fx.com%2FVictoriaMetrics)](https://x.com/VictoriaMetrics/)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&label=Join&labelColor=red&logoColor=white&logo=reddit&link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics)](https://www.reddit.com/r/VictoriaMetrics/)\n\n<picture>\n  <source srcset=\"docs/victoriametrics/logo_white.webp\" media=\"(prefers-color-scheme: dark)\">\n  <source srcset=\"docs/victoriametrics/logo.webp\" media=\"(prefers-color-scheme: light)\">\n  <img src=\"docs/victoriametrics/logo.webp\" width=\"300\" alt=\"VictoriaMetrics logo\">\n</picture>\n\nVictoriaMetrics is a fast, cost-saving, and scalable solution for monitoring and managing time series data. It delivers high performance and reliability, making it an ideal choice for businesses of all sizes.\n\nHere are some resources and information about VictoriaMetrics:\n\n- Documentation: [docs.victoriametrics.com](https://docs.victoriametrics.com)\n- Case studies: [Grammarly, Roblox, Wix,...](https://docs.victoriametrics.com/victoriametrics/casestudies/).\n- Available: [Binary releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest), docker images [Docker Hub](https://hub.docker.com/r/victoriametrics/victoria-metrics/) and [Quay](https://quay.io/repository/victoriametrics/victoria-metrics), [Source code](https://github.com/VictoriaMetrics/VictoriaMetrics)\n- Deployment types: [Single-node version](https://docs.victoriametrics.com/), [Cluster version](https://docs.victoriametrics.com/victoriametrics/cluster-victoriametrics/), and [Enterprise version](https://docs.victoriametrics.com/victoriametrics/enterprise/)\n- Changelog: [CHANGELOG](https://docs.victoriametrics.com/victoriametrics/changelog/), and [How to upgrade](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-upgrade-victoriametrics)\n- Community: [Slack](https://slack.victoriametrics.com/), [X (Twitter)](https://x.com/VictoriaMetrics), [LinkedIn](https://www.linkedin.com/company/victoriametrics/), [YouTube](https://www.youtube.com/@VictoriaMetrics)\n\nYes, we open-source both the single-node VictoriaMetrics and the cluster version.\n\n## Prominent features\n\nVictoriaMetrics is optimized for timeseries data, even when old time series are constantly replaced by new ones at a high rate, it offers a lot of features:\n\n* **Long-term storage for Prometheus** or as a drop-in replacement for Prometheus and Graphite in Grafana.\n* **Powerful stream aggregation**: Can be used as a StatsD alternative.\n* **Ideal for big data**: Works well with large amounts of time series data from APM, Kubernetes, IoT sensors, connected cars, industrial telemetry, financial data and various [Enterprise workloads](https://docs.victoriametrics.com/victoriametrics/enterprise/).\n* **Query language**: Supports both PromQL and the more performant MetricsQL.\n* **Easy to setup**: No dependencies, single [small binary](https://medium.com/@valyala/stripping-dependency-bloat-in-victoriametrics-docker-image-983fb5912b0d), configuration through command-line flags, but the default is also fine-tuned; backup and restore with [instant snapshots](https://medium.com/@valyala/how-victoriametrics-makes-instant-snapshots-for-multi-terabyte-time-series-data-e1f3fb0e0282).\n* **Global query view**: Multiple Prometheus instances or any other data sources may ingest data into VictoriaMetrics and queried via a single query.\n* **Various Protocols**: Support metric scraping, ingestion and backfilling in various protocol.\n    * [Prometheus exporters](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-scrape-prometheus-exporters-such-as-node-exporter), [Prometheus remote write API](https://docs.victoriametrics.com/victoriametrics/integrations/prometheus/), [Prometheus exposition format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-prometheus-exposition-format).\n    * [InfluxDB line protocol](https://docs.victoriametrics.com/victoriametrics/integrations/influxdb/) over HTTP, TCP and UDP.\n    * [Graphite plaintext protocol](https://docs.victoriametrics.com/victoriametrics/integrations/graphite/#ingesting) with [tags](https://graphite.readthedocs.io/en/latest/tags.html#carbon).\n    * [OpenTSDB put message](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-telnet).\n    * [HTTP OpenTSDB /api/put requests](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-http).\n    * [JSON line format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-json-line-format).\n    * [Arbitrary CSV data](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-csv-data).\n    * [Native binary format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-native-format).\n    * [DataDog agent or DogStatsD](https://docs.victoriametrics.com/victoriametrics/integrations/datadog/).\n    * [NewRelic infrastructure agent](https://docs.victoriametrics.com/victoriametrics/integrations/newrelic/#sending-data-from-agent).\n    * [OpenTelemetry metrics format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#sending-data-via-opentelemetry).\n* **NFS-based storages**: Supports storing data on NFS-based storages such as Amazon EFS, Google Filestore.\n* And many other features such as metrics relabeling, cardinality limiter, etc.\n\n## Enterprise version\n\nIn addition, the Enterprise version includes extra features:\n\n- **Anomaly detection**: Automation and simplification of your alerting rules, covering complex anomalies found in metrics data.\n- **Backup automation**: Automates regular backup procedures.\n- **Multiple retentions**: Reducing storage costs by specifying different retentions for different datasets.\n- **Downsampling**: Reducing storage costs and increasing performance for queries over historical data.\n- **Stable releases** with long-term support lines ([LTS](https://docs.victoriametrics.com/victoriametrics/lts-releases/)).\n- **Comprehensive support**: First-class consulting, feature requests and technical support provided by the core VictoriaMetrics dev team.\n- Many other features, which you can read about on [the Enterprise page](https://docs.victoriametrics.com/victoriametrics/enterprise/).\n\n[Contact us](mailto:info@victoriametrics.com) if you need enterprise support for VictoriaMetrics. Or you can request a free trial license [here](https://victoriametrics.com/products/enterprise/trial/), downloaded Enterprise binaries are available at [Github Releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest).\n\nWe strictly apply security measures in everything we do. VictoriaMetrics has achieved security certifications for Database Software Development and Software-Based Monitoring Services. See [Security page](https://victoriametrics.com/security/) for more details.\n\n## Benchmarks \n\nSome good benchmarks VictoriaMetrics achieved:\n\n* **Minimal memory footprint**: handling millions of unique timeseries with [10x less RAM](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) than InfluxDB, up to [7x less RAM](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) than Prometheus, Thanos or Cortex.\n* **Highly scalable and performance** for [data ingestion](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and [querying](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4), [20x outperforms](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) InfluxDB and TimescaleDB.\n* **High data compression**: [70x more data points](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4) may be stored into limited storage than TimescaleDB, [7x less storage](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) space is required than Prometheus, Thanos or Cortex.\n* **Reducing storage costs**: [10x more effective](https://docs.victoriametrics.com/victoriametrics/casestudies/#grammarly) than Graphite according to the Grammarly case study.\n* **A single-node VictoriaMetrics** can replace medium-sized clusters built with competing solutions such as Thanos, M3DB, Cortex, InfluxDB or TimescaleDB. See [VictoriaMetrics vs Thanos](https://medium.com/@valyala/comparing-thanos-to-victoriametrics-cluster-b193bea1683), [Measuring vertical scalability](https://medium.com/@valyala/measuring-vertical-scalability-for-time-series-databases-in-google-cloud-92550d78d8ae), [Remote write storage wars - PromCon 2019](https://promcon.io/2019-munich/talks/remote-write-storage-wars/).\n* **Optimized for storage**: [Works well with high-latency IO](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and low IOPS (HDD and network storage in AWS, Google Cloud, Microsoft Azure, etc.).\n\n## Community and contributions\n\nFeel free asking any questions regarding VictoriaMetrics:\n\n* [Slack Inviter](https://slack.victoriametrics.com/) and [Slack channel](https://victoriametrics.slack.com/)\n* [X (Twitter)](https://x.com/VictoriaMetrics/)\n* [Linkedin](https://www.linkedin.com/company/victoriametrics/)\n* [Reddit](https://www.reddit.com/r/VictoriaMetrics/)\n* [Telegram-en](https://t.me/VictoriaMetrics_en)\n* [Telegram-ru](https://t.me/VictoriaMetrics_ru1)\n* [Mastodon](https://mastodon.social/@victoriametrics/)\n\nIf you like VictoriaMetrics and want to contribute, then please [read these docs](https://docs.victoriametrics.com/victoriametrics/contributing/).\n\n## VictoriaMetrics Logo\n\nThe provided [ZIP file](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/VM_logo.zip) contains three folders with different logo orientations. Each folder includes the following file types:\n\n* JPEG: Preview files\n* PNG: Preview files with transparent background\n* AI: Adobe Illustrator files\n\n### VictoriaMetrics Logo Usage Guidelines\n\n#### Font\n\n* Font Used: Lato Black\n* Download here: [Lato Font](https://fonts.google.com/specimen/Lato)\n\n#### Color Palette\n\n* Black [#000000](https://www.color-hex.com/color/000000)\n* Purple [#4d0e82](https://www.color-hex.com/color/4d0e82)\n* Orange [#ff2e00](https://www.color-hex.com/color/ff2e00)\n* White [#ffffff](https://www.color-hex.com/color/ffffff)\n\n### Logo Usage Rules\n\n* Only use the Lato Black font as specified.\n* Maintain sufficient clear space around the logo for visibility.\n* Do not modify the spacing, alignment, or positioning of design elements.\n* You may resize the logo as needed, but ensure all proportions remain intact.\n\nThank you for your cooperation!\n",
      "stars_today": 17
    },
    {
      "id": 81227005,
      "name": "faiss",
      "full_name": "facebookresearch/faiss",
      "description": "A library for efficient similarity search and clustering of dense vectors.",
      "html_url": "https://github.com/facebookresearch/faiss",
      "stars": 38773,
      "forks": 4189,
      "language": "C++",
      "topics": [],
      "created_at": "2017-02-07T16:07:05Z",
      "updated_at": "2026-01-16T20:28:18Z",
      "pushed_at": "2026-01-16T03:02:11Z",
      "open_issues": 280,
      "owner": {
        "login": "facebookresearch",
        "avatar_url": "https://avatars.githubusercontent.com/u/16943930?v=4"
      },
      "readme": "# Faiss\n\nFaiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. Faiss is written in C++ with complete wrappers for Python/numpy. Some of the most useful algorithms are implemented on the GPU. It is developed primarily at Meta's [Fundamental AI Research](https://ai.facebook.com/) group.\n\n## News\n\nSee [CHANGELOG.md](CHANGELOG.md) for detailed information about latest features.\n\n## Introduction\n\nFaiss contains several methods for similarity search. It assumes that the instances are represented as vectors and are identified by an integer, and that the vectors can be compared with L2 (Euclidean) distances or dot products. Vectors that are similar to a query vector are those that have the lowest L2 distance or the highest dot product with the query vector. It also supports cosine similarity, since this is a dot product on normalized vectors.\n\nSome of the methods, like those based on binary vectors and compact quantization codes, solely use a compressed representation of the vectors and do not require to keep the original vectors. This generally comes at the cost of a less precise search but these methods can scale to billions of vectors in main memory on a single server. Other methods, like HNSW and NSG add an indexing structure on top of the raw vectors to make searching more efficient.\n\nThe GPU implementation can accept input from either CPU or GPU memory. On a server with GPUs, the GPU indexes can be used a drop-in replacement for the CPU indexes (e.g., replace `IndexFlatL2` with `GpuIndexFlatL2`) and copies to/from GPU memory are handled automatically. Results will be faster however if both input and output remain resident on the GPU. Both single and multi-GPU usage is supported.\n\n## Installing\n\nFaiss comes with precompiled libraries for Anaconda in Python, see [faiss-cpu](https://anaconda.org/pytorch/faiss-cpu), [faiss-gpu](https://anaconda.org/pytorch/faiss-gpu) and [faiss-gpu-cuvs](https://anaconda.org/pytorch/faiss-gpu-cuvs). The library is mostly implemented in C++, the only dependency is a [BLAS](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) implementation. Optional GPU support is provided via CUDA or AMD ROCm, and the Python interface is also optional. The backend GPU implementations of NVIDIA [cuVS](https://github.com/rapidsai/cuvs) can also be enabled optionally. It compiles with cmake. See [INSTALL.md](INSTALL.md) for details.\n\n## How Faiss works\n\nFaiss is built around an index type that stores a set of vectors, and provides a function to search in them with L2 and/or dot product vector comparison. Some index types are simple baselines, such as exact search. Most of the available indexing structures correspond to various trade-offs with respect to\n\n- search time\n- search quality\n- memory used per index vector\n- training time\n- adding time\n- need for external data for unsupervised training\n\nThe optional GPU implementation provides what is likely (as of March 2017) the fastest exact and approximate (compressed-domain) nearest neighbor search implementation for high-dimensional vectors, fastest Lloyd's k-means, and fastest small k-selection algorithm known. [The implementation is detailed here](https://arxiv.org/abs/1702.08734).\n\n## Full documentation of Faiss\n\nThe following are entry points for documentation:\n\n- the full documentation can be found on the [wiki page](http://github.com/facebookresearch/faiss/wiki), including a [tutorial](https://github.com/facebookresearch/faiss/wiki/Getting-started), a [FAQ](https://github.com/facebookresearch/faiss/wiki/FAQ) and a [troubleshooting section](https://github.com/facebookresearch/faiss/wiki/Troubleshooting)\n- the [doxygen documentation](https://faiss.ai/) gives per-class information extracted from code comments\n- to reproduce results from our research papers, [Polysemous codes](https://arxiv.org/abs/1609.01882) and [Billion-scale similarity search with GPUs](https://arxiv.org/abs/1702.08734), refer to the [benchmarks README](benchs/README.md). For [\nLink and code: Fast indexing with graphs and compact regression codes](https://arxiv.org/abs/1804.09996), see the [link_and_code README](benchs/link_and_code)\n\n## Authors\n\nThe main authors of Faiss are:\n- [Herv√© J√©gou](https://github.com/jegou) initiated the Faiss project and wrote its first implementation\n- [Matthijs Douze](https://github.com/mdouze) implemented most of the CPU Faiss\n- [Jeff Johnson](https://github.com/wickedfoo) implemented all of the GPU Faiss\n- [Lucas Hosseini](https://github.com/beauby) implemented the binary indexes and the build system\n- [Chengqi Deng](https://github.com/KinglittleQ) implemented NSG, NNdescent and much of the additive quantization code.\n- [Alexandr Guzhva](https://github.com/alexanderguzhva) many optimizations: SIMD, memory allocation and layout, fast decoding kernels for vector codecs, etc.\n- [Gergely Szilvasy](https://github.com/algoriddle) build system, benchmarking framework.\n\n## Reference\n\nReferences to cite when you use Faiss in a research paper:\n```\n@article{douze2024faiss,\n      title={The Faiss library},\n      author={Matthijs Douze and Alexandr Guzhva and Chengqi Deng and Jeff Johnson and Gergely Szilvasy and Pierre-Emmanuel Mazar√© and Maria Lomeli and Lucas Hosseini and Herv√© J√©gou},\n      year={2024},\n      eprint={2401.08281},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}\n```\nFor the GPU version of Faiss, please cite:\n```\n@article{johnson2019billion,\n  title={Billion-scale similarity search with {GPUs}},\n  author={Johnson, Jeff and Douze, Matthijs and J{\\'e}gou, Herv{\\'e}},\n  journal={IEEE Transactions on Big Data},\n  volume={7},\n  number={3},\n  pages={535--547},\n  year={2019},\n  publisher={IEEE}\n}\n```\n\n## Join the Faiss community\n\nFor public discussion of Faiss or for questions, visit https://github.com/facebookresearch/faiss/discussions.\n\nWe monitor the [issues page](http://github.com/facebookresearch/faiss/issues) of the repository.\nYou can report bugs, ask questions, etc.\n\n## Legal\n\nFaiss is MIT-licensed, refer to the [LICENSE file](https://github.com/facebookresearch/faiss/blob/main/LICENSE) in the top level directory.\n\nCopyright ¬© Meta Platforms, Inc.\n",
      "stars_today": 15
    },
    {
      "id": 1020533866,
      "name": "joyagent-jdgenie",
      "full_name": "jd-opensource/joyagent-jdgenie",
      "description": "ÂºÄÊ∫êÁöÑÁ´ØÂà∞Á´Ø‰∫ßÂìÅÁ∫ßÈÄöÁî®Êô∫ËÉΩ‰Ωì",
      "html_url": "https://github.com/jd-opensource/joyagent-jdgenie",
      "stars": 11143,
      "forks": 1485,
      "language": "Java",
      "topics": [],
      "created_at": "2025-07-16T02:59:53Z",
      "updated_at": "2026-01-16T16:42:16Z",
      "pushed_at": "2025-12-16T13:38:16Z",
      "open_issues": 203,
      "owner": {
        "login": "jd-opensource",
        "avatar_url": "https://avatars.githubusercontent.com/u/75349771?v=4"
      },
      "readme": "# AgentÂºÄÊ∫êgitÂºÄÊ∫êÊñáÊ°£\nÁÆÄ‰Ωì‰∏≠Êñá | [English Version](README_EN.md)\n\n## ‰∏öÁïåÈ¶ñ‰∏™ÂºÄÊ∫êÈ´òÂÆåÊàêÂ∫¶ËΩªÈáèÂåñÈÄöÁî®Â§öÊô∫ËÉΩ‰Ωì‰∫ßÂìÅ(JoyAgent-JDGenie)\n**Ëß£ÂÜ≥Âø´ÈÄüÊûÑÂª∫Â§öÊô∫ËÉΩ‰Ωì‰∫ßÂìÅÁöÑÊúÄÂêé‰∏ÄÂÖ¨ÈáåÈóÆÈ¢ò**\n\n## new release\nÂ§öÊ®°ÊÄÅÁü•ËØÜÁÆ°ÁêÜÂπ≥Âè∞ÊòØ‰∏ÄÊ¨æÈù¢ÂêëÂ§öÊ®°ÊÄÅÈùûÁªìÊûÑÂåñÁü•ËØÜÁöÑRAGËß£ÂÜ≥ÊñπÊ°àÔºåÈõÜÊàêËß£Êûê„ÄÅÊ£ÄÁ¥¢‰∏éÁîüÊàêËÉΩÂäõÔºåËÉΩÂ§üÈ´òÊïàÂ§ÑÁêÜÂ§çÊùÇÊñáÊ°£Ôºå‰∏∫Êô∫ËÉΩÈóÆÁ≠î‰∏éÂÜÖÂÆπÁîüÊàêÊèê‰æõ‰∏ÄÁ´ôÂºèÊîØÊåÅ„ÄÇ\n\n[**<font color=red>Â§öÊ®°ÊÄÅÁü•ËØÜÁÆ°ÁêÜÔºöÈù¢ÂêëÂ§öÊ®°ÊÄÅÊñáÊ°£ÁöÑÁªºÂêàÊÄßRAGÂπ≥Âè∞Ôºå‰∏∫Â§çÊùÇÊñáÊ°£ÁöÑÊô∫ËÉΩÈóÆÁ≠î‰∏éÂÜÖÂÆπÁîüÊàêÊèê‰æõ‰∏ÄÁ´ôÂºèËß£ÂÜ≥ÊñπÊ°à„ÄÇ</font>**](README_mrag.md)\nÔºàÊ≥®ÊÑè‰ΩøÁî®mragÂàÜÊîØÔºâ\n![](./docs/img/mrag/mrag_struct.png)\n\n‰ºÅ‰∏öÂÜÖÈÉ®Áü•ËØÜ‰∏ªË¶ÅÂåÖÊã¨ÁªìÊûÑÂåñË°®Ê†ºÁü•ËØÜÂíåÈùûÁªìÊûÑÂåñÁü•ËØÜ„ÄÇÂõ†Ê≠§ÂØπ‰∫éÁªìÊûÑÂåñË°®Ê†ºÁü•ËØÜÂª∫ËÆæ‰∫ÜÂºÄÁÆ±Âç≥Áî®ÁöÑDataAgentËÉΩÂäõÔºå‰∏ªË¶ÅÂåÖÊã¨Êï∞ÊçÆÊ≤ªÁêÜDGPÂçèËÆÆ„ÄÅÊô∫ËÉΩÈóÆÊï∞ÂíåÊô∫ËÉΩËØäÊñ≠ÂàÜÊûê„ÄÇ\n\n[**<font color=red>JoyDataAgentÔºöÈ¶ñ‰∏™ÂºÄÊ∫êÁöÑÂåÖÂê´Êï∞ÊçÆÊ≤ªÁêÜDGPÂçèËÆÆ„ÄÅÊô∫ËÉΩÈóÆÊï∞ÂíåÊô∫ËÉΩËØäÊñ≠ÂàÜÊûêÁöÑÊô∫ËÉΩ‰Ωì</font>**](README_DataAgent.md)\nÔºàÊ≥®ÊÑè‰ΩøÁî®data_agentÂàÜÊîØÔºâ\n<img width=\"1200\" height=\"675\" alt=\"image\" src=\"https://github.com/user-attachments/assets/3a449185-4863-4171-8dda-72cb70b2fa91\" />\n\n## ÁÆÄ‰ªã\n\nÂΩìÂâçÁõ∏ÂÖ≥ÂºÄÊ∫êagent‰∏ªË¶ÅÊòØSDKÊàñËÄÖÊ°ÜÊû∂ÔºåÁî®Êà∑ËøòÈúÄÂü∫‰∫éÊ≠§ÂÅöËøõ‰∏ÄÊ≠•ÁöÑÂºÄÂèëÔºåÊó†Ê≥ïÁõ¥Êé•ÂÅöÂà∞ÂºÄÁÆ±Âç≥Áî®„ÄÇÊàë‰ª¨ÂºÄÊ∫êÁöÑJoyAgent-JDGenieÊòØÁ´ØÂà∞Á´ØÁöÑÂ§öAgent‰∫ßÂìÅÔºåÂØπ‰∫éËæìÂÖ•ÁöÑqueryÊàñËÄÖ‰ªªÂä°ÔºåÂèØ‰ª•Áõ¥Êé•ÂõûÁ≠îÊàñËÄÖËß£ÂÜ≥„ÄÇ‰æãÂ¶ÇÁî®Êà∑query\"ÁªôÊàëÂÅö‰∏Ä‰∏™ÊúÄËøëÁæéÂÖÉÂíåÈªÑÈáëÁöÑËµ∞ÂäøÂàÜÊûê\"ÔºåJoyAgent-GenieÂèØ‰ª•Áõ¥Êé•ÁªôÂá∫ÁΩëÈ°µÁâàÊàñËÄÖPPTÁâàÁöÑÊä•ÂëäÊñáÊ°£„ÄÇ\n\nJoyAgent-JDGenieÊòØ‰∏Ä‰∏™ÈÄöÁî®ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºåÂØπ‰∫éÁî®Êà∑ÈúÄË¶ÅÂÆöÂà∂ÁöÑ‰∏Ä‰∫õÊñ∞Âú∫ÊôØÂäüËÉΩÔºåÂè™ÈúÄÂ∞ÜÁõ∏ÂÖ≥ÁöÑÂ≠êÊô∫ËÉΩ‰ΩìÊàñËÄÖÂ∑•ÂÖ∑ÊåÇËΩΩÂà∞JoyAgent-GenieÂç≥ÂèØ„ÄÇ‰∏∫‰∫ÜÈ™åËØÅJoyAgent-JDGenieÁöÑÈÄöÁî®ÊÄßÔºåÂú®GAIAÊ¶úÂçïValidationÈõÜÂáÜÁ°ÆÁéá**75.15%„ÄÅ**TestÈõÜ**65.12%**ÔºåÂ∑≤Ë∂ÖË∂äOWLÔºàCAMELÔºâ„ÄÅSmolagentÔºàHuggingfaceÔºâ„ÄÅLRC-HuaweiÔºàHuaweiÔºâ„ÄÅxManusÔºàOpenManusÔºâ„ÄÅAutoAgentÔºàÈ¶ôÊ∏ØÂ§ßÂ≠¶ÔºâÁ≠âË°å‰∏öÁü•Âêç‰∫ßÂìÅ„ÄÇ\n\nÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑÂºÄÊ∫êÂ§öÊô∫ËÉΩ‰Ωì‰∫ßÂìÅJoyAgent-JDGenieÁõ∏ÂØπÊØîËæÉËΩªÈáèÔºå‰∏çÂÉèÈòøÈáåÁöÑSpringAI-AlibabaÈúÄË¶Å‰æùËµñÈòøÈáå‰∫ëÁôæÁÇºÂπ≥Âè∞Áõ∏ÂÖ≥ÂäüËÉΩÔºàÂü∫‰∫éÁôæÁÇºÂπ≥Âè∞Ë∞ÉÁî®LLMÔºâÔºåCoze‰æùËµñÁÅ´Â±±ÂºïÊìéÂπ≥Âè∞„ÄÇ\n\nÊàë‰ª¨Êï¥‰ΩìÂºÄÊ∫ê‰∫ÜÊô∫ËÉΩ‰Ωì‰∫ßÂìÅJoyAgent-JDGenieÔºåÂåÖÊã¨ÂâçÁ´Ø„ÄÅÂêéÁ´Ø„ÄÅÊ°ÜÊû∂„ÄÅÂºïÊìé„ÄÅÊ†∏ÂøÉÂ≠êÊô∫ËÉΩ‰ΩìÔºàÊä•ÂëäÁîüÊàêÊô∫ËÉΩ‰Ωì„ÄÅ‰ª£Á†ÅÊô∫ËÉΩ‰Ωì„ÄÅPPTÊô∫ËÉΩ‰Ωì„ÄÅÊñá‰ª∂Êô∫ËÉΩ‰ΩìÁ≠âÔºâ„ÄÅÊÉ≥Áî®ÂæÆË∞ÉÂêéÊïàÊûúÊõ¥Â•ΩÁöÑÊ¨¢Ëøé‰ΩøÁî®JoyAgent„ÄÇ\n## Ê°à‰æãÂ±ïÁ§∫\n<table>\n<tbody>\n<tr>\n<td><img src=\"./docs/img/È¶ñÈ°µ.png\" alt=\"\"></td>\n<td><img src=\"./docs/img/ppt.png\" alt=\"\"></td>\n</tr>\n<tr>\n<td><img src=\"./docs/img/report.png\" alt=\"\"></td>\n<td><img src=\"./docs/img/table_analysis.png\" alt=\"\"></td>\n</tr>\n</tbody>\n</table>\n\n\n\n<table>\n<tbody>\n<tr>\n<td>\n\n<video src=\"https://private-user-images.githubusercontent.com/49786633/469170308-065b8d1a-92e4-470a-bbe3-426fafeca5c4.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTMxOTEzNzEsIm5iZiI6MTc1MzE5MTA3MSwicGF0aCI6Ii80OTc4NjYzMy80NjkxNzAzMDgtMDY1YjhkMWEtOTJlNC00NzBhLWJiZTMtNDI2ZmFmZWNhNWM0Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA3MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNzIyVDEzMzExMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWRjNGY5ZTlmMTA4ODVhMWE0ZmEzYzU3YTIwYzJkYmIyY2Y0ZWE0NGUwZWU2ODAxNDA2MzQ0NzMyMWFlNTdiNWImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.fJyoUGcWjPWyG64ZwIcWWKz3FrBWuXAHHfdTLpIaaeU\" data-canonical-src=\"https://private-user-images.githubusercontent.com/49786633/469170308-065b8d1a-92e4-470a-bbe3-426fafeca5c4.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTMxOTEzNzEsIm5iZiI6MTc1MzE5MTA3MSwicGF0aCI6Ii80OTc4NjYzMy80NjkxNzAzMDgtMDY1YjhkMWEtOTJlNC00NzBhLWJiZTMtNDI2ZmFmZWNhNWM0Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA3MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNzIyVDEzMzExMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWRjNGY5ZTlmMTA4ODVhMWE0ZmEzYzU3YTIwYzJkYmIyY2Y0ZWE0NGUwZWU2ODAxNDA2MzQ0NzMyMWFlNTdiNWImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.fJyoUGcWjPWyG64ZwIcWWKz3FrBWuXAHHfdTLpIaaeU\" controls=\"controls\" muted=\"muted\" class=\"d-block rounded-bottom-2 border-top width-fit\" style=\"max-height:640px; min-height: 200px\">\n</video>\n\n<td>\n\n<video src=\"https://private-user-images.githubusercontent.com/49786633/469171050-15dcf089-5659-489e-849d-39c651ca7e5a.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTMxOTEzNzEsIm5iZiI6MTc1MzE5MTA3MSwicGF0aCI6Ii80OTc4NjYzMy80NjkxNzEwNTAtMTVkY2YwODktNTY1OS00ODllLTg0OWQtMzljNjUxY2E3ZTVhLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA3MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNzIyVDEzMzExMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTY5ZGU2MWU3NzA5NjYxM2ZhZDYxYTZjMWQxYWMzNGM2MTY2ODkzMTIzYjQ1NzRiOGZkOWUyODYzNmQ4N2Y5ZTUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.7KW-JGmFACnf5IS3kL7M0eV8uZhlxDD8Br61XvcgmjY\" data-canonical-src=\"https://private-user-images.githubusercontent.com/49786633/469171050-15dcf089-5659-489e-849d-39c651ca7e5a.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTMxOTEzNzEsIm5iZiI6MTc1MzE5MTA3MSwicGF0aCI6Ii80OTc4NjYzMy80NjkxNzEwNTAtMTVkY2YwODktNTY1OS00ODllLTg0OWQtMzljNjUxY2E3ZTVhLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA3MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNzIyVDEzMzExMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTY5ZGU2MWU3NzA5NjYxM2ZhZDYxYTZjMWQxYWMzNGM2MTY2ODkzMTIzYjQ1NzRiOGZkOWUyODYzNmQ4N2Y5ZTUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.7KW-JGmFACnf5IS3kL7M0eV8uZhlxDD8Br61XvcgmjY\" controls=\"controls\" muted=\"muted\" class=\"d-block rounded-bottom-2 border-top width-fit\" style=\"max-height:640px; min-height: 200px\">\n</video>\n\n</td>\n</tr>\n<tr>\n<td>\n<video src=\"https://private-user-images.githubusercontent.com/49786633/469171112-cd99e2f8-9887-459f-ae51-00e7883fa050.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTMxOTEzNzEsIm5iZiI6MTc1MzE5MTA3MSwicGF0aCI6Ii80OTc4NjYzMy80NjkxNzExMTItY2Q5OWUyZjgtOTg4Ny00NTlmLWFlNTEtMDBlNzg4M2ZhMDUwLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA3MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNzIyVDEzMzExMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWYyYmU5ODg4ZjI5NDNjZjBiYTVjYWRjMTI2ZGEyMDdjOWU2OTk2M2EwZjU4N2ZkYzU5NTQ5ZDJjMmUxMWNjNjAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.OSPODm-E7K7PJaao8uThG1toIKsX3h93UEXS5GDqruQ\" data-canonical-src=\"https://private-user-images.githubusercontent.com/49786633/469171112-cd99e2f8-9887-459f-ae51-00e7883fa050.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTMxOTEzNzEsIm5iZiI6MTc1MzE5MTA3MSwicGF0aCI6Ii80OTc4NjYzMy80NjkxNzExMTItY2Q5OWUyZjgtOTg4Ny00NTlmLWFlNTEtMDBlNzg4M2ZhMDUwLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA3MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNzIyVDEzMzExMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWYyYmU5ODg4ZjI5NDNjZjBiYTVjYWRjMTI2ZGEyMDdjOWU2OTk2M2EwZjU4N2ZkYzU5NTQ5ZDJjMmUxMWNjNjAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.OSPODm-E7K7PJaao8uThG1toIKsX3h93UEXS5GDqruQ\" controls=\"controls\" muted=\"muted\" class=\"d-block rounded-bottom-2 border-top width-fit\" style=\"max-height:640px; min-height: 200px\">\n</video>\n</td>\n<td>\n\n<video src=\"https://private-user-images.githubusercontent.com/49786633/469171151-657bbe61-5516-4ab9-84c2-c6ca75cc4a6f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTMxOTEzNzEsIm5iZiI6MTc1MzE5MTA3MSwicGF0aCI6Ii80OTc4NjYzMy80NjkxNzExNTEtNjU3YmJlNjEtNTUxNi00YWI5LTg0YzItYzZjYTc1Y2M0YTZmLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA3MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNzIyVDEzMzExMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTVmNGExZTlhNmM5NWMzMjc3ZWFlNTcyMzZjZTA4NWU4ZjY3OTA5ZTg5NzgwNDA2ODExNTg5MTkyNGQ5NDYzNTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.n3ZWlSK1GSM5Zyibk-D9jAArzDqvX3WdZtj7IdzG-4I\" data-canonical-src=\"https://private-user-images.githubusercontent.com/49786633/469171151-657bbe61-5516-4ab9-84c2-c6ca75cc4a6f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTMxOTEzNzEsIm5iZiI6MTc1MzE5MTA3MSwicGF0aCI6Ii80OTc4NjYzMy80NjkxNzExNTEtNjU3YmJlNjEtNTUxNi00YWI5LTg0YzItYzZjYTc1Y2M0YTZmLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA3MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNzIyVDEzMzExMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTVmNGExZTlhNmM5NWMzMjc3ZWFlNTcyMzZjZTA4NWU4ZjY3OTA5ZTg5NzgwNDA2ODExNTg5MTkyNGQ5NDYzNTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.n3ZWlSK1GSM5Zyibk-D9jAArzDqvX3WdZtj7IdzG-4I\" controls=\"controls\" muted=\"muted\" class=\"d-block rounded-bottom-2 border-top width-fit\" style=\"max-height:640px; min-height: 200px\">\n</video>\n  \n</td>\n</tr>\n</tbody>\n</table>\n\n## ‰∫ßÂìÅÂØπÊØî\n\n<table>\n<thead>\n<tr>\n<th>ÂàÜÁ±ª</th>\n<th>agent</th>\n<th>ÊòØÂê¶ÂºÄÊ∫ê</th>\n<th>ÊòØÂê¶ÂºÄÊ∫êÂÆåÊï¥‰∫ßÂìÅ</th>\n<th>ÊòØÂê¶‰æùËµñÁîüÊÄÅ</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td rowspan=\"2\"><strong>SDKÁ±ª</strong></td>\n<td>SpringAI-Alibaba</td>\n<td>ÈÉ®ÂàÜ</td>\n<td>Âê¶ÔºåÂè™ÂºÄÊ∫êSDKÔºàSDKÔºâ</td>\n<td>ÊòØÔºàÈòøÈáå‰∫ëÁôæÁÇºÂπ≥Âè∞Ôºâ</td>\n</tr>\n<tr>\n<td>Coze</td>\n<td>ÈÉ®ÂàÜ</td>\n<td>Âê¶ÔºåÂè™ÂºÄÊ∫êÈÉ®ÂàÜNieo SDKÔºàSDKÔºâ</td>\n<td>ÊòØÔºàÁÅ´Â±±ÂºïÊìéÂπ≥Âè∞Ôºâ</td>\n</tr>\n<tr>\n<td rowspan=\"6\"><strong>Ê°ÜÊû∂Á±ª</strong></td>\n<td>Fellow</td>\n<td>ÊòØ</td>\n<td>Âê¶ÔºåÂè™ÂºÄÊ∫ê‰∫ÜEkoÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºàÊ°ÜÊû∂Ôºâ</td>\n<td>Âê¶</td>\n</tr>\n<tr>\n<td>Dify</td>\n<td>ÊòØ</td>\n<td>Âê¶ÔºåÂè™ÂºÄÊ∫ê‰∫ÜÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂Ôºå‰∏î‰∏ªË¶ÅÊòØworkflowÔºàÊ°ÜÊû∂Ôºâ</td>\n<td>Âê¶</td>\n</tr>\n<tr>\n<td>SkyworkAI</td>\n<td>ÊòØ</td>\n<td>Âê¶ÔºåÂè™ÂºÄÊ∫ê‰∫ÜÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºàÊ°ÜÊû∂Ôºâ</td>\n<td>Âê¶</td>\n</tr>\n<tr>\n<td>OpenManus</td>\n<td>ÊòØ</td>\n<td>Âê¶ÔºåÂè™ÂºÄÊ∫ê‰∫ÜÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºàÊ°ÜÊû∂Ôºâ</td>\n<td>Âê¶</td>\n</tr>\n<tr>\n<td>Owl</td>\n<td>ÊòØ</td>\n<td>Âê¶ÔºåÂè™ÂºÄÊ∫ê‰∫ÜÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºàÊ°ÜÊû∂Ôºâ</td>\n<td>Âê¶</td>\n</tr>\n<tr>\n<td>n8n</td>\n<td>ÊòØ</td>\n<td>Âê¶ÔºåÂè™ÂºÄÊ∫ê‰∫ÜÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂Ôºå‰∏î‰∏ªË¶ÅÊòØworkflowÔºàÊ°ÜÊû∂Ôºâ</td>\n<td>Âê¶</td>\n</tr>\n<tr>\n<td rowspan=\"3\"><strong>ÂçèËÆÆÁ±ª</strong></td>\n<td>MCP</td>\n<td>ÊòØ</td>\n<td>Âê¶ÔºåÂè™ÊòØÂºÄÊ∫êÂçèËÆÆ</td>\n<td>Âê¶</td>\n</tr>\n<tr>\n<td>A2A</td>\n<td>ÊòØ</td>\n<td>Âê¶ÔºåÂè™ÊòØÂºÄÊ∫êÂçèËÆÆ</td>\n<td>Âê¶</td>\n</tr>\n<tr>\n<td>AG-UI</td>\n<td>ÊòØ</td>\n<td>Âê¶ÔºåÂè™ÊòØÂºÄÊ∫êÂçèËÆÆ</td>\n<td>Âê¶</td>\n</tr>\n<tr>\n<td rowspan=\"2\"><strong>ÊäÄÊúØÊ®°ÂùóÁ±ª</strong></td>\n<td>memory0</td>\n<td>ÊòØ</td>\n<td>Âê¶ÔºåÂè™ÊòØÂºÄÊ∫êÁöÑÊäÄÊúØÊ®°Âùó</td>\n<td>Âê¶</td>\n</tr>\n<tr>\n<td>LlamaIndex</td>\n<td>ÊòØ</td>\n<td>Âê¶ÔºåÂè™ÊòØÂºÄÊ∫êÁöÑÊäÄÊúØÊ®°Âùó</td>\n<td>Âê¶</td>\n</tr>\n<tr>\n<td><strong>‰∫ßÂìÅÁ±ª</strong></td>\n<td>Our</td>\n<td>ÊòØ</td>\n<td>ÊòØÔºåÂºÄÊ∫êÁ´ØÂà∞Á´ØÂÆåÊï¥ÁöÑAgent‰∫ßÂìÅÔºà‰∫ßÂìÅÔºâ</td>\n<td>Âê¶</td>\n</tr>\n</tbody>\n</table>\n\n## Ê°ÜÊû∂ÊïàÊûúÂÖàËøõÊÄß\n\n### TestÈõÜÊïàÊûú 65.12%\n<img width=\"3524\" height=\"1022\" alt=\"test\" src=\"https://github.com/user-attachments/assets/06c85286-e61f-4b5e-8335-413cd22ecbf4\" />\n\n### ValidationÈõÜÊïàÊûú 75.15%\n\n| Agent                     | Score      | Score_level1 | Score_level2 | Score_level3 | Êú∫ÊûÑ         |\n|---------------------------|------------|--------------|--------------|--------------|------------|\n| Alita v2.1                | 0.8727     | 0.8868       | 0.8953       | 0.7692       | Princeton  |\n| Skywork                   | 0.8242     | 0.9245       | 0.8372       | 0.5769       | Â§©Â∑•         |\n| AWorld                    | 0.7758     | 0.8868       | 0.7791       | 0.5385       | Ant Group  |\n| Langfun                   | 0.7697     | 0.8679       | 0.7674       | 0.5769       | DeepMind   |\n| **JoyAgent-JDGenie** | **0.7515** | **0.8679**   | **0.7791**   | **0.4230**   | **JD**    |\n| OWL                       | 0.6909     | 0.8491       | 0.6744       | 0.4231       | CAMEL      |\n| Smolagent                 | 0.5515     | 0.6792       | 0.5349       | 0.3462       | Huggingface |\n| AutoAgent                 | 0.5515     | 0.7170       | 0.5349       | 0.2692       | HKU        |\n| Magentic                  | 0.4606     | 0.5660       | 0.4651       | 0.2308       | MSR AI Frontiers |\n| LRC-Huawei                | 0.406      | 0.5283       | 0.4302       | 0.0769       | Huawei     |\n| xManus                    | 0.4061     | 0.8113       | 0.2791       | 0.0000       | OpenManus  |\n\n<img width=\"1073\" height=\"411\" alt=\"score\" src=\"https://github.com/user-attachments/assets/9d997b68-565e-4228-8f5b-229158f33617\" />\n\n## Á≥ªÁªüÊû∂ÊûÑ\n\n![archi](./docs/img/archi.png)\n\nÊú¨ÂºÄÊ∫êÈ°πÁõÆÂü∫‰∫éJoyAgent-JDGenie‰∫ßÂìÅÂºÄÊ∫ê‰∫ÜÊï¥‰ΩìÁöÑ‰∫ßÂìÅÁïåÈù¢„ÄÅÊô∫ËÉΩ‰ΩìÁöÑÂ§öÁßçÊ†∏ÂøÉÊ®°ÂºèÔºàreactÊ®°Âºè„ÄÅplan and executorÊ®°ÂºèÁ≠âÔºâ„ÄÅÂ§ö‰∏™Â≠êÊô∫ËÉΩ‰ΩìÔºàreport agent„ÄÅsearch agentÁ≠âÔºâ‰ª•ÂèäÂ§öÊï¥‰ΩìÈó¥‰∫§‰∫íÂçèËÆÆ„ÄÇ\n\n### ‰∏ªË¶ÅÁâπÁÇπÂíå‰ºòÂäø\n\n- **Á´ØÂà∞Á´ØÂÆåÊï¥ÁöÑÂ§öÊô∫ËÉΩ‰Ωì‰∫ßÂìÅÔºåÂºÄÁÆ±Âç≥Áî®ÔºåÊîØÊåÅ‰∫åÊ¨°ÂºÄÂèë**\n- **Êô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÂçèËÆÆ**\n  - ÊîØÊåÅÂ§öÁßçÊô∫ËÉΩ‰ΩìËÆæËÆ°Ê®°Âºè\n  - Â§öÊô∫ËÉΩ‰Ωì‰∏ä‰∏ãÊñáÁÆ°ÁêÜ\n  - È´òÂπ∂ÂèëDAGÊâßË°åÂºïÊìéÔºåÊûÅËá¥ÁöÑÊâßË°åÊïàÁéá\n- **Â≠êÊô∫ËÉΩ‰ΩìÂíåÂ∑•ÂÖ∑**\n  - Â≠êAgentÂíåÂ∑•ÂÖ∑ÂèØÊèíÊãîÔºöÈ¢ÑÁΩÆÂ§öÁßçÂ≠êÊô∫ËÉΩ‰ΩìÂíåÂ∑•ÂÖ∑\n  - Â§öÁßçÊñá‰ª∂‰∫§‰ªòÊ†∑ÂºèÔºöhtml„ÄÅppt„ÄÅmarkdown\n  - planÂíåÂ∑•ÂÖ∑Ë∞ÉÁî® RL‰ºòÂåñËø≠‰ª£\n  - ÂÖ®ÈìæË∑ØÊµÅÂºèËæìÂá∫\n\n### ‰∏ªË¶ÅÂàõÊñ∞ÁÇπ\n\n![invo](./docs/img/invo.png)\n\n#### multi-level and multi-pattern thinking:ÁªìÂêàÂ§öÁßçÊô∫ËÉΩ‰ΩìËÆæËÆ°Ê®°ÂºèÊîØÊåÅÂ§öÂ±ÇÁ∫ßÁöÑËßÑÂàíÂíåÊÄùËÄÉ\n- **multi-level**Ôºöwork level Âíå task level\n- **multi-pattern**Ôºöplan and executorÊ®°ÂºèÂíåreactÊ®°Âºè\n\n#### cross task workflow memory:Ë∑®‰ªªÂä°Á∫ßÂà´ÁöÑÁõ∏‰ºº‰ªªÂä°memory\n\n#### tool evolution via auto-disassembly-and-reassembly of atom-tools\n- Âü∫‰∫éÂ∑≤ÊúâÂ∑•ÂÖ∑Ëø≠‰ª£‰∫ßÁîüÊñ∞Â∑•ÂÖ∑ÔºåËÄå‰∏çÊòØ‰ªé0-1Áõ¥Êé•ÁîüÊàêÊñ∞Â∑•ÂÖ∑ÔºàÂáèÂ∞ëÈîôËØØÂ∑•ÂÖ∑ÁöÑÁîüÊàêÔºâ \n- Âü∫‰∫éÂ∑≤ÊúâÂ∑•ÂÖ∑ÈöêÊÄßÊãÜËß£‰∏∫ÂéüÂ≠êÂ∑•ÂÖ∑ÔºåÂπ∂Âü∫‰∫éÂéüÂ≠êÂ∑•ÂÖ∑ÁªìÂêàÂ§ßÊ®°ÂûãËá™Âä®ÁªÑÂêàÊàêÊñ∞Â∑•ÂÖ∑Ôºà‰∏çÈúÄË¶ÅËä±Ë¥π‰∫∫ÂäõÈ¢ÑÂÖàÂÆö‰πâÂíåÊãÜËß£ÂéüÂ≠êÂ∑•ÂÖ∑Ôºâ\n\n\n\n## Âø´ÈÄüÂºÄÂßã\n\n### ÊñπÂºè1: docker ‰∏ÄÈîÆÂêØÂä®ÊúçÂä°\n\n```\n1. git clone https://github.com/jd-opensource/joyagent-jdgenie.git\n\n2. ÊâãÂä®Êõ¥Êñ∞ genie-backend/src/main/resources/application.yml‰∏≠ base_url„ÄÅapikey„ÄÅmodel„ÄÅmax_tokens„ÄÅmodel_nameÁ≠âÈÖçÁΩÆ\n‰ΩøÁî®DeepSeekÊó∂: Ê≥®ÊÑèdeepseek-chat ‰∏∫max_tokens: 8192\n\nÊâãÂä®Êõ¥Êñ∞ genie-tool/.env_template ‰∏≠ÁöÑ OPENAI_API_KEY„ÄÅOPENAI_BASE_URL„ÄÅDEFAULT_MODEL„ÄÅSERPER_SEARCH_API_KEY\n‰ΩøÁî®DeepSeekÊó∂: ËÆæÁΩÆDEEPSEEK_API_KEY„ÄÅDEEPSEEK_API_BASEÔºåDEFAULT_MODEL ËÆæÁΩÆ‰∏∫ deepseek/deepseek-chatÔºåÊâÄÊúâ ${DEFAULT_MODEL} ‰πüÈÉΩÊîπÊàêdeepseek/deepseek-chat\n\n3. ÁºñËØëdockerfile\ndocker build -t genie:latest .\n\n4. ÂêØÂä®dockerfile\ndocker run -d -p 3000:3000 -p 8080:8080 -p 1601:1601 --name genie-app genie:latest\n\n5. ÊµèËßàÂô®ËæìÂÖ• localhost:3000 ËÆøÈóÆgenie\n```\nÂ¶ÇÊûúÈÉ®ÁΩ≤ÈÅáÂà∞ÈóÆÈ¢òÔºåÂèØ‰ª•ÂèÇËÄÉËßÜÈ¢ë:„Äê5ÂàÜÈíü‰ΩøÁî®deepseekÂêØÂä®ÂºÄÊ∫êÊô∫ËÉΩ‰ΩìÂ∫îÁî®joyagent-genie-ÂìîÂì©ÂìîÂì©„Äë https://b23.tv/8VQDBOK\n\n### ÊñπÂºè2: ÊâãÂä®ÂàùÂßãÂåñÁéØÂ¢ÉÔºåÂêØÂä®ÊúçÂä°\n\n#### ÁéØÂ¢ÉÂáÜÂ§á\n- jdk17\n- python3.11\n- pythonÁéØÂ¢ÉÂáÜÂ§á\n  - pip install uv\n  - cd genie-tool\n  - uv sync\n  - source .venv/bin/activate\n\n#### ÊñπÊ°à1ÔºöÊâãÂä®step by stepÈÉ®ÁΩ≤ÊâãÂÜå\nÊâãÂä®Ë∂ÖËØ¶ÁªÜÊîªÁï•ÂèÇËÄÉ [Step by Step](./Deploy.md)\n\n#### ÊñπÊ°à2ÔºöÊâãÂä®‰∏ÄÈîÆÂêØÂä®ÈÉ®ÁΩ≤ÔºàÊé®ËçêÔºâ\n\nÁõ¥Êé•ÈÄöËøáshellÂêØÂä®ÊâÄÊúâÊúçÂä°\n```\nsh check_dep_port.sh # Ê£ÄÊü•ÊâÄÊúâ‰æùËµñÂíåÁ´ØÂè£Âç†Áî®ÊÉÖÂÜµ\nsh Genie_start.sh  # Áõ¥Êé•ÂêØÂä®Ôºå‰ª•ÂêéÊîπÂä®ÈÖçÁΩÆÁõ¥Êé•ÈáçÂêØÂä®ËÑöÊú¨Âç≥ÂèØÔºåcontrol+c ‰∏ÄÈîÆkillÊâÄÊúâÊúçÂä°\n```\nÈÉ®ÁΩ≤Êó∂ÂèØ‰ª•ÂèÇËÄÉËßÜÈ¢ë:„Äêjoyagent-jdgenieÈÉ®ÁΩ≤ÊºîÁ§∫„Äë https://www.bilibili.com/video/BV1Py8Yz4ELK/?vd_source=a5601a346d433a490c55293e76180c9d\n\n## ‰∫åÊ¨°ÂºÄÂèë\n\n### Â¶Ç‰ΩïÊ∑ªÂä†Ëá™Â∑±ÁöÑMCPÂ∑•ÂÖ∑Âà∞JoyAgent-JDGenie‰∏≠\n\n#### ÈÖçÁΩÆÊñá‰ª∂\n\nÂú® `genie-backend/src/main/resources/application.yml` Ê∑ªÂä†mcp_serverÊúçÂä°ÔºåÂ§ö‰∏™serverÈÄóÂè∑ÂàÜÈöî\nÂú® `ui/.env` ‰∏≠ÂèØ‰ª•‰øÆÊîπÂâçÁ´ØËØ∑Ê±ÇÂêéÁ´ØÁöÑË∑ØÂæÑ\n\n```yaml\nmcp_server_url: \"http://ip1:port1/sse,http://ip2:port2/sse\"\n```\n\n#### ÂêØÂä®ÊúçÂä°\n\n```bash\nsh start_genie.sh\n```\n\n#### ÂºÄÂßãÂØπËØù\n\nÊØîÂ¶ÇÊ∑ªÂä†12306Â∑•ÂÖ∑ÂêéÔºåËßÑÂàí7Êúà7Â§©2‰∫∫‰ªéÂåó‰∫¨Âá∫ÂèëÂéªÊñ∞ÁñÜÊóÖË°åËÆ°ÂàíÔºåÂπ∂Êü•ËØ¢Áõ∏ÂÖ≥ÁÅ´ËΩ¶Á•®‰ø°ÊÅØÔºå\ngenie‰ºöËøõË°åÊóÖË°åËÆ°ÂàíËÆæËÆ°ÔºåÁÑ∂ÂêéË∞ÉÁî®mcpÂ∑•ÂÖ∑Êü•ËØ¢ËΩ¶Á•®‰ø°ÊÅØÔºåÊúÄÁªàËæìÂá∫Êä•Âëä„ÄÇ\n![img.png](./docs/img/mcp_example.png)\n\n\n### Êñ∞Â¢ûËá™ÂÆö‰πâÂ≠êAgentÂà∞JoyAgent-JDGenie‰∏≠\n\nÂÆûÁé∞BaseToolÊé•Âè£ÔºåÂ£∞ÊòéÂ∑•ÂÖ∑ÁöÑÂêçÁß∞„ÄÅÊèèËø∞„ÄÅÂèÇÊï∞„ÄÅË∞ÉÁî®ÊñπÊ≥ï„ÄÇ\n\n```java\n/**\n * Â∑•ÂÖ∑Âü∫Êé•Âè£\n */\npublic interface BaseTool {\n    String getName(); // Â∑•ÂÖ∑ÂêçÁß∞\n    String getDescription(); // Â∑•ÂÖ∑ÊèèËø∞\n    Map<String, Object> toParams(); // Â∑•ÂÖ∑ÂèÇÊï∞\n    Object execute(Object input); // Ë∞ÉÁî®Â∑•ÂÖ∑\n}\n\n// Â§©Ê∞îÊô∫ËÉΩ‰ΩìÁ§∫‰æã\npublic class WeatherTool implements BaseTool {\n    @Override\n    public String getName() {\n        return \"agent_weather\";\n    }\n\n    @Override\n    public String getDescription() {\n        return \"ËøôÊòØ‰∏Ä‰∏™ÂèØ‰ª•Êü•ËØ¢Â§©Ê∞îÁöÑÊô∫ËÉΩ‰Ωì\";\n    }\n\n    @Override\n    public Map<String, Object> toParams() {\n        return \"{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"location\\\":{\\\"description\\\":\\\"Âú∞ÁÇπ\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"location\\\"]}\";\n    }\n\n    @Override\n    public Object execute(Object input) {\n        return \"‰ªäÊó•Â§©Ê∞îÊô¥Êúó\";\n    }\n}\n```\n\nÂú®`com.jd.genie.controller.GenieController#buildToolCollection`‰∏≠Ê∑ªÂä†Â¶Ç‰∏ã‰ª£Á†ÅÔºåÂºïÂÖ•Ëá™ÂÆö‰πâAgent\n\n```java\nWeatherTool weatherTool = new WeatherTool();\ntoolCollection.addTool(weatherTool);\n```\n\n#### ÂêØÂä®ÊúçÂä°\n\n```bash\nsh start_genie.sh\n```\n\n\n## È°πÁõÆÂÖ±Âª∫ËÄÖ\nË¥°ÁåÆËÄÖÔºöLiu Shangkun,Li Xiang,[Li Yang](https://scholar.google.com.hk/citations?hl=zh-CN&user=AeCTbv8AAAAJ&view_op=list_works&gmla=AH8HC4zYqeayQxrQFmScZ7XYxLah1enc8ynhQYMtBdPmjwfpMBvsTj_OoBkFTPCw1Xi2xk7gbTzHPH-QpJSw_sGkCKdYDVXSu8Ty2tNJMhs),Jia Shilin,Tian Shaohua,Wang Zhen,Yao Ting,Wang Hongtao,Zhou Xiaoqing,Liu min,Zhang Shuang,Liuwen,Yangdong,Xu Jialei,Zhou Meilei,Zhao Tingchong,Wu jiaxing, Wang Hanmin, Zhou Zhiyuan, Xu Shiyue,Liu Jiarun, Hou Kang, Jing Lingtuan, Guo Hongliang, Wang Zhijiang, Liu Yanchen, Chen Kun, Ke Huilin, Pan Zheyi, Duan Zhewen, Tu Shengkun, Zhang Haidong, Wang Heng,Li Bo,Zhang Konghongbo,Guo fenghua, [Wang Haofen](https://tjdi.tongji.edu.cn/TeacherDetail.do?id=4991&lang=), Zhang Junbo, Liu Haibo, Yang Haoran, Qiao Jiayang\n\nÊâÄÂ±ûÊú∫ÊûÑ:‰∫¨‰∏úCHO‰ºÅ‰∏ö‰ø°ÊÅØÂåñÂõ¢ÈòüÔºàEIÔºâ„ÄÅ‰∫¨‰∏úÁßëÊäÄÂçèÂêåÂäûÂÖ¨Âõ¢Èòü„ÄÅ‰∫¨‰∏úÁâ©ÊµÅÊï∞ÊçÆËµÑ‰∫ßÂõ¢Èòü\n\n## Ë¥°ÁåÆÂíåÂêà‰Ωú\n\nÊàë‰ª¨Ê¨¢ËøéÊâÄÊúâÂ•ΩÊÉ≥Ê≥ïÂíåÂª∫ËÆÆÔºåÂ¶ÇÊûúÊÇ®ÊÉ≥Êàê‰∏∫È°πÁõÆÁöÑÂÖ±Âª∫ËÄÖÔºåÂèØÈöèÊó∂ÂêëÊàë‰ª¨ÊèêPull Request„ÄÇÊó†ËÆ∫ÊòØÂÆåÂñÑ‰∫ßÂìÅÂíåÊ°ÜÊû∂„ÄÅ‰øÆÂ§çbugËøòÊòØÊ∑ªÂä†Êñ∞ÁâπÊÄßÔºåÊÇ®ÁöÑË¥°ÁåÆÈÉΩÈùûÂ∏∏ÂÆùË¥µ„ÄÇ\nÂú®Ê≠§‰πãÂâçÈúÄË¶ÅÊÇ®ÈòÖËØªÂπ∂Á≠æÁΩ≤Ë¥°ÁåÆËÄÖÂçèËÆÆÂπ∂ÂèëÈÄÅÂà∞ÈÇÆÁÆ±org.developer3@jd.comÔºåËØ∑ÈòÖËØª [Ë¥°ÁåÆÊåáÂçó‰∏≠ÊñáÁâà](https://github.com/jd-opensource/joyagent-jdgenie/blob/main/contributor_ZH.pdf)Ôºå[Ë¥°ÁåÆÊåáÂçóËã±ÊñáÁâà](https://github.com/jd-opensource/joyagent-jdgenie/blob/main/contributor_EN.pdf)\n\n\n## ÂºïÁî®\n\nÂ¶ÇÈúÄÂ≠¶ÊúØÂºïÁî®ÔºåËØ∑‰ΩøÁî®‰ª•‰∏ã BibTeXÔºö\n```bibtex\n@software{JoyAgent-JDGenie,\n  author = {Agent Team at JDCHO},\n  title = {JoyAgent-JDGenie},\n  year = {2025},\n  url = {https://github.com/jd-opensource/joyagent-jdgenie},\n  version = {0.1.0},\n  publisher = {GitHub},\n  email = {jiashilin1@jd.com;liyang.1236@jd.com;liushangkun@jd.com;tianshaohua.1@jd.com;wangzhen449@jd.com;yaoting.2@jd.com;houkang6@jd.com;jinglingtuan@jd.com;guohongliang@jd.com}\n}\n```\n\n## Contributors\n\n<a href=\"https://github.com/jd-opensource/joyagent-jdgenie/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=jd-opensource/joyagent-jdgenie\" />\n</a>\n\n# Star History\n[![Star History Chart](https://api.star-history.com/svg?repos=jd-opensource/joyagent-jdgenie&type=Date&cache=false)](https://star-history.com/#jd-opensource/joyagent-jdgenie&Date)\n\nÊ¨¢ËøéÊ≤üÈÄöÂíåËÅîÁ≥ªÊàë‰ª¨  \n<img width=\"396\" height=\"396\" alt=\"ME1758722833951\" src=\"https://github.com/user-attachments/assets/0c47720f-78a4-4a98-b634-a8274072d36c\" />\n\n\n[//]: # (![contact]&#40;./docs/img/contact.jpg&#41;)\n",
      "stars_today": 15
    },
    {
      "id": 71525630,
      "name": "miniaudio",
      "full_name": "mackron/miniaudio",
      "description": "Audio playback and capture library written in C, in a single source file.",
      "html_url": "https://github.com/mackron/miniaudio",
      "stars": 6120,
      "forks": 511,
      "language": "C",
      "topics": [
        "android",
        "audio",
        "audio-library",
        "bsd",
        "capture",
        "decoding",
        "emscripten",
        "flac",
        "ios",
        "linux",
        "macos",
        "mp3",
        "osx",
        "playback",
        "public-domain",
        "recording",
        "vorbis",
        "wasapi",
        "wav",
        "windows"
      ],
      "created_at": "2016-10-21T03:17:26Z",
      "updated_at": "2026-01-16T23:41:11Z",
      "pushed_at": "2026-01-16T23:41:10Z",
      "open_issues": 9,
      "owner": {
        "login": "mackron",
        "avatar_url": "https://avatars.githubusercontent.com/u/1232553?v=4"
      },
      "readme": "<h1 align=\"center\">\n    <a href=\"https://miniaud.io\"><img src=\"https://miniaud.io/img/miniaudio_wide.png\" alt=\"miniaudio\" width=\"1280\"></a>\n    <br>\n</h1>\n\n<h4 align=\"center\">An audio playback and capture library in a single source file.</h4>\n\n<p align=\"center\">\n    <a href=\"https://discord.gg/9vpqbjU\"><img src=\"https://img.shields.io/discord/712952679415939085?label=discord&logo=discord&style=flat-square\" alt=\"discord\"></a>\n    <a href=\"https://x.com/mackron\"><img alt=\"x\" src=\"https://img.shields.io/twitter/url?url=https%3A%2F%2Fx.com%2Fmackron&style=flat-square&logo=x&label=%40mackron\"></a>\n</p>\n\n<p align=\"center\">\n    <a href=\"#features\">Features</a> -\n    <a href=\"#examples\">Examples</a> -\n    <a href=\"#building\">Building</a> -\n    <a href=\"#documentation\">Documentation</a> -\n    <a href=\"#supported-platforms\">Supported Platforms</a> -\n    <a href=\"#security\">Security</a> -\n    <a href=\"#license\">License</a>\n</p>\n\nminiaudio is written in C with no dependencies except the standard library and should compile clean on all major\ncompilers without the need to install any additional development packages. All major desktop and mobile platforms\nare supported.\n\n\nFeatures\n========\n- Simple build system with no external dependencies.\n- Simple and flexible API.\n- Low-level API for direct access to raw audio data.\n- High-level API for sound management, mixing, effects and optional 3D spatialization.\n- Flexible node graph system for advanced mixing and effect processing.\n- Resource management for loading sound files.\n- Decoding, with built-in support for WAV, FLAC, and MP3, in addition to being able to plug in custom decoders.\n- Encoding (WAV only).\n- Data conversion.\n- Resampling, including custom resamplers.\n- Channel mapping.\n- Basic generation of waveforms and noise.\n- Basic effects and filters.\n\nRefer to the [Programming Manual](https://miniaud.io/docs/manual/) for a more complete description of\navailable features in miniaudio.\n\n\nExamples\n========\n\nThis example shows one way to play a sound using the high level API.\n\n```c\n#include \"miniaudio/miniaudio.h\"\n\n#include <stdio.h>\n\nint main()\n{\n    ma_result result;\n    ma_engine engine;\n\n    result = ma_engine_init(NULL, &engine);\n    if (result != MA_SUCCESS) {\n        return -1;\n    }\n\n    ma_engine_play_sound(&engine, \"sound.wav\", NULL);\n\n    printf(\"Press Enter to quit...\");\n    getchar();\n\n    ma_engine_uninit(&engine);\n\n    return 0;\n}\n```\n\nThis example shows how to decode and play a sound using the low level API.\n\n```c\n#include \"miniaudio/miniaudio.h\"\n\n#include <stdio.h>\n\nvoid data_callback(ma_device* pDevice, void* pOutput, const void* pInput, ma_uint32 frameCount)\n{\n    ma_decoder* pDecoder = (ma_decoder*)pDevice->pUserData;\n    if (pDecoder == NULL) {\n        return;\n    }\n\n    ma_decoder_read_pcm_frames(pDecoder, pOutput, frameCount, NULL);\n\n    (void)pInput;\n}\n\nint main(int argc, char** argv)\n{\n    ma_result result;\n    ma_decoder decoder;\n    ma_device_config deviceConfig;\n    ma_device device;\n\n    if (argc < 2) {\n        printf(\"No input file.\\n\");\n        return -1;\n    }\n\n    result = ma_decoder_init_file(argv[1], NULL, &decoder);\n    if (result != MA_SUCCESS) {\n        return -2;\n    }\n\n    deviceConfig = ma_device_config_init(ma_device_type_playback);\n    deviceConfig.playback.format   = decoder.outputFormat;\n    deviceConfig.playback.channels = decoder.outputChannels;\n    deviceConfig.sampleRate        = decoder.outputSampleRate;\n    deviceConfig.dataCallback      = data_callback;\n    deviceConfig.pUserData         = &decoder;\n\n    if (ma_device_init(NULL, &deviceConfig, &device) != MA_SUCCESS) {\n        printf(\"Failed to open playback device.\\n\");\n        ma_decoder_uninit(&decoder);\n        return -3;\n    }\n\n    if (ma_device_start(&device) != MA_SUCCESS) {\n        printf(\"Failed to start playback device.\\n\");\n        ma_device_uninit(&device);\n        ma_decoder_uninit(&decoder);\n        return -4;\n    }\n\n    printf(\"Press Enter to quit...\");\n    getchar();\n\n    ma_device_uninit(&device);\n    ma_decoder_uninit(&decoder);\n\n    return 0;\n}\n```\n\nMore examples can be found in the [examples](examples) folder or online here: https://miniaud.io/docs/examples/\n\n\nBuilding\n========\nJust compile miniaudio.c like any other source file and include miniaudio.h like a normal header. There's no need\nto install any dependencies. On Windows and macOS there's no need to link to anything. On Linux and BSD just link\nto `-lpthread` and `-lm`. On iOS you need to compile as Objective-C. Link to `-ldl` if you get errors about\n`dlopen()`, etc.\n\nIf you get errors about undefined references to `__sync_val_compare_and_swap_8`, `__atomic_load_8`, etc. you\nneed to link with `-latomic`.\n\nABI compatibility is not guaranteed between versions so take care if compiling as a DLL/SO. The suggested way\nto integrate miniaudio is by adding it directly to your source tree.\n\nYou can also use CMake if that's your preference.\n\n\nDocumentation\n=============\nOnline documentation can be found here: https://miniaud.io/docs/\n\nDocumentation can also be found at the top of [miniaudio.h](https://raw.githubusercontent.com/mackron/miniaudio/master/miniaudio.h)\nwhich is always the most up-to-date and authoritative source of information on how to use miniaudio. All other\ndocumentation is generated from this in-code documentation.\n\n\nSupported Platforms\n===================\n- Windows\n- macOS, iOS\n- Linux\n- FreeBSD / OpenBSD / NetBSD\n- Android\n- Raspberry Pi\n- Emscripten / HTML5\n\nminiaudio should compile clean on other platforms, but it will not include any support for playback or capture\nby default. To support that, you would need to implement a custom backend. You can do this without needing to\nmodify the miniaudio source code. See the [custom_backend](examples/custom_backend.c) example.\n\nBackends\n--------\n- WASAPI\n- DirectSound\n- WinMM\n- Core Audio (Apple)\n- ALSA\n- PulseAudio\n- JACK\n- sndio (OpenBSD)\n- audio(4) (NetBSD and OpenBSD)\n- OSS (FreeBSD)\n- AAudio (Android 8.0+)\n- OpenSL|ES (Android only)\n- Web Audio (Emscripten)\n- Null (Silence)\n- Custom\n\n\nSecurity\n========\nSee the miniaudio [security policy](.github/SECURITY.md).\n\n\nLicense\n=======\nYour choice of either public domain or [MIT No Attribution](https://github.com/aws/mit-0).\n",
      "stars_today": 15
    },
    {
      "id": 120360765,
      "name": "chromium",
      "full_name": "chromium/chromium",
      "description": "The official GitHub mirror of the Chromium source",
      "html_url": "https://github.com/chromium/chromium",
      "stars": 22751,
      "forks": 8492,
      "language": "C++",
      "topics": [],
      "created_at": "2018-02-05T20:55:32Z",
      "updated_at": "2026-01-17T00:59:32Z",
      "pushed_at": "2026-01-17T00:59:25Z",
      "open_issues": 141,
      "owner": {
        "login": "chromium",
        "avatar_url": "https://avatars.githubusercontent.com/u/30044?v=4"
      },
      "readme": "# GitHub Copilot Integration in Chromium\n\nThis directory provides instructions and prompts for integrating GitHub Copilot\nwith the chromium codebase.\n\nThis directory is currently in a prototyping state and may be removed in the\nfuture. As we add support for multiple coding IDE/agents, we will likely pull\ncommon prompts and instructions into a central directory with stubs for bespoke\nIDE/agent integration. Please check with your organization before using GitHub\nCopilot.\n\n## Where is copilot-instructions.md?\n[`copilot-intructions.md`](../copilot-instructions.md) is typically a single\ninstruction file that contains default instructions for a workspace. These\ninstructions are automatically included in every chat request.\n\nUntil the prompt in `copilot-intructions.md` is generally agreed upon for the\nchromium repo, this file is intentionally excluded from the repo, and added to\nthe [.gitignore](../.gitignore) for your customization.\n\nFor generating your own `copilot-intructions.md`, type\n`/create_copilot_instructions` in GitHub Copilot to get started.\n\n## Code Layout\n- [.github/instructions](./instructions/): Custom instructions for specific\n  tasks. For example, you can create instruction files for different programming\n  languages, frameworks, or project types. You can attach individual prompt\n  files to a chat request, or you can configure them to be automatically\n  included for specific files or folders with `applyTo` syntax.\n- [.github/prompts](./prompts/): Prompt files can be easily triggered from chat\n  with `/` and allow you to craft complete prompts in Markdown files.\n  Unlike custom instructions that supplement your chat queries prompts, prompt\n  files are standalone prompts that you can store within your workspace and\n  share with others. With prompt files, you can create reusable templates for\n  common tasks, store domain expertise in the codebase, and standardize AI\n  interactions across your team.\n- [.github/resources](./resources/): Prompt files that are resources for use by\n  other prompts and instructions.\n\n## User Specific Prompts\nUsers can create their own prompts or instructions that match the regex\n`.github/**/user_.md` which is captured in the [.gitignore](../.gitignore).\n\n## Contributing Guidelines\nUse `/git_commit_ghc`\n\n- [.github/instructions](./instructions/): Instructions that are automatically\n  picked up using `applyTo` syntax will have a much higher review bar then those\n  without it.\n- [.github/prompts](./prompts/): All prompts should specify a `mode` and\n  `description`.\n- [.github/resources](./resources/): All prompt resources should have an active\n  reference or usecase a file in `instructions` or `prompts`, and should be\n  cleaned up if their references are modified or removed.\n",
      "stars_today": 14
    },
    {
      "id": 69495170,
      "name": "fastify",
      "full_name": "fastify/fastify",
      "description": "Fast and low overhead web framework, for Node.js",
      "html_url": "https://github.com/fastify/fastify",
      "stars": 35426,
      "forks": 2549,
      "language": "JavaScript",
      "topics": [
        "hacktoberfest",
        "nodejs",
        "performance",
        "speed",
        "webframework"
      ],
      "created_at": "2016-09-28T19:10:14Z",
      "updated_at": "2026-01-16T21:47:52Z",
      "pushed_at": "2026-01-16T21:47:44Z",
      "open_issues": 109,
      "owner": {
        "login": "fastify",
        "avatar_url": "https://avatars.githubusercontent.com/u/24939410?v=4"
      },
      "readme": "<div align=\"center\"> <a href=\"https://fastify.dev/\">\n    <img\n      src=\"https://github.com/fastify/graphics/raw/HEAD/fastify-landscape-outlined.svg\"\n      width=\"650\"\n      height=\"auto\"\n    />\n  </a>\n</div>\n\n<div align=\"center\">\n\n[![CI](https://github.com/fastify/fastify/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/fastify/fastify/actions/workflows/ci.yml)\n[![Package Manager\nCI](https://github.com/fastify/fastify/actions/workflows/package-manager-ci.yml/badge.svg?branch=main)](https://github.com/fastify/fastify/actions/workflows/package-manager-ci.yml)\n[![Web\nsite](https://github.com/fastify/fastify/actions/workflows/website.yml/badge.svg?branch=main)](https://github.com/fastify/fastify/actions/workflows/website.yml)\n[![neostandard javascript style](https://img.shields.io/badge/code_style-neostandard-brightgreen?style=flat)](https://github.com/neostandard/neostandard)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/7585/badge)](https://bestpractices.coreinfrastructure.org/projects/7585)\n\n</div>\n\n<div align=\"center\">\n\n[![NPM\nversion](https://img.shields.io/npm/v/fastify.svg?style=flat)](https://www.npmjs.com/package/fastify)\n[![NPM\ndownloads](https://img.shields.io/npm/dm/fastify.svg?style=flat)](https://www.npmjs.com/package/fastify)\n[![Security Responsible\nDisclosure](https://img.shields.io/badge/Security-Responsible%20Disclosure-yellow.svg)](https://github.com/fastify/fastify/blob/main/SECURITY.md)\n[![Discord](https://img.shields.io/discord/725613461949906985)](https://discord.gg/fastify)\n[![Contribute with Gitpod](https://img.shields.io/badge/Contribute%20with-Gitpod-908a85?logo=gitpod&color=blue)](https://gitpod.io/#https://github.com/fastify/fastify)\n[![Open Collective backers and sponsors](https://img.shields.io/opencollective/all/fastify)](https://github.com/sponsors/fastify#sponsors)\n\n</div>\n\n<br />\n\nAn efficient server implies a lower cost of the infrastructure, better\nresponsiveness under load, and happy users. How can you efficiently handle the\nresources of your server, knowing that you are serving the highest number of\nrequests possible, without sacrificing security validations and handy\ndevelopment?\n\nEnter Fastify. Fastify is a web framework highly focused on providing the best\ndeveloper experience with the least overhead and a powerful plugin architecture.\nIt is inspired by Hapi and Express and as far as we know, it is one of the\nfastest web frameworks in town.\n\nThe `main` branch refers to the Fastify `v5` release.\nCheck out the [`4.x` branch](https://github.com/fastify/fastify/tree/4.x) for `v4`.\n\n### Table of Contents\n\n - [Quick start](#quick-start)\n - [Install](#install)\n - [Example](#example)\n - [Core features](#core-features)\n - [Benchmarks](#benchmarks)\n - [Documentation](#documentation)\n - [Ecosystem](#ecosystem)\n - [Support](#support)\n - [Team](#team)\n - [Hosted by](#hosted-by)\n - [License](#license)\n\n\n### Quick start\n\nCreate a folder and make it your current working directory:\n\n```sh\nmkdir my-app\ncd my-app\n```\n\nGenerate a fastify project with `npm init`:\n\n```sh\nnpm init fastify\n```\n\nInstall dependencies:\n\n```sh\nnpm i\n```\n\nTo start the app in dev mode:\n\n```sh\nnpm run dev\n```\n\nFor production mode:\n\n```sh\nnpm start\n```\n\nUnder the hood `npm init` downloads and runs [Fastify\nCreate](https://github.com/fastify/create-fastify), which in turn uses the\ngenerate functionality of [Fastify CLI](https://github.com/fastify/fastify-cli).\n\n\n### Install\n\nTo install Fastify in an existing project as a dependency:\n\n```sh\nnpm i fastify\n```\n\n### Example\n\n```js\n// Require the framework and instantiate it\n\n// ESM\nimport Fastify from 'fastify'\n\nconst fastify = Fastify({\n  logger: true\n})\n// CommonJs\nconst fastify = require('fastify')({\n  logger: true\n})\n\n// Declare a route\nfastify.get('/', (request, reply) => {\n  reply.send({ hello: 'world' })\n})\n\n// Run the server!\nfastify.listen({ port: 3000 }, (err, address) => {\n  if (err) throw err\n  // Server is now listening on ${address}\n})\n```\n\nWith async-await:\n\n```js\n// ESM\nimport Fastify from 'fastify'\n\nconst fastify = Fastify({\n  logger: true\n})\n// CommonJs\nconst fastify = require('fastify')({\n  logger: true\n})\n\nfastify.get('/', async (request, reply) => {\n  reply.type('application/json').code(200)\n  return { hello: 'world' }\n})\n\nfastify.listen({ port: 3000 }, (err, address) => {\n  if (err) throw err\n  // Server is now listening on ${address}\n})\n```\n\nDo you want to know more? Head to the <a\nhref=\"./docs/Guides/Getting-Started.md\"><code><b>Getting Started</b></code></a>.\nIf you learn best by reading code, explore the official [demo](https://github.com/fastify/demo).\n\n> ## Note\n> `.listen` binds to the local host, `localhost`, interface by default\n> (`127.0.0.1` or `::1`, depending on the operating system configuration). If\n> you are running Fastify in a container (Docker,\n> [GCP](https://cloud.google.com/), etc.), you may need to bind to `0.0.0.0`. Be\n> careful when listening on all interfaces; it comes with inherent\n> [security\n> risks](https://web.archive.org/web/20170711105010/https://snyk.io/blog/mongodb-hack-and-secure-defaults/).\n> See [the documentation](./docs/Reference/Server.md#listen) for more\n> information.\n\n### Core features\n\n- **Highly performant:** as far as we know, Fastify is one of the fastest web\n  frameworks in town, depending on the code complexity we can serve up to 76+\n  thousand requests per second.\n- **Extensible:** Fastify is fully extensible via its hooks, plugins, and\n  decorators.\n- **Schema-based:** even if it is not mandatory we recommend using [JSON\n  Schema](https://json-schema.org/) to validate your routes and serialize your\n  outputs. Internally Fastify compiles the schema in a highly performant\n  function.\n- **Logging:** logs are extremely important but are costly; we chose the best\n  logger to almost remove this cost, [Pino](https://github.com/pinojs/pino)!\n- **Developer friendly:** the framework is built to be very expressive and help\n  developers in their daily use without sacrificing performance and\n  security.\n\n### Benchmarks\n\n__Machine:__ EX41S-SSD, Intel Core i7, 4Ghz, 64GB RAM, 4C/8T, SSD.\n\n__Method:__: `autocannon -c 100 -d 40 -p 10 localhost:3000` * 2, taking the\nsecond average\n\n| Framework          | Version                    | Router?      |  Requests/sec |\n| :----------------- | :------------------------- | :----------: | ------------: |\n| Express            | 4.17.3                     | &#10003;     | 14,200        |\n| hapi               | 20.2.1                     | &#10003;     | 42,284        |\n| Restify            | 8.6.1                      | &#10003;     | 50,363        |\n| Koa                | 2.13.0                     | &#10007;     | 54,272        |\n| **Fastify**        | **4.0.0**                  | **&#10003;** | **77,193**    |\n| -                  |                            |              |               |\n| `http.Server`      | 16.14.2\t                  | &#10007;     | 74,513        |\n\nThese benchmarks taken using https://github.com/fastify/benchmarks. This is a\nsynthetic \"hello world\" benchmark that aims to evaluate the framework overhead.\nThe overhead that each framework has on your application depends on your\napplication. You should __always__ benchmark if performance matters to you.\n\n## Documentation\n* [__`Getting Started`__](./docs/Guides/Getting-Started.md)\n* [__`Guides`__](./docs/Guides/Index.md)\n* [__`Server`__](./docs/Reference/Server.md)\n* [__`Routes`__](./docs/Reference/Routes.md)\n* [__`Encapsulation`__](./docs/Reference/Encapsulation.md)\n* [__`Logging`__](./docs/Reference/Logging.md)\n* [__`Middleware`__](./docs/Reference/Middleware.md)\n* [__`Hooks`__](./docs/Reference/Hooks.md)\n* [__`Decorators`__](./docs/Reference/Decorators.md)\n* [__`Validation and Serialization`__](./docs/Reference/Validation-and-Serialization.md)\n* [__`Fluent Schema`__](./docs/Guides/Fluent-Schema.md)\n* [__`Lifecycle`__](./docs/Reference/Lifecycle.md)\n* [__`Reply`__](./docs/Reference/Reply.md)\n* [__`Request`__](./docs/Reference/Request.md)\n* [__`Errors`__](./docs/Reference/Errors.md)\n* [__`Content Type Parser`__](./docs/Reference/ContentTypeParser.md)\n* [__`Plugins`__](./docs/Reference/Plugins.md)\n* [__`Testing`__](./docs/Guides/Testing.md)\n* [__`Benchmarking`__](./docs/Guides/Benchmarking.md)\n* [__`How to write a good plugin`__](./docs/Guides/Write-Plugin.md)\n* [__`Plugins Guide`__](./docs/Guides/Plugins-Guide.md)\n* [__`HTTP2`__](./docs/Reference/HTTP2.md)\n* [__`Long Term Support`__](./docs/Reference/LTS.md)\n* [__`TypeScript and types support`__](./docs/Reference/TypeScript.md)\n* [__`Serverless`__](./docs/Guides/Serverless.md)\n* [__`Recommendations`__](./docs/Guides/Recommendations.md)\n\n## Ecosystem\n\n- [Core](./docs/Guides/Ecosystem.md#core) - Core plugins maintained by the\n  _Fastify_ [team](#team).\n- [Community](./docs/Guides/Ecosystem.md#community) - Community-supported\n  plugins.\n- [Live Examples](https://github.com/fastify/example) - Multirepo with a broad\n  set of real working examples.\n- [Discord](https://discord.gg/D3FZYPy) - Join our discord server and chat with\n  the maintainers.\n\n## Support\nPlease visit [Fastify help](https://github.com/fastify/help) to view prior\nsupport issues and to ask new support questions.\n\nVersion 3 of Fastify and lower are EOL and will not receive any security or bug\nfixes.\n\nFastify's partner, HeroDevs, provides commercial security fixes for all\nunsupported versions at [https://herodevs.com/support/fastify-nes][hd-link].\nFastify's supported version matrix is available in the\n[Long Term Support][lts-link] documentation.\n\n## Contributing\n\nWhether reporting bugs, discussing improvements and new ideas, or writing code,\nwe welcome contributions from anyone and everyone. Please read the [CONTRIBUTING](./CONTRIBUTING.md)\nguidelines before submitting pull requests.\n\n## Team\n\n_Fastify_ is the result of the work of a great community. Team members are\nlisted in alphabetical order.\n\n**Lead Maintainers:**\n* [__Matteo Collina__](https://github.com/mcollina),\n  <https://x.com/matteocollina>, <https://www.npmjs.com/~matteo.collina>\n* [__Tomas Della Vedova__](https://github.com/delvedor),\n  <https://x.com/delvedor>, <https://www.npmjs.com/~delvedor>\n* [__KaKa Ng__](https://github.com/climba03003),\n  <https://www.npmjs.com/~climba03003>\n* [__Manuel Spigolon__](https://github.com/eomm),\n  <https://x.com/manueomm>, <https://www.npmjs.com/~eomm>\n* [__James Sumners__](https://github.com/jsumners),\n  <https://x.com/jsumners79>, <https://www.npmjs.com/~jsumners>\n\n### Fastify Core team\n* [__Aras Abbasi__](https://github.com/uzlopak),\n  <https://www.npmjs.com/~uzlopak>\n* [__Harry Brundage__](https://github.com/airhorns/),\n  <https://x.com/harrybrundage>, <https://www.npmjs.com/~airhorns>\n* [__Matteo Collina__](https://github.com/mcollina),\n  <https://x.com/matteocollina>, <https://www.npmjs.com/~matteo.collina>\n* [__G√ºrg√ºn Dayƒ±oƒülu__](https://github.com/gurgunday),\n  <https://www.npmjs.com/~gurgunday>\n* [__Tomas Della Vedova__](https://github.com/delvedor),\n  <https://x.com/delvedor>, <https://www.npmjs.com/~delvedor>\n* [__Carlos Fuentes__](https://github.com/metcoder95),\n  <https://x.com/metcoder95>, <https://www.npmjs.com/~metcoder95>\n* [__Vincent Le Goff__](https://github.com/zekth)\n* [__Luciano Mammino__](https://github.com/lmammino),\n  <https://x.com/loige>, <https://www.npmjs.com/~lmammino>\n* [__Jean Michelet__](https://github.com/jean-michelet),\n  <https://www.npmjs.com/~jean-michelet>\n* [__KaKa Ng__](https://github.com/climba03003),\n  <https://www.npmjs.com/~climba03003>\n* [__Luis Orbaiceta__](https://github.com/luisorbaiceta),\n  <https://x.com/luisorbai>, <https://www.npmjs.com/~luisorbaiceta>\n* [__Maksim Sinik__](https://github.com/fox1t),\n  <https://x.com/maksimsinik>, <https://www.npmjs.com/~fox1t>\n* [__Manuel Spigolon__](https://github.com/eomm),\n  <https://x.com/manueomm>, <https://www.npmjs.com/~eomm>\n* [__James Sumners__](https://github.com/jsumners),\n  <https://x.com/jsumners79>, <https://www.npmjs.com/~jsumners>\n\n### Fastify Plugins team\n* [__Harry Brundage__](https://github.com/airhorns/),\n  <https://x.com/harrybrundage>, <https://www.npmjs.com/~airhorns>\n* [__Simone Busoli__](https://github.com/simoneb),\n  <https://x.com/simonebu>, <https://www.npmjs.com/~simoneb>\n* [__Dan Castillo__](https://github.com/dancastillo),\n  <https://www.npmjs.com/~dancastillo>\n* [__Matteo Collina__](https://github.com/mcollina),\n  <https://x.com/matteocollina>, <https://www.npmjs.com/~matteo.collina>\n* [__G√ºrg√ºn Dayƒ±oƒülu__](https://github.com/gurgunday),\n  <https://www.npmjs.com/~gurgunday>\n* [__Tomas Della Vedova__](https://github.com/delvedor),\n  <https://x.com/delvedor>, <https://www.npmjs.com/~delvedor>\n* [__Carlos Fuentes__](https://github.com/metcoder95),\n  <https://x.com/metcoder95>, <https://www.npmjs.com/~metcoder95>\n* [__Vincent Le Goff__](https://github.com/zekth)\n* [__Jean Michelet__](https://github.com/jean-michelet),\n  <https://www.npmjs.com/~jean-michelet>\n* [__KaKa Ng__](https://github.com/climba03003),\n  <https://www.npmjs.com/~climba03003>\n* [__Maksim Sinik__](https://github.com/fox1t),\n  <https://x.com/maksimsinik>, <https://www.npmjs.com/~fox1t>\n* [__Frazer Smith__](https://github.com/Fdawgs), <https://www.npmjs.com/~fdawgs>\n* [__Manuel Spigolon__](https://github.com/eomm),\n  <https://x.com/manueomm>, <https://www.npmjs.com/~eomm>\n\n### Emeritus Contributors\nGreat contributors to a specific area of the Fastify ecosystem will be invited\nto join this group by Lead Maintainers when they decide to step down from the\nactive contributor's group.\n\n* [__Tommaso Allevi__](https://github.com/allevo),\n  <https://x.com/allevitommaso>, <https://www.npmjs.com/~allevo>\n* [__Ethan Arrowood__](https://github.com/Ethan-Arrowood/),\n  <https://x.com/arrowoodtech>, <https://www.npmjs.com/~ethan_arrowood>\n* [__√áaƒüatay √áalƒ±__](https://github.com/cagataycali),\n  <https://x.com/cagataycali>, <https://www.npmjs.com/~cagataycali>\n* [__David Mark Clements__](https://github.com/davidmarkclements),\n  <https://x.com/davidmarkclem>,\n  <https://www.npmjs.com/~davidmarkclements>\n* [__dalisoft__](https://github.com/dalisoft), <https://x.com/dalisoft>,\n  <https://www.npmjs.com/~dalisoft>\n* [__Dustin Deus__](https://github.com/StarpTech),\n  <https://x.com/dustindeus>, <https://www.npmjs.com/~starptech>\n* [__Denis F√§cke__](https://github.com/SerayaEryn),\n  <https://x.com/serayaeryn>, <https://www.npmjs.com/~serayaeryn>\n* [__Rafael Gonzaga__](https://github.com/rafaelgss),\n  <https://x.com/_rafaelgss>, <https://www.npmjs.com/~rafaelgss>\n* [__Trivikram Kamat__](https://github.com/trivikr),\n  <https://x.com/trivikram>, <https://www.npmjs.com/~trivikr>\n* [__Ayoub El Khattabi__](https://github.com/AyoubElk),\n  <https://x.com/ayoubelkh>, <https://www.npmjs.com/~ayoubelk>\n* [__Cemre Mengu__](https://github.com/cemremengu),\n  <https://x.com/cemremengu>, <https://www.npmjs.com/~cemremengu>\n* [__Salman Mitha__](https://github.com/salmanm),\n  <https://www.npmjs.com/~salmanm>\n* [__Nathan Woltman__](https://github.com/nwoltman),\n  <https://x.com/NathanWoltman>, <https://www.npmjs.com/~nwoltman>\n\n## Hosted by\n\n[<img\nsrc=\"https://github.com/openjs-foundation/artwork/blob/main/openjs_foundation/openjs_foundation-logo-horizontal-color.png?raw=true\"\nwidth=\"250px;\"/>](https://openjsf.org/projects)\n\nWe are an [At-Large\nProject](https://github.com/openjs-foundation/cross-project-council/blob/HEAD/PROJECT_PROGRESSION.md#at-large-projects)\nin the [OpenJS Foundation](https://openjsf.org/).\n\n## Sponsors\n\nSupport this project by becoming a [SPONSOR](./SPONSORS.md)!\nFastify has an [Open Collective](https://opencollective.com/fastify)\npage where we accept and manage financial contributions.\n\n## Acknowledgments\n\nThis project is kindly sponsored by:\n- [NearForm](https://nearform.com)\n- [Platformatic](https://platformatic.dev)\n\nPast Sponsors:\n- [LetzDoIt](https://www.letzdoitapp.com/)\n\nThis list includes all companies that support one or more team members\nin maintaining this project.\n\n## License\n\nLicensed under [MIT](./LICENSE).\n\nFor your convenience, here is a list of all the licenses of our production\ndependencies:\n- MIT\n- ISC\n- BSD-3-Clause\n- BSD-2-Clause\n\n[hd-link]: https://www.herodevs.com/support/fastify-nes?utm_source=fastify&utm_medium=link&utm_campaign=github_readme\n[lts-link]: https://fastify.dev/docs/latest/Reference/LTS/\n",
      "stars_today": 14
    },
    {
      "id": 413918947,
      "name": "turborepo",
      "full_name": "vercel/turborepo",
      "description": "Build system optimized for JavaScript¬†and TypeScript, written in Rust",
      "html_url": "https://github.com/vercel/turborepo",
      "stars": 29555,
      "forks": 2222,
      "language": "Rust",
      "topics": [
        "build-system",
        "build-tool",
        "javascript",
        "monorepo",
        "typescript"
      ],
      "created_at": "2021-10-05T17:37:11Z",
      "updated_at": "2026-01-17T00:58:47Z",
      "pushed_at": "2026-01-17T00:56:14Z",
      "open_issues": 129,
      "owner": {
        "login": "vercel",
        "avatar_url": "https://avatars.githubusercontent.com/u/14985020?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://turborepo.dev\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://user-images.githubusercontent.com/4060187/196936123-f6e1db90-784d-4174-b774-92502b718836.png\">\n      <img src=\"https://user-images.githubusercontent.com/4060187/196936104-5797972c-ab10-4834-bd61-0d1e5f442c9c.png\" height=\"128\">\n    </picture>\n    <h1 align=\"center\">Turborepo</h1>\n  </a>\n</p>\n\n<p align=\"center\">\n  <a aria-label=\"Vercel logo\" href=\"https://vercel.com/\"><img src=\"https://img.shields.io/badge/MADE%20BY%20Vercel-000000.svg?style=for-the-badge&logo=Vercel&labelColor=000\"></a>\n  <a aria-label=\"NPM version\" href=\"https://www.npmjs.com/package/turbo\"><img alt=\"\" src=\"https://img.shields.io/npm/v/turbo.svg?style=for-the-badge&labelColor=000000\"></a>\n  <a aria-label=\"License\" href=\"https://github.com/vercel/turborepo/blob/main/LICENSE\"><img alt=\"\" src=\"https://img.shields.io/npm/l/turbo.svg?style=for-the-badge&labelColor=000000&color=\"></a>\n  <a aria-label=\"Join the community on GitHub\" href=\"https://github.com/vercel/turborepo/discussions\"><img alt=\"\" src=\"https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&logo=turborepo&labelColor=000000&logoWidth=20&logoColor=white\"></a>\n</p>\n\nTurborepo is a high-performance build system for JavaScript and TypeScript codebases, written in Rust.\n\n## Getting Started\n\nVisit https://turborepo.dev to get started with Turborepo.\n\n## Contributing\n\nSee [CONTRIBUTING.md](https://github.com/vercel/turborepo/blob/main/CONTRIBUTING.md) for more information.\n\n## Community\n\nThe Turborepo community can be found on [GitHub Discussions](https://github.com/vercel/turborepo/discussions), where you can ask questions, voice ideas, and share your projects.\n\nTo chat with other community members, you can join [Vercel Community's `#turborepo` tag](https://vercel.community/tag/turborepo).\n\nOur [Code of Conduct](https://github.com/vercel/turborepo/blob/main/CODE_OF_CONDUCT.md) applies to all Turborepo community channels.\n\n## Who is using Turborepo?\n\nTurborepo is used by the world's leading companies. Check out the [Turborepo Showcase](https://turborepo.dev/showcase) to learn more.\n\n## Updates\n\nFollow [@turborepo](https://x.com/turborepo) on X for project updates.\n\n## Security\n\nIf you believe you have found a security vulnerability in Turborepo, we encourage you to responsibly disclose this and not open a public issue. We will investigate all legitimate reports. Email `security@vercel.com` to disclose any security vulnerabilities.\n\nhttps://vercel.com/security\n",
      "stars_today": 14
    },
    {
      "id": 949523404,
      "name": "cursor-talk-to-figma-mcp",
      "full_name": "grab/cursor-talk-to-figma-mcp",
      "description": "TalkToFigma: MCP integration between Cursor and Figma, allowing Cursor Agentic AI to communicate with Figma for reading designs and modifying them programmatically.",
      "html_url": "https://github.com/grab/cursor-talk-to-figma-mcp",
      "stars": 6128,
      "forks": 645,
      "language": "JavaScript",
      "topics": [
        "agent",
        "agentic",
        "agentic-ai",
        "ai",
        "ai-agents",
        "automation",
        "cursor",
        "design",
        "figma",
        "generative-ai",
        "llm",
        "llms",
        "mcp",
        "model-context-protocol"
      ],
      "created_at": "2025-03-16T16:45:37Z",
      "updated_at": "2026-01-16T19:57:34Z",
      "pushed_at": "2025-11-03T01:00:00Z",
      "open_issues": 73,
      "owner": {
        "login": "grab",
        "avatar_url": "https://avatars.githubusercontent.com/u/17284363?v=4"
      },
      "readme": "# Cursor Talk to Figma MCP\n\nThis project implements a Model Context Protocol (MCP) integration between Cursor AI and Figma, allowing Cursor to communicate with Figma for reading designs and modifying them programmatically.\n\nhttps://github.com/user-attachments/assets/129a14d2-ed73-470f-9a4c-2240b2a4885c\n\n## Project Structure\n\n- `src/talk_to_figma_mcp/` - TypeScript MCP server for Figma integration\n- `src/cursor_mcp_plugin/` - Figma plugin for communicating with Cursor\n- `src/socket.ts` - WebSocket server that facilitates communication between the MCP server and Figma plugin\n\n## Get Started\n\n1. Install Bun if you haven't already:\n\n```bash\ncurl -fsSL https://bun.sh/install | bash\n```\n\n2. Run setup, this will also install MCP in your Cursor's active project\n\n```bash\nbun setup\n```\n\n3. Start the Websocket server\n\n```bash\nbun socket\n```\n\n4. **NEW** Install Figma plugin from [Figma community page](https://www.figma.com/community/plugin/1485687494525374295/cursor-talk-to-figma-mcp-plugin) or [install locally](#figma-plugin)\n\n## Quick Video Tutorial\n\n[Video Link](https://www.linkedin.com/posts/sonnylazuardi_just-wanted-to-share-my-latest-experiment-activity-7307821553654657024-yrh8)\n\n## Design Automation Example\n\n**Bulk text content replacement**\n\nThanks to [@dusskapark](https://github.com/dusskapark) for contributing the bulk text replacement feature. Here is the [demo video](https://www.youtube.com/watch?v=j05gGT3xfCs).\n\n**Instance Override Propagation**\nAnother contribution from [@dusskapark](https://github.com/dusskapark)\nPropagate component instance overrides from a source instance to multiple target instances with a single command. This feature dramatically reduces repetitive design work when working with component instances that need similar customizations. Check out our [demo video](https://youtu.be/uvuT8LByroI).\n\n## Development Setup\n\nTo develop, update your mcp config to direct to your local directory.\n\n```json\n{\n  \"mcpServers\": {\n    \"TalkToFigma\": {\n      \"command\": \"bun\",\n      \"args\": [\"/path-to-repo/src/talk_to_figma_mcp/server.ts\"]\n    }\n  }\n}\n```\n\n## Manual Setup and Installation\n\n### MCP Server: Integration with Cursor\n\nAdd the server to your Cursor MCP configuration in `~/.cursor/mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"TalkToFigma\": {\n      \"command\": \"bunx\",\n      \"args\": [\"cursor-talk-to-figma-mcp@latest\"]\n    }\n  }\n}\n```\n\n### WebSocket Server\n\nStart the WebSocket server:\n\n```bash\nbun socket\n```\n\n### Figma Plugin\n\n1. In Figma, go to Plugins > Development > New Plugin\n2. Choose \"Link existing plugin\"\n3. Select the `src/cursor_mcp_plugin/manifest.json` file\n4. The plugin should now be available in your Figma development plugins\n\n## Windows + WSL Guide\n\n1. Install bun via powershell\n\n```bash\npowershell -c \"irm bun.sh/install.ps1|iex\"\n```\n\n2. Uncomment the hostname `0.0.0.0` in `src/socket.ts`\n\n```typescript\n// uncomment this to allow connections in windows wsl\nhostname: \"0.0.0.0\",\n```\n\n3. Start the websocket\n\n```bash\nbun socket\n```\n\n## Usage\n\n1. Start the WebSocket server\n2. Install the MCP server in Cursor\n3. Open Figma and run the Cursor MCP Plugin\n4. Connect the plugin to the WebSocket server by joining a channel using `join_channel`\n5. Use Cursor to communicate with Figma using the MCP tools\n\n## MCP Tools\n\nThe MCP server provides the following tools for interacting with Figma:\n\n### Document & Selection\n\n- `get_document_info` - Get information about the current Figma document\n- `get_selection` - Get information about the current selection\n- `read_my_design` - Get detailed node information about the current selection without parameters\n- `get_node_info` - Get detailed information about a specific node\n- `get_nodes_info` - Get detailed information about multiple nodes by providing an array of node IDs\n- `set_focus` - Set focus on a specific node by selecting it and scrolling viewport to it\n- `set_selections` - Set selection to multiple nodes and scroll viewport to show them\n\n### Annotations\n\n- `get_annotations` - Get all annotations in the current document or specific node\n- `set_annotation` - Create or update an annotation with markdown support\n- `set_multiple_annotations` - Batch create/update multiple annotations efficiently\n- `scan_nodes_by_types` - Scan for nodes with specific types (useful for finding annotation targets)\n\n### Prototyping & Connections\n\n- `get_reactions` - Get all prototype reactions from nodes with visual highlight animation\n- `set_default_connector` - Set a copied FigJam connector as the default connector style for creating connections (must be set before creating connections)\n- `create_connections` - Create FigJam connector lines between nodes, based on prototype flows or custom mapping\n\n### Creating Elements\n\n- `create_rectangle` - Create a new rectangle with position, size, and optional name\n- `create_frame` - Create a new frame with position, size, and optional name\n- `create_text` - Create a new text node with customizable font properties\n\n### Modifying text content\n\n- `scan_text_nodes` - Scan text nodes with intelligent chunking for large designs\n- `set_text_content` - Set the text content of a single text node\n- `set_multiple_text_contents` - Batch update multiple text nodes efficiently\n\n### Auto Layout & Spacing\n\n- `set_layout_mode` - Set the layout mode and wrap behavior of a frame (NONE, HORIZONTAL, VERTICAL)\n- `set_padding` - Set padding values for an auto-layout frame (top, right, bottom, left)\n- `set_axis_align` - Set primary and counter axis alignment for auto-layout frames\n- `set_layout_sizing` - Set horizontal and vertical sizing modes for auto-layout frames (FIXED, HUG, FILL)\n- `set_item_spacing` - Set distance between children in an auto-layout frame\n\n### Styling\n\n- `set_fill_color` - Set the fill color of a node (RGBA)\n- `set_stroke_color` - Set the stroke color and weight of a node\n- `set_corner_radius` - Set the corner radius of a node with optional per-corner control\n\n### Layout & Organization\n\n- `move_node` - Move a node to a new position\n- `resize_node` - Resize a node with new dimensions\n- `delete_node` - Delete a node\n- `delete_multiple_nodes` - Delete multiple nodes at once efficiently\n- `clone_node` - Create a copy of an existing node with optional position offset\n\n### Components & Styles\n\n- `get_styles` - Get information about local styles\n- `get_local_components` - Get information about local components\n- `create_component_instance` - Create an instance of a component\n- `get_instance_overrides` - Extract override properties from a selected component instance\n- `set_instance_overrides` - Apply extracted overrides to target instances\n\n### Export & Advanced\n\n- `export_node_as_image` - Export a node as an image (PNG, JPG, SVG, or PDF) - limited support on image currently returning base64 as text\n\n### Connection Management\n\n- `join_channel` - Join a specific channel to communicate with Figma\n\n### MCP Prompts\n\nThe MCP server includes several helper prompts to guide you through complex design tasks:\n\n- `design_strategy` - Best practices for working with Figma designs\n- `read_design_strategy` - Best practices for reading Figma designs\n- `text_replacement_strategy` - Systematic approach for replacing text in Figma designs\n- `annotation_conversion_strategy` - Strategy for converting manual annotations to Figma's native annotations\n- `swap_overrides_instances` - Strategy for transferring overrides between component instances in Figma\n- `reaction_to_connector_strategy` - Strategy for converting Figma prototype reactions to connector lines using the output of 'get_reactions', and guiding the use 'create_connections' in sequence\n\n## Development\n\n### Building the Figma Plugin\n\n1. Navigate to the Figma plugin directory:\n\n   ```\n   cd src/cursor_mcp_plugin\n   ```\n\n2. Edit code.js and ui.html\n\n## Best Practices\n\nWhen working with the Figma MCP:\n\n1. Always join a channel before sending commands\n2. Get document overview using `get_document_info` first\n3. Check current selection with `get_selection` before modifications\n4. Use appropriate creation tools based on needs:\n   - `create_frame` for containers\n   - `create_rectangle` for basic shapes\n   - `create_text` for text elements\n5. Verify changes using `get_node_info`\n6. Use component instances when possible for consistency\n7. Handle errors appropriately as all commands can throw exceptions\n8. For large designs:\n   - Use chunking parameters in `scan_text_nodes`\n   - Monitor progress through WebSocket updates\n   - Implement appropriate error handling\n9. For text operations:\n   - Use batch operations when possible\n   - Consider structural relationships\n   - Verify changes with targeted exports\n10. For converting legacy annotations:\n    - Scan text nodes to identify numbered markers and descriptions\n    - Use `scan_nodes_by_types` to find UI elements that annotations refer to\n    - Match markers with their target elements using path, name, or proximity\n    - Categorize annotations appropriately with `get_annotations`\n    - Create native annotations with `set_multiple_annotations` in batches\n    - Verify all annotations are properly linked to their targets\n    - Delete legacy annotation nodes after successful conversion\n11. Visualize prototype noodles as FigJam connectors:\n\n- Use `get_reactions` to extract prototype flows,\n- set a default connector with `set_default_connector`,\n- and generate connector lines with `create_connections` for clear visual flow mapping.\n\n## License\n\nMIT\n",
      "stars_today": 14
    },
    {
      "id": 633817517,
      "name": "pixi",
      "full_name": "prefix-dev/pixi",
      "description": "Package management made easy",
      "html_url": "https://github.com/prefix-dev/pixi",
      "stars": 6131,
      "forks": 409,
      "language": "Rust",
      "topics": [
        "conda",
        "conda-environment",
        "conda-packages",
        "package-management",
        "package-manager",
        "package-manager-tool",
        "python-virtual-environment",
        "rust",
        "rust-lang"
      ],
      "created_at": "2023-04-28T10:51:16Z",
      "updated_at": "2026-01-16T23:56:10Z",
      "pushed_at": "2026-01-16T15:49:21Z",
      "open_issues": 569,
      "owner": {
        "login": "prefix-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/111356225?v=4"
      },
      "readme": "<h1>\n  <a href=\"https://github.com/prefix-dev/pixi/\">\n    <picture>\n      <source srcset=\"https://github.com/user-attachments/assets/fb67afa5-1c2a-4f47-9b8e-d60648557bfc\" type=\"image/png\">\n      <source srcset=\"https://github.com/user-attachments/assets/fa2e98c2-0913-4098-9579-8f2efff7f814\" type=\"image/webp\">\n      <img src=\"https://github.com/user-attachments/assets/fb67afa5-1c2a-4f47-9b8e-d60648557bfc\" alt=\"banner\">\n    </picture>\n  </a>\n</h1>\n\n<h1 align=\"center\">\n\n![License][license-badge]\n[![Project Chat][chat-badge]][chat-url]\n[![Pixi Badge][pixi-badge]][pixi-url]\n\n\n[license-badge]: https://img.shields.io/badge/license-BSD--3--Clause-blue?style=flat-square\n[chat-badge]: https://img.shields.io/discord/1082332781146800168.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2&style=flat-square\n[chat-url]: https://discord.gg/kKV8ZxyzY4\n[pixi-badge]:https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/prefix-dev/pixi/main/assets/badge/v0.json&style=flat-square\n[pixi-url]: https://pixi.sh\n\n</h1>\n\n# Pixi: Package Management Made Easy\n\n## Overview\n\n`pixi` is a cross-platform, multi-language package manager and workflow tool built on the foundation of the conda ecosystem. It provides developers with an exceptional experience similar to popular package managers like [`cargo`](https://doc.rust-lang.org/cargo/) or [`npm`](https://docs.npmjs.com), but for any language.\n\nDeveloped with ‚ù§Ô∏è at [prefix.dev](https://prefix.dev).\n[![Real-time pixi_demo](https://github.com/prefix-dev/pixi/assets/12893423/0fc8f8c8-ac13-4c14-891b-dc613f25475b)](https://asciinema.org/a/636482)\n\n## Highlights\n\n- Supports **multiple languages** including Python, C++, and R using Conda packages. You can find available packages on [prefix.dev](https://prefix.dev).\n- Compatible with all major operating systems: Linux, Windows, macOS (including Apple Silicon).\n- Always includes an up-to-date [**lock file**](https://pixi.sh/latest/workspace/lockfile/).\n- Provides a clean and simple Cargo-like **command-line interface**.\n- Allows you to install tools **per-project** or **system-wide**.\n- Entirely written in **Rust** and built on top of the **[rattler](https://github.com/conda/rattler)** library.\n\n## Getting Started\n\n- ‚ö° [Installation](#installation)\n- ‚öôÔ∏è [Examples](/examples)\n- üìö [Documentation](https://pixi.sh/)\n- üòç [Contributing](#contributing)\n- üî® [Built using Pixi](#built-using-pixi)\n- üöÄ [GitHub Action](https://github.com/prefix-dev/setup-pixi)\n\n## Status\n\nPixi is ready for production!\nWe are working hard to keep file-format changes compatible with the previous\nversions so that you can rely on Pixi with peace of mind.\n\nSome notable features we envision for upcoming releases are:\n\n- **Build and publish** your project as a Conda package.\n- Support for **dependencies from source**.\n- More powerful \"global installation\" of packages towards a deterministic setup of global packages on multiple machines.\n\n## Installation\n\n`pixi` can be installed on macOS, Linux, and Windows. The provided scripts will automatically download the latest version of `pixi`, extract it, and move the `pixi` binary to `~/.pixi/bin`. If this directory does not exist, the script will create it.\n\n### macOS and Linux\n\nTo install Pixi on macOS and Linux, open a terminal and run the following command:\n\n```bash\ncurl -fsSL https://pixi.sh/install.sh | sh\n# or with brew\nbrew install pixi\n```\n\nThe script will also update your `~/.bashrc` to include `~/.pixi/bin` in your `PATH`, allowing you to invoke the `pixi` command from anywhere.\nYou might need to restart your terminal or source your shell for the changes to take effect.\n\nStarting with macOS Catalina [zsh is the default login shell and interactive shell](https://support.apple.com/en-us/102360). Therefore, you might want to use `zsh` instead of `bash` in the install command:\n\n```zsh\ncurl -fsSL https://pixi.sh/install.sh | zsh\n```\n\nThe script will also update your `~/.zshrc` to include `~/.pixi/bin` in your `PATH`, allowing you to invoke the `pixi` command from anywhere.\n\n### Windows\n\nTo install Pixi on Windows, open a PowerShell terminal (you may need to run it as an administrator) and run the following command:\n\n```powershell\npowershell -ExecutionPolicy ByPass -c \"irm -useb https://pixi.sh/install.ps1 | iex\"\n```\nChanging the [execution policy](https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_execution_policies?view=powershell-7.4#powershell-execution-policies) allows running a script from the internet.\nCheck the script you would be running with:\n```powershell\npowershell -c \"irm -useb https://pixi.sh/install.ps1 | more\"\n```\n\nThe script will inform you once the installation is successful and add the `~/.pixi/bin` directory to your `PATH`, which will allow you to run the `pixi` command from any location.\nOr with `winget`\n\n```shell\nwinget install prefix-dev.pixi\n```\n\n### Autocompletion\n\nTo get autocompletion follow the instructions for your shell.\nAfterwards, restart the shell or source the shell config file.\n\n#### Bash (default on most Linux systems)\n\nAdd the following to the end of `~/.bashrc`:\n\n```bash\n# ~/.bashrc\n\neval \"$(pixi completion --shell bash)\"\n```\n#### Zsh (default on macOS)\n\nAdd the following to the end of `~/.zshrc`:\n\n\n```zsh\n# ~/.zshrc\n\neval \"$(pixi completion --shell zsh)\"\n```\n\n#### PowerShell (pre-installed on all Windows systems)\n\nAdd the following to the end of `Microsoft.PowerShell_profile.ps1`.\nYou can check the location of this file by querying the `$PROFILE` variable in PowerShell.\nTypically the path is `~\\Documents\\PowerShell\\Microsoft.PowerShell_profile.ps1` or\n`~/.config/powershell/Microsoft.PowerShell_profile.ps1` on -Nix.\n\n```pwsh\n(& pixi completion --shell powershell) | Out-String | Invoke-Expression\n```\n\n#### Fish\n\nAdd the following to the end of `~/.config/fish/config.fish`:\n\n```fish\n# ~/.config/fish/config.fish\n\npixi completion --shell fish | source\n```\n\n#### Nushell\n\nAdd the following to your Nushell config file (find it by running `$nu.config-path` in Nushell):\n\n```nushell\nmkdir $\"($nu.data-dir)/vendor/autoload\"\npixi completion --shell nushell | save --force $\"($nu.data-dir)/vendor/autoload/pixi-completions.nu\"\n```\n\n#### Elvish\n\nAdd the following to the end of `~/.elvish/rc.elv`:\n\n```elv\n# ~/.elvish/rc.elv\n\neval (pixi completion --shell elvish | slurp)\n```\n\n### Distro Packages\n\n[![Packaging status](https://repology.org/badge/vertical-allrepos/pixi.svg)](https://repology.org/project/pixi/versions)\n\n#### Arch Linux\n\nYou can install `pixi` from the [extra repository](https://archlinux.org/packages/extra/x86_64/pixi/) using [pacman](https://wiki.archlinux.org/title/Pacman):\n\n```shell\npacman -S pixi\n```\n\n#### Alpine Linux\n\n`pixi` is available for [Alpine Edge](https://pkgs.alpinelinux.org/packages?name=pixi&branch=edge). It can be installed via [apk](https://wiki.alpinelinux.org/wiki/Alpine_Package_Keeper) after enabling the [testing repository](https://wiki.alpinelinux.org/wiki/Repositories).\n\n```shell\napk add pixi\n```\n\n## Build/install from source\n\n`pixi` is 100% written in Rust and therefore it can be installed, built and tested with cargo.\nTo start using `pixi` from a source build run:\n\n```shell\ncargo install --locked --git https://github.com/prefix-dev/pixi.git pixi\n```\n\nWe don't publish to `crates.io` anymore, so you need to install it from the repository.\nThe reason for this is that we depend on some unpublished crates which disallows us to publish to `crates.io`.\n\nor when you want to make changes use:\n\n```shell\ncargo build\ncargo test\n```\n\nIf you have any issues building because of the dependency on `rattler` checkout\nit's [compile steps](https://github.com/conda/rattler/tree/main#give-it-a-try)\n\n## Uninstall\n\nTo uninstall, the Pixi binary should be removed.\nDelete `pixi` from the `$PIXI_DIR` which is default to `~/.pixi/bin/pixi`\n\nSo on Linux its:\n\n```shell\nrm ~/.pixi/bin/pixi\n```\n\nand on Windows:\n\n```shell\n$PIXI_BIN = \"$Env:LocalAppData\\pixi\\bin\\pixi\"; Remove-Item -Path $PIXI_BIN\n```\n\nAfter this command you can still use the tools you installed with `pixi`.\nTo remove these as well just remove the whole `~/.pixi` directory and remove the directory from your path.\n\n# Usage\n\nThe cli looks as follows:\n\n```bash\n‚ûú pixi\nPixi [version 0.59.0] - Developer Workflow and Environment Management for Multi-Platform, Language-Agnostic\nWorkspaces.\n\nPixi is a versatile developer workflow tool designed to streamline the management of your workspace's dependencies,\ntasks, and environments.\nBuilt on top of the Conda ecosystem, Pixi offers seamless integration with the PyPI ecosystem.\n\nBasic Usage:\n    Initialize pixi for a workspace:\n    $ pixi init\n    $ pixi add python numpy pytest\n\n    Run a task:\n    $ pixi task add test 'pytest -s'\n    $ pixi run test\n\nFound a Bug or Have a Feature Request?\nOpen an issue at: https://github.com/prefix-dev/pixi/issues\n\nNeed Help?\nAsk a question on the Prefix Discord server: https://discord.gg/kKV8ZxyzY4\n\nFor more information, see the documentation at: https://pixi.sh\n\nUsage: pixi [OPTIONS] [COMMAND]\n\nCommands:\n  add         Adds dependencies to the workspace [aliases: a]\n  auth        Login to prefix.dev or anaconda.org servers to access private channels\n  build       Workspace configuration\n  clean       Cleanup the environments\n  completion  Generates a completion script for a shell\n  config      Configuration management\n  exec        Run a command and install it in a temporary environment [aliases: x]\n  global      Subcommand for global package management actions [aliases: g]\n  info        Information about the system, workspace and environments for the current machine\n  init        Creates a new workspace\n  import      Imports a file into an environment in an existing workspace.\n  install     Install an environment, both updating the lockfile and installing the environment [aliases: i]\n  list        List the packages of the current workspace [aliases: ls]\n  lock        Solve environment and update the lock file without installing the environments\n  reinstall   Re-install an environment, both updating the lockfile and re-installing the environment\n  remove      Removes dependencies from the workspace [aliases: rm]\n  run         Runs task in the pixi environment [aliases: r]\n  search      Search a conda package\n  shell       Start a shell in a pixi environment, run `exit` to leave the shell [aliases: s]\n  shell-hook  Print the pixi environment activation script\n  task        Interact with tasks in the workspace\n  tree        Show a tree of workspace dependencies [aliases: t]\n  update      The `update` command checks if there are newer versions of the dependencies and updates the `pixi.lock`\n              file and environments accordingly\n  upgrade     Checks if there are newer versions of the dependencies and upgrades them in the lockfile and manifest\n              file\n  upload      Upload a conda package\n  workspace   Modify the workspace configuration file through the command line\n  help        Print this message or the help of the given subcommand(s)\n\nOptions:\n  -V, --version  Print version\n\nGlobal Options:\n  -h, --help           Display help information\n  -v, --verbose...     Increase logging verbosity (-v for warnings, -vv for info, -vvv for debug, -vvvv for trace)\n  -q, --quiet...       Decrease logging verbosity (quiet mode)\n      --color <COLOR>  Whether the log needs to be colored [env: PIXI_COLOR=] [default: auto] [possible values:\n                       always, never, auto]\n      --no-progress    Hide all progress bars, always turned on if stderr is not a terminal [env: PIXI_NO_PROGRESS=]\n      --list           List all installed commands (built-in and extensions)\n```\n\n## Creating a Pixi workspace\n\nInitialize a new workspace and navigate to the workspace directory\n\n```\npixi init myworkspace\ncd myworkspace\n```\n\nAdd the dependencies you want to use\n\n```\npixi add cowpy\n```\n\nRun the installed package in its environment\n\n```bash\npixi run cowpy \"Thanks for using pixi\"\n```\n\nActivate a shell in the environment\n\n```shell\npixi shell\ncowpy \"Thanks for using pixi\"\nexit\n```\n\nCheck out https://pixi.sh/dev/first_workspace/ for a more detailed introduction to workspaces.\n\n## Installing a conda package globally\n\nYou can also globally install conda packages into their own environment.\nThis behavior is similar to [`pipx`](https://github.com/pypa/pipx) or [`condax`](https://github.com/mariusvniekerk/condax).\n\n```bash\npixi global install cowpy\n```\n\n## Use in GitHub Actions\n\nYou can use Pixi in GitHub Actions to install dependencies and run commands.\nIt supports automatic caching of your environments.\n\n```yml\n- uses: prefix-dev/setup-pixi@v0.8.1\n- run: pixi exec cowpy \"Thanks for using pixi\"\n```\n\nSee the [documentation](https://pixi.sh/latest/advanced/github_actions) for more details.\n\n<a name=\"contributing\"></a>\n\n## Contributing üòç\n\nWe would absolutely love for you to contribute to Pixi!\nWhether you want to start an issue, fix a bug you encountered, or suggest an\nimprovement, every contribution is greatly appreciated.\n\nIf you're just getting started with our project or stepping into the Rust\necosystem for the first time, we've got your back!\nWe recommend beginning with issues labeled as `good first issue`.\nThese are carefully chosen tasks that provide a smooth entry point into\ncontributing.These issues are typically more straightforward and are a great way\nto get familiar with the project.\n\nGot questions or ideas, or just want to chat? Join our lively conversations on\nDiscord.\nWe're very active and would be happy to welcome you to our\ncommunity. [Join our discord server today!][chat-url]\n\n<a name=\"pixibuilt\"></a>\n\n## Built using Pixi\n\nTo see what's being built with `pixi` check out the [Community](/docs/misc/Community.md) page.\n",
      "stars_today": 14
    },
    {
      "id": 576303915,
      "name": "KernelSU",
      "full_name": "tiann/KernelSU",
      "description": "A Kernel based root solution for Android",
      "html_url": "https://github.com/tiann/KernelSU",
      "stars": 14725,
      "forks": 3013,
      "language": "Kotlin",
      "topics": [
        "android",
        "kernel",
        "kernelsu",
        "root",
        "su"
      ],
      "created_at": "2022-12-09T14:03:54Z",
      "updated_at": "2026-01-17T00:35:17Z",
      "pushed_at": "2026-01-16T15:09:12Z",
      "open_issues": 29,
      "owner": {
        "login": "tiann",
        "avatar_url": "https://avatars.githubusercontent.com/u/4233744?v=4"
      },
      "readme": "**English** | [Espa√±ol](README_ES.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](README_CN.md) | [ÁπÅÈ´î‰∏≠Êñá](README_TW.md) | [Êó•Êú¨Ë™û](README_JP.md) | [ÌïúÍµ≠Ïñ¥](README_KR.md) | [Polski](README_PL.md) | [Portugu√™s (Brasil)](README_PT-BR.md) | [T√ºrk√ße](README_TR.md) | [–†—É—Å—Å–∫–∏–π](README_RU.md) | [Ti·∫øng Vi·ªát](README_VI.md) | [Indonesia](README_ID.md) | [◊¢◊ë◊®◊ô◊™](README_IW.md) | [‡§π‡§ø‡§Ç‡§¶‡•Ä](README_IN.md) | [Italiano](README_IT.md)\n\n# KernelSU\n\n<img src=\"https://kernelsu.org/logo.png\" style=\"width: 96px;\" alt=\"logo\">\n\nA kernel-based root solution for Android devices.\n\n[![Latest release](https://img.shields.io/github/v/release/tiann/KernelSU?label=Release&logo=github)](https://github.com/tiann/KernelSU/releases/latest)\n[![Weblate](https://img.shields.io/badge/Localization-Weblate-teal?logo=weblate)](https://hosted.weblate.org/engage/kernelsu)\n[![Channel](https://img.shields.io/badge/Follow-Telegram-blue.svg?logo=telegram)](https://t.me/KernelSU)\n[![License: GPL v2](https://img.shields.io/badge/License-GPL%20v2-orange.svg?logo=gnu)](https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html)\n[![GitHub License](https://img.shields.io/github/license/tiann/KernelSU?logo=gnu)](/LICENSE)\n\n## Features\n\n1. Kernel-based `su` and root access management.\n2. Module system based on [metamodules](https://kernelsu.org/guide/metamodule.html): Pluggable infrastructure for systemless modifications.\n3. [App Profile](https://kernelsu.org/guide/app-profile.html): Lock up the root power in a cage.\n\n## Compatibility state\n\nKernelSU officially supports Android GKI 2.0 devices (kernel 5.10+). Older kernels (4.14+) are also supported, but the kernel will need to be built manually.\n\nWith this, WSA, ChromeOS, and container-based Android are all supported.\n\nCurrently, only the `arm64-v8a` and `x86_64` architectures are supported.\n\n## Usage\n\n- [Installation](https://kernelsu.org/guide/installation.html)\n- [How to build](https://kernelsu.org/guide/how-to-build.html)\n- [Official website](https://kernelsu.org/)\n\n## Translation\n\nTo help translate KernelSU or improve existing translations, please use [Weblate](https://hosted.weblate.org/engage/kernelsu/). PR of Manager's translation is no longer accepted, because it will conflict with Weblate.\n\n## Discussion\n\n- Telegram: [@KernelSU](https://t.me/KernelSU)\n\n## Security\n\nFor information on reporting security vulnerabilities in KernelSU, see [SECURITY.md](/SECURITY.md).\n\n## License\n\n- Files under the `kernel` directory are [GPL-2.0-only](https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html).\n- All other parts except the `kernel` directory are [GPL-3.0-or-later](https://www.gnu.org/licenses/gpl-3.0.html).\n\n## Credits\n\n- [Kernel-Assisted Superuser](https://git.zx2c4.com/kernel-assisted-superuser/about/): The KernelSU idea.\n- [Magisk](https://github.com/topjohnwu/Magisk): The powerful root tool.\n- [genuine](https://github.com/brevent/genuine/): APK v2 signature validation.\n- [Diamorphine](https://github.com/m0nad/Diamorphine): Some rootkit skills.\n",
      "stars_today": 13
    },
    {
      "id": 208325027,
      "name": "ESP32Marauder",
      "full_name": "justcallmekoko/ESP32Marauder",
      "description": "A suite of WiFi/Bluetooth offensive and defensive tools for the ESP32",
      "html_url": "https://github.com/justcallmekoko/ESP32Marauder",
      "stars": 9590,
      "forks": 1076,
      "language": "C++",
      "topics": [
        "arduino",
        "beacon",
        "bluetooth",
        "command-line",
        "deauth",
        "deauthentication",
        "deauthentication-attack",
        "defensive",
        "esp32",
        "esp32-s2",
        "esp8266",
        "espressif",
        "firmware",
        "flipper-zero",
        "flipperzero",
        "iot",
        "offensive",
        "scanner",
        "spammer",
        "wifi"
      ],
      "created_at": "2019-09-13T18:37:40Z",
      "updated_at": "2026-01-17T00:42:05Z",
      "pushed_at": "2026-01-16T03:37:37Z",
      "open_issues": 235,
      "owner": {
        "login": "justcallmekoko",
        "avatar_url": "https://avatars.githubusercontent.com/u/25190487?v=4"
      },
      "readme": "<!---[![License: MIT](https://img.shields.io/github/license/mashape/apistatus.svg)](https://github.com/justcallmekoko/ESP32Marauder/blob/master/LICENSE)--->\n<!---[![Gitter](https://badges.gitter.im/justcallmekoko/ESP32Marauder.png)](https://gitter.im/justcallmekoko/ESP32Marauder)--->\n<!---[![Build Status](https://travis-ci.com/justcallmekoko/ESP32Marauder.svg?branch=master)](https://travis-ci.com/justcallmekoko/ESP32Marauder)--->\n<!---Shields/Badges https://shields.io/--->\n\n# ESP32 Marauder\n<p align=\"center\"><img alt=\"Marauder logo\" src=\"https://github.com/justcallmekoko/ESP32Marauder/blob/master/pictures/marauder_skull_patch_04_full_final.png?raw=true\" width=\"300\"></p>\n<p align=\"center\">\n  <b>A suite of WiFi/Bluetooth offensive and defensive tools for the ESP32</b>\n  <br><br>\n  <a href=\"https://github.com/justcallmekoko/ESP32Marauder/blob/master/LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/github/license/mashape/apistatus.svg\"></a>\n  <a href=\"https://gitter.im/justcallmekoko/ESP32Marauder\"><img alt=\"Gitter\" src=\"https://badges.gitter.im/justcallmekoko/ESP32Marauder.png\"/></a>\n  <a href=\"https://github.com/justcallmekoko/ESP32Marauder/releases/latest\"><img src=\"https://img.shields.io/github/downloads/justcallmekoko/ESP32Marauder/total\" alt=\"Downloads\"/></a>\n  <br>\n  <a href=\"https://twitter.com/intent/follow?screen_name=jcmkyoutube\"><img src=\"https://img.shields.io/twitter/follow/jcmkyoutube?style=social&logo=twitter\" alt=\"Twitter\"></a>\n  <a href=\"https://www.instagram.com/just.call.me.koko\"><img src=\"https://img.shields.io/badge/Follow%20Me-Instagram-orange\" alt=\"Instagram\"/></a>\n  <br><br>\n</p>\n    \n[![Build and Push](https://github.com/justcallmekoko/ESP32Marauder/actions/workflows/build_push.yml/badge.svg)](https://github.com/justcallmekoko/ESP32Marauder/actions/workflows/build_push.yml)\n\n## Getting Started\nDownload the [latest release](https://github.com/justcallmekoko/ESP32Marauder/releases/latest) of the firmware.  \n\nCheck out the project [wiki](https://github.com/justcallmekoko/ESP32Marauder/wiki) for a full overview of the ESP32 Marauder\n\n# For Sale Now\nYou can buy the ESP32 Marauder using [this link](https://www.justcallmekokollc.com)\n",
      "stars_today": 13
    },
    {
      "id": 910702543,
      "name": "Nrfr",
      "full_name": "Ackites/Nrfr",
      "description": "üåç ÂÖç Root ÁöÑ SIM Âç°ÂõΩÂÆ∂Á†Å‰øÆÊîπÂ∑•ÂÖ∑ | Ëß£ÂÜ≥ÂõΩÈôÖÊº´Ê∏∏Êó∂ÁöÑÂÖºÂÆπÊÄßÈóÆÈ¢òÔºåÂ∏ÆÂä©‰ΩøÁî®Êµ∑Â§ñ SIM Âç°Ëé∑ÂæóÊõ¥Â•ΩÁöÑÊú¨Âú∞Âåñ‰ΩìÈ™åÔºåËß£ÈîÅËøêËê•ÂïÜÈôêÂà∂ÔºåÁ™ÅÁ†¥Âå∫ÂüüÈôêÂà∂",
      "html_url": "https://github.com/Ackites/Nrfr",
      "stars": 5959,
      "forks": 505,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2025-01-01T05:57:30Z",
      "updated_at": "2026-01-16T23:20:01Z",
      "pushed_at": "2025-07-16T01:08:53Z",
      "open_issues": 67,
      "owner": {
        "login": "Ackites",
        "avatar_url": "https://avatars.githubusercontent.com/u/91859281?v=4"
      },
      "readme": "<div align=\"center\">\n  <h1>Nrfr</h1>\n  <p>üåç ÂÖç Root ÁöÑ SIM Âç°ÂõΩÂÆ∂Á†Å‰øÆÊîπÂ∑•ÂÖ∑ÔºåËÆ©‰Ω†ÁöÑÁΩëÁªúÊõ¥Ëá™Áî±</p>\n\n  <p>\n    <img src=\"https://img.shields.io/badge/platform-Android-3DDC84?logo=android\" alt=\"Platform\">\n    <img src=\"https://img.shields.io/badge/Android-8+-3DDC84?logo=android\" alt=\"Android Version\">\n    <img src=\"https://img.shields.io/badge/Go-1.21+-00ADD8?logo=go\" alt=\"Go Version\">\n    <img src=\"https://img.shields.io/badge/React-19-61DAFB?logo=react\" alt=\"React Version\">\n    <img src=\"https://img.shields.io/badge/TypeScript-5-3178C6?logo=typescript\" alt=\"TypeScript Version\">\n    <img src=\"https://img.shields.io/badge/Tailwind-3-38B2AC?logo=tailwind-css\" alt=\"Tailwind Version\">\n    <img src=\"https://img.shields.io/badge/Wails-2-000000?logo=wails\" alt=\"Wails Version\">\n  </p>\n\n  <p>\n      <img src=\"https://img.shields.io/github/stars/Ackites/Nrfr?style=flat\" alt=\"Stars\">\n      <img src=\"https://img.shields.io/github/forks/Ackites/Nrfr?style=flat\" alt=\"Forks\">\n      <img src=\"https://img.shields.io/github/issues/Ackites/Nrfr?style=flat\" alt=\"Issues\">\n      <img src=\"https://img.shields.io/github/last-commit/Ackites/Nrfr?style=flat\" alt=\"Last Commit\">\n      <img src=\"https://img.shields.io/github/release/Ackites/Nrfr?style=flat\" alt=\"Release\">\n      <img src=\"https://img.shields.io/github/downloads/Ackites/Nrfr/total?style=flat\" alt=\"Downloads\">\n      <img src=\"https://img.shields.io/github/license/Ackites/Nrfr?style=flat\" alt=\"License\">\n      <img src=\"https://img.shields.io/badge/Follow-@actkites-1DA1F2?logo=x&style=flat\" alt=\"Follow on X\">\n  </p>\n\n  <div style=\"display: flex; justify-content: center; align-items: center; gap: 20px; margin: 20px 0;\">\n    <img src=\"docs/images/client.png\" alt=\"Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑ÁïåÈù¢\" width=\"500\">\n    <img src=\"docs/images/app.png\" alt=\"Android Â∫îÁî®ÁïåÈù¢\" width=\"220\">\n  </div>\n   <br>\n</div>\n\nNrfr ÊòØ‰∏ÄÊ¨æÂº∫Â§ßÁöÑ SIM Âç°ÂõΩÂÆ∂Á†Å‰øÆÊîπÂ∑•ÂÖ∑ÔºåÊó†ÈúÄ Root ÊùÉÈôêÂç≥ÂèØ‰øÆÊîπ SIM Âç°ÂõΩÂÆ∂Á†Å„ÄÇÊú¨È°πÁõÆÂÆåÂÖ®Âü∫‰∫é Android Á≥ªÁªüÂéüÁîü API ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ\nXposed„ÄÅMagisk Á≠â‰ªª‰ΩïÁ¨¨‰∏âÊñπÊ°ÜÊû∂Ôºå‰ªÖÈÄöËøáË∞ÉÁî®Á≥ªÁªüÁ∫ßÊé•Âè£ÂÆûÁé∞ÂäüËÉΩ„ÄÇÈÄöËøá‰øÆÊîπÂõΩÂÆ∂Á†ÅÔºå‰Ω†ÂèØ‰ª•Ôºö\n\n- üåè Ëß£ÈîÅËøêËê•ÂïÜÈôêÂà∂Ôºå‰ΩøÁî®Êõ¥Â§öÊú¨Âú∞ÂäüËÉΩ\n- üîì Á™ÅÁ†¥Êüê‰∫õÂå∫ÂüüÈôêÂà∂ÁöÑÂ∫îÁî®ÂíåÊúçÂä°\n- üõ†Ô∏è Ëß£ÂÜ≥ÂõΩÈôÖÊº´Ê∏∏Êó∂ÁöÑÂÖºÂÆπÊÄßÈóÆÈ¢ò\n- üåê Â∏ÆÂä©‰ΩøÁî®Êµ∑Â§ñ SIM Âç°Ëé∑ÂæóÊõ¥Â•ΩÁöÑÊú¨Âú∞Âåñ‰ΩìÈ™å\n- ‚öôÔ∏è Ëß£ÂÜ≥ÈÉ®ÂàÜÂ∫îÁî®ËØÜÂà´ SIM Âç°Âú∞Âå∫ÈîôËØØÁöÑÈóÆÈ¢ò\n\n## üì± ‰ΩøÁî®Ê°à‰æã\n\n### ËøêËê•ÂïÜÈÖçÁΩÆ‰ºòÂåñ\n\n- ÊâãÊú∫Êó†Ê≥ïÊ≠£Á°ÆËØÜÂà´ËøêËê•ÂïÜÈÖçÁΩÆ\n- Êüê‰∫õËøêËê•ÂïÜÁâπÂÆöÂäüËÉΩÊó†Ê≥ï‰ΩøÁî®\n- ÁΩëÁªúÈÖçÁΩÆ‰∏éÂΩìÂú∞ËøêËê•ÂïÜ‰∏çÂåπÈÖç\n\n### ËøêËê•ÂïÜÂèÇÊï∞ÈÄÇÈÖç\n\n- ËøêËê•ÂïÜÂäüËÉΩÈÖçÁΩÆ‰∏çÂÆåÊï¥\n- ÁΩëÁªúÂèÇÊï∞‰∏éËøêËê•ÂïÜÈªòËÆ§ÈÖçÁΩÆ‰∏çÂåπÈÖç\n- ËøêËê•ÂïÜÁâπÂÆöÊúçÂä°Êó†Ê≥ïÊ≠£Â∏∏ÂêØÁî®\n\n### Êº´Ê∏∏ÁΩëÁªúËØÜÂà´\n\n- Êº´Ê∏∏Êó∂ËøêËê•ÂïÜÂêçÁß∞ÊòæÁ§∫ÂºÇÂ∏∏\n- ÁΩëÁªúÈÖçÁΩÆ‰∏éÊº´Ê∏∏Âú∞ËøêËê•ÂïÜ‰∏çÂåπÈÖç\n- ËøêËê•ÂïÜÁâπÂÆöÂäüËÉΩÊó†Ê≥ï‰ΩøÁî®\n\n### TikTok Âå∫ÂüüÈôêÂà∂Ëß£Èô§\n\n- TikTok ÁΩëÁªúÈîôËØØ\n- Êó†Ê≥ïÊ≠£Â∏∏‰ΩøÁî® TikTok ÁöÑÂÆåÊï¥ÂäüËÉΩ\n\n### Samsung Health Âå∫ÂüüÈôêÂà∂Ëß£Èô§\n\n- Êó†Ê≥ïÈÄöËøá Samsung Health ÁöÑÈ¶ñÊ¨° SIM Âç°Ê£ÄÊµã\n- Êó†Ê≥ïÂêåÊ≠•ÂÅ•Â∫∑Êï∞ÊçÆ\n- Êó†Ê≥ïÊ≠£Â∏∏‰ΩøÁî® Samsung Health ÁöÑÂÆåÊï¥ÂäüËÉΩ\n\n‰Ω†ÂèØ‰ª•Ôºö\n\n1. ‰ΩøÁî® Nrfr ‰øÆÊîπ SIM Âç°ÂõΩÂÆ∂Á†Å‰∏∫ÊîØÊåÅÁöÑÂú∞Âå∫ÔºàÂ¶Ç JP„ÄÅUS Á≠âÔºâ\n2. ÈáçÊñ∞ÊâìÂºÄ TikTokÔºåÂ∞±ÂèØ‰ª•Ê≠£Â∏∏‰ΩøÁî®‰∫Ü\n\n## üí° ÂÆûÁé∞ÂéüÁêÜ\n\nNrfr ÈÄöËøáË∞ÉÁî® Android Á≥ªÁªüÁ∫ß APIÔºàCarrierConfigLoaderÔºâ‰øÆÊîπÁ≥ªÁªüÂÜÖÁöÑËøêËê•ÂïÜÈÖçÁΩÆÂèÇÊï∞ÔºåËÄå**‰∏çÊòØÁõ¥Êé•‰øÆÊîπ SIM Âç°**„ÄÇËøôÁßçÂÆûÁé∞ÊñπÂºèÔºö\n\n- ÂÆåÂÖ®Âú®Á≥ªÁªüÂ±ÇÈù¢Â∑•‰ΩúÔºå‰∏ç‰ºöÂØπ SIM Âç°Êú¨Ë∫´ËøõË°å‰ªª‰Ωï‰øÆÊîπÊàñÈÄ†ÊàêÊçüÂùè\n- ‰ªÖÊîπÂèòÁ≥ªÁªüÂØπ SIM Âç°‰ø°ÊÅØÁöÑËØªÂèñÊñπÂºè\n- Âü∫‰∫é Android ÂéüÁîü API ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ‰ªª‰ΩïÁ¨¨‰∏âÊñπÊ°ÜÊû∂ÔºàÂ¶Ç Xposed„ÄÅMagisk Á≠âÔºâ\n- ÈÄöËøá Shizuku ‰ªÖÊèê‰æõÂøÖË¶ÅÁöÑÊùÉÈôêÊîØÊåÅ\n- ÊâÄÊúâ‰øÆÊîπÈÉΩÊòØÂèØÈÄÜÁöÑÔºåÈöèÊó∂ÂèØ‰ª•ËøòÂéü\n\n## ‚ú® ÁâπÊÄß\n\n- üîí ÂÆâÂÖ®ÂèØÈù†\n   - Êó†ÈúÄ Root ÊùÉÈôê\n   - ‰∏ç‰øÆÊîπÁ≥ªÁªüÊñá‰ª∂\n   - ‰∏çÂΩ±ÂìçÁ≥ªÁªüÁ®≥ÂÆöÊÄß\n   - ‰∏ç‰ºöÂØπ SIM Âç°ÈÄ†Êàê‰ªª‰ΩïÂΩ±Âìç\n- üîÑ ÂäüËÉΩÂÆåÂñÑ\n   - ÊîØÊåÅÈöèÊó∂ËøòÂéü‰øÆÊîπ\n   - ÊîØÊåÅÂèåÂç°ËÆæÂ§áÔºåÂèØÂàÜÂà´ÈÖçÁΩÆ\n   - ‰∏ÄÊ¨°‰øÆÊîπÊ∞∏‰πÖÁîüÊïàÔºåÈáçÂêØÂêé‰øùÊåÅ\n- üöÄ ÁÆÄÂçïÊòìÁî®\n   - ‰∏ÄÈîÆÂêØÂä®Â∑•ÂÖ∑\n   - Êô∫ËÉΩÊ£ÄÊµãËÆæÂ§áÂíå SIM Âç°Áä∂ÊÄÅ\n   - Ëá™Âä®ÂÆâË£ÖÊâÄÈúÄÂ∫îÁî®\n   - ÁÆÄÊ¥Å‰ºòÈõÖÁöÑÁî®Êà∑ÁïåÈù¢\n   - ËΩªÈáè‰∏îÈ´òÊïàÔºåÂÆâË£ÖÂåÖ‰ΩìÁßØÂ∞è\n\n## ‚ö†Ô∏è Ê≥®ÊÑè‰∫ãÈ°π\n\n- ÈúÄË¶ÅÂÆâË£ÖÂπ∂ÂêØÁî® Shizuku\n- ‰øÆÊîπÂõΩÂÆ∂Á†ÅÂèØËÉΩ‰ºöÂΩ±ÂìçËøêËê•ÂïÜÊúçÂä°ÔºåËØ∑Ë∞®ÊÖéÊìç‰Ωú\n- ÈÉ®ÂàÜËÆæÂ§áÂèØËÉΩ‰∏çÊîØÊåÅ‰øÆÊîπÂõΩÂÆ∂Á†Å\n- Â¶ÇÈúÄËøòÂéüËÆæÁΩÆÔºåËØ∑‰ΩøÁî®Â∫îÁî®ÂÜÖÁöÑËøòÂéüÂäüËÉΩ\n\n## üöÄ Âø´ÈÄüÂºÄÂßã\n\n‰∏ãËΩΩÈ°µÈù¢Êúâ‰∏§‰∏™Êñá‰ª∂Ôºå‰∏Ä‰∏™ÊòØÂê´Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑ÁöÑÂéãÁº©ÂåÖÔºåÂè¶‰∏Ä‰∏™Â∞±Âè™ÊòØ APK ÂÆâË£ÖÂåÖ„ÄÇ**Êé®Ëçê‰ΩøÁî®Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑**ÔºåËØ∑ÊåâÁÖß‰ª•‰∏ãÊ≠•È™§Êìç‰ΩúÔºö\n\n1. ÂáÜÂ§áÊâãÊú∫\n    - ÂêØÁî®ÂºÄÂèëËÄÖÈÄâÈ°πÔºàÂÖ∑‰ΩìÁöÑËá™Â∑±Êü•‰∏Ä‰∏ãÔºâ\n    - ËøõÂÖ•ÂºÄÂèëËÄÖÈÄâÈ°πÔºåÂºÄÂêØ USB Ë∞ÉËØï\n    - ÂºÄÂêØ USB Ë∞ÉËØïÔºàÂÆâÂÖ®ËÆæÁΩÆÔºâÔºåÂ¶ÇÊûúÊúâÂ∞±ÂºÄÂêØ\n    - ÂºÄÂêØ USB ÂÆâË£ÖÔºàÂÖÅËÆ∏ÈÄöËøá USB ÂÆâË£ÖÂ∫îÁî®Ôºâ\n    - Â¶ÇÊûúÊèêÁ§∫Êú™Áü•Êù•Ê∫êÂ∫îÁî®ÂÆâË£ÖÔºåËØ∑ÂÖÅËÆ∏‰ªéÊ≠§Êù•Ê∫êÂÆâË£Ö\n\n2. ËøûÊé•ÊâãÊú∫Âà∞ÁîµËÑë\n    - ‰ΩøÁî®Êï∞ÊçÆÁ∫øÂ∞ÜÊâãÊú∫ËøûÊé•Âà∞ÁîµËÑë\n    - Âú®ÊâãÊú∫‰∏äÂÖÅËÆ∏ USB Ë∞ÉËØïÊéàÊùÉ\n\n3. ‰∏ãËΩΩÂπ∂ÂêØÂä® Nrfr Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑\n    - ‰ªé Release È°µÈù¢‰∏ãËΩΩÊúÄÊñ∞ÁâàÊú¨ÁöÑÂø´ÈÄüÂêØÂä®Â∑•ÂÖ∑\n    - Ëß£ÂéãÂπ∂ËøêË°å Nrfr Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑\n    - Â∑•ÂÖ∑‰ºöËá™Âä®Ê£ÄÊµãÂ∑≤ËøûÊé•ÁöÑËÆæÂ§á\n\n4. ÂÆâË£ÖÂøÖË¶ÅÁªÑ‰ª∂\n    - Â∑•ÂÖ∑‰ºöËá™Âä®ÂÆâË£Ö Shizuku Âà∞ÊâãÊú∫\n    - ÊåâÁÖßÊèêÁ§∫ÂêØÁî® Shizuku\n    - Á≠âÂæÖÂ∑•ÂÖ∑Ëá™Âä®ÂÆâË£Ö Nrfr Â∫îÁî®\n\n5. ‰øÆÊîπÂõΩÂÆ∂Á†Å\n    - Âú®ÊâãÊú∫‰∏äÊâìÂºÄ Nrfr Â∫îÁî®\n    - ÈÄâÊã©ÈúÄË¶Å‰øÆÊîπÁöÑ SIM Âç°\n    - ËÆæÁΩÆÁõÆÊ†áÂõΩÂÆ∂Á†Å\n    - Â∫îÁî®‰øÆÊîπ\n\n‰øÆÊîπÂÆåÊàêÂêéÊó†ÈúÄÈáçÂêØËÆæÂ§áÔºåËÆæÁΩÆ‰ºöÁ´ãÂç≥ÁîüÊïàÂπ∂Ê∞∏‰πÖ‰øùÊåÅ„ÄÇÂ¶ÇÈúÄËøòÂéüÔºåËØ∑‰ΩøÁî®Â∫îÁî®ÂÜÖÁöÑËøòÂéüÂäüËÉΩ„ÄÇ\n\n## üì¶ ÊûÑÂª∫\n\nÈ°πÁõÆÂåÖÂê´‰∏§‰∏™ÈÉ®ÂàÜÔºöÂø´ÈÄüÂêØÂä®Â∑•ÂÖ∑ÔºàÊ°åÈù¢Á´ØÔºâÂíåÊâãÊú∫Â∫îÁî®ÔºàAndroidÔºâ„ÄÇ\n\n### Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑ (nrfr-client)\n\n```bash\n# ËøõÂÖ•ÂÆ¢Êà∑Á´ØÁõÆÂΩï\ncd nrfr-client\n\n# ÂÆâË£Ö‰æùËµñ\nnpm install\n\n# ÂºÄÂèëÊ®°Âºè\nwails dev\n\n# ÊûÑÂª∫ÂèëÂ∏ÉÁâàÊú¨\nwails build\n```\n\n### Android Â∫îÁî® (app)\n\n```bash\n# ËøõÂÖ• Android Â∫îÁî®ÁõÆÂΩï\ncd app\n\n# ‰ΩøÁî® Gradle ÊûÑÂª∫ Debug ÁâàÊú¨\n./gradlew assembleDebug\n```\n\nÊûÑÂª∫ÂÆåÊàêÂêéÔºåÂèØ‰ª•Âú®‰ª•‰∏ã‰ΩçÁΩÆÊâæÂà∞ÁîüÊàêÁöÑÊñá‰ª∂Ôºö\n\n- Âø´ÈÄüÂêØÂä®Â∑•ÂÖ∑: `nrfr-client/build/bin/`\n- Android Â∫îÁî®: `app/build/outputs/apk/`\n\n## üìù ‰æùËµñÈ°π\n\n- [Shizuku](https://shizuku.rikka.app/) - Áî®‰∫éÊèê‰æõÁâπÊùÉÊúçÂä°\n- [ADB](https://developer.android.com/tools/adb) - Android Ë∞ÉËØïÊ°•Êé•\n\n## ü§ù Ë¥°ÁåÆ\n\nÊ¨¢ËøéÊèê‰∫§ Pull Request Âíå IssueÔºÅÂú®Êèê‰∫§‰πãÂâçÔºåËØ∑Á°Æ‰øùÔºö\n\n- ‰ª£Á†ÅÁªèËøáÊµãËØï\n- ÈÅµÂæ™Áé∞ÊúâÁöÑ‰ª£Á†ÅÈ£éÊ†º\n- Êõ¥Êñ∞Áõ∏ÂÖ≥ÊñáÊ°£\n- ÊèèËø∞Ê∏ÖÊ•öÊîπÂä®ÁöÑÁõÆÁöÑÂíåÂΩ±Âìç\n\n## üìÑ ËÆ∏ÂèØËØÅ\n\nÊú¨È°πÁõÆÈááÁî® [Apache-2.0](LICENSE) ËÆ∏ÂèØËØÅ„ÄÇ\n\n## ‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé\n\nÊú¨Â∑•ÂÖ∑‰ªÖ‰æõÂ≠¶‰π†ÂíåÁ†îÁ©∂‰ΩøÁî®„ÄÇ‰ΩøÁî®Êú¨Â∑•ÂÖ∑‰øÆÊîπÁ≥ªÁªüËÆæÁΩÆÂèØËÉΩ‰ºöÂΩ±ÂìçËÆæÂ§áÁöÑÊ≠£Â∏∏‰ΩøÁî®ÔºåËØ∑Ëá™Ë°åÊâøÊãÖÈ£éÈô©„ÄÇ‰ΩúËÄÖ‰∏çÂØπ‰ªª‰ΩïÂèØËÉΩÁöÑÊçüÂ§±Ë¥üË¥£„ÄÇ\n\n## üíñ ÊîØÊåÅ\n\nÂ¶ÇÊûú‰Ω†ËßâÂæóËøô‰∏™È°πÁõÆÊúâÂ∏ÆÂä©Ôºö\n\n- Âú® X ‰∏äÂÖ≥Ê≥® [@actkites](https://x.com/intent/follow?screen_name=actkites)\n- ÁªôÈ°πÁõÆÁÇπ‰∏™ Star ‚≠ê\n- ÂàÜ‰∫´ÁªôÊõ¥Â§öÁöÑ‰∫∫\n\n## ‚≠ê Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Ackites/Nrfr&type=Date)](https://star-history.com/#Ackites/Nrfr&Date)\n\n## üôè È∏£Ë∞¢\n\n- [Shizuku](https://shizuku.rikka.app/) - ÊÑüË∞¢ Shizuku Êèê‰æõÁöÑÁâπÊùÉÊúçÂä°ÊîØÊåÅ\n\n## üöÄ ËµûÂä©ÂïÜ\n\n<div>\n  <p><strong>Êú¨È°πÁõÆ CDN Âä†ÈÄüÂèäÂÆâÂÖ®Èò≤Êä§Áî± Tencent EdgeOne ËµûÂä©</strong></p>\n  <a href=\"https://edgeone.ai/zh?from=github\" target=\"_blank\">\n    <img src=\"https://edgeone.ai/media/34fe3a45-492d-4ea4-ae5d-ea1087ca7b4b.png\" alt=\"Tencent EdgeOne\" width=\"200\">\n  </a>\n  <p><a href=\"https://edgeone.ai/zh?from=github\" target=\"_blank\">‰∫öÊ¥≤ÊúÄ‰Ω≥CDN„ÄÅËæπÁºòÂíåÂÆâÂÖ®Ëß£ÂÜ≥ÊñπÊ°à - Tencent EdgeOne</a></p>\n</div>\n\n[![Powered by DartNode](https://dartnode.com/branding/DN-Open-Source-sm.png)](https://dartnode.com \"Powered by DartNode - Free VPS for Open Source\")\n",
      "stars_today": 13
    },
    {
      "id": 507775,
      "name": "elasticsearch",
      "full_name": "elastic/elasticsearch",
      "description": "Free and Open Source, Distributed, RESTful Search Engine",
      "html_url": "https://github.com/elastic/elasticsearch",
      "stars": 75887,
      "forks": 25790,
      "language": "Java",
      "topics": [
        "elasticsearch",
        "java",
        "search-engine"
      ],
      "created_at": "2010-02-08T13:20:56Z",
      "updated_at": "2026-01-16T22:20:09Z",
      "pushed_at": "2026-01-17T00:33:55Z",
      "open_issues": 5354,
      "owner": {
        "login": "elastic",
        "avatar_url": "https://avatars.githubusercontent.com/u/6764390?v=4"
      },
      "readme": "= Elasticsearch\n\nElasticsearch is a distributed search and analytics engine, scalable data store and vector database optimized for speed and relevance on production-scale workloads. Elasticsearch is the foundation of Elastic's open Stack platform. Search in near real-time over massive datasets, perform vector searches, integrate with generative AI applications, and much more.\n\nUse cases enabled by Elasticsearch include:\n\n* https://www.elastic.co/search-labs/blog/articles/retrieval-augmented-generation-rag[Retrieval Augmented Generation (RAG)]\n* https://www.elastic.co/search-labs/blog/categories/vector-search[Vector search]\n* Full-text search\n* Logs\n* Metrics\n* Application performance monitoring (APM)\n* Security logs\n\n\\... and more!\n\nTo learn more about Elasticsearch's features and capabilities, see our\nhttps://www.elastic.co/products/elasticsearch[product page].\n\nTo access information on https://www.elastic.co/search-labs/blog/categories/ml-research[machine learning innovations] and the latest https://www.elastic.co/search-labs/blog/categories/lucene[Lucene contributions from Elastic], more information can be found in https://www.elastic.co/search-labs[Search Labs].\n\n[[get-started]]\n== Get started\n\nThe simplest way to set up Elasticsearch is to create a managed deployment with\nhttps://www.elastic.co/cloud/as-a-service[Elasticsearch Service on Elastic\nCloud].\n\nIf you prefer to install and manage Elasticsearch yourself, you can download\nthe latest version from\nhttps://www.elastic.co/downloads/elasticsearch[elastic.co/downloads/elasticsearch].\n\n=== Run Elasticsearch locally\n\n////\nIMPORTANT: This content is replicated in the Elasticsearch repo. See `run-elasticsearch-locally.asciidoc`.\nEnsure both files are in sync.\n\nhttps://github.com/elastic/start-local is the source of truth.\n////\n\n[WARNING]\n====\nDO NOT USE THESE INSTRUCTIONS FOR PRODUCTION DEPLOYMENTS.\n\nThis setup is intended for local development and testing only.\n====\n\nQuickly set up Elasticsearch and Kibana in Docker for local development or testing, using the https://github.com/elastic/start-local?tab=readme-ov-file#-try-elasticsearch-and-kibana-locally[`start-local` script].\n\n‚ÑπÔ∏è For more detailed information about the `start-local` setup, refer to the https://github.com/elastic/start-local[README on GitHub].\n\n==== Prerequisites\n\n- If you don't have Docker installed, https://www.docker.com/products/docker-desktop[download and install Docker Desktop] for your operating system.\n- If you're using Microsoft Windows, then install https://learn.microsoft.com/en-us/windows/wsl/install[Windows Subsystem for Linux (WSL)].\n\n==== Trial license\nThis setup comes with a one-month trial license that includes all Elastic features.\n\nAfter the trial period, the license reverts to *Free and open - Basic*.\nRefer to https://www.elastic.co/subscriptions[Elastic subscriptions] for more information.\n\n==== Run `start-local`\n\nTo set up Elasticsearch and Kibana locally, run the `start-local` script:\n\n[source,sh]\n----\ncurl -fsSL https://elastic.co/start-local | sh\n----\n// NOTCONSOLE\n\nThis script creates an `elastic-start-local` folder containing configuration files and starts both Elasticsearch and Kibana using Docker.\n\nAfter running the script, you can access Elastic services at the following endpoints:\n\n* *Elasticsearch*: http://localhost:9200\n* *Kibana*: http://localhost:5601\n\nThe script generates a random password for the `elastic` user, which is displayed at the end of the installation and stored in the `.env` file.\n\n[CAUTION]\n====\nThis setup is for local testing only. HTTPS is disabled, and Basic authentication is used for Elasticsearch. For security, Elasticsearch and Kibana are accessible only through `localhost`.\n====\n\n==== API access\n\nAn API key for Elasticsearch is generated and stored in the `.env` file as `ES_LOCAL_API_KEY`.\nUse this key to connect to Elasticsearch with a https://www.elastic.co/guide/en/elasticsearch/client/index.html[programming language client] or the https://www.elastic.co/guide/en/elasticsearch/reference/current/rest-apis.html[REST API].\n\nFrom the `elastic-start-local` folder, check the connection to Elasticsearch using `curl`:\n\n[source,sh]\n----\nsource .env\ncurl $ES_LOCAL_URL -H \"Authorization: ApiKey ${ES_LOCAL_API_KEY}\"\n----\n\nTo use the password for the `elastic` user, set and export the `ES_LOCAL_PASSWORD` environment variable. For example:\n\n[source,sh]\n----\nsource .env\nexport ES_LOCAL_PASSWORD\n----\n\n// NOTCONSOLE\n\n=== Send requests to Elasticsearch\n\nYou send data and other requests to Elasticsearch through REST APIs.\nYou can interact with Elasticsearch using any client that sends HTTP requests,\nsuch as the https://www.elastic.co/guide/en/elasticsearch/client/index.html[Elasticsearch\nlanguage clients] and https://curl.se[curl].\n\n==== Using curl\n\nHere's an example curl command to create a new Elasticsearch index, using basic auth:\n\n[source,sh]\n----\ncurl -u elastic:$ES_LOCAL_PASSWORD \\\n  -X PUT \\\n  http://localhost:9200/my-new-index \\\n  -H 'Content-Type: application/json'\n----\n\n// NOTCONSOLE\n\n==== Using a language client\n\nTo connect to your local dev Elasticsearch cluster with a language client, you can use basic authentication with the `elastic` username and the password stored in the `ES_LOCAL_PASSWORD` environment variable.\n\nYou'll use the following connection details:\n\n* **Elasticsearch endpoint**: `http://localhost:9200`\n* **Username**: `elastic`\n* **Password**: `$ES_LOCAL_PASSWORD` (Value you set in the environment variable)\n\nFor example, to connect with the Python `elasticsearch` client:\n\n[source,python]\n----\nimport os\nfrom elasticsearch import Elasticsearch\n\nusername = 'elastic'\npassword = os.getenv('ES_LOCAL_PASSWORD') # Value you set in the environment variable\n\nclient = Elasticsearch(\n    \"http://localhost:9200\",\n    basic_auth=(username, password)\n)\n\nprint(client.info())\n----\n\n==== Using the Dev Tools Console\n\nKibana's developer console provides an easy way to experiment and test requests.\nTo access the console, open Kibana, then go to **Management** > **Dev Tools**.\n\n**Add data**\n\nYou index data into Elasticsearch by sending JSON objects (documents) through the REST APIs.\nWhether you have structured or unstructured text, numerical data, or geospatial data,\nElasticsearch efficiently stores and indexes it in a way that supports fast searches.\n\nFor timestamped data such as logs and metrics, you typically add documents to a\ndata stream made up of multiple auto-generated backing indices.\n\nTo add a single document to an index, submit an HTTP post request that targets the index.\n\n----\nPOST /customer/_doc/1\n{\n  \"firstname\": \"Jennifer\",\n  \"lastname\": \"Walters\"\n}\n----\n\nThis request automatically creates the `customer` index if it doesn't exist,\nadds a new document that has an ID of 1, and\nstores and indexes the `firstname` and `lastname` fields.\n\nThe new document is available immediately from any node in the cluster.\nYou can retrieve it with a GET request that specifies its document ID:\n\n----\nGET /customer/_doc/1\n----\n\nTo add multiple documents in one request, use the `_bulk` API.\nBulk data must be newline-delimited JSON (NDJSON).\nEach line must end in a newline character (`\\n`), including the last line.\n\n----\nPUT customer/_bulk\n{ \"create\": { } }\n{ \"firstname\": \"Monica\",\"lastname\":\"Rambeau\"}\n{ \"create\": { } }\n{ \"firstname\": \"Carol\",\"lastname\":\"Danvers\"}\n{ \"create\": { } }\n{ \"firstname\": \"Wanda\",\"lastname\":\"Maximoff\"}\n{ \"create\": { } }\n{ \"firstname\": \"Jennifer\",\"lastname\":\"Takeda\"}\n----\n\n**Search**\n\nIndexed documents are available for search in near real-time.\nThe following search matches all customers with a first name of _Jennifer_\nin the `customer` index.\n\n----\nGET customer/_search\n{\n  \"query\" : {\n    \"match\" : { \"firstname\": \"Jennifer\" }\n  }\n}\n----\n\n**Explore**\n\nYou can use Discover in Kibana to interactively search and filter your data.\nFrom there, you can start creating visualizations and building and sharing dashboards.\n\nTo get started, create a _data view_ that connects to one or more Elasticsearch indices,\ndata streams, or index aliases.\n\n. Go to **Management > Stack Management > Kibana > Data Views**.\n. Select **Create data view**.\n. Enter a name for the data view and a pattern that matches one or more indices,\nsuch as _customer_.\n. Select **Save data view to Kibana**.\n\nTo start exploring, go to **Analytics > Discover**.\n\n[[upgrade]]\n== Upgrade\n\nTo upgrade from an earlier version of Elasticsearch, see the\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/setup-upgrade.html[Elasticsearch upgrade\ndocumentation].\n\n[[build-source]]\n== Build from source\n\nElasticsearch uses https://gradle.org[Gradle] for its build system.\n\nTo build a distribution for your local OS and print its output location upon\ncompletion, run:\n----\n./gradlew localDistro\n----\n\nTo build a distribution for another platform, run the related command:\n----\n./gradlew :distribution:archives:linux-tar:assemble\n./gradlew :distribution:archives:darwin-tar:assemble\n./gradlew :distribution:archives:windows-zip:assemble\n----\n\nDistributions are output to `distribution/archives`.\n\nTo run the test suite, see xref:TESTING.asciidoc[TESTING].\n\n[[docs]]\n== Documentation\n\nFor the complete Elasticsearch documentation visit\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/index.html[elastic.co].\n\nFor information about our documentation processes, see the\nxref:https://github.com/elastic/elasticsearch/blob/main/docs/README.md[docs README].\n\n[[examples]]\n== Examples and guides\n\nThe https://github.com/elastic/elasticsearch-labs[`elasticsearch-labs`] repo contains executable Python notebooks, sample apps, and resources to test out Elasticsearch for vector search, hybrid search and generative AI use cases.\n\n\n[[contribute]]\n== Contribute\n\nFor contribution guidelines, see xref:CONTRIBUTING.md[CONTRIBUTING].\n\n[[questions]]\n== Questions? Problems? Suggestions?\n\n* To report a bug or request a feature, create a\nhttps://github.com/elastic/elasticsearch/issues/new/choose[GitHub Issue]. Please\nensure someone else hasn't created an issue for the same topic.\n\n* Need help using Elasticsearch? Reach out on the\nhttps://discuss.elastic.co[Elastic Forum] or https://ela.st/slack[Slack]. A\nfellow community member or Elastic engineer will be happy to help you out.\n",
      "stars_today": 12
    },
    {
      "id": 3432266,
      "name": "kotlin",
      "full_name": "JetBrains/kotlin",
      "description": "The Kotlin Programming Language. ",
      "html_url": "https://github.com/JetBrains/kotlin",
      "stars": 52174,
      "forks": 6183,
      "language": "Kotlin",
      "topics": [
        "compiler",
        "gradle-plugin",
        "intellij-plugin",
        "kotlin",
        "kotlin-library",
        "maven-plugin",
        "programming-language",
        "wasm",
        "webassembly"
      ],
      "created_at": "2012-02-13T17:29:58Z",
      "updated_at": "2026-01-16T23:54:17Z",
      "pushed_at": "2026-01-16T23:58:50Z",
      "open_issues": 207,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "[![official project](https://jb.gg/badges/official.svg)](https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub)\n[![TeamCity (simple build status)](https://img.shields.io/teamcity/http/teamcity.jetbrains.com/s/Kotlin_KotlinPublic_Compiler.svg)](https://teamcity.jetbrains.com/buildConfiguration/Kotlin_KotlinPublic_Compiler?branch=%3Cdefault%3E&buildTypeTab=overview&mode=builds)\n[![Maven Central](https://img.shields.io/maven-central/v/org.jetbrains.kotlin/kotlin-maven-plugin.svg)](https://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.jetbrains.kotlin%22)\n[![GitHub license](https://img.shields.io/badge/license-Apache%20License%202.0-blue.svg?style=flat)](https://www.apache.org/licenses/LICENSE-2.0)\n[![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A)](https://ge.jetbrains.com/scans?search.rootProjectNames=Kotlin)\n\n# Kotlin Programming Language\n\nWelcome to [Kotlin](https://kotlinlang.org/)!   \nKotlin is a concise multiplatform language developed by [JetBrains](https://www.jetbrains.com/) and [contributors](https://kotlinlang.org/docs/contribute.html).\n\nSome handy links:\n\n * [Kotlin Site](https://kotlinlang.org/)\n * [Getting Started Guide](https://kotlinlang.org/docs/tutorials/getting-started.html)\n * [Try Kotlin](https://play.kotlinlang.org/)\n * [Kotlin Standard Library](https://kotlinlang.org/api/latest/jvm/stdlib/index.html)\n * [Issue Tracker](https://youtrack.jetbrains.com/issues/KT)\n * [Kotlin YouTube Channel](https://www.youtube.com/channel/UCP7uiEZIqci43m22KDl0sNw)\n * [Forum](https://discuss.kotlinlang.org/)\n * [Kotlin Blog](https://blog.jetbrains.com/kotlin/)\n * [Subscribe to Kotlin YouTube channel](https://www.youtube.com/channel/UCP7uiEZIqci43m22KDl0sNw)\n * [Follow Kotlin on Twitter](https://twitter.com/kotlin)\n * [Public Slack channel](https://slack.kotlinlang.org/)\n * [TeamCity CI build](https://teamcity.jetbrains.com/project.html?tab=projectOverview&projectId=Kotlin)\n * [Kotlin Foundation](https://kotlinfoundation.org/)\n\n## Kotlin Multiplatform capabilities\n\nSupport for multiplatform programming is one of Kotlin‚Äôs key benefits. It reduces time spent writing and maintaining the same code for [different platforms](https://kotlinlang.org/docs/reference/mpp-supported-platforms.html) while retaining the flexibility and benefits of native programming.\n\n * [Kotlin Multiplatform](https://www.jetbrains.com/kotlin-multiplatform/) and [Compose Multiplatform](https://www.jetbrains.com/compose-multiplatform/) for sharing business logic and UI between Android, iOS, desktop, and web.\n * [Get started with Kotlin Multiplatform](https://www.jetbrains.com/help/kotlin-multiplatform-dev/get-started.html)\n * [Kotlin Multiplatform Benefits](https://kotlinlang.org/docs/reference/multiplatform.html)\n * [Share code on all platforms](https://kotlinlang.org/docs/reference/mpp-share-on-platforms.html#share-code-on-all-platforms)\n * [Share code on similar platforms](https://kotlinlang.org/docs/reference/mpp-share-on-platforms.html#share-code-on-similar-platforms)\n\n## Editing Kotlin\n\n * [Kotlin IntelliJ IDEA Plugin](https://kotlinlang.org/docs/tutorials/getting-started.html) ([source code](https://github.com/JetBrains/intellij-community/tree/master/plugins/kotlin))\n * [Kotlin Eclipse Plugin](https://kotlinlang.org/docs/tutorials/getting-started-eclipse.html)\n * [Kotlin Sublime Text Package](https://github.com/vkostyukov/kotlin-sublime-package)\n\n## Build environment requirements\n\nThis repository is using [Gradle toolchains](https://docs.gradle.org/current/userguide/toolchains.html) feature\nto select and auto-provision required JDKs from [Eclipse Adoptium](https://adoptium.net) project.\n\nAlternatively, it is still possible to only provide required JDKs via environment variables \n(see [gradle.properties](./gradle.properties#L5) for supported variable names). To ensure Gradle uses only JDKs \nfrom environmental variables - disable Gradle toolchain auto-detection by passing `-Porg.gradle.java.installations.auto-detect=false` option\n(or put it into `$GRADLE_USER_HOME/gradle.properties`).\n\nOn Windows you might need to add long paths setting to the repo:\n\n    git config core.longpaths true \n\n## Building\n\nThe project is built with Gradle. Run Gradle to build the project and to run the tests \nusing the following command on Unix/macOS:\n\n    ./gradlew <tasks-and-options>\n    \nor the following command on Windows:\n\n    gradlew <tasks-and-options>\n\nOn the first project configuration gradle will download and setup the dependencies on:\n\n* `intellij-core` is a part of command line compiler and contains only necessary APIs.\n* `idea-full` is a full blown IntelliJ IDEA Community Edition to be used in the plugin module.\n\nThese dependencies are quite large, so depending on the quality of your internet connection \nyou might face timeouts getting them. In this case, you can increase timeout by specifying the following \ncommand line parameters on the first run: \n    \n    ./gradlew -Dhttp.socketTimeout=60000 -Dhttp.connectionTimeout=60000\n\n## Important gradle tasks\n\n- `clean` - clean build results\n- `dist` - assembles the compiler distribution into `dist/kotlinc/` folder\n- `install` - build and install all public artifacts into local maven repository\n- `coreLibsTest` - build and run stdlib, reflect and kotlin-test tests\n- `gradlePluginTest` - build and run gradle plugin tests\n- `compilerTest` - build and run all compiler tests\n\nTo reproduce TeamCity build use `-Pteamcity=true` flag. Local builds don't run proguard and have jar compression disabled by default.\n\n**OPTIONAL:** Some artifacts, mainly Maven plugin ones, are built separately with Maven.\nRefer to [libraries/ReadMe.md](libraries/ReadMe.md) for details.\n\nTo build Kotlin/Native, see\n[kotlin-native/README.md](kotlin-native/README.md#building-from-source).\n\n## <a name=\"working-in-idea\"></a> Working with the project in IntelliJ IDEA\n\nIt is recommended to use the latest released version of Intellij IDEA (Community or Ultimate Edition). You can download IntelliJ IDEA [here](https://www.jetbrains.com/idea/download).\n\nAfter cloning the project, import the project in IntelliJ by choosing the project directory in the Open project dialog.\n\nFor handy work with compiler tests it's recommended to use [Kotlin Compiler Test Helper](https://github.com/demiurg906/test-data-helper-plugin).\n\n### Dependency verification\n\nWe have a [dependencies verification](https://docs.gradle.org/current/userguide/dependency_verification.html) feature enabled in the\nrepository for all Gradle builds. Gradle will check hashes (md5 and sha256) of used dependencies and will fail builds with\n`Dependency verification failed` errors when local artifacts are absent or have different hashes listed in the\n[verification-metadata.xml](https://github.com/JetBrains/kotlin/blob/master/gradle/verification-metadata.xml) file.\n\nIt's expected that `verification-metadata.xml` should only be updated with the commits that modify the build. There are some tips how\nto perform such updates:\n\n- Delete `components` section of `verification-metadata.xml` to avoid stockpiling of old unused dependencies. You may use the following command:\n```bash\n#macOS\nsed -i '' -e '/<components>/,/<\\/components>/d' gradle/verification-metadata.xml\n#Linux & Git for Windows\nsed -i -e '/<components>/,/<\\/components>/d' gradle/verification-metadata.xml\n```\n- Re-generate dependencies with Gradle's `--write-verification-metadata` command (verify update relates to your changes)\n\n```bash\n./gradlew --write-verification-metadata sha256,md5 -Pkotlin.native.enabled=true resolveDependencies\n```\n\n*`resolveDependencies` task resolves dependencies for all platforms including dependencies downloaded by plugins.*\n\nYou can also use `./scripts/update-verification-metadata.sh` script which includes both of these steps\n\nKeep in mind:\n\n- If you‚Äôre adding a dependency with OS mentioned in an artifact name (`darwin`, `mac`, `osx`, `linux`, `windows`), remember to add them to \n  `implicitDependencies` configuration or update `resolveDependencies` task if needed. `resolveDependencies` should resolve all dependencies\n  including dependencies for different platforms.\n- If you have a `local.properties` file in your Kotlin project folder, make sure that it doesn't contain `kotlin.native.enabled=false`.\n  Otherwise, native-only dependencies may not be added to the verification metadata. This is because `local.properties` has higher \n  precedence than the `-Pkotlin.native.enabled=true` specified in the Gradle command.\n\n## Using -dev versions\n\nWe publish `-dev` versions frequently.\n\nFor `-dev` versions you can use the [list of available versions](https://redirector.kotlinlang.org/maven/bootstrap/org/jetbrains/kotlin/kotlin-compiler/maven-metadata.xml) and include this maven repository:\n\n```kotlin\nmaven(\"https://redirector.kotlinlang.org/maven/bootstrap\")\n```\n\n# License\nKotlin is distributed under the terms of the Apache License (Version 2.0). See [license folder](license/README.md) for details.\n\n# Contributing\n\nPlease be sure to review Kotlin's [contributing guidelines](docs/contributing.md) to learn how to help the project.\n\n# Kotlin Foundation\n\nThe Kotlin Foundation is a non-profit organization whose mission is to promote and advance the Kotlin ecosystem. You can learn more about the structure and goals of the Kotlin Foundation on its [official website](https://kotlinfoundation.org/).\n",
      "stars_today": 11
    },
    {
      "id": 569041,
      "name": "curl",
      "full_name": "curl/curl",
      "description": "A command line tool and library for transferring data with URL syntax, supporting DICT, FILE, FTP, FTPS, GOPHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, TFTP, WS and WSS. libcurl offers a myriad of powerful features",
      "html_url": "https://github.com/curl/curl",
      "stars": 40391,
      "forks": 7018,
      "language": "C",
      "topics": [
        "c",
        "client",
        "curl",
        "ftp",
        "gopher",
        "hacktoberfest",
        "http",
        "https",
        "imaps",
        "ldap",
        "libcurl",
        "library",
        "mqtt",
        "pop3",
        "scp",
        "sftp",
        "transfer-data",
        "transferring-data",
        "user-agent",
        "websocket"
      ],
      "created_at": "2010-03-18T22:32:22Z",
      "updated_at": "2026-01-17T00:47:01Z",
      "pushed_at": "2026-01-16T15:44:32Z",
      "open_issues": 41,
      "owner": {
        "login": "curl",
        "avatar_url": "https://avatars.githubusercontent.com/u/16928085?v=4"
      },
      "readme": "<!--\nCopyright (C) Daniel Stenberg, <daniel@haxx.se>, et al.\n\nSPDX-License-Identifier: curl\n-->\n\n# [![curl logo](https://curl.se/logo/curl-logo.svg)](https://curl.se/)\n\ncurl is a command-line tool for transferring data from or to a server using\nURLs. It supports these protocols: DICT, FILE, FTP, FTPS, GOPHER, GOPHERS,\nHTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP,\nSCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, TFTP, WS and WSS.\n\nLearn how to use curl by reading [the\nman page](https://curl.se/docs/manpage.html) or [everything\ncurl](https://everything.curl.dev/).\n\nFind out how to install curl by reading [the INSTALL\ndocument](https://curl.se/docs/install.html).\n\nlibcurl is the library curl is using to do its job. It is readily available to\nbe used by your software. Read [the libcurl\nman page](https://curl.se/libcurl/c/libcurl.html) to learn how.\n\n## Open Source\n\ncurl is Open Source and is distributed under an MIT-like\n[license](https://curl.se/docs/copyright.html).\n\n## Contact\n\nContact us on a suitable [mailing list](https://curl.se/mail/) or\nuse GitHub [issues](https://github.com/curl/curl/issues)/\n[pull requests](https://github.com/curl/curl/pulls)/\n[discussions](https://github.com/curl/curl/discussions).\n\nAll contributors to the project are listed in [the THANKS\ndocument](https://curl.se/docs/thanks.html).\n\n## Commercial support\n\nFor commercial support, maybe private and dedicated help with your problems or\napplications using (lib)curl visit [the support page](https://curl.se/support.html).\n\n## Website\n\nVisit the [curl website](https://curl.se/) for the latest news and downloads.\n\n## Source code\n\nDownload the latest source from the Git server:\n\n    git clone https://github.com/curl/curl\n\n## Security problems\n\nReport suspected security problems via [our HackerOne\npage](https://hackerone.com/curl) and not in public.\n\n## Backers\n\nThank you to all our backers :pray: [Become a backer](https://opencollective.com/curl#section-contribute).\n\n## Sponsors\n\nSupport this project by becoming a [sponsor](https://curl.se/sponsors.html).\n",
      "stars_today": 11
    },
    {
      "id": 59771425,
      "name": "zephyr",
      "full_name": "zephyrproject-rtos/zephyr",
      "description": "Primary Git Repository for the Zephyr Project. Zephyr is a new generation, scalable, optimized, secure RTOS for multiple hardware architectures.",
      "html_url": "https://github.com/zephyrproject-rtos/zephyr",
      "stars": 14194,
      "forks": 8518,
      "language": "C",
      "topics": [
        "bluetooth",
        "bluetooth-le",
        "embedded",
        "embedded-c",
        "iot",
        "mcu",
        "microcontroller",
        "real-time",
        "rtos",
        "zephyr",
        "zephyr-rtos",
        "zephyros"
      ],
      "created_at": "2016-05-26T17:54:19Z",
      "updated_at": "2026-01-16T20:58:19Z",
      "pushed_at": "2026-01-16T20:56:56Z",
      "open_issues": 3497,
      "owner": {
        "login": "zephyrproject-rtos",
        "avatar_url": "https://avatars.githubusercontent.com/u/19595895?v=4"
      },
      "readme": ".. raw:: html\n\n   <a href=\"https://www.zephyrproject.org\">\n     <p align=\"center\">\n       <picture>\n         <source media=\"(prefers-color-scheme: dark)\" srcset=\"doc/_static/images/logo-readme-dark.svg\">\n         <source media=\"(prefers-color-scheme: light)\" srcset=\"doc/_static/images/logo-readme-light.svg\">\n         <img src=\"doc/_static/images/logo-readme-light.svg\">\n       </picture>\n     </p>\n   </a>\n\n   <a href=\"https://bestpractices.coreinfrastructure.org/projects/74\"><img src=\"https://bestpractices.coreinfrastructure.org/projects/74/badge\"></a>\n   <a href=\"https://scorecard.dev/viewer/?uri=github.com/zephyrproject-rtos/zephyr\"><img src=\"https://api.securityscorecards.dev/projects/github.com/zephyrproject-rtos/zephyr/badge\"></a>\n   <a href=\"https://github.com/zephyrproject-rtos/zephyr/actions/workflows/twister.yaml?query=branch%3Amain\"><img src=\"https://github.com/zephyrproject-rtos/zephyr/actions/workflows/twister.yaml/badge.svg?event=push\"></a>\n\n\nThe Zephyr Project is a scalable real-time operating system (RTOS) supporting\nmultiple hardware architectures, optimized for resource constrained devices,\nand built with security in mind.\n\nThe Zephyr OS is based on a small-footprint kernel designed for use on\nresource-constrained systems: from simple embedded environmental sensors and\nLED wearables to sophisticated smart watches and IoT wireless gateways.\n\nThe Zephyr kernel supports multiple architectures, including ARM (Cortex-A,\nCortex-R, Cortex-M), Intel x86, ARC, Tensilica Xtensa, and RISC-V,\nSPARC, MIPS, and a large number of `supported boards`_.\n\n.. below included in doc/introduction/introduction.rst\n\n\nGetting Started\n***************\n\nWelcome to Zephyr! See the `Introduction to Zephyr`_ for a high-level overview,\nand the documentation's `Getting Started Guide`_ to start developing.\n\n.. start_include_here\n\nCommunity Support\n*****************\n\nCommunity support is provided via mailing lists and Discord; see the Resources\nbelow for details.\n\n.. _project-resources:\n\nResources\n*********\n\nHere's a quick summary of resources to help you find your way around:\n\nGetting Started\n---------------\n\n  | üìñ `Zephyr Documentation`_\n  | üöÄ `Getting Started Guide`_\n  | üôãüèΩ `Tips when asking for help`_\n  | üíª `Code samples`_\n\nCode and Development\n--------------------\n\n  | üåê `Source Code Repository`_\n  | üì¶ `Releases`_\n  | ü§ù `Contribution Guide`_\n\nCommunity and Support\n---------------------\n\n  | üí¨ `Discord Server`_ for real-time community discussions\n  | üìß `User mailing list (users@lists.zephyrproject.org)`_\n  | üìß `Developer mailing list (devel@lists.zephyrproject.org)`_\n  | üì¨ `Other project mailing lists`_\n  | üìö `Project Wiki`_\n\nIssue Tracking and Security\n---------------------------\n\n  | üêõ `GitHub Issues`_\n  | üîí `Security documentation`_\n  | üõ°Ô∏è `Security Advisories Repository`_\n  | ‚ö†Ô∏è Report security vulnerabilities at vulnerabilities@zephyrproject.org\n\nAdditional Resources\n--------------------\n  | üåê `Zephyr Project Website`_\n  | üì∫ `Zephyr Tech Talks`_\n\n.. _Zephyr Project Website: https://www.zephyrproject.org\n.. _Discord Server: https://chat.zephyrproject.org\n.. _supported boards: https://docs.zephyrproject.org/latest/boards/index.html\n.. _Zephyr Documentation: https://docs.zephyrproject.org\n.. _Introduction to Zephyr: https://docs.zephyrproject.org/latest/introduction/index.html\n.. _Getting Started Guide: https://docs.zephyrproject.org/latest/develop/getting_started/index.html\n.. _Contribution Guide: https://docs.zephyrproject.org/latest/contribute/index.html\n.. _Source Code Repository: https://github.com/zephyrproject-rtos/zephyr\n.. _GitHub Issues: https://github.com/zephyrproject-rtos/zephyr/issues\n.. _Releases: https://github.com/zephyrproject-rtos/zephyr/releases\n.. _Project Wiki: https://github.com/zephyrproject-rtos/zephyr/wiki\n.. _User mailing list (users@lists.zephyrproject.org): https://lists.zephyrproject.org/g/users\n.. _Developer mailing list (devel@lists.zephyrproject.org): https://lists.zephyrproject.org/g/devel\n.. _Other project mailing lists: https://lists.zephyrproject.org/g/main/subgroups\n.. _Code samples: https://docs.zephyrproject.org/latest/samples/index.html\n.. _Security documentation: https://docs.zephyrproject.org/latest/security/index.html\n.. _Security Advisories Repository: https://github.com/zephyrproject-rtos/zephyr/security\n.. _Tips when asking for help: https://docs.zephyrproject.org/latest/develop/getting_started/index.html#asking-for-help\n.. _Zephyr Tech Talks: https://www.zephyrproject.org/tech-talks\n",
      "stars_today": 11
    },
    {
      "id": 37912398,
      "name": "nginx",
      "full_name": "nginx/nginx",
      "description": "The official NGINX Open Source repository.",
      "html_url": "https://github.com/nginx/nginx",
      "stars": 29105,
      "forks": 7718,
      "language": "C",
      "topics": [
        "content-cache",
        "http",
        "http2",
        "http3",
        "https",
        "load-balancer",
        "mail-proxy-server",
        "nginx",
        "quic",
        "reverse-proxy",
        "security",
        "tcp-proxy-server",
        "tls",
        "udp-proxy-server",
        "web-server"
      ],
      "created_at": "2015-06-23T10:26:27Z",
      "updated_at": "2026-01-16T21:09:42Z",
      "pushed_at": "2026-01-16T12:13:36Z",
      "open_issues": 317,
      "owner": {
        "login": "nginx",
        "avatar_url": "https://avatars.githubusercontent.com/u/1412239?v=4"
      },
      "readme": "<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/user-attachments/assets/9335b488-ffcc-4157-8364-2370a0b70ad0\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/user-attachments/assets/3a7eeb08-1133-47f5-859c-fad4f5a6a013\">\n  <img alt=\"NGINX Banner\">\n</picture>\n\n[![Project Status: Active ‚Äì The project has reached a stable, usable state and is being actively developed.](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)\n[![Community Forum](https://img.shields.io/badge/community-forum-009639?logo=discourse&link=https%3A%2F%2Fcommunity.nginx.org)](https://community.nginx.org)\n[![License](https://img.shields.io/badge/License-BSD%202--Clause-blue.svg)](/LICENSE)\n[![Code of Conduct](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](/CODE_OF_CONDUCT.md)\n\nNGINX (pronounced \"engine x\" or \"en-jin-eks\") is the world's most popular Web Server, high performance Load Balancer, Reverse Proxy, API Gateway and Content Cache.\n\nNGINX is free and open source software, distributed under the terms of a simplified [2-clause BSD-like license](LICENSE).\n\nEnterprise distributions, commercial support and training are available from [F5, Inc](https://www.f5.com/products/nginx).\n\n> [!IMPORTANT]\n> The goal of this README is to provide a basic, structured introduction to NGINX for novice users. Please refer to the [full NGINX documentation](https://nginx.org/en/docs/) for detailed information on [installing](https://nginx.org/en/docs/install.html), [building](https://nginx.org/en/docs/configure.html), [configuring](https://nginx.org/en/docs/dirindex.html), [debugging](https://nginx.org/en/docs/debugging_log.html), and more. These documentation pages also contain a more detailed [Beginners Guide](https://nginx.org/en/docs/beginners_guide.html), How-Tos, [Development guide](https://nginx.org/en/docs/dev/development_guide.html), and a complete module and [directive reference](https://nginx.org/en/docs/dirindex.html).\n\n# Table of contents\n- [How it works](#how-it-works)\n  - [Modules](#modules)\n  - [Configurations](#configurations)\n  - [Runtime](#runtime)\n- [Downloading and installing](#downloading-and-installing)\n  - [Stable and Mainline binaries](#stable-and-mainline-binaries)\n  - [Linux binary installation process](#linux-binary-installation-process)\n  - [FreeBSD installation process](#freebsd-installation-process)\n  - [Windows executables](#windows-executables)\n  - [Dynamic modules](#dynamic-modules)\n- [Getting started with NGINX](#getting-started-with-nginx)\n  - [Installing SSL certificates and enabling TLS encryption](#installing-ssl-certificates-and-enabling-tls-encryption)\n  - [Load Balancing](#load-balancing)\n  - [Rate limiting](#rate-limiting)\n  - [Content caching](#content-caching)\n- [Building from source](#building-from-source)\n  - [Installing dependencies](#installing-dependencies)\n  - [Cloning the NGINX GitHub repository](#cloning-the-nginx-github-repository)\n  - [Configuring the build](#configuring-the-build)\n  - [Compiling](#compiling)\n  - [Location of binary and installation](#location-of-binary-and-installation)\n  - [Running and testing the installed binary](#running-and-testing-the-installed-binary)\n- [Asking questions and reporting issues](#asking-questions-and-reporting-issues)\n- [Contributing code](#contributing-code)\n- [Additional help and resources](#additional-help-and-resources)\n- [Changelog](#changelog)\n- [License](#license)\n\n# How it works\nNGINX is installed software with binary packages available for all major operating systems and Linux distributions. See [Tested OS and Platforms](https://nginx.org/en/#tested_os_and_platforms) for a full list of compatible systems.\n\n> [!IMPORTANT]\n> While nearly all popular Linux-based operating systems are distributed with a community version of nginx, we highly advise installation and usage of official [packages](https://nginx.org/en/linux_packages.html) or sources from this repository. Doing so ensures that you're using the most recent release or source code, including the latest feature-set, fixes and security patches.\n\n## Modules\nNGINX is comprised of individual modules, each extending core functionality by providing additional, configurable features. See \"Modules reference\" at the bottom of [nginx documentation](https://nginx.org/en/docs/) for a complete list of official modules.\n\nNGINX modules can be built and distributed as static or dynamic modules. Static modules are defined at build-time, compiled, and distributed in the resulting binaries. See [Dynamic Modules](#dynamic-modules) for more information on how they work, as well as, how to obtain, install, and configure them.\n\n> [!TIP]\n> You can issue the following command to see which static modules your NGINX binaries were built with:\n```bash\nnginx -V\n```\n> See [Configuring the build](#configuring-the-build) for information on how to include specific Static modules into your nginx build.\n\n## Configurations\nNGINX is highly flexible and configurable. Provisioning the software is achieved via text-based config file(s) accepting parameters called \"[Directives](https://nginx.org/en/docs/dirindex.html)\". See [Configuration File's Structure](https://nginx.org/en/docs/beginners_guide.html#conf_structure) for a comprehensive description of how NGINX configuration files work.\n\n> [!NOTE]\n> The set of directives available to your distribution of NGINX is dependent on which [modules](#modules) have been made available to it.\n\n## Runtime\nRather than running in a single, monolithic process, NGINX is architected to scale beyond Operating System process limitations by operating as a collection of processes. They include:\n- A \"master\" process that maintains worker processes, as well as, reads and evaluates configuration files.\n- One or more \"worker\" processes that process data (eg. HTTP requests).\n\nThe number of [worker processes](https://nginx.org/en/docs/ngx_core_module.html#worker_processes) is defined in the configuration file and may be fixed for a given configuration or automatically adjusted to the number of available CPU cores. In most cases, the latter option optimally balances load across available system resources, as NGINX is designed to efficiently distribute work across all worker processes.\n\n> [!TIP]\n> Processes synchronize data through shared memory. For this reason, many NGINX directives require the allocation of shared memory zones. As an example, when configuring [rate limiting](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req), connecting clients may need to be tracked in a [common memory zone](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req_zone) so all worker processes can know how many times a particular client has accessed the server in a span of time.\n\n# Downloading and installing\nFollow these steps to download and install precompiled NGINX binaries. You may also choose to [build NGINX locally from source code](#building-from-source).\n\n## Stable and Mainline binaries\nNGINX binaries are built and distributed in two versions: stable and mainline. Stable binaries are built from stable branches and only contain critical fixes backported from the mainline version. Mainline binaries are built from the [master branch](https://github.com/nginx/nginx/tree/master) and contain the latest features and bugfixes. You'll need to [decide which is appropriate for your purposes](https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/#choosing-between-a-stable-or-a-mainline-version).\n\n## Linux binary installation process\nThe NGINX binary installation process takes advantage of package managers native to specific Linux distributions. For this reason, first-time installations involve adding the official NGINX package repository to your system's package manager. Follow [these steps](https://nginx.org/en/linux_packages.html) to download, verify, and install NGINX binaries using the package manager appropriate for your Linux distribution.\n\n### Upgrades\nFuture upgrades to the latest version can be managed using the same package manager without the need to manually download and verify binaries.\n\n## FreeBSD installation process\nFor more information on installing NGINX on FreeBSD system, visit https://nginx.org/en/docs/install.html\n\n## Windows executables\nWindows executables for mainline and stable releases can be found on the main [NGINX download page](https://nginx.org/en/download.html). Note that the current implementation of NGINX for Windows is at the Proof-of-Concept stage and should only be used for development and testing purposes. For additional information, please see [nginx for Windows](https://nginx.org/en/docs/windows.html).\n\n## Dynamic modules\nNGINX version 1.9.11 added support for [Dynamic Modules](https://nginx.org/en/docs/ngx_core_module.html#load_module). Unlike Static modules, dynamically built modules can be downloaded, installed, and configured after the core NGINX binaries have been built. [Official dynamic module binaries](https://nginx.org/en/linux_packages.html#dynmodules) are available from the same package repository as the core NGINX binaries described in previous steps.\n\n> [!TIP]\n> [NGINX JavaScript (njs)](https://github.com/nginx/njs), is a popular NGINX dynamic module that enables the extension of core NGINX functionality using familiar JavaScript syntax.\n\n> [!IMPORTANT]\n> If desired, dynamic modules can also be built statically into NGINX at compile time.\n\n# Getting started with NGINX\nFor a gentle introduction to NGINX basics, please see our [Beginner‚Äôs Guide](https://nginx.org/en/docs/beginners_guide.html).\n\n## Installing SSL certificates and enabling TLS encryption\nSee [Configuring HTTPS servers](https://nginx.org/en/docs/http/configuring_https_servers.html) for a quick guide on how to enable secure traffic to your NGINX installation.\n\n## Load Balancing\nFor a quick start guide on configuring NGINX as a Load Balancer, please see [Using nginx as HTTP load balancer](https://nginx.org/en/docs/http/load_balancing.html).\n\n## Rate limiting\nSee our [Rate Limiting with NGINX](https://blog.nginx.org/blog/rate-limiting-nginx) blog post for an overview of core concepts for provisioning NGINX as an API Gateway.\n\n## Content caching\nSee [A Guide to Caching with NGINX and NGINX Plus](https://blog.nginx.org/blog/nginx-caching-guide) blog post for an overview of how to use NGINX as a content cache (e.g. edge server of a content delivery network).\n\n# Building from source\nThe following steps can be used to build NGINX from source code available in this repository.\n\n## Installing dependencies\nMost Linux distributions will require several dependencies to be installed in order to build NGINX. The following instructions are specific to the `apt` package manager, widely available on most Ubuntu/Debian distributions and their derivatives.\n\n> [!TIP]\n> It is always a good idea to update your package repository lists prior to installing new packages.\n> ```bash\n> sudo apt update\n> ```\n\n### Installing compiler and make utility\nUse the following command to install the GNU C compiler and Make utility.\n\n```bash\nsudo apt install gcc make\n```\n\n### Installing dependency libraries\n\n```bash\nsudo apt install libpcre3-dev zlib1g-dev\n```\n\n> [!WARNING]\n> This is the minimal set of dependency libraries needed to build NGINX with rewriting and gzip capabilities. Other dependencies may be required if you choose to build NGINX with additional modules. Monitor the output of the `configure` command discussed in the following sections for information on which modules may be missing. For example, if you plan to use SSL certificates to encrypt traffic with TLS, you'll need to install the OpenSSL library. To do so, issue the following command.\n\n>```bash\n>sudo apt install libssl-dev\n\n## Cloning the NGINX GitHub repository\nUsing your preferred method, clone the NGINX repository into your development directory. See [Cloning a GitHub Repository](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository) for additional help.\n\n```bash\ngit clone https://github.com/nginx/nginx.git\n```\n\n## Configuring the build\nPrior to building NGINX, you must run the `configure` script with [appropriate flags](https://nginx.org/en/docs/configure.html). This will generate a Makefile in your NGINX source root directory that can then be used to compile NGINX with [options specified during configuration](https://nginx.org/en/docs/configure.html).\n\nFrom the NGINX source code repository's root directory:\n\n```bash\nauto/configure\n```\n\n> [!IMPORTANT]\n> Configuring the build without any flags will compile NGINX with the default set of options. Please refer to https://nginx.org/en/docs/configure.html for a full list of available build configuration options.\n\n## Compiling\nThe `configure` script will generate a `Makefile` in the NGINX source root directory upon successful execution. To compile NGINX into a binary, issue the following command from that same directory:\n\n```bash\nmake\n```\n\n## Location of binary and installation\nAfter successful compilation, a binary will be generated at `<NGINX_SRC_ROOT_DIR>/objs/nginx`. To install this binary, issue the following command from the source root directory:\n\n```bash\nsudo make install\n```\n\n> [!IMPORTANT]\n> The binary will be installed into the `/usr/local/nginx/` directory.\n\n## Running and testing the installed binary\nTo run the installed binary, issue the following command:\n\n```bash\nsudo /usr/local/nginx/sbin/nginx\n```\n\nYou may test NGINX operation using `curl`.\n\n```bash\ncurl localhost\n```\n\nThe output of which should start with:\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n```\n\n# Asking questions and reporting issues\nSee our [Support](SUPPORT.md) guidelines for information on how discuss the codebase, ask troubleshooting questions, and report issues.\n\n# Contributing code\nPlease see the [Contributing](CONTRIBUTING.md) guide for information on how to contribute code.\n\n# Additional help and resources\n- See the [NGINX Community Blog](https://blog.nginx.org/) for more tips, tricks and HOW-TOs related to NGINX and related projects.\n- Access [nginx.org](https://nginx.org/), your go-to source for all documentation, information and software related to the NGINX suite of projects.\n\n# Changelog\nSee our [changelog](https://nginx.org/en/CHANGES) to keep track of updates.\n\n# License\n[2-clause BSD-like license](LICENSE)\n\n---\nAdditional documentation available at: https://nginx.org/en/docs\n",
      "stars_today": 10
    },
    {
      "id": 1103607,
      "name": "jenkins",
      "full_name": "jenkinsci/jenkins",
      "description": "Jenkins automation server",
      "html_url": "https://github.com/jenkinsci/jenkins",
      "stars": 24921,
      "forks": 9316,
      "language": "Java",
      "topics": [
        "cicd",
        "continuous-delivery",
        "continuous-deployment",
        "continuous-integration",
        "devops",
        "groovy",
        "hacktoberfest",
        "java",
        "jenkins",
        "pipelines-as-code"
      ],
      "created_at": "2010-11-22T21:21:23Z",
      "updated_at": "2026-01-16T20:08:04Z",
      "pushed_at": "2026-01-16T20:24:19Z",
      "open_issues": 3554,
      "owner": {
        "login": "jenkinsci",
        "avatar_url": "https://avatars.githubusercontent.com/u/107424?v=4"
      },
      "readme": "<a href=\"https://jenkins.io\">\n    <img width=\"400\" src=\"https://www.jenkins.io/images/jenkins-logo-title-dark.svg\" alt=\"Jenkins logo\"> \n</a>\n\n[![Jenkins Regular Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog%2Fbadge.json)](https://www.jenkins.io/changelog)\n[![Jenkins LTS Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog-stable%2Fbadge.json)](https://www.jenkins.io/changelog-stable)\n[![Docker Pulls](https://img.shields.io/docker/pulls/jenkins/jenkins.svg)](https://hub.docker.com/r/jenkins/jenkins/)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3538/badge)](https://bestpractices.coreinfrastructure.org/projects/3538)\n[![Reproducible Builds](https://img.shields.io/badge/Reproducible_Builds-ok-green)](https://maven.apache.org/guides/mini/guide-reproducible-builds.html)\n[![Gitter](https://img.shields.io/gitter/room/jenkinsci/jenkins)](https://app.gitter.im/#/room/#jenkinsci_jenkins:gitter.im)\n\n---\n\n# Table of Contents\n\n- [About](#about)\n- [What to Use Jenkins for and When to Use It](#what-to-use-jenkins-for-and-when-to-use-it)\n- [Downloads](#downloads)\n- [Getting Started (Development)](#getting-started-development)\n- [Source](#source)\n- [Contributing to Jenkins](#contributing-to-jenkins)\n- [News and Website](#news-and-website)\n- [Governance](#governance)\n- [Adopters](#adopters)\n- [License](#license)\n\n---\n\n# About\n\nIn a nutshell, Jenkins is the leading open-source automation server.\nBuilt with Java, it provides over 2,000 [plugins](https://plugins.jenkins.io/) to support automating virtually anything,\nso that humans can spend their time doing things machines cannot.\n\n# What to Use Jenkins for and When to Use It\n\nUse Jenkins to automate your development workflow, so you can focus on work that matters most. Jenkins is commonly used for:\n\n- Building projects\n- Running tests to detect bugs and other issues as soon as they are introduced\n- Static code analysis\n- Deployment\n\nExecute repetitive tasks, save time, and optimize your development process with Jenkins.\n\n# Downloads\n\nThe Jenkins project provides official distributions as WAR files, Docker images, native packages and installers for platforms including several Linux distributions and Windows.\nSee the [Downloads](https://www.jenkins.io/download) page for references.\n\nFor all distributions Jenkins offers two release lines:\n\n- [Weekly](https://www.jenkins.io/download/weekly/) -\n  Frequent releases which include all new features, improvements, and bug fixes.\n- [Long-Term Support (LTS)](https://www.jenkins.io/download/lts/) -\n  Older release line which gets periodically updated via bug fix backports.\n\nLatest releases:\n\n[![Jenkins Regular Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog%2Fbadge.json)](https://www.jenkins.io/changelog)\n[![Jenkins LTS Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog-stable%2Fbadge.json)](https://www.jenkins.io/changelog-stable)\n\n# Getting Started (Development)\n\nFor more information on setting up your development environment, contributing, and working with Jenkins internals, check the [contributing guide](CONTRIBUTING.md) and the [Jenkins Developer Documentation](https://www.jenkins.io/doc/developer/).\n\n# Source\n\nOur latest and greatest source of Jenkins can be found on [GitHub](https://github.com/jenkinsci/jenkins). Fork us!\n\n# Contributing to Jenkins\n\nNew to open source or Jenkins? Here‚Äôs how to get started:\n\n- Read the [Contribution Guidelines](CONTRIBUTING.md)\n- Check our [good first issues](https://github.com/jenkinsci/jenkins/issues?q=is%3Aissue%20is%3Aopen%20label%3A%22good%20first%20issue%22)\n- Join our [Gitter chat](https://app.gitter.im/#/room/#jenkinsci_newcomer-contributors:gitter.im) for questions and help\n\nFor more information about participating in the community and contributing to the Jenkins project,\nsee [this page](https://www.jenkins.io/participate/).\n\nDocumentation for Jenkins core maintainers is in the [maintainers guidelines](docs/MAINTAINERS.adoc).\n\n# News and Website\n\nAll information about Jenkins can be found on our [official website](https://www.jenkins.io/), including documentation, blog posts, plugin listings, community updates, and more.\n\nStay up-to-date with the latest Jenkins news, tutorials, and release notes:\n\n- [Jenkins Blog](https://www.jenkins.io/blog/)\n- [Documentation](https://www.jenkins.io/doc/)\n- [Plugins Index](https://plugins.jenkins.io/)\n- [Events](https://www.jenkins.io/events/)\n\nFollow Jenkins on social media to stay connected with the community:\n\n- [Twitter / X](https://x.com/jenkinsci)\n- [YouTube](https://www.youtube.com/@jenkinscicd)\n- [LinkedIn](https://www.linkedin.com/company/jenkins-project/)\n\n# Governance\n\nThe Jenkins project is governed by an open source community.\nTo learn more about the governance structure, project leadership, and how decisions are made, visit the [Governance Page](https://www.jenkins.io/project/governance/).\n\n# Adopters\n\nJenkins is trusted by **millions of users** and adopted by **thousands of companies** around the world ‚Äî from startups to enterprises ‚Äî to automate their software delivery pipelines.\n\nExplore the [Adopters Page](https://www.jenkins.io/project/adopters/) and https://stories.jenkins.io to see:\n\n- Companies and organizations using Jenkins\n- Success stories and case studies\n- How Jenkins is used in different industries\n\n> If your company uses Jenkins and you'd like to be featured, feel free to [submit your story](https://www.jenkins.io/project/adopters/contributing/#share-your-story)!\n\n# License\n\nJenkins is **licensed** under the **[MIT License](LICENSE.txt)**.\n",
      "stars_today": 10
    },
    {
      "id": 34777562,
      "name": "srs",
      "full_name": "ossrs/srs",
      "description": "SRS is a simple, high-efficiency, real-time media server supporting RTMP, WebRTC, HLS, HTTP-FLV, HTTP-TS, SRT, MPEG-DASH, and GB28181, with codec support for H.264, H.265, AV1, VP9, AAC, Opus, and G.711.",
      "html_url": "https://github.com/ossrs/srs",
      "stars": 28389,
      "forks": 5642,
      "language": "C++",
      "topics": [
        "audio",
        "c",
        "c-plus-plus",
        "dash",
        "hevc",
        "hls",
        "live",
        "live-streaming",
        "low-latency",
        "media-server",
        "multimedia",
        "prometheus-exporter",
        "rtmp",
        "server-side",
        "srt",
        "streaming",
        "video",
        "video-conferencing",
        "video-streaming",
        "webrtc"
      ],
      "created_at": "2015-04-29T06:59:32Z",
      "updated_at": "2026-01-17T00:04:57Z",
      "pushed_at": "2025-12-13T13:24:42Z",
      "open_issues": 17,
      "owner": {
        "login": "ossrs",
        "avatar_url": "https://avatars.githubusercontent.com/u/12165287?v=4"
      },
      "readme": "# SRS(Simple Realtime Server)\n\n![](http://ossrs.net/gif/v1/sls.gif?site=github.com&path=/srs/develop)\n[![](https://github.com/ossrs/srs/actions/workflows/codeql-analysis.yml/badge.svg?branch=develop)](https://github.com/ossrs/srs/actions?query=workflow%3ACodeQL+branch%3Adevelop)\n[![](https://github.com/ossrs/srs/actions/workflows/release.yml/badge.svg)](https://github.com/ossrs/srs/actions/workflows/release.yml?query=workflow%3ARelease)\n[![](https://img.shields.io/twitter/follow/srs_server?style=social)](https://twitter.com/srs_server)\n[![](https://img.shields.io/badge/SRS-YouTube-red)](https://www.youtube.com/@srs_server)\n[![](https://badgen.net/discord/members/yZ4BnPmHAd)](https://discord.gg/yZ4BnPmHAd)\n[![](https://opencollective.com/srs-server/tiers/badge.svg)](https://opencollective.com/srs-server)\n[![](https://img.shields.io/docker/pulls/ossrs/srs)](https://hub.docker.com/r/ossrs/srs/tags)\n[![](https://codecov.io/gh/ossrs/srs/graph/badge.svg?token=Zx2LhdtA39)](https://codecov.io/gh/ossrs/srs)\n\nSRS/7.0 ([Kai](https://ossrs.io/lts/en-us/product#release-70)) is a simple, high-efficiency, and real-time video server, \nsupporting RTMP/WebRTC/HLS/HTTP-FLV/SRT/MPEG-DASH/GB28181, Linux/macOS, X86_64/ARMv7/AARCH64/M1/RISCV/LOONGARCH/MIPS,\nwith codec support for H.264, H.265, AV1, VP9, AAC, Opus, and G.711, \nand essential [features](trunk/doc/Features.md#features).\n\n[![SRS Overview](https://ossrs.net/wiki/images/SRS-SingleNode-4.0-sd.png?v=114)](https://ossrs.net/wiki/images/SRS-SingleNode-4.0-hd.png)\n\n> Note: For more details on the single-node architecture for SRS, please visit the following [link](https://www.figma.com/file/333POxVznQ8Wz1Rxlppn36/SRS-4.0-Server-Arch).\n\nSRS is licenced under [MIT](https://github.com/ossrs/srs/blob/develop/LICENSE), and some third-party libraries are \ndistributed under their [licenses](https://ossrs.io/lts/en-us/license).\n\n<a name=\"product\"></a> <a name=\"usage-docker\"></a>\n\n## Usage\n\nPlease check the Getting Started guide in [English](https://ossrs.io/lts/en-us/docs/v5/doc/getting-started) \nor [Chinese](https://ossrs.net/lts/zh-cn/docs/v5/doc/getting-started). We highly recommend using SRS with docker:\n\n```bash\ndocker run --rm -it -p 1935:1935 -p 1985:1985 -p 8080:8080 \\\n    -p 8000:8000/udp -p 10080:10080/udp ossrs/srs:6\n```\n\n> Tips: If you're in China, use this image `registry.cn-hangzhou.aliyuncs.com/ossrs/srs:6` for faster speed.\n\nOpen [http://localhost:8080/](http://localhost:8080/) to verify, and then stream using the following\n[FFmpeg](https://ffmpeg.org/download.html) command:\n\n```bash\nffmpeg -re -i ./doc/source.flv -c copy -f flv -y rtmp://localhost/live/livestream\n```\n\nAlternatively, stream by [OBS](https://obsproject.com/download) using the following configuration:\n\n* Service: `Custom`\n* Server: `rtmp://localhost/live`\n* Stream Key: `livestream`\n\nPlay the following streams using media players:\n\n* To play an RTMP stream with URL `rtmp://localhost/live/livestream` on [VLC player](https://www.videolan.org/), open the player, go to Media > Open Network Stream, enter the URL and click Play.\n* You can play HTTP-FLV stream URL [http://localhost:8080/live/livestream.flv](http://localhost:8080/players/srs_player.html?autostart=true&stream=livestream.flv) on a webpage using the srs-player, an HTML5-based player.\n* Use srs-player for playing HLS stream with URL [http://localhost:8080/live/livestream.m3u8](http://localhost:8080/players/srs_player.html?autostart=true&stream=livestream.m3u8).\n\nIf you'd like to use WebRTC, convert RTMP to WebRTC, or convert WebRTC to RTMP, please check out \nthe wiki documentation in either [English](https://ossrs.io/lts/en-us/docs/v5/doc/getting-started#webrtc) or \n[Chinese](https://ossrs.net/lts/zh-cn/docs/v5/doc/getting-started#webrtc).\n\nTo learn more about RTMP, HLS, HTTP-FLV, SRT, MPEG-DASH, WebRTC protocols, clustering, \nHTTP API, DVR, and transcoding, please check the documents in [English](https://ossrs.io) \nor [Chinese](https://ossrs.net).\n\nIf you want to use an IDE, VSCode is recommended. VSCode supports macOS, and Linux\nplatforms. The settings are ready. All you need to do is open the folder with VSCode and \nenjoy the efficiency brought by the IDE. See [VSCode README](.vscode/README.md) for details.\n\n## Sponsor\n\nWould you like additional assistance from us? By becoming a sponsor or backer of SRS, we can provide you \nwith the support you need:\n\n* Backer: $5 per month, online text chat support through Discord.\n* Sponsor: $100 per month, online text chat plus online meeting support.\n\nPlease visit [OpenCollective](https://opencollective.com/srs-server) to become a backer or sponsor, and send \nus a direct message on [Discord](https://discord.gg/yZ4BnPmHAd). We are currently providing support to the \ndevelopers listed below:\n\n[![](https://opencollective.com/srs-server/backers.svg?width=800&button=false)](https://opencollective.com/srs-server)\n\nAt SRS, our goal is to create a free, open-source community that helps developers all over the world \nbuild high-quality streaming and RTC platforms for their businesses.\n\n<a name=\"authors\"></a>\n\n## Contributing\n\nThe [maintainers](trunk/AUTHORS.md#maintainers), and [contributors](trunk/AUTHORS.md#contributors) are listed [here](trunk/AUTHORS.md). The maintainers \nwho made significant contributions and maintained parts of SRS are listed below, ranked by the number of commits:\n\n* [Winlin](https://github.com/winlinvip): Founder of the project, focusing on ST and Issues/PR. Responsible for architecture and maintenance.\n* [XiaoZhihong](https://github.com/xiaozhihong): Concentrates on WebRTC/QUIC and SRT, with expertise in network QoS. Contributed to ARM on ST and was the original contributor for WebRTC.\n* [ChenHaibo](https://github.com/duiniuluantanqin): Specializes in GB28181 and HTTP API, contributing to patches for FFmpeg with WHIP.\n* [ZhangJunqin](https://github.com/chundonglinlin): Focused on H.265, Prometheus Exporter, and API module.\n* [XiaLixin](https://github.com/xialixin): Specializes in GB28181, with expertise in live streaming and WebRTC.\n* [Jacob Su](https://github.com/suzp1984): Jacob Su has contributed to various modules of SRS.\n* [ShiWei](https://github.com/runner365): Specializes in SRT and H.265, maintaining SRT and FLV patches for FFmpeg. An expert in codecs and FFmpeg.\n* [ChenGuanghua](https://github.com/chen-guanghua): Focused on WebRTC/QoS and introduced the Asan toolchain to SRS.\n* [LiPeng](https://github.com/lipeng19811218): Concentrates on WebRTC and contributes to memory management and smart pointers.\n* [ZhaoWenjie](https://github.com/wenjiegit): One of the earliest contributors, focusing on HDS. Has expertise in client technology.\n* [WuPengqiang](https://github.com/Bepartofyou): Focused on H.265, initially contributed to the FFmpeg module in SRS for transcoding AAC with OPUS for WebRTC.\n\nA huge `THANK YOU` goes out to:\n\n* All the [contributors](trunk/AUTHORS.md#contributors) of SRS.\n* All the friends of SRS who gave [big support](https://ossrs.net/lts/zh-cn/product).\n* [Genes](http://sourceforge.net/users/genes), [Mabbott](http://sourceforge.net/users/mabbott), and [Michael Talyanksy](https://github.com/michaeltalyansky) for making and sharing [State Threads](https://github.com/ossrs/state-threads/tree/srs).\n\nWe're really thankful to everyone in the community for helping us find bugs and improve the project. \nTo stay in touch and keep helping our community, please check out this [guide](https://github.com/ossrs/srs/contribute).\n\n## LICENSE\n\nSRS is licenced under [MIT](https://github.com/ossrs/srs/blob/develop/LICENSE), and some third-party libraries are \ndistributed under their [licenses](https://ossrs.io/lts/en-us/license).\n\n## Releases\n\n* 2025-12-03, [Release v6.0-r0](https://github.com/ossrs/srs/releases/tag/v6.0-r0), v6.0-r0, 6.0 release0, v6.0.184, 170962 lines.\n* 2025-11-03, [Release v6.0-b3](https://github.com/ossrs/srs/releases/tag/v6.0-b3), v6.0-b3, 6.0 beta3, v6.0.183, 170957 lines.\n* 2025-10-16, [Release v6.0-b2](https://github.com/ossrs/srs/releases/tag/v6.0-b2), v6.0-b2, 6.0 beta2, v6.0.181, 170948 lines.\n* 2025-09-15, [Release v6.0-b1](https://github.com/ossrs/srs/releases/tag/v6.0-b1), v6.0-b1, 6.0 beta1, v6.0.177, 170611 lines.\n* 2025-08-12, [Release v6.0-b0](https://github.com/ossrs/srs/releases/tag/v6.0-b0), v6.0-b0, 6.0 beta0, v6.0.172, 170417 lines.\n* 2025-05-03, [Release v6.0-a2](https://github.com/ossrs/srs/releases/tag/v6.0-a2), v6.0-a2, 6.0 alpha2, v6.0.165, 169712 lines.\n* 2024-09-01, [Release v6.0-a1](https://github.com/ossrs/srs/releases/tag/v6.0-a1), v6.0-a1, 6.0 alpha1, v6.0.155, 169636 lines.\n* 2024-07-27, [Release v6.0-a0](https://github.com/ossrs/srs/releases/tag/v6.0-a0), v6.0-a0, 6.0 alpha0, v6.0.145, 169259 lines.\n* 2024-07-04, [Release v6.0-d6](https://github.com/ossrs/srs/releases/tag/v6.0-d6), v6.0-d6, 6.0 dev6, v6.0.134, 168904 lines.\n* 2024-06-15, [Release v6.0-d5](https://github.com/ossrs/srs/releases/tag/v6.0-d5), v6.0-d5, 6.0 dev5, v6.0.129, 168454 lines.\n* 2024-02-15, [Release v6.0-d4](https://github.com/ossrs/srs/releases/tag/v6.0-d4), v6.0-d4, 6.0 dev4, v6.0.113, 167695 lines.\n* 2023-11-19, [Release v6.0-d3](https://github.com/ossrs/srs/releases/tag/v6.0-d3), v6.0-d3, 6.0 dev3, v6.0.101, 167560 lines.\n* 2023-09-28, [Release v6.0-d2](https://github.com/ossrs/srs/releases/tag/v6.0-d2), v6.0-d2, 6.0 dev2, v6.0.85, 167509 lines.\n* 2023-08-31, [Release v6.0-d1](https://github.com/ossrs/srs/releases/tag/v6.0-d1), v6.0-d1, 6.0 dev1, v6.0.72, 167135 lines.\n* 2023-07-09, [Release v6.0-d0](https://github.com/ossrs/srs/releases/tag/v6.0-d0), v6.0-d0, 6.0 dev0, v6.0.59, 166739 lines.\n* 2024-06-15, [Release v5.0-r3](https://github.com/ossrs/srs/releases/tag/v5.0-r3), v5.0-r3, 5.0 release3, v5.0.213, 163585 lines.\n* 2024-04-03, [Release v5.0-r2](https://github.com/ossrs/srs/releases/tag/v5.0-r2), v5.0-r2, 5.0 release2, v5.0.210, 163515 lines.\n* 2024-02-15, [Release v5.0-r1](https://github.com/ossrs/srs/releases/tag/v5.0-r1), v5.0-r1, 5.0 release1, v5.0.208, 163441 lines.\n* 2023-12-30, [Release v5.0-r0](https://github.com/ossrs/srs/releases/tag/v5.0-r0), v5.0-r0, 5.0 release0, v5.0.205, 163363 lines.\n* 2023-11-19, [Release v5.0-b7](https://github.com/ossrs/srs/releases/tag/v5.0-b7), v5.0-b7, 5.0 beta7, v5.0.200, 163305 lines.\n* 2023-10-25, [Release v5.0-b6](https://github.com/ossrs/srs/releases/tag/v5.0-b6), v5.0-b6, 5.0 beta6, v5.0.195, 163303 lines.\n* 2023-09-28, [Release v5.0-b5](https://github.com/ossrs/srs/releases/tag/v5.0-b5), v5.0-b5, 5.0 beta5, v5.0.185, 163254 lines.\n* 2023-08-31, [Release v5.0-b4](https://github.com/ossrs/srs/releases/tag/v5.0-b4), v5.0-b4, 5.0 beta4, v5.0.176, 162919 lines.\n* 2023-08-02, [Release v5.0-b3](https://github.com/ossrs/srs/releases/tag/v5.0-b3), v5.0-b3, 5.0 beta3, v5.0.170, 162704 lines.\n* 2023-07-09, [Release v5.0-b2](https://github.com/ossrs/srs/releases/tag/v5.0-b2), v5.0-b2, 5.0 beta2, v5.0.166, 162520 lines.\n* 2023-06-11, [Release v5.0-b1](https://github.com/ossrs/srs/releases/tag/v5.0-b1), v5.0-b1, 5.0 beta1, v5.0.157, 162494 lines.\n* 2023-05-14, [Release v5.0-b0](https://github.com/ossrs/srs/releases/tag/v5.0-b0), v5.0-b0, 5.0 beta0, v5.0.155, 162600 lines.\n* 2023-03-23, [Release v5.0-a5](https://github.com/ossrs/srs/releases/tag/v5.0-a5), v5.0-a5, 5.0 alpha5, v5.0.148, 162066 lines.\n* 2023-02-12, [Release v5.0-a4](https://github.com/ossrs/srs/releases/tag/v5.0-a4), v5.0-a4, 5.0 alpha4, v5.0.141, 161897 lines.\n* 2023-01-02, [Release v5.0-a3](https://github.com/ossrs/srs/releases/tag/v5.0-a3), v5.0-a3, 5.0 alpha3, v5.0.128, 161327 lines.\n* 2022-12-18, [Release v5.0-a2](https://github.com/ossrs/srs/releases/tag/v5.0-a2), v5.0-a2, 5.0 alpha2, v5.0.112, 161233 lines.\n* 2022-12-01, [Release v5.0-a1](https://github.com/ossrs/srs/releases/tag/v5.0-a1), v5.0-a1, 5.0 alpha1, v5.0.100, 160817 lines.\n* 2022-11-25, [Release v5.0-a0](https://github.com/ossrs/srs/releases/tag/v5.0-a0), v5.0-a0, 5.0 alpha0, v5.0.98, 159813 lines.\n* 2022-11-22, [Release v4.0-r4](https://github.com/ossrs/srs/releases/tag/v4.0-r4), v4.0-r4, 4.0 release4, v4.0.268, 145482 lines.\n* 2022-09-16, [Release v4.0-r3](https://github.com/ossrs/srs/releases/tag/v4.0-r3), v4.0-r3, 4.0 release3, v4.0.265, 145328 lines.\n* 2022-08-24, [Release v4.0-r2](https://github.com/ossrs/srs/releases/tag/v4.0-r2), v4.0-r2, 4.0 release2, v4.0.257, 144890 lines.\n* 2022-06-29, [Release v4.0-r1](https://github.com/ossrs/srs/releases/tag/v4.0-r1), v4.0-r1, 4.0 release1, v4.0.253, 144680 lines.\n* 2022-06-11, [Release v4.0-r0](https://github.com/ossrs/srs/releases/tag/v4.0-r0), v4.0-r0, 4.0 release0, v4.0.252, 144680 lines.\n* 2020-06-27, [Release v3.0-r0](https://github.com/ossrs/srs/releases/tag/v3.0-r0), 3.0 release0, 3.0.141, 122674 lines.\n* 2020-02-02, [Release v3.0-b0](https://github.com/ossrs/srs/releases/tag/v3.0-b0), 3.0 beta0, 3.0.112, 121709 lines.\n* 2019-10-04, [Release v3.0-a0](https://github.com/ossrs/srs/releases/tag/v3.0-a0), 3.0 alpha0, 3.0.56, 107946 lines.\n* 2017-03-03, [Release v2.0-r0](https://github.com/ossrs/srs/releases/tag/v2.0-r0), 2.0 release0, 2.0.234, 86373 lines.\n* 2016-08-06, [Release v2.0-b0](https://github.com/ossrs/srs/releases/tag/v2.0-b0), 2.0 beta0, 2.0.210, 89704 lines.\n* 2015-08-23, [Release v2.0-a0](https://github.com/ossrs/srs/releases/tag/v2.0-a0), 2.0 alpha0, 2.0.185, 89022 lines.\n* 2014-12-05, [Release v1.0-r0](https://github.com/ossrs/srs/releases/tag/v1.0-r0), all bug fixed, 1.0.10, 59391 lines.\n* 2014-10-09, [Release v0.9.8](https://github.com/ossrs/srs/releases/tag/v0.9.8), all bug fixed, 1.0.0, 59316 lines.\n* 2014-04-07, [Release v0.9.1](https://github.com/ossrs/srs/releases/tag/v0.9.1), live streaming. 30000 lines.\n* 2013-10-23, [Release v0.1.0](https://github.com/ossrs/srs/releases/tag/v0.1.0), rtmp. 8287 lines.\n* 2013-10-17, Created.\n\n## Features\n\nPlease read [FEATURES](trunk/doc/Features.md#features).\n\n<a name=\"history\"></a> <a name=\"change-logs\"></a>\n## Changelog\n\nPlease read [CHANGELOG](trunk/doc/CHANGELOG.md#changelog).\n\n## Performance\n\nPlease read [PERFORMANCE](trunk/doc/PERFORMANCE.md#performance).\n\n## Architecture\n\nPlease read [ARCHITECTURE](trunk/doc/Architecture.md#architecture).\n\n## Ports\n\nPlease read [PORTS](trunk/doc/Resources.md#ports).\n\n## APIs\n\nPlease read [APIS](trunk/doc/Resources.md#apis).\n\n## Mirrors\n\nPlease read [MIRRORS](trunk/doc/Resources.md#mirrors).\n\n## Dockers\n\nPlease read [DOCKERS](trunk/doc/Dockers.md).\n\nBeijing, 2013.10<br/>\nWinlin\n\n",
      "stars_today": 10
    },
    {
      "id": 1062572,
      "name": "Catch2",
      "full_name": "catchorg/Catch2",
      "description": "A modern, C++-native, test framework for unit-tests, TDD and BDD - using C++14, C++17 and later (C++11 support is in v2.x branch, and C++03 on the Catch1.x branch)",
      "html_url": "https://github.com/catchorg/Catch2",
      "stars": 20123,
      "forks": 3184,
      "language": "C++",
      "topics": [
        "bdd",
        "cpp",
        "cpp14",
        "framework",
        "no-dependencies",
        "tdd",
        "test-framework",
        "testing"
      ],
      "created_at": "2010-11-08T18:22:56Z",
      "updated_at": "2026-01-16T17:22:09Z",
      "pushed_at": "2026-01-13T08:10:07Z",
      "open_issues": 415,
      "owner": {
        "login": "catchorg",
        "avatar_url": "https://avatars.githubusercontent.com/u/33321405?v=4"
      },
      "readme": "<a id=\"top\"></a>\n\n<table width=\"100%\">\n  <tr>\n    <td align=\"center\" width=\"50%\"><img src=\"/data/artwork/catch2-logo-full-with-background.svg\" width=\"100%\"></td>\n    <td align=\"center\" width=\"50%\">\n      <figure>\n        <figcaption>Special thanks to:</figcaption>\n        <a href=\"https://tuple.app/catch2\"><img src=\"/data/sponsors/github_repo_sponsorship.png\" width=\"100%\"></a>\n      </figure>\n    </td>\n  </tr>\n</table>\n\n[![Github Releases](https://img.shields.io/github/release/catchorg/catch2.svg)](https://github.com/catchorg/catch2/releases)\n[![Linux build status](https://github.com/catchorg/Catch2/actions/workflows/linux-simple-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/linux-simple-builds.yml)\n[![Linux build status](https://github.com/catchorg/Catch2/actions/workflows/linux-other-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/linux-other-builds.yml)\n[![MacOS build status](https://github.com/catchorg/Catch2/actions/workflows/mac-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/mac-builds.yml)\n[![Build Status](https://ci.appveyor.com/api/projects/status/github/catchorg/Catch2?svg=true&branch=devel)](https://ci.appveyor.com/project/catchorg/catch2)\n[![Code Coverage](https://codecov.io/gh/catchorg/Catch2/branch/devel/graph/badge.svg)](https://codecov.io/gh/catchorg/Catch2)\n[![Try online](https://img.shields.io/badge/try-online-blue.svg)](https://godbolt.org/z/EdoY15q9G)\n[![Join the chat in Discord: https://discord.gg/4CWS9zD](https://img.shields.io/badge/Discord-Chat!-brightgreen.svg)](https://discord.gg/4CWS9zD)\n\n\n## What is Catch2?\n\nCatch2 is mainly a unit testing framework for C++, but it also\nprovides basic micro-benchmarking features, and simple BDD macros.\n\nCatch2's main advantage is that using it is both simple and natural.\nTest names do not have to be valid identifiers, assertions look like\nnormal C++ boolean expressions, and sections provide a nice and local way\nto share set-up and tear-down code in tests.\n\n**Example unit test**\n```cpp\n#include <catch2/catch_test_macros.hpp>\n\n#include <cstdint>\n\nuint32_t factorial( uint32_t number ) {\n    return number <= 1 ? number : factorial(number-1) * number;\n}\n\nTEST_CASE( \"Factorials are computed\", \"[factorial]\" ) {\n    REQUIRE( factorial( 1) == 1 );\n    REQUIRE( factorial( 2) == 2 );\n    REQUIRE( factorial( 3) == 6 );\n    REQUIRE( factorial(10) == 3'628'800 );\n}\n```\n\n**Example microbenchmark**\n```cpp\n#include <catch2/catch_test_macros.hpp>\n#include <catch2/benchmark/catch_benchmark.hpp>\n\n#include <cstdint>\n\nuint64_t fibonacci(uint64_t number) {\n    return number < 2 ? number : fibonacci(number - 1) + fibonacci(number - 2);\n}\n\nTEST_CASE(\"Benchmark Fibonacci\", \"[!benchmark]\") {\n    REQUIRE(fibonacci(5) == 5);\n\n    REQUIRE(fibonacci(20) == 6'765);\n    BENCHMARK(\"fibonacci 20\") {\n        return fibonacci(20);\n    };\n\n    REQUIRE(fibonacci(25) == 75'025);\n    BENCHMARK(\"fibonacci 25\") {\n        return fibonacci(25);\n    };\n}\n```\n\n_Note that benchmarks are not run by default, so you need to run it explicitly\nwith the `[!benchmark]` tag._\n\n\n## Catch2 v3 has been released!\n\nYou are on the `devel` branch, where the v3 version is being developed.\nv3 brings a bunch of significant changes, the big one being that Catch2\nis no longer a single-header library. Catch2 now behaves as a normal\nlibrary, with multiple headers and separately compiled implementation.\n\nThe documentation is slowly being updated to take these changes into\naccount, but this work is currently still ongoing.\n\nFor migrating from the v2 releases to v3, you should look at [our\ndocumentation](docs/migrate-v2-to-v3.md#top). It provides a simple\nguidelines on getting started, and collects most common migration\nproblems.\n\nFor the previous major version of Catch2 [look into the `v2.x` branch\nhere on GitHub](https://github.com/catchorg/Catch2/tree/v2.x).\n\n\n## How to use it\nThis documentation comprises these three parts:\n\n* [Why do we need yet another C++ Test Framework?](docs/why-catch.md#top)\n* [Tutorial](docs/tutorial.md#top) - getting started\n* [Reference section](docs/Readme.md#top) - all the details\n\n\n## More\n* Issues and bugs can be raised on the [Issue tracker on GitHub](https://github.com/catchorg/Catch2/issues)\n* For discussion or questions please use [our Discord](https://discord.gg/4CWS9zD)\n* See who else is using Catch2 in [Open Source Software](docs/opensource-users.md#top)\nor [commercially](docs/commercial-users.md#top).\n",
      "stars_today": 10
    },
    {
      "id": 693187866,
      "name": "rolldown",
      "full_name": "rolldown/rolldown",
      "description": "Fast Rust bundler for JavaScript/TypeScript with Rollup-compatible API.",
      "html_url": "https://github.com/rolldown/rolldown",
      "stars": 12650,
      "forks": 683,
      "language": "Rust",
      "topics": [
        "bundler",
        "javascript",
        "typescript"
      ],
      "created_at": "2023-09-18T14:20:28Z",
      "updated_at": "2026-01-16T23:27:54Z",
      "pushed_at": "2026-01-16T17:11:37Z",
      "open_issues": 238,
      "owner": {
        "login": "rolldown",
        "avatar_url": "https://avatars.githubusercontent.com/u/94954945?v=4"
      },
      "readme": "<p align=\"center\">\n  <br>\n  <br>\n  <a href=\"https://rolldown.rs\" target=\"_blank\" rel=\"noopener noreferrer\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://rolldown.rs/rolldown-light.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://rolldown.rs/rolldown-dark.svg\">\n      <img alt=\"rolldown logo\" src=\"https://rolldown.rs/rolldown-dark.svg\" height=\"60\">\n    </picture>\n  </a>\n  <br>\n  <br>\n  <br>\n</p>\n\n<div align=\"center\">\n\n[![MIT licensed][badge-license]][url-license]\n[![NPM version][badge-npm-version]][url-npm]\n[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/rolldown/rolldown)\n[![Discord chat][badge-discord]][discord-url]\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/rolldown/rolldown)\n\n</div>\n\n<div align=\"center\">\n\n[![NPM Unpacked Size (with version)](https://img.shields.io/npm/unpacked-size/rolldown/latest?label=npm)][url-npm]\n[![NPM Unpacked Size darwin-arm64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest?label=darwin-arm64)](https://www.npmjs.com/package/@rolldown/binding-darwin-arm64)\n[![NPM Unpacked Size darwin-x64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-x64/latest?label=darwin-x64)](https://www.npmjs.com/package/@rolldown/binding-darwin-x64)\n[![NPM Unpacked Size linux-x64-gnu](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-linux-x64-gnu/latest?label=linux-x64-gnu)](https://www.npmjs.com/package/@rolldown/binding-linux-x64-gnu)\n[![NPM Unpacked Size win32-x64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest?label=win32-x64)](https://www.npmjs.com/package/@rolldown/binding-win32-x64-msvc)\n[![NPM Unpacked Size wasm32-wasi](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-wasm32-wasi/latest?label=wasm32-wasi)](https://www.npmjs.com/package/@rolldown/binding-wasm32-wasi)\n\n</div>\n\n<div align=\"center\">\n\n[![pkg.pr.new](https://pkg.pr.new/badge/pkg.pr.new/pkg.pr.new?style=flat&color=000&logoSize=auto)](https://pkg.pr.new/~/rolldown/rolldown)\n\n</div>\n\n<div align=\"center\">\n\n[![rolldown-starter-stackblitz](https://developer.stackblitz.com/img/open_in_stackblitz.svg)](https://stackblitz.com/fork/github/rolldown/rolldown-starter-stackblitz)\n\n</div>\n\n> üöß **Beta Software**\n>\n> Rolldown is currently in beta status. While it can already handle most production use cases, there may still be bugs and rough edges. Most notably, the built-in minification feature is still in alpha status.\n\n# Rolldown\n\nRolldown is a JavaScript/TypeScript bundler written in Rust intended to serve as the future bundler used in [Vite](https://vitejs.dev/). It provides Rollup-compatible APIs and plugin interface, but will be more similar to esbuild in scope.\n\nFor more information, please check out the documentation at [rolldown.rs](https://rolldown.rs/guide/getting-started).\n\n## VoidZero Inc.\n\nRolldown is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/posts/announcing-voidzero-inc).\n\nIf you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!\n\n## Contributing\n\nWe would love to have more contributors involved!\n\nTo get started, please read our [Contributing Guide](https://rolldown.rs/contribution-guide/).\n\n## Credits\n\nThe Rolldown project is heavily inspired by:\n\n- [Rollup](https://github.com/rollup/rollup), created by [Rich Harris](https://github.com/Rich-Harris) and maintained by [Lukas Taegert-Atkinson](https://github.com/lukastaegert).\n- [esbuild](https://github.com/evanw/esbuild), created by [Evan Wallace](https://github.com/evanw).\n\nAnd supported by:\n\n- [napi-rs](https://github.com/napi-rs/napi-rs) for Node.js add-ons in Rust via Node-API.\n- [oxc](https://github.com/oxc-project/oxc) for the underlying parser, resolver, and sourcemap support.\n\n## Licenses\n\nThis project is licensed under the [MIT License](LICENSE).\n\nThis project also partially contains code derived or copied from the following projects:\n\n- [rollup(MIT)](https://github.com/rollup/rollup/blob/680912e2ceb42c8d5e571e01c6ece0e4889aecbb/LICENSE-CORE.md)\n- [esbuild(MIT)](https://github.com/evanw/esbuild/blob/0c8a0a901d9a6c7bbff9b4dd347c8a3f65f6c6dd/LICENSE.md)\n\nLicenses of these projects are listed in [THIRD-PARTY-LICENSE](/THIRD-PARTY-LICENSE)\n\n[badge-discord]: https://img.shields.io/discord/1079625926024900739?logo=discord&label=Discord\n[discord-url]: https://chat.rolldown.rs\n[badge-license]: https://img.shields.io/badge/license-MIT-blue.svg\n[url-license]: https://github.com/rolldown/rolldown/blob/main/LICENSE\n[badge-npm-version]: https://img.shields.io/npm/v/rolldown/latest?color=brightgreen\n[url-npm]: https://www.npmjs.com/package/rolldown/v/latest\n\n[badge-binary-size-windows]: [https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest]\n[badge-binary-size-macos]: [https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest]\n",
      "stars_today": 10
    },
    {
      "id": 511691380,
      "name": "lance",
      "full_name": "lance-format/lance",
      "description": "Open Lakehouse Format for Multimodal AI. Convert from Parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..",
      "html_url": "https://github.com/lance-format/lance",
      "stars": 5945,
      "forks": 523,
      "language": "Rust",
      "topics": [
        "apache-arrow",
        "computer-vision",
        "data-analysis",
        "data-analytics",
        "data-centric",
        "data-format",
        "data-science",
        "dataops",
        "deep-learning",
        "duckdb",
        "embeddings",
        "llms",
        "machine-learning",
        "mlops",
        "python",
        "rust"
      ],
      "created_at": "2022-07-07T22:29:29Z",
      "updated_at": "2026-01-16T23:58:15Z",
      "pushed_at": "2026-01-16T22:02:25Z",
      "open_issues": 993,
      "owner": {
        "login": "lance-format",
        "avatar_url": "https://avatars.githubusercontent.com/u/243204601?v=4"
      },
      "readme": "<div align=\"center\">\n<p align=\"center\">\n\n<img width=\"257\" alt=\"Lance Logo\" src=\"https://user-images.githubusercontent.com/917119/199353423-d3e202f7-0269-411d-8ff2-e747e419e492.png\">\n\n**The Open Lakehouse Format for Multimodal AI**<br/>\n**High-performance vector search, full-text search, random access, and feature engineering capabilities for the lakehouse.**<br/>\n**Compatible with Pandas, DuckDB, Polars, PyArrow, Ray, Spark, and more integrations on the way.**\n\n<a href=\"https://lance.org\">Documentation</a> ‚Ä¢\n<a href=\"https://lance.org/community\">Community</a> ‚Ä¢\n<a href=\"https://discord.gg/lance\">Discord</a>\n\n[CI]: https://github.com/lance-format/lance/actions/workflows/rust.yml\n[CI Badge]: https://github.com/lance-format/lance/actions/workflows/rust.yml/badge.svg\n[Docs]: https://lance.org\n[Docs Badge]: https://img.shields.io/badge/docs-passing-brightgreen\n[crates.io]: https://crates.io/crates/lance\n[crates.io badge]: https://img.shields.io/crates/v/lance.svg\n[Python versions]: https://pypi.org/project/pylance/\n[Python versions badge]: https://img.shields.io/pypi/pyversions/pylance\n\n[![CI Badge]][CI]\n[![Docs Badge]][Docs]\n[![crates.io badge]][crates.io]\n[![Python versions badge]][Python versions]\n\n</p>\n</div>\n\n<hr />\n\nLance is an open lakehouse format for multimodal AI. It contains a file format, table format, and catalog spec that allows you to build a complete lakehouse on top of object storage to power your AI workflows. Lance is perfect for:\n\n1. Building search engines and feature stores with hybrid search capabilities.\n2. Large-scale ML training requiring high performance IO and random access.\n3. Storing, querying, and managing multimodal data including images, videos, audio, text, and embeddings.\n\nThe key features of Lance include:\n\n* **Expressive hybrid search:** Combine vector similarity search, full-text search (BM25), and SQL analytics on the same dataset with accelerated secondary indices.\n\n* **Lightning-fast random access:** 100x faster than Parquet or Iceberg for random access without sacrificing scan performance.\n\n* **Native multimodal data support:** Store images, videos, audio, text, and embeddings in a single unified format with efficient blob encoding and lazy loading.\n\n* **Data evolution:** Efficiently add columns with backfilled values without full table rewrites, perfect for ML feature engineering.\n\n* **Zero-copy versioning:** ACID transactions, time travel, and automatic versioning without needing extra infrastructure.\n\n* **Rich ecosystem integrations:** Apache Arrow, Pandas, Polars, DuckDB, Apache Spark, Ray, Trino, Apache Flink, and open catalogs (Apache Polaris, Unity Catalog, Apache Gravitino).\n\nFor more details, see the full [Lance format specification](https://lance.org/format).\n\n> [!TIP]\n> Lance is in active development and we welcome contributions. Please see our [contributing guide](https://lance.org/community/contributing/) for more information.\n\n## Quick Start\n\n**Installation**\n\n```shell\npip install pylance\n```\n\nTo install a preview release:\n\n```shell\npip install --pre --extra-index-url https://pypi.fury.io/lance-format/pylance\n```\n\n> [!NOTE]\n> For versions prior to 1.0.0-beta.4, you can find them at https://pypi.fury.io/lancedb/pylance\n\n> [!TIP]\n> Preview releases are released more often than full releases and contain the\n> latest features and bug fixes. They receive the same level of testing as full releases.\n> We guarantee they will remain published and available for download for at\n> least 6 months. When you want to pin to a specific version, prefer a stable release.\n\n**Converting to Lance**\n\n```python\nimport lance\n\nimport pandas as pd\nimport pyarrow as pa\nimport pyarrow.dataset\n\ndf = pd.DataFrame({\"a\": [5], \"b\": [10]})\nuri = \"/tmp/test.parquet\"\ntbl = pa.Table.from_pandas(df)\npa.dataset.write_dataset(tbl, uri, format='parquet')\n\nparquet = pa.dataset.dataset(uri, format='parquet')\nlance.write_dataset(parquet, \"/tmp/test.lance\")\n```\n\n**Reading Lance data**\n```python\ndataset = lance.dataset(\"/tmp/test.lance\")\nassert isinstance(dataset, pa.dataset.Dataset)\n```\n\n**Pandas**\n```python\ndf = dataset.to_table().to_pandas()\ndf\n```\n\n**DuckDB**\n```python\nimport duckdb\n\n# If this segfaults, make sure you have duckdb v0.7+ installed\nduckdb.query(\"SELECT * FROM dataset LIMIT 10\").to_df()\n```\n\n**Vector search**\n\nDownload the sift1m subset\n\n```shell\nwget ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz\ntar -xzf sift.tar.gz\n```\n\nConvert it to Lance\n\n```python\nimport lance\nfrom lance.vector import vec_to_table\nimport numpy as np\nimport struct\n\nnvecs = 1000000\nndims = 128\nwith open(\"sift/sift_base.fvecs\", mode=\"rb\") as fobj:\n    buf = fobj.read()\n    data = np.array(struct.unpack(\"<128000000f\", buf[4 : 4 + 4 * nvecs * ndims])).reshape((nvecs, ndims))\n    dd = dict(zip(range(nvecs), data))\n\ntable = vec_to_table(dd)\nuri = \"vec_data.lance\"\nsift1m = lance.write_dataset(table, uri, max_rows_per_group=8192, max_rows_per_file=1024*1024)\n```\n\nBuild the index\n\n```python\nsift1m.create_index(\"vector\",\n                    index_type=\"IVF_PQ\",\n                    num_partitions=256,  # IVF\n                    num_sub_vectors=16)  # PQ\n```\n\nSearch the dataset\n\n```python\n# Get top 10 similar vectors\nimport duckdb\n\ndataset = lance.dataset(uri)\n\n# Sample 100 query vectors. If this segfaults, make sure you have duckdb v0.7+ installed\nsample = duckdb.query(\"SELECT vector FROM dataset USING SAMPLE 100\").to_df()\nquery_vectors = np.array([np.array(x) for x in sample.vector])\n\n# Get nearest neighbors for all of them\nrs = [dataset.to_table(nearest={\"column\": \"vector\", \"k\": 10, \"q\": q})\n      for q in query_vectors]\n```\n\n## Directory structure\n\n| Directory          | Description              |\n|--------------------|--------------------------|\n| [rust](./rust)     | Core Rust implementation |\n| [python](./python) | Python bindings (PyO3)   |\n| [java](./java)     | Java bindings (JNI)      |\n| [docs](./docs)     | Documentation source     |\n\n## Benchmarks\n\n### Vector search\n\nWe used the SIFT dataset to benchmark our results with 1M vectors of 128D\n\n1. For 100 randomly sampled query vectors, we get <1ms average response time (on a 2023 m2 MacBook Air)\n\n![avg_latency.png](docs/src/images/avg_latency.png)\n\n2. ANNs are always a trade-off between recall and performance\n\n![avg_latency.png](docs/src/images/recall_vs_latency.png)\n\n### Vs. parquet\n\nWe create a Lance dataset using the Oxford Pet dataset to do some preliminary performance testing of Lance as compared to Parquet and raw image/XMLs. For analytics queries, Lance is 50-100x better than reading the raw metadata. For batched random access, Lance is 100x better than both parquet and raw files.\n\n![](docs/src/images/lance_perf.png)\n\n## Why Lance for AI/ML workflows?\n\nThe machine learning development cycle involves multiple stages:\n\n```mermaid\ngraph LR\n    A[Collection] --> B[Exploration];\n    B --> C[Analytics];\n    C --> D[Feature Engineer];\n    D --> E[Training];\n    E --> F[Evaluation];\n    F --> C;\n    E --> G[Deployment];\n    G --> H[Monitoring];\n    H --> A;\n```\n\nTraditional lakehouse formats were designed for SQL analytics and struggle with AI/ML workloads that require:\n- **Vector search** for similarity and semantic retrieval\n- **Fast random access** for sampling and interactive exploration\n- **Multimodal data** storage (images, videos, audio alongside embeddings)\n- **Data evolution** for feature engineering without full table rewrites\n- **Hybrid search** combining vectors, full-text, and SQL predicates\n\nWhile existing formats (Parquet, Iceberg, Delta Lake) excel at SQL analytics, they require additional specialized systems for AI capabilities. Lance brings these AI-first features directly into the lakehouse format.\n\nA comparison of different formats across ML development stages:\n\n|                     | Lance | Parquet & ORC | JSON & XML | TFRecord | Database | Warehouse |\n|---------------------|-------|---------------|------------|----------|----------|-----------|\n| Analytics           | Fast  | Fast          | Slow       | Slow     | Decent   | Fast      |\n| Feature Engineering | Fast  | Fast          | Decent     | Slow     | Decent   | Good      |\n| Training            | Fast  | Decent        | Slow       | Fast     | N/A      | N/A       |\n| Exploration         | Fast  | Slow          | Fast       | Slow     | Fast     | Decent    |\n| Infra Support       | Rich  | Rich          | Decent     | Limited  | Rich     | Rich      |\n\n",
      "stars_today": 10
    },
    {
      "id": 740710728,
      "name": "extensions-source",
      "full_name": "keiyoushi/extensions-source",
      "description": "Source code of extensions in https://github.com/keiyoushi/extensions",
      "html_url": "https://github.com/keiyoushi/extensions-source",
      "stars": 3596,
      "forks": 1032,
      "language": "Kotlin",
      "topics": [
        "android",
        "hacktoberfest",
        "kotlin",
        "mihon",
        "tachiyomi"
      ],
      "created_at": "2024-01-08T22:47:46Z",
      "updated_at": "2026-01-16T17:22:36Z",
      "pushed_at": "2026-01-16T15:01:43Z",
      "open_issues": 799,
      "owner": {
        "login": "keiyoushi",
        "avatar_url": "https://avatars.githubusercontent.com/u/113362897?v=4"
      },
      "readme": "# Keiyoushi Extensions\n\n### Please give the repo a :star:\n\n| Build                                                                                                                                                                               | Need Help?                                                                                                                                              |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [![CI](https://github.com/keiyoushi/extensions-source/actions/workflows/build_push.yml/badge.svg)](https://github.com/keiyoushi/extensions-source/actions/workflows/build_push.yml) | [![Discord](https://img.shields.io/discord/1193460528052453448.svg?label=discord&labelColor=7289da&color=2c2f33&style=flat)](https://discord.gg/3FbCpdKbdY) |\n\n## Usage\n**If you are new to repository/extensions, please read the [Keiyoushi Getting Started guide](https://keiyoushi.github.io/docs/guides/getting-started#adding-the-extension-repo) first.**\n\n* You can add our repo by visiting the [Keiyoushi Website](https://keiyoushi.github.io/add-repo)\n* Otherwise, copy & paste the following URL: https://raw.githubusercontent.com/keiyoushi/extensions/repo/index.min.json\n\n## Requests\n\nTo request a new source or bug fix, [create an issue](https://github.com/keiyoushi/extensions-source/issues/new/choose).\n\nPlease note that creating an issue does not mean that the source will be added or fixed in a timely\nfashion, because the work is volunteer-based. Some sources may also be impossible to do or prohibitively\ndifficult to maintain.\n\nIf you would like to see a request fulfilled and have the necessary skills to do so, consider contributing!\nIssues are up-for-grabs for any developer if there is no assigned user already.\n\n## Contributing\n\nContributions are welcome!\n\nCheck out the repo's [issue backlog](https://github.com/keiyoushi/extensions-source/issues) for source requests and bug reports.\n\n## License\n\n    Copyright 2015 Javier Tom√°s\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n\n## Disclaimer\n\nThis project does not have any affiliation with the content providers available.\n\nThis project is not affiliated with Mihon/Tachiyomi. Don't ask for help about these extensions at the\nofficial support means of Mihon/Tachiyomi. All credits to the codebase goes to the original contributors.\n",
      "stars_today": 10
    },
    {
      "id": 149340903,
      "name": "apriltag",
      "full_name": "AprilRobotics/apriltag",
      "description": "AprilTag is a visual fiducial system popular for robotics research.",
      "html_url": "https://github.com/AprilRobotics/apriltag",
      "stars": 2080,
      "forks": 623,
      "language": "C",
      "topics": [
        "robotics"
      ],
      "created_at": "2018-09-18T19:25:08Z",
      "updated_at": "2026-01-16T23:36:54Z",
      "pushed_at": "2026-01-08T20:11:33Z",
      "open_issues": 30,
      "owner": {
        "login": "AprilRobotics",
        "avatar_url": "https://avatars.githubusercontent.com/u/43387976?v=4"
      },
      "readme": "AprilTag 3\n==========\nAprilTag is a visual fiducial system popular in robotics research. This repository contains the most recent version of AprilTag, AprilTag 3, which includes a faster (>2x) detector, improved detection rate on small tags, flexible tag layouts, and pose estimation. AprilTag consists of a small C library with minimal dependencies.\n\nYou can find tag images for the pre-generated layouts [here](https://github.com/AprilRobotics/apriltag-imgs). We recommend using the tagStandard41h12 layout.\n\nTable of Contents\n=================\n- [Papers](#papers)\n- [Install](#install)\n- [Usage](#usage)\n  - [Choosing a Tag Family](#choosing-a-tag-family)\n  - [Getting Started with the Detector](#getting-started-with-the-detector)\n    - [Python](#python)\n    - [C](#c)\n    - [Matlab](#matlab)\n    - [Julia](#julia)\n  - [Upgrading from AprilTag 2](#upgrading-from-aprilTag-2)\n  - [OpenCV Integration](#opencv-integration)\n  - [Tuning the Detector Parameters](#tuning-the-detector-parameters)\n    - [Increasing speed.](#increasing-speed)\n    - [Increasing detection distance.](#increasing-detection-distance)\n  - [Pose Estimation.](#pose-estimation)\n- [Debugging](#debugging)\n- [Flexible Layouts](#flexible-layouts)\n- [Support](#support)\n\nPapers\n======\nAprilTag is the subject of the following papers.\n\n[AprilTag: A robust and flexible visual fiducial system](https://april.eecs.umich.edu/papers/details.php?name=olson2011tags)\n\n[AprilTag 2: Efficient and robust fiducial detection](https://april.eecs.umich.edu/papers/details.php?name=wang2016iros)\n\n[Flexible Layouts for Fiducial Tags](https://april.eecs.umich.edu/papers/details.php?name=krogius2019iros)\n\nInstall\n=======\n\nOfficially only Linux operating systems are supported, although users have had success installing on Windows too.\n\nThe default installation will place headers in /usr/local/include and shared library in /usr/local/lib. It also installs a pkg-config script into /usr/local/lib/pkgconfig and will install a python wrapper if python3 is installed.\n\n```\ncmake -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build --target install\n```\nThis will build shared (\\*.so) libraries by default. If you need static (\\*.a) libraries set `BUILD_SHARED_LIBS` to `OFF`:\n```\ncmake -B build -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF\ncmake --build build --target install\n```\n\nIf you have Ninja (`sudo apt install ninja-build`) installed, you can use:\n```\ncmake -B build -GNinja -DCMAKE_BUILD_TYPE=Release\ncmake --build build --target install\n```\nto generate and compile via the ninja build script. It will be much faster than with cmake's default Makefile generator.\n\nYou can omit `--target install` if you only want to use this locally without installing.\n\n\nUsage\n=====\n\n## Choosing a Tag Family\nFor the vast majority of applications, the tagStandard41h12 family will be the correct choice. You can find the images for the tags in the [apriltag-imgs repo](https://github.com/AprilRobotics/apriltag-imgs). Scale up the images in your favorite editor and print them out.\n\nSome heuristics for when to choose other tag families:\n1. If you need more tags, use tagStandard52h13\n2. If you need to maximize the use of space on a small circular object, use tagCircle49h12 (or tagCircle21h7).\n3. If you want to make a recursive tag use tagCustom48h12.\n4. If you want compatibility with the ArUcO detector use tag36h11\n\nIf none of these fit your needs, generate your own custom tag family [here](https://github.com/AprilRobotics/apriltag-generation).\n\n## Getting Started with the Detector\n### Python\n\n    import cv2\n    import numpy as np\n    from apriltag import apriltag\n\n    imagepath = 'test.jpg'\n    image = cv2.imread(imagepath, cv2.IMREAD_GRAYSCALE)\n    detector = apriltag(\"tagStandard41h12\")\n\n    detections = detector.detect(image)\n\nAlternately you can use the AprilTag python bindings created by [duckietown](https://github.com/duckietown/lib-dt-apriltags).\n\n### C\n\n    image_u8_t* im = image_u8_create_from_pnm(\"test.pnm\");\n    if (im == NULL) {\n        fprintf(stderr, \"Failed to load pnm image.\\n\");\n        exit(1);\n    }\n    apriltag_detector_t *td = apriltag_detector_create();\n    apriltag_family_t *tf = tagStandard41h12_create();\n    apriltag_detector_add_family(td, tf);\n    zarray_t *detections = apriltag_detector_detect(td, im);\n\n    for (int i = 0; i < zarray_size(detections); i++) {\n        apriltag_detection_t *det;\n        zarray_get(detections, i, &det);\n\n        // Do stuff with detections here.\n    }\n    // Cleanup.\n    apriltag_detections_destroy(detections);\n    tagStandard41h12_destroy(tf);\n    apriltag_detector_destroy(td);\n\n### Matlab\n\nProvided by third-party [here](https://github.com/alddiaz/MATLAB_AprilTag3).\n\n### Julia\n\nProvided by third-party [here](https://github.com/JuliaRobotics/AprilTags.jl)\n\n\n## Upgrading from AprilTag 2\nFor most use-cases this should be a drop in replacement.\n\n* The options refine_decode, refine_pose, and black_border have been removed.\n* If you have generated your own families, you will need to regenerate the c code for those families. The java code however does not need to be regenerated so this should be quick and easy.\n\n\n## OpenCV Integration\n\nNote that this library has no external dependencies. Most applications\nwill require, at minimum, a method for acquiring images.\n\nSee example/opencv_demo.cc for an example of using AprilTag in C++ with OpenCV.\nAfter building the repository you can run the example opencv application with:\n\n    $ ./build/opencv_demo\n\nImage data in a cv::Mat object can be passed to AprilTag without creating\na deep copy. Simply create an image_u8_t header for the cv::Mat data buffer:\n\n    cv::Mat img;\n\n    image_u8_t img_header = { .width = img.cols,\n        .height = img.rows,\n        .stride = img.cols,\n        .buf = img.data\n    };\n\n\n\n## Tuning the Detector Parameters\n### Increasing speed.\nIncreasing the quad_decimate parameter will increase the speed of the detector at the cost of detection distance.  If you have extra cpu cores to throw at the problem then you can increase nthreads. If your image is somewhat noisy, increasing the quad_sigma parameter can increase speed.\n\n### Increasing detection distance.\nFirst choose an example image and run the detector with debug=1 to generate the debug images. These show the detector's output at each step in the detection pipeline.\nIf the border of your tag is not being detected as a quadrilateral, decrease quad_decimate (all the way to 1 if necessary).\nIf the border of the tag is detected then experiment with changing decode_sharpening.\n\n## Pose Estimation.\nWe provide a method for computing the pose of the tag as follows (alternately use OpenCv's Pnp solver with SOLVEPNP_IPPE_SQUARE). You will need to include the apriltag_pose.h header file and then call the estimate_tag_pose function as follows:\n\n    // First create an apriltag_detection_info_t struct using your known parameters.\n    apriltag_detection_info_t info;\n    info.det = det;\n    info.tagsize = tagsize;\n    info.fx = fx;\n    info.fy = fy;\n    info.cx = cx;\n    info.cy = cy;\n\n    // Then call estimate_tag_pose.\n    apriltag_pose_t pose;\n    double err = estimate_tag_pose(&info, &pose);\n    // Do something with pose.\n    ...\n\nwhere the parameters are as follows:\n* `det`: The tag detection struct (april_detection_t).\n* `tagsize`: The size of the tag in meters. Each tag design has a black border and a white border, but some designs have the white border on the inside and some have the black border on the inside. The tagsize is thus measured from where the two borders meet, see the figure below for an example.\n* `fx`, `fy`: The camera's focal length (in pixels). For most cameras `fx` and `fy` will be equal or nearly so.\n* `cx`, `cy`: The camera's focal center (in pixels). For most cameras this will be approximately the same as the image center.\n\nNote: The tag size should not be measured from the outside of the tag. The tag size is defined as the distance between the detection corners, or alternately, the length of the edge between the white border and the black border. The following illustration marks the detection corners with red Xs and the tag size with a red arrow for a tag from the 48h12Custom tag family.\n\n ![The tag size is the width of the edge between the white and black borders.](tag_size_48h12.png)\n\n### Coordinate System\nThe coordinate system has the origin at the camera center. The z-axis points from the camera center out the camera lens. The x-axis is to the right in the image taken by the camera, and y is down. The tag's coordinate frame is centered at the center of the tag. From the viewer's perspective, the x-axis is to the right, y-axis down, and z-axis is into the tag.\n\nDebugging\n=========\n\nYou can enable [AddressSanitizer](https://clang.llvm.org/docs/AddressSanitizer.html) to debug memory issues for Debug builds by setting the `ASAN` option:\n```\ncmake -B build -GNinja -DCMAKE_BUILD_TYPE=Debug -DASAN=ON\ncmake --build build\n```\n\nMostly you can then run your executables as usual and inspect the sanitiser output. If you get a message like `ASan runtime does not come first in initial library list; you should either link runtime to your application or manually preload it with LD_PRELOAD.` you have to preload the corresponding `libasan.so.5` like this:\n```\nLD_PRELOAD=/usr/lib/x86_64-linux-gnu/libasan.so.5 ./build/opencv_demo\n```\n\nFlexible Layouts\n================\nAprilTag 3 supports a wide variety of possible tag layouts in addition to the classic layout supported in AprilTag 2. The tag's data bits can now go outside of the tag border, and it is also possible to define layouts with \"holes\" inside of the tag border where there are no data bits. In this repo we have included:\n\n* Two families of the new standard layout. This layout adds a layer of data bits around the outside of the tag border, increasing data density, and the number of possible tags, at the cost of a slight decrease in detection distance.\n* Two families of circular tags.\n* One family which has a hole in the middle. This could be used for example for drone applications by placing different sized tags inside of each other to allow detection over a wide range of distances.\n\nYou can generate your own tag families using our other repo, [AprilTag-Generation](https://github.com/AprilRobotics/apriltag-generation).\n\n\nSupport\n=======\nPlease create an issue on this GitHub for any questions instead of sending a private message. This allows other people with the same question to find your answer.\n",
      "stars_today": 10
    },
    {
      "id": 1038771433,
      "name": "ai-elements",
      "full_name": "vercel/ai-elements",
      "description": "AI Elements is a component library and custom registry built on top of shadcn/ui to help you build AI-native applications faster.",
      "html_url": "https://github.com/vercel/ai-elements",
      "stars": 1418,
      "forks": 173,
      "language": "TypeScript",
      "topics": [
        "ai",
        "elements",
        "shadcn-ui",
        "vercel"
      ],
      "created_at": "2025-08-15T19:37:48Z",
      "updated_at": "2026-01-17T01:00:54Z",
      "pushed_at": "2026-01-17T00:05:39Z",
      "open_issues": 31,
      "owner": {
        "login": "vercel",
        "avatar_url": "https://avatars.githubusercontent.com/u/14985020?v=4"
      },
      "readme": "# ‚ñ≤ AI Elements\n\n[AI Elements](https://ai-sdk.dev/elements) is a component library built on top of [shadcn/ui](https://ui.shadcn.com/) to help you build AI-native applications faster.\n\n## Overview\n\nAI Elements provides pre-built, customizable React components specifically designed for AI applications, including conversations, messages, code blocks, reasoning displays, and more. The CLI makes it easy to add these components to your Next.js project.\n\n## Installation\n\nYou can use the AI Elements CLI directly with npx, or install it globally:\n\n```bash\n# Use directly (recommended)\nnpx ai-elements@latest\n\n# Or using shadcn cli\nnpx shadcn@latest add https://ai-sdk.dev/elements/api/registry/all.json\n```\n\n## Prerequisites\n\nBefore using AI Elements, ensure your project meets these requirements:\n\n- **Node.js** 18 or later\n- **Next.js** project with [AI SDK](https://ai-sdk.dev/) installed\n- **shadcn/ui** initialized in your project (`npx shadcn@latest init`)\n- **Tailwind CSS** configured (AI Elements supports CSS Variables mode only)\n\n## Usage\n\n### Install All Components\n\nInstall all available AI Elements components at once:\n\n```bash\nnpx ai-elements@latest\n```\n\nThis command will:\n\n- Set up shadcn/ui if not already configured\n- Install all AI Elements components to your configured components directory\n- Add necessary dependencies to your project\n\n### Install Specific Components\n\nInstall individual components using the `add` command:\n\n```bash\nnpx ai-elements@latest add <component-name>\n```\n\nExamples:\n\n```bash\n# Install the message component\nnpx ai-elements@latest add message\n\n# Install the conversation component\nnpx ai-elements@latest add conversation\n\n# Install the code-block component\nnpx ai-elements@latest add code-block\n```\n\n### Alternative: Use with shadcn CLI\n\nYou can also install components using the standard shadcn/ui CLI:\n\n```bash\n# Install all components\nnpx shadcn@latest add https://ai-sdk.dev/elements/api/registry/all.json\n\n# Install a specific component\nnpx shadcn@latest add https://ai-sdk.dev/elements/api/registry/message.json\n```\n\n## Available Components\n\nAI Elements includes the following components:\n\n| Component          | Description                                             |\n| ------------------ | ------------------------------------------------------- |\n| **Chatbot**        |                                                         |\n| `actions`          | Interactive action buttons for AI responses             |\n| `branch`           | Branch visualization for conversation flows             |\n| `chain-of-thought` | Display AI reasoning and thought processes              |\n| `code-block`       | Syntax-highlighted code display with copy functionality |\n| `context`          | Display Context consumption                             |\n| `conversation`     | Container for chat conversations                        |\n| `image`            | AI-generated image display component                    |\n| `inline-citation`  | Inline source citations                                 |\n| `loader`           | Loading states for AI operations                        |\n| `message`          | Individual chat messages with avatars                   |\n| `open-in-chat`     | Open in chat button for a message                       |\n| `plan`             | Plan and task planning display component                |\n| `prompt-input`     | Advanced input component with model selection           |\n| `queue`            | Message and todo queue with attachments                 |\n| `reasoning`        | Display AI reasoning and thought processes              |\n| `response`         | Formatted AI response display                           |\n| `shimmer`          | Text shimmer animation effect                           |\n| `sources`          | Source attribution component                            |\n| `suggestion`       | Quick action suggestions                                |\n| `task`             | Task completion tracking                                |\n| `tool`             | Tool usage visualization                                |\n| `confirmation`     | Tool execution approval workflows                       |\n| **Vibe-Coding**    |                                                         |\n| `artifact`         | Display a code or document                              |\n| `web-preview`      | Embedded web page previews                              |\n| **Workflow**       |                                                         |\n| `canvas`           | ReactFlow canvas for workflow visualizations            |\n| `connection`       | Connection line component for workflow edges            |\n| `controls`         | Flow controls for canvas (zoom, fit view, etc.)         |\n| `edge`             | Edge component for connections between workflow nodes   |\n| `node`             | Node component for workflow graphs                      |\n| `panel`            | Panel component for canvas overlays                     |\n| `toolbar`          | Node toolbar for workflow elements                      |\n\n## Quick Start Example\n\nAfter installing components, you can use them in your React application:\n\n```tsx\n'use client';\n\nimport { useChat } from '@ai-sdk/react';\nimport {\n  Conversation,\n  ConversationContent,\n} from '@/components/ai-elements/conversation';\nimport {\n  Message,\n  MessageContent,\n  MessageResponse,\n} from '@/components/ai-elements/message';\n\nexport default function Chat() {\n  const { messages } = useChat();\n\n  return (\n    <Conversation>\n      <ConversationContent>\n        {messages.map((message, index) => (\n          <Message key={index} from={message.role}>\n            <MessageContent>\n              <MessageResponse>{message.content}</MessageResponse>\n            </MessageContent>\n          </Message>\n        ))}\n      </ConversationContent>\n    </Conversation>\n  );\n}\n```\n\n## How It Works\n\nThe AI Elements CLI:\n\n1. **Detects your package manager** (npm, pnpm, yarn, or bun) automatically\n2. **Fetches component registry** from `https://ai-sdk.dev/elements/api/registry/registry.json`\n3. **Installs components** using the shadcn/ui CLI under the hood\n4. **Adds dependencies** and integrates with your existing shadcn/ui setup\n\nComponents are installed to your configured shadcn/ui components directory (typically `@/components/ai-elements/`) and become part of your codebase, allowing for full customization.\n\n## Configuration\n\nAI Elements uses your existing shadcn/ui configuration. Components will be installed to the directory specified in your `components.json` file.\n\n## Recommended Setup\n\nFor the best experience, we recommend:\n\n1. **AI Gateway**: Set up [Vercel AI Gateway](https://vercel.com/docs/ai-gateway) and add `AI_GATEWAY_API_KEY` to your `.env.local`\n2. **CSS Variables**: Use shadcn/ui's CSS Variables mode for theming\n3. **TypeScript**: Enable TypeScript for better development experience\n\n## Contributing\n\nIf you'd like to contribute to AI Elements, please follow these steps:\n\n1. Fork the repository\n2. Create a new branch\n3. Make your changes to the components in `packages/elements`.\n4. Open a PR to the `main` branch.\n\n---\n\nMade with ‚ù§Ô∏è by [Vercel](https://vercel.com)\n",
      "stars_today": 10
    },
    {
      "id": 1148753,
      "name": "spring-framework",
      "full_name": "spring-projects/spring-framework",
      "description": "Spring Framework",
      "html_url": "https://github.com/spring-projects/spring-framework",
      "stars": 59513,
      "forks": 38908,
      "language": "Java",
      "topics": [
        "framework",
        "spring",
        "spring-framework"
      ],
      "created_at": "2010-12-08T04:04:45Z",
      "updated_at": "2026-01-16T23:16:24Z",
      "pushed_at": "2026-01-16T23:16:16Z",
      "open_issues": 327,
      "owner": {
        "login": "spring-projects",
        "avatar_url": "https://avatars.githubusercontent.com/u/317776?v=4"
      },
      "readme": "# <img src=\"framework-docs/src/docs/spring-framework.png\" width=\"80\" height=\"80\"> Spring Framework [![Build Status](https://github.com/spring-projects/spring-framework/actions/workflows/build-and-deploy-snapshot.yml/badge.svg?branch=main)](https://github.com/spring-projects/spring-framework/actions/workflows/build-and-deploy-snapshot.yml?query=branch%3Amain) [![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A)](https://ge.spring.io/scans?search.rootProjectNames=spring)\n\nThis is the home of the Spring Framework: the foundation for all [Spring projects](https://spring.io/projects). Collectively the Spring Framework and the family of Spring projects are often referred to simply as \"Spring\". \n\nSpring provides everything required beyond the Java programming language for creating enterprise applications for a wide range of scenarios and architectures. Please read the [Overview](https://docs.spring.io/spring-framework/reference/overview.html) section of the reference documentation for a more complete introduction.\n\n## Code of Conduct\n\nThis project is governed by the [Spring Code of Conduct](https://github.com/spring-projects/spring-framework/?tab=coc-ov-file#contributor-code-of-conduct). By participating, you are expected to uphold this code of conduct. Please report unacceptable behavior to spring-code-of-conduct@spring.io.\n\n## Access to Binaries\n\nFor access to artifacts or a distribution zip, see the [Spring Framework Artifacts](https://github.com/spring-projects/spring-framework/wiki/Spring-Framework-Artifacts) wiki page.\n\n## Documentation\n\nThe Spring Framework maintains reference documentation ([published](https://docs.spring.io/spring-framework/reference/) and [source](framework-docs/modules/ROOT)), GitHub [wiki pages](https://github.com/spring-projects/spring-framework/wiki), and an\n[API reference](https://docs.spring.io/spring-framework/docs/current/javadoc-api/). There are also [guides and tutorials](https://spring.io/guides) across Spring projects.\n\n## Micro-Benchmarks\n\nSee the [Micro-Benchmarks](https://github.com/spring-projects/spring-framework/wiki/Micro-Benchmarks) wiki page.\n\n## Build from Source\n\nSee the [Build from Source](https://github.com/spring-projects/spring-framework/wiki/Build-from-Source) wiki page and the [CONTRIBUTING.md](CONTRIBUTING.md) file.\n\n## Continuous Integration Builds\n\nCI builds are defined with [GitHub Actions workflows](.github/workflows).\n\n## Stay in Touch\n\nFollow [@SpringCentral](https://twitter.com/springcentral), [@SpringFramework](https://twitter.com/springframework), and its [team members](https://twitter.com/springframework/lists/team/members) on ùïè. In-depth articles can be found at [The Spring Blog](https://spring.io/blog/), and releases are announced via our [releases feed](https://spring.io/blog/category/releases).\n\n## License\n\nThe Spring Framework is released under version 2.0 of the [Apache License](https://www.apache.org/licenses/LICENSE-2.0).\n",
      "stars_today": 9
    },
    {
      "id": 74175805,
      "name": "istio",
      "full_name": "istio/istio",
      "description": "Connect, secure, control, and observe services.",
      "html_url": "https://github.com/istio/istio",
      "stars": 37831,
      "forks": 8215,
      "language": "Go",
      "topics": [
        "api-management",
        "circuit-breaker",
        "consul",
        "enforce-policies",
        "envoy",
        "fault-injection",
        "kubernetes",
        "lyft-envoy",
        "microservice",
        "microservices",
        "nomad",
        "polyglot-microservices",
        "proxies",
        "request-routing",
        "resiliency",
        "service-mesh"
      ],
      "created_at": "2016-11-18T23:57:21Z",
      "updated_at": "2026-01-16T22:58:27Z",
      "pushed_at": "2026-01-16T22:58:22Z",
      "open_issues": 498,
      "owner": {
        "login": "istio",
        "avatar_url": "https://avatars.githubusercontent.com/u/23534644?v=4"
      },
      "readme": "# Istio\n\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1395/badge)](https://bestpractices.coreinfrastructure.org/projects/1395)\n[![Go Report Card](https://goreportcard.com/badge/github.com/istio/istio)](https://goreportcard.com/report/github.com/istio/istio)\n[![GoDoc](https://godoc.org/istio.io/istio?status.svg)](https://godoc.org/istio.io/istio)\n\n<a href=\"https://istio.io/\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/projects/istio/icon/color/istio-icon-color.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/istio/istio/raw/master/logo/istio-bluelogo-whitebackground-unframed.svg\">\n      <img title=\"Istio\" height=\"100\" width=\"100\" alt=\"Istio logo\" src=\"https://github.com/istio/istio/raw/master/logo/istio-bluelogo-whitebackground-unframed.svg\">\n    </picture>\n</a>\n\n---\n\nIstio is an open source service mesh that layers transparently onto existing distributed applications. Istio‚Äôs powerful features provide a uniform and more efficient way to secure, connect, and monitor services. Istio is the path to load balancing, service-to-service authentication, and monitoring ‚Äì with few or no service code changes.\n\n- For in-depth information about how to use Istio, visit [istio.io](https://istio.io)\n- To ask questions and get assistance from our community, visit [GitHub Discussions](https://github.com/istio/istio/discussions)\n- To learn how to participate in our overall community, visit [our community page](https://istio.io/about/community)\n\nIn this README:\n\n- [Introduction](#introduction)\n- [Repositories](#repositories)\n- [Issue management](#issue-management)\n\nIn addition, here are some other documents you may wish to read:\n\n- [Istio Community](https://github.com/istio/community#istio-community) - describes how to get involved and contribute to the Istio project\n- [Istio Developer's Guide](https://github.com/istio/istio/wiki/Preparing-for-Development) - explains how to set up and use an Istio development environment\n- [Project Conventions](https://github.com/istio/istio/wiki/Development-Conventions) - describes the conventions we use within the code base\n- [Creating Fast and Lean Code](https://github.com/istio/istio/wiki/Writing-Fast-and-Lean-Code) - performance-oriented advice and guidelines for the code base\n\nYou'll find many other useful documents on our [Wiki](https://github.com/istio/istio/wiki).\n\n## Introduction\n\n[Istio](https://istio.io/latest/docs/concepts/what-is-istio/) is an open platform for providing a uniform way to [integrate\nmicroservices](https://istio.io/latest/docs/examples/microservices-istio/), manage [traffic flow](https://istio.io/latest/docs/concepts/traffic-management/) across microservices, enforce policies\nand aggregate telemetry data. Istio's control plane provides an abstraction\nlayer over the underlying cluster management platform, such as Kubernetes.\n\nIstio is composed of these components:\n\n- **Envoy** - Sidecar proxies per microservice to handle ingress/egress traffic\n   between services in the cluster and from a service to external\n   services. The proxies form a _secure microservice mesh_ providing a rich\n   set of functions like discovery, rich layer-7 routing, circuit breakers,\n   policy enforcement and telemetry recording/reporting\n   functions.\n\n  > Note: The service mesh is not an overlay network. It\n  > simplifies and enhances how microservices in an application talk to each\n  > other over the network provided by the underlying platform.\n\n* **Ztunnel** - A lightweight data plane proxy written in Rust,\n    used in Ambient mesh mode to provide secure connectivity and observability for workloads without sidecar proxies.\n\n- **Istiod** - The Istio control plane. It provides service discovery, configuration and certificate management.\n\n## Repositories\n\nThe Istio project is divided across a few GitHub repositories:\n\n- [istio/api](https://github.com/istio/api). This repository defines\ncomponent-level APIs and common configuration formats for the Istio platform.\n\n- [istio/community](https://github.com/istio/community). This repository contains\ninformation on the Istio community, including the various documents that govern\nthe Istio open source project.\n\n- [istio/istio](README.md). This is the main code repository. It hosts Istio's\ncore components, install artifacts, and sample programs. It includes:\n\n    - [istioctl](istioctl/). This directory contains code for the\n[_istioctl_](https://istio.io/latest/docs/reference/commands/istioctl/) command line utility.\n\n    - [pilot](pilot/). This directory\ncontains platform-specific code to populate the\n[abstract service model](https://istio.io/docs/concepts/traffic-management/#pilot), dynamically reconfigure the proxies\nwhen the application topology changes, as well as translate\n[routing rules](https://istio.io/latest/docs/reference/config/networking/) into proxy specific configuration.\n\n    - [security](security/). This directory contains [security](https://istio.io/latest/docs/concepts/security/) related code.\n\n- [istio/proxy](https://github.com/istio/proxy). The Istio proxy contains\nextensions to the [Envoy proxy](https://github.com/envoyproxy/envoy) (in the form of\nEnvoy filters) that support authentication, authorization, and telemetry collection.\n\n- [istio/ztunnel](https://github.com/istio/ztunnel). The repository contains the Rust implementation of the ztunnel\ncomponent of Ambient mesh.\n\n- [istio/client-go](https://github.com/istio/client-go). This repository defines\n  auto-generated Kubernetes clients for interacting with Istio resources programmatically.\n\n> [!NOTE]\n> Only the `istio/api` and `istio/client-go` repositories expose stable interfaces intended for direct usage as libraries.\n\n## Issue management\n\nWe use GitHub to track all of our bugs and feature requests. Each issue we track has a variety of metadata:\n\n- **Epic**. An epic represents a feature area for Istio as a whole. Epics are fairly broad in scope and are basically product-level things.\nEach issue is ultimately part of an epic.\n\n- **Milestone**. Each issue is assigned a milestone. This is 0.1, 0.2, ..., or 'Nebulous Future'. The milestone indicates when we\nthink the issue should get addressed.\n\n- **Priority**. Each issue has a priority which is represented by the column in the [Prioritization](https://github.com/orgs/istio/projects/6) project. Priority can be one of\nP0, P1, P2, or >P2. The priority indicates how important it is to address the issue within the milestone. P0 says that the\nmilestone cannot be considered achieved if the issue isn't resolved.\n\n---\n\n<div align=\"center\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/color/cncf-color.svg\">\n      <img width=\"300\" alt=\"Cloud Native Computing Foundation logo\" src=\"https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg\">\n    </picture>\n    <p>Istio is a <a href=\"https://cncf.io\">Cloud Native Computing Foundation</a> project.</p>\n</div>\n",
      "stars_today": 9
    },
    {
      "id": 15045751,
      "name": "compose",
      "full_name": "docker/compose",
      "description": "Define and run multi-container applications with Docker",
      "html_url": "https://github.com/docker/compose",
      "stars": 36829,
      "forks": 5703,
      "language": "Go",
      "topics": [
        "docker",
        "docker-compose",
        "go",
        "golang",
        "orchestration"
      ],
      "created_at": "2013-12-09T11:40:58Z",
      "updated_at": "2026-01-16T23:49:21Z",
      "pushed_at": "2026-01-15T18:45:50Z",
      "open_issues": 54,
      "owner": {
        "login": "docker",
        "avatar_url": "https://avatars.githubusercontent.com/u/5429470?v=4"
      },
      "readme": "# Table of Contents\n- [Docker Compose](#docker-compose)\n- [Where to get Docker Compose](#where-to-get-docker-compose)\n    + [Windows and macOS](#windows-and-macos)\n    + [Linux](#linux)\n- [Quick Start](#quick-start)\n- [Contributing](#contributing)\n- [Legacy](#legacy)\n\n# Docker Compose\n\n[![GitHub release](https://img.shields.io/github/v/release/docker/compose.svg?style=flat-square)](https://github.com/docker/compose/releases/latest)\n[![PkgGoDev](https://img.shields.io/badge/go.dev-docs-007d9c?style=flat-square&logo=go&logoColor=white)](https://pkg.go.dev/github.com/docker/compose/v5)\n[![Build Status](https://img.shields.io/github/actions/workflow/status/docker/compose/ci.yml?label=ci&logo=github&style=flat-square)](https://github.com/docker/compose/actions?query=workflow%3Aci)\n[![Go Report Card](https://goreportcard.com/badge/github.com/docker/compose/v5?style=flat-square)](https://goreportcard.com/report/github.com/docker/compose/v5)\n[![Codecov](https://codecov.io/gh/docker/compose/branch/main/graph/badge.svg?token=HP3K4Y4ctu)](https://codecov.io/gh/docker/compose)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/docker/compose/badge)](https://api.securityscorecards.dev/projects/github.com/docker/compose)\n![Docker Compose](logo.png?raw=true \"Docker Compose Logo\")\n\nDocker Compose is a tool for running multi-container applications on Docker\ndefined using the [Compose file format](https://compose-spec.io).\nA Compose file is used to define how one or more containers that make up\nyour application are configured.\nOnce you have a Compose file, you can create and start your application with a\nsingle command: `docker compose up`.\n\n> **Note**: About Docker Swarm\n> Docker Swarm used to rely on the legacy compose file format but did not adopt the compose specification\n> so is missing some of the recent enhancements in the compose syntax. After \n> [acquisition by Mirantis](https://www.mirantis.com/software/swarm/) swarm isn't maintained by Docker Inc, and\n> as such some Docker Compose features aren't accessible to swarm users.\n\n# Where to get Docker Compose\n\n### Windows and macOS\n\nDocker Compose is included in\n[Docker Desktop](https://www.docker.com/products/docker-desktop/)\nfor Windows and macOS.\n\n### Linux\n\nYou can download Docker Compose binaries from the\n[release page](https://github.com/docker/compose/releases) on this repository.\n\nRename the relevant binary for your OS to `docker-compose` and copy it to `$HOME/.docker/cli-plugins`\n\nOr copy it into one of these folders to install it system-wide:\n\n* `/usr/local/lib/docker/cli-plugins` OR `/usr/local/libexec/docker/cli-plugins`\n* `/usr/lib/docker/cli-plugins` OR `/usr/libexec/docker/cli-plugins`\n\n(might require making the downloaded file executable with `chmod +x`)\n\n\nQuick Start\n-----------\n\nUsing Docker Compose is a three-step process:\n1. Define your app's environment with a `Dockerfile` so it can be\n   reproduced anywhere.\n2. Define the services that make up your app in `compose.yaml` so\n   they can be run together in an isolated environment.\n3. Lastly, run `docker compose up` and Compose will start and run your entire\n   app.\n\nA Compose file looks like this:\n\n```yaml\nservices:\n  web:\n    build: .\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - .:/code\n  redis:\n    image: redis\n```\n\nContributing\n------------\n\nWant to help develop Docker Compose? Check out our\n[contributing documentation](CONTRIBUTING.md).\n\nIf you find an issue, please report it on the\n[issue tracker](https://github.com/docker/compose/issues/new/choose).\n\nLegacy\n-------------\n\nThe Python version of Compose is available under the `v1` [branch](https://github.com/docker/compose/tree/v1).\n",
      "stars_today": 9
    },
    {
      "id": 26038648,
      "name": "spdlog",
      "full_name": "gabime/spdlog",
      "description": "Fast C++ logging library.",
      "html_url": "https://github.com/gabime/spdlog",
      "stars": 28127,
      "forks": 5026,
      "language": "C++",
      "topics": [
        "cpp",
        "cpp11",
        "header-only",
        "logging",
        "spdlog"
      ],
      "created_at": "2014-11-01T01:28:53Z",
      "updated_at": "2026-01-16T21:22:06Z",
      "pushed_at": "2026-01-15T20:54:28Z",
      "open_issues": 51,
      "owner": {
        "login": "gabime",
        "avatar_url": "https://avatars.githubusercontent.com/u/6052198?v=4"
      },
      "readme": "# spdlog\r\n\r\n \r\n[![ci](https://github.com/gabime/spdlog/actions/workflows/linux.yml/badge.svg)](https://github.com/gabime/spdlog/actions/workflows/linux.yml)&nbsp;\r\n[![ci](https://github.com/gabime/spdlog/actions/workflows/windows.yml/badge.svg)](https://github.com/gabime/spdlog/actions/workflows/windows.yml)&nbsp;\r\n[![ci](https://github.com/gabime/spdlog/actions/workflows/macos.yml/badge.svg)](https://github.com/gabime/spdlog/actions/workflows/macos.yml)&nbsp;\r\n[![Build status](https://ci.appveyor.com/api/projects/status/d2jnxclg20vd0o50?svg=true&branch=v1.x)](https://ci.appveyor.com/project/gabime/spdlog) [![Release](https://img.shields.io/github/release/gabime/spdlog.svg)](https://github.com/gabime/spdlog/releases/latest)\r\n\r\nFast C++ logging library\r\n\r\n\r\n## Install\r\n#### Header-only version\r\nCopy the include [folder](include/spdlog) to your build tree and use a C++11 compiler.\r\n\r\n#### Compiled version (recommended - much faster compile times)\r\n```console\r\n$ git clone https://github.com/gabime/spdlog.git\r\n$ cd spdlog && mkdir build && cd build\r\n$ cmake .. && cmake --build .\r\n```\r\nsee example [CMakeLists.txt](example/CMakeLists.txt) on how to use.\r\n\r\n## Platforms\r\n* Linux, FreeBSD, OpenBSD, Solaris, AIX\r\n* Windows (msvc 2013+, cygwin)\r\n* macOS (clang 3.5+)\r\n* Android\r\n\r\n## Package managers:\r\n* Debian: `sudo apt install libspdlog-dev`\r\n* Homebrew: `brew install spdlog`\r\n* MacPorts: `sudo port install spdlog`\r\n* FreeBSD:  `pkg install spdlog`\r\n* Fedora: `dnf install spdlog`\r\n* Gentoo: `emerge dev-libs/spdlog`\r\n* Arch Linux: `pacman -S spdlog`\r\n* openSUSE: `sudo zypper in spdlog-devel`\r\n* ALT Linux: `apt-get install libspdlog-devel`\r\n* vcpkg: `vcpkg install spdlog`\r\n* conan: `conan install --requires=spdlog/[*]`\r\n* conda: `conda install -c conda-forge spdlog`\r\n* build2: ```depends: spdlog ^1.8.2```\r\n\r\n\r\n## Features\r\n* Very fast (see [benchmarks](#benchmarks) below).\r\n* Headers only or compiled\r\n* Feature-rich formatting, using the excellent [fmt](https://github.com/fmtlib/fmt) library.\r\n* Asynchronous mode (optional)\r\n* [Custom](https://github.com/gabime/spdlog/wiki/Custom-formatting) formatting.\r\n* Multi/Single threaded loggers.\r\n* Various log targets:\r\n  * Rotating log files.\r\n  * Daily log files.\r\n  * Console logging (colors supported).\r\n  * syslog.\r\n  * Windows event log.\r\n  * Windows debugger (```OutputDebugString(..)```).\r\n  * Log to Qt widgets ([example](#log-to-qt-with-nice-colors)).\r\n  * Easily [extendable](https://github.com/gabime/spdlog/wiki/Sinks#implementing-your-own-sink) with custom log targets.\r\n* Log filtering - log levels can be modified at runtime as well as compile time.\r\n* Support for loading log levels from argv or environment var.\r\n* [Backtrace](#backtrace-support) support - store debug messages in a ring buffer and display them later on demand.\r\n\r\n## Usage samples\r\n\r\n#### Basic usage\r\n```c++\r\n#include \"spdlog/spdlog.h\"\r\n\r\nint main() \r\n{\r\n    spdlog::info(\"Welcome to spdlog!\");\r\n    spdlog::error(\"Some error message with arg: {}\", 1);\r\n    \r\n    spdlog::warn(\"Easy padding in numbers like {:08d}\", 12);\r\n    spdlog::critical(\"Support for int: {0:d};  hex: {0:x};  oct: {0:o}; bin: {0:b}\", 42);\r\n    spdlog::info(\"Support for floats {:03.2f}\", 1.23456);\r\n    spdlog::info(\"Positional args are {1} {0}..\", \"too\", \"supported\");\r\n    spdlog::info(\"{:<30}\", \"left aligned\");\r\n    \r\n    spdlog::set_level(spdlog::level::debug); // Set *global* log level to debug\r\n    spdlog::debug(\"This message should be displayed..\");    \r\n    \r\n    // change log pattern\r\n    spdlog::set_pattern(\"[%H:%M:%S %z] [%n] [%^---%L---%$] [thread %t] %v\");\r\n    \r\n    // Compile time log levels\r\n    // Note that this does not change the current log level, it will only\r\n    // remove (depending on SPDLOG_ACTIVE_LEVEL) the call on the release code.\r\n    SPDLOG_TRACE(\"Some trace message with param {}\", 42);\r\n    SPDLOG_DEBUG(\"Some debug message\");\r\n}\r\n\r\n```\r\n---\r\n#### Create stdout/stderr logger object\r\n```c++\r\n#include \"spdlog/spdlog.h\"\r\n#include \"spdlog/sinks/stdout_color_sinks.h\"\r\nvoid stdout_example()\r\n{\r\n    // create a color multi-threaded logger\r\n    auto console = spdlog::stdout_color_mt(\"console\");    \r\n    auto err_logger = spdlog::stderr_color_mt(\"stderr\");    \r\n    spdlog::get(\"console\")->info(\"loggers can be retrieved from a global registry using the spdlog::get(logger_name)\");\r\n}\r\n```\r\n\r\n---\r\n#### Basic file logger\r\n```c++\r\n#include \"spdlog/sinks/basic_file_sink.h\"\r\nvoid basic_logfile_example()\r\n{\r\n    try \r\n    {\r\n        auto logger = spdlog::basic_logger_mt(\"basic_logger\", \"logs/basic-log.txt\");\r\n    }\r\n    catch (const spdlog::spdlog_ex &ex)\r\n    {\r\n        std::cout << \"Log init failed: \" << ex.what() << std::endl;\r\n    }\r\n}\r\n```\r\n---\r\n#### Rotating files\r\n```c++\r\n#include \"spdlog/sinks/rotating_file_sink.h\"\r\nvoid rotating_example()\r\n{\r\n    // Create a file rotating logger with 5 MB size max and 3 rotated files\r\n    auto max_size = 1048576 * 5;\r\n    auto max_files = 3;\r\n    auto logger = spdlog::rotating_logger_mt(\"some_logger_name\", \"logs/rotating.txt\", max_size, max_files);\r\n}\r\n```\r\n\r\n---\r\n#### Daily files\r\n```c++\r\n\r\n#include \"spdlog/sinks/daily_file_sink.h\"\r\nvoid daily_example()\r\n{\r\n    // Create a daily logger - a new file is created every day at 2:30 am\r\n    auto logger = spdlog::daily_logger_mt(\"daily_logger\", \"logs/daily.txt\", 2, 30);\r\n}\r\n\r\n```\r\n\r\n---\r\n#### Backtrace support\r\n```c++\r\n// Debug messages can be stored in a ring buffer instead of being logged immediately.\r\n// This is useful to display debug logs only when needed (e.g. when an error happens).\r\n// When needed, call dump_backtrace() to dump them to your log.\r\n\r\nspdlog::enable_backtrace(32); // Store the latest 32 messages in a buffer. \r\n// or my_logger->enable_backtrace(32)..\r\nfor(int i = 0; i < 100; i++)\r\n{\r\n  spdlog::debug(\"Backtrace message {}\", i); // not logged yet..\r\n}\r\n// e.g. if some error happened:\r\nspdlog::dump_backtrace(); // log them now! show the last 32 messages\r\n// or my_logger->dump_backtrace(32)..\r\n```\r\n\r\n---\r\n#### Periodic flush\r\n```c++\r\n// periodically flush all *registered* loggers every 3 seconds:\r\n// warning: only use if all your loggers are thread-safe (\"_mt\" loggers)\r\nspdlog::flush_every(std::chrono::seconds(3));\r\n\r\n```\r\n\r\n---\r\n#### Stopwatch\r\n```c++\r\n// Stopwatch support for spdlog\r\n#include \"spdlog/stopwatch.h\"\r\nvoid stopwatch_example()\r\n{\r\n    spdlog::stopwatch sw;    \r\n    spdlog::debug(\"Elapsed {}\", sw);\r\n    spdlog::debug(\"Elapsed {:.3}\", sw);       \r\n}\r\n\r\n```\r\n\r\n---\r\n#### Log binary data in hex\r\n```c++\r\n// many types of std::container<char> types can be used.\r\n// ranges are supported too.\r\n// format flags:\r\n// {:X} - print in uppercase.\r\n// {:s} - don't separate each byte with space.\r\n// {:p} - don't print the position on each line start.\r\n// {:n} - don't split the output into lines.\r\n// {:a} - show ASCII if :n is not set.\r\n\r\n#include \"spdlog/fmt/bin_to_hex.h\"\r\n\r\nvoid binary_example()\r\n{\r\n    auto console = spdlog::get(\"console\");\r\n    std::array<char, 80> buf;\r\n    console->info(\"Binary example: {}\", spdlog::to_hex(buf));\r\n    console->info(\"Another binary example:{:n}\", spdlog::to_hex(std::begin(buf), std::begin(buf) + 10));\r\n    // more examples:\r\n    // logger->info(\"uppercase: {:X}\", spdlog::to_hex(buf));\r\n    // logger->info(\"uppercase, no delimiters: {:Xs}\", spdlog::to_hex(buf));\r\n    // logger->info(\"uppercase, no delimiters, no position info: {:Xsp}\", spdlog::to_hex(buf));\r\n}\r\n\r\n```\r\n\r\n---\r\n#### Logger with multi sinks - each with a different format and log level\r\n```c++\r\n\r\n// create a logger with 2 targets, with different log levels and formats.\r\n// The console will show only warnings or errors, while the file will log all. \r\nvoid multi_sink_example()\r\n{\r\n    auto console_sink = std::make_shared<spdlog::sinks::stdout_color_sink_mt>();\r\n    console_sink->set_level(spdlog::level::warn);\r\n    console_sink->set_pattern(\"[multi_sink_example] [%^%l%$] %v\");\r\n\r\n    auto file_sink = std::make_shared<spdlog::sinks::basic_file_sink_mt>(\"logs/multisink.txt\", true);\r\n    file_sink->set_level(spdlog::level::trace);\r\n\r\n    spdlog::logger logger(\"multi_sink\", {console_sink, file_sink});\r\n    logger.set_level(spdlog::level::debug);\r\n    logger.warn(\"this should appear in both console and file\");\r\n    logger.info(\"this message should not appear in the console, only in the file\");\r\n}\r\n```\r\n\r\n---\r\n#### Register several loggers - change global level\r\n```c++\r\n\r\n// Creation of loggers. Set levels to all registered loggers. \r\nvoid set_level_example()\r\n{\r\n    auto logger1 = spdlog::basic_logger_mt(\"logger1\", \"logs/logger1.txt\");\r\n    auto logger2 = spdlog::basic_logger_mt(\"logger2\", \"logs/logger2.txt\");\r\n\r\n    spdlog::set_default_logger(logger2);\r\n    spdlog::default_logger()->set_level(spdlog::level::trace); // set level for the default logger (logger2) to trace\r\n\r\n    spdlog::trace(\"trace message to the logger2 (specified as default)\");\r\n\r\n    spdlog::set_level(spdlog::level::off) // (sic!) set level for *all* registered loggers to off (disable)\r\n  \r\n    logger1.warn(\"warn message will not appear because the level set to off\");\r\n    logger2.warn(\"warn message will not appear because the level set to off\");\r\n    spdlog::warn(\"warn message will not appear because the level set to off\");\r\n}\r\n```\r\n\r\n---\r\n#### User-defined callbacks about log events\r\n```c++\r\n\r\n// create a logger with a lambda function callback, the callback will be called\r\n// each time something is logged to the logger\r\nvoid callback_example()\r\n{\r\n    auto callback_sink = std::make_shared<spdlog::sinks::callback_sink_mt>([](const spdlog::details::log_msg &msg) {\r\n         // for example you can be notified by sending an email to yourself\r\n    });\r\n    callback_sink->set_level(spdlog::level::err);\r\n\r\n    auto console_sink = std::make_shared<spdlog::sinks::stdout_color_sink_mt>();\r\n    spdlog::logger logger(\"custom_callback_logger\", {console_sink, callback_sink});\r\n\r\n    logger.info(\"some info log\");\r\n    logger.error(\"critical issue\"); // will notify you\r\n}\r\n```\r\n\r\n---\r\n#### Asynchronous logging\r\n```c++\r\n#include \"spdlog/async.h\"\r\n#include \"spdlog/sinks/basic_file_sink.h\"\r\nvoid async_example()\r\n{\r\n    // default thread pool settings can be modified *before* creating the async logger:\r\n    // spdlog::init_thread_pool(8192, 1); // queue with 8k items and 1 backing thread.\r\n    auto async_file = spdlog::basic_logger_mt<spdlog::async_factory>(\"async_file_logger\", \"logs/async_log.txt\");\r\n    // alternatively:\r\n    // auto async_file = spdlog::create_async<spdlog::sinks::basic_file_sink_mt>(\"async_file_logger\", \"logs/async_log.txt\");   \r\n}\r\n\r\n```\r\n\r\n---\r\n#### Asynchronous logger with multi sinks\r\n```c++\r\n#include \"spdlog/async.h\"\r\n#include \"spdlog/sinks/stdout_color_sinks.h\"\r\n#include \"spdlog/sinks/rotating_file_sink.h\"\r\n\r\nvoid multi_sink_example2()\r\n{\r\n    spdlog::init_thread_pool(8192, 1);\r\n    auto stdout_sink = std::make_shared<spdlog::sinks::stdout_color_sink_mt >();\r\n    auto rotating_sink = std::make_shared<spdlog::sinks::rotating_file_sink_mt>(\"mylog.txt\", 1024*1024*10, 3);\r\n    std::vector<spdlog::sink_ptr> sinks {stdout_sink, rotating_sink};\r\n    auto logger = std::make_shared<spdlog::async_logger>(\"loggername\", sinks.begin(), sinks.end(), spdlog::thread_pool(), spdlog::async_overflow_policy::block);\r\n    spdlog::register_logger(logger);\r\n}\r\n```\r\n \r\n---\r\n#### User-defined types\r\n```c++\r\ntemplate<>\r\nstruct fmt::formatter<my_type> : fmt::formatter<std::string>\r\n{\r\n    auto format(my_type my, format_context &ctx) const -> decltype(ctx.out())\r\n    {\r\n        return fmt::format_to(ctx.out(), \"[my_type i={}]\", my.i);\r\n    }\r\n};\r\n\r\nvoid user_defined_example()\r\n{\r\n    spdlog::info(\"user defined type: {}\", my_type(14));\r\n}\r\n\r\n```\r\n\r\n---\r\n#### User-defined flags in the log pattern\r\n```c++ \r\n// Log patterns can contain custom flags.\r\n// the following example will add new flag '%*' - which will be bound to a <my_formatter_flag> instance.\r\n#include \"spdlog/pattern_formatter.h\"\r\nclass my_formatter_flag : public spdlog::custom_flag_formatter\r\n{\r\npublic:\r\n    void format(const spdlog::details::log_msg &, const std::tm &, spdlog::memory_buf_t &dest) override\r\n    {\r\n        std::string some_txt = \"custom-flag\";\r\n        dest.append(some_txt.data(), some_txt.data() + some_txt.size());\r\n    }\r\n\r\n    std::unique_ptr<custom_flag_formatter> clone() const override\r\n    {\r\n        return spdlog::details::make_unique<my_formatter_flag>();\r\n    }\r\n};\r\n\r\nvoid custom_flags_example()\r\n{    \r\n    auto formatter = std::make_unique<spdlog::pattern_formatter>();\r\n    formatter->add_flag<my_formatter_flag>('*').set_pattern(\"[%n] [%*] [%^%l%$] %v\");\r\n    spdlog::set_formatter(std::move(formatter));\r\n}\r\n\r\n```\r\n\r\n---\r\n#### Custom error handler\r\n```c++\r\nvoid err_handler_example()\r\n{\r\n    // can be set globally or per logger(logger->set_error_handler(..))\r\n    spdlog::set_error_handler([](const std::string &msg) { spdlog::get(\"console\")->error(\"*** LOGGER ERROR ***: {}\", msg); });\r\n    spdlog::get(\"console\")->info(\"some invalid message to trigger an error {}{}{}{}\", 3);\r\n}\r\n\r\n```\r\n\r\n---\r\n#### syslog\r\n```c++\r\n#include \"spdlog/sinks/syslog_sink.h\"\r\nvoid syslog_example()\r\n{\r\n    std::string ident = \"spdlog-example\";\r\n    auto syslog_logger = spdlog::syslog_logger_mt(\"syslog\", ident, LOG_PID);\r\n    syslog_logger->warn(\"This is warning that will end up in syslog.\");\r\n}\r\n```\r\n---\r\n#### Android example\r\n```c++\r\n#include \"spdlog/sinks/android_sink.h\"\r\nvoid android_example()\r\n{\r\n    std::string tag = \"spdlog-android\";\r\n    auto android_logger = spdlog::android_logger_mt(\"android\", tag);\r\n    android_logger->critical(\"Use \\\"adb shell logcat\\\" to view this message.\");\r\n}\r\n```\r\n\r\n---\r\n#### Load log levels from the env variable or argv\r\n\r\n```c++\r\n#include \"spdlog/cfg/env.h\"\r\nint main (int argc, char *argv[])\r\n{\r\n    spdlog::cfg::load_env_levels();\r\n    // or specify the env variable name:\r\n    // MYAPP_LEVEL=info,mylogger=trace && ./example\r\n    // spdlog::cfg::load_env_levels(\"MYAPP_LEVEL\");\r\n    // or from the command line:\r\n    // ./example SPDLOG_LEVEL=info,mylogger=trace\r\n    // #include \"spdlog/cfg/argv.h\" // for loading levels from argv\r\n    // spdlog::cfg::load_argv_levels(argc, argv);\r\n}\r\n```\r\nSo then you can:\r\n\r\n```console\r\n$ export SPDLOG_LEVEL=info,mylogger=trace\r\n$ ./example\r\n```\r\n\r\n\r\n---\r\n#### Log file open/close event handlers\r\n```c++\r\n// You can get callbacks from spdlog before/after a log file has been opened or closed. \r\n// This is useful for cleanup procedures or for adding something to the start/end of the log file.\r\nvoid file_events_example()\r\n{\r\n    // pass the spdlog::file_event_handlers to file sinks for open/close log file notifications\r\n    spdlog::file_event_handlers handlers;\r\n    handlers.before_open = [](spdlog::filename_t filename) { spdlog::info(\"Before opening {}\", filename); };\r\n    handlers.after_open = [](spdlog::filename_t filename, std::FILE *fstream) { fputs(\"After opening\\n\", fstream); };\r\n    handlers.before_close = [](spdlog::filename_t filename, std::FILE *fstream) { fputs(\"Before closing\\n\", fstream); };\r\n    handlers.after_close = [](spdlog::filename_t filename) { spdlog::info(\"After closing {}\", filename); };\r\n    auto my_logger = spdlog::basic_logger_st(\"some_logger\", \"logs/events-sample.txt\", true, handlers);        \r\n}\r\n```\r\n\r\n---\r\n#### Replace the Default Logger\r\n```c++\r\nvoid replace_default_logger_example()\r\n{\r\n    auto new_logger = spdlog::basic_logger_mt(\"new_default_logger\", \"logs/new-default-log.txt\", true);\r\n    spdlog::set_default_logger(new_logger);\r\n    spdlog::info(\"new logger log message\");\r\n}\r\n```\r\n\r\n---\r\n#### Log to Qt with nice colors\r\n```c++\r\n#include \"spdlog/spdlog.h\"\r\n#include \"spdlog/sinks/qt_sinks.h\"\r\nMainWindow::MainWindow(QWidget *parent) : QMainWindow(parent)\r\n{\r\n    setMinimumSize(640, 480);\r\n    auto log_widget = new QTextEdit(this);\r\n    setCentralWidget(log_widget);\r\n    int max_lines = 500; // keep the text widget to max 500 lines. remove old lines if needed.\r\n    auto logger = spdlog::qt_color_logger_mt(\"qt_logger\", log_widget, max_lines);\r\n    logger->info(\"Some info message\");\r\n}\r\n```\r\n---\r\n\r\n#### Mapped Diagnostic Context\r\n```c++\r\n// Mapped Diagnostic Context (MDC) is a map that stores key-value pairs (string values) in thread local storage.\r\n// Each thread maintains its own MDC, which loggers use to append diagnostic information to log outputs.\r\n// Note: it is not supported in asynchronous mode due to its reliance on thread-local storage.\r\n#include \"spdlog/mdc.h\"\r\nvoid mdc_example()\r\n{\r\n    spdlog::mdc::put(\"key1\", \"value1\");\r\n    spdlog::mdc::put(\"key2\", \"value2\");\r\n    // if not using the default format, use the %& formatter to print mdc data\r\n    // spdlog::set_pattern(\"[%H:%M:%S %z] [%^%L%$] [%&] %v\");\r\n}\r\n```\r\n---\r\n## Benchmarks\r\n\r\nBelow are some [benchmarks](bench/bench.cpp) done in Ubuntu 64 bit, Intel i7-4770 CPU @ 3.40GHz\r\n\r\n#### Synchronous mode\r\n```\r\n[info] **************************************************************\r\n[info] Single thread, 1,000,000 iterations\r\n[info] **************************************************************\r\n[info] basic_st         Elapsed: 0.17 secs        5,777,626/sec\r\n[info] rotating_st      Elapsed: 0.18 secs        5,475,894/sec\r\n[info] daily_st         Elapsed: 0.20 secs        5,062,659/sec\r\n[info] empty_logger     Elapsed: 0.07 secs       14,127,300/sec\r\n[info] **************************************************************\r\n[info] C-string (400 bytes). Single thread, 1,000,000 iterations\r\n[info] **************************************************************\r\n[info] basic_st         Elapsed: 0.41 secs        2,412,483/sec\r\n[info] rotating_st      Elapsed: 0.72 secs        1,389,196/sec\r\n[info] daily_st         Elapsed: 0.42 secs        2,393,298/sec\r\n[info] null_st          Elapsed: 0.04 secs       27,446,957/sec\r\n[info] **************************************************************\r\n[info] 10 threads, competing over the same logger object, 1,000,000 iterations\r\n[info] **************************************************************\r\n[info] basic_mt         Elapsed: 0.60 secs        1,659,613/sec\r\n[info] rotating_mt      Elapsed: 0.62 secs        1,612,493/sec\r\n[info] daily_mt         Elapsed: 0.61 secs        1,638,305/sec\r\n[info] null_mt          Elapsed: 0.16 secs        6,272,758/sec\r\n```\r\n#### Asynchronous mode\r\n```\r\n[info] -------------------------------------------------\r\n[info] Messages     : 1,000,000\r\n[info] Threads      : 10\r\n[info] Queue        : 8,192 slots\r\n[info] Queue memory : 8,192 x 272 = 2,176 KB \r\n[info] -------------------------------------------------\r\n[info] \r\n[info] *********************************\r\n[info] Queue Overflow Policy: block\r\n[info] *********************************\r\n[info] Elapsed: 1.70784 secs     585,535/sec\r\n[info] Elapsed: 1.69805 secs     588,910/sec\r\n[info] Elapsed: 1.7026 secs      587,337/sec\r\n[info] \r\n[info] *********************************\r\n[info] Queue Overflow Policy: overrun\r\n[info] *********************************\r\n[info] Elapsed: 0.372816 secs    2,682,285/sec\r\n[info] Elapsed: 0.379758 secs    2,633,255/sec\r\n[info] Elapsed: 0.373532 secs    2,677,147/sec\r\n\r\n```\r\n\r\n## Documentation\r\n\r\nDocumentation can be found in the [wiki](https://github.com/gabime/spdlog/wiki) pages.\r\n\r\n---\r\n\r\n### Powered by\r\n<a href=\"https://jb.gg/OpenSource\">\r\n  <img src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg\" alt=\"JetBrains logo\" width=\"200\">\r\n</a>\r\n",
      "stars_today": 9
    },
    {
      "id": 129717717,
      "name": "loki",
      "full_name": "grafana/loki",
      "description": "Like Prometheus, but for logs.",
      "html_url": "https://github.com/grafana/loki",
      "stars": 27395,
      "forks": 3895,
      "language": "Go",
      "topics": [
        "cloudnative",
        "grafana",
        "hacktoberfest",
        "logging",
        "loki",
        "prometheus"
      ],
      "created_at": "2018-04-16T09:22:48Z",
      "updated_at": "2026-01-16T23:24:37Z",
      "pushed_at": "2026-01-17T00:58:33Z",
      "open_issues": 2200,
      "owner": {
        "login": "grafana",
        "avatar_url": "https://avatars.githubusercontent.com/u/7195757?v=4"
      },
      "readme": "<p align=\"center\"><img src=\"docs/sources/logo_and_name.png\" alt=\"Loki Logo\"></p>\n\n<a href=\"https://github.com/grafana/loki/actions/workflows/check.yml\"><img src=\"https://github.com/grafana/loki/actions/workflows/check.yml/badge.svg\" alt=\"Check\" /></a>\n<a href=\"https://goreportcard.com/report/github.com/grafana/loki\"><img src=\"https://goreportcard.com/badge/github.com/grafana/loki\" alt=\"Go Report Card\" /></a>\n<a href=\"https://slack.grafana.com/\"><img src=\"https://img.shields.io/badge/join%20slack-%23loki-brightgreen.svg\" alt=\"Slack\" /></a>\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/loki.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:loki)\n\n# Loki: like Prometheus, but for logs.\n\nLoki is a horizontally-scalable, highly-available, multi-tenant log aggregation system inspired by [Prometheus](https://prometheus.io/).\nIt is designed to be very cost effective and easy to operate.\nIt does not index the contents of the logs, but rather a set of labels for each log stream.\n\nCompared to other log aggregation systems, Loki:\n\n- does not do full text indexing on logs. By storing compressed, unstructured logs and only indexing metadata, Loki is simpler to operate and cheaper to run.\n- indexes and groups log streams using the same labels you‚Äôre already using with Prometheus, enabling you to seamlessly switch between metrics and logs using the same labels that you‚Äôre already using with Prometheus.\n- is an especially good fit for storing [Kubernetes](https://kubernetes.io/) Pod logs. Metadata such as Pod labels is automatically scraped and indexed.\n- has native support in Grafana (needs Grafana v6.0).\n\nA Loki-based logging stack consists of 3 components:\n\n- [Alloy](https://github.com/grafana/alloy) is agent, responsible for gathering logs and sending them to Loki.\n- [Loki](https://github.com/grafana/loki) is the main service, responsible for storing logs and processing queries.\n- [Grafana](https://github.com/grafana/grafana) for querying and displaying the logs.\n\n**Note that Alloy replaced Promtail in the stack, because Promtail is considered to be feature complete, and future development for logs collection will be in [Grafana Alloy](https://github.com/grafana/alloy).**\n\nLoki is like Prometheus, but for logs: we prefer a multidimensional label-based approach to indexing, and want a single-binary, easy to operate system with no dependencies.\nLoki differs from Prometheus by focusing on logs instead of metrics, and delivering logs via push, instead of pull.\n\n## Getting started\n\n* [Installing Loki](https://grafana.com/docs/loki/latest/installation/)\n* [Installing Alloy](https://grafana.com/docs/loki/latest/send-data/alloy/)\n* [Getting Started](https://grafana.com/docs/loki/latest/get-started/)\n\n## Upgrading\n\n* [Upgrading Loki](https://grafana.com/docs/loki/latest/upgrading/)\n\n## Documentation\n\n* [Latest release](https://grafana.com/docs/loki/latest/)\n* [Upcoming release](https://grafana.com/docs/loki/next/), at the tip of the main branch\n\nCommonly used sections:\n\n- [API documentation](https://grafana.com/docs/loki/latest/api/) for getting logs into Loki.\n- [Labels](https://grafana.com/docs/loki/latest/getting-started/labels/)\n- [Operations](https://grafana.com/docs/loki/latest/operations/)\n- [Promtail](https://grafana.com/docs/loki/latest/clients/promtail/) is an agent which tails log files and pushes them to Loki.\n- [Pipelines](https://grafana.com/docs/loki/latest/clients/promtail/pipelines/) details the log processing pipeline.\n- [Docker Driver Client](https://grafana.com/docs/loki/latest/clients/docker-driver/) is a Docker plugin to send logs directly to Loki from Docker containers.\n- [LogCLI](https://grafana.com/docs/loki/latest/query/logcli/) provides a command-line interface for querying logs.\n- [Loki Canary](https://grafana.com/docs/loki/latest/operations/loki-canary/) monitors your Loki installation for missing logs.\n- [Troubleshooting](https://grafana.com/docs/loki/latest/operations/troubleshooting/) presents help dealing with error messages.\n- [Loki in Grafana](https://grafana.com/docs/loki/latest/operations/grafana/) describes how to set up a Loki datasource in Grafana.\n\n## Getting Help\n\nIf you have any questions or feedback regarding Loki:\n\n- Search existing thread in the Grafana Labs community forum for Loki: [https://community.grafana.com](https://community.grafana.com/c/grafana-loki/)\n- Ask a question on the Loki Slack channel. To invite yourself to the Grafana Slack, visit [https://slack.grafana.com/](https://slack.grafana.com/) and join the #loki channel.\n- [File an issue](https://github.com/grafana/loki/issues/new) for bugs, issues and feature suggestions.\n- Send an email to [lokiproject@googlegroups.com](mailto:lokiproject@googlegroups.com), or use the [web interface](https://groups.google.com/forum/#!forum/lokiproject).\n- UI issues should be filed directly in [Grafana](https://github.com/grafana/grafana/issues/new).\n\nYour feedback is always welcome.\n\n## Further Reading\n\n- The original [design doc](https://docs.google.com/document/d/11tjK_lvp1-SVsFZjgOTr1vV3-q6vBAsZYIQ5ZeYBkyM/view) for Loki is a good source for discussion of the motivation and design decisions.\n- Callum Styan's March 2019 DevOpsDays Vancouver talk \"[Grafana Loki: Log Aggregation for Incident Investigations][devopsdays19-talk]\".\n- Grafana Labs blog post \"[How We Designed Loki to Work Easily Both as Microservices and as Monoliths][architecture-blog]\".\n- Tom Wilkie's early-2019 CNCF Paris/FOSDEM talk \"[Grafana Loki: like Prometheus, but for logs][fosdem19-talk]\" ([slides][fosdem19-slides], [video][fosdem19-video]).\n- David Kaltschmidt's KubeCon 2018 talk \"[On the OSS Path to Full Observability with Grafana][kccna18-event]\" ([slides][kccna18-slides], [video][kccna18-video]) on how Loki fits into a cloud-native environment.\n- Goutham Veeramachaneni's blog post \"[Loki: Prometheus-inspired, open source logging for cloud natives](https://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/)\" on details of the Loki architecture.\n- David Kaltschmidt's blog post \"[Closer look at Grafana's user interface for Loki](https://grafana.com/blog/2019/01/02/closer-look-at-grafanas-user-interface-for-loki/)\" on the ideas that went into the logging user interface.\n\n[devopsdays19-talk]: https://grafana.com/blog/2019/05/06/how-loki-correlates-metrics-and-logs-and-saves-you-money/\n[architecture-blog]: https://grafana.com/blog/2019/04/15/how-we-designed-loki-to-work-easily-both-as-microservices-and-as-monoliths/\n[fosdem19-talk]: https://fosdem.org/2019/schedule/event/loki_prometheus_for_logs/\n[fosdem19-slides]: https://speakerdeck.com/grafana/grafana-loki-like-prometheus-but-for-logs\n[fosdem19-video]: https://mirror.as35701.net/video.fosdem.org/2019/UB2.252A/loki_prometheus_for_logs.mp4\n[kccna18-event]: https://kccna18.sched.com/event/GrXC/on-the-oss-path-to-full-observability-with-grafana-david-kaltschmidt-grafana-labs\n[kccna18-slides]: https://speakerdeck.com/davkal/on-the-path-to-full-observability-with-oss-and-launch-of-loki\n[kccna18-video]: https://www.youtube.com/watch?v=U7C5SpRtK74&list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU&index=346\n\n## Contributing\n\nRefer to [CONTRIBUTING.md](CONTRIBUTING.md)\n\n### Building from source\n\nLoki can be run in a single host, no-dependencies mode using the following commands.\n\nYou need an up-to-date version of [Go](https://go.dev/), we recommend using the version found in our [Makefile](https://github.com/grafana/loki/blob/main/Makefile)\n\n```bash\n# Checkout source code\n$ git clone https://github.com/grafana/loki\n$ cd loki\n\n# Build binary\n$ go build ./cmd/loki\n\n# Run executable\n$ ./loki -config.file=./cmd/loki/loki-local-config.yaml\n```\n\nAlternatively, on Unix systems you can use `make` to build the binary, which adds additional arguments to the `go build` command.\n\n```bash\n# Build binary\n$ make loki\n\n# Run executable\n$ ./cmd/loki/loki -config.file=./cmd/loki/loki-local-config.yaml\n```\n\nTo build Promtail on non-Linux platforms, use the following command:\n\n```bash\n$ go build ./clients/cmd/promtail\n```\n\nOn Linux, Promtail requires the systemd headers to be installed if\nJournal support is enabled.\nTo enable Journal support the go build tag flag `promtail_journal_enabled` should be passed\n\nWith Journal support on Ubuntu, run with the following commands:\n\n```bash\n$ sudo apt install -y libsystemd-dev\n$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail\n```\n\nWith Journal support on CentOS, run with the following commands:\n\n```bash\n$ sudo yum install -y systemd-devel\n$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail\n```\n\nOtherwise, to build Promtail without Journal support, run `go build`\nwith CGO disabled:\n\n```bash\n$ CGO_ENABLED=0 go build ./clients/cmd/promtail\n```\n\n## Adopters\n\nPlease see [ADOPTERS.md](ADOPTERS.md) for some of the organizations using Loki today.\nIf you would like to add your organization to the list, please open a PR to add it to the list.\n\n## License\n\nGrafana Loki is distributed under [AGPL-3.0-only](LICENSE). For Apache-2.0 exceptions, see [LICENSING.md](LICENSING.md).\n",
      "stars_today": 9
    },
    {
      "id": 47023603,
      "name": "xxl-job",
      "full_name": "xuxueli/xxl-job",
      "description": "A distributed task scheduling framework.ÔºàÂàÜÂ∏ÉÂºè‰ªªÂä°Ë∞ÉÂ∫¶Âπ≥Âè∞XXL-JOBÔºâ",
      "html_url": "https://github.com/xuxueli/xxl-job",
      "stars": 29819,
      "forks": 11436,
      "language": "Java",
      "topics": [
        "cron",
        "distributed",
        "glue",
        "java",
        "job",
        "quartz",
        "restful",
        "schedule",
        "scheduler",
        "task",
        "xxl-job"
      ],
      "created_at": "2015-11-28T12:59:34Z",
      "updated_at": "2026-01-17T00:46:58Z",
      "pushed_at": "2026-01-04T08:44:34Z",
      "open_issues": 237,
      "owner": {
        "login": "xuxueli",
        "avatar_url": "https://avatars.githubusercontent.com/u/10633817?v=4"
      },
      "readme": "<p align=\"center\" >\n    <img src=\"https://www.xuxueli.com/doc/static/xxl-job/images/xxl-logo.jpg\" width=\"150\">\n    <h3 align=\"center\">XXL-JOB</h3>\n    <p align=\"center\">\n        XXL-JOB, a distributed task scheduling framework.\n        <br>\n        <a href=\"https://www.xuxueli.com/xxl-job/\"><strong>-- Home Page --</strong></a>\n        <br>\n        <br>\n        <a href=\"https://github.com/xuxueli/xxl-job/actions\">\n            <img src=\"https://github.com/xuxueli/xxl-job/workflows/Java%20CI/badge.svg\" >\n        </a>\n        <a href=\"https://central.sonatype.com/artifact/com.xuxueli/xxl-job-core\">\n            <img src=\"https://img.shields.io/maven-central/v/com.xuxueli/xxl-job-core\" >\n        </a>\n        <a href=\"https://github.com/xuxueli/xxl-job/releases\">\n         <img src=\"https://img.shields.io/github/release/xuxueli/xxl-job.svg\" >\n        </a>\n        <a href=\"https://github.com/xuxueli/xxl-job/\">\n            <img src=\"https://img.shields.io/github/stars/xuxueli/xxl-job\" >\n        </a>\n        <a href=\"https://hub.docker.com/r/xuxueli/xxl-job-admin/\">\n            <img src=\"https://img.shields.io/docker/pulls/xuxueli/xxl-job-admin\" >\n        </a>\n        <a href=\"http://www.gnu.org/licenses/gpl-3.0.html\">\n         <img src=\"https://img.shields.io/badge/license-GPLv3-blue.svg\" >\n        </a>\n        <a href=\"https://www.xuxueli.com/page/donate.html\">\n           <img src=\"https://img.shields.io/badge/%24-donate-ff69b4.svg?style=flat\" >\n        </a>\n    </p>\n</p>\n\n\n## Introduction\nXXL-JOB is a distributed task scheduling framework. \nIt's core design goal is to develop quickly and learn simple, lightweight, and easy to expand. \nNow, it's already open source, and many companies use it in production environments, real \"out-of-the-box\".\n\nXXL-JOBÊòØ‰∏Ä‰∏™ÂàÜÂ∏ÉÂºè‰ªªÂä°Ë∞ÉÂ∫¶Âπ≥Âè∞ÔºåÂÖ∂Ê†∏ÂøÉËÆæËÆ°ÁõÆÊ†áÊòØÂºÄÂèëËøÖÈÄü„ÄÅÂ≠¶‰π†ÁÆÄÂçï„ÄÅËΩªÈáèÁ∫ß„ÄÅÊòìÊâ©Â±ï„ÄÇÁé∞Â∑≤ÂºÄÊîæÊ∫ê‰ª£Á†ÅÂπ∂Êé•ÂÖ•Â§öÂÆ∂ÂÖ¨Âè∏Á∫ø‰∏ä‰∫ßÂìÅÁ∫øÔºåÂºÄÁÆ±Âç≥Áî®„ÄÇ\n\n\n## Sponsor\nXXL-JOB is an open source and free project, with its ongoing development made possible entirely by the support of these awesome backers.\n\nXXL-JOB ÊòØ‰∏Ä‰∏™ÂºÄÊ∫ê‰∏îÂÖçË¥πÈ°πÁõÆÔºåÂÖ∂Ê≠£Âú®ËøõË°åÁöÑÂºÄÂèëÂÆåÂÖ®ÂæóÁõä‰∫éÊîØÊåÅËÄÖÁöÑÊîØÊåÅ„ÄÇÂºÄÊ∫ê‰∏çÊòìÔºå[ÂâçÂæÄËµûÂä©È°πÁõÆÂºÄÂèë](https://www.xuxueli.com/page/donate.html )\n\n<!-- supporter start -->\n<h3 style=\"color: #E6BE8A;\" >ÈáëÁâåËµûÂä©Êñπ</h3>\n<table>\n<tr>\n    <td>\n        <a href=\"https://www.aliyun.com/product/aliware/mse?utm_content=g_1000401794\" title=\"\" target=\"_blank\" >\n            <img width=\"150px\" src=\"http://www.xuxueli.com/page/static/images/logo_aliyun2.png\" >\n            <br>\n            <span style=\"text-decoration:underline;color: #E6BE8A;\" >ÈòøÈáå‰∫ë Êèê‰æõ‰∫ë‰∏äÊâòÁÆ° XXL-JOB</span>\n        </a>\n    </td>\n    <td>\n        <a href=\"https://www.mall4j.com/cn/?statId=10\" title=\"\" target=\"_blank\" >\n            <img width=\"150px\" src=\"http://www.xuxueli.com/page/static/images/logo_mail4j.png\" >\n        </a>\n    </td>\n</tr>\n</table>\n<!-- supporter end -->\n\n\n## Documentation\n- [‰∏≠ÊñáÊñáÊ°£](https://www.xuxueli.com/xxl-job/)\n- [English Documentation](https://www.xuxueli.com/xxl-job/en/)\n\n\n## Communication    \n- [Á§æÂå∫‰∫§ÊµÅ](https://www.xuxueli.com/page/community.html)\n\n\n## Features\n- 1„ÄÅÁÆÄÂçïÔºöÊîØÊåÅÈÄöËøáWebÈ°µÈù¢ÂØπ‰ªªÂä°ËøõË°åCRUDÊìç‰ΩúÔºåÊìç‰ΩúÁÆÄÂçïÔºå‰∏ÄÂàÜÈíü‰∏äÊâãÔºõ\n- 2„ÄÅÂä®ÊÄÅÔºöÊîØÊåÅÂä®ÊÄÅ‰øÆÊîπ‰ªªÂä°Áä∂ÊÄÅ„ÄÅÂêØÂä®/ÂÅúÊ≠¢‰ªªÂä°Ôºå‰ª•ÂèäÁªàÊ≠¢ËøêË°å‰∏≠‰ªªÂä°ÔºåÂç≥Êó∂ÁîüÊïàÔºõ\n- 3„ÄÅË∞ÉÂ∫¶‰∏≠ÂøÉHAÔºà‰∏≠ÂøÉÂºèÔºâÔºöË∞ÉÂ∫¶ÈááÁî®‰∏≠ÂøÉÂºèËÆæËÆ°Ôºå‚ÄúË∞ÉÂ∫¶‰∏≠ÂøÉ‚ÄùËá™Á†îË∞ÉÂ∫¶ÁªÑ‰ª∂Âπ∂ÊîØÊåÅÈõÜÁæ§ÈÉ®ÁΩ≤ÔºåÂèØ‰øùËØÅË∞ÉÂ∫¶‰∏≠ÂøÉHAÔºõ\n- 4„ÄÅÊâßË°åÂô®HAÔºàÂàÜÂ∏ÉÂºèÔºâÔºö‰ªªÂä°ÂàÜÂ∏ÉÂºèÊâßË°åÔºå‰ªªÂä°\"ÊâßË°åÂô®\"ÊîØÊåÅÈõÜÁæ§ÈÉ®ÁΩ≤ÔºåÂèØ‰øùËØÅ‰ªªÂä°ÊâßË°åHAÔºõ\n- 5„ÄÅÊ≥®ÂÜå‰∏≠ÂøÉ: ÊâßË°åÂô®‰ºöÂë®ÊúüÊÄßËá™Âä®Ê≥®ÂÜå‰ªªÂä°, Ë∞ÉÂ∫¶‰∏≠ÂøÉÂ∞Ü‰ºöËá™Âä®ÂèëÁé∞Ê≥®ÂÜåÁöÑ‰ªªÂä°Âπ∂Ëß¶ÂèëÊâßË°å„ÄÇÂêåÊó∂Ôºå‰πüÊîØÊåÅÊâãÂä®ÂΩïÂÖ•ÊâßË°åÂô®Âú∞ÂùÄÔºõ\n- 6„ÄÅÂºπÊÄßÊâ©ÂÆπÁº©ÂÆπÔºö‰∏ÄÊó¶ÊúâÊñ∞ÊâßË°åÂô®Êú∫Âô®‰∏äÁ∫øÊàñËÄÖ‰∏ãÁ∫øÔºå‰∏ãÊ¨°Ë∞ÉÂ∫¶Êó∂Â∞Ü‰ºöÈáçÊñ∞ÂàÜÈÖç‰ªªÂä°Ôºõ\n- 7„ÄÅËß¶ÂèëÁ≠ñÁï•ÔºöÊèê‰æõ‰∏∞ÂØåÁöÑ‰ªªÂä°Ëß¶ÂèëÁ≠ñÁï•ÔºåÂåÖÊã¨ÔºöCronËß¶Âèë„ÄÅÂõ∫ÂÆöÈó¥ÈöîËß¶Âèë„ÄÅÂõ∫ÂÆöÂª∂Êó∂Ëß¶Âèë„ÄÅAPIÔºà‰∫ã‰ª∂ÔºâËß¶Âèë„ÄÅ‰∫∫Â∑•Ëß¶Âèë„ÄÅÁà∂Â≠ê‰ªªÂä°Ëß¶ÂèëÔºõ\n- 8„ÄÅË∞ÉÂ∫¶ËøáÊúüÁ≠ñÁï•ÔºöË∞ÉÂ∫¶‰∏≠ÂøÉÈîôËøáË∞ÉÂ∫¶Êó∂Èó¥ÁöÑË°•ÂÅøÂ§ÑÁêÜÁ≠ñÁï•ÔºåÂåÖÊã¨ÔºöÂøΩÁï•„ÄÅÁ´ãÂç≥Ë°•ÂÅøËß¶Âèë‰∏ÄÊ¨°Á≠âÔºõ\n- 9„ÄÅÈòªÂ°ûÂ§ÑÁêÜÁ≠ñÁï•ÔºöË∞ÉÂ∫¶Ëøá‰∫éÂØÜÈõÜÊâßË°åÂô®Êù•‰∏çÂèäÂ§ÑÁêÜÊó∂ÁöÑÂ§ÑÁêÜÁ≠ñÁï•ÔºåÁ≠ñÁï•ÂåÖÊã¨ÔºöÂçïÊú∫‰∏≤Ë°åÔºàÈªòËÆ§Ôºâ„ÄÅ‰∏¢ÂºÉÂêéÁª≠Ë∞ÉÂ∫¶„ÄÅË¶ÜÁõñ‰πãÂâçË∞ÉÂ∫¶Ôºõ\n- 10„ÄÅ‰ªªÂä°Ë∂ÖÊó∂ÊéßÂà∂ÔºöÊîØÊåÅËá™ÂÆö‰πâ‰ªªÂä°Ë∂ÖÊó∂Êó∂Èó¥Ôºå‰ªªÂä°ËøêË°åË∂ÖÊó∂Â∞Ü‰ºö‰∏ªÂä®‰∏≠Êñ≠‰ªªÂä°Ôºõ\n- 11„ÄÅ‰ªªÂä°Â§±Ë¥•ÈáçËØïÔºöÊîØÊåÅËá™ÂÆö‰πâ‰ªªÂä°Â§±Ë¥•ÈáçËØïÊ¨°Êï∞ÔºåÂΩì‰ªªÂä°Â§±Ë¥•Êó∂Â∞Ü‰ºöÊåâÁÖßÈ¢ÑËÆæÁöÑÂ§±Ë¥•ÈáçËØïÊ¨°Êï∞‰∏ªÂä®ËøõË°åÈáçËØïÔºõÂÖ∂‰∏≠ÂàÜÁâá‰ªªÂä°ÊîØÊåÅÂàÜÁâáÁ≤íÂ∫¶ÁöÑÂ§±Ë¥•ÈáçËØïÔºõ\n- 12„ÄÅ‰ªªÂä°Â§±Ë¥•ÂëäË≠¶ÔºõÈªòËÆ§Êèê‰æõÈÇÆ‰ª∂ÊñπÂºèÂ§±Ë¥•ÂëäË≠¶ÔºåÂêåÊó∂È¢ÑÁïôÊâ©Â±ïÊé•Âè£ÔºåÂèØÊñπ‰æøÁöÑÊâ©Â±ïÁü≠‰ø°„ÄÅÈíâÈíâÁ≠âÂëäË≠¶ÊñπÂºèÔºõ\n- 13„ÄÅË∑ØÁî±Á≠ñÁï•ÔºöÊâßË°åÂô®ÈõÜÁæ§ÈÉ®ÁΩ≤Êó∂Êèê‰æõ‰∏∞ÂØåÁöÑË∑ØÁî±Á≠ñÁï•ÔºåÂåÖÊã¨ÔºöÁ¨¨‰∏Ä‰∏™„ÄÅÊúÄÂêé‰∏Ä‰∏™„ÄÅËΩÆËØ¢„ÄÅÈöèÊú∫„ÄÅ‰∏ÄËá¥ÊÄßHASH„ÄÅÊúÄ‰∏çÁªèÂ∏∏‰ΩøÁî®„ÄÅÊúÄËøëÊúÄ‰πÖÊú™‰ΩøÁî®„ÄÅÊïÖÈöúËΩ¨Áßª„ÄÅÂøôÁ¢åËΩ¨ÁßªÁ≠âÔºõ\n- 14„ÄÅÂàÜÁâáÂπøÊí≠‰ªªÂä°ÔºöÊâßË°åÂô®ÈõÜÁæ§ÈÉ®ÁΩ≤Êó∂Ôºå‰ªªÂä°Ë∑ØÁî±Á≠ñÁï•ÈÄâÊã©\"ÂàÜÁâáÂπøÊí≠\"ÊÉÖÂÜµ‰∏ãÔºå‰∏ÄÊ¨°‰ªªÂä°Ë∞ÉÂ∫¶Â∞Ü‰ºöÂπøÊí≠Ëß¶ÂèëÈõÜÁæ§‰∏≠ÊâÄÊúâÊâßË°åÂô®ÊâßË°å‰∏ÄÊ¨°‰ªªÂä°ÔºåÂèØÊ†πÊçÆÂàÜÁâáÂèÇÊï∞ÂºÄÂèëÂàÜÁâá‰ªªÂä°Ôºõ\n- 15„ÄÅÂä®ÊÄÅÂàÜÁâáÔºöÂàÜÁâáÂπøÊí≠‰ªªÂä°‰ª•ÊâßË°åÂô®‰∏∫Áª¥Â∫¶ËøõË°åÂàÜÁâáÔºåÊîØÊåÅÂä®ÊÄÅÊâ©ÂÆπÊâßË°åÂô®ÈõÜÁæ§‰ªéËÄåÂä®ÊÄÅÂ¢ûÂä†ÂàÜÁâáÊï∞ÈáèÔºåÂçèÂêåËøõË°å‰∏öÂä°Â§ÑÁêÜÔºõÂú®ËøõË°åÂ§ßÊï∞ÊçÆÈáè‰∏öÂä°Êìç‰ΩúÊó∂ÂèØÊòæËëóÊèêÂçá‰ªªÂä°Â§ÑÁêÜËÉΩÂäõÂíåÈÄüÂ∫¶„ÄÇ\n- 16„ÄÅÊïÖÈöúËΩ¨ÁßªÔºö‰ªªÂä°Ë∑ØÁî±Á≠ñÁï•ÈÄâÊã©\"ÊïÖÈöúËΩ¨Áßª\"ÊÉÖÂÜµ‰∏ãÔºåÂ¶ÇÊûúÊâßË°åÂô®ÈõÜÁæ§‰∏≠Êüê‰∏ÄÂè∞Êú∫Âô®ÊïÖÈöúÔºåÂ∞Ü‰ºöËá™Âä®FailoverÂàáÊç¢Âà∞‰∏ÄÂè∞Ê≠£Â∏∏ÁöÑÊâßË°åÂô®ÂèëÈÄÅË∞ÉÂ∫¶ËØ∑Ê±Ç„ÄÇ\n- 17„ÄÅ‰ªªÂä°ËøõÂ∫¶ÁõëÊéßÔºöÊîØÊåÅÂÆûÊó∂ÁõëÊéß‰ªªÂä°ËøõÂ∫¶Ôºõ\n- 18„ÄÅRollingÂÆûÊó∂Êó•ÂøóÔºöÊîØÊåÅÂú®Á∫øÊü•ÁúãË∞ÉÂ∫¶ÁªìÊûúÔºåÂπ∂‰∏îÊîØÊåÅ‰ª•RollingÊñπÂºèÂÆûÊó∂Êü•ÁúãÊâßË°åÂô®ËæìÂá∫ÁöÑÂÆåÊï¥ÁöÑÊâßË°åÊó•ÂøóÔºõ\n- 19„ÄÅGLUEÔºöÊèê‰æõWeb IDEÔºåÊîØÊåÅÂú®Á∫øÂºÄÂèë‰ªªÂä°ÈÄªËæë‰ª£Á†ÅÔºåÂä®ÊÄÅÂèëÂ∏ÉÔºåÂÆûÊó∂ÁºñËØëÁîüÊïàÔºåÁúÅÁï•ÈÉ®ÁΩ≤‰∏äÁ∫øÁöÑËøáÁ®ã„ÄÇÊîØÊåÅ30‰∏™ÁâàÊú¨ÁöÑÂéÜÂè≤ÁâàÊú¨ÂõûÊ∫Ø„ÄÇ\n- 20„ÄÅËÑöÊú¨‰ªªÂä°ÔºöÊîØÊåÅ‰ª•GLUEÊ®°ÂºèÂºÄÂèëÂíåËøêË°åËÑöÊú¨‰ªªÂä°ÔºåÂåÖÊã¨Shell„ÄÅPython„ÄÅNodeJS„ÄÅPHP„ÄÅPowerShellÁ≠âÁ±ªÂûãËÑöÊú¨;\n- 21„ÄÅÂëΩ‰ª§Ë°å‰ªªÂä°ÔºöÂéüÁîüÊèê‰æõÈÄöÁî®ÂëΩ‰ª§Ë°å‰ªªÂä°HandlerÔºàBean‰ªªÂä°Ôºå\"CommandJobHandler\"ÔºâÔºõ‰∏öÂä°ÊñπÂè™ÈúÄË¶ÅÊèê‰æõÂëΩ‰ª§Ë°åÂç≥ÂèØÔºõ\n- 22„ÄÅ‰ªªÂä°‰æùËµñÔºöÊîØÊåÅÈÖçÁΩÆÂ≠ê‰ªªÂä°‰æùËµñÔºåÂΩìÁà∂‰ªªÂä°ÊâßË°åÁªìÊùü‰∏îÊâßË°åÊàêÂäüÂêéÂ∞Ü‰ºö‰∏ªÂä®Ëß¶Âèë‰∏ÄÊ¨°Â≠ê‰ªªÂä°ÁöÑÊâßË°å, Â§ö‰∏™Â≠ê‰ªªÂä°Áî®ÈÄóÂè∑ÂàÜÈöîÔºõ\n- 23„ÄÅ‰∏ÄËá¥ÊÄßÔºö‚ÄúË∞ÉÂ∫¶‰∏≠ÂøÉ‚ÄùÈÄöËøáDBÈîÅ‰øùËØÅÈõÜÁæ§ÂàÜÂ∏ÉÂºèË∞ÉÂ∫¶ÁöÑ‰∏ÄËá¥ÊÄß, ‰∏ÄÊ¨°‰ªªÂä°Ë∞ÉÂ∫¶Âè™‰ºöËß¶Âèë‰∏ÄÊ¨°ÊâßË°åÔºõ\n- 24„ÄÅËá™ÂÆö‰πâ‰ªªÂä°ÂèÇÊï∞ÔºöÊîØÊåÅÂú®Á∫øÈÖçÁΩÆË∞ÉÂ∫¶‰ªªÂä°ÂÖ•ÂèÇÔºåÂç≥Êó∂ÁîüÊïàÔºõ\n- 25„ÄÅË∞ÉÂ∫¶Á∫øÁ®ãÊ±†ÔºöË∞ÉÂ∫¶Á≥ªÁªüÂ§öÁ∫øÁ®ãËß¶ÂèëË∞ÉÂ∫¶ËøêË°åÔºåÁ°Æ‰øùË∞ÉÂ∫¶Á≤æÁ°ÆÊâßË°åÔºå‰∏çË¢´Â†µÂ°ûÔºõ\n- 26„ÄÅÊï∞ÊçÆÂä†ÂØÜÔºöË∞ÉÂ∫¶‰∏≠ÂøÉÂíåÊâßË°åÂô®‰πãÈó¥ÁöÑÈÄöËÆØËøõË°åÊï∞ÊçÆÂä†ÂØÜÔºåÊèêÂçáË∞ÉÂ∫¶‰ø°ÊÅØÂÆâÂÖ®ÊÄßÔºõ\n- 27„ÄÅÈÇÆ‰ª∂Êä•Ë≠¶Ôºö‰ªªÂä°Â§±Ë¥•Êó∂ÊîØÊåÅÈÇÆ‰ª∂Êä•Ë≠¶ÔºåÊîØÊåÅÈÖçÁΩÆÂ§öÈÇÆ‰ª∂Âú∞ÂùÄÁæ§ÂèëÊä•Ë≠¶ÈÇÆ‰ª∂Ôºõ\n- 28„ÄÅÊé®ÈÄÅmaven‰∏≠Â§Æ‰ªìÂ∫ì: Â∞Ü‰ºöÊääÊúÄÊñ∞Á®≥ÂÆöÁâàÊé®ÈÄÅÂà∞maven‰∏≠Â§Æ‰ªìÂ∫ì, Êñπ‰æøÁî®Êà∑Êé•ÂÖ•Âíå‰ΩøÁî®;\n- 29„ÄÅËøêË°åÊä•Ë°®ÔºöÊîØÊåÅÂÆûÊó∂Êü•ÁúãËøêË°åÊï∞ÊçÆÔºåÂ¶Ç‰ªªÂä°Êï∞Èáè„ÄÅË∞ÉÂ∫¶Ê¨°Êï∞„ÄÅÊâßË°åÂô®Êï∞ÈáèÁ≠âÔºõ‰ª•ÂèäË∞ÉÂ∫¶Êä•Ë°®ÔºåÂ¶ÇË∞ÉÂ∫¶Êó•ÊúüÂàÜÂ∏ÉÂõæÔºåË∞ÉÂ∫¶ÊàêÂäüÂàÜÂ∏ÉÂõæÁ≠âÔºõ\n- 30„ÄÅÂÖ®ÂºÇÊ≠•Ôºö‰ªªÂä°Ë∞ÉÂ∫¶ÊµÅÁ®ãÂÖ®ÂºÇÊ≠•ÂåñËÆæËÆ°ÂÆûÁé∞ÔºåÂ¶ÇÂºÇÊ≠•Ë∞ÉÂ∫¶„ÄÅÂºÇÊ≠•ËøêË°å„ÄÅÂºÇÊ≠•ÂõûË∞ÉÁ≠âÔºåÊúâÊïàÂØπÂØÜÈõÜË∞ÉÂ∫¶ËøõË°åÊµÅÈáèÂâäÂ≥∞ÔºåÁêÜËÆ∫‰∏äÊîØÊåÅ‰ªªÊÑèÊó∂Èïø‰ªªÂä°ÁöÑËøêË°åÔºõ\n- 31„ÄÅË∑®ËØ≠Ë®Ä/OpenAPIÔºöË∞ÉÂ∫¶‰∏≠ÂøÉ‰∏éÊâßË°åÂô®Êèê‰æõËØ≠Ë®ÄÊó†ÂÖ≥ÁöÑ OpenApiÔºàRESTful Ê†ºÂºèÔºâÔºåÁ¨¨‰∏âÊñπ‰ªªÊÑèËØ≠Ë®ÄÂèØÊçÆÊ≠§ÂØπÊé•Ë∞ÉÂ∫¶‰∏≠ÂøÉÊàñËÄÖÂÆûÁé∞ÊâßË°åÂô®ÔºåÂÆûÁé∞Â§öËØ≠Ë®ÄÊîØÊåÅ„ÄÇÈô§Ê≠§‰πãÂ§ñÔºåËøòÊèê‰æõ‰∫Ü ‚ÄúÂ§ö‰ªªÂä°Ê®°Âºè‚ÄùÂíå‚ÄúhttpJobHandler‚ÄùÁ≠âÂÖ∂‰ªñË∑®ËØ≠Ë®ÄÊñπÊ°àÔºõ\n- 32„ÄÅÂõΩÈôÖÂåñÔºöË∞ÉÂ∫¶‰∏≠ÂøÉÊîØÊåÅÂõΩÈôÖÂåñËÆæÁΩÆÔºåÊèê‰æõ‰∏≠Êñá„ÄÅËã±Êñá‰∏§ÁßçÂèØÈÄâËØ≠Ë®ÄÔºåÈªòËÆ§‰∏∫‰∏≠ÊñáÔºõ\n- 33„ÄÅÂÆπÂô®ÂåñÔºöÊèê‰æõÂÆòÊñπdockerÈïúÂÉèÔºåÂπ∂ÂÆûÊó∂Êõ¥Êñ∞Êé®ÈÄÅdockerhubÔºåËøõ‰∏ÄÊ≠•ÂÆûÁé∞‰∫ßÂìÅÂºÄÁÆ±Âç≥Áî®Ôºõ\n- 34„ÄÅÁ∫øÁ®ãÊ±†ÈöîÁ¶ªÔºöË∞ÉÂ∫¶Á∫øÁ®ãÊ±†ËøõË°åÈöîÁ¶ªÊãÜÂàÜÔºåÊÖ¢‰ªªÂä°Ëá™Âä®ÈôçÁ∫ßËøõÂÖ•\"Slow\"Á∫øÁ®ãÊ±†ÔºåÈÅøÂÖçËÄóÂ∞ΩË∞ÉÂ∫¶Á∫øÁ®ãÔºåÊèêÈ´òÁ≥ªÁªüÁ®≥ÂÆöÊÄßÔºõ\n- 35„ÄÅÁî®Êà∑ÁÆ°ÁêÜÔºöÊîØÊåÅÂú®Á∫øÁÆ°ÁêÜÁ≥ªÁªüÁî®Êà∑ÔºåÂ≠òÂú®ÁÆ°ÁêÜÂëò„ÄÅÊôÆÈÄöÁî®Êà∑‰∏§ÁßçËßíËâ≤Ôºõ\n- 36„ÄÅÊùÉÈôêÊéßÂà∂ÔºöÊâßË°åÂô®Áª¥Â∫¶ËøõË°åÊùÉÈôêÊéßÂà∂ÔºåÁÆ°ÁêÜÂëòÊã•ÊúâÂÖ®ÈáèÊùÉÈôêÔºåÊôÆÈÄöÁî®Êà∑ÈúÄË¶ÅÂàÜÈÖçÊâßË°åÂô®ÊùÉÈôêÂêéÊâçÂÖÅËÆ∏Áõ∏ÂÖ≥Êìç‰ΩúÔºõ\n- 37„ÄÅAI‰ªªÂä°ÔºöÂéüÁîüÊèê‰æõAIÊâßË°åÂô®ÔºåÂπ∂ÂÜÖÁΩÆÂ§ö‰∏™AI‰ªªÂä°HandlerÔºå‰∏éspring-ai„ÄÅollama„ÄÅdifyÁ≠âÈõÜÊàêÊâìÈÄöÔºåÊîØÊåÅÂø´ÈÄüÂºÄÂèëAIÁ±ª‰ªªÂä°„ÄÇ\n- 38„ÄÅÂÆ°ËÆ°Êó•ÂøóÔºöËÆ∞ÂΩï‰ªªÂä°Êìç‰ΩúÊïèÊÑü‰ø°ÊÅØÔºåÁî®‰∫éÁ≥ªÁªüÁõëÊéß„ÄÅÂÆ°ËÆ°ÂíåÂÆâÂÖ®ÂàÜÊûêÔºåÂèØÂø´ÈÄüËøΩÊ∫ØÂºÇÂ∏∏Ë°å‰∏∫‰ª•ÂèäÂÆö‰ΩçÊéíÊü•ÈóÆÈ¢ò„ÄÇ\n- 39„ÄÅ‰ºòÈõÖÂÅúÊú∫ÔºöË∞ÉÂ∫¶‰∏≠ÂøÉÂÅúÊú∫ÔºåÊ£ÄÊµãÊó∂Èó¥ËΩÆÈùûÁ©∫Êó∂‰∏ªÂä®Á≠âÂæÖË∞ÉÂ∫¶ÂÆåÊàêÔºõÂÆ¢Êà∑Á´ØÂÅúÊú∫ÔºåÊ£ÄÊµãÂ≠òÂú®ËøêË°å‰∏≠‰ªªÂä°Êó∂ÔºåÂÅúÊ≠¢Êé•Êî∂Êñ∞‰ªªÂä°Âπ∂‰∏ªÂä®Á≠âÂæÖ‰ªªÂä°ÊâßË°åÂÆåÊàêÔºõ\n\n## Development\n‰∫é2015Âπ¥‰∏≠ÔºåÊàëÂú®github‰∏äÂàõÂª∫XXL-JOBÈ°πÁõÆ‰ªìÂ∫ìÂπ∂Êèê‰∫§Á¨¨‰∏Ä‰∏™commitÔºåÈöè‰πãËøõË°åÁ≥ªÁªüÁªìÊûÑËÆæËÆ°ÔºåUIÈÄâÂûãÔºå‰∫§‰∫íËÆæËÆ°‚Ä¶‚Ä¶\n\n‰∫é2015-11ÊúàÔºåXXL-JOBÁªà‰∫éRELEASE‰∫ÜÁ¨¨‰∏Ä‰∏™Â§ßÁâàÊú¨V1.0Ôºå ÈöèÂêéÊàëÂ∞Ü‰πãÂèëÂ∏ÉÂà∞OSCHINAÔºåXXL-JOBÂú®OSCHINA‰∏äËé∑Âæó‰∫Ü@Á∫¢ËñØÁöÑÁÉ≠Èó®Êé®ËçêÔºåÂêåÊúüÂàÜÂà´ËææÂà∞‰∫ÜOSCHINAÁöÑ‚ÄúÁÉ≠Èó®Âä®Âºπ‚ÄùÊéíË°åÁ¨¨‰∏ÄÂíågit.oschinaÁöÑÂºÄÊ∫êËΩØ‰ª∂ÊúàÁÉ≠Â∫¶ÊéíË°åÁ¨¨‰∏ÄÔºåÂú®Ê≠§ÁâπÂà´ÊÑüË∞¢Á∫¢ËñØÔºåÊÑüË∞¢Â§ßÂÆ∂ÁöÑÂÖ≥Ê≥®ÂíåÊîØÊåÅ„ÄÇ\n\n‰∫é2015-12ÊúàÔºåÊàëÂ∞ÜXXL-JOBÂèëË°®Âà∞ÊàëÂè∏ÂÜÖÈÉ®Áü•ËØÜÂ∫ìÔºåÂπ∂‰∏îÂæóÂà∞ÂÜÖÈÉ®Âêå‰∫ãËÆ§ÂèØ„ÄÇ\n\n‰∫é2016-01ÊúàÔºåÊàëÂè∏Â±ïÂºÄXXL-JOBÁöÑÂÜÖÈÉ®Êé•ÂÖ•ÂíåÂÆöÂà∂Â∑•‰ΩúÔºåÂú®Ê≠§ÊÑüË∞¢Ë¢ÅÊüêÂíåÂ∞πÊüê‰∏§‰ΩçÂêå‰∫ãÁöÑË¥°ÁåÆÔºåÂêåÊó∂‰πüÊÑüË∞¢ÂÜÖÈÉ®ÂÖ∂‰ªñÁªô‰∏éÂÖ≥Ê≥®‰∏éÊîØÊåÅÁöÑÂêå‰∫ã„ÄÇ\n\n‰∫é2017-05-13ÔºåÂú®‰∏äÊµ∑‰∏æÂäûÁöÑ \"[Á¨¨62ÊúüÂºÄÊ∫ê‰∏≠ÂõΩÊ∫êÂàõ‰ºö](https://www.oschina.net/event/2236961)\" ÁöÑ \"ÊîæÁ†ÅËøáÊù•\" ÁéØËäÇÔºåÊàëÁôªÂè∞ÂØπXXL-JOBÂÅö‰∫ÜÊºîËÆ≤ÔºåÂè∞‰∏ã‰∫îÁôæ‰ΩçÂú®Âú∫ËßÇ‰ºóÂèçÂìçÁÉ≠ÁÉàÔºà[ÂõæÊñáÂõûÈ°æ](https://www.oschina.net/question/2686220_2242120) Ôºâ„ÄÇ\n\n‰∫é2017-10-22ÔºåÂèàÊãç‰∫ë Open Talk ËÅîÂêà Spring Cloud ‰∏≠ÂõΩÁ§æÂå∫‰∏æÂäûÁöÑ \"[ËøõÂáªÁöÑÂæÆÊúçÂä°ÂÆûÊàòÊ¥æ‰∏äÊµ∑Á´ô](https://opentalk.upyun.com/303.html)\"ÔºåÊàëÁôªÂè∞ÂØπXXL-JOBÂÅö‰∫ÜÊºîËÆ≤ÔºåÁé∞Âú∫ËßÇ‰ºóÂèçÂìçÁÉ≠ÁÉàÂπ∂Âú®‰ºöÂêé‰∏éXXL-JOBÁî®Êà∑ÁÉ≠ÁÉàËÆ®ËÆ∫‰∫§ÊµÅ„ÄÇ\n\n‰∫é2017-12-11ÔºåXXL-JOBÊúâÂπ∏ÂèÇ‰ºö„Ää[InfoQ ArchSummitÂÖ®ÁêÉÊû∂ÊûÑÂ∏àÂ≥∞‰ºö](http://bj2017.archsummit.com/)„ÄãÔºåÂπ∂Ë¢´ÊãçÊãçË¥∑Êû∂ÊûÑÊÄªÁõë\"Êù®Ê≥¢ËÄÅÂ∏à\"Âú®‰∏ìÈ¢ò \"[ÂæÆÊúçÂä°ÂéüÁêÜ„ÄÅÂü∫Á°ÄÊû∂ÊûÑÂíåÂºÄÊ∫êÂÆûË∑µ](http://bj2017.archsummit.com/training/2)\" ‰∏≠Áé∞Âú∫‰ªãÁªç„ÄÇ\n\n‰∫é2017-12-18ÔºåXXL-JOBÂèÇ‰∏é\"[2017Âπ¥Â∫¶ÊúÄÂèóÊ¨¢Ëøé‰∏≠ÂõΩÂºÄÊ∫êËΩØ‰ª∂](http://www.oschina.net/project/top_cn_2017?sort=1)\"ËØÑÊØîÔºåÂú®ÂΩìÊó∂Â∑≤ÂΩïÂÖ•ÁöÑÁ∫¶‰πùÂçÉ‰∏™ÂõΩ‰∫ßÂºÄÊ∫êÈ°πÁõÆ‰∏≠ËßíÈÄêÔºåÊúÄÁªàËøõÂÖ•‰∫ÜÂâç30Âº∫„ÄÇ\n\n‰∫é2018-01-15ÔºåXXL-JOBÂèÇ‰∏é\"[2017Á†Å‰∫ëÊúÄÁÅ´ÂºÄÊ∫êÈ°πÁõÆ](https://www.oschina.net/news/92438/2017-mayun-top-50)\"ËØÑÊØîÔºåÂú®ÂΩìÊó∂Â∑≤ÂΩïÂÖ•ÁöÑÁ∫¶ÂÖ≠ÂçÉ‰∫îÁôæ‰∏™Á†Å‰∫ëÈ°πÁõÆ‰∏≠ËßíÈÄêÔºåÊúÄÁªàËøõÂéª‰∫ÜÂâç20Âº∫„ÄÇ\n\n‰∫é2018-04-14ÔºåiTechPlusÂú®‰∏äÊµ∑‰∏æÂäûÁöÑ \"[2018‰∫íËÅîÁΩëÂºÄÂèëËÄÖÂ§ß‰ºö](http://www.itdks.com/eventlist/detail/2065)\"ÔºåÊàëÁôªÂè∞ÂØπXXL-JOBÂÅö‰∫ÜÊºîËÆ≤ÔºåÁé∞Âú∫ËßÇ‰ºóÂèçÂìçÁÉ≠ÁÉàÂπ∂Âú®‰ºöÂêé‰∏éXXL-JOBÁî®Êà∑ÁÉ≠ÁÉàËÆ®ËÆ∫‰∫§ÊµÅ„ÄÇ\n\n‰∫é2018-05-27ÔºåÂú®‰∏äÊµ∑‰∏æÂäûÁöÑ \"[Á¨¨75ÊúüÂºÄÊ∫ê‰∏≠ÂõΩÊ∫êÂàõ‰ºö](https://www.oschina.net/event/2278742)\" ÁöÑ \"Êû∂ÊûÑ\" ‰∏ªÈ¢ò‰∏ìÂú∫ÔºåÊàëÁôªÂè∞ËøõË°å‚ÄúÂü∫Á°ÄÊû∂ÊûÑ‰∏é‰∏≠Èó¥‰ª∂ÂõæË∞±‚Äù‰∏ªÈ¢òÊºîËÆ≤ÔºåÂè∞‰∏ã‰∏äÂçÉ‰ΩçÂú®Âú∫ËßÇ‰ºóÂèçÂìçÁÉ≠ÁÉàÔºà[ÂõæÊñáÂõûÈ°æ](https://www.oschina.net/question/3802184_2280606) Ôºâ„ÄÇ\n\n‰∫é2018-12-05ÔºåXXL-JOBÂèÇ‰∏é\"[2018Âπ¥Â∫¶ÊúÄÂèóÊ¨¢Ëøé‰∏≠ÂõΩÂºÄÊ∫êËΩØ‰ª∂](https://www.oschina.net/project/top_cn_2018?sort=1)\"ËØÑÊØîÔºåÂú®ÂΩìÊó∂Â∑≤ÂΩïÂÖ•ÁöÑ‰∏Ä‰∏áÂ§ö‰∏™ÂºÄÊ∫êÈ°πÁõÆ‰∏≠ËßíÈÄêÔºåÊúÄÁªàÊéíÂêçÁ¨¨19Âêç„ÄÇ\n\n‰∫é2019-12-10ÔºåXXL-JOBÂèÇ‰∏é\"[2019Âπ¥Â∫¶ÊúÄÂèóÊ¨¢Ëøé‰∏≠ÂõΩÂºÄÊ∫êËΩØ‰ª∂](https://www.oschina.net/project/top_cn_2019)\"ËØÑÊØîÔºåÂú®ÂΩìÊó∂Â∑≤ÂΩïÂÖ•ÁöÑ‰∏Ä‰∏áÂ§ö‰∏™ÂºÄÊ∫êÈ°πÁõÆ‰∏≠ËßíÈÄêÔºåÊúÄÁªàÊéíÂêç\"ÂºÄÂèëÊ°ÜÊû∂ÂíåÂü∫Á°ÄÁªÑ‰ª∂Á±ª\"Á¨¨9Âêç„ÄÇ\n\n‰∫é2020-11-16ÔºåXXL-JOBÂèÇ‰∏é\"[2020Âπ¥Â∫¶ÊúÄÂèóÊ¨¢Ëøé‰∏≠ÂõΩÂºÄÊ∫êËΩØ‰ª∂](https://www.oschina.net/project/top_cn_2020)\"ËØÑÊØîÔºåÂú®ÂΩìÊó∂Â∑≤ÂΩïÂÖ•ÁöÑ‰∏Ä‰∏áÂ§ö‰∏™ÂºÄÊ∫êÈ°πÁõÆ‰∏≠ËßíÈÄêÔºåÊúÄÁªàÊéíÂêç\"ÂºÄÂèëÊ°ÜÊû∂ÂíåÂü∫Á°ÄÁªÑ‰ª∂Á±ª\"Á¨¨8Âêç„ÄÇ\n\n‰∫é2021-12-06ÔºåXXL-JOBÂèÇ‰∏é\"[2021Âπ¥Â∫¶OSC‰∏≠ÂõΩÂºÄÊ∫êÈ°πÁõÆËØÑÈÄâ](https://www.oschina.net/project/top_cn_2021) \"ËØÑÊØîÔºåÂú®ÂΩìÊó∂Â∑≤ÂΩïÂÖ•ÁöÑ‰∏Ä‰∏áÂ§ö‰∏™ÂºÄÊ∫êÈ°πÁõÆ‰∏≠ËßíÈÄêÔºåÊúÄÁªàÂΩìÈÄâ\"ÊúÄÂèóÊ¨¢ËøéÈ°πÁõÆ\"„ÄÇ\n\n‰∫é2024-11-06ÔºåXXL-JOBÁªè GitCode ÂÆòÊñπËØÑÂÆ°ÔºåËé∑Âæó ‚ÄúG-StarÈ°πÁõÆÊØï‰∏öËÆ§ËØÅ‚Äù„ÄÇ\n\n> ÊàëÂè∏Â§ß‰ºóÁÇπËØÑÁõÆÂâçÂ∑≤Êé•ÂÖ•XXL-JOBÔºåÂÜÖÈÉ®Âà´Âêç„ÄäFerrari„ÄãÔºàFerrariÂü∫‰∫éXXL-JOBÁöÑV1.1ÁâàÊú¨ÂÆöÂà∂ËÄåÊàêÔºåÊñ∞Êé•ÂÖ•Â∫îÁî®Êé®ËçêÂçáÁ∫ßÊúÄÊñ∞ÁâàÊú¨Ôºâ„ÄÇ\nÊçÆÊúÄÊñ∞ÁªüËÆ°, Ëá™2016-01-21Êé•ÂÖ•Ëá≥2017-12-01ÊúüÈó¥ÔºåËØ•Á≥ªÁªüÂ∑≤Ë∞ÉÂ∫¶Á∫¶100‰∏áÊ¨°ÔºåË°®Áé∞‰ºòÂºÇ„ÄÇÊñ∞Êé•ÂÖ•Â∫îÁî®Êé®Ëçê‰ΩøÁî®ÊúÄÊñ∞ÁâàÊú¨ÔºåÂõ†‰∏∫ÁªèËøáÊï∞ÂçÅ‰∏™ÁâàÊú¨ÁöÑÊõ¥Êñ∞ÔºåÁ≥ªÁªüÁöÑ‰ªªÂä°Ê®°Âûã„ÄÅUI‰∫§‰∫íÊ®°Âûã‰ª•ÂèäÂ∫ïÂ±ÇË∞ÉÂ∫¶ÈÄöËÆØÊ®°ÂûãÈÉΩÊúâ‰∫ÜËæÉÂ§ßÁöÑ‰ºòÂåñÂíåÊèêÂçáÔºåÊ†∏ÂøÉÂäüËÉΩÊõ¥Âä†Á®≥ÂÆöÈ´òÊïà„ÄÇ\n\nËá≥‰ªäÔºåXXL-JOBÂ∑≤Êé•ÂÖ•Â§öÂÆ∂ÂÖ¨Âè∏ÁöÑÁ∫ø‰∏ä‰∫ßÂìÅÁ∫øÔºåÊé•ÂÖ•Âú∫ÊôØÂ¶ÇÁîµÂïÜ‰∏öÂä°ÔºåO2O‰∏öÂä°ÂíåÂ§ßÊï∞ÊçÆ‰Ωú‰∏öÁ≠âÔºåÊà™Ê≠¢ÊúÄÊñ∞ÁªüËÆ°Êó∂Èó¥‰∏∫Ê≠¢ÔºåXXL-JOBÂ∑≤Êé•ÂÖ•ÁöÑÂÖ¨Âè∏ÂåÖÊã¨‰∏çÈôê‰∫éÔºö\n    \n\t- 1„ÄÅÂ§ß‰ºóÁÇπËØÑ„ÄêÁæéÂõ¢ÁÇπËØÑ„Äë\n\t- 2„ÄÅÂ±±‰∏úÂ≠¶ËÄåÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏Ôºõ\n\t- 3„ÄÅÂÆâÂæΩÊÖßÈÄö‰∫íËÅîÁßëÊäÄÊúâÈôêÂÖ¨Âè∏Ôºõ\n\t- 4„ÄÅ‰∫∫‰∫∫ËÅöË¥¢ÈáëÊúçÔºõ\n\t- 5„ÄÅ‰∏äÊµ∑Ê£†Ê££‰ø°ÊÅØÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n\t- 6„ÄÅËøêÊª°Êª°„ÄêËøêÊª°Êª°„Äë\n\t- 7„ÄÅÁ±≥ÂÖ∂Êûó (‰∏≠ÂõΩÂå∫)„ÄêÁ±≥ÂÖ∂Êûó„Äë\n\t- 8„ÄÅÂ¶àÂ¶àËÅîÁõü\n\t- 9„ÄÅ‰πùÊ®±Â§©‰∏ãÔºàÂåó‰∫¨Ôºâ‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n\t- 10„ÄÅ‰∏áÊôÆÊãâÊñØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„Äê‰∏ÄÂä†ÊâãÊú∫„Äë\n\t- 11„ÄÅ‰∏äÊµ∑‰∫ø‰øùÂÅ•Â∫∑ÁÆ°ÁêÜÊúâÈôêÂÖ¨Âè∏\n\t- 12„ÄÅÊµ∑Â∞îÈ¶®Âé®„ÄêÊµ∑Â∞î„Äë\n\t- 13„ÄÅÊ≤≥ÂçóÂ§ßÁ∫¢ÂåÖÁîµÂ≠êÂïÜÂä°ÊúâÈôêÂÖ¨Âè∏\n\t- 14„ÄÅÊàêÈÉΩÈ°∫ÁÇπÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n\t- 15„ÄÅÊ∑±Âú≥Â∏ÇÊÄ°‰∫öÈÄö\n\t- 16„ÄÅÊ∑±Âú≥È∫¶‰∫ö‰ø°ÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n\t- 17„ÄÅ‰∏äÊµ∑ÂçöËéπÁßëÊäÄ‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n\t- 18„ÄÅ‰∏≠ÂõΩÂπ≥ÂÆâÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„Äê‰∏≠ÂõΩÂπ≥ÂÆâ„Äë\n\t- 19„ÄÅÊù≠Â∑ûÁü•Êó∂‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n\t- 20„ÄÅÂçöËéπÁßëÊäÄÔºà‰∏äÊµ∑ÔºâÊúâÈôêÂÖ¨Âè∏\n\t- 21„ÄÅÊàêÈÉΩ‰æùËÉΩËÇ°‰ªΩÊúâÈôêË¥£‰ªªÂÖ¨Âè∏\n\t- 22„ÄÅÊπñÂçóÈ´òÈò≥ÈÄöËÅî‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n\t- 23„ÄÅÊ∑±Âú≥Â∏ÇÈÇ¶Âæ∑ÊñáÂåñÂèëÂ±ïÊúâÈôêÂÖ¨Âè∏\n\t- 24„ÄÅÁ¶èÂª∫ÈòøÊÄùÂèØÁΩëÁªúÊïôËÇ≤ÊúâÈôêÂÖ¨Âè∏\n\t- 25„ÄÅ‰ºò‰ø°‰∫åÊâãËΩ¶„Äê‰ºò‰ø°„Äë\n\t- 26„ÄÅ‰∏äÊµ∑ÊÇ†Ê∏∏Â†ÇÊäïËµÑÂèëÂ±ïËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„ÄêÊÇ†Ê∏∏Â†Ç„Äë\n\t- 27„ÄÅÂåó‰∫¨Á≤âÁ¨îËìùÂ§©ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n\t- 28„ÄÅ‰∏≠ÁßÄÁßëÊäÄ(Êó†Èî°)ÊúâÈôêÂÖ¨Âè∏\n\t- 29„ÄÅÊ≠¶Ê±âÁ©∫ÂøÉÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n\t- 30„ÄÅÂåó‰∫¨ËöÇËöÅÈ£éÊö¥ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n\t- 31„ÄÅÂõõÂ∑ù‰∫íÂÆúËææÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n\t- 32„ÄÅÈí±ÂåÖË°å‰∫ëÔºàÂåó‰∫¨ÔºâÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n\t- 33„ÄÅÈáçÂ∫ÜÊ¨£ÊâçÈõÜÂõ¢\n    - 34„ÄÅÂí™Âíï‰∫íÂä®Â®±‰πêÊúâÈôêÂÖ¨Âè∏„Äê‰∏≠ÂõΩÁßªÂä®„Äë\n    - 35„ÄÅÂåó‰∫¨ËØ∫‰∫¶ËÖæÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 36„ÄÅÂ¢ûÈïøÂºïÊìé(Âåó‰∫¨)‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 37„ÄÅÂåó‰∫¨Ëã±Ë¥ùÊÄùÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 38„ÄÅÂàöÊ≥∞ÈõÜÂõ¢\n    - 39„ÄÅÊ∑±Âú≥Ê≥∞‰πÖ‰ø°ÊÅØÁ≥ªÁªüËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 40„ÄÅÈöèË°å‰ªòÊîØ‰ªòÊúâÈôêÂÖ¨Âè∏\n    - 41„ÄÅÂπøÂ∑ûÁÄöÂÜúÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 42„ÄÅ‰∫´ÁÇπÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 43„ÄÅÊù≠Â∑ûÊØîÊô∫ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 44„ÄÅÂú≥‰∏¥ÁïåÁ∫øÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 45„ÄÅÂπøÂ∑ûÁü•ËØÜÂúàÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 46„ÄÅÂõΩË™âÂïÜ‰∏ö‰∏äÊµ∑ÊúâÈôêÂÖ¨Âè∏\n    - 47„ÄÅÊµ∑Â∞îÊ∂àË¥πÈáëËûçÊúâÈôêÂÖ¨Âè∏ÔºåÂó®‰ªò„ÄÅÂ§üËä±„ÄêÊµ∑Â∞î„Äë\n    - 48„ÄÅÂπøÂ∑ûÂ∑¥ÂõæÈ≤Å‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 49„ÄÅÊ∑±Âú≥Â∏ÇÈπèÊµ∑ËøêÁîµÂ≠êÊï∞ÊçÆ‰∫§Êç¢ÊúâÈôêÂÖ¨Âè∏\n    - 50„ÄÅÊ∑±Âú≥Â∏Ç‰∫öÈ£ûÁîµÂ≠êÂïÜÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 51„ÄÅ‰∏äÊµ∑Ë∂£ÂåªÁΩëÁªúÊúâÈôêÂÖ¨Âè∏\n    - 52„ÄÅËÅöÈáëËµÑÊú¨\n    - 53„ÄÅÂåó‰∫¨Áà∂ÊØçÈÇ¶ÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 54„ÄÅ‰∏≠Â±±ÂÖÉËµ´ËΩØ‰ª∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 55„ÄÅ‰∏≠ÂïÜÊÉ†Ê∞ë(Âåó‰∫¨)ÁîµÂ≠êÂïÜÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 56„ÄÅÂáØ‰∫¨ÈõÜÂõ¢\n    - 57„ÄÅÂçéÂ§èÁ•®ËÅîÔºàÂåó‰∫¨ÔºâÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 58„ÄÅÊãçÊãçË¥∑„ÄêÊãçÊãçË¥∑„Äë\n    - 59„ÄÅÂåó‰∫¨Â∞öÂæ∑Êú∫ÊûÑÂú®Á∫øÊïôËÇ≤ÊúâÈôêÂÖ¨Âè∏\n    - 60„ÄÅ‰ªªÂ≠êË°åËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 61„ÄÅÂåó‰∫¨Êó∂ÊÄÅÁîµÂ≠êÂïÜÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 62„ÄÅÊ∑±Âú≥Âç∑ÁöÆÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 63„ÄÅÂåó‰∫¨ÂÆâÂçöÈÄöÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 64„ÄÅÊú™Êù•Êó†Á∫øÁΩë\n    - 65„ÄÅÂé¶Èó®Áì∑Á¶ßÁΩëÁªúÊúâÈôêÂÖ¨Âè∏\n    - 66„ÄÅÂåó‰∫¨ÈÄíËìùÁßëËΩØ‰ª∂ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 67„ÄÅÈÉëÂ∑ûÂàõÊµ∑ËΩØ‰ª∂ÁßëÊäÄÂÖ¨Âè∏\n    - 68„ÄÅÂåó‰∫¨ÂõΩÊßê‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 69„ÄÅÊµ™ÊΩÆËΩØ‰ª∂ÈõÜÂõ¢\n    - 70„ÄÅÂ§öÁ´ãÊÅí(Âåó‰∫¨)‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 71„ÄÅÂπøÂ∑ûÊûÅËøÖÂÆ¢‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 72„ÄÅËµ´Âü∫Ôºà‰∏≠ÂõΩÔºâÈõÜÂõ¢ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 73„ÄÅÊµ∑ÊäïÊ±á\n    - 74„ÄÅ‰∏äÊµ∑Ê∂¶ÁõäÂàõ‰∏öÂ≠µÂåñÂô®ÁÆ°ÁêÜËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 75„ÄÅÊ±âÁ∫≥Ê£ÆÔºàÂé¶Èó®ÔºâÊï∞ÊçÆËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 76„ÄÅÂÆâ‰ø°‰ø°Êâò\n    - 77„ÄÅÂ≤öÂÑíË¥¢ÂØå\n    - 78„ÄÅÊç∑ÈÅìËΩØ‰ª∂\n    - 79„ÄÅÊπñÂåó‰∫´‰∏ÉÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 80„ÄÅÊπñÂçóÂàõÂèëÁßëÊäÄË¥£‰ªªÊúâÈôêÂÖ¨Âè∏\n    - 81„ÄÅÊ∑±Âú≥Â∞èÂÆâÊó∂‰ª£‰∫íËÅîÁΩëÈáëËûçÊúçÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 82„ÄÅÊπñÂåó‰∫´‰∏ÉÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 83„ÄÅÈí±ÂåÖË°å‰∫ë(Âåó‰∫¨)ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 84„ÄÅ360ÈáëËûç„Äê360„Äë\n    - 85„ÄÅÊòì‰ºÅÁßÄ\n    - 86„ÄÅÊë©Ë¥ùÔºà‰∏äÊµ∑ÔºâÁîüÁâ©ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 87„ÄÅÂπø‰∏úËäØÊô∫ÊÖßÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 88„ÄÅËÅîÊÉ≥ÈõÜÂõ¢„ÄêËÅîÊÉ≥„Äë\n    - 89„ÄÅÊÄ™ÂÖΩÂÖÖÁîµ\n    - 90„ÄÅË°åÂúÜÊ±ΩËΩ¶\n    - 91„ÄÅÊ∑±Âú≥Â∫óÂ∫óÈÄöÁßëÊäÄÈÇÆÁÆ±ÂÖ¨Âè∏\n    - 92„ÄÅ‰∫¨‰∏ú„Äê‰∫¨‰∏ú„Äë\n    - 93„ÄÅÁ±≥Â∫ÑÁêÜË¥¢\n    - 94„ÄÅÂíñÂï°ÊòìËûç\n    - 95„ÄÅÊ¢ßÊ°êËØöÈÄâ\n    - 96„ÄÅÊÅíÂ§ßÂú∞‰∫ß„ÄêÊÅíÂ§ß„Äë\n    - 97„ÄÅÊòÜÊòéÈæôÊÖß\n    - 98„ÄÅ‰∏äÊµ∑Ê∂©Áë∂ËΩØ‰ª∂\n    - 99„ÄÅÊòì‰ø°„ÄêÁΩëÊòì„Äë\n    - 100„ÄÅÈìúÊùøË°ó\n    - 101„ÄÅÊù≠Â∑û‰∫ëËã•ÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 102„ÄÅÁâπÁôæÊÉ†Ôºà‰∏≠ÂõΩÔºâÊúâÈôêÂÖ¨Âè∏\n    - 103„ÄÅÂ∏∏Â±±‰ºóÂç°ËøêÂäõ‰æõÂ∫îÈìæÁÆ°ÁêÜÊúâÈôêÂÖ¨Âè∏\n    - 104„ÄÅÊ∑±Âú≥Á´ãÂàõÁîµÂ≠êÂïÜÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 105„ÄÅÊù≠Â∑ûÊô∫ËØ∫ÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 106„ÄÅÂåó‰∫¨‰∫ëÊºæ‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 107„ÄÅÊ∑±Âú≥Â∏ÇÂ§öÈì∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 108„ÄÅ‰∫≤ÂÆùÂÆù\n    - 109„ÄÅ‰∏äÊµ∑ÂçöÂç°ËΩØ‰ª∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 110„ÄÅÊô∫ÊÖßÊ†ëÂú®Á∫øÊïôËÇ≤Âπ≥Âè∞\n    - 111„ÄÅÁ±≥ÊóèÈáëËûç\n    - 112„ÄÅÂåó‰∫¨Ëæ∞Ê£Æ‰∏ñÁ∫™\n    - 113„ÄÅ‰∫ëÂçóÊªáÂåªÈÄö\n    - 114„ÄÅÂπøÂ∑ûÂ∏ÇÂàÜÈ¢ÜÁΩëÁªúÁßëÊäÄÊúâÈôêË¥£‰ªªÂÖ¨Âè∏\n    - 115„ÄÅÊµôÊ±üÂæÆËÉΩÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 116„ÄÅ‰∏äÊµ∑È¶®È£ûÁîµÂ≠êÂïÜÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 117„ÄÅ‰∏äÊµ∑ÂÆùÂ∞äÁîµÂ≠êÂïÜÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 118„ÄÅÁõ¥ÂÆ¢ÈÄöÁßëÊäÄÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 119„ÄÅÁßëÂ∫¶ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 120„ÄÅ‰∏äÊµ∑Êï∞ÊÖßÁ≥ªÁªüÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 121„ÄÅÊàëÁöÑÂåªËçØÁΩë\n    - 122„ÄÅÂ§öÁ≤âÂπ≥Âè∞\n    - 123„ÄÅÈìÅÁî≤‰∫åÊâãÊú∫\n    - 124„ÄÅ‰∏äÊµ∑Êµ∑Êñ∞ÂæóÊï∞ÊçÆÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 125„ÄÅÊ∑±Âú≥Â∏ÇÁèçÁà±ÁΩë‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏„ÄêÁèçÁà±ÁΩë„Äë\n    - 126„ÄÅÂ∞èËúúËúÇ\n    - 127„ÄÅÂêâËç£Êï∞ÁßëÊäÄ\n    - 128„ÄÅ‰∏äÊµ∑ÊÅ∫Âüü‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 129„ÄÅÂπøÂ∑ûËçîÊîØÁΩëÁªúÊúâÈôêÂÖ¨Âè∏„ÄêËçîÊûùFM„Äë\n    - 130„ÄÅÊù≠Â∑ûÈó™ÂÆùÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 131„ÄÅÂåó‰∫¨‰∫íËÅîÊñ∞ÁΩëÁßëÊäÄÂèëÂ±ïÊúâÈôêÂÖ¨Âè∏\n    - 132„ÄÅË™âÈÅìÁßëÊäÄ\n    - 133„ÄÅÂ±±Ë•øÂÖÜÁõõÊàøÂú∞‰∫ßÂºÄÂèëÊúâÈôêÂÖ¨Âè∏\n    - 134„ÄÅÂåó‰∫¨ËìùÁùøÈÄöËææÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 135„ÄÅÊúà‰∫ÆÂ∞èÂ±ãÔºà‰∏≠ÂõΩÔºâÊúâÈôêÂÖ¨Âè∏„ÄêËìùÊúà‰∫Æ„Äë\n    - 136„ÄÅÈùíÂ≤õÂõΩÁëû‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 137„ÄÅÂçöÈõÖ‰∫ëËÆ°ÁÆóÔºàÂåó‰∫¨ÔºâÊúâÈôêÂÖ¨Âè∏\n    - 138„ÄÅÂçéÊ≥∞ËØÅÂà∏È¶ôÊ∏ØÂ≠êÂÖ¨Âè∏\n    - 139„ÄÅÊù≠Â∑û‰∏úÊñπÈÄö‰ø°ËΩØ‰ª∂ÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 140„ÄÅÊ≠¶Ê±âÂçöÊôüÂÆâÂÖ®ÊäÄÊúØËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 141„ÄÅÊ∑±Âú≥Â∏ÇÂÖ≠Â∫¶‰∫∫ÂíåÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 142„ÄÅÊù≠Â∑ûË∂£Áª¥ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏ÔºàÂ∞èÂΩ±Ôºâ\n    - 143„ÄÅÂÆÅÊ≥¢ÂçïËΩ¶‰æ†‰πãÂÆ∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„ÄêÂçïËΩ¶‰æ†„Äë\n    - 144„ÄÅ‰∏Å‰∏Å‰∫ëÂ∫∑‰ø°ÊÅØÁßëÊäÄÔºàÂåó‰∫¨ÔºâÊúâÈôêÂÖ¨Âè∏\n    - 145„ÄÅ‰∫ëÈí±Ë¢ã\n    - 146„ÄÅÂçó‰∫¨‰∏≠ÂÖ¥ÂäõÁª¥\n    - 147„ÄÅ‰∏äÊµ∑ÁüΩÊòåÈÄö‰ø°ÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 148„ÄÅÊ∑±Âú≥Ëê®ÁßëÁßëÊäÄ\n    - 149„ÄÅ‰∏≠ÈÄöÊúçÂàõÁ´ãÁßëÊäÄÊúâÈôêË¥£‰ªªÂÖ¨Âè∏\n    - 150„ÄÅÊ∑±Âú≥Â∏ÇÂØπÂ∫ÑÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 151„ÄÅ‰∏äËØÅÊâÄ‰ø°ÊÅØÁΩëÁªúÊúâÈôêÂÖ¨Âè∏\n    - 152„ÄÅÊù≠Â∑ûÁÅ´ÁÉß‰∫ëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„ÄêÂ©öÁ§ºÁ∫™„Äë\n    - 153„ÄÅÂ§©Ê¥•ÈùíËäíÊûúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„ÄêËäíÊûúÂ§¥Êù°„Äë\n    - 154„ÄÅÈïøÈ£ûÂÖâÁ∫§ÂÖâÁºÜËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 155„ÄÅ‰∏ñÁ∫™ÂáØÊ≠åÔºàÂåó‰∫¨ÔºâÂåªÁñóÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 156„ÄÅÊµôÊ±üÈúñÊ¢ìÊéßËÇ°ÊúâÈôêÂÖ¨Âè∏\n    - 157„ÄÅÊ±üË•øËÖæÈ£ûÁΩëÁªúÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 158„ÄÅÂÆâËøÖÁâ©ÊµÅÊúâÈôêÂÖ¨Âè∏\n    - 159„ÄÅËÇâËÅîÁΩë\n    - 160„ÄÅÂåó‰∫¨ÂåóÂπøÊ¢ØÂΩ±ÂπøÂëä‰º†Â™íÊúâÈôêÂÖ¨Âè∏\n    - 161„ÄÅ‰∏äÊµ∑Êï∞ÊÖßÁ≥ªÁªüÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 162„ÄÅÂ§ßÂøóÂ§©Êàê\n    - 163„ÄÅ‰∏äÊµ∑‰∫ëÈπäÂåª\n    - 164„ÄÅ‰∏äÊµ∑‰∫ëÈπäÂåª\n    - 165„ÄÅÂ¢®ËøπÂ§©Ê∞î„ÄêÂ¢®ËøπÂ§©Ê∞î„Äë\n    - 166„ÄÅ‰∏äÊµ∑ÈÄ∏Ê©ô‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 167„ÄÅÊ≤ÖÊúãÁâ©ËÅî\n    - 168„ÄÅÊù≠Â∑ûÊÅíÁîü‰∫ëËûçÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 169„ÄÅÁªøÁ±≥ËÅîÂàõ\n    - 170„ÄÅÈáçÂ∫ÜÊòìÂÆ†ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 171„ÄÅÂÆâÂæΩÂºïËà™ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏Ôºà‰πêËÅåÁΩëÔºâ\n    - 172„ÄÅ‰∏äÊµ∑Êï∞ËÅîÂåª‰ø°‰ºÅ‰∏öÂèëÂ±ïÊúâÈôêÂÖ¨Âè∏\n    - 173„ÄÅËâØÂΩ¨Âª∫Êùê\n    - 174„ÄÅÊù≠Â∑ûÊ±ÇÊòØÂêåÂàõÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 175„ÄÅËç∑È©¨ÂõΩÈôÖ\n    - 176„ÄÅÁÇπÈõáÁΩë\n    - 177„ÄÅÊ∑±Âú≥Â∏ÇÂçéÊòüÂÖâÁîµÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 178„ÄÅÂé¶Èó®Á•ûÂ∑ûÈπ∞ËΩØ‰ª∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 179„ÄÅÊ∑±Âú≥Â∏ÇÊãõÂïÜ‰ø°ËØ∫‰∫∫ÂØø‰øùÈô©ÊúâÈôêÂÖ¨Âè∏\n    - 180„ÄÅ‰∏äÊµ∑Â•ΩÂ±ãÁΩë‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 181„ÄÅÊµ∑‰ø°ÈõÜÂõ¢„ÄêÊµ∑‰ø°„Äë\n    - 182„ÄÅ‰ø°ÂáåÂèØ‰ø°ÊÅØÁßëÊäÄÔºà‰∏äÊµ∑ÔºâÊúâÈôêÂÖ¨Âè∏\n    - 183„ÄÅÈïøÊò•Â§©ÊàêÁßëÊäÄÂèëÂ±ïÊúâÈôêÂÖ¨Âè∏\n    - 184„ÄÅÁî®ÂèãÈáëËûç‰ø°ÊÅØÊäÄÊúØËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„ÄêÁî®Âèã„Äë\n    - 185„ÄÅÂåó‰∫¨ÂíñÂï°ÊòìËûçÊúâÈôêÂÖ¨Âè∏\n    - 186„ÄÅÂõΩÊäïÁëûÈì∂Âü∫ÈáëÁÆ°ÁêÜÊúâÈôêÂÖ¨Âè∏\n    - 187„ÄÅÊôãÊùæ(‰∏äÊµ∑)ÁΩëÁªú‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 188„ÄÅÊ∑±Âú≥Â∏ÇÈöèÊâãÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„ÄêÈöèÊâãËÆ∞„Äë\n    - 189„ÄÅÊ∑±Âú≥Ê∞¥Âä°ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 190„ÄÅÊòì‰ºÅÁßÄ„ÄêÊòì‰ºÅÁßÄ„Äë\n    - 191„ÄÅÂåó‰∫¨Á£Å‰∫ëÁßëÊäÄ\n    - 192„ÄÅÂçó‰∫¨ËúÇÊ≥∞‰∫íËÅîÁΩëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 193„ÄÅÁ´†È±ºÁõ¥Êí≠\n    - 194„ÄÅÂ•ñÂ§öÂ§öÁßëÊäÄ\n    - 195„ÄÅÂ§©Ê¥•Â∏ÇÁ•ûÂ∑ûÂïÜÈæôÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 196„ÄÅÂ≤©ÂøÉÁßëÊäÄ\n    - 197„ÄÅËΩ¶Á†ÅÁßëÊäÄÔºàÂåó‰∫¨ÔºâÊúâÈôêÂÖ¨Âè∏\n    - 198„ÄÅË¥µÈò≥Â∏ÇÊäïËµÑÊéßËÇ°ÈõÜÂõ¢\n    - 199„ÄÅÂ∫∑ÊóóËÇ°‰ªΩ\n    - 200„ÄÅÈæôËÖæÂá∫Ë°å\n    - 201„ÄÅÊù≠Â∑ûÂçéÈáèËΩØ‰ª∂\n    - 202„ÄÅÂêàËÇ•È°∂Â≤≠ÂåªÁñóÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 203„ÄÅÈáçÂ∫ÜË°®ËææÂºèÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 204„ÄÅ‰∏äÊµ∑Á±≥ÈÅì‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 205„ÄÅÂåó‰∫¨ÁõäÂèã‰ºöÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 206„ÄÅÂåó‰∫¨ËûçË¥ØÁîµÂ≠êÂïÜÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 207„ÄÅ‰∏≠ÂõΩÂ§ñÊ±á‰∫§Êòì‰∏≠ÂøÉ\n    - 208„ÄÅ‰∏≠ÂõΩÂ§ñËøêËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 209„ÄÅ‰∏≠ÂõΩ‰∏äÊµ∑ÊôìÂúàÊïôËÇ≤ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 210„ÄÅÊôÆËÅîËΩØ‰ª∂ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 211„ÄÅÂåó‰∫¨ÁßëËìùËΩØ‰ª∂ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 212„ÄÅÊ±üËãèÊñØËØ∫Áâ©ËÅîÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 213„ÄÅÂåó‰∫¨ÊêúÁãê-ÁãêÂèã„ÄêÊêúÁãê„Äë\n    - 214„ÄÅÊñ∞Â§ßÈôÜÁΩëÂïÜÈáëËûç\n    - 215„ÄÅÂ±±‰∏úÁ•ûÁ†Å‰∏≠Á®é‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 216„ÄÅÊ≤≥ÂçóÊ±áÈ°∫ÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 217„ÄÅÂåó‰∫¨ÂçéÂ§èÊÄùÊ∫êÁßëÊäÄÂèëÂ±ïÊúâÈôêÂÖ¨Âè∏\n    - 218„ÄÅ‰∏äÊµ∑‰∏úÊôÆ‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 219„ÄÅ‰∏äÊµ∑È∏£ÂãÉÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 220„ÄÅÂπø‰∏úÂ≠¶ËãëÊïôËÇ≤ÂèëÂ±ïÊúâÈôêÂÖ¨Âè∏\n    - 221„ÄÅÊ∑±Âú≥Âº∫Êó∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 222„ÄÅ‰∏äÊµ∑‰∫ëÁ†∫‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 223„ÄÅÈáçÂ∫ÜÊÑâÂÆ¢Ë°åÁΩëÁªúÊúâÈôêÂÖ¨Âè∏\n    - 224„ÄÅÊï∞‰∫ë\n    - 225„ÄÅÂõΩÂÆ∂ÁîµÁΩëËøêÊ£ÄÈÉ®\n    - 226„ÄÅÊù≠Â∑ûÊâæË∂£\n    - 227„ÄÅÊµ©È≤∏‰∫ëËÆ°ÁÆóÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 228„ÄÅÁßëÂ§ßËÆØÈ£û„ÄêÁßëÂ§ßËÆØÈ£û„Äë\n    - 229„ÄÅÊù≠Â∑ûË°åË£ÖÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 230„ÄÅÂç≥ÊúâÂàÜÊúüÈáëËûç\n    - 231„ÄÅÊ∑±Âú≥Ê≥ïÂè∏Âæ∑‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 232„ÄÅ‰∏äÊµ∑ÂçöÂ§ç‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 233„ÄÅÊù≠Â∑û‰∫ëÂòâ‰∫ëËÆ°ÁÆóÊúâÈôêÂÖ¨Âè∏\n    - 234„ÄÅÊúâÂÆ∂Ê∞ëÂÆø(ÊúâÂÆ∂ÁæéÂÆø)\n    - 235„ÄÅÂåó‰∫¨Ëµ¢ÈîÄÈÄöËΩØ‰ª∂ÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 236„ÄÅÊµôÊ±üËÅöÊúâË¥¢ÈáëËûçÊúçÂä°Â§ñÂåÖÊúâÈôêÂÖ¨Âè∏\n    - 237„ÄÅÊòìÊóèÊô∫Ê±á(Âåó‰∫¨)ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 238„ÄÅÂêàËÇ•È°∂Â≤≠ÂåªÁñóÁßëÊäÄÂºÄÂèëÊúâÈôêÂÖ¨Âè∏\n    - 239„ÄÅËΩ¶ËàπÂÆù(Ê∑±Âú≥)Êó≠Áè©ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏)\n    - 240„ÄÅÂπøÂ∑ûÂØåÂäõÂú∞‰∫ßÊúâÈôêÂÖ¨Âè∏\n    - 241„ÄÅÊ∞¢ËØæÔºà‰∏äÊµ∑ÔºâÊïôËÇ≤ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 242„ÄÅÊ≠¶Ê±âÊ∞™ÁªÜËÉûÁΩëÁªúÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 243„ÄÅÊù≠Â∑ûÊúâ‰∫ëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 244„ÄÅ‰∏äÊµ∑‰ªôË±ÜÊô∫ËÉΩÊú∫Âô®‰∫∫ÊúâÈôêÂÖ¨Âè∏\n    - 245„ÄÅÊãâÂç°ÊãâÊîØ‰ªòËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„ÄêÊãâÂç°Êãâ„Äë\n    - 246„ÄÅËôéÂΩ©Âç∞Ëâ∫ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 247„ÄÅÂåó‰∫¨Êï∞ÂæÆÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 248„ÄÅÂπø‰∏úÊô∫ÁëûÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 249„ÄÅÊâæÈí¢ÁΩë\n    - 250„ÄÅ‰πùÊú∫ÁΩë\n    - 251„ÄÅÊù≠Â∑ûË∑ëË∑ëÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 252„ÄÅÊ∑±Âú≥Êú™Êù•‰∫ëÈõÜ\n    - 253„ÄÅÊù≠Â∑ûÊØèÊó•ÁªôÂäõÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 254„ÄÅ‰∏äÊµ∑ÈΩêÁäá‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 255„ÄÅÊª¥Êª¥Âá∫Ë°å„ÄêÊª¥Êª¥„Äë\n    - 256„ÄÅÂêàËÇ•‰∫ëËØä‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 257„ÄÅ‰∫ëÁü•Â£∞Êô∫ËÉΩÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 258„ÄÅÂçó‰∫¨Âù¶ÈÅìÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 259„ÄÅÁà±‰πê‰ºòÔºà‰∫åÊâãÂπ≥Âè∞Ôºâ\n    - 260„ÄÅÁå´ÁúºÁîµÂΩ±ÔºàÁßÅÊúâÂåñÈÉ®ÁΩ≤Ôºâ„ÄêÁå´ÁúºÁîµÂΩ±„Äë\n    - 261„ÄÅÁæéÂõ¢Â§ßË±°ÔºàÁßÅÊúâÂåñÈÉ®ÁΩ≤Ôºâ„ÄêÁæéÂõ¢Â§ßË±°„Äë\n    - 262„ÄÅ‰Ωú‰∏öÂ∏ÆÊïôËÇ≤ÁßëÊäÄÔºàÂåó‰∫¨ÔºâÊúâÈôêÂÖ¨Âè∏„Äê‰Ωú‰∏öÂ∏Æ„Äë\n    - 263„ÄÅÂåó‰∫¨Â∞èÂπ¥Á≥ï‰∫íËÅîÁΩëÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 264„ÄÅÂ±±‰∏úÁü©ÈòµËΩØ‰ª∂Â∑•Á®ãËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 265„ÄÅÈôïË•øÂõΩÈ©øËΩØ‰ª∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 266„ÄÅÂêõÂºÄ‰ø°ÊÅØÁßëÊäÄ\n    - 267„ÄÅÊùëÈ∏üÁΩëÁªúÁßëÊäÄÊúâÈôêË¥£‰ªªÂÖ¨Âè∏\n    - 268„ÄÅ‰∫ëÂçóÂõΩÈôÖ‰ø°ÊâòÊúâÈôêÂÖ¨Âè∏\n    - 269„ÄÅÈáëÊô∫ÊïôËÇ≤\n    - 270„ÄÅÁè†Êµ∑Â∏ÇÁ≠ëÂ∑¢ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 271„ÄÅ‰∏äÊµ∑ÁôæËÉúËΩØ‰ª∂ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 272„ÄÅÊ∑±Âú≥Â∏ÇÁßëÁõæÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 273„ÄÅÂìàÂï∞Âá∫Ë°å„ÄêÂìàÂï∞„Äë\n    - 274„ÄÅÈÄîËôéÂÖªËΩ¶„ÄêÈÄîËôé„Äë\n    - 275„ÄÅÂç°ÊÄù‰ºòÊ¥æ‰∫∫ÂäõËµÑÊ∫êÈõÜÂõ¢\n    - 276„ÄÅÂçó‰∫¨ËßÇ‰∏∫Êô∫ÊÖßËΩØ‰ª∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 277„ÄÅÊù≠Â∑ûÂüéÂ∏ÇÂ§ßËÑëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 278„ÄÅÁåøËæÖÂØº„ÄêÁåøËæÖÂØº„Äë\n    - 279„ÄÅÊ¥õÈò≥ÂÅ•ÂàõÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 280„ÄÅÈ≠îÂäõËÄ≥Êúµ\n    - 281„ÄÅ‰∫øÈò≥‰ø°ÈÄö\n    - 282„ÄÅ‰∏äÊµ∑ÊãõÈ≤§ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 283„ÄÅÂõõÂ∑ùÂïÜÊóÖÊó†ÂøßÁßëÊäÄÊúçÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 284„ÄÅUUË∑ëËÖø\n    - 285„ÄÅÂåó‰∫¨ËÄÅËôéËØÅÂà∏„ÄêËÄÅËôéËØÅÂà∏„Äë\n    - 286„ÄÅÊÇ†Ê¥ªÁúÅÂêßÔºàÂåó‰∫¨ÔºâÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 287„ÄÅF5Êú™Êù•ÂïÜÂ∫ó\n    - 288„ÄÅÊ∑±Âú≥ÁéØÈò≥ÈÄö‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 289„ÄÅÈÅ†ÂÇ≥Èõª‰ø°\n    - 290„ÄÅ‰Ωú‰∏öÂ∏ÆÔºàÂåó‰∫¨ÔºâÊïôËÇ≤ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„Äê‰Ωú‰∏öÂ∏Æ„Äë\n    - 291„ÄÅÊàêÈÉΩÁßëÈ∏øÊô∫‰ø°ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 292„ÄÅÂåó‰∫¨Êú®Â±ãÊó∂‰ª£ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 293„ÄÅÂ§ßÂ≠¶ÈÄöÔºàÂìàÂ∞îÊª®ÔºâÁßëÊäÄÊúâÈôêË¥£‰ªªÂÖ¨Âè∏\n    - 294„ÄÅÊµôÊ±üÂçéÂù§ÈÅìÂ®ÅÊï∞ÊçÆÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 295„ÄÅÂêâÁ••Ëà™Á©∫„ÄêÂêâÁ••Ëà™Á©∫„Äë\n    - 296„ÄÅÂçó‰∫¨ÂúÜÂë®ÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 297„ÄÅÂπøÂ∑ûÂ∏ÇÊ¥ãËë±omallÁîµÂ≠êÂïÜÂä°\n    - 298„ÄÅÂ§©Ê¥•ËÅîÁâ©ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 299„ÄÅË∑ëÂì™ÂÑøÁßëÊäÄÔºàÂåó‰∫¨ÔºâÊúâÈôêÂÖ¨Âè∏\n    - 300„ÄÅÊ∑±Âú≥Â∏ÇÁæéË•øË•øÈ§êÈ•ÆÊúâÈôêÂÖ¨Âè∏(ÂñúËå∂)\n    - 301„ÄÅÂπ≥ÂÆâ‰∏çÂä®‰∫ßÊúâÈôêÂÖ¨Âè∏„ÄêÂπ≥ÂÆâ„Äë\n    - 302„ÄÅÊ±üËãè‰∏≠Êµ∑ÊòáÁâ©ËÅîÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 303„ÄÅÊπñÂçóÁâôÂåªÂ∏ÆÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 304„ÄÅÈáçÂ∫ÜÊ∞ëËà™ÂáØ‰∫ö‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏ÔºàÊòìÈÄöËà™Ôºâ\n    - 305„ÄÅÈÄíÊòìÔºà‰∏äÊµ∑ÔºâÊô∫ËÉΩÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 306„ÄÅ‰∫öÊúµ\n    - 307„ÄÅÊµôÊ±üÊñ∞ËØæÂ†ÇÊïôËÇ≤ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 308„ÄÅÂåó‰∫¨ËúÇÂàõÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 309„ÄÅÂæ∑‰∏ÄÊô∫ÊÖßÂüéÂ∏Ç‰ø°ÊÅØÁ≥ªÁªüÊúâÈôêÂÖ¨Âè∏\n    - 310„ÄÅÂåó‰∫¨ÁøºÁÇπÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 311„ÄÅÊπñÂçóÊô∫Êï∞Êñ∞Áª¥Â∫¶‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 312„ÄÅÂåó‰∫¨ÁéñÊâ¨ÂçöÊñáÊñáÂåñÂèëÂ±ïÊúâÈôêÂÖ¨Âè∏\n    - 313„ÄÅ‰∏äÊµ∑ÂÆáÁè©‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 314„ÄÅÂÖ®ÊôØÊô∫ËÅîÔºàÊ≠¶Ê±âÔºâÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 315„ÄÅÂ§©Ê¥•ÊòìÂÆ¢Êª°ÂõΩÈôÖÁâ©ÊµÅÊúâÈôêÂÖ¨Âè∏\n    - 316„ÄÅÂçó‰∫¨Áà±Á¶èË∑ØÊ±ΩËΩ¶ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 317„ÄÅÊàëÊàøÊóÖÂ±ÖÈõÜÂõ¢\n    - 318„ÄÅÊπõÊ±ü‰∫≤ÈÇªÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 319„ÄÅÊ∑±Âú≥Â∏ÇÂßúÁßëÁΩëÁªúÊúâÈôêÂÖ¨Âè∏\n    - 320„ÄÅÈùíÂ≤õÊó•Êó•È°∫Áâ©ÊµÅÊúâÈôêÂÖ¨Âè∏\n    - 321„ÄÅÂçó‰∫¨Â§™Â∑ù‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 322„ÄÅÁæéÂõæ‰πãÂÆ∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„ÄêÁæéÂõæ„Äë\n    - 323„ÄÅÂçó‰∫¨Â§™Â∑ù‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 324„ÄÅ‰ºóËñ™ÁßëÊäÄÔºàÂåó‰∫¨ÔºâÊúâÈôêÂÖ¨Âè∏\n    - 325„ÄÅÊ≠¶Ê±âÂÆâÂÆâÁâ©ËÅîÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 326„ÄÅÂåó‰∫¨Êô∫ÂÆ¢ÊúóÈÅìÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 327„ÄÅÊ∑±Âú≥Â∏ÇË∂ÖÁ∫ßÁå©Áå©ÂÅ•Ë∫´ÁÆ°ÁêÜÁÆ°ÁêÜÊúâÈôêÂÖ¨Âè∏\n    - 328„ÄÅÈáçÂ∫ÜËææÂøóÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 329„ÄÅ‰∏äÊµ∑‰∫´ËØÑ‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 330„ÄÅËñ™Âæó‰ªò‰ø°ÊÅØÁßëÊäÄ\n    - 331„ÄÅË∑üË∞ÅÂ≠¶\n    - 332„ÄÅ‰∏≠ÈÅìÔºàËãèÂ∑ûÔºâÊóÖÊ∏∏ÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 333„ÄÅÂπøÂ∑ûÂ∞èÂç´ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 334„ÄÅ‰∏äÊµ∑ÈùûÁ†ÅÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 335„ÄÅÈÄîÂÆ∂ÁΩëÁΩëÁªúÊäÄÊúØÔºàÂåó‰∫¨ÔºâÊúâÈôêÂÖ¨Âè∏„ÄêÈÄîÂÆ∂„Äë\n    - 336„ÄÅÂπøÂ∑ûËæâÂá°‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 337„ÄÅÂ§©Áª¥Â∞î‰ø°ÊÅØÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 338„ÄÅ‰∏äÊµ∑ÊûÅË±ÜÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 339„ÄÅËãèÂ∑ûËß¶Ëææ‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 340„ÄÅÂåó‰∫¨ÁÉ≠‰∫ëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 341„ÄÅ‰∏≠Êô∫‰ºÅÊúçÔºàÂåó‰∫¨ÔºâÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 342„ÄÅÊòìËÅî‰∫ëËÆ°ÁÆóÔºàÊù≠Â∑ûÔºâÊúâÈôêË¥£‰ªªÂÖ¨Âè∏\n    - 343„ÄÅÈùíÂ≤õËà™Á©∫ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„ÄêÈùíÂ≤õËà™Á©∫„Äë\n    - 344„ÄÅÂ±±Ë•øÂçöÁùøÈÄöÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 345„ÄÅÁΩëÊòìÊù≠Â∑ûÁΩëÁªúÊúâÈôêÂÖ¨Âè∏„ÄêÁΩëÊòì„Äë\n    - 346„ÄÅÂåó‰∫¨ÊûúÊûú‰πêÂ≠¶ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 347„ÄÅÁôæÊúõËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 348„ÄÅ‰∏≠‰øùÈáëÊúçÔºàÊ∑±Âú≥ÔºâÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 349„ÄÅÂ§©Ê¥•ËøêÂèãÁâ©ÊµÅÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 350„ÄÅÂπø‰∏úÂàõËÉΩÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 351„ÄÅ‰∏äÊµ∑ÂÄöÂçö‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 352„ÄÅÊ∑±Âú≥ÁôæÊûúÂõ≠ÂÆû‰∏öÔºàÈõÜÂõ¢ÔºâËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 353„ÄÅÂπøÂ∑ûÁªÜÂàªÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 354„ÄÅÊ≠¶Ê±âÈ∏ø‰∏ö‰ºóÂàõÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 355„ÄÅÈáëÈî°ÁßëÊäÄÔºàÂπøÂ∑ûÔºâÊúâÈôêÂÖ¨Âè∏\n    - 356„ÄÅÊòìÁëûÂõΩÈôÖÁîµÂ≠êÂïÜÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 357„ÄÅÂ•áÁÇπ‰∫ë\n    - 358„ÄÅ‰∏≠ËßÜ‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 359„ÄÅÂºÄÊ∫êÈ°πÁõÆ:datax-web\n    - 360„ÄÅ‰∫ëÁü•Â£∞Êô∫ËÉΩÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 361„ÄÅÂºÄÊ∫êÈ°πÁõÆ:bboss\n    - 362„ÄÅÊàêÈÉΩÊ∑±È©æÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 363„ÄÅFunPlus„ÄêË∂£Âä†„Äë\n    - 364„ÄÅÊù≠Â∑ûÂàõÂå†‰ø°ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 365„ÄÅÈæôÂå†ÔºàÂåó‰∫¨ÔºâÁßëÊäÄÂèëÂ±ïÊúâÈôêÂÖ¨Âè∏\n    - 366„ÄÅÂπøÂ∑û‰∏ÄÈìæÈÄö‰∫íËÅîÁΩëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 367„ÄÅ‰∏äÊµ∑ÊòüËâæÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 368„ÄÅËôéÂçöÁΩëÁªúÊäÄÊúØ(‰∏äÊµ∑)ÊúâÈôêÂÖ¨Âè∏\n    - 369„ÄÅÈùíÂ≤õ‰ºòÁ±≥‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 370„ÄÅÂÖ´Áª¥ÈÄöÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 371„ÄÅÁÉüÂè∞Âêà‰∫´Êô∫ÊòüÊï∞ÊçÆÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 372„ÄÅ‰∏úÂê¥ËØÅÂà∏ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 373„ÄÅ‰∏≠ÈÄö‰∫ë‰ªìËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„Äê‰∏≠ÈÄö„Äë\n    - 374„ÄÅÂåó‰∫¨Âä†Ëè≤Áå´ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 375„ÄÅÂåó‰∫¨Âå†ÂøÉÊºîÁªéÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 376„ÄÅÂÆùË¥ùËµ∞Â§©‰∏ã\n    - 377„ÄÅÂé¶Èó®‰ºóÂ∫ìÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 378„ÄÅÊµ∑ÈÄöËØÅÂà∏Êï∞ÊçÆ‰∏≠ÂøÉ\n    - 389„ÄÅÊπñÂçóÂø´‰πêÈÄöÂÆùÂ∞èÈ¢ùË¥∑Ê¨æÊúâÈôêÂÖ¨Âè∏\n    - 380„ÄÅÊµôÊ±üÂ§ßÂçéÊäÄÊúØËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 381„ÄÅÊù≠Â∑ûÈ≠îÁ≠∑ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 382„ÄÅÈùíÂ≤õÊéåËÆØÈÄöÂå∫ÂùóÈìæÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 383„ÄÅÊñ∞Â§ßÈôÜÈáëËûçÁßëÊäÄ\n    - 384„ÄÅÂ∏∏Â∑ûÁé∫ÊãìËΩØ‰ª∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 385„ÄÅÂåó‰∫¨Ê≠£‰øùÁΩëÊ†ºÊïôËÇ≤ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 386„ÄÅÁªü‰∏Ä‰ºÅ‰∏öÔºà‰∏≠ÂõΩÔºâÊäïËµÑÊúâÈôêÂÖ¨Âè∏„ÄêÁªü‰∏Ä„Äë\n    - 387„ÄÅÂæÆÈù©ÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 388„ÄÅÊù≠Â∑ûËûçÊòìÁÆóÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 399„ÄÅÈùíÂ≤õ‰∏äÂï•Áè≠ÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 390„ÄÅ‰∫¨‰∏úÈÖí‰∏ñÁïå\n    - 391„ÄÅÊù≠Â∑ûÁà±Âçö‰ªïÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 392„ÄÅ‰∫îÊòüÈáëÊúçÊéßËÇ°ÊúâÈôêÂÖ¨Âè∏\n    - 393„ÄÅÁ¶èÂª∫‰πêÊë©Áâ©ËÅîÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 394„ÄÅÁôæÁÇºÊô∫ËÉΩÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 395„ÄÅÂ±±‰∏úËÉΩÊ∫êÊï∞Êô∫‰∫ëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 396„ÄÅÊãõÂïÜÂ±ÄËÉΩÊ∫êËøêËæìËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 397„ÄÅ‰∏â‰∏ÄÈõÜÂõ¢„Äê‰∏â‰∏Ä„Äë\n    - 398„ÄÅ‰∏úÂ∑¥ÊñáÔºàÊ∑±Âú≥ÔºâÂÅ•Â∫∑ÁÆ°ÁêÜÊúâÈôêÂÖ¨Âè∏\n    - 399„ÄÅÁ¥¢ÊòìËΩØ‰ª∂\n    - 400„ÄÅÊ∑±Âú≥Â∏ÇÂÆÅËøúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 401„ÄÅÁÜôÁâõÂåªÁñó\n    - 402„ÄÅÂçó‰∫¨Êô∫Èπ§ÁîµÂ≠êÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 403„ÄÅÂòÄÂóíÂá∫Ë°å„ÄêÂòÄÂóíÂá∫Ë°å„Äë\n    - 404„ÄÅÂπøÂ∑ûËôéÁâô‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„ÄêËôéÁâô„Äë\n    - 405„ÄÅÂπøÂ∑ûÊ¨ßËé±ÈõÖÁôæÂ∫ìÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„ÄêÊ¨ßËé±ÈõÖ„Äë\n    - 406„ÄÅÂæÆÂæÆÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 407„ÄÅÊàëÁà±ÊàëÂÆ∂ÊàøÂú∞‰∫ßÁªèÁ∫™ÊúâÈôêÂÖ¨Âè∏„ÄêÊàëÁà±ÊàëÂÆ∂„Äë\n    - 408„ÄÅ‰πùÂè∑ÂèëÁé∞\n    - 409„ÄÅËñ™‰∫∫Ëñ™‰∫ã\n    - 410„ÄÅÊ≠¶Ê±âÊ∞™ÁªÜËÉûÁΩëÁªúÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 411„ÄÅÂπøÂ∑ûÂ∏ÇÊñØÂáØÂ•áÂïÜ‰∏öÊúâÈôêÂÖ¨Âè∏\n    - 412„ÄÅÂæÆÊ∑ºÂïÜÂ≠¶Èô¢\n    - 413„ÄÅÊù≠Â∑ûËΩ¶ÁõõÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 414„ÄÅÊ∑±ÂÖ∞ÁßëÊäÄÔºà‰∏äÊµ∑ÔºâÊúâÈôêÂÖ¨Âè∏\n    - 415„ÄÅÂÆâÂæΩ‰∏≠ÁßëÁæéÁªú‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 416„ÄÅÊØî‰∫öËø™Ê±ΩËΩ¶Â∑•‰∏öÊúâÈôêÂÖ¨Âè∏„ÄêÊØî‰∫öËø™„Äë\n    - 417„ÄÅÊπñÂçóÂ∞èÊ°î‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 418„ÄÅÂÆâÂæΩÁßëÂ§ßÂõΩÂàõËΩØ‰ª∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 419„ÄÅÂÖãËÄåÁëû\n    - 420„ÄÅÈôïË•ø‰∫ëÂü∫ÂçéÊµ∑‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 421„ÄÅÂÆâÂæΩÊ∑±ÂÆÅÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 422„ÄÅÂπø‰∏úÂ∫∑Áà±Â§öÊï∞Â≠óÂÅ•Â∫∑ÊúâÈôêÂÖ¨Âè∏\n    - 423„ÄÅÂòâÈáåÁîµÂ≠êÂïÜÂä°\n    - 424„ÄÅ‰∏äÊµ∑Êó∂‰ª£ÂÖâÂçéÊïôËÇ≤ÂèëÂ±ïÊúâÈôêÂÖ¨Âè∏\n    - 425„ÄÅCityDo\n    - 426„ÄÅ‰∏äÊµ∑Á¶πÁü•‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 427„ÄÅÂπø‰∏úÊô∫ÁëûÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 428„ÄÅË•øÂÆâÁà±Èì≠ÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 429„ÄÅÂøÉÂåªÂõΩÈôÖÊï∞Â≠óÂåªÁñóÁ≥ªÁªü(Â§ßËøû)ÊúâÈôêÂÖ¨Âè∏\n    - 430„ÄÅ‰πêÂÖ∂ÁîµÂïÜ\n    - 431„ÄÅÈîêËææÁßëÊäÄ\n    - 432„ÄÅÂ§©Ê¥•ÈïøÂüéÊª®Èì∂Ê±ΩËΩ¶ÈáëËûçÊúâÈôêÂÖ¨Âè∏\n    - 433„ÄÅ‰ª£Á†ÅÁΩë\n    - 434„ÄÅ‰∏úËéûÂ∏Ç‰∏úÂüé‰πî‰º¶ËΩØ‰ª∂ÂºÄÂèëÂ∑•‰ΩúÂÆ§\n    - 435„ÄÅÊµôÊ±üÁôæÂ∫îÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 436„ÄÅ‰∏äÊµ∑ÂäõÁà±Â∏ù‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏(Red E)\n    - 437„ÄÅ‰∫ëÂæôÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 438„ÄÅÂåó‰∫¨Â∫∑Êô∫‰πêÊÄùÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„ÄêÂ§ßÂß®ÂêóAPP„Äë\n    - 439„ÄÅÂÆâÂæΩÂºÄÂÖÉÁû¨ËßÜÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 440„ÄÅÁ´ãÊñπ\n    - 441„ÄÅÂé¶Èó®Á∫µË°åÁßëÊäÄ\n    - 442„ÄÅ‰πêÂ±±-Ëè≤Â∞ºÂÖãÊñØÂçäÂØº‰ΩìÊúâÈôêÂÖ¨Âè∏\n    - 443„ÄÅÊ≠¶Ê±âÂÖâË∞∑ËÅîÂêàÈõÜÂõ¢ÊúâÈôêÂÖ¨Âè∏\n    - 444„ÄÅ‰∏äÊµ∑Èáë‰ªïËææËΩØ‰ª∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 445„ÄÅÊ∑±Âú≥Êòì‰∏ñÈÄöËææÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 446„ÄÅÁà±Âä®Ë∂ÖË∂ä‰∫∫Â∑•Êô∫ËÉΩÁßëÊäÄÔºàÂåó‰∫¨ÔºâÊúâÈôêË¥£‰ªªÂÖ¨Âè∏\n    - 447„ÄÅËø™ÊôÆ‰ø°ÔºàÂåó‰∫¨ÔºâÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 448„ÄÅÊéåÁ´ôÁßëÊäÄÔºàÂåó‰∫¨ÔºâÊúâÈôêÂÖ¨Âè∏\n    - 449„ÄÅÊ∑±Âú≥Â∏ÇÂçé‰∫ë‰∏≠ÁõõËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 450„ÄÅ‰∏äÊµ∑ÂéüÂúàÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 451„ÄÅÂπøÂ∑ûËµûËµè‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 452„ÄÅAmber Group\n    - 453„ÄÅÂæ∑Â®ÅÂõΩÈôÖË¥ßËøê‰ª£ÁêÜÔºà‰∏äÊµ∑ÔºâÂÖ¨Âè∏\n    - 454„ÄÅÊµôÊ±üÊù∞Â§´ÂÖÑÂºüÊô∫ÊÖßÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 455„ÄÅ‰ø°‰πüÁßëÊäÄ\n    - 456„ÄÅÂºÄÊÄùÊó∂‰ª£ÁßëÊäÄÔºàÊ∑±Âú≥ÔºâÊúâÈôêÂÖ¨Âè∏\n    - 457„ÄÅÂ§ßËøûÊßêÂæ∑ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 458„ÄÅÂêåÁ®ãÁîüÊ¥ª\n    - 459„ÄÅÊùæÊûúÂá∫Ë°å\n    - 460„ÄÅ‰ºÅÈπÖÊùè‰ªÅÈõÜÂõ¢\n    - 461„ÄÅÂÆÅÊ≥¢Áßë‰∫ë‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 462„ÄÅ‰∏äÊµ∑Ê†ºËìùÂ®ÅÈ©∞‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 463„ÄÅÊù≠Â∑ûË∂£Ê∑òÈ≤∏ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 464„ÄÅÊπñÂ∑ûÂ∏ÇÊï∞Â≠óÊÉ†Ê∞ëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 465„ÄÅ‰πêÊôÆÔºàÂåó‰∫¨ÔºâÂåªÁñóÂô®Ê¢∞ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 466„ÄÅÂπøÂ∑ûÂ∏ÇÊô¥Â∑ùÈ´òÊñ∞ÊäÄÊúØÂºÄÂèëÊúâÈôêÂÖ¨Âè∏\n    - 467„ÄÅÂ±±Ë•øÁºáÂÆ¢ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 468„ÄÅÂæêÂ∑ûÂç°Ë•øÁ©ÜÁîµÂ≠êÂïÜÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 469„ÄÅÊ†ºÂàõ‰∏úÊô∫ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 470„ÄÅ‰∏ñÁ∫™Èæô‰ø°ÊÅØÁΩëÁªúÊúâÈôêË¥£‰ªªÂÖ¨Âè∏\n    - 471„ÄÅÈÇ¶ÈÅìÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 472„ÄÅÊ≤≥Âçó‰∏≠ÁõüÊñ∞‰∫ëÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 473„ÄÅÊ®™Áê¥‰∫∫ÂØø‰øùÈô©ÊúâÈôêÂÖ¨Âè∏\n    - 474„ÄÅ‰∏äÊµ∑Êµ∑ÈöÜÂçéÈíü‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 475„ÄÅ‰∏äÊµ∑‰πÖÊπõ\n    - 476„ÄÅ‰∏äÊµ∑‰ªôË±ÜÊô∫ËÉΩÊú∫Âô®‰∫∫ÊúâÈôêÂÖ¨Âè∏\n    - 477„ÄÅÂπøÂ∑ûÊ±áÂ∞öÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 478„ÄÅÊ∑±Âú≥Â∏ÇÈòøÂç°Á¥¢ËµÑËÆØËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 479„ÄÅÈùíÂ≤õ‰Ω≥ÂÆ∂Â∫∑ÂÅ•Â∫∑ÁÆ°ÁêÜÊúâÈôêË¥£‰ªªÂÖ¨Âè∏\n    - 480„ÄÅËìùÂüéÂÖÑÂºü\n    - 481„ÄÅÊàêÈÉΩÂ§©Â∫úÈÄöÈáëËûçÊúçÂä°ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 482„ÄÅÊ∑±Âú≥‰∫ëÈïñÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 483„ÄÅ‰∏äÊµ∑ÂΩ±ÂàõÁßëÊäÄ\n    - 484„ÄÅÊàêÈÉΩËâæÊãâÁâ©ËÅî\n    - 485„ÄÅÂåó‰∫¨ÂÆ¢ÈÇªÂ∞öÂìÅÁΩëÁªúÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 486„ÄÅITÂÆûÊàòËÅîÁõü\n    - 487„ÄÅÊù≠Â∑ûÂ∞§ÊãâÂ§´ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 488„ÄÅ‰∏≠Â§ßÊ£ÄÊµã(ÊπñÂçó)ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 489„ÄÅÊ±üËãèÁîµËÄÅËôéÂ∑•‰∏ö‰∫íËÅîÁΩëËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 490„ÄÅ‰∏äÊµ∑Âä©ÈÄö‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 491„ÄÅÂåó‰∫¨Á¨¶ËäÇÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 492„ÄÅÊù≠Â∑ûËã±Á•êÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 493„ÄÅÊ±üËãèÁîµËÄÅËôéÂ∑•‰∏ö‰∫íËÅîÁΩëËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 494„ÄÅÊ∑±Âú≥Â∏ÇÁÇπÁå´ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 495„ÄÅÊù≠Â∑ûÂ§©Èü≥\n    - 496„ÄÅÊ∑±Âú≥Â∏Ç‰∫åÂçÅ‰∏ÄÁßëÊäÄ‰∫íËÅîÁΩëÊúâÈôêÂÖ¨Âè∏\n    - 497„ÄÅÊµ∑ÂçóÊµ∑Âè£ÁøéÂ∫¶ÁßëÊäÄ\n    - 498„ÄÅÂåó‰∫¨Â∞èË∂£Êô∫ÂìÅÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 499„ÄÅÂπøÂ∑ûÁü≥Á´πËÆ°ÁÆóÊú∫ËΩØ‰ª∂ÊúâÈôêÂÖ¨Âè∏\n    - 500„ÄÅÊ∑±Âú≥Â∏ÇÊÉüÂÆ¢Êï∞ÊçÆÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 501„ÄÅ‰∏≠ÂõΩÂåªÁñóÂô®Ê¢∞ÊúâÈôêÂÖ¨Âè∏\n    - 502„ÄÅ‰∏äÊµ∑‰∫ëË∞¶ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 503„ÄÅ‰∏äÊµ∑Á£êÂÜú‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 504„ÄÅÂπøÂ∑ûÈ¢ÜËà™È£üÂìÅÊúâÈôêÂÖ¨Âè∏\n    - 505„ÄÅÈùíÂ≤õÊéåËÆØÈÄöÂå∫ÂùóÈìæÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 506„ÄÅÂåó‰∫¨Êñ∞ÁΩëÊï∞Á†Å‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 507„ÄÅË∂Ö‰Ωì‰ø°ÊÅØÁßëÊäÄ(Ê∑±Âú≥)ÊúâÈôêÂÖ¨Âè∏\n    - 508„ÄÅÈïøÊ≤ôÂ∫óÂ∏ÆÊâã‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 509„ÄÅ‰∏äÊµ∑Âä©ÂºìË£ÖÈ•∞Â∑•Á®ãÊúâÈôêÂÖ¨Âè∏\n    - 510„ÄÅÊù≠Â∑ûÂØªËÅîÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 511„ÄÅÊàêÈÉΩÂ§ßÊ∑òÂÆ¢ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 512„ÄÅÊùæÊûúÂá∫Ë°å\n    - 513„ÄÅÊ∑±Âú≥Â∏ÇÂî§Ê¢¶ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 514„ÄÅ‰∏äÊ±ΩÈõÜÂõ¢ÂïÜÁî®ËΩ¶ÊäÄÊúØ‰∏≠ÂøÉ\n    - 515„ÄÅÂåó‰∫¨‰∏≠Ëà™ËÆØÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 516„ÄÅÂåóÈæô‰∏≠ÁΩë(Âåó‰∫¨)ÁßëÊäÄÊúâÈôêË¥£‰ªªÂÖ¨Âè∏\n    - 517„ÄÅÂâçÊµ∑Ë∂ÖÁ∫ßÂâçÂè∞(Ê∑±Âú≥)‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 518„ÄÅ‰∏äÊµ∑‰∏≠ÂïÜÁΩëÁªúËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 519„ÄÅ‰∏äÊµ∑Âä©ÈÄö‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 520„ÄÅÂÆÅÊ≥¢ËÅöËáªÊô∫ËÉΩÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 521„ÄÅ‰∏äÊµ∑Èõ∂Âä®Êï∞Á†ÅÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 522„ÄÅÊµôÊ±üÂ≠¶Êµ∑ÊïôËÇ≤ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 523„ÄÅËÅöÂ≠¶‰∫ë(Â±±‰∏ú)‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 524„ÄÅÂ§öÊ∞üÂ§öÊñ∞ÊùêÊñôËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 525„ÄÅÊô∫ÊÖßÁúºÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 526„ÄÅÂπø‰∏úÊô∫ÈÄö‰∫∫ÊâçËøûÈîÅËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 527„ÄÅ‰∏ñÁ∫™ÂºÄÂÖÉÊô∫Âç∞‰∫íËÅîÁßëÊäÄÈõÜÂõ¢ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 528„ÄÅÂåó‰∫¨ÁêÜÊÉ≥Ê±ΩËΩ¶„ÄêÁêÜÊÉ≥Ê±ΩËΩ¶„Äë\n    - 529„ÄÅÂ∑ΩÈÄ∏ÁßëÊäÄ(ÈáçÂ∫Ü)ÊúâÈôêÂÖ¨Âè∏\n    - 530„ÄÅ‰πâ‰πåË¥≠ÁîµÂ≠êÂïÜÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 531„ÄÅÊ∑±Âú≥Â∏ÇÁèÇËé±ËíÇÂ∞îÊúçÈ•∞ÊúâÈôêÂÖ¨Âè∏\n    - 532„ÄÅÊ±üË•øÂõΩÊ≥∞Âà©Ê∞ë‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 533„ÄÅÂπøË•øÂπøÁîµÂ§ßÊï∞ÊçÆÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 534„ÄÅÊù≠Â∑ûËâæÈ∫¶ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 535„ÄÅÂπøÂ∑ûÂ∞èÊª¥ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 536„ÄÅ‰Ω≥ÁºòÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 537„ÄÅ‰∏äÊµ∑Ê∑±Êìé‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 538„ÄÅÊ≠¶ÂïÜÁΩë\n    - 539„ÄÅÁ¶èÂª∫Ê∞ëÊú¨‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 540„ÄÅÊù≠Â∑ûÊÉ†Âêà‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 541„ÄÅÂé¶Èó®Áà±Á´ãÂæóÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 542„ÄÅÊàêÈÉΩÊãüÂêàÊú™Êù•ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 543„ÄÅÂÆÅÊ≥¢ËÅöËáªÊô∫ËÉΩÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 544„ÄÅÂπø‰∏úÁôæÊÖßÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 545„ÄÅÁ¨®È©¨ÁΩëÁªú\n    - 546„ÄÅÊ∑±Âú≥Â∏Ç‰ø°ÂÆâÊï∞Â≠óÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 547„ÄÅÊ∑±Âú≥Â∏ÇÊÄù‰πêÊï∞ÊçÆÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 548„ÄÅÂõõÂ∑ùÁªøÊ∫êÈõÜÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 549„ÄÅÊπñÂçó‰∫ëÂåªÈìæÁîüÁâ©ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 550„ÄÅÊù≠Â∑ûÊ∫êËØöÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 551„ÄÅÂåó‰∫¨ÂºÄËØæÂêßÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 552„ÄÅÂåó‰∫¨Â§öÊù•ÁÇπ‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 553„ÄÅJEECG BOOT‰Ωé‰ª£Á†ÅÂºÄÂèëÂπ≥Âè∞\n    - 554„ÄÅËãèÂ∑ûÂêåÂÖÉËΩØÊéß‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 555„ÄÅÊ±üËãèÂ§ßÊ≥∞‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 556„ÄÅÂåó‰∫¨Â§ßÁ¶πÊ±áÊô∫\n    - 557„ÄÅÂåó‰∫¨ÁõõÂì≤ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 558„ÄÅÂπøÂ∑ûÈíõÂä®ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 559„ÄÅÂåó‰∫¨Â§ßÁ¶πÊ±áÊô∫ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 560„ÄÅÊπñÂçóÈºéÁø∞ÊñáÂåñËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 561„ÄÅËãèÂ∑ûÂÆâËΩØ‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 562„ÄÅËäíÊûútv\n    - 563„ÄÅ‰∏äÊµ∑Ëâ∫ËµõÊóóËΩØ‰ª∂ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 564„ÄÅ‰∏≠Áõà‰ºòÂàõËµÑËÆØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 565„ÄÅ‰πê‰πéÂÖ¨ÂØì\n    - 566„ÄÅÂêØÊòé‰ø°ÊÅØ\n    - 567„ÄÅËãèÂ∑ûÂÆâËΩØ\n    - 568„ÄÅÂçó‰∫¨ÂØåÈáëÁöÑËΩØ‰ª∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 569„ÄÅÊ∑±Âú≥Â∏ÇÊñ∞ÁßëËÅöÂêàÁΩëÁªúÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 570„ÄÅ‰Ω†Â•ΩÁé∞Âú®(Âåó‰∫¨)ÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 571„ÄÅ360ËÄÉËØïÂÆùÂÖ∏\n    - 572„ÄÅÂåó‰∫¨‰∏ÄÈõ∂ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 573„ÄÅÂé¶Èó®ÊòüÁ∫µ‰ø°ÊÅØ\n    - 574„ÄÅDalligent Solusi Indonesia\n    - 575„ÄÅÊ∑±Âú≥ÂçéÊôÆÁâ©ËÅîÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 576„ÄÅÊ∑±Âú≥Ë°åÂÅ•Ëá™Âä®ÂåñËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 577„ÄÅÊ∑±Âú≥Â∏ÇÂØåËûç‰ø°ÊÅØÁßëÊäÄÊúçÂä°ÊúâÈôêÂÖ¨Âè∏\n    - 578„ÄÅËìùÈ∏ü‰∫ë\n    - 579„ÄÅ‰∏äÊµ∑ÊæéÂçöË¥¢ÁªèËµÑËÆØÊúâÈôêÂÖ¨Âè∏\n    - 580„ÄÅÂåó‰∫¨Â∞èÈ∏¶ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 581„ÄÅÊù≠Â∑ûÁõàÊ≥â‰∫ëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 582„ÄÅÊÉüÂÆ¢Êï∞ÊçÆ\n    - 583„ÄÅGOSOÈ¶ôËúúÈó∫ÁßÄ\n    - 584„ÄÅÊôÆ‰πêÂ∏àÔºà‰∏äÊµ∑ÔºâÊï∞Â≠óÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 585„ÄÅË•øÂÆâÂ∏ÇÈõÅÂ°îÂå∫ÂíñÂåóÂ†ÇÁΩëÁªúÁßëÊäÄÈÉ®\n    - 586„ÄÅÂÆÅÊ≥¢ËÅöËáªÊô∫ËÉΩÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 587„ÄÅÊôÆ‰πêÂ∏àÊï∞Â≠óÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 588„ÄÅÊ±üËãèËüπËÅîÁΩëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 589„ÄÅÊù≠Â∑ûÊú™Êô∫ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 590„ÄÅÂÆâÂêâÊô∫Ë°åÁâ©ÊµÅÊúâÈôêÂÖ¨Âè∏\n    - 591„ÄÅÂçéÁîüÂ§ßÂÆ∂Â±ÖÈõÜÂõ¢ÊúâÈôêÂÖ¨Âè∏\n    - 592„ÄÅÁæéÂøÉÈ£üÂìÅÔºàÂπøÂ∑ûÔºâÊúâÈôêÂÖ¨Âè∏\n    - 593„ÄÅË¥ßÊãâÊãâ„ÄêË¥ßÊãâÊãâAPP„Äë\n    - 594„ÄÅÊù≠Â∑ûÊÄùÈü¨ÁëûÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 595„ÄÅÊù≠Â∑ûÁéñËûçÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 596„ÄÅÂåó‰∫¨‰ºòÊµ∑ÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 597„ÄÅÊµôÊ±üÂ§ßÁª¥È´òÊñ∞ÊäÄÊúØËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 598„ÄÅÁ≤§Ê∏ØÊæ≥Â§ßÊπæÂå∫Êï∞Â≠óÁªèÊµéÁ†îÁ©∂Èô¢\n    - 599„ÄÅÊôÆÂ∫∑ÔºàÊù≠Â∑ûÔºâÂÅ•Â∫∑ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 600„ÄÅÂçéË•øËØÅÂà∏ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„ÄêÂçéË•øËØÅÂà∏„Äë\n    - 601„ÄÅÊù≠Â∑ûÊµ∑Â∫∑Êú∫Âô®‰∫∫ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„ÄêÊµ∑Â∫∑„Äë\n    - 602„ÄÅÊ≤≥ÂçóÂÆ∏ÈÇ¶‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 603„ÄÅÊàêÈÉΩÊ¨°ÂÖÉËäÇÁÇπÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 604„ÄÅÂØåÂ£´Â∫∑ÁßëÊäÄÈõÜÂõ¢„ÄêÂØåÂ£´Â∫∑„Äë\n    - 605„ÄÅÈùíÂ≤õ‰∏úËΩØËΩΩÊ≥¢ÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 606„ÄÅÂ∞èËèäÂø´Ë∑ëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 607„ÄÅËßÜÊ∫êËÇ°‰ªΩ\n    - 608„ÄÅÂÆÅÊ≥¢ËÅöËáªÊô∫ËÉΩÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 609„ÄÅÈòîÂ§©ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 610„ÄÅÁΩëÂÆøÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 611„ÄÅÂçó‰∫¨Ê¢µÈºé‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 612„ÄÅÊàøÂ§©‰∏ã„ÄêÊàøÂ§©‰∏ã„Äë\n    - 613„ÄÅÁâπÁì¶ÁâπËÉΩÊ∫êÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 614„ÄÅÊãìËø™Êô∫ËÉΩÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 615„ÄÅ‰∏úËΩØÈõÜÂõ¢„Äê‰∏úËΩØ„Äë\n    - 616„ÄÅÂºÄÊôÆ‰∫ë\n    - 617„ÄÅÈ¢ÜËØæÁΩëÁªú\n    - 618„ÄÅÂçó‰∫¨ÁâπÁª¥ËΩØ‰ª∂ÊúâÈôêÂÖ¨Âè∏\n    - 619„ÄÅÁ¶èÂª∫ÊòìËÅî‰ºó‰øùÁùøÈÄö‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 620„ÄÅÊµôÊ±üÊ†∏ÂøÉÂêåËä±È°∫ÈáëËûçÁßëÊäÄÊúâÈôêÂÖ¨Âè∏„ÄêÂêåËä±È°∫„Äë\n    - 621„ÄÅÊµôÊ±üÂçöËßÇÁëûÊÄùÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 622„ÄÅÂåó‰∫¨Êñ∞Áæé‰∫íÈÄöÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 623„ÄÅÂåó‰∫¨ÊúâÁîüÂçöÂ§ßËΩØ‰ª∂ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 624„ÄÅÊó∂‰ª£‰∏≠ÂõΩ\n    - 625„ÄÅÈ±ºÊ≥°ÁΩë\n    - 626„ÄÅ‰∏ÄÁ≤íÊñπÁ≥ñÔºàÂÆâÂæΩÔºâÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 627„ÄÅÂåó‰∫¨Â§ñÁ†îÂú®Á∫øÊï∞Â≠óÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 628„ÄÅÂæ∑ÁîµÔºà‰∏≠ÂõΩÔºâÈÄö‰ø°ÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 629„ÄÅÊù≠Â∑ûÂØªËÅîÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 630„ÄÅÊ©ôËÅîÔºà‰∏≠ÂõΩÔºâÊúâÈôêÂÖ¨Âè∏\n    - 631„ÄÅÂåó‰∫¨ÊâøÂêØÈÄöÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 632„ÄÅÈì∂ËÅîÊï∞ÊçÆÊúçÂä°ÊúâÈôêÂÖ¨Âè∏„ÄêÈì∂ËÅî„Äë\n    - 633„ÄÅ‰∏äÊµ∑Êô∂Á°ÆÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 634„ÄÅ‰∫ö‰ø°ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 635„ÄÅÁ¶èÂª∫Êñ∞Ëà™Áâ©ËÅîÁΩëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 636„ÄÅ‰∏äÊâ¨ËΩØ‰ª∂\n    - 637„ÄÅÊ∑±ËìùÊ±ΩËΩ¶ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 638„ÄÅÂçóÊòåËäÇÁÇπÊ±áÊô∫ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 639„ÄÅÈîêÊòéÊäÄÊúØ\n    - 640„ÄÅÂÜçÈÄ†ÂÜçÁîüÂÅ•Â∫∑ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 641„ÄÅÂçéÂÆùËØÅÂà∏\n    - 642„ÄÅÂçìÊ≠£ÂåªÁñó\n    - 643„ÄÅÊ∑±Âú≥Êπõ‰ø°ÁßëÊäÄ\n    - 644„ÄÅÈôïË•øÈë´‰ºó‰∏∫ËΩØ‰ª∂ÊúâÈôêÂÖ¨Âè∏\n    - 645„ÄÅÊ∑±Âú≥Â∏ÇÊ∂¶ÂÜúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 646„ÄÅÂ∫öÂïÜÊïôËÇ≤Êô∫ËÉΩÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 647„ÄÅÊù≠Â∑ûÁ•éÂ£∞ÁßëÊäÄ\n    - 648„ÄÅÂõõÂ∑ù‰πÖËøúÈì∂Êµ∑ËΩØ‰ª∂ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 649„ÄÅGeeFoxÊûÅÁãê‰Ωé‰ª£Á†Å\n    - 650„ÄÅÊµôÊ±üÂíå‰ªÅÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 651„ÄÅÂÆÅÊ≥¢ËÅöËáªÊô∫ËÉΩÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 652„ÄÅÁ¶èÂª∫Á¶èÊòïËΩØ‰ª∂ÂºÄÂèëËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„ÄêÁ¶èÊòï„Äë\n    - 653„ÄÅÂπøÂ∑û‰∏≠ÈïøÂ∫∑Ëææ‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 654„ÄÅÊ≠¶Ê±âË∂£Êîπ‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 655„ÄÅÂåó‰∫¨ÂçéÂ§èÊÄùÊ∫êÁßëÊäÄÂèëÂ±ïÊúâÈôêÂÖ¨Âè∏\n    - 656„ÄÅÂÆÅÊ≥¢ÂÖ≥ÂÖ≥ÈÄöÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 657„ÄÅÈùíÂ≤õÂêïÊ∞èÈ§êÈ•ÆÊúâÈôêÂÖ¨Âè∏\n    - 658„ÄÅÊù≠Â∑û‰πêÂàªÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 659„ÄÅ‰∏äÊµ∑Á∫¢Áì¶‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 660„ÄÅÈôïË•øÊóÖÂ∞èÂÆù‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 661„ÄÅ‰∏≠ÁßëÂçìÊÅí(Â§ßËøû)ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 662„ÄÅÂåó‰∫¨ÂçéÁõäÁ≤æÁÇπÁîüÁâ©ÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 663„ÄÅÈ©¨Â£´Âü∫Ôºà‰∏≠ÂõΩÔºâËà™ËøêÊúâÈôêÂÖ¨Âè∏„ÄêÈ©¨Â£´Âü∫„Äë\n    - 664„ÄÅÈôïË•øÁæéÂíöÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 665„ÄÅÂ±±‰∏úÊñ∞ÂåóÊ¥ã‰ø°ÊÅØÊäÄÊúØËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏ \n    - 666„ÄÅÁ¶èÂª∫‰∏≠ÁëûÊñáÂåñÂèëÂ±ïÈõÜÂõ¢ÊúâÈôêÂÖ¨Âè∏\n    - 667„ÄÅÈªëÈæôÊ±üÁúÅÂª∫Â∑•ÈõÜÂõ¢ÊúâÈôêË¥£‰ªªÂÖ¨Âè∏„ÄêÈªëÈæôÊ±üÁúÅÂª∫Â∑•„Äë\n    - 668„ÄÅÂøó‰ø°ËÉΩËææÂÆâÂÖ®ÁßëÊäÄ(ÂπøÂ∑û)ÊúâÈôêÂÖ¨Âè∏\n    - 669„ÄÅÈáçÂ∫ÜÂºÄÊ∫êÂÖ±ÂàõÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 670„ÄÅÂçéÊ≥∞‰∫∫ÂØø‰øùÈô©ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„ÄêÂçéÊ≥∞‰∫∫ÂØø„Äë\n    - 671„ÄÅÊàêÈÉΩÁõòÂè§Á∫µÊ®™ÈõÜÂõ¢\n    - 672„ÄÅÂåó‰∫¨ÊûúÊûú‰πêÂ≠¶ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 673„ÄÅÂåó‰∫¨Âáå‰∫ëÁ©∫Èó¥ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 674„ÄÅ‰∏¥Â∑•ÈáçÊú∫ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 675„ÄÅ‰∏äÊµ∑ÁÉ≠È£éÊó∂Â∞öÁÆ°ÁêÜÈõÜÂõ¢„ÄêÁÉ≠È£é„Äë\n    - 676„ÄÅHashKey Exchange\n    - 677„ÄÅÂÇ≤Âü∫ÔºàÊ∑±Âú≥ÔºâË∑®Â¢ÉÂïÜÂä°ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 678„ÄÅÈùíÂ≤õÊñáËææÈÄöÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 679„ÄÅÊù≠Â∑ûÊôÆÁΩó‰∫ëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 680„ÄÅÊµôÊ±ü‰∫ëÈπ≠ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 681„ÄÅ‰∏≠Â±±Â∏ÇËäØÂÆèÊüøÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 682„ÄÅÊ∑±Âú≥Â∏ÇÂÆ∂ÂÆ∂È°∫Áâ©ËÅîÁßëÊäÄ\n    - 683„ÄÅÈáçÂ∫ÜÊñëË•øÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 684„ÄÅÁ¶èÂª∫ÁúÅÊ≥∞Âè§‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 685„ÄÅË¥µÈò≥Ê∞∏Èùí‰ª™ÁîµÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 686„ÄÅÂπøÂ∑ûÂçö‰æùÁâπÊô∫ËÉΩ‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 687„ÄÅÊ≤≥ÂçóÂÆ†Âë¶Âë¶‰ø°ÊÅØÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 688„ÄÅÈôïË•øÊòüÈÇëÁ©∫Èó¥ÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 689„ÄÅÂπø‰∏úË•øÊ¨ßÂÖãÂÆû‰∏öÊúâÈôêÂÖ¨Âè∏\n    - 690„ÄÅÂî±ÂêßÈ∫¶È¢ÇKTV\n    - 691„ÄÅËÅîÈÄö‰∫ë\n    - 692„ÄÅÂåó‰∫¨Áà±ËØùÊú¨ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 693„ÄÅÂåó‰∫¨Ëµ∑ÂàõÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 694„ÄÅÂπ≥ÂÆâËØÅÂà∏„ÄêÂπ≥ÂÆâËØÅÂà∏„Äë\n    - 695„ÄÅÂêàËÇ•‰∏≠ÁßëÁ±ªËÑëÊô∫ËÉΩÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 696„ÄÅÂçó‰∫¨Âêå‰ªÅÂ†ÇÂÅ•Â∫∑‰∫ß‰∏öÊúâÈôêÂÖ¨Âè∏„ÄêÂêå‰ªÅÂ†Ç„Äë\n    - 697„ÄÅÈìú‰ªÅÂ∏ÇÁ¢ßÊ±üÂå∫Êô∫ÊÉ†Âä†Ê≤πÁ´ô\n    - 698„ÄÅÊÉüÂÆ¢Êï∞ÊçÆ\n    - 699„ÄÅÂá§Âá∞Êñ∞Èóª„ÄêÂá§Âá∞Êñ∞Èóª„Äë\n    - 700„ÄÅÊ∑±Âú≥ÁéãÂäõÊô∫ËÉΩ\n    - 701„ÄÅËøîÂà©ÁΩëÊï∞Â≠óÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 702„ÄÅ‰∏äÊµ∑ÈòúËÉΩ‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 703„ÄÅÊ∑±Âú≥Â∏ÇÊûÅËÉΩË∂ÖÁîµÊï∞Â≠óÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 704„ÄÅÊµ∑ÁõÆÊòüÊøÄÂÖâÁßëÊäÄÈõÜÂõ¢ËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏\n    - 705„ÄÅÂÆâÂÖãÂàõÊñ∞ÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„ÄêÂÆâÂÖã„Äë\n    - 706„ÄÅÂ§ßÂ∫ÜÁÇπÁ•ûÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 707„ÄÅÊµôÊ±üÈõ∂Ë∑ëÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„ÄêÈõ∂Ë∑ë„Äë\n    - 708„ÄÅÊàêÈÉΩÊàêÁîµÈáëÁõòÂÅ•Â∫∑Êï∞ÊçÆÊäÄÊúØÊúâÈôêÂÖ¨Âè∏\n    - 709„ÄÅÊàêÈÉΩÊûÅÁ±≥ÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏„ÄêÊûÅÁ±≥„Äë\n    - 710„ÄÅÈ°∫Âæ∑ËÅå‰∏öÊäÄÊúØÂ§ßÂ≠¶\n    - 711„ÄÅ‰∏≠ÈÇÆËØÅÂà∏ÊúâÈôêË¥£‰ªªÂÖ¨Âè∏„Äê‰∏≠ÈÇÆËØÅÂà∏„Äë\n    - 712„ÄÅÂøóË±™Èìæ‰∫ëÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 713„ÄÅÊπñÂçó‰∏áÈ≤∏ÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 714„ÄÅÂπøÂ∑û‰∏áË°®\n    - 715„ÄÅÂÜçÊÉ†Ôºà‰∏äÊµ∑ÔºâÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 716„ÄÅ‰∏äÊµ∑Áà±ËØöË£ï‰ø°ÊÅØÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 717„ÄÅÊù≠Â∑ûËøàÁëûÊï∞Â≠óÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - 718„ÄÅÂπøÂ∑û‰∏≤ËÅîÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏\n    - ‚Ä¶‚Ä¶\n\n> Êõ¥Â§öÊé•ÂÖ•ÁöÑÂÖ¨Âè∏ÔºåÊ¨¢ËøéÂú® [ÁôªËÆ∞Âú∞ÂùÄ](https://github.com/xuxueli/xxl-job/issues/1 ) ÁôªËÆ∞ÔºåÁôªËÆ∞‰ªÖ‰ªÖ‰∏∫‰∫Ü‰∫ßÂìÅÊé®Âπø„ÄÇ\n\nÊ¨¢ËøéÂ§ßÂÆ∂ÁöÑÂÖ≥Ê≥®Âíå‰ΩøÁî®ÔºåXXL-JOB‰πüÂ∞ÜÊã•Êä±ÂèòÂåñÔºåÊåÅÁª≠ÂèëÂ±ï„ÄÇ\n\n\n## Contributing\nContributions are welcome! Open a pull request to fix a bug, or open an [Issue](https://github.com/xuxueli/xxl-job/issues/) to discuss a new feature or change.\n\nÊ¨¢ËøéÂèÇ‰∏éÈ°πÁõÆË¥°ÁåÆÔºÅÊØîÂ¶ÇÊèê‰∫§PR‰øÆÂ§ç‰∏Ä‰∏™bugÔºåÊàñËÄÖÊñ∞Âª∫ [Issue](https://github.com/xuxueli/xxl-job/issues/) ËÆ®ËÆ∫Êñ∞ÁâπÊÄßÊàñËÄÖÂèòÊõ¥„ÄÇ\n\n\n## Copyright and License\nThis product is open source and free, and will continue to provide free community technical support. Individual or enterprise users are free to access and use.\n\n- Licensed under the GNU General Public License (GPL) v3.\n- Copyright (c) 2015-present, xuxueli.\n\n‰∫ßÂìÅÂºÄÊ∫êÂÖçË¥πÔºåÂπ∂‰∏îÂ∞ÜÊåÅÁª≠Êèê‰æõÂÖçË¥πÁöÑÁ§æÂå∫ÊäÄÊúØÊîØÊåÅ„ÄÇ‰∏™‰∫∫Êàñ‰ºÅ‰∏öÂÜÖÈÉ®ÂèØËá™Áî±ÁöÑÊé•ÂÖ•Âíå‰ΩøÁî®„ÄÇÂ¶ÇÊúâÈúÄË¶ÅÂèØ [ÈÇÆ‰ª∂ËÅîÁ≥ª](https://www.xuxueli.com/page/community.html) ‰ΩúËÄÖÂÖçË¥πËé∑ÂèñÈ°πÁõÆÊéàÊùÉ„ÄÇ\n",
      "stars_today": 8
    },
    {
      "id": 33014811,
      "name": "notepad-plus-plus",
      "full_name": "notepad-plus-plus/notepad-plus-plus",
      "description": "Notepad++ official repository",
      "html_url": "https://github.com/notepad-plus-plus/notepad-plus-plus",
      "stars": 26746,
      "forks": 5055,
      "language": "C++",
      "topics": [
        "editor",
        "notepad",
        "notepad-official",
        "windows"
      ],
      "created_at": "2015-03-28T00:05:08Z",
      "updated_at": "2026-01-17T00:27:03Z",
      "pushed_at": "2026-01-15T22:22:15Z",
      "open_issues": 2811,
      "owner": {
        "login": "notepad-plus-plus",
        "avatar_url": "https://avatars.githubusercontent.com/u/12589084?v=4"
      },
      "readme": "What is Notepad++ ?\r\n===================\r\n\r\n[![GitHub release](https://img.shields.io/github/release/notepad-plus-plus/notepad-plus-plus.svg)](../../releases/latest)&nbsp;&nbsp;&nbsp;&nbsp;[![Build Status](https://img.shields.io/github/actions/workflow/status/notepad-plus-plus/notepad-plus-plus/CI_build.yml)](https://github.com/notepad-plus-plus/notepad-plus-plus/actions/workflows/CI_build.yml)\r\n&nbsp;&nbsp;&nbsp;&nbsp;[![Join the discussions at https://community.notepad-plus-plus.org/](https://notepad-plus-plus.org/assets/images/NppCommunityBadge.svg)](https://community.notepad-plus-plus.org/)\r\n\r\nNotepad++ is a free (free as in both \"free speech\" and \"free beer\") source code\r\neditor and Notepad replacement that supports several programming languages and\r\nnatural languages. Running in the MS Windows environment, its use is governed by\r\n[GPL License](LICENSE).\r\n\r\nSee the [Notepad++ official site](https://notepad-plus-plus.org/) for more information.\r\n\r\n\r\nNotepad++ GPG Release Key\r\n-------------------------\r\n_Since the release of version 7.6.5 Notepad++ is signed using GPG with the following key:_\r\n\r\n- **Signer:** Notepad++\r\n- **E-mail:** don.h@free.fr\r\n- **Key ID:** 0x8D84F46E\r\n- **Key fingerprint:** 14BC E436 2749 B2B5 1F8C 7122 6C42 9F1D 8D84 F46E\r\n- **Key type:** RSA 4096/4096\r\n- **Created:** 2019-03-11\r\n- **Expires:** 2027-03-13\r\n\r\nhttps://github.com/notepad-plus-plus/notepad-plus-plus/blob/master/nppGpgPub.asc\r\n\r\n\r\nSupported OS\r\n------------\r\n\r\nAll the Windows systems still supported by Microsoft are supported by Notepad++. However, not all Notepad++ users can or want to use the newest system. Here is the [Supported systems information](SUPPORTED_SYSTEM.md) you may need in case you are one of them.\r\n\r\n\r\n\r\n\r\nBuild Notepad++\r\n---------------\r\n\r\nPlease follow [build guide](BUILD.md) to build Notepad++ from source.\r\n\r\n\r\nContribution\r\n------------\r\n\r\nContributions are welcome. Be mindful of our [Contribution Rules](CONTRIBUTING.md) to increase the likelihood of your contribution getting accepted.\r\n\r\n[Notepad++ Contributors](https://github.com/notepad-plus-plus/notepad-plus-plus/graphs/contributors)\r\n\r\n",
      "stars_today": 8
    },
    {
      "id": 2310495,
      "name": "ceph",
      "full_name": "ceph/ceph",
      "description": "Ceph is a distributed object, block, and file storage platform ",
      "html_url": "https://github.com/ceph/ceph",
      "stars": 16090,
      "forks": 6254,
      "language": "C++",
      "topics": [
        "block-storage",
        "cloud-storage",
        "distributed-file-system",
        "distributed-storage",
        "erasure-coding",
        "fuse",
        "hdfs",
        "high-performance",
        "highly-available",
        "iscsi",
        "kubernetes",
        "nfs",
        "nvme-over-fabrics",
        "object-store",
        "posix",
        "replication",
        "s3",
        "smb",
        "software-defined-storage",
        "storage"
      ],
      "created_at": "2011-09-01T21:41:26Z",
      "updated_at": "2026-01-17T00:44:25Z",
      "pushed_at": "2026-01-16T21:19:54Z",
      "open_issues": 930,
      "owner": {
        "login": "ceph",
        "avatar_url": "https://avatars.githubusercontent.com/u/1015767?v=4"
      },
      "readme": "# Ceph - a scalable distributed storage system\n\nSee https://ceph.com/ for current information about Ceph.\n\n## Status\n\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/2220/badge)](https://www.bestpractices.dev/projects/2220)\n[![Issue Backporting](https://github.com/ceph/ceph/actions/workflows/create-backport-trackers.yml/badge.svg)](https://github.com/ceph/ceph/actions/workflows/create-backport-trackers.yml)\n\n## Contributing Code\n\nMost of Ceph is dual-licensed under the LGPL version 2.1 or 3.0. Some\nmiscellaneous code is either public domain or licensed under a BSD-style\nlicense.\n\nThe Ceph documentation is licensed under Creative Commons Attribution Share\nAlike 3.0 (CC-BY-SA-3.0). \n\nSome headers included in the `ceph/ceph` repository are licensed under the GPL.\nSee the file `COPYING` for a full inventory of licenses by file.\n\nAll code contributions must include a valid \"Signed-off-by\" line. See the file\n`SubmittingPatches.rst` for details on this and instructions on how to generate\nand submit patches.\n\nAssignment of copyright is not required to contribute code. Code is\ncontributed under the terms of the applicable license.\n\n\n## Checking out the source\n\nClone the ceph/ceph repository from github by running the following command on\na system that has git installed:\n\n\tgit clone git@github.com:ceph/ceph\n\nAlternatively, if you are not a github user, you should run the following\ncommand on a system that has git installed:\n\n\tgit clone https://github.com/ceph/ceph.git\n\nWhen the `ceph/ceph` repository has been cloned to your system, run the\nfollowing commands to move into the cloned `ceph/ceph` repository and to check\nout the git submodules associated with it:\n\n    cd ceph\n\tgit submodule update --init --recursive --progress\n\n\n## Build Prerequisites\n\n*section last updated 06 Sep 2024*\n\nWe provide the Debian and Ubuntu ``apt`` commands in this procedure. If you use\na system with a different package manager, then you will have to use different\ncommands. \n\n#. Install ``curl``:\n\n    apt install curl\n\n#. Install package dependencies by running the ``install-deps.sh`` script:\n\n\t./install-deps.sh\n\n#. Install the ``python3-routes`` package:\n\n    apt install python3-routes\n\n\n## Building Ceph\n\nThese instructions are meant for developers who are compiling the code for\ndevelopment and testing. To build binaries that are suitable for installation\nwe recommend that you build `.deb` or `.rpm` packages, or refer to\n``ceph.spec.in`` or ``debian/rules`` to see which configuration options are\nspecified for production builds.\n\nTo build Ceph, follow this procedure: \n\n1. Make sure that you are in the top-level `ceph` directory that\n   contains `do_cmake.sh` and `CONTRIBUTING.rst`.\n2. Run the `do_cmake.sh` script:\n\n       ./do_cmake.sh\n\n   See [build types](#build-types).\n\n3. Move into the `build` directory:\n\n       cd build\n4. Use the `ninja` buildsystem to build the development environment:\n\n       ninja -j3\n\n   > [!IMPORTANT]\n   >\n   > [Ninja](https://ninja-build.org/) is the build system used by the Ceph\n   > project to build test builds.  The number of jobs used by `ninja` is \n   > derived from the number of CPU cores of the building host if unspecified. \n   > Use the `-j` option to limit the job number if build jobs are running \n   > out of memory. If you attempt to run `ninja` and receive a message that \n   > reads `g++: fatal error: Killed signal terminated program cc1plus`, then \n   > you have run out of memory.\n   >\n   > Using the `-j` option with an argument appropriate to the hardware on\n   > which the `ninja` command is run is expected to result in a successful\n   > build. For example, to limit the job number to 3, run the command `ninja\n   > -j3`. On average, each `ninja` job run in parallel needs approximately\n   > 2.5 GiB of RAM.\n\n   This documentation assumes that your build directory is a subdirectory of\n   the `ceph.git` checkout. If the build directory is located elsewhere, point\n   `CEPH_GIT_DIR` to the correct path of the checkout. Additional CMake args \n   can be specified by setting ARGS before invoking ``do_cmake.sh``. \n   See [cmake options](#cmake-options) for more details. For example:\n\n       ARGS=\"-DCMAKE_C_COMPILER=gcc-7\" ./do_cmake.sh\n\n   To build only certain targets, run a command of the following form:\n\n       ninja [target name]\n\n5. Install the vstart cluster:\n\n       ninja install\n\n## Build Types\n\n``do_cmake.sh`` by default creates a \"debug build\" of Ceph (assuming `.git` exists).\nA ``Debug`` build runtime performance may be as little as 20% of that of a non-debug build.\nPass ``-DCMAKE_BUILD_TYPE=RelWithDebInfo`` to ``do_cmake.sh`` to create a\nnon-debug build.\nThe default build type is ``RelWithDebInfo`` once `.git` does not exist.\n\n| CMake mode          | Debug info | Optimizations      | Sanitizers          | Checks                   | Use for           |\n| ------------------- | ---------- | -------------------|-------------------- | -------------------------| ------------------|\n| `Debug`             | Yes        | `-Og`              | None                | `ceph_assert`, `assert`  | gdb, development  |\n| `RelWithDebInfo`    | Yes        | `-O2`, `-DNDEBUG`  | None                | `ceph_assert` only       | production        |\n \n### CMake Options\n\nThe `-D` flag can be used with `cmake` to speed up the process of building Ceph\nand to customize the build.\n\n#### Building without RADOS Gateway\n\nThe RADOS Gateway is built by default. To build Ceph without the RADOS Gateway,\nrun a command of the following form:\n\n\tcmake -DWITH_RADOSGW=OFF [path to top-level ceph directory]\n\n#### Building with debugging and arbitrary dependency locations \n\nRun a command of the following form to build Ceph with debugging and alternate\nlocations for some external dependencies:\n\n\tcmake -DCMAKE_INSTALL_PREFIX=/opt/ceph -DCMAKE_C_FLAGS=\"-Og -g3 -gdwarf-4\" \\\n\t..\n\nCeph has several bundled dependencies such as Boost, RocksDB and Arrow. By\ndefault, `cmake` builds these bundled dependencies from source instead of using\nlibraries that are already installed on the system. You can opt to use these\nsystem libraries, as long as they meet Ceph's version requirements. To use\nsystem libraries, use `cmake` options like `WITH_SYSTEM_BOOST`, as in the\nfollowing example:\n\n\tcmake -DWITH_SYSTEM_BOOST=ON [...]\n\nTo view an exhaustive list of -D options, invoke `cmake -LH`:\n\n\tcmake -LH\n\n#### Preserving diagnostic colors\n\nIf you pipe `ninja` to `less` and would like to preserve the diagnostic colors\nin the output in order to make errors and warnings more legible, run the\nfollowing command:  \n\n\tcmake -DDIAGNOSTICS_COLOR=always ...\n\nThe above command works only with supported compilers.\n\nThe diagnostic colors will be visible when the following command is run: \n\n\tninja | less -R\n\nOther available values for `DIAGNOSTICS_COLOR` are `auto` (default) and\n`never`.\n\n## Tips and Tricks\n\n   * Use \"debug builds\" only when needed. Debugging builds are helpful for\n     development, but they can slow down performance. Use\n     `-DCMAKE_BUILD_TYPE=Release` when debugging isn't necessary.\n   * Enable Selective Daemons when testing specific components. Don't start\n     unnecessary daemons.\n   * Preserve Existing Data skip cluster reinitialization between tests by\n     using the `-n` flag.\n   * To manage a vstart cluster, stop daemons using `./stop.sh` and start them\n     with `./vstart.sh --daemon osd.${ID} [--nodaemonize]`. \n   * Restart the sockets by stopping and restarting the daemons associated with\n     them. This ensures that there are no stale sockets in the cluster.\n   * To track RocksDB performance, set `export ROCKSDB_PERF=true` and start\n     the cluster by using the command `./vstart.sh -n -d -x --bluestore`. \n   * Build with `vstart-base` using debug flags in cmake, compile, and deploy\n     via `./vstart.sh -d -n --bluestore`.\n   * To containerize, generate configurations with `vstart.sh`, and deploy with\n     Docker, mapping directories and configuring the network.\n   * Manage containers using `docker run`, `stop`, and `rm`. For detailed\n     setups, consult the Ceph-Container repository.\n\n##  Troubleshooting     \n \n   * Cluster Fails to Start: Look for errors in the logs under the `out/`\n     directory.\n   * OSD Crashes: Check the OSD logs for errors.\n   * Cluster in a `Health Error` State: Run the `ceph status` command to\n     identify the issue.\n   * RocksDB Errors: Look for RocksDB-related errors in the OSD logs.\n\n## Building a source tarball\n\nTo build a complete source tarball with everything needed to build from\nsource and/or build a (deb or rpm) package, run\n\n\t./make-dist\n\nThis will create a tarball like ceph-$version.tar.bz2 from git.\n(Ensure that any changes you want to include in your working directory\nare committed to git.)\n\n\n## Running a test cluster\n\nFrom the `ceph/` directory, run the following commands to launch a test Ceph\ncluster:\n\n\tcd build\n\tninja vstart        # builds just enough to run vstart\n\t../src/vstart.sh --debug --new -x --localhost --bluestore\n\t./bin/ceph -s\n\nMost Ceph commands are available in the `bin/` directory. For example:\n\n\t./bin/rbd create foo --size 1000\n\t./bin/rados -p foo bench 30 write\n\nTo shut down the test cluster, run the following command from the `build/`\ndirectory:\n\n\t../src/stop.sh\n\nUse the sysvinit script to start or stop individual daemons: \n\n\t./bin/init-ceph restart osd.0\n\t./bin/init-ceph stop\n\n\n## Running unit tests\n\nTo build and run all tests (in parallel using all processors), use `ctest`:\n\n\tcd build\n\tninja\n\tctest -j$(nproc)\n\n(Note: Many targets built from src/test are not run using `ctest`.\nTargets starting with \"unittest\" are run in `ninja check` and thus can\nbe run with `ctest`. Targets starting with \"ceph_test\" can not, and should\nbe run by hand.)\n\nWhen failures occur, look in build/Testing/Temporary for logs.\n\nTo build and run all tests and their dependencies without other\nunnecessary targets in Ceph:\n\n\tcd build\n\tninja check -j$(nproc)\n\nTo run an individual test manually, run `ctest` with -R (regex matching):\n\n\tctest -R [regex matching test name(s)]\n\n(Note: `ctest` does not build the test it's running or the dependencies needed\nto run it)\n\nTo run an individual test manually and see all the tests output, run\n`ctest` with the -V (verbose) flag:\n\n\tctest -V -R [regex matching test name(s)]\n\nTo run tests manually and run the jobs in parallel, run `ctest` with \nthe `-j` flag:\n\n\tctest -j [number of jobs]\n\nThere are many other flags you can give `ctest` for better control\nover manual test execution. To view these options run:\n\n\tman ctest\n\n\n### Building Ceph using Containers\n\nCeph now provides tools to build the code, run unit tests, or build packages\nfrom within an OCI-style container using Podman or Docker! This allows one to\nbuild code for distributions other than the one you have on your system, avoids\nthe need to install build dependencies for Ceph on your local system and\nprovides an opportunity to test builds on platforms that are not yet supported\nby the official build infrastructure. For more details see the [container build\ndocument](ContainerBuild.md).\n\n\n## Building the Documentation\n\n### Prerequisites\n\nThe list of package dependencies for building the documentation can be\nfound in `doc_deps.deb.txt`:\n\n\tsudo apt-get install `cat doc_deps.deb.txt`\n\n### Building the Documentation\n\nTo build the documentation, ensure that you are in the top-level\n`/ceph` directory, and execute the build script. For example:\n\n\tadmin/build-doc\n\n## Reporting Issues\n\nTo report an issue and view existing issues, please visit https://tracker.ceph.com/projects/ceph.\n",
      "stars_today": 8
    },
    {
      "id": 70777180,
      "name": "Mailspring",
      "full_name": "Foundry376/Mailspring",
      "description": ":love_letter: A beautiful, fast and fully open source mail client for Mac, Windows and Linux.",
      "html_url": "https://github.com/Foundry376/Mailspring",
      "stars": 17085,
      "forks": 963,
      "language": "JavaScript",
      "topics": [
        "electron",
        "electron-app",
        "email",
        "imap",
        "linux",
        "mail",
        "osx",
        "windows"
      ],
      "created_at": "2016-10-13T06:45:50Z",
      "updated_at": "2026-01-17T00:37:38Z",
      "pushed_at": "2026-01-16T18:52:56Z",
      "open_issues": 13,
      "owner": {
        "login": "Foundry376",
        "avatar_url": "https://avatars.githubusercontent.com/u/1065759?v=4"
      },
      "readme": "# üíå Mailspring\n\n**Mailspring is a new version of Nylas Mail maintained by one of the original authors. It's faster, leaner, and shipping today!** It replaces the JavaScript sync code in Nylas Mail with a new C++ sync engine based on [Mailcore2](https://github.com/MailCore/mailcore2). It uses roughly half the RAM and CPU of Nylas Mail and idles with almost zero \"CPU Wakes\", which translates to great battery life. It also has an entirely revamped composer and other great new features.\n\nMailspring's UI is open source (GPLv3) and written in TypeScript with [Electron](https://github.com/atom/electron) and [React](https://facebook.github.io/react/) - it's built on a plugin architecture and was designed to be easy to extend. Check out [CONTRIBUTING.md](https://github.com/Foundry376/Mailspring/blob/master/CONTRIBUTING.md) to get started!\n\nMailspring's sync engine is spawned by the Electron application and runs locally on your computer. [It is open source (GPLv3) and written in C++ and C.](https://github.com/Foundry376/Mailspring-Sync) For convenience, however, when you set up your development environment, Mailspring uses the latest version of the sync engine we've shipped for your platform so you don't need to pull sources or install its compile-time dependencies.\n\n![Mailspring Screenshot](https://github.com/Foundry376/Mailspring/raw/master/screenshots/hero_graphic_mac%402x.png)\n\n## Features\n\nMailspring comes packed with powerful features like Unified Inbox, Snooze, Send\nLater, Mail Rules, Templates and more. Mailspring Pro, which you can unlock\nwith a monthly subscription, adds even more features for people who send a ton\nof email: link tracking, read receipts, mailbox analytics, contact and company\nprofiles. **All of these features run in the client - Mailspring does not send\nyour email credentials to the cloud.** For a full list of features, check out\n[getmailspring.com](https://getmailspring.com/).\n\n## Download Mailspring\n\nYou can download compiled versions of Mailspring for Windows, Mac OS X, and\nLinux (deb, rpm and snap) from\n[https://getmailspring.com/download](https://getmailspring.com/download).\n\n## Getting Help\n\nYou can find community-based help and discussion with other Mailspring users on our\n[Discourse community](https://community.getmailspring.com/).\n\n## Contributing\n\nMailspring is entirely open-source. Pull requests and contributions are\nwelcome! There are three ways to contribute: building a plugin, building a\ntheme, and submitting pull requests to the project itself. When you're getting\nstarted, you may want to join our\n[Discourse](https://community.getmailspring.com/) so you can ask questions and\nlearn from other people doing development.\n\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg)](CODE_OF_CONDUCT.md)\n\n### Running Mailspring from Source\n\nTo install all dependencies and run Mailspring from its source code,\nrun the following commands from the root directory of the Mailspring repository:\n\n```\nexport npm_config_arch=x64 # If you are on an M1 / Apple Silicon Mac\nnpm install\nnpm start\n```\n\nYou can attach command line parameters by separating them using a double hyphen:\n\n```\nnpm start -- --help\n```\n\n### Building Mailspring\n\nTo build Mailspring, you need to run the following command from the root directory\nof the Mailspring repository:\n\n```\nnpm run-script build\n```\n\n### Building A Plugin\n\nPlugins lie at the heart of Mailspring and give it its powerful features.\nBuilding your own plugins allows you to integrate the app with other tools,\nexperiment with new workflows, and more. Follow the [Getting Started\nguide](https://Foundry376.github.io/Mailspring/) to write your first plugin in\nfive minutes.\n\n- To create your own theme, check out the\n  [Mailspring-Theme-Starter](https://github.com/Foundry376/Mailspring-Theme-Starter).\n\n- To create your own plugin, check out the\n  [Mailspring-Plugin-Starter](https://github.com/Foundry376/Mailspring-Plugin-Starter).\n\nA plugin \"store\" like the Chrome Web Store is coming soon, and will make it\neasy for other users to discover plugins you create. (Right now, users need to\n\"sideload\" the plugins into the app by downloading them and copying them into\nplace.)\n\nYou can share and browse Mailspring Plugins, and discuss plugin development\nwith other developers, on our\n[Discourse](https://community.getmailspring.com/).\n\n### Building a Theme\n\nThe Mailspring user interface is styled using CSS, which means it's easy to\nmodify and extend. Mailspring comes stock with a few beautiful themes, and\nthere are many more which have been built by community developers. To start\ncreating a theme, [clone the theme starter](https://github.com/Foundry376/Mailspring-Theme-Starter)!\n\nIf you are updating an existing Nylas theme for Mailspring here is a\n[step by step tutorial](https://community.getmailspring.com/t/updating-an-n1-nylas-mail-theme-for-mailspring/195).\nNotice: as part of the update process you will probably need to [import mailspring base variables](https://github.com/Foundry376/Mailspring/issues/326#issuecomment-343757775).\n\nYou can share and browse Mailspring Themes, and discuss theme development with other developers, on our [Discourse](https://community.getmailspring.com/).\n\n### Localizing / Translating\n\nMailspring (1.5.0 and above) supports localization. If you're a fluent speaker of\nanother language, we'd love your help improving translations. Check out the\n[LOCALIZATION](https://github.com/Foundry376/Mailspring/blob/master/LOCALIZATION.md)\nguide for more information. You can discuss localization and translation with\nother developers on our [Discourse](https://community.getmailspring.com/).\n\n### Contributing to Mailspring Core\n\nPull requests are always welcome - check out\n[CONTRIBUTING](https://github.com/Foundry376/Mailspring/blob/master/CONTRIBUTING.md)\nfor more information about setting up the development environment, running\ntests locally, and submitting pull requests.\n",
      "stars_today": 8
    },
    {
      "id": 19330466,
      "name": "xxHash",
      "full_name": "Cyan4973/xxHash",
      "description": "Extremely fast non-cryptographic hash algorithm",
      "html_url": "https://github.com/Cyan4973/xxHash",
      "stars": 10746,
      "forks": 878,
      "language": "C",
      "topics": [
        "c",
        "dispersion",
        "hash",
        "hash-checksum",
        "hash-functions",
        "smhasher",
        "xxhash"
      ],
      "created_at": "2014-04-30T23:32:49Z",
      "updated_at": "2026-01-16T18:08:32Z",
      "pushed_at": "2025-12-17T19:23:32Z",
      "open_issues": 25,
      "owner": {
        "login": "Cyan4973",
        "avatar_url": "https://avatars.githubusercontent.com/u/750081?v=4"
      },
      "readme": "\nxxHash - Extremely fast hash algorithm\n======================================\n\nxxHash is an Extremely fast Hash algorithm, processing at RAM speed limits.\nCode is highly portable, and produces hashes identical across all platforms (little / big endian).\nThe library includes the following algorithms :\n- XXH32 : generates 32-bit hashes, using 32-bit arithmetic\n- XXH64 : generates 64-bit hashes, using 64-bit arithmetic\n- XXH3 (since `v0.8.0`): generates 64 or 128-bit hashes, using vectorized arithmetic.\n  The 128-bit variant is called XXH128.\n\nAll variants successfully complete the [SMHasher](https://code.google.com/p/smhasher/wiki/SMHasher) test suite\nwhich evaluates the quality of hash functions (collision, dispersion and randomness).\nAdditional tests, which evaluate more thoroughly speed and collision properties of 64-bit hashes, [are also provided](https://github.com/Cyan4973/xxHash/tree/dev/tests).\n\n|Branch      |Status   |\n|------------|---------|\n|release     | [![Build Status](https://github.com/Cyan4973/xxHash/actions/workflows/ci.yml/badge.svg?branch=release)](https://github.com/Cyan4973/xxHash/actions?query=branch%3Arelease+) |\n|dev         | [![Build Status](https://github.com/Cyan4973/xxHash/actions/workflows/ci.yml/badge.svg?branch=dev)](https://github.com/Cyan4973/xxHash/actions?query=branch%3Adev+) |\n\n\nBenchmarks\n-------------------------\n\nThe benchmarked reference system uses an Intel i7-9700K cpu, and runs Ubuntu x64 20.04.\nThe [open source benchmark program] is compiled with `clang` v10.0 using `-O3` flag.\n\n| Hash Name     | Width | Bandwidth (GB/s) | Small Data Velocity | Quality | Comment |\n| ---------     | ----- | ---------------- | ----- | --- | --- |\n| __XXH3__ (SSE2) |  64 | 31.5 GB/s        | 133.1 | 10\n| __XXH128__ (SSE2) | 128 | 29.6 GB/s      | 118.1 | 10\n| _RAM sequential read_ | N/A | 28.0 GB/s  |   N/A | N/A | _for reference_\n| City64        |    64 | 22.0 GB/s        |  76.6 | 10\n| T1ha2         |    64 | 22.0 GB/s        |  99.0 |  9 | Slightly worse [collisions]\n| City128       |   128 | 21.7 GB/s        |  57.7 | 10\n| __XXH64__     |    64 | 19.4 GB/s        |  71.0 | 10\n| SpookyHash    |    64 | 19.3 GB/s        |  53.2 | 10\n| Mum           |    64 | 18.0 GB/s        |  67.0 |  9 | Slightly worse [collisions]\n| __XXH32__     |    32 |  9.7 GB/s        |  71.9 | 10\n| City32        |    32 |  9.1 GB/s        |  66.0 | 10\n| Murmur3       |    32 |  3.9 GB/s        |  56.1 | 10\n| SipHash       |    64 |  3.0 GB/s        |  43.2 | 10\n| FNV64         |    64 |  1.2 GB/s        |  62.7 |  5 | Poor avalanche properties\n| Blake2        |   256 |  1.1 GB/s        |   5.1 | 10 | Cryptographic\n| SHA1          |   160 |  0.8 GB/s        |   5.6 | 10 | Cryptographic but broken\n| MD5           |   128 |  0.6 GB/s        |   7.8 | 10 | Cryptographic but broken\n\n[open source benchmark program]: https://github.com/Cyan4973/xxHash/tree/release/tests/bench\n[collisions]: https://github.com/Cyan4973/xxHash/wiki/Collision-ratio-comparison#collision-study\n\nnote 1: Small data velocity is a _rough_ evaluation of algorithm's efficiency on small data. For more detailed analysis, please refer to next paragraph.\n\nnote 2: some algorithms feature _faster than RAM_ speed. In which case, they can only reach their full speed potential when input is already in CPU cache (L3 or better). Otherwise, they max out on RAM speed limit.\n\n### Small data\n\nPerformance on large data is only one part of the picture.\nHashing is also very useful in constructions like hash tables and bloom filters.\nIn these use cases, it's frequent to hash a lot of small data (starting at a few bytes).\nAlgorithm's performance can be very different for such scenarios, since parts of the algorithm,\nsuch as initialization or finalization, become fixed cost.\nThe impact of branch mis-prediction also becomes much more present.\n\nXXH3 has been designed for excellent performance on both long and small inputs,\nwhich can be observed in the following graph:\n\n![XXH3, latency, random size](https://user-images.githubusercontent.com/750081/61976089-aedeab00-af9f-11e9-9239-e5375d6c080f.png)\n\nFor a more detailed analysis, please visit the wiki :\nhttps://github.com/Cyan4973/xxHash/wiki/Performance-comparison#benchmarks-concentrating-on-small-data-\n\nQuality\n-------------------------\n\nSpeed is not the only property that matters.\nProduced hash values must respect excellent dispersion and randomness properties,\nso that any sub-section of it can be used to maximally spread out a table or index,\nas well as reduce the amount of collisions to the minimal theoretical level, following the [birthday paradox].\n\n`xxHash` has been tested with Austin Appleby's excellent SMHasher test suite,\nand passes all tests, ensuring reasonable quality levels.\nIt also passes extended tests from [newer forks of SMHasher], featuring additional scenarios and conditions.\n\nFinally, xxHash provides its own [massive collision tester](https://github.com/Cyan4973/xxHash/tree/dev/tests/collisions),\nable to generate and compare billions of hashes to test the limits of 64-bit hash algorithms.\nOn this front too, xxHash features good results, in line with the [birthday paradox].\nA more detailed analysis is documented [in the wiki](https://github.com/Cyan4973/xxHash/wiki/Collision-ratio-comparison).\n\n[birthday paradox]: https://en.wikipedia.org/wiki/Birthday_problem\n[newer forks of SMHasher]: https://github.com/rurban/smhasher\n\n\n### Build modifiers\n\nThe following macros can be set at compilation time to modify `libxxhash`'s behavior. They are generally disabled by default.\n\n- `XXH_INLINE_ALL`: Make all functions `inline`, implementation is directly included within `xxhash.h`.\n                    Inlining functions is beneficial for speed, notably for small keys.\n                    It's _extremely effective_ when key's length is expressed as _a compile time constant_,\n                    with performance improvements observed in the +200% range .\n                    See [this article](https://fastcompression.blogspot.com/2018/03/xxhash-for-small-keys-impressive-power.html) for details.\n- `XXH_PRIVATE_API`: same outcome as `XXH_INLINE_ALL`. Still available for legacy support.\n                     The name underlines that `XXH_*` symbol names will not be exported.\n- `XXH_STATIC_LINKING_ONLY`: gives access to internal state declaration, required for static allocation.\n                             Incompatible with dynamic linking, due to risks of ABI changes.\n- `XXH_NAMESPACE`: Prefixes all symbols with the value of `XXH_NAMESPACE`.\n                   This macro can only use compilable character set.\n                   Useful to evade symbol naming collisions,\n                   in case of multiple inclusions of xxHash's source code.\n                   Client applications still use the regular function names,\n                   as symbols are automatically translated through `xxhash.h`.\n- `XXH_FORCE_ALIGN_CHECK`: Use a faster direct read path when input is aligned.\n                           This option can result in dramatic performance improvement on architectures unable to load memory from unaligned addresses\n                           when input to hash happens to be aligned on 32 or 64-bit boundaries.\n                           It is (slightly) detrimental on platform with good unaligned memory access performance (same instruction for both aligned and unaligned accesses).\n                           This option is automatically disabled on `x86`, `x64` and `aarch64`, and enabled on all other platforms.\n- `XXH_FORCE_MEMORY_ACCESS`: The default method `0` uses a portable `memcpy()` notation.\n                             Method `1` uses a gcc-specific `packed` attribute, which can provide better performance for some targets.\n                             Method `2` forces unaligned reads, which is not standard compliant, but might sometimes be the only way to extract better read performance.\n                             Method `3` uses a byteshift operation, which is best for old compilers which don't inline `memcpy()` or big-endian systems without a byteswap instruction.\n- `XXH_CPU_LITTLE_ENDIAN`: By default, endianness is determined by a runtime test resolved at compile time.\n                           If, for some reason, the compiler cannot simplify the runtime test, it can cost performance.\n                           It's possible to skip auto-detection and simply state that the architecture is little-endian by setting this macro to 1.\n                           Setting it to 0 states big-endian.\n- `XXH_ENABLE_AUTOVECTORIZE`: Auto-vectorization may be triggered for XXH32 and XXH64, depending on cpu vector capabilities and compiler version.\n                              Note: auto-vectorization tends to be triggered more easily with recent versions of `clang`.\n                              For XXH32, SSE4.1 or equivalent (NEON) is enough, while XXH64 requires AVX512.\n                              Unfortunately, auto-vectorization is generally detrimental to XXH performance.\n                              For this reason, the xxhash source code tries to prevent auto-vectorization by default.\n                              That being said, systems evolve, and this conclusion is not forthcoming.\n                              For example, it has been reported that recent Zen4 cpus are more likely to improve performance with vectorization.\n                              Therefore, should you prefer or want to test vectorized code, you can enable this flag:\n                              it will remove the no-vectorization protection code, thus making it more likely for XXH32 and XXH64 to be auto-vectorized.\n- `XXH32_ENDJMP`: Switch multi-branch finalization stage of XXH32 by a single jump.\n                  This is generally undesirable for performance, especially when hashing inputs of random sizes.\n                  But depending on exact architecture and compiler, a jump might provide slightly better performance on small inputs. Disabled by default.\n- `XXH_IMPORT`: MSVC specific: should only be defined for dynamic linking, as it prevents linkage errors.\n- `XXH_NO_STDLIB`: Disable invocation of `<stdlib.h>` functions, notably `malloc()` and `free()`.\n                   `libxxhash`'s `XXH*_createState()` will always fail and return `NULL`.\n                   But one-shot hashing (like `XXH32()`) or streaming using statically allocated states\n                   still work as expected.\n                   This build flag is useful for embedded environments without dynamic allocation.\n- `XXH_memcpy`, `XXH_memset`, `XXH_memcmp` : redirect `memcpy()`, `memset()` and `memcmp()` to some user-selected symbol at compile time.\n                   Redirecting all 3 removes the need to include `<string.h>` standard library.\n- `XXH_NO_EXTERNC_GUARD`: When `xxhash.h` is compiled in C++ mode, removes the `extern \"C\" { .. }` block guard.\n- `XXH_DEBUGLEVEL` : When set to any value >= 1, enables `assert()` statements.\n                     This (slightly) slows down execution, but may help finding bugs during debugging sessions.\n\n#### Binary size control\n- `XXH_NO_XXH3` : removes symbols related to `XXH3` (both 64 & 128 bits) from generated binary.\n                  `XXH3` is by far the largest contributor to `libxxhash` size,\n                  so it's useful to reduce binary size for applications which do not employ `XXH3`.\n- `XXH_NO_LONG_LONG`: removes compilation of algorithms relying on 64-bit `long long` types\n                      which include `XXH3` and `XXH64`.\n                      Only `XXH32` will be compiled.\n                      Useful for targets (architectures and compilers) without 64-bit support.\n- `XXH_NO_STREAM`: Disables the streaming API, limiting the library to single shot variants only.\n- `XXH_NO_INLINE_HINTS`: By default, xxHash uses `__attribute__((always_inline))` and `__forceinline` to improve performance at the cost of code size.\n                         Defining this macro to 1 will mark all internal functions as `static`, allowing the compiler to decide whether to inline a function or not.\n                         This is very useful when optimizing for smallest binary size,\n                         and is automatically defined when compiling with `-O0`, `-Os`, `-Oz`, or `-fno-inline` on GCC and Clang.\n                         It may also be required to successfully compile using `-Og`, depending on compiler version.\n- `XXH_SIZE_OPT`: `0`: default, optimize for speed\n                  `1`: default for `-Os` and `-Oz`: disables some speed hacks for size optimization\n                  `2`: makes code as small as possible, performance may cry\n\n#### Build modifiers specific for XXH3\n- `XXH_VECTOR` : manually select a vector instruction set (default: auto-selected at compilation time). Available instruction sets are `XXH_SCALAR`, `XXH_SSE2`, `XXH_AVX2`, `XXH_AVX512`, `XXH_NEON` and `XXH_VSX`. Compiler may require additional flags to ensure proper support (for example, `gcc` on x86_64 requires `-mavx2` for `AVX2`, or `-mavx512f` for `AVX512`).\n- `XXH_PREFETCH_DIST` : select prefetching distance. For close-to-metal adaptation to specific hardware platforms. XXH3 only.\n- `XXH_NO_PREFETCH` : disable prefetching. Some platforms or situations may perform better without prefetching. XXH3 only.\n\n#### Build modifiers for `xxhsum` CLI\n- `XXH_1ST_SPEED_TARGET` : select an initial speed target, expressed in MB/s, for the first speed test in benchmark mode. Benchmark will adjust the target at subsequent iterations, but the first test is made \"blindly\" by targeting this speed. Currently conservatively set to 10 MB/s, to support very slow (emulated) platforms.\n\n#### Makefile variables\nWhen compiling the Command Line Interface `xxhsum` using `make`, the following environment variables can also be set :\n- `DISPATCH=1` : use `xxh_x86dispatch.c`, select at runtime between `scalar`, `sse2`, `avx2` or `avx512` instruction set. This option is only valid for `x86`/`x64` systems. It is enabled by default when target `x86`/`x64` is detected. It can be forcefully turned off using `DISPATCH=0`.\n- `LIBXXH_DISPATCH=1` : same idea, implemented a runtime vector extension detector, but within `libxxhash`. This parameter is disabled by default. When enabled (only valid for `x86`/`x64` systems), new symbols published in `xxh_x86dispatch.h` become accessible. At the time of this writing, it's required to include `xxh_x86dispatch.h` in order to access the symbols with runtime vector extension detection.\n- `NODE_JS=1` : When compiling `xxhsum` for Node.js with Emscripten, this links the `NODERAWFS` library for unrestricted filesystem access and patches `isatty` to make the command line utility correctly detect the terminal. This does make the binary specific to Node.js.\n\n### Building xxHash - Using vcpkg\n\nYou can download and install xxHash using the [vcpkg](https://github.com/Microsoft/vcpkg) dependency manager:\n\n    git clone https://github.com/Microsoft/vcpkg.git\n    cd vcpkg\n    ./bootstrap-vcpkg.sh\n    ./vcpkg integrate install\n    ./vcpkg install xxhash\n\nThe xxHash port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n### Example\n\nThe simplest example calls xxhash 64-bit variant as a one-shot function\ngenerating a hash value from a single buffer, and invoked from a C/C++ program:\n\n```C\n#include \"xxhash.h\"\n\n    (...)\n    XXH64_hash_t hash = XXH64(buffer, size, seed);\n}\n```\n\nStreaming variant is more involved, but makes it possible to provide data incrementally:\n\n```C\n#include \"stdlib.h\"   /* abort() */\n#include \"xxhash.h\"\n\n\nXXH64_hash_t calcul_hash_streaming(FileHandler fh)\n{\n    /* create a hash state */\n    XXH64_state_t* const state = XXH64_createState();\n    if (state==NULL) abort();\n\n    size_t const bufferSize = SOME_SIZE;\n    void* const buffer = malloc(bufferSize);\n    if (buffer==NULL) abort();\n\n    /* Initialize state with selected seed */\n    XXH64_hash_t const seed = 0;   /* or any other value */\n    if (XXH64_reset(state, seed) == XXH_ERROR) abort();\n\n    /* Feed the state with input data, any size, any number of times */\n    (...)\n    while ( /* some data left */ ) {\n        size_t const length = get_more_data(buffer, bufferSize, fh);\n        if (XXH64_update(state, buffer, length) == XXH_ERROR) abort();\n        (...)\n    }\n    (...)\n\n    /* Produce the final hash value */\n    XXH64_hash_t const hash = XXH64_digest(state);\n\n    /* State could be re-used; but in this example, it is simply freed  */\n    free(buffer);\n    XXH64_freeState(state);\n\n    return hash;\n}\n```\n\n\n### License\n\nThe library files `xxhash.c` and `xxhash.h` are BSD licensed.\nThe utility `xxhsum` is GPL licensed.\n\n\n### Other programming languages\n\nBeyond the C reference version,\nxxHash is also available from many different programming languages,\nthanks to great contributors.\nThey are [listed here](http://www.xxhash.com/#other-languages).\n\n\n### Packaging status\n\nMany distributions bundle a package manager\nwhich allows easy xxhash installation as both a `libxxhash` library\nand `xxhsum` command line interface.\n\n[![Packaging status](https://repology.org/badge/vertical-allrepos/xxhash.svg)](https://repology.org/project/xxhash/versions)\n\n\n### Special Thanks\n\n- Takayuki Matsuoka, aka @t-mat, for creating `xxhsum -c` and great support during early xxh releases\n- Mathias Westerdahl, aka @JCash, for introducing the first version of `XXH64`\n- Devin Hussey, aka @easyaspi314, for incredible low-level optimizations on `XXH3` and `XXH128`\n",
      "stars_today": 8
    },
    {
      "id": 178075572,
      "name": "kserve",
      "full_name": "kserve/kserve",
      "description": "Standardized Distributed Generative and Predictive AI Inference Platform for Scalable, Multi-Framework Deployment on Kubernetes",
      "html_url": "https://github.com/kserve/kserve",
      "stars": 5007,
      "forks": 1343,
      "language": "Go",
      "topics": [
        "artificial-intelligence",
        "cncf",
        "genai",
        "hacktoberfest",
        "istio",
        "k8s",
        "knative",
        "kserve",
        "kubeflow",
        "kubernetes",
        "llm-inference",
        "machine-learning",
        "mlops",
        "model-interpretability",
        "model-serving",
        "pytorch",
        "service-mesh",
        "tensorflow",
        "vllm",
        "xgboost"
      ],
      "created_at": "2019-03-27T21:14:14Z",
      "updated_at": "2026-01-16T21:09:28Z",
      "pushed_at": "2026-01-16T21:09:20Z",
      "open_issues": 595,
      "owner": {
        "login": "kserve",
        "avatar_url": "https://avatars.githubusercontent.com/u/83512434?v=4"
      },
      "readme": "# KServe\n[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white)](https://pkg.go.dev/github.com/kserve/kserve)\n[![Coverage Status](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/andyi2it/5174bd748ac63a6e4803afea902e9810/raw/coverage.json)](https://github.com/kserve/kserve/actions/workflows/go.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/kserve/kserve)](https://goreportcard.com/report/github.com/kserve/kserve)\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/6643/badge)](https://bestpractices.coreinfrastructure.org/projects/6643)\n[![Releases](https://img.shields.io/github/release-pre/kserve/kserve.svg?sort=semver)](https://github.com/kserve/kserve/releases)\n[![LICENSE](https://img.shields.io/github/license/kserve/kserve.svg)](https://github.com/kserve/kserve/blob/master/LICENSE)\n[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](https://github.com/kserve/community/blob/main/README.md#questions-and-issues)\n[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20KServe%20Guru-006BFF)](https://gurubase.io/g/kserve)\n\nKServe is a standardized distributed generative and predictive AI inference platform for scalable, multi-framework deployment on Kubernetes.\n\nKServe is being [used by many organizations](https://kserve.github.io/website/docs/community/adopters) and is a [Cloud Native Computing Foundation (CNCF)](https://www.cncf.io/) incubating project.\n\nFor more details, visit the [KServe website](https://kserve.github.io/website/).\n\n![KServe](/docs/diagrams/kserve_new.png)\n\n### Why KServe?\n\nSingle platform that unifies Generative and Predictive AI inference on Kubernetes. Simple enough for quick deployments, yet powerful enough to handle enterprise-scale AI workloads with advanced features.\n\n### Features\n\n**Generative AI**\n  * üß† **LLM-Optimized**: OpenAI-compatible inference protocol for seamless integration with large language models\n  * üöÖ **GPU Acceleration**: High-performance serving with GPU support and optimized memory management for large models\n  * üíæ **Model Caching**: Intelligent model caching to reduce loading times and improve response latency for frequently used models\n  * üóÇÔ∏è **KV Cache Offloading**: Advanced memory management with KV cache offloading to CPU/disk for handling longer sequences efficiently\n  * üìà **Autoscaling**: Request-based autoscaling capabilities optimized for generative workload patterns\n  * üîß **Hugging Face Ready**: Native support for Hugging Face models with streamlined deployment workflows\n\n**Predictive AI**\n  * üßÆ **Multi-Framework**: Support for TensorFlow, PyTorch, scikit-learn, XGBoost, ONNX, and more\n  * üîÄ **Intelligent Routing**: Seamless request routing between predictor, transformer, and explainer components with automatic traffic management\n  * üîÑ **Advanced Deployments**: Canary rollouts, inference pipelines, and ensembles with InferenceGraph\n  * ‚ö° **Autoscaling**: Request-based autoscaling with scale-to-zero for predictive workloads\n  * üîç **Model Explainability**: Built-in support for model explanations and feature attribution to understand prediction reasoning\n  * üìä **Advanced Monitoring**: Enables payload logging, outlier detection, adversarial detection, and drift detection\n  * üí∞ **Cost Efficient**: Scale-to-zero on expensive resources when not in use, reducing infrastructure costs\n\n### Learn More\nTo learn more about KServe, how to use various supported features, and how to participate in the KServe community, \nplease follow the [KServe website documentation](https://kserve.github.io/website). \nAdditionally, we have compiled a list of [presentations and demos](https://kserve.github.io/website/docs/community/presentations) to dive through various details.\n\n### :hammer_and_wrench: Installation\n\n#### Standalone Installation\n- **[Standard Kubernetes Installation](https://kserve.github.io/website/docs/admin-guide/overview#raw-kubernetes-deployment)**: Compared to Serverless Installation, this is a more **lightweight** installation. However, this option does not support canary deployment and request based autoscaling with scale-to-zero.\n- **[Knative Installation](https://kserve.github.io/website/docs/admin-guide/overview#serverless-deployment)**: KServe by default installs Knative for **serverless deployment** for InferenceService.\n- **[ModelMesh Installation](https://kserve.github.io/website/docs/admin-guide/overview#modelmesh-deployment)**: You can optionally install ModelMesh to enable **high-scale**, **high-density** and **frequently-changing model serving** use cases. \n- **[Quick Installation](https://kserve.github.io/website/docs/getting-started/quickstart-guide)**: Install KServe on your local machine.\n\n#### Kubeflow Installation\nKServe is an important addon component of Kubeflow, please learn more from the [Kubeflow KServe documentation](https://www.kubeflow.org/docs/external-add-ons/kserve/kserve). Check out the following guides for running [on AWS](https://awslabs.github.io/kubeflow-manifests/main/docs/component-guides/kserve) or [on OpenShift Container Platform](https://github.com/kserve/kserve/blob/master/docs/OPENSHIFT_GUIDE.md).\n\n### :flight_departure: [Create your first InferenceService](https://kserve.github.io/website/docs/getting-started/genai-first-isvc)\n\n### :bulb: [Roadmap](./ROADMAP.md)\n\n### :blue_book: [InferenceService API Reference](https://kserve.github.io/website/docs/reference/crd-api)\n\n### :toolbox: [Developer Guide](https://kserve.github.io/website/docs/developer-guide)\n\n### :writing_hand: [Contributor Guide](https://kserve.github.io/website/docs/developer-guide/contribution)\n\n### :handshake: [Adopters](https://kserve.github.io/website/docs/community/adopters)\n\n### Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=kserve/kserve&type=Date)](https://www.star-history.com/#kserve/kserve&Date)\n",
      "stars_today": 8
    },
    {
      "id": 681215919,
      "name": "APatch",
      "full_name": "bmax121/APatch",
      "description": "The patching of Android kernel and Android system",
      "html_url": "https://github.com/bmax121/APatch",
      "stars": 6926,
      "forks": 637,
      "language": "Kotlin",
      "topics": [
        "android",
        "inline-hook",
        "kernel",
        "magisk",
        "magisk-module",
        "patch",
        "root"
      ],
      "created_at": "2023-08-21T14:20:01Z",
      "updated_at": "2026-01-16T20:44:35Z",
      "pushed_at": "2026-01-15T19:20:43Z",
      "open_issues": 88,
      "owner": {
        "login": "bmax121",
        "avatar_url": "https://avatars.githubusercontent.com/u/12316019?v=4"
      },
      "readme": "<div align=\"center\">\n<a href=\"https://github.com/bmax121/APatch/releases/latest\"><img src=\"https://images.weserv.nl/?url=https://raw.githubusercontent.com/bmax121/APatch/main/app/src/main/ic_launcher-playstore.png&mask=circle\" style=\"width: 128px;\" alt=\"logo\"></a>\n\n<h1 align=\"center\">APatch</h1>\n\n[![Latest Release](https://img.shields.io/github/v/release/bmax121/APatch?label=Release&logo=github)](https://github.com/bmax121/APatch/releases/latest)\n[![Nightly Release](https://img.shields.io/badge/Nightly%20release-gray?logo=hackthebox&logoColor=fff)](https://nightly.link/bmax121/APatch/workflows/build/main/APatch)\n[![Weblate](https://img.shields.io/badge/Localization-Weblate-teal?logo=weblate)](https://hosted.weblate.org/engage/APatch)\n[![Channel](https://img.shields.io/badge/Follow-Telegram-blue.svg?logo=telegram)](https://t.me/APatchGroup)\n[![GitHub License](https://img.shields.io/github/license/bmax121/APatch?logo=gnu)](/LICENSE)\n\n</div>\n\nThe patching of Android kernel and Android system.\n\n- A new kernel-based root solution for Android devices.\n- APM: Support for modules similar to Magisk.\n- KPM: Support for modules that allow you to inject any code into the kernel (Provides kernel function `inline-hook` and `syscall-table-hook`).\n- APatch relies on [KernelPatch](https://github.com/bmax121/KernelPatch/).\n- The APatch UI and the APModule source code have been derived and modified from [KernelSU](https://github.com/tiann/KernelSU).\n\n[<img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\"\n     alt=\"Get it on F-Droid\"\n     height=\"80\">](https://f-droid.org/packages/me.bmax.apatch/)\n\nOr download the latest APK from the [Releases Section](https://github.com/bmax121/APatch/releases/latest).\n\n## Supported Versions\n\n- Only supports the ARM64 architecture.\n- Only supports Android kernel versions 3.18 - 6.12\n\nSupport for Samsung devices with security protection: Planned\n\n## Requirement\n\nKernel configs:\n\n- `CONFIG_KALLSYMS=y` and `CONFIG_KALLSYMS_ALL=y`\n\n- `CONFIG_KALLSYMS=y` and `CONFIG_KALLSYMS_ALL=n`: Initial support\n\n## Security Alert\n\nThe **SuperKey** has higher privileges than root access.  \nWeak or compromised keys can lead to unauthorized control of your device.  \nIt is critical to use robust keys and safeguard them from exposure to maintain the security of your device.\n\n## Translation\n\nTo help translate APatch or improve existing translations, please use [Weblate](https://hosted.weblate.org/engage/apatch/). PR of APatch translation is no longer accepted, because it will conflict with Weblate.\n\n<div align=\"center\">\n\n[![Translation Status](https://hosted.weblate.org/widget/APatch/open-graph.png)](https://hosted.weblate.org/engage/APatch/)\n\n</div>\n\n## Get Help\n\n### Usage\n\nFor usage, please refer to [our official documentation](https://apatch.dev).  \nIt's worth noting that the documentation is currently not quite complete, and the content may change at any time.  \nFurthermore, we need more volunteers to [contribute to the documentation](https://github.com/AndroidPatch/APatchDocs) in other languages.\n\n### Updates\n\n- Telegram Channel: [@APatchUpdates](https://t.me/APatchChannel)\n\n### Discussions\n\n- Telegram Group: [@APatchDiscussions(EN/CN)](https://t.me/Apatch_discuss)\n- Telegram Group: [‰∏≠Êñá](https://t.me/APatch_CN_Group)\n\n### More Information\n\n- [Documents](docs/)\n\n## Credits\n\n- [KernelPatch](https://github.com/bmax121/KernelPatch/): The core.\n- [Magisk](https://github.com/topjohnwu/Magisk): magiskboot and magiskpolicy.\n- [KernelSU](https://github.com/tiann/KernelSU): App UI, and Magisk module like support.\n\n## License\n\nAPatch is licensed under the GNU General Public License v3 [GPL-3](http://www.gnu.org/copyleft/gpl.html).\n",
      "stars_today": 8
    },
    {
      "id": 747412989,
      "name": "aShellYou",
      "full_name": "DP-Hridayan/aShellYou",
      "description": "A material you designed app for your ADB needs",
      "html_url": "https://github.com/DP-Hridayan/aShellYou",
      "stars": 1487,
      "forks": 65,
      "language": "Kotlin",
      "topics": [
        "adb",
        "android",
        "debugging",
        "hridayan",
        "krishnassh",
        "magisk",
        "material-design",
        "md3",
        "otg",
        "root",
        "shell",
        "shizuku",
        "wireless-debugging"
      ],
      "created_at": "2024-01-23T21:55:08Z",
      "updated_at": "2026-01-16T17:08:22Z",
      "pushed_at": "2026-01-16T15:35:37Z",
      "open_issues": 16,
      "owner": {
        "login": "DP-Hridayan",
        "avatar_url": "https://avatars.githubusercontent.com/u/157479796?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"https://capsule-render.vercel.app/api?type=waving&height=300&color=gradient&text=aShell%20You&animation=fadeIn&desc=ADB%20at%20your%20fingertips&descAlign=50&descAlignY=55&fontAlignY=35\" />\n</p>\n\n> **aShell You** is a fully-featured Android shell utility app with **Material Design 3 UI**, letting you run **ADB**, **root** and **shell** commands on your  device or others via OTG/wireless, packed in a beautiful and smart interface\n\n</br>\n\n<p align=\"center\"> \n<a href=\"https://github.com/DP-Hridayan/aShellYou/stargazers\">\n    <img alt=\"GitHub stars\" src=\"https://img.shields.io/github/stars/DP-Hridayan/aShellYou?style=for-the-badge&logo=github&label=Stars\" />\n  </a>\n  <a href=\"https://github.com/DP-Hridayan/aShellYou/forks\">\n    <img alt=\"GitHub forks\" src=\"https://img.shields.io/github/forks/DP-Hridayan/aShellYou?style=for-the-badge&logo=github&label=Forks\" />\n  </a>\n  <a href=\"https://github.com/DP-Hridayan/aShellYou/issues\">\n    <img alt=\"GitHub issues\" src=\"https://img.shields.io/github/issues/DP-Hridayan/aShellYou?style=for-the-badge&logo=github&label=Issues\" />\n  </a>\n  <a href=\"https://github.com/DP-Hridayan/aShellYou/releases/latest\">\n    <img alt=\"GitHub release\" src=\"https://img.shields.io/github/v/release/DP-Hridayan/aShellYou?style=for-the-badge&logo=github&label=Release\" />\n  </a>\n    <a href=\"https://shields.rbtlog.dev/in.hridayan.ashell\">\n    <img alt=\"GitHub release\" src=\"https://shields.rbtlog.dev/simple/in.hridayan.ashell?style=for-the-badge\" />\n  </a>\n  <a href=\"https://github.com/DP-Hridayan/aShellYou/releases\">\n    <img alt=\"GitHub All Releases\" src=\"https://img.shields.io/github/downloads/DP-Hridayan/aShellYou/total?style=for-the-badge&logo=download&label=Downloads\" />\n  </a>\n  <a href=\"https://github.com/DP-Hridayan/aShellYou/graphs/contributors\">\n    <img alt=\"Contributors\" src=\"https://img.shields.io/github/contributors/DP-Hridayan/aShellYou?style=for-the-badge&logo=github&label=Contributors\" />\n  </a>\n  <a href=\"https://github.com/DP-Hridayan/aShellYou/blob/main/LICENSE\">\n    <img alt=\"License\" src=\"https://img.shields.io/github/license/DP-Hridayan/aShellYou?style=for-the-badge&logo=open-source-initiative&label=License\" />\n  </a>\n</p>\n\n<p align=\"center\"> \n    <img alt=\"Platform\" src=\"https://img.shields.io/badge/Platform-Android-3DDC84?style=for-the-badge&logo=android&logoColor=white\" />\n   <img alt=\"Language\" src=\"https://img.shields.io/badge/Kotlin-%23B125E3.svg?style=for-the-badge&logo=kotlin&logoColor=white\"/>\n  <img alt=\"UI\" src=\"https://img.shields.io/badge/Jetpack%20Compose-%23007ACC.svg?style=for-the-badge&logo=jetpackcompose&logoColor=white\"/>\n      <img src=\"https://img.shields.io/badge/Material%20Design-757575?style=for-the-badge&logo=material-design&logoColor=white\"/>\n  <img src=\"https://img.shields.io/badge/Dagger%20Hilt-%236200EE.svg?style=for-the-badge&logo=dagger&logoColor=white\"/>\n  <img src=\"https://img.shields.io/badge/Room-3F51B5?style=for-the-badge&logo=sqlite&logoColor=white\"/>\n  <img alt=\"Min SDK\" src=\"https://img.shields.io/badge/MinSDK-28-yellow?style=for-the-badge\" />\n  <img alt=\"Target SDK\" src=\"https://img.shields.io/badge/TargetSDK-36-blue?style=for-the-badge\" />\n  <a href=\"https://crowdin.com/project/ashellyou\">\n    <img alt=\"Crowdin\" src=\"https://img.shields.io/badge/Translation-Crowdin-222222?style=for-the-badge&logo=crowdin&logoColor=white\"/>\n</a>\n</p>\n\n</br>\n\n<h2 align=\"center\">Screenshots</h2>\n  <div align=\"center\">\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/01.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/02.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/03.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <br/>\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/04.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/05.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/06.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <br/>\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/07.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/08.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/09.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <br/>\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/10.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/11.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/12.jpeg\" width=\"25%\" style=\"margin:10px\" />\n  <br/>\n</div>\n\n</br>\n\n## Features\n\nüé® **Modern Material Design 3 UI**\n> Experience a clean, smooth, and responsive user interface built with Material You design. Explore different color palettes in theme settings!\n</br>\n\nüì≤ **Execute Commands with Ease**\n> Run ADB shell commands directly on your device using Shizuku, root access, or Wireless Debugging ‚Äî all without needing a PC.\n</br>\n\nüîå **Control Other Devices**\n> Send ADB commands to other Android devices using OTG cable or Wireless Debugging ‚Äî perfect for developers and tinkerers.\n</br>\n\nüìö **Common ADB Command Examples**\n> Built-in examples help you understand and run useful commands instantly without memorizing syntax.\n</br>\n\nüìÅ **ADB based File Explorer for connected devices**\n> ADB push/pull based file manager will help you perform file operations such as delete, copy, move, etc. on the connected device.\n</br>\n\nüõ†Ô∏è **Support for Continuous Commands**\n> Seamlessly run long or continuous shell commands like `logcat`, `top`, or `watch` and view live updates without interruptions.\n</br>\n\nüîç **Search in Command Output**\n> Quickly find what you're looking for in the output of your command using the integrated search functionality.\n</br>\n\nüìù **Save Output to File**\n> Save the output of any command to a `.txt` file for future reference or sharing ‚Äî handy for logs and debugging.\n</br>\n\nüì§ **Share Output Instantly**\n> One-tap sharing lets you send your output to other apps like Notes, Gmail, or Telegram.\n</br>\n\nüìë **Bookmark Commands**\n> Save frequently used commands to bookmarks so you can run them again with a single tap.\n</br>\n\nüîÉ **Backup and restore app settings and database locally**\n> aShellYou lets you have the option to backup app settings and database for restore later.\n</br>\n\nüåë **AMOLED-Friendly Dark Theme**\n> Includes a sleek dark mode designed to save battery and look great on AMOLED screens.\n</br>\n\nüéâ **Packed with Extras**\n> Tons of small but useful features to enhance your productivity and make ADB power-user workflows smoother.\n\n</br>\n\n## Requirements\n\n> * A working **[Shizuku](https://shizuku.rikka.app/)** environment or **root access**\n> * Shizuku/Root is **not required** when executing ADB commands on **other devices** using **OTG** or **Wireless Debugging**\n\n<br/>\n\n>[!CAUTION]\n>\n> Using **aShell You** requires basic knowledge of `ADB/Linux commands`.\n>**aShell You** is **not responsible** for any harm caused to your device by improper use of ADB commands\n\n<br/>\n\n>[!TIP]\n>\n> Please visit our **[Wiki](https://github.com/DP-Hridayan/aShellYou/wiki)** for instructions/setup-guides\n\n</br>\n\n## Resources & Links\n\n<p align=\"start\">\n  <a href=\"https://github.com/DP-Hridayan/aShellYou/releases/latest/\">\n    <img src=\"assets/github.png\" width=\"130\" alt=\"GitHub\" />\n  </a>\n  &nbsp;&nbsp;\n  <a href=\"https://apt.izzysoft.de/fdroid/index/apk/in.hridayan.ashell\">\n    <img src=\"assets/izzy.png\" width=\"130\" alt=\"F-Droid\" />\n  </a>\n  <br/><br/>\n  <a href=\"https://t.me/aShellYou\">\n    <img src=\"assets/telegram.png\" width=\"180\" alt=\"Join Telegram\" />\n  </a>\n  <br/><br/>\n  <a href=\"https://www.buymeacoffee.com/Hridayan\">\n    <img src=\"https://github.com/DP-Hridayan/aShellYou/assets/157479796/d0ad79e4-a19e-4686-9f30-dc1cb1e85168\" width=\"200\" alt=\"Buy Me a Coffee\" />\n  </a></p>\n\n  </br>\n\n## Translations\n\n<p align=\"start\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/translations-dark.svg?ts=1768577579\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"docs/translations-light.svg?ts=1768577579\">\n    <img src=\"translations-light.svg\" alt=\"Translation Progress\" />\n  </picture>\n</p>\n\n>[!NOTE]\n>\n> Help us make this project accessible to more people by contributing translations on **[Crowdin](https://crowdin.com/project/ashellyou)**\n>\n> Thanks to our Crowdin [translators](docs/translators.md)\n\n</br>\n\n## Task list\n\n<table align=\"start\" style=\"border-collapse: collapse; margin-top: 20px;\">\n  <tr>\n    <th style=\"padding: 8px; border: 1px solid #ddd; text-align: left;\">Task</th>\n    <th style=\"padding: 8px; border: 1px solid #ddd; text-align: left;\">Status</th>\n  </tr>\n  <tr>\n    <td style=\"padding: 8px; border: 1px solid #ddd;\">Wifi ADB Feature</td>\n    <td style=\"padding: 8px; border: 1px solid #ddd; color: green;\">‚úÖ Done</td>\n  </tr>\n  <tr>\n    <td style=\"padding: 8px; border: 1px solid #ddd;\">Migrate to kotlin</td>\n    <td style=\"padding: 8px; border: 1px solid #ddd; color: green;\">‚úÖ Done</td>\n  </tr>\n  <tr>\n    <td style=\"padding: 8px; border: 1px solid #ddd;\">Proper localization</td>\n    <td style=\"padding: 8px; border: 1px solid #ddd; color: gray;\">‚è∫Ô∏è In progress</td>\n  </tr>\n  <tr>\n    <td style=\"padding: 8px; border: 1px solid #ddd;\">Fix scripts execution</td>\n    <td style=\"padding: 8px; border: 1px solid #ddd; color: gray;\">‚¨ú To Do</td>\n  </tr>\n  <tr>\n    <td style=\"padding: 8px; border: 1px solid #ddd;\">Add Fastboot</td>\n    <td style=\"padding: 8px; border: 1px solid #ddd; color: gray;\">‚¨ú To Do</td>\n  </tr>\n    <tr>\n    <td style=\"padding: 8px; border: 1px solid #ddd;\">Add Interactive shell</td>\n    <td style=\"padding: 8px; border: 1px solid #ddd; color: gray;\">‚¨ú To Do</td>\n  </tr>\n</table>\n\n<br/>\n\n## Star history\n\n<a href=\"https://star-history.com/#DP-Hridayan/aShellYou&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=DP-Hridayan/aShellYou&type=Timeline&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=DP-Hridayan/aShellYou&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=DP-Hridayan/aShellYou&type=Timeline\" />\n </picture>\n</a>\n\n<br></br>\n\n## License\n\n```\nDesigned and developed by DP Hridayan @2024\nThis project is licensed under the GNU General Public License v3.0\n```\n>[!NOTE]\n>\n>Full license copy [here](LICENSE.md)\n\n</br>\n\n## Contributors\n<a href=\"https://github.com/dp-hridayan/ashellyou/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=dp-hridayan/ashellyou\" />\n</a>\n</br>\n",
      "stars_today": 8
    },
    {
      "id": 20587599,
      "name": "flink",
      "full_name": "apache/flink",
      "description": "Apache Flink",
      "html_url": "https://github.com/apache/flink",
      "stars": 25719,
      "forks": 13831,
      "language": "Java",
      "topics": [
        "big-data",
        "flink",
        "java",
        "python",
        "scala",
        "sql"
      ],
      "created_at": "2014-06-07T07:00:10Z",
      "updated_at": "2026-01-16T20:01:03Z",
      "pushed_at": "2026-01-16T21:18:28Z",
      "open_issues": 235,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "# Apache Flink\n\nApache Flink is an open source stream processing framework with powerful stream- and batch-processing capabilities.\n\nLearn more about Flink at [https://flink.apache.org/](https://flink.apache.org/)\n\n\n### Features\n\n* A streaming-first runtime that supports both batch processing and data streaming programs\n\n* Elegant and fluent APIs in Java\n\n* A runtime that supports very high throughput and low event latency at the same time\n\n* Support for *event time* and *out-of-order* processing in the DataStream API, based on the *Dataflow Model*\n\n* Flexible windowing (time, count, sessions, custom triggers) across different time semantics (event time, processing time)\n\n* Fault-tolerance with *exactly-once* processing guarantees\n\n* Natural back-pressure in streaming programs\n\n* Libraries for Graph processing (batch), Machine Learning (batch), and Complex Event Processing (streaming)\n\n* Custom memory management for efficient and robust switching between in-memory and out-of-core data processing algorithms\n\n* Compatibility layers for Apache Hadoop MapReduce\n\n* Integration with YARN, HDFS, HBase, and other components of the Apache Hadoop ecosystem\n\n\n### Streaming Example\n```java\n// pojo class WordWithCount\npublic class WordWithCount {\n    public String word;\n    public int count;\n\n    public WordWithCount() {}\n    \n    public WordWithCount(String word, int count) {\n        this.word = word;\n        this.count = count;\n    }\n}\n\n// main method\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nDataStreamSource<String> text = env.socketTextStream(host, port);\nDataStream<WordWithCount> windowCounts = text\n    .flatMap(\n        (FlatMapFunction<String, String>) (line, collector) \n            -> Arrays.stream(line.split(\"\\\\s\")).forEach(collector::collect)\n    ).returns(String.class)\n    .map(word -> new WordWithCount(word, 1)).returns(TypeInformation.of(WordWithCount.class))\n    .keyBy(wordWithCnt -> wordWithCnt.word)\n    .window(TumblingProcessingTimeWindows.of(Duration.ofSeconds(5)))\n    .sum(\"count\").returns(TypeInformation.of(WordWithCount.class));\n\nwindowCounts.print();\nenv.execute();\n}\n```\n\n### Batch Example\n```java\n// pojo class WordWithCount\npublic class WordWithCount {\n    public String word;\n    public int count;\n\n    public WordWithCount() {}\n\n    public WordWithCount(String word, int count) {\n        this.word = word;\n        this.count = count;\n    }\n}\n\n// main method\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv.setRuntimeMode(RuntimeExecutionMode.BATCH);\nFileSource<String> source = FileSource.forRecordStreamFormat(new TextLineInputFormat(), new Path(\"MyInput.txt\")).build();\nDataStreamSource<String> text = env.fromSource(source, WatermarkStrategy.noWatermarks(), \"MySource\");\nDataStream<WordWithCount> windowCounts = text\n        .flatMap((FlatMapFunction<String, String>) (line, collector) -> Arrays\n                .stream(line.split(\"\\\\s\"))\n                .forEach(collector::collect)).returns(String.class)\n        .map(word -> new WordWithCount(word, 1)).returns(TypeInformation.of(WordWithCount.class))\n        .keyBy(wordWithCount -> wordWithCount.word)\n        .sum(\"count\").returns(TypeInformation.of(WordWithCount.class));\n\nwindowCounts.print();\nenv.execute();\n```\n\n\n\n## Building Apache Flink from Source\n\nPrerequisites for building Flink:\n\n* Unix-like environment (we use Linux, Mac OS X, Cygwin, WSL)\n* Git\n* Maven (we require version 3.8.6)\n* Java (version 11, 17, or 21)\n\n### Basic Build Instructions\n\nFirst, clone the repository:\n\n```\ngit clone https://github.com/apache/flink.git\ncd flink\n```\n\nThen, choose one of the following commands based on your preferred Java version:\n\n**For Java 11**\n\n```\n./mvnw clean package -DskipTests -Djdk11 -Pjava11-target\n```\n\n**For Java 17 (Default)**\n\n```\n./mvnw clean package -DskipTests -Djdk17 -Pjava17-target\n```\n\n**For Java 21**\n\n```\n./mvnw clean package -DskipTests -Djdk21 -Pjava21-target\n```\n\nThe build process will take approximately 10 minutes to complete.\nFlink will be installed in `build-target`.\n\n### Notes\n\n* Make sure your JAVA_HOME environment variable points to the correct JDK version\n* The build command uses Maven wrapper (mvnw) which ensures the correct Maven version is used\n* The -DskipTests flag skips running tests to speed up the build process\n* Each Java version requires its corresponding profile (-Pjava<version>-target) and JDK flag (-Djdk<version>)\n\n## Developing Flink\n\nThe Flink committers use IntelliJ IDEA to develop the Flink codebase.\nWe recommend IntelliJ IDEA for developing projects that involve Scala code.\n\nMinimal requirements for an IDE are:\n* Support for Java and Scala (also mixed projects)\n* Support for Maven with Java and Scala\n\n\n### IntelliJ IDEA\n\nThe IntelliJ IDE supports Maven out of the box and offers a plugin for Scala development.\n\n* IntelliJ download: [https://www.jetbrains.com/idea/](https://www.jetbrains.com/idea/)\n* IntelliJ Scala Plugin: [https://plugins.jetbrains.com/plugin/?id=1347](https://plugins.jetbrains.com/plugin/?id=1347)\n\nCheck out our [Setting up IntelliJ](https://nightlies.apache.org/flink/flink-docs-master/flinkDev/ide_setup.html#intellij-idea) guide for details.\n\n### Eclipse Scala IDE\n\n**NOTE:** From our experience, this setup does not work with Flink\ndue to deficiencies of the old Eclipse version bundled with Scala IDE 3.0.3 or\ndue to version incompatibilities with the bundled Scala version in Scala IDE 4.4.1.\n\n**We recommend to use IntelliJ instead (see above)**\n\n## Support\n\nDon‚Äôt hesitate to ask!\n\nContact the developers and community on the [mailing lists](https://flink.apache.org/community.html#mailing-lists) if you need any help.\n\n[Open an issue](https://issues.apache.org/jira/browse/FLINK) if you find a bug in Flink.\n\n\n## Documentation\n\nThe documentation of Apache Flink is located on the website: [https://flink.apache.org](https://flink.apache.org)\nor in the `docs/` directory of the source code.\n\n\n## Fork and Contribute\n\nThis is an active open-source project. We are always open to people who want to use the system or contribute to it.\nContact us if you are looking for implementation tasks that fit your skills.\nThis article describes [how to contribute to Apache Flink](https://flink.apache.org/contributing/how-to-contribute.html).\n\n## Externalized Connectors\n\nMost Flink connectors have been externalized to individual repos under the [Apache Software Foundation](https://github.com/apache):\n\n* [flink-connector-aws](https://github.com/apache/flink-connector-aws)\n* [flink-connector-cassandra](https://github.com/apache/flink-connector-cassandra)\n* [flink-connector-elasticsearch](https://github.com/apache/flink-connector-elasticsearch)\n* [flink-connector-gcp-pubsub](https://github.com/apache/flink-connector-gcp-pubsub)\n* [flink-connector-hbase](https://github.com/apache/flink-connector-hbase)\n* [flink-connector-hive](https://github.com/apache/flink-connector-hive)\n* [flink-connector-jdbc](https://github.com/apache/flink-connector-jdbc)\n* [flink-connector-kafka](https://github.com/apache/flink-connector-kafka)\n* [flink-connector-mongodb](https://github.com/apache/flink-connector-mongodb)\n* [flink-connector-opensearch](https://github.com/apache/flink-connector-opensearch)\n* [flink-connector-prometheus](https://github.com/apache/flink-connector-prometheus)\n* [flink-connector-pulsar](https://github.com/apache/flink-connector-pulsar)\n* [flink-connector-rabbitmq](https://github.com/apache/flink-connector-rabbitmq)\n\n## About\n\nApache Flink is an open source project of The Apache Software Foundation (ASF).\nThe Apache Flink project originated from the [Stratosphere](http://stratosphere.eu) research project.\n",
      "stars_today": 7
    },
    {
      "id": 65214191,
      "name": "envoy",
      "full_name": "envoyproxy/envoy",
      "description": "Cloud-native high-performance edge/middle/service proxy",
      "html_url": "https://github.com/envoyproxy/envoy",
      "stars": 27340,
      "forks": 5216,
      "language": "C++",
      "topics": [
        "cars",
        "cats",
        "cats-over-dogs",
        "cncf",
        "corgis",
        "more-cats",
        "nanoservices",
        "rocket-ships"
      ],
      "created_at": "2016-08-08T15:07:24Z",
      "updated_at": "2026-01-17T00:17:14Z",
      "pushed_at": "2026-01-16T23:50:23Z",
      "open_issues": 1689,
      "owner": {
        "login": "envoyproxy",
        "avatar_url": "https://avatars.githubusercontent.com/u/30125649?v=4"
      },
      "readme": "![Envoy Logo](https://github.com/envoyproxy/artwork/blob/main/PNG/Envoy_Logo_Final_PANTONE.png)\n\n[Cloud-native high-performance edge/middle/service proxy](https://www.envoyproxy.io/)\n\nEnvoy is hosted by the [Cloud Native Computing Foundation](https://cncf.io) (CNCF). If you are a\ncompany that wants to help shape the evolution of technologies that are container-packaged,\ndynamically-scheduled and microservices-oriented, consider joining the CNCF. For details about who's\ninvolved and how Envoy plays a role, read the CNCF\n[announcement](https://www.cncf.io/blog/2017/09/13/cncf-hosts-envoy/).\n\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1266/badge)](https://bestpractices.coreinfrastructure.org/projects/1266)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/envoyproxy/envoy/badge)](https://securityscorecards.dev/viewer/?uri=github.com/envoyproxy/envoy)\n[![CLOMonitor](https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/envoy/badge)](https://clomonitor.io/projects/cncf/envoy)\n[![Azure Pipelines](https://dev.azure.com/cncf/envoy/_apis/build/status/11?branchName=main)](https://dev.azure.com/cncf/envoy/_build/latest?definitionId=11&branchName=main)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/envoy.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:envoy)\n[![Jenkins](https://powerci.osuosl.org/buildStatus/icon?job=build-envoy-static-master&subject=ppc64le%20build)](https://powerci.osuosl.org/job/build-envoy-static-master/)\n[![Jenkins](https://ibmz-ci.osuosl.org/buildStatus/icon?job=Envoy_IBMZ_CI&subject=s390x%20build)](https://ibmz-ci.osuosl.org/job/Envoy_IBMZ_CI/)\n\n## Documentation\n\n* [Official documentation](https://www.envoyproxy.io/)\n* [FAQ](https://www.envoyproxy.io/docs/envoy/latest/faq/overview)\n* [Example documentation](https://github.com/envoyproxy/examples/)\n* [Blog](https://medium.com/@mattklein123/envoy-threading-model-a8d44b922310) about the threading model\n* [Blog](https://medium.com/@mattklein123/envoy-hot-restart-1d16b14555b5) about hot restart\n* [Blog](https://medium.com/@mattklein123/envoy-stats-b65c7f363342) about stats architecture\n* [Blog](https://medium.com/@mattklein123/the-universal-data-plane-api-d15cec7a) about universal data plane API\n* [Blog](https://medium.com/@mattklein123/lyfts-envoy-dashboards-5c91738816b1) on Lyft's Envoy dashboards\n\n## Related\n\n* [data-plane-api](https://github.com/envoyproxy/data-plane-api): v2 API definitions as a standalone\n  repository. This is a read-only mirror of [api](api/).\n* [envoy-perf](https://github.com/envoyproxy/envoy-perf): Performance testing framework.\n* [envoy-filter-example](https://github.com/envoyproxy/envoy-filter-example): Example of how to add new filters\n  and link to the main repository.\n\n## Contact\n\n* [envoy-announce](https://groups.google.com/forum/#!forum/envoy-announce): Low frequency mailing\n  list where we will email announcements only.\n* [envoy-security-announce](https://groups.google.com/forum/#!forum/envoy-security-announce): Low frequency mailing\n  list where we will email security related announcements only.\n* [envoy-users](https://groups.google.com/forum/#!forum/envoy-users): General user discussion.\n* [envoy-dev](https://groups.google.com/forum/#!forum/envoy-dev): Envoy developer discussion (APIs,\n  feature design, etc.).\n* [envoy-maintainers](https://groups.google.com/forum/#!forum/envoy-maintainers): Use this list\n  to reach all core Envoy maintainers.\n* [Twitter](https://twitter.com/EnvoyProxy/): Follow along on Twitter!\n* [Slack](https://envoyproxy.slack.com/): Slack, to get invited go [here](https://communityinviter.com/apps/envoyproxy/envoy).\n  * NOTE: Response to user questions is best effort on Slack. For a \"guaranteed\" response please email\n    envoy-users@ per the guidance in the following linked thread.\n\nPlease see [this](https://groups.google.com/forum/#!topic/envoy-announce/l9zjYsnS3TY) email thread\nfor information on email list usage.\n\n## Contributing\n\nContributing to Envoy is fun and modern C++ is a lot less scary than you might think if you don't\nhave prior experience. To get started:\n\n* [Contributing guide](CONTRIBUTING.md)\n* [Beginner issues](https://github.com/envoyproxy/envoy/issues?q=is%3Aopen+is%3Aissue+label%3Abeginner)\n* [Build/test quick start using docker](ci#building-and-running-tests-as-a-developer)\n* [Developer guide](DEVELOPER.md)\n* Consider installing the Envoy [development support toolchain](https://github.com/envoyproxy/envoy/blob/main/support/README.md), which helps automate parts of the development process, particularly those involving code review.\n* Please make sure that you let us know if you are working on an issue so we don't duplicate work!\n\n## Community Meeting\n\nThe Envoy team has a scheduled meeting time twice per month on Tuesday at 9am PT. The public\nGoogle calendar is [here](https://goo.gl/PkDijT).  The meeting will only be held\nif there are agenda items listed in the [meeting\nminutes](https://goo.gl/5Cergb).  Any member of the community should be able to\npropose agenda items by adding to the minutes.  The maintainers will either confirm\nthe additions to the agenda, or will cancel the meeting within 24 hours of the scheduled\ndate if there is no confirmed agenda.\n\n## Security\n\n### Security Audit\n\nThere has been several third party engagements focused on Envoy security:\n* In 2018 Cure53 performed a security audit, [full report](docs/security/audit_cure53_2018.pdf).\n* In 2021 Ada Logics performed an audit on our fuzzing infrastructure with recommendations for improvements, [full report](docs/security/audit_fuzzer_adalogics_2021.pdf).\n\n### Reporting security vulnerabilities\n\nIf you've found a vulnerability or a potential vulnerability in Envoy please let us know at\n[envoy-security](mailto:envoy-security@googlegroups.com). We'll send a confirmation\nemail to acknowledge your report, and we'll send an additional email when we've identified the issue\npositively or negatively.\n\nFor further details please see our complete [security release process](SECURITY.md).\n\n### ppc64le builds\n\nBuilds for the ppc64le architecture or using aws-lc are not covered by the envoy security policy. The ppc64le architecture is currently best-effort and not maintained by the Envoy maintainers.\n\n## Releases\n\nFor further details please see our [release process](https://github.com/envoyproxy/envoy/blob/main/RELEASES.md).\n",
      "stars_today": 7
    },
    {
      "id": 139910229,
      "name": "cli",
      "full_name": "npm/cli",
      "description": "the package manager for JavaScript",
      "html_url": "https://github.com/npm/cli",
      "stars": 9436,
      "forks": 4064,
      "language": "JavaScript",
      "topics": [
        "javascript",
        "nodejs",
        "npm",
        "npm-cli",
        "package-manager",
        "tools"
      ],
      "created_at": "2018-07-05T23:26:52Z",
      "updated_at": "2026-01-16T21:39:16Z",
      "pushed_at": "2026-01-15T19:42:38Z",
      "open_issues": 630,
      "owner": {
        "login": "npm",
        "avatar_url": "https://avatars.githubusercontent.com/u/6078720?v=4"
      },
      "readme": "# npm - a JavaScript package manager\n\n### Requirements\n\nYou should be running a currently supported version of [Node.js](https://nodejs.org/en/download/) to run **`npm`**.  For a list of which versions of Node.js are currently supported, please see the [Node.js releases](https://nodejs.org/en/about/previous-releases) page.\n\n### Installation\n\n**`npm`** comes bundled with [**`node`**](https://nodejs.org/), & most third-party distributions, by default. Officially supported downloads/distributions can be found at: [nodejs.org/en/download](https://nodejs.org/en/download)\n\n#### Direct Download\n\nYou can download & install **`npm`** directly from [**npmjs**.com](https://npmjs.com/) using our custom `install.sh` script:\n\n```bash\ncurl -qL https://www.npmjs.com/install.sh | sh\n```\n\n#### Node Version Managers\n\nIf you're looking to manage multiple versions of **`Node.js`** &/or **`npm`**, consider using a [node version manager](https://github.com/search?q=node+version+manager+archived%3Afalse&type=repositories&ref=advsearch)\n\n### Usage\n\n```bash\nnpm <command>\n```\n\n### Links & Resources\n\n* [**Documentation**](https://docs.npmjs.com/) - Official docs & how-tos for all things **npm**\n    * Note: you can also search docs locally with `npm help-search <query>`\n* [**Bug Tracker**](https://github.com/npm/cli/issues) - Search or submit bugs against the CLI\n* [**Community Feedback and Discussions**](https://github.com/orgs/community/discussions/categories/npm) - Contribute ideas & discussion around the npm registry, website & CLI\n* [**RFCs**](https://github.com/npm/rfcs) - Contribute ideas & specifications for the API/design of the npm CLI\n* [**Service Status**](https://status.npmjs.org/) - Monitor the current status & see incident reports for the website & registry\n* [**Project Status**](https://npm.github.io/statusboard/) - See the health of all our maintained OSS projects in one view\n* [**Support**](https://www.npmjs.com/support) - Experiencing problems with the **npm** [website](https://npmjs.com) or [registry](https://registry.npmjs.org)? [File a ticket](https://www.npmjs.com/support)\n\n### Acknowledgments\n\n* `npm` is configured to use the **npm Public Registry** at [https://registry.npmjs.org](https://registry.npmjs.org) by default; Usage of this registry is subject to **Terms of Use** available at [https://npmjs.com/policies/terms](https://npmjs.com/policies/terms)\n* You can configure `npm` to use any other compatible registry you prefer. You can read more about [configuring third-party registries](https://docs.npmjs.com/cli/v7/using-npm/registry)\n\n### FAQ on Branding\n\n#### Is it \"npm\" or \"NPM\" or \"Npm\"?\n\n**`npm`** should never be capitalized unless it is being displayed in a location that is customarily all-capitals (ex. titles on `man` pages).\n\n#### Is \"npm\" an acronym for \"Node Package Manager\"?\n\nContrary to popular belief, **`npm`** **is not** in fact an acronym for \"Node Package Manager\"; It is a recursive bacronymic abbreviation for **\"npm is not an acronym\"** (if the project was named \"ninaa\", then it would be an acronym). The precursor to **`npm`** was actually a bash utility named **\"pm\"**, which was the shortform name of **\"pkgmakeinst\"** - a bash function that installed various things on various platforms. If **`npm`** were to ever have been considered an acronym, it would be as \"node pm\" or, potentially \"new pm\".\n",
      "stars_today": 7
    },
    {
      "id": 696990839,
      "name": "Sigma-Web-Dev-Course",
      "full_name": "CodeWithHarry/Sigma-Web-Dev-Course",
      "description": "Source Code for Sigma Web Development Course",
      "html_url": "https://github.com/CodeWithHarry/Sigma-Web-Dev-Course",
      "stars": 10870,
      "forks": 3048,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2023-09-26T20:34:11Z",
      "updated_at": "2026-01-16T19:21:52Z",
      "pushed_at": "2024-11-05T13:28:33Z",
      "open_issues": 179,
      "owner": {
        "login": "CodeWithHarry",
        "avatar_url": "https://avatars.githubusercontent.com/u/48705673?v=4"
      },
      "readme": "# Welcome to Sigma's Web Development Course - Hindi Web Development Tutorials! üöÄ\n\n## What's Inside:\n\nIf you've been itching to dive into the world of web development but feel lost in a sea of English tutorials, you're in the right place! Our course is exclusively in Hindi and is crafted to guide you from being an absolute beginner to a seasoned pro, one step at a time.\n\n## Who Can Benefit?\n\n### This course is a perfect fit for:\n\n1. Beginners eager to start their web development journey\n2. Intermediate developers looking to refine their skills\n3. Individuals who prefer learning in Hindi\n\n## What You'll Master:\n\n### During this course, you'll delve into:\n\n1. The fundamentals of HTML, CSS, and JavaScript\n2. Both front-end and back-end development\n3. How to seamlessly integrate databases\n4. Real-world project implementation\n5. And a whole lot more!\n\n## The Schedule:\n\nWe're committed to your growth. Expect fresh source code additions nearly every day. Keep up the pace with our schedule and watch your skills soar! üìÖ\n\nGet ready to embark on an exciting coding journey! üë®‚Äçüíªüåü\n\nReady to start? [Click here](https://www.youtube.com/playlist?list=PLu0W_9lII9agq5TrH9XLIKQvv0iaF2X3w) to access the complete YouTube playlist.\n",
      "stars_today": 7
    },
    {
      "id": 204459250,
      "name": "xv6-riscv",
      "full_name": "mit-pdos/xv6-riscv",
      "description": "Xv6 for RISC-V",
      "html_url": "https://github.com/mit-pdos/xv6-riscv",
      "stars": 9122,
      "forks": 3617,
      "language": "C",
      "topics": [],
      "created_at": "2019-08-26T11:15:28Z",
      "updated_at": "2026-01-17T00:07:01Z",
      "pushed_at": "2025-12-17T22:37:29Z",
      "open_issues": 34,
      "owner": {
        "login": "mit-pdos",
        "avatar_url": "https://avatars.githubusercontent.com/u/12404246?v=4"
      },
      "readme": "xv6 is a re-implementation of Dennis Ritchie's and Ken Thompson's Unix\nVersion 6 (v6).  xv6 loosely follows the structure and style of v6,\nbut is implemented for a modern RISC-V multiprocessor using ANSI C.\n\nACKNOWLEDGMENTS\n\nxv6 is inspired by John Lions's Commentary on UNIX 6th Edition (Peer\nto Peer Communications; ISBN: 1-57398-013-7; 1st edition (June 14,\n2000)).  See also https://pdos.csail.mit.edu/6.1810/, which provides\npointers to on-line resources for v6.\n\nThe following people have made contributions: Russ Cox (context switching,\nlocking), Cliff Frey (MP), Xiao Yu (MP), Nickolai Zeldovich, and Austin\nClements.\n\nWe are also grateful for the bug reports and patches contributed by\nAbhinavpatel00, Takahiro Aoyagi, Marcelo Arroyo, Hirbod Behnam, Silas\nBoyd-Wickizer, Anton Burtsev, carlclone, Ian Chen, clivezeng, Dan\nCross, Cody Cutler, Mike CAT, Tej Chajed, Asami Doi,Wenyang Duan,\nechtwerner, eyalz800, Nelson Elhage, Saar Ettinger, Alice Ferrazzi,\nNathaniel Filardo, flespark, Peter Froehlich, Yakir Goaron, Shivam\nHanda, Matt Harvey, Bryan Henry, jaichenhengjie, Jim Huang, Mat√∫≈°\nJ√≥kay, John Jolly, Alexander Kapshuk, Anders Kaseorg, kehao95,\nWolfgang Keller, Jungwoo Kim, Jonathan Kimmitt, Eddie Kohler, Vadim\nKolontsov, Austin Liew, l0stman, Pavan Maddamsetti, Imbar Marinescu,\nYandong Mao, Matan Shabtay, Hitoshi Mitake, Carmi Merimovich,\nmes900903, Mark Morrissey, mtasm, Joel Nider, Hayato Ohhashi,\nOptimisticSide, papparapa, phosphagos, Harry Porter, Greg Price, Zheng\nqhuo, Quancheng, RayAndrew, Jude Rich, segfault, Ayan Shafqat, Eldar\nSehayek, Yongming Shen, Fumiya Shigemitsu, snoire, Taojie, Cam Tenny,\ntyfkda, Warren Toomey, Stephen Tu, Alissa Tung, Rafael Ubal, unicornx,\nAmane Uehara, Pablo Ventura, Luc Videau, Xi Wang, WaheedHafez, Keiichi\nWatanabe, Lucas Wolf, Nicolas Wolovick, wxdao, Grant Wu, x653, Andy\nZhang, Jindong Zhang, Icenowy Zheng, ZhUyU1997, and Zou Chang Wei.\n\nERROR REPORTS\n\nPlease send errors and suggestions to Frans Kaashoek and Robert Morris\n(kaashoek,rtm@mit.edu).  The main purpose of xv6 is as a teaching\noperating system for MIT's 6.1810, so we are more interested in\nsimplifications and clarifications than new features.\n\nBUILDING AND RUNNING XV6\n\nYou will need a RISC-V \"newlib\" tool chain from\nhttps://github.com/riscv/riscv-gnu-toolchain, and qemu compiled for\nriscv64-softmmu.  Once they are installed, and in your shell\nsearch path, you can run \"make qemu\".\n",
      "stars_today": 7
    },
    {
      "id": 64060314,
      "name": "TheFatRat",
      "full_name": "screetsec/TheFatRat",
      "description": "Thefatrat a massive exploiting tool : Easy tool to generate backdoor and easy tool to post exploitation attack like browser attack and etc . This tool compiles a malware with popular payload and then the compiled malware can be execute on windows, android, mac . The malware that created with this tool also have an ability to bypass most AV software protection .",
      "html_url": "https://github.com/screetsec/TheFatRat",
      "stars": 10914,
      "forks": 2498,
      "language": "C",
      "topics": [
        "accessibility",
        "antivirus",
        "autorun",
        "backdoor",
        "bypass",
        "bypass-av",
        "bypassantivirus",
        "dracos",
        "hacking",
        "kali-linux",
        "linux",
        "malware",
        "metasploit-framework",
        "msfvenom",
        "rat",
        "remote",
        "remote-access",
        "thefatrat",
        "tool",
        "trojan"
      ],
      "created_at": "2016-07-24T10:30:19Z",
      "updated_at": "2026-01-16T22:18:07Z",
      "pushed_at": "2024-03-17T12:09:38Z",
      "open_issues": 145,
      "owner": {
        "login": "screetsec",
        "avatar_url": "https://avatars.githubusercontent.com/u/17976841?v=4"
      },
      "readme": "\n# TheFatRat \n\n[![Version](https://img.shields.io/badge/TheFatRat-1.9.8-brightgreen.svg?maxAge=259200)]()\n[![Version](https://img.shields.io/badge/Codename-Target-red.svg?maxAge=259200)]()\n[![Stage](https://img.shields.io/badge/Release-Testing-brightgreen.svg)]()\n[![Build](https://img.shields.io/badge/Supported_OS-Linux-orange.svg)]()\n[![Available](https://img.shields.io/badge/Available-BlackArch-red.svg?maxAge=259200)]()\n[![Documentation](https://img.shields.io/badge/CEHv10-eccouncil-blue.svg?maxAge=259200)](https://github.com/ManhNho/CEHv10/tree/master/Slides)\n[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-blue.svg?style=flat)]()\n\n\n###  A Massive Exploiting Tool\n\n![Banner](https://user-images.githubusercontent.com/17976841/65820028-6ae17e00-e24e-11e9-894f-35836481cc2c.png)\n\n**TheFatRat** is an exploiting tool which compiles a malware with famous payload, and then the compiled maware can be executed on Linux , Windows , Mac and Android. **TheFatRat** Provides An Easy way to create Backdoors and Payload which can bypass most anti-virus. \n \n ## Information\n This tool is for educational purpose only, usage of TheFatRat for attacking targets without prior mutual consent is illegal.\nDevelopers assume no liability and are not responsible for any misuse or damage cause by this program.\n\n ## Features !\n - Fully Automating MSFvenom & Metasploit.\n- Local or remote listener Generation.\n- Easily Make Backdoor by category Operating System.\n- Generate payloads in Various formats.\n- Bypass anti-virus backdoors.\n- File pumper that you can use for increasing the size of your files.\n- The ability to detect external IP & Interface address .\n- Automatically creates AutoRun files for USB / CDROM exploitation\n\n### But it's shit! And your implementation sucks!\n- Yes, you're probably correct. Feel free to \"Not use it\" and there is a pull button to \"Make it better\". \n\n\n# Installation\nInstructions on how to install *TheFatRat*\n```bash\ngit clone https://github.com/Screetsec/TheFatRat.git\ncd TheFatRat\nchmod +x setup.sh && ./setup.sh\n```\n### Update \n```bash\ncd TheFatRat\n./update && chmod +x setup.sh && ./setup.sh\n```\n### Troubleshoot on TheFatRat\nchk_tools script to use in case of problems in setup.sh of fatrat\nthis script will check if everything is in the right version to run fatrat\nand will also provide you a solution for the problem\n```\ncd TheFatRat\nchmod +x chk_tools \n./chk_tools\n```\n\n## Tools Overview\n| Front View | Sample Feature\t|\n| ------------  | ------------ |\n|![Index](https://cloud.githubusercontent.com/assets/17976841/25420100/9ee12cf6-2a80-11e7-8dfa-c2e3cfe71366.png)|![f](https://user-images.githubusercontent.com/17976841/65820886-91a4b200-e258-11e9-9a00-1e5905f6be16.jpg)\n\n## Documentation\n- Documentation Available in Modules CEH v9 and V10 , Download source here \n\t- [CEHv10 Module 06 System Hacking.pdf](https://github.com/khanhnnvn/CEHv10/blob/master/Labs/CEHv10%20Module%2006%20System%20Hacking.pdf)\n\t- [CEHv10 Module 17 Hacking Mobile Platforms.pdf](https://github.com/khanhnnvn/CEHv10/blob/master/Labs/CEHv10%20Module%2017%20Hacking%20Mobile%20Platforms.pdf)\n- Published in International Journal of Cyber-Security and Digital Forensics\n\t- [Malware Analysis Of Backdoor Creator : TheFatRat](https://www.researchgate.net/publication/323574673_MALWARE_ANALYSIS_OF_BACKDOOR_CREATOR_FATRAT)\n- Youtube Videos \n\t- [How To Download & Install TheFatRat](https://www.youtube.com/watch?v=FsSgJFxyzFQ)\n\t- [TheFatRat 1.9.6 - Trodebi ( Embed Trojan into Debian Package )](https://www.youtube.com/watch?v=NCsrcqhUBCc&feature=youtu.be&list=PLbyfDadg3caj6nc3KBk375lKWDOjiCmb8)\n\t- [hacking windows 10 with TheFatRat](https://www.youtube.com/watch?v=bFXVAXRXE9Q )\n\t- [Hacking Windows using TheFatRat + Apache2 Server + Ettercap + Metasploit](https://www.youtube.com/watch?v=FlXMslSjnGw)\n\t- [Hacking with a Microsoft Office Word Document from TheFatRat](https://www.youtube.com/watch?v=lglOXojT84M)\n\t- [XSS to powershell attack and bypass Antivirus using BeEF + TheFatRat + Metasploit](https://www.youtube.com/watch?v=pbvg7pgxVjo)\n\t- [TheFatRat - Hacking Over WAN - Embedding Payload in Original Android APK - Without Port Forwarding](https://www.youtube.com/watch?v=XLNigYZ5-fM)\n\t- [How To Automatically Embed Payloads In APK's - Evil-Droid, Thefatrat & Apkinjector](https://www.youtube.com/watch?v=C_Og6LnEZSg)\n\t- [Bind FUD Payload with JPG and Hack over WAN with TheFatRat](https://www.youtube.com/watch?v=VPl1TMCAIy8)\n\n\n## Changelog\nAll notable changes to this project will be documented in this [file](https://github.com/Screetsec/thefatrat/blob/master/CHANGELOG.md).\n\n### About issues\n- Read the [document](https://github.com/Screetsec/TheFatRat/blob/master/issues.md) before making an issue\n\n## Alternative Best Tool - Generating Backdoor & Bypass \n- [Veil-Framework /Veil](https://github.com/Veil-Framework/Veil) - Veil Framework \n- [Shellter](https://www.shellterproject.com/download/) - Shellter AV Evasion Artware\n- [Unicorn](https://github.com/trustedsec/unicorn) - Trustedsec \n- [MSFvenom Payload Creator (MSFPC)](https://github.com/g0tmi1k/msfpc) - g0tmi1k\n- [Venom](https://github.com/r00t-3xp10it/venom) - Pedro Ubuntu\n- [Phantom-Evasion](https://github.com/oddcod3/Phantom-Evasion) - Diego Cornacchini\n\n\n## Credits & Thanks\n- [Offensive Security](https://www.offensive-security.com/) - Offensive Security\n- [dracOs Linux](https://dracos-linux.org/) - Penetration Testing OS From Indonesia\n- [peterpt](https://github.com/peterpt) - Maintainer & Contributor\n- [Dana James Traversie](https://github.com/dana-at-cp/backdoor-apk) - backdoor_apk\n- [z0noxz](https://github.com/z0noxz/powerstager) - Powerstager\n- [TrustedSec](https://github.com/trustedsec/unicorn) - Unicorn\n- [Raphael Mudge](https://github.com/rsmudge) - External Source\n- [astr0baby](https://astr0baby.wordpress.com) - Reference Source\n- [NgeSEC](https://ngesec.id/) Community\n- [Gauli(dot)Net](https://gauli.net/) - Lab Penetration\n\n## License\nTheFatRat is made with üñ§ by Edo Maland & All [Contributors](https://github.com/Screetsec/TheFatRat/graphs/contributors). See the **License** file for more details.\n\n\n",
      "stars_today": 7
    },
    {
      "id": 500289888,
      "name": "formbricks",
      "full_name": "formbricks/formbricks",
      "description": "Open Source Qualtrics Alternative",
      "html_url": "https://github.com/formbricks/formbricks",
      "stars": 11752,
      "forks": 2088,
      "language": "TypeScript",
      "topics": [
        "experience-management",
        "form",
        "forms",
        "nextjs",
        "open-source",
        "react",
        "reactjs",
        "survey",
        "survey-analysis",
        "survey-data",
        "survey-form",
        "surveys",
        "tailwindcss",
        "turborepo",
        "typeform",
        "typescript",
        "xm"
      ],
      "created_at": "2022-06-06T04:25:21Z",
      "updated_at": "2026-01-16T23:59:04Z",
      "pushed_at": "2026-01-16T16:37:31Z",
      "open_issues": 228,
      "owner": {
        "login": "formbricks",
        "avatar_url": "https://avatars.githubusercontent.com/u/105877416?v=4"
      },
      "readme": "<div id=\"top\"></div>\n\n<p align=\"center\">Help us grow and star us on Github! ‚≠êÔ∏è</p>\n\n<p align=\"center\">\n\n<a href=\"https://formbricks.com\">\n\n<img width=\"120\" alt=\"Open Source Privacy First Experience Management Solution Qualtrics Alternative Logo\" src=\"https://github.com/formbricks/formbricks/assets/72809645/0086704f-bee7-4d38-9cc8-fa42ee59e004\">\n\n</a>\n\n<h3 align=\"center\">Formbricks</h3>\n\n<p align=\"center\">\nThe Open Source Qualtrics Alternative\n<br />\n<a href=\"https://formbricks.com/\">Website</a>\n</p>\n</p>\n\n<p align=\"center\">\n<a href=\"https://github.com/formbricks/formbricks/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/License-AGPL-purple\" alt=\"License\"></a> <a href=\"https://github.com/formbricks/formbricks/stargazers\"><img src=\"https://img.shields.io/github/stars/formbricks/formbricks?logo=github\" alt=\"Github Stars\"></a>\n<a href=\"https://insights.linuxfoundation.org/project/formbricks\"><img src=\"https://insights.linuxfoundation.org/api/badge/health-score?project=formbricks\"></a>\n<a href=\"https://news.ycombinator.com/item?id=32303986\"><img src=\"https://img.shields.io/badge/Hacker%20News-122-%23FF6600\" alt=\"Hacker News\"></a>\n<a href=\"[https://www.producthunt.com/products/formbricks](https://www.producthunt.com/posts/formbricks)\"><img src=\"https://img.shields.io/badge/Product%20Hunt-455-orange?logo=producthunt&logoColor=%23fff\" alt=\"Product Hunt\"></a>\n<a href=\"https://github.blog/2023-04-12-github-accelerator-our-first-cohort-and-whats-next/\"><img src=\"https://img.shields.io/badge/2023-blue?logo=github&label=Github%20Accelerator\" alt=\"Github Accelerator\"></a>\n<a href=\"https://github.com/formbricks/formbricks/issues?q=is:issue+is:open+label:%22%F0%9F%99%8B%F0%9F%8F%BB%E2%80%8D%E2%99%82%EF%B8%8Fhelp+wanted%22\"><img src=\"https://img.shields.io/badge/Help%20Wanted-Contribute-blue\"></a>\n</p>\n\n<br/>\n\n<div style=\"background-color:#f8fafc; border-radius:5px;\">\n<p align=\"center\">\n<i>Trusted by</i><br/>\n  <img width=\"867\" alt=\"clients-hi-res\" src=\"https://github.com/formbricks/formbricks/assets/72809645/924d3693-f66a-4063-bb31-6e5789a8175a\">\n</p>\n<div>\n\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/2570\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/2570\" alt=\"Trendshift Badge for formbricks/formbricks\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n## ‚ú® About Formbricks\n\n<img width=\"1527\" alt=\"formbricks-sneak\" src=\"https://github-production-user-asset-6210df.s3.amazonaws.com/675065/249441967-ccb89ea3-82b4-4bf2-8d2c-528721ec313b.png\">\n\nFormbricks provides a free and open source surveying platform. Gather feedback at every point in the user journey with beautiful in-app, website, link and email surveys. Build on top of Formbricks or leverage prebuilt data analysis capabilities.\n\n**Try it out in the cloud at [formbricks.com](https://app.formbricks.com/auth/signup)**\n\n## üí™ Mission: Empower your team, craft an irresistible experience.\n\nFormbricks is both a free and open source survey platform - and a privacy-first experience management platform. Use in-app, website, link and email surveys to gather user and customer insights at every point of their journey. Leverage Formbricks Insight Platform or build your own. Life's too short for mediocre UX.\n\n### Table of Contents\n\n- [Features](#features)\n\n- [Getting Started](#getting-started)\n\n- [Cloud Version](#cloud-version)\n\n- [Self-hosted Version](#self-hosted-version)\n\n- [Development](#development)\n\n- [Contribution](#contribution)\n\n- [Contact](#contact-us)\n\n- [Security](#security)\n\n- [License](#license)\n\n<a id=\"features\"></a>\n\n### Features\n\n- üì≤ Create **conversion-optimized surveys** with our no-code editor with several question types.\n\n- üìö Choose from a variety of best-practice **templates**.\n\n- üë©üèª Launch and **target your surveys to specific user groups** without changing your application code.\n\n- üîó Create shareable **link surveys**.\n\n- üë®‚Äçüë©‚Äçüë¶ Invite your organization members to **collaborate** on your surveys.\n\n- üîå Integrate Formbricks with **Slack, Notion, Zapier, n8n and more**.\n\n- üîí All **open source**, transparent and self-hostable.\n\n### Built on Open Source\n\n- üíª [Typescript](https://www.typescriptlang.org/)\n\n- üöÄ [Next.js](https://nextjs.org/)\n\n- ‚öõÔ∏è [React](https://reactjs.org/)\n\n- üé® [TailwindCSS](https://tailwindcss.com/)\n\n- üìö [Prisma](https://prisma.io/)\n\n- üîí [Auth.js](https://authjs.dev/)\n\n- üßò‚Äç‚ôÇÔ∏è [Zod](https://zod.dev/)\n\n- üêõ [Vitest](https://vitest.dev/)\n\n<a id=\"getting-started\"></a>\n\n## üöÄ Getting started\n\nWe've got several options depending on your need to help you quickly get started with Formbricks.\n\n<a id=\"cloud-version\"></a>\n\n### ‚òÅÔ∏è Cloud Version\n\nFormbricks has a hosted cloud offering with a generous free plan to get you up and running as quickly as possible. To get started, please visit [formbricks.com](https://app.formbricks.com/auth/signup).\n\n<a id=\"self-hosted-version\"></a>\n\n### üê≥ Self-hosting Formbricks\n\nFormbricks is available Open-Source under AGPLv3 license. You can host Formbricks on your own servers using Docker without a subscription.\n\nIf you opt for self-hosting Formbricks, here are a few options to consider:\n\n#### Docker\n\nTo get started with self-hosting with Docker, take a look at our [self-hosting docs](https://formbricks.com/docs/self-hosting/deployment).\n\n#### Community-managed One Click Hosting\n\n##### Railway\n\nYou can deploy Formbricks on [Railway](https://railway.app) using the button below.\n\n[![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/new/template/PPDzCd)\n\n##### RepoCloud\n\nOr you can also deploy Formbricks on [RepoCloud](https://repocloud.io) using the button below.\n\n[![Deploy on RepoCloud](https://d16t0pc4846x52.cloudfront.net/deploy.png)](https://repocloud.io/details/?app_id=254)\n\n##### Zeabur\n\nOr you can also deploy Formbricks on [Zeabur](https://zeabur.com) using the button below.\n\n[![Deploy to Zeabur](https://zeabur.com/button.svg)](https://zeabur.com/templates/G4TUJL)\n\n<a id=\"development\"></a>\n\n## üë®‚Äçüíª Development\n\n### Prerequisites\n\nHere is what you need to be able to run Formbricks:\n\n- [Node.js](https://nodejs.org/en) (Version: >=18.x)\n\n- [Pnpm](https://pnpm.io/)\n\n- [Docker](https://www.docker.com/) - to run PostgreSQL and MailHog\n\n### Local Setup\n\nTo get started locally, we've got a [guide to help you](https://formbricks.com/docs/developer-docs/contributing/get-started#local-machine-setup).\n\n### Gitpod Setup\n\n1. Click the button below to open this project in Gitpod.\n\n2. This will open a fully configured workspace in your browser with all the necessary dependencies already installed.\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/formbricks/formbricks)\n\n<a id=\"contribution\"></a>\n\n## ‚úçÔ∏è Contribution\n\nWe are very happy if you are interested in contributing to Formbricks ü§ó\n\nHere are a few options:\n\n- Star this repo.\n\n- Create issues every time you feel something is missing or goes wrong.\n\n- Upvote issues with üëç reaction so we know what the demand for a particular issue is to prioritize it within the roadmap.\n\n- Note: For the time being, we can only facilitate code contributions as an exception.\n\n## All Thanks To Our Contributors\n\n<a href=\"https://github.com/formbricks/formbricks/graphs/contributors\">\n\n<img src=\"https://contrib.rocks/image?repo=formbricks/formbricks\" />\n\n</a>\n\n## Thanks\n\nFormbricks is supported by the following companies who provide us with their tools for free as part of their open-source support:\n\n<a href=\"https://www.chromatic.com/\"><img src=\"https://user-images.githubusercontent.com/321738/84662277-e3db4f80-af1b-11ea-88f5-91d67a5e59f6.png\" width=\"153\" height=\"30\" alt=\"Chromatic\" /></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n<a href=\"https://sentry.io/\"><img src=\"https://github.com/user-attachments/assets/d743ffd4-b575-4802-a29a-10136be9227e\" width=\"150\" height=\"30\" alt=\"Sentry\" /></a>\n\n<a id=\"contact-us\"></a>\n\n## üìÜ Contact us\n\nLet's have a chat about your survey needs and get you started.\n\n<a href=\"https://cal.com/johannes/onboarding?utm_source=banner&utm_campaign=oss\"><img alt=\"Book us with Cal.com\" src=\"https://cal.com/book-with-cal-dark.svg\" /></a>\n\n<a id=\"license\"></a>\n\n<a id=\"security\"></a>\n\n## üîí Security\n\nWe take security very seriously. If you come across any security vulnerabilities, please disclose them by sending an email to security@formbricks.com. We appreciate your help in making our platform as secure as possible and are committed to working with you to resolve any issues quickly and efficiently. See [`SECURITY.md`](./SECURITY.md) for more information.\n\n<a id=\"license\"></a>\n\n## üë©‚Äç‚öñÔ∏è License\n\n### The AGPL Formbricks Core\n\nThe Formbricks core application is licensed under the [AGPLv3 Open Source License](https://github.com/formbricks/formbricks/blob/main/LICENSE). The core application is fully functional and includes everything you need to design & run link surveys, website surveys and in-app surveys. You can use the software for free for personal and commercial use. You're also allowed to create and distribute modified versions as long as you document the changes you make incl. date. The AGPL license requires you to publish your modified version under the AGPLv3 license as well.\n\n### The Enterprise Edition\n\nAdditional to the AGPL licensed Formbricks core, this repository contains code licensed under an Enterprise license. The [code](https://github.com/formbricks/formbricks/tree/main/apps/web/modules/ee) and [license](https://github.com/formbricks/formbricks/blob/main/apps/web/modules/ee/LICENSE) for the enterprise functionality can be found in the `/apps/web/modules/ee` folder of this repository. This additional functionality is not part of the AGPLv3 licensed Formbricks core and is designed to meet the needs of larger teams and enterprises. This advanced functionality is already included in the Docker images, but you need an [Enterprise License Key](https://formbricks.com/docs/self-hosting/enterprise) to unlock it.\n\n### White-Labeling Formbricks and Other Licensing Needs\n\nWe currently do not offer Formbricks white-labeled. That means that we don't sell a license which let's other companies resell Formbricks to third parties under their name nor take parts (like the survey editor) out of Formbricks to add to their own software products. Any other needs? [Send us an email](mailto:hola@formbricks.com).\n\n### Why charge for Enterprise Features?\n\nThe Enterprise Edition allows us to fund the development of Formbricks sustainably. It guarantees that the free and open-source surveying infrastructure we're building will be around for decades to come.\n\n<p align=\"right\"><a href=\"#top\">üîº Back to top</a></p>\n",
      "stars_today": 7
    },
    {
      "id": 222824662,
      "name": "dagger",
      "full_name": "dagger/dagger",
      "description": "Automation engine to build, test and ship any codebase. Runs locally, in CI, or directly in the cloud",
      "html_url": "https://github.com/dagger/dagger",
      "stars": 15282,
      "forks": 844,
      "language": "Go",
      "topics": [
        "agents",
        "ai",
        "caching",
        "ci-cd",
        "containers",
        "continuous-deployment",
        "continuous-integration",
        "dag",
        "dagger",
        "devops",
        "docker",
        "graphql",
        "workflows"
      ],
      "created_at": "2019-11-20T01:31:51Z",
      "updated_at": "2026-01-17T00:06:25Z",
      "pushed_at": "2026-01-16T23:16:43Z",
      "open_issues": 836,
      "owner": {
        "login": "dagger",
        "avatar_url": "https://avatars.githubusercontent.com/u/78824383?v=4"
      },
      "readme": "## Dagger: a better way to ship\n\nDagger is a platform for automating software delivery. It can build, test and ship any codebase, reliably and at scale.\n\nDagger runs locally, in your CI server, or directly in the cloud. \n\n```\nbrew install dagger/tap/dagger\n```\n\n## Why Dagger?\n\nDagger makes your software delivery *programmable*, *local-first*, *repeatable* and *observable*.\n\n**Programmable**. Shell scripts and proprietary YAML are no longer acceptable for automating software delivery. Dagger provides: a complete execution engine and system API; SDKs for 8 languages; an interactive REPL; a rich ecosystem of reusable modules; and more.\n\n**Local-first**. Once you automate a task with Dagger, it will reliably run on any supported system: your laptop, AI sandbox, CI server, or dedicated cloud infrastructure. The only dependency is a container runtime like Docker.\n\n**Repeatable**. Tools run in containers, orchestrated by sandboxed functions. Host dependencies are explicit and strictly typed. Intermediate artifacts are built just-in-time. Every operation is incremental by default, with advanced cache control. Whether it's a test report, a build or a deployment, Dagger gives you an output you can trust.\n\n**Observable**. Every operation emits a full OpenTelemetry trace, enriched by granular logs and metrics. Visualize the trace in directly in the terminal, or in a web view. Debug complex workflows immediately instead of guessing what went wrong from a wall of text logs.\n\n## Features\n\n**System API**. A cross-language API for orchestrating containers, filesystems, secrets, git repositories, network tunnels, and more. Every operation is typed and composable.\n\n**SDKs in 8 languages**. Native SDKs for Go, Python, TypeScript, PHP, Java, .NET, Elixir and Rust. Each SDK is generated from the API schema, so you get idiomatic code with full type safety and editor support.\n\n**Typed artifacts**. Define custom object types with encapsulated state and functions. Types are content-addressed and can be passed across SDK language boundaries and module boundaries without serialization.\n\n**Incremental execution**. Every operation is keyed by its inputs. Change one file and only the affected operations re-run. Caching is content-addressed and works automatically across local runs and CI.\n\n**Runs anywhere**. The only requirement is a Linux container runtime. Runs natively on Linux, or via Docker Desktop and similar products on macOS and Windows. Local and CI behavior are identical.\n\n**Built-in tracing**. Every operation emits OpenTelemetry spans. The CLI includes a live TUI; traces can also be exported to Jaeger, Honeycomb, or any OTel-compatible backend.\n\n\n## Getting started\n\n- [Documentation](https://docs.dagger.io)\n- [Quickstart](https://docs.dagger.io/quickstart)\n\n## Community\n\n- [Discord](https://discord.gg/dagger-io)\n- [GitHub Discussions](https://github.com/dagger/dagger/discussions)\n\n## Contributing\n\nSee [CONTRIBUTING.md](https://github.com/dagger/dagger/blob/main/CONTRIBUTING.md).\n",
      "stars_today": 7
    },
    {
      "id": 349372179,
      "name": "lightdash",
      "full_name": "lightdash/lightdash",
      "description": "Self-serve BI to 10x your data team ‚ö°Ô∏è",
      "html_url": "https://github.com/lightdash/lightdash",
      "stars": 5467,
      "forks": 666,
      "language": "TypeScript",
      "topics": [
        "business-intelligence",
        "data-analytics",
        "data-visualization",
        "dbt"
      ],
      "created_at": "2021-03-19T09:44:40Z",
      "updated_at": "2026-01-16T22:39:09Z",
      "pushed_at": "2026-01-16T18:24:10Z",
      "open_issues": 1699,
      "owner": {
        "login": "lightdash",
        "avatar_url": "https://avatars.githubusercontent.com/u/65912827?v=4"
      },
      "readme": "<h1 align=\"center\">\n        <a target=\"_blank\" href=\"https://www.lightdash.com\"><img align=\"center\" style=\"width:100%;\" src=\"https://assets.website-files.com/62a9ae93cf7542032ae55b9c/62c5c71252b090df3224c706_gh-cover%20(2).png\"> </a>\n</h1>\n\n<p align=\"center\">The open-source Looker alternative.</p>\n\n<div align=\"center\">\n        <a target=\"_blank\" href=\"https://www.loom.com/share/c0805a236a994de397ac5142fdfe4b7f\"><img align=\"center\" style=\"max-width:300px;\" src=\"/static/screenshots/lightdash_preview_chart_animation.gif\"> </a>\n</div>\n<br>\n<p align=\"center\">\n    <a href=\"http://www.lightdash.com\"><b>Website</b></a> ‚Ä¢\n    <a href=\"https://www.loom.com/share/c0805a236a994de397ac5142fdfe4b7f\"><b>Watch demo</b></a> ‚Ä¢\n    <a href=\"http://docs.lightdash.com/\"><b>Docs</b></a> ‚Ä¢\n    <a href=\"https://join.slack.com/t/lightdash-community/shared_invite/zt-2wgtavou8-VRhwXI%7EQbjCAHQs0WBac3w\"><b>Join Slack Community</b></a>\n</p>\n<div align=\"center\">\n<img src=\"https://img.shields.io/github/license/lightdash/lightdash\" />\n</div>\n<div align=\"center\">\n<img src=\"https://img.shields.io/docker/cloud/build/lightdash/lightdash\" />\n</div>\n<div align=\"center\">\n<img src=\"https://img.shields.io/github/languages/top/lightdash/lightdash\" />\n<img src=\"https://img.shields.io/docker/v/lightdash/lightdash?label=latest%20image\" />\n<img src=\"https://img.shields.io/github/package-json/dependency-version/lightdash/lightdash/react?filename=packages%2Ffrontend%2Fpackage.json\" />\n<img src=\"https://img.shields.io/github/package-json/dependency-version/lightdash/lightdash/express?filename=packages%2Fbackend%2Fpackage.json\" />\n<img src=\"https://img.shields.io/static/v1?logo=data:image/png;base64,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&label=dbt-version&message=1.5.3&color=orange\" />\n</div>\n\n<div align=\"center\">\n\n### Enable everybody in your company to answer their own questions using data\n\nconnect your dbt project --> add metrics into dbt --> share insights with your team\n\nIf you're a fan, star the repo ‚≠êÔ∏è (we [plant a tree](#the-lightdash-forest) for every GitHub star we get üå±).\n\nCome join the team, [we're hiring](https://lightdash.notion.site/Lightdash-Job-Board-a2c7d872794b45deb7b76ad68701d750).\n\n</div>\n\n## Features:\n\n- [x] üôè Familiar interface for your users to self-serve using pre-defined metrics\n- [x] üë©‚Äçüíª Declare dimensions and metrics in yaml alongside your dbt project\n- [x] ü§ñ Automatically creates dimensions from your dbt models\n- [x] üìñ dbt descriptions and metadata synced for your users\n- [x] üîç Easily access to underlying records of charts as well as ability to data drill-down\n- [x] üßÆ Table calculations make it easy to dig into your data, on the fly\n- [x] üïµÔ∏è‚Äç‚ôÄÔ∏è Lineage lets you see the upstream and downstream dependencies of a model\n- [x] üìä Comprehensive and intuitive data visualisation library for your metrics\n- [x] üë∑‚Äç‚ôÇÔ∏è Save charts & build dashboards to share your insights with your team\n- [x] üíª Powerful developer experience including Preview BI Environments and automated content validation via CI/CD\n- [x] üîÑ Explore version history of all your charts and roll-back at any point\n- [x] üöÄ Easily share your work via URL or schedule deliveries via Slack or Email\n\nSomething missing? Check out our [open issues](https://github.com/lightdash/lightdash/issues)\nto see if what you're looking for already exists (and give it a üëç). Otherwise, we'd love it if\nyou'd [open a new issue with your request](https://github.com/lightdash/lightdash/issues/new/choose) üòä\n\n## Demo\n\nPlay with our [demo app](https://demo.lightdash.com)!\n\n## Quick start\n\n### Start with Lightdash Cloud\n\nYou can avoid the hassle of hosting and configuring Lightdash yourself by¬†[signing up for a free trial of Lightdash Cloud](https://app.lightdash.cloud/register). More details on pricing [available](https://www.lightdash.com/pricing).\n\n### 1-click deploy\n\nDeploy Lightdash with 1-click on [Render](https://render.com) for free.\n\n<div>\n\n<a href=\"https://render.com/deploy?repo=https://github.com/lightdash/lightdash-deploy-render\">\n  <img src=\"https://render.com/images/deploy-to-render-button.svg\" alt=\"Deploy to Render\">\n</a>\n\n</div>\n\n### Run locally\n\nTake advantage of our installation script to easily run Lightdash locally.\n\n```bash\ngit clone https://github.com/lightdash/lightdash\ncd lightdash\n./scripts/install.sh\n```\n\n### Deploy to production\n\nFollow our [kubernetes guide](https://docs.lightdash.com/self-host/self-host-lightdash) to deploy Lightdash to\nproduction using our [community helm charts](https://github.com/lightdash/helm-charts).\n\n\n## Getting started\n\nStep 1 - ‚ö°Ô∏è [Self-host Lightdash (optional)](https://docs.lightdash.com/self-host/self-host-lightdash)\n\nStep 2 - üîå [Connect a project](https://docs.lightdash.com/get-started/setup-lightdash/connect-project)\n\nStep 3 - üë©‚Äçüíª [Create your first metric](https://docs.lightdash.com/get-started/setup-lightdash/intro-metrics-dimensions)\n\n## Community Support\n\nüì£ If you want something a bit more, then [head on over to our Slack Community](https://join.slack.com/t/lightdash-community/shared_invite/zt-2wgtavou8-VRhwXI%7EQbjCAHQs0WBac3w) where you‚Äôll be able to chat directly with all of us at Lightdash and all the other amazing members of our community. We‚Äôre happy to talk about anything from feature requests, implementation details or dbt quirks to memes and SQL jokes!\n\nYou can also keep up to date with Lightdash by following us here:\n\n- [Twitter](https://twitter.com/lightdash_devs)\n- [LinkedIn](https://www.linkedin.com/company/lightdash)\n\n## About Lightdash\n\n### üóÇ **Keep all of your business logic in one place.**\n\nWe let you define your metrics and dimensions directly in your dbt project, keeping all of your business logic in one place and increasing the context around your analytics.\n\nNo more deciding which of the four different values for total revenue is the **_right_** one (you can thank us later üòâ).\n\n### ü§ù **Build trust in your data.**\n\nWe want everyone at your company to feel like they can trust the data. So, why not **_show_** them that they can?\n\nWe bring the context you want around data quality _into_ your BI tool so people know that they can trust the data.\n\n### üß± **Give users meaningful building blocks to answer their own data questions.**\n\nWith Lightdash, you can leave the SQL to the experts. We give your data team the tools they need to build metrics and dimensions that everyone else can use.\n\nSo, anybody in the business can combine, segment, and filter these metrics and dimensions to answer their own questions.\n\n### üìñ **Open source, now and forever**\n\n**Lightdash is built with our community, for our community.**\n\nWe think that a BI tool should be affordable, configurable, and secure - and being open source lets us be all three üôÇ\n\n### ü§ë **Affordable analytics**\n\nLove Looker, but don't love Looker's price tag?\n\nWith Lightdash, we offer a free self-hosted service (it's all just open source!), or an affordable cloud-service option if you're looking for an easy analytics set up.\n\n## Docs\n\nHave a question about a feature? Or maybe fancy some light reading? Head on over to\nour [Lightdash documentation](https://docs.lightdash.com/) to check out our tutorials, reference docs, FAQs and more.\n\n## Reporting bugs and feature requests\n\nWant to report a bug or request a feature? Open an [issue](https://github.com/lightdash/lightdash/issues/new/choose).\n\n## The Lightdash Forest\n\nWe're planting trees with the help of the Lightdash community.\n\nTree planting is one of the simplest and most cost-effective means of mitigating climate change, by absorbing CO2 from the atmosphere. So we thought it would be pretty neat to grow a forest while we grow Lightdash.\n\nWant to help us grow our forest?\n\nJust star this repo! We plant a tree for every star we get on Github. ‚≠êÔ∏è ‚û°Ô∏è üå±\n\nWe plant trees with TIST, you can read all about them here: https://program.tist.org/.\n\n## Developing locally & Contributing\n\nWe love contributions big or small, check out [our guide](https://github.com/lightdash/lightdash/blob/main/.github/CONTRIBUTING.md#contributing-to-lightdash) on how to get started.\n\nSee our [instructions](https://github.com/lightdash/lightdash/blob/main/.github/CONTRIBUTING.md#setup-development-environment) on developing Lightdash locally.\n\n## Contributors ‚ú®\n\nThanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/rahul-jain-83055b45/\"><img src=\"https://avatars.githubusercontent.com/u/370587?v=4?s=100\" width=\"100px;\" alt=\"Rahul Jain\"/><br /><sub><b>Rahul Jain</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=rahulj51\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/owlas\"><img src=\"https://avatars.githubusercontent.com/u/11660098?v=4?s=100\" width=\"100px;\" alt=\"Oliver Laslett\"/><br /><sub><b>Oliver Laslett</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=owlas\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=owlas\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Aowlas\" title=\"Bug reports\">üêõ</a> <a href=\"#design-owlas\" title=\"Design\">üé®</a> <a href=\"#infra-owlas\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TuringLovesDeathMetal\"><img src=\"https://avatars.githubusercontent.com/u/31848148?v=4?s=100\" width=\"100px;\" alt=\"Katie Hindson\"/><br /><sub><b>Katie Hindson</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3ATuringLovesDeathMetal\" title=\"Bug reports\">üêõ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=TuringLovesDeathMetal\" title=\"Documentation\">üìñ</a> <a href=\"#design-TuringLovesDeathMetal\" title=\"Design\">üé®</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=TuringLovesDeathMetal\" title=\"Code\">üíª</a> <a href=\"#ideas-TuringLovesDeathMetal\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.hamzahchaudhary.com\"><img src=\"https://avatars.githubusercontent.com/u/14341285?v=4?s=100\" width=\"100px;\" alt=\"Hamzah Chaudhary\"/><br /><sub><b>Hamzah Chaudhary</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=hamzahc1\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=hamzahc1\" title=\"Code\">üíª</a> <a href=\"#ideas-hamzahc1\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Ahamzahc1\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/harry-grieve-81427771/\"><img src=\"https://avatars.githubusercontent.com/u/28747142?v=4?s=100\" width=\"100px;\" alt=\"Harry Grieve\"/><br /><sub><b>Harry Grieve</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=h-grieve\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://tkdodo.eu\"><img src=\"https://avatars.githubusercontent.com/u/1021430?v=4?s=100\" width=\"100px;\" alt=\"Dominik Dorfmeister\"/><br /><sub><b>Dominik Dorfmeister</b></sub></a><br /><a href=\"#design-TkDodo\" title=\"Design\">üé®</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/amin-nejad\"><img src=\"https://avatars.githubusercontent.com/u/44096034?v=4?s=100\" width=\"100px;\" alt=\"amin-nejad\"/><br /><sub><b>amin-nejad</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Aamin-nejad\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mitjapotocin\"><img src=\"https://avatars.githubusercontent.com/u/36345162?v=4?s=100\" width=\"100px;\" alt=\"Mitja Potoƒçin\"/><br /><sub><b>Mitja Potoƒçin</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=mitjapotocin\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ZeRego\"><img src=\"https://avatars.githubusercontent.com/u/9117144?v=4?s=100\" width=\"100px;\" alt=\"Jose Rego\"/><br /><sub><b>Jose Rego</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=ZeRego\" title=\"Code\">üíª</a> <a href=\"#design-ZeRego\" title=\"Design\">üé®</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=ZeRego\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3AZeRego\" title=\"Bug reports\">üêõ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=ZeRego\" title=\"Tests\">‚ö†Ô∏è</a> <a href=\"#infra-ZeRego\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.rahul3v.xyz\"><img src=\"https://avatars.githubusercontent.com/u/24385409?v=4?s=100\" width=\"100px;\" alt=\"Rahul\"/><br /><sub><b>Rahul</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Arahul3v\" title=\"Bug reports\">üêõ</a> <a href=\"#design-rahul3v\" title=\"Design\">üé®</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=rahul3v\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=rahul3v\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jeshua.co\"><img src=\"https://avatars.githubusercontent.com/u/2297823?v=4?s=100\" width=\"100px;\" alt=\"Jeshua Maxey\"/><br /><sub><b>Jeshua Maxey</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Ajeshuamaxey\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/srjonemed\"><img src=\"https://avatars.githubusercontent.com/u/34316602?v=4?s=100\" width=\"100px;\" alt=\"Sreejith Madhavan\"/><br /><sub><b>Sreejith Madhavan</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Asrjonemed\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/skame\"><img src=\"https://avatars.githubusercontent.com/u/1732972?v=4?s=100\" width=\"100px;\" alt=\"skame\"/><br /><sub><b>skame</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Askame\" title=\"Bug reports\">üêõ</a> <a href=\"#design-skame\" title=\"Design\">üé®</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/sgoley\"><img src=\"https://avatars.githubusercontent.com/u/10283176?v=4?s=100\" width=\"100px;\" alt=\"sgoley\"/><br /><sub><b>sgoley</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=sgoley\" title=\"Documentation\">üìñ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/djayatillake\"><img src=\"https://avatars.githubusercontent.com/u/54331742?v=4?s=100\" width=\"100px;\" alt=\"djayatillake\"/><br /><sub><b>djayatillake</b></sub></a><br /><a href=\"#design-djayatillake\" title=\"Design\">üé®</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=djayatillake\" title=\"Code\">üíª</a> <a href=\"#ideas-djayatillake\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/silentninja\"><img src=\"https://avatars.githubusercontent.com/u/4469754?v=4?s=100\" width=\"100px;\" alt=\"Mukesh\"/><br /><sub><b>Mukesh</b></sub></a><br /><a href=\"#data-silentninja\" title=\"Data\">üî£</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Asilentninja\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/andreiafreitas\"><img src=\"https://avatars.githubusercontent.com/u/25464035?v=4?s=100\" width=\"100px;\" alt=\"Andreia Freitas\"/><br /><sub><b>Andreia Freitas</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=andreiafreitas\" title=\"Tests\">‚ö†Ô∏è</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=andreiafreitas\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jaybe78\"><img src=\"https://avatars.githubusercontent.com/u/3605098?v=4?s=100\" width=\"100px;\" alt=\"jb\"/><br /><sub><b>jb</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=jaybe78\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Ajaybe78\" title=\"Bug reports\">üêõ</a> <a href=\"#design-jaybe78\" title=\"Design\">üé®</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/amychen1776\"><img src=\"https://avatars.githubusercontent.com/u/46451573?v=4?s=100\" width=\"100px;\" alt=\"Amy Chen\"/><br /><sub><b>Amy Chen</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=amychen1776\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jkeech\"><img src=\"https://avatars.githubusercontent.com/u/746020?v=4?s=100\" width=\"100px;\" alt=\"John Keech\"/><br /><sub><b>John Keech</b></sub></a><br /><a href=\"#infra-jkeech\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ihack.us/\"><img src=\"https://avatars.githubusercontent.com/u/19791?v=4?s=100\" width=\"100px;\" alt=\"Dr. Ernie Prabhakar\"/><br /><sub><b>Dr. Ernie Prabhakar</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Adrernie\" title=\"Bug reports\">üêõ</a> <a href=\"#ideas-drernie\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PriPatel\"><img src=\"https://avatars.githubusercontent.com/u/12776522?v=4?s=100\" width=\"100px;\" alt=\"PriPatel\"/><br /><sub><b>PriPatel</b></sub></a><br /><a href=\"#design-PriPatel\" title=\"Design\">üé®</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3APriPatel\" title=\"Bug reports\">üêõ</a> <a href=\"#ideas-PriPatel\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/NaomiJohnson\"><img src=\"https://avatars.githubusercontent.com/u/29288519?v=4?s=100\" width=\"100px;\" alt=\"NaomiJohnson\"/><br /><sub><b>NaomiJohnson</b></sub></a><br /><a href=\"#design-NaomiJohnson\" title=\"Design\">üé®</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3ANaomiJohnson\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rshen36\"><img src=\"https://avatars.githubusercontent.com/u/20313306?v=4?s=100\" width=\"100px;\" alt=\"Rich Shen\"/><br /><sub><b>Rich Shen</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=rshen36\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=rshen36\" title=\"Tests\">‚ö†Ô∏è</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Arshen36\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://davidgasquez.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/1682202?v=4?s=100\" width=\"100px;\" alt=\"David Gasquez\"/><br /><sub><b>David Gasquez</b></sub></a><br /><a href=\"#ideas-davidgasquez\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#design-davidgasquez\" title=\"Design\">üé®</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/xjaner\"><img src=\"https://avatars.githubusercontent.com/u/2011404?v=4?s=100\" width=\"100px;\" alt=\"xjaner\"/><br /><sub><b>xjaner</b></sub></a><br /><a href=\"#ideas-xjaner\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chrisbol-lf\"><img src=\"https://avatars.githubusercontent.com/u/94607640?v=4?s=100\" width=\"100px;\" alt=\"Chris Bol\"/><br /><sub><b>Chris Bol</b></sub></a><br /><a href=\"#ideas-chrisbol-lf\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://stackoverflow.com/users/815977/tigger\"><img src=\"https://avatars.githubusercontent.com/u/841497?v=4?s=100\" width=\"100px;\" alt=\"Anil V\"/><br /><sub><b>Anil V</b></sub></a><br /><a href=\"#ideas-avaitla\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rlebrao\"><img src=\"https://avatars.githubusercontent.com/u/18443331?v=4?s=100\" width=\"100px;\" alt=\"rlebrao\"/><br /><sub><b>rlebrao</b></sub></a><br /><a href=\"#ideas-rlebrao\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Arlebrao\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/philcarr-tsl\"><img src=\"https://avatars.githubusercontent.com/u/90601643?v=4?s=100\" width=\"100px;\" alt=\"philcarr-tsl\"/><br /><sub><b>philcarr-tsl</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Aphilcarr-tsl\" title=\"Bug reports\">üêõ</a> <a href=\"#data-philcarr-tsl\" title=\"Data\">üî£</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/HashimsGitHub\"><img src=\"https://avatars.githubusercontent.com/u/79075502?v=4?s=100\" width=\"100px;\" alt=\"HashimsGitHub\"/><br /><sub><b>HashimsGitHub</b></sub></a><br /><a href=\"#infra-HashimsGitHub\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nathaliabj\"><img src=\"https://avatars.githubusercontent.com/u/31137824?v=4?s=100\" width=\"100px;\" alt=\"Nathalia Buitrago Jurado\"/><br /><sub><b>Nathalia Buitrago Jurado</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=nathaliabj\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=nathaliabj\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Anathaliabj\" title=\"Bug reports\">üêõ</a> <a href=\"#design-nathaliabj\" title=\"Design\">üé®</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/norbag\"><img src=\"https://avatars.githubusercontent.com/u/1949405?v=4?s=100\" width=\"100px;\" alt=\"norbag\"/><br /><sub><b>norbag</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Anorbag\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Shrpp\"><img src=\"https://avatars.githubusercontent.com/u/97470912?v=4?s=100\" width=\"100px;\" alt=\"Shrpp\"/><br /><sub><b>Shrpp</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3AShrpp\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/elbination\"><img src=\"https://avatars.githubusercontent.com/u/24672834?v=4?s=100\" width=\"100px;\" alt=\"Cuong Vu\"/><br /><sub><b>Cuong Vu</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Aelbination\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://2rara.github.io\"><img src=\"https://avatars.githubusercontent.com/u/27809401?v=4?s=100\" width=\"100px;\" alt=\"Takaaki Yoshikawa\"/><br /><sub><b>Takaaki Yoshikawa</b></sub></a><br /><a href=\"#ideas-2rara\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nkotlyarov\"><img src=\"https://avatars.githubusercontent.com/u/5070583?v=4?s=100\" width=\"100px;\" alt=\"nkotlyarov\"/><br /><sub><b>nkotlyarov</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Ankotlyarov\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://kimmonzon.com\"><img src=\"https://avatars.githubusercontent.com/u/1046316?v=4?s=100\" width=\"100px;\" alt=\"kim monzon\"/><br /><sub><b>kim monzon</b></sub></a><br /><a href=\"#ideas-generalistcodes\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rverheijen\"><img src=\"https://avatars.githubusercontent.com/u/68638877?v=4?s=100\" width=\"100px;\" alt=\"rverheijen\"/><br /><sub><b>rverheijen</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=rverheijen\" title=\"Tests\">‚ö†Ô∏è</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Arverheijen\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/scarrucciu\"><img src=\"https://avatars.githubusercontent.com/u/8050761?v=4?s=100\" width=\"100px;\" alt=\"Spencer Carrucciu\"/><br /><sub><b>Spencer Carrucciu</b></sub></a><br /><a href=\"#ideas-scarrucciu\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pixie79\"><img src=\"https://avatars.githubusercontent.com/u/534416?v=4?s=100\" width=\"100px;\" alt=\"Mark Olliver\"/><br /><sub><b>Mark Olliver</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Apixie79\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gary-beautypie\"><img src=\"https://avatars.githubusercontent.com/u/71257526?v=4?s=100\" width=\"100px;\" alt=\"gary-beautypie\"/><br /><sub><b>gary-beautypie</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Agary-beautypie\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://blog.d2x.com.br\"><img src=\"https://avatars.githubusercontent.com/u/10980654?v=4?s=100\" width=\"100px;\" alt=\"Andr√© Claudino\"/><br /><sub><b>Andr√© Claudino</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=andreclaudino\" title=\"Code\">üíª</a> <a href=\"#infra-andreclaudino\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jim80net\"><img src=\"https://avatars.githubusercontent.com/u/176915?v=4?s=100\" width=\"100px;\" alt=\"Jim Park\"/><br /><sub><b>Jim Park</b></sub></a><br /><a href=\"#infra-jim80net\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gc-p\"><img src=\"https://avatars.githubusercontent.com/u/75038807?v=4?s=100\" width=\"100px;\" alt=\"gc-p\"/><br /><sub><b>gc-p</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Agc-p\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mlazowik\"><img src=\"https://avatars.githubusercontent.com/u/1978721?v=4?s=100\" width=\"100px;\" alt=\"Micha≈Ç ≈Åazowik\"/><br /><sub><b>Micha≈Ç ≈Åazowik</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=mlazowik\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/CCDoubleU\"><img src=\"https://avatars.githubusercontent.com/u/33049059?v=4?s=100\" width=\"100px;\" alt=\"Chun Wei\"/><br /><sub><b>Chun Wei</b></sub></a><br /><a href=\"#ideas-CCDoubleU\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/snyh-paulhenderson\"><img src=\"https://avatars.githubusercontent.com/u/91830919?v=4?s=100\" width=\"100px;\" alt=\"snyh-paulhenderson\"/><br /><sub><b>snyh-paulhenderson</b></sub></a><br /><a href=\"#ideas-snyh-paulhenderson\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/captnswing\"><img src=\"https://avatars.githubusercontent.com/u/325377?v=4?s=100\" width=\"100px;\" alt=\"Frank Hoffs√ºmmer\"/><br /><sub><b>Frank Hoffs√ºmmer</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Acaptnswing\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/smoens\"><img src=\"https://avatars.githubusercontent.com/u/1371244?v=4?s=100\" width=\"100px;\" alt=\"Sarah Moens\"/><br /><sub><b>Sarah Moens</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=smoens\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Sync271\"><img src=\"https://avatars.githubusercontent.com/u/67158080?v=4?s=100\" width=\"100px;\" alt=\"Abhishek K M\"/><br /><sub><b>Abhishek K M</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=Sync271\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://coconauts.net/\"><img src=\"https://avatars.githubusercontent.com/u/1983672?v=4?s=100\" width=\"100px;\" alt=\"Javier Rengel Jim√©nez\"/><br /><sub><b>Javier Rengel Jim√©nez</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=rephus\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Arephus\" title=\"Bug reports\">üêõ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=rephus\" title=\"Tests\">‚ö†Ô∏è</a> <a href=\"#infra-rephus\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=rephus\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://@VFisa\"><img src=\"https://avatars.githubusercontent.com/u/2714554?v=4?s=100\" width=\"100px;\" alt=\"Fisa\"/><br /><sub><b>Fisa</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3AVfisa\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/JoelAlander\"><img src=\"https://avatars.githubusercontent.com/u/33990367?v=4?s=100\" width=\"100px;\" alt=\"JoelAlander\"/><br /><sub><b>JoelAlander</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3AJoelAlander\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chadfl\"><img src=\"https://avatars.githubusercontent.com/u/44757973?v=4?s=100\" width=\"100px;\" alt=\"Chad Floyd\"/><br /><sub><b>Chad Floyd</b></sub></a><br /><a href=\"#ideas-chadfl\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/claudino-kognita\"><img src=\"https://avatars.githubusercontent.com/u/102805681?v=4?s=100\" width=\"100px;\" alt=\"Andr√© Claudino\"/><br /><sub><b>Andr√© Claudino</b></sub></a><br /><a href=\"#ideas-claudino-kognita\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/ianahuja/\"><img src=\"https://avatars.githubusercontent.com/u/9979944?v=4?s=100\" width=\"100px;\" alt=\"12ian34\"/><br /><sub><b>12ian34</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=12ian34\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3A12ian34\" title=\"Bug reports\">üêõ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=12ian34\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/raphaelauv\"><img src=\"https://avatars.githubusercontent.com/u/10202690?v=4?s=100\" width=\"100px;\" alt=\"raphaelauv\"/><br /><sub><b>raphaelauv</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Araphaelauv\" title=\"Bug reports\">üêõ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=raphaelauv\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/BA-CY\"><img src=\"https://avatars.githubusercontent.com/u/54427954?v=4?s=100\" width=\"100px;\" alt=\"BA-CY\"/><br /><sub><b>BA-CY</b></sub></a><br /><a href=\"#ideas-BA-CY\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/JohnRomanski\"><img src=\"https://avatars.githubusercontent.com/u/382382?v=4?s=100\" width=\"100px;\" alt=\"John Romanski\"/><br /><sub><b>John Romanski</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3AJohnRomanski\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jamiedavenport.dev\"><img src=\"https://avatars.githubusercontent.com/u/1329874?v=4?s=100\" width=\"100px;\" alt=\"Jamie Davenport\"/><br /><sub><b>Jamie Davenport</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Ajamiedavenport\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.windmark.se\"><img src=\"https://avatars.githubusercontent.com/u/3810163?v=4?s=100\" width=\"100px;\" alt=\"Marcus Windmark\"/><br /><sub><b>Marcus Windmark</b></sub></a><br /><a href=\"#ideas-windmark\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/restackio\"><img src=\"https://avatars.githubusercontent.com/u/27010949?v=4?s=100\" width=\"100px;\" alt=\"Shruti Kuber\"/><br /><sub><b>Shruti Kuber</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=kuberaspeaking\" title=\"Documentation\">üìñ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Fszta\"><img src=\"https://avatars.githubusercontent.com/u/36471574?v=4?s=100\" width=\"100px;\" alt=\"Fszta\"/><br /><sub><b>Fszta</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=Fszta\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://muhsin-kamil.web.app\"><img src=\"https://avatars.githubusercontent.com/u/62111075?v=4?s=100\" width=\"100px;\" alt=\"Mohamed Muhsin\"/><br /><sub><b>Mohamed Muhsin</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=muhsinkamil\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/magants\"><img src=\"https://avatars.githubusercontent.com/u/83379220?v=4?s=100\" width=\"100px;\" alt=\"magants\"/><br /><sub><b>magants</b></sub></a><br /><a href=\"#ideas-magants\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/mcarlsson/\"><img src=\"https://avatars.githubusercontent.com/u/7769335?v=4?s=100\" width=\"100px;\" alt=\"Martin Carlsson\"/><br /><sub><b>Martin Carlsson</b></sub></a><br /><a href=\"#ideas-Martin-Carlsson\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3AMartin-Carlsson\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/toinbis\"><img src=\"https://avatars.githubusercontent.com/u/68685?v=4?s=100\" width=\"100px;\" alt=\"Tomas ƒåerkasas\"/><br /><sub><b>Tomas ƒåerkasas</b></sub></a><br /><a href=\"#ideas-toinbis\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TiFaBl\"><img src=\"https://avatars.githubusercontent.com/u/1732972?v=4?s=100\" width=\"100px;\" alt=\"TiFaBl\"/><br /><sub><b>TiFaBl</b></sub></a><br /><a href=\"#ideas-TiFaBl\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ericcecchi.com\"><img src=\"https://avatars.githubusercontent.com/u/1455025?v=4?s=100\" width=\"100px;\" alt=\"Eric Cecchi\"/><br /><sub><b>Eric Cecchi</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=ericcecchi\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/KristyMayer\"><img src=\"https://avatars.githubusercontent.com/u/107724505?v=4?s=100\" width=\"100px;\" alt=\"KristyMayer\"/><br /><sub><b>KristyMayer</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3AKristyMayer\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rahulstomar08\"><img src=\"https://avatars.githubusercontent.com/u/110521220?v=4?s=100\" width=\"100px;\" alt=\"rahulstomar08\"/><br /><sub><b>rahulstomar08</b></sub></a><br /><a href=\"#ideas-rahulstomar08\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/charlespicowski\"><img src=\"https://avatars.githubusercontent.com/u/102390879?v=4?s=100\" width=\"100px;\" alt=\"Charles Picowski\"/><br /><sub><b>Charles Picowski</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Acharlespicowski\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ironchef\"><img src=\"https://avatars.githubusercontent.com/u/287705?v=4?s=100\" width=\"100px;\" alt=\"Matt Machczynski\"/><br /><sub><b>Matt Machczynski</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Aironchef\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://iraklijani.com/\"><img src=\"https://avatars.githubusercontent.com/u/962095?v=4?s=100\" width=\"100px;\" alt=\"Irakli Janiashvili\"/><br /><sub><b>Irakli Janiashvili</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=IrakliJani\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3AIrakliJani\" title=\"Bug reports\">üêõ</a> <a href=\"#design-IrakliJani\" title=\"Design\">üé®</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=IrakliJani\" title=\"Tests\">‚ö†Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gordonkjlee\"><img src=\"https://avatars.githubusercontent.com/u/7281432?v=4?s=100\" width=\"100px;\" alt=\"Gordon Lee\"/><br /><sub><b>Gordon Lee</b></sub></a><br /><a href=\"#ideas-gordonkjlee\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=gordonkjlee\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/olly-writes-code\"><img src=\"https://avatars.githubusercontent.com/u/7778402?v=4?s=100\" width=\"100px;\" alt=\"Olly\"/><br /><sub><b>Olly</b></sub></a><br /><a href=\"#ideas-olly-writes-code\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Aolly-writes-code\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gautamdoulani\"><img src=\"https://avatars.githubusercontent.com/u/3624491?v=4?s=100\" width=\"100px;\" alt=\"gautamdoulani\"/><br /><sub><b>gautamdoulani</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=gautamdoulani\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/davidpeitinho\"><img src=\"https://avatars.githubusercontent.com/u/116002164?v=4?s=100\" width=\"100px;\" alt=\"David Peitinho\"/><br /><sub><b>David Peitinho</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Adavidpeitinho\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.whispy.me\"><img src=\"https://avatars.githubusercontent.com/u/4189234?v=4?s=100\" width=\"100px;\" alt=\"Istvan Meszaros\"/><br /><sub><b>Istvan Meszaros</b></sub></a><br /><a href=\"#ideas-IstvanM\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://rifkiamil.medium.com/\"><img src=\"https://avatars.githubusercontent.com/u/1672403?v=4?s=100\" width=\"100px;\" alt=\"Rif\"/><br /><sub><b>Rif</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=rifkiamil\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/phillipwilhelm\"><img src=\"https://avatars.githubusercontent.com/u/5200312?v=4?s=100\" width=\"100px;\" alt=\"Phillip W.\"/><br /><sub><b>Phillip W.</b></sub></a><br /><a href=\"#ideas-phillipwilhelm\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/XiaozhouWang85\"><img src=\"https://avatars.githubusercontent.com/u/42941066?v=4?s=100\" width=\"100px;\" alt=\"XiaozhouWang85\"/><br /><sub><b>XiaozhouWang85</b></sub></a><br /><a href=\"#ideas-XiaozhouWang85\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://rebeccasanjabi.com\"><img src=\"https://avatars.githubusercontent.com/u/47192430?v=4?s=100\" width=\"100px;\" alt=\"Rebecca Sanjabi\"/><br /><sub><b>Rebecca Sanjabi</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Arsanjabi\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kailin-lu\"><img src=\"https://avatars.githubusercontent.com/u/31902827?v=4?s=100\" width=\"100px;\" alt=\"Kailin L\"/><br /><sub><b>Kailin L</b></sub></a><br /><a href=\"#ideas-kailin-lu\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/metin-karakus-b586b6132\"><img src=\"https://avatars.githubusercontent.com/u/61006227?v=4?s=100\" width=\"100px;\" alt=\"Metin Karakus\"/><br /><sub><b>Metin Karakus</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=m-karakus\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yasmin-e\"><img src=\"https://avatars.githubusercontent.com/u/67699259?v=4?s=100\" width=\"100px;\" alt=\"Yasmine\"/><br /><sub><b>Yasmine</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=yasmin-e\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Ayasmin-e\" title=\"Bug reports\">üêõ</a> <a href=\"#ideas-yasmin-e\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"#design-yasmin-e\" title=\"Design\">üé®</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://piotr.pilis.pl/\"><img src=\"https://avatars.githubusercontent.com/u/29205792?v=4?s=100\" width=\"100px;\" alt=\"Piotr Pilis\"/><br /><sub><b>Piotr Pilis</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=pilis\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/judahrand\"><img src=\"https://avatars.githubusercontent.com/u/17158624?v=4?s=100\" width=\"100px;\" alt=\"Judah Rand\"/><br /><sub><b>Judah Rand</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Ajudahrand\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://annebelleo.github.io\"><img src=\"https://avatars.githubusercontent.com/u/20630578?v=4?s=100\" width=\"100px;\" alt=\"Annebelle Olminkhof\"/><br /><sub><b>Annebelle Olminkhof</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=annebelleo\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://apolonio.dev\"><img src=\"https://avatars.githubusercontent.com/u/11734877?v=4?s=100\" width=\"100px;\" alt=\"Victor Apolonio\"/><br /><sub><b>Victor Apolonio</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=vapolonio\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://rodolfo42.com\"><img src=\"https://avatars.githubusercontent.com/u/1674699?v=4?s=100\" width=\"100px;\" alt=\"Rodolfo Ferreira\"/><br /><sub><b>Rodolfo Ferreira</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=rodolfo42\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.patrickbrusven.com/\"><img src=\"https://avatars.githubusercontent.com/u/84103244?v=4?s=100\" width=\"100px;\" alt=\"Patrick Brusven\"/><br /><sub><b>Patrick Brusven</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=patrickbrusven\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/thomaspurchas\"><img src=\"https://avatars.githubusercontent.com/u/782311?v=4?s=100\" width=\"100px;\" alt=\"Thomas Purchas\"/><br /><sub><b>Thomas Purchas</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=thomaspurchas\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Athomaspurchas\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.dradrian.com\"><img src=\"https://avatars.githubusercontent.com/u/7521223?v=4?s=100\" width=\"100px;\" alt=\"Adrian Letchford\"/><br /><sub><b>Adrian Letchford</b></sub></a><br /><a href=\"#ideas-robolyst\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ifunanyacollins\"><img src=\"https://avatars.githubusercontent.com/u/31220512?v=4?s=100\" width=\"100px;\" alt=\"Collins\"/><br /><sub><b>Collins</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=Ifunanyacollins\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pvanderlinden\"><img src=\"https://avatars.githubusercontent.com/u/391586?v=4?s=100\" width=\"100px;\" alt=\"Paul van der Linden\"/><br /><sub><b>Paul van der Linden</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Apvanderlinden\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://chrischuck.com\"><img src=\"https://avatars.githubusercontent.com/u/13311268?v=4?s=100\" width=\"100px;\" alt=\"Chris\"/><br /><sub><b>Chris</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=Chrischuck\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://mikethoun.com\"><img src=\"https://avatars.githubusercontent.com/u/8367471?v=4?s=100\" width=\"100px;\" alt=\"Mike Thoun\"/><br /><sub><b>Mike Thoun</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=mikethoun\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://leonkozlowski.com\"><img src=\"https://avatars.githubusercontent.com/u/24438337?v=4?s=100\" width=\"100px;\" alt=\"Leon Kozlowski\"/><br /><sub><b>Leon Kozlowski</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=leonkozlowski\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nathancoleman\"><img src=\"https://avatars.githubusercontent.com/u/3476400?v=4?s=100\" width=\"100px;\" alt=\"Nathan Coleman\"/><br /><sub><b>Nathan Coleman</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=nathancoleman\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jnfrati.tk\"><img src=\"https://avatars.githubusercontent.com/u/23369263?v=4?s=100\" width=\"100px;\" alt=\"Nicolas Frati\"/><br /><sub><b>Nicolas Frati</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=jnfrati\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/fredmny\"><img src=\"https://avatars.githubusercontent.com/u/27257093?v=4?s=100\" width=\"100px;\" alt=\"Fred\"/><br /><sub><b>Fred</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=fredmny\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gictor\"><img src=\"https://avatars.githubusercontent.com/u/2518420?v=4?s=100\" width=\"100px;\" alt=\"Victor Lindell\"/><br /><sub><b>Victor Lindell</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=gictor\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/stellar-ahmed\"><img src=\"https://avatars.githubusercontent.com/u/125902091?v=4?s=100\" width=\"100px;\" alt=\"stellar-ahmed\"/><br /><sub><b>stellar-ahmed</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Astellar-ahmed\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/coopkw\"><img src=\"https://avatars.githubusercontent.com/u/82987430?v=4?s=100\" width=\"100px;\" alt=\"Cooper Williams\"/><br /><sub><b>Cooper Williams</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=coopkw\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lokeswaran-aj\"><img src=\"https://avatars.githubusercontent.com/u/74011196?v=4?s=100\" width=\"100px;\" alt=\"Lokeswaran Aruljothi\"/><br /><sub><b>Lokeswaran Aruljothi</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=lokeswaran-aj\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/joaoviana\"><img src=\"https://avatars.githubusercontent.com/u/7611706?v=4?s=100\" width=\"100px;\" alt=\"Jo√£o Viana\"/><br /><sub><b>Jo√£o Viana</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=joaoviana\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=joaoviana\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Ajoaoviana\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/muhammadjufry\"><img src=\"https://avatars.githubusercontent.com/u/97773130?v=4?s=100\" width=\"100px;\" alt=\"Muhammad Jufry\"/><br /><sub><b>Muhammad Jufry</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Amuhammadjufry\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/patrikbraborec\"><img src=\"https://avatars.githubusercontent.com/u/18550315?v=4?s=100\" width=\"100px;\" alt=\"Patrik Braborec\"/><br /><sub><b>Patrik Braborec</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=patrikbraborec\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Apatrikbraborec\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rawkode\"><img src=\"https://avatars.githubusercontent.com/u/145816?v=4?s=100\" width=\"100px;\" alt=\"David Flanagan\"/><br /><sub><b>David Flanagan</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=rawkode\" title=\"Code\">üíª</a> <a href=\"#infra-rawkode\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">üöá</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://pullstack.ninja/\"><img src=\"https://avatars.githubusercontent.com/u/22260031?v=4?s=100\" width=\"100px;\" alt=\"Moulik Aggarwal\"/><br /><sub><b>Moulik Aggarwal</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=aggmoulik\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/CVamsi27\"><img src=\"https://avatars.githubusercontent.com/u/55316723?v=4?s=100\" width=\"100px;\" alt=\"Chandaluri Vamsi Krishna\"/><br /><sub><b>Chandaluri Vamsi Krishna</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=CVamsi27\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/elton-okawa\"><img src=\"https://avatars.githubusercontent.com/u/24387035?v=4?s=100\" width=\"100px;\" alt=\"Elton Okawa\"/><br /><sub><b>Elton Okawa</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=elton-okawa\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jayanand05\"><img src=\"https://avatars.githubusercontent.com/u/113882904?v=4?s=100\" width=\"100px;\" alt=\"JAY ANAND\"/><br /><sub><b>JAY ANAND</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=jayanand05\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/yuishikawa0301/\"><img src=\"https://avatars.githubusercontent.com/u/1523515?v=4?s=100\" width=\"100px;\" alt=\"Yu Ishikawa\"/><br /><sub><b>Yu Ishikawa</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=yu-iskw\" title=\"Code\">üíª</a> <a href=\"#ideas-yu-iskw\" title=\"Ideas, Planning, & Feedback\">ü§î</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/magnew\"><img src=\"https://avatars.githubusercontent.com/u/1864179?v=4?s=100\" width=\"100px;\" alt=\"magnew\"/><br /><sub><b>magnew</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=magnew\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Amagnew\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://advith.me\"><img src=\"https://avatars.githubusercontent.com/u/4915950?v=4?s=100\" width=\"100px;\" alt=\"Advith Chelikani\"/><br /><sub><b>Advith Chelikani</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3AAChelikani\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://pranavdhar.netlify.com\"><img src=\"https://avatars.githubusercontent.com/u/73348574?v=4?s=100\" width=\"100px;\" alt=\"Sai Pranavdhar Reddy N\"/><br /><sub><b>Sai Pranavdhar Reddy N</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=iampranavdhar\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ujwalkumar1995\"><img src=\"https://avatars.githubusercontent.com/u/20976813?v=4?s=100\" width=\"100px;\" alt=\"Ujwal Kumar\"/><br /><sub><b>Ujwal Kumar</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=ujwalkumar1995\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nimit9\"><img src=\"https://avatars.githubusercontent.com/u/37402791?v=4?s=100\" width=\"100px;\" alt=\"Nimit Haria\"/><br /><sub><b>Nimit Haria</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=nimit9\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tnightengale\"><img src=\"https://avatars.githubusercontent.com/u/17347282?v=4?s=100\" width=\"100px;\" alt=\"Teghan Nightengale\"/><br /><sub><b>Teghan Nightengale</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=tnightengale\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dmattia\"><img src=\"https://avatars.githubusercontent.com/u/8922077?v=4?s=100\" width=\"100px;\" alt=\"David Mattia\"/><br /><sub><b>David Mattia</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=dmattia\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ayush117\"><img src=\"https://avatars.githubusercontent.com/u/25580209?v=4?s=100\" width=\"100px;\" alt=\"Ayush Trivedi\"/><br /><sub><b>Ayush Trivedi</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=ayush117\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zoltan-kski\"><img src=\"https://avatars.githubusercontent.com/u/2300833?v=4?s=100\" width=\"100px;\" alt=\"Zoltan K.\"/><br /><sub><b>Zoltan K.</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=zoltan-kski\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://my-portfolio-ankush263.vercel.app/\"><img src=\"https://avatars.githubusercontent.com/u/86042508?v=4?s=100\" width=\"100px;\" alt=\"Ankush Banik\"/><br /><sub><b>Ankush Banik</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=Ankush263\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/karan0handa\"><img src=\"https://avatars.githubusercontent.com/u/79533543?v=4?s=100\" width=\"100px;\" alt=\"Karan Handa\"/><br /><sub><b>Karan Handa</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=karan0handa\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rohitverma007\"><img src=\"https://avatars.githubusercontent.com/u/3745109?v=4?s=100\" width=\"100px;\" alt=\"Rohit Verma\"/><br /><sub><b>Rohit Verma</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=rohitverma007\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dwitkowski.eu\"><img src=\"https://avatars.githubusercontent.com/u/43667775?v=4?s=100\" width=\"100px;\" alt=\"David Witkowski\"/><br /><sub><b>David Witkowski</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=chodera\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/iMac7\"><img src=\"https://avatars.githubusercontent.com/u/76876702?v=4?s=100\" width=\"100px;\" alt=\"iMac\"/><br /><sub><b>iMac</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=iMac7\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Kobold\"><img src=\"https://avatars.githubusercontent.com/u/36694?v=4?s=100\" width=\"100px;\" alt=\"Andy Kish\"/><br /><sub><b>Andy Kish</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=Kobold\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://bilal.cc\"><img src=\"https://avatars.githubusercontent.com/u/55330484?v=4?s=100\" width=\"100px;\" alt=\"Bilal Ahmad Bhat\"/><br /><sub><b>Bilal Ahmad Bhat</b></sub></a><br /><a href=\"#ideas-crediblebilal\" title=\"Ideas, Planning, & Feedback\">ü§î</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=crediblebilal\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Shifan-Gu\"><img src=\"https://avatars.githubusercontent.com/u/101873365?v=4?s=100\" width=\"100px;\" alt=\"Shifan Gu\"/><br /><sub><b>Shifan Gu</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3AShifan-Gu\" title=\"Bug reports\">üêõ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=Shifan-Gu\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dansreis\"><img src=\"https://avatars.githubusercontent.com/u/9052608?v=4?s=100\" width=\"100px;\" alt=\"Daniel Reis\"/><br /><sub><b>Daniel Reis</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=dansreis\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Adansreis\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jogeshwar01\"><img src=\"https://avatars.githubusercontent.com/u/85165953?v=4?s=100\" width=\"100px;\" alt=\"Jogeshwar Singh\"/><br /><sub><b>Jogeshwar Singh</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=jogeshwar01\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lancerael\"><img src=\"https://avatars.githubusercontent.com/u/11949472?v=4?s=100\" width=\"100px;\" alt=\"lancerael\"/><br /><sub><b>lancerael</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=lancerael\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Alancerael\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://ulisesgascon.com/\"><img src=\"https://avatars.githubusercontent.com/u/5110813?v=4?s=100\" width=\"100px;\" alt=\"Ulises Gasc√≥n\"/><br /><sub><b>Ulises Gasc√≥n</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=UlisesGascon\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/GtheSheep\"><img src=\"https://avatars.githubusercontent.com/u/13685708?v=4?s=100\" width=\"100px;\" alt=\"Gary James\"/><br /><sub><b>Gary James</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=GtheSheep\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/almeidabbm\"><img src=\"https://avatars.githubusercontent.com/u/22939015?v=4?s=100\" width=\"100px;\" alt=\"Bruno Almeida\"/><br /><sub><b>Bruno Almeida</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=almeidabbm\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/filp\"><img src=\"https://avatars.githubusercontent.com/u/382538?v=4?s=100\" width=\"100px;\" alt=\"Filipe Dobreira\"/><br /><sub><b>Filipe Dobreira</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=filp\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=filp\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/joemiltonm\"><img src=\"https://avatars.githubusercontent.com/u/64725924?v=4?s=100\" width=\"100px;\" alt=\"Joe Milton\"/><br /><sub><b>Joe Milton</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=joemiltonm\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://lassu.dev\"><img src=\"https://avatars.githubusercontent.com/u/30611343?v=4?s=100\" width=\"100px;\" alt=\"Andras Lassu\"/><br /><sub><b>Andras Lassu</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=la55u\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chasewoo\"><img src=\"https://avatars.githubusercontent.com/u/1282787?v=4?s=100\" width=\"100px;\" alt=\"Chase Wu\"/><br /><sub><b>Chase Wu</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=chasewoo\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/agha4to\"><img src=\"https://avatars.githubusercontent.com/u/138995798?v=4?s=100\" width=\"100px;\" alt=\"agha4to\"/><br /><sub><b>agha4to</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=agha4to\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sakce\"><img src=\"https://avatars.githubusercontent.com/u/49978945?v=4?s=100\" width=\"100px;\" alt=\"Jovan Sakovic\"/><br /><sub><b>Jovan Sakovic</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=sakce\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Inder782\"><img src=\"https://avatars.githubusercontent.com/u/124162738?v=4?s=100\" width=\"100px;\" alt=\"Inder Singh Chandel\"/><br /><sub><b>Inder Singh Chandel</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=Inder782\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anshul45\"><img src=\"https://avatars.githubusercontent.com/u/80778090?v=4?s=100\" width=\"100px;\" alt=\"Anshul Garwal\"/><br /><sub><b>Anshul Garwal</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=anshul45\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jpetey75\"><img src=\"https://avatars.githubusercontent.com/u/5532776?v=4?s=100\" width=\"100px;\" alt=\"Jake Peterson\"/><br /><sub><b>Jake Peterson</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=jpetey75\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/cooldude6000\"><img src=\"https://avatars.githubusercontent.com/u/143312648?v=4?s=100\" width=\"100px;\" alt=\"cooldude6000\"/><br /><sub><b>cooldude6000</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=cooldude6000\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=cooldude6000\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/calculuslmvt\"><img src=\"https://avatars.githubusercontent.com/u/55044051?v=4?s=100\" width=\"100px;\" alt=\"AYUSH SINGH\"/><br /><sub><b>AYUSH SINGH</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=calculuslmvt\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/xinlingqudongX\"><img src=\"https://avatars.githubusercontent.com/u/26372348?v=4?s=100\" width=\"100px;\" alt=\"xinlingqudongX\"/><br /><sub><b>xinlingqudongX</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3AxinlingqudongX\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aayushi1995\"><img src=\"https://avatars.githubusercontent.com/u/25344927?v=4?s=100\" width=\"100px;\" alt=\"Aayushi Kambariya\"/><br /><sub><b>Aayushi Kambariya</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=aayushi1995\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/maxdiplogit\"><img src=\"https://avatars.githubusercontent.com/u/111004544?v=4?s=100\" width=\"100px;\" alt=\"Harshmeet Singh\"/><br /><sub><b>Harshmeet Singh</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=maxdiplogit\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/andrewdw\"><img src=\"https://avatars.githubusercontent.com/u/4855214?v=4?s=100\" width=\"100px;\" alt=\"Andrew Dillion-Walshe\"/><br /><sub><b>Andrew Dillion-Walshe</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=andrewdw\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=andrewdw\" title=\"Documentation\">üìñ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dub.sh/MUN9v4r\"><img src=\"https://avatars.githubusercontent.com/u/89914602?v=4?s=100\" width=\"100px;\" alt=\"Ayush Sharma\"/><br /><sub><b>Ayush Sharma</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=ayush3160\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sanjay-sol\"><img src=\"https://avatars.githubusercontent.com/u/114111046?v=4?s=100\" width=\"100px;\" alt=\"sanjay sirangi\"/><br /><sub><b>sanjay sirangi</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=sanjay-sol\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/varunguleriaCodes\"><img src=\"https://avatars.githubusercontent.com/u/152203177?v=4?s=100\" width=\"100px;\" alt=\"Varun Guleria\"/><br /><sub><b>Varun Guleria</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=varunguleriaCodes\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Guru6163\"><img src=\"https://avatars.githubusercontent.com/u/42559222?v=4?s=100\" width=\"100px;\" alt=\"Guruprasath Sankaran\"/><br /><sub><b>Guruprasath Sankaran</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=Guru6163\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/VenkataRohan\"><img src=\"https://avatars.githubusercontent.com/u/83659881?v=4?s=100\" width=\"100px;\" alt=\"VenkataRohan\"/><br /><sub><b>VenkataRohan</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=VenkataRohan\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/inverts\"><img src=\"https://avatars.githubusercontent.com/u/4111862?v=4?s=100\" width=\"100px;\" alt=\"Dave\"/><br /><sub><b>Dave</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=inverts\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/BhuvaneshPatil\"><img src=\"https://avatars.githubusercontent.com/u/27822551?v=4?s=100\" width=\"100px;\" alt=\"Bhuvanesh\"/><br /><sub><b>Bhuvanesh</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=BhuvaneshPatil\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://parthiblol.netlify.app\"><img src=\"https://avatars.githubusercontent.com/u/94271200?v=4?s=100\" width=\"100px;\" alt=\"Parthib Datta\"/><br /><sub><b>Parthib Datta</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=ptdatta\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://zhyd1997.eth.limo\"><img src=\"https://avatars.githubusercontent.com/u/31362988?v=4?s=100\" width=\"100px;\" alt=\"Yadong Zhang\"/><br /><sub><b>Yadong Zhang</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=zhyd1997\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://yshplsngh.in\"><img src=\"https://avatars.githubusercontent.com/u/134866490?v=4?s=100\" width=\"100px;\" alt=\"Yashpal\"/><br /><sub><b>Yashpal</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=yshplsngh\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/stajics\"><img src=\"https://avatars.githubusercontent.com/u/17711182?v=4?s=100\" width=\"100px;\" alt=\"Srdjan Stajic\"/><br /><sub><b>Srdjan Stajic</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=stajics\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/RANJITHp07\"><img src=\"https://avatars.githubusercontent.com/u/107017062?v=4?s=100\" width=\"100px;\" alt=\"Ranjth P\"/><br /><sub><b>Ranjth P</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=RANJITHp07\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://basitbalogun.vercel.app/\"><img src=\"https://avatars.githubusercontent.com/u/68718781?v=4?s=100\" width=\"100px;\" alt=\"Basit Balogun\"/><br /><sub><b>Basit Balogun</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=Basit-Balogun10\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=Basit-Balogun10\" title=\"Tests\">‚ö†Ô∏è</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/notgiorgi\"><img src=\"https://avatars.githubusercontent.com/u/12987425?v=4?s=100\" width=\"100px;\" alt=\"Giorgi Bagdavadze\"/><br /><sub><b>Giorgi Bagdavadze</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=notgiorgi\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anoopw3bdev\"><img src=\"https://avatars.githubusercontent.com/u/44577841?v=4?s=100\" width=\"100px;\" alt=\"Anoop P\"/><br /><sub><b>Anoop P</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=anoopw3bdev\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dub.sh/snxvqzq\"><img src=\"https://avatars.githubusercontent.com/u/76897266?v=4?s=100\" width=\"100px;\" alt=\"Ali Amer\"/><br /><sub><b>Ali Amer</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=aliamerj\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/virendrapatil24\"><img src=\"https://avatars.githubusercontent.com/u/70162563?v=4?s=100\" width=\"100px;\" alt=\"Virendra Patil\"/><br /><sub><b>Virendra Patil</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=virendrapatil24\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://janstepanovsky.cz\"><img src=\"https://avatars.githubusercontent.com/u/854103?v=4?s=100\" width=\"100px;\" alt=\"Honza Stepanovsky\"/><br /><sub><b>Honza Stepanovsky</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=hhhonzik\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://pimmey.com\"><img src=\"https://avatars.githubusercontent.com/u/5588929?v=4?s=100\" width=\"100px;\" alt=\"Yegor Borisenco\"/><br /><sub><b>Yegor Borisenco</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=pimmey\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Apimmey\" title=\"Bug reports\">üêõ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lakshz\"><img src=\"https://avatars.githubusercontent.com/u/81241551?v=4?s=100\" width=\"100px;\" alt=\"Lakshya Satpal\"/><br /><sub><b>Lakshya Satpal</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=lakshz\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://tatiana.inama.dev\"><img src=\"https://avatars.githubusercontent.com/u/8246284?v=4?s=100\" width=\"100px;\" alt=\"Tatiana Inama\"/><br /><sub><b>Tatiana Inama</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=tatianainama\" title=\"Code\">üíª</a> <a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Atatianainama\" title=\"Bug reports\">üêõ</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Divyansh200102\"><img src=\"https://avatars.githubusercontent.com/u/146909065?v=4?s=100\" width=\"100px;\" alt=\"Divyansh200102\"/><br /><sub><b>Divyansh200102</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=Divyansh200102\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/manhnguyen1998\"><img src=\"https://avatars.githubusercontent.com/u/37845948?v=4?s=100\" width=\"100px;\" alt=\"„Ç∞„Ç®„É≥„Éª„Éí„É•„Éº„Éª„Éû„Ç§„É≥\"/><br /><sub><b>„Ç∞„Ç®„É≥„Éª„Éí„É•„Éº„Éª„Éû„Ç§„É≥</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=manhnguyen1998\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/raghvendra-singh-rathore-b47a3a161/\"><img src=\"https://avatars.githubusercontent.com/u/35917821?v=4?s=100\" width=\"100px;\" alt=\"raghvendra\"/><br /><sub><b>raghvendra</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/issues?q=author%3Afork-boy\" title=\"Bug reports\">üêõ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=fork-boy\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shanzeim\"><img src=\"https://avatars.githubusercontent.com/u/211318613?v=4?s=100\" width=\"100px;\" alt=\"shanzeim\"/><br /><sub><b>shanzeim</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=shanzeim\" title=\"Documentation\">üìñ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jesshitchcock\"><img src=\"https://avatars.githubusercontent.com/u/13378707?v=4?s=100\" width=\"100px;\" alt=\"Jess Hitchcock\"/><br /><sub><b>Jess Hitchcock</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=jesshitchcock\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/albert-franzi\"><img src=\"https://avatars.githubusercontent.com/u/3647015?v=4?s=100\" width=\"100px;\" alt=\"AFranzi\"/><br /><sub><b>AFranzi</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=afranzi\" title=\"Code\">üíª</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ongdisheng\"><img src=\"https://avatars.githubusercontent.com/u/63136897?v=4?s=100\" width=\"100px;\" alt=\"ongdisheng\"/><br /><sub><b>ongdisheng</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=ongdisheng\" title=\"Code\">üíª</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://spiss.dev\"><img src=\"https://avatars.githubusercontent.com/u/35728419?v=4?s=100\" width=\"100px;\" alt=\"Lukas Spiss\"/><br /><sub><b>Lukas Spiss</b></sub></a><br /><a href=\"https://github.com/lightdash/lightdash/commits?author=Spissable\" title=\"Documentation\">üìñ</a> <a href=\"https://github.com/lightdash/lightdash/commits?author=Spissable\" title=\"Code\">üíª</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification.\nContributions of any kind welcome!\n",
      "stars_today": 7
    },
    {
      "id": 510342492,
      "name": "client",
      "full_name": "Droid-ify/client",
      "description": "Clutterfree F-Droid client",
      "html_url": "https://github.com/Droid-ify/client",
      "stars": 6183,
      "forks": 157,
      "language": "Kotlin",
      "topics": [
        "android",
        "android-application",
        "fdroid",
        "kotlin",
        "kotlin-android",
        "kotlin-flow"
      ],
      "created_at": "2022-07-04T12:03:15Z",
      "updated_at": "2026-01-16T23:43:57Z",
      "pushed_at": "2026-01-15T23:01:53Z",
      "open_issues": 249,
      "owner": {
        "login": "Droid-ify",
        "avatar_url": "https://avatars.githubusercontent.com/u/123971387?v=4"
      },
      "readme": "<div align=\"center\">\n\n<img width=\"\" src=\"metadata/en-US/images/featureGraphic.png\" alt=\"Droid-ify\" align=\"center\">\n\n> **Clutterfree F-Droid client**\n\n[![GitHub stars](https://img.shields.io/github/stars/Iamlooker/Droid-ify?color=%2359a14f&style=for-the-badge)](https://github.com/Iamlooker/Droid-ify/stargazers)\n[![GitHub downloads](https://img.shields.io/github/downloads/Iamlooker/Droid-ify/total.svg?color=%236f9645&style=for-the-badge)](https://github.com/Iamlooker/Droid-ify/releases/)\n[![GitHub latest release](https://img.shields.io/github/v/release/Iamlooker/Droid-ify?display_name=tag&color=%23d97706&style=for-the-badge)](https://github.com/Iamlooker/Droid-ify/releases/latest)\n[![F-Droid latest release](https://img.shields.io/f-droid/v/com.looker.droidify?color=%23ea9010&style=for-the-badge)](https://f-droid.org/packages/com.looker.droidify)\n</div>\n<div align=\"left\">\n\n<img src=\"metadata/en-US/images/phoneScreenshots/1.png\" width=\"25%\" /><img src=\"metadata/en-US/images/phoneScreenshots/2.png\" width=\"25%\" /><img src=\"metadata/en-US/images/phoneScreenshots/3.png\" width=\"25%\" /><img src=\"metadata/en-US/images/phoneScreenshots/4.png\" width=\"25%\" />\n\n* Browse and install apps from F-Droid repositories\n* Automatic app updates in the background\n* Multiple installation methods (Session, Root, Shizuku)\n* Add custom repositories with one tap\n* Works completely offline after initial sync\n\n### Get Started\n\n**Download**: [GitHub Releases](https://github.com/Iamlooker/Droid-ify/releases/latest) ‚Ä¢ [F-Droid](https://f-droid.org/packages/com.looker.droidify)\n\n**Signature:**\n```\nED:88:59:C5:5A:F3:11:16:26:58:B9:4A:F9:82:B9:F0:91:DC:D2:76:28:D4:DE:34:86:D1:21:7E:BF:3C:99:35\n```\n\n> [!IMPORTANT]\n> Signature for older versions on F-Droid might be different\n\n**Build**: See [Building Guide](docs/building.md) for development setup\n\n### Contributing\n\n**Want to help?** Check out our [Contributing Guide](CONTRIBUTING.md)\n\n### Translations\n\n[![Translation status](https://hosted.weblate.org/widgets/droidify/-/horizontal-auto.svg)](https://hosted.weblate.org/engage/droidify/?utm_source=widget)\n\n### License\n\n```\nDroid-ify\n\nCopyright (C) 2025 LooKeR\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n```\n\n</div>\n",
      "stars_today": 7
    },
    {
      "id": 7691631,
      "name": "moby",
      "full_name": "moby/moby",
      "description": "The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems",
      "html_url": "https://github.com/moby/moby",
      "stars": 71368,
      "forks": 18882,
      "language": "Go",
      "topics": [
        "containers",
        "docker",
        "go",
        "golang"
      ],
      "created_at": "2013-01-18T18:10:57Z",
      "updated_at": "2026-01-16T18:51:38Z",
      "pushed_at": "2026-01-16T17:16:01Z",
      "open_issues": 3777,
      "owner": {
        "login": "moby",
        "avatar_url": "https://avatars.githubusercontent.com/u/27259197?v=4"
      },
      "readme": "The Moby Project\n================\n\n[![PkgGoDev](https://pkg.go.dev/badge/github.com/moby/moby/v2)](https://pkg.go.dev/github.com/moby/moby/v2)\n![GitHub License](https://img.shields.io/github/license/moby/moby)\n[![Go Report Card](https://goreportcard.com/badge/github.com/moby/moby/v2)](https://goreportcard.com/report/github.com/moby/moby/v2)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/moby/moby/badge)](https://scorecard.dev/viewer/?uri=github.com/moby/moby)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10989/badge)](https://www.bestpractices.dev/projects/10989)\n\n\n![Moby Project logo](docs/static_files/moby-project-logo.png \"The Moby Project\")\n\nMoby is an open-source project created by Docker to enable and accelerate software containerization.\n\nIt provides a \"Lego set\" of toolkit components, the framework for assembling them into custom container-based systems, and a place for all container enthusiasts and professionals to experiment and exchange ideas.\nComponents include container build tools, a container registry, orchestration tools, a runtime and more, and these can be used as building blocks in conjunction with other tools and projects.\n\n## Principles\n\nMoby is an open project guided by strong principles, aiming to be modular, flexible and without too strong an opinion on user experience.\nIt is open to the community to help set its direction.\n\n- Modular: the project includes lots of components that have well-defined functions and APIs that work together.\n- Batteries included but swappable: Moby includes enough components to build fully featured container systems, but its modular architecture ensures that most of the components can be swapped by different implementations.\n- Usable security: Moby provides secure defaults without compromising usability.\n- Developer focused: The APIs are intended to be functional and useful to build powerful tools.\nThey are not necessarily intended as end user tools but as components aimed at developers.\nDocumentation and UX is aimed at developers not end users.\n\n## Audience\n\nThe Moby Project is intended for engineers, integrators and enthusiasts looking to modify, hack, fix, experiment, invent and build systems based on containers.\nIt is not for people looking for a commercially supported system, but for people who want to work and learn with open source code.\n\n## Relationship with Docker\n\nThe components and tools in the Moby Project are initially the open source components that Docker and the community have built for the Docker Project.\nNew projects can be added if they fit with the community goals. Docker is committed to using Moby as the upstream for the Docker Product.\nHowever, other projects are also encouraged to use Moby as an upstream, and to reuse the components in diverse ways, and all these uses will be treated in the same way. External maintainers and contributors are welcomed.\n\nThe Moby project is not intended as a location for support or feature requests for Docker products, but as a place for contributors to work on open source code, fix bugs, and make the code more useful.\nThe releases are supported by the maintainers, community and users, on a best efforts basis only. For customers who want enterprise or commercial support, [Docker Desktop](https://www.docker.com/products/docker-desktop/) and [Mirantis Container Runtime](https://www.mirantis.com/software/mirantis-container-runtime/) are the appropriate products for these use cases.\n\n-----\n\nLegal\n=====\n\n*Brought to you courtesy of our legal counsel. For more context,\nplease see the [NOTICE](https://github.com/moby/moby/blob/master/NOTICE) document in this repo.*\n\nUse and transfer of Moby may be subject to certain restrictions by the\nUnited States and other governments.\n\nIt is your responsibility to ensure that your use and/or transfer does not\nviolate applicable laws.\n\nFor more information, please see https://www.bis.doc.gov\n\nLicensing\n=========\nMoby is licensed under the Apache License, Version 2.0. See\n[LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full\nlicense text.\n",
      "stars_today": 6
    },
    {
      "id": 75104123,
      "name": "prettier",
      "full_name": "prettier/prettier",
      "description": "Prettier is an opinionated code formatter.",
      "html_url": "https://github.com/prettier/prettier",
      "stars": 51406,
      "forks": 4635,
      "language": "JavaScript",
      "topics": [
        "angular",
        "ast",
        "css",
        "flow",
        "formatter",
        "graphql",
        "html",
        "javascript",
        "json",
        "jsx",
        "less",
        "markdown",
        "prettier",
        "printer",
        "scss",
        "typescript",
        "vue",
        "yaml"
      ],
      "created_at": "2016-11-29T17:13:37Z",
      "updated_at": "2026-01-16T22:11:41Z",
      "pushed_at": "2026-01-16T20:46:43Z",
      "open_issues": 1449,
      "owner": {
        "login": "prettier",
        "avatar_url": "https://avatars.githubusercontent.com/u/25822731?v=4"
      },
      "readme": "[![Prettier Banner](https://unpkg.com/prettier-logo@1.0.3/images/prettier-banner-light.svg)](https://prettier.io)\n\n<h2 align=\"center\">Opinionated Code Formatter</h2>\n\n<p align=\"center\">\n  <em>\n    JavaScript\n    ¬∑ TypeScript\n    ¬∑ Flow\n    ¬∑ JSX\n    ¬∑ JSON\n  </em>\n  <br />\n  <em>\n    CSS\n    ¬∑ SCSS\n    ¬∑ Less\n  </em>\n  <br />\n  <em>\n    HTML\n    ¬∑ Vue\n    ¬∑ Angular\n  </em>\n  <br />\n  <em>\n    GraphQL\n    ¬∑ Markdown\n    ¬∑ YAML\n  </em>\n  <br />\n  <em>\n    <a href=\"https://prettier.io/docs/plugins\">\n      Your favorite language?\n    </a>\n  </em>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/prettier/prettier/actions?query=branch%3Amain\">\n    <img alt=\"CI Status\" src=\"https://img.shields.io/github/check-runs/prettier/prettier/main?style=flat-square&label=CI\"></a>\n  <a href=\"https://codecov.io/gh/prettier/prettier\">\n    <img alt=\"Coverage Status\" src=\"https://img.shields.io/codecov/c/github/prettier/prettier.svg?style=flat-square\"></a>\n  <a href=\"https://x.com/acdlite/status/974390255393505280\">\n    <img alt=\"Blazing Fast\" src=\"https://img.shields.io/badge/speed-blazing%20%F0%9F%94%A5-brightgreen.svg?style=flat-square\"></a>\n  <br/>\n  <a href=\"https://www.npmjs.com/package/prettier\">\n    <img alt=\"npm version\" src=\"https://img.shields.io/npm/v/prettier.svg?style=flat-square\"></a>\n  <a href=\"https://www.npmjs.com/package/prettier\">\n    <img alt=\"weekly downloads from npm\" src=\"https://img.shields.io/npm/dw/prettier.svg?style=flat-square\"></a>\n  <a href=\"https://github.com/prettier/prettier#badge\">\n    <img alt=\"code style: prettier\" src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\"></a>\n  <a href=\"https://x.com/intent/follow?screen_name=PrettierCode\">\n    <img alt=\"Follow Prettier on X\" src=\"https://img.shields.io/badge/%40PrettierCode-9f9f9f?style=flat-square&logo=x&labelColor=555\"></a>\n</p>\n\n## Intro\n\nPrettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary.\n\n### Input\n\n<!-- prettier-ignore -->\n```js\nfoo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne());\n```\n\n### Output\n\n```js\nfoo(\n  reallyLongArg(),\n  omgSoManyParameters(),\n  IShouldRefactorThis(),\n  isThereSeriouslyAnotherOne(),\n);\n```\n\nPrettier can be run [in your editor](https://prettier.io/docs/editors) on-save, in a [pre-commit hook](https://prettier.io/docs/precommit), or in [CI environments](https://prettier.io/docs/cli#list-different) to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again!\n\n---\n\n**[Documentation](https://prettier.io/docs/)**\n\n[Install](https://prettier.io/docs/install) ¬∑\n[Options](https://prettier.io/docs/options) ¬∑\n[CLI](https://prettier.io/docs/cli) ¬∑\n[API](https://prettier.io/docs/api)\n\n**[Playground](https://prettier.io/playground/)**\n\n---\n\n## Badge\n\nShow the world you're using _Prettier_ ‚Üí [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\n\n```md\n[![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\n```\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md).\n",
      "stars_today": 6
    },
    {
      "id": 26337322,
      "name": "rancher",
      "full_name": "rancher/rancher",
      "description": "Complete container management platform",
      "html_url": "https://github.com/rancher/rancher",
      "stars": 25250,
      "forks": 3149,
      "language": "Go",
      "topics": [
        "cattle",
        "containers",
        "docker",
        "kubernetes",
        "orchestration",
        "rancher"
      ],
      "created_at": "2014-11-07T20:49:31Z",
      "updated_at": "2026-01-16T20:16:15Z",
      "pushed_at": "2026-01-16T20:15:51Z",
      "open_issues": 3184,
      "owner": {
        "login": "rancher",
        "avatar_url": "https://avatars.githubusercontent.com/u/9343010?v=4"
      },
      "readme": "# Rancher\n\n[![Docker Pulls](https://img.shields.io/docker/pulls/rancher/rancher.svg)](https://store.docker.com/community/images/rancher/rancher)\n[![Go Report Card](https://goreportcard.com/badge/github.com/rancher/rancher)](https://goreportcard.com/report/github.com/rancher/rancher)\n\nRancher is an open source container management platform built for organizations that deploy containers in production. Rancher makes it easy to run Kubernetes everywhere, meet IT requirements, and empower DevOps teams.\n\n## Stable Release\n\n<!-- stable v2.13.1 DO NOT REMOVE THIS LINE -->\n* v2.13.1 - `rancher/rancher:v2.13.1` / `rancher/rancher:stable` - Read the full release [notes](https://github.com/rancher/rancher/releases/tag/v2.13.1).\n  \nTo get automated notifications of our latest release, you can watch the announcements category in our [forums](http://forums.rancher.com/c/announcements), or subscribe to the RSS feed `https://forums.rancher.com/c/announcements.rss`.\n\n## Quick Start\n\n    sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher\n\nOpen your browser to https://localhost\n\n## Installation\n\nSee [Installing/Upgrading Rancher](https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-and-upgrade) for all installation options.\n\n### Minimum Requirements\n\n* Operating Systems\n  * Please see [Support Matrix](https://rancher.com/support-matrix/) for specific OS versions for each Rancher version. Note that the link will default to the support matrix for the latest version of Rancher. Use the left navigation menu to select a different Rancher version. \n* Hardware & Software\n  * Please see [Installation Requirements](https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-requirements) for hardware and software requirements.\n\n### Using Rancher\n\nTo learn more about using Rancher, please refer to our [Rancher Documentation](https://ranchermanager.docs.rancher.com/v2.8).\n\n## Source Code\n\nThis repo is a meta-repo used for packaging and contains the majority of Rancher codebase. For other Rancher projects and modules, [see go.mod](https://github.com/rancher/rancher/blob/release/v2.8/go.mod) for the full list.\n\nRancher also includes other open source libraries and projects, [see go.mod](https://github.com/rancher/rancher/blob/release/v2.8/go.mod) for the full list.\n\n## Build configuration\n\nRefer to the [build docs](docs/build.md) on how to customize the building and packaging of Rancher.\n\n## Support, Discussion, and Community\nIf you need any help with Rancher, please join us at either our [Rancher forums](http://forums.rancher.com/) or [Slack](https://slack.rancher.io/) where most of our team hangs out at.\n\nPlease submit any Rancher bugs, issues, and feature requests to [rancher/rancher](https://github.com/rancher/rancher/issues).\n\nFor security issues, please first check our [security policy](https://github.com/rancher/rancher/security) and email security-rancher@suse.com instead of posting a public issue in GitHub.  You may (but are not required to) use the GPG key located on [Keybase](https://keybase.io/rancher).\n\n# License\n\nCopyright (c) 2014-2025 [SUSE](http://rancher.com)\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n",
      "stars_today": 6
    },
    {
      "id": 48833910,
      "name": "tikv",
      "full_name": "tikv/tikv",
      "description": "Distributed transactional key-value database, originally created to complement TiDB",
      "html_url": "https://github.com/tikv/tikv",
      "stars": 16467,
      "forks": 2240,
      "language": "Rust",
      "topics": [
        "cncf",
        "consensus",
        "distributed-transactions",
        "hacktoberfest",
        "key-value",
        "raft",
        "rocksdb",
        "rust",
        "tidb",
        "tikv"
      ],
      "created_at": "2015-12-31T04:51:32Z",
      "updated_at": "2026-01-17T00:23:39Z",
      "pushed_at": "2026-01-15T15:30:29Z",
      "open_issues": 1643,
      "owner": {
        "login": "tikv",
        "avatar_url": "https://avatars.githubusercontent.com/u/41004122?v=4"
      },
      "readme": "<img src=\"images/tikv-logo.png\" alt=\"tikv_logo\" width=\"300\"/>\n\n## [Website](https://tikv.org) | [Documentation](https://tikv.org/docs/latest/concepts/overview/) | [Community Chat](https://slack.tidb.io/invite?team=tikv-wg&channel=general)\n\n[![Build Status](https://ci.pingcap.net/buildStatus/icon?job=tikv_ghpr_build_master)](https://ci.pingcap.net/blue/organizations/jenkins/tikv_ghpr_build_master/activity)\n[![Coverage Status](https://codecov.io/gh/tikv/tikv/branch/master/graph/badge.svg)](https://codecov.io/gh/tikv/tikv)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/2574/badge)](https://bestpractices.coreinfrastructure.org/projects/2574)\n\nTiKV is an open-source, distributed, and transactional key-value database. Unlike other traditional NoSQL systems, TiKV not only provides classical key-value APIs, but also transactional APIs with ACID compliance. Built in Rust and powered by Raft, TiKV was originally created by [PingCAP](https://en.pingcap.com) to complement [TiDB](https://github.com/pingcap/tidb), a distributed HTAP database compatible with the MySQL protocol.\n\nThe design of TiKV ('Ti' stands for titanium) is inspired by some great distributed systems from Google, such as BigTable, Spanner, and Percolator, and some of the latest achievements in academia in recent years, such as the Raft consensus algorithm.\n\nIf you're interested in contributing to TiKV, or want to build it from source, see [CONTRIBUTING.md](./CONTRIBUTING.md).\n\n![cncf_logo](images/cncf.png#gh-light-mode-only)\n![cncf_logo](images/cncf-white.png#gh-dark-mode-only)\n\nTiKV is a graduated project of the [Cloud Native Computing Foundation](https://cncf.io/) (CNCF). If you are an organization that wants to help shape the evolution of technologies that are container-packaged, dynamically-scheduled and microservices-oriented, consider joining the CNCF. For details about who's involved and how TiKV plays a role, read the CNCF [announcement](https://www.cncf.io/announcements/2020/09/02/cloud-native-computing-foundation-announces-tikv-graduation/).\n\n---\n\nWith the implementation of the Raft consensus algorithm in Rust and consensus state stored in RocksDB, TiKV guarantees data consistency. [Placement Driver (PD)](https://github.com/pingcap/pd/), which is introduced to implement auto-sharding, enables automatic data migration. The transaction model is similar to Google's Percolator with some performance improvements. TiKV also provides snapshot isolation (SI), snapshot isolation with lock (SQL: `SELECT ... FOR UPDATE`), and externally consistent reads and writes in distributed transactions.\n\nTiKV has the following key features:\n\n- **Geo-Replication**\n\n    TiKV uses [Raft](http://raft.github.io/) and the Placement Driver to support Geo-Replication.\n\n- **Horizontal scalability**\n\n    With PD and carefully designed Raft groups, TiKV excels in horizontal scalability and can easily scale to 100+ TBs of data.\n\n- **Consistent distributed transactions**\n\n    Similar to Google's Spanner, TiKV supports externally-consistent distributed transactions.\n\n- **Coprocessor support**\n\n    Similar to HBase, TiKV implements a coprocessor framework to support distributed computing.\n\n- **Cooperates with [TiDB](https://github.com/pingcap/tidb)**\n\n    Thanks to the internal optimization, TiKV and TiDB can work together to be a compelling database solution with high horizontal scalability, externally-consistent transactions, support for RDBMS, and NoSQL design patterns.\n\n## Governance\n\nSee [Governance](https://github.com/tikv/community/blob/master/GOVERNANCE.md).\n\n## Documentation\n\nFor instructions on deployment, configuration, and maintenance of TiKV,see TiKV documentation on our [website](https://tikv.org/docs/4.0/tasks/introduction/). For more details on concepts and designs behind TiKV, see [Deep Dive TiKV](https://tikv.org/deep-dive/introduction/).\n\n> **Note:**\n>\n> We have migrated our documentation from the [TiKV's wiki page](https://github.com/tikv/tikv/wiki/) to the [official website](https://tikv.org/docs). The original Wiki page is discontinued. If you have any suggestions or issues regarding documentation, offer your feedback [here](https://github.com/tikv/website).\n\n## TiKV adopters\n\nYou can view the list of [TiKV Adopters](https://tikv.org/adopters/).\n\n## TiKV software stack\n\n![The TiKV software stack](images/tikv_stack.png)\n\n- **Placement Driver:** PD is the cluster manager of TiKV, which periodically checks replication constraints to balance load and data automatically.\n- **Store:** There is a RocksDB within each Store and it stores data into the local disk.\n- **Region:** Region is the basic unit of Key-Value data movement. Each Region is replicated to multiple Nodes. These multiple replicas form a Raft group.\n- **Node:** A physical node in the cluster. Within each node, there are one or more Stores. Within each Store, there are many Regions.\n\nWhen a node starts, the metadata of the Node, Store and Region are recorded into PD. The status of each Region and Store is reported to PD regularly.\n\n## Quick start\n\n### Deploy a playground with TiUP\n\nThe most quickest to try out TiKV with TiDB is using TiUP, a component manager for TiDB.\n\nYou can see [this page](https://docs.pingcap.com/tidb/stable/quick-start-with-tidb#deploy-a-local-test-environment-using-tiup-playground) for a step by step tutorial.\n\n### Deploy a playground with binary\n\nTiKV is able to run separately with PD, which is the minimal deployment required.\n\n1. Download and extract binaries.\n\n```bash\n$ export TIKV_VERSION=v7.5.0\n$ export GOOS=darwin  # only {darwin, linux} are supported\n$ export GOARCH=amd64 # only {amd64, arm64} are supported\n$ curl -O  https://tiup-mirrors.pingcap.com/tikv-$TIKV_VERSION-$GOOS-$GOARCH.tar.gz\n$ curl -O  https://tiup-mirrors.pingcap.com/pd-$TIKV_VERSION-$GOOS-$GOARCH.tar.gz\n$ tar -xzf tikv-$TIKV_VERSION-$GOOS-$GOARCH.tar.gz\n$ tar -xzf pd-$TIKV_VERSION-$GOOS-$GOARCH.tar.gz\n```\n\n2. Start PD instance.\n\n```bash\n$ ./pd-server --name=pd --data-dir=/tmp/pd/data --client-urls=\"http://127.0.0.1:2379\" --peer-urls=\"http://127.0.0.1:2380\" --initial-cluster=\"pd=http://127.0.0.1:2380\" --log-file=/tmp/pd/log/pd.log\n```\n\n3. Start TiKV instance.\n\n```bash\n$ ./tikv-server --pd-endpoints=\"127.0.0.1:2379\" --addr=\"127.0.0.1:20160\" --data-dir=/tmp/tikv/data --log-file=/tmp/tikv/log/tikv.log\n```\n\n4. Install TiKV Client(Python) and verify the deployment, required Python 3.5+.\n\n```bash\n$ pip3 install -i https://test.pypi.org/simple/ tikv-client\n```\n\n```python\nfrom tikv_client import RawClient\n\nclient = RawClient.connect([\"127.0.0.1:2379\"])\n\nclient.put(b'foo', b'bar')\nprint(client.get(b'foo')) # b'bar'\n\nclient.put(b'foo', b'baz')\nprint(client.get(b'foo')) # b'baz'\n```\n\n### Deploy a cluster with Docker Compose\n\nThe easiest way to run a complete TiKV cluster (3 PD + 3 TiKV nodes) for development and testing is using Docker Compose. The setup uses pre-built TiKV and PD nightly images from Docker Hub, so no building is required.\n\n> **Note:** On macOS, use `docker compose` (space) instead of `docker-compose` (hyphen) in all commands.\n\n1. Start the cluster:\n\n```bash\n$ docker-compose up -d\n# On macOS, use: docker compose up -d\n```\n\n2. Check cluster status:\n\n```bash\n$ docker-compose ps\n# On macOS, use: docker compose ps\n```\n\n3. Access the cluster:\n\n- PD endpoints: `127.0.0.1:23791`, `127.0.0.1:23792`, `127.0.0.1:23793`\n- TiKV status: `http://localhost:20181/status`, `http://localhost:20182/status`, `http://localhost:20183/status`\n\nFor more details, see [docker-compose.README.md](./docker-compose.README.md).\n\n### Deploy a cluster with TiUP\n\nYou can see [this manual](./doc/deploy.md) of production-like cluster deployment presented by @c4pt0r.\n\n### Build from source\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md).\n\n## Client drivers\n\n- [Go](https://github.com/tikv/client-go) (The most stable and widely used)\n- [Java](https://github.com/tikv/client-java)\n- [Rust](https://github.com/tikv/client-rust)\n- [C](https://github.com/tikv/client-c)\n\nIf you want to try the Go client, see [Go Client](https://tikv.org/docs/4.0/reference/clients/go/).\n\n## Security\n\n### Security audit\n\nA third-party security auditing was performed by Cure53. See the full report [here](./security/Security-Audit.pdf).\n\n### Reporting Security Vulnerabilities\n\nTo report a security vulnerability, please send an email to [TiKV-security](mailto:tikv-security@lists.cncf.io) group.\n\nSee [Security](SECURITY.md) for the process and policy followed by the TiKV project.\n\n## Communication\n\nCommunication within the TiKV community abides by [TiKV Code of Conduct](./CODE_OF_CONDUCT.md). Here is an excerpt:\n\n> In the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n### Social Media\n\n- [Twitter](https://twitter.com/tikvproject)\n- [Blog](https://tikv.org/blog/)\n- [Reddit](https://www.reddit.com/r/TiKV)\n- Post questions or help answer them on [Stack Overflow](https://stackoverflow.com/questions/tagged/tikv)\n\n### Slack\n\nJoin the TiKV community on [Slack](https://slack.tidb.io/invite?team=tikv-wg&channel=general) - Sign up and join channels on TiKV topics that interest you.\n\n## License\n\nTiKV is under the Apache 2.0 license. See the [LICENSE](./LICENSE) file for details.\n\n## Acknowledgments\n\n- Thanks [etcd](https://github.com/coreos/etcd) for providing some great open source tools.\n- Thanks [RocksDB](https://github.com/facebook/rocksdb) for their powerful storage engines.\n- Thanks [rust-clippy](https://github.com/rust-lang/rust-clippy). We do love the great project.\n",
      "stars_today": 6
    },
    {
      "id": 50205233,
      "name": "debezium",
      "full_name": "debezium/debezium",
      "description": "Change data capture for a variety of databases. Please log issues at https://github.com/debezium/dbz/issues.",
      "html_url": "https://github.com/debezium/debezium",
      "stars": 12295,
      "forks": 2827,
      "language": "Java",
      "topics": [
        "apache-kafka",
        "cdc",
        "change-data-capture",
        "data-pipeline",
        "database",
        "debezium",
        "event-streaming",
        "hacktoberfest",
        "kafka",
        "kafka-connect",
        "kafka-producer"
      ],
      "created_at": "2016-01-22T20:17:05Z",
      "updated_at": "2026-01-16T12:39:15Z",
      "pushed_at": "2026-01-16T17:54:50Z",
      "open_issues": 110,
      "owner": {
        "login": "debezium",
        "avatar_url": "https://avatars.githubusercontent.com/u/11964329?v=4"
      },
      "readme": "[![License](http://img.shields.io/:license-apache%202.0-brightgreen.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)\n[![Maven Central](https://img.shields.io/maven-central/v/io.debezium/debezium-core?color=bright-green)](https://central.sonatype.com/search?q=io.debezium)\n[![User chat](https://img.shields.io/badge/chat-users-brightgreen.svg)](https://debezium.zulipchat.com/#narrow/stream/302529-users)\n[![Developer chat](https://img.shields.io/badge/chat-devs-brightgreen.svg)](https://debezium.zulipchat.com/#narrow/stream/302533-dev)\n[![Google Group](https://img.shields.io/:mailing%20list-debezium-brightgreen.svg)](https://groups.google.com/forum/#!forum/debezium)\n[![Stack Overflow](http://img.shields.io/:stack%20overflow-debezium-brightgreen.svg)](http://stackoverflow.com/questions/tagged/debezium)\n\nCopyright Debezium Authors.\nLicensed under the [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0).\nThe Antlr grammars within the debezium-ddl-parser module are licensed under the [MIT License](https://opensource.org/licenses/MIT).\n\nEnglish | [Chinese](README_ZH.md) | [Japanese](README_JA.md) | [Korean](README_KO.md)\n\n# Debezium\n\nDebezium is an open source project that provides a low latency data streaming platform for change data capture (CDC). You set up and configure Debezium to monitor your databases, and then your applications consume events for each row-level change made to the database. Only committed changes are visible, so your application doesn't have to worry about transactions or changes that are rolled back. Debezium provides a single model of all change events, so your application does not have to worry about the intricacies of each kind of database management system. Additionally, since Debezium records the history of data changes in durable, replicated logs, your application can be stopped and restarted at any time, and it will be able to consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely.\n\nMonitoring databases and being notified when data changes has always been complicated. Relational database triggers can be useful, but are specific to each database and often limited to updating state within the same database (not communicating with external processes). Some databases offer APIs or frameworks for monitoring changes, but there is no standard so each database's approach is different and requires a lot of knowledged and specialized code. It still is very challenging to ensure that all changes are seen and processed in the same order while minimally impacting the database.\n\nDebezium provides modules that do this work for you. Some modules are generic and work with multiple database management systems, but are also a bit more limited in functionality and performance. Other modules are tailored for specific database management systems, so they are often far more capable and they leverage the specific features of the system.\n\n## Basic architecture\n\nDebezium is a change data capture (CDC) platform that achieves its durability, reliability, and fault tolerance qualities by reusing Kafka and Kafka Connect. Each connector deployed to the Kafka Connect distributed, scalable, fault tolerant service monitors a single upstream database server, capturing all of the changes and recording them in one or more Kafka topics (typically one topic per database table). Kafka ensures that all of these data change events are replicated and totally ordered, and allows many clients to independently consume these same data change events with little impact on the upstream system. Additionally, clients can stop consuming at any time, and when they restart they resume exactly where they left off. Each client can determine whether they want exactly-once or at-least-once delivery of all data change events, and all data change events for each database/table are delivered in the same order they occurred in the upstream database.\n\nApplications that don't need or want this level of fault tolerance, performance, scalability, and reliability can instead use Debezium's *embedded connector engine* to run a connector directly within the application space. They still want the same data change events, but prefer to have the connectors send them directly to the application rather than persist them inside Kafka.\n\n## Common use cases\n\nThere are a number of scenarios in which Debezium can be extremely valuable, but here we outline just a few of them that are more common.\n\n### Cache invalidation\n\nAutomatically invalidate entries in a cache as soon as the record(s) for entries change or are removed. If the cache is running in a separate process (e.g., Redis, Memcache, Infinispan, and others), then the simple cache invalidation logic can be placed into a separate process or service, simplifying the main application. In some situations, the logic can be made a little more sophisticated and can use the updated data in the change events to update the affected cache entries.\n\n### Simplifying monolithic applications\n\nMany applications update a database and then do additional work after the changes are committed: update search indexes, update a cache, send notifications, run business logic, etc. This is often called \"dual-writes\" since the application is writing to multiple systems outside of a single transaction. Not only is the application logic complex and more difficult to maintain, dual writes also risk losing data or making the various systems inconsistent if the application were to crash after a commit but before some/all of the other updates were performed. Using change data capture, these other activities can be performed in separate threads or separate processes/services when the data is committed in the original database. This approach is more tolerant of failures, does not miss events, scales better, and more easily supports upgrading and operations.\n\n### Sharing databases\n\nWhen multiple applications share a single database, it is often non-trivial for one application to become aware of the changes committed by another application. One approach is to use a message bus, although non-transactional message busses suffer from the \"dual-writes\" problems mentioned above. However, this becomes very straightforward with Debezium: each application can monitor the database and react to the changes.\n\n### Data integration\n\nData is often stored in multiple places, especially when it is used for different purposes and has slightly different forms. Keeping the multiple systems synchronized can be challenging, but simple ETL-type solutions can be implemented quickly with Debezium and simple event processing logic.\n\n### CQRS\n\nThe [Command Query Responsibility Separation (CQRS)](http://martinfowler.com/bliki/CQRS.html) architectural pattern uses a one data model for updating and one or more other data models for reading. As changes are recorded on the update-side, those changes are then processed and used to update the various read representations. As a result CQRS applications are usually more complicated, especially when they need to ensure reliable and totally-ordered processing. Debezium and CDC can make this more approachable: writes are recorded as normal, but Debezium captures those changes in durable, totally ordered streams that are consumed by the services that asynchronously update the read-only views. The write-side tables can represent domain-oriented entities, or when CQRS is paired with [Event Sourcing](http://martinfowler.com/eaaDev/EventSourcing.html) the write-side tables are the append-only event log of commands.\n\n## Building Debezium\n\nThe following software is required to work with the Debezium codebase and build it locally:\n\n* [Git](https://git-scm.com) 2.2.1 or later\n* JDK 21 or later, e.g. [OpenJDK](http://openjdk.java.net/projects/jdk/)\n* [Docker Engine](https://docs.docker.com/engine/install/) or [Docker Desktop](https://docs.docker.com/desktop/) 1.9 or later\n* [Apache Maven](https://maven.apache.org/index.html) 3.9.8 or later  \n  (or invoke the wrapper with `./mvnw` for Maven commands)\n\nSee the links above for installation instructions on your platform. You can verify the versions are installed and running:\n\n    $ git --version\n    $ javac -version\n    $ mvn -version\n    $ docker --version\n\n### Why Docker?\n\nMany open source software projects use Git, Java, and Maven, but requiring Docker is less common. Debezium is designed to talk to a number of external systems, such as various databases and services, and our integration tests verify Debezium does this correctly. But rather than expect you have all of these software systems installed locally, Debezium's build system uses Docker to automatically download or create the necessary images and start containers for each of the systems. The integration tests can then use these services and verify Debezium behaves as expected, and when the integration tests finish, Debezium's build will automatically stop any containers that it started.\n\nDebezium also has a few modules that are not written in Java, and so they have to be required on the target operating system. Docker lets our build do this using images with the target operating system(s) and all necessary development tools.\n\nUsing Docker has several advantages:\n\n1. You don't have to install, configure, and run specific versions of each external services on your local machine, or have access to them on your local network. Even if you do, Debezium's build won't use them.\n1. We can test multiple versions of an external service. Each module can start whatever containers it needs, so different modules can easily use different versions of the services.\n1. Everyone can run complete builds locally. You don't have to rely upon a remote continuous integration server running the build in an environment set up with all the required services.\n1. All builds are consistent. When multiple developers each build the same codebase, they should see exactly the same results -- as long as they're using the same or equivalent JDK, Maven, and Docker versions. That's because the containers will be running the same versions of the services on the same operating systems. Plus, all of the tests are designed to connect to the systems running in the containers, so nobody has to fiddle with connection properties or custom configurations specific to their local environments.\n1. No need to clean up the services, even if those services modify and store data locally. Docker *images* are cached, so reusing them to start containers is fast and consistent. However, Docker *containers* are never reused: they always start in their pristine initial state, and are discarded when they are shutdown. Integration tests rely upon containers, and so cleanup is handled automatically.\n\n### Configure your Docker environment\n\nThe Docker Maven Plugin will resolve the docker host by checking the following environment variables:\n\n    export DOCKER_HOST=tcp://10.1.2.2:2376\n    export DOCKER_CERT_PATH=/path/to/cdk/.vagrant/machines/default/virtualbox/.docker\n    export DOCKER_TLS_VERIFY=1\n\nThese can be set automatically if using Docker Machine or something similar.\n\n#### Colima\nIn order to run testcontainers against [colima](https://github.com/abiosoft/colima) the env vars below should be set (assume we use `default` profile of colima)\n\n    colima start\n    export TESTCONTAINERS_DOCKER_SOCKET_OVERRIDE=/var/run/docker.sock\n    export TESTCONTAINERS_HOST_OVERRIDE=\"0.0.0.0\"\n    export DOCKER_HOST=\"unix://${HOME}/.colima/default/docker.sock\"\n\n#### Docker Desktop on Apple Silicon\n\nWhen running on Apple Silicon, the Docker Maven Plugin needs to be configured to use the `linux/amd64` platform. Additionally, it should be pointed to the Docker socket created by Docker Desktop using the `docker.host` system property.\n\nFor example:\n\n```shell\nmvn docker:start \\\n  -Ddocker.host=unix://$HOME/.docker/run/docker.sock \\\n  -Ddocker.platform=linux/amd64 \\\n  -pl debezium-connector-sqlserver\n```\n\nTo avoid repetition in CLI commands, these system properties can be defined in the user's Maven profile.\nHere's an example `~/.m2/settings.xml` profile:\n\n```xml\n<settings>\n  <profiles>\n    <profile>\n      <id>default</id>\n      <properties>\n        <docker.host>unix://${user.home}/.docker/run/docker.sock</docker.host>\n        <docker.platform>linux/amd64</docker.platform>\n      </properties>\n    </profile>\n  </profiles>\n\n  <activeProfiles>\n    <activeProfile>default</activeProfile>\n  </activeProfiles>\n</settings>\n```\n\n### Building the code\n\nFirst obtain the code by cloning the Git repository:\n\n    $ git clone https://github.com/debezium/debezium.git\n    $ cd debezium\n\nThen build the code using Maven:\n\n    $ mvn clean verify\n\nThe build starts and uses several Docker containers for different DBMSes. Note that if Docker is not running or configured, you'll likely get an arcane error -- if this is the case, always verify that Docker is running, perhaps by using `docker ps` to list the running containers.\n\n### Don't have Docker running locally for builds?\n\nYou can skip the integration tests and docker-builds with the following command:\n\n    $ mvn clean verify -DskipITs\n\n### Building just the artifacts, without running tests, CheckStyle, etc.\n\nYou can skip all non-essential plug-ins (tests, integration tests, CheckStyle, formatter, API compatibility check, etc.) using the \"quick\" build profile:\n\n    $ mvn clean verify -Dquick\n\nThis provides the fastest way for solely producing the output artifacts, without running any of the QA related Maven plug-ins.\nThis comes in handy for producing connector JARs and/or archives as quickly as possible, e.g. for manual testing in Kafka Connect.\n\n### Running tests of the Postgres connector using the wal2json or pgoutput logical decoding plug-ins\n\nThe Postgres connector supports three logical decoding plug-ins for streaming changes from the DB server to the connector: decoderbufs (the default), wal2json, and pgoutput.\nTo run the integration tests of the PG connector using wal2json, enable the \"wal2json-decoder\" build profile:\n\n    $ mvn clean install -pl :debezium-connector-postgres -Pwal2json-decoder\n    \nTo run the integration tests of the PG connector using pgoutput, enable the \"pgoutput-decoder\" and \"postgres-10\" build profiles:\n\n    $ mvn clean install -pl :debezium-connector-postgres -Ppgoutput-decoder,postgres-10\n\nA few tests currently don't pass when using the wal2json plug-in.\nLook for references to the types defined in `io.debezium.connector.postgresql.DecoderDifferences` to find these tests.\n\n### Running tests of the Postgres connector with specific Apicurio Version\nTo run the tests of PG connector using wal2json or pgoutput logical decoding plug-ins with a specific version of Apicurio, a test property can be passed as:\n\n    $ mvn clean install -pl debezium-connector-postgres -Pwal2json-decoder \n          -Ddebezium.test.apicurio.version=1.3.1.Final\n\nIn absence of the property the stable version of Apicurio will be fetched.\n\n### Running tests of the Postgres connector against an external database, e.g. Amazon RDS\nPlease note if you want to test against a *non-RDS* cluster, this test requires `<your user>` to be a superuser with not only `replication` but permissions\nto login to `all` databases in `pg_hba.conf`.  It also requires `postgis` packages to be available on the target server for some of the tests to pass.\n\n    $ mvn clean install -pl debezium-connector-postgres -Pwal2json-decoder \\\n         -Ddocker.skip.build=true -Ddocker.skip.run=true -Dpostgres.host=<your PG host> \\\n         -Dpostgres.user=<your user> -Dpostgres.password=<your password> \\\n         -Ddebezium.test.records.waittime=10\n\nAdjust the timeout value as needed.\n\nSee [PostgreSQL on Amazon RDS](debezium-connector-postgres/RDS.md) for details on setting up a database on RDS to test against.\n\n### Running tests of the Oracle connector using Oracle XStream\n\n    $ mvn clean install -pl debezium-connector-oracle -Poracle-xstream,oracle-tests -Dinstantclient.dir=<path-to-instantclient>\n\n### Running tests of the Oracle connector with a non-CDB database\n\n    $ mvn clean install -pl debezium-connector-oracle -Poracle-tests -Dinstantclient.dir=<path-to-instantclient> -Ddatabase.pdb.name=\n\n### Running the tests for MongoDB with oplog capturing from an IDE\n\nWhen running the test without maven, please make sure you pass the correct parameters to the execution. Look for the correct parameters in `.github/workflows/mongodb-oplog-workflow.yml` and\nappend them to the JVM execution parameters, prefixing them with `debezium.test`. As the execution will happen outside of the lifecycle execution, you need to start the MongoDB container manually\nfrom the MongoDB connector directory\n\n    $ mvn docker:start -B -am -Passembly -Dcheckstyle.skip=true -Dformat.skip=true -Drevapi.skip -Dcapture.mode=oplog -Dversion.mongo.server=3.6 -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn -Dmaven.wagon.http.pool=false -Dmaven.wagon.httpconnectionManager.ttlSeconds=120 -Dcapture.mode=oplog -Dmongo.server=3.6\n\nThe relevant portion of the line will look similar to the following:\n\n    java -ea -Ddebezium.test.capture.mode=oplog -Ddebezium.test.version.mongo.server=3.6 -Djava.awt.headless=true -Dconnector.mongodb.members.auto.discover=false -Dconnector.mongodb.name=mongo1 -DskipLongRunningTests=true [...]\n\n## Contributing\n\nThe Debezium community welcomes anyone that wants to help out in any way, whether that includes reporting problems, helping with documentation, or contributing code changes to fix bugs, add tests, or implement new features. See [this document](CONTRIBUTING.md) for details.\n\nA big thank you to all the Debezium contributors!\n\n<a href=\"https://github.com/debezium/debezium/graphs/contributors\">\n  <img src=\"https://contributors-img.web.app/image?repo=debezium/debezium\" />\n</a>\n",
      "stars_today": 6
    },
    {
      "id": 57452143,
      "name": "android",
      "full_name": "bitwarden/android",
      "description": "Bitwarden mobile apps (Password Manager and Authenticator) for Android.",
      "html_url": "https://github.com/bitwarden/android",
      "stars": 8272,
      "forks": 930,
      "language": "Kotlin",
      "topics": [
        "android",
        "bitwarden",
        "compose",
        "jetpack",
        "kotlin"
      ],
      "created_at": "2016-04-30T16:43:17Z",
      "updated_at": "2026-01-16T21:58:48Z",
      "pushed_at": "2026-01-16T22:42:32Z",
      "open_issues": 145,
      "owner": {
        "login": "bitwarden",
        "avatar_url": "https://avatars.githubusercontent.com/u/15990069?v=4"
      },
      "readme": "# Bitwarden Android\n\n## Contents\n\n- [Compatibility](#compatibility)\n- [Setup](#setup)\n- [Dependencies](#dependencies)\n\n## Compatibility\n\n- **Minimum SDK**: 29 (Android 10)\n- **Target SDK**: 36 (Android 16)\n- **Device Types Supported**: Phone and Tablet\n- **Orientations Supported**: Portrait and Landscape\n\n## Setup\n\n1. Clone the repository:\n\n    ```sh\n    $ git clone https://github.com/bitwarden/android\n    ```\n\n2. Create a `user.properties` file in the root directory of the project and add the following properties:\n\n    - `gitHubToken`: A \"classic\" Github Personal Access Token (PAT) with the `read:packages` scope (ex: `gitHubToken=gph_xx...xx`). These can be generated by going to the [Github tokens page](https://github.com/settings/tokens). See [the Github Packages user documentation concerning authentication](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-gradle-registry#authenticating-to-github-packages) for more details.\n    - `localSdk`: A boolean value to determine if the SDK should be loaded from the local maven artifactory (ex: `localSdk=true`). This is particularly useful when developing new SDK capabilities. Review [Linking SDK to clients](https://contributing.bitwarden.com/getting-started/sdk/#linking-the-sdk-to-clients) for more details.\n\n3. Setup the code style formatter:\n\n    All code must follow the guidelines described in the [Code Style Guidelines document](docs/STYLE_AND_BEST_PRACTICES.md). To aid in adhering to these rules, all contributors should apply `docs/bitwarden-style.xml` as their code style scheme. In IntelliJ / Android Studio:\n\n    - Navigate to `Preferences > Editor > Code Style`.\n    - Hit the `Manage` button next to `Scheme`.\n    - Select `Import`.\n    - Find the `bitwarden-style.xml` file in the project's `docs/` directory.\n    - Import \"from\" `BitwardenStyle` \"to\" `BitwardenStyle`.\n    - Hit `Apply` and `OK` to save the changes and exit Preferences.\n\n    Note that in some cases you may need to restart Android Studio for the changes to take effect.\n\n    All code should be formatted before submitting a pull request. This can be done manually but it can also be helpful to create a macro with a custom keyboard binding to auto-format when saving. In Android Studio on OS X:\n\n    - Select `Edit > Macros > Start Macro Recording`\n    - Select `Code > Optimize Imports`\n    - Select `Code > Reformat Code`\n    - Select `File > Save All`\n    - Select `Edit > Macros > Stop Macro Recording`\n\n    This can then be mapped to a set of keys by navigating to `Android Studio > Preferences` and editing the macro under `Keymap` (ex : shift + command + s).\n\n    Please avoid mixing formatting and logical changes in the same commit/PR. When possible, fix any large formatting issues in a separate PR before opening one to make logical changes to the same code. This helps others focus on the meaningful code changes when reviewing the code.\n\n4. Setup JDK `Version` `21`:\n\n    - Navigate to `Preferences > Build, Execution, Deployment > Build Tools > Gradle`.\n    - Hit the selected Gradle JDK next to `Gradle JDK:`.\n    - Select a `21.x` version or hit `Download JDK...` if not present.\n    - Select `Version` `21`.\n    - Select your preferred `Vendor`.\n    - Hit `Download`.\n    - Hit `Apply`.\n\n5. Setup `detekt` pre-commit hook (optional):\n\nRun the following script from the root of the repository to install the hook. This will overwrite any existing pre-commit hook if present.\n\n```shell\necho \"Writing detekt pre-commit hook...\"\ncat << 'EOL' > .git/hooks/pre-commit\n#!/usr/bin/env bash\n\necho \"Running detekt check...\"\nOUTPUT=\"/tmp/detekt-$(date +%s)\"\n./gradlew -Pprecommit=true detekt > $OUTPUT\nEXIT_CODE=$?\nif [ $EXIT_CODE -ne 0 ]; then\n  cat $OUTPUT\n  rm $OUTPUT\n  echo \"***********************************************\"\n  echo \"                 detekt failed                 \"\n  echo \" Please fix the above issues before committing \"\n  echo \"***********************************************\"\n  exit $EXIT_CODE\nfi\nrm $OUTPUT\nEOL\necho \"detekt pre-commit hook written to .git/hooks/pre-commit\"\necho \"Making the hook executable\"\nchmod +x .git/hooks/pre-commit\n\necho \"detekt pre-commit hook installed successfully to .git/hooks/pre-commit\"\n```\n\n## Dependencies\n\n### Application Dependencies\n\nThe following is a list of all third-party dependencies included as part of the application beyond the standard Android SDK.\n\n- **AndroidX Activity**\n    - https://developer.android.com/jetpack/androidx/releases/activity\n    - Purpose: Allows access composable APIs built on top of Activity.\n    - License: Apache 2.0\n\n- **AndroidX Appcompat**\n    - https://developer.android.com/jetpack/androidx/releases/appcompat\n    - Purpose: Allows access to new APIs on older API versions.\n    - License: Apache 2.0\n\n- **AndroidX Autofill**\n    - https://developer.android.com/jetpack/androidx/releases/autofill\n    - Purpose: Allows access to tools for building inline autofill UI.\n    - License: Apache 2.0\n\n- **AndroidX Biometrics**\n    - https://developer.android.com/jetpack/androidx/releases/biometric\n    - Purpose: Authenticate with biometrics or device credentials.\n    - License: Apache 2.0\n\n- **AndroidX Browser**\n    - https://developer.android.com/jetpack/androidx/releases/browser\n    - Purpose: Displays webpages with the user's default browser.\n    - License: Apache 2.0\n\n- **AndroidX Camera**\n    - https://developer.android.com/jetpack/androidx/releases/camera\n    - Purpose: Display and capture images for barcode scanning.\n    - License: Apache 2.0\n\n- **AndroidX Compose**\n    - https://developer.android.com/jetpack/androidx/releases/compose\n    - Purpose: A Kotlin-based declarative UI framework.\n    - License: Apache 2.0\n\n- **AndroidX Core**\n    - https://developer.android.com/jetpack/androidx/releases/core\n    - Purpose: Backwards compatible platform features and APIs.\n    - License: Apache 2.0\n\n- **AndroidX Credentials**\n    - https://developer.android.com/jetpack/androidx/releases/credentials\n    - Purpose: Unified access to user's credentials.\n    - License: Apache 2.0\n\n- **AndroidX Lifecycle**\n    - https://developer.android.com/jetpack/androidx/releases/lifecycle\n    - Purpose: Lifecycle aware components and tooling.\n    - License: Apache 2.0\n\n- **AndroidX Navigation**\n    - https://developer.android.com/jetpack/androidx/releases/navigation\n    - Purpose: Provides a consistent API for navigating between Android components.\n    - License: Apache 2.0\n\n- **AndroidX Room**\n    - https://developer.android.com/jetpack/androidx/releases/room\n    - Purpose: A convenient SQLite-based persistence layer for Android.\n    - License: Apache 2.0\n\n- **AndroidX Security**\n    - https://developer.android.com/jetpack/androidx/releases/security\n    - Purpose: Safely manage keys and encrypt files and sharedpreferences.\n    - License: Apache 2.0\n\n- **AndroidX WorkManager**\n    - https://developer.android.com/jetpack/androidx/releases/work\n    - Purpose: The WorkManager is used to schedule deferrable, asynchronous tasks that must be run reliably.\n    - License: Apache 2.0\n\n- **Dagger Hilt**\n    - https://github.com/google/dagger\n    - Purpose: Dependency injection framework.\n    - License: Apache 2.0\n\n- **Glide**\n    - https://github.com/bumptech/glide\n    - Purpose: Image loading and caching.\n    - License: BSD, part MIT and Apache 2.0\n\n- **kotlinx.collections.immutable**\n    - https://github.com/Kotlin/kotlinx.collections.immutable\n    - Purpose: Immutable collection interfaces and implementation prototypes for Kotlin.\n    - License: Apache 2.0\n\n- **kotlinx.coroutines**\n    - https://github.com/Kotlin/kotlinx.coroutines\n    - Purpose: Kotlin coroutines library for asynchronous and reactive code.\n    - License: Apache 2.0\n\n- **kotlinx.serialization**\n    - https://github.com/Kotlin/kotlinx.serialization/\n    - Purpose: JSON serialization library for Kotlin.\n    - License: Apache 2.0\n\n- **OkHttp 3**\n    - https://github.com/square/okhttp\n    - Purpose: An HTTP client used by the library to intercept and log traffic.\n    - License: Apache 2.0\n\n- **Retrofit 2**\n    - https://github.com/square/retrofit\n    - Purpose: A networking layer interface.\n    - License: Apache 2.0\n\n- **Timber**\n    - https://github.com/JakeWharton/timber\n    - Purpose: Extensible logging library for Android.\n    - License: Apache 2.0\n\n- **ZXing**\n    - https://github.com/zxing/zxing\n    - Purpose: Barcode scanning and generation.\n    - License: Apache 2.0\n\nThe following is an additional list of third-party dependencies that are only included in the non-F-Droid build variants of the application.\n\n- **Firebase Cloud Messaging**\n    - https://github.com/firebase/firebase-android-sdk\n    - Purpose: Allows for push notification support.\n    - License: Apache 2.0\n\n- **Firebase Crashlytics**\n    - https://github.com/firebase/firebase-android-sdk\n    - Purpose: SDK for crash and non-fatal error reporting.\n    - License: Apache 2.0\n\n- **Google Play Reviews**\n    - https://developer.android.com/reference/com/google/android/play/core/release-notes\n    - Purpose: On standard builds provide an interface to add a review for the password manager application in Google Play.\n    - License: Apache 2.0\n\n### Development Environment Dependencies\n\nThe following is a list of additional third-party dependencies used as part of the local development environment. This includes test-related artifacts as well as tools related to code quality and linting. These are not present in the final packaged application.\n\n- **detekt**\n    - https://github.com/detekt/detekt\n    - Purpose: A static code analysis tool for the Kotlin programming language.\n    - License: Apache 2.0\n\n- **JUnit 5**\n    - https://github.com/junit-team/junit5\n    - Purpose: Unit Testing framework for testing application code.\n    - License: Eclipse Public License 2.0\n\n- **MockK**\n    - https://github.com/mockk/mockk\n    - Purpose: Kotlin-friendly mocking library.\n    - License: Apache 2.0\n\n- **Robolectric**\n    - https://github.com/robolectric/robolectric\n    - Purpose: A unit testing framework for code directly depending on the Android framework.\n    - License: MIT\n\n- **Turbine**\n    - https://github.com/cashapp/turbine\n    - Purpose: A small testing library for kotlinx.coroutine's Flow.\n    - License: Apache 2.0\n\n### CI/CD Dependencies\n\nThe following is a list of additional third-party dependencies used as part of the CI/CD workflows. These are not present in the final packaged application.\n\n- **Fastlane**\n    - https://fastlane.tools/\n    - Purpose: Automates building, signing, and distributing applications.\n    - License: MIT\n\n- **Kover**\n    - https://github.com/Kotlin/kotlinx-kover\n    - Purpose: Kotlin code coverage toolset.\n    - License: Apache 2.0\n",
      "stars_today": 6
    },
    {
      "id": 170244456,
      "name": "hidden",
      "full_name": "dwarvesf/hidden",
      "description": "An ultra-light MacOS utility that helps hide menu bar icons",
      "html_url": "https://github.com/dwarvesf/hidden",
      "stars": 13181,
      "forks": 364,
      "language": "Swift",
      "topics": [
        "macos",
        "swift",
        "utilities"
      ],
      "created_at": "2019-02-12T03:22:19Z",
      "updated_at": "2026-01-16T23:27:46Z",
      "pushed_at": "2025-11-06T15:27:28Z",
      "open_issues": 141,
      "owner": {
        "login": "dwarvesf",
        "avatar_url": "https://avatars.githubusercontent.com/u/10388449?v=4"
      },
      "readme": "<p align=\"center\">\n\t<img width=\"200\" height=\"200\" margin-right=\"100%\" src=\"https://github.com/dwarvesf/hidden/blob/develop/img/icon_512%402x.png?raw=true\">\n</p>\n<p align=\"center\">\n\t<a href=\"https://webuild.community\">\n\t\t<img src=\"https://raw.githubusercontent.com/webuild-community/badge/master/svg/love.svg\" />\n\t</a>\n\t<a href=\"https://github.com/dwarvesf/hidden/releases/latest\">\n \t\t<img src=\"https://img.shields.io/badge/download-latest-brightgreen.svg\" alt=\"download\">\n\t</a>\n\t<a href=\"https://img.shields.io/badge/platform-macOS-lightgrey.svg\">\n \t\t<img src=\"https://img.shields.io/badge/platform-macOS-lightgrey.svg\" alt=\"platform\">\n\t</a>\n\t<a href=\"https://img.shields.io/badge/requirements-macOS High Sierra+-ff69b4.svg\">\n \t\t<img src=\"https://img.shields.io/badge/requirements-macOS High Sierra+-ff69b4.svg\" alt=\"systemrequirements\">\n\t</a>\n</p>\n\n## Hidden Bar\nHidden Bar lets you hide menu bar items to give your Mac a cleaner look.\n\n<p align=\"center\">\n\t<img width=\"400\" src=\"img/screen1.png\">\n\t<img width=\"400\" src=\"img/screen2.png\">\n</p>\n\n## üöÄ Install\n\n### Ô£ø App Store\n\n[![AppStore](img/appstore.svg)](https://itunes.apple.com/app/hidden-bar/id1452453066)\n\n### Others\n\nThe Hidden Bar is notarized before distributed out side App Store. It's safe to use üëç\n\n#### Using Homebrew\n\n```\nbrew install --cask hiddenbar\n```\n\n#### Manual download\n\n- [Download latest version](https://github.com/dwarvesf/hidden/releases/latest)\n- Open and drag the app to the Applications folder.\n- Launch Hidden and drag the icon in your menu bar (hold CMD) to the right so it is between some other icons.\n\n## üïπ Usage\n\n* `‚åò` + drag to move the Hidden icons around in the menu bar.\n* Click the Arrow icon to hide menu bar items.\n\n<p align=\"center\">\n\t<img src=\"img/tutorial.gif\">\n</p>\n\n## ‚ú®<a href=\"https://github.com/dwarvesf/hidden/graphs/contributors\">Contributors</a>\n\nThis project exists thanks to all the people who contribute. Thank you guys so much üëè\n\n[![](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/images/0)](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/links/0)[![](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/images/1)](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/links/1)[![](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/images/2)](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/links/2)[![](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/images/3)](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/links/3)[![](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/images/4)](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/links/4)[![](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/images/5)](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/links/5)[![](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/images/6)](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/links/6)[![](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/images/7)](https://sourcerer.io/fame/phucledien/dwarvesf/hidden/links/7)\n\nPlease read [this](CONTRIBUTING.md) before you make a contribution.\n\n## Requirements\nmacOS version >= 10.13\n\n## You may also like\n- [Blurred](https://github.com/dwarvesf/Blurred) - A macOS utility that helps reduce distraction by dimming your inactive noise\n- [Micro Sniff](https://github.com/dwarvesf/micro-sniff) - An ultra-light macOS utility that notify whenever your micro-device is being used\n- [VimMotion](https://github.com/dwarvesf/VimMotionPublic) Vim style shortcut for MacOS\n## License\n\nMIT &copy; [Dwarves Foundation](https://github.com/dwarvesf)\n",
      "stars_today": 6
    },
    {
      "id": 789761983,
      "name": "QuickRecorder",
      "full_name": "lihaoyun6/QuickRecorder",
      "description": "A lightweight screen recorder based on ScreenCapture Kit for macOS / Âü∫‰∫é ScreenCapture Kit ÁöÑËΩªÈáèÂåñÂ§öÂäüËÉΩ macOS ÂΩïÂ±èÂ∑•ÂÖ∑",
      "html_url": "https://github.com/lihaoyun6/QuickRecorder",
      "stars": 7840,
      "forks": 435,
      "language": "Swift",
      "topics": [],
      "created_at": "2024-04-21T13:45:19Z",
      "updated_at": "2026-01-16T21:39:09Z",
      "pushed_at": "2025-06-11T07:47:27Z",
      "open_issues": 152,
      "owner": {
        "login": "lihaoyun6",
        "avatar_url": "https://avatars.githubusercontent.com/u/16348097?v=4"
      },
      "readme": "#\n<p align=\"center\">\n<img src=\"./QuickRecorder/Assets.xcassets/AppIcon.appiconset/icon_128x128@2x.png\" width=\"200\" height=\"200\" />\n<h1 align=\"center\">QuickRecorder</h1>\n<h3 align=\"center\">A lightweight and high-performance screen recorder for macOS<br><a href=\"./README_zh.md\">[‰∏≠ÊñáÁâàÊú¨]</a><br><a href=\"https://lihaoyun6.github.io/quickrecorder/\">[Landing Page]</a>\n</p>\n\n## Screenshot\n<p align=\"center\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./img/preview_en_dark.png\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"./img/preview_en.png\">\n  <img alt=\"QuickRecorder Screenshots\" src=\"./img/preview_en.png\" width=\"840\"/>\n</picture>\n</p>\n\n## Installation and Usage\n### System Requirements:\n- macOS 12.3 and Later\n\n### Install:\nDownload the latest installation file [here](../../releases/latest) or install via Homebrew:\n\n```bash\nbrew install lihaoyun6/tap/quickrecorder\n```\n\n### Features/Usage:\n- You can use QuickRecorder to record your screens / windows / applications / mobile devices... etc.\n\n- QuickRecorder supports driver-free audio loopback recording, mouse highlighting, screen magnifier and many more useful features.  \n- The new **\"[Presenter Overlay](https://support.apple.com/guide/facetime/presenter-overlay-video-conferencing-fctm6333f4bd/mac)\"** in macOS 14 was fully supported by QuickRecorder, which can overlay the camera in real time on your recording *(macOS 12/13 can only use camera floating window)*  \n- QuickRecorder is able to record `HEVC with Alpha` video format, that can contain alpha channel in the output file *(currently only iMovie and FCPX support this feature)*  \n\n## Q&A\n**1. Where can I reopen the main panel after closing it?**\n> Click the Dock tile or Menubar icon of QuickRecorder to reopen the main panel at any time.\n\n**2. Why does QuickRecorder not a sandbox app?**\n> QuickRecorder has no plans to be uploaded to the App Store, so it does not need to be designed as a sandbox app.  \n\n**3. How to independently control the volume of system sound and sound from microphone in other video editor?**\n> QuickRecorder will merge the audio input from the microphone to the main audio track after recording by default. If you need to edit the video, you can turn off the `Record Microphone to Main Track` option in the settings panel. After turning off, the system sound and sound from microphone will be recorded into two audio tracks and can be edited independently.  \n\n## Donate\n<img src=\"./img/donate.png\" width=\"350\"/>\n\n## Thanks\n[Azayaka](https://github.com/Mnpn/Azayaka) @Mnpn\n> The source of inspiration and part of the code of the screen recording engine comes from the Azayaka project, and I am also one of the code contributors to this project\n\n[KeyboardShortcuts](https://github.com/sindresorhus/KeyboardShortcuts) @sindresorhus  \n> QuickRecorder uses this swift library to handle shortcut key events  \n\n[SwiftLAME](https://github.com/hidden-spectrum/SwiftLAME) @Hidden Spectrum\n> QuickRecorder uses this swift library to handle MP3 output\n\n[ChatGPT](https://chat.openai.com) @OpenAI\n> Note: Part of the code in this project was generated or refactored using ChatGPT.\n",
      "stars_today": 6
    },
    {
      "id": 105363726,
      "name": "martin",
      "full_name": "maplibre/martin",
      "description": "Blazing fast and lightweight PostGIS, MBtiles and PMtiles tile server, tile generation, and mbtiles tooling.",
      "html_url": "https://github.com/maplibre/martin",
      "stars": 3259,
      "forks": 318,
      "language": "Rust",
      "topics": [
        "hacktoberfest",
        "leaflet",
        "mapbox-gl",
        "mapbox-gl-js",
        "mapbox-vector-tile",
        "maplibre",
        "maplibre-gl-js",
        "maps",
        "mbtiles",
        "pmtiles",
        "postgis",
        "postgresql",
        "rust",
        "vector-tiles",
        "webserver"
      ],
      "created_at": "2017-09-30T10:53:46Z",
      "updated_at": "2026-01-16T18:37:31Z",
      "pushed_at": "2026-01-16T12:12:20Z",
      "open_issues": 105,
      "owner": {
        "login": "maplibre",
        "avatar_url": "https://avatars.githubusercontent.com/u/75709127?v=4"
      },
      "readme": "[![Martin](https://raw.githubusercontent.com/maplibre/martin/main/logo.png)](https://maplibre.org/martin/)\n\n[![Book](https://img.shields.io/badge/docs-Book-informational)](https://maplibre.org/martin)\n[![docs.rs docs](https://docs.rs/martin/badge.svg)](https://docs.rs/martin)\n[![](https://img.shields.io/badge/Slack-%23maplibre--martin-blueviolet?logo=slack)](https://slack.openstreetmap.us/)\n[![GitHub](https://img.shields.io/badge/github-maplibre/martin-8da0cb?logo=github)](https://github.com/maplibre/martin)\n[![crates.io version](https://img.shields.io/crates/v/martin.svg)](https://crates.io/crates/martin)\n[![Security audit](https://github.com/maplibre/martin/workflows/Security%20audit/badge.svg)](https://github.com/maplibre/martin/security)\n[![CI build](https://github.com/maplibre/martin/actions/workflows/ci.yml/badge.svg)](https://github.com/maplibre/martin/actions)\n[![Codecov](https://img.shields.io/codecov/c/github/maplibre/martin)](https://app.codecov.io/gh/maplibre/martin)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/11613/badge)](https://www.bestpractices.dev/projects/11613)\n\nMartin is a tile server and a set of tools able to generate vector tiles on the fly\nfrom large `PostgreSQL` databases, and serve tiles from `PMTiles` and `MBTiles` files. Martin optimizes for speed and heavy traffic, and is written in [Rust](https://github.com/rust-lang/rust).\n\n## Features\n\n* Serve [vector tiles](https://github.com/mapbox/vector-tile-spec) from\n  * [PostGIS](https://github.com/postgis/postgis) databases, automatically discovering compatible tables and functions\n  * [PMTile](https://protomaps.com/blog/pmtiles-v3-whats-new), both local files and over HTTP\n  * [MBTile](https://github.com/mapbox/mbtiles-spec) files\n* [Combine](https://maplibre.org/martin/sources-composite.html) multiple tile sources into one\n* Serve [styles](https://maplibre.org/martin/sources-styles.html) and generate [sprites](https://maplibre.org/martin/sources-sprites.html) or [font glyphs](https://maplibre.org/martin/sources-fonts.html) on the fly\n* Generate tiles in bulk from any Martin-supported sources into an `MBTiles` file with [martin-cp](https://maplibre.org/martin/martin-cp.html) tool\n* Examine, copy, validate, compare, and apply diffs between `MBTiles` files with [mbtiles](https://maplibre.org/martin/tools.html#mbtiles) tool\n\n## Documentation\n\n* [Quick Start](https://maplibre.org/martin/quick-start.html)\n* [Installation](https://maplibre.org/martin/installation.html)\n* Running with [CLI](https://maplibre.org/martin/run-with-cli.html)\n  or [configuration file](https://maplibre.org/martin/config-file.html)\n* [Usage and API](https://maplibre.org/martin/using.html)\n\n## Getting Involved\n\nJoin the `#maplibre-martin` slack channel at OSMUS -- automatic invite is at <https://slack.openstreetmap.us/>\n\n## Contributing\n\nLike any open source project, Martin welcomes contributions from anyone who wants to help improve it.\n\n* See [Development Guide](https://maplibre.org/martin/development.html) for setup\n* Use `just help` for common commands\n* Check [help wanted](https://github.com/maplibre/martin/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22) issues\n\n## License\n\nLicensed under either of\n\n* Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n* MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://opensource.org/licenses/MIT>)\n  at your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in the work by you, as defined in the\nApache-2.0 license, shall be dual licensed as above, without any\nadditional terms or conditions.\n",
      "stars_today": 6
    },
    {
      "id": 2055965,
      "name": "swagger-ui",
      "full_name": "swagger-api/swagger-ui",
      "description": "Swagger UI is a collection of HTML, JavaScript, and CSS assets that dynamically generate beautiful documentation from a Swagger-compliant API.",
      "html_url": "https://github.com/swagger-api/swagger-ui",
      "stars": 28530,
      "forks": 9248,
      "language": "JavaScript",
      "topics": [
        "hacktoberfest",
        "oas",
        "open-source",
        "openapi",
        "openapi-specification",
        "openapi3",
        "openapi31",
        "rest",
        "rest-api",
        "swagger",
        "swagger-api",
        "swagger-js",
        "swagger-oss",
        "swagger-ui"
      ],
      "created_at": "2011-07-15T22:56:39Z",
      "updated_at": "2026-01-16T17:32:45Z",
      "pushed_at": "2026-01-14T08:48:02Z",
      "open_issues": 1340,
      "owner": {
        "login": "swagger-api",
        "avatar_url": "https://avatars.githubusercontent.com/u/7658037?v=4"
      },
      "readme": "# <img src=\"https://raw.githubusercontent.com/swagger-api/swagger.io/wordpress/images/assets/SWU-logo-clr.png\" width=\"300\">\n\n[![NPM version](https://badge.fury.io/js/swagger-ui.svg)](http://badge.fury.io/js/swagger-ui)\n[![Build Status](https://jenkins.swagger.io/view/OSS%20-%20JavaScript/job/oss-swagger-ui-master/badge/icon?subject=jenkins%20build)](https://jenkins.swagger.io/view/OSS%20-%20JavaScript/job/oss-swagger-ui-master/)\n[![npm audit](https://jenkins.swagger.io/buildStatus/icon?job=oss-swagger-ui-security-audit&subject=npm%20audit)](https://jenkins.swagger.io/job/oss-swagger-ui-security-audit/lastBuild/console)\n[![total GitHub contributors](https://img.shields.io/github/contributors-anon/swagger-api/swagger-ui.svg)](https://github.com/swagger-api/swagger-ui/graphs/contributors)\n\n[![monthly npm installs](https://img.shields.io/npm/dm/swagger-ui.svg?label=npm%20downloads)](https://www.npmjs.com/package/swagger-ui)\n![docker registry](https://img.shields.io/badge/docker-docker.swagger.io%2Fswaggerapi%2Fswagger--ui-blue)\n![monthly packagist installs](https://img.shields.io/packagist/dm/swagger-api/swagger-ui.svg?label=packagist%20installs)\n[![gzip size](https://img.shields.io/bundlephobia/minzip/swagger-ui.svg?label=gzip%20size)](https://bundlephobia.com/package/swagger-ui)\n\n## Introduction\n[Swagger UI](https://swagger.io/tools/swagger-ui/) allows anyone ‚Äî be it your development team or your end consumers ‚Äî to visualize and interact with the API‚Äôs resources without having any of the implementation logic in place. It‚Äôs automatically generated from your OpenAPI (formerly known as Swagger) Specification, with the visual documentation making it easy for back end implementation and client side consumption.\n\n## General\n**üëâüèº Want to score an easy open-source contribution?** Check out our [Good first issue](https://github.com/swagger-api/swagger-ui/issues?q=is%3Aissue+is%3Aopen+label%3A%22Good+first+issue%22) label.\n\n**üï∞Ô∏è Looking for the older version of Swagger UI?** Refer to the [*2.x* branch](https://github.com/swagger-api/swagger-ui/tree/2.x).\n\n\nThis repository publishes three different NPM modules:\n\n* [swagger-ui](https://www.npmjs.com/package/swagger-ui) is a traditional npm module intended for use in single-page applications that are capable of resolving dependencies (via Webpack, Browserify, etc.).\n* [swagger-ui-dist](https://www.npmjs.com/package/swagger-ui-dist) is a dependency-free module that includes everything you need to serve Swagger UI in a server-side project, or a single-page application that can't resolve npm module dependencies.\n* [swagger-ui-react](https://www.npmjs.com/package/swagger-ui-react) is Swagger UI packaged as a React component for use in React applications.\n\nWe strongly suggest that you use `swagger-ui` instead of `swagger-ui-dist` if you're building a single-page application, since `swagger-ui-dist` is significantly larger.\n\nIf you are looking for plain ol' HTML/JS/CSS, [download the latest release](https://github.com/swagger-api/swagger-ui/releases/latest) and copy the contents of the `/dist` folder to your server.\n\n\n## Compatibility\nThe OpenAPI Specification has undergone 5 revisions since initial creation in 2010.  Compatibility between Swagger UI and the OpenAPI Specification is as follows:\n\n| Swagger UI Version | Release Date | OpenAPI Spec compatibility                           | Notes                                                                 |\n|--------------------|--------------|------------------------------------------------------|-----------------------------------------------------------------------|\n| 5.19.0             | 2025-02-17   | 2.0, 3.0.0, 3.0.1, 3.0.2, 3.0.3, 3.0.4, 3.1.0, 3.1.1 | [tag v5.19.0](https://github.com/swagger-api/swagger-ui/tree/v5.19.0) |\n| 5.0.0              | 2023-06-12   | 2.0, 3.0.0, 3.0.1, 3.0.2, 3.0.3, 3.1.0               | [tag v5.0.0](https://github.com/swagger-api/swagger-ui/tree/v5.0.0)   |\n| 4.0.0              | 2021-11-03   | 2.0, 3.0.0, 3.0.1, 3.0.2, 3.0.3                      | [tag v4.0.0](https://github.com/swagger-api/swagger-ui/tree/v4.0.0)   |\n| 3.18.3             | 2018-08-03   | 2.0, 3.0.0, 3.0.1, 3.0.2, 3.0.3                      | [tag v3.18.3](https://github.com/swagger-api/swagger-ui/tree/v3.18.3) |\n| 3.0.21             | 2017-07-26   | 2.0                                                  | [tag v3.0.21](https://github.com/swagger-api/swagger-ui/tree/v3.0.21) |\n| 2.2.10             | 2017-01-04   | 1.1, 1.2, 2.0                                        | [tag v2.2.10](https://github.com/swagger-api/swagger-ui/tree/v2.2.10) |\n| 2.1.5              | 2016-07-20   | 1.1, 1.2, 2.0                                        | [tag v2.1.5](https://github.com/swagger-api/swagger-ui/tree/v2.1.5)   |\n| 2.0.24             | 2014-09-12   | 1.1, 1.2                                             | [tag v2.0.24](https://github.com/swagger-api/swagger-ui/tree/v2.0.24) |\n| 1.0.13             | 2013-03-08   | 1.1, 1.2                                             | [tag v1.0.13](https://github.com/swagger-api/swagger-ui/tree/v1.0.13) |\n| 1.0.1              | 2011-10-11   | 1.0, 1.1                                             | [tag v1.0.1](https://github.com/swagger-api/swagger-ui/tree/v1.0.1)   |\n\n## Anonymized analytics\n\nSwaggerUI uses [Scarf](https://scarf.sh/) to collect [anonymized installation analytics](https://github.com/scarf-sh/scarf-js?tab=readme-ov-file#as-a-user-of-a-package-using-scarf-js-what-information-does-scarf-js-send-about-me). These analytics help support the maintainers of this library and ONLY run during installation. To [opt out](https://github.com/scarf-sh/scarf-js?tab=readme-ov-file#as-a-user-of-a-package-using-scarf-js-how-can-i-opt-out-of-analytics), you can set the `scarfSettings.enabled` field to `false` in your project's `package.json`:\n\n```\n// package.json\n{\n  // ...\n  \"scarfSettings\": {\n    \"enabled\": false\n  }\n  // ...\n}\n```\n\nAlternatively, you can set the environment variable `SCARF_ANALYTICS` to `false` as part of the environment that installs your npm packages, e.g., `SCARF_ANALYTICS=false npm install`.\n\n## Documentation\n\n#### Usage\n- [Installation](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/installation.md)\n- [Configuration](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/configuration.md)\n- [CORS](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/cors.md)\n- [OAuth2](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/oauth2.md)\n- [Deep Linking](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/deep-linking.md)\n- [Limitations](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/limitations.md)\n- [Version detection](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/usage/version-detection.md)\n\n#### Customization\n- [Overview](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/customization/overview.md)\n- [Plugin API](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/customization/plugin-api.md)\n- [Custom layout](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/customization/custom-layout.md)\n\n#### Development\n- [Setting up](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/development/setting-up.md)\n- [Scripts](https://github.com/swagger-api/swagger-ui/blob/HEAD/docs/development/scripts.md)\n\n#### Contributing\n- [Contributing](https://github.com/swagger-api/.github/blob/HEAD/CONTRIBUTING.md)\n\n##### Integration Tests\n\nYou will need JDK of version 7 or higher as instructed here\nhttps://nightwatchjs.org/guide/getting-started/installation.html#install-selenium-server\n\nIntegration tests can be run locally with `npm run e2e` - be sure you aren't running a dev server when testing!\n\n### Browser support\nSwagger UI works in the latest versions of Chrome, Safari, Firefox, and Edge.\n\n### Known Issues\n\nTo help with the migration, here are the currently known issues with 3.X. This list will update regularly, and will not include features that were not implemented in previous versions.\n\n- Only part of the parameters previously supported are available.\n- The JSON Form Editor is not implemented.\n- Support for `collectionFormat` is partial.\n- l10n (translations) is not implemented.\n- Relative path support for external files is not implemented.\n\n## Security contact\n\nPlease disclose any security-related issues or vulnerabilities by emailing [security@swagger.io](mailto:security@swagger.io), instead of using the public issue tracker.\n\n## License\n\nSwaggerUI is licensed under [Apache 2.0 license](https://github.com/swagger-api/swagger-ui/blob/master/LICENSE).\nSwaggerUI comes with an explicit [NOTICE](https://github.com/swagger-api/swagger-ui/blob/master/NOTICE) file\ncontaining additional legal notices and information.\n",
      "stars_today": 5
    },
    {
      "id": 4524181,
      "name": "folly",
      "full_name": "facebook/folly",
      "description": "An open-source C++ library developed and used at Facebook.",
      "html_url": "https://github.com/facebook/folly",
      "stars": 30213,
      "forks": 5842,
      "language": "C++",
      "topics": [],
      "created_at": "2012-06-01T20:49:04Z",
      "updated_at": "2026-01-16T22:24:26Z",
      "pushed_at": "2026-01-16T22:24:22Z",
      "open_issues": 437,
      "owner": {
        "login": "facebook",
        "avatar_url": "https://avatars.githubusercontent.com/u/69631?v=4"
      },
      "readme": "Folly: Facebook Open-source Library\n===================================\n\n<a href=\"https://opensource.facebook.com/support-ukraine\">\n  <img src=\"https://img.shields.io/badge/Support-Ukraine-FFD500?style=flat&labelColor=005BBB\" alt=\"Support Ukraine - Help Provide Humanitarian Aid to Ukraine.\" />\n</a>\n\n# What is `folly`?\n\n<img src=\"static/logo.svg\" alt=\"Logo Folly\" width=\"15%\" align=\"right\" />\n\nFolly (an acronym loosely after Facebook Open Source Library) is a\nlibrary of C++17 components designed with practicality and efficiency\nin mind. **Folly contains a variety of core library components used extensively\nat Facebook**. In particular, it's often a dependency of Facebook's other\nopen source C++ efforts and place where those projects can share code.\n\nIt complements (as opposed to competing against) offerings\nsuch as Boost and of course `std`. In fact, we embark on defining our\nown component only when something we need is either not available, or\ndoes not meet the needed performance profile. We endeavor to remove\nthings from folly if or when `std` or Boost obsoletes them.\n\nPerformance concerns permeate much of Folly, sometimes leading to\ndesigns that are more idiosyncratic than they would otherwise be (see\ne.g. `PackedSyncPtr.h`, `SmallLocks.h`). Good performance at large\nscale is a unifying theme in all of Folly.\n\n## Check it out in the intro video\n[![Explain Like I‚Äôm 5: Folly](https://img.youtube.com/vi/Wr_IfOICYSs/0.jpg)](https://www.youtube.com/watch?v=Wr_IfOICYSs)\n\n# Logical Design\n\nFolly is a collection of relatively independent components, some as\nsimple as a few symbols. There is no restriction on internal\ndependencies, meaning that a given folly module may use any other\nfolly components.\n\nAll symbols are defined in the top-level namespace `folly`, except of\ncourse macros. Macro names are ALL_UPPERCASE and should be prefixed\nwith `FOLLY_`. Namespace `folly` defines other internal namespaces\nsuch as `internal` or `detail`. User code should not depend on symbols\nin those namespaces.\n\n# Physical Design\n\nAt the top level Folly uses the classic \"stuttering\" scheme\n`folly/folly` used by Boost and others. The first directory serves as\nan installation root of the library (with possible versioning a la\n`folly-1.0/`), and the second is to distinguish the library when\nincluding files, e.g. `#include <folly/FBString.h>`.\n\nThe directory structure is flat (mimicking the namespace structure),\ni.e. we don't have an elaborate directory hierarchy (it is possible\nthis will change in future versions). The subdirectory `experimental`\ncontains files that are used inside folly and possibly at Facebook but\nnot considered stable enough for client use. Your code should not use\nfiles in `folly/experimental` lest it may break when you update Folly.\n\nThe `folly/folly/test` subdirectory includes the unittests for all\ncomponents, usually named `ComponentXyzTest.cpp` for each\n`ComponentXyz.*`. The `folly/folly/docs` directory contains\ndocumentation.\n\n# What's in it?\n\nBecause of folly's fairly flat structure, the best way to see what's in it\nis to look at the headers in [top level `folly/` directory](https://github.com/facebook/folly/tree/main/folly). You can also\ncheck the [`docs` folder](folly/docs) for documentation, starting with the\n[overview](folly/docs/Overview.md).\n\nFolly is published on GitHub at https://github.com/facebook/folly.\n\n# Build Notes\n\nBecause folly does not provide any ABI compatibility guarantees from commit to\ncommit, we generally recommend building folly as a static library.\n\nfolly supports gcc (5.1+), clang, or MSVC. It should run on Linux (x86-32,\nx86-64, and ARM), iOS, macOS, and Windows (x86-64). The CMake build is only\ntested on some of these platforms; at a minimum, we aim to support macOS and\nLinux (on the latest Ubuntu LTS release or newer.)\n\n## `getdeps.py`\n\nThis script is used by many of Meta's OSS tools.  It will download and build all of the necessary dependencies first, and will then invoke cmake etc to build folly.  This will help ensure that you build with relevant versions of all of the dependent libraries, taking into account what versions are installed locally on your system.\n\nIt's written in python so you'll need python3.6 or later on your PATH.  It works on Linux, macOS and Windows.\n\nThe settings for folly's cmake build are held in its getdeps manifest `build/fbcode_builder/manifests/folly`, which you can edit locally if desired.\n\n### Dependencies\n\nIf on Linux or MacOS (with homebrew installed) you can install system dependencies to save building them:\n\n    # Clone the repo\n    git clone https://github.com/facebook/folly\n    # Install dependencies\n    cd folly\n    sudo ./build/fbcode_builder/getdeps.py install-system-deps --recursive\n\nIf you'd like to see the packages before installing them:\n\n    ./build/fbcode_builder/getdeps.py install-system-deps --dry-run --recursive\n\nOn other platforms or if on Linux and without system dependencies `getdeps.py` will mostly download and build them for you during the build step.\n\nSome of the dependencies `getdeps.py` uses and installs are:\n\n  * a version of boost compiled with C++14 support.\n  * googletest is required to build and run folly's tests.\n\n### Build\n\nThis script will download and build all of the necessary dependencies first,\nand will then invoke cmake etc to build folly.  This will help ensure that you build with relevant versions of all of the dependent libraries, taking into account what versions are installed locally on your system.\n\n`getdeps.py` currently requires python 3.6+ to be on your path.\n\n`getdeps.py` will invoke cmake etc.\n\n    # Clone the repo\n    git clone https://github.com/facebook/folly\n    cd folly\n    # Build, using system dependencies if available\n    python3 ./build/fbcode_builder/getdeps.py --allow-system-packages build\n\nIt puts output in its scratch area:\n\n  * `installed/folly/lib/libfolly.a`: Library\n\nYou can also specify a `--scratch-path` argument to control\nthe location of the scratch directory used for the build. You can find the default scratch install location from logs or with `python3 ./build/fbcode_builder/getdeps.py show-inst-dir`.\n\nThere are also\n`--install-dir` and `--install-prefix` arguments to provide some more\nfine-grained control of the installation directories. However, given that\nfolly provides no compatibility guarantees between commits we generally\nrecommend building and installing the libraries to a temporary location, and\nthen pointing your project's build at this temporary location, rather than\ninstalling folly in the traditional system installation directories. e.g., if you are building with CMake you can use the `CMAKE_PREFIX_PATH` variable to allow CMake to find folly in this temporary installation directory when\nbuilding your project.\n\nIf you want to invoke `cmake` again to iterate, there is a helpful `run_cmake.py` script output in the scratch build directory.  You can find the scratch build directory from logs or with `python3 ./build/fbcode_builder/getdeps.py show-build-dir`.\n\n### Run tests\n\nBy default `getdeps.py` will build the tests for folly. To run them:\n\n    cd folly\n    python3 ./build/fbcode_builder/getdeps.py --allow-system-packages test\n\n### `build.sh`/`build.bat` wrapper\n\n`build.sh` can be used on Linux and MacOS, on Windows use\nthe `build.bat` script instead. Its a wrapper around `getdeps.py`.\n\n## Build with cmake directly\n\nIf you don't want to let getdeps invoke cmake for you then by default, building the tests is disabled as part of the CMake `all` target.\nTo build the tests, specify `-DBUILD_TESTS=ON` to CMake at configure time.\n\nNB if you want to invoke `cmake` again to iterate on a `getdeps.py` build, there is a helpful `run_cmake.py` script output in the scratch-path build directory. You can find the scratch build directory from logs or with `python3 ./build/fbcode_builder/getdeps.py show-build-dir`.\n\nRunning tests with ctests also works if you cd to the build dir, e.g.\n`(cd $(python3 ./build/fbcode_builder/getdeps.py show-build-dir) && ctest)`\n\n### Finding dependencies in non-default locations\n\nIf you have boost, gtest, or other dependencies installed in a non-default\nlocation, you can use the `CMAKE_INCLUDE_PATH` and `CMAKE_LIBRARY_PATH`\nvariables to make CMAKE look also look for header files and libraries in\nnon-standard locations.  For example, to also search the directories\n`/alt/include/path1` and `/alt/include/path2` for header files and the\ndirectories `/alt/lib/path1` and `/alt/lib/path2` for libraries, you can invoke\n`cmake` as follows:\n\n```\ncmake \\\n  -DCMAKE_INCLUDE_PATH=/alt/include/path1:/alt/include/path2 \\\n  -DCMAKE_LIBRARY_PATH=/alt/lib/path1:/alt/lib/path2 ...\n```\n\n## Ubuntu LTS, CentOS Stream, Fedora\n\nUse the `getdeps.py` approach above. We test in CI on Ubuntu LTS, and occasionally on other distros.\n\nIf you find the set of system packages is not quite right for your chosen distro, you can specify distro version specific overrides in the dependency manifests (e.g. https://github.com/facebook/folly/blob/main/build/fbcode_builder/manifests/boost ). You could probably make it work on most recent Ubuntu/Debian or Fedora/Redhat derived distributions.\n\nAt time of writing (Dec 2021) there is a build break on GCC 11.x based systems in lang_badge_test.  If you don't need badge functionality you can work around by commenting it out from CMakeLists.txt (unfortunately fbthrift does need it)\n\n## Windows (Vcpkg)\n\nNote that many tests are disabled for folly Windows builds, you can see them in the log from the cmake configure step, or by looking for WINDOWS_DISABLED in `CMakeLists.txt`\n\nThat said, `getdeps.py` builds work on Windows and are tested in CI.\n\nIf you prefer, you can try Vcpkg. folly is available in [Vcpkg](https://github.com/Microsoft/vcpkg#vcpkg) and releases may be built via `vcpkg install folly:x64-windows`.\n\nYou may also use `vcpkg install folly:x64-windows --head` to build against `main`.\n\n## macOS\n\n`getdeps.py` builds work on macOS and are tested in CI, however if you prefer, you can try one of the macOS package managers\n\n### Homebrew\n\nfolly is available as a Formula and releases may be built via `brew install folly`.\n\nYou may also use `folly/build/bootstrap-osx-homebrew.sh` to build against `main`:\n\n```\n  ./folly/build/bootstrap-osx-homebrew.sh\n```\n\nThis will create a build directory `_build` in the top-level.\n\n### MacPorts\n\nInstall the required packages from MacPorts:\n\n```\n  sudo port install \\\n    boost \\\n    cmake \\\n    gflags \\\n    git \\\n    google-glog \\\n    libevent \\\n    libtool \\\n    lz4 \\\n    lzma \\\n    openssl \\\n    snappy \\\n    xz \\\n    zlib\n```\n\nDownload and install double-conversion:\n\n```\n  git clone https://github.com/google/double-conversion.git\n  cd double-conversion\n  cmake -DBUILD_SHARED_LIBS=ON .\n  make\n  sudo make install\n```\n\nDownload and install folly with the parameters listed below:\n\n```\n  git clone https://github.com/facebook/folly.git\n  cd folly\n  mkdir _build\n  cd _build\n  cmake ..\n  make\n  sudo make install\n```\n",
      "stars_today": 5
    },
    {
      "id": 334274271,
      "name": "OpenSearch",
      "full_name": "opensearch-project/OpenSearch",
      "description": "üîé Open source distributed and RESTful search engine.",
      "html_url": "https://github.com/opensearch-project/OpenSearch",
      "stars": 12220,
      "forks": 2376,
      "language": "Java",
      "topics": [
        "analytics",
        "apache2",
        "foss",
        "java",
        "search",
        "search-engine"
      ],
      "created_at": "2021-01-29T22:10:00Z",
      "updated_at": "2026-01-16T21:56:59Z",
      "pushed_at": "2026-01-16T15:54:13Z",
      "open_issues": 2529,
      "owner": {
        "login": "opensearch-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/80134844?v=4"
      },
      "readme": "<a href=\"https://opensearch.org/\">\n  <img src=\"https://opensearch.org/assets/img/opensearch-logo-themed.svg\" height=\"64px\">\n</a>\n\n[![License](https://img.shields.io/badge/license-Apache%20v2-blue.svg)](https://github.com/opensearch-project/OpenSearch/blob/main/LICENSE.txt)\n[![LFX Health Score](https://insights.linuxfoundation.org/api/badge/health-score?project=opensearch-foundation)](https://insights.linuxfoundation.org/project/opensearch-foundation)\n[![LFX Active Contributors](https://insights.linuxfoundation.org/api/badge/active-contributors?project=opensearch-foundation)](https://insights.linuxfoundation.org/project/opensearch-foundation)\n[![Code Coverage](https://codecov.io/gh/opensearch-project/OpenSearch/branch/main/graph/badge.svg)](https://codecov.io/gh/opensearch-project/OpenSearch)\n![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/opensearch-project/OpenSearch?sort=semver)\n[![Linkedin](https://img.shields.io/badge/Follow-Linkedin-blue)](https://www.linkedin.com/company/opensearch-project)\n\n- [Welcome!](#welcome)\n- [Project Resources](#project-resources)\n- [Code of Conduct](#code-of-conduct)\n- [Security](#security)\n- [License](#license)\n- [Copyright](#copyright)\n- [Trademark](#trademark)\n\n## Welcome!\n\nOpenSearch is an open-source, enterprise-grade search and observability suite that brings order to unstructured data at scale.\n\n## Project Resources\n\n* [Project Website](https://opensearch.org/)\n* [Downloads](https://opensearch.org/downloads/)\n* [Documentation](https://docs.opensearch.org/)\n* Need help? Try [Forums](https://discuss.opendistrocommunity.dev/) or [Slack](https://opensearch.org/slack/)\n* [Contributing to OpenSearch](CONTRIBUTING.md)\n* [Maintainer Responsibilities](MAINTAINERS.md)\n* [Release Management](RELEASING.md)\n* [Admin Responsibilities](ADMINS.md)\n* [Testing](TESTING.md)\n* [Security](SECURITY.md)\n\n## Code of Conduct\n\nThe project's [Code of Conduct](CODE_OF_CONDUCT.md) outlines our expectations for all participants in our community, based on the [OpenSearch Code of Conduct](https://opensearch.org/code-of-conduct/). Please contact [conduct@opensearch.foundation](mailto:conduct@opensearch.foundation) with any additional questions or comments.\n\n## Security\nIf you discover a potential security issue in this project we ask that you notify OpenSearch Security directly via email to security@opensearch.org. Please do **not** create a public GitHub issue.\n\n## License\n\nThis project is licensed under the [Apache v2.0 License](LICENSE.txt).\n\n## Copyright\n\nCopyright OpenSearch Contributors. See [NOTICE](NOTICE.txt) for details.\n\n## Trademark\n\nOpenSearch is a registered trademark of LF Projects, LLC.\n\nOpenSearch includes certain Apache-licensed Elasticsearch code from Elasticsearch B.V. and other source code. Elasticsearch B.V. is not the source of that other source code. ELASTICSEARCH is a registered trademark of Elasticsearch B.V.\n\n",
      "stars_today": 5
    },
    {
      "id": 158256479,
      "name": "iceberg",
      "full_name": "apache/iceberg",
      "description": "Apache Iceberg",
      "html_url": "https://github.com/apache/iceberg",
      "stars": 8440,
      "forks": 2969,
      "language": "Java",
      "topics": [
        "apache",
        "hacktoberfest",
        "iceberg"
      ],
      "created_at": "2018-11-19T16:26:46Z",
      "updated_at": "2026-01-16T19:29:36Z",
      "pushed_at": "2026-01-16T17:52:55Z",
      "open_issues": 541,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\n  - Licensed to the Apache Software Foundation (ASF) under one\n  - or more contributor license agreements.  See the NOTICE file\n  - distributed with this work for additional information\n  - regarding copyright ownership.  The ASF licenses this file\n  - to you under the Apache License, Version 2.0 (the\n  - \"License\"); you may not use this file except in compliance\n  - with the License.  You may obtain a copy of the License at\n  -\n  -   http://www.apache.org/licenses/LICENSE-2.0\n  -\n  - Unless required by applicable law or agreed to in writing,\n  - software distributed under the License is distributed on an\n  - \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n  - KIND, either express or implied.  See the License for the\n  - specific language governing permissions and limitations\n  - under the License.\n  -->\n\n![Iceberg](https://iceberg.apache.org/assets/images/Iceberg-logo.svg)\n\n[![](https://github.com/apache/iceberg/actions/workflows/java-ci.yml/badge.svg)](https://github.com/apache/iceberg/actions/workflows/java-ci.yml)\n[![Slack](https://img.shields.io/badge/chat-on%20Slack-brightgreen.svg)](https://apache-iceberg.slack.com/)\n\nIceberg is a high-performance format for huge analytic tables. Iceberg brings the reliability and simplicity of SQL tables to big data, while making it possible for engines like Spark, Trino, Flink, Presto, Hive and Impala to safely work with the same tables, at the same time.\n\nBackground and documentation is available at <https://iceberg.apache.org>\n\n\n## Status\n\nIceberg is under active development at the Apache Software Foundation.\n\nThe [Iceberg format specification][iceberg-spec] is stable and new features are added with each version.\n\nThe core Java library is located in this repository and is the reference implementation for other libraries.\n\n[Documentation][iceberg-docs] is available for all libraries and integrations.\n\n[iceberg-docs]: https://iceberg.apache.org/docs/latest/\n[iceberg-spec]: https://iceberg.apache.org/spec/\n\n## Collaboration\n\nIceberg tracks issues in GitHub and prefers to receive contributions as pull requests.\n\nCommunity discussions happen primarily on the [dev mailing list][dev-list] or on specific issues.\n\n[dev-list]: mailto:dev@iceberg.apache.org\n\n\n### Building\n\nIceberg is built using Gradle with Java 17 or 21.\n\n* To invoke a build and run tests: `./gradlew build`\n* To skip tests: `./gradlew build -x test -x integrationTest`\n* To fix code style for default versions: `./gradlew spotlessApply`\n* To fix code style for all versions of Spark/Hive/Flink:`./gradlew spotlessApply -DallModules`\n\nIceberg table support is organized in library modules:\n\n* `iceberg-common` contains utility classes used in other modules\n* `iceberg-api` contains the public Iceberg API\n* `iceberg-core` contains implementations of the Iceberg API and support for Avro data files, **this is what processing engines should depend on**\n* `iceberg-parquet` is an optional module for working with tables backed by Parquet files\n* `iceberg-arrow` is an optional module for reading Parquet into Arrow memory\n* `iceberg-orc` is an optional module for working with tables backed by ORC files\n* `iceberg-hive-metastore` is an implementation of Iceberg tables backed by the Hive metastore Thrift client\n* `iceberg-data` is an optional module for working with tables directly from JVM applications\n\nIceberg also has modules for adding Iceberg support to processing engines:\n\n* `iceberg-spark` is an implementation of Spark's Datasource V2 API for Iceberg with submodules for each spark versions (use [runtime jars](https://iceberg.apache.org/multi-engine-support/#runtime-jar) for a shaded version to avoid dependency conflicts)\n* `iceberg-flink` contains classes for integrating with Apache Flink (use [iceberg-flink-runtime](https://iceberg.apache.org/multi-engine-support/#runtime-jar) for a shaded version)\n* `iceberg-mr` contains an InputFormat and other classes for integrating with Apache Hive\n\n---\n**NOTE**\n\nThe tests require Docker to execute. On macOS (with Docker Desktop), you might need to create a symbolic name to the docker socket in order to be detected by the tests:\n\n```\nsudo ln -s $HOME/.docker/run/docker.sock /var/run/docker.sock\n```\n\nIn some cases the testcontainer may exit with an initialization error because of an illegal state exception in the GenericContainer.  One work around for this problem is to set `selinux` into permissive mode before running the tests. \n\n```\nsudo setenforce Permissive\n./gradlew ...\nsudo setenforce Enforcing\n```\n\n---\n\n### Engine Compatibility\n\nSee the [Multi-Engine Support](https://iceberg.apache.org/multi-engine-support/) page to know about Iceberg compatibility with different Spark, Flink and Hive versions.\nFor other engines such as Presto or Trino, please visit their websites for Iceberg integration details.\n\n### Implementations\n\nThis repository contains the Java implementation of Iceberg. Other implementations can be found at:\n\n* **Go**: [iceberg-go](https://github.com/apache/iceberg-go)\n* **PyIceberg** (Python): [iceberg-python](https://github.com/apache/iceberg-python)\n* **Rust**: [iceberg-rust](https://github.com/apache/iceberg-rust)\n* **C++**: [iceberg-cpp](https://github.com/apache/iceberg-cpp)\n",
      "stars_today": 5
    },
    {
      "id": 89033556,
      "name": "firebase-ios-sdk",
      "full_name": "firebase/firebase-ios-sdk",
      "description": "Firebase SDK for Apple App Development",
      "html_url": "https://github.com/firebase/firebase-ios-sdk",
      "stars": 6488,
      "forks": 1712,
      "language": "C++",
      "topics": [
        "ai",
        "analytics",
        "authentication",
        "crash-reporting",
        "database",
        "database-as-a-service",
        "firebase",
        "firebase-auth",
        "firebase-authentication",
        "firebase-database",
        "firebase-messaging",
        "firebase-storage",
        "gemini",
        "ios-sdk",
        "objective-c",
        "push-notifications",
        "storage-service"
      ],
      "created_at": "2017-04-22T00:26:50Z",
      "updated_at": "2026-01-16T22:13:41Z",
      "pushed_at": "2026-01-16T23:29:30Z",
      "open_issues": 420,
      "owner": {
        "login": "firebase",
        "avatar_url": "https://avatars.githubusercontent.com/u/1335026?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://cocoapods.org/pods/Firebase\">\n    <img src=\"https://img.shields.io/github/v/release/Firebase/firebase-ios-sdk?style=flat&label=CocoaPods\"/>\n  </a>\n  <a href=\"https://swiftpackageindex.com/firebase/firebase-ios-sdk\">\n    <img src=\"https://img.shields.io/github/v/release/Firebase/firebase-ios-sdk?style=flat&label=Swift%20Package%20Index&color=red\"/>\n  </a>\n  <a href=\"https://cocoapods.org/pods/Firebase\">\n    <img src=\"https://img.shields.io/github/license/Firebase/firebase-ios-sdk?style=flat\"/>\n  </a><br/>\n  <a href=\"https://swiftpackageindex.com/firebase/firebase-ios-sdk\">\n    <img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Ffirebase%2Ffirebase-ios-sdk%2Fbadge%3Ftype%3Dplatforms\"/>\n  </a>\n  <a href=\"https://swiftpackageindex.com/firebase/firebase-ios-sdk\">\n    <img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Ffirebase%2Ffirebase-ios-sdk%2Fbadge%3Ftype%3Dswift-versions\"/>\n  </a>\n</p>\n\n# Firebase Apple Open Source Development\n\nThis repository contains the source code for all Apple platform Firebase SDKs except FirebaseAnalytics.\n\nFirebase is an app development platform with tools to help you build, grow, and\nmonetize your app. More information about Firebase can be found on the\n[official Firebase website](https://firebase.google.com).\n\n## Installation\n\nSee the subsections below for details about the different installation methods. Where\navailable, it's recommended to install any libraries with a `Swift` suffix to get the\nbest experience when writing your app in Swift.\n\n1. [Standard pod install](#standard-pod-install)\n2. [Swift Package Manager](#swift-package-manager)\n3. [Installing from the GitHub repo](#installing-from-github)\n4. [Experimental Carthage](#carthage-ios-only)\n\n### Standard pod install\n\nFor instructions on the standard pod install, visit:\n[https://firebase.google.com/docs/ios/setup](https://firebase.google.com/docs/ios/setup).\n\n### Swift Package Manager\n\nInstructions for [Swift Package Manager](https://swift.org/package-manager/) support can be\nfound in the [SwiftPackageManager.md](SwiftPackageManager.md) Markdown file.\n\n### Installing from GitHub\n\nThese instructions can be used to access the Firebase repo at other branches,\ntags, or commits.\n\n#### Background\n\nSee [the Podfile Syntax Reference](https://guides.cocoapods.org/syntax/podfile.html#pod)\nfor instructions and options about overriding pod source locations.\n\n#### Accessing Firebase Source Snapshots\n\nAll official releases are tagged in this repo and available via CocoaPods. To access a local\nsource snapshot or unreleased branch, use Podfile directives like the following:\n\nTo access FirebaseFirestore via a branch:\n```ruby\npod 'FirebaseCore', :git => 'https://github.com/firebase/firebase-ios-sdk.git', :branch => 'main'\npod 'FirebaseFirestore', :git => 'https://github.com/firebase/firebase-ios-sdk.git', :branch => 'main'\n```\n\nTo access FirebaseMessaging via a checked-out version of the firebase-ios-sdk repo:\n```ruby\npod 'FirebaseCore', :path => '/path/to/firebase-ios-sdk'\npod 'FirebaseMessaging', :path => '/path/to/firebase-ios-sdk'\n```\n\n### Carthage (iOS only)\n\nInstructions for the experimental Carthage distribution can be found at\n[Carthage.md](Carthage.md).\n\n### Using Firebase from a Framework or a library\n\nFor details on using Firebase from a Framework or a library, refer to [firebase_in_libraries.md](docs/firebase_in_libraries.md).\n\n## Development\n\nTo develop Firebase software in this repository, ensure that you have at least\nthe following software:\n\n* Xcode 16.2 (or later)\n\nCocoaPods is still the canonical way to develop, but much of the repo now supports\ndevelopment with Swift Package Manager.\n\n### CocoaPods\n\nInstall the following:\n* CocoaPods 1.12.0 (or later)\n* [CocoaPods generate](https://github.com/square/cocoapods-generate)\n\nFor the pod that you want to develop:\n\n```ruby\npod gen Firebase{name here}.podspec --local-sources=./ --auto-open --platforms=ios\n```\n\nNote: If the CocoaPods cache is out of date, you may need to run\n`pod repo update` before the `pod gen` command.\n\nNote: Set the `--platforms` option to `macos` or `tvos` to develop/test for\nthose platforms. Since 10.2, Xcode does not properly handle multi-platform\nCocoaPods workspaces.\n\nFirestore has a self-contained Xcode project. See\n[Firestore/README](Firestore/README.md) Markdown file.\n\n#### Development for Catalyst\n* `pod gen {name here}.podspec --local-sources=./ --auto-open --platforms=ios`\n* Check the Mac box in the App-iOS Build Settings\n* Sign the App in the Settings Signing & Capabilities tab\n* Click Pods in the Project Manager\n* Add Signing to the iOS host app and unit test targets\n* Select the Unit-unit scheme\n* Run it to build and test\n\nAlternatively, disable signing in each target:\n* Go to Build Settings tab\n* Click `+`\n* Select `Add User-Defined Setting`\n* Add `CODE_SIGNING_REQUIRED` setting with a value of `NO`\n\n### Swift Package Manager\n* To enable test schemes: `./scripts/setup_spm_tests.sh`\n* `open Package.swift` or double click `Package.swift` in Finder.\n* Xcode will open the project\n  * Choose a scheme for a library to build or test suite to run\n  * Choose a target platform by selecting the run destination along with the scheme\n\n### Adding a New Firebase Pod\n\nRefer to [AddNewPod](docs/AddNewPod.md) Markdown file for details.\n\n### Managing Headers and Imports\n\nFor information about managing headers and imports, see [HeadersImports](HeadersImports.md) Markdown file.\n\n### Code Formatting\n\nTo ensure that the code is formatted consistently, run the script\n[./scripts/check.sh](https://github.com/firebase/firebase-ios-sdk/blob/main/scripts/check.sh)\nbefore creating a pull request (PR).\n\nGitHub Actions will verify that any code changes are done in a style-compliant\nway. Install `clang-format` and `mint`:\n\n```console\nbrew install clang-format@21\nbrew install mint\n```\n\n### Running Unit Tests\n\nSelect a scheme and press Command-u to build a component and run its unit tests.\n\n### Running Sample Apps\nTo run the sample apps and integration tests, you'll need a valid\n`GoogleService-Info.plist\n` file. The Firebase Xcode project contains dummy plist\nfiles without real values, but they can be replaced with real plist files. To get your own\n`GoogleService-Info.plist` files:\n\n1. Go to the [Firebase Console](https://console.firebase.google.com/)\n2. Create a new Firebase project, if you don't already have one\n3. For each sample app you want to test, create a new Firebase app with the sample app's bundle\nidentifier (e.g., `com.google.Database-Example`)\n4. Download the resulting `GoogleService-Info.plist` and add it to the Xcode project.\n\n### Coverage Report Generation\n\nFor coverage report generation instructions, see [scripts/code_coverage_report/README](scripts/code_coverage_report/README.md) Markdown file.\n\n## Specific Component Instructions\nSee the sections below for any special instructions for those components.\n\n### Firebase AI Logic\n\nSee the [Firebase AI Logic README](FirebaseAI#development) for instructions\nabout building and testing the SDK.\n\n### Firebase Auth\n\nFor specific Firebase Auth development, refer to the [Auth Sample README](FirebaseAuth/Tests/Sample/README.md) for instructions about\nbuilding and running the FirebaseAuth pod along with various samples and tests.\n\n### Firebase Database\n\nThe Firebase Database Integration tests can be run against a locally running Database Emulator\nor against a production instance.\n\nTo run against a local emulator instance, invoke `./scripts/run_database_emulator.sh start` before\nrunning the integration test.\n\nTo run against a production instance, provide a valid `GoogleServices-Info.plist` and copy it to\n`FirebaseDatabase/Tests/Resources/GoogleService-Info.plist`. Your Security Rule must be set to\n[public](https://firebase.google.com/docs/database/security/quickstart) while your tests are\nrunning.\n\n### Firebase Dynamic Links\n\nFirebase Dynamic Links is **deprecated** and should not be used in new projects. The service will shut down on August 25, 2025.\n\nPlease see our [Dynamic Links Deprecation FAQ documentation](https://firebase.google.com/support/dynamic-links-faq) for more guidance.\n\n### Firebase Performance Monitoring\n\nFor specific Firebase Performance Monitoring development, see\n[the Performance README](FirebasePerformance/README.md) for instructions about building the SDK\nand [the Performance TestApp README](FirebasePerformance/Tests/TestApp/README.md) for instructions about\nintegrating Performance with the dev test App.\n\n### Firebase Storage\n\nTo run the Storage Integration tests, follow the instructions in\n[StorageIntegration.swift](FirebaseStorage/Tests/Integration/StorageIntegration.swift).\n\n#### Push Notifications\n\nPush notifications can only be delivered to specially provisioned App IDs in the developer portal.\nIn order to test receiving push notifications, you will need to:\n\n1. Change the bundle identifier of the sample app to something you own in your Apple Developer\naccount and enable that App ID for push notifications.\n2. You'll also need to\n[upload your APNs Provider Authentication Key or certificate to the\nFirebase Console](https://firebase.google.com/docs/cloud-messaging/ios/certs)\nat **Project Settings > Cloud Messaging > [Your Firebase App]**.\n3. Ensure your iOS device is added to your Apple Developer portal as a test device.\n\n#### iOS Simulator\n\nThe iOS Simulator cannot register for remote notifications and will not receive push notifications.\nTo receive push notifications, follow the steps above and run the app on a physical device.\n\n## Building with Firebase on Apple platforms\n\nFirebase provides official beta support for macOS, Catalyst, and tvOS. visionOS and watchOS\nare community supported. Thanks to community contributions for many of the multi-platform PRs.\n\nAt this time, most of Firebase's products are available across Apple platforms. There are still\na few gaps, especially on visionOS and watchOS. For details about the current support matrix, see\n[this chart](https://firebase.google.com/docs/ios/learn-more#firebase_library_support_by_platform)\nin Firebase's documentation.\n\n### visionOS\n\nWhere supported, visionOS works as expected with the exception of Firestore via Swift Package\nManager where it is required to use the source distribution.\n\nTo enable the Firestore source distribution, quit Xcode and open the desired\nproject from the command line with the `FIREBASE_SOURCE_FIRESTORE` environment\nvariable: `open --env FIREBASE_SOURCE_FIRESTORE /path/to/project.xcodeproj`.\nTo go back to using the binary distribution of Firestore, quit Xcode and open\nXcode like normal, without the environment variable.\n\n### watchOS\nThanks to contributions from the community, many of Firebase SDKs now compile, run unit tests, and\nwork on watchOS. See the [Independent Watch App Sample](Example/watchOSSample).\n\nKeep in mind that watchOS is not officially supported by Firebase. While we can catch basic unit\ntest issues with GitHub Actions, there may be some changes where the SDK no longer works as expected\non watchOS. If you encounter this, please\n[file an issue](https://github.com/firebase/firebase-ios-sdk/issues).\n\nDuring app setup in the console, you may get to a step that mentions something like \"Checking if the\napp has communicated with our servers\". This relies on Analytics and will not work on watchOS.\n**It's safe to ignore the message and continue**, the rest of the SDKs will work as expected.\n\n#### Additional Crashlytics Notes\n* watchOS has limited support. Due to watchOS restrictions, mach exceptions and signal crashes are\nnot recorded. (Crashes in SwiftUI are generated as mach exceptions, so will not be recorded)\n\n## Combine\nThanks to contributions from the community, _FirebaseCombineSwift_ contains support for Apple's Combine\nframework. This module is currently under development and not yet supported for use in production\nenvironments. For more details, please refer to the [docs](FirebaseCombineSwift/README.md).\n\n## Roadmap\n\nSee [Roadmap](ROADMAP.md) for more about the Firebase Apple SDK Open Source\nplans and directions.\n\n## Contributing\n\nSee [Contributing](CONTRIBUTING.md) for more information on contributing to the Firebase\nApple SDK.\n\n## License\n\nThe contents of this repository are licensed under the\n[Apache License, version 2.0](http://www.apache.org/licenses/LICENSE-2.0).\n\nYour use of Firebase is governed by the\n[Terms of Service for Firebase Services](https://firebase.google.com/terms/).\n",
      "stars_today": 5
    },
    {
      "id": 113404957,
      "name": "kata-containers",
      "full_name": "kata-containers/kata-containers",
      "description": "Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs. https://katacontainers.io/",
      "html_url": "https://github.com/kata-containers/kata-containers",
      "stars": 7286,
      "forks": 1241,
      "language": "Rust",
      "topics": [
        "acrn",
        "containers",
        "cri",
        "cri-o",
        "docker",
        "firecracker",
        "k8s",
        "kubernetes",
        "kvm",
        "oci",
        "qemu",
        "security",
        "virtual-machine",
        "virtualization"
      ],
      "created_at": "2017-12-07T05:01:12Z",
      "updated_at": "2026-01-17T00:34:46Z",
      "pushed_at": "2026-01-16T15:41:38Z",
      "open_issues": 1695,
      "owner": {
        "login": "kata-containers",
        "avatar_url": "https://avatars.githubusercontent.com/u/33289952?v=4"
      },
      "readme": "<img src=\"https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/6e4619c416ff4bd19e1c087f27a43eea/www-images-prod/openstack-logo/kata/SVG/kata-1.svg\" width=\"900\">\n\n[![CI | Publish Kata Containers payload](https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml/badge.svg)](https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml) [![Kata Containers Nightly CI](https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml/badge.svg)](https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/kata-containers/kata-containers/badge)](https://scorecard.dev/viewer/?uri=github.com/kata-containers/kata-containers)\n\n# Kata Containers\n\nWelcome to Kata Containers!\n\nThis repository is the home of the Kata Containers code for the 2.0 and newer\nreleases.\n\nIf you want to learn about Kata Containers, visit the main\n[Kata Containers website](https://katacontainers.io).\n\n## Introduction\n\nKata Containers is an open source project and community working to build a\nstandard implementation of lightweight Virtual Machines (VMs) that feel and\nperform like containers, but provide the workload isolation and security\nadvantages of VMs.\n\n## License\n\nThe code is licensed under the Apache 2.0 license.\nSee [the license file](LICENSE) for further details.\n\n## Platform support\n\nKata Containers currently runs on 64-bit systems supporting the following\ntechnologies:\n\n| Architecture | Virtualization technology |\n|-|-|\n| `x86_64`, `amd64` | [Intel](https://www.intel.com) VT-x, AMD SVM |\n| `aarch64` (\"`arm64`\")| [ARM](https://www.arm.com) Hyp |\n| `ppc64le` | [IBM](https://www.ibm.com) Power |\n| `s390x` | [IBM](https://www.ibm.com) Z & LinuxONE SIE |\n\n### Hardware requirements\n\nThe [Kata Containers runtime](src/runtime) provides a command to\ndetermine if your host system is capable of running and creating a\nKata Container:\n\n```bash\n$ kata-runtime check\n```\n\n> **Notes:**\n>\n> - This command runs a number of checks including connecting to the\n>   network to determine if a newer release of Kata Containers is\n>   available on GitHub. If you do not wish this to check to run, add\n>   the `--no-network-checks` option.\n>\n> - By default, only a brief success / failure message is printed.\n>   If more details are needed, the `--verbose` flag can be used to display the\n>   list of all the checks performed.\n>\n> - If the command is run as the `root` user additional checks are\n>   run (including checking if another incompatible hypervisor is running).\n>   When running as `root`, network checks are automatically disabled.\n\n## Getting started\n\nSee the [installation documentation](docs/install).\n\n## Documentation\n\nSee the [official documentation](docs) including:\n\n- [Installation guides](docs/install)\n- [Developer guide](docs/Developer-Guide.md)\n- [Design documents](docs/design)\n  - [Architecture overview](docs/design/architecture)\n  - [Architecture 3.0 overview](docs/design/architecture_3.0/)\n\n## Configuration\n\nKata Containers uses a single\n[configuration file](src/runtime/README.md#configuration)\nwhich contains a number of sections for various parts of the Kata\nContainers system including the [runtime](src/runtime), the\n[agent](src/agent) and the [hypervisor](#hypervisors).\n\n## Hypervisors\n\nSee the [hypervisors document](docs/hypervisors.md) and the\n[Hypervisor specific configuration details](src/runtime/README.md#hypervisor-specific-configuration).\n\n## Community\n\nTo learn more about the project, its community and governance, see the\n[community repository](https://github.com/kata-containers/community). This is\nthe first place to go if you wish to contribute to the project.\n\n## Getting help\n\nSee the [community](#community) section for ways to contact us.\n\n### Raising issues\n\nPlease raise an issue\n[in this repository](https://github.com/kata-containers/kata-containers/issues).\n\n> **Note:**\n> If you are reporting a security issue, please follow the [vulnerability reporting process](https://github.com/kata-containers/community#vulnerability-handling)\n\n## Developers\n\nSee the [developer guide](docs/Developer-Guide.md).\n\n### Components\n\n### Main components\n\nThe table below lists the core parts of the project:\n\n| Component | Type | Description |\n|-|-|-|\n| [runtime](src/runtime) | core | Main component run by a container manager and providing a containerd shimv2 runtime implementation. |\n| [runtime-rs](src/runtime-rs) | core | The Rust version runtime. |\n| [agent](src/agent) | core | Management process running inside the virtual machine / POD that sets up the container environment. |\n| [`dragonball`](src/dragonball) | core | An optional built-in VMM brings out-of-the-box Kata Containers experience with optimizations on container workloads |\n| [documentation](docs) | documentation | Documentation common to all components (such as design and install documentation). |\n| [tests](tests) | tests | Excludes unit tests which live with the main code. |\n\n### Additional components\n\nThe table below lists the remaining parts of the project:\n\n| Component | Type | Description |\n|-|-|-|\n| [packaging](tools/packaging) | infrastructure | Scripts and metadata for producing packaged binaries<br/>(components, hypervisors, kernel and rootfs). |\n| [kernel](https://www.kernel.org) | kernel | Linux kernel used by the hypervisor to boot the guest image. Patches are stored [here](tools/packaging/kernel). |\n| [osbuilder](tools/osbuilder) | infrastructure | Tool to create \"mini O/S\" rootfs and initrd images and kernel for the hypervisor. |\n| [kata-debug](tools/packaging/kata-debug/README.md) | infrastructure | Utility tool to gather Kata Containers debug information from Kubernetes clusters. |\n| [`agent-ctl`](src/tools/agent-ctl) | utility | Tool that provides low-level access for testing the agent. |\n| [`kata-ctl`](src/tools/kata-ctl) | utility | Tool that provides advanced commands and debug facilities. |\n| [`trace-forwarder`](src/tools/trace-forwarder) | utility | Agent tracing helper. |\n| [`runk`](src/tools/runk) | utility | Standard OCI container runtime based on the agent. |\n| [`ci`](.github/workflows) | CI | Continuous Integration configuration files and scripts. |\n| [`ocp-ci`](ci/openshift-ci/README.md) | CI | Continuous Integration configuration for the OpenShift pipelines. |\n| [`katacontainers.io`](https://github.com/kata-containers/www.katacontainers.io) | Source for the [`katacontainers.io`](https://www.katacontainers.io) site. |\n| [`Webhook`](tools/testing/kata-webhook/README.md) | utility | Example of a simple admission controller webhook to annotate pods with the Kata runtime class |\n\n### Packaging and releases\n\nKata Containers is now\n[available natively for most distributions](docs/install/README.md#packaged-installation-methods).\n\n## General tests\n\nSee the [tests documentation](tests/README.md).\n\n## Metrics tests\n\nSee the [metrics documentation](tests/metrics/README.md).\n\n## Glossary of Terms\n\nSee the [glossary of terms](https://github.com/kata-containers/kata-containers/wiki/Glossary) related to Kata Containers.\n",
      "stars_today": 5
    },
    {
      "id": 22711802,
      "name": "wine",
      "full_name": "wine-mirror/wine",
      "description": null,
      "html_url": "https://github.com/wine-mirror/wine",
      "stars": 3811,
      "forks": 1224,
      "language": "C",
      "topics": [],
      "created_at": "2014-08-07T07:02:05Z",
      "updated_at": "2026-01-16T22:37:18Z",
      "pushed_at": "2026-01-16T22:36:36Z",
      "open_issues": 11,
      "owner": {
        "login": "wine-mirror",
        "avatar_url": "https://avatars.githubusercontent.com/u/8382127?v=4"
      },
      "readme": "## INTRODUCTION\n\nWine is a program which allows running Microsoft Windows programs\n(including DOS, Windows 3.x, Win32, and Win64 executables) on Unix.\nIt consists of a program loader which loads and executes a Microsoft\nWindows binary, and a library (called Winelib) that implements Windows\nAPI calls using their Unix, X11 or Mac equivalents.  The library may also\nbe used for porting Windows code into native Unix executables.\n\nWine is free software, released under the GNU LGPL; see the file\nLICENSE for the details.\n\n\n## QUICK START\n\nFrom the top-level directory of the Wine source (which contains this file),\nrun:\n\n```\n./configure\nmake\n```\n\nThen either install Wine:\n\n```\nmake install\n```\n\nOr run Wine directly from the build directory:\n\n```\n./wine notepad\n```\n\nRun programs as `wine program`. For more information and problem\nresolution, read the rest of this file, the Wine man page, and\nespecially the wealth of information found at https://www.winehq.org.\n\n\n## REQUIREMENTS\n\nTo compile and run Wine, you must have one of the following:\n\n- Linux version 2.6.22 or later\n- FreeBSD 12.4 or later\n- Solaris x86 9 or later\n- NetBSD-current\n- macOS 10.12 or later\n\nAs Wine requires kernel-level thread support to run, only the operating\nsystems mentioned above are supported.  Other operating systems which\nsupport kernel threads may be supported in the future.\n\n**FreeBSD info**:\n  See https://wiki.freebsd.org/Wine for more information.\n\n**Solaris info**:\n  You will most likely need to build Wine with the GNU toolchain\n  (gcc, gas, etc.). Warning : installing gas does *not* ensure that it\n  will be used by gcc. Recompiling gcc after installing gas or\n  symlinking cc, as and ld to the gnu tools is said to be necessary.\n\n**NetBSD info**:\n  Make sure you have the USER_LDT, SYSVSHM, SYSVSEM, and SYSVMSG options\n  turned on in your kernel.\n\n**macOS info**:\n  You need Xcode/Xcode Command Line Tools or Apple cctools.  The\n  minimum requirements for compiling Wine are clang 3.8 with the\n  MacOSX10.13.sdk and mingw-w64 v12 for 32-bit wine.  The\n  MacOSX10.14.sdk and later can build 64-bit wine.\n\n**Supported file systems**:\n  Wine should run on most file systems. A few compatibility problems\n  have also been reported using files accessed through Samba. Also,\n  NTFS does not provide all the file system features needed by some\n  applications.  Using a native Unix file system is recommended.\n\n**Basic requirements**:\n  You need to have the X11 development include files installed\n  (called xorg-dev in Debian and libX11-devel in Red Hat).\n  Of course you also need make (most likely GNU make).\n  You also need flex version 2.5.33 or later and bison.\n\n**Optional support libraries**:\n  Configure will display notices when optional libraries are not found\n  on your system. See https://gitlab.winehq.org/wine/wine/-/wikis/Building-Wine\n  for hints about the packages you should install. On 64-bit\n  platforms, you have to make sure to install the 32-bit versions of\n  these libraries.\n\n\n## COMPILATION\n\nTo build Wine, do:\n\n```\n./configure\nmake\n```\n\nThis will build the program \"wine\" and numerous support libraries/binaries.\nThe program \"wine\" will load and run Windows executables.\nThe library \"libwine\" (\"Winelib\") can be used to compile and link\nWindows source code under Unix.\n\nTo see compile configuration options, do `./configure --help`.\n\nFor more information, see https://gitlab.winehq.org/wine/wine/-/wikis/Building-Wine\n\n\n## SETUP\n\nOnce Wine has been built correctly, you can do `make install`; this\nwill install the wine executable and libraries, the Wine man page, and\nother needed files.\n\nDon't forget to uninstall any conflicting previous Wine installation\nfirst.  Try either `dpkg -r wine` or `rpm -e wine` or `make uninstall`\nbefore installing.\n\nOnce installed, you can run the `winecfg` configuration tool. See the\nSupport area at https://www.winehq.org/ for configuration hints.\n\n\n## RUNNING PROGRAMS\n\nWhen invoking Wine, you may specify the entire path to the executable,\nor a filename only.\n\nFor example, to run Notepad:\n\n```\nwine notepad            (using the search Path as specified in\nwine notepad.exe         the registry to locate the file)\n\nwine c:\\\\windows\\\\notepad.exe      (using DOS filename syntax)\n\nwine ~/.wine/drive_c/windows/notepad.exe  (using Unix filename syntax)\n\nwine notepad.exe readme.txt          (calling program with parameters)\n```\n\nWine is not perfect, so some programs may crash. If that happens you\nwill get a crash log that you should attach to your report when filing\na bug.\n\n\n## GETTING MORE INFORMATION\n\n- **WWW**: A great deal of information about Wine is available from WineHQ at\n\thttps://www.winehq.org/ : various Wine Guides, application database,\n\tbug tracking. This is probably the best starting point.\n\n- **FAQ**: The Wine FAQ is located at https://gitlab.winehq.org/wine/wine/-/wikis/FAQ\n\n- **Wiki**: The Wine Wiki is located at https://gitlab.winehq.org/wine/wine/-/wikis/\n\n- **Gitlab**: Wine development is hosted at https://gitlab.winehq.org\n\n- **Mailing lists**:\n\tThere are several mailing lists for Wine users and developers; see\n\thttps://gitlab.winehq.org/wine/wine/-/wikis/Forums for more\n\tinformation.\n\n- **Bugs**: Report bugs to Wine Bugzilla at https://bugs.winehq.org\n\tPlease search the bugzilla database to check whether your\n\tproblem is already known or fixed before posting a bug report.\n\n- **IRC**: Online help is available at channel `#WineHQ` on irc.libera.chat.\n",
      "stars_today": 5
    },
    {
      "id": 3777210,
      "name": "squirrel",
      "full_name": "rime/squirrel",
      "description": "„ÄêÈº†È¨öÁÆ°„ÄëRime for macOS",
      "html_url": "https://github.com/rime/squirrel",
      "stars": 5640,
      "forks": 461,
      "language": "Swift",
      "topics": [],
      "created_at": "2012-03-20T16:17:18Z",
      "updated_at": "2026-01-16T18:40:49Z",
      "pushed_at": "2026-01-14T00:24:56Z",
      "open_issues": 194,
      "owner": {
        "login": "rime",
        "avatar_url": "https://avatars.githubusercontent.com/u/10554324?v=4"
      },
      "readme": "    Èº†È¨öÁÆ°\n    Áà≤Áâ©ÈõñÂæÆÊÉÖ‰∏çÊ∑∫\n    Êñ∞Ë©©ÈÜâÂ¢®ÊôÇ‰∏ÄÊèÆ\n    Âà•ÂæåÂØÑÊàëÁÑ°Ëæ≠ÈÅ†\n\n    „ÄÄ„ÄÄ„ÄÄ‚Äî‚ÄîÊ≠êÈôΩ‰øÆ\n\n‰ªäÁî±„ÄÄ[‰∏≠Â∑ûÈüªËº∏ÂÖ•Ê≥ïÂºïÊìéÔºèRime Input Method Engine](https://rime.im)\nÂèäÂÖ∂‰ªñÈñãÊ∫êÊäÄË°ìÂº∑ÂäõÈ©ÖÂãï\n\n„ÄêÈº†È¨öÁÆ°„ÄëËº∏ÂÖ•Ê≥ï\n===\n[![Download](https://img.shields.io/github/v/release/rime/squirrel)](https://github.com/rime/squirrel/releases/latest)\n[![Build Status](https://github.com/rime/squirrel/actions/workflows/commit-ci.yml/badge.svg)](https://github.com/rime/squirrel/actions/workflows)\n[![GitHub Tag](https://img.shields.io/github/tag/rime/squirrel.svg)](https://github.com/rime/squirrel)\n\nÂºèÊÅïÂ†Ç ÁâàÊ¨äÊâÄÁÑ°\n\nÊéàÊ¨äÊ¢ùÊ¨æÔºö[GPL v3](https://www.gnu.org/licenses/gpl-3.0.en.html)\n\nÈ†ÖÁõÆ‰∏ªÈ†ÅÔºö[rime.im](https://rime.im)\n\nÊÇ®ÂèØËÉΩÈÇÑÈúÄË¶Å Rime Áî®ÊñºÂÖ∂‰ªñÊìç‰ΩúÁ≥ªÁµ±ÁöÑÁôºË°åÁâàÔºö\n\n  * „Äê‰∏≠Â∑ûÈüª„ÄëÔºàibus-rime„ÄÅfcitx-rimeÔºâÁî®Êñº Linux\n  * „ÄêÂ∞èÁãºÊØ´„ÄëÁî®Êñº Windows\n\nÂÆâË£ùËº∏ÂÖ•Ê≥ï\n---\n\nÊú¨ÂìÅÈÅ©Áî®Êñº macOS 13.0+\n\nÂàùÊ¨°ÂÆâË£ùÔºåÂ¶ÇÊûúÂú®ÈÉ®‰ªΩÊáâÁî®Á®ãÂ∫è‰∏≠Êâì‰∏çÂá∫Â≠óÔºåË´ãË®ªÈä∑‰∏¶ÈáçÊñ∞ÁôªÈåÑ„ÄÇ\n\n‰ΩøÁî®Ëº∏ÂÖ•Ê≥ï\n---\n\nÈÅ∏ÂèñËº∏ÂÖ•Ê≥ïÊåáÁ§∫Âô®ËèúÂñÆË£èÁöÑ„Äê„Ñì„ÄëÂ≠óÊ®£ÂúñÊ®ôÔºåÈñãÂßãÁî®Èº†È¨öÁÆ°ÂØ´Â≠ó„ÄÇ\nÈÄöÈÅéÂø´Êç∑Èçµ `` Ctrl+` `` Êàñ `F4` ÂëºÂá∫ÊñπÊ°àÈÅ∏ÂñÆ„ÄÅÂàáÊèõËº∏ÂÖ•ÊñπÂºè„ÄÇ\n\nÂÆöË£ΩËº∏ÂÖ•Ê≥ï\n---\n\nÂÆöË£ΩÊñπÊ≥ïÔºåË´ãÂèÉËÄÉÁ∑ö‰∏ä [Âπ´Âä©ÊñáÊ™î](https://rime.im/docs/)„ÄÇ\n\n‰ΩøÁî®Á≥ªÁµ±Ëº∏ÂÖ•Ê≥ïËèúÂñÆÔºö\n\n  * ÈÅ∏‰∏≠„ÄåÂú®Á∑öÊñáÊ™î„ÄçÂèØÊâìÈñã‰ª•‰∏äÁ∂≤ÂùÄ\n  * Á∑®ËºØÁî®Êà∂Ë®≠ÂÆöÂæåÔºåÈÅ∏Êìá„ÄåÈáçÊñ∞ÈÉ®ÁΩ≤„Äç‰ª•‰ª§‰øÆÊîπÁîüÊïà\n\nÂÆâË£ùËº∏ÂÖ•ÊñπÊ°à\n---\n\n‰ΩøÁî® [/plum/](https://github.com/rime/plum) ÈÖçÁΩÆÁÆ°ÁêÜÂô®Áç≤ÂèñÊõ¥Â§öËº∏ÂÖ•ÊñπÊ°à„ÄÇ\n\nËá¥Ë¨ù\n---\n\nËº∏ÂÖ•ÊñπÊ°àË®≠Ë®àÔºö\n\n  * „ÄêÊúôÊúàÊãºÈü≥„ÄëÁ≥ªÂàó\n\n    ÊÑüË¨ù CC-CEDICT„ÄÅAndroid ÊãºÈü≥„ÄÅÊñ∞ÈÖ∑Èü≥„ÄÅopencc Á≠âÈñãÊ∫êÈ†ÖÁõÆ\n\nÁ®ãÂ∫èË®≠Ë®àÔºö\n\n  * ‰ΩõÊåØ\n  * Linghua Zhang\n  * Chongyu Zhu\n  * Èõ™ÈΩã\n  * faberii\n  * Chun-wei Kuo\n  * Junlu Cheng\n  * Jak Wings\n  * xiehuc\n\nÁæéË°ìÔºö\n\n  * ÂúñÊ®ôË®≠Ë®à ‰ΩõÊåØ„ÄÅÊ¢ÅÊµ∑„ÄÅÈõ®ÈÅé‰πãÂæå\n  * ÈÖçËâ≤ÊñπÊ°à Aben„ÄÅChongyu Zhu„ÄÅskoj„ÄÅSuperoutman„ÄÅ‰ΩõÊåØ„ÄÅÊ¢ÅÊµ∑\n\nÊú¨ÂìÅÂºïÁî®‰∫Ü‰ª•‰∏ãÈñãÊ∫êËªü‰ª∂Ôºö\n\n  * Boost C++ Libraries  (Boost Software License)\n  * capnproto (MIT License)\n  * darts-clone  (New BSD License)\n  * google-glog  (New BSD License)\n  * Google Test  (New BSD License)\n  * LevelDB  (New BSD License)\n  * librime  (New BSD License)\n  * OpenCC / ÈñãÊîæ‰∏≠ÊñáËΩâÊèõ  (Apache License 2.0)\n  * plum / Êù±È¢®Á†¥ (GNU Lesser General Public License 3.0)\n  * Sparkle  (MIT License)\n  * UTF8-CPP  (Boost Software License)\n  * yaml-cpp  (MIT License)\n\nÊÑüË¨ùÁéãÂÖ¨Â≠êÊçêË¥àÈñãÁôºÁî®Ê©ü„ÄÇ\n\nÂïèÈ°åËàáÂèçÈ•ã\n---\n\nÁôºÁèæÁ®ãÂ∫èÊúâ BUGÔºåÊàñÂª∫Ë≠∞ÔºåÊàñÊÑüÊÉ≥ÔºåË´ãÂèçÈ•ãÂà∞ [Rime ‰ª£Á¢º‰πãÂÆ∂Ë®éË´ñÂçÄ](https://github.com/rime/home/discussions)\n\nËÅØÁπ´ÊñπÂºè\n---\n\nÊäÄË°ì‰∫§ÊµÅÔºåÊ≠°ËøéÂÖâËá® [Rime ‰ª£Á¢º‰πãÂÆ∂](https://github.com/rime/home)Ôºå\nÊàñËá¥‰ø° Rime ÈñãÁôºËÄÖ <rimeime@gmail.com>„ÄÇ\n\nË¨ùË¨ù\n",
      "stars_today": 5
    },
    {
      "id": 963665823,
      "name": "embabel-agent",
      "full_name": "embabel/embabel-agent",
      "description": "Agent framework for the JVM. Pronounced Em-BAY-bel /…õmÀàbe…™b…ôl/",
      "html_url": "https://github.com/embabel/embabel-agent",
      "stars": 3047,
      "forks": 276,
      "language": "Kotlin",
      "topics": [
        "agent",
        "agentic-ai",
        "agents",
        "ai",
        "ai-agents",
        "aiagentframework",
        "genai",
        "generative-ai",
        "java",
        "kotlin",
        "llms",
        "multi-agents",
        "multi-agents-orchestration",
        "multi-agents-system",
        "spring"
      ],
      "created_at": "2025-04-10T03:06:07Z",
      "updated_at": "2026-01-16T22:01:08Z",
      "pushed_at": "2026-01-17T00:34:32Z",
      "open_issues": 84,
      "owner": {
        "login": "embabel",
        "avatar_url": "https://avatars.githubusercontent.com/u/152664703?v=4"
      },
      "readme": "# Embabel Agent Framework\n\n<img align=\"left\" src=\"https://github.com/embabel/embabel-agent/blob/main/embabel-agent-api/images/315px-Meister_der_Weltenchronik_001.jpg?raw=true\" width=\"180\">\n\n[![Docs](https://img.shields.io/badge/docs-live-brightgreen)](https://docs.embabel.com/embabel-agent/guide/0.1.2-SNAPSHOT/)\n![Build](https://github.com/embabel/embabel-agent/actions/workflows/maven.yml/badge.svg)\n[![YourKit](https://img.shields.io/badge/Profiling-YourKit-blue)](https://www.yourkit.com/)\n[![JProfiler](https://img.shields.io/badge/Profiled%20with-JProfiler-blue)](https://www.ej-technologies.com/products/jprofiler/overview.html)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=embabel_embabel-agent&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=embabel_embabel-agent)\n[![Discord](https://img.shields.io/discord/1277751399261798401?logo=discord)](https://discord.gg/t6bjkyj93q)\n\n[//]: # ([![Quality Gate Status]&#40;https://sonarcloud.io/api/project_badges/measure?project=embabel_embabel-agent&metric=alert_status&token=d275d89d09961c114b8317a4796f84faf509691c&#41;]&#40;https://sonarcloud.io/summary/new_code?id=embabel_embabel-agent&#41;)\n\n[//]: # ([![Bugs]&#40;https://sonarcloud.io/api/project_badges/measure?project=embabel_embabel-agent&metric=bugs&#41;]&#40;https://sonarcloud.io/summary/new_code?id=embabel_embabel-agent&#41;)\n![Kotlin](https://img.shields.io/badge/kotlin-%237F52FF.svg?style=for-the-badge&logo=kotlin&logoColor=white)\n![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&logo=openjdk&logoColor=white)\n![Spring](https://img.shields.io/badge/spring-%236DB33F.svg?style=for-the-badge&logo=spring&logoColor=white)\n![Spring Boot](https://img.shields.io/badge/Spring%20Boot-6DB33F.svg?style=for-the-badge&logo=Spring-Boot&logoColor=white)\n![Apache Tomcat](https://img.shields.io/badge/apache%20tomcat-%23F8DC75.svg?style=for-the-badge&logo=apache-tomcat&logoColor=black)\n![Apache Maven](https://img.shields.io/badge/Apache%20Maven-C71A36?style=for-the-badge&logo=Apache%20Maven&logoColor=white)\n![JUnit](https://img.shields.io/badge/JUnit5-25A162.svg?style=for-the-badge&logo=JUnit5&logoColor=white)\n![ChatGPT](https://img.shields.io/badge/chatGPT-74aa9c?style=for-the-badge&logo=openai&logoColor=white)\n![Jinja](https://img.shields.io/badge/jinja-white.svg?style=for-the-badge&logo=jinja&logoColor=black)\n![JSON](https://img.shields.io/badge/JSON-000?logo=json&logoColor=fff)\n![GitHub Actions](https://img.shields.io/badge/github%20actions-%232671E5.svg?style=for-the-badge&logo=githubactions&logoColor=white)\n![SonarQube](https://img.shields.io/badge/SonarQube-black?style=for-the-badge&logo=sonarqube&logoColor=4E9BCD)\n![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)\n![IntelliJ IDEA](https://img.shields.io/badge/IntelliJIDEA-000000.svg?style=for-the-badge&logo=intellij-idea&logoColor=white)\n[![License](https://img.shields.io/github/license/embabel/embabel-agent?style=for-the-badge&logo=apache&color=brightgreen)](https://www.apache.org/licenses/LICENSE-2.0)\n[![Commits](https://img.shields.io/github/commit-activity/m/embabel/embabel-agent.svg?label=commits&style=for-the-badge&logo=git&logoColor=white)](https://github.com/embabel/embabel-agent/pulse)\n\n&nbsp;&nbsp;&nbsp;&nbsp;\n\nEmbabel (Em-BAY-bel) is a framework for authoring agentic flows on the JVM that seamlessly mix LLM-prompted interactions\nwith code and domain models. Supports\nintelligent path finding towards goals. Written in Kotlin\nbut offers a natural usage\nmodel from Java.\nFrom the creator of Spring.\n\n&nbsp;\n\n## Key Concepts\n\nModels agentic flows in terms of:\n\n- **Actions**: Steps an agent takes\n- **Goals**: What an agent is trying to achieve\n- **Conditions**: Conditions to assess before executing an action or determining that a goal has been achieved.\n  Conditions are reassessed after each action is executed.\n- **Domain model**: Objects underpinning the flow and informing Actions, Goals and Conditions.\n- **Plan**: A sequence of actions to achieve a goal. Plans are dynamically formulated by the system, not the programmer.\n  The\n  system replans after the completion of each action, allowing it to adapt to new information as well as observe the\n  effects of the previous action.\n  This is effectively an [OODA loop](https://en.wikipedia.org/wiki/OODA_loop).\n\n> Application developers don't usually have to deal with these concepts directly,\n> as most conditions result from data flow defined in code, allowing the system to infer\n> pre and post conditions.\n\nThese concepts underpin these differentiators versus other agent frameworks:\n\n- **Sophisticated planning.** Goes beyond a finite state machine or sequential execution\n  with nesting by introducing a true planning step, using a\n  non-LLM AI algorithm. This enables the system to perform tasks it wasn‚Äôt programmed to do by combining known\n  steps in\n  a novel order, as well as make decisions about parallelization and other runtime behavior.\n- **Superior extensibility and reuse**: Because of dynamic planning, adding more domain objects, actions, goals and\n  conditions\n  can extend the capability of the system, _without editing FSM definitions_ or existing code.\n- **Strong typing and the benefits of object orientation**: Actions, goals and conditions are informed by a domain\n  model, which can\n  include behavior. Everything is strongly typed and prompts and\n  manually authored code interact cleanly. No more magic maps. Enjoy full refactoring support.\n\nOther benefits:\n\n- **Platform abstraction**: Clean separation between programming model and platform internals allows running locally\n  while\n  potentially offering higher QoS in production without changing application code.\n- **Designed for LLM mixing**: It is easy to build applications that mix LLMs, ensuring the most cost-effective yet\n  capable solution.\n  This enables the system to leverage the strengths of different models for different tasks. In particular, it\n  facilitates\n  the use of local models for point tasks. This can be important for cost and privacy.\n- **Built on Spring and the JVM,** making it easy to access existing enterprise functionality and capabilities.\n  For example:\n    - Spring can inject and manage agents, including using Spring AOP to decorate functions.\n    - Robust persistence and transaction management solutions are available.\n- **Designed for testability** from the ground up. Both unit testing and agent end to end testing are easy.\n\nFlows can be authored in one of two ways:\n\n- An annotation-based model similar to Spring MVC, with types annotated with the Spring stereotype `@Agent`, using\n  `@Goal`, `@Condition` and\n  `@Action` methods.\n- Idiomatic Kotlin DSL with `agent {` and `action {` blocks.\n\nEither way, flows are backed by a domain model of objects that can have rich behavior.\n\n> We are working toward allowing natural language actions and goals to be deployed.\n\nThe planning step is pluggable.\n\nThe default planning approach is\n[Goal Oriented Action Planning](https://medium.com/@vedantchaudhari/goal-oriented-action-planning-34035ed40d0b).\nGOAP is a popular AI planning algorithm used in gaming. It allows for dynamic decision-making and action selection based\non the current state of the world and the goals of the agent.\n\nGoals, actions and plans are independent of GOAP. Embabel also\nsupports [Utility AI](https://en.wikipedia.org/wiki/Utility_system) out of the box, which can run the same actions but\nchooses actions\nbased on (potentially dynamic) utility scores rather than strict preconditions and postconditions. This is valuable for\nexploration and\nopen-ended tasks, when we do not need to achieve a specific goal but want to maximize overall utility.\n\nThe framework executes via an `AgentPlatform` implementation.\n\nAn agent platform supports the following modes of execution:\n\n- **Focused**, where user code requests particular functionality: User code calls a method to run a particular agent,\n  passing in input. This is ideal for code-driven flows such as a flow invoked in response to an incoming event.\n- **Closed**, where user intent (or another incoming event) is classified to choose an agent. The platform tries to\n  find a\n  suitable agent among all the agents it knows about.\n  Agent choice is dynamic, but only actions defined within the particular agent\n  will run.\n- **Open**, where the user's intent is assessed and the platform uses _all_ its resources to try to achieve it. The\n  platform tries to find a\n  suitable goal among all the goals it knows about and builds a custom agent to achieve it from the start state,\n  including relevant actions and conditions. The platform will not proceed if it is unconvinced as to the applicability\n  of any goal. The `GoalChoiceApprover` interface provides developers a way to limit goal choice further.\n\nOpen mode is the most powerful, but least deterministic.\n> In open mode, the platform is capable of finding novel paths that were not envisioned by developers, and even\n> combining functionality from multiple providers.\n\nEven in open mode, the platform will only perform individual steps\nthat have been specified. (Of course, steps may themselves be LLM\ntransforms, in which case the prompts are controlled by user code but the\nresults are still non-deterministic.)\n\nPossible future modes:\n\n- **Evolving** mode: Where the platform can work with multiple goals in the same process and modify a running process to\n  add further goals and agents.\n  For example, an action can realize that it has become important to achieve additional goals.\n\nEmbabel agent systems will also support federation, both with other Embabel systems (allowing planning to incorporate\nremote actions and goals) and third party agent frameworks.\n\n## Quick Start\n\nGet an agent running in under 5 minutes.\n\nCreate your own agent repo from our [Java](https://github.com/embabel/java-agent-template)\nor [Kotlin](https://github.com/embabel/kotlin-agent-template) GitHub template by clicking the \"Use this template\"\nbutton.\n\nYou'll have an agent running in under a minute\nif you already have an `OPENAI_API_KEY` and have Maven installed.\n\n**üìö For examples and tutorials**, see\nthe [Embabel Agent Examples Repository](https://github.com/embabel/embabel-agent-examples)\n\n**üöó For a sophisticated, realistic example application**, see\nthe [Tripper travel planner agent](https://github.com/embabel/tripper)\n\n<img src=\"images/tripper_output1.jpg\" alt=\"Travel Planner Output\" width=\"600\"/>\n\n*AI-generated travel itinerary with detailed recommendations*\n\n<img src=\"images/tripper_map.jpg\" alt=\"Interactive map\" width=\"600\"/>\n\n*Map link included in output*\n\n## Why Is Embabel Needed?\n\nTL;DR Because the evolution of agent frameworks is early and there's a lot of room for improvement; because an agent\nframework on the JVM will deliver great business value.\n\n- _Why do we need an agent framework at all_? We can write code without higher level abstractions, directly invoking\n  LLMs and controlling flow directly in code. However, a higher level agent framework offers compelling benefits. For\n  example:\n    - Breaking up LLM interactions, making them simpler and more focused. This maximizes reuse and minimizes cost and\n      errors. It often allows us to use cheaper models for point interactions.\n    - Facilitating both unit and integration testing, which remain as important with agentic systems as with any other\n      software systems.\n    - Increasing composability where subflows and individual actions can be reused\n    - Making applications more manageable and robust, enabling a workflow manager to control their execution and retry\n      operations while maintaining previous state\n    - Enhancing safety through the ability to apply guardrails in many places\n- _Why do we need an agent framework for the JVM when solutions exist in Python?_: While agent frameworks initially\n  appeared predominantly Python, it's early and there's plenty of room for novel and\n  superior\n  approaches. The key adjacency is not the LLM--which is a simple HTTP call away--but existing code and\n  infrastructure\n  assets that are more valuable on the JVM than in Python.\n- _Why not use just Spring AI?_ Spring AI is great. We build on it, and embrace the Spring component model. However, we\n  believe that most applications should work with higher\n  level APIs. An analogy: Spring AI exists at the level of the Servlet API, while Embabel is more like Spring MVC.\n  Complex requirements are much easier to express and test in Embabel than with direct use of Spring AI.\n- _Why not attempt to contribute this project to Spring?_ This project requires different governance\n  from Spring, where most projects exist in stable environments and dependability and stability outweighs rapid\n  innovation. Second, the\n  concepts are not JVM-specific. We hope that Embabel will become the leading agent framework across platforms. While\n  the Spring brand is valuable in Java, it is not in TypeScript or Python.\n\n## Show Me The Code\n\nIn Java or Kotlin, agent implementation code is intuitive and easy to test.\n\n<details open>\n<summary>Java</summary>\n\n```java\n\n@Agent(description = \"Find news based on a person's star sign\")\npublic class StarNewsFinder {\n\n    private final HoroscopeService horoscopeService;\n    private final int storyCount;\n\n    // Services are injected by Spring\n    public StarNewsFinder(\n            HoroscopeService horoscopeService,\n            @Value(\"${star-news-finder.story.count:5}\") int storyCount) {\n        this.horoscopeService = horoscopeService;\n        this.storyCount = storyCount;\n    }\n\n    @Action\n    public StarPerson extractStarPerson(UserInput userInput, Ai ai) {\n        return ai\n                .withLlm(OpenAiModels.GPT_41)\n                .createObjectIfPossible(\n                        \"\"\"\n                                Create a person from this user input, extracting their name and star sign:\n                                %s\"\"\".formatted(userInput.getContent()),\n                        StarPerson.class\n                );\n    }\n\n    @Action\n    public Horoscope retrieveHoroscope(StarPerson starPerson) {\n        return new Horoscope(horoscopeService.dailyHoroscope(starPerson.sign()));\n    }\n\n    // toolGroups specifies tools that are required for this action to run\n    @Action(toolGroups = {CoreToolGroups.WEB})\n    public RelevantNewsStories findNewsStories(\n            StarPerson person,\n            Horoscope horoscope,\n            Ai ai) {\n        var prompt = \"\"\"\n                %s is an astrology believer with the sign %s.\n                Their horoscope for today is:\n                    <horoscope>%s</horoscope>\n                Given this, use web tools and generate search queries\n                to find %d relevant news stories summarize them in a few sentences.\n                Include the URL for each story.\n                Do not look for another horoscope reading or return results directly about astrology;\n                find stories relevant to the reading above.\n                \n                For example:\n                - If the horoscope says that they may\n                want to work on relationships, you could find news stories about\n                novel gifts\n                - If the horoscope says that they may want to work on their career,\n                find news stories about training courses.\"\"\".formatted(\n                person.name(), person.sign(), horoscope.summary(), storyCount);\n        return ai\n                .withDefaultLlm()\n                .createObject(prompt, RelevantNewsStories.class);\n    }\n\n    // The @AchievesGoal annotation indicates that completing this action\n    // achieves the given goal, so the agent can be complete\n    @AchievesGoal(\n            description = \"Write an amusing writeup for the target person based on their horoscope and current news stories\",\n            export = @Export(\n                    remote = true,\n                    name = \"starNewsWriteupJava\",\n                    startingInputTypes = {StarPerson.class, UserInput.class})\n    )\n    @Action\n    public Writeup writeup(\n            StarPerson person,\n            RelevantNewsStories relevantNewsStories,\n            Horoscope horoscope,\n            Ai ai) {\n        var llm = LlmOptions\n                .withModel(OpenAiModels.GPT_41_MINI)\n                // High temperature for creativity\n                .withTemperature(0.9);\n\n        var newsItems = relevantNewsStories.getItems().stream()\n                .map(item -> \"- \" + item.getUrl() + \": \" + item.getSummary())\n                .collect(Collectors.joining(\"\\n\"));\n\n        var prompt = \"\"\"\n                Take the following news stories and write up something\n                amusing for the target person.\n                \n                Begin by summarizing their horoscope in a concise, amusing way, then\n                talk about the news. End with a surprising signoff.\n                \n                %s is an astrology believer with the sign %s.\n                Their horoscope for today is:\n                    <horoscope>%s</horoscope>\n                Relevant news stories are:\n                %s\n                \n                Format it as Markdown with links.\"\"\".formatted(\n                person.name(), person.sign(), horoscope.summary(), newsItems);\n        return ai\n                .withLlm(llm)\n                .createObject(prompt, Writeup.class);\n    }\n}\n```\n\n</details>\n\n<details>\n<summary>Kotlin</summary>\n\n```kotlin\n@Agent(description = \"Find news based on a person's star sign\")\nclass StarNewsFinder(\n    // Services such as Horoscope are injected by Spring\n    private val horoscopeService: HoroscopeService,\n    // Potentially externalized by Spring\n    @param:Value(\"\\${star-news-finder.story.count:5}\")\n    private val storyCount: Int = 5,\n) {\n\n    @Action\n    fun extractPerson(\n        userInput: UserInput,\n        ai: Ai\n    ): StarPerson =\n        // All prompts are typesafe\n        ai.withDefaultLlm()\n            .createObject(\"Create a person from this user input, extracting their name and star sign: $userInput\")\n\n    // This action doesn't use an LLM\n    // Embabel makes it easy to mix LLM use with regular code\n    @Action\n    fun retrieveHoroscope(starPerson: StarPerson) =\n        Horoscope(horoscopeService.dailyHoroscope(starPerson.sign))\n\n    // This action uses tools\n    // \"toolGroups\" specifies tools that are required for this action to run\n    @Action(toolGroups = [ToolGroup.WEB])\n    fun findNewsStories(\n        person: StarPerson,\n        horoscope: Horoscope,\n        ai: Ai,\n    ): RelevantNewsStories =\n        ai.withDefaultLlm().createObject(\n            \"\"\"\n            ${person.name} is an astrology believer with the sign ${person.sign}.\n            Their horoscope for today is:\n                <horoscope>${horoscope.summary}</horoscope>\n            Given this, use web tools and generate search queries\n            to find $storyCount relevant news stories summarize them in a few sentences.\n            Include the URL for each story.\n            Do not look for another horoscope reading or return results directly about astrology;\n            find stories relevant to the reading above.\n\n            For example:\n            - If the horoscope says that they may\n            want to work on relationships, you could find news stories about\n            novel gifts\n            - If the horoscope says that they may want to work on their career,\n            find news stories about training courses.\n        \"\"\".trimIndent()\n        )\n\n    // The @AchievesGoal annotation indicates that completing this action\n    // achieves the given goal, so the agent run will be complete\n    @AchievesGoal(\n        description = \"Write an amusing writeup for the target person based on their horoscope and current news stories\",\n    )\n    @Action\n    fun writeup(\n        person: StarPerson,\n        relevantNewsStories: RelevantNewsStories,\n        horoscope: Horoscope,\n        ai: Ai,\n    ): Writeup =\n        ai\n            .withLlm(\n                LlmOptions\n                    .withModel(model)\n                    .withTemperature(0.9)\n            )\n            .createObject(\n                \"\"\"\n            Take the following news stories and write up something\n            amusing for the target person.\n\n            Begin by summarizing their horoscope in a concise, amusing way, then\n            talk about the news. End with a surprising signoff.\n\n            ${person.name} is an astrology believer with the sign ${person.sign}.\n            Their horoscope for today is:\n                <horoscope>${horoscope.summary}</horoscope>\n            Relevant news stories are:\n            ${relevantNewsStories.items.joinToString(\"\\n\") { \"- ${it.url}: ${it.summary}\" }}\n\n            Format it as Markdown with links.\n        \"\"\".trimIndent()\n            )\n\n}\n```\n\n</details>\n\n\nThe following domain classes ensure type safety:\n\n<details open>\n<summary>Java</summary>\n\n```java\n\n@JsonClassDescription(\"Person with astrology details\")\n@JsonDeserialize(as = StarPerson.class)\npublic record StarPerson(\n        String name,\n        @JsonPropertyDescription(\"Star sign\") String sign\n) implements Person {\n\n    @JsonCreator\n    public StarPerson(\n            @JsonProperty(\"name\") String name,\n            @JsonProperty(\"sign\") String sign\n    ) {\n        this.name = name;\n        this.sign = sign;\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n}\n\npublic record Horoscope(String summary) {\n}\n\n@JsonClassDescription(\"Writeup relating to a person's horoscope and relevant news\")\npublic record Writeup(String text) implements HasContent {\n\n    @JsonCreator\n    public Writeup(@JsonProperty(\"text\") String text) {\n        this.text = text;\n    }\n\n    @Override\n    public String getContent() {\n        return text;\n    }\n}\n\n```\n\n</details>\n\n<details>\n<summary>Kotlin</summary>\n\n```kotlin\ndata class RelevantNewsStories(\n    val items: List<NewsStory>\n)\n\ndata class NewsStory(\n    val url: String,\n\n    val summary: String,\n)\n\ndata class Subject(\n    val name: String,\n    val sign: String,\n)\n\ndata class Horoscope(\n    val summary: String,\n)\n\ndata class FunnyWriteup(\n    override val text: String,\n) : HasContent\n```\n\n</details>\n\nIt's easy to unit test your agents to ensure that they correctly execute logic\nand pass the correct prompts and hyperparameters to LLMs. For example:\n\n```java\npublic class StarNewsFinderTest {\n\n    @Test\n    void writeupPromptMustContainKeyData() {\n        HoroscopeService horoscopeService = mock(HoroscopeService.class);\n        StarNewsFinder starNewsFinder = new StarNewsFinder(horoscopeService, 5);\n        var context = new FakeOperationContext();\n        context.expectResponse(new com.embabel.example.horoscope.Writeup(\"Gonna be a good day\"));\n\n        NewsStory cockatoos = new NewsStory(\n                \"https://fake.com.au\",\n                \"Cockatoo behavior\",\n                \"Cockatoos are eating cabbages\"\n        );\n\n        NewsStory emus = new NewsStory(\n                \"https://morefake.com.au\",\n                \"Emu movements\",\n                \"Emus are massing\"\n        );\n\n        StarPerson starPerson = new StarPerson(\"Lynda\", \"Scorpio\");\n        RelevantNewsStories relevantNewsStories = new RelevantNewsStories(Arrays.asList(cockatoos, emus));\n        Horoscope horoscope = new Horoscope(\"This is a good day for you\");\n\n        starNewsFinder.writeup(starPerson, relevantNewsStories, horoscope, context);\n\n        var prompt = context.getLlmInvocations().getFirst().getPrompt();\n        var toolGroups = context.getLlmInvocations().getFirst().getInteraction().getToolGroups();\n\n\n        assertTrue(prompt.contains(starPerson.getName()));\n        assertTrue(prompt.contains(starPerson.sign()));\n        assertTrue(prompt.contains(cockatoos.getSummary()));\n        assertTrue(prompt.contains(emus.getSummary()));\n\n        assertTrue(toolGroups.isEmpty(), \"The LLM should not have been given any tool groups\");\n    }\n}\n```\n\n## Dog Food Policy\n\nWe believe that all aspects of software development and business can and should\nbe greatly accelerated through the use of AI agents. The ultimate decision\nmakers remain human, but they can and should be greatly augmented.\n\n> This project practices extreme dogfooding.\n\n<!-- TODO photo of Duke with kibble -->\n\nOur key principles:\n\n1. **We will use AI agents to help every aspect of the project:** coding, documentation, community management, producing\n   marketing copy etc.\n   Any\n   human performing a task should ask why it cannot be automated, and strive toward maximum automation.\n2. **Developers retain ultimate control.** Developers are responsible for guiding agents toward the solution and\n   iterating\n   as necessary. A developer who commits or merges an agent contribution\n   is responsible for ensuring that it meets the project coding standards, which are\n   independent of the use of agents. For example, code must be human-readable.\n3. **We will favour open source agents built on the Embabel platform,** and contribute improvements. While\n   commercial agents\n   may be more advanced in some areas, we believe that our\n   platform is the best general solution for automation and by dogfooding we will improve it fastest.\n   By open sourcing agents used on our open source projects, we will maximize benefit to the community.\n4. **We will prioritize agents that help accelerate our progress.** Per the flight safety advice to fit your own mask\n   before helping others, we will prioritize\n   agents that help us accelerate our own progress. This will not only produce useful examples, but increase overall\n   project velocity.\n\nDevelopers must carefully read all code they commit and improve generated code if possible.\n\n> Coding agents are a special case. While the `embabel-agent-code` submodule offers support for project modification\n> that is useful for project bootstrapping, coding agents are the most mature of commercial agents, and their vendors\n> are\n> heavily subsidising their users, making it economically irrational to insist on our own platform.\n\n## Getting Started\n\n- Get the bits\n- Set up your environment\n- Run the application\n\n### Getting the bits\n\nChoose one of the following:\n\n- Clone the repository via `git clone https://github.com/embabel/embabel-agent`\n- Create a new Spring Boot project and add the necessary dependencies (see \"Using Embabel Agent Framework in Your\n  Project\" below)\n\n### Environment variables\n\n> Environment variables are consistent with common usage, rather than Spring AI.\n> For example, we prefer `OPENAI_API_KEY` to `SPRING_AI_OPENAI_API_KEY`.\n\nRequired:\n\n- `OPENAI_API_KEY`: For the OpenAI API\n\nOptional:\n\n- `ANTHROPIC_API_KEY`: For the Anthropic API. Necessary for the coding agent.\n\n> We strongly recommend providing both an OpenAI and Anthropic key, as some examples require both. And it's important to\n> try to find the best LLM for a given task, rather than automatically choose a familiar provider.\n\n### Services\n\nYou will need a Docker Desktop version [`>4.43.2`](https://docs.docker.com/desktop/release-notes/).\nBe sure to activate the following MCP tools from the catalog:\n\n- Brave Search\n- Fetch\n- Puppeteer\n- Wikipedia\n\n> You can also set up your own MCP tools using Spring AI conventions. See the `application-docker-desktop.yml` file for\n> an example.\n\nIf you're running Ollama locally, include the `embabel ollama starter` and Embabel will automatically connect to your\nOllama\nendpoint and make all models available.\n\n```xml\n\n<dependency>\n    <groupId>com.embabel.agent</groupId>\n    <artifactId>embabel-agent-starter-ollama</artifactId>\n</dependency>\n```\n\n### Running\n\nCreate your own agent project with\n\n```\nuvx --from git+https://github.com/embabel/project-creator.git project-creator\n```\n\n### Example Agents\n\n> **üìö For examples and tutorials**, see\n> the [Embabel Agent Examples Repository](https://github.com/embabel/embabel-agent-examples)\n\n```bash\n# Clone and run examples\ngit clone https://github.com/embabel/embabel-agent-examples\ncd embabel-agent-examples/scripts/kotlin\n./shell.sh\n```\n\n#### Shell Commands\n\nSpring Shell is an easy way to interact with the Embabel agent framework, especially during development.\n\nType `help` to see available commands. Use `execute` or `x` to run an agent:\n\n```\nexecute \"Lynda is a Scorpio, find news for her\" -p -r\n```\n\nThis will look for an agent, choose the star finder agent and\nrun the flow. `-p` will log prompts `-r` will log LLM responses.\nOmit these for less verbose logging.\n\nOptions:\n\n- `-p` logs prompts\n- `-r` logs LLM responses\n\nUse the `chat` command to enter an interactive chat with the agent.\nIt will attempt to run the most appropriate\nagent for each command.\n\n> Spring Shell supports history. Type `!!` to repeat the last command.\n> This will survive restarts, so is handy when iterating on an agent.\n\n#### Further examples\n\nExample commands within the shell:\n\n```\n# Perplexity style deep research\n# Requires both OpenAI and Anthropic keys and Docker Desktop with the MCP extension (or your own web tools)\nexecute \"research the recent australian federal election. what is the position of the greens party?\"\n\n# x is a shortcut for execute\nx \"fact check the following: holden cars are still made in australia; the koel is a bird native only to australia; fidel castro is justin trudeau's father\"\n\n```\n\n### Bringing in additional LLMs\n\n#### Local models with well-known providers\n\nThe Embabel Agent Framework supports local models from:\n\n- Ollama: Simply add `embabel-agent-starter-ollama` starter to your pom.xml and your local Ollama endpoint will be\n  queries. All local models will be\n  available.\n- Docker: Add the `embabel-agent-starter-dockermodels` starter to your pom.xml and your local Docker endpoint will be\n  queried. All local models will be available.\n- LMStudio: This uses the openAI compatible client. Just include LMStudio as a dependency and make sure your LMStudio\n  server is running.\n\n#### Custom LLMs\n\nYou can define an LLM for any provider for which a Spring AI `ChatModel` is available.\n\nSimply define Spring beans of type `Llm`.\nSee the `OpenAiConfiguration` class as an example.\n\nRemember:\n\n- Provide the knowledge cutoff date if you know it\n- Make the configuration class conditional on any required API key.\n\n## Roadmap\n\nThis project is in its early stages, but we have big plans.\nThe milestones and issues in this repository are a good reference.\nOur key goals:\n\n- **Become the natural way to Gen AI-enable Java applications**, and especially those built on Spring.\n- **Prove the power of the approach**. Demonstrate that this approach is the best way to build safe, dependable, Gen AI\n  applications.\n  In particular:\n    - Demonstrate the power of extensibility without modification, by adding goals and actions\n    - Demonstrate the potential to become the PaaS for natural language\n    - Demonstrate the potential of agent federation within the GOAP model\n    - Demonstrate budget-aware agents, such as \"Research the following topic, spending up to 20c if you are still\n      learning\"\n    - Integrate with data stores and demonstrate the power of surfacing existing functionality inside an organization\n- **Take the model to other platforms**: The conceptual framework is not JVM specific. Once established, we intend to\n  create TypeScript\n  and Python projects.\n\nThere is a lot to do, and you are awesome. We look forward to your contribution!\n\n## Application Design\n\n### Domain objects\n\nApplications center around domain objects. These can be instantiated by LLMs or user\ncode, and manipulated by user code.\n\nUse Jackson annotations to help LLMs with descriptions as well as mark fields to ignore.\nFor example:\n\n```kotlin\n@JsonClassDescription(\"Person with astrology details\")\ndata class StarPerson(\n    override val name: String,\n    @get:JsonPropertyDescription(\"Star sign\")\n    val sign: String,\n) : Person\n```\n\nSee [Java Json Schema Generation - Module Jackson](https://github.com/victools/jsonschema-generator/tree/main/jsonschema-module-jackson)\nfor documentation of the library used.\n\nDomain objects can have behaviors that are automatically exposed to LLMs when they are in scope. Simply annotate methods\nwith the Spring AI `@Tool` annotation.\n\n> When exposing `@Tool` methods on domain objects, be sure that the tool is safe to invoke. Even the best LLMs can get\n> trigger-happy. For example, be careful about methods that can mutate or delete data. This is likely better modeled via\n> an explicit call to a non-tool method on the same domain class, in a code action.\n\n## Using Embabel as an MCP server\n\nYou can use the Embabel agent platform as an MCP server from a\nUI like Claude Desktop. The Embabel MCP server is available over SSE.\n\nConfigure Claude Desktop as follows in your `claude_desktop_config.yml`:\n\n```json\n{\n  \"mcpServers\": {\n    \"embabel\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-remote\",\n        \"http://localhost:8080/sse\"\n      ]\n    }\n  }\n}\n\n```\n\nSee [MCP Quickstart for Claude Desktop Users](https://modelcontextprotocol.io/quickstart/user) for how to configure\nClaude Desktop.\n\nThe [MCP Inspector](https://github.com/modelcontextprotocol/inspector) is a helpful tool for interacting with your\nEmbabel\nSSE server, manually invoking tools and checking the exposed prompts and resources.\n\nStart the MCP Inspector with:\n\n```bash\nnpx @modelcontextprotocol/inspector\n```\n\n## Consuming MCP Servers\n\nThe Embabel Agent Framework provides built-in support for consuming Model Context Protocol (MCP) servers, allowing you\nto extend your applications with powerful AI capabilities through standardized interfaces.\n\n### What is MCP?\n\nModel Context Protocol (MCP) is an open protocol that standardizes how applications provide context and extra\nfunctionality to large language models. Introduced by Anthropic, MCP has emerged as the de facto standard for connecting\nAI agents to tools, functioning as a client-server protocol where:\n\n- **Clients** (like Embabel Agent) send requests to servers\n- **Servers** process those requests to deliver necessary context to the AI model\n\nMCP simplifies integration between AI applications and external tools, transforming an \"M√óN problem\" into an \"M+N\nproblem\" through standardization - similar to what USB did for hardware peripherals.\n\n### Configuring MCP in Embabel Agent\n\nTo configure MCP servers in your Embabel Agent application, add the following to your `application.yml`:\n\n```yaml\nspring:\n  ai:\n    mcp:\n      client:\n        enabled: true\n        name: embabel\n        version: 1.0.0\n        request-timeout: 30s\n        type: SYNC\n        stdio:\n          connections:\n            docker-mcp:\n              command: docker\n              args:\n                - run\n                - -i\n                - --rm\n                - alpine/socat\n                - STDIO\n                - TCP:host.docker.internal:8811\n```\n\nThis configuration sets up an MCP client that connects to a Docker-based MCP server. The connection uses STDIO transport\nthrough Docker's socat utility to connect to a TCP endpoint.\n\n### Docker Desktop MCP Integration\n\nDocker has embraced MCP with their Docker MCP Catalog and Toolkit, which provides:\n\n1. **Centralized Discovery** - A trusted hub for discovering MCP tools integrated into Docker Hub\n2. **Containerized Deployment** - Run MCP servers as containers without complex setup\n3. **Secure Credential Management** - Centralized, encrypted credential handling\n4. **Built-in Security** - Sandbox isolation and permissions management\n\nThe Docker MCP ecosystem includes over 100 verified tools from partners like Stripe, Elastic, Neo4j, and more, all\naccessible through Docker's infrastructure.\n\n### Learn More\n\n- [Docker MCP Documentation](https://docs.docker.com/desktop/features/gordon/mcp/)\n- [Docker MCP Servers Repository](https://github.com/docker/mcp-servers)\n- [Introducing Docker MCP Catalog and Toolkit](https://www.docker.com/blog/introducing-docker-mcp-catalog-and-toolkit/)\n- [MCP Introduction and Overview](https://www.philschmid.de/mcp-introduction)\n\n## A2A\n\nEmbabel integrates with the [A2A](https://github.com/google-a2a/A2A) protocol, allowing you to connect to other\nA2A-enabled agents and\nservices.\n\nEnable the `a2a` Spring profile to start the A2A server.\n\nYou'll need the following environment variable:\n\n- `GOOGLE_STUDIO_API_KEY`: Your Google Studio API key, which is used for Gemini.\n\nStart the Google A2A web interface using the `a2a` Docker profile:\n\n```bash\ndocker compose --profile a2a up\n```\n\nGo to the web interface running within the container at `http://localhost:12000/`.\n\nConnect to your agent at `host.docker.internal:8080/a2a`. Note that `localhost:8080/a2a` won't work as the server\ncannot access it when running in a Docker container.\n\n## Running Tests\n\nRun the tests via Maven.\n\n```bash\nmvn test\n```\n\nThis will run both unit and integration tests\nbut will not require an internet connection or any external services.\n\n## Spring profiles\n\nSpring profiles are used to configure the application for different environments and behaviors.\n\nModel profiles:\n\n- `docker-desktop`: Talking to Docker Desktop with the MCP extension. **This is recommended for the best experience,\n  with Docker-provided web tools.**\n\nLogging profiles:\n\n- `severance`: [Severance](https://www.youtube.com/watch?v=xEQP4VVuyrY&ab_channel=AppleTV) specific logging. Praise\n  Kier!\n- `starwars`: Star Wars specific logging. Feel the force\n- `colossus`: Colossus specific logging. The Forbin Project.\n\n## Testing\n\nA key goal of this framework is ease of testing.\nJust as Spring eased testing of early enterprise Java applications,\nthis framework facilitates testing of AI applications.\n\nTypes of testing:\n\n- Unit tests: All agents are unit testable, like any Spring-managed beans. Construct them with mock objects; call\n  individual action methods. The testing library facilitates testing prompts.\n- Integration tests: tbd\n\n## Logging\n\nAll logging in this project is either debug logging in the relevant\nclass itself, or results from the stream of events of type `AgentEvent`.\n\nEdit `application.yml` if you want to see debug logging from the relevant classes and packages.\n\nAvailable logging experiences:\n\n- `severance`: Severance logging. Praise Kier\n- `starwars`: Star Wars logging. Feel the force. The default as it's understood throughout the galaxy.\n- `colossus`: Colossus logging. The Forbin Project.\n- `montypython`: Monty Python logging. No one expects it.\n- `hh`: Hitchhiker's Guide to the Galaxy logging. The answer is 42.\n\nIf none of these profiles is chosen, Embabel will use vanilla logging.\nThis makes me sad.\n\n## Adding Embabel Agent Framework to Your Project\n\n### Maven Central Availability\n\n**Since version 0.2.0**, Embabel Agent Framework is available directly on Maven Central, simplifying dependency\nmanagement. You no longer need to configure custom repositories for stable releases.\n\n---\n\n### Maven\n\n#### For version 0.2.0 and above (Recommended)\n\nSimply add the Embabel Spring Boot starter dependency to your `pom.xml`:\n\n```xml\n\n<dependency>\n    <groupId>com.embabel.agent</groupId>\n    <artifactId>embabel-agent-starter</artifactId>\n    <version>${embabel-agent.version}</version>\n</dependency>\n```\n\nNo additional repository configuration is needed! Maven Central is configured by default.\n\n#### For versions prior to 0.2.0 or for SNAPSHOT versions\n\nYou need to add the Embabel repositories to your `pom.xml`:\n\n```xml\n\n<repositories>\n    <repository>\n        <id>embabel-releases</id>\n        <url>https://repo.embabel.com/artifactory/libs-release</url>\n        <releases>\n            <enabled>true</enabled>\n        </releases>\n        <snapshots>\n            <enabled>false</enabled>\n        </snapshots>\n    </repository>\n    <repository>\n        <id>embabel-snapshots</id>\n        <url>https://repo.embabel.com/artifactory/libs-snapshot</url>\n        <releases>\n            <enabled>false</enabled>\n        </releases>\n        <snapshots>\n            <enabled>true</enabled>\n        </snapshots>\n    </repository>\n</repositories>\n```\n\nThen add the dependency:\n\n```xml\n\n<dependency>\n    <groupId>com.embabel.agent</groupId>\n    <artifactId>embabel-agent-starter</artifactId>\n    <version>${embabel-agent.version}</version>\n</dependency>\n```\n\n---\n\n### Gradle (Kotlin DSL)\n\n#### For version 0.2.0 and above (Recommended)\n\nAdd the required repositories to your `build.gradle.kts`:\n\n```kotlin\nrepositories {\n    mavenCentral()\n    maven {\n        name = \"Spring Milestones\"\n        url = uri(\"https://repo.spring.io/milestone\")\n    }\n}\n```\n\nAdd the Embabel Agent starter:\n\n```kotlin\ndependencies {\n    implementation(\"com.embabel.agent:embabel-agent-starter:${embabelAgentVersion}\")\n}\n```\n\n#### For versions prior to 0.2.0 or for SNAPSHOT versions\n\nAdd all required repositories to your `build.gradle.kts`:\n\n```kotlin\nrepositories {\n    mavenCentral()\n    maven {\n        name = \"embabel-releases\"\n        url = uri(\"https://repo.embabel.com/artifactory/libs-release\")\n        mavenContent {\n            releasesOnly()\n        }\n    }\n    maven {\n        name = \"embabel-snapshots\"\n        url = uri(\"https://repo.embabel.com/artifactory/libs-snapshot\")\n        mavenContent {\n            snapshotsOnly()\n        }\n    }\n    maven {\n        name = \"Spring Milestones\"\n        url = uri(\"https://repo.spring.io/milestone\")\n    }\n}\n```\n\nAdd the Embabel Agent starter:\n\n```kotlin\ndependencies {\n    implementation(\"com.embabel.agent:embabel-agent-starter:${embabelAgentVersion}\")\n}\n```\n\n---\n\n### Gradle (Groovy DSL)\n\n#### For version 0.2.0 and above (Recommended)\n\nAdd the required repositories to your `build.gradle`:\n\n```groovy\nrepositories {\n    mavenCentral()\n    maven {\n        name = 'Spring Milestones'\n        url = 'https://repo.spring.io/milestone'\n    }\n}\n```\n\nAdd the Embabel Agent starter:\n\n```groovy\ndependencies {\n    implementation \"com.embabel.agent:embabel-agent-starter:${embabelAgentVersion}\"\n}\n```\n\n#### For versions prior to 0.2.0 or for SNAPSHOT versions\n\nAdd all required repositories to your `build.gradle`:\n\n```groovy\nrepositories {\n    mavenCentral()\n    maven {\n        name = 'embabel-releases'\n        url = 'https://repo.embabel.com/artifactory/libs-release'\n        mavenContent {\n            releasesOnly()\n        }\n    }\n    maven {\n        name = 'embabel-snapshots'\n        url = 'https://repo.embabel.com/artifactory/libs-snapshot'\n        mavenContent {\n            snapshotsOnly()\n        }\n    }\n    maven {\n        name = 'Spring Milestones'\n        url = 'https://repo.spring.io/milestone'\n    }\n}\n```\n\nAdd the Embabel Agent starter:\n\n```groovy\ndependencies {\n    implementation 'com.embabel.agent:embabel-agent-starter:${embabelAgentVersion}'\n}\n```\n\n---\n\n### Important Notes\n\n#### Spring Milestones Repository\n\nThe Spring Milestones repository is required because the Embabel BOM (`embabel-agent-dependencies`) has transitive\ndependencies on experimental Spring components, specifically the `mcp-bom`. This BOM is not available on Maven Central\nand is only published to the Spring milestone repository.\n\n**Note for Gradle users:** Unlike Maven, Gradle does not inherit repository configurations declared in parent POMs or\nBOMs. Therefore, it is necessary to explicitly declare the Spring milestone repository in your repositories block to\nensure proper resolution of all transitive dependencies.\n\n#### Repository Types\n\n- **Maven Central** (since v0.2.0): For stable releases 0.2.0 and above\n- **Embabel Releases Repository**: For stable releases prior to 0.2.0\n- **Embabel Snapshots Repository**: For development/snapshot versions (e.g., `0.3.0-SNAPSHOT`)\n\n---\n\n### Quick Start Examples\n\n#### Maven with latest stable version\n\n```xml\n\n<dependency>\n    <groupId>com.embabel.agent</groupId>\n    <artifactId>embabel-agent-starter</artifactId>\n    <version>0.3.0</version>\n</dependency>\n```\n\n#### Gradle Kotlin DSL with latest stable version\n\n```kotlin\nimplementation(\"com.embabel.agent:embabel-agent-starter:0.3.0\")\n```\n\n#### Gradle Groovy DSL with latest stable version\n\n```groovy\nimplementation 'com.embabel.agent:embabel-agent-starter:0.3.0'\n```\n\n## Contributing\n\nWe welcome contributions to the Embabel Agent Framework.\n\nLook at the [coding style guide](embabel-agent-api/.embabel/coding-style.md) for style guidelines.\nThis file also informs coding agent behavior.\n\n## Miscellaneous\n\n- _Why the name Embabel?_\n  The \"babel\" part is ultimately inspired by the story of the Tower of Babel, perhaps via Douglas\n  Adams' [babelfish](https://www.youtube.com/watch?v=iuumnjJWFO4&ab_channel=BBCStudios).\n  Per @lasuac:\n  _While Adams' fish in the ear enabled universal translation between species, Embabel aims at translating human intent\n  to JVM code, AI models, and enterprise systems._\n  \"embabel\" also sounds like \"enable.\"\n- Milestone names are Australian animals. Mythical animals such as \"bunyip\" and \"yowie\" are used for futures that may or\n  not be implemented.\n- README badges come from [here](https://github.com/Ileriayo/markdown-badges)\n  and [here](https://home.aveek.io/GitHub-Profile-Badges/).\n- Don't forget to join [Discord](https://discord.gg/t6bjkyj93q) to collaborate with the Embabel community. It is a good\n  place to receive support, showcase your work, discuss ideas and connect with like-minded people.\n\n## Star history\n\n[![Star History Chart](https://api.star-history.com/svg?repos=embabel/embabel-agent&type=Date)](https://star-history.com/#embabel/embabel-agent&Date)\n\n## Contributors\n\n[![Embabel contributors](https://contrib.rocks/image?repo=embabel/embabel-agent)](https://github.com/embabel/embabel-agent/graphs/contributors)\n\n\n\n--------------------\n(c) Embabel Software Inc 2024-2025.\n",
      "stars_today": 5
    },
    {
      "id": 230609507,
      "name": "mollyim-android",
      "full_name": "mollyim/mollyim-android",
      "description": "Enhanced and security-focused fork of Signal.",
      "html_url": "https://github.com/mollyim/mollyim-android",
      "stars": 2956,
      "forks": 156,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2019-12-28T12:50:31Z",
      "updated_at": "2026-01-17T00:48:29Z",
      "pushed_at": "2026-01-16T13:54:23Z",
      "open_issues": 245,
      "owner": {
        "login": "mollyim",
        "avatar_url": "https://avatars.githubusercontent.com/u/58849401?v=4"
      },
      "readme": "# Molly\n\n[![Test](https://github.com/mollyim/mollyim-android/workflows/Test/badge.svg)](https://github.com/mollyim/mollyim-android/actions)\n[![Reproducible build](https://github.com/mollyim/mollyim-android/actions/workflows/reprocheck.yml/badge.svg)](https://github.com/mollyim/mollyim-android/actions/workflows/reprocheck.yml)\n[![Translation status](https://hosted.weblate.org/widgets/molly-instant-messenger/-/svg-badge.svg)](https://hosted.weblate.org/engage/molly-instant-messenger/?utm_source=widget)\n[![Financial contributors](https://opencollective.com/mollyim/tiers/badge.svg)](https://opencollective.com/mollyim#category-CONTRIBUTE)\n[![Cloudsmith](https://img.shields.io/badge/OSS%20hosting%20by-cloudsmith-blue?logo=cloudsmith&style=flat-square)](https://cloudsmith.com)\n\nMolly is a hardened version of [Signal](https://github.com/signalapp/Signal-Android) for Android, the fast simple yet secure messaging app by [Signal Foundation](https://signal.org).\n\n## Introduction\n\nBack in 2018, Signal allowed the user to set a passphrase to secure the local message database. But this option was removed with the introduction of file-based encryption on Android. Molly brings it back again with additional security features.\n\nMolly connects to Signal's servers, so you can chat with your Signal contacts seamlessly. Before signing up, please remember to review the [Signal Terms & Privacy Policy](https://signal.org/legal/).\n\nWe update Molly every two weeks to include the latest Signal features and fixes. The exceptions are security patches, which are applied as soon as they are available.\n\n## Download\n\nYou can download the app from GitHub's [Releases](https://github.com/mollyim/mollyim-android/releases/latest) page or install it from the [Molly F-Droid Repo](https://molly.im/fdroid/):\n\n[<img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\"\n    alt=\"Get it on F-Droid\"\n    height=\"80\">](https://molly.im/fdroid/)\n\nThere are two versions available: **Molly** or **Molly-FOSS**. Learn the differences [below](#free-and-open-source) and download the right one for you.\n\nYou can also get **Molly-FOSS** from [Accrescent](https://accrescent.app/):\n\n<a href=\"https://accrescent.app/app/im.molly.app\">\n   <img alt=\"Get it on Accrescent\"\n      src=\"https://accrescent.app/badges/get-it-on.png\"\n      height=\"80\">\n</a>\n\nTo [verify](https://developer.android.com/studio/command-line/apksigner#usage-verify) the APK, use the following signing certificate fingerprints:\n```\nSHA-256: 6aa80fdf4a8cc13737cfb434fc0cde486f09cf8fcda21a67bea5ee1ca2700886\nSHA-1: 49ce310cdd0c09c8c34eb31a8005c6bf13f5a4f1\n```\n\n## Features\n\nMolly has unique features compared to Signal:\n\n- **Data encryption at rest** - Protect your app database with [passphrase encryption](https://github.com/mollyim/mollyim-android/wiki/Data-Encryption-At-Rest)\n- **Secure RAM wiper** - Securely shred sensitive data from device memory\n- **Automatic lock** - Lock the app automatically under user-defined conditions\n- **Multi-device support** - Link multiple devices to a single Signal account, including Android tablets\n- **UnifiedPush** - Receive push notifications without Google through the UnifiedPush protocol\n- **Block unknown contacts** - Block messages and calls from unknown senders for security and anti-spam\n- **Disappearing call history** - Clear call logs together with expiring messages\n- **Custom backup scheduling** - Set daily or weekly interval and the number of backups to retain\n- **SOCKS proxy and Tor support** - Tunnel app network traffic via proxy and Orbot\n- **Debug logs are optional** - Android logging can be disabled\n\nAdditionally, you will find all the features of Signal, along with some minor tweaks and improvements.\n\n## Free and Open-Source\n\nMolly is open-source just like Signal. But Signal depends on proprietary Google software for some features.\n\nTo support a 100% free and auditable app, Molly comes in two versions: one with proprietary blobs like Signal, and one without. They are called Molly and Molly-FOSS, respectively. You can install the flavor of your choice at any time, and it will replace any previously installed version. The data and settings will be preserved so that you do not have to re-register.\n\n### Feature Comparison\n\nHere's how some key features work in different versions of the app:\n\n| Feature                           | Molly-FOSS       | Molly                | Signal               |\n| --------------------------------- | ---------------- | -------------------- | -------------------- |\n| Push notifications <sup>(1)</sup> | ‚úî WebSocket<br>‚úî UnifiedPush | ‚ö† FCM<br>‚úî WebSocket<br>‚úî UnifiedPush | ‚ö† FCM<br>‚úî WebSocket |\n| Location sharing                 | ‚úî OpenStreetMap  | ‚ö† Google Maps        | ‚ö† Google Maps        |\n\n<sup>(1)</sup> You might need to turn off system-level battery restrictions for the app to receive messages when the app isn't open.\n\n### UnifiedPush\n\n[UnifiedPush](https://unifiedpush.org/) is an open standard for delivering push notifications, offering a privacy-friendly alternative to Google's proprietary FCM service. It allows users to choose their own notification distributor.\n\n> [!IMPORTANT]\n> To use UnifiedPush notifications, you need access to a [MollySocket](https://github.com/mollyim/mollysocket) server to link your Signal account to UnifiedPush. You can either run MollySocket on a server you control (strongly advised) or use a public instance.\n\nCurrently, UnifiedPush is unavailable for linked devices.\n\n## Compatibility with Signal\n\nMolly and Signal apps can be installed on the same device. If you need a second number for messaging, you can register Molly with a different number while keeping Signal active. Any phone number capable of receiving SMS or calls can be used during registration.\n\nIf you wish to use the same phone number for both Molly and Signal, you must register Molly as a linked device. Registering the same number independently on both apps will result in only the most recently registered app staying active, while the other will go offline.\n\nFor Signal users looking to switch to Molly without changing the phone number, please refer to the [Migrating From Signal](https://github.com/mollyim/mollyim-android/wiki/Migrating-From-Signal) guide on the wiki.\n\n## Backups\n\nBackups are fully compatible. Signal [backups](https://support.signal.org/hc/en-us/articles/360007059752-Backup-and-Restore-Messages) can be restored in Molly, and the other way around, simply by choosing the backup folder and file. However, to import a backup from Signal, you must use a matching or newer version of Molly.\n\n## Feedback\n\n- [Submit bugs and feature requests](https://github.com/mollyim/mollyim-android/issues) on GitHub\n- Join us at [#mollyim:matrix.org](https://matrix.to/#/#mollyim:matrix.org) on Matrix (via space: [#mollyim-space:matrix.org](https://matrix.to/#/#mollyim-space:matrix.org))\n- For news, tips, and tricks, follow [@mollyim](https://fosstodon.org/@mollyim) on Mastodon\n\n## Reproducible Builds\n\nMolly supports reproducible builds, so that anyone can run the build process to reproduce the same APK as the original release.\n\nPlease check the guide in the [reproducible-builds](https://github.com/mollyim/mollyim-android/blob/master/reproducible-builds) directory.\n\n## Changelog\n\nSee the [Changelog](https://github.com/mollyim/mollyim-android/wiki/Changelog) to view recent changes.\n\n## License\n\nLicensed under the [GNU AGPLv3](https://www.gnu.org/licenses/agpl-3.0.html).\n\nOriginal license and export notices in the [original README](README-ORIG.md).\n\n## Acknowledgements\n\nThanks to the following organizations for supporting the **Molly** project.\n\n<div align=\"center\">\n<table>\n<tr>\n  <td>\n    <a href=\"https://nlnet.nl/\" target=\"_blank\">\n      <img src=\"https://nlnet.nl/logo/banner.svg\" alt=\"NLnet logo\" height=\"56\" />\n    </a>\n  </td>\n  <td>\n    <a href=\"https://bahnhof.cloud/en/\" target=\"_blank\">\n      <img src=\"https://upload.wikimedia.org/wikipedia/de/c/c0/Bahnhof_AB_logo.svg\" alt=\"Bahnhof logo\" height=\"56\" />\n    </a>\n  </td>\n  <td>\n    <a href=\"https://cloudsmith.com/blog/cloudsmith-loves-opensource/\" target=\"_blank\">\n      <img src=\"https://raw.githubusercontent.com/opswithranjan/CloudsmithLogo/main/CloudsmithLogoCropped.jpeg\" alt=\"Cloudsmith logo\" height=\"32\" />\n    </a>\n  </td>\n  <td>\n    <a href=\"https://www.jetbrains.com/community/opensource/\" target=\"_blank\">\n      <img src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg\" alt=\"JetBrains logo\" height=\"32\" />\n    </a>\n  </td>\n</tr>\n</table>\n</div>\n\n## Legal Notice\n\nThis project is *NOT* affiliated with Signal Messenger or the Signal Foundation.\n\nThe software is developed independently and provided as-is, without warranties of any kind. Use at your own risk.\n",
      "stars_today": 5
    },
    {
      "id": 29759715,
      "name": "zstd",
      "full_name": "facebook/zstd",
      "description": "Zstandard - Fast real-time compression algorithm",
      "html_url": "https://github.com/facebook/zstd",
      "stars": 26417,
      "forks": 2380,
      "language": "C",
      "topics": [],
      "created_at": "2015-01-24T00:22:38Z",
      "updated_at": "2026-01-17T00:27:28Z",
      "pushed_at": "2025-12-22T05:05:20Z",
      "open_issues": 245,
      "owner": {
        "login": "facebook",
        "avatar_url": "https://avatars.githubusercontent.com/u/69631?v=4"
      },
      "readme": "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/facebook/zstd/dev/doc/images/zstd_logo86.png\" alt=\"Zstandard\"></p>\n\n__Zstandard__, or `zstd` as short version, is a fast lossless compression algorithm,\ntargeting real-time compression scenarios at zlib-level and better compression ratios.\nIt's backed by a very fast entropy stage, provided by [Huff0 and FSE library](https://github.com/Cyan4973/FiniteStateEntropy).\n\nZstandard's format is stable and documented in [RFC8878](https://datatracker.ietf.org/doc/html/rfc8878). Multiple independent implementations are already available.\nThis repository represents the reference implementation, provided as an open-source dual [BSD](LICENSE) OR [GPLv2](COPYING) licensed **C** library,\nand a command line utility producing and decoding `.zst`, `.gz`, `.xz` and `.lz4` files.\nShould your project require another programming language,\na list of known ports and bindings is provided on [Zstandard homepage](https://facebook.github.io/zstd/#other-languages).\n\n**Development branch status:**\n\n[![Build Status][travisDevBadge]][travisLink]\n[![Build status][CircleDevBadge]][CircleLink]\n[![Build status][CirrusDevBadge]][CirrusLink]\n[![Fuzzing Status][OSSFuzzBadge]][OSSFuzzLink]\n\n[travisDevBadge]: https://api.travis-ci.com/facebook/zstd.svg?branch=dev \"Continuous Integration test suite\"\n[travisLink]: https://travis-ci.com/facebook/zstd\n[CircleDevBadge]: https://circleci.com/gh/facebook/zstd/tree/dev.svg?style=shield \"Short test suite\"\n[CircleLink]: https://circleci.com/gh/facebook/zstd\n[CirrusDevBadge]: https://api.cirrus-ci.com/github/facebook/zstd.svg?branch=dev\n[CirrusLink]: https://cirrus-ci.com/github/facebook/zstd\n[OSSFuzzBadge]: https://oss-fuzz-build-logs.storage.googleapis.com/badges/zstd.svg\n[OSSFuzzLink]: https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:zstd\n\n## Benchmarks\n\nFor reference, several fast compression algorithms were tested and compared\non a desktop featuring a Core i7-9700K CPU @ 4.9GHz\nand running Ubuntu 24.04 (`Linux 6.8.0-53-generic`),\nusing [lzbench], an open-source in-memory benchmark by @inikep\ncompiled with [gcc] 14.2.0,\non the [Silesia compression corpus].\n\n[lzbench]: https://github.com/inikep/lzbench\n[Silesia compression corpus]: https://sun.aei.polsl.pl//~sdeor/index.php?page=silesia\n[gcc]: https://gcc.gnu.org/\n\n| Compressor name         | Ratio | Compression| Decompress.|\n| ---------------         | ------| -----------| ---------- |\n| **zstd 1.5.7 -1**       | 2.896 |   510 MB/s |  1550 MB/s |\n| brotli 1.1.0 -1         | 2.883 |   290 MB/s |   425 MB/s |\n| [zlib] 1.3.1 -1         | 2.743 |   105 MB/s |   390 MB/s |\n| **zstd 1.5.7 --fast=1** | 2.439 |   545 MB/s |  1850 MB/s |\n| quicklz 1.5.0 -1        | 2.238 |   520 MB/s |   750 MB/s |\n| **zstd 1.5.7 --fast=4** | 2.146 |   665 MB/s |  2050 MB/s |\n| lzo1x 2.10 -1           | 2.106 |   650 MB/s |   780 MB/s |\n| [lz4] 1.10.0            | 2.101 |   675 MB/s |  3850 MB/s |\n| snappy 1.2.1            | 2.089 |   520 MB/s |  1500 MB/s |\n| lzf 3.6 -1              | 2.077 |   410 MB/s |   820 MB/s |\n\n[zlib]: https://www.zlib.net/\n[lz4]: https://lz4.github.io/lz4/\n\nThe negative compression levels, specified with `--fast=#`,\noffer faster compression and decompression speed\nat the cost of compression ratio.\n\nZstd can also offer stronger compression ratios at the cost of compression speed.\nSpeed vs Compression trade-off is configurable by small increments.\nDecompression speed is preserved and remains roughly the same at all settings,\na property shared by most LZ compression algorithms, such as [zlib] or lzma.\n\nThe following tests were run\non a server running Linux Debian (`Linux version 4.14.0-3-amd64`)\nwith a Core i7-6700K CPU @ 4.0GHz,\nusing [lzbench], an open-source in-memory benchmark by @inikep\ncompiled with [gcc] 7.3.0,\non the [Silesia compression corpus].\n\nCompression Speed vs Ratio | Decompression Speed\n---------------------------|--------------------\n![Compression Speed vs Ratio](doc/images/CSpeed2.png \"Compression Speed vs Ratio\") | ![Decompression Speed](doc/images/DSpeed3.png \"Decompression Speed\")\n\nA few other algorithms can produce higher compression ratios at slower speeds, falling outside of the graph.\nFor a larger picture including slow modes, [click on this link](doc/images/DCspeed5.png).\n\n\n## The case for Small Data compression\n\nPrevious charts provide results applicable to typical file and stream scenarios (several MB). Small data comes with different perspectives.\n\nThe smaller the amount of data to compress, the more difficult it is to compress. This problem is common to all compression algorithms, and reason is, compression algorithms learn from past data how to compress future data. But at the beginning of a new data set, there is no \"past\" to build upon.\n\nTo solve this situation, Zstd offers a __training mode__, which can be used to tune the algorithm for a selected type of data.\nTraining Zstandard is achieved by providing it with a few samples (one file per sample). The result of this training is stored in a file called \"dictionary\", which must be loaded before compression and decompression.\nUsing this dictionary, the compression ratio achievable on small data improves dramatically.\n\nThe following example uses the `github-users` [sample set](https://github.com/facebook/zstd/releases/tag/v1.1.3), created from [github public API](https://developer.github.com/v3/users/#get-all-users).\nIt consists of roughly 10K records weighing about 1KB each.\n\nCompression Ratio | Compression Speed | Decompression Speed\n------------------|-------------------|--------------------\n![Compression Ratio](doc/images/dict-cr.png \"Compression Ratio\") | ![Compression Speed](doc/images/dict-cs.png \"Compression Speed\") | ![Decompression Speed](doc/images/dict-ds.png \"Decompression Speed\")\n\n\nThese compression gains are achieved while simultaneously providing _faster_ compression and decompression speeds.\n\nTraining works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient it is (there is no _universal dictionary_).\nHence, deploying one dictionary per type of data will provide the greatest benefits.\nDictionary gains are mostly effective in the first few KB. Then, the compression algorithm will gradually use previously decoded content to better compress the rest of the file.\n\n### Dictionary compression How To:\n\n1. Create the dictionary\n\n   `zstd --train FullPathToTrainingSet/* -o dictionaryName`\n\n2. Compress with dictionary\n\n   `zstd -D dictionaryName FILE`\n\n3. Decompress with dictionary\n\n   `zstd -D dictionaryName --decompress FILE.zst`\n\n\n## Build instructions\n\n`make` is the main build system of this project.\nIt is the reference, and other build systems are periodically updated to stay compatible.\nHowever, small drifts and feature differences can be present, since perfect synchronization is difficult.\nFor this reason, when your build system allows it, prefer employing `make`.\n\n### Makefile\n\nAssuming your system supports standard `make` (or `gmake`),\njust invoking `make` in root directory generates `zstd` cli at root,\nand also generates `libzstd` into `lib/`.\n\nOther standard targets include:\n- `make install` : install zstd cli, library and man pages\n- `make check` : run `zstd`, test its essential behavior on local platform\n\nThe `Makefile` follows the [GNU Standard Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html),\nallowing staged install, standard compilation flags, directory variables and command variables.\n\nFor advanced use cases, specialized flags which control binary generation and installation paths are documented\nin [`lib/README.md`](lib/README.md#modular-build) for the `libzstd` library\nand in [`programs/README.md`](programs/README.md#compilation-variables) for the `zstd` CLI.\n\n### cmake\n\nA `cmake` project generator is available for generating Makefiles or other build scripts\nto create the `zstd` binary as well as `libzstd` dynamic and static libraries.\nThe repository root now contains a minimal `CMakeLists.txt` that forwards to `build/cmake`,\nso you can configure the project with a standard `cmake -S .` invocation,\nwhile the historical `cmake -S build/cmake` entry point remains fully supported.\n\n```bash\ncmake -S . -B build-cmake\ncmake --build build-cmake\n```\n\nBy default, `CMAKE_BUILD_TYPE` is set to `Release`.\n\n#### Support for Fat (Universal2) Output\n\n`zstd` can be built and installed with support for both Apple Silicon (M1/M2) as well as Intel by using CMake's Universal2 support.\nTo perform a Fat/Universal2 build and install use the following commands:\n\n```bash\ncmake -S . -B build-cmake-debug -G Ninja -DCMAKE_OSX_ARCHITECTURES=\"x86_64;x86_64h;arm64\"\ncd build-cmake-debug\nninja\nsudo ninja install\n```\n\n### Meson\n\nA Meson project is provided within [`build/meson`](build/meson). Follow\nbuild instructions in that directory.\n\nYou can also take a look at [`.travis.yml`](.travis.yml) file for an\nexample about how Meson is used to build this project.\n\nNote that default build type is **release**.\n\n### VCPKG\nYou can build and install zstd [vcpkg](https://github.com/Microsoft/vcpkg/) dependency manager:\n\n    git clone https://github.com/Microsoft/vcpkg.git\n    cd vcpkg\n    ./bootstrap-vcpkg.sh\n    ./vcpkg integrate install\n    ./vcpkg install zstd\n\nThe zstd port in vcpkg is kept up to date by Microsoft team members and community contributors.\nIf the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n### Conan\n\nYou can install pre-built binaries for zstd or build it from source using [Conan](https://conan.io/). Use the following command:\n\n```bash\nconan install --requires=\"zstd/[*]\" --build=missing\n```\n\nThe zstd Conan recipe is kept up to date by Conan maintainers and community contributors.\nIf the version is out of date, please [create an issue or pull request](https://github.com/conan-io/conan-center-index) on the ConanCenterIndex repository.\n\n### Visual Studio (Windows)\n\nGoing into `build` directory, you will find additional possibilities:\n- Projects for Visual Studio 2008 and 2010.\n  + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.\n- Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,\n  which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution.\n- It is now recommended to generate Visual Studio solutions from `cmake`\n\n### Buck\n\nYou can build the zstd binary via buck by executing: `buck build programs:zstd` from the root of the repo.\nThe output binary will be in `buck-out/gen/programs/`.\n\n### Bazel\n\nYou can integrate zstd into your Bazel project by using the module hosted on the [Bazel Central Repository](https://registry.bazel.build/modules/zstd).\n\n## Testing\n\nYou can run quick local smoke tests by running `make check`.\nIf you can't use `make`, execute the `playTest.sh` script from the `src/tests` directory.\nTwo env variables `$ZSTD_BIN` and `$DATAGEN_BIN` are needed for the test script to locate the `zstd` and `datagen` binary.\nFor information on CI testing, please refer to `TESTING.md`.\n\n## Status\n\nZstandard is deployed within Meta and many other large cloud infrastructures,\nto compress humongous amounts of data in various formats and use cases.\nIt is also continuously fuzzed for security issues by Google's [oss-fuzz](https://github.com/google/oss-fuzz/tree/master/projects/zstd) program.\n\n## License\n\nZstandard is dual-licensed under [BSD](LICENSE) OR [GPLv2](COPYING).\n\n## Contributing\n\nThe `dev` branch is the one where all contributions are merged before reaching `release`.\nDirect commit to `release` are not permitted.\nFor more information, please read [CONTRIBUTING](CONTRIBUTING.md).\n",
      "stars_today": 4
    },
    {
      "id": 139914932,
      "name": "quarkus",
      "full_name": "quarkusio/quarkus",
      "description": "Quarkus: Supersonic Subatomic Java. ",
      "html_url": "https://github.com/quarkusio/quarkus",
      "stars": 15408,
      "forks": 3057,
      "language": "Java",
      "topics": [
        "cloud-native",
        "hacktoberfest",
        "java",
        "kubernetes",
        "reactive"
      ],
      "created_at": "2018-07-06T00:44:20Z",
      "updated_at": "2026-01-16T20:23:09Z",
      "pushed_at": "2026-01-16T22:11:32Z",
      "open_issues": 2670,
      "owner": {
        "login": "quarkusio",
        "avatar_url": "https://avatars.githubusercontent.com/u/47638783?v=4"
      },
      "readme": "[![Quarkus](https://design.jboss.org/quarkus/logo/final/PNG/quarkus_logo_horizontal_rgb_1280px_default.png#gh-light-mode-only)](https://quarkus.io/#gh-light-mode-only)\n[![Quarkus](https://design.jboss.org/quarkus/logo/final/PNG/quarkus_logo_horizontal_rgb_1280px_reverse.png#gh-dark-mode-only)](https://quarkus.io/#gh-dark-mode-only)\n\n[![Version](https://img.shields.io/maven-central/v/io.quarkus/quarkus-bom?logo=apache-maven&style=for-the-badge)](https://search.maven.org/artifact/io.quarkus/quarkus-bom)\n[![GitHub Actions Status](<https://img.shields.io/github/actions/workflow/status/QuarkusIO/quarkus/ci-actions-incremental.yml?branch=main&logo=GitHub&style=for-the-badge>)](https://github.com/quarkusio/quarkus/actions?query=workflow%3A%22Quarkus+CI%22)\n[![Commits](https://img.shields.io/github/commit-activity/m/quarkusio/quarkus.svg?label=commits&style=for-the-badge&logo=git&logoColor=white)](https://github.com/quarkusio/quarkus/pulse)\n[![License](https://img.shields.io/github/license/quarkusio/quarkus?style=for-the-badge&logo=apache&color=brightgreen)](https://www.apache.org/licenses/LICENSE-2.0)\n[![Project Chat](https://img.shields.io/badge/zulip-join_chat-brightgreen.svg?style=for-the-badge&logo=zulip)](https://quarkusio.zulipchat.com/)\n[![Gitpod Ready-to-Code](https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?style=for-the-badge&logo=gitpod&logoColor=white)](https://gitpod.io/#https://github.com/quarkusio/quarkus/-/tree/main/)\n[![Supported JVM Versions](https://img.shields.io/badge/JVM-17--21-brightgreen.svg?style=for-the-badge&logo=openjdk)](https://github.com/quarkusio/quarkus/actions/runs/113853915/)\n[![Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-007EC5?style=for-the-badge&logo=gradle)](https://ge.quarkus.io/scans)\n[![GitHub Repo stars](https://img.shields.io/github/stars/quarkusio/quarkus?style=for-the-badge)](https://github.com/quarkusio/quarkus/stargazers)\n[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Quarkus%20Guru-007EC5?style=for-the-badge)](https://gurubase.io/g/quarkus)\n\n# Quarkus - Supersonic Subatomic Java\n\nQuarkus is a Cloud Native, (Linux) Container First framework for writing Java applications.\n\n* **Container First**:\nMinimal footprint Java applications optimal for running in containers.\n* **Cloud Native**:\nEmbraces [12 factor architecture](https://12factor.net) in environments like Kubernetes.\n* **Unify imperative and reactive**:\nBrings under one programming model non-blocking and imperative styles of development.\n* **Standards-based**:\nBased on the standards and frameworks you love and use (RESTEasy and JAX-RS, Hibernate ORM and JPA, Netty, Eclipse Vert.x, Eclipse MicroProfile, Apache Camel...).\n* **Microservice First**:\nBrings lightning fast startup time and code turnaround to Java apps.\n* **Developer Joy**:\nDevelopment centric experience without compromise to bring your amazing apps to life in no time.\n\n_All under ONE framework._\n\n## Getting Started\n\n* [Documentation](https://quarkus.io)\n* [Wiki](https://github.com/quarkusio/quarkus/wiki)\n\n## Migration Guides\n\nWe collect all the migration notes in our [migration guides](https://github.com/quarkusio/quarkus/wiki/Migration-Guides).\n\n## Release Planning\n\nInterested in when the next release is coming? Check our [release planning](https://github.com/quarkusio/quarkus/wiki/Release-Planning) document for details.\n\n## How to build Quarkus\n\nThe build instructions are available in the [contribution guide](CONTRIBUTING.md).\n",
      "stars_today": 4
    },
    {
      "id": 53614190,
      "name": "mosquitto",
      "full_name": "eclipse-mosquitto/mosquitto",
      "description": "Eclipse Mosquitto - An open source MQTT broker",
      "html_url": "https://github.com/eclipse-mosquitto/mosquitto",
      "stars": 10516,
      "forks": 2572,
      "language": "C",
      "topics": [
        "broker",
        "eclipse-iot",
        "mosquitto",
        "mqtt"
      ],
      "created_at": "2016-03-10T20:19:09Z",
      "updated_at": "2026-01-16T07:27:11Z",
      "pushed_at": "2026-01-15T08:22:00Z",
      "open_issues": 810,
      "owner": {
        "login": "eclipse-mosquitto",
        "avatar_url": "https://avatars.githubusercontent.com/u/185921483?v=4"
      },
      "readme": "Eclipse Mosquitto\n=================\n\nMosquitto is an open source implementation of a server for version 5.0, 3.1.1,\nand 3.1 of the MQTT protocol. It also includes a C and C++ client library, and\nthe `mosquitto_pub` and `mosquitto_sub` utilities for publishing and\nsubscribing.\n\n## Links\n\nSee the following links for more information on MQTT:\n\n- Community page: <http://mqtt.org/>\n- MQTT v3.1.1 standard: <https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/mqtt-v3.1.1.html>\n- MQTT v5.0 standard: <https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html>\n\nMosquitto project information is available at the following locations:\n\n- Main homepage: <https://mosquitto.org/>\n- Find existing bugs or submit a new bug: <https://github.com/eclipse/mosquitto/issues>\n- Source code repository: <https://github.com/eclipse/mosquitto>\n\nThere is also a public test server available at <https://test.mosquitto.org/>\n\n## Installing\n\nSee <https://mosquitto.org/download/> for details on installing binaries for\nvarious platforms.\n\n## Quick start\n\nIf you have installed a binary package the broker should have been started\nautomatically. If not, it can be started with a very basic configuration:\n\n    mosquitto\n\nThen use `mosquitto_sub` to subscribe to a topic:\n\n    mosquitto_sub -t 'test/topic' -v\n\nAnd to publish a message:\n\n    mosquitto_pub -t 'test/topic' -m 'hello world'\n\nNote that starting the broker like this allows anonymous/unauthenticated access\nbut only from the local computer, so it's only really useful for initial testing.\n\nIf you want to have clients from another computer connect, you will need to\nprovide a configuration file. If you have installed from a binary package, you\nwill probably already have a configuration file at somewhere like\n`/etc/mosquitto/mosquitto.conf`. If you've compiled from source, you can write\nyour config file then run as `mosquitto -c /path/to/mosquitto.conf`.\n\nTo start your config file you define a listener and you will need to think\nabout what authentication you require. It is not advised to run your broker\nwith anonymous access when it is publically available.\n\nFor details on how to do this, look at the\n[authentication methods](https://mosquitto.org/documentation/authentication-methods/)\navailable and the [dynamic security plugin](https://mosquitto.org/documentation/dynamic-security/).\n\n## Documentation\n\nDocumentation for the broker, clients and client library API can be found in\nthe man pages, which are available online at <https://mosquitto.org/man/>. There\nare also pages with an introduction to the features of MQTT, the\n`mosquitto_passwd` utility for dealing with username/passwords, and a\ndescription of the configuration file options available for the broker.\n\nDetailed client library API documentation can be found at <https://mosquitto.org/api/>\n\n## Building from source\n\nTo build from source the recommended route for end users is to download the\narchive from <https://mosquitto.org/download/>.\n\nOn Windows and Mac, use `cmake` to build. On other platforms, just run `make`\nto build. For Windows, see also `README-windows.md`.\n\nIf you are building from the git repository then the documentation will not\nalready be built. Use `make binary` to skip building the man pages, or install\n`docbook-xsl` on Debian/Ubuntu systems.\n\n### Build Dependencies\n\n* c-ares (libc-ares-dev on Debian based systems) - only when compiled with `make WITH_SRV=yes`\n* cJSON - for client JSON output support. Disable with `make WITH_CJSON=no` Auto detected with CMake.\n* libwebsockets (libwebsockets-dev) - enable with `make WITH_WEBSOCKETS=yes`\n* openssl (libssl-dev on Debian based systems) - disable with `make WITH_TLS=no`\n* pthreads - for client library thread support. This is required to support the\n  `mosquitto_loop_start()` and `mosquitto_loop_stop()` functions. If compiled\n  without pthread support, the library isn't guaranteed to be thread safe.\n* uthash / utlist - bundled versions of these headers are provided, disable their use with `make WITH_BUNDLED_DEPS=no`\n* xsltproc (xsltproc and docbook-xsl on Debian based systems) - only needed when building from git sources - disable with `make WITH_DOCS=no`\n\nEquivalent options for enabling/disabling features are available when using the CMake build.\n\n\n## Credits\n\nMosquitto was written by Roger Light <roger@atchoo.org>\n",
      "stars_today": 4
    },
    {
      "id": 206121828,
      "name": "FreeRTOS",
      "full_name": "FreeRTOS/FreeRTOS",
      "description": "'Classic' FreeRTOS distribution.  Started as Git clone of FreeRTOS SourceForge SVN repo.  Submodules the kernel.",
      "html_url": "https://github.com/FreeRTOS/FreeRTOS",
      "stars": 6875,
      "forks": 1930,
      "language": "C",
      "topics": [],
      "created_at": "2019-09-03T16:25:27Z",
      "updated_at": "2026-01-16T22:42:15Z",
      "pushed_at": "2026-01-01T00:25:56Z",
      "open_issues": 25,
      "owner": {
        "login": "FreeRTOS",
        "avatar_url": "https://avatars.githubusercontent.com/u/54647343?v=4"
      },
      "readme": "The [FreeRTOS 202411.00](https://github.com/FreeRTOS/FreeRTOS/tree/202411.00) release updates FreeRTOS Kernel, FreeRTOS+TCP, coreMQTT, corePKCS11, coreHTTP, coreJSON, AWS IoT Over-the-air-Updates (OTA), AWS IoT Device Shadow, AWS IoT Jobs, AWS IoT Device Defender, Backoff Algorithm, AWS IoT Fleet Provisioning, coreSNTP, SigV4, and FreeRTOS Cellular Interface libraries to their [202406-LTS](https://github.com/FreeRTOS/FreeRTOS-LTS/blob/202406-LTS/CHANGELOG.md) versions. It also updates coreMQTT Agent to v1.3.0 and MbedTLS to v3.5.1. This release also adds ARMv7-R No_GIC Port Demo, ARMv7-R MPU Port Demos and FreeRTOS_Plus_TCP_IPv6_Demo Windows Simulator Demo. Additionally, all WinSim Demos are updated to use TLSv1.3. This release also updates WolfSSL to version v5.6.4.\n\nThe [FreeRTOS 202212.00](https://github.com/FreeRTOS/FreeRTOS/tree/202212.00) release updates FreeRTOS Kernel, FreeRTOS+TCP, coreMQTT, corePKCS11, coreHTTP, coreJSON, AWS IoT Over-the-air-Updates (OTA), AWS IoT Device Shadow, AWS IoT Jobs, AWS IoT Device Defender, Backoff Algorithm, AWS IoT Fleet Provisioning, coreSNTP, SigV4, and FreeRTOS Cellular Interface libraries to their [LTS 2.0](https://github.com/FreeRTOS/FreeRTOS-LTS/blob/202210-LTS/CHANGELOG.md) versions. It also updates coreMQTT Agent to v1.2.0 to be compatible with coreMQTT v2.X.X, and updates MbedTLS to v3.2.1. This release also adds Visual Studio static library projects for the FreeRTOS Kernel, FreeRTOS+TCP, Logging, MbedTLS, coreHTTP, and corePKCS11. With the addition of the static library projects, all Visual Studio projects have been updated to use them. Additionally, all demos dependent on coreMQTT have been updated to work with coreMQTT v2.X.X.\n\n## Getting started\nThe [FreeRTOS.org](https://www.freertos.org) website contains a [FreeRTOS Kernel Quick Start Guide](https://www.freertos.org/Documentation/01-FreeRTOS-quick-start/01-Beginners-guide/02-Quick-start-guide), a [list of supported devices and compilers](https://www.freertos.org/RTOS_ports.html), the [API reference](https://www.freertos.org/Documentation/02-Kernel/04-API-references/01-Task-creation/00-TaskHandle), and many other resources.\n\n### Getting help\nYou can use your Github login to get support from both the FreeRTOS community and directly from the primary FreeRTOS developers on our [active support forum](https://forums.freertos.org).  The [FAQ](https://www.freertos.org/Why-FreeRTOS/FAQs) provides another support resource.\n\n## Cloning this repository\nThis repo uses [Git Submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules) to bring in dependent components.\n\n**Note:** If you download the ZIP file provided by the GitHub UI, you will not get the contents of the submodules. (The ZIP file is also not a valid git repository)\n\nIf using Windows, because this repository and its submodules contain symbolic links, set `core.symlinks` to true with the following command:\n```\ngit config --global core.symlinks true\n```\nIn addition to this, either enable [Developer Mode](https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development) or, whenever using a git command that writes to the system (e.g. `git pull`, `git clone`, and `git submodule update --init --recursive`), use a console elevated as administrator so that git can properly create symbolic links for this repository. Otherwise, symbolic links will be written as normal files with the symbolic links' paths in them as text. [This](https://blogs.windows.com/windowsdeveloper/2016/12/02/symlinks-windows-10/) gives more explanation.\n\nTo clone using HTTPS:\n```\ngit clone https://github.com/FreeRTOS/FreeRTOS.git --recurse-submodules\n```\nUsing SSH:\n```\ngit clone git@github.com:FreeRTOS/FreeRTOS.git --recurse-submodules\n```\n\nIf you have downloaded the repo without using the `--recurse-submodules` argument, you need to run:\n```\ngit submodule update --init --recursive\n```\n\n## Repository structure\nThis repository contains the FreeRTOS Kernel, a number of supplementary libraries including the LTS ones, and a comprehensive set of example projects.  Many libraries (including the FreeRTOS kernel) are included as Git submodules from their own Git repositories.\n\n### Kernel source code and example projects\n```FreeRTOS/Source``` contains the FreeRTOS kernel source code (submoduled from https://github.com/FreeRTOS/FreeRTOS-Kernel).\n\n```FreeRTOS/Demo``` contains pre-configured example projects that demonstrate the FreeRTOS kernel executing on different hardware platforms and using different compilers.\n\n### Supplementary library source code and example projects\n```FreeRTOS-Plus/Source``` contains source code for additional FreeRTOS component libraries, as well as select partner provided libraries. These subdirectories contain further readme files and links to documentation.\n\n```FreeRTOS-Plus/Demo``` contains pre-configured example projects that demonstrate the FreeRTOS kernel used with the additional FreeRTOS component libraries.\n\n## Previous releases\n[Releases](https://github.com/FreeRTOS/FreeRTOS/releases) contains older FreeRTOS releases.\n\n\n## Learning FreeRTOS\n\nFor detailed and up-to-date information about FreeRTOS, including getting started guides and documentation for both new and experienced users, please refer to the official FreeRTOS website:\nhttps://www.freertos.org/\n\n## FreeRTOS Lab Projects\nFreeRTOS Lab projects are libraries and demos that are fully functional, but may be experimental or undergoing optimizations and refactorization to improve memory usage, modularity, documentation, demo usability, or test coverage.\n\nMost FreeRTOS Lab libraries can be found in the [FreeRTOS-Labs repository](https://github.com/FreeRTOS/FreeRTOS-Labs).\n\nA number of FreeRTOS Lab Demos can be found in the [FreeRTOS Github Organization](https://github.com/FreeRTOS) by searching for \"Lab\" or following [this link](https://github.com/FreeRTOS?q=Lab&type=&language=) to the search results.\n\n## coreMQTT Agent Demos\nThe [FreeRTOS/coreMQTT-Agent-Demos](https://github.com/FreeRTOS/coreMQTT-Agent-Demos) repository contains demos to showcase use of the [coreMQTT-Agent](https://github.com/FreeRTOS/coreMQTT-Agent) library to share an MQTT connection between multiple application tasks.\n\nThe demos show a single MQTT connection usage between multiple application tasks for interacting with AWS services (including [Over-the-air-Updates](https://docs.aws.amazon.com/freertos/latest/userguide/freertos-ota-dev.html), [Device Shadow](https://docs.aws.amazon.com/iot/latest/developerguide/iot-device-shadows.html),\n [Device Defender](https://docs.aws.amazon.com/iot/latest/developerguide/device-defender.html)) alongside performing simple Publish-Subscribe operations.\n## CBMC\n\nThe `FreeRTOS/Test/CBMC/proofs` directory contains CBMC proofs.\n\nTo learn more about CBMC and proofs specifically, review the training material [here](https://model-checking.github.io/cbmc-training).\n\nIn order to run these proofs you will need to install CBMC and other tools by following the instructions [here](https://model-checking.github.io/cbmc-training/installation.html).\n",
      "stars_today": 4
    },
    {
      "id": 6331631,
      "name": "fio",
      "full_name": "axboe/fio",
      "description": "Flexible I/O Tester",
      "html_url": "https://github.com/axboe/fio",
      "stars": 6028,
      "forks": 1369,
      "language": "C",
      "topics": [],
      "created_at": "2012-10-22T08:20:41Z",
      "updated_at": "2026-01-16T15:40:07Z",
      "pushed_at": "2026-01-16T15:40:02Z",
      "open_issues": 232,
      "owner": {
        "login": "axboe",
        "avatar_url": "https://avatars.githubusercontent.com/u/2619634?v=4"
      },
      "readme": "Overview and history\n--------------------\n\nFio was originally written to save me the hassle of writing special test case\nprograms when I wanted to test a specific workload, either for performance\nreasons or to find/reproduce a bug. The process of writing such a test app can\nbe tiresome, especially if you have to do it often.  Hence I needed a tool that\nwould be able to simulate a given I/O workload without resorting to writing a\ntailored test case again and again.\n\nA test work load is difficult to define, though. There can be any number of\nprocesses or threads involved, and they can each be using their own way of\ngenerating I/O. You could have someone dirtying large amounts of memory in a\nmemory mapped file, or maybe several threads issuing reads using asynchronous\nI/O. fio needed to be flexible enough to simulate both of these cases, and many\nmore.\n\nFio spawns a number of threads or processes doing a particular type of I/O\naction as specified by the user. fio takes a number of global parameters, each\ninherited by the thread unless otherwise parameters given to them overriding\nthat setting is given.  The typical use of fio is to write a job file matching\nthe I/O load one wants to simulate.\n\n\nSource\n------\n\nFio resides in a git repo, the canonical place is:\n\n\thttps://git.kernel.org/pub/scm/linux/kernel/git/axboe/fio\n\nSnapshots are frequently generated and :file:`fio-git-*.tar.gz` include the git\nmeta data as well. Other tarballs are archives of official fio releases.\nSnapshots can download from:\n\n\thttps://brick.kernel.dk/snaps/\n\nThere are also two official mirrors. Both of these are automatically synced with\nthe main repository, when changes are pushed. If the main repo is down for some\nreason, either one of these is safe to use as a backup:\n\n\thttps://git.kernel.org/pub/scm/linux/kernel/git/axboe/fio.git\n\n\thttps://github.com/axboe/fio.git\n\n\nMailing list\n------------\n\nThe fio project mailing list is meant for anything related to fio including\ngeneral discussion, bug reporting, questions, and development. For bug reporting,\nsee REPORTING-BUGS.\n\nAn automated mail detailing recent commits is automatically sent to the list at\nmost daily. The list address is fio@vger.kernel.org, subscribe by sending an\nemail to fio+subscribe@vger.kernel.org or visit\nhttps://subspace.kernel.org/vger.kernel.org.html.\n\nArchives can be found here:\n\n\thttps://www.spinics.net/lists/fio/\n\nor here:\n\n\thttps://lore.kernel.org/fio/\n\nand archives for the old list can be found here:\n\n\thttp://maillist.kernel.dk/fio-devel/\n\n\nAuthor\n------\n\nFio was written by Jens Axboe <axboe@kernel.dk> to enable flexible testing of\nthe Linux I/O subsystem and schedulers. He got tired of writing specific test\napplications to simulate a given workload, and found that the existing I/O\nbenchmark/test tools out there weren't flexible enough to do what he wanted.\n\nJens Axboe <axboe@kernel.dk> 20060905\n\n\nMaintainers\n-----------\n\nFio is maintained by Jens Axboe <axboe@kernel.dk and\nVincent Fu <vincentfu@gmail.com> - however, for reporting bugs please use\nthe fio reflector or the GitHub page rather than email any of them\ndirectly. By using the public resources, others will be able to learn from\nthe responses too. Chances are also good that other members will be able to\nhelp with your inquiry as well.\n\n\nBinary packages\n---------------\n\nDebian:\n\tStarting with Debian \"Squeeze\", fio packages are part of the official\n\tDebian repository. https://packages.debian.org/search?keywords=fio .\n\nUbuntu:\n\tStarting with Ubuntu 10.04 LTS (aka \"Lucid Lynx\"), fio packages are part\n\tof the Ubuntu \"universe\" repository.\n\thttps://packages.ubuntu.com/search?keywords=fio .\n\nRed Hat, Fedora, CentOS & Co:\n\tStarting with Fedora 9/Extra Packages for Enterprise Linux 4, fio\n\tpackages are part of the Fedora/EPEL repositories.\n\thttps://packages.fedoraproject.org/pkgs/fio/ .\n\nMandriva:\n\tMandriva has integrated fio into their package repository, so installing\n\ton that distro should be as easy as typing ``urpmi fio``.\n\nArch Linux:\n        An Arch Linux package is provided under the Community sub-repository:\n        https://www.archlinux.org/packages/?sort=&q=fio\n\nSolaris:\n\tPackages for Solaris are available from OpenCSW. Install their pkgutil\n\ttool (http://www.opencsw.org/get-it/pkgutil/) and then install fio via\n\t``pkgutil -i fio``.\n\nWindows:\n        Beginning with fio 3.31 Windows installers for tagged releases are\n        available on GitHub at https://github.com/axboe/fio/releases. The\n        latest installers for Windows can also be obtained as GitHub Actions\n        artifacts by selecting a build from\n        https://github.com/axboe/fio/actions. These require logging in to a\n        GitHub account.\n\nBSDs:\n\tPackages for BSDs may be available from their binary package repositories.\n\tLook for a package \"fio\" using their binary package managers.\n\n\nBuilding\n--------\n\nJust type::\n\n $ ./configure\n $ make\n $ make install\n\nNote that GNU make is required. On BSDs it's available from devel/gmake within\nports directory; on Solaris it's in the SUNWgmake package.  On platforms where\nGNU make isn't the default, type ``gmake`` instead of ``make``.\n\nConfigure will print the enabled options. Note that on Linux based platforms,\nthe libaio development packages must be installed to use the libaio\nengine. Depending on the distro, it is usually called libaio-devel or libaio-dev.\n\nFor gfio, gtk 2.18 (or newer), associated glib threads, and cairo are required\nto be installed.  gfio isn't built automatically and can be enabled with a\n``--enable-gfio`` option to configure.\n\nTo build fio with a cross-compiler::\n\n $ make clean\n $ make CROSS_COMPILE=/path/to/toolchain/prefix\n\nConfigure will attempt to determine the target platform automatically.\n\nIt's possible to build fio for ESX as well, use the ``--esx`` switch to\nconfigure.\n\nThe HTTP engine is enabled depending on if the curl and openssl shared libraries\nare detected on the system. For Ubuntu, these packages are libcurl4-openssl-dev\nand libssl-dev.\n\n\nWindows\n~~~~~~~\n\nThe minimum versions of Windows for building/running fio are Windows 7/Windows\nServer 2008 R2. On Windows, Cygwin (https://www.cygwin.com/) is required in\norder to build fio. To create an MSI installer package install WiX from\nhttps://wixtoolset.org and run :file:`dobuild.cmd` from the :file:`os/windows`\ndirectory.\n\nHow to compile fio on 64-bit Windows:\n\n 1. Install Cygwin (https://www.cygwin.com/). Install **make** and all\n    packages starting with **mingw64-x86_64**. Ensure\n    **mingw64-x86_64-zlib** are installed if you wish\n    to enable fio's log compression functionality.\n 2. Open the Cygwin Terminal.\n 3. Go to the fio directory (source files).\n 4. Run ``make clean && make -j``.\n\nTo build fio for 32-bit Windows, ensure the -i686 versions of the previously\nmentioned -x86_64 packages are installed and run ``./configure\n--build-32bit-win`` before ``make``.\n\nIt's recommended that once built or installed, fio be run in a Command Prompt or\nother 'native' console such as console2, since there are known to be display and\nsignal issues when running it under a Cygwin shell (see\nhttps://github.com/mintty/mintty/issues/56 and\nhttps://github.com/mintty/mintty/wiki/Tips#inputoutput-interaction-with-alien-programs\nfor details).\n\n\nDocumentation\n~~~~~~~~~~~~~\n\nFio uses Sphinx_ to generate documentation from the reStructuredText_ files.\nTo build HTML formatted documentation run ``make -C doc html`` and direct your\nbrowser to :file:`./doc/output/html/index.html`.  To build manual page run\n``make -C doc man`` and then ``man doc/output/man/fio.1``.  To see what other\noutput formats are supported run ``make -C doc help``.\n\n.. _reStructuredText: https://www.sphinx-doc.org/rest.html\n.. _Sphinx: https://www.sphinx-doc.org\n\n\nPlatforms\n---------\n\nFio works on (at least) Linux, Solaris, AIX, HP-UX, OSX, NetBSD, OpenBSD,\nWindows, FreeBSD, and DragonFly. Some features and/or options may only be\navailable on some of the platforms, typically because those features only apply\nto that platform (like the solarisaio engine, or the splice engine on Linux).\n\nSome features are not available on FreeBSD/Solaris even if they could be\nimplemented, I'd be happy to take patches for that. An example of that is disk\nutility statistics and (I think) huge page support, support for that does exist\nin FreeBSD/Solaris.\n\nFio uses pthread mutexes for signaling and locking and some platforms do not\nsupport process shared pthread mutexes. As a result, on such platforms only\nthreads are supported. This could be fixed with sysv ipc locking or other\nlocking alternatives.\n\nOther \\*BSD platforms are untested, but fio should work there almost out of the\nbox. Since I don't do test runs or even compiles on those platforms, your\nmileage may vary. Sending me patches for other platforms is greatly\nappreciated. There's a lot of value in having the same test/benchmark tool\navailable on all platforms.\n\nNote that POSIX aio is not enabled by default on AIX. Messages like these::\n\n    Symbol resolution failed for /usr/lib/libc.a(posix_aio.o) because:\n        Symbol _posix_kaio_rdwr (number 2) is not exported from dependent module /unix.\n\nindicate one needs to enable POSIX aio. Run the following commands as root::\n\n    # lsdev -C -l posix_aio0\n        posix_aio0 Defined  Posix Asynchronous I/O\n    # cfgmgr -l posix_aio0\n    # lsdev -C -l posix_aio0\n        posix_aio0 Available  Posix Asynchronous I/O\n\nPOSIX aio should work now. To make the change permanent::\n\n    # chdev -l posix_aio0 -P -a autoconfig='available'\n        posix_aio0 changed\n\n\nRunning fio\n-----------\n\nRunning fio is normally the easiest part - you just give it the job file\n(or job files) as parameters::\n\n\t$ fio [options] [jobfile] ...\n\nand it will start doing what the *jobfile* tells it to do. You can give more\nthan one job file on the command line, fio will serialize the running of those\nfiles. Internally that is the same as using the :option:`stonewall` parameter\ndescribed in the parameter section.\n\nIf the job file contains only one job, you may as well just give the parameters\non the command line. The command line parameters are identical to the job\nparameters, with a few extra that control global parameters.  For example, for\nthe job file parameter :option:`iodepth=2 <iodepth>`, the mirror command line\noption would be :option:`--iodepth 2 <iodepth>` or :option:`--iodepth=2\n<iodepth>`. You can also use the command line for giving more than one job\nentry. For each :option:`--name <name>` option that fio sees, it will start a\nnew job with that name.  Command line entries following a\n:option:`--name <name>` entry will apply to that job, until there are no more\nentries or a new :option:`--name <name>` entry is seen. This is similar to the\njob file options, where each option applies to the current job until a new []\njob entry is seen.\n\nfio does not need to run as root, except if the files or devices specified in\nthe job section requires that. Some other options may also be restricted, such\nas memory locking, I/O scheduler switching, and decreasing the nice value.\n\nIf *jobfile* is specified as ``-``, the job file will be read from standard\ninput.\n",
      "stars_today": 4
    },
    {
      "id": 381857226,
      "name": "typespec",
      "full_name": "microsoft/typespec",
      "description": null,
      "html_url": "https://github.com/microsoft/typespec",
      "stars": 5539,
      "forks": 331,
      "language": "Java",
      "topics": [
        "json-schema",
        "openapi3",
        "protobuf",
        "typespec"
      ],
      "created_at": "2021-06-30T23:29:49Z",
      "updated_at": "2026-01-16T23:55:44Z",
      "pushed_at": "2026-01-16T23:55:40Z",
      "open_issues": 1042,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# TypeSpec\n\n[Official Docs](https://typespec.io/) | [Try TypeSpec Online](https://aka.ms/trytypespec) | [Getting Started](https://typespec.io/docs) | [Language Overview](https://typespec.io/docs/language-basics/overview)\n\nTypeSpec is a language for defining cloud service APIs and shapes. TypeSpec is a highly extensible language with primitives that can describe API shapes common among REST, OpenAPI, gRPC, and other protocols.\n\nTypeSpec is excellent for generating many different API description formats, client and service code, documentation, and other assets while keeping your TypeSpec definition as a single source of truth.\n\nUsing TypeSpec, you can create reusable patterns for all aspects of an API and package those reusable patterns into libraries. These patterns establish \"guardrails\" for API designers and make it easier to follow best practices than to deviate from them. TypeSpec also has a rich linter framework with the ability to flag anti-patterns as well as an emitter framework that lets you control the output to ensure it follows the patterns you want.\n\nTypeSpec is a Microsoft-built, community-supported project. Your ideas, feedbacks, and code make all the difference and we deeply appreciate the support from the community.\n\n## [Installation](https://typespec.io/docs)\n\n```\nnpm install -g @typespec/compiler\n```\n\n#### Tools\n\nThe [TypeSpec VS Code extension](https://marketplace.visualstudio.com/items?itemName=typespec.typespec-vscode) can be installed from the VS Code [marketplace](https://marketplace.visualstudio.com/items?itemName=typespec.typespec-vscode) or directly on the command line:\n\n```\ntsp code install\n```\n\nThe [TypeSpec VS Extension](https://marketplace.visualstudio.com/items?itemName=typespec.typespecvs) can be installed from the [VS Marketplace](https://marketplace.visualstudio.com/items?itemName=typespec.typespecvs) or directly on the command line:\n\n```\ntsp vs install\n```\n\n## [Usage](https://typespec.io/docs#create-first-typespec-project)\n\n### TypeSpec to OpenAPI 3.0 Example\n\nThis example uses the `@typespec/http`, `@typespec/rest`, and `@typespec/openapi3` libraries to define a basic REST service and generate an OpenAPI 3.0 document from it.\n\nRun the following command and select \"Generic REST API\":\n\n```\ntsp init\n```\n\nHit enter a few times to confirm the defaults.\n\nCopy the contents below into your **main.tsp**:\n\n```typespec\nimport \"@typespec/http\";\nimport \"@typespec/rest\";\nimport \"@typespec/openapi3\";\n\nusing Http;\nusing Rest;\n\n/** This is a pet store service. */\n@service(#{ title: \"Pet Store Service\" })\n@server(\"https://example.com\", \"The service endpoint\")\nnamespace PetStore;\n\n@route(\"/pets\")\ninterface Pets {\n  list(): Pet[];\n}\n\nmodel Pet {\n  @minLength(100)\n  name: string;\n\n  @minValue(0)\n  @maxValue(100)\n  age: int32;\n\n  kind: \"dog\" | \"cat\" | \"fish\";\n}\n```\n\nInstall the dependencies of main.tsp:\n\n```\ntsp install\n```\n\nCompile it to OpenAPI 3.0:\n\n```\ntsp compile main.tsp --emit @typespec/openapi3\n```\n\nYou can find the emitted OpenAPI output in `./tsp-output/openapi.json`.\n\n## Advanced Scenarios\n\n### Installing nightly version\n\nOn every commit to the main branch, packages with changes are automatically published to npm with the `@next` tag.\nThe [packages](#packages) section shows which version corresponds to the `next` tag for each package.\n\nTo use a `nightly` version of the packages, go over each one of the packages in the `package.json` file and update it to either the latest published `@next` version or `@latest`, whichever is the newest. You can also use the tag `latest` or `next` instead of an explicit version.\n\nAfter updating the package.json file you can run `npm update --force`. Force is required as there might be some incompatible version requirement.\n\nExample\n\n```json5\n// Stable setup\n\"dependencies\": {\n  \"@typespec/compiler\": \"~0.30.0\",\n  \"@typespec/http\": \"~0.14.0\",\n  \"@typespec/rest\": \"~0.14.0\",\n  \"@typespec/openapi\": \"~0.9.0\",\n}\n\n// Consume next version\n// In this example: compiler and openapi have changes but rest library has none\n\"dependencies\": {\n  \"@typespec/compiler\": \"~0.31.0-dev.5\",\n  \"@typespec/http\": \"~0.14.0\",\n  \"@typespec/rest\": \"~0.14.0\", // No changes to @typespec/rest library so need to stay the latest.\n  \"@typespec/openapi\": \"~0.10.0-dev.2\",\n}\n```\n\n## Packages\n\n| Name                                               | Changelog                        | Latest                                                                                                                                   | Next                                                                      |\n| -------------------------------------------------- | -------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |\n| Core functionality                                 |                                  |                                                                                                                                          |                                                                           |\n| [@typespec/compiler][compiler_src]                 | [Changelog][compiler_chg]        | [![](https://img.shields.io/npm/v/@typespec/compiler)](https://www.npmjs.com/package/@typespec/compiler)                                 | ![](https://img.shields.io/npm/v/@typespec/compiler/next)                 |\n| TypeSpec Libraries                                 |                                  |                                                                                                                                          |                                                                           |\n| [@typespec/http][http_src]                         | [Changelog][http_chg]            | [![](https://img.shields.io/npm/v/@typespec/http)](https://www.npmjs.com/package/@typespec/http)                                         | ![](https://img.shields.io/npm/v/@typespec/http/next)                     |\n| [@typespec/rest][rest_src]                         | [Changelog][rest_chg]            | [![](https://img.shields.io/npm/v/@typespec/rest)](https://www.npmjs.com/package/@typespec/rest)                                         | ![](https://img.shields.io/npm/v/@typespec/rest/next)                     |\n| [@typespec/openapi][openapi_src]                   | [Changelog][openapi_chg]         | [![](https://img.shields.io/npm/v/@typespec/openapi)](https://www.npmjs.com/package/@typespec/openapi)                                   | ![](https://img.shields.io/npm/v/@typespec/openapi/next)                  |\n| [@typespec/openapi3][openapi3_src]                 | [Changelog][openapi3_chg]        | [![](https://img.shields.io/npm/v/@typespec/openapi3)](https://www.npmjs.com/package/@typespec/openapi3)                                 | ![](https://img.shields.io/npm/v/@typespec/openapi3/next)                 |\n| [@typespec/versioning][versioning_src]             | [Changelog][versioning_chg]      | [![](https://img.shields.io/npm/v/@typespec/versioning)](https://www.npmjs.com/package/@typespec/versioning)                             | ![](https://img.shields.io/npm/v/@typespec/versioning/next)               |\n| TypeSpec Tools                                     |                                  |                                                                                                                                          |                                                                           |\n| [@typespec/prettier-plugin-typespec][prettier_src] | [Changelog][prettier_chg]        | [![](https://img.shields.io/npm/v/@typespec/prettier-plugin-typespec)](https://www.npmjs.com/package/@typespec/prettier-plugin-typespec) | ![](https://img.shields.io/npm/v/@typespec/prettier-plugin-typespec/next) |\n| [typespec-vs][typespec-vs_src]                     | [Changelog][typespec-vs_chg]     | [![](https://img.shields.io/npm/v/typespec-vs)](https://www.npmjs.com/package/typespec-vs)                                               | ![](https://img.shields.io/npm/v/typespec-vs/next)                        |\n| [typespec-vscode][typespec-vscode_src]             | [Changelog][typespec-vscode_chg] | [![](https://img.shields.io/npm/v/typespec-vscode)](https://www.npmjs.com/package/typespec-vscode)                                       | ![](https://img.shields.io/npm/v/typespec-vscode/next)                    |\n| [tmlanguage-generator][tmlanguage_src]             | [Changelog][tmlanguage_chg]      | [![](https://img.shields.io/npm/v/tmlanguage-generator)](https://www.npmjs.com/package/tmlanguage-generator)                             | ![](https://img.shields.io/npm/v/tmlanguage-generator/next)               |\n\n[compiler_src]: packages/compiler\n[compiler_chg]: packages/compiler/CHANGELOG.md\n[http_src]: packages/http\n[http_chg]: packages/http/CHANGELOG.md\n[rest_src]: packages/rest\n[rest_chg]: packages/rest/CHANGELOG.md\n[openapi_src]: packages/openapi\n[openapi_chg]: packages/openapi/CHANGELOG.md\n[openapi3_src]: packages/openapi3\n[openapi3_chg]: packages/openapi3/CHANGELOG.md\n[versioning_src]: packages/versioning\n[versioning_chg]: packages/versioning/CHANGELOG.md\n[prettier_src]: packages/prettier-plugin-typespec\n[prettier_chg]: packages/prettier-plugin-typespec/CHANGELOG.md\n[typespec-vs_src]: packages/typespec-vs\n[typespec-vs_chg]: packages/typespec-vs/CHANGELOG.md\n[typespec-vscode_src]: packages/typespec-vscode\n[typespec-vscode_chg]: packages/typespec-vscode/CHANGELOG.md\n[tmlanguage_src]: packages/tmlanguage-generator\n[tmlanguage_chg]: packages/tmlanguage-generator/CHANGELOG.md\n\n`@next` version of the package are the latest versions available on the `main` branch.\n",
      "stars_today": 4
    },
    {
      "id": 805199381,
      "name": "YuyanIme",
      "full_name": "gurecn/YuyanIme",
      "description": "ËØ≠ÁáïËæìÂÖ•Ê≥ï-‰∏ÄÊ¨æÂü∫‰∫éRimeÂÆöÂà∂ÂºÄÂèëÁöÑ‰πùÈîÆ„ÄÅÂÖ®Êãº„ÄÅÂèåÊãº„ÄÅÊâãÂÜô„ÄÅÁÅ´ÊòüÊñáÁ≠âÊñπÊ°à„ÄÅÊîØÊåÅÊÇ¨ÊµÆ„ÄÅÂçïÊâã„ÄÅÊï∞Â≠óË°åÁ≠âÈîÆÁõòÊ®°ÂºèÁöÑ‰∏≠ÊñáËæìÂÖ•Ê≥ï",
      "html_url": "https://github.com/gurecn/YuyanIme",
      "stars": 3009,
      "forks": 161,
      "language": "Kotlin",
      "topics": [
        "double-pinyin",
        "ime",
        "input-method",
        "keyboard",
        "pinyin",
        "qwerty",
        "rime",
        "t9"
      ],
      "created_at": "2024-05-24T04:53:19Z",
      "updated_at": "2026-01-16T14:20:54Z",
      "pushed_at": "2025-12-22T09:27:43Z",
      "open_issues": 346,
      "owner": {
        "login": "gurecn",
        "avatar_url": "https://avatars.githubusercontent.com/u/8704526?v=4"
      },
      "readme": "# ËØ≠ÁáïËæìÂÖ•Ê≥ï\nÈõ®Ááï‰ª•ÂÖ∂ÊïèÊç∑„ÄÅ‰ºòÈõÖÁöÑÈ£ûË°åÂßøÊÄÅÔºåÂú®Èõ®Â§©‰æùÁÑ∂Â§üÈ£ûÁøî„ÄÅ‰∏çÁïèËâ∞Èô©„ÄÅÂãáÂæÄÁõ¥ÂâçÁöÑÈ£ûÁøîÊÄÅÂ∫¶ÔºåË¢´Ëµã‰∫à**ÁÅµÂ∑ß„ÄÅËÅ™Êòé„ÄÅ‰º∂‰øê„ÄÅÁßØÊûÅ„ÄÅÂàõÊñ∞**ÁöÑÂØìÊÑè„ÄÇËØ≠Ë®ÄÊòØ‰∫∫Á±ª‰∫§ÊµÅÁöÑÂü∫Êú¨Â∑•ÂÖ∑ÔºåÊòØÊúÄÈáçË¶ÅÁöÑÊñáÂåñËΩΩ‰ΩìÔºåËæìÂÖ•ÊñπÂºèÊòØËØ≠Ë®Ä‰∫§ÊµÅÂíå‰ø°ÊÅØ‰º†ÈÄíÁöÑÈáçË¶ÅÁéØËäÇÔºå‰ΩøËØ≠Ë®Ä‰∫§ÊµÅÂèòÂæóÊõ¥Âä†**È´òÊïà„ÄÅ‰æøÊç∑**„ÄÇ  \n[ËØ≠ÁáïËæìÂÖ•Ê≥ï](https://github.com/gurecn/YuyanIme)ÁßâÊâøËøô‰∫õÁâπÁÇπÔºå‰ª•‚Äú**ÊòìÁî®„ÄÅÂø´ÈÄü„ÄÅÂáÜÁ°Æ**‚Äù‰∏∫Ê†∏ÂøÉÁêÜÂøµÔºåËøΩÊ±ÇÊûÅËá¥„ÄÅÂçìË∂ä„ÄÅÊµÅÁïÖÁöÑËæìÂÖ•‰ΩìÈ™å„ÄÇ Âú®ËÆæËÆ°‰∏äÔºåËØ≠ÁáïËæìÂÖ•Ê≥ïÂÄüÈâ¥‰∏ªÊµÅÁöÑË∞∑Ê≠åÊãºÈü≥„ÄÅÂæÆ‰ø°ËæìÂÖ•Ê≥ïÁ≠â‰∏ªÊµÅËæìÂÖ•Ê≥ïÁ≤æÂçéÔºåËøΩÊ±ÇÊï¥‰ΩìÁÆÄÊ¥ÅÂ§ßÊñπÔºåÊòì‰∫é‰∏äÊâã„ÄÇÊîØÊåÅÂ§öÁßçËæìÂÖ•ÊñπÂºèÔºåËßÑÂàíÂåÖÊã¨ÊãºÈü≥„ÄÅÊâãÂÜô„ÄÅËØ≠Èü≥Á≠âÔºåÊª°Ë∂≥‰∏çÂêåÁî®Êà∑ÁöÑËæìÂÖ•ÈúÄÊ±Ç„ÄÇÊîØÊåÅ‰∏∞ÂØåÁöÑ‰∏™ÊÄßÂåñËÆæÁΩÆÈÄâÈ°πÔºåÁî®Êà∑ÂèØ‰ª•Ê†πÊçÆËá™Â∑±ÁöÑÂñúÂ•ΩËøõË°åËá™ÂÆö‰πâËÆæÁΩÆÔºåËÆ©ËæìÂÖ•Êõ¥Âä†Á¨¶Âêà‰∏™‰∫∫‰π†ÊÉØ„ÄÇ\n## ÂÆâË£Ö‰ΩøÁî®Ôºö\nÂçé‰∏∫Â∫îÁî®Â∏ÇÂú∫Ôºö[Â∫îÁî®Âú∞ÂùÄ](https://appgallery.cloud.huawei.com/appDetail?pkgName=com.yuyan.pinyin.online.release)ÔºåÂ∫îÁî®ÂÆùÔºö[Â∫îÁî®Âú∞ÂùÄ](https://sj.qq.com/appdetail/com.yuyan.pinyin.online.release)ÔºåÂ∑≤‰∏äÊû∂ËØ≠ÁáïËæìÂÖ•Ê≥ïÔºåÂèØÁõ¥Êé•ÊêúÁ¥¢ÂÆâË£Ö„ÄÇ\n‰πüÂèØ‰ª•Áõ¥Êé•ÁÇπÂáª[Github Releases](https://github.com/gurecn/YuyanIme/releases)Ôºå‰∏ãËΩΩÊúÄÊñ∞ÁâàÊú¨ÂÆâË£ÖÂåÖÁõ¥Êé•ÂÆâË£Ö‰ΩøÁî®„ÄÇ \nÂõΩÂÜÖËÆøÈóÆGithubÊÖ¢ÁöÑËØùÔºåÂèØÁÇπÂáª[Gitee Releases](https://gitee.com/gurecn/YuyanIme/releases)‰∏ãËΩΩ„ÄÇ\nÊâãÊú∫Êâ´Á†Å‰∏ãËΩΩÂú∞ÂùÄÔºö\n| Github                           | Gitee                          |\n|----------------------------------|--------------------------------|\n| ![github](./download/github.png) | ![gitee](./download/gitee.png) |\n\n‰ΩøÁî®ËøáÁ®ã‰∏≠‰ªª‰ΩïÈóÆÈ¢òÂèØ‰ª•ÂàõÂª∫issues„ÄÅÂ∫îÁî®ÂÜÖÂèçÈ¶àÊàñÈÄöËøáÈÇÆ‰ª∂Á≠âÊñπÂºèÂèçÈ¶àÔºåÊú¨‰∫∫‰ºöÊ†πÊçÆÈúÄÊ±ÇÂèäÊó∂‰øÆÂ§ç„ÄÇ\n## ËÆæËÆ°ÂéüÂàôÔºö\n### Á∫ØËæìÂÖ•ÂäüËÉΩÔºå‰∏ªÊâìËΩªÂø´„ÄÇ\nÂñúÊ¨¢ÁÆÄÊ¥ÅÁöÑÊàëÁúãÂà∞‰∏Ä‰∏™‰∏™ÊãºÈü≥ËæìÂÖ•Ê≥ïÂ∑•ÂÖ∑ËΩØ‰ª∂ÈÄêÊ∏êË∂ãÂêëÁπÅÊùÇÔºåËΩØ‰ª∂ÂÜÖÂêÑÁßçÁúºËä±Áº≠‰π±ÁöÑÊó†Áî®ÂäüËÉΩ‰ª•ÂèäÁÉ¶‰∫∫ÁöÑÂπøÂëäËÆ©ÊàëÊó†Ê≥ïÂøçÂèó„ÄÇ  \n**Âõ†Ê≠§ÊàëÊÉ≥Ë¶ÅÂÆöÂà∂Âá∫‰∏ÄÊ¨æÁÆÄÊ¥Å„ÄÅÂÆûÁî®„ÄÅÂ•ΩÁî®ÁöÑËæìÂÖ•Ê≥ïÔºõ**\n### ÊúÄÂ∞è„ÄÅÂøÖË¶ÅÁöÑÊùÉÈôêÂéüÂàôÔºåÊõ¥ÂÆâÂÖ®„ÄÇ\nÂΩìÂâç‰∏ªÊµÅËæìÂÖ•Ê≥ïËé∑ÂèñÂêÑÁ±ªÈùûÂøÖË¶ÅÊùÉÈôêÔºåÊó†ËßÜÁî®Êà∑ÈöêÁßÅÔºåÈöèÊÑè‰∏ä‰º†„ÄÅÂàÜÊûêÁî®Êà∑Êï∞ÊçÆ„ÄÇËôΩÁÑ∂Â§ßÊï∞ÊçÆ‰∏ç‰ºöÂå∫Âà´ÂØπÂæÖÔºå‰ΩÜÊàë‰ªçÁÑ∂Â∏åÊúõËá™Â∑±ÁöÑÊï∞ÊçÆÂè™Âú®Ëá™Â∑±ÁöÑÊâãÊú∫ÈáåÔºå‰∏çË¶ÅÂú®Êàë‰∏çÁü•ÊÉÖ„ÄÅÊó†ÊÑèËØÜÁöÑÊÉÖÂÜµ‰∏ãÔºåÊääÊâÄÊúâÊï∞ÊçÆ‰∏ä‰º†„ÄÇ    \n**ËØ≠ÁáïËæìÂÖ•Ê≥ïË∞®ÈÅµÂæ™ÂøÖË¶Å„ÄÅÊúÄÂ∞èÂåñÊùÉÈôêÔºåÂè™‰∏∫ËæìÂÖ•ËÄåÂ≠òÂú®ÔºåÁ∫ØÂáÄ„ÄÅÂÆâÂÖ®„ÄÅÊõ¥È´òÊïà„ÄÇ**  \nËØ≠ÁáïËæìÂÖ•Ê≥ï‰ªÖ‰ΩøÁî®Á≥ªÁªüÈªòËÆ§‰∏∫ËæìÂÖ•Ê≥ïÂºÄÂêØÁöÑ`Ââ™Ë¥¥Êùø`ÔºàÂâ™Ë¥¥ÊùøÂäüËÉΩÔºâ„ÄÅ`ËÆæÂ§áËøêÂä®‰∏éÊñπÂêë`ÔºàÂ±èÂπïÊñπÂêëÂèòÊõ¥Ôºâ„ÄÅ`Â™í‰ΩìÈü≥ÊéßÂà∂`ÔºàÊåâÈîÆÈü≥ÊïàÔºâ„ÄÅ`ÊåØÂä®`ÔºàÊåâÈîÆÊåØÂä®ÔºâÊùÉÈôêÔºå‰∏çËé∑ÂèñÁΩëÁªú„ÄÅÂ≠òÂÇ®„ÄÅ‰ΩçÁΩÆ„ÄÅËæÖÂä©ÂäüËÉΩÁ≠âÂÖ∂‰ªñÊùÉÈôêÔºåÂÆåÂÖ®Á¶ªÁ∫ø‰∏ç‰∏ä‰º†‰∫ëÁ´ØÔºåËæìÂÖ•Êï∞ÊçÆ‰∏çÈááÈõÜ„ÄÅ‰∏çËÆ∞ÂΩïÔºå‰∏çËÆøÈóÆ‰ªª‰Ωï‰∏™‰∫∫„ÄÅÁªàÁ´Ø„ÄÅ‰ΩçÁΩÆ„ÄÅÂ≠òÂÇ®Á≠â‰ø°ÊÅØ„ÄÇ\n### Âü∫‰∫éRimeÂºïÊìéÔºå‰ΩÜÊõ¥Êòì‰∏äÊâã„ÄÇ\nÂΩìÂâçÂºÄÊîæÁöÑËæìÂÖ•Ê≥ïÂºïÊìé‰∏≠Ôºå[RimeÂºïÊìé](https://github.com/rime/librime)Â∑≤ÁªèË∂ãÂêëÂÆåÂñÑ„ÄÇÁÑ∂ÂêéÂØπ‰∫éÂ∞èÁôΩÁî®Êà∑Êù•ËØ¥Ôºå‰∏äÊâãÂç¥Âπ∂‰∏çÂÆπÊòìÔºöÂêÑÁßçËæìÂÖ•ÊñπÊ°àÂÆöÂà∂ÂèäÂÖºÂÆπÈóÆÈ¢òÔºåÂêÑÁßçÈîÆÁõòÁöÑÁïåÈù¢ÊïàÊûú‰ºòÂåñÈóÆÈ¢ò„ÄÇ  \n**Âõ†Ê≠§ÊàëÊÉ≥Ë¶ÅÂÆöÂà∂Âá∫‰∏ÄÊ¨æÂü∫‰∫éRimeÂºïÊìéÁöÑÂÆâË£ÖÂç≥Áî®ÔºåÂì™ÊÄïÊ≤°Êó∂Èó¥Á†îÁ©∂‰πüËÉΩÂ•ΩÁî®ÁöÑËæìÂÖ•Ê≥ïÔºõ**\n### ËæìÂÖ•Ê®°ÂºèÊõ¥ÂÆåÂñÑ„ÄÇ\nÊúÄÊó©Êé•Ëß¶ÂÆâÂçìÂπ≥Âè∞ÁöÑ[ÂêåÊñáËæìÂÖ•Ê≥ï](https://github.com/osfans)ÔºåÂêéÈù¢Êé•Ëß¶[Â∞è‰ºÅÈπÖËæìÂÖ•Ê≥ï](https://github.com/fcitx5-android/fcitx5-android)ÔºåÂùáÈááÁî®RimeÊñπÊ°àËøõË°åÂÆöÂà∂ÔºåÂú®ËæìÂÖ•Â±ÇÈù¢Â∑≤ÁªèÊª°Ë∂≥Â§ßÈÉ®ÂàÜÈúÄÊ±Ç„ÄÇ‰ΩÜÊòØÂ∞è‰ºÅÈπÖËæìÂÖ•Ê≥ï‰πùÂÆ´Ê†ºÈîÆÁõò‰∏çÊîØÊåÅÔºåÂêåÊñáËæìÂÖ•Ê≥ïÂÄôÈÄâËØçÈÄâÊã©‰∏ç‰æø‰∏îÊó†Ê≥ïÈÄâÊã©ÊãºÈü≥ÁªÑÂêàÔºå‰ΩøÁî®Ëµ∑Êù•Á°ÆÂÆûÈúÄË¶ÅÂãáÊ∞î„ÄÇ  \nËØ≠ÁáïËæìÂÖ•Ê≥ïÂÜÖÁΩÆÂ§öÂ•ó‰ºòÁßÄËØçÂ∫ìÔºå‰ºòÂåñRime‰πùÂÆ´ËæìÂÖ•ÊñπÊ°à„ÄÅ‰π±Â∫èËæìÂÖ•ÊñπÊ°àÔºåÊîØÊåÅÁªùÂ§ßÈÉ®ÂàÜËæìÂá∫Âú∫ÊôØÔºåÊèêÂçáËæìÂÖ•ÊïàÁéá„ÄÇ  \n**Âõ†Ê≠§ÊàëÊÉ≥ÂÆöÂà∂Âá∫‰∏ÄÊ¨æÊîØÊåÅÂØπÂ∞èÁôΩÁî®Êà∑Êù•ËØ¥‰ΩøÁî®Êõ¥ÊôÆÂèäÁöÑ‰πùÂÆ´Ê†ºÔºåÂêåÊó∂ÁªìÂêàÂÖ®ÈîÆ„ÄÅÂèåÊãº„ÄÅÊâãÂÜô„ÄÅËØ≠Èü≥Á≠âÂ§öÁßçÊñπÊ°àÁöÑËæìÂÖ•Ê≥ï„ÄÇ**  \n### ‰∏™ÊÄßÂåñÂÆöÂà∂Êõ¥Ë¥¥ÂøÉ„ÄÇ\nÊâãÊú∫Â±èÂπïË∂äÊù•Ë∂äÂ§ßÔºå‰ΩÜÊòØÂú®Ëµ∞Ë∑ØÊó∂Ôºå‰∏ÄÊâãÊèê‰∏úË•øÔºå‰∏ÄÊâãÊâìÂ≠óÂõûÂ§çÊ∂àÊÅØÂØπÊàëÊù•ËØ¥ÊòØ‰∏™Â§¥ÁñºÂú∞ÈóÆÈ¢òÔºåÈÄâÊã©ÂÄôÈÄâËØçÂ§ü‰∏çÂà∞„ÄÅÈÄâÊã©Âá∫ÈîôÂ±°Â±°Âá∫Áé∞ÔºåÂõ†Ê≠§ÊàëÂÆöÂà∂‰∫ÜÂçïÊâãÊ®°Âºè„ÄÅÊÇ¨ÊµÆÈîÆÁõò„ÄÇ  \nËæìÂÖ•Êï∞Â≠óË¶Å‰πàÂàáÊç¢Âà∞Êï∞Â≠óÈîÆÁõòÔºåË¶Å‰πàÈïøÊåâÊåâÈîÆËæìÂÖ•ÔºåÂØπËæìÂÖ•Êù•ËØ¥ÈÉΩ‰∏ç‰æøÊç∑ÔºåÂõ†Ê≠§ÊàëÂÆöÂà∂‰∫ÜÈîÆÁõòÊï∞Â≠óË°å„ÄÇ  \nÂ§úÈó¥ËæìÂÖ•Êó∂ÔºåÂ±èÂπïÂà∫ÁúºÔºåÂõ†Ê≠§ÊàëÂÆöÂà∂‰∫ÜÊ∑±Ëâ≤‰∏ªÈ¢òËá™Âä®ÂàáÊç¢ÂäüËÉΩ„ÄÇÊõ¥Â§öË¥¥ÂøÉÂÆöÂà∂È°πÊ≠£Âú®ËøõË°å‰∏≠„ÄÇ\n\n## ÂÆûÁé∞ÂäüËÉΩÔºö\n+ ÊñπÊ°àÂÜÖÁΩÆÔºöÂÖ®ÊãºÔºà‰πùÂÆ´Ê†º„ÄÅÂÖ®ÈîÆÔºâ„ÄÅÂèåÊãº(Â∞èÈπ§„ÄÅÊô∫ËÉΩABC„ÄÅËá™ÁÑ∂Á†Å„ÄÅÁ¥´ÂÖâ„ÄÅÂæÆËΩØ„ÄÅÊêúÁãó„ÄÅ‰π±Â∫è17)„ÄÅÊâãÂÜô„ÄÅ‰∫îÁ¨îÁîªÔºõÊîØÊåÅÁÆÄÊãº„ÄÅÂÖ®ÊãºÔºõ\n+ Ëã±ÊñáËæìÂÖ•ÔºöÊô∫ËÉΩÂÖ®ÈîÆËã±ÊñáËæìÂÖ•Ôºõ\n+ ËØçÂ∫ìÊãìÂ±ïÔºöÊîØÊåÅÈõæÂááËØçÂ∫ì„ÄÅÁôΩÈúúËØçÂ∫ìÁ≠âÂ§öÁßçËØçÂ∫ìÊãìÂ±ïÔºåËæìÂÖ•‰ΩìÈ™åËâØÂ•ΩÔºõ\n+ Á¨¶Âè∑ËæìÂÖ•Ôºö‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠¶„ÄÅÈ¢úÊñáÂ≠ó„ÄÅEMOJIË°®ÊÉÖËæìÂÖ•„ÄÅÂæÆ‰ø°ÁâπÊïàË°®ÊÉÖÔºõ\n+ Êï∞Â≠óËæìÂÖ•ÔºöÊï∞Â≠óÈîÆÁõòËæìÂÖ•„ÄÅÈîÆÁõòÊï∞Â≠óË°åËæìÂÖ•Ôºõ \n+ ÈîÆÁõòËá™ÂÆö‰πâÔºöËá™ÂÆö‰πâËèúÂçïÊ†è„ÄÅ‰∏ªÈ¢ò„ÄÅÊ∑±Ëâ≤Ê®°Âºè„ÄÅÈîÆÁõòË∞ÉËäÇ„ÄÅÈîÆÁõòÊï∞Â≠óË°å„ÄÅÈîÆÁõò‰ΩçÁΩÆÁßªÂä®Ôºõ \n+ ÂçïÊâãÈîÆÁõòÔºöÂ∑¶„ÄÅÂè≥ÊâãÊ®°ÂºèÂàáÊç¢Ôºõ\n+ ÊÇ¨ÊµÆÈîÆÁõòÔºöÊÇ¨ÊµÆÈîÆÁõòÊ®°ÂºèÔºåÈîÆÁõòÊãñÊãΩ„ÄÅÁßªÂä®Ôºõ\n+ Ëä±ÊºæÂ≠óËæìÂÖ•ÔºöÁÅ´ÊòüÊñáÔºàÁÑ±ÊöíÂ¶èÔºâ„ÄÅ Ëä±Ëó§Â≠óÔºàŒ∂‡∏±Õ°Ëä±‡∏±Õ°Ëó§‡∏±Õ°Â≠ó‡∏±Õ°‚úæÔºâ„ÄÅÂáå‰π±Â≠óÔºà\"“â“â“âÂáå“â“â“â‰π±“â“â“âÂ≠ó“â“â“âÔºâ„ÄÅÂèëËäΩÂ≠óÔºàÂèë‡ΩºËäΩ‡ΩºÂ≠ó‡ΩºÔºâ„ÄÅÈõæÈúæÂ≠óÔºà“à“à“à“àÈõæ“à“à“à“àÈúæ“à“à“à“àÂ≠ó“à“à“à“àÔºâ„ÄÅÁ¶ÅÊ≠¢Êü•ÁúãÔºàÁ¶Å‚É†Ê≠¢‚É†Êü•‚É†Áúã‚É†Ôºâ„ÄÅÈïøËçâÂ≠óÔºà\"“àÈïø“â“â“àËçâ“â“â“àÂ≠ó“âÔºâ„ÄÅËµ∑È£é‰∫ÜÔºà=ÕüÕüÕûÕûÈ£é=ÕüÕüÕûÕûÂ§™=ÕüÕüÕûÕûÂ§ß=ÕüÕüÕûÕûÔºâËä±ÊºæËæìÂÖ•Ôºõ \n+ ÊãºÈü≥ËæìÂÖ•Êâ©Â±ïÔºöÊîØÊåÅÁπÅ‰Ωì„ÄÅÁÆÄ‰ΩìÔºåÊîØÊåÅ‰∏≠Ëã±ÊñáÊ∑∑ËæìÔºåÊîØÊåÅË°®ÊÉÖÊèèËø∞ËæìÂÖ•Ôºõ\n+ Ââ™ÂàáÊùøÔºöÊîØÊåÅÂâ™ÂàáÊùøËÅîÊÉ≥ÊòæÁ§∫„ÄÅÂâ™ÂàáÊùøÂèäÊ∏ÖÁ©∫Êìç‰ΩúÔºõ\n+ Â∏∏Áî®ËØ≠ÔºöÊîØÊåÅËá™ÂÆö‰πâÂ∏∏Áî®ËØ≠„ÄÅÂ∏∏Áî®ËØ≠Âø´Êç∑ËæìÂÖ•„ÄÅÁºñËæë„ÄÅÂà†Èô§Á≠âÊìç‰ΩúÔºõ\n+ ÂÖ®Èù¢Â±èÈîÆÁõò‰ºòÂåñÔºöÊîØÊåÅÂÖ®Èù¢Â±èÈîÆÁõò‰ºòÂåñÂØºËà™Ê†èÂäüËÉΩÔºõ\n+ ÈöêËóèËæìÂÖ•Ê≥ïÂõæÊ†áÔºöÊîØÊåÅÈöêËóèËæìÂÖ•Ê≥ïÂõæÊ†áÂäüËÉΩ„ÄÇ\n\n## Â∑≤Áü•ÈóÆÈ¢òÔºö\n* Â∞èÁ±≥ÊâãÊú∫‰∏≠ÈîÆÁõòËèúÂçïÁÇπÂáªËÆæÁΩÆÁ≠âÊó†ÂèçÂ∫î:  \n  Áî±‰∫éÂ∞èÁ±≥ÊâãÊú∫‰∏≠ÈîÆÁõòË∑≥ËΩ¨Â∫îÁî®ÁïåÈù¢ÈúÄÂÄüÂä©`ÂêéÂè∞ÂºπÂá∫ÁïåÈù¢`ÊùÉÈôêÔºåËØ•ÊùÉÈôêÈúÄÁî®Êà∑ÊâãÂä®ÂºÄÂêØÔºöËÆæÁΩÆ-Â∫îÁî®ÁÆ°ÁêÜ-ËØ≠ÁáïËæìÂÖ•Ê≥ï-ÊùÉÈôêÁÆ°ÁêÜ-ÂºÄÂêØ`ÂêéÂè∞ÂºπÂá∫ÁïåÈù¢`ÊùÉÈôêÂç≥ÂèØ„ÄÇ\n* ‰∏âÊòüÊâãÊú∫ÊåâÈîÆÈü≥ÈáèË∞ÉËäÇÊó†Êïà:  \n  ËØ≠ÁáïËæìÂÖ•Ê≥ï‰ΩøÁî®Á≥ªÁªü`ÈÄöÁü•`Èü≥Èáè‰Ωú‰∏∫ÊåâÈîÆÈªòËÆ§Èü≥ÈáèÔºå‰ΩÜ‰∏çÂêåÊâãÊú∫Ë°®Áé∞‰∏çÂêå„ÄÇËæìÂÖ•Ê≥ï‰ºö‰ª•ÊâãÊú∫Á≥ªÁªüÈü≥ÈáèËÆæÁΩÆ‰∏∫ÂâçÊèêÔºåÂΩìÊâãÊú∫ÈùôÈü≥Êó∂ÔºåÊó†ËæìÂÖ•Ê≥ïÊåâÈîÆÈü≥„ÄÇÂΩìÊâãÊú∫Êú™ÈùôÈü≥Êó∂Ôºå‰ª•`ÈÄöÁü•`Èü≥ÈáèÂ§ßÂ∞è‰∏∫Âü∫ÂáÜËøõË°åË∞ÉËäÇ„ÄÇÂú®‰∏âÊòüÊâãÊú∫‰∏≠ÔºåÂü∫‰∫é`Á≥ªÁªü`Èü≥ÈáèÂ§ßÂ∞èËøõË°åË∞ÉËß£„ÄÇ\n* Âú®ËæìÂÖ•‰∏ÄÂçäÂÜÖÂÆπÊó∂ÂàáÊç¢Ê®™Á´ñÂ±èÔºåËæÉÂ§ßÊ¶ÇÁéáÂØºËá¥Ê®™Â±èÊ®°ÂºèÂ±èÂπïËß¶Êë∏Êó†ÊïàÔºå‰ªÖËÉΩÁÇπÂáªÈîÆÁõòÊåâÈîÆ„ÄÇ\n  ‰∏¥Êó∂ÊñπÊ°àÔºöÂàáÊç¢Ê®™Á´ñÂ±èÂâçÔºåÁ°Æ‰øùËæìÂÖ•Ê°ÜÂÜÖÂÆπ‰∏∫Á©∫„ÄÇ\n\n## ÂºÄÂèëÁéØÂ¢ÉÔºö\n> Android SDK: minSdk 23, [app/build.gradle](./app/build.gradle)  \n> Á¨¨‰∏âÊñπÂ∫ì: [build.gradle](./build.gradle)  \n> JDK: OpenJDK version \"17.0.11\" 2024-04-16\n\n## ÊûÑÂª∫È°πÁõÆÔºö\n### 1. ÂÖãÈöÜÊ≠§È°πÁõÆÂπ∂ÊãâÂèñÊâÄÊúâÂ≠êÊ®°Âùó„ÄÇ\n```sh\ngit clone git@github.com:gurecn/YuyanIme.git\ngit submodule update --init --recursive\n```\n### 2. ÂØºÂÖ•Android Studio\nÂª∫ËÆÆ‰ΩøÁî®ÊúÄÊñ∞„ÄÅÁ®≥ÂÆöÁâàÊú¨ÔºåÊú¨‰∫∫‰ΩøÁî®`Android Studio Iguana | 2023.2.1 Patch 1`ÁâàÊú¨ÔºåÊåâÁÖßÂ∏∏ËßÑÈ°πÁõÆÂØºÂÖ•Âç≥ÂèØÔºå`Android Studio`‰ºöËá™Âä®ÂÆâË£ÖÂπ∂ÈÖçÁΩÆ Android ÂºÄÂèëÁéØÂ¢É„ÄÇ\n\n## ÈîÆÁõòÈ¢ÑËßàÔºö\n| ‰πùÂÆ´ÈîÆÁõò | ÂÖ®ÊãºÈîÆÁõò | ‰π±Â∫è17 |\n| - | - | - |\n| ![‰πùÂÆ´Ê†ºÊãºÈü≥ÈîÆÁõò](./images/t9_pinyin.jpg) | ![ÂÖ®ÈîÆÊãºÈü≥ÈîÆÁõò](./images/qwerty_pinyin.jpg) | ![‰π±Â∫è17ÊãºÈü≥](./images/double_lx17.jpg) |\n\n| ÂèåÊãºÈîÆÁõò | Á¨îÁîªÈîÆÁõò | ÊâãÂÜôÈîÆÁõò |\n| - | - | - |\n| ![ÂèåÊãºÈîÆÁõò](./images/double_pinyin.jpg) | ![Á¨îÁîªÈîÆÁõò](./images/stroke_pinyin.jpg) | ![ÊâãÂÜôÈîÆÁõò](./images/writing_pinyin.jpg) |\n\n| Ëã±ËØ≠ÈîÆÁõò | Êï∞Â≠óÈîÆÁõò | ÁºñËæëÈîÆÁõò |\n| - | - | - |\n| ![Ëã±ËØ≠ÈîÆÁõò](./images/qwerty.jpg) |  ![Êï∞Â≠óÈîÆÁõò](./images/number.jpg) | ![ÁºñËæëÈîÆÁõò](./images/textedit.jpg) |\n\n| Ââ™ÂàáÊùø | ÂçïÊâãÈîÆÁõò | ÊÇ¨ÊµÆÈîÆÁõò |\n| - | - | - |\n| ![Ââ™ÂàáÊùø](./images/clipboard.jpg) | ![ÂçïÊâãÈîÆÁõò](./images/onehand.jpg) | ![ÊÇ¨ÊµÆÈîÆÁõò](./images/float.jpg) |\n\n| Ë°®ÊÉÖÈîÆÁõò | ÂæÆ‰ø°ÁâπÊïà | Êï∞Â≠óË°å |\n| - | - | - |\n| ![Ë°®ÊÉÖÈîÆÁõò](./images/emoji.jpg) | ![ÂæÆ‰ø°ÁâπÊïà](./images/emoji_wechat.jpg) | ![Êï∞Â≠óË°å](./images/number_line.jpg) |\n\n| Ê∑±Ëâ≤‰∏ªÈ¢ò | ËÆæÁΩÆËèúÂçï |\n| - | - |\n| ![Ê∑±Ëâ≤‰∏ªÈ¢ò](./images/dark.jpg) | ![ËÆæÁΩÆËèúÂçï](./images/setting.jpg) |\n\n## È∏£Ë∞¢Ôºö\nÊÑüË∞¢‰ª•‰∏ã‰ºòÁßÄÁöÑÂºÄÊ∫êÁ§æÂå∫Ë¥°ÁåÆÔºö\n- [RIME](http://rime.im)\n- [ÂêåÊñáËæìÂÖ•Ê≥ï](https://github.com/osfans)\n- [Â∞è‰ºÅÈπÖËæìÂÖ•Ê≥ï](https://github.com/fcitx5-android/fcitx5-android)\n- [ÈõæÂááÊãºÈü≥](https://github.com/iDvel/rime-ice)\n- [ÁôΩÈúúÊãºÈü≥](https://github.com/gaboolic/rime-frost)\n\n## ËÅîÁ≥ª‰ΩúËÄÖÔºö\nËÆøÈóÆÊàëÁöÑËµÑÊ∫ê: <a href=\"https://github.com/gurecn\">https://github.com/gurecn</a>  \n\nÁªôÊàëÂèëÈÄÅÈÇÆÁÆ±Ôºö[gurecn@163.com](mailto:gurecn@163.com)\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=gurecn/YuyanIme&type=Date)](https://star-history.com/#gurecn/YuyanIme&Date)\n\n\n\n\n",
      "stars_today": 4
    },
    {
      "id": 102578345,
      "name": "lede",
      "full_name": "coolsnowwolf/lede",
      "description": "Lean's LEDE source",
      "html_url": "https://github.com/coolsnowwolf/lede",
      "stars": 31243,
      "forks": 19532,
      "language": "C",
      "topics": [
        "lede",
        "lua",
        "openwrt-feed",
        "openwrt-package",
        "openwrt-zh-cn"
      ],
      "created_at": "2017-09-06T07:39:03Z",
      "updated_at": "2026-01-16T15:00:46Z",
      "pushed_at": "2026-01-16T15:00:19Z",
      "open_issues": 812,
      "owner": {
        "login": "coolsnowwolf",
        "avatar_url": "https://avatars.githubusercontent.com/u/31687149?v=4"
      },
      "readme": "# Ê¨¢ËøéÊù•Âà∞ Lean ÁöÑ LEDE Ê∫êÁ†Å‰ªìÂ∫ì\n\n‰∏∫ÂõΩ‰∫ßÈæôËäØ LOONGSON SoC loongarch64 / È£ûËÖæ Phytium ËÖæÈîê D2000 Á≥ªÂàóÊû∂ÊûÑÊ∑ªÂä†ÊîØÊåÅ\n\nI18N: [English](README_EN.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](README.md) | [Êó•Êú¨Ë™û](README_JA.md)\n\n## ÂÆòÊñπËÆ®ËÆ∫Áæ§\n\nÂ¶ÇÊúâÊäÄÊúØÈóÆÈ¢òÈúÄË¶ÅËÆ®ËÆ∫ÊàñËÄÖ‰∫§ÊµÅÔºåÊ¨¢ËøéÂä†ÂÖ•‰ª•‰∏ãÁæ§Ôºö\n\n1. QQ ËÆ®ËÆ∫Áæ§ÔºöOp Âõ∫‰ª∂ÊäÄÊúØÁ†îÁ©∂Áæ§ÔºåÂè∑Á†Å 891659613ÔºåÂä†Áæ§ÈìæÊé•Ôºö[ÁÇπÂáªÂä†ÂÖ•](https://qm.qq.com/q/IMa6Yf2SgC \"OpÂõ∫‰ª∂ÊäÄÊúØÁ†îÁ©∂Áæ§\")\n2. TG ËÆ®ËÆ∫Áæ§ÔºöOP ÁºñËØëÂÆòÊñπÂ§ßÁæ§ÔºåÂä†Áæ§ÈìæÊé•Ôºö[ÁÇπÂáªÂä†ÂÖ•](https://t.me/JhKgAA6Hx1 \"OP ÁºñËØëÂÆòÊñπÂ§ßÁæ§\")\n\n## ËΩØË∑ØÁî± ArmSoM Sige Á≥ªÂàó‰ªãÁªç\n\nArmSoM-Sige Á≥ªÂàóÔºöËΩØË∑ØÁî±„ÄÅÂçïÊùøËÆ°ÁÆóÊú∫„ÄÅÂ∞èÂûãÊúçÂä°Âô®‰∏éÊô∫ËÉΩÂÆ∂Â±ÖÁöÑÂÖ®ËÉΩ‰πãÈÄâ„ÄÇ\n\n[ÂïÜÂìÅ‰ªãÁªçÈ°µÈù¢ - ArmSom ÂìÅÁâåÂ∫ó](https://shop518100695.taobao.com/)\n\nË¥≠‰π∞ÈìæÊé•Ôºö\n\n[![sige1-zh](doc/sige-zh.jpg)](https://item.taobao.com/item.htm?id=721197662185)\n\n## Êñ∞‰∏Ä‰ª£ OpenWrt WIFI7 Á°¨Ë∑ØÁî± CW Q3600 Á≥ªÂàó‰ªãÁªç\n\nÁïÖÁΩëWi-Fi7 ÔºåÂ¶Ç7ËÄåËá≥Ôºà2.5GÁΩëÂè£ÔºâÔºåÂèåÁ≥ªÁªüËá™Áî±ÂàáÊç¢\n\n[ÂïÜÂìÅ‰ªãÁªçÈ°µÈù¢ - ÁïÖÁΩë ÂìÅÁâåÂ∫ó](https://www.changwang.cn/products.html?typeid=149)\n\nË¥≠‰π∞ÈìæÊé•Ôºö\n\n[![cw-zh](doc/cw-zh.jpg)](https://www.changwang.cn/product.html?id=29)\n\n## Ê≥®ÊÑè\n\n1. **‰∏çË¶ÅÁî® root Áî®Êà∑ËøõË°åÁºñËØë**\n2. ÂõΩÂÜÖÁî®Êà∑ÁºñËØëÂâçÊúÄÂ•ΩÂáÜÂ§áÂ•ΩÊ¢ØÂ≠ê\n3. ÈªòËÆ§ÁôªÈôÜIP 192.168.1.1 ÂØÜÁ†Å password\n\n## ÁºñËØëÂëΩ‰ª§\n\n1. È¶ñÂÖàË£ÖÂ•Ω Linux Á≥ªÁªüÔºåÊé®Ëçê Debian Êàñ Ubuntu LTS 22/24\n\n2. ÂÆâË£ÖÁºñËØë‰æùËµñ\n\n   ```bash\n   sudo apt update -y\n   sudo apt full-upgrade -y\n   sudo apt install -y ack antlr3 asciidoc autoconf automake autopoint binutils bison build-essential \\\n   bzip2 ccache clang cmake cpio curl device-tree-compiler flex gawk gcc-multilib g++-multilib gettext \\\n   genisoimage git gperf haveged help2man intltool libc6-dev-i386 libelf-dev libfuse-dev libglib2.0-dev \\\n   libgmp3-dev libltdl-dev libmpc-dev libmpfr-dev libncurses5-dev libncursesw5-dev libpython3-dev \\\n   libreadline-dev libssl-dev libtool llvm lrzsz libnsl-dev ninja-build p7zip p7zip-full patch pkgconf \\\n   python3 python3-pyelftools python3-setuptools qemu-utils rsync scons squashfs-tools subversion \\\n   swig texinfo uglifyjs upx-ucl unzip vim wget xmlto xxd zlib1g-dev\n   ```\n\n3. ‰∏ãËΩΩÊ∫ê‰ª£Á†ÅÔºåÊõ¥Êñ∞ feeds Âπ∂ÈÄâÊã©ÈÖçÁΩÆ\n\n   ```bash\n   git clone https://github.com/coolsnowwolf/lede\n   cd lede\n   ./scripts/feeds update -a\n   ./scripts/feeds install -a\n   make menuconfig\n   ```\n\n4. ‰∏ãËΩΩ dl Â∫ìÔºåÁºñËØëÂõ∫‰ª∂\nÔºà-j ÂêéÈù¢ÊòØÁ∫øÁ®ãÊï∞ÔºåÁ¨¨‰∏ÄÊ¨°ÁºñËØëÊé®ËçêÁî®ÂçïÁ∫øÁ®ãÔºâ\n\n   ```bash\n   make download -j8\n   make V=s -j1\n   ```\n\nÊú¨Â•ó‰ª£Á†Å‰øùËØÅËÇØÂÆöÂèØ‰ª•ÁºñËØëÊàêÂäü„ÄÇÈáåÈù¢ÂåÖÊã¨‰∫Ü R24 ÊâÄÊúâÊ∫ê‰ª£Á†ÅÔºåÂåÖÊã¨ IPK ÁöÑ„ÄÇ\n\n‰Ω†ÂèØ‰ª•Ëá™Áî±‰ΩøÁî®Ôºå‰ΩÜÊ∫êÁ†ÅÁºñËØë‰∫åÊ¨°ÂèëÂ∏ÉËØ∑Ê≥®ÊòéÊàëÁöÑ GitHub ‰ªìÂ∫ìÈìæÊé•„ÄÇË∞¢Ë∞¢Âêà‰ΩúÔºÅ\n\n‰∫åÊ¨°ÁºñËØëÔºö\n\n```bash\ncd lede\ngit pull\n./scripts/feeds update -a\n./scripts/feeds install -a\nmake defconfig\nmake download -j8\nmake V=s -j$(nproc)\n```\n\nÂ¶ÇÊûúÈúÄË¶ÅÈáçÊñ∞ÈÖçÁΩÆÔºö\n\n```bash\nrm -rf .config\nmake menuconfig\nmake V=s -j$(nproc)\n```\n\nÁºñËØëÂÆåÊàêÂêéËæìÂá∫Ë∑ØÂæÑÔºöbin/targets\n\n### ‰ΩøÁî® WSL/WSL2 ËøõË°åÁºñËØë\n\nÁî±‰∫é WSL ÁöÑ PATH ‰∏≠ÂåÖÂê´Â∏¶ÊúâÁ©∫Ê†ºÁöÑ Windows Ë∑ØÂæÑÔºåÊúâÂèØËÉΩ‰ºöÂØºËá¥ÁºñËØëÂ§±Ë¥•ÔºåËØ∑Âú® `make` ÂâçÈù¢Âä†‰∏äÔºö\n\n```bash\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n```\n\nÁî±‰∫éÈªòËÆ§ÊÉÖÂÜµ‰∏ãÔºåË£ÖËΩΩÂà∞ WSL ÂèëË°åÁâàÁöÑ NTFS Ê†ºÂºèÁöÑÈ©±Âä®Âô®Â∞Ü‰∏çÂå∫ÂàÜÂ§ßÂ∞èÂÜôÔºåÂõ†Ê≠§Â§ßÊ¶ÇÁéáÂú® WSL/WSL2 ÁöÑÁºñËØëÊ£ÄÊü•‰∏≠‰ºöËøîÂõû‰ª•‰∏ãÈîôËØØÔºö\n\n```txt\nBuild dependency: OpenWrt can only be built on a case-sensitive filesystem\n```\n\n‰∏Ä‰∏™ÊØîËæÉÁÆÄÊ¥ÅÁöÑËß£ÂÜ≥ÊñπÊ≥ïÊòØÔºåÂú® `git clone` ÂâçÂÖàÂàõÂª∫ Repository ÁõÆÂΩïÔºåÂπ∂‰∏∫ÂÖ∂ÂêØÁî®Â§ßÂ∞èÂÜôÊïèÊÑüÔºö\n\n```powershell\n# ‰ª•ÁÆ°ÁêÜÂëòË∫´‰ªΩÊâìÂºÄÁªàÁ´Ø\nPS > fsutil.exe file setCaseSensitiveInfo <your_local_lede_path> enable\n# Â∞ÜÊú¨È°πÁõÆ git clone Âà∞ÂºÄÂêØ‰∫ÜÂ§ßÂ∞èÂÜôÊïèÊÑüÁöÑÁõÆÂΩï <your_local_lede_path> ‰∏≠\nPS > git clone https://github.com/coolsnowwolf/lede <your_local_lede_path>\n```\n\n> ÂØπÂ∑≤Áªè `git clone` ÂÆåÊàêÁöÑÈ°πÁõÆÁõÆÂΩïÊâßË°å `fsutil.exe` ÂëΩ‰ª§Êó†Ê≥ïÁîüÊïàÔºåÂ§ßÂ∞èÂÜôÊïèÊÑüÂè™ÂØπÊñ∞Â¢ûÁöÑÊñá‰ª∂ÂèòÊõ¥ÊúâÊïà„ÄÇ\n\n### macOS ÂéüÁîüÁ≥ªÁªüËøõË°åÁºñËØë\n\n1. Âú® AppStore ‰∏≠ÂÆâË£Ö Xcode\n\n2. ÂÆâË£Ö HomebrewÔºö\n\n   ```bash\n   /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n   ```\n\n3. ‰ΩøÁî® Homebrew ÂÆâË£ÖÂ∑•ÂÖ∑Èìæ„ÄÅ‰æùËµñ‰∏éÂü∫Á°ÄËΩØ‰ª∂ÂåÖÔºö\n\n   ```bash\n   brew unlink awk\n   brew install coreutils diffutils findutils gawk gnu-getopt gnu-tar grep make ncurses pkg-config wget quilt xz\n   brew install gcc@11\n   ```\n\n4. ÁÑ∂ÂêéËæìÂÖ•‰ª•‰∏ãÂëΩ‰ª§ÔºåÊ∑ªÂä†Âà∞Á≥ªÁªüÁéØÂ¢ÉÂèòÈáè‰∏≠Ôºö\n\n   - intel ËäØÁâáÁöÑ mac\n\n   ```bash\n   echo 'export PATH=\"/usr/local/opt/coreutils/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/usr/local/opt/findutils/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/usr/local/opt/gnu-getopt/bin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/usr/local/opt/gnu-tar/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/usr/local/opt/grep/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/usr/local/opt/gnu-sed/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/usr/local/opt/make/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   ```\n\n   - apple ËäØÁâáÁöÑ mac\n\n   ```zsh\n   echo 'export PATH=\"/opt/homebrew/opt/coreutils/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/opt/homebrew/opt/findutils/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/opt/homebrew/opt/gnu-getopt/bin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/opt/homebrew/opt/gnu-tar/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/opt/homebrew/opt/grep/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/opt/homebrew/opt/gnu-sed/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   echo 'export PATH=\"/opt/homebrew/opt/make/libexec/gnubin:$PATH\"' >> ~/.bashrc\n   ```\n\n5. ÈáçÊñ∞Âä†ËΩΩ‰∏Ä‰∏ã shell ÂêØÂä®Êñá‰ª∂ `source ~/.bashrc`ÔºåÁÑ∂ÂêéËæìÂÖ• `bash` ËøõÂÖ• bash shellÔºåÂ∞±ÂèØ‰ª•Âíå Linux ‰∏ÄÊ†∑Ê≠£Â∏∏ÁºñËØë‰∫Ü\n\n## ÁâπÂà´ÊèêÁ§∫\n\n1. Ê∫ê‰ª£Á†Å‰∏≠Áªù‰∏çÂê´‰ªª‰ΩïÂêéÈó®ÂíåÂèØ‰ª•ÁõëÊéßÊàñËÄÖÂä´ÊåÅ‰Ω†ÁöÑ HTTPS ÁöÑÈó≠Ê∫êËΩØ‰ª∂Ôºå SSL ÂÆâÂÖ®ÊòØ‰∫íËÅîÁΩëÊúÄÂêéÁöÑÂ£ÅÂûíÔºåÂÆâÂÖ®Âπ≤ÂáÄÊâçÊòØÂõ∫‰ª∂Â∫îËØ•ÂÅöÂà∞ÁöÑ„ÄÇ\n\n2. ÊÉ≥Â≠¶‰π† OpenWrt ÂºÄÂèëÔºå‰ΩÜÊòØÊë∏‰∏çÁùÄÈó®ÈÅìÔºüËá™Â≠¶Ê≤°ÊØÖÂäõÔºüÂü∫Á°ÄÂ§™Â∑ÆÔºüÊÄïÂ§™ÈöæÂ≠¶‰∏ç‰ºöÔºüË∑üÁùÄ‰ΩêÂ§ßÂ≠¶ OpenWrt ÂºÄÂèëÂÖ•Èó®ÂüπËÆ≠Áè≠Âä©‰Ω†ËÉΩÂ≠¶ÊúâÊâÄÊàê\nÊä•ÂêçÂú∞ÂùÄÔºö[ÁÇπÂáªÊä•Âêç](http://forgotfun.org/2018/04/openwrt-training-2018.html \"Êä•Âêç\")\n\n3. QCA IPQ60xx ÂºÄÊ∫ê‰ªìÂ∫ìÂú∞ÂùÄÔºö<https://github.com/coolsnowwolf/openwrt-gl-ax1800>\n\n4. Â≠òÊ°£ÁâàÊú¨‰ªìÂ∫ìÂú∞ÂùÄÔºö<https://github.com/coolsnowwolf/openwrt>\n\n## ÊçêË¥à\n\nÂ¶ÇÊûú‰Ω†ËßâÂæóÊ≠§È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåÂèØ‰ª•ÊçêÂä©Êàë‰ª¨Ôºå‰ª•ÈºìÂä±È°πÁõÆËÉΩÊåÅÁª≠ÂèëÂ±ïÔºåÊõ¥Âä†ÂÆåÂñÑ\n\n ![star](doc/star.png)\n",
      "stars_today": 3
    },
    {
      "id": 70198664,
      "name": "lottie-ios",
      "full_name": "airbnb/lottie-ios",
      "description": "An iOS library to natively render After Effects vector animations",
      "html_url": "https://github.com/airbnb/lottie-ios",
      "stars": 26619,
      "forks": 3829,
      "language": "Swift",
      "topics": [
        "animation",
        "bodymovin",
        "custom-transitions",
        "ios",
        "ios-animation",
        "ios-transition",
        "keyframes",
        "swift",
        "transition-animation"
      ],
      "created_at": "2016-10-06T22:38:38Z",
      "updated_at": "2026-01-16T22:36:47Z",
      "pushed_at": "2026-01-13T14:44:25Z",
      "open_issues": 44,
      "owner": {
        "login": "airbnb",
        "avatar_url": "https://avatars.githubusercontent.com/u/698437?v=4"
      },
      "readme": "# Lottie for iOS\n [![Version](https://img.shields.io/cocoapods/v/lottie-ios.svg?style=flat)](https://cocoapods.org/pods/lottie-ios) [![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage) [![SwiftPM](https://img.shields.io/badge/SPM-supported-DE5C43.svg?style=flat)](https://swift.org/package-manager/) [![License](https://img.shields.io/cocoapods/l/lottie-ios.svg?style=flat)](https://cocoapods.org/pods/lottie-ios) [![Platform](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/airbnb/lottie-ios) [![Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/airbnb/lottie-ios)\n\n**View documentation, FAQ, help, examples, and more at [airbnb.io/lottie](https://airbnb.io/lottie/)**\n\nLottie is a cross-platform library for iOS, macOS, tvOS, visionOS, [Android](https://github.com/airbnb/lottie-android), and [Web](https://github.com/airbnb/lottie-web) that natively renders vector-based animations and art in realtime with minimal code.\n\nLottie loads and renders animations and vectors exported in the bodymovin JSON format. Bodymovin JSON can be created and exported from After Effects with [bodymovin](https://github.com/bodymovin/bodymovin), Sketch with [Lottie Sketch Export](https://github.com/buba447/Lottie-Sketch-Export), and from [Haiku](https://www.haikuanimator.com).\n\nDesigners can create **and ship** beautiful animations without an engineer painstakingly recreating them by hand.\nSince the animations are backed by JSON, they are extremely small in size but can be large in complexity!\nAnimations can be played, resized, looped, sped up, slowed down, reversed, and even interactively scrubbed.\nLottie can play or loop just a portion of the animation as well, the possibilities are endless!\nAnimations can even be ***changed at runtime*** in various ways! Change the color, position, or any keyframable value!\n\nHere is just a small sampling of the power of Lottie\n\n![Example1](_Gifs/Examples1.gif)\n![Example2](_Gifs/Examples2.gif)\n\n<img src=\"_Gifs/Community 2_3.gif\" />\n\n![Example3](_Gifs/Examples3.gif)\n\n![Abcs](_Gifs/Examples4.gif)\n\n## Installing Lottie\nLottie supports [Swift Package Manager](https://www.swift.org/package-manager/), [CocoaPods](https://cocoapods.org/), and [Carthage](https://github.com/Carthage/Carthage) (Both dynamic and static).\n\n### Github Repo\n\nYou can pull the [Lottie Github Repo](https://github.com/airbnb/lottie-ios/) and include the `Lottie.xcodeproj` to build a dynamic or static library.\n\n### Swift Package Manager\n\nTo install Lottie using [Swift Package Manager](https://github.com/swiftlang/swift-package-manager) you can follow the [tutorial published by Apple](https://developer.apple.com/documentation/xcode/adding_package_dependencies_to_your_app) using the URL for the Lottie repo with the current version:\n\n1. In Xcode, select ‚ÄúFile‚Äù ‚Üí ‚ÄúAdd Packages...‚Äù\n1. Enter https://github.com/airbnb/lottie-spm.git\n\nor you can add the following dependency to your `Package.swift`:\n\n```swift\n.package(url: \"https://github.com/airbnb/lottie-spm.git\", from: \"4.5.2\")\n```\n\nWhen using Swift Package Manager we recommend using the [lottie-spm](https://github.com/airbnb/lottie-spm) repo instead of the main lottie-ios repo.  The main git repository for [lottie-ios](https://github.com/airbnb/lottie-ios) is somewhat large (300+ MB), and Swift Package Manager always downloads the full repository with all git history. The [lottie-spm](https://github.com/airbnb/lottie-spm) repo is much smaller (less than 500kb), so can be downloaded much more quickly. \n\nInstead of downloading the full git history of Lottie and building it from source, the lottie-spm repo just contains a pointer to the precompiled XCFramework included in the [latest lottie-ios release](https://github.com/airbnb/lottie-ios/releases/latest) (typically ~8MB). If you prefer to include Lottie source directly your project, you can directly depend on the main lottie-ios repo by referencing `https://github.com/airbnb/lottie-ios.git` instead.\n\n### CocoaPods\nAdd the pod to your Podfile:\n```ruby\npod 'lottie-ios'\n```\n\nAnd then run:\n```ruby\npod install\n```\nAfter installing the cocoapod into your project import Lottie with\n```swift\nimport Lottie\n```\n\n### Carthage\nAdd Lottie to your Cartfile:\n```\ngithub \"airbnb/lottie-ios\" \"master\"\n```\n\nAnd then run:\n```\ncarthage update\n```\nIn your application targets ‚ÄúGeneral‚Äù tab under the ‚ÄúLinked Frameworks and Libraries‚Äù section, drag and drop lottie-ios.framework from the Carthage/Build/iOS directory that `carthage update` produced.\n\n## Swift Version Support\n\nLottie supports Swift / Xcode versions back to the minimum version that is permitted by Apple for submissions to the App Store. You can see the most up-to-date information for which Swift versions Lottie supports on [Swift Package Index](https://swiftpackageindex.com/airbnb/lottie-ios):\n\n[![Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/airbnb/lottie-ios)\n\n## Privacy\n\nLottie does not collect any data. We provide this notice to help you fill out [App Privacy Details](https://developer.apple.com/app-store/app-privacy-details/). We additionally provide a [privacy manifest](https://github.com/airbnb/lottie-ios/blob/master/Sources/PrivacyInfo.xcprivacy) which can be included in your app.\n\n## Security\n\nWe distribute XCFramework bundles for each release on [GitHub](https://github.com/airbnb/lottie-ios/releases/latest). In Lottie 4.4.0 and later, these XCFramework bundles include a [code signature](https://developer.apple.com/documentation/xcode/verifying-the-origin-of-your-xcframeworks). These bundles are self-signed under the name \"Lottie iOS\" and have the following fingerprint:\n\n```\n89 2F 1B 43 04 7B 50 53 8F 2F 46 EA D9 29 00 DD 3D 48 11 F358 21 78 C0 61 A5 FB 20 F1 11 CB 26\n```\n\nIn Xcode you can verify this by selecting `Lottie.xcframework` and confirming that it shows the following information:\n\n![Code Signature in Xcode](_Gifs/code_signature.png)\n\n## Contributing\n\nWe always appreciate contributions from the community. To make changes to the project, you can clone the repo and open `Lottie.xcworkspace`. This workspace includes:\n - the Lottie framework (for iOS, macOS, and tvOS)\n - unit tests and snapshot tests (for iOS, must be run on an iPhone 8 simulator)\n - an Example iOS app that lets you browse and test over 100 sample animations included in the repo\n\nAll pull requests with new features or bug fixes that affect how animations render should include snapshot test cases that validate the included changes. \n  - To add a new sample animation to the snapshot testing suite, you can add the `.json` file to `Tests/Samples`. Re-run the snapshot tests to generate the new snapshot image files.\n  - To update existing snapshots after making changes, you can set `isRecording = true` in `SnapshotTests.swift` `setUp()` method and then re-run the snapshot tests.\n\nThe project also includes several helpful commands defined in our [Rakefile](https://github.com/airbnb/lottie-ios/blob/master/Rakefile). To use these, you need to install [Bundler](https://bundler.io/):\n\n```bash\n$ sudo gem install bundle\n$ bundle install\n```\n\nFor example, all Swift code should be formatted according to the [Airbnb Swift Style Guide](https://github.com/airbnb/swift). After making changes, you can reformat the code automatically using [SwiftFormat](https://github.com/nicklockwood/SwiftFormat) and [SwiftLint](https://github.com/realm/SwiftLint) by running `bundle exec rake format:swift`. Other helpful commands include:\n\n```bash\n$ bundle exec rake build:all # builds all targets for all platforms\n$ bundle exec rake build:package:iOS # builds the Lottie package for iOS\n$ bundle exec rake test:package # tests the Lottie package\n$ bundle exec rake format:swift # reformat Swift code based on the Airbnb Swift Style Guide\n```\n",
      "stars_today": 3
    },
    {
      "id": 261039251,
      "name": "swift-composable-architecture",
      "full_name": "pointfreeco/swift-composable-architecture",
      "description": "A library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind.",
      "html_url": "https://github.com/pointfreeco/swift-composable-architecture",
      "stars": 14260,
      "forks": 1626,
      "language": "Swift",
      "topics": [
        "architecture",
        "composition",
        "modularity",
        "swiftui",
        "testability",
        "uikit"
      ],
      "created_at": "2020-05-03T23:18:40Z",
      "updated_at": "2026-01-16T02:34:15Z",
      "pushed_at": "2025-12-30T21:38:44Z",
      "open_issues": 23,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# The Composable Architecture\n\n[![CI](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml/badge.svg)](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](https://www.pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n\nThe Composable Architecture (TCA, for short) is a library for building applications in a consistent \nand understandable way, with composition, testing, and ergonomics in mind. It can be used in \nSwiftUI, UIKit, and more, and on any Apple platform (iOS, macOS, iPadOS, visionOS, tvOS, and watchOS).\n\n* [What is the Composable Architecture?](#what-is-the-composable-architecture)\n* [Learn more](#learn-more)\n* [Examples](#examples)\n* [Basic usage](#basic-usage)\n* [Documentation](#documentation)\n* [FAQ](#faq)\n* [Community](#community)\n* [Installation](#installation)\n* [Translations](#translations)\n\n## What is the Composable Architecture?\n\nThis library provides a few core tools that can be used to build applications of varying purpose and \ncomplexity. It provides compelling stories that you can follow to solve many problems you encounter \nday-to-day when building applications, such as:\n\n* **State management**\n  <br> How to manage the state of your application using simple value types, and share state across \n  many screens so that mutations in one screen can be immediately observed in another screen.\n\n* **Composition**\n  <br> How to break down large features into smaller components that can be extracted to their own, \n  isolated modules and be easily glued back together to form the feature.\n\n* **Side effects**\n  <br> How to let certain parts of the application talk to the outside world in the most testable \n  and understandable way possible.\n\n* **Testing**\n  <br> How to not only test a feature built in the architecture, but also write integration tests \n  for features that have been composed of many parts, and write end-to-end tests to understand how \n  side effects influence your application. This allows you to make strong guarantees that your \n  business logic is running in the way you expect.\n\n* **Ergonomics**\n  <br> How to accomplish all of the above in a simple API with as few concepts and moving parts as \n  possible.\n\n## Learn More\n\nThe Composable Architecture was designed over the course of many episodes on \n[Point-Free][pointfreeco], a video series exploring advanced programming topics in the Swift language, \nhosted by [Brandon Williams][mbrandonw] and [Stephen Celis][stephencelis].\n\nYou can watch all of the episodes [here][tca-episode-collection], as well as a dedicated, [multipart\ntour][tca-tour] of the architecture from scratch.\n\n<a href=\"https://www.pointfree.co/collections/tours/composable-architecture-1-0\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0243.jpeg\" width=\"600\">\n</a>\n\n## Examples\n\n[![Screen shots of example applications](https://d3rccdn33rt8ze.cloudfront.net/composable-architecture/demos.png)](./Examples)\n\nThis repo comes with _lots_ of examples to demonstrate how to solve common and complex problems with \nthe Composable Architecture. Check out [this](./Examples) directory to see them all, including:\n\n* [Case Studies](./Examples/CaseStudies)\n  * Getting started\n  * Effects\n  * Navigation\n  * Higher-order reducers\n  * Reusable components\n* [Location manager](https://github.com/pointfreeco/composable-core-location/tree/main/Examples/LocationManager)\n* [Motion manager](https://github.com/pointfreeco/composable-core-motion/tree/main/Examples/MotionManager)\n* [Search](./Examples/Search)\n* [Speech Recognition](./Examples/SpeechRecognition)\n* [SyncUps app](./Examples/SyncUps)\n* [Tic-Tac-Toe](./Examples/TicTacToe)\n* [Todos](./Examples/Todos)\n* [Voice memos](./Examples/VoiceMemos)\n\nLooking for something more substantial? Check out the source code for [isowords][gh-isowords], an \niOS word search game built in SwiftUI and the Composable Architecture.\n\n## Basic Usage\n\n> [!Note] \n> For a step-by-step interactive tutorial, be sure to check out [Meet the Composable\n> Architecture][meet-tca].\n\nTo build a feature using the Composable Architecture you define some types and values that model \nyour domain:\n\n* **State**: A type that describes the data your feature needs to perform its logic and render its \nUI.\n* **Action**: A type that represents all of the actions that can happen in your feature, such as \nuser actions, notifications, event sources and more.\n* **Reducer**: A function that describes how to evolve the current state of the app to the next \nstate given an action. The reducer is also responsible for returning any effects that should be \nrun, such as API requests, which can be done by returning an `Effect` value.\n* **Store**: The runtime that actually drives your feature. You send all user actions to the store \nso that the store can run the reducer and effects, and you can observe state changes in the store \nso that you can update UI.\n\nThe benefits of doing this are that you will instantly unlock testability of your feature, and you \nwill be able to break large, complex features into smaller domains that can be glued together.\n\nAs a basic example, consider a UI that shows a number along with \"+\" and \"‚àí\" buttons that increment \nand decrement the number. To make things interesting, suppose there is also a button that when \ntapped makes an API request to fetch a random fact about that number and displays it in the view.\n\nTo implement this feature we create a new type that will house the domain and behavior of the \nfeature, and it will be annotated with the `@Reducer` macro:\n\n```swift\nimport ComposableArchitecture\n\n@Reducer\nstruct Feature {\n}\n```\n\nIn here we need to define a type for the feature's state, which consists of an integer for the \ncurrent count, as well as an optional string that represents the fact being presented:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable {\n    var count = 0\n    var numberFact: String?\n  }\n}\n```\n\n> [!Note] \n> We've applied the `@ObservableState` macro to `State` in order to take advantage of the\n> observation tools in the library.\n\nWe also need to define a type for the feature's actions. There are the obvious actions, such as \ntapping the decrement button, increment button, or fact button. But there are also some slightly \nnon-obvious ones, such as the action that occurs when we receive a response from the fact API \nrequest:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action {\n    case decrementButtonTapped\n    case incrementButtonTapped\n    case numberFactButtonTapped\n    case numberFactResponse(String)\n  }\n}\n```\n\nAnd then we implement the `body` property, which is responsible for composing the actual logic and \nbehavior for the feature. In it we can use the `Reduce` reducer to describe how to change the\ncurrent state to the next state, and what effects need to be executed. Some actions don't need to\nexecute effects, and they can return `.none` to represent that:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action { /* ... */ }\n\n  var body: some Reducer<State, Action> {\n    Reduce { state, action in\n      switch action {\n      case .decrementButtonTapped:\n        state.count -= 1\n        return .none\n\n      case .incrementButtonTapped:\n        state.count += 1\n        return .none\n\n      case .numberFactButtonTapped:\n        return .run { [count = state.count] send in\n          let (data, _) = try await URLSession.shared.data(\n            from: URL(string: \"http://numbersapi.com/\\(count)/trivia\")!\n          )\n          await send(\n            .numberFactResponse(String(decoding: data, as: UTF8.self))\n          )\n        }\n\n      case let .numberFactResponse(fact):\n        state.numberFact = fact\n        return .none\n      }\n    }\n  }\n}\n```\n\nAnd then finally we define the view that displays the feature. It holds onto a `StoreOf<Feature>` \nso that it can observe all changes to the state and re-render, and we can send all user actions to \nthe store so that state changes:\n\n```swift\nstruct FeatureView: View {\n  let store: StoreOf<Feature>\n\n  var body: some View {\n    Form {\n      Section {\n        Text(\"\\(store.count)\")\n        Button(\"Decrement\") { store.send(.decrementButtonTapped) }\n        Button(\"Increment\") { store.send(.incrementButtonTapped) }\n      }\n\n      Section {\n        Button(\"Number fact\") { store.send(.numberFactButtonTapped) }\n      }\n      \n      if let fact = store.numberFact {\n        Text(fact)\n      }\n    }\n  }\n}\n```\n\nIt is also straightforward to have a UIKit controller driven off of this store. You can observe\nstate changes in the store in `viewDidLoad`, and then populate the UI components with data from\nthe store. The code is a bit longer than the SwiftUI version, so we have collapsed it here:\n\n<details>\n  <summary>Click to expand!</summary>\n\n  ```swift\n  class FeatureViewController: UIViewController {\n    let store: StoreOf<Feature>\n\n    init(store: StoreOf<Feature>) {\n      self.store = store\n      super.init(nibName: nil, bundle: nil)\n    }\n\n    required init?(coder: NSCoder) {\n      fatalError(\"init(coder:) has not been implemented\")\n    }\n\n    override func viewDidLoad() {\n      super.viewDidLoad()\n\n      let countLabel = UILabel()\n      let decrementButton = UIButton()\n      let incrementButton = UIButton()\n      let factLabel = UILabel()\n      \n      // Omitted: Add subviews and set up constraints...\n      \n      observe { [weak self] in\n        guard let self \n        else { return }\n        \n        countLabel.text = \"\\(self.store.count)\"\n        factLabel.text = self.store.numberFact\n      }\n    }\n\n    @objc private func incrementButtonTapped() {\n      self.store.send(.incrementButtonTapped)\n    }\n    @objc private func decrementButtonTapped() {\n      self.store.send(.decrementButtonTapped)\n    }\n    @objc private func factButtonTapped() {\n      self.store.send(.numberFactButtonTapped)\n    }\n  }\n  ```\n</details>\n\nOnce we are ready to display this view, for example in the app's entry point, we can construct a \nstore. This can be done by specifying the initial state to start the application in, as well as \nthe reducer that will power the application:\n\n```swift\nimport ComposableArchitecture\n\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd that is enough to get something on the screen to play around with. It's definitely a few more \nsteps than if you were to do this in a vanilla SwiftUI way, but there are a few benefits. It gives \nus a consistent manner to apply state mutations, instead of scattering logic in some observable \nobjects and in various action closures of UI components. It also gives us a concise way of \nexpressing side effects. And we can immediately test this logic, including the effects, without \ndoing much additional work.\n\n### Testing\n\n> [!Note] \n> For more in-depth information on testing, see the dedicated [testing][testing-article] article. \n\nTo test use a `TestStore`, which can be created with the same information as the `Store`, but it \ndoes extra work to allow you to assert how your feature evolves as actions are sent:\n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature()\n  }\n}\n```\n\nOnce the test store is created we can use it to make an assertion of an entire user flow of steps. \nEach step of the way we need to prove that state changed how we expect. For example, we can \nsimulate the user flow of tapping on the increment and decrement buttons:\n\n```swift\n// Test that tapping on the increment/decrement buttons changes the count\nawait store.send(.incrementButtonTapped) {\n  $0.count = 1\n}\nawait store.send(.decrementButtonTapped) {\n  $0.count = 0\n}\n```\n\nFurther, if a step causes an effect to be executed, which feeds data back into the store, we must \nassert on that. For example, if we simulate the user tapping on the fact button we expect to \nreceive a fact response back with the fact, which then causes the `numberFact` state to be \npopulated:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = ???\n}\n```\n\nHowever, how do we know what fact is going to be sent back to us?\n\nCurrently our reducer is using an effect that reaches out into the real world to hit an API server, \nand that means we have no way to control its behavior. We are at the whims of our internet \nconnectivity and the availability of the API server in order to write this test.\n\nIt would be better for this dependency to be passed to the reducer so that we can use a live \ndependency when running the application on a device, but use a mocked dependency for tests. We can \ndo this by adding a property to the `Feature` reducer:\n\n```swift\n@Reducer\nstruct Feature {\n  let numberFact: (Int) async throws -> String\n  // ...\n}\n```\n\nThen we can use it in the `reduce` implementation:\n\n```swift\ncase .numberFactButtonTapped:\n  return .run { [count = state.count] send in \n    let fact = try await self.numberFact(count)\n    await send(.numberFactResponse(fact))\n  }\n```\n\nAnd in the entry point of the application we can provide a version of the dependency that actually \ninteracts with the real world API server:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature(\n            numberFact: { number in\n              let (data, _) = try await URLSession.shared.data(\n                from: URL(string: \"http://numbersapi.com/\\(number)\")!\n              )\n              return String(decoding: data, as: UTF8.self)\n            }\n          )\n        }\n      )\n    }\n  }\n}\n```\n\nBut in tests we can use a mock dependency that immediately returns a deterministic, predictable \nfact: \n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature(numberFact: { \"\\($0) is a good number Brent\" })\n  }\n}\n```\n\nWith that little bit of upfront work we can finish the test by simulating the user tapping on the \nfact button, and then receiving the response from the dependency to present the fact:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = \"0 is a good number Brent\"\n}\n```\n\nWe can also improve the ergonomics of using the `numberFact` dependency in our application. Over \ntime the application may evolve into many features, and some of those features may also want access \nto `numberFact`, and explicitly passing it through all layers can get annoying. There is a process \nyou can follow to ‚Äúregister‚Äù dependencies with the library, making them instantly available to any \nlayer in the application.\n\n> [!Note] \n> For more in-depth information on dependency management, see the dedicated\n> [dependencies][dependencies-article] article. \n\nWe can start by wrapping the number fact functionality in a new type:\n\n```swift\nstruct NumberFactClient {\n  var fetch: (Int) async throws -> String\n}\n```\n\nAnd then registering that type with the dependency management system by conforming the client to\nthe `DependencyKey` protocol, which requires you to specify the live value to use when running the\napplication in simulators or devices:\n\n```swift\nextension NumberFactClient: DependencyKey {\n  static let liveValue = Self(\n    fetch: { number in\n      let (data, _) = try await URLSession.shared\n        .data(from: URL(string: \"http://numbersapi.com/\\(number)\")!\n      )\n      return String(decoding: data, as: UTF8.self)\n    }\n  )\n}\n\nextension DependencyValues {\n  var numberFact: NumberFactClient {\n    get { self[NumberFactClient.self] }\n    set { self[NumberFactClient.self] = newValue }\n  }\n}\n```\n\nWith that little bit of upfront work done you can instantly start making use of the dependency in \nany feature by using the `@Dependency` property wrapper:\n\n```diff\n @Reducer\n struct Feature {\n-  let numberFact: (Int) async throws -> String\n+  @Dependency(\\.numberFact) var numberFact\n   \n   ‚Ä¶\n\n-  try await self.numberFact(count)\n+  try await self.numberFact.fetch(count)\n }\n```\n\nThis code works exactly as it did before, but you no longer have to explicitly pass the dependency \nwhen constructing the feature's reducer. When running the app in previews, the simulator or on a \ndevice, the live dependency will be provided to the reducer, and in tests the test dependency will \nbe provided.\n\nThis means the entry point to the application no longer needs to construct dependencies:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd the test store can be constructed without specifying any dependencies, but you can still \noverride any dependency you need to for the purpose of the test:\n\n```swift\nlet store = TestStore(initialState: Feature.State()) {\n  Feature()\n} withDependencies: {\n  $0.numberFact.fetch = { \"\\($0) is a good number Brent\" }\n}\n\n// ...\n```\n\nThat is the basics of building and testing a feature in the Composable Architecture. There are \n_a lot_ more things to be explored, such as composition, modularity, adaptability, and complex \neffects. The [Examples](./Examples) directory has a bunch of projects to explore to see more \nadvanced usages.\n\n## Documentation\n\nThe documentation for releases and `main` are available here:\n\n* [`main`](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture)\n* [1.x.x](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/~/documentation/composablearchitecture)\n\nThere are a number of articles in the documentation that you may find helpful as you become more \ncomfortable with the library:\n\n* [Getting started][getting-started-article]\n* [Dependencies][dependencies-article]\n* [Testing][testing-article]\n* [Navigation][navigation-article]\n* [Sharing state][sharing-state-article]\n* [Performance][performance-article]\n* [Concurrency][concurrency-article]\n* [Bindings][bindings-article]\n\n## FAQ\n\nWe have a [dedicated article][faq-article] for all of the most frequently asked questions and\ncomments people have concerning the library.\n\n## Community\n\nIf you want to discuss the Composable Architecture or have a question about how to use it to solve \na particular problem, there are a number of places you can discuss with fellow \n[Point-Free](http://www.pointfree.co) enthusiasts:\n\n* For long-form discussions, we recommend the [discussions][gh-discussions] tab of this repo.\n* For casual chat, we recommend the [Point-Free Community slack](http://pointfree.co/slack-invite).\n\n## Installation\n\nYou can add ComposableArchitecture to an Xcode project by adding it as a package dependency.\n\n  1. From the **File** menu, select **Add Package Dependencies...**\n  2. Enter \"https://github.com/pointfreeco/swift-composable-architecture\" into the package \n     repository URL text field\n  3. Depending on how your project is structured:\n      - If you have a single application target that needs access to the library, then add \n        **ComposableArchitecture** directly to your application.\n      - If you want to use this library from multiple Xcode targets, or mix Xcode targets and SPM \n        targets, you must create a shared framework that depends on **ComposableArchitecture** and \n        then depend on that framework in all of your targets. For an example of this, check out the \n        [Tic-Tac-Toe](./Examples/TicTacToe) demo application, which splits lots of features into \n        modules and consumes the static library in this fashion using the **tic-tac-toe** Swift \n        package.\n\n## Companion libraries\n\nThe Composable Architecture is built with extensibility in mind, and there are a number of\ncommunity-supported libraries available to enhance your applications:\n\n* [Composable Architecture Extras](https://github.com/Ryu0118/swift-composable-architecture-extras):\n  A companion library to the Composable Architecture.\n* [TCAComposer](https://github.com/mentalflux/tca-composer): A macro framework for generating\n  boiler-plate code in the Composable Architecture.\n* [TCACoordinators](https://github.com/johnpatrickmorgan/TCACoordinators): The coordinator pattern\n  in the Composable Architecture.\n\nIf you'd like to contribute a library, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link\nto it!\n\n## Translations\n\nThe following translations of this README have been contributed by members of the community:\n\n* [Arabic](https://gist.github.com/NorhanBoghdadi/1b98d55c02b683ddef7e05c2ebcccd47)\n* [French](https://gist.github.com/nikitamounier/0e93eb832cf389db12f9a69da030a2dc)\n* [Hindi](https://gist.github.com/akashsoni01/b358ee0b3b747167964ef6946123c88d)\n* [Indonesian](https://gist.github.com/wendyliga/792ea9ac5cc887f59de70a9e39cc7343)\n* [Italian](https://gist.github.com/Bellaposa/5114e6d4d55fdb1388e8186886d48958)\n* [Japanese](https://gist.github.com/Achoo-kr/2d0712deb77f78b3379551ac7baea3e4)\n* [Korean](https://gist.github.com/Achoo-kr/5d8936d12e71028fcc4a7c5e078ca038)\n* [Polish](https://gist.github.com/MarcelStarczyk/6b6153051f46912a665c32199f0d1d54)\n* [Portuguese](https://gist.github.com/SevioCorrea/2bbf337cd084a58c89f2f7f370626dc8)\n* [Russian](https://gist.github.com/SubvertDev/3317d0c3b35ed601be330d6fc0df5aba)\n* [Simplified Chinese](https://gist.github.com/sh3l6orrr/10c8f7c634a892a9c37214f3211242ad)\n* [Spanish](https://gist.github.com/pitt500/f5e32fccb575ce112ffea2827c7bf942)\n* [Turkish](https://gist.github.com/gokhanamal/93001244ef0c1cec58abeb1afc0de37c)\n* [Ukrainian](https://gist.github.com/barabashd/33b64676195ce41f4bb73c327ea512a8)\n\nIf you'd like to contribute a translation, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link \nto a [Gist](https://gist.github.com)!\n\n## Credits and thanks\n\nThe following people gave feedback on the library at its early stages and helped make the library \nwhat it is today:\n\nPaul Colton, Kaan Dedeoglu, Matt Diephouse, Josef Dole≈æal, Eimantas, Matthew Johnson, George \nKaimakas, Nikita Leonov, Christopher Liscio, Jeffrey Macko, Alejandro Martinez, Shai Mishali, Willis \nPlummer, Simon-Pierre Roy, Justin Price, Sven A. Schmidt, Kyle Sherman, Petr ≈†√≠ma, Jasdev Singh, \nMaxim Smirnov, Ryan Stone, Daniel Hollis Tavares, and all of the [Point-Free][pointfreeco] \nsubscribers üòÅ.\n\nSpecial thanks to [Chris Liscio](https://twitter.com/liscio) who helped us work through many strange \nSwiftUI quirks and helped refine the final API.\n\nAnd thanks to [Shai Mishali](https://github.com/freak4pc) and the\n[CombineCommunity](https://github.com/CombineCommunity/CombineExt/) project, from which we took \ntheir implementation of `Publishers.Create`, which we use in `Effect` to help bridge delegate and \ncallback-based APIs, making it much easier to interface with 3rd party frameworks.\n\n## Other libraries\n\nThe Composable Architecture was built on a foundation of ideas started by other libraries, in \nparticular [Elm](https://elm-lang.org) and [Redux](https://redux.js.org/).\n\nThere are also many architecture libraries in the Swift and iOS community. Each one of these has \ntheir own set of priorities and trade-offs that differ from the Composable Architecture.\n\n* [RIBs](https://github.com/uber/RIBs)\n* [Loop](https://github.com/ReactiveCocoa/Loop)\n* [ReSwift](https://github.com/ReSwift/ReSwift)\n* [Workflow](https://github.com/square/workflow)\n* [ReactorKit](https://github.com/ReactorKit/ReactorKit)\n* [RxFeedback](https://github.com/NoTests/RxFeedback.swift)\n* [Mobius.swift](https://github.com/spotify/mobius.swift)\n* <details>\n  <summary>And more</summary>\n\n  * [Fluxor](https://github.com/FluxorOrg/Fluxor)\n  * [PromisedArchitectureKit](https://github.com/RPallas92/PromisedArchitectureKit)\n  </details>\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n\n[pointfreeco]: https://www.pointfree.co\n[mbrandonw]: https://twitter.com/mbrandonw\n[stephencelis]: https://twitter.com/stephencelis\n[tca-episode-collection]: https://www.pointfree.co/collections/composable-architecture\n[tca-tour]: https://www.pointfree.co/collections/tours/composable-architecture-1-0\n[gh-isowords]: https://github.com/pointfreeco/isowords\n[gh-discussions]: https://github.com/pointfreeco/swift-composable-architecture/discussions\n[swift-forum]: https://forums.swift.org/c/related-projects/swift-composable-architecture\n[testing-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/testingtca\n[faq-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/faq\n[dependencies-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/dependencymanagement\n[getting-started-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/gettingstarted\n[navigation-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/navigation\n[performance-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/performance\n[concurrency-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/swiftconcurrency\n[bindings-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/bindings\n[sharing-state-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/sharingstate\n[meet-tca]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/tutorials/meetcomposablearchitecture\n",
      "stars_today": 3
    },
    {
      "id": 404320053,
      "name": "foundry",
      "full_name": "foundry-rs/foundry",
      "description": "Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.",
      "html_url": "https://github.com/foundry-rs/foundry",
      "stars": 10034,
      "forks": 2341,
      "language": "Rust",
      "topics": [
        "alloy",
        "blockchain",
        "bytecode",
        "compiler",
        "compilers",
        "dapp",
        "eth",
        "ethereum",
        "evm",
        "framework",
        "fuzzing",
        "ir",
        "rust",
        "solidity",
        "testing",
        "tooling"
      ],
      "created_at": "2021-09-08T11:23:11Z",
      "updated_at": "2026-01-16T22:09:19Z",
      "pushed_at": "2026-01-17T00:52:35Z",
      "open_issues": 558,
      "owner": {
        "login": "foundry-rs",
        "avatar_url": "https://avatars.githubusercontent.com/u/99892494?v=4"
      },
      "readme": "<div align=\"center\">\n  <img src=\".github/assets/banner.png\" alt=\"Foundry banner\" />\n\n&nbsp;\n\n[![Github Actions][gha-badge]][gha-url] [![Telegram Chat][tg-badge]][tg-url] [![Telegram Support][tg-support-badge]][tg-support-url]\n![Foundry](https://img.shields.io/badge/Foundry-grey?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAElElEQVR4nH1VUUhUaRg9984YdzBpkqR0Z210rIESIXSabEbcHgydrpNRRj00kWaztj0U1MOW0MOIbD300IvLMqBpMTGYxdoqyoRNDUESBDWwUuPugCSSsTM7u0Oj1/+efdiMcmnP2/fDd77D4f/OB6xCa2urQZbllVICYGtqanK1tLS4AdgAyAAgyzJaW1sNq/ulT4twOGw4fPiwAGDp7Ow8VV1d7bVarRWxWCw/k8mgsbExm0wmZ+Lx+M/Xr1//CcAsSVmSJH01McLhsAEAnE5nx+Tk5B/xeJxOp5N9fX2sqqqixWLhnTt36HA4GIvFGI1GU3V1df5Pe/9D1t7eHkgkEuzo6GBPT49WWloq7Ha7fujQITocDu7atUs3m83i6tWr2okTJ/jixQuePn265zPScDhskGUZe/fubXv8+DFv3rypbdiwQaxbt46RSIT79u3j0NAQb926RVVVOT4+TqvVyvz8fD0YDC5NTk6ysbHxlCRJ/5KSlAAURyKRTFNTkwAg7t69S5/Px76+Pq7GyMgI9+/fz9HRUQIQO3bsEKOjo38DsJCUJADw+/0BVVW7otHo8ps3b4yvXr3CxMQETCYTTCYTNE0DAOTl5SGXy0FRFOzZswdmsxkVFRXLNTU1xmg0+kNvb+/3AGAcGBiI7969Wwcg6urq+OTJE967d49btmzh9PT0R3WJRIKBQIDBYJBTU1NsaGggAGGz2fTe3t5fAeQZAWwuLi4uP3nypOT1emEwGFBeXo7a2losLCygoaEB/f39MJlMCIVCkCQJBw8ehNVqhcfjQXNzs1RSUiKtX7++DEAZqqqq3KFQiABYUFDAM2fOkCQXFxdJkvfv32dhYSG9Xi+vXbvG2dnZj4oDgQCLioqoKAqHhobodDq/Mc7NzUklJSUIBoOw2WzYtm0blpeXsWbNGkxMTODp06doa2vD4OAgNm7cCIvFApLQdR3nzp3Dzp078fLlSxQVFeHdu3cAgIpHjx69/zBUX5k+MDBAt9vNY8eOsbu7m6lUigcOHKDL5WImkyHJz9TGYrEcALsMIPn69esZTdMIgM+ePUNXVxdu376NsrIyuN1uXLp0CWazGcPDw3C5XFBVFWfPnkVNTQ18Pp+ezWY5MzPzO4DfAABHjhzpJslUKqVdvHiR4+PjbG9vZy6XI0kuLS0xmUxSCEGS9Pv9LC0tpdFoZGVlpSaEoM/nuwIAKx/7q5GRkb9CoZBQVVWcP3+ez58/J0mm02kODg7ywoULjMViTKfTtNvtXLt2LTdt2qTncrnlsbGxLICvSUqfrl5HJBLh1NTUkhBCJ8mFhQX29/dTVVUWFBTwwYMH1HWdly9fpqIoeiKRWJqfn2d1dXWnLMuf7zMAHD16tGd+fn7FZy2bzYrKykodAAFQVVV9cXFRkNTevn3Lubk5trS0XPnfxHE4HN8ODw+nV/yanp6mx+Ohx+P5aIMQgmNjY3/W1tZ+t5rsSwG7+fjx4/76+vrm7du32woLC00AkE6n38fj8ZmHDx/+cuPGjR8BJL8YsCtYdQIMALYqilKvKEo9APuHty+egH8A3GfFDJXmxmMAAAAASUVORK5CYII%3D&link=https%3A%2F%2Fbook.getfoundry.sh%2F)\n\n[gha-badge]: https://img.shields.io/github/actions/workflow/status/foundry-rs/foundry/test.yml?branch=master\n[gha-url]: https://github.com/foundry-rs/foundry/actions\n[tg-badge]: https://img.shields.io/endpoint?color=neon&logo=telegram&label=chat&style=flat-square&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Ffoundry_rs\n[tg-url]: https://t.me/foundry_rs\n[tg-support-badge]: https://img.shields.io/endpoint?color=neon&logo=telegram&label=support&style=flat-square&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Ffoundry_support\n[tg-support-url]: https://t.me/foundry_support\n\n**[Install](https://getfoundry.sh/getting-started/installation)**\n| [Docs][foundry-docs]\n| [Developer Guidelines](./docs/dev/README.md)\n| [Contributing](./CONTRIBUTING.md)\n| [Crate Docs](https://foundry-rs.github.io/foundry)\n\n</div>\n\n---\n\n### Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.\n\nFoundry consists of:\n\n- [**Forge**](#forge): Build, test, fuzz, debug and deploy [Solidity][solidity] contracts, like Hardhat, Brownie, Ape.\n- [**Cast**](#cast): A Swiss Army knife for interacting with EVM smart contracts, sending transactions and getting chain data.\n- [**Anvil**](#anvil): Fast local Ethereum development node, akin to Hardhat Network, Tenderly.\n- [**Chisel**](#chisel): Fast, utilitarian, and verbose Solidity REPL.\n\n**Need help getting started with Foundry? Read the [üìñ Foundry Docs][foundry-docs]!**\n\n![Demo](.github/assets/demo.gif)\n\n## Features\n\n- **High-Performance Compilation**\n\n  - **Fast and Flexible**: Automatically detects and installs the required Solidity compiler version.\n  - **Solidity and Vyper Support**: Fully supports both Solidity and Vyper out-of-the-box.\n  - **Incremental Compilation**: Re-compiles only changed files, saving time.\n  - **Parallelized Pipeline**: Leverages multi-core systems for ultra-fast builds.\n  - **Broad Compatibility**: Supports non-standard directory structures, including [Hardhat repos](https://twitter.com/gakonst/status/1461289225337421829).\n\n- **Advanced Testing**\n\n  - **No Context Switching**: Write tests directly in Solidity.\n  - **Fuzz Testing**: Quickly identify edge cases with input shrinking and counter-example generation.\n  - **Invariant Testing**: Ensure complex system properties hold across a wide range of inputs.\n  - **Debugging Made Easy**: Use [forge-std](https://github.com/foundry-rs/forge-std)'s `console.sol` for flexible debug logging.\n  - **Interactive Debugger**: Step through your Solidity code with Foundry's interactive debugger, making it easy to pinpoint issues.\n\n- **Powerful Runtime Features**\n\n  - **RPC Forking**: Fast and efficient remote RPC forking backed by [Alloy][alloy].\n  - **Lightweight & Portable**: No dependency on Nix or other package managers for installation.\n\n- **Streamlined CI/CD**\n\n  - **Optimized CI**: Accelerate builds, run tests and execute scripts using [Foundry's GitHub action][foundry-gha].\n\n## Installation\n\nGetting started is very easy:\n\nInstall `foundryup`:\n\n```\ncurl -L https://foundry.paradigm.xyz | bash\n```\n\nNext, run `foundryup`.\n\nIt will automatically install the latest version of the precompiled binaries: [`forge`](#forge), [`cast`](#cast), [`anvil`](#anvil), and [`chisel`](#chisel).\n\n```\nfoundryup\n```\n\n**Done!**\n\nFor additional details see the [installation guide](https://getfoundry.sh/getting-started/installation) in the [Foundry Docs][foundry-docs].\n\nIf you're experiencing any issues while installing, check out [Getting Help](#getting-help) and the [FAQ](https://getfoundry.sh/faq).\n\n## How Fast?\n\nForge is quite fast at both compiling (leveraging `solc` with [foundry-compilers]) and testing.\n\nSee the benchmarks below. Older benchmarks against [DappTools][dapptools] can be found in the [v0.2.0 announcement post][benchmark-post] and in the [Convex Shutdown Simulation][convex] repository.\n\n### Testing Benchmarks\n\n| Project                                       | Type                 | [Forge 1.0][foundry-1.0] | [Forge 0.2][foundry-0.2] | DappTools | Speedup        |\n| --------------------------------------------- | -------------------- | ------------------------ | ------------------------ | --------- | -------------- |\n| [vectorized/solady][solady]                   | Unit / Fuzz          | 0.9s                     | 2.3s                     | -         | 2.6x           |\n| [morpho-org/morpho-blue][morpho-blue]         | Invariant            | 0.7s                     | 1m43s                    | -         | 147.1x         |\n| [morpho-org/morpho-blue-oracles][morpho-blue] | Integration (Cold)   | 6.1s                     | 6.3s                     | -         | 1.04x          |\n| [morpho-org/morpho-blue-oracles][morpho-blue] | Integration (Cached) | 0.6s                     | 0.9s                     | -         | 1.50x          |\n| [transmissions11/solmate][solmate]            | Unit / Fuzz          | 2.7s                     | 2.8s                     | 6m34s     | 1.03x / 140.0x |\n| [reflexer-labs/geb][geb]                      | Unit / Fuzz          | 0.2s                     | 0.4s                     | 23s       | 2.0x / 57.5x   |\n\n_In the above benchmarks, compilation was always skipped_\n\n**Takeaway: Forge dramatically outperforms the competition, delivering blazing-fast execution speeds while continuously expanding its robust feature set.**\n\n### Compilation Benchmarks\n\n<div align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\".github/assets/build_benchmark_solady_dark.png\" width=\"600px\">\n    <img src=\".github/assets/build_benchmark_solady_light.png\" width=\"600px\">\n  </picture>\n\n<picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\".github/assets/build_benchmark_openzeppelin_dark.png\" width=\"600px\">\n    <img src=\".github/assets/build_benchmark_openzeppelin_light.png\" width=\"600px\">\n  </picture>\n\n&nbsp;\n\n</div>\n\n**Takeaway: Forge compilation is consistently faster than Hardhat by a factor of `2.1x` to `5.2x`, depending on the amount of caching involved.**\n\n## Forge\n\nForge helps you build, test, fuzz, debug and deploy Solidity contracts.\n\nThe best way to understand Forge is to simply try it (in less than 30 seconds!).\n\nFirst, let's initialize a new `counter` example repository:\n\n```sh\nforge init counter\n```\n\nNext `cd` into `counter` and build:\n\n```sh\nforge build\n```\n\n```console\n[‚†ä] Compiling...\n[‚†î] Compiling 27 files with Solc 0.8.28\n[‚†í] Solc 0.8.28 finished in 452.13ms\nCompiler run successful!\n```\n\nLet's [test](https://getfoundry.sh/forge/tests#tests) our contracts:\n\n```sh\nforge test\n```\n\n```console\n[‚†ä] Compiling...\nNo files changed, compilation skipped\n\nRan 2 tests for test/Counter.t.sol:CounterTest\n[PASS] testFuzz_SetNumber(uint256) (runs: 256, Œº: 31121, ~: 31277)\n[PASS] test_Increment() (gas: 31293)\nSuite result: ok. 2 passed; 0 failed; 0 skipped; finished in 5.35ms (4.86ms CPU time)\n\nRan 1 test suite in 5.91ms (5.35ms CPU time): 2 tests passed, 0 failed, 0 skipped (2 total tests)\n```\n\nFinally, let's run our deployment script:\n\n```sh\nforge script script/Counter.s.sol\n```\n\n```console\n[‚†ä] Compiling...\nNo files changed, compilation skipped\nScript ran successfully.\nGas used: 109037\n\nIf you wish to simulate on-chain transactions pass a RPC URL.\n```\n\nRun `forge --help` to explore the full list of available subcommands and their usage.\n\nMore documentation can be found in the [forge](https://getfoundry.sh/forge/overview) section of the Foundry Docs.\n\n## Cast\n\nCast is a Swiss Army knife for interacting with Ethereum applications from the command line.\n\nHere are a few examples of what you can do:\n\n**Check the latest block on Ethereum Mainnet**:\n\n```sh\ncast block-number --rpc-url https://eth.merkle.io\n```\n\n**Check the Ether balance of `vitalik.eth`**\n\n```sh\ncast balance vitalik.eth --ether --rpc-url https://eth.merkle.io\n```\n\n**Replay and trace a transaction**\n\n```sh\ncast run 0x9c32042f5e997e27e67f82583839548eb19dc78c4769ad6218657c17f2a5ed31 --rpc-url https://eth.merkle.io\n```\n\nOptionally, pass `--etherscan-api-key <API_KEY>` to decode transaction traces using verified source maps, providing more detailed and human-readable information.\n\n---\n\nRun `cast --help` to explore the full list of available subcommands and their usage.\n\nMore documentation can be found in the [cast](https://getfoundry.sh/cast/overview) section of the Foundry Docs.\n\n## Anvil\n\nAnvil is a fast local Ethereum development node.\n\nLet's fork Ethereum mainnet at the latest block:\n\n```sh\nanvil --fork-url https://eth.merkle.io\n```\n\nYou can use those same `cast` subcommands against your `anvil` instance:\n\n```sh\ncast block-number\n```\n\n---\n\nRun `anvil --help` to explore the full list of available features and their usage.\n\nMore documentation can be found in the [anvil](https://getfoundry.sh/anvil/overview) section of the Foundry Docs.\n\n## Chisel\n\nChisel is a fast, utilitarian, and verbose Solidity REPL.\n\nTo use Chisel, simply type `chisel`.\n\n```sh\nchisel\n```\n\nFrom here, start writing Solidity code! Chisel will offer verbose feedback on each input.\n\nCreate a variable `a` and query it:\n\n```console\n‚ûú uint256 a = 123;\n‚ûú a\nType: uint256\n‚îú Hex: 0x7b\n‚îú Hex (full word): 0x000000000000000000000000000000000000000000000000000000000000007b\n‚îî Decimal: 123\n```\n\nFinally, run `!source` to see `a` was applied:\n\n```solidity\n// SPDX-License-Identifier: UNLICENSED\npragma solidity ^0.8.28;\n\nimport {Vm} from \"forge-std/Vm.sol\";\n\ncontract REPL {\n    Vm internal constant vm = Vm(address(uint160(uint256(keccak256(\"hevm cheat code\")))));\n\n    /// @notice REPL contract entry point\n    function run() public {\n        uint256 a = 123;\n    }\n}\n```\n\n---\n\nRun `chisel --help` to explore the full list of available features and their usage.\n\nMore documentation can be found in the [chisel](https://getfoundry.sh/chisel/overview) section of the Foundry Docs.\n\n## Configuration\n\nFoundry is highly configurable, allowing you to tailor it to your needs. Configuration is managed via a file called [`foundry.toml`](./crates/config) located in the root of your project or any parent directory. For a full list of configuration options, refer to the [config package documentation](./crates/config/README.md#all-options).\n\nYou can find additional [setup and configurations guides](https://getfoundry.sh/config/overview) in the [Foundry Docs][foundry-docs] and in the [config crate](./crates/config/README.md):\n\n- [Configuring with `foundry.toml`](https://getfoundry.sh/config/overview)\n- [Setting up VSCode][vscode-setup]\n- [Shell autocompletions][shell-setup]\n\n**Profiles and Namespaces**\n\n- Configuration can be organized into **profiles**, which are arbitrarily namespaced for flexibility.\n- The default profile is named `default`. Learn more in the [Default Profile section](./crates/config/README.md#default-profile).\n- To select a different profile, set the `FOUNDRY_PROFILE` environment variable.\n- Override specific settings using environment variables prefixed with `FOUNDRY_` (e.g., `FOUNDRY_SRC`).\n\n---\n\n## Contributing\n\nContributions are welcome and highly appreciated. To get started, check out the [contributing guidelines](./CONTRIBUTING.md).\n\nIf you want to contribute, or follow along with contributor discussion, you can use our [main telegram](https://t.me/foundry_rs) to chat with us about the development of Foundry!\n\n## Support\n\nHaving trouble? See if the answer to your question can be found in the [Foundry Docs][foundry-docs].\n\nIf the answer is not there:\n- Join the [support Telegram][tg-support-url] to get help, or\n- Open an issue with [the bug](https://github.com/foundry-rs/foundry/issues/new)\n\n#### License\n\n<sup>\nLicensed under either of <a href=\"LICENSE-APACHE\">Apache License, Version\n2.0</a> or <a href=\"LICENSE-MIT\">MIT license</a> at your option.\n</sup>\n\n<br>\n\n<sub>\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in these crates by you, as defined in the Apache-2.0 license,\nshall be dual licensed as above, without any additional terms or conditions.\n</sub>\n\n## Acknowledgements\n\n- Foundry is a clean-room rewrite of the testing framework [DappTools][dapptools]. None of this would have been possible without the DappHub team's work over the years.\n- [Matthias Seitz](https://twitter.com/mattsse_): Created [ethers-solc] (now [foundry-compilers]) which is the backbone of our compilation pipeline, as well as countless contributions to ethers, in particular the `abigen` macros.\n- [Rohit Narurkar](https://twitter.com/rohitnarurkar): Created the Rust Solidity version manager [svm-rs](https://github.com/roynalnaruto/svm-rs) which we use to auto-detect and manage multiple Solidity versions.\n- [Brock Elmore](https://twitter.com/brockjelmore): For extending the VM's cheatcodes and implementing [structured call tracing](https://github.com/foundry-rs/foundry/pull/192), a critical feature for debugging smart contract calls.\n- Thank you to [Depot](https://depot.dev) for sponsoring us with their fast GitHub runners and sccache, which we use in CI to reduce build and test times significantly.\n- All the other [contributors](https://github.com/foundry-rs/foundry/graphs/contributors) to the [ethers-rs](https://github.com/gakonst/ethers-rs), [alloy][alloy] & [foundry](https://github.com/foundry-rs/foundry) repositories and chatrooms.\n\n[solidity]: https://soliditylang.org/\n[foundry-docs]: https://getfoundry.sh\n[foundry-gha]: https://github.com/foundry-rs/foundry-toolchain\n[foundry-compilers]: https://github.com/foundry-rs/compilers\n[ethers-solc]: https://github.com/gakonst/ethers-rs/tree/master/ethers-solc/\n[solady]: https://github.com/Vectorized/solady\n[openzeppelin]: https://github.com/OpenZeppelin/openzeppelin-contracts/tree/release-v5.1\n[morpho-blue]: https://github.com/morpho-org/morpho-blue\n[solmate]: https://github.com/transmissions11/solmate/\n[geb]: https://github.com/reflexer-labs/geb\n[benchmark-post]: https://www.paradigm.xyz/2022/03/foundry-02#blazing-fast-compilation--testing\n[convex]: https://github.com/mds1/convex-shutdown-simulation\n[vscode-setup]: https://getfoundry.sh/config/vscode.html\n[shell-setup]: https://getfoundry.sh/config/shell-autocompletion.html\n[foundry-0.2]: https://github.com/foundry-rs/foundry/releases/tag/nightly-5b7e4cb3c882b28f3c32ba580de27ce7381f415a\n[foundry-1.0]: https://github.com/foundry-rs/foundry/releases/tag/nightly-59f354c179f4e7f6d7292acb3d068815c79286d1\n[dapptools]: https://github.com/dapphub/dapptools\n[alloy]: https://github.com/alloy-rs/alloy\n",
      "stars_today": 3
    },
    {
      "id": 936473202,
      "name": "FlashMLA",
      "full_name": "deepseek-ai/FlashMLA",
      "description": "FlashMLA: Efficient Multi-head Latent Attention Kernels",
      "html_url": "https://github.com/deepseek-ai/FlashMLA",
      "stars": 11973,
      "forks": 934,
      "language": "C++",
      "topics": [],
      "created_at": "2025-02-21T06:31:27Z",
      "updated_at": "2026-01-16T12:51:04Z",
      "pushed_at": "2026-01-16T10:02:58Z",
      "open_issues": 82,
      "owner": {
        "login": "deepseek-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/148330874?v=4"
      },
      "readme": "# FlashMLA\n\n## Introduction\n\nFlashMLA is DeepSeek's library of optimized attention kernels, powering the [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) and [DeepSeek-V3.2-Exp](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp) models. This repository contains the following implementations:\n\n**Sparse Attention Kernels**\n\n*These kernels power DeepSeek Sparse Attention (DSA), as introduced in [this paper](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp).*\n\n- Token-level sparse attention for the prefill stage\n- Token-level sparse attention for the decoding stage, with FP8 KV cache\n\n**Dense Attention Kernels**\n\n- Dense attention for the prefill stage\n- Dense attention for the decoding stage\n\n## News\n\n- **2025.09.29 Release of Sparse Attention Kernels**: With the launch of [DeepSeek-V3.2](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp), we are releasing the corresponding token-level sparse attention kernels. These kernels power the model's DeepSeek Sparse Attention (DSA) and achieve up to 640 TFlops during prefilling and 410 TFlops during decoding. We also release a deep-dive blog for our new FP8 sparse decoding kernel. Check it out [here](docs/20250929-hopper-fp8-sparse-deep-dive.md).\n- **2025.08.01 Kernels for MHA on SM100**: Thanks to [NVIDIA's PR](https://github.com/deepseek-ai/FlashMLA/pull/76) for MHA forward / backward kernels on SM100!\n- **2025.04.22 Deep-Dive Blog**: We'd love to share the technical details behind the new FlashMLA kernel! Check out our deep-dive write-up [here](docs/20250422-new-kernel-deep-dive.md).\n- **2025.04.22 Performance Update**: We're excited to announce the new release of Flash MLA, which delivers 5% ~ 15% performance improvement for compute-bound workloads, achieving up to 660 TFlops on NVIDIA H800 SXM5 GPUs. The interface of the new version is fully compatible with the old one. Simply upgrade to the new version for an immediate performance boost! üöÄüöÄüöÄ\n\n## Performance\n\n#### Test & benchmark MLA decoding (Sparse & Dense):\n\n```bash\npython tests/test_flash_mla_dense_decoding.py\npython tests/test_flash_mla_sparse_decoding.py\n```\n\nThe dense MLA decoding kernel achieves up to 3000 GB/s in memory-bound configuration and 660 TFLOPS in computation-bound configuration on H800 SXM5 with CUDA 12.8. The token-level sparse MLA decoding kernel (which uses an FP8 KV cache while performing the matrix multiplication in bfloat16) achieves 410 TFLOPS in compute-bound configuration on H800 SXM5 with CUDA 12.8, and achieves up to 350 TFlops on B200 (which is not really optimized yet).\n\n#### Test & benchmark MHA prefill (Dense):\n\n```bash\npython tests/test_fmha_sm100.py\n```\n\nIt achieves up to 1460 TFlops in forward and 1000 TFlops in backward computation on B200, as reported by NVIDIA.\n\n#### Test & benchmark MLA prefill (Sparse):\n\n```bash\npython tests/test_flash_mla_sparse_prefill.py\n```\n\nIt achieves up to 640 TFlops in forward computation on H800 SXM5 with CUDA 12.8, and achieves up to 1450 TFlops on B200, CUDA 12.9.\n\n## Requirements\n\n- SM90 / SM100 (See the support matrix below)\n- CUDA 12.8 and above (CUDA 12.9+ is required for SM100 kernels)\n- PyTorch 2.0 and above\n\nSupport matrix:\n\n| Kernel | GPU Architecture | MLA Mode [2] | KVCache Format |\n| :---: | :---: | :---: | :---: |\n| Dense Decoding | SM90 | MQA | BF16 |\n| Sparse Decoding | SM90 & SM100 | MQA | FP8 [1] |\n| Dense Prefill | SM100 | MHA |  |\n| Sparse Prefill | SM90 & SM100 | MQA |  |\n\n[1]: For more details on using FP8 KV cache, see documents below.\n\n[2]: Here \"MLA Mode\" refers to the mode used for MLA calculation. MQA stands for Multi-Query Attention mode (i.e. `head_dim_k` =  576 with `head_dim_v` = 512), while MHA stands for Multi-Head Attention mode (i.e. `head_dim_k` = 192 / 128 with `head_dim_v` = 128). For a detailed explanation of these modes, please refer to the appendix of [DeepSeek V3.2's Paper](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp).\n\n## Installation\n\n```bash\ngit clone https://github.com/deepseek-ai/FlashMLA.git flash-mla\ncd flash-mla\ngit submodule update --init --recursive\npip install -v .\n```\n\n## Usage\n\n### MLA Decoding\n\nTo use the MLA decoding kernels, call get_mla_metadata once before the decoding loop to get the tile scheduler metadata. Then, call flash_mla_with_kvcache in each decoding step. For example:\n\n```python\nfrom flash_mla import get_mla_metadata, flash_mla_with_kvcache\n\ntile_scheduler_metadata, num_splits = get_mla_metadata(\n    cache_seqlens,\n    s_q * h_q // h_kv,\n    h_kv,\n    h_q,\n    is_fp8,\n    topk,\n)\n\nfor i in range(num_layers):\n    ...\n    o_i, lse_i = flash_mla_with_kvcache(\n        q_i, kvcache_i, block_table, cache_seqlens, dv,\n        tile_scheduler_metadata, num_splits,\n        is_causal, is_fp8_kvcache, indices,\n    )\n    ...\n```\n\nWhere\n\n- `s_q` is the number of q tokens per q sequence. If MTP (speculative decoding) is disabled, it should be 1.\n- `h_kv` is the number of key-value heads.\n- `h_q` is the number of query heads.\n\n**FP8 KV Cache:**\nIf `is_fp8_kvcache` is set to `True`, the kernel reads the KV cache in the \"FP8 with scale\" format (described below). It dequantizes the cache to bfloat16 and performs attention computation in bfloat16. The output is also in bfloat16.\n\nIn the \"FP8 with scale\" format, each token's KV cache is 656 Bytes, structured as:\n-   **First 512 bytes:** The \"quantized NoPE\" part, containing 512 `float8_e4m3` values.\n-   **Next 16 bytes:** Scale factors, containing 4 `float32` values. The first `float32` is the scale for the first 128 `float8_e4m3` values, the second for the next 128, and so on.\n-   **Last 128 bytes:** The \"RoPE\" part, containing 64 `bfloat16` values. This part is not quantized for accuracy.\n\nSee `tests/quant.py` for quantization and dequantization details.\n\n**Sparse Attention (`indices` tensor):**\nThe `indices` tensor (if provided) enables token-level sparse attention by instructing the kernel to compute attention only for specified tokens.\n\n-   **Shape:** `indices` should be a 3D tensor of shape `(batch_size, seq_len_q, topk)`.\n-   **Format:** `indices_in_kvcache[i][j][k] = (the index of the page block where token t resides) * page_block_size + (the offset of token t within the page block)`, where `t` is the k-th token for the j-th query sequence in the i-th batch. Since the index of the page block has already been encoded into `indices_in_kvcache`, the kernel does not require the `block_table` parameter.\n-   **Invalid entries:** Set invalid indices to `-1`.\n\n**Return Values:**\nThe kernel returns `(out, lse)`, where:\n-   `out` is the attention result.\n-   `lse` is the log-sum-exp value of the attention scores for each query head.\n\nSee `tests/test_flash_mla_decoding.py` for a complete example.\n\n### Sparse MLA Prefill\n\nFor the sparse MLA prefill kernel, call `flash_mla_sparse_fwd` directly with the following parameters:\n-   `q`: Query tensor of shape `[s_q, h_q, d_qk]`\n-   `kv`: Key-Value tensor of shape `[s_kv, h_kv, d_qk]`\n-   `indices`: Indices tensor of shape `[s_q, h_kv, topk]`\n-   `sm_scale`: A scalar value\n\n**Note on batching:** This kernel does not support a batch dimension. For multi-batch inference, reshape the input tensors and adjust the `indices` parameter to simulate batch processing.\n\n**Invalid indices:** Set invalid entries in `indices` to `-1` or any number `>= s_kv`.\n\n**Return Values and Equivalent PyTorch Code:**\nThe kernel returns `(out, max_logits, lse)`. This is equivalent to the following PyTorch operations:\n\n```python\nQ: [s_q, h_q, d_qk], bfloat16\nkv: [s_kv, h_kv, d_qk], bfloat16\nindices: [s_q, h_kv, topk], int32\n\nkv = kv.squeeze(1)  # [s_kv, d_qk], h_kv must be 1\nindices = indices.squeeze(1)    # [s_q, topk]\nfocused_kv = kv[indices]    # For the i-th sequence (s_q), the corresponding KV tokens are selected from the KV cache based on indices[i, :]. This operation results in a tensor of shape [s_q, topk, d_qk].\n\nP = (Q @ focused_kv.transpose(-1, -2)) * sm_scale * math.log2(math.e)    # [s_q, h_q, topk]\nmax_logits = P.max(dim=-1) # [s_q, h_q]\nlse = log2sumexp2(P, dim=-1, base=2)   # [s_q, h_q]Ôºå\"log2sumexp2\" means that the exponentiation and logarithm are base-2\nS = exp2(P - lse)      # [s_q, h_q, topk]\nout = S @ focused_kv  # [s_q, h_q, d_qk]\n\nreturn (out, max_logits, lse)\n```\n\nSee `tests/test_flash_mla_prefill.py` for a complete example.\n\n### Dense MHA Prefill\n\nThis kernel implements the standard dense Multi-Head Attention (MHA) forward and backward operations. It can be called using:\n-   `flash_attn_varlen_func`\n-   `flash_attn_varlen_qkvpacked_func`\n-   `flash_attn_varlen_kvpacked_func`\n\nThe usage is similar to the `flash_attn` package. See `tests/test_fmha_sm100.py` for a complete example.\n\n## Acknowledgement\n\nFlashMLA is inspired by [FlashAttention 2&3](https://github.com/dao-AILab/flash-attention/) and [cutlass](https://github.com/nvidia/cutlass) projects.\n\n## Community Support\n\n### MetaX\nFor MetaX GPUs, visit the official website: [MetaX](https://www.metax-tech.com).\n\nThe corresponding FlashMLA version can be found at: [MetaX-MACA/FlashMLA](https://github.com/MetaX-MACA/FlashMLA)\n\n\n### Moore Threads\nFor the Moore Threads GPU, visit the official website: [Moore Threads](https://www.mthreads.com/).\n\nThe corresponding FlashMLA version is available on GitHub: [MooreThreads/MT-flashMLA](https://github.com/MooreThreads/MT-flashMLA).\n\n\n### Hygon DCU\nFor the Hygon DCU, visit the official website: [Hygon Developer](https://developer.sourcefind.cn/).\n\nThe corresponding FlashMLA version is available here: [OpenDAS/MLAttention](https://developer.sourcefind.cn/codes/OpenDAS/MLAttention).\n\n\n### Intellifusion\nFor the Intellifusion NNP, visit the official website: [Intellifusion](https://www.intellif.com).\n\nThe corresponding FlashMLA version is available on Gitee: [Intellifusion/tyllm](https://gitee.com/Intellifusion_2025/tyllm/blob/master/python/tylang/flash_mla.py).\n\n\n### Iluvatar Corex\nFor Iluvatar Corex GPUs, visit the official website: [Iluvatar Corex](https://www.iluvatar.com).\n\nThe corresponding FlashMLA version is available on GitHub: [Deep-Spark/FlashMLA](https://github.com/Deep-Spark/FlashMLA/tree/iluvatar_flashmla)\n\n\n### AMD Instinct\nFor AMD Instinct GPUs, visit the official website: [AMD Instinct](https://www.amd.com/en/products/accelerators/instinct.html).\n\nThe corresponding FlashMLA version can be found at: [AITER/MLA](https://github.com/ROCm/aiter/blob/main/aiter/mla.py)\n\n## Citation\n\n```bibtex\n@misc{flashmla2025,\n      title={FlashMLA: Efficient Multi-head Latent Attention Kernels},\n      author={Jiashi Li, Shengyu Liu},\n      year={2025},\n      publisher = {GitHub},\n      howpublished = {\\url{https://github.com/deepseek-ai/FlashMLA}},\n}\n```\n",
      "stars_today": 3
    },
    {
      "id": 154201259,
      "name": "hermes",
      "full_name": "facebook/hermes",
      "description": "A JavaScript engine optimized for running React Native.",
      "html_url": "https://github.com/facebook/hermes",
      "stars": 10747,
      "forks": 726,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2018-10-22T19:13:00Z",
      "updated_at": "2026-01-16T19:01:44Z",
      "pushed_at": "2026-01-16T19:01:28Z",
      "open_issues": 171,
      "owner": {
        "login": "facebook",
        "avatar_url": "https://avatars.githubusercontent.com/u/69631?v=4"
      },
      "readme": "# Hermes JS Engine\n[![MIT license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/facebook/hermes/blob/HEAD/LICENSE)\n[![npm version](https://img.shields.io/npm/v/hermes-engine.svg?style=flat)](https://www.npmjs.com/package/hermes-engine)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://github.com/facebook/hermes/blob/HEAD/CONTRIBUTING.md)\n<img src=\"./doc/img/logo.svg\" alt=\"Hermes logo - large H with wings\" align=\"right\" width=\"20%\"/>\n\nHermes is a JavaScript engine optimized for fast start-up of [React Native](https://reactnative.dev/) apps. It features ahead-of-time static optimization and compact bytecode.\n\nIf you're only interested in using pre-built Hermes in a new or existing React Native app, you do not need to follow this guide or have direct access to the Hermes source. Instead, just follow [these instructions to enable Hermes](https://reactnative.dev/docs/hermes).\n\n> Noted that each Hermes release is aimed at a specific RN version. The rule of thumb is to always follow [Hermes releases](https://github.com/facebook/hermes/releases) strictly. Version mismatch can result in instant crash of your apps in the worst case scenario.\n\nIf you want to know how to build and hack on Hermes directly, and/or integrate Hermes built from source into a React Native app then read on.\n\n**[Hermes Blog](doc/blog/README.md)** - Technical articles and deep dives into Hermes internals.\n\nThe instructions here very briefly cover steps to build the Hermes CLI. They assume you have typical native development tools setup for your OS, and support for cmake and Ninja. For more details of required dependencies, building Hermes with different options, etc. follow these links instead:\n\n* [Building and Running Hermes](doc/BuildingAndRunning.md)\n* [Using a custom Hermes build in a React Native app](doc/ReactNativeIntegration.md#using-a-custom-hermes-build-in-a-react-native-app)\n\nTo build a local debug version of the Hermes CLI tools the following steps should get you started on macOS/Linux:\n\n```shell\nmkdir hermes_workingdir\ncd hermes_workingdir\ngit clone https://github.com/facebook/hermes.git\ncmake -S hermes -B build -G Ninja -DCMAKE_BUILD_TYPE=Debug\ncmake --build ./build\n```\n\nOr if you're using Windows, the following should get you going in a Git Bash shell:\n\n```shell\nmkdir hermes_workingdir\ncd hermes_workingdir\ngit -c core.autocrlf=false clone https://github.com/facebook/hermes.git\ncmake -S hermes -B build -G 'Visual Studio 16 2019' -A x64\ncmake --build ./build\n```\n\nYou will now be in a directory with the output of building Hermes into CLI tools. From here you can run a piece of JavaScript as follows:\n\n```shell\necho \"'use strict'; function hello() { print('Hello World'); } hello();\" | ./bin/hermes\n```\n\n## Contributing\n\nThe main purpose of this repository is to continue to evolve Hermes, making it faster and more efficient. We are grateful to the community for contributing bugfixes and improvements. Read below to learn how you can take part in improving Hermes.\n\n### Code of Conduct\n\nFacebook has adopted a [Code of Conduct](./CODE_OF_CONDUCT.md) that we expect project participants to adhere to. Please read [the full text](https://code.fb.com/codeofconduct) so that you can understand what actions will and will not be tolerated.\n\n### Contributing Guide\n\nRead our [contributing guide](CONTRIBUTING.md) to learn about our development process, how to propose bugfixes and improvements, and how to build and test your changes to Hermes.\n\n### License\n\nHermes is [MIT licensed](./LICENSE).\n",
      "stars_today": 3
    },
    {
      "id": 66302557,
      "name": "SwiftFormat",
      "full_name": "nicklockwood/SwiftFormat",
      "description": "A command-line tool and Xcode Extension for formatting Swift code",
      "html_url": "https://github.com/nicklockwood/SwiftFormat",
      "stars": 8658,
      "forks": 669,
      "language": "Swift",
      "topics": [],
      "created_at": "2016-08-22T19:39:05Z",
      "updated_at": "2026-01-16T23:10:48Z",
      "pushed_at": "2026-01-16T19:03:25Z",
      "open_issues": 327,
      "owner": {
        "login": "nicklockwood",
        "avatar_url": "https://avatars.githubusercontent.com/u/546885?v=4"
      },
      "readme": "![](EditorExtension/Application/Assets.xcassets/AppIcon.appiconset/icon_256x256.png)\n\n[![PayPal](https://img.shields.io/badge/paypal-donate-blue.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=9ZGWNK5FEZFF6&source=url)\n[![Build](https://github.com/nicklockwood/SwiftFormat/actions/workflows/build.yml/badge.svg)](https://github.com/nicklockwood/SwiftFormat/actions/workflows/build.yml)\n[![Codecov](https://codecov.io/gh/nicklockwood/SwiftFormat/graphs/badge.svg)](https://codecov.io/gh/nicklockwood/SwiftFormat)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fnicklockwood%2FSwiftFormat%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/nicklockwood/swiftformat)\n[![License](https://img.shields.io/badge/license-MIT-lightgrey.svg)](https://opensource.org/licenses/MIT)\n[![Mastodon](https://img.shields.io/badge/mastodon-@nicklockwood@mastodon.social-636dff.svg)](https://mastodon.social/@nicklockwood)\n\nTable of Contents\n-----------------\n\n- [What?](#what-is-this)\n- [Why?](#why-would-i-want-to-do-that)\n- [How?](#how-do-i-install-it)\n    - [Command-line tool](#command-line-tool)\n    - [Xcode source editor extension](#xcode-source-editor-extension)\n    - [Xcode build phase](#xcode-build-phase)\n    - [Swift Package Manager plugin](#swift-package-manager-plugin)\n    - [Via Applescript](#via-applescript)\n    - [VSCode plugin](#vscode-plugin)\n    - [Sublime Text plugin](#sublime-text-plugin)\n    - [Nova plugin](nova-plugin)\n    - [Git pre-commit hook](#git-pre-commit-hook)\n    - [GitHub Actions](#github-actions)\n    - [On CI using Danger](#on-ci-using-danger)\n    - [Bazel build](#bazel-build)\n    - [Docker](#docker)\n    - [Prerelease Builds](#prerelease-builds)\n- [Configuration](#configuration)\n    - [Options](#options)\n    - [Rules](#rules)\n    - [Swift version](#swift-version)\n    - [Config file](#config-file)\n    - [Globs](#globs)\n    - [Linting](#linting)\n    - [Error codes](#error-codes)\n    - [Cache](#cache)\n    - [File headers](#file-headers)\n    - [Markdown formatting](#markdown-formatting)\n- [FAQ](#faq)\n- [Known issues](#known-issues)\n- [Tip Jar](#tip-jar)\n- [Credits](#credits)\n\n\nWhat is this?\n----------------\n\nSwiftFormat is a code library and command-line tool for reformatting Swift code on macOS, Linux or Windows.\n\nSwiftFormat goes above and beyond what you might expect from a code formatter. In addition to adjusting white space it can insert or remove implicit `self`, remove redundant parentheses, and correct many other deviations from the standard Swift idioms.\n\n\nWhy would I want to do that?\n-----------------------------\n\nMany programmers have a preferred style for formatting their code, and others seem entirely blind to the existing formatting conventions of a project (to the enragement of their colleagues).\n\nWhen collaborating on a project, it can be helpful to agree on a common coding style, but enforcing that manually is tedious and error-prone, and can lead to arguments if some participants take it more seriously than others.\n\nHaving a tool to automatically enforce a common style eliminates those issues, and lets you focus on the behavior of the code, not its presentation.\n\n\nHow do I install it?\n---------------------\n\nThat depends - There are several ways you can use SwiftFormat:\n\n1. As a command-line tool that you run manually, or as part of some other toolchain\n2. As a Source Editor Extension that you can invoke via the Editor > SwiftFormat menu within Xcode\n3. As a build phase in your Xcode project, so that it runs every time you press Cmd-R or Cmd-B, or\n4. As a Git pre-commit hook, so that it runs on any files you've changed before you check them in\n\n\nCommand-line tool\n-------------------\n\n**Installation:**\n\nYou can install the `swiftformat` command-line tool on macOS or Linux using [Homebrew](http://brew.sh/). Assuming you already have Homebrew installed, just type:\n\n```bash\n$ brew install swiftformat\n```\n\nTo update to the latest version once installed:\n\n```bash\n$ brew upgrade swiftformat\n```\n\nAlternatively, you can install the tool on macOS or Linux by using [Mint](https://github.com/yonaskolb/Mint) as follows:\n\n```bash\n$ mint install nicklockwood/SwiftFormat\n```\n\nOr if you prefer, you can check out and build SwiftFormat manually on macOS, Linux or Windows as follows:\n\n```bash\n$ git clone https://github.com/nicklockwood/SwiftFormat\n$ cd SwiftFormat\n$ swift build -c release\n```\n\nIf you are installing SwiftFormat into your project directory, you can use [CocoaPods](https://cocoapods.org/) on macOS to automatically install the swiftformat binary along with your other pods - see the Xcode build phase instructions below for details.\n\nAnother option is to include the binary artifactbundle in your `Package.swift`:\n\n```swift\n.binaryTarget(\n    name: \"swiftformat\",\n    url: \"https://github.com/nicklockwood/SwiftFormat/releases/download/0.55.0/swiftformat-macos.artifactbundle.zip\",\n    checksum: \"CHECKSUM\"\n),\n``` \n\nIf you would prefer not to use a package manager, you can build the command-line app manually:\n\n1. open `SwiftFormat.xcodeproj` and build the `SwiftFormat (Application)` scheme.\n\n2. Drag the `swiftformat` binary into `/usr/local/bin/` (this is a hidden folder, but you can use the Finder's `Go > Go to Folder...` menu to open it).\n\n3. Open `~/.bash_profile` in your favorite text editor (this is a hidden file, but you can type `open ~/.bash_profile` in the terminal to open it).\n\n4. Add the following line to the file: `alias swiftformat=\"/usr/local/bin/swiftformat --indent 4\"` (you can omit the `--indent 4`, or replace it with something else. Run `swiftformat --help` to see the available options).\n\n5. Save the `.bash_profile` file and run the command `source ~/.bash_profile` for the changes to take effect.\n\n**Usage:**\n\nIf you followed the installation instructions above, you can now just type\n\n```bash\n$ swiftformat .\n```\n\n(that's a space and then a period after the command) in the terminal to format any Swift files in the current directory. In place of the `.`, you can instead type an absolute or relative path to the file or directory that you want to format.\n\n**WARNING:** `swiftformat .` will overwrite any Swift files it finds in the current directory, and any subfolders therein. If you run it in your home directory, it will probably reformat every Swift file on your hard drive.\n\nTo use it safely, do the following:\n\n1. Choose a file or directory that you want to apply the changes to.\n\n2. Make sure that you have committed all your changes to that code safely in git (or whatever source control system you use).\n\n3. (Optional) In Terminal, type `swiftformat --infer-options \"/path/to/your/code/\"`. This will suggest a set of formatting options to use that match your existing project style (but you are free to ignore these and use the defaults, or your own settings if you prefer).\n\n    The path can point to either a single Swift file or a directory of files. It can be either be absolute, or relative to the current directory. The `\"\"` quotes around the path are optional, but if the path contains spaces then you either need to use quotes, or escape each space with `\\`. You may include multiple paths separated by spaces.\n\n4. In Terminal, type `swiftformat \"/path/to/your/code/\"`. The same rules apply as above with respect to paths, and multiple space-delimited paths are allowed.\n\n    If you used `--infer-options` to generate a suggested set of options in step 3, you should copy and paste them into the command, either before or after the path(s) to your source files.\n\n    If you have created a [config file](#config-file), you can specify its path using `--config \"/path/to/your/config-file/\"`. Alternatively, if you name the file `.swiftformat` and place it inside the project you are formatting, it will be picked up automatically.\n\n5. Press enter to begin formatting. Once the formatting is complete, use your source control system to check the changes, and verify that no undesirable changes have been introduced. If they have, revert the changes, tweak the options and try again.\n\n6. (Optional) commit the changes.\n\nFollowing these instructions *should* ensure that you avoid catastrophic data loss, but in the unlikely event that it wipes your hard drive, **please note that I accept no responsibility**.\n\n**Using Standard Input/Output:**\n\nIf you prefer, you can use unix pipes to include SwiftFormat as part of a command chain. For example, this is an alternative way to format a file:\n\n```bash\n$ cat /path/to/file.swift | swiftformat --output /path/to/file.swift\n```\n\nOmitting the `--output /path/to/file.swift` will print the formatted file to Standard Output (stdout). You can also pass \"stdout\" explicitly as the output path:\n\n```bash\n$ cat /path/to/file.swift | swiftformat --output stdout\n```\n\nOr you can use `>` to specify the output path as follows:\n\n```bash\n$ cat /path/to/file.swift | swiftformat > /path/to/file.swift\n```\n\nIf you do not supply an input file, SwiftFormat will automatically take its input from Standard Input (stdin), but will time-out if no input is received immediately and display the help screen. To make it explicit, pass \"stdin\" as the input path:\n\n```bash\n$ cat /path/to/file.swift | swiftformat stdin\n```\n\nWhen using stdin, SwiftFormat does not have access to the file path of the input, so features that rely on the file location (such as inserting the creation date into header comments, or detecting `.swiftformat` configuration files in the file path) will not work. To solve this, you can provide the file path using the `--stdin-path` argument:\n\n```bash\n$ cat /path/to/file.swift | swiftformat stdin --stdinpath /path/to/file.swift\n```\n\n\nXcode source editor extension\n-----------------------------\n\n**Installation:**\n\nLike the command-line tool, you can install the SwiftFormat for Xcode extension application via [Homebrew](http://brew.sh/). Assuming you already have Homebrew installed, type:\n\n```bash\n$ brew install --cask swiftformat-for-xcode\n```\n\nThis will install SwiftFormat for Xcode in your Applications folder. Double-click the app to launch it, and then follow the on-screen instructions.\n\n**NOTE:** The app should be correctly signed, but if you get a Gatekeeper warning when trying to open it you can bypass this by right-clicking (or control-clicking) the app and selecting `Open`.\n\nTo update to the latest version once installed use:\n\n```bash\n$ brew upgrade --cask swiftformat-for-xcode\n```\n\nAlternatively, if you prefer not to use Homebrew, you'll find the latest version of the SwiftFormat for Xcode application on the [GitHub Releases](https://github.com/nicklockwood/SwiftFormat/releases) page. Download and unpack the zip archive, then drag `SwiftFormat for Xcode.app` into your `Applications` folder.\n\n**Usage:**\n\nOnce you have launched the app and restarted Xcode, you'll find a SwiftFormat option under Xcode's Editor menu. If the SwiftFormat menu does not appear [this thread](https://github.com/nicklockwood/SwiftFormat/issues/494) may help. \n\nYou can configure the formatting [rules](#rules) and [options](#options) using the SwiftFormat for Xcode host application. There is currently no way to override these per-project, however, you can import and export different configurations using the File menu. You will need to do this again each time you switch projects.\n\nThe format of the configuration file is described in the [Config section](#config-file) below.\n\n**Note:** SwiftFormat for Xcode cannot automatically detect changes to an imported configuration file. If you update the `.swiftformat` file for your project, you will need to manually re-import that file into SwiftFormat for Xcode in order for the Xcode source editor extension to use the new configuration.\n\n\nXcode build phase\n-------------------\n\n**NOTE:** Adding this script will overwrite your source files as you work on them, which has the annoying side-effect of clearing the undo history. You may wish to add the script to your test target rather than your main target, so that it is invoked only when you run the unit tests, and not every time you build the app.\n\nAlternatively, you might want to consider running SwiftFormat in [lint](#linting) mode as part of your normal build, and then running a formatting pass manually, or as part of a less-frequent build target (such as the tests).\n\n### Using Swift Package Manager\n\nTo set up SwiftFormat as an Xcode build phase, do the following:\n\n#### 1) Create a BuildTools folder and Package.swift\n\n1. Create a folder called `BuildTools` in the same folder as your xcodeproj file\n2. In this folder, create a file called `Package.swift`, with the following contents:\n```swift\n// swift-tools-version:5.1\nimport PackageDescription\n\nlet package = Package(\n    name: \"BuildTools\",\n    platforms: [.macOS(.v10_11)],\n    dependencies: [\n        .package(url: \"https://github.com/nicklockwood/SwiftFormat\", from: \"0.58.7\"),\n    ],\n    targets: [.target(name: \"BuildTools\", path: \"\")]\n)\n```\n3. If you are running Xcode 11.4 or later, in the `BuildTools` folder create a file called `Empty.swift` with nothing in it. This is to satisfy a change in Swift Package Manager.\n\n#### 2) Add a Build phase to your app target\n\n1. Click on your project in the file list, choose your target under `TARGETS`, click the `Build Phases` tab\n2. Add a `New Run Script Phase` by clicking the little plus icon in the top left\n3. Uncheck the `Based on dependency analysis` checkbox\n4. Drag the new `Run Script` phase **above** the `Compile Sources` phase, expand it and paste the following script:\n\n    ```bash\n    cd BuildTools\n    SDKROOT=(xcrun --sdk macosx --show-sdk-path)\n    #swift package update #Uncomment this line temporarily to update the version used to the latest matching your BuildTools/Package.swift file\n    swift run -c release swiftformat \"$SRCROOT\"\n    ```\n\nYou can also use `swift run -c release --package-path BuildTools swiftformat \"$SRCROOT\"` if you need a more complex script and `cd BuildTools` breaks stuff.\n\n**NOTE:** You may wish to check BuildTools/Package.swift into your source control so that the version used by your run-script phase is kept in version control. It is recommended to add the following to your .gitignore file: `BuildTools/.build` and `BuildTools/.swiftpm`.\n\n**NOTE (2):** If you are using Xcode 15 or later, make sure that the `ENABLE_USER_SCRIPT_SANDBOXING` (aka \"User Script Sandboxing\") option is set to NO, otherwise SwiftFormat won't be able to run correctly.\n\n### Using CocoaPods\n\n#### 1) Add the SwiftFormat CLI to your Podfile\n\n1. Add the `swiftformat` binary to your project directory via [CocoaPods](https://cocoapods.org/), by adding the following line to your Podfile then running `pod install`:\n\n    ```ruby\n    pod 'SwiftFormat/CLI', '~> 0.58.7'\n    ```\n\n**NOTE:** This will only install the pre-built command-line app, not the source code for the SwiftFormat framework.\n\n**NOTE (2):** When installing this way, GateKeeper may block swiftformat from running until you open it manually the first time by right-clicking in the Finder and selecting \"Open\".\n\n#### 2) Add a Build phase to your app target\n\n1. Click on your project in the file list, choose your target under `TARGETS`, click the `Build Phases` tab\n2. Add a `New Run Script Phase` by clicking the little plus icon in the top left\n3. Uncheck the `Based on dependency analysis` checkbox\n4. Drag the new `Run Script` phase **above** the `Compile Sources` phase, expand it and paste the following script:\n\n    ```bash\n    \"${PODS_ROOT}/SwiftFormat/CommandLineTool/swiftformat\" \"$SRCROOT\"\n    ```\n\n### Alternative: Locally installed SwiftFormat\n\nAlternatively, you could use a locally installed swiftformat command-line tool instead by putting the following in your Run Script build phase:\n\n```bash\nif which swiftformat >/dev/null; then\n  swiftformat .\nelse\n  echo \"warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\"\nfi\n```\n\nThis is not recommended for shared projects however, as different team members using different versions of SwiftFormat may result in noise in the commit history as code gets reformatted inconsistently.\n\nIf you installed SwiftFormat via Homebrew on Apple Silicon, you might experience this warning:\n\n> warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\n\nThat is because Homebrew on Apple Silicon installs the binaries into the `/opt/homebrew/bin`\nfolder by default. To instruct Xcode where to find SwiftFormat, you can either add\n`/opt/homebrew/bin` to the `PATH` environment variable in your build phase\n\n```bash\nif [[ \"$(uname -m)\" == arm64 ]]; then\n    export PATH=\"/opt/homebrew/bin:$PATH\"\nfi\n\nif which swiftformat > /dev/null; then\n  swiftformat .\nelse\n  echo \"warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\"\nfi\n```\n\nor you can create a symbolic link in `/usr/local/bin` pointing to the actual binary:\n\n```bash\nln -s /opt/homebrew/bin/swiftformat /usr/local/bin/swiftformat\n```\n\nSwift Package Manager plugin\n-----------------------------\n\nYou can use `SwiftFormat` as a SwiftPM command plugin.\n\n**NOTE:** Swift 5.6 or higher is required. Add the package to your dependencies in your `Package.swift` file.\n\n```swift\ndependencies: [\n    // ...\n    .package(url: \"https://github.com/nicklockwood/SwiftFormat\", from: \"0.58.7\"),\n]\n```\n\nThe plugin will find an existing `.swiftformat` in your package root folder and honor it automatically.\n\n### Trigger Plugin From Command-Line\n\n```bash\nswift package plugin --allow-writing-to-package-directory swiftformat\n```\n\nYou can limit the formatting to a particular target with `--target` option.\n\nYou can also specify `SwiftFormat` arguments, e.g. `--swift-version`.\n\nExample\n\n```bash\nswift package plugin --allow-writing-to-package-directory swiftformat --target MyLibrary --swift-version 5.6 --verbose\n```\n\n### Trigger Plugin From Xcode\n\nIn Xcode 14 you can trigger the command plugin execution for a Swift package or an Xcode project.\n\nFor an Xcode project the project's main directory will be processed and the `--target` option will be ignored.\n\nYou can also specify `SwiftFormat` arguments, e.g. `--swift-version`.\n\n![Run plugin in Xcode 14](https://user-images.githubusercontent.com/4176826/179352584-db7f7f42-452c-4a42-a329-01b115a237a7.gif)\n\nVia AppleScript\n----------------\n\nTo run SwiftFormat on the frontmost Xcode document (project or workspace) you can use the following AppleScript:\n\n```applescript\ntell application \"Xcode\"\n    set frontWindow to the first window\n    set myPath to path of document of frontWindow\n    do shell script \"cd \" & myPath & \";cd ..; /usr/local/bin/swiftformat .\"\nend tell\n```\n\nSome Apps you can trigger this from are [BetterTouchTool](https://folivora.ai), [Alfred](https://www.alfredapp.com) or [Keyboard Maestro](https://www.keyboardmaestro.com/main/). Another option is to define a QuickAction for Xcode via Automator and then assign a keyboard shortcut for it in the System Preferences.\n\n\nVSCode plugin\n--------------\n\nIf you prefer to use Microsoft's [VSCode](https://code.visualstudio.com) editor for writing Swift, [Valentin Knabel](https://github.com/vknabel) has created a [VSCode plugin](https://marketplace.visualstudio.com/items?itemName=vknabel.vscode-swiftformat) for SwiftFormat.\n\n\nSublime Text plugin\n--------------------\n\nIf you prefer to use the [Sublime Text](https://www.sublimetext.com) editor, try the [Sublime-Swift-Format plugin](https://github.com/aerobounce/Sublime-Swift-Format) by [Aerobounce](https://github.com/aerobounce).\n\n\nNova plugin\n-----------\n\nIf you prefer to use the [Nova](https://panic.com/nova) editor, try the [SwiftFormat extension](https://extensions.panic.com/extensions/org.padraig/org.padraig.SwiftFormat/) by [P√°draig √ì Cinn√©ide](https://mastodon.social/@PadraigOCinneide).\n\n\nGit pre-commit hook\n---------------------\n\n1. Follow the instructions for installing the SwiftFormat command-line tool.\n\n2. Install [git-format-staged](https://github.com/hallettj/git-format-staged).\n\n3. Edit or create a `.git/hooks/pre-commit` file in your project folder. The .git folder is hidden but should already exist if you are using Git with your project, so open it with the terminal, or the Finder's `Go > Go to Folder...` menu.\n\n4. Add the following line in the pre-commit file. The `{}` will be replaced automatically by the path to the Swift file being formatted:\n\n    ```bash\n    #!/bin/bash\n    git-format-staged --formatter \"swiftformat stdin --stdin-path '{}'\" \"*.swift\"\n    ```\n    \n    (Note that this example uses your locally installed version of SwiftFormat, not a separate copy in your project repository. You can replace `swiftformat` with the path to a copy inside your project if you prefer.)\n    \n5. enable the hook by typing `chmod +x .git/hooks/pre-commit` in the terminal.\n \nThe pre-commit hook will now run whenever you run `git commit`. Running `git commit --no-verify` will skip the pre-commit hook.\n\n**NOTE:** If you are using Git via a GUI client such as [Tower](https://www.git-tower.com), [additional steps](https://www.git-tower.com/help/mac/faq-and-tips/faq/hook-scripts) may be needed.\n\n**NOTE (2):** Unlike the Xcode build phase approach, git pre-commit hook won't be checked in to source control, and there's no way to guarantee that all users of the project are using the same version of SwiftFormat. For a collaborative project, you might want to consider a *post*-commit hook instead, which would run on your continuous integration server.\n\nGitHub Actions\n---------------------\n\n1. SwiftFormat comes preinstalled on all macOS GitHub-hosted runners. If you are self hosting you will need to ensure SwiftFormat is installed on your runner.\n2. Create a GitHub Actions workflow using SwiftFormat, passing the `--reporter github-actions-log` command line option. The following example action lints pull requests using SwiftFormat, reporting warnings using the GitHub Actions log.\n```yaml\n# Lint.yml\nname: Lint\non: pull_request\n\njobs:\n  Lint:\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: SwiftFormat\n        run: swiftformat --lint . --reporter github-actions-log\n```\n\nOn CI using Danger\n-------------------\n\nTo setup SwiftFormat to be used by your continuous integration system using [Danger](http://danger.systems/ruby/), do the following:\n\n1. Follow the [`instructions`](http://danger.systems/guides/getting_started.html) to setup Danger.\n2. Add the [`danger-swiftformat`](https://github.com/garriguv/danger-ruby-swiftformat) plugin to your `Gemfile`.\n3. Add the following to your `Dangerfile`:\n\n    ```ruby\n    swiftformat.binary_path = \"/path/to/swiftformat\" # optional\n    swiftformat.additional_args = \"--indent tab --self insert\" # optional\n    swiftformat.check_format(fail_on_error: true)\n    ```\n\n    **NOTE:** It is recommended to add the `swiftformat` binary to your project directory to ensure the same version is used each time (see the [Xcode build phase](#xcode-build-phase) instructions above).\n\n\nBazel Build\n-----------\n\nIf you use [Bazel](https://bazel.build/) to build your Swift projects and want to ensure that only properly formatted code is merged to your main branch, try [rules_swiftformat](https://github.com/cgrindel/rules_swiftformat). The repository contains Bazel rules and macros that format Swift source files using SwiftFormat, test that the formatted files exist in the workspace directory, and copy the formatted files to the workspace directory.\n\n\nDocker\n-----------\n\nSwiftFormat publishes releases into [GitHub Packages](https://github.com/features/packages) Docker registry. To pull the image call:\n\n```bash\n$ docker pull ghcr.io/nicklockwood/swiftformat:latest\n```\n\nBy default, the container runs `swiftformat .` Therefore, you need to provide a path either via an argument:\n\n```bash\ndocker run --rm -v /local/source/path:/work ghcr.io/nicklockwood/swiftformat:latest /work\n```\n\nor by changing the working dir:\n\n```bash\ndocker run --rm -v /local/source/path:/work -w /work ghcr.io/nicklockwood/swiftformat:latest\n```\n\nTo check the installed SwiftFormat version:\n\n```bash\ndocker run --rm ghcr.io/nicklockwood/swiftformat:latest --version\n```\n\nLinting example:\n\n```bash\ndocker run --rm -v /local/source/path:/work ghcr.io/nicklockwood/swiftformat:latest /work --lint\n```\n\nPrerelease Builds\n-----------------\n\n***Prerelease builds are subject to breaking changes.***\n\nNew rules, options, and fixes are merged to the [`develop`](https://github.com/nicklockwood/SwiftFormat/commits/develop/) branch before being incorporated into an official release. You may want to use a prerelease version of SwiftFormat that includes the latest unreleased changes.\n\n**Homebrew:**\n\nThe [Homebrew](http://brew.sh/) `--HEAD` option downloads, builds, and installs the latest changes from the `develop` branch. \n\nYou can install a prerelease build via Homebrew by running:\n\n```bash\n$ brew install swiftformat --HEAD\n```\n\n**Nightly Builds:**\n\nNightly builds of the `develop` branch are available in the [calda/SwiftFormat-nightly](https://github.com/calda/SwiftFormat-nightly) repo. A new release is published every day, unless there have been no changes to `develop` since the last release. You can download executables for the latest nightly release [here](https://github.com/calda/SwiftFormat-nightly/releases/latest).\n\nCommit SHAs on `develop` are unstable since that branch is occasionally rebased, but artifact URLs and tags in [calda/SwiftFormat-nightly](https://github.com/calda/SwiftFormat-nightly) are stable references that can be used from other repos or tools.\n\nConfiguration\n-------------\n\nSwiftFormat's configuration is split between **rules** and **options**. Rules are functions in the SwiftFormat library that apply changes to the code. Options are settings that control the behavior of the rules. \n\n\nOptions\n-------\n\nThe options available in SwiftFormat can be displayed using the `--options` command-line argument. The default value for each option is indicated in the help text.\n\nRules are configured by adding `--[option_name] [value]` to your command-line arguments, or by creating a `.swiftformat` [config file](#config-file) and placing it in your project directory.\n\nA given option may affect multiple rules. Use `--rule-info [rule_name]` command for details about which options affect a given rule, or see the [Rules.md](https://github.com/nicklockwood/SwiftFormat/blob/main/Rules.md) file.\n\nYou can configure options for specific files or code ranges by using `swiftformat:options` directive in comments inside your Swift file. To temporarily set one or more options inside a source file, use:\n\n```swift\n// swiftformat:options --indent 2 --allman true\n```\n\nTo apply an options override only to a particular line, use the `:this`, `:next` or `:previous` modifiers:\n\n```swift\nlet indexUrl: URL // swiftformat:options:this --preserve-acronyms url \n\n// swiftformat:options:next --semicolons inline\ndoTheThing(); print(\"Did the thing\")\n```\n\n\nRules\n-----\n\nSwiftFormat includes over 50 rules, and new ones are added all the time. An up-to-date list can be found in [Rules.md](https://github.com/nicklockwood/SwiftFormat/blob/main/Rules.md) along with documentation for how they are used.\n\nThe list of available rules can be displayed within the command-line app using the `--rules` argument. Rules can be either enabled or disabled. Most are enabled by default. Disabled rules are marked with \"(disabled)\" when displayed using `--rules`.\n\nYou can use the `--rule-info [rule_name]` command to get information about a specific rule. Pass a comma-delimited list of rule names to get information for multiple rules at once, or use `--rule-info` with no argument for info on all rules.\n\nYou can disable rules individually using `--disable` followed by a list of one or more comma-delimited rule names, or enable opt-in rules using `--enable` followed by the rule names:\n\n```bash\n--disable redundantSelf,trailingClosures\n--enable isEmpty\n```\n\nIf you prefer, you can use multiple `--enable`/`--disable` arguments instead of using commas:\n\n```bash\n--disable indent\n--disable linebreaks\n--disable redundantSelf\n```\n\nAlternatively, you can use the line continuation character `\\` to wrap a single argument over multiple line:\n\n```bash         \n--disable          \\\n    indent,        \\\n    linebreaks,    \\\n    redundantSelf\n```\n\nTo avoid automatically opting-in to new rules when SwiftFormat is updated, you can disable all rules using:\n\n```bash\n--disable all\n```\n\nAnd then individually enable just the rules you want. Alternatively, use the`--rules` argument to *only* enable the rules you specify:\n\n```bash\n--rules indent,linebreaks\n```\n\nAs above, you may include multiple `--rules` arguments, or use the line continuation character `\\` to wrap the rules onto separate lines:\n\n```bash\n--rules redundantSelf\n--rules         \\\n    indent,     \\\n    linebreaks\n```\n\nTo see exactly which rules were applied to a given file, you can use the `--verbose` command-line option to force SwiftFormat to print a more detailed log as it applies the formatting. **NOTE:** running in verbose mode is slower than the default mode.\n\nYou can disable rules for specific files or code ranges by using `swiftformat:` directives in comments inside your Swift file. To temporarily disable one or more rules inside a source file, use:\n\n```swift\n// swiftformat:disable <rule1> [<rule2> [rule<3> ...]]\n```\n\nTo enable the rule(s) again, use:\n\n```swift\n// swiftformat:enable <rule1> [<rule2> [rule<3> ...]]\n```\n\nTo disable all rules use:\n\n```swift\n// swiftformat:disable all\n```\n\nAnd to enable them all again, use:\n\n```swift\n// swiftformat:enable all\n```\n\nTo temporarily prevent one or more rules being applied to just the next line, use:\n\n```swift\n// swiftformat:disable:next <rule1> [<rule2> [rule<3> ...]]\nlet foo = bar // rule(s) will be disabled for this line\nlet bar = baz // rule(s) will be re-enabled for this line\n```\n\nYou can also use `this` or `previous` to enable or disable rules for the current or previous line. There is no need to manually re-enable a rule after using the `next`, `this` or `previous` directives.\n\n**NOTE:** The `swiftformat:enable` directive only serves to counter a previous `swiftformat:disable` directive in the same file. It is not possible to use `swiftformat:enable` to enable a rule that was not already enabled when formatting started.\n\n\nSwift version\n-------------\n\nMost SwiftFormat rules are version-agnostic, but some are applicable only to newer Swift versions. These rules will be disabled automatically if the Swift version is not specified, so to make sure that the full functionality is available you should specify the version of Swift that is used by your project.\n\nYou can specify the Swift compiler version in one of two ways:\n\nYou can specify your project's Swift compiler version using the `--swift-version` command line argument. You can also add the `--swift-version` option to your `.swiftformat` file.\n\nAnother option is to add a `.swift-version` file to your project directory. This is a text file that should contain the minimum Swift version supported by your project, and is also supported by some other tools. Any `.swift-version` files always take precedence over the `--swift-version` argument.\n\nBoth the `.swift-version` file and the `--swift-version` option in a `.swiftformat` file are applied hierarchically; If you have submodules in your project that use a different Swift version, you can add separate swift version configurations for those directories.\n\nSwift language mode\n-------------------\n\nSwiftFormat also allows you to specify the Swift _language mode_ used by your project. This is distinct from the Swift compiler version. For example, you can use the Swift 6.0 compiler with either the Swift 5 language mode or the Swift 6 language mode. Some SwiftFormat rules will behave differently under different Swift language modes.\n\nYou can specify your project's Swift language mode using the `--language-mode` command line argument. You can also add the `--language-mode` option to your `.swiftformat` file.\n\nIf not specified, SwiftFormat uses the default language mode of the specified Swift compiler version. The default language mode in Swift 5.x and Swift 6.x is the Swift 5 language mode. If your project uses the Swift 6 language mode, you should specify `--language-mode 6`.\n\n\nConfig file\n-----------\n\nAlthough it is possible to configure SwiftFormat directly by using the command-line [options](#options) and [rules](#rules) detailed above, it is sometimes more convenient to create a configuration file, which can be added to your project and shared with other developers.\n\nA SwiftFormat configuration file consists of one or more command-line options, split onto separate lines, e.g:\n\n```\n--allman true\n--indent tab\n--disable elseOnSameLine,semicolons\n```\n\nWhile formatting, SwiftFormat will automatically check inside each subdirectory for the presence of a `.swiftformat` file and will apply any options that it finds there to the files in that directory.\n\nThis allows you to override certain rules or formatting options just for a particular directory of files. You can also specify excluded files relative to that directory using `--exclude`, which may be more convenient than specifying them at the top-level:\n\n```\n--exclude Pods,Generated\n```\n\nThe `--exclude` option takes a comma-delimited list of file or directory paths to exclude from formatting. Excluded paths are relative to the config file containing the `--exclude` command. The excluded paths can include wildcards, specified using Unix \"Glob\" syntax, as [documented below](#globs).\n\nConfig files named \".swiftformat\" will be processed automatically, however, you can select an additional configuration file to use for formatting using the `--config \"path/to/config/file\"` command-line argument. A configuration file selected using `--config` does not need to be named \".swiftformat\", and can be located outside of the project directory.\n\nThe config file format is designed to be edited by hand. You may include blank lines for readability, and can also add comments using a hash prefix (#), e.g.\n\n```\n# format options\n--allman true\n--indent tab # tabs FTW!\n\n# file options\n--exclude Pods\n\n# rules\n--disable elseOnSameLine,semicolons\n```\n\nYou can create multiple configuration sections within a single `.swiftformat` file to apply different formatting options to different parts of your project. Each section should specify a `--filter` glob pattern to determine which files the configuration applies to. Options in that section are used when formatting files that match `--filter` glob, in addition to the base options in the file.\n\n```\n--enable indent\n--indent 4\n\n[Tests]\n--filter **/Tests/**\n--enable noForceUnwrapInTests\n--enable noForceTryInTests\n--indent 2\n```\n\nIf you would prefer not to edit the configuration file by hand, you can use the [SwiftFormat for Xcode](#xcode-source-editor-extension) app to edit the configuration and export a configuration file. You can also use the swiftformat command-line-tool's `--inferoptions` command to generate a config file from your existing project, like this:\n\n```bash\n$ cd /path/to/project\n$ swiftformat --infer-options . --output .swiftformat\n```\n\nGlobs\n-----\n\nWhen excluding files from formatting using the `--exclude` option, you may wish to make use of wildcard paths (aka \"Globs\") to match all files that match a particular naming convention without having to manually list them all.\n\nSwiftFormat's glob syntax is based on Ruby's implementation, which varies slightly from the Unix standard. The following patterns are supported:\n\n* `*` - A single star matches zero or more characters in a filename, but *not* a `/`.\n\n* `**` - A double star will match anything, including one or more `/`.\n\n* `?` - A question mark will match any single character except `/`.\n\n* `[abc]` - Matches any single character inside the brackets.\n\n* `[a-z]` - Matches a single character in the specified range in the brackets.\n\n* `{foo,bar}` - Matches any one of the comma-delimited strings inside the braces.\n\nExamples:\n\n* `foo.swift` - Matches the file \"foo.swift\" in the same directory as the config file.\n\n* `*.swift` - Matches any Swift file in the same directory as the config file.\n\n* `foo/bar.swift` - Matches the file \"bar.swift\" in the directory \"foo\".\n\n* `**/foo.swift` - Matches any file named \"foo.swift\" in the project.\n\n* `**/*.swift` - Matches any Swift file in the project.\n\n* `**/Generated` - Matches any folder called `Generated` in the project.\n\n* `**/*_generated.swift` - Matches any Swift file with the suffix \"_generated\" in the project.\n\n\nLinting\n-------\n\nSwiftFormat is primarily designed as a formatter rather than a linter, i.e. it is designed to fix your code rather than tell you what's wrong with it. However, sometimes it can be useful to verify that code has been formatted in a context where it is not desirable to actually change it.\n\nA typical example would be as part of a CI (Continuous Integration) process, where you may wish to have an automated script that checks committed code for style violations. While you can use a separate tool such as [SwiftLint](https://github.com/realm/SwiftLint) for this, it makes sense to be able to validate the formatting against the exact same rules as you are using to apply it.\n\nIn order to run SwiftFormat as a linter, you can use the `--lint` command-line option:\n\n```bash\n$ swiftformat --lint path/to/project\n```\n\nThis runs the same rules as format mode, and all the same configuration options apply, however, no files will be modified. Instead, SwiftFormat will format each file in memory and then compare the result against the input and report the lines that required changes.\n\nThe `--lint` option is similar to `--dry-run`, but `--lint` returns warnings for every line that required changes, and will return a nonzero error code (see [Error codes](#error-codes) below) if any changes are detected, which is useful if you want it to fail a build step on your CI server.\n\nIf you would prefer `--lint` not to fail your build, you can use the `--lenient` option to force SwiftFormat to return success in `--lint` mode even when formatting issues were detected.\n\n```bash\n$ swiftformat --lint --lenient path/to/project\n```\n\nBy default, `--lint` will only report lines that require formatting, but you can use the additional `--verbose` flag to display additional info about which files were checked, even if there were no changes needed.\n\nIf you would prefer not to see a warning for each and every formatting change, you can use the `--quiet` flag to suppress all output except errors.\n\nSometimes you may wish to autoformat some rules, but only lint others. To do that, use the `--lintonly` option in your config file to specify rules that should only be applied in `--lint` mode:\n\n```\n--rules braces,indent\n--lint-only trailingClosures,unusedArguments\n```\n\n\nError codes\n-----------\n\nThe swiftformat command-line tool will always exit with one of the following codes:\n\n* 0 - Success. This code will be returned in the event of a successful formatting run or if `--lint` detects no violations.\n* 1 - Lint failure. This code will be returned when running in `--lint` mode, or when autocorrecting in `--strict` mode, if the input requires formatting.\n* 70 - Program error. This code will be returned if there is a problem with the input or configuration arguments.\n\n\nCache\n------\n\nSwiftFormat uses a cache file to avoid reformatting files that haven't changed. For a large project, this can significantly reduce processing time.\n\nBy default, the cache is stored in `~/Library/Caches/com.charcoaldesign.swiftformat` on macOS, or `/tmp/com.charcoaldesign.swiftformat` on Linux. Use the command-line option `--cache ignore` to ignore the cached version and re-apply formatting to all files. Alternatively, you can use `--cache clear` to delete the cache (or you can just manually delete the cache file).\n\nThe cache is shared between all projects. The file is fairly small, as it only stores the path and size for each file, not the contents. If you do start experiencing slowdown due to the cache growing too large, you might want to consider using a separate cache file for each project.\n\nYou can specify a custom cache file location by passing a path as the `--cache` option value. For example, you might want to store the cache file inside your project directory. It is fine to check in the cache file if you want to share it between different users of your project, as the paths stored in the cache are relative to the location of the formatted files.\n\n\nFile headers\n-------------\n\nSwiftFormat can be configured to strip or replace the header comments in every file with a template. The \"header comment\" is defined as a comment block that begins on the first nonblank line in the file, and is followed by at least one blank line. This may consist of a single comment body, or multiple comments on consecutive lines:\n\n```swift\n// This is a header comment\n```\n\n```swift\n// This is a regular comment\nfunc foo(bar: Int) -> Void { ... }\n```\n\nThe header template is a string that you provide using the `--header` command-line option. Passing a value of `ignore` (the default) will leave the header comments unmodified. Passing `strip` or an empty string `\"\"` will remove them. If you wish to provide a custom header template, the format is as follows:\n\nFor a single-line template: `--header \"Copyright (c) 2017 Foobar Industries\"`\n\nFor a multiline comment, mark linebreaks with `\\n`: `--header \"First line\\nSecond line\"`\n\nYou can optionally include Swift comment markup in the template if you wish: `--header \"/*--- Header comment ---*/\"`\n\nIf you do not include comment markup, each line in the template will be prepended with `//` and a single space.\n\nIt is common practice to include the file name, creation date and/or the current year in a comment header copyright notice. To do that, you can use the following placeholders:\n\n* `{file}` - the name of the file\n* `{year}` - the current year\n* `{created}` - the date on which the file was created\n* `{created.year}` - the year in which the file was created\n* `{author.name}` - the name of the user who first committed the file\n* `{author.email}` - the email of the user who first committed the file \n\nFor example, a header template of:\n\n```bash\n--header \"{file}\\nCopyright (c) {year} Foobar Industries\\nCreated by John Smith on {created}.\"\n```\n\nWill be formatted as:\n\n```swift\n// SomeFile.swift\n// Copyright (c) 2019 Foobar Industries\n// Created by John Smith on 01/02/2016.\n```\n\n**NOTE:** the `{year}` value and `{created}` date format are determined from the current locale and timezone of the machine running the script. `{author.name}` and `{author.email}` requires the project to be version controlled by git.\n\n\nMarkdown formatting\n-------------------\n\nSwiftFormat can format Swift code blocks inside Markdown files (`.md`). This is useful for keeping code examples in documentation, README files, and other markdown content properly formatted.\n\n````diff\n  ### Sample README\n  \n  This is a nice project with lots of cool APIs to know about, including:\n  \n  ```swift\n  func foo(\n- bar: Bar,\n- baaz: Baaz\n+     bar: Bar,\n+     baaz: Baaz\n  ) -> Foo { ... }\n  ```\n````\n\nTo format Swift code blocks in markdown files, use the `--markdown-files` option with either `strict` or `lenient`:\n\n```bash\n$ swiftformat . --markdown-files strict\n$ swiftformat . --markdown-files lenient\n```\n\nOr add it to your `.swiftformat` config file:\n\n```\n--markdown-files strict\n```\n\n**Formatting modes:**\n\nSwiftFormat supports two modes for handling markdown files:\n\n- `lenient` (default): Ignores parsing errors in code blocks and continues formatting\n- `strict`: Fails if any code blocks contain parsing errors\n\nSwiftFormat's tokenizer is more permissive than the Swift compiler and typically only emits errors when encountering unbalanced scope tokens like `(` or `{`.\n\n**Code block options:**\n\nYou can specify options for options for individual code blocks by adding them after the opening delimiter. For example, you can use `no-format` to prevent a code block from being parsed or formatted:\n\n````md\n```swift no-format\nfunc example()\n{\n    doSomething()\n}\n```\n````\n\nYou can also specify SwiftFormat command line options to configure the behavior of individual rules:\n\n````md\n```swift --indent 2\nfunc example() {\n  doSomething()\n}\n```\n\n```swift --disable redundantSelf\nfunc example() {\n    self.doSomething()\n}\n```\n````\n\nFAQ\n-----\n\n*Q. How is this different from SwiftLint?*\n\n> A. SwiftLint is primarily designed to find and report code smells and style violations in your code. SwiftFormat is designed to fix them. While SwiftLint can autocorrect some issues, and SwiftFormat has some support for [linting](#linting), their primary functions are different.\n\n\n*Q. Can SwiftFormat and SwiftLint be used together?*\n\n> A. Absolutely! The style rules encouraged by both tools are quite similar, and SwiftFormat even fixes some style violations that SwiftLint warns about but can't currently autocorrect.\n\n\n*Q. What platforms does SwiftFormat support?*\n\n> A. SwiftFormat works on macOS 10.13 (High Sierra) and above, and also runs on Ubuntu Linux and Windows.\n\n\n*Q. What versions of Swift are supported?*\n\n> A. The SwiftFormat framework and command-line tool can be compiled using Swift 5.3 and above, and can format programs written in Swift 4.x or 5. Swift 3.x is no longer actively supported. If you are still using Swift 3.x or earlier and find that SwiftFormat breaks your code, the best solution is probably to revert to an earlier SwiftFormat release, or enable only a small subset of rules. Use the `--swift-version` argument to enable additional rules specific to later Swift versions.\n\n\n*Q. SwiftFormat made changes I didn't want it to. How can I find out which rules to disable?*\n\n> A. If you run SwiftFormat using the `--verbose` option, it will tell you which rules were applied to each file. You can then selectively disable certain rules using the `--disable` argument (see below).\n\n\n*Q. People on my team have different SwiftFormat versions installed. How can we ensure consistent formatting?\n\n> A. You can specify a `--min-version` argument in your project's .swiftformat` file to fail the build if developers attempt to use an older SwiftFormat version.\n\n\n*Q. How can I modify the formatting rules?*\n\n> A. Many configuration options are exposed in the command-line interface or `.swiftformat` configuration file. You can either set these manually, or use the `--infer-options` argument to automatically generate the configuration from your existing project.\n\n> If there is a rule that you don't like, and which cannot be configured to your liking via the command-line options, you can disable one or more rules by using the `--disable` argument, followed by the name of the rules, separated by commas. You can display a list of all supported rules using the `--rules` argument, and their behaviors are documented above this section in the README.\n\n> If you are using the Xcode source editor extension, rules and options can be configured using the [SwiftFormat for Xcode](#xcode-source-editor-extension) host application. Unfortunately, due to limitation of the Extensions API, there is no way to configure these on a per-project basis.\n\n> If the options you want aren't exposed, and disabling the rule doesn't solve the problem, the rules are implemented in the file `Rules.swift`, so you can modify them and build a new version of the command-line tool. If you think your changes might be generally useful, make a pull request.\n\n\nQ. I don't want to be surprised by new rules added when I upgrade SwiftFormat. How can I prevent this?\n\n> A. You can use the `--rules` argument to specify an exclusive list of rules to run. If new rules are added, they won't be enabled if you have specified a `--rules` list in your SwiftFormat configuration.\n\n\n*Q. Why can't I set the indent width or choose between tabs/spaces in the [SwiftFormat for Xcode](#xcode-source-editor-extension) options?*\n\n> Indent width and tabs/spaces can be configured in Xcode on a per project-basis. You'll find the option under \"Text Settings\" in the Files inspector of the right-hand sidebar.\n\n\n*Q. After applying SwiftFormat, my code won't compile. Is that a bug?*\n\n> A. SwiftFormat should ideally never break your code. Check the [known issues](#known-issues), and if it's not already listed there, or the suggested workaround doesn't solve your problem, please [open an issue on GitHub](https://github.com/nicklockwood/SwiftFormat/issues).\n\n\n*Q. Can I use SwiftFormat to lint my code without changing it?*\n\n> A. Yes, see the [linting](#linting) section above for details.\n\n\n*Q. Can I use the `SwiftFormat.framework` inside another app?*\n\n> A. Yes, the SwiftFormat framework can be included in an app or test target, and used for many kinds of parsing and processing of Swift source code besides formatting. The SwiftFormat framework is available as a [CocoaPod](https://cocoapods.org/pods/SwiftFormat) for easy integration.\n\n*Q. How to create own rule?*\n\n> A. 1) Open `SwiftFormat.xcodeproj`; 2) Add a rule in `Sources/Rules/..`; 3) Add a test in `Tests/Rules/..`; 4) Add an example in `Sources/Examples.swift`; 5) Run all tests.\n\n*Q. How do I run and debug the command line tool in Xcode while developing a new rule?*\n\n> A. You can run the `swiftformat` command line tool via the `Swift Format (Command Line Tool)` scheme, and you can pass in arguments like `/path/to/my/code --config /path/to/my/config` as the `Arguments Passed On Launch` in Xcode's scheme editor. More instructions are available [here](https://github.com/nicklockwood/SwiftFormat/pull/1804#issuecomment-2263079432).\n\nKnown issues\n---------------\n\n* When using the Xcode Source Editor Extension, the SwiftFormat menu sometimes disappears from Xcode. If this happens, try moving or renaming Xcode temporarily and then changing it back. Failing that, the suggestions in [this thread](https://github.com/nicklockwood/SwiftFormat/issues/494) may help.\n\n* The `enumNamespaces` rule replaces classes that have only static members with an `enum`. If the class is subclassed, or if there is code that depends on the class exposing certain runtime behaviors, this may break the program. To solve this you can either fix it on a per-case basis by adding a `// swiftformat:disable:next enumNamespaces` comment directive above the class declaration, or you can add `--enum-namespaces structs-only` to prevent the rule being applied to classes, or you can just disable the `enumNamespaces` rule completely.\n\n* The `redundantVoidReturnType` rule can inadvertently alter the type signature for closures, for example in cases where the closure calls a `@discardableResult` function. To solve this you can either fix it on a per-case basis by adding a `// swiftformat:disable:next redundantVoidReturnType` comment directive to disable the rule for a specific call site, or you can add `--closure-void preserve` to your [configuration](#configuration) to disable the rule completely for closures (regular functions or methods aren't affected).\n\n* The `redundantType` rule can introduce ambiguous code in certain cases when using the default mode of `--redundant-type inferred`. This can be worked around by by using `--redundant-type explicit`, or by manually removing the redundant type reference on the affected line, or by using the `// swiftformat:disable:next redundantType` comment directive to disable the rule at the call site (or just disable the `redundantType` rule completely).\n\n* If a type initializer or factory method returns an implicitly unwrapped optional value then the `redundantType` rule may remove the explicit type in a situation where it's actually required. To work around this you can either use `--redundant-type explicit`, or use the `// swiftformat:disable:next redundantType` comment directive to disable the rule at the call site (or just disable the `redundantType` rule completely).\n\n* When using the `initCoderUnavailable` rule, if an `init` that is marked as unavailable is overridden elsewhere in the program then it will cause a compilation error. The recommended workaround is to remove the override (which shouldn't affect the program behavior if the init was really unused) or use the `// swiftformat:disable:next initCoderUnavailable` comment directive to disable the rule for the overridden init (or just disable the `initCoderUnavailable` rule completely).\n\n* When using the `extensionAccessControl` rule with the `--extension-acl on-extension` option, if you have public methods defined on an internal type defined in another file, the resultant public extension will no longer compile. The recommended solution is to manually remove the `public` modifier (this won't change the program behavior) or disable the `extensionAccessControl` rule.\n\n* When using the `preferKeyPath` rule, conversion of `compactMap { $0.foo }` to `compactMap(\\.foo)` or `flatMap { $0.foo }` to `flatMap(\\.foo)` will result in code that fails to compile if `foo` is not an `Optional` property. This is due to a difference in the way that Swift handles type inference for closures vs keyPaths, as discussed [here](https://bugs.swift.org/browse/SR-13347). The recommended workaround is to replace `compactMap()` or `flatMap()` with `map()` in these cases, which will not change the behavior of the code.\n\n* When using the `--self remove` option, the `redundantSelf` rule will remove references to `self` in autoclosure arguments, which may change the meaning of the code, or cause it not to compile. To work around this issue, use the `--self-required` option to provide a comma-delimited list of methods to be excluded from the rule. The `expect()` function from the popular [Nimble](https://github.com/Quick/Nimble) unit testing framework is already excluded by default. If you are using the `--self insert` option then this is not an issue.\n\n* If you assign `SomeClass.self` to a variable and then instantiate an instance of the class using that variable, Swift requires that you use an explicit `.init()`, however, the `redundantInit` rule is not currently capable of detecting this situation in all cases, and may remove the `.init`. To work around this issue, use the `// swiftformat:disable:next redundantInit` comment directive to disable the rule for any affected lines of code (or just disable the `redundantInit` rule completely).\n\n* The `--self insert` option can only recognize locally declared member variables, not ones inherited from superclasses or extensions in other files, so it cannot insert missing `self` references for those. Note that the reverse is not true: `--self remove` should remove *all* redundant `self` references.\n\n* The `trailingClosures` rule can generate ambiguous code if a function has multiple optional closure arguments, or if multiple functions have signatures differing only by the name of the closure argument. For this reason, the rule is limited to anonymous closure arguments by default. You can use the `--trailing-closures` and `--never-trailing` arguments to explicitly opt in or out of trailing closure support for specific functions.\n\n* The `isEmpty` rule will convert `count == 0` to `isEmpty` even for types that do not have an `isEmpty` method, such as `NSArray`/`NSDictionary`/etc. Use of Foundation collections in Swift code is pretty rare, but just in case, the rule is disabled by default.\n\n* The `preferForLoop` rule will convert `foo.forEach` to `for item in foo` even for types that do not conform to the `Sequence` protocol and cannot be used with a `for ... in` loop. There are no such types built in, but custom types may have this issue.\n\n* If a file begins with a comment, the `stripHeaders` rule will remove it if it is followed by a blank line. To avoid this, make sure that the first comment is directly followed by a line of code.\n\n* When running a version of SwiftFormat built using Xcode 10.2 on macOS 10.14.3 or earlier, you may experience a crash with the error \"dyld: Library not loaded: @rpath/libswiftCore.dylib\". To fix this, you need to install the [Swift 5 Runtime Support for Command Line Tools](https://support.apple.com/kb/DL1998). These tools are included by default in macOS 10.14.4 and later.\n\n* If you have a generic typealias that defines a closure (e.g. `typealias ResultCompletion<T> = (Result<T, Error>) -> Void`) and use this closure as an argument in a generic function (e.g. `func handle<T: Decodable>(_ completion: ResultCompletion<T>)`), the `opaqueGenericParameters` rule may update the function definition to use `some` syntax (e.g. `func handle(_ completion: ResultCompletion<some Decodable>)`). `some` syntax is not permitted in closure parameters, so this will no longer compile. Workarounds include spelling out the closure explicitly in the generic function (instead of using a `typealias`) or disabling the `opaqueGenericParameters` rule (e.g. with `// swiftformat:disable:next opaqueGenericParameters`).\n\n* If compiling for macOS with Xcode 14.0 and configuring SwiftFormat with `--swift-version 5.7`, the `genericExtensions` rule may cause a build failure by updating extensions of the format `extension Collection where Element == Foo` to `extension Collection<Foo>`. This fails to compile for macOS in Xcode 14.0, because the macOS SDK in that version of Xcode [does not include](https://forums.swift.org/t/xcode-14-rc-cannot-specialize-protocol-type/60171) the Swift 5.7 standard library. Workarounds include using `--swift-version 5.6` instead, updating to Xcode 14.1+, or disabling the `genericExtensions` rule (e.g. with `// swiftformat:disable:next genericExtensions`).\n\n* The `propertyTypes` rule can cause a build failure in cases where there are multiple static overloads with the same name but different return types. As a workaround you can rename the overloads to no longer conflict, or exclude the property name with `--preserve-symbols propertyName,otherPropertyName,etc`.\n\n* The `propertyTypes` rule can cause a build failure in cases where the property's type is a protocol / existential like `let shapeStyle: ShapeStyle = .myShapeStyle`, and the value used on the right-hand side is defined in an extension like `extension ShapeStyle where Self == MyShapeStyle { static var myShapeStyle: MyShapeStyle { ... } }`. As a workaround you can use the existential `any` syntax (`let shapeStyle: any ShapeStyle = .myShapeStyle`), which the rule will preserve as-is, or exclude the type name and/or property name with `--preserve-symbols ShapeStyle,myShapeStyle,etc`.\n\n* The `propertyTypes` rule can cause a build failure in cases like `let foo = Foo.bar` where the value is a static member that doesn't return the same time. For example, `let foo: Foo = .bar` would be invalid if the `bar` property was defined as `static var bar: Bar`. As a workaround you can write the name of the type explicitly, like `let foo: Bar = Foo.bar`, or exclude the type name and/or property name with `--preserve-symbols Bar,bar,etc`.\n\n\nTip Jar\n-----------\n\nSwiftFormat is not a commercially-funded product, it's a labor of love given freely to the community. If you find it useful, please consider making a donation.\n\n[![Donate via PayPal](https://www.paypalobjects.com/en_GB/i/btn/btn_donate_LG.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=9ZGWNK5FEZFF6&source=url)\n\n\nCredits\n------------\n\n* [Cal Stephens](https://github.com/calda) - Numerous new formatting rules, options and bug fixes\n* [Tony Arnold](https://github.com/tonyarnold) - SwiftFormat for Xcode\n* [Vincent Bernier](https://github.com/vinceburn) - SwiftFormat for Xcode settings UI\n* [Vikram Kriplaney](https://github.com/markiv) - SwiftFormat for Xcode icon and search feature\n* [Hyperphonic](https://github.com/hyperphonic0) - Xcode 12 compatibility for SwiftFormat\n* [Maxime Marinel](https://github.com/bourvill) - Git pre-commit hook script\n* [Romain Pouclet](https://github.com/palleas) - Homebrew formula\n* [Aerobounce](https://github.com/aerobounce) - Homebrew cask and Sublime Text plugin\n* [Facundo Menzella](https://github.com/facumenzella) - Several new formatting rules and options\n* [Ali Akhtarzada](https://github.com/aliak00) - Several path-related CLI enhancements\n* [Yonas Kolb](https://github.com/yonaskolb) - Swift Package Manager integration\n* [Wolfgang Lutz](https://github.com/Lutzifer) - AppleScript integration instructions\n* [Bal√°zs Kilv√°dy](https://github.com/balitm) - Xcode lint warning integration\n* [Anthony Miller](https://github.com/AnthonyMDev) - Improvements to wrap/indent logic\n* [Shingo Takagi](https://github.com/zizi4n5) - Several brace-related bug fixes\n* [Benedek Kozma](https://github.com/cyberbeni) - Lint-only rules option\n* [Juri Pakaste](https://github.com/juri) - Filelist feature\n* [Jim Puls](https://github.com/puls) - Big Sur icon update\n* [Daniele Formichelli](https://github.com/danyf90) - JSON reporter\n* [Jonas Boberg](https://github.com/bobergj) - Github actions log reporter\n* [Mahdi Bchatnia](https://github.com/inket) - Linux build workflow\n* [Saleem Abdulrasool](https://github.com/compnerd) - Windows build workflow\n* [Arthur Semenyutin](https://github.com/vox-humana) - Docker image\n* [Marco Eidinger](https://github.com/MarcoEidinger) - Swift Package Manager plugin\n* [Hampus TaÃägerud](https://github.com/hampustagerud) - Git integration for fileHeader rule\n* [Nick Lockwood](https://github.com/nicklockwood) - Everything else\n\n([Full list of contributors](https://github.com/nicklockwood/SwiftFormat/graphs/contributors))\n",
      "stars_today": 3
    },
    {
      "id": 893309711,
      "name": "KitsuneMagisk",
      "full_name": "1q23lyc45/KitsuneMagisk",
      "description": "A fork of KitsuneMagisk. Thanks to the original author @HuskyDG.",
      "html_url": "https://github.com/1q23lyc45/KitsuneMagisk",
      "stars": 1620,
      "forks": 195,
      "language": "C++",
      "topics": [
        "android-root",
        "aosp",
        "kitsune",
        "magisk"
      ],
      "created_at": "2024-11-24T04:51:55Z",
      "updated_at": "2026-01-16T11:17:54Z",
      "pushed_at": "2025-08-24T16:14:49Z",
      "open_issues": 16,
      "owner": {
        "login": "1q23lyc45",
        "avatar_url": "https://avatars.githubusercontent.com/u/174172451?v=4"
      },
      "readme": "# Sunset Notice for KitsuneMagisk\n\nLast update: August 24th, 2025\n\n## TL;DR\n\nThis project is entering archival due to technical roadblocks beyond the current resources of its sole maintainer (me) and general lack of free time. No further commits, reviews, or releases are planned. The GitHub repository will be archived read-only within the next few days.\n\n## What does ‚Äúarchived‚Äù mean?\n\nThe repo will become read-only.\nAll issues and PRs will remain visible for historical purposes but will not be triaged.\nThe website, wiki, and downloads will stay up with no promise of future updates or security fixes.\n\n## License remains absolutely unchanged\n\nThe project continues to be licensed under the GNU General Public License v3.0-or-later (GPL-3.0-or-later).\nNothing in this notice constitutes a relicensing.\n\n## Important warnings about future variants\n\nThis project will **NOT** be re-released under any proprietary or closed-source license.\nI will **NOT** grant anyone permission to use any part of the code in a way that violates GPLv3-or-later.\nAny subsequent distribution showing up as a closed-source binary or obfuscated fork is **unauthorized** and considered a **counterfeit**.\n‚Äì Such builds may contain **trojans, spyware, adware, or other malicious software**.\n‚Äì **Use them at your own risk‚Äîwe strongly recommend you avoid them.**\n\n## Thank-you\n\nMany thanks to every contributor, translator, tester, and enthusiastic user who helped along the way. While the lights are dimming here, the code remains open. Fork freely under the terms of the GPL.\n\nSee you in other repos.\n",
      "stars_today": 3
    },
    {
      "id": 982577878,
      "name": "nav3-recipes",
      "full_name": "android/nav3-recipes",
      "description": "Implement common use cases with Jetpack Navigation 3",
      "html_url": "https://github.com/android/nav3-recipes",
      "stars": 1109,
      "forks": 118,
      "language": "Kotlin",
      "topics": [
        "android",
        "compose",
        "navigation"
      ],
      "created_at": "2025-05-13T05:23:51Z",
      "updated_at": "2026-01-16T23:09:38Z",
      "pushed_at": "2026-01-15T18:13:03Z",
      "open_issues": 54,
      "owner": {
        "login": "android",
        "avatar_url": "https://avatars.githubusercontent.com/u/32689599?v=4"
      },
      "readme": "# Navigation 3 - Code recipes\n[Jetpack Navigation 3](https://goo.gle/nav3) is a library for app navigation. This repository contains recipes for how to \nuse its APIs to implement common navigation use cases. Each recipe introduces a single concept. Instead\nof making existing recipes more complex, there should be a new recipe for that particular concept.\n\nEvery Navigation 3 release will be an opportunity for patterns you see in recipes to \"graduate\" and become\n(optional) helpers in the library itself. Then we'll update the recipe to use that prebuilt helper, thus\nensuring that the recipes continue to be a good way to approach these kinds of problems.\n\nRecipes on the `main` branch use the **latest** (which may be an alpha or snapshot) version of Nav3. For recipes that use **stable** versions, check the [releases page](https://github.com/android/nav3-recipes/releases).\n\n## Recipes\nThese are the recipes and what they demonstrate. \n\n### Basic API examples\n- **[Basic](app/src/main/java/com/example/nav3recipes/basic)**: Shows most basic API usage.\n- **[Saveable back stack](app/src/main/java/com/example/nav3recipes/basicsaveable)**: As above, with a persistent back stack.\n- **[Entry provider DSL](app/src/main/java/com/example/nav3recipes/basicdsl)**: As above, using the entryProvider DSL.\n\n### Deep links\nRead the [guide to deeplinking](docs/deeplink-guide.md). Upvote [this issue](https://issuetracker.google.com/470282247) if you would like an API for deeplinks.\n- **[Basic](app/src/main/java/com/example/nav3recipes/deeplink/basic)**: Shows how to parse a deep link URL from an Android Intent into a navigation key.\n- **[Advanced](app/src/main/java/com/example/nav3recipes/deeplink/advanced)**: Shows how to handle deep links with a synthetic back stack and correct \"Up\" navigation behavior.\n\n### Layouts using Scenes\n- **[List-Detail Scene](app/src/main/java/com/example/nav3recipes/scenes/listdetail)**: Shows how to create a custom, list-detail layout using a `Scene` and `SceneStrategy` (see video of UI behavior below).\n- **[Two pane Scene](app/src/main/java/com/example/nav3recipes/scenes/twopane)**: Shows how to create a custom, 2-pane layout.\n- **[BottomSheet](app/src/main/java/com/example/nav3recipes/bottomsheet)**: Shows how to create a BottomSheet destination.\n- **[Dialog](app/src/main/java/com/example/nav3recipes/dialog)**: Shows how to create a Dialog.\n\n### Material adaptive layouts\nExamples showing how to use the layouts provided by the [Compose Material3 Adaptive Navigation3 library](https://developer.android.com/jetpack/androidx/releases/compose-material3-adaptive#compose_material3_adaptive_navigation3_version_10_2)\n- **[List-Detail](app/src/main/java/com/example/nav3recipes/material/listdetail)**: Shows how to use a Material adaptive list-detail layout.\n- **[Supporting Pane](app/src/main/java/com/example/nav3recipes/material/supportingpane)**: Shows how to use a Material adaptive supporting pane layout.\n\nNote: If you find a bug or have a feature request for Material3 Adaptive Scenes [please file it here](https://issuetracker.google.com/issues/new?component=1467081). Don't file an issue on this repository.\n\n### Animations\n- **[Animations](app/src/main/java/com/example/nav3recipes/animations)**: Shows how to override the default animations for all destinations and a single destination.\n\n### Common use cases\n- **[Common navigation UI](app/src/main/java/com/example/nav3recipes/commonui)**: A common navigation toolbar where each item in the toolbar navigates to a top level destination.  \n- **[Multiple back stacks](app/src/main/java/com/example/nav3recipes/multiplestacks)**: Shows how to create multiple top level routes, each with its own back stack. Top level routes are displayed in a navigation bar allowing users to switch between them. State is retained for each top level route, and the navigation state persists config changes and process death.  \n- **[Conditional navigation](app/src/main/java/com/example/nav3recipes/conditional)**: Switch to a different navigation flow when a condition is met. For example, for authentication or first-time user onboarding.\n\n### Architecture\n- **[Hilt - Modularized navigation code](app/src/main/java/com/example/nav3recipes/modular/hilt)**: Demonstrates how to decouple navigation code into separate modules (uses Dagger/Hilt for DI). \n- **[Koin - Modularized navigation code](app/src/main/java/com/example/nav3recipes/modular/koin)**: Demonstrates how to decouple navigation code into separate modules (uses Koin for DI).\n\n### Passing navigation arguments to ViewModels\n- **[Basic ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/basic)**: Navigation arguments are passed to a ViewModel constructed using `viewModel()`\n- **[Hilt injected ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/hilt)**: Navigation arguments are passed to a ViewModel constructed using `hiltViewModel()`\n- **[Koin injected ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/koin)**: Navigation arguments are passed to a ViewModel constructed using `koinViewModel()`\n\n### Returning Results\n- **[Returning Results as Events](app/src/main/java/com/example/nav3recipes/results/event)**: Returning results as events to content in another NavEntry.\n- **[Returning Results as State](app/src/main/java/com/example/nav3recipes/results/state)**: Returning results as state stored in a CompositionLocal.\n\n### Future recipes\nThe most upvoted [recipe requests]([url](https://github.com/android/nav3-recipes/issues?q=is%3Aissue%20state%3Aopen%20label%3Arecipe-request)) will be considered for implementation. Don't see your recipe? [File a request for one here](https://github.com/android/nav3-recipes/issues/new?template=1-recipe-request.md)\n\n## Custom layout example\nThe following is a screen recording showing the navigation behavior of a [custom, list-detail Scene](app/src/main/java/com/example/nav3recipes/scenes/listdetail).\n\n![Custom layout example](/docs/images/ListDetailScene.gif)\n\n## Instructions\nClone this repository and open the root folder in [Android Studio](https://developer.android.com/studio). Each recipe is contained in its own package with its own `Activity`.\n\n## Found an issue?\nIf the issue is _directly related to this project_, as in, it's reproducible without modifying this project's source code, then please [file an issue on github](https://github.com/android/nav3-recipes/issues/new?template=2-bug-report.md). If you've found an issue with the Jetpack Navigation 3 library, please [file an issue on the issue tracker](https://issuetracker.google.com/issues/new?component=1750212&template=2102223).\n\n## Contributing\nWe'd love to accept your contributions. Please follow [these instructions](CONTRIBUTING.md).\n\n## Compose Multiplatform Recipes\nCMP recipes can be found [here](https://github.com/terrakok/nav3-recipes).\n\n## License\n```\nCopyright 2025 The Android Open Source Project\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    https://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n",
      "stars_today": 3
    },
    {
      "id": 22458259,
      "name": "Alamofire",
      "full_name": "Alamofire/Alamofire",
      "description": "Elegant HTTP Networking in Swift",
      "html_url": "https://github.com/Alamofire/Alamofire",
      "stars": 42299,
      "forks": 7669,
      "language": "Swift",
      "topics": [
        "alamofire",
        "carthage",
        "certificate-pinning",
        "cocoapods",
        "httpurlresponse",
        "networking",
        "parameter-encoding",
        "public-key-pinning",
        "request",
        "response",
        "swift",
        "swift-package-manager",
        "urlrequest",
        "urlsession",
        "xcode"
      ],
      "created_at": "2014-07-31T05:56:19Z",
      "updated_at": "2026-01-16T21:52:13Z",
      "pushed_at": "2025-12-20T07:34:46Z",
      "open_issues": 39,
      "owner": {
        "login": "Alamofire",
        "avatar_url": "https://avatars.githubusercontent.com/u/7774181?v=4"
      },
      "readme": "![Alamofire: Elegant Networking in Swift](https://raw.githubusercontent.com/Alamofire/Alamofire/master/Resources/AlamofireLogo.png)\n\n[![Swift](https://img.shields.io/badge/Swift-6.0_6.1_6.2-orange?style=flat-square)](https://img.shields.io/badge/Swift-6.0_6.1_6.2-Orange?style=flat-square)\n[![Platforms](https://img.shields.io/badge/Platforms-macOS_iOS_tvOS_watchOS_visionOS_Linux_Windows_Android-yellowgreen?style=flat-square)](https://img.shields.io/badge/Platforms-macOS_iOS_tvOS_watchOS_vision_OS_Linux_Windows_Android-Green?style=flat-square)\n[![CocoaPods Compatible](https://img.shields.io/cocoapods/v/Alamofire.svg?style=flat-square)](https://img.shields.io/cocoapods/v/Alamofire.svg)\n[![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat-square)](https://github.com/Carthage/Carthage)\n[![Swift Package Manager](https://img.shields.io/badge/Swift_Package_Manager-compatible-orange?style=flat-square)](https://img.shields.io/badge/Swift_Package_Manager-compatible-orange?style=flat-square)\n[![Swift Forums](https://img.shields.io/badge/Swift_Forums-Alamofire-orange?style=flat-square)](https://forums.swift.org/c/related-projects/alamofire/37)\n\nAlamofire is an HTTP networking library written in Swift.\n\n- [Features](#features)\n- [Component Libraries](#component-libraries)\n- [Requirements](#requirements)\n- [Migration Guides](#migration-guides)\n- [Communication](#communication)\n- [Installation](#installation)\n- [Contributing](#contributing)\n- [Usage](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#using-alamofire)\n  - [**Introduction -**](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#introduction) [Making Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#making-requests), [Response Handling](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-handling), [Response Validation](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-validation), [Response Caching](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-caching)\n  - **HTTP -** [HTTP Methods](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#http-methods), [Parameters and Parameter Encoder](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md##request-parameters-and-parameter-encoders), [HTTP Headers](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#http-headers), [Authentication](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#authentication)\n  - **Large Data -** [Downloading Data to a File](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#downloading-data-to-a-file), [Uploading Data to a Server](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#uploading-data-to-a-server)\n  - **Tools -** [Statistical Metrics](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#statistical-metrics), [cURL Command Output](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#curl-command-output)\n- [Advanced Usage](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md)\n  - **URL Session -** [Session Manager](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#session), [Session Delegate](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#sessiondelegate), [Request](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#request)\n  - **Routing -** [Routing Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#routing-requests), [Adapting and Retrying Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#adapting-and-retrying-requests-with-requestinterceptor)\n  - **Model Objects -** [Custom Response Handlers](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#customizing-response-handlers)\n  - **Advanced Concurrency -** [Swift Concurrency](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#using-alamofire-with-swift-concurrency) and [Combine](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#using-alamofire-with-combine)\n  - **Connection -** [Security](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#security), [Network Reachability](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#network-reachability)\n- [Open Radars](#open-radars)\n- [FAQ](#faq)\n- [Credits](#credits)\n- [Donations](#donations)\n- [License](#license)\n\n## Features\n\n- [x] Chainable Request / Response Methods\n- [x] Swift Concurrency Support Back to iOS 13, macOS 10.15, tvOS 13, and watchOS 6.\n- [x] Combine Support\n- [x] URL / JSON Parameter Encoding\n- [x] Upload File / Data / Stream / MultipartFormData\n- [x] Download File using Request or Resume Data\n- [x] Authentication with `URLCredential`\n- [x] HTTP Response Validation\n- [x] Upload and Download Progress Closures with Progress\n- [x] cURL Command Output\n- [x] Dynamically Adapt and Retry Requests\n- [x] TLS Certificate and Public Key Pinning\n- [x] Network Reachability\n- [x] Comprehensive Unit and Integration Test Coverage\n- [x] [Complete Documentation](https://alamofire.github.io/Alamofire)\n\n## Write Requests Fast!\n\nAlamofire's compact syntax and extensive feature set allow requests with powerful features like automatic retry to be written in just a few lines of code.\n\n```swift\n// Automatic String to URL conversion, Swift concurrency support, and automatic retry.\nlet response = await AF.request(\"https://httpbin.org/get\", interceptor: .retryPolicy)\n                       // Automatic HTTP Basic Auth.\n                       .authenticate(username: \"user\", password: \"pass\")\n                       // Caching customization.\n                       .cacheResponse(using: .cache)\n                       // Redirect customization.\n                       .redirect(using: .follow)\n                       // Validate response code and Content-Type.\n                       .validate()\n                       // Produce a cURL command for the request.\n                       .cURLDescription { description in\n                         print(description)\n                       }\n                       // Automatic Decodable support with background parsing.\n                       .serializingDecodable(DecodableType.self)\n                       // Await the full response with metrics and a parsed body.\n                       .response\n// Detailed response description for easy debugging.\ndebugPrint(response)\n```\n\n## Component Libraries\n\nIn order to keep Alamofire focused specifically on core networking implementations, additional component libraries have been created by the [Alamofire Software Foundation](https://github.com/Alamofire/Foundation) to bring additional functionality to the Alamofire ecosystem.\n\n- [AlamofireImage](https://github.com/Alamofire/AlamofireImage) - An image library including image response serializers, `UIImage` and `UIImageView` extensions, custom image filters, an auto-purging in-memory cache, and a priority-based image downloading system.\n- [AlamofireNetworkActivityIndicator](https://github.com/Alamofire/AlamofireNetworkActivityIndicator) - Controls the visibility of the network activity indicator on iOS using Alamofire. It contains configurable delay timers to help mitigate flicker and can support `URLSession` instances not managed by Alamofire.\n\n## Requirements\n\n| Platform                                             | Minimum Swift Version | Installation                                                                                                         | Status                   |\n| ---------------------------------------------------- | --------------------- | -------------------------------------------------------------------------------------------------------------------- | ------------------------ |\n| iOS 10.0+ / macOS 10.12+ / tvOS 10.0+ / watchOS 3.0+ | 6.0 / Xcode 16.0      | [CocoaPods](#cocoapods), [Carthage](#carthage), [Swift Package Manager](#swift-package-manager), [Manual](#manually) | Fully Tested             |\n| Linux                                                | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n| Windows                                              | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n| Android                                              | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n\n#### Known Issues on Linux and Windows\n\nAlamofire builds on Linux, Windows, and Android but there are missing features and many issues in the underlying `swift-corelibs-foundation` that prevent full functionality and may cause crashes. These include:\n\n- `ServerTrustManager` and associated certificate functionality is unavailable, so there is no certificate pinning and no client certificate support.\n- Various methods of HTTP authentication may crash, including HTTP Basic and HTTP Digest. Crashes may occur if responses contain server challenges.\n- Cache control through `CachedResponseHandler` and associated APIs is unavailable, as the underlying delegate methods aren't called.\n- `URLSessionTaskMetrics` are never gathered.\n- `WebSocketRequest` is not available.\n\nDue to these issues, Alamofire is unsupported on Linux, Windows, and Android. Please report any crashes to the [Swift bug reporter](https://bugs.swift.org).\n\n## Migration Guides\n\n- [Alamofire 5.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%205.0%20Migration%20Guide.md)\n- [Alamofire 4.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%204.0%20Migration%20Guide.md)\n- [Alamofire 3.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%203.0%20Migration%20Guide.md)\n- [Alamofire 2.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%202.0%20Migration%20Guide.md)\n\n## Communication\n\n- If you **need help with making network requests** using Alamofire, use [Stack Overflow](https://stackoverflow.com/questions/tagged/alamofire) and tag `alamofire`.\n- If you need to **find or understand an API**, check [our documentation](http://alamofire.github.io/Alamofire/) or [Apple's documentation for `URLSession`](https://developer.apple.com/documentation/foundation/url_loading_system), on top of which Alamofire is built.\n- If you need **help with an Alamofire feature**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you'd like to **discuss Alamofire best practices**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you'd like to **discuss a feature request**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you **found a bug**, open an issue here on GitHub and follow the guide. The more detail the better!\n\n## Installation\n\n### Swift Package Manager\n\nThe [Swift Package Manager](https://swift.org/package-manager/) is a tool for automating the distribution of Swift code and is integrated into the `swift` compiler.\n\nOnce you have your Swift package set up, adding Alamofire as a dependency is as easy as adding it to the `dependencies` value of your `Package.swift` or the Package list in Xcode.\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/Alamofire/Alamofire.git\", .upToNextMajor(from: \"5.11.0\"))\n]\n```\n\nNormally you'll want to depend on the `Alamofire` target:\n\n```swift\n.product(name: \"Alamofire\", package: \"Alamofire\")\n```\n\nBut if you want to force Alamofire to be dynamically linked (do not do this unless you're sure you need it), you can depend on the `AlamofireDynamic` target:\n\n```swift\n.product(name: \"AlamofireDynamic\", package: \"Alamofire\")\n```\n\n### CocoaPods\n\n[CocoaPods](https://cocoapods.org) is a dependency manager for Cocoa projects. For usage and installation instructions, visit their website. To integrate Alamofire into your Xcode project using CocoaPods, specify it in your `Podfile`:\n\n```ruby\npod 'Alamofire'\n```\n\n### Carthage\n\n[Carthage](https://github.com/Carthage/Carthage) is a decentralized dependency manager that builds your dependencies and provides you with binary frameworks. To integrate Alamofire into your Xcode project using Carthage, specify it in your `Cartfile`:\n\n```ogdl\ngithub \"Alamofire/Alamofire\"\n```\n\n### Manually\n\nIf you prefer not to use any of the aforementioned dependency managers, you can integrate Alamofire into your project manually.\n\n#### Embedded Framework\n\n- Open up Terminal, `cd` into your top-level project directory, and run the following command \"if\" your project is not initialized as a git repository:\n\n  ```bash\n  $ git init\n  ```\n\n- Add Alamofire as a git [submodule](https://git-scm.com/docs/git-submodule) by running the following command:\n\n  ```bash\n  $ git submodule add https://github.com/Alamofire/Alamofire.git\n  ```\n\n- Open the new `Alamofire` folder, and drag the `Alamofire.xcodeproj` into the Project Navigator of your application's Xcode project.\n\n  > It should appear nested underneath your application's blue project icon. Whether it is above or below all the other Xcode groups does not matter.\n\n- Select the `Alamofire.xcodeproj` in the Project Navigator and verify the deployment target matches that of your application target.\n- Next, select your application project in the Project Navigator (blue project icon) to navigate to the target configuration window and select the application target under the \"Targets\" heading in the sidebar.\n- In the tab bar at the top of that window, open the \"General\" panel.\n- Click on the `+` button under the \"Embedded Binaries\" section.\n- You will see two different `Alamofire.xcodeproj` folders each with two different versions of the `Alamofire.framework` nested inside a `Products` folder.\n\n  > It does not matter which `Products` folder you choose from, but it does matter whether you choose the top or bottom `Alamofire.framework`.\n\n- Select the top `Alamofire.framework` for iOS and the bottom one for macOS.\n\n  > You can verify which one you selected by inspecting the build log for your project. The build target for `Alamofire` will be listed as `Alamofire iOS`, `Alamofire macOS`, `Alamofire tvOS`, or `Alamofire watchOS`.\n\n- And that's it!\n\n  > The `Alamofire.framework` is automagically added as a target dependency, linked framework and embedded framework in a copy files build phase which is all you need to build on the simulator and a device.\n\n## Contributing\n\nBefore contributing to Alamofire, please read the instructions detailed in our [contribution guide](https://github.com/Alamofire/Alamofire/blob/master/CONTRIBUTING.md).\n\n## Open Radars\n\nThe following radars have some effect on the current implementation of Alamofire.\n\n- [`rdar://21349340`](http://www.openradar.me/radar?id=5517037090635776) - Compiler throwing warning due to toll-free bridging issue in the test case\n- `rdar://26870455` - Background URL Session Configurations do not work in the simulator\n- `rdar://26849668` - Some URLProtocol APIs do not properly handle `URLRequest`\n\n## Resolved Radars\n\nThe following radars have been resolved over time after being filed against the Alamofire project.\n\n- [`rdar://26761490`](http://www.openradar.me/radar?id=5010235949318144) - Swift string interpolation causing memory leak with common usage.\n  - (Resolved): 9/1/17 in Xcode 9 beta 6.\n- [`rdar://36082113`](http://openradar.appspot.com/radar?id=4942308441063424) - `URLSessionTaskMetrics` failing to link on watchOS 3.0+\n  - (Resolved): Just add `CFNetwork` to your linked frameworks.\n- `FB7624529` - `urlSession(_:task:didFinishCollecting:)` never called on watchOS\n  - (Resolved): Metrics now collected on watchOS 7+.\n\n## FAQ\n\n### What's the origin of the name Alamofire?\n\nAlamofire is named after the [Alamo Fire flower](https://aggie-horticulture.tamu.edu/wildseed/alamofire.html), a hybrid variant of the Bluebonnet, the official state flower of Texas.\n\n## Credits\n\nAlamofire is owned and maintained by the [Alamofire Software Foundation](http://alamofire.org). You can follow them on Twitter at [@AlamofireSF](https://twitter.com/AlamofireSF) for project updates and releases.\n\n### Security Disclosure\n\nIf you believe you have identified a security vulnerability with Alamofire, you should report it as soon as possible via email to security@alamofire.org. Please do not post it to a public issue tracker.\n\n## Sponsorship\n\nThe [ASF](https://github.com/Alamofire/Foundation#members) is looking to raise money to officially stay registered as a federal non-profit organization.\nRegistering will allow Foundation members to gain some legal protections and also allow us to put donations to use, tax-free.\nSponsoring the ASF will enable us to:\n\n- Pay our yearly legal fees to keep the non-profit in good status\n- Pay for our mail servers to help us stay on top of all questions and security issues\n- Potentially fund test servers to make it easier for us to test the edge cases\n- Potentially fund developers to work on one of our projects full-time\n\nThe community adoption of the ASF libraries has been amazing.\nWe are greatly humbled by your enthusiasm around the projects and want to continue to do everything we can to move the needle forward.\nWith your continued support, the ASF will be able to improve its reach and also provide better legal safety for the core members.\nIf you use any of our libraries for work, see if your employers would be interested in donating.\nAny amount you can donate, whether once or monthly, to help us reach our goal would be greatly appreciated.\n\n[Sponsor Alamofire](https://github.com/sponsors/Alamofire)\n\n## Supporters\n\n[MacStadium](https://macstadium.com) provides Alamofire with a free, hosted Mac mini.\n\n![Powered by MacStadium](https://raw.githubusercontent.com/Alamofire/Alamofire/master/Resources/MacStadiumLogo.png)\n\n## License\n\nAlamofire is released under the MIT license. [See LICENSE](https://github.com/Alamofire/Alamofire/blob/master/LICENSE) for details.\n",
      "stars_today": 2
    },
    {
      "id": 53370988,
      "name": "lighthouse",
      "full_name": "GoogleChrome/lighthouse",
      "description": "Automated auditing, performance metrics, and best practices for the web.",
      "html_url": "https://github.com/GoogleChrome/lighthouse",
      "stars": 29725,
      "forks": 9635,
      "language": "JavaScript",
      "topics": [
        "audit",
        "best-practices",
        "chrome-devtools",
        "developer-tools",
        "performance-analysis",
        "performance-metrics",
        "pwa",
        "web"
      ],
      "created_at": "2016-03-08T01:03:11Z",
      "updated_at": "2026-01-16T23:30:54Z",
      "pushed_at": "2026-01-16T17:34:56Z",
      "open_issues": 490,
      "owner": {
        "login": "GoogleChrome",
        "avatar_url": "https://avatars.githubusercontent.com/u/1778935?v=4"
      },
      "readme": "# Lighthouse  [![GitHub Actions Status Badge](https://github.com/GoogleChrome/lighthouse/workflows/CI/badge.svg)](https://github.com/GoogleChrome/lighthouse/actions/workflows/ci.yml) [![GitHub Actions Status Badge](https://github.com/GoogleChrome/lighthouse/workflows/unit/badge.svg)](https://github.com/GoogleChrome/lighthouse/actions/workflows/unit.yml) [![GitHub Actions Status Badge](https://github.com/GoogleChrome/lighthouse/workflows/smoke/badge.svg)](https://github.com/GoogleChrome/lighthouse/actions/workflows/smoke.yml) [![Coverage Status](https://codecov.io/gh/GoogleChrome/lighthouse/branch/main/graph/badge.svg)](https://codecov.io/gh/GoogleChrome/lighthouse) [![Build tracker for Lighthouse](https://img.shields.io/badge/buildtracker-ok-blue)](https://lh-build-tracker.herokuapp.com/) [![NPM lighthouse package](https://img.shields.io/npm/v/lighthouse.svg)](https://npmjs.org/package/lighthouse)\n\n> Lighthouse analyzes web apps and web pages, collecting modern performance metrics and insights on developer best practices.\n\n- Using Lighthouse\n  - [Using Lighthouse in Chrome DevTools](#using-lighthouse-in-chrome-devtools)\n  - [Using the Chrome extension](#using-the-chrome-extension)\n  - [Using the Node CLI](#using-the-node-cli)\n    * [CLI options](#cli-options)\n  - [Using the Node module](#using-the-node-module)\n  - [Viewing a report](#viewing-a-report)\n    * [Online Viewer](#online-viewer)\n  - [Docs & Recipes](#docs--recipes)\n  - [Developing Lighthouse](#develop)\n    * [Setup](#setup)\n    * [Run](#run)\n    * [Tests](#tests)\n    * [Docs](#docs)\n- Associated Products and Projects\n  - [Lighthouse Integrations in Web Perf services](#lighthouse-integrations-in-web-perf-services)\n  - [Lighthouse Integrations in non-Web Perf services](#lighthouse-integrations-in-non-web-perf-services)\n  - [Plugins](#plugins)\n  - [Related projects](#related-projects)\n- [FAQ](#faq)\n  * [How does Lighthouse work?](#how-does-lighthouse-work)\n  * [Can I configure the lighthouse run?](#can-i-configure-the-lighthouse-run)\n  * [How does Lighthouse use network throttling, and how can I make it better?](#how-does-lighthouse-use-network-throttling-and-how-can-i-make-it-better)\n  * [Are results sent to a remote server?](#are-results-sent-to-a-remote-server)\n  * [How do I get localized Lighthouse results?](#how-do-i-get-localized-lighthouse-results-via-the-cli)\n  * [How do I author custom audits to extend Lighthouse?](#how-do-i-author-custom-audits-to-extend-lighthouse)\n  * [How do I contribute?](#how-do-i-contribute)\n\n## Using Lighthouse in Chrome DevTools\n\nLighthouse is integrated directly into the Chrome DevTools, under the \"Lighthouse\" panel.\n\n**Installation**: install [Chrome](https://www.google.com/chrome/browser).\n\n**Run it**: open Chrome DevTools, select the Lighthouse panel, and hit \"Generate report\".\n\n<img width=\"550\" alt=\"Lighthouse integration in Chrome DevTools.\" src=\"https://user-images.githubusercontent.com/2766281/204185043-9c49abe5-baee-4b26-b5ce-ece410661213.png\">\n\n## Using the Chrome extension\n\nThe Chrome extension was available prior to Lighthouse being available in Chrome Developer Tools, and offers similar functionality.\n\n**Installation**: [install the extension](https://chrome.google.com/webstore/detail/lighthouse/blipmdconlkpinefehnmjammfjpmpbjk) from the Chrome Web Store.\n\n**Run it**: follow the [extension quick-start guide](https://developers.google.com/web/tools/lighthouse/#extension).\n\n## Using the Node CLI\n\nThe Node CLI provides the most flexibility in how Lighthouse runs can be configured and reported. Users who want more advanced usage, or want to run Lighthouse in an automated fashion should use the Node CLI.\n\n> [!NOTE]\n> Lighthouse requires Node 22 (LTS) or later.\n\n**Installation**:\n\n```sh\nnpm install -g lighthouse\n# or use yarn:\n# yarn global add lighthouse\n```\n\n**Run it**: `lighthouse https://airhorner.com/`\n\nBy default, Lighthouse writes the report to an HTML file. You can control the output format by passing flags.\n\n### CLI options\n\n<!-- To update the help output:\n  node cli --help | pbcopy\n-->\n\n```\n$ lighthouse --help\n\nlighthouse <url> <options>\n\nLogging:\n  --verbose  Displays verbose logging  [boolean] [default: false]\n  --quiet    Displays no progress, debug logs, or errors  [boolean] [default: false]\n\nConfiguration:\n  --save-assets                  Save the trace contents & devtools logs to disk  [boolean] [default: false]\n  --list-all-audits              Prints a list of all available audits and exits  [boolean] [default: false]\n  --list-trace-categories        Prints a list of all required trace categories and exits  [boolean] [default: false]\n  --additional-trace-categories  Additional categories to capture with the trace (comma-delimited).  [string]\n  --config-path                  The path to the config JSON.\n                                 An example config file: core/config/lr-desktop-config.js  [string]\n  --preset                       Use a built-in configuration.\n                                 WARNING: If the --config-path flag is provided, this preset will be ignored.  [string] [choices: \"perf\", \"experimental\", \"desktop\"]\n  --chrome-flags                 Custom flags to pass to Chrome (space-delimited). For a full list of flags, see https://bit.ly/chrome-flags\n                                 Additionally, use the CHROME_PATH environment variable to use a specific Chrome binary. Requires Chromium version 66.0 or later. If omitted, any detected Chrome Canary or Chrome stable will be used.  [string] [default: \"\"]\n  --port                         The port to use for the debugging protocol. Use 0 for a random port  [number] [default: 0]\n  --hostname                     The hostname to use for the debugging protocol.  [string] [default: \"localhost\"]\n  --form-factor                  Determines how performance metrics are scored and if mobile-only audits are skipped. For desktop, use --preset=desktop instead.  [string] [choices: \"mobile\", \"desktop\"]\n  --screenEmulation              Sets screen emulation parameters. See also --preset. Use --screenEmulation.disabled to disable. Otherwise set these 4 parameters individually: --screenEmulation.mobile --screenEmulation.width=360 --screenEmulation.height=640 --screenEmulation.deviceScaleFactor=2\n  --emulatedUserAgent            Sets useragent emulation  [string]\n  --max-wait-for-load            The timeout (in milliseconds) to wait before the page is considered done loading and the run should continue. WARNING: Very high values can lead to large traces and instability  [number]\n  --enable-error-reporting       Enables error reporting, overriding any saved preference. --no-enable-error-reporting will do the opposite. More: https://github.com/GoogleChrome/lighthouse/blob/main/docs/error-reporting.md  [boolean]\n  --gather-mode, -G              Collect artifacts from a connected browser and save to disk. (Artifacts folder path may optionally be provided). If audit-mode is not also enabled, the run will quit early.\n  --audit-mode, -A               Process saved artifacts from disk. (Artifacts folder path may be provided, otherwise defaults to ./latest-run/)\n  --only-audits                  Only run the specified audits  [array]\n  --only-categories              Only run the specified categories. Available categories: accessibility, best-practices, performance, seo  [array]\n  --skip-audits                  Run everything except these audits  [array]\n  --disable-full-page-screenshot Disables collection of the full page screenshot, which can be quite large  [boolean]\n\nOutput:\n  --output       Reporter for the results, supports multiple values. choices: \"json\", \"html\", \"csv\"  [array] [default: [\"html\"]]\n  --output-path  The file path to output the results. Use 'stdout' to write to stdout.\n                   If using JSON output, default is stdout.\n                   If using HTML or CSV output, default is a file in the working directory with a name based on the test URL and date.\n                   If using multiple outputs, --output-path is appended with the standard extension for each output type. \"reports/my-run\" -> \"reports/my-run.report.html\", \"reports/my-run.report.json\", etc.\n                   Example: --output-path=./lighthouse-results.html  [string]\n  --view         Open HTML report in your browser  [boolean] [default: false]\n\nOptions:\n  --version                            Show version number  [boolean]\n  --help                               Show help  [boolean]\n  --cli-flags-path                     The path to a JSON file that contains the desired CLI flags to apply. Flags specified at the command line will still override the file-based ones.\n  --locale                             The locale/language the report should be formatted in\n  --blocked-url-patterns               Block any network requests to the specified URL patterns  [array]\n  --disable-storage-reset              Disable clearing the browser cache and other storage APIs before a run  [boolean]\n  --throttling-method                  Controls throttling method  [string] [choices: \"devtools\", \"provided\", \"simulate\"]\n  --throttling\n  --throttling.rttMs                   Controls simulated network RTT (TCP layer)\n  --throttling.throughputKbps          Controls simulated network download throughput\n  --throttling.requestLatencyMs        Controls emulated network RTT (HTTP layer)\n  --throttling.downloadThroughputKbps  Controls emulated network download throughput\n  --throttling.uploadThroughputKbps    Controls emulated network upload throughput\n  --throttling.cpuSlowdownMultiplier   Controls simulated + emulated CPU throttling\n  --extra-headers                      Set extra HTTP Headers to pass with request\n  --precomputed-lantern-data-path      Path to the file where lantern simulation data should be read from, overwriting the lantern observed estimates for RTT and server latency.  [string]\n  --lantern-data-output-path           Path to the file where lantern simulation data should be written to, can be used in a future run with the `precomputed-lantern-data-path` flag.  [string]\n  --plugins                            Run the specified plugins  [array]\n  --channel  [string] [default: \"cli\"]\n  --chrome-ignore-default-flags  [boolean] [default: false]\n\nExamples:\n  lighthouse <url> --view                                                                          Opens the HTML report in a browser after the run completes\n  lighthouse <url> --config-path=./myconfig.js                                                     Runs Lighthouse with your own configuration: custom audits, report generation, etc.\n  lighthouse <url> --output=json --output-path=./report.json --save-assets                         Save trace, screenshots, and named JSON report.\n  lighthouse <url> --screenEmulation.disabled --throttling-method=provided --no-emulatedUserAgent  Disable device emulation and all throttling\n  lighthouse <url> --chrome-flags=\"--window-size=412,660\"                                          Launch Chrome with a specific window size\n  lighthouse <url> --quiet --chrome-flags=\"--headless\"                                             Launch Headless Chrome, turn off logging\n  lighthouse <url> --extra-headers \"{\\\"Cookie\\\":\\\"monster=blue\\\", \\\"x-men\\\":\\\"wolverine\\\"}\"        Stringify'd JSON HTTP Header key/value pairs to send in requests\n  lighthouse <url> --extra-headers=./path/to/file.json                                             Path to JSON file of HTTP Header key/value pairs to send in requests\n  lighthouse <url> --only-categories=performance,seo                                               Only run the specified categories. Available categories: accessibility, best-practices, performance, seo\n\nFor more information on Lighthouse, see https://developers.google.com/web/tools/lighthouse/.\n```\n\n##### Output Examples\n\n```sh\nlighthouse\n# saves `./<HOST>_<DATE>.report.html`\n\nlighthouse --output json\n# json output sent to stdout\n\nlighthouse --output html --output-path ./report.html\n# saves `./report.html`\n\n# NOTE: specifying an output path with multiple formats ignores your specified extension for *ALL* formats\nlighthouse --output json --output html --output-path ./myfile.json\n# saves `./myfile.report.json` and `./myfile.report.html`\n\nlighthouse --output json --output html\n# saves `./<HOST>_<DATE>.report.json` and `./<HOST>_<DATE>.report.html`\n\nlighthouse --output-path=~/mydir/foo.out --save-assets\n# saves `~/mydir/foo.report.html`\n# saves `~/mydir/foo-0.trace.json` and `~/mydir/foo-0.devtoolslog.json`\n\nlighthouse --output-path=./report.json --output json\n# saves `./report.json`\n```\n\n##### Lifecycle Examples\nYou can run a subset of Lighthouse's lifecycle if desired via the `--gather-mode` (`-G`) and  `--audit-mode` (`-A`) CLI flags.\n\n```sh\nlighthouse http://example.com -G\n# launches browser, collects artifacts, saves them to disk (in `./latest-run/`) and quits\n\nlighthouse http://example.com -A\n# skips browser interaction, loads artifacts from disk (in `./latest-run/`), runs audits on them, generates report\n\nlighthouse http://example.com -GA\n# Normal gather + audit run, but also saves collected artifacts to disk for subsequent -A runs.\n\n\n# You can optionally provide a custom folder destination to -G/-A/-GA. Without a value, the default will be `$PWD/latest-run`.\nlighthouse -GA=./gmailartifacts https://gmail.com\n```\n\n\n#### Notes on Error Reporting\n\nThe first time you run the CLI you will be prompted with a message asking you if Lighthouse can anonymously report runtime exceptions. The Lighthouse team uses this information to detect new bugs and avoid regressions. Opting out will not affect your ability to use Lighthouse in any way. [Learn more](https://github.com/GoogleChrome/lighthouse/blob/main/docs/error-reporting.md).\n\n## Using the Node module\nYou can also use Lighthouse programmatically with the Node module.\n\nRead [Using Lighthouse programmatically](./docs/readme.md#using-programmatically) for help getting started.\\\nRead [Lighthouse Configuration](./docs/configuration.md) to learn more about the configuration options available.\n\n## Viewing a report\n\nLighthouse can produce a report as JSON or HTML.\n\nHTML report:\n\n<img src=\"https://raw.githubusercontent.com/GoogleChrome/lighthouse/443ff2c8a297dfd2297dfaca86c4966a87c8574a/assets/example_audit.png\" alt=\"Lighthouse example audit\" width=\"500px\">\n\n### Online Viewer\n\nRunning Lighthouse with the `--output=json` flag generates a JSON dump of the run.\nYou can view this report online by visiting <https://googlechrome.github.io/lighthouse/viewer/>\nand dragging the file onto the app. You can also use the \"Export\" button from the\ntop of any Lighthouse HTML report and open the report in the\n[Lighthouse Viewer](https://googlechrome.github.io/lighthouse/viewer/).\n\nIn the Viewer, reports can be shared by clicking the share icon in the top\nright corner and signing in to GitHub.\n\n> [!NOTE]\n>  shared reports are stashed as a secret Gist in GitHub, under your account.\n\n## Docs & Recipes\n\nUseful documentation, examples, and recipes to get you started.\n\n**Docs**\n\n- [Dealing with variance](./docs/variability.md)\n- [Using Lighthouse programmatically](./docs/readme.md#using-programmatically)\n- [Testing a site with authentication](./docs/authenticated-pages.md)\n- [Developing Plugins](./docs/plugins.md)\n- [Making a New Audit](./docs/new-audits.md)\n- [Testing on a mobile device](./docs/readme.md#testing-on-a-mobile-device)\n- [Lighthouse Architecture](./docs/architecture.md)\n\n**Recipes**\n\n- [Plugin](./docs/recipes/lighthouse-plugin-example) - example Lighthouse plugin\n- [Custom Audit example](./docs/recipes/custom-audit) - extend Lighthouse, run your own audits\n\n**Videos**\n\nThe session from Google I/O 2018 covers the new performance engine, upcoming Lighthouse REST API, and using the Chrome UX report to evaluate real-user data.\n\n[![Watch the Lighthouse @ Google I/O 2018 session.](https://img.youtube.com/vi/UvK9zAsSM8Q/0.jpg)](https://www.youtube.com/watch?v=UvK9zAsSM8Q)\n\nThe session from Google I/O 2017 covers architecture, writing custom audits,\nGitHub/Travis/CI integration, headless Chrome, and more:\n\n[![Watch the Lighthouse @ Google I/O 2017 session.](https://img.youtube.com/vi/NoRYn6gOtVo/0.jpg)](https://www.youtube.com/watch?v=NoRYn6gOtVo)\n\n_Click the image to watch the video on YouTube._\n\n## Develop\n\nRead on for the basics of hacking on Lighthouse. Also, see [Contributing](./CONTRIBUTING.md)\nfor detailed information.\n\n### Setup\n\n```sh\n# yarn should be installed first\n\ngit clone https://github.com/GoogleChrome/lighthouse\n\ncd lighthouse\nyarn\nyarn build-all\n```\n\n### Run\n\n```sh\nnode cli http://example.com\n# append --chrome-flags=\"--no-sandbox --headless --disable-gpu\" if you run into problems connecting to Chrome\n```\n\n> **Getting started tip**: `node --inspect-brk cli http://example.com` to open up Chrome DevTools and step\nthrough the entire app. See [Debugging Node.js with Chrome\nDevTools](https://medium.com/@paul_irish/debugging-node-js-nightlies-with-chrome-devtools-7c4a1b95ae27#.59rma3ukm)\nfor more info.\n\n### Tests\n\n```sh\n# lint and test all files\nyarn test\n\n# run all unit tests\nyarn unit\n\n# run a given unit test (e.g. core/test/audits/byte-efficiency/uses-long-cache-ttl-test.js)\nyarn mocha uses-long-cache-ttl\n\n# watch for file changes and run tests\n#   Requires http://entrproject.org : brew install entr\nyarn watch\n\n## run linting, unit, and smoke tests separately\nyarn lint\nyarn unit\nyarn smoke\n\n## run tsc compiler\nyarn type-check\n```\n\n### Docs\n\nSome of our docs have tests that run only in CI by default. To modify our documentation, you'll need to run `yarn build-pack && yarn test-docs` locally to make sure they pass.\n\n**Additional Dependencies**\n- `brew install jq`\n\n## Lighthouse Integrations in Web Perf services\n\nThis section details services that have integrated Lighthouse data. If you're working on a cool project integrating Lighthouse and would like to be featured here, file an issue to this repo or tweet at us [@_____lighthouse](https://twitter.com/____lighthouse)!\n\n* **[Web Page Test](https://www.webpagetest.org)** ‚Äî An [open source](https://github.com/WPO-Foundation/webpagetest) tool for measuring and analyzing the performance of web pages on real devices. Users can choose to produce a Lighthouse report alongside the analysis of WebPageTest results.\n\n* **[HTTPArchive](http://httparchive.org/)** - HTTPArchive tracks how the web is built by crawling 500k pages with Web Page Test, including Lighthouse results, and stores the information in BigQuery where it is [publicly available](https://discuss.httparchive.org/t/quickstart-guide-to-exploring-the-http-archive/682).\n\n* **[Calibre](https://calibreapp.com)** - Calibre is a comprehensive performance monitoring platform running on Lighthouse. See the performance impact of your work before it hits production with GitHub Pull Request Reviews. Track the impact of Third Party scripts. Automate your performance system with a developer-first Node.js API. Try Calibre with a free 15-day trial.\n\n* **[DebugBear](https://www.debugbear.com/)** - DebugBear is a website monitoring tool based on Lighthouse. See how your scores and metrics changed over time, with a focus on understanding what caused each change. DebugBear is a paid product with a free 30-day trial.\n\n* **[Treo](https://treo.sh)** - Treo is Lighthouse as a Service. It provides regression testing, geographical regions, custom networks, and integrations with GitHub & Slack. Treo is a paid product with plans for solo-developers and teams.\n\n* **[PageVitals](https://pagevitals.com)** - PageVitals combines Lighthouse, CrUX and field testing to monitor the performance of websites. See how your website performs over time and get alerted if it gets too slow. Drill down and find the real cause of any performance issue. PageVitals is a paid product with a free 14-day trial.\n\n* **[Screpy](https://screpy.com)** - Screpy is a web analysis tool that can analyze all pages of your websites in one dashboard and monitor them with your team. It's powered by Lighthouse and it also includes some different analysis tools (SERP, W3C, Uptime, etc). Screpy has free and paid plans.\n\n* **[Siteimprove Performance](https://siteimprove.com/en/performance/)** ‚Äî Siteimprove Performance is a web Performance monitoring solution that enables a marketer, manager or decision maker to understand and optimize website load times. Get easy-to-use insights with a focus on quick and impactful wins. Siteimprove Performance is a paid product with a free 14-day trial.\n\n* **[SpeedCurve](https://speedcurve.com)** ‚Äî SpeedCurve is a tool for continuously monitoring web performance across different browsers, devices, and regions. It can aggregate any metric including Lighthouse scores across multiple pages and sites, and allows you to set performance budgets with Slack or email alerts. SpeedCurve is a paid product with a free 30-day trial.\n\n* **[Foo](https://www.foo.software/lighthouse)** - Lighthouse-as-a-service offering free and premium plans. Provides monitoring and historical reporting of Lighthouse audits with CircleCI, GitHub, and other integrations. Features include Slack notifications, PR comment reporting and more.\n\n* **[Apdex](https://apdex.co)** - Apdex is a website performance service. The main features are historical Lighthouse report visualizations, mobile/desktop options, alerts, uptime monitoring, and more. There are flexible paid plans and a 30-day free trial.\n\n* **[Websu](https://websu.io)** - Websu is an open source project to provide Lighthouse-as-a-Service through a simple HTTP REST API. The main features are ability to host and deploy in your own environment and historical Lighthouse report summaries.\n\n* **[DTEKT.IO](https://dtekt.io)** - DTEKT is a website performance and uptime monitoring service. It uses lighthouse to provide visibility into the performance of websites from multiple locations on multiple devices. It offers three months free trial and paid plans.\n\n* **[SpeedVitals](https://speedvitals.com)** - SpeedVitals is a Lighthouse powered tool to measure web performance across multiple devices and locations. It has various features like Layout Shift Visualization, Waterfall Chart, Field Data and Resource Graphs. SpeedVitals offers both free and paid plans.\n\n* **[Lighthouse Metrics](https://lighthouse-metrics.com/)** - Lighthouse Metrics gives you global performance insights with a single test. You can also monitor your websites on a daily or hourly base. Lighthouse Metrics offers free global one-time tests and performance monitoring as a paid feature with a free 14-day trial.\n\n* **[Auditzy](https://auditzy.com)** - Auditzy‚Ñ¢ is a robust website auditing & monitoring tool which lets you analyze your web page(s) pre-user journey. Analyze the Competitor Health Metric, Core Web Vitals, and Technology. Compare your web pages with your competitors to understand where you are leading or lagging. Real-time notification with Slack. Have Seamless Collaboration with Multiple Teams. Automate your Audits hourly, daily, weekly, and so on. It has a free trial with pay as you go plans.\n\n* **[Lighthouse Metrics China](http://lighthousemetricschina.com)** - The first Lighthouse metrics tool specifically designed for China. Experience unparalleled website monitoring capabilities with Lighthouse. Gain insights into the fluctuations of your scores and metrics within the realm of the [Great Firewall of China](https://www.chinafirewalltest.co), enabling a comprehensive understanding of the factors influencing each change. Lighthouse Metrics China offers both free and paid plans.\n\n* **[DeploymentHawk](https://deploymenthawk.com)** - DeploymentHawk is an automated site auditing tool powered by Lighthouse. Effortlessly catch performance, accessibility, and SEO issues before they impact your users. DeploymentHawk is a paid product with a free 7-day trial.\n\n* **[Guardius](https://guardius.io)** - Guardius is a DevOps and DevSecOps SaaS platform that integrates Lighthouse to deliver automated web performance analysis. It not only provides metrics evaluation and automatic scanning but also enables performance comparisons across different periods and ongoing observation over time. Additionally, Guardius offers predefined and customized alerts tailored to your specific requirements. A free version of Guardius is available for users to explore its features.\n\n* **[SonƒÅ](https://getsona.io)** - Powered by Lighthouse amongst others, SonƒÅ delivers in-depth insights into your website‚Äôs health. Track changes over time, share reports, and receive actionable recommendations to improve performance, accessibility, SEO, best practices, and security. SonƒÅ is free during its beta period.\n\n* **[FERU](https://feru.app)** - Run Google Lighthouse speed tests from multiple regions worldwide. Lighthouse scores, Core Web Vitals, and mobile performance metrics to easily test your site's speed, accessibility, and SEO. FERU offers an always-free plan alongside premium features for advanced analysis and monitoring.\n\n* **[LightKeeper](https://www.lightkeeper.cloud)** - Lighthouse testing service with free HAR Matrix view and multi-region testing (3 free regions, 25+ paid), supporting authenticated pages and cross-region performance comparison\n\n## Lighthouse Integrations in non-Web Perf services\n\n* **[PageWatch](https://pagewatch.dev/)** ‚Äî PageWatch is a tool to find problem pages on your website.  It provides insights into spelling errors, layout issues, slow pages (powered by Lighthouse) and more.  PageWatch is offered via free and paid plans.\n\n* **[Fluxguard](https://fluxguard.com/)** - Fluxguard provides website DOM change monitoring orchestrated with Google Puppeteer, and audited by Lighthouse. Fluxguard is a freemium product, with monthly monitoring of up to 75 pages for free.\n\n* **[Microlink](https://microlink.io)** ‚Äî Microlink is a cloud browser as API. It offers Lighthouse reports on demand, making it easy to build any service on top. Similar functionality is available via the underlying open-source project named browserless.\n\n* **[Wattspeed](https://wattspeed.com/)** ‚Äî Wattspeed is a free tool that generates snapshots - historical captures of your web pages that include Lighthouse scores, a list of technologies, W3C HTML validator results, DOM size, mixed content info, and more.\n\n## Plugins\n\n* **[lighthouse-plugin-field-performance](https://github.com/treosh/lighthouse-plugin-field-performance)** - a plugin that adds real-user performance metrics for the URL using the data from [Chrome UX Report](https://developers.google.com/web/tools/chrome-user-experience-report/).\n\n* **[lighthouse-plugin-publisher-ads](https://github.com/googleads/publisher-ads-lighthouse-plugin)** - a tool to improve ad speed and overall quality through a series of automated audits. At the moment, this is primarily targeted at sites using Google Ad Manager. This tool will aid in resolving discovered problems, providing a tool to be used to evaluate effectiveness of iterative changes while suggesting actionable feedback.\n\n* **[lighthouse-plugin-crux](https://github.com/dvelasquez/lighthouse-plugin-crux)** - a plugin that quickly gathers real-user-metrics data from the [Chrome UX Report API](https://developers.google.com/web/tools/chrome-user-experience-report/api/reference).\n\n## Related projects\n\nOther awesome open source projects that use Lighthouse.\n\n* **[auto-lighthouse](https://github.com/TGiles/auto-lighthouse)** - a CLI for crawling a domain and generating mobile and desktop reports for each page.\n* **[Exthouse](https://github.com/treosh/exthouse)** - Analyze the impact of a browser extension on web performance.\n* **[Gimbal](https://labs.moduscreate.com/gimbal-web-performance-audit-budgeting)** - An [open source (MIT licensed)](https://github.com/ModusCreateOrg/gimbal) tool used to measure, analyze, and budget aspects of a web application. Gimbal also integrates reports with GitHub pull requests.\n* **[Gradle Lighthouse Plugin](https://github.com/Cognifide/gradle-lighthouse-plugin)** - An open source Gradle plugin that runs Lighthouse tests on multiple URLs and asserts category score thresholds (useful in continuous integration).\n* **[lighthouse-badges](https://github.com/emazzotta/lighthouse-badges)** - Generate gh-badges (shields.io) based on Lighthouse performance.\n* **[lighthouse-batch](https://github.com/mikestead/lighthouse-batch)** - Run Lighthouse over a number of sites and generate a summary of their metrics/scores.\n* **[lighthouse-batch-parallel](https://github.com/Carr1005/lighthouse-batch-parallel)** - Run multiple Lighthouse runs in parallel to accelerate the data collecting process, get the result stream (csv, json, js object) in your own process (warning: performance results may be volatile).\n* **[lighthouse-check-action](https://github.com/foo-software/lighthouse-check-action)** - A GitHub Action to run Lighthouse in a workflow, featuring Slack notifications and report upload to S3.\n* **[lighthouse-check-orb](https://circleci.com/orbs/registry/orb/foo-software/lighthouse-check)** - A CircleCI Orb to run Lighthouse in a workflow, featuring Slack notifications and report upload to S3.\n* **[andreasonny83/lighthouse-ci](https://github.com/andreasonny83/lighthouse-ci)** - Run Lighthouse and assert scores satisfy your custom thresholds.\n* **[GoogleChrome/lighthouse-ci](https://github.com/GoogleChrome/lighthouse-ci)** - (**official**) Automate running Lighthouse for every commit, viewing the changes, and preventing regressions.\n* **[lighthouse-ci-action](https://github.com/treosh/lighthouse-ci-action)** - A GitHub Action that makes it easy to run Lighthouse in CI and keep your pages small using performance budgets.\n* **[lighthouse-gh-reporter](https://github.com/carlesnunez/lighthouse-gh-reporter)** - Run Lighthouse in CI and report back in a comment on your pull requests\n* **[lighthouse-jest-example](https://github.com/justinribeiro/lighthouse-jest-example)** - Gather performance metrics via Lighthouse and assert results with Jest; uses Puppeteer to start Chrome with network emulation settings defined by WebPageTest.\n* **[lighthouse-lambda](https://github.com/Otterseer/lighthouse-lambda)** - Run Lighthouse on AWS Lambda with prebuilt stable desktop Headless Chrome.\n* **[lighthouse-matchers](https://github.com/ackama/lighthouse-matchers)** - Provides RSpec matchers for executing and evaluating Google Chrome Lighthouse audit scores.\n* **[lighthouse-mocha-example](https://github.com/rishichawda/lighthouse-mocha-example)** - Run Lighthouse performance tests with Mocha and chrome-launcher.\n* **[lighthouse-monitor](https://github.com/verivox/lighthouse-monitor)** - Run Lighthouse against all your URLs. Send metrics to any backend you want, save all reports with automatic data retention, and compare any two results in a web UI.\n* **[lighthouse-persist](https://github.com/foo-software/lighthouse-persist)** - Run Lighthouse and upload HTML reports to an AWS S3 bucket.\n* **[lighthouse-viewer](https://github.com/dvelasquez/lighthouse-viewer/tree/main/packages/lighthouse-viewer)** - Render the Lighthouse JSON into a report, using the Lighthouse Report Renderer repackaged as UMD and ESM. Also available with React, Svelte and Vue wrappers.\n* **[lighthouse4u](https://github.com/godaddy/lighthouse4u)** - LH4U provides Google Lighthouse as a service, surfaced by both a friendly UI+API, and backed by Elastic Search for easy querying and visualization.\n* **[react-lighthouse-viewer](https://www.npmjs.com/package/react-lighthouse-viewer)** - Render a Lighthouse JSON report in a React Component.\n* **[site-audit-seo](https://github.com/viasite/site-audit-seo)** - CLI tool for SEO site audit, crawl site, lighthouse each page. Output to console and tables in csv, xlsx, json, web or Google Drive.\n* **[webpack-lighthouse-plugin](https://github.com/addyosmani/webpack-lighthouse-plugin)** - Run Lighthouse from a Webpack build.\n* **[cypress-audit](https://github.com/mfrachet/cypress-audit)** - Run Lighthouse and Pa11y audits directly in your E2E test suites.\n* **[laravel-lighthouse](https://github.com/adityadees/laravel-lighthouse)** - Google Lighthouse wrapper for laravel framework to run Google Lighthouse CLI with custom option and can automatically save result in your server directory.\n* **[Neodymium](https://github.com/Xceptance/neodymium/wiki/Accessibility)** - The Neodymium test automation framework integrates Lighthouse for accessibility and Web Vitals verification, allowing programmatic validation and assertion of all audit values.\n\n## FAQ\n\n### How does Lighthouse work?\n\nSee [Lighthouse Architecture](./docs/architecture.md).\n\n### Why is the performance score so low? It looks fine to me.\n\nLighthouse reports the performance metrics as they would be experienced by a typical mobile user on a 4G connection and a mid-tier ~$200 phone. Even if it loads quickly on your device and network, users in other environments will experience the site very differently.\n\nRead more in our [guide to throttling](./docs/throttling.md).\n\n### Why does the performance score change so much?\n\nLighthouse performance scores will change due to inherent variability in web and network technologies, even if there hasn't been a code change. Test in consistent environments, run Lighthouse multiple times, and beware of variability before drawing conclusions about a performance-impacting change.\n\nRead more in our [guide to reducing variability](./docs/variability.md).\n\n### Can I configure the lighthouse run?\n\nYes! Details in [Lighthouse configuration](./docs/configuration.md).\n\n### How does Lighthouse use network throttling, and how can I make it better?\n\nGood question. Network and CPU throttling are applied by default in a Lighthouse run. The network\nattempts to emulate slow 4G connectivity and the CPU is slowed down 4x from your machine's default speed. If you\nprefer to run Lighthouse without throttling, you'll have to use the CLI and disable it with the\n`--throttling.*` flags mentioned above.\n\nRead more in our [guide to network throttling](./docs/throttling.md).\n\n### Are results sent to a remote server?\n\nNope. Lighthouse runs locally, auditing a page using a local version of the Chrome browser installed on the\nmachine. Report results are never processed or beaconed to a remote server.\n\n### How do I get localized Lighthouse results via the CLI?\n\nStarting in Lighthouse 8.0, Lighthouse relies entirely on native `Intl` support and no longer uses an `Intl` polyfill. If you're using Node 14 or later, there should be no issue because Node is now [built with `full-icu` by default](https://nodejs.medium.com/node-js-12-to-lts-and-node-js-13-is-here-e28d6a4a2bd#9514).\n\nHowever, if you're using a `small-icu` Node build, you may see Lighthouse log messages about your locale not being available. To remedy this, you can manually install ICU data by using the [`full-icu`](https://www.npmjs.com/package/full-icu) module and the [`--icu-data-dir` node flag](https://nodejs.org/api/intl.html#intl_providing_icu_data_at_runtime) at launch.\n\n### How do I author custom audits to extend Lighthouse?\n\n> **Tip**: see [Lighthouse Architecture](./docs/architecture.md) for more information\non terminology and architecture.\n\nLighthouse can be extended to run custom audits and gatherers that you author.\nThis is great if you're already tracking performance metrics in your site and\nwant to surface those metrics within a Lighthouse report.\n\nIf you're interested in running your own custom audits, check out our\n[Custom Audit Example](./docs/recipes/custom-audit) over in recipes.\n\n### How do I contribute?\n\nWe'd love help writing audits, fixing bugs, and making the tool more useful!\nSee [Contributing](./CONTRIBUTING.md) to get started.\n\n---\n<p align=\"center\">\n  <img src=\"./assets/lighthouse-logo_512px.png\" alt=\"Lighthouse logo\" height=\"150\">\n  <br>\n  <b>Lighthouse</b>, Ààlƒ´tÀåhous (n): a <s>tower or other structure</s> tool containing a beacon light\n  to warn or guide <s>ships at sea</s> developers.\n</p>\n",
      "stars_today": 2
    },
    {
      "id": 439772085,
      "name": "linera-protocol",
      "full_name": "linera-io/linera-protocol",
      "description": "Main repository for the Linera protocol",
      "html_url": "https://github.com/linera-io/linera-protocol",
      "stars": 31955,
      "forks": 2261,
      "language": "Rust",
      "topics": [
        "blockchain",
        "rust",
        "wasm"
      ],
      "created_at": "2021-12-19T04:09:21Z",
      "updated_at": "2026-01-16T19:58:13Z",
      "pushed_at": "2026-01-16T19:58:11Z",
      "open_issues": 568,
      "owner": {
        "login": "linera-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/107513858?v=4"
      },
      "readme": "# <img src=\"https://github.com/linera-io/linera-protocol/assets/1105398/fe08c941-93af-4114-bb83-bcc0eaec95f9\" width=\"250\" height=\"85\" />\n\n[![License](https://img.shields.io/github/license/linera-io/linera-protocol)](LICENSE)\n[![Build Status for Docker](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml)\n[![Build Status for Rust](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml)\n[![Build Status for Documentation](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml)\n[![Twitter](https://img.shields.io/twitter/follow/linera_io)](https://x.com/linera_io)\n[![Discord](https://img.shields.io/discord/984941796272521226)](https://discord.com/invite/linera)\n\n<!-- [![Build Status for Kubernetes](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml) -->\n\n[Linera](https://linera.io) is a decentralized blockchain infrastructure designed for highly scalable,\nsecure, low-latency Web3 applications.\n\n## Documentation\n\nVisit our [developer page](https://linera.dev) and read our\n[whitepaper](https://linera.io/whitepaper) to learn more about the Linera protocol.\n\n## Repository Structure\n\nThe main crates and directories of this repository can be summarized as follows: (listed\nfrom low to high levels in the dependency graph)\n\n* [`linera-base`](https://linera-io.github.io/linera-protocol/linera_base/index.html) Base\n  definitions, including cryptography.\n\n* [`linera-version`](https://linera-io.github.io/linera-protocol/linera_version/index.html)\n  A library to manage version info in binaries and services.\n\n* [`linera-views`](https://linera-io.github.io/linera-protocol/linera_views/index.html) A\n  library mapping complex data structures onto a key-value store. The corresponding\n  procedural macros are implemented in `linera-views-derive`.\n\n* [`linera-execution`](https://linera-io.github.io/linera-protocol/linera_execution/index.html)\n  Persistent data and the corresponding logic for runtime and execution of Linera\n  applications.\n\n* [`linera-chain`](https://linera-io.github.io/linera-protocol/linera_chain/index.html)\n  Persistent data and the corresponding logic for chains of blocks, certificates, and\n  cross-chain messaging.\n\n* [`linera-storage`](https://linera-io.github.io/linera-protocol/linera_storage/index.html)\n  Defines the storage abstractions for the protocol on top of `linera-chain`.\n\n* [`linera-core`](https://linera-io.github.io/linera-protocol/linera_core/index.html) The\n  core Linera protocol, including client and server logic, node synchronization, etc.\n\n* [`linera-rpc`](https://linera-io.github.io/linera-protocol/linera_rpc/index.html)\n  Defines the data-type for RPC messages (currently all client &#x2194; proxy &#x2194;\n  chain &#x2194; chain interactions), and track the corresponding data schemas.\n\n* [`linera-client`](https://linera-io.github.io/linera-protocol/linera_client/index.html)\n  Library for writing Linera clients.  Used for the command-line\n  client and the node service in `linera-service`, as well as the Web\n  client in [`linera-web`](https://github.com/linera-io/linera-web/).\n\n* [`linera-service`](https://linera-io.github.io/linera-protocol/linera_service/index.html)\n  Executable for clients (aka CLI wallets), proxy (aka validator frontend) and servers.\n\n* [`linera-sdk`](https://linera-io.github.io/linera-protocol/linera_sdk/index.html) The\n  library to develop Linera applications written in Rust for the Wasm virtual machine. The\n  corresponding procedural macros are implemented in `linera-sdk-derive`.\n\n* [`examples`](./examples) Examples of Linera applications written in Rust.\n\n## Prerequisites\n\nSee [`INSTALL.md`](./INSTALL.md) for software requirements to develop in this repo.\n\n## Quickstart with the Linera CLI tool\n\nThe following commands set up a local test network and run some transfers between the\nmicrochains owned by a single wallet.\n\n```bash\n# Make sure to compile the Linera binaries and add them in the $PATH.\n# cargo build -p linera-storage-service -p linera-service --bins\nexport PATH=\"$PWD/target/debug:$PATH\"\n\n# Import the optional helper function `linera_spawn`.\nsource /dev/stdin <<<\"$(linera net helper 2>/dev/null)\"\n\n# Run a local test network with the default parameters and a number of microchains\n# owned by the default wallet. This also defines `LINERA_TMP_DIR`.\nlinera_spawn \\\nlinera net up --with-faucet --faucet-port 8080\n\n# Remember the URL of the faucet.\nFAUCET_URL=http://localhost:8080\n\n# If you're using a testnet, start here and run this instead:\n#   LINERA_TMP_DIR=$(mktemp -d)\n#   FAUCET_URL=https://faucet.testnet-XXX.linera.net  # for some value XXX\n```\n\nEnable logs for user applications:\n\n```bash\nexport LINERA_APPLICATION_LOGS=true\n```\n\nSet the path of the future wallet:\n\n```bash\nexport LINERA_WALLET=\"$LINERA_TMP_DIR/wallet.json\"\nexport LINERA_KEYSTORE=\"$LINERA_TMP_DIR/keystore.json\"\nexport LINERA_STORAGE=\"rocksdb:$LINERA_TMP_DIR/client.db\"\n\n# Initialize a new user wallet.\nlinera wallet init --faucet $FAUCET_URL\n\n# Request chains.\nINFO1=($(linera wallet request-chain --faucet $FAUCET_URL))\nINFO2=($(linera wallet request-chain --faucet $FAUCET_URL))\nCHAIN1=\"${INFO1[0]}\"\nACCOUNT1=\"${INFO1[1]}\"\nCHAIN2=\"${INFO2[0]}\"\nACCOUNT2=\"${INFO2[1]}\"\n\n# Show the different chains tracked by the wallet.\nlinera wallet show\n\n# Query the chain balance of some of the chains.\nlinera query-balance \"$CHAIN1\"\nlinera query-balance \"$CHAIN2\"\n\n# Transfer 10 units then 5 back.\nlinera transfer 10 --from \"$CHAIN1\" --to \"$CHAIN2\"\nlinera transfer 5 --from \"$CHAIN2\" --to \"$CHAIN1\"\n\n# Query balances again.\nlinera query-balance \"$CHAIN1\"\nlinera query-balance \"$CHAIN2\"\n\n# Now let's fund the user balances.\nlinera transfer 5 --from \"$CHAIN1\" --to \"$CHAIN1:$ACCOUNT1\"\nlinera transfer 2 --from \"$CHAIN1:$ACCOUNT1\" --to \"$CHAIN2:$ACCOUNT2\"\n\n# Query user balances again.\nlinera query-balance \"$CHAIN1:$ACCOUNT1\"\nlinera query-balance \"$CHAIN2:$ACCOUNT2\"\n```\n\nMore complex examples may be found in our [developer manual](https://linera.dev) as well\nas the [example applications](./examples) in this repository.\n\n## Contributing\n\nWe welcome contributions from the community! If you'd like to contribute to the Linera protocol:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\nFor detailed guidelines, see our [contribution guide](./CONTRIBUTING.md).\n",
      "stars_today": 2
    },
    {
      "id": 23418517,
      "name": "hadoop",
      "full_name": "apache/hadoop",
      "description": "Apache Hadoop",
      "html_url": "https://github.com/apache/hadoop",
      "stars": 15448,
      "forks": 9185,
      "language": "Java",
      "topics": [
        "hadoop"
      ],
      "created_at": "2014-08-28T07:00:08Z",
      "updated_at": "2026-01-16T08:24:09Z",
      "pushed_at": "2026-01-16T06:03:57Z",
      "open_issues": 91,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "For the latest information about Hadoop, please visit our website at:\n\n   http://hadoop.apache.org/\n\nand our wiki, at:\n\n   https://cwiki.apache.org/confluence/display/HADOOP/\n",
      "stars_today": 2
    },
    {
      "id": 7056202,
      "name": "fmt",
      "full_name": "fmtlib/fmt",
      "description": "A modern formatting library",
      "html_url": "https://github.com/fmtlib/fmt",
      "stars": 23164,
      "forks": 2813,
      "language": "C++",
      "topics": [
        "c-plus-plus",
        "chrono",
        "cpp",
        "cross-platform",
        "floating-point",
        "formatting",
        "multiplatform",
        "output",
        "performance",
        "printf",
        "ranges",
        "unicode"
      ],
      "created_at": "2012-12-07T16:26:46Z",
      "updated_at": "2026-01-16T18:48:48Z",
      "pushed_at": "2026-01-16T18:48:40Z",
      "open_issues": 11,
      "owner": {
        "login": "fmtlib",
        "avatar_url": "https://avatars.githubusercontent.com/u/7280830?v=4"
      },
      "readme": "<img src=\"https://user-images.githubusercontent.com/576385/156254208-f5b743a9-88cf-439d-b0c0-923d53e8d551.png\" alt=\"{fmt}\" width=\"25%\"/>\n\n[![image](https://github.com/fmtlib/fmt/workflows/linux/badge.svg)](https://github.com/fmtlib/fmt/actions?query=workflow%3Alinux)\n[![image](https://github.com/fmtlib/fmt/workflows/macos/badge.svg)](https://github.com/fmtlib/fmt/actions?query=workflow%3Amacos)\n[![image](https://github.com/fmtlib/fmt/workflows/windows/badge.svg)](https://github.com/fmtlib/fmt/actions?query=workflow%3Awindows)\n[![fmt is continuously fuzzed at oss-fuzz](https://oss-fuzz-build-logs.storage.googleapis.com/badges/fmt.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?\\%0Acolspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20\\%0ASummary&q=proj%3Dfmt&can=1)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/8880/badge)](https://www.bestpractices.dev/projects/8880)\n[![image](https://api.securityscorecards.dev/projects/github.com/fmtlib/fmt/badge)](https://securityscorecards.dev/viewer/?uri=github.com/fmtlib/fmt)\n[![Ask questions at StackOverflow with the tag fmt](https://img.shields.io/badge/stackoverflow-fmt-blue.svg)](https://stackoverflow.com/questions/tagged/fmt)\n\n**{fmt}** is an open-source formatting library providing a fast and safe\nalternative to C stdio and C++ iostreams.\n\nIf you like this project, please consider donating to one of the funds\nthat help victims of the war in Ukraine: <https://u24.gov.ua/>.\n\n[Documentation](https://fmt.dev)\n\n[Cheat Sheets](https://hackingcpp.com/cpp/libs/fmt.html)\n\nQ&A: ask questions on [StackOverflow with the tag\nfmt](https://stackoverflow.com/questions/tagged/fmt).\n\nTry {fmt} in [Compiler Explorer](https://godbolt.org/z/8Mx1EW73v).\n\n# Features\n\n- Simple [format API](https://fmt.dev/latest/api/) with positional\n  arguments for localization\n- Implementation of [C++20\n  std::format](https://en.cppreference.com/w/cpp/utility/format) and\n  [C++23 std::print](https://en.cppreference.com/w/cpp/io/print)\n- [Format string syntax](https://fmt.dev/latest/syntax/) similar\n  to Python\\'s\n  [format](https://docs.python.org/3/library/stdtypes.html#str.format)\n- Fast IEEE 754 floating-point formatter with correct rounding,\n  shortness and round-trip guarantees using the\n  [Dragonbox](https://github.com/jk-jeon/dragonbox) algorithm\n- Portable Unicode support\n- Safe [printf\n  implementation](https://fmt.dev/latest/api/#printf-formatting)\n  including the POSIX extension for positional arguments\n- Extensibility: [support for user-defined\n  types](https://fmt.dev/latest/api/#formatting-user-defined-types)\n- High performance: faster than common standard library\n  implementations of `(s)printf`, iostreams, `to_string` and\n  `to_chars`, see [Speed tests](#speed-tests) and [Converting a\n  hundred million integers to strings per\n  second](http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html)\n- Small code size both in terms of source code with the minimum\n  configuration consisting of just three files, `base.h`, `format.h`\n  and `format-inl.h`, and compiled code; see [Compile time and code\n  bloat](#compile-time-and-code-bloat)\n- Reliability: the library has an extensive set of\n  [tests](https://github.com/fmtlib/fmt/tree/master/test) and is\n  [continuously fuzzed](https://bugs.chromium.org/p/oss-fuzz/issues/list?colspec=ID%20Type%20Component%20Status%20Proj%20Reported%20Owner%20Summary&q=proj%3Dfmt&can=1)\n- Safety: the library is fully type-safe, errors in format strings can\n  be reported at compile time, automatic memory management prevents\n  buffer overflow errors\n- Ease of use: small self-contained code base, no external\n  dependencies, permissive MIT\n  [license](https://github.com/fmtlib/fmt/blob/master/LICENSE)\n- [Portability](https://fmt.dev/latest/#portability) with\n  consistent output across platforms and support for older compilers\n- Clean warning-free codebase even on high warning levels such as\n  `-Wall -Wextra -pedantic`\n- Locale independence by default\n- Optional header-only configuration enabled with the\n  `FMT_HEADER_ONLY` macro\n\nSee the [documentation](https://fmt.dev) for more details.\n\n# Examples\n\n**Print to stdout** ([run](https://godbolt.org/z/Tevcjh))\n\n``` c++\n#include <fmt/base.h>\n\nint main() {\n  fmt::print(\"Hello, world!\\n\");\n}\n```\n\n**Format a string** ([run](https://godbolt.org/z/oK8h33))\n\n``` c++\nstd::string s = fmt::format(\"The answer is {}.\", 42);\n// s == \"The answer is 42.\"\n```\n\n**Format a string using positional arguments**\n([run](https://godbolt.org/z/Yn7Txe))\n\n``` c++\nstd::string s = fmt::format(\"I'd rather be {1} than {0}.\", \"right\", \"happy\");\n// s == \"I'd rather be happy than right.\"\n```\n\n**Print dates and times** ([run](https://godbolt.org/z/c31ExdY3W))\n\n``` c++\n#include <fmt/chrono.h>\n\nint main() {\n  auto now = std::chrono::system_clock::now();\n  fmt::print(\"Date and time: {}\\n\", now);\n  fmt::print(\"Time: {:%H:%M}\\n\", now);\n}\n```\n\nOutput:\n\n    Date and time: 2023-12-26 19:10:31.557195597\n    Time: 19:10\n\n**Print a container** ([run](https://godbolt.org/z/MxM1YqjE7))\n\n``` c++\n#include <vector>\n#include <fmt/ranges.h>\n\nint main() {\n  std::vector<int> v = {1, 2, 3};\n  fmt::print(\"{}\\n\", v);\n}\n```\n\nOutput:\n\n    [1, 2, 3]\n\n**Check a format string at compile time**\n\n``` c++\nstd::string s = fmt::format(\"{:d}\", \"I am not a number\");\n```\n\nThis gives a compile-time error in C++20 because `d` is an invalid\nformat specifier for a string.\n\n**Write a file from a single thread**\n\n``` c++\n#include <fmt/os.h>\n\nint main() {\n  auto out = fmt::output_file(\"guide.txt\");\n  out.print(\"Don't {}\", \"Panic\");\n}\n```\n\nThis can be [up to 9 times faster than `fprintf`](\nhttp://www.zverovich.net/2020/08/04/optimal-file-buffer-size.html).\n\n**Print with colors and text styles**\n\n``` c++\n#include <fmt/color.h>\n\nint main() {\n  fmt::print(fg(fmt::color::crimson) | fmt::emphasis::bold,\n             \"Hello, {}!\\n\", \"world\");\n  fmt::print(fg(fmt::color::floral_white) | bg(fmt::color::slate_gray) |\n             fmt::emphasis::underline, \"Ol√°, {}!\\n\", \"Mundo\");\n  fmt::print(fg(fmt::color::steel_blue) | fmt::emphasis::italic,\n             \"‰Ω†Â•Ω{}ÔºÅ\\n\", \"‰∏ñÁïå\");\n}\n```\n\nOutput on a modern terminal with Unicode support:\n\n![image](https://github.com/fmtlib/fmt/assets/%0A576385/2a93c904-d6fa-4aa6-b453-2618e1c327d7)\n\n# Benchmarks\n\n## Speed tests\n\n| Library           | Method        | Run Time, s |\n|-------------------|---------------|-------------|\n| libc              | printf        |   0.66      |\n| libc++            | std::ostream  |   1.63      |\n| {fmt} 12.1        | fmt::print    |   0.44      |\n| Boost Format 1.88 | boost::format |   3.89      |\n| Folly Format      | folly::format |   1.28      |\n\n{fmt} is the fastest of the benchmarked methods, \\~50% faster than\n`printf`.\n\nThe above results were generated by building `tinyformat_test.cpp` on\nmacOS 15.6.1 with `clang++ -O3 -DNDEBUG -DSPEED_TEST -DHAVE_FORMAT`, and\ntaking the best of three runs. In the test, the format string\n`\"%0.10f:%04d:%+g:%s:%p:%c:%%\\n\"` or equivalent is filled 2,000,000\ntimes with output sent to `/dev/null`; for further details refer to the\n[source](https://github.com/fmtlib/format-benchmark/blob/master/src/tinyformat-test.cc).\n\n{fmt} is up to 20-30x faster than `std::ostringstream` and `sprintf` on\nIEEE754 `float` and `double` formatting\n([dtoa-benchmark](https://github.com/fmtlib/dtoa-benchmark)) and faster\nthan [double-conversion](https://github.com/google/double-conversion)\nand [ryu](https://github.com/ulfjack/ryu):\n\n[![image](https://user-images.githubusercontent.com/576385/95684665-11719600-0ba8-11eb-8e5b-972ff4e49428.png)](https://fmt.dev/unknown_mac64_clang12.0.html)\n\n## Compile time and code bloat\n\nThe script [bloat-test.py][test] from [format-benchmark][bench] tests compile\ntime and code bloat for nontrivial projects. It generates 100 translation units\nand uses `printf()` or its alternative five times in each to simulate a\nmedium-sized project. The resulting executable size and compile time (Apple\nclang version 15.0.0 (clang-1500.1.0.2.5), macOS Sonoma, best of three) is shown\nin the following tables.\n\n[test]: https://github.com/fmtlib/format-benchmark/blob/master/bloat-test.py\n[bench]: https://github.com/fmtlib/format-benchmark\n\n**Optimized build (-O3)**\n\n| Method          | Compile Time, s | Executable size, KiB | Stripped size, KiB |\n|-----------------|-----------------|----------------------|--------------------|\n| printf          |             1.6 |                   54 |                 50 |\n| IOStreams       |            28.4 |                   98 |                 84 |\n| {fmt} `1122268` |             5.0 |                   54 |                 50 |\n| tinyformat      |            32.6 |                  164 |                136 |\n| Boost Format    |            55.0 |                  530 |                317 |\n\n{fmt} is fast to compile and is comparable to `printf` in terms of per-call\nbinary size (within a rounding error on this system).\n\n**Non-optimized build**\n\n| Method          | Compile Time, s | Executable size, KiB | Stripped size, KiB |\n|-----------------|-----------------|----------------------|--------------------|\n| printf          |             1.4 |                   54 |                 50 |\n| IOStreams       |            27.0 |                   88 |                 68 |\n| {fmt} `1122268` |             4.7 |                   87 |                 84 |\n| tinyformat      |            28.1 |                  185 |                145 |\n| Boost Format    |            38.9 |                  678 |                381 |\n\n`libc`, `lib(std)c++`, and `libfmt` are all linked as shared libraries\nto compare formatting function overhead only. Boost Format is a\nheader-only library so it doesn\\'t provide any linkage options.\n\n## Running the tests\n\nPlease refer to [Building the\nlibrary](https://fmt.dev/latest/get-started/#building-from-source) for\ninstructions on how to build the library and run the unit tests.\n\nBenchmarks reside in a separate repository,\n[format-benchmarks](https://github.com/fmtlib/format-benchmark), so to\nrun the benchmarks you first need to clone this repository and generate\nMakefiles with CMake:\n\n    $ git clone --recursive https://github.com/fmtlib/format-benchmark.git\n    $ cd format-benchmark\n    $ cmake .\n\nThen you can run the speed test:\n\n    $ make speed-test\n\nor the bloat test:\n\n    $ make bloat-test\n\n# Migrating code\n\n[clang-tidy](https://clang.llvm.org/extra/clang-tidy/) v18 provides the\n[modernize-use-std-print](https://clang.llvm.org/extra/clang-tidy/checks/modernize/use-std-print.html)\ncheck that is capable of converting occurrences of `printf` and\n`fprintf` to `fmt::print` if configured to do so. (By default it\nconverts to `std::print`.)\n\n# Notable projects using this library\n\n- [0 A.D.](https://play0ad.com/): a free, open-source, cross-platform\n  real-time strategy game\n- [AMPL/MP](https://github.com/ampl/mp): an open-source library for\n  mathematical programming\n- [Apple's FoundationDB](https://github.com/apple/foundationdb): an open-source,\n  distributed, transactional key-value store\n- [Aseprite](https://github.com/aseprite/aseprite): animated sprite\n  editor & pixel art tool\n- [AvioBook](https://www.aviobook.aero/en): a comprehensive aircraft\n  operations suite\n- [Blizzard Battle.net](https://battle.net/): an online gaming\n  platform\n- [Celestia](https://celestia.space/): real-time 3D visualization of\n  space\n- [Ceph](https://ceph.com/): a scalable distributed storage system\n- [ccache](https://ccache.dev/): a compiler cache\n- [ClickHouse](https://github.com/ClickHouse/ClickHouse): an\n  analytical database management system\n- [ContextVision](https://www.contextvision.com/): medical imaging software\n- [Contour](https://github.com/contour-terminal/contour/): a modern\n  terminal emulator\n- [CUAUV](https://cuauv.org/): Cornell University\\'s autonomous\n  underwater vehicle\n- [Drake](https://drake.mit.edu/): a planning, control, and analysis\n  toolbox for nonlinear dynamical systems (MIT)\n- [Envoy](https://github.com/envoyproxy/envoy): C++ L7 proxy and\n  communication bus (Lyft)\n- [FiveM](https://fivem.net/): a modification framework for GTA V\n- [fmtlog](https://github.com/MengRao/fmtlog): a performant\n  fmtlib-style logging library with latency in nanoseconds\n- [Folly](https://github.com/facebook/folly): Facebook open-source\n  library\n- [GemRB](https://gemrb.org/): a portable open-source implementation\n  of Bioware's Infinity Engine\n- [Grand Mountain\n  Adventure](https://store.steampowered.com/app/1247360/Grand_Mountain_Adventure/):\n  a beautiful open-world ski & snowboarding game\n- [HarpyWar/pvpgn](https://github.com/pvpgn/pvpgn-server): Player vs\n  Player Gaming Network with tweaks\n- [KBEngine](https://github.com/kbengine/kbengine): an open-source\n  MMOG server engine\n- [Keypirinha](https://keypirinha.com/): a semantic launcher for\n  Windows\n- [Kodi](https://kodi.tv/) (formerly xbmc): home theater software\n- [Knuth](https://kth.cash/): high-performance Bitcoin full-node\n- [libunicode](https://github.com/contour-terminal/libunicode/): a\n  modern C++17 Unicode library\n- [MariaDB](https://mariadb.org/): relational database management\n  system\n- [Microsoft Verona](https://github.com/microsoft/verona): research\n  programming language for concurrent ownership\n- [MongoDB](https://mongodb.com/): distributed document database\n- [MongoDB Smasher](https://github.com/duckie/mongo_smasher): a small\n  tool to generate randomized datasets\n- [OpenSpace](https://openspaceproject.com/): an open-source\n  astrovisualization framework\n- [PenUltima Online (POL)](https://www.polserver.com/): an MMO server,\n  compatible with most Ultima Online clients\n- [PyTorch](https://github.com/pytorch/pytorch): an open-source\n  machine learning library\n- [quasardb](https://www.quasardb.net/): a distributed,\n  high-performance, associative database\n- [Quill](https://github.com/odygrd/quill): asynchronous low-latency\n  logging library\n- [QKW](https://github.com/ravijanjam/qkw): generalizing aliasing to\n  simplify navigation, and execute complex multi-line terminal\n  command sequences\n- [redis-cerberus](https://github.com/HunanTV/redis-cerberus): a Redis\n  cluster proxy\n- [redpanda](https://vectorized.io/redpanda): a 10x faster Kafka¬Æ\n  replacement for mission-critical systems written in C++\n- [rpclib](http://rpclib.net/): a modern C++ msgpack-RPC server and\n  client library\n- [Salesforce Analytics\n  Cloud](https://www.salesforce.com/analytics-cloud/overview/):\n  business intelligence software\n- [Scylla](https://www.scylladb.com/): a Cassandra-compatible NoSQL\n  data store that can handle 1 million transactions per second on a\n  single server\n- [Seastar](http://www.seastar-project.org/): an advanced, open-source\n  C++ framework for high-performance server applications on modern\n  hardware\n- [spdlog](https://github.com/gabime/spdlog): super fast C++ logging\n  library\n- [Stellar](https://www.stellar.org/): financial platform\n- [Touch Surgery](https://www.touchsurgery.com/): surgery simulator\n- [TrinityCore](https://github.com/TrinityCore/TrinityCore):\n  open-source MMORPG framework\n- [üêô userver framework](https://userver.tech/): open-source\n  asynchronous framework with a rich set of abstractions and database\n  drivers\n- [Windows Terminal](https://github.com/microsoft/terminal): the new\n  Windows terminal\n\n[More\\...](https://github.com/search?q=fmtlib&type=Code)\n\nIf you are aware of other projects using this library, please let me\nknow by [email](mailto:victor.zverovich@gmail.com) or by submitting an\n[issue](https://github.com/fmtlib/fmt/issues).\n\n# Motivation\n\nSo why yet another formatting library?\n\nThere are plenty of methods for doing this task, from standard ones like\nthe printf family of function and iostreams to Boost Format and\nFastFormat libraries. The reason for creating a new library is that\nevery existing solution that I found either had serious issues or\ndidn\\'t provide all the features I needed.\n\n## printf\n\nThe good thing about `printf` is that it is pretty fast and readily\navailable being a part of the C standard library. The main drawback is\nthat it doesn\\'t support user-defined types. `printf` also has safety\nissues although they are somewhat mitigated with [\\_\\_attribute\\_\\_\n((format (printf,\n\\...))](https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html) in\nGCC. There is a POSIX extension that adds positional arguments required\nfor\n[i18n](https://en.wikipedia.org/wiki/Internationalization_and_localization)\nto `printf` but it is not a part of C99 and may not be available on some\nplatforms.\n\n## iostreams\n\nThe main issue with iostreams is best illustrated with an example:\n\n``` c++\nstd::cout << std::setprecision(2) << std::fixed << 1.23456 << \"\\n\";\n```\n\nwhich is a lot of typing compared to printf:\n\n``` c++\nprintf(\"%.2f\\n\", 1.23456);\n```\n\nMatthew Wilson, the author of FastFormat, called this \\\"chevron hell\\\".\niostreams don\\'t support positional arguments by design.\n\nThe good part is that iostreams support user-defined types and are safe\nalthough error handling is awkward.\n\n## Boost Format\n\nThis is a very powerful library that supports both `printf`-like format\nstrings and positional arguments. Its main drawback is performance.\nAccording to various benchmarks, it is much slower than other methods\nconsidered here. Boost Format also has excessive build times and severe\ncode bloat issues (see [Benchmarks](#benchmarks)).\n\n## FastFormat\n\nThis is an interesting library that is fast, safe and has positional\narguments. However, it has significant limitations, citing its author:\n\n> Three features that have no hope of being accommodated within the\n> current design are:\n>\n> - Leading zeros (or any other non-space padding)\n> - Octal/hexadecimal encoding\n> - Runtime width/alignment specification\n\nIt is also quite big and has a heavy dependency, on STLSoft, which might be\ntoo restrictive for use in some projects.\n\n## Boost Spirit.Karma\n\nThis is not a formatting library but I decided to include it here for\ncompleteness. As iostreams, it suffers from the problem of mixing\nverbatim text with arguments. The library is pretty fast, but slower on\ninteger formatting than `fmt::format_to` with format string compilation\non Karma\\'s own benchmark, see [Converting a hundred million integers to\nstrings per\nsecond](http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html).\n\n# License\n\n{fmt} is distributed under the MIT\n[license](https://github.com/fmtlib/fmt/blob/master/LICENSE).\n\n# Documentation License\n\nThe [Format String Syntax](https://fmt.dev/latest/syntax/) section\nin the documentation is based on the one from Python [string module\ndocumentation](https://docs.python.org/3/library/string.html#module-string).\nFor this reason, the documentation is distributed under the Python\nSoftware Foundation license available in\n[doc/python-license.txt](https://raw.github.com/fmtlib/fmt/master/doc/python-license.txt).\nIt only applies if you distribute the documentation of {fmt}.\n\n# Maintainers\n\nThe {fmt} library is maintained by Victor Zverovich\n([vitaut](https://github.com/vitaut)) with contributions from many other\npeople. See\n[Contributors](https://github.com/fmtlib/fmt/graphs/contributors) and\n[Releases](https://github.com/fmtlib/fmt/releases) for some of the\nnames. Let us know if your contribution is not listed or mentioned\nincorrectly and we\\'ll make it right.\n\n# Security Policy\n\nTo report a security issue, please disclose it at [security\nadvisory](https://github.com/fmtlib/fmt/security/advisories/new).\n\nThis project is maintained by a team of volunteers on a\nreasonable-effort basis. As such, please give us at least *90* days to\nwork on a fix before public exposure.\n",
      "stars_today": 2
    },
    {
      "id": 35732214,
      "name": "SwiftLint",
      "full_name": "realm/SwiftLint",
      "description": "A tool to enforce Swift style and conventions.",
      "html_url": "https://github.com/realm/SwiftLint",
      "stars": 19393,
      "forks": 2277,
      "language": "Swift",
      "topics": [
        "code-quality",
        "hacktoberfest",
        "linter",
        "linting",
        "static-analysis",
        "swift"
      ],
      "created_at": "2015-05-16T16:59:31Z",
      "updated_at": "2026-01-16T23:43:34Z",
      "pushed_at": "2026-01-16T15:23:25Z",
      "open_issues": 474,
      "owner": {
        "login": "realm",
        "avatar_url": "https://avatars.githubusercontent.com/u/7575099?v=4"
      },
      "readme": "# SwiftLint\n\nA tool to enforce Swift style and conventions, loosely based on the now\narchived [GitHub Swift Style Guide](https://github.com/github/swift-style-guide).\nSwiftLint enforces the style guide rules that are generally accepted by the\nSwift community. These rules are well described in popular style guides like\n[Kodeco's Swift Style Guide](https://github.com/kodecocodes/swift-style-guide).\n\nSwiftLint rules are predominantly based on [SwiftSyntax](https://github.com/swiftlang/swift-syntax).\nSome rules still hook into [Clang](http://clang.llvm.org) and\n[SourceKit](http://www.jpsim.com/uncovering-sourcekit) to access type information.\n\n[![Supported Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Frealm%2FSwiftLint%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/realm/SwiftLint)\n[![Supported Platforms](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Frealm%2FSwiftLint%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/realm/SwiftLint)\n[![Buildkite Build Status](https://badge.buildkite.com/e2a5bc32c347e76e2793e4c5764a5f42bcd42bbe32f79c3a53.svg?branch=main)](https://buildkite.com/swiftlint/swiftlint)\n\n![SwiftLint violations highlighted in the Xcode editor](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/screenshot.png)\n\nThis project adheres to the\n[Contributor Covenant Code of Conduct](https://realm.io/conduct).\nBy participating, you are expected to uphold this code.\n\n> Switch Language:\n> [‰∏≠Êñá](https://github.com/realm/SwiftLint/blob/main/README_CN.md),\n> [ÌïúÍµ≠Ïñ¥](https://github.com/realm/SwiftLint/blob/main/README_KR.md)\n\n## Video Introduction\n\nTo get a high-level overview of SwiftLint, we encourage you to watch this\npresentation recorded January 9th, 2017 by JP Simard (transcript provided):\n\n[![Presentation](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/presentation.svg)](https://youtu.be/9Z1nTMTejqU)\n\n## Installation\n\n### [Swift Package Manager](https://github.com/apple/swift-package-manager)\n\nSwiftLint can be used as a [command plugin](#swift-package-command-plugin)\nor a [build tool plugin](#build-tool-plugins).\n\nAdd\n\n```swift\n.package(url: \"https://github.com/SimplyDanny/SwiftLintPlugins\", from: \"<version>\")\n```\n\nto your `Package.swift` file to consume the latest release of SwiftLint\nautomatically or pin the dependency to a specific version:\n\n```swift\n.package(url: \"https://github.com/SimplyDanny/SwiftLintPlugins\", exact: \"<version>\")\n```\n\nTherein, replace `<version>` with the desired minimum or exact version.\n\n> [!NOTE]\n> Consuming the plugins directly from the SwiftLint repository comes\n> with several drawbacks. To avoid them and reduce the overhead imposed, it's\n> highly recommended to consume the plugins from the dedicated\n> [SwiftLintPlugins repository](https://github.com/SimplyDanny/SwiftLintPlugins),\n> even though plugins from the SwiftLint repository are also absolutely\n> functional. If the plugins from SwiftLint are preferred, just use the URL\n> `https://github.com/realm/SwiftLint` in the package declarations above.\n>\n> However, [SwiftLintPlugins](https://github.com/SimplyDanny/SwiftLintPlugins)\n> facilitates plugin adoption massively. It lists some of the reasons that\n> drive the plugins as provided by SwiftLint itself very troublesome. Since\n> the plugin code and the releases are kept in sync, there is no difference\n> in functionality between the two, but you spare yourself a lot of time and\n> trouble using the dedicated plugins repository.\n>\n> This document assumes you're relying on SwiftLintPlugins.\n\n### [Xcode Package Dependency](https://developer.apple.com/documentation/xcode/adding-package-dependencies-to-your-app)\n\nUse the following link to add SwiftLint as a Package Dependency to an Xcode\nproject:\n\n```bash\nhttps://github.com/SimplyDanny/SwiftLintPlugins\n```\n\n### [Homebrew](http://brew.sh)\n\n```bash\nbrew install swiftlint\n```\n\n### [CocoaPods](https://cocoapods.org)\n\nAdd the following to your `Podfile`:\n\n```ruby\npod 'SwiftLint'\n```\n\nThis will download the SwiftLint binaries and dependencies in `Pods/` during\nyour next `pod install` execution and will allow you to invoke it via\n`${PODS_ROOT}/SwiftLint/swiftlint` in your Script Build Phases.\n\nInstalling via Cocoapods also enables pinning to a specific version of\nSwiftLint rather than simply the latest (which is the case with\n[Homebrew](#homebrew)).\n\nNote that this will add the SwiftLint binaries, its dependencies' binaries, and\nthe Swift binary library distribution to the `Pods/` directory, so checking in\nthis directory to SCM such as Git is discouraged.\n\n### [Mint](https://github.com/yonaskolb/mint)\n\n```bash\nmint install realm/SwiftLint\n```\n\n### [Bazel](https://bazel.build)\n\nPut this in your `MODULE.bazel`:\n\n```bzl\nbazel_dep(name = \"swiftlint\", version = \"0.52.4\", repo_name = \"SwiftLint\")\n```\n\nOr put this in your `WORKSPACE`:\n\n<details>\n\n<summary>WORKSPACE</summary>\n\n```bzl\nload(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\")\n\nhttp_archive(\n    name = \"build_bazel_rules_apple\",\n    sha256 = \"390841dd5f8a85fc25776684f4793d56e21b098dfd7243cd145b9831e6ef8be6\",\n    url = \"https://github.com/bazelbuild/rules_apple/releases/download/2.4.1/rules_apple.2.4.1.tar.gz\",\n)\n\nload(\n    \"@build_bazel_rules_apple//apple:repositories.bzl\",\n    \"apple_rules_dependencies\",\n)\n\napple_rules_dependencies()\n\nload(\n    \"@build_bazel_rules_swift//swift:repositories.bzl\",\n    \"swift_rules_dependencies\",\n)\n\nswift_rules_dependencies()\n\nload(\n    \"@build_bazel_rules_swift//swift:extras.bzl\",\n    \"swift_rules_extra_dependencies\",\n)\n\nswift_rules_extra_dependencies()\n\nhttp_archive(\n    name = \"SwiftLint\",\n    sha256 = \"c6ea58b9c72082cdc1ada4a2d48273ecc355896ed72204cedcc586b6ccb8aca6\",\n    url = \"https://github.com/realm/SwiftLint/releases/download/0.52.4/bazel.tar.gz\",\n)\n\nload(\"@SwiftLint//bazel:repos.bzl\", \"swiftlint_repos\")\n\nswiftlint_repos()\n\nload(\"@SwiftLint//bazel:deps.bzl\", \"swiftlint_deps\")\n\nswiftlint_deps()\n```\n\n</details>\n\nThen you can run SwiftLint in the current directory with this command:\n\n```console\nbazel run -c opt @SwiftLint//:swiftlint\n```\n\n### Pre-Built Package\n\nDownload `SwiftLint.pkg` from the\n[latest GitHub release](https://github.com/realm/SwiftLint/releases/latest) and\nrun it.\n\n### From Source\n\nMake sure the build tool [Bazel](https://bazel.build) and a\nrecent [Swift toolchain](https://www.swift.org/download/) are\ninstalled and all tools are discoverable in your `PATH`.\n\nTo build SwiftLint, clone this repository and run `make install`.\n\n## Setup\n\n> [!IMPORTANT]\n> While it may seem intuitive to run SwiftLint before compiling Swift source\n> files to exit a build early when there are lint violations, it is important\n> to understand that SwiftLint is designed to analyze valid source code that\n> is compilable. Non-compiling code can very easily lead to unexpected and\n> confusing results, especially when executing with `--fix`/`--autocorrect`\n> command line arguments.\n\n### Build Tool Plugins\n\nSwiftLint can be used as a build tool plugin for both\n[Swift Package projects](#swift-package-projects)\nand [Xcode projects](#xcode-projects).\n\nThe build tool plugin determines the SwiftLint working directory by locating\nthe topmost config file within the package/project directory. If a config file\nis not found therein, the package/project directory is used as the working\ndirectory.\n\nThe plugin throws an error when it is unable to resolve the SwiftLint working\ndirectory. For example, this will occur in Xcode projects where the target's\nSwift files are not located within the project directory.\n\nTo maximize compatibility with the plugin, avoid project structures that require\nthe use of the `--config` option.\n\n### Swift Package Projects\n\n> [!NOTE]\n> Requires installing via [Swift Package Manager](#swift-package-manager).\n\nBuild tool plugins run when building each target. When a project has multiple\ntargets, the plugin must be added to the desired targets individually.\n\nTo do this, add the plugin to the target(s) to be linted as follows:\n\n```swift\n.target(\n    ...\n    plugins: [.plugin(name: \"SwiftLintBuildToolPlugin\", package: \"SwiftLintPlugins\")]\n),\n```\n\n### Swift Package Command Plugin\n\n> [!NOTE]\n> Requires installing via [Swift Package Manager](#swift-package-manager).\n\nThe command plugin enables running SwiftLint from the command line as follows:\n\n```shell\nswift package plugin swiftlint\n```\n\n### Xcode Projects\n\n> [!NOTE]\n> Requires installing via [Xcode Package Dependency](#xcode-package-dependency).\n\nBuild tool plugins run as a build phase of each target. When a project has\nmultiple targets, the plugin must be added to the desired targets individually.\n\nTo do this, add the `SwiftLintBuildToolPlugin` to the `Run Build Tool Plug-ins`\nphase of the `Build Phases` for the target(s) to be linted.\n\n> [!TIP]\n> When using the plugin for the first time, be sure to trust and enable\n> it when prompted. If a macros build warning exists, select it to trust\n> and enable the macros as well.\n\nFor unattended use (e.g. on CI), package plugin and macro\nvalidations can be disabled with either of the following:\n\n* Using `xcodebuild` options:\n\n  ```bash\n  -skipPackagePluginValidation\n  -skipMacroValidation\n  ```\n\n* Setting Xcode defaults:\n\n  ```bash\n  defaults write com.apple.dt.Xcode IDESkipPackagePluginFingerprintValidatation -bool YES\n  defaults write com.apple.dt.Xcode IDESkipMacroFingerprintValidation -bool YES\n  ```\n\n> [!IMPORTANT]\n> The unattended use options bypass Xcode's validation dialogs\n> and implicitly trust all plugins and macros, which has security implications.\n\n#### Unexpected Xcode Project Structures\n\nProject structures where SwiftLint's configuration file is located\noutside of the package/project directory are not directly supported\nby the build tool plugin. This is because it isn't possible to pass\narguments to build tool plugins (e.g., passing the config file path).\n\nIf your project structure doesn't work directly with the build tool\nplugin, please consider one of the following options:\n\n* To use a config file located outside the package/project directory, a config\n  file may be added to that directory specifying a parent config path to the\n  other config file, e.g., `parent_config: path/to/.swiftlint.yml`.\n* You can also consider the use of a\n  [Run Script Build Phase](#xcode-run-script-build-phase) in place of the build\n  tool plugin.\n\n### Xcode Run Script Build Phase\n\n> [!NOTE]\n> Based upon the installation method used, the shell command syntax in the\n> Run Script Build Phase may be different or additional configuration could\n> be required. Refer to the [installation](#installation) instructions for\n> more information.\n\nIf the build tool plugin does not work for your project setup or when\nadditional custom setup is required, SwiftLint can be added as a Run Script\nBuild Phase. This is useful when a project setup relies on the `--config`\nSwiftLint option; or to lint all targets together in a single `swiftlint`\ninvocation. File inclusions and exclusions can be configured in the\n[`.swiftlint.yml` configuration](#configuration).\n\nTo do this, add a custom script to a `Run Script` phase of the `Build Phases`\nof the primary app target, after the `Compile Sources` phase. Use the\nfollowing script implementation:\n\n```bash\nif command -v swiftlint >/dev/null 2>&1\nthen\n    swiftlint\nelse\n    echo \"warning: `swiftlint` command not found - See https://github.com/realm/SwiftLint#installation for installation instructions.\"\nfi\n```\n\nIf you're using the SwiftLintPlugin in a Swift package,\nyou may refer to the `swiftlint` executable in the\nfollowing way:\n\n```bash\nSWIFT_PACKAGE_DIR=\"${BUILD_DIR%Build/*}SourcePackages/artifacts\"\nSWIFTLINT_CMD=\"$SWIFT_PACKAGE_DIR/swiftlintplugins/SwiftLintBinary/SwiftLintBinary.artifactbundle/macos/swiftlint\"\n\nif test -f \"$SWIFTLINT_CMD\" 2>&1\nthen\n    \"$SWIFTLINT_CMD\"\nelse\n    echo \"warning: `swiftlint` command not found - See https://github.com/realm/SwiftLint#xcode-run-script-build-phase for installation instructions.\"\nfi\n```\n\n> [!NOTE]\n> The `SWIFTLINT_CMD` path uses the default Xcode configuration and has been\n> tested on Xcode 15/16. In case of another configuration (e.g. a custom\n> Swift package path), please adapt the values accordingly.\n<!-- markdownlint-disable MD028 -->\n> [!TIP]\n> Uncheck `Based on dependency analysis` to run `swiftlint` on all incremental\n> builds, suppressing the unspecified outputs warning.\n\n#### Consideration for Xcode 15.0\n\nXcode 15 made a significant change by setting the default value of the\n`ENABLE_USER_SCRIPT_SANDBOXING` build setting from `NO` to `YES`.\nAs a result, SwiftLint encounters an error related to missing file permissions,\nwhich typically manifests as\n`error: Sandbox: swiftlint(19427) deny(1) file-read-data.`\n\nTo resolve this issue, it is necessary to manually set the\n`ENABLE_USER_SCRIPT_SANDBOXING` setting to `NO` for the specific target that\nSwiftLint is being configured for.\n\n#### Consideration for Apple Silicon\n\nIf you installed SwiftLint via Homebrew on Apple Silicon, you might experience\nthis warning:\n\n```bash\nwarning: SwiftLint not installed, download from https://github.com/realm/SwiftLint\n```\n\nThat is because Homebrew on Apple Silicon installs the binaries into the\n`/opt/homebrew/bin` folder by default. To instruct Xcode where to find\nSwiftLint, you can either add `/opt/homebrew/bin` to the `PATH` environment\nvariable in your build phase:\n\n```bash\nif [[ \"$(uname -m)\" == arm64 ]]\nthen\n    export PATH=\"/opt/homebrew/bin:$PATH\"\nfi\n\nif command -v swiftlint >/dev/null 2>&1\nthen\n    swiftlint\nelse\n    echo \"warning: `swiftlint` command not found - See https://github.com/realm/SwiftLint#installation for installation instructions.\"\nfi\n```\n\nor you can create a symbolic link in `/usr/local/bin` pointing to the actual\nbinary:\n\n```bash\nln -s /opt/homebrew/bin/swiftlint /usr/local/bin/swiftlint\n```\n\n#### Additional Considerations\n\nIf you wish to fix violations as well, your script could run\n`swiftlint --fix && swiftlint` instead of just `swiftlint`. This will mean\nthat all correctable violations are fixed while ensuring warnings show up in\nyour project for remaining violations.\n\nIf you've installed SwiftLint via CocoaPods the script should look like this:\n\n```bash\n\"${PODS_ROOT}/SwiftLint/swiftlint\"\n```\n\n### Visual Studio Code\n\nTo integrate SwiftLint with [Visual Studio Code](https://code.visualstudio.com), install the\n[`vscode-swiftlint`](https://marketplace.visualstudio.com/items?itemName=vknabel.vscode-swiftlint)\nextension from the marketplace.\n\n### Fastlane\n\nYou can use the official\n[`swiftlint` fastlane action](https://docs.fastlane.tools/actions/swiftlint)\nto run SwiftLint as part of your fastlane process.\n\n```ruby\nswiftlint(\n    mode: :lint,                            # SwiftLint mode: :lint (default) or :autocorrect\n    executable: \"Pods/SwiftLint/swiftlint\", # The SwiftLint binary path (optional). Important if you've installed it via CocoaPods\n    path: \"/path/to/lint\",                  # Specify path to lint (optional)\n    output_file: \"swiftlint.result.json\",   # The path of the output file (optional)\n    reporter: \"json\",                       # The custom reporter to use (optional)\n    config_file: \".swiftlint-ci.yml\",       # The path of the configuration file (optional)\n    files: [                                # List of files to process (optional)\n        \"AppDelegate.swift\",\n        \"path/to/project/Model.swift\"\n    ],\n    ignore_exit_status: true,               # Allow fastlane to continue even if SwiftLint returns a non-zero exit status (Default: false)\n    quiet: true,                            # Don't print status logs like 'Linting ' & 'Done linting' (Default: false)\n    strict: true                            # Fail on warnings? (Default: false)\n)\n```\n\n### Docker\n\nSwiftLint is also available as a [Docker](https://www.docker.com/) image using\n`Ubuntu`. So just the first time you need to pull the docker image using the\nnext command:\n\n```bash\ndocker pull ghcr.io/realm/swiftlint:latest\n```\n\nThen following times, you just run `swiftlint` inside of the docker like:\n\n```bash\ndocker run -it -v `pwd`:`pwd` -w `pwd` ghcr.io/realm/swiftlint:latest\n```\n\nThis will execute `swiftlint` in the folder where you are right now (`pwd`),\nshowing an output like:\n\n```bash\n$ docker run -it -v `pwd`:`pwd` -w `pwd` ghcr.io/realm/swiftlint:latest\nLinting Swift files in current working directory\nLinting 'RuleDocumentation.swift' (1/490)\n...\nLinting 'YamlSwiftLintTests.swift' (490/490)\nDone linting! Found 0 violations, 0 serious in 490 files.\n```\n\nHere you have more documentation about the usage of\n[Docker Images](https://docs.docker.com/).\n\n## Command Line Usage\n\n```txt\n$ swiftlint help\nOVERVIEW: A tool to enforce Swift style and conventions.\n\nUSAGE: swiftlint <subcommand>\n\nOPTIONS:\n  --version               Show the version.\n  -h, --help              Show help information.\n\nSUBCOMMANDS:\n  analyze                 Run analysis rules\n  docs                    Open SwiftLint documentation website in the default web browser\n  generate-docs           Generates markdown documentation for selected group of rules\n  lint (default)          Print lint warnings and errors\n  baseline                Operations on existing baselines\n  reporters               Display the list of reporters and their identifiers\n  rules                   Display the list of rules and their identifiers\n  version                 Display the current version of SwiftLint\n\n  See 'swiftlint help <subcommand>' for detailed help.\n```\n\nRun `swiftlint` in the directory containing the Swift files to lint. Directories\nwill be searched recursively.\n\nTo specify a list of files when using `lint` or `analyze`\n(like the list of files modified by Xcode specified by the\n[`ExtraBuildPhase`](https://github.com/norio-nomura/ExtraBuildPhase) Xcode\nplugin, or modified files in the working tree based on `git ls-files -m`), you\ncan do so by passing the option `--use-script-input-files` and setting the\nfollowing instance variables: `SCRIPT_INPUT_FILE_COUNT`\nand `SCRIPT_INPUT_FILE_0`, `SCRIPT_INPUT_FILE_1`, ...,\n`SCRIPT_INPUT_FILE_{SCRIPT_INPUT_FILE_COUNT - 1}`.\nSimilarly, files can be read from file lists by passing\nthe option `--use-script-input-file-lists` and setting the\nfollowing instance variables: `SCRIPT_INPUT_FILE_LIST_COUNT`\nand `SCRIPT_INPUT_FILE_LIST_0`, `SCRIPT_INPUT_FILE_LIST_1`, ...,\n`SCRIPT_INPUT_FILE_LIST_{SCRIPT_INPUT_FILE_LIST_COUNT - 1}`.\n\nThese are same environment variables set for input files to\n[custom Xcode script phases](http://indiestack.com/2014/12/speeding-up-custom-script-phases/).\n\n## Working With Multiple Swift Versions\n\nSwiftLint hooks into SourceKit so it continues working even as Swift evolves!\n\nThis also keeps SwiftLint lean, as it doesn't need to ship with a full Swift\ncompiler, it just communicates with the official one you already have installed\non your machine.\n\nYou should always run SwiftLint with the same toolchain you use to compile your\ncode.\n\nYou may want to override SwiftLint's default Swift toolchain if you have\nmultiple toolchains or Xcodes installed.\n\nHere's the order in which SwiftLint determines which Swift toolchain to use:\n\n* `$XCODE_DEFAULT_TOOLCHAIN_OVERRIDE`\n* `$TOOLCHAIN_DIR` or `$TOOLCHAINS`\n* `xcrun -find swift`\n* `/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n* `/Applications/Xcode-beta.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n* `~/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n* `~/Applications/Xcode-beta.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n\n`sourcekitd.framework` is expected to be found in the `usr/lib/` subdirectory of\nthe value passed in the paths above.\n\nYou may also set the `TOOLCHAINS` environment variable to the reverse-DNS\nnotation that identifies a Swift toolchain version:\n\n```shell\nTOOLCHAINS=com.apple.dt.toolchain.Swift_2_3 swiftlint --fix\n```\n\nOn Linux, SourceKit is expected to be located in\n`/usr/lib/libsourcekitdInProc.so` or specified by the `LINUX_SOURCEKIT_LIB_PATH`\nenvironment variable.\n\n## Git `pre-commit` Hook\n\nSwiftLint can be run as a [pre-commit](https://pre-commit.com/) hook.\nOnce [installed](https://pre-commit.com/#install), add this to the\n`.pre-commit-config.yaml` in the root of your repository:\n\n```yaml\nrepos:\n  - repo: https://github.com/realm/SwiftLint\n    rev: 0.57.1\n    hooks:\n      - id: swiftlint\n```\n\nAdjust `rev` to the SwiftLint version of your choice.  `pre-commit autoupdate`\ncan be used to update to the current version.\n\nSwiftLint can be configured using `entry` to apply fixes and fail on errors:\n\n```yaml\n-   repo: https://github.com/realm/SwiftLint\n    rev: 0.57.1\n    hooks:\n    -   id: swiftlint\n        entry: swiftlint --fix --strict\n```\n\n## Rules\n\nOver 200 rules are included in SwiftLint and the Swift community (that's you!)\ncontinues to contribute more over time.\n[Pull requests](https://github.com/realm/SwiftLint/blob/main/CONTRIBUTING.md)\nare encouraged.\n\nYou can find an updated list of rules and more information about them in the\n[Rule Directory](https://realm.github.io/SwiftLint/rule-directory.html).\n\nYou can also check the\n[Source/SwiftLintBuiltInRules/Rules](https://github.com/realm/SwiftLint/tree/main/Source/SwiftLintBuiltInRules/Rules)\ndirectory to see their implementation.\n\n### Opt-In Rules\n\n`opt_in_rules` are disabled by default (i.e., you have to explicitly enable them\nin your configuration file).\n\nGuidelines on when to mark a rule as opt-in:\n\n* A rule that can have many false positives (e.g. `empty_count`)\n* A rule that is too slow\n* A rule that is not general consensus or is only useful in some cases\n  (e.g. `force_unwrapping`)\n\n### Disable rules in code\n\nRules can be disabled with a comment inside a source file with the following\nformat:\n\n`// swiftlint:disable <rule1> [<rule2> <rule3>...]`\n\nThe rules will be disabled until the end of the file or until the linter sees a\nmatching enable comment:\n\n`// swiftlint:enable <rule1> [<rule2> <rule3>...]`\n\nFor example:\n\n```swift\n// swiftlint:disable colon\nlet noWarning :String = \"\" // No warning about colons immediately after variable names!\n// swiftlint:enable colon\nlet hasWarning :String = \"\" // Warning generated about colons immediately after variable names\n```\n\nIncluding the `all` keyword will disable all rules until the linter sees a\nmatching enable comment:\n\n`// swiftlint:disable all`\n`// swiftlint:enable all`\n\nFor example:\n\n```swift\n// swiftlint:disable all\nlet noWarning :String = \"\" // No warning about colons immediately after variable names!\nlet i = \"\" // Also no warning about short identifier names\n// swiftlint:enable all\nlet hasWarning :String = \"\" // Warning generated about colons immediately after variable names\nlet y = \"\" // Warning generated about short identifier names\n```\n\nIt's also possible to modify a `disable` or `enable` command by appending\n`:previous`, `:this` or `:next` for only applying the command to the previous,\nthis (current) or next line respectively.\n\nFor example:\n\n```swift\n// swiftlint:disable:next force_cast\nlet noWarning = NSNumber() as! Int\nlet hasWarning = NSNumber() as! Int\nlet noWarning2 = NSNumber() as! Int // swiftlint:disable:this force_cast\nlet noWarning3 = NSNumber() as! Int\n// swiftlint:disable:previous force_cast\n```\n\nRun `swiftlint rules` to print a list of all available rules and their\nidentifiers.\n\n### Configuration\n\nConfigure SwiftLint by adding a `.swiftlint.yml` file from the directory you'll\nrun SwiftLint from. The following parameters can be configured:\n\nRule inclusion:\n\n* `disabled_rules`: Disable rules from the default enabled set.\n* `opt_in_rules`: Enable rules that are not part of the default set. The\n   special `all` identifier will enable all opt in linter rules, except the ones\n   listed in `disabled_rules`.\n* `only_rules`: Only the rules specified in this list will be enabled.\n   Cannot be specified alongside `disabled_rules` or `opt_in_rules`.\n* `analyzer_rules`: This is an entirely separate list of rules that are only\n  run by the `analyze` command. All analyzer rules are opt-in, so this is the\n  only configurable rule list, there are no equivalents for `disabled_rules`\n  and `only_rules`. The special `all` identifier can also be used here to enable\n  all analyzer rules, except the ones listed in `disabled_rules`.\n\n```yaml\n# By default, SwiftLint uses a set of sensible default rules you can adjust:\ndisabled_rules: # rule identifiers turned on by default to exclude from running\n  - colon\n  - comma\n  - control_statement\nopt_in_rules: # some rules are turned off by default, so you need to opt-in\n  - empty_count # find all the available rules by running: `swiftlint rules`\n\n# Alternatively, specify all rules explicitly by uncommenting this option:\n# only_rules: # delete `disabled_rules` & `opt_in_rules` if using this\n#   - empty_parameters\n#   - vertical_whitespace\n\nanalyzer_rules: # rules run by `swiftlint analyze`\n  - explicit_self\n\n# Case-sensitive paths to include during linting. Directory paths supplied on the\n# command line will be ignored.\nincluded: \n  - Sources\nexcluded: # case-sensitive paths to ignore during linting. Takes precedence over `included`\n  - Carthage\n  - Pods\n  - Sources/ExcludedFolder\n  - Sources/ExcludedFile.swift\n  - Sources/*/ExcludedFile.swift # exclude files with a wildcard\n\n# If true, SwiftLint will not fail if no lintable files are found.\nallow_zero_lintable_files: false\n\n# If true, SwiftLint will treat all warnings as errors.\nstrict: false\n\n# If true, SwiftLint will treat all errors as warnings.\nlenient: false\n\n# The path to a baseline file, which will be used to filter out detected violations.\nbaseline: Baseline.json\n\n# The path to save detected violations to as a new baseline.\nwrite_baseline: Baseline.json\n\n# If true, SwiftLint will check for updates after linting or analyzing.\ncheck_for_updates: true\n\n# configurable rules can be customized from this configuration file\n# binary rules can set their severity level\nforce_cast: warning # implicitly\nforce_try:\n  severity: warning # explicitly\n# rules that have both warning and error levels, can set just the warning level\n# implicitly\nline_length: 110\n# they can set both implicitly with an array\ntype_body_length:\n  - 300 # warning\n  - 400 # error\n# or they can set both explicitly\nfile_length:\n  warning: 500\n  error: 1200\n# naming rules can set warnings/errors for min_length and max_length\n# additionally they can set excluded names\ntype_name:\n  min_length: 4 # only warning\n  max_length: # warning and error\n    warning: 40\n    error: 50\n  excluded: iPhone # excluded via string\n  allowed_symbols: [\"_\"] # these are allowed in type names\nidentifier_name:\n  min_length: # only min_length\n    error: 4 # only error\n  excluded: # excluded via string array\n    - id\n    - URL\n    - GlobalAPIKey\nreporter: \"xcode\" # reporter type (xcode, json, csv, checkstyle, codeclimate, junit, html, emoji, sonarqube, markdown, github-actions-logging, summary)\n```\n\nYou can also use environment variables in your configuration file,\nby using `${SOME_VARIABLE}` in a string.\n\n### Defining Custom Rules\n\nIn addition to the rules that the main SwiftLint project ships with, SwiftLint\ncan also run two types of custom rules that you can define yourself in your own\nprojects:\n\n#### 1. Swift Custom Rules\n\nThese rules are written the same way as the Swift-based rules that ship with\nSwiftLint so they're fast, accurate, can leverage SwiftSyntax, can be unit\ntested, and more.\n\nUsing these requires building SwiftLint with Bazel as described in\n[this video](https://vimeo.com/820572803) or its associated code in\n[github.com/jpsim/swiftlint-bazel-example](https://github.com/jpsim/swiftlint-bazel-example).\n\n#### 2. Regex Custom Rules\n\nYou can define custom regex-based rules in your configuration file using the\nfollowing syntax:\n\n```yaml\ncustom_rules:\n  pirates_beat_ninjas: # rule identifier\n    included:\n      - \".*\\\\.swift\" # regex that defines paths to include during linting. optional.\n    excluded:\n      - \".*Test\\\\.swift\" # regex that defines paths to exclude during linting. optional\n    name: \"Pirates Beat Ninjas\" # rule name. optional.\n    regex: \"([nN]inja)\" # matching pattern\n    capture_group: 0 # number of regex capture group to highlight the rule violation at. optional.\n    match_kinds: # SyntaxKinds to match. optional.\n      - comment\n      - identifier\n    message: \"Pirates are better than ninjas.\" # violation message. optional.\n    severity: error # violation severity. optional.\n  no_hiding_in_strings:\n    regex: \"([nN]inja)\"\n    match_kinds: string\n```\n\nThis is what the output would look like:\n\n![Custom violations highlighted in the Xcode editor](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/custom-rule.png)\n\nIt is important to note that the regular expression pattern is used with the\nflags `s` and `m` enabled, that is `.`\n[matches newlines](https://developer.apple.com/documentation/foundation/nsregularexpression/options/1412529-dotmatcheslineseparators)\nand `^`/`$`\n[match the start and end of lines](https://developer.apple.com/documentation/foundation/nsregularexpression/options/1408263-anchorsmatchlines),\nrespectively. If you do not want to have `.` match newlines, for example, the\nregex can be prepended by `(?-s)`.\n\nYou can filter the matches by providing one or more `match_kinds`, which will\nreject matches that include syntax kinds that are not present in this list. Here\nare all the possible syntax kinds:\n\n* `argument`\n* `attribute.builtin`\n* `attribute.id`\n* `buildconfig.id`\n* `buildconfig.keyword`\n* `comment`\n* `comment.mark`\n* `comment.url`\n* `doccomment`\n* `doccomment.field`\n* `identifier`\n* `keyword`\n* `number`\n* `objectliteral`\n* `parameter`\n* `placeholder`\n* `string`\n* `string_interpolation_anchor`\n* `typeidentifier`\n\nAll syntax kinds used in a snippet of Swift code can be extracted asking\n[SourceKitten](https://github.com/jpsim/SourceKitten). For example,\n`sourcekitten syntax --text \"struct S {}\"` delivers\n\n* `source.lang.swift.syntaxtype.keyword` for the `struct` keyword and\n* `source.lang.swift.syntaxtype.identifier` for its name `S`\n\nwhich match to `keyword` and `identifier` in the above list.\n\nIf using custom rules in combination with `only_rules`, you must include the\nliteral string `custom_rules` in the `only_rules` list:\n\n```yaml\nonly_rules:\n  - custom_rules\n\ncustom_rules:\n  no_hiding_in_strings:\n    regex: \"([nN]inja)\"\n    match_kinds: string\n```\n\nUnlike Swift custom rules, you can use official SwiftLint builds\n(e.g. from Homebrew) to run regex custom rules.\n\n### Auto-correct\n\nSwiftLint can automatically correct certain violations. Files on disk are\noverwritten with a corrected version.\n\nPlease make sure to have backups of these files before running\n`swiftlint --fix`, otherwise important data may be lost.\n\nStandard linting is disabled while correcting because of the high likelihood of\nviolations (or their offsets) being incorrect after modifying a file while\napplying corrections.\n\n### Analyze\n\nThe `swiftlint analyze` command can lint Swift files using the\nfull type-checked AST. The compiler log path containing the clean `swiftc` build\ncommand invocation (incremental builds will fail) must be passed to `analyze`\nvia the `--compiler-log-path` flag.\ne.g. `--compiler-log-path /path/to/xcodebuild.log`\n\nThis can be obtained by\n\n1. Cleaning DerivedData (incremental builds won't work with analyze)\n2. Running `xcodebuild -workspace {WORKSPACE}.xcworkspace -scheme {SCHEME} > xcodebuild.log`\n3. Running `swiftlint analyze --compiler-log-path xcodebuild.log`\n\nAnalyzer rules tend to be considerably slower than lint rules.\n\n## Using Multiple Configuration Files\n\nSwiftLint offers a variety of ways to include multiple configuration files.\nMultiple configuration files get merged into one single configuration that is\nthen applied just as a single configuration file would get applied.\n\nThere are quite a lot of use cases where using multiple configuration files\ncould be helpful:\n\nFor instance, one could use a team-wide shared SwiftLint configuration while\nallowing overrides in each project via a child configuration file.\n\nTeam-Wide Configuration:\n\n```yaml\ndisabled_rules:\n- force_cast\n```\n\nProject-Specific Configuration:\n\n```yaml\nopt_in_rules:\n- force_cast\n```\n\n### Child/Parent Configs (Locally)\n\nYou can specify a `child_config` and/or a `parent_config` reference within a\nconfiguration file. These references should be local paths relative to the\nfolder of the configuration file they are specified in. This even works\nrecursively, as long as there are no cycles and no ambiguities.\n\n**A child config is treated as a refinement and thus has a higher priority**,\nwhile a parent config is considered a base with lower priority in case of\nconflicts.\n\nHere's an example, assuming you have the following file structure:\n\n```txt\nProjectRoot\n    |_ .swiftlint.yml\n    |_ .swiftlint_refinement.yml\n    |_ Base\n        |_ .swiftlint_base.yml\n```\n\nTo include both the refinement and the base file, your `.swiftlint.yml` should\nlook like this:\n\n```yaml\nchild_config: .swiftlint_refinement.yml\nparent_config: Base/.swiftlint_base.yml\n```\n\nWhen merging parent and child configs, `included` and `excluded` configurations\nare processed carefully to account for differences in the directory location\nof the containing configuration files.\n\n### Child/Parent Configs (Remote)\n\nJust as you can provide local `child_config`/`parent_config` references,\ninstead of referencing local paths, you can just put urls that lead to\nconfiguration files. In order for SwiftLint to detect these remote references,\nthey must start with `http://` or `https://`.\n\nThe referenced remote configuration files may even recursively reference other\nremote configuration files, but aren't allowed to include local references.\n\nUsing a remote reference, your `.swiftlint.yml` could look like this:\n\n```yaml\nparent_config: https://myteamserver.com/our-base-swiftlint-config.yml\n```\n\nEvery time you run SwiftLint and have an Internet connection, SwiftLint tries\nto get a new version of every remote configuration that is referenced. If this\nrequest times out, a cached version is used if available. If there is no cached\nversion available, SwiftLint fails ‚Äì but no worries, a cached version should be\nthere once SwiftLint has run successfully at least once.\n\nIf needed, the timeouts for the remote configuration fetching can be specified\nmanually via the configuration file(s) using the\n`remote_timeout`/`remote_timeout_if_cached` specifiers. These values default\nto 2 seconds or 1 second, respectively.\n\n### Command Line\n\nInstead of just providing one configuration file when running SwiftLint via the\ncommand line, you can also pass a hierarchy, where the first configuration is\ntreated as a parent, while the last one is treated as the highest-priority\nchild.\n\nA simple example including just two configuration files looks like this:\n\n`swiftlint --config .swiftlint.yml --config .swiftlint_child.yml`\n\n### Nested Configurations\n\nIn addition to a main configuration (the `.swiftlint.yml` file in the root\nfolder), you can put other configuration files named `.swiftlint.yml` into the\ndirectory structure that then get merged as a child config, but only with an\neffect for those files that are within the same directory as the config or in a\ndeeper directory where there isn't another configuration file. In other words:\nNested configurations don't work recursively ‚Äì there's a maximum number of one\nnested configuration per file that may be applied in addition to the main\nconfiguration.\n\n`.swiftlint.yml` files are only considered as a nested configuration if they\nhave not been used to build the main configuration already (e. g. by having\nbeen referenced via something like `child_config: Folder/.swiftlint.yml`).\nAlso, `parent_config`/`child_config` specifications of nested configurations\nare getting ignored because there's no sense to that.\n\nIf one (or more) SwiftLint file(s) are explicitly specified via the `--config`\nparameter, that configuration will be treated as an override, no matter whether\nthere exist other `.swiftlint.yml` files somewhere within the directory.\n**So if you want to use nested configurations, you can't use the `--config`\nparameter.**\n\n## License\n\n[MIT licensed.](https://github.com/realm/SwiftLint/blob/main/LICENSE)\n\n## About\n\nSwiftLint is utterly maintained by volunteers contributing to its success\nentirely in their free time. As such, SwiftLint isn't a commercial product\nin any way.\n\nBe kind to the people maintaining SwiftLint as a hobby and accept that their\ntime is limited. Support them by contributing to the project, reporting issues,\nand helping others in the community.\n\nSpecial thanks go to [MacStadium](https://www.macstadium.com) for providing\nphysical Mac mini machines to run our performance tests.\n\n![MacStadium](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/macstadium.png)\n\nWe also thank Realm (now MongoDB) for their initial contributions and setup of\nthe project.\n",
      "stars_today": 2
    },
    {
      "id": 19438,
      "name": "ggplot2",
      "full_name": "tidyverse/ggplot2",
      "description": "An implementation of the Grammar of Graphics in R",
      "html_url": "https://github.com/tidyverse/ggplot2",
      "stars": 6858,
      "forks": 2118,
      "language": "R",
      "topics": [
        "data-visualisation",
        "r",
        "visualisation"
      ],
      "created_at": "2008-05-25T01:21:32Z",
      "updated_at": "2026-01-16T17:51:54Z",
      "pushed_at": "2025-12-18T13:22:01Z",
      "open_issues": 92,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# ggplot2 <a href=\"https://ggplot2.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" alt=\"ggplot2 website\" /></a>\n\n<!-- badges: start -->\n\n[![R-CMD-check](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml)\n[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/ggplot2)](https://cran.r-project.org/package=ggplot2)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/ggplot2/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/ggplot2)\n<!-- badges: end -->\n\n## Overview\n\nggplot2 is a system for declaratively creating graphics, based on [The\nGrammar of\nGraphics](https://link.springer.com/book/10.1007/0-387-28695-0). You\nprovide the data, tell ggplot2 how to map variables to aesthetics, what\ngraphical primitives to use, and it takes care of the details.\n\n## Installation\n\n``` r\n# The easiest way to get ggplot2 is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just ggplot2:\ninstall.packages(\"ggplot2\")\n\n# Or the development version from GitHub:\n# install.packages(\"pak\")\npak::pak(\"tidyverse/ggplot2\")\n```\n\n## Cheatsheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-visualization-cheatsheet-thumbs.png\" width=\"630\" height=\"252\" alt=\"ggplot2 cheatsheet\" /></a>\n\n## Usage\n\nIt‚Äôs hard to succinctly describe how ggplot2 works because it embodies a\ndeep philosophy of visualisation. However, in most cases you start with\n`ggplot()`, supply a dataset and aesthetic mapping (with `aes()`). You\nthen add on layers (like `geom_point()` or `geom_histogram()`), scales\n(like `scale_colour_brewer()`), faceting specifications (like\n`facet_wrap()`) and coordinate systems (like `coord_flip()`).\n\n``` r\nlibrary(ggplot2)\n\nggplot(mpg, aes(displ, hwy, colour = class)) +\n  geom_point()\n```\n\n<img src=\"man/figures/README-example-1.png\" alt=\"Scatterplot of engine displacement versus highway miles per gallon, for 234 cars coloured by 7 'types' of car. The displacement and miles per gallon are inversely correlated.\"  />\n\n## Lifecycle\n\n[![lifecycle](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n\nggplot2 is now 18 years old and is used by hundreds of thousands of\npeople to make millions of plots. That means, by-and-large, ggplot2\nitself changes relatively little. When we do make changes, they will be\ngenerally to add new functions or arguments rather than changing the\nbehaviour of existing functions, and if we do make changes to existing\nbehaviour we will do them for compelling reasons.\n\nIf you are looking for innovation, look to ggplot2‚Äôs rich ecosystem of\nextensions. See a community maintained list at\n<https://exts.ggplot2.tidyverse.org/gallery/>.\n\n## Learning ggplot2\n\nIf you are new to ggplot2 you are better off starting with a systematic\nintroduction, rather than trying to learn from reading individual\ndocumentation pages. Currently, there are several good places to start:\n\n1.  The [Data Visualization](https://r4ds.hadley.nz/data-visualize) and\n    [Communication](https://r4ds.hadley.nz/communication) chapters in [R\n    for Data Science](https://r4ds.hadley.nz). R for Data Science is\n    designed to give you a comprehensive introduction to the\n    [tidyverse](https://tidyverse.org/), and these two chapters will get\n    you up to speed with the essentials of ggplot2 as quickly as\n    possible.\n\n2.  If you‚Äôd like to take an online course, try [Data Visualization in R\n    With\n    ggplot2](https://learning.oreilly.com/videos/data-visualization-in/9781491963661/)\n    by Kara Woo.\n\n3.  If you‚Äôd like to follow a webinar, try [Plotting Anything with\n    ggplot2](https://youtu.be/h29g21z0a68) by Thomas Lin Pedersen.\n\n4.  If you want to dive into making common graphics as quickly as\n    possible, I recommend [The R Graphics\n    Cookbook](https://r-graphics.org) by Winston Chang. It provides a\n    set of recipes to solve common graphics problems.\n\n5.  If you‚Äôve mastered the basics and want to learn more, read [ggplot2:\n    Elegant Graphics for Data Analysis](https://ggplot2-book.org). It\n    describes the theoretical underpinnings of ggplot2 and shows you how\n    all the pieces fit together. This book helps you understand the\n    theory that underpins ggplot2, and will help you create new types of\n    graphics specifically tailored to your needs.\n\n6.  For articles about announcements and deep-dives you can visit the\n    [tidyverse blog](https://tidyverse.org/tags/ggplot2/).\n\n## Getting help\n\nThere are two main places to get help with ggplot2:\n\n1.  The [Posit Community](https://forum.posit.co/) (formerly RStudio\n    Community) is a friendly place to ask any questions about ggplot2.\n\n2.  [Stack\n    Overflow](https://stackoverflow.com/questions/tagged/ggplot2?sort=frequent&pageSize=50)\n    is a great source of answers to common ggplot2 questions. It is also\n    a great place to get help, once you have created a reproducible\n    example that illustrates your problem.\n",
      "stars_today": 2
    },
    {
      "id": 537233603,
      "name": "reth",
      "full_name": "paradigmxyz/reth",
      "description": "Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol, in Rust",
      "html_url": "https://github.com/paradigmxyz/reth",
      "stars": 5330,
      "forks": 2232,
      "language": "Rust",
      "topics": [
        "blockchain",
        "contributor-friendly",
        "distributed-systems",
        "ethereum",
        "execution-layer",
        "modular",
        "p2p",
        "rust"
      ],
      "created_at": "2022-09-15T23:05:57Z",
      "updated_at": "2026-01-17T00:42:43Z",
      "pushed_at": "2026-01-17T00:55:40Z",
      "open_issues": 449,
      "owner": {
        "login": "paradigmxyz",
        "avatar_url": "https://avatars.githubusercontent.com/u/97369466?v=4"
      },
      "readme": "# reth\n\n[![bench status](https://github.com/paradigmxyz/reth/actions/workflows/bench.yml/badge.svg)](https://github.com/paradigmxyz/reth/actions/workflows/bench.yml)\n[![CI status](https://github.com/paradigmxyz/reth/workflows/unit/badge.svg)][gh-ci]\n[![cargo-lint status](https://github.com/paradigmxyz/reth/actions/workflows/lint.yml/badge.svg)][gh-lint]\n[![Telegram Chat][tg-badge]][tg-url]\n\n**Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol**\n\n![](./assets/reth-prod.png)\n\n**[Install](https://paradigmxyz.github.io/reth/installation/installation.html)**\n| [User Docs](https://reth.rs)\n| [Developer Docs](./docs)\n| [Crate Docs](https://reth.rs/docs)\n\n[gh-ci]: https://github.com/paradigmxyz/reth/actions/workflows/unit.yml\n[gh-lint]: https://github.com/paradigmxyz/reth/actions/workflows/lint.yml\n[tg-badge]: https://img.shields.io/endpoint?color=neon&logo=telegram&label=chat&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Fparadigm%5Freth\n\n## What is Reth?\n\nReth (short for Rust Ethereum, [pronunciation](https://x.com/kelvinfichter/status/1597653609411268608)) is a new Ethereum full node implementation that is focused on being user-friendly, highly modular, as well as being fast and efficient. Reth is an Execution Layer (EL) and is compatible with all Ethereum Consensus Layer (CL) implementations that support the [Engine API](https://github.com/ethereum/execution-apis/tree/a0d03086564ab1838b462befbc083f873dcf0c0f/src/engine). It is originally built and driven forward by [Paradigm](https://paradigm.xyz/), and is licensed under the Apache and MIT licenses.\n\n## Goals\n\nAs a full Ethereum node, Reth allows users to connect to the Ethereum network and interact with the Ethereum blockchain. This includes sending and receiving transactions/logs/traces, as well as accessing and interacting with smart contracts. Building a successful Ethereum node requires creating a high-quality implementation that is both secure and efficient, as well as being easy to use on consumer hardware. It also requires building a strong community of contributors who can help support and improve the software.\n\nMore concretely, our goals are:\n\n1. **Modularity**: Every component of Reth is built to be used as a library: well-tested, heavily documented and benchmarked. We envision that developers will import the node's crates, mix and match, and innovate on top of them. Examples of such usage include but are not limited to spinning up standalone P2P networks, talking directly to a node's database, or \"unbundling\" the node into the components you need. To achieve that, we are licensing Reth under the Apache/MIT permissive license. You can learn more about the project's components [here](./docs/repo/layout.md).\n2. **Performance**: Reth aims to be fast, so we use Rust and the [Erigon staged-sync](https://erigon.substack.com/p/erigon-stage-sync-and-control-flows) node architecture. We also use our Ethereum libraries (including [Alloy](https://github.com/alloy-rs/alloy/) and [revm](https://github.com/bluealloy/revm/)) which we've battle-tested and optimized via [Foundry](https://github.com/foundry-rs/foundry/).\n3. **Free for anyone to use any way they want**: Reth is free open source software, built for the community, by the community. By licensing the software under the Apache/MIT license, we want developers to use it without being bound by business licenses, or having to think about the implications of GPL-like licenses.\n4. **Client Diversity**: The Ethereum protocol becomes more antifragile when no node implementation dominates. This ensures that if there's a software bug, the network does not finalize a bad block. By building a new client, we hope to contribute to Ethereum's antifragility.\n5. **Support as many EVM chains as possible**: We aspire that Reth can full-sync not only Ethereum, but also other chains like Optimism, Polygon, BNB Smart Chain, and more. If you're working on any of these projects, please reach out.\n6. **Configurability**: We want to solve for node operators that care about fast historical queries, but also for hobbyists who cannot operate on large hardware. We also want to support teams and individuals who want both sync from genesis and via \"fast sync\". We envision that Reth will be configurable enough and provide configurable \"profiles\" for the tradeoffs that each team faces.\n\n## Status\n\nReth is production ready, and suitable for usage in mission-critical environments such as staking or high-uptime services. We also actively recommend professional node operators to switch to Reth in production for performance and cost reasons in use cases where high performance with great margins is required such as RPC, MEV, Indexing, Simulations, and P2P activities.\n\nMore historical context below:\n\n-   We released 1.0 \"production-ready\" stable Reth in June 2024.\n    -   Reth completed an audit with [Sigma Prime](https://sigmaprime.io/), the developers of [Lighthouse](https://github.com/sigp/lighthouse), the Rust Consensus Layer implementation. Find it [here](./audit/sigma_prime_audit_v2.pdf).\n    -   Revm (the EVM used in Reth) underwent an audit with [Guido Vranken](https://x.com/guidovranken) (#1 [Ethereum Bug Bounty](https://ethereum.org/en/bug-bounty)). We will publish the results soon.\n-   We released multiple iterative beta versions, up to [beta.9](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.9) on Monday June 3, 2024, the last beta release.\n-   We released [beta](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) on Monday March 4, 2024, our first breaking change to the database model, providing faster query speed, smaller database footprint, and allowing \"history\" to be mounted on separate drives.\n-   We shipped iterative improvements until the last alpha release on February 28, 2024, [0.1.0-alpha.21](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.21).\n-   We [initially announced](https://www.paradigm.xyz/2023/06/reth-alpha) [0.1.0-alpha.1](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.1) on June 20, 2023.\n\n### Database compatibility\n\nWe do not have any breaking database changes since beta.1, and we do not plan any in the near future.\n\nReth [v0.2.0-beta.1](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) includes\na [set of breaking database changes](https://github.com/paradigmxyz/reth/pull/5191) that makes it impossible to use database files produced by earlier versions.\n\nIf you had a database produced by alpha versions of Reth, you need to drop it with `reth db drop`\n(using the same arguments such as `--config` or `--datadir` that you passed to `reth node`), and resync using the same `reth node` command you've used before.\n\n## For Users\n\nSee the [Reth documentation](https://reth.rs/) for instructions on how to install and run Reth.\n\n## For Developers\n\n### Using reth as a library\n\nYou can use individual crates of reth in your project.\n\nThe crate docs can be found [here](https://reth.rs/docs/).\n\nFor a general overview of the crates, see [Project Layout](./docs/repo/layout.md).\n\n### Contributing\n\nIf you want to contribute, or follow along with contributor discussion, you can use our [main telegram](https://t.me/paradigm_reth) to chat with us about the development of Reth!\n\n-   Our contributor guidelines can be found in [`CONTRIBUTING.md`](./CONTRIBUTING.md).\n-   See our [contributor docs](./docs) for more information on the project. A good starting point is [Project Layout](./docs/repo/layout.md).\n\n### Building and testing\n\n<!--\nWhen updating this, also update:\n- Cargo.toml\n- .github/workflows/lint.yml\n-->\n\nThe Minimum Supported Rust Version (MSRV) of this project is [1.88.0](https://blog.rust-lang.org/2025/06/26/Rust-1.88.0/).\n\nSee the docs for detailed instructions on how to [build from source](https://reth.rs/installation/source/).\n\nTo fully test Reth, you will need to have [Geth installed](https://geth.ethereum.org/docs/getting-started/installing-geth), but it is possible to run a subset of tests without Geth.\n\nFirst, clone the repository:\n\n```sh\ngit clone https://github.com/paradigmxyz/reth\ncd reth\n```\n\nNext, run the tests:\n\n```sh\ncargo nextest run --workspace\n\n# Run the Ethereum Foundation tests\nmake ef-tests\n```\n\nWe highly recommend using [`cargo nextest`](https://nexte.st/) to speed up testing.\nUsing `cargo test` to run tests may work fine, but this is not tested and does not support more advanced features like retries for spurious failures.\n\n> **Note**\n>\n> Some tests use random number generators to generate test data. If you want to use a deterministic seed, you can set the `SEED` environment variable.\n\n## Getting Help\n\nIf you have any questions, first see if the answer to your question can be found in the [docs][book].\n\nIf the answer is not there:\n\n-   Join the [Telegram][tg-url] to get help, or\n-   Open a [discussion](https://github.com/paradigmxyz/reth/discussions/new) with your question, or\n-   Open an issue with [the bug](https://github.com/paradigmxyz/reth/issues/new?assignees=&labels=C-bug%2CS-needs-triage&projects=&template=bug.yml)\n\n## Security\n\nSee [`SECURITY.md`](./SECURITY.md).\n\n## Acknowledgements\n\nReth is a new implementation of the Ethereum protocol. In the process of developing the node we investigated the design decisions other nodes have made to understand what is done well, what is not, and where we can improve the status quo.\n\nNone of this would have been possible without them, so big shoutout to the teams below:\n\n-   [Geth](https://github.com/ethereum/go-ethereum/): We would like to express our heartfelt gratitude to the go-ethereum team for their outstanding contributions to Ethereum over the years. Their tireless efforts and dedication have helped to shape the Ethereum ecosystem and make it the vibrant and innovative community it is today. Thank you for your hard work and commitment to the project.\n-   [Erigon](https://github.com/ledgerwatch/erigon) (fka Turbo-Geth): Erigon pioneered the [\"Staged Sync\" architecture](https://erigon.substack.com/p/erigon-stage-sync-and-control-flows) that Reth is using, as well as [introduced MDBX](https://github.com/ledgerwatch/erigon/wiki/Choice-of-storage-engine) as the database of choice. We thank Erigon for pushing the state of the art research on the performance limits of Ethereum nodes.\n-   [Akula](https://github.com/akula-bft/akula/): Reth uses forks of the Apache versions of Akula's [MDBX Bindings](https://github.com/paradigmxyz/reth/pull/132), [FastRLP](https://github.com/paradigmxyz/reth/pull/63) and [ECIES](https://github.com/paradigmxyz/reth/pull/80). Given that these packages were already released under the Apache License, and they implement standardized solutions, we decided not to reimplement them to iterate faster. We thank the Akula team for their contributions to the Rust Ethereum ecosystem and for publishing these packages.\n\n## Warning\n\nThe `NippyJar` and `Compact` encoding formats and their implementations are designed for storing and retrieving data internally. They are not hardened to safely read potentially malicious data.\n\n[book]: https://reth.rs/\n[tg-url]: https://t.me/paradigm_reth\n",
      "stars_today": 2
    },
    {
      "id": 38304949,
      "name": "GRDB.swift",
      "full_name": "groue/GRDB.swift",
      "description": "A toolkit for SQLite databases, with a focus on application development",
      "html_url": "https://github.com/groue/GRDB.swift",
      "stars": 8106,
      "forks": 831,
      "language": "Swift",
      "topics": [
        "database",
        "database-observation",
        "grdb",
        "spm",
        "sql",
        "sql-builder",
        "sqlite",
        "sqlite-databases"
      ],
      "created_at": "2015-06-30T11:17:06Z",
      "updated_at": "2026-01-16T21:46:36Z",
      "pushed_at": "2026-01-16T12:18:54Z",
      "open_issues": 12,
      "owner": {
        "login": "groue",
        "avatar_url": "https://avatars.githubusercontent.com/u/54219?v=4"
      },
      "readme": "<picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB~dark.png\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB.png\">\n    <img alt=\"GRDB: A toolkit for SQLite databases, with a focus on application development.\" src=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB.png\">\n</picture>\n\n<p align=\"center\">\n    <strong>A toolkit for SQLite databases, with a focus on application development</strong><br>\n    Proudly serving the community since 2015\n</p>\n\n<p align=\"center\">\n    <a href=\"https://developer.apple.com/swift/\"><img alt=\"Swift 6.1\" src=\"https://img.shields.io/badge/swift-6.1-orange.svg?style=flat\"></a>\n    <a href=\"https://github.com/groue/GRDB.swift/blob/master/LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/github/license/groue/GRDB.swift.svg?maxAge=2592000\"></a>\n    <a href=\"https://github.com/groue/GRDB.swift/actions/workflows/CI.yml\"><img alt=\"CI Status\" src=\"https://github.com/groue/GRDB.swift/actions/workflows/CI.yml/badge.svg?branch=master\"></a>\n</p>\n\n**Latest release**: December 13, 2025 ‚Ä¢ [version 7.9.0](https://github.com/groue/GRDB.swift/tree/v7.9.0) ‚Ä¢ [CHANGELOG](CHANGELOG.md) ‚Ä¢ [Migrating From GRDB 6 to GRDB 7](Documentation/GRDB7MigrationGuide.md)\n\n**Requirements**: iOS 13.0+ / macOS 10.15+ / tvOS 13.0+ / watchOS 7.0+ &bull; SQLite 3.20.0+ &bull; Swift 6.1+ / Xcode 16.3+\n\n**Contact**:\n\n- Release announcements and usage tips: follow [@groue@hachyderm.io](https://hachyderm.io/@groue) on Mastodon.\n- Report bugs in a [Github issue](https://github.com/groue/GRDB.swift/issues/new). Make sure you check the [existing issues](https://github.com/groue/GRDB.swift/issues?q=is%3Aopen) first.\n- A question? Looking for advice? Do you wonder how to contribute? Fancy a chat? Go to the [GitHub discussions](https://github.com/groue/GRDB.swift/discussions), or the [GRDB forums](https://forums.swift.org/c/related-projects/grdb).\n\n\n## What is GRDB?\n\nUse this library to save your application‚Äôs permanent data into SQLite databases. It comes with built-in tools that address common needs:\n\n- **SQL Generation**\n    \n    Enhance your application models with persistence and fetching methods, so that you don't have to deal with SQL and raw database rows when you don't want to.\n\n- **Database Observation**\n    \n    Get notifications when database values are modified. \n\n- **Robust Concurrency**\n    \n    Multi-threaded applications can efficiently use their databases, including WAL databases that support concurrent reads and writes. \n\n- **Migrations**\n    \n    Evolve the schema of your database as you ship new versions of your application.\n    \n- **Leverage your SQLite skills**\n\n    Not all developers need advanced SQLite features. But when you do, GRDB is as sharp as you want it to be. Come with your SQL and SQLite skills, or learn new ones as you go!\n\n---\n\n<p align=\"center\">\n    <a href=\"#usage\">Usage</a> &bull;\n    <a href=\"#documentation\">Documentation</a> &bull;\n    <a href=\"#installation\">Installation</a> &bull;\n    <a href=\"#faq\">FAQ</a>\n</p>\n\n---\n\n## Usage\n\n<details open>\n  <summary>Start using the database in four steps</summary>\n\n```swift\nimport GRDB\n\n// 1. Open a database connection\nlet dbQueue = try DatabaseQueue(path: \"/path/to/database.sqlite\")\n\n// 2. Define the database schema\ntry dbQueue.write { db in\n    try db.create(table: \"player\") { t in\n        t.primaryKey(\"id\", .text)\n        t.column(\"name\", .text).notNull()\n        t.column(\"score\", .integer).notNull()\n    }\n}\n\n// 3. Define a record type\nstruct Player: Codable, Identifiable, FetchableRecord, PersistableRecord {\n    var id: String\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// 4. Write and read in the database\ntry dbQueue.write { db in\n    try Player(id: \"1\", name: \"Arthur\", score: 100).insert(db)\n    try Player(id: \"2\", name: \"Barbara\", score: 1000).insert(db)\n}\n\ntry dbQueue.read { db in\n    let player = try Player.find(db, id: \"1\"))\n    \n    let bestPlayers = try Player\n        .order(\\.score.desc)\n        .limit(10)\n        .fetchAll(db)\n}\n```\n\n</details>\n\n<details>\n    <summary>Access to raw SQL</summary>\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player (\n          id TEXT PRIMARY KEY,\n          name TEXT NOT NULL,\n          score INT NOT NULL)\n        \"\"\")\n    \n    try db.execute(sql: \"\"\"\n        INSERT INTO player (id, name, score)\n        VALUES (?, ?, ?)\n        \"\"\", arguments: [\"1\", \"Arthur\", 100])\n    \n    // Avoid SQL injection with SQL interpolation\n    let id = \"2\"\n    let name = \"O'Brien\"\n    let score = 1000\n    try db.execute(literal: \"\"\"\n        INSERT INTO player (id, name, score)\n        VALUES (\\(id), \\(name), \\(score))\n        \"\"\")\n}\n```\n\nSee [Executing Updates](#executing-updates)\n\n</details>\n\n<details>\n    <summary>Access to raw database rows and values</summary>\n\n```swift\ntry dbQueue.read { db in\n    // Fetch database rows\n    let rows = try Row.fetchCursor(db, sql: \"SELECT * FROM player\")\n    while let row = try rows.next() {\n        let id: String = row[\"id\"]\n        let name: String = row[\"name\"]\n        let score: Int = row[\"score\"]\n    }\n    \n    // Fetch values\n    let playerCount = try Int.fetchOne(db, sql: \"SELECT COUNT(*) FROM player\")! // Int\n    let playerNames = try String.fetchAll(db, sql: \"SELECT name FROM player\") // [String]\n}\n\nlet playerCount = try dbQueue.read { db in\n    try Int.fetchOne(db, sql: \"SELECT COUNT(*) FROM player\")!\n}\n```\n\nSee [Fetch Queries](#fetch-queries)\n\n</details>\n\n<details>\n    <summary>Database model types aka \"records\"</summary>\n\n```swift\nstruct Player: Codable, Identifiable, FetchableRecord, PersistableRecord {\n    var id: String\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\ntry dbQueue.write { db in\n    // Create database table\n    try db.create(table: \"player\") { t in\n        t.primaryKey(\"id\", .text)\n        t.column(\"name\", .text).notNull()\n        t.column(\"score\", .integer).notNull()\n    }\n    \n    // Insert a record\n    var player = Player(id: \"1\", name: \"Arthur\", score: 100)\n    try player.insert(db)\n    \n    // Update a record\n    player.score += 10\n    try score.update(db)\n    \n    try player.updateChanges { $0.score += 10 }\n    \n    // Delete a record\n    try player.delete(db)\n}\n```\n\nSee [Records](#records)\n\n</details>\n\n<details>\n    <summary>Query the database with the Swift query interface</summary>\n\n```swift\ntry dbQueue.read { db in\n    // Player\n    let player = try Player.find(db, id: \"1\")\n    \n    // Player?\n    let arthur = try Player.filter { $0.name == \"Arthur\" }.fetchOne(db)\n    \n    // [Player]\n    let bestPlayers = try Player.order(\\.score.desc).limit(10).fetchAll(db)\n    \n    // Int\n    let playerCount = try Player.fetchCount(db)\n    \n    // SQL is always welcome\n    let players = try Player.fetchAll(db, sql: \"SELECT * FROM player\")\n}\n```\n\nSee the [Query Interface](#the-query-interface)\n\n</details>\n\n<details>\n    <summary>Database changes notifications</summary>\n\n```swift\n// Define the observed value\nlet observation = ValueObservation.tracking { db in\n    try Player.fetchAll(db)\n}\n\n// Start observation\nlet cancellable = observation.start(\n    in: dbQueue,\n    onError: { error in ... },\n    onChange: { (players: [Player]) in print(\"Fresh players: \\(players)\") })\n```\n\nReady-made support for Combine and RxSwift:\n\n```swift\n// Swift concurrency\nfor try await players in observation.values(in: dbQueue) {\n    print(\"Fresh players: \\(players)\")\n}\n\n// Combine\nlet cancellable = observation.publisher(in: dbQueue).sink(\n    receiveCompletion: { completion in ... },\n    receiveValue: { (players: [Player]) in print(\"Fresh players: \\(players)\") })\n\n// RxSwift\nlet disposable = observation.rx.observe(in: dbQueue).subscribe(\n    onNext: { (players: [Player]) in print(\"Fresh players: \\(players)\") },\n    onError: { error in ... })\n```\n\nSee [Database Observation], [Combine Support], [RxGRDB].\n\n</details>\n\nDocumentation\n=============\n\n**GRDB runs on top of SQLite**: you should get familiar with the [SQLite FAQ](http://www.sqlite.org/faq.html). For general and detailed information, jump to the [SQLite Documentation](http://www.sqlite.org/docs.html).\n\n\n#### Demo Applications & Frequently Asked Questions\n\n- [Demo Applications]\n- [FAQ]\n\n#### Reference\n\n- üìñ [GRDB Reference](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/)\n\n#### Getting Started\n\n- [Installation](#installation)\n- [Database Connections]: Connect to SQLite databases\n\n#### SQLite and SQL\n\n- [SQLite API](#sqlite-api): The low-level SQLite API &bull; [executing updates](#executing-updates) &bull; [fetch queries](#fetch-queries) &bull; [SQL Interpolation]\n\n#### Records and the Query Interface\n\n- [Records](#records): Fetching and persistence methods for your custom structs and class hierarchies\n- [Query Interface](#the-query-interface): A swift way to generate SQL &bull; [create tables, indexes, etc](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema) &bull; [requests](#requests) ‚Ä¢ [associations between record types](Documentation/AssociationsBasics.md)\n\n#### Application Tools\n\n- [Migrations]: Transform your database as your application evolves.\n- [Full-Text Search]: Perform efficient and customizable full-text searches.\n- [Database Observation]: Observe database changes and transactions.\n- [Encryption](#encryption): Encrypt your database with SQLCipher.\n- [Backup](#backup): Dump the content of a database to another.\n- [Interrupt a Database](#interrupt-a-database): Abort any pending database operation.\n- [Sharing a Database]: How to share an SQLite database between multiple processes - recommendations for App Group containers, App Extensions, App Sandbox, and file coordination.\n\n#### Good to Know\n\n- [Concurrency]: How to access databases in a multi-threaded application.\n- [Combine](Documentation/Combine.md): Access and observe the database with Combine publishers.\n- [Avoiding SQL Injection](#avoiding-sql-injection)\n- [Error Handling](#error-handling)\n- [Unicode](#unicode)\n- [Memory Management](#memory-management)\n- [Data Protection](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections)\n- :bulb: [Migrating From GRDB 6 to GRDB 7](Documentation/GRDB7MigrationGuide.md)\n- :bulb: [Why Adopt GRDB?](Documentation/WhyAdoptGRDB.md)\n- :bulb: [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices)\n\n#### Companion Libraries\n\n- [GRDBQuery](https://github.com/groue/GRDBQuery): Access and observe the database from your SwiftUI views.\n- [GRDBSnapshotTesting](https://github.com/groue/GRDBSnapshotTesting): Test your database. \n\n**[FAQ]**\n\n**[Sample Code](#sample-code)**\n\n\nInstallation\n============\n\n**The installation procedures below have GRDB use the version of SQLite that ships with the target operating system.**\n\nSee [Encryption](#encryption) for the installation procedure of GRDB with SQLCipher.\n\nSee [Custom SQLite builds](Documentation/CustomSQLiteBuilds.md) for the installation procedure of GRDB with a customized build of SQLite.\n\n\n## Swift Package Manager\n\nThe [Swift Package Manager](https://swift.org/package-manager/) automates the distribution of Swift code. To use GRDB with SPM, add a dependency to `https://github.com/groue/GRDB.swift.git`\n\nGRDB offers two libraries, `GRDB` and `GRDB-dynamic`. Pick only one. When in doubt, prefer `GRDB`. The `GRDB-dynamic` library can reveal useful if you are going to link it with multiple targets within your app and only wish to link to a shared, dynamic framework once. See [How to link a Swift Package as dynamic](https://forums.swift.org/t/how-to-link-a-swift-package-as-dynamic/32062) for more information.\n\n> **Note**: Linux support is provided by contributors. It is not automatically tested, and not officially maintained. If you notice a build or runtime failure on Linux, please open a pull request with the necessary fix, thank you!\n\n\n## CocoaPods\n\n[CocoaPods](http://cocoapods.org/) is a dependency manager for Xcode projects. To use GRDB with CocoaPods (version 1.2 or higher), specify in your `Podfile`:\n\n```ruby\npod 'GRDB.swift'\n```\n\nGRDB can be installed as a framework, or a static library.\n\n**Important Note for CocoaPods installation**\n\nDue to an [issue](https://github.com/CocoaPods/CocoaPods/issues/11839) in CocoaPods, it is currently not possible to deploy new versions of GRDB to CocoaPods. The last version available on CocoaPods is 6.24.1. To install later versions of GRDB using CocoaPods, use one of the following workarounds:\n\n- Depend on the `GRDB7` branch. This is more or less equivalent to what `pod 'GRDB.swift', '~> 7.0'` would normally do, if CocoaPods would accept new GRDB versions to be published:\n\n    ```ruby\n    # Can't use semantic versioning due to https://github.com/CocoaPods/CocoaPods/issues/11839\n    pod 'GRDB.swift', git: 'https://github.com/groue/GRDB.swift.git', branch: 'GRDB7'\n    ```\n\n- Depend on a specific version explicitly (Replace the tag with the version you want to use):\n\n    ```ruby\n    # Can't use semantic versioning due to https://github.com/CocoaPods/CocoaPods/issues/11839\n    # Replace the tag with the tag that you want to use.\n    pod 'GRDB.swift', git: 'https://github.com/groue/GRDB.swift.git', tag: 'v6.29.0' \n    ```\n\n## Carthage\n\n[Carthage](https://github.com/Carthage/Carthage) is **unsupported**. For some context about this decision, see [#433](https://github.com/groue/GRDB.swift/issues/433).\n\n\n## Manually\n\n1. [Download](https://github.com/groue/GRDB.swift/releases) a copy of GRDB, or clone its repository and make sure you checkout the latest tagged version.\n\n2. Embed the `GRDB.xcodeproj` project in your own project.\n\n3. Add the `GRDB` target in the **Target Dependencies** section of the **Build Phases** tab of your application target (extension target for WatchOS).\n\n4. Add the `GRDB.framework` to the **Embedded Binaries** section of the **General**  tab of your application target (extension target for WatchOS).\n\n\nDatabase Connections\n====================\n\nGRDB provides two classes for accessing SQLite databases: [`DatabaseQueue`] and [`DatabasePool`]:\n\n```swift\nimport GRDB\n\n// Pick one:\nlet dbQueue = try DatabaseQueue(path: \"/path/to/database.sqlite\")\nlet dbPool = try DatabasePool(path: \"/path/to/database.sqlite\")\n```\n\nThe differences are:\n\n- Database pools allow concurrent database accesses (this can improve the performance of multithreaded applications).\n- Database pools open your SQLite database in the [WAL mode](https://www.sqlite.org/wal.html) (unless read-only).\n- Database queues support [in-memory databases](https://www.sqlite.org/inmemorydb.html).\n\n**If you are not sure, choose [`DatabaseQueue`].** You will always be able to switch to [`DatabasePool`] later.\n\nFor more information and tips when opening connections, see [Database Connections](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections).\n\n\nSQLite API\n==========\n\n**In this section of the documentation, we will talk SQL.** Jump to the [query interface](#the-query-interface) if SQL is not your cup of tea.\n\n- [Executing Updates](#executing-updates)\n- [Fetch Queries](#fetch-queries)\n    - [Fetching Methods](#fetching-methods)\n    - [Row Queries](#row-queries)\n    - [Value Queries](#value-queries)\n- [Values](#values)\n    - [Data](#data-and-memory-savings)\n    - [Date and DateComponents](#date-and-datecomponents)\n    - [NSNumber, NSDecimalNumber, and Decimal](#nsnumber-nsdecimalnumber-and-decimal)\n    - [Swift enums](#swift-enums)\n    - [`DatabaseValueConvertible`]: the protocol for custom value types\n- [Transactions and Savepoints]\n- [SQL Interpolation]\n\nAdvanced topics:\n\n- [Prepared Statements]\n- [Custom SQL Functions and Aggregates](#custom-sql-functions-and-aggregates)\n- [Database Schema Introspection](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschemaintrospection)\n- [Row Adapters](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter)\n- [Raw SQLite Pointers](#raw-sqlite-pointers)\n\n\n## Executing Updates\n\nOnce granted with a [database connection], the [`execute(sql:arguments:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/execute(sql:arguments:)) method executes the SQL statements that do not return any database row, such as `CREATE TABLE`, `INSERT`, `DELETE`, `ALTER`, etc.\n\nFor example:\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            name TEXT NOT NULL,\n            score INT)\n        \"\"\")\n    \n    try db.execute(\n        sql: \"INSERT INTO player (name, score) VALUES (?, ?)\",\n        arguments: [\"Barbara\", 1000])\n    \n    try db.execute(\n        sql: \"UPDATE player SET score = :score WHERE id = :id\",\n        arguments: [\"score\": 1000, \"id\": 1])\n    }\n}\n```\n\nThe `?` and colon-prefixed keys like `:score` in the SQL query are the **statements arguments**. You pass arguments with arrays or dictionaries, as in the example above. See [Values](#values) for more information on supported arguments types (Bool, Int, String, Date, Swift enums, etc.), and [`StatementArguments`] for a detailed documentation of SQLite arguments.\n\nYou can also embed query arguments right into your SQL queries, with [`execute(literal:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/execute(literal:)), as in the example below. See [SQL Interpolation] for more details.\n\n```swift\ntry dbQueue.write { db in\n    let name = \"O'Brien\"\n    let score = 550\n    try db.execute(literal: \"\"\"\n        INSERT INTO player (name, score) VALUES (\\(name), \\(score))\n        \"\"\")\n}\n```\n\n**Never ever embed values directly in your raw SQL strings**. See [Avoiding SQL Injection](#avoiding-sql-injection) for more information:\n\n```swift\n// WRONG: don't embed values in raw SQL strings\nlet id = 123\nlet name = textField.text\ntry db.execute(\n    sql: \"UPDATE player SET name = '\\(name)' WHERE id = \\(id)\")\n\n// CORRECT: use arguments dictionary\ntry db.execute(\n    sql: \"UPDATE player SET name = :name WHERE id = :id\",\n    arguments: [\"name\": name, \"id\": id])\n\n// CORRECT: use arguments array\ntry db.execute(\n    sql: \"UPDATE player SET name = ? WHERE id = ?\",\n    arguments: [name, id])\n\n// CORRECT: use SQL Interpolation\ntry db.execute(\n    literal: \"UPDATE player SET name = \\(name) WHERE id = \\(id)\")\n```\n\n**Join multiple statements with a semicolon**:\n\n```swift\ntry db.execute(sql: \"\"\"\n    INSERT INTO player (name, score) VALUES (?, ?);\n    INSERT INTO player (name, score) VALUES (?, ?);\n    \"\"\", arguments: [\"Arthur\", 750, \"Barbara\", 1000])\n\ntry db.execute(literal: \"\"\"\n    INSERT INTO player (name, score) VALUES (\\(\"Arthur\"), \\(750));\n    INSERT INTO player (name, score) VALUES (\\(\"Barbara\"), \\(1000));\n    \"\"\")\n```\n\nWhen you want to make sure that a single statement is executed, use a prepared [`Statement`].\n\n**After an INSERT statement**, you can get the row ID of the inserted row with [`lastInsertedRowID`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/lastinsertedrowid):\n\n```swift\ntry db.execute(\n    sql: \"INSERT INTO player (name, score) VALUES (?, ?)\",\n    arguments: [\"Arthur\", 1000])\nlet playerId = db.lastInsertedRowID\n```\n\nDon't miss [Records](#records), that provide classic **persistence methods**:\n\n```swift\nvar player = Player(name: \"Arthur\", score: 1000)\ntry player.insert(db)\nlet playerId = player.id\n```\n\n\n## Fetch Queries\n\n[Database connections] let you fetch database rows, plain values, and custom models aka \"records\".\n\n**Rows** are the raw results of SQL queries:\n\n```swift\ntry dbQueue.read { db in\n    if let row = try Row.fetchOne(db, sql: \"SELECT * FROM wine WHERE id = ?\", arguments: [1]) {\n        let name: String = row[\"name\"]\n        let color: Color = row[\"color\"]\n        print(name, color)\n    }\n}\n```\n\n\n**Values** are the Bool, Int, String, Date, Swift enums, etc. stored in row columns:\n\n```swift\ntry dbQueue.read { db in\n    let urls = try URL.fetchCursor(db, sql: \"SELECT url FROM wine\")\n    while let url = try urls.next() {\n        print(url)\n    }\n}\n```\n\n\n**Records** are your application objects that can initialize themselves from rows:\n\n```swift\nlet wines = try dbQueue.read { db in\n    try Wine.fetchAll(db, sql: \"SELECT * FROM wine\")\n}\n```\n\n- [Fetching Methods](#fetching-methods) and [Cursors](#cursors)\n- [Row Queries](#row-queries)\n- [Value Queries](#value-queries)\n- [Records](#records)\n\n\n### Fetching Methods\n\n**Throughout GRDB**, you can always fetch *cursors*, *arrays*, *sets*, or *single values* of any fetchable type (database [row](#row-queries), simple [value](#value-queries), or custom [record](#records)):\n\n```swift\ntry Row.fetchCursor(...) // A Cursor of Row\ntry Row.fetchAll(...)    // [Row]\ntry Row.fetchSet(...)    // Set<Row>\ntry Row.fetchOne(...)    // Row?\n```\n\n- `fetchCursor` returns a **[cursor](#cursors)** over fetched values:\n    \n    ```swift\n    let rows = try Row.fetchCursor(db, sql: \"SELECT ...\") // A Cursor of Row\n    ```\n    \n- `fetchAll` returns an **array**:\n    \n    ```swift\n    let players = try Player.fetchAll(db, sql: \"SELECT ...\") // [Player]\n    ```\n\n- `fetchSet` returns a **set**:\n    \n    ```swift\n    let names = try String.fetchSet(db, sql: \"SELECT ...\") // Set<String>\n    ```\n\n- `fetchOne` returns a **single optional value**, and consumes a single database row (if any).\n    \n    ```swift\n    let count = try Int.fetchOne(db, sql: \"SELECT COUNT(*) ...\") // Int?\n    ```\n\n**All those fetching methods require an SQL string that contains a single SQL statement.** When you want to fetch from multiple statements joined with a semicolon, iterate the multiple [prepared statements] found in the SQL string.\n\n### Cursors\n\nüìñ [`Cursor`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/cursor)\n\n**Whenever you consume several rows from the database, you can fetch an Array, a Set, or a Cursor**.\n\nThe `fetchAll()` and `fetchSet()` methods return regular Swift array and sets, that you iterate like all other arrays and sets:\n\n```swift\ntry dbQueue.read { db in\n    // [Player]\n    let players = try Player.fetchAll(db, sql: \"SELECT ...\")\n    for player in players {\n        // use player\n    }\n}\n```\n\nUnlike arrays and sets, cursors returned by `fetchCursor()` load their results step after step:\n\n```swift\ntry dbQueue.read { db in\n    // Cursor of Player\n    let players = try Player.fetchCursor(db, sql: \"SELECT ...\")\n    while let player = try players.next() {\n        // use player\n    }\n}\n```\n\n- **Cursors can not be used on any thread**: you must consume a cursor on the dispatch queue it was created in. Particularly, don't extract a cursor out of a database access method:\n    \n    ```swift\n    // Wrong\n    let cursor = try dbQueue.read { db in\n        try Player.fetchCursor(db, ...)\n    }\n    while let player = try cursor.next() { ... }\n    ```\n    \n    Conversely, arrays and sets may be consumed on any thread:\n    \n    ```swift\n    // OK\n    let array = try dbQueue.read { db in\n        try Player.fetchAll(db, ...)\n    }\n    for player in array { ... }\n    ```\n    \n- **Cursors can be iterated only one time.** Arrays and sets can be iterated many times.\n\n- **Cursors iterate database results in a lazy fashion**, and don't consume much memory. Arrays and sets contain copies of database values, and may take a lot of memory when there are many fetched results.\n\n- **Cursors are granted with direct access to SQLite,** unlike arrays and sets that have to take the time to copy database values. If you look after extra performance, you may prefer cursors.\n\n- **Cursors can feed Swift collections.**\n    \n    You will most of the time use `fetchAll` or `fetchSet` when you want an array or a set. For more specific needs, you may prefer one of the initializers below. All of them accept an extra optional `minimumCapacity` argument which helps optimizing your app when you have an idea of the number of elements in a cursor (the built-in `fetchAll` and `fetchSet` do not perform such an optimization).\n    \n    **Arrays** and all types conforming to `RangeReplaceableCollection`:\n    \n    ```swift\n    // [String]\n    let cursor = try String.fetchCursor(db, ...)\n    let array = try Array(cursor)\n    ```\n    \n    **Sets**:\n    \n    ```swift\n    // Set<Int>\n    let cursor = try Int.fetchCursor(db, ...)\n    let set = try Set(cursor)\n    ```\n    \n    **Dictionaries**:\n    \n    ```swift\n    // [Int64: [Player]]\n    let cursor = try Player.fetchCursor(db)\n    let dictionary = try Dictionary(grouping: cursor, by: { $0.teamID })\n    \n    // [Int64: Player]\n    let cursor = try Player.fetchCursor(db).map { ($0.id, $0) }\n    let dictionary = try Dictionary(uniqueKeysWithValues: cursor)\n    ```\n\n- **Cursors adopt the [Cursor](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/cursor) protocol, which looks a lot like standard [lazy sequences](https://developer.apple.com/reference/swift/lazysequenceprotocol) of Swift.** As such, cursors come with many convenience methods: `compactMap`, `contains`, `dropFirst`, `dropLast`, `drop(while:)`, `enumerated`, `filter`, `first`, `flatMap`, `forEach`, `joined`, `joined(separator:)`, `max`, `max(by:)`, `min`, `min(by:)`, `map`, `prefix`, `prefix(while:)`, `reduce`, `reduce(into:)`, `suffix`:\n    \n    ```swift\n    // Prints all Github links\n    try URL\n        .fetchCursor(db, sql: \"SELECT url FROM link\")\n        .filter { url in url.host == \"github.com\" }\n        .forEach { url in print(url) }\n    \n    // An efficient cursor of coordinates:\n    let locations = try Row.\n        .fetchCursor(db, sql: \"SELECT latitude, longitude FROM place\")\n        .map { row in\n            CLLocationCoordinate2D(latitude: row[0], longitude: row[1])\n        }\n    ```\n\n- **Cursors are not Swift sequences.** That's because Swift sequences can't handle iteration errors, when reading SQLite results may fail at any time.\n\n- **Cursors require a little care**:\n    \n    - Don't modify the results during a cursor iteration:\n        \n        ```swift\n        // Undefined behavior\n        while let player = try players.next() {\n            try db.execute(sql: \"DELETE ...\")\n        }\n        ```\n    \n    - Don't turn a cursor of `Row` into an array or a set. You would not get the distinct rows you expect. To get a array of rows, use `Row.fetchAll(...)`. To get a set of rows, use `Row.fetchSet(...)`. Generally speaking, make sure you copy a row whenever you extract it from a cursor for later use: `row.copy()`.\n\nIf you don't see, or don't care about the difference, use arrays. If you care about memory and performance, use cursors when appropriate.\n\n\n### Row Queries\n\n- [Fetching Rows](#fetching-rows)\n- [Column Values](#column-values)\n- [DatabaseValue](#databasevalue)\n- [Rows as Dictionaries](#rows-as-dictionaries)\n- üìñ [`Row`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/row)\n\n\n#### Fetching Rows\n\nFetch **cursors** of rows, **arrays**, **sets**, or **single** rows (see [fetching methods](#fetching-methods)):\n\n```swift\ntry dbQueue.read { db in\n    try Row.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Row\n    try Row.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Row]\n    try Row.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Row>\n    try Row.fetchOne(db, sql: \"SELECT ...\", arguments: ...)    // Row?\n    \n    let rows = try Row.fetchCursor(db, sql: \"SELECT * FROM wine\")\n    while let row = try rows.next() {\n        let name: String = row[\"name\"]\n        let color: Color = row[\"color\"]\n        print(name, color)\n    }\n}\n\nlet rows = try dbQueue.read { db in\n    try Row.fetchAll(db, sql: \"SELECT * FROM player\")\n}\n```\n\nArguments are optional arrays or dictionaries that fill the positional `?` and colon-prefixed keys like `:name` in the query:\n\n```swift\nlet rows = try Row.fetchAll(db,\n    sql: \"SELECT * FROM player WHERE name = ?\",\n    arguments: [\"Arthur\"])\n\nlet rows = try Row.fetchAll(db,\n    sql: \"SELECT * FROM player WHERE name = :name\",\n    arguments: [\"name\": \"Arthur\"])\n```\n\nSee [Values](#values) for more information on supported arguments types (Bool, Int, String, Date, Swift enums, etc.), and [`StatementArguments`] for a detailed documentation of SQLite arguments.\n\nUnlike row arrays that contain copies of the database rows, row cursors are close to the SQLite metal, and require a little care:\n\n> **Note**: **Don't turn a cursor of `Row` into an array or a set**. You would not get the distinct rows you expect. To get a array of rows, use `Row.fetchAll(...)`. To get a set of rows, use `Row.fetchSet(...)`. Generally speaking, make sure you copy a row whenever you extract it from a cursor for later use: `row.copy()`.\n\n\n#### Column Values\n\n**Read column values** by index or column name:\n\n```swift\nlet name: String = row[0]      // 0 is the leftmost column\nlet name: String = row[\"name\"] // Leftmost matching column - lookup is case-insensitive\nlet name: String = row[Column(\"name\")] // Using query interface's Column\n```\n\nMake sure to ask for an optional when the value may be NULL:\n\n```swift\nlet name: String? = row[\"name\"]\n```\n\nThe `row[]` subscript returns the type you ask for. See [Values](#values) for more information on supported value types:\n\n```swift\nlet bookCount: Int     = row[\"bookCount\"]\nlet bookCount64: Int64 = row[\"bookCount\"]\nlet hasBooks: Bool     = row[\"bookCount\"] // false when 0\n\nlet string: String     = row[\"date\"]      // \"2015-09-11 18:14:15.123\"\nlet date: Date         = row[\"date\"]      // Date\nself.date = row[\"date\"] // Depends on the type of the property.\n```\n\nYou can also use the `as` type casting operator:\n\n```swift\nrow[...] as Int\nrow[...] as Int?\n```\n\nThrowing accessors exist as well. Their use is not encouraged, because a database decoding error is a programming error. If an application stores invalid data in the database file, that is a bug that needs to be fixed:\n\n```swift\nlet name = try row.decode(String.self, atIndex: 0)\nlet bookCount = try row.decode(Int.self, forColumn: \"bookCount\")\n```\n\n> **Warning**: avoid the `as!` and `as?` operators:\n> \n> ```swift\n> if let int = row[...] as? Int { ... } // BAD - doesn't work\n> if let int = row[...] as Int? { ... } // GOOD\n> ```\n\n> **Warning**: avoid nil-coalescing row values, and prefer the `coalesce` method instead:\n>\n> ```swift\n> let name: String? = row[\"nickname\"] ?? row[\"name\"]     // BAD - doesn't work\n> let name: String? = row.coalesce([\"nickname\", \"name\"]) // GOOD\n> ```\n\nGenerally speaking, you can extract the type you need, provided it can be converted from the underlying SQLite value:\n\n- **Successful conversions include:**\n    \n    - All numeric SQLite values to all numeric Swift types, and Bool (zero is the only false boolean).\n    - Text SQLite values to Swift String.\n    - Blob SQLite values to Foundation Data.\n    \n    See [Values](#values) for more information on supported types (Bool, Int, String, Date, Swift enums, etc.)\n    \n- **NULL returns nil.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT NULL\")!\n    row[0] as Int? // nil\n    row[0] as Int  // fatal error: could not convert NULL to Int.\n    ```\n    \n    There is one exception, though: the [DatabaseValue](#databasevalue) type:\n    \n    ```swift\n    row[0] as DatabaseValue // DatabaseValue.null\n    ```\n    \n- **Missing columns return nil.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'foo' AS foo\")!\n    row[\"missing\"] as String? // nil\n    row[\"missing\"] as String  // fatal error: no such column: missing\n    ```\n    \n    You can explicitly check for a column presence with the `hasColumn` method.\n\n- **Invalid conversions throw a fatal error.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'Mom‚Äôs birthday'\")!\n    row[0] as String // \"Mom‚Äôs birthday\"\n    row[0] as Date?  // fatal error: could not convert \"Mom‚Äôs birthday\" to Date.\n    row[0] as Date   // fatal error: could not convert \"Mom‚Äôs birthday\" to Date.\n    \n    let row = try Row.fetchOne(db, sql: \"SELECT 256\")!\n    row[0] as Int    // 256\n    row[0] as UInt8? // fatal error: could not convert 256 to UInt8.\n    row[0] as UInt8  // fatal error: could not convert 256 to UInt8.\n    ```\n    \n    Those conversion fatal errors can be avoided with the [DatabaseValue](#databasevalue) type:\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'Mom‚Äôs birthday'\")!\n    let dbValue: DatabaseValue = row[0]\n    if dbValue.isNull {\n        // Handle NULL\n    } else if let date = Date.fromDatabaseValue(dbValue) {\n        // Handle valid date\n    } else {\n        // Handle invalid date\n    }\n    ```\n    \n    This extra verbosity is the consequence of having to deal with an untrusted database: you may consider fixing the content of your database instead. See [Fatal Errors](#fatal-errors) for more information.\n    \n- **SQLite has a weak type system, and provides [convenience conversions](https://www.sqlite.org/c3ref/column_blob.html) that can turn String to Int, Double to Blob, etc.**\n    \n    GRDB will sometimes let those conversions go through:\n    \n    ```swift\n    let rows = try Row.fetchCursor(db, sql: \"SELECT '20 small cigars'\")\n    while let row = try rows.next() {\n        row[0] as Int   // 20\n    }\n    ```\n    \n    Don't freak out: those conversions did not prevent SQLite from becoming the immensely successful database engine you want to use. And GRDB adds safety checks described just above. You can also prevent those convenience conversions altogether by using the [DatabaseValue](#databasevalue) type.\n\n\n#### DatabaseValue\n\nüìñ [`DatabaseValue`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalue)\n\n**`DatabaseValue` is an intermediate type between SQLite and your values, which gives information about the raw value stored in the database.**\n\nYou get `DatabaseValue` just like other value types:\n\n```swift\nlet dbValue: DatabaseValue = row[0]\nlet dbValue: DatabaseValue? = row[\"name\"] // nil if and only if column does not exist\n\n// Check for NULL:\ndbValue.isNull // Bool\n\n// The stored value:\ndbValue.storage.value // Int64, Double, String, Data, or nil\n\n// All the five storage classes supported by SQLite:\nswitch dbValue.storage {\ncase .null:                 print(\"NULL\")\ncase .int64(let int64):     print(\"Int64: \\(int64)\")\ncase .double(let double):   print(\"Double: \\(double)\")\ncase .string(let string):   print(\"String: \\(string)\")\ncase .blob(let data):       print(\"Data: \\(data)\")\n}\n```\n\nYou can extract regular [values](#values) (Bool, Int, String, Date, Swift enums, etc.) from `DatabaseValue` with the [fromDatabaseValue()](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible/fromdatabasevalue(_:)-21zzv) method:\n\n```swift\nlet dbValue: DatabaseValue = row[\"bookCount\"]\nlet bookCount   = Int.fromDatabaseValue(dbValue)   // Int?\nlet bookCount64 = Int64.fromDatabaseValue(dbValue) // Int64?\nlet hasBooks    = Bool.fromDatabaseValue(dbValue)  // Bool?, false when 0\n\nlet dbValue: DatabaseValue = row[\"date\"]\nlet string = String.fromDatabaseValue(dbValue)     // \"2015-09-11 18:14:15.123\"\nlet date   = Date.fromDatabaseValue(dbValue)       // Date?\n```\n\n`fromDatabaseValue` returns nil for invalid conversions:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 'Mom‚Äôs birthday'\")!\nlet dbValue: DatabaseValue = row[0]\nlet string = String.fromDatabaseValue(dbValue) // \"Mom‚Äôs birthday\"\nlet int    = Int.fromDatabaseValue(dbValue)    // nil\nlet date   = Date.fromDatabaseValue(dbValue)   // nil\n```\n\n\n#### Rows as Dictionaries\n\nRow adopts the standard [RandomAccessCollection](https://developer.apple.com/documentation/swift/randomaccesscollection) protocol, and can be seen as a dictionary of [DatabaseValue](#databasevalue):\n\n```swift\n// All the (columnName, dbValue) tuples, from left to right:\nfor (columnName, dbValue) in row {\n    ...\n}\n```\n\n**You can build rows from dictionaries** (standard Swift dictionaries and NSDictionary). See [Values](#values) for more information on supported types:\n\n```swift\nlet row: Row = [\"name\": \"foo\", \"date\": nil]\nlet row = Row([\"name\": \"foo\", \"date\": nil])\nlet row = Row(/* [AnyHashable: Any] */) // nil if invalid dictionary\n```\n\nYet rows are not real dictionaries: they may contain duplicate columns:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 1 AS foo, 2 AS foo\")!\nrow.columnNames    // [\"foo\", \"foo\"]\nrow.databaseValues // [1, 2]\nrow[\"foo\"]         // 1 (leftmost matching column)\nfor (columnName, dbValue) in row { ... } // (\"foo\", 1), (\"foo\", 2)\n```\n\n**When you build a dictionary from a row**, you have to disambiguate identical columns, and choose how to present database values. For example:\n\n- A `[String: DatabaseValue]` dictionary that keeps leftmost value in case of duplicated column name:\n\n    ```swift\n    let dict = Dictionary(row, uniquingKeysWith: { (left, _) in left })\n    ```\n\n- A `[String: AnyObject]` dictionary which keeps rightmost value in case of duplicated column name. This dictionary is identical to FMResultSet's resultDictionary from FMDB. It contains NSNull values for null columns, and can be shared with Objective-C:\n\n    ```swift\n    let dict = Dictionary(\n        row.map { (column, dbValue) in\n            (column, dbValue.storage.value as AnyObject)\n        },\n        uniquingKeysWith: { (_, right) in right })\n    ```\n\n- A `[String: Any]` dictionary that can feed, for example, JSONSerialization:\n    \n    ```swift\n    let dict = Dictionary(\n        row.map { (column, dbValue) in\n            (column, dbValue.storage.value)\n        },\n        uniquingKeysWith: { (left, _) in left })\n    ```\n\nSee the documentation of [`Dictionary.init(_:uniquingKeysWith:)`](https://developer.apple.com/documentation/swift/dictionary/2892961-init) for more information.\n\n\n### Value Queries\n\nüìñ [`DatabaseValueConvertible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible)\n\n**Instead of rows, you can directly fetch values.** There are many supported [value types](#values) (Bool, Int, String, Date, Swift enums, etc.).\n\nLike rows, fetch values as **cursors**, **arrays**, **sets**, or **single** values (see [fetching methods](#fetching-methods)). Values are extracted from the leftmost column of the SQL queries:\n\n```swift\ntry dbQueue.read { db in\n    try Int.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Int\n    try Int.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Int]\n    try Int.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Int>\n    try Int.fetchOne(db, sql: \"SELECT ...\", arguments: ...)    // Int?\n    \n    let maxScore = try Int.fetchOne(db, sql: \"SELECT MAX(score) FROM player\") // Int?\n    let names = try String.fetchAll(db, sql: \"SELECT name FROM player\")       // [String]\n}\n```\n\n`Int.fetchOne` returns nil in two cases: either the SELECT statement yielded no row, or one row with a NULL value:\n\n```swift\n// No row:\ntry Int.fetchOne(db, sql: \"SELECT 42 WHERE FALSE\") // nil\n\n// One row with a NULL value:\ntry Int.fetchOne(db, sql: \"SELECT NULL\")           // nil\n\n// One row with a non-NULL value:\ntry Int.fetchOne(db, sql: \"SELECT 42\")             // 42\n```\n\nFor requests which may contain NULL, fetch optionals:\n\n```swift\ntry dbQueue.read { db in\n    try Optional<Int>.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Int?\n    try Optional<Int>.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Int?]\n    try Optional<Int>.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Int?>\n}\n```\n\n> :bulb: **Tip**: One advanced use case, when you fetch one value, is to distinguish the cases of a statement that yields no row, or one row with a NULL value. To do so, use `Optional<Int>.fetchOne`, which returns a double optional `Int??`:\n> \n> ```swift\n> // No row:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT 42 WHERE FALSE\") // .none\n> // One row with a NULL value:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT NULL\")           // .some(.none)\n> // One row with a non-NULL value:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT 42\")             // .some(.some(42))\n> ```\n\nThere are many supported value types (Bool, Int, String, Date, Swift enums, etc.). See [Values](#values) for more information.\n\n\n## Values\n\nGRDB ships with built-in support for the following value types:\n\n- **Swift Standard Library**: Bool, Double, Float, all signed and unsigned integer types, String, [Swift enums](#swift-enums).\n    \n- **Foundation**: [Data](#data-and-memory-savings), [Date](#date-and-datecomponents), [DateComponents](#date-and-datecomponents), [Decimal](#nsnumber-nsdecimalnumber-and-decimal), NSNull, [NSNumber](#nsnumber-nsdecimalnumber-and-decimal), NSString, URL, [UUID](#uuid).\n    \n- **CoreGraphics**: CGFloat.\n\n- **[DatabaseValue](#databasevalue)**, the type which gives information about the raw value stored in the database.\n\n- **Full-Text Patterns**: [FTS3Pattern](Documentation/FullTextSearch.md#fts3pattern) and [FTS5Pattern](Documentation/FullTextSearch.md#fts5pattern).\n\n- Generally speaking, all types that adopt the [`DatabaseValueConvertible`] protocol.\n\nValues can be used as [statement arguments](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments):\n\n```swift\nlet url: URL = ...\nlet verified: Bool = ...\ntry db.execute(\n    sql: \"INSERT INTO link (url, verified) VALUES (?, ?)\",\n    arguments: [url, verified])\n```\n\nValues can be [extracted from rows](#column-values):\n\n```swift\nlet rows = try Row.fetchCursor(db, sql: \"SELECT * FROM link\")\nwhile let row = try rows.next() {\n    let url: URL = row[\"url\"]\n    let verified: Bool = row[\"verified\"]\n}\n```\n\nValues can be [directly fetched](#value-queries):\n\n```swift\nlet urls = try URL.fetchAll(db, sql: \"SELECT url FROM link\")  // [URL]\n```\n\nUse values in [Records](#records):\n\n```swift\nstruct Link: FetchableRecord {\n    var url: URL\n    var isVerified: Bool\n    \n    init(row: Row) {\n        url = row[\"url\"]\n        isVerified = row[\"verified\"]\n    }\n}\n```\n\nUse values in the [query interface](#the-query-interface):\n\n```swift\nlet url: URL = ...\nlet link = try Link.filter { $0.url == url }.fetchOne(db)\n```\n\n\n### Data (and Memory Savings)\n\n**Data** suits the BLOB SQLite columns. It can be stored and fetched from the database just like other [values](#values):\n\n```swift\nlet rows = try Row.fetchCursor(db, sql: \"SELECT data, ...\")\nwhile let row = try rows.next() {\n    let data: Data = row[\"data\"]\n}\n```\n\nAt each step of the request iteration, the `row[]` subscript creates *two copies* of the database bytes: one fetched by SQLite, and another, stored in the Swift Data value.\n\n**You have the opportunity to save memory** by not copying the data fetched by SQLite:\n\n```swift\nwhile let row = try rows.next() {\n    try row.withUnsafeData(name: \"data\") { (data: Data?) in\n        ...\n    }\n}\n```\n\nThe non-copied data does not live longer than the iteration step: make sure that you do not use it past this point.\n\n\n### Date and DateComponents\n\n[**Date**](#date) and [**DateComponents**](#datecomponents) can be stored and fetched from the database.\n\nHere is how GRDB supports the various [date formats](https://www.sqlite.org/lang_datefunc.html) supported by SQLite:\n\n| SQLite format                | Date               | DateComponents |\n|:---------------------------- |:------------------:|:--------------:|\n| YYYY-MM-DD                   |       Read ¬π       | Read / Write   |\n| YYYY-MM-DD HH:MM             |       Read ¬π ¬≤     | Read ¬≤ / Write |\n| YYYY-MM-DD HH:MM:SS          |       Read ¬π ¬≤     | Read ¬≤ / Write |\n| YYYY-MM-DD HH:MM:SS.SSS      | Read ¬π ¬≤ / Write ¬π | Read ¬≤ / Write |\n| YYYY-MM-DD**T**HH:MM         |       Read ¬π ¬≤     |      Read ¬≤    |\n| YYYY-MM-DD**T**HH:MM:SS      |       Read ¬π ¬≤     |      Read ¬≤    |\n| YYYY-MM-DD**T**HH:MM:SS.SSS  |       Read ¬π ¬≤     |      Read ¬≤    |\n| HH:MM                        |                    | Read ¬≤ / Write |\n| HH:MM:SS                     |                    | Read ¬≤ / Write |\n| HH:MM:SS.SSS                 |                    | Read ¬≤ / Write |\n| Timestamps since unix epoch  |       Read ¬≥       |                |\n| `now`                        |                    |                |\n\n¬π Missing components are assumed to be zero. Dates are stored and read in the UTC time zone, unless the format is followed by a timezone indicator ‚ÅΩ¬≤‚Åæ.\n\n¬≤ This format may be optionally followed by a timezone indicator of the form `[+-]HH:MM` or just `Z`.\n\n¬≥ GRDB 2+ interprets numerical values as timestamps that fuel `Date(timeIntervalSince1970:)`. Previous GRDB versions used to interpret numbers as [julian days](https://en.wikipedia.org/wiki/Julian_day). Julian days are still supported, with the `Date(julianDay:)` initializer.\n\n> **Warning**: the range of valid years in the SQLite date formats is 0000-9999. You will need to pick another date format when your application needs to process years outside of this range. See the following chapters.\n\n\n#### Date\n\n**Date** can be stored and fetched from the database just like other [values](#values):\n\n```swift\ntry db.execute(\n    sql: \"INSERT INTO player (creationDate, ...) VALUES (?, ...)\",\n    arguments: [Date(), ...])\n\nlet row = try Row.fetchOne(db, ...)!\nlet creationDate: Date = row[\"creationDate\"]\n```\n\nDates are stored using the format \"YYYY-MM-DD HH:MM:SS.SSS\" in the UTC time zone. It is precise to the millisecond.\n\n> **Note**: this format was chosen because it is the only format that is:\n> \n> - Comparable (`ORDER BY date` works)\n> - Comparable with the SQLite keyword CURRENT_TIMESTAMP (`WHERE date > CURRENT_TIMESTAMP` works)\n> - Able to feed [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html)\n> - Precise enough\n>\n> **Warning**: the range of valid years in the SQLite date format is 0000-9999. You will experience problems with years outside of this range, such as decoding errors, or invalid date computations with [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html).\n\nSome applications may prefer another date format:\n\n- Some may prefer ISO-8601, with a `T` separator.\n- Some may prefer ISO-8601, with a time zone.\n- Some may need to store years beyond the 0000-9999 range.\n- Some may need sub-millisecond precision.\n- Some may need exact `Date` roundtrip.\n- Etc.\n\n**You should think twice before choosing a different date format:**\n\n- ISO-8601 is about *exchange and communication*, when SQLite is about *storage and data manipulation*. Sharing the same representation in your database and in JSON files only provides a superficial convenience, and should be the least of your priorities. Don't store dates as ISO-8601 without understanding what you lose. For example, ISO-8601 time zones forbid database-level date comparison. \n- Sub-millisecond precision and exact `Date` roundtrip are not as obvious needs as it seems at first sight. Dates generally don't precisely roundtrip as soon as they leave your application anyway, because the other systems your app communicates with use their own date representation (the Android version of your app, the server your application is talking to, etc.) On top of that, `Date` comparison is at least as hard and nasty as [floating point comparison](https://www.google.com/search?q=floating+point+comparison+is+hard).\n\nThe customization of date format is explicit. For example:\n\n```swift\nlet date = Date()\nlet timeInterval = date.timeIntervalSinceReferenceDate\ntry db.execute(\n    sql: \"INSERT INTO player (creationDate, ...) VALUES (?, ...)\",\n    arguments: [timeInterval, ...])\n\nif let row = try Row.fetchOne(db, ...) {\n    let timeInterval: TimeInterval = row[\"creationDate\"]\n    let creationDate = Date(timeIntervalSinceReferenceDate: timeInterval)\n}\n```\n\nSee also [Codable Records] for more date customization options, and [`DatabaseValueConvertible`] if you want to define a Date-wrapping type with customized database representation.\n\n\n#### DateComponents\n\nDateComponents is indirectly supported, through the **DatabaseDateComponents** helper type.\n\nDatabaseDateComponents reads date components from all [date formats supported by SQLite](https://www.sqlite.org/lang_datefunc.html), and stores them in the format of your choice, from HH:MM to YYYY-MM-DD HH:MM:SS.SSS.\n\n> **Warning**: the range of valid years is 0000-9999. You will experience problems with years outside of this range, such as decoding errors, or invalid date computations with [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html). See [Date](#date) for more information.\n\nDatabaseDateComponents can be stored and fetched from the database just like other [values](#values):\n\n```swift\nlet components = DateComponents()\ncomponents.year = 1973\ncomponents.month = 9\ncomponents.day = 18\n\n// Store \"1973-09-18\"\nlet dbComponents = DatabaseDateComponents(components, format: .YMD)\ntry db.execute(\n    sql: \"INSERT INTO player (birthDate, ...) VALUES (?, ...)\",\n    arguments: [dbComponents, ...])\n\n// Read \"1973-09-18\"\nlet row = try Row.fetchOne(db, sql: \"SELECT birthDate ...\")!\nlet dbComponents: DatabaseDateComponents = row[\"birthDate\"]\ndbComponents.format         // .YMD (the actual format found in the database)\ndbComponents.dateComponents // DateComponents\n```\n\n\n### NSNumber, NSDecimalNumber, and Decimal\n\n**NSNumber** and **Decimal** can be stored and fetched from the database just like other [values](#values).\n\nHere is how GRDB supports the various data types supported by SQLite:\n\n|                 |    Integer   |     Double   |    String    |\n|:--------------- |:------------:|:------------:|:------------:|\n| NSNumber        | Read / Write | Read / Write |     Read     |\n| NSDecimalNumber | Read / Write | Read / Write |     Read     |\n| Decimal         |     Read     |     Read     | Read / Write |\n\n- All three types can decode database integers and doubles:\n\n    ```swift\n    let number = try NSNumber.fetchOne(db, sql: \"SELECT 10\")            // NSNumber\n    let number = try NSDecimalNumber.fetchOne(db, sql: \"SELECT 1.23\")   // NSDecimalNumber\n    let number = try Decimal.fetchOne(db, sql: \"SELECT -100\")           // Decimal\n    ```\n    \n- All three types decode database strings as decimal numbers:\n\n    ```swift\n    let number = try NSNumber.fetchOne(db, sql: \"SELECT '10'\")          // NSDecimalNumber (sic)\n    let number = try NSDecimalNumber.fetchOne(db, sql: \"SELECT '1.23'\") // NSDecimalNumber\n    let number = try Decimal.fetchOne(db, sql: \"SELECT '-100'\")         // Decimal\n    ```\n\n- `NSNumber` and `NSDecimalNumber` send 64-bit signed integers and doubles in the database:\n\n    ```swift\n    // INSERT INTO transfer VALUES (10)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSNumber(value: 10)])\n    \n    // INSERT INTO transfer VALUES (10.0)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSNumber(value: 10.0)])\n    \n    // INSERT INTO transfer VALUES (10)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSDecimalNumber(string: \"10.0\")])\n    \n    // INSERT INTO transfer VALUES (10.5)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSDecimalNumber(string: \"10.5\")])\n    ```\n    \n    > **Warning**: since SQLite does not support decimal numbers, sending a non-integer `NSDecimalNumber` can result in a loss of precision during the conversion to double.\n    >\n    > Instead of sending non-integer `NSDecimalNumber` to the database, you may prefer:\n    >\n    > - Send `Decimal` instead (those store decimal strings in the database).\n    > - Send integers instead (for example, store amounts of cents instead of amounts of Euros).\n\n- `Decimal` sends decimal strings in the database:\n\n    ```swift\n    // INSERT INTO transfer VALUES ('10')\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [Decimal(10)])\n    \n    // INSERT INTO transfer VALUES ('10.5')\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [Decimal(string: \"10.5\")!])\n    ```\n\n\n### UUID\n\n**UUID** can be stored and fetched from the database just like other [values](#values).\n\nGRDB stores uuids as 16-bytes data blobs, and decodes them from both 16-bytes data blobs and strings such as \"E621E1F8-C36C-495A-93FC-0C247A3E6E5F\".\n\n\n### Swift Enums\n\n**Swift enums** and generally all types that adopt the [RawRepresentable](https://developer.apple.com/library/tvos/documentation/Swift/Reference/Swift_RawRepresentable_Protocol/index.html) protocol can be stored and fetched from the database just like their raw [values](#values):\n\n```swift\nenum Color : Int {\n    case red, white, rose\n}\n\nenum Grape : String {\n    case chardonnay, merlot, riesling\n}\n\n// Declare empty DatabaseValueConvertible adoption\nextension Color : DatabaseValueConvertible { }\nextension Grape : DatabaseValueConvertible { }\n\n// Store\ntry db.execute(\n    sql: \"INSERT INTO wine (grape, color) VALUES (?, ?)\",\n    arguments: [Grape.merlot, Color.red])\n\n// Read\nlet rows = try Row.fetchCursor(db, sql: \"SELECT * FROM wine\")\nwhile let row = try rows.next() {\n    let grape: Grape = row[\"grape\"]\n    let color: Color = row[\"color\"]\n}\n```\n\n**When a database value does not match any enum case**, you get a fatal error. This fatal error can be avoided with the [DatabaseValue](#databasevalue) type:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 'syrah'\")!\n\nrow[0] as String  // \"syrah\"\nrow[0] as Grape?  // fatal error: could not convert \"syrah\" to Grape.\nrow[0] as Grape   // fatal error: could not convert \"syrah\" to Grape.\n\nlet dbValue: DatabaseValue = row[0]\nif dbValue.isNull {\n    // Handle NULL\n} else if let grape = Grape.fromDatabaseValue(dbValue) {\n    // Handle valid grape\n} else {\n    // Handle unknown grape\n}\n```\n\n\n## Custom SQL Functions and Aggregates\n\n**SQLite lets you define SQL functions and aggregates.**\n\nA custom SQL function or aggregate extends SQLite:\n\n```sql\nSELECT reverse(name) FROM player;   -- custom function\nSELECT maxLength(name) FROM player; -- custom aggregate\n```\n\n- [Custom SQL Functions](#custom-sql-functions)\n- [Custom Aggregates](#custom-aggregates)\n\n\n### Custom SQL Functions\n\nüìñ [`DatabaseFunction`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasefunction)\n\nA *function* argument takes an array of [DatabaseValue](#databasevalue), and returns any valid [value](#values) (Bool, Int, String, Date, Swift enums, etc.) The number of database values is guaranteed to be *argumentCount*.\n\nSQLite has the opportunity to perform additional optimizations when functions are \"pure\", which means that their result only depends on their arguments. So make sure to set the *pure* argument to true when possible.\n\n```swift\nlet reverse = DatabaseFunction(\"reverse\", argumentCount: 1, pure: true) { (values: [DatabaseValue]) in\n    // Extract string value, if any...\n    guard let string = String.fromDatabaseValue(values[0]) else {\n        return nil\n    }\n    // ... and return reversed string:\n    return String(string.reversed())\n}\n```\n\nYou make a function available to a database connection through its configuration:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(function: reverse)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // \"oof\"\n    try String.fetchOne(db, sql: \"SELECT reverse('foo')\")!\n}\n```\n\n\n**Functions can take a variable number of arguments:**\n\nWhen you don't provide any explicit *argumentCount*, the function can take any number of arguments:\n\n```swift\nlet averageOf = DatabaseFunction(\"averageOf\", pure: true) { (values: [DatabaseValue]) in\n    let doubles = values.compactMap { Double.fromDatabaseValue($0) }\n    return doubles.reduce(0, +) / Double(doubles.count)\n}\ndb.add(function: averageOf)\n\n// 2.0\ntry Double.fetchOne(db, sql: \"SELECT averageOf(1, 2, 3)\")!\n```\n\n\n**Functions can throw:**\n\n```swift\nlet sqrt = DatabaseFunction(\"sqrt\", argumentCount: 1, pure: true) { (values: [DatabaseValue]) in\n    guard let double = Double.fromDatabaseValue(values[0]) else {\n        return nil\n    }\n    guard double >= 0 else {\n        throw DatabaseError(message: \"invalid negative number\")\n    }\n    return sqrt(double)\n}\ndb.add(function: sqrt)\n\n// SQLite error 1 with statement `SELECT sqrt(-1)`: invalid negative number\ntry Double.fetchOne(db, sql: \"SELECT sqrt(-1)\")!\n```\n\n\n**Use custom functions in the [query interface](#the-query-interface):**\n\n```swift\n// SELECT reverseString(\"name\") FROM player\nPlayer.select { reverseString($0.name) }\n```\n\n\n**GRDB ships with built-in SQL functions that perform unicode-aware string transformations.** See [Unicode](#unicode).\n\n\n### Custom Aggregates\n\nüìñ [`DatabaseFunction`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasefunction), [`DatabaseAggregate`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseaggregate)\n\nBefore registering a custom aggregate, you need to define a type that adopts the `DatabaseAggregate` protocol:\n\n```swift\nprotocol DatabaseAggregate {\n    // Initializes an aggregate\n    init()\n    \n    // Called at each step of the aggregation\n    mutating func step(_ dbValues: [DatabaseValue]) throws\n    \n    // Returns the final result\n    func finalize() throws -> DatabaseValueConvertible?\n}\n```\n\nFor example:\n\n```swift\nstruct MaxLength : DatabaseAggregate {\n    var maxLength: Int = 0\n    \n    mutating func step(_ dbValues: [DatabaseValue]) {\n        // At each step, extract string value, if any...\n        guard let string = String.fromDatabaseValue(dbValues[0]) else {\n            return\n        }\n        // ... and update the result\n        let length = string.count\n        if length > maxLength {\n            maxLength = length\n        }\n    }\n    \n    func finalize() -> DatabaseValueConvertible? {\n        maxLength\n    }\n}\n\nlet maxLength = DatabaseFunction(\n    \"maxLength\",\n    argumentCount: 1,\n    pure: true,\n    aggregate: MaxLength.self)\n```\n\nLike [custom SQL Functions](#custom-sql-functions), you make an aggregate function available to a database connection through its configuration:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(function: maxLength)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // Some Int\n    try Int.fetchOne(db, sql: \"SELECT maxLength(name) FROM player\")!\n}\n```\n\nThe `step` method of the aggregate takes an array of [DatabaseValue](#databasevalue). This array contains as many values as the *argumentCount* parameter (or any number of values, when *argumentCount* is omitted).\n\nThe `finalize` method of the aggregate returns the final aggregated [value](#values) (Bool, Int, String, Date, Swift enums, etc.).\n\nSQLite has the opportunity to perform additional optimizations when aggregates are \"pure\", which means that their result only depends on their inputs. So make sure to set the *pure* argument to true when possible.\n\n\n**Use custom aggregates in the [query interface](#the-query-interface):**\n\n```swift\n// SELECT maxLength(\"name\") FROM player\nlet request = Player.select { maxLength($0.name) }\ntry Int.fetchOne(db, request) // Int?\n```\n\n\n## Raw SQLite Pointers\n\n**If not all SQLite APIs are exposed in GRDB, you can still use the [SQLite C Interface](https://www.sqlite.org/c3ref/intro.html) and call [SQLite C functions](https://www.sqlite.org/c3ref/funclist.html).**\n\nTo access the C SQLite functions from SQLCipher or the system SQLite, you need to perform an extra import:\n\n```swift\nimport SQLite3   // System SQLite\nimport SQLCipher // SQLCipher\n\nlet sqliteVersion = String(cString: sqlite3_libversion())\n```\n\nRaw pointers to database connections and statements are available through the `Database.sqliteConnection` and `Statement.sqliteStatement` properties:\n\n```swift\ntry dbQueue.read { db in\n    // The raw pointer to a database connection:\n    let sqliteConnection = db.sqliteConnection\n\n    // The raw pointer to a statement:\n    let statement = try db.makeStatement(sql: \"SELECT ...\")\n    let sqliteStatement = statement.sqliteStatement\n}\n```\n\n> **Note**\n>\n> - Those pointers are owned by GRDB: don't close connections or finalize statements created by GRDB.\n> - GRDB opens SQLite connections in the \"[multi-thread mode](https://www.sqlite.org/threadsafe.html)\", which (oddly) means that **they are not thread-safe**. Make sure you touch raw databases and statements inside their dedicated dispatch queues.\n> - Use the raw SQLite C Interface at your own risk. GRDB won't prevent you from shooting yourself in the foot.\n\n\nRecords\n=======\n\n**On top of the [SQLite API](#sqlite-api), GRDB provides protocols** that help manipulating database rows as regular objects named \"records\":\n\n```swift\ntry dbQueue.write { db in\n    if var place = try Player.fetchOne(db, id: 1) {\n        player.score += 10\n        try player.update(db)\n    }\n}\n```\n\nOf course, you need to open a [database connection], and [create database tables](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema) first.\n\nTo define a record type, define a type and extend it with database protocols:\n\n- `FetchableRecord` makes it possible to fetch instances from the database.\n- `PersistableRecord` makes it possible to save instances into the database.\n- `Codable` (not mandatory) provides ready-made serialization to and from database rows.\n- `Identifiable` (not mandatory) provides extra convenience database methods.\n\nTo make it easier to customize database requests, also nest a `Columns` enum: \n\n```swift\nstruct Player: Codable, Identifiable {\n    var id: Int64\n    var name: String\n    var score: Int\n    var team: String?\n}\n\n// Add database support\nextension Player: FetchableRecord, PersistableRecord {\n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n        static let team = Column(CodingKeys.team)\n    }\n}\n```\n\nSee more [examples of record definitions](#examples-of-record-definitions) below.\n\n> Note: if you are familiar with Core Data's NSManagedObject or Realm's Object, you may experience a cultural shock: GRDB records are not uniqued, do not auto-update, and do not lazy-load. This is both a purpose, and a consequence of protocol-oriented programming.\n>\n> Tip: The [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices) guide provides general guidance..\n>\n> Tip: See the [Demo Applications] for sample apps that uses records.\n\n**Overview**\n\n- [Inserting Records](#inserting-records)\n- [Fetching Records](#fetching-records)\n- [Updating Records](#updating-records)\n- [Deleting Records](#deleting-records)\n- [Counting Records](#counting-records)\n\n**Protocols and the Record Class**\n\n- [Record Protocols Overview](#record-protocols-overview)\n- [FetchableRecord Protocol](#fetchablerecord-protocol)\n- [TableRecord Protocol](#tablerecord-protocol)\n- [PersistableRecord Protocol](#persistablerecord-protocol)\n    - [Persistence Methods]\n    - [Persistence Methods and the `RETURNING` clause]\n    - [Persistence Callbacks]\n- [Identifiable Records]\n- [Codable Records]\n- [Record Comparison]\n- [Record Customization Options]\n- [Record Timestamps and Transaction Date]\n\n\n### Inserting Records\n\nTo insert a record in the database, call the `insert` method:\n\n```swift\nlet player = Player(id: 1, name: \"Arthur\", score: 1000)\ntry player.insert(db)\n```\n\n:point_right: `insert` is available for types that adopt the [PersistableRecord] protocol.\n\n\n### Fetching Records\n\nTo fetch records from the database, call a [fetching method](#fetching-methods):\n\n```swift\nlet arthur = try Player.fetchOne(db,            // Player?\n    sql: \"SELECT * FROM players WHERE name = ?\",\n    arguments: [\"Arthur\"])\n\nlet bestPlayers = try Player                    // [Player]\n    .order(\\.score.desc)\n    .limit(10)\n    .fetchAll(db)\n    \nlet spain = try Country.fetchOne(db, id: \"ES\")  // Country?\nlet italy = try Country.find(db, id: \"IT\")      // Country\n```\n\n:point_right: Fetching from raw SQL is available for types that adopt the [FetchableRecord] protocol.\n\n:point_right: Fetching without SQL, using the [query interface](#the-query-interface), is available for types that adopt both [FetchableRecord] and [TableRecord] protocol.\n\n\n### Updating Records\n\nTo update a record in the database, call the `update` method:\n\n```swift\nvar player: Player = ...\nplayer.score = 1000\ntry player.update(db)\n```\n\nIt is possible to [avoid useless updates](#record-comparison):\n\n```swift\n// does not hit the database if score has not changed\ntry player.updateChanges(db) {\n    $0.score = 1000\n}\n```\n\nSee the [query interface](#the-query-interface) for batch updates:\n\n```swift\ntry Player\n    .filter { $0.team == \"red\" }\n    .updateAll(db) { $0.score += 1 }\n```\n\n:point_right: update methods are available for types that adopt the [PersistableRecord] protocol. Batch updates are available on the [TableRecord] protocol.\n\n\n### Deleting Records\n\nTo delete a record in the database, call the `delete` method:\n\n```swift\nlet player: Player = ...\ntry player.delete(db)\n```\n\nYou can also delete by primary key, unique key, or perform batch deletes (see [Delete Requests](#delete-requests)):\n\n```swift\ntry Player.deleteOne(db, id: 1)\ntry Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\ntry Country.deleteAll(db, ids: [\"FR\", \"US\"])\ntry Player\n    .filter { $0.email == nil }\n    .deleteAll(db)\n```\n\n:point_right: delete methods are available for types that adopt the [PersistableRecord] protocol. Batch deletes are available on the [TableRecord] protocol.\n\n\n### Counting Records\n\nTo count records, call the `fetchCount` method:\n\n```swift\nlet playerCount: Int = try Player.fetchCount(db)\n\nlet playerWithEmailCount: Int = try Player\n    .filter { $0.email == nil }\n    .fetchCount(db)\n```\n\n:point_right: `fetchCount` is available for types that adopt the [TableRecord] protocol.\n\n\nDetails follow:\n\n- [Record Protocols Overview](#record-protocols-overview)\n- [FetchableRecord Protocol](#fetchablerecord-protocol)\n- [TableRecord Protocol](#tablerecord-protocol)\n- [PersistableRecord Protocol](#persistablerecord-protocol)\n- [Identifiable Records]\n- [Codable Records]\n- [Record Comparison]\n- [Record Customization Options]\n- [Examples of Record Definitions](#examples-of-record-definitions)\n\n\n## Record Protocols Overview\n\n**GRDB ships with three record protocols**. Your own types will adopt one or several of them, according to the abilities you want to extend your types with.\n\n- [FetchableRecord] is able to **decode database rows**.\n    \n    ```swift\n    struct Place: FetchableRecord { ... }\n    \n    let places = try dbQueue.read { db in\n        try Place.fetchAll(db, sql: \"SELECT * FROM place\")\n    }\n    ```\n    \n    > :bulb: **Tip**: `FetchableRecord` can derive its implementation from the standard `Decodable` protocol. See [Codable Records] for more information.\n    \n    `FetchableRecord` can decode database rows, but it is not able to build SQL requests for you. For that, you also need `TableRecord`:\n    \n- [TableRecord] is able to **generate SQL queries**:\n    \n    ```swift\n    struct Place: TableRecord { ... }\n    \n    let placeCount = try dbQueue.read { db in\n        // Generates and runs `SELECT COUNT(*) FROM place`\n        try Place.fetchCount(db)\n    }\n    ```\n    \n    When a type adopts both `TableRecord` and `FetchableRecord`, it can load from those requests:\n    \n    ```swift\n    struct Place: TableRecord, FetchableRecord { ... }\n    \n    try dbQueue.read { db in\n        let places = try Place.order(\\.title).fetchAll(db)\n        let paris = try Place.fetchOne(id: 1)\n    }\n    ```\n\n- [PersistableRecord] is able to **write**: it can create, update, and delete rows in the database:\n    \n    ```swift\n    struct Place : PersistableRecord { ... }\n    \n    try dbQueue.write { db in\n        try Place.delete(db, id: 1)\n        try Place(...).insert(db)\n    }\n    ```\n    \n    A persistable record can also [compare](#record-comparison) itself against other records, and avoid useless database updates.\n    \n    > :bulb: **Tip**: `PersistableRecord` can derive its implementation from the standard `Encodable` protocol. See [Codable Records] for more information.\n\n\n## FetchableRecord Protocol\n\nüìñ [`FetchableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/fetchablerecord)\n\n**The FetchableRecord protocol grants fetching methods to any type** that can be built from a database row:\n\n```swift\nprotocol FetchableRecord {\n    /// Row initializer\n    init(row: Row) throws\n}\n```\n\nFor example:\n\n```swift\nstruct Place {\n    var id: Int64?\n    var title: String\n    var coordinate: CLLocationCoordinate2D\n}\n\nextension Place: FetchableRecord {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n    \n    init(row: Row) {\n        id = row[Columns.id]\n        title = row[Columns.title]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[Columns.latitude],\n            longitude: row[Columns.longitude])\n    }\n}\n```\n\nSee [column values](#column-values) for more information about the `row[]` subscript.\n\nWhen your record type adopts the standard Decodable protocol, you don't have to provide the implementation for `init(row:)`. See [Codable Records] for more information:\n\n```swift\n// That's all\nstruct Player: Decodable, FetchableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n```\n\nFetchableRecord allows adopting types to be fetched from SQL queries:\n\n```swift\ntry Place.fetchCursor(db, sql: \"SELECT ...\", arguments:...) // A Cursor of Place\ntry Place.fetchAll(db, sql: \"SELECT ...\", arguments:...)    // [Place]\ntry Place.fetchSet(db, sql: \"SELECT ...\", arguments:...)    // Set<Place>\ntry Place.fetchOne(db, sql: \"SELECT ...\", arguments:...)    // Place?\n```\n\nSee [fetching methods](#fetching-methods) for information about the `fetchCursor`, `fetchAll`, `fetchSet` and `fetchOne` methods. See [`StatementArguments`] for more information about the query arguments.\n\n> **Note**: for performance reasons, the same row argument to `init(row:)` is reused during the iteration of a fetch query. If you want to keep the row for later use, make sure to store a copy: `self.row = row.copy()`.\n\n> **Note**: The `FetchableRecord.init(row:)` initializer fits the needs of most applications. But some application are more demanding than others. When FetchableRecord does not exactly provide the support you need, have a look at the [Beyond FetchableRecord] chapter.\n\n\n## TableRecord Protocol\n\nüìñ [`TableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord)\n\n**The TableRecord protocol** generates SQL for you:\n\n```swift\nprotocol TableRecord {\n    static var databaseTableName: String { get }\n    static var databaseSelection: [any SQLSelectable] { get }\n}\n```\n\nThe `databaseSelection` type property is optional, and documented in the [Columns Selected by a Request] chapter.\n\nThe `databaseTableName` type property is the name of a database table. By default, it is derived from the type name:\n\n```swift\nstruct Place: TableRecord { }\n\nprint(Place.databaseTableName) // prints \"place\"\n```\n\nFor example:\n\n- Place: `place`\n- Country: `country`\n- PostalAddress: `postalAddress`\n- HTTPRequest: `httpRequest`\n- TOEFL: `toefl`\n\nYou can still provide a custom table name:\n\n```swift\nstruct Place: TableRecord {\n    static let databaseTableName = \"location\"\n}\n\nprint(Place.databaseTableName) // prints \"location\"\n```\n\nWhen a type adopts both TableRecord and [FetchableRecord](#fetchablerecord-protocol), it can be fetched using the [query interface](#the-query-interface):\n\n```swift\n// SELECT * FROM place WHERE name = 'Paris'\nlet paris = try Place.filter { $0.name == \"Paris\" }.fetchOne(db)\n```\n\nTableRecord can also fetch deal with primary and unique keys: see [Fetching by Key](#fetching-by-key) and [Testing for Record Existence](#testing-for-record-existence).\n\n\n## PersistableRecord Protocol\n\nüìñ [`EncodableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/encodablerecord), [`MutablePersistableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/mutablepersistablerecord), [`PersistableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/persistablerecord)\n\n**GRDB record types can create, update, and delete rows in the database.**\n\nThose abilities are granted by three protocols:\n\n```swift\n// Defines how a record encodes itself into the database\nprotocol EncodableRecord {\n    /// Defines the values persisted in the database\n    func encode(to container: inout PersistenceContainer) throws\n}\n\n// Adds persistence methods\nprotocol MutablePersistableRecord: TableRecord, EncodableRecord {\n    /// Optional method that lets your adopting type store its rowID upon\n    /// successful insertion. Don't call it directly: it is called for you.\n    mutating func didInsert(_ inserted: InsertionSuccess)\n}\n\n// Adds immutability\nprotocol PersistableRecord: MutablePersistableRecord {\n    /// Non-mutating version of the optional didInsert(_:)\n    func didInsert(_ inserted: InsertionSuccess)\n}\n```\n\nYes, three protocols instead of one. Here is how you pick one or the other:\n\n- **If your type is a class**, choose `PersistableRecord`. On top of that, implement `didInsert(_:)` if the database table has an auto-incremented primary key.\n\n- **If your type is a struct, and the database table has an auto-incremented primary key**, choose `MutablePersistableRecord`, and implement `didInsert(_:)`.\n\n- **Otherwise**, choose `PersistableRecord`, and ignore `didInsert(_:)`.\n\nThe `encode(to:)` method defines which [values](#values) (Bool, Int, String, Date, Swift enums, etc.) are assigned to database columns.\n\nThe optional `didInsert` method lets the adopting type store its rowID after successful insertion, and is only useful for tables that have an auto-incremented primary key. It is called from a protected dispatch queue, and serialized with all database updates.\n\nFor example:\n\n```swift\nextension Place: MutablePersistableRecord {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n    \n    /// The values persisted in the database\n    func encode(to container: inout PersistenceContainer) {\n        container[Columns.id] = id\n        container[Columns.title] = title\n        container[Columns.latitude] = coordinate.latitude\n        container[Columns.longitude] = coordinate.longitude\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n\nvar paris = Place(\n    id: nil,\n    title: \"Paris\",\n    coordinate: CLLocationCoordinate2D(latitude: 48.8534100, longitude: 2.3488000))\n\ntry paris.insert(db)\nparis.id   // some value\n```\n\nWhen your record type adopts the standard Encodable protocol, you don't have to provide the implementation for `encode(to:)`. See [Codable Records] for more information:\n\n```swift\n// That's all\nstruct Player: Encodable, MutablePersistableRecord {\n    var id: Int64?\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n\n### Persistence Methods\n\nTypes that adopt the [PersistableRecord] protocol are given methods that insert, update, and delete:\n\n```swift\n// INSERT\ntry place.insert(db)\nlet insertedPlace = try place.inserted(db) // non-mutating\n\n// UPDATE\ntry place.update(db)\ntry place.update(db, columns: [\"title\"])\n\n// Maybe UPDATE\ntry place.updateChanges(db, from: otherPlace)\ntry place.updateChanges(db) { $0.isFavorite = true }\n\n// INSERT or UPDATE\ntry place.save(db)\nlet savedPlace = place.saved(db) // non-mutating\n\n// UPSERT\ntry place.upsert(db)\nlet insertedPlace = place.upsertAndFetch(db)\n\n// DELETE\ntry place.delete(db)\n\n// EXISTENCE CHECK\nlet exists = try place.exists(db)\n```\n\nSee [Upsert](#upsert) below for more information about upserts.\n\n**The [TableRecord] protocol comes with batch operations**:\n\n```swift\n// UPDATE\ntry Place.updateAll(db, ...)\n\n// DELETE\ntry Place.deleteAll(db)\ntry Place.deleteAll(db, ids:...)\ntry Place.deleteAll(db, keys:...)\ntry Place.deleteOne(db, id:...)\ntry Place.deleteOne(db, key:...)\n```\n\nFor more information about batch updates, see [Update Requests](#update-requests).\n\n- All persistence methods can throw a [DatabaseError](#error-handling).\n\n- `update` and `updateChanges` throw [RecordError] if the database does not contain any row for the primary key of the record.\n\n- `save` makes sure your values are stored in the database. It performs an UPDATE if the record has a non-null primary key, and then, if no row was modified, an INSERT. It directly performs an INSERT if the record has no primary key, or a null primary key.\n\n- `delete` and `deleteOne` returns whether a database row was deleted or not. `deleteAll` returns the number of deleted rows. `updateAll` returns the number of updated rows. `updateChanges` returns whether a database row was updated or not.\n\n**All primary keys are supported**, including composite primary keys that span several columns, and the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html).\n\n**To customize persistence methods**, you provide [Persistence Callbacks], described below. Do not attempt at overriding the ready-made persistence methods.\n\n### Upsert\n\n[UPSERT](https://www.sqlite.org/lang_UPSERT.html) is an SQLite feature that causes an INSERT to behave as an UPDATE or a no-op if the INSERT would violate a uniqueness constraint (primary key or unique index).\n\n> **Note**: Upsert apis are available from SQLite 3.35.0+: iOS 15.0+, macOS 12.0+, tvOS 15.0+, watchOS 8.0+, or with a [custom SQLite build] or [SQLCipher](#encryption).\n>\n> **Note**: With regard to [persistence callbacks](#available-callbacks), an upsert behaves exactly like an insert. In particular: the `aroundInsert(_:)` and `didInsert(_:)` callbacks reports the rowid of the inserted or updated row; `willUpdate`, `aroundUpdate`, `didUpdate` are not called.\n\n[PersistableRecord] provides three upsert methods:\n\n- `upsert(_:)`\n    \n    Inserts or updates a record.\n    \n    The upsert behavior is triggered by a violation of any uniqueness constraint on the table (primary key or unique index). In case of conflict, all columns but the primary key are overwritten with the inserted values:\n    \n    ```swift\n    struct Player: Encodable, PersistableRecord {\n        var id: Int64\n        var name: String\n        var score: Int\n    }\n    \n    // INSERT INTO player (id, name, score)\n    // VALUES (1, 'Arthur', 1000)\n    // ON CONFLICT DO UPDATE SET\n    //   name = excluded.name,\n    //   score = excluded.score\n    let player = Player(id: 1, name: \"Arthur\", score: 1000)\n    try player.upsert(db)\n    ```\n\n- `upsertAndFetch(_:onConflict:doUpdate:)` (requires [FetchableRecord] conformance)\n\n    Inserts or updates a record, and returns the upserted record.\n    \n    The `onConflict` and `doUpdate` arguments let you further control the upsert behavior. Make sure you check the [SQLite UPSERT documentation](https://www.sqlite.org/lang_UPSERT.html) for detailed information.\n    \n    - `onConflict`: the \"conflict target\" is the array of columns in the uniqueness constraint (primary key or unique index) that triggers the upsert.\n        \n        If empty (the default), all uniqueness constraint are considered.\n    \n    - `doUpdate`: a closure that returns columns assignments to perform in case of conflict. Other columns are overwritten with the inserted values.\n        \n        By default, all inserted columns but the primary key and the conflict target are overwritten.\n    \n    In the example below, we upsert the new vocabulary word \"jovial\". It is inserted if that word is not already in the dictionary. Otherwise, `count` is incremented, `isTainted` is not overwritten, and `kind` is overwritten:\n    \n    ```swift\n    // CREATE TABLE vocabulary(\n    //   word TEXT NOT NULL PRIMARY KEY,\n    //   kind TEXT NOT NULL,\n    //   isTainted BOOLEAN DEFAULT 0,\n    //   count INT DEFAULT 1))\n    struct Vocabulary: Encodable, PersistableRecord {\n        var word: String\n        var kind: String\n        var isTainted: Bool\n    }\n    \n    // INSERT INTO vocabulary(word, kind, isTainted)\n    // VALUES('jovial', 'adjective', 0)\n    // ON CONFLICT(word) DO UPDATE SET \\\n    //   count = count + 1,   -- on conflict, count is incremented\n    //   kind = excluded.kind -- on conflict, kind is overwritten\n    // RETURNING *\n    let vocabulary = Vocabulary(word: \"jovial\", kind: \"adjective\", isTainted: false)\n    let upserted = try vocabulary.upsertAndFetch(\n        db, onConflict: [\"word\"],\n        doUpdate: { _ in\n            [Column(\"count\") += 1,            // on conflict, count is incremented\n             Column(\"isTainted\").noOverwrite] // on conflict, isTainted is NOT overwritten\n        })\n    ```\n    \n    The `doUpdate` closure accepts an `excluded` TableAlias argument that refers to the inserted values that trigger the conflict. You can use it to specify an explicit overwrite, or to perform a computation. In the next example, the upsert keeps the maximum date in case of conflict:\n    \n    ```swift\n    // INSERT INTO message(id, text, date)\n    // VALUES(...)\n    // ON CONFLICT DO UPDATE SET \\\n    //   text = excluded.text,\n    //   date = MAX(date, excluded.date)\n    // RETURNING *\n    let upserted = try message.upsertAndFetch(doUpdate: { excluded in\n        // keep the maximum date in case of conflict\n        [Column(\"date\").set(to: max(Column(\"date\"), excluded[\"date\"]))]\n    })\n    ```\n\n- `upsertAndFetch(_:as:onConflict:doUpdate:)` (does not require [FetchableRecord] conformance)\n\n    This method is identical to `upsertAndFetch(_:onConflict:doUpdate:)` described above, but you can provide a distinct [FetchableRecord] record type as a result, in order to specify the returned columns.\n\n### Persistence Methods and the `RETURNING` clause\n\nSQLite is able to return values from a inserted, updated, or deleted row, with the [`RETURNING` clause](https://www.sqlite.org/lang_returning.html).\n\n> **Note**: Support for the `RETURNING` clause is available from SQLite 3.35.0+: iOS 15.0+, macOS 12.0+, tvOS 15.0+, watchOS 8.0+, or with a [custom SQLite build] or [SQLCipher](#encryption).\n\nThe `RETURNING` clause helps dealing with database features such as auto-incremented ids, default values, and [generated columns](https://sqlite.org/gencol.html). You can, for example, insert a few columns and fetch the default or generated ones in one step.\n\nGRDB uses the `RETURNING` clause in all persistence methods that contain `AndFetch` in their name.\n\nFor example, given a database table with an auto-incremented primary key and a default score:\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player(\n          id INTEGER PRIMARY KEY AUTOINCREMENT,\n          name TEXT NOT NULL,\n          score INTEGER NOT NULL DEFAULT 1000)\n        \"\"\")\n}\n```\n\nYou can define a record type with full database information, and another partial record type that deals with a subset of columns:\n\n```swift\n// A player with full database information\nstruct Player: Codable, PersistableRecord, FetchableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// A partial player\nstruct PartialPlayer: Encodable, PersistableRecord {\n    static let databaseTableName = \"player\"\n    var name: String\n    \n    typealias Columns = Player.Columns\n}\n```\n\nAnd now you can get a full player by inserting a partial one:\n\n```swift\ntry dbQueue.write { db in\n    let partialPlayer = PartialPlayer(name: \"Alice\")\n    \n    // INSERT INTO player (name) VALUES ('Alice') RETURNING *\n    let player = try partialPlayer.insertAndFetch(db, as: Player.self)\n    print(player.id)    // The inserted id\n    print(player.name)  // The inserted name\n    print(player.score) // The default score\n}\n```\n\nFor extra precision, you can select only the columns you need, and fetch the desired value from the provided prepared [`Statement`]:\n\n```swift\ntry dbQueue.write { db in\n    let partialPlayer = PartialPlayer(name: \"Alice\")\n    \n    // INSERT INTO player (name) VALUES ('Alice') RETURNING score\n    let score = try partialPlayer.insertAndFetch(db) { statement in\n        try Int.fetchOne(statement)\n    } select: {\n        [$0.score]\n    }\n    print(score) // Prints 1000, the default score\n}\n```\n\nThere are other similar persistence methods, such as `upsertAndFetch`, `saveAndFetch`, `updateAndFetch`, `updateChangesAndFetch`, etc. They all behave like `upsert`, `save`, `update`, `updateChanges`, except that they return saved values. For example:\n\n```swift\n// Save and return the saved player\nlet savedPlayer = try player.saveAndFetch(db)\n```\n\nSee [Persistence Methods], [Upsert](#upsert), and [`updateChanges` methods](#the-updatechanges-methods) for more information.\n\n**Batch operations** can return updated or deleted values:\n\n> **Warning**: Make sure you check the [documentation of the `RETURNING` clause](https://www.sqlite.org/lang_returning.html#limitations_and_caveats), which describes important limitations and caveats for batch operations.\n\n```swift\nlet request = Player.filter(...)...\n\n// Fetch all deleted players\n// DELETE FROM player RETURNING *\nlet deletedPlayers = try request.deleteAndFetchAll(db) // [Player]\n\n// Fetch a selection of columns from the deleted rows\n// DELETE FROM player RETURNING name\nlet statement = try request.deleteAndFetchStatement(db) { [$0.name] }\nlet deletedNames = try String.fetchSet(statement)\n\n// Fetch all updated players\n// UPDATE player SET score = score + 10 RETURNING *\nlet updatedPlayers = try request.updateAndFetchAll(db) { [$0.score += 10] } // [Player]\n\n// Fetch a selection of columns from the updated rows\n// UPDATE player SET score = score + 10 RETURNING score\nlet statement = try request.updateAndFetchStatement(db) {\n    [$0.score += 10]\n} select: {\n    [$0.score]\n}\nlet updatedScores = try Int.fetchAll(statement)\n```\n\n\n### Persistence Callbacks\n\nYour custom type may want to perform extra work when the persistence methods are invoked.\n\nTo this end, your record type can implement **persistence callbacks**. Callbacks are methods that get called at certain moments of a record's life cycle. With callbacks it is possible to write code that will run whenever an record is inserted, updated, or deleted.\n\nIn order to use a callback method, you need to provide its implementation. For example, a frequently used callback is `didInsert`, in the case of auto-incremented database ids:\n\n```swift\nstruct Player: MutablePersistableRecord {\n    var id: Int64?\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n\ntry dbQueue.write { db in\n    var player = Player(id: nil, ...)\n    try player.insert(db)\n    print(player.id) // didInsert was called: prints some non-nil id\n}\n```\n\nCallbacks can also help implementing record validation:\n\n```swift\nstruct Link: PersistableRecord {\n    var url: URL\n    \n    func willSave(_ db: Database) throws {\n        if url.host == nil {\n            throw ValidationError(\"url must be absolute.\")\n        }\n    }\n}\n\ntry link.insert(db) // Calls the willSave callback\ntry link.update(db) // Calls the willSave callback\ntry link.save(db)   // Calls the willSave callback\ntry link.upsert(db) // Calls the willSave callback\n```\n\n#### Available Callbacks\n\nHere is a list with all the available [persistence callbacks], listed in the same order in which they will get called during the respective operations:\n\n- Inserting a record (all `record.insert` and `record.upsert` methods)\n    - `willSave`\n    - `aroundSave`\n    - `willInsert`\n    - `aroundInsert`\n    - `didInsert`\n    - `didSave`\n    \n- Updating a record (all `record.update` methods)\n    - `willSave`\n    - `aroundSave`\n    - `willUpdate`\n    - `aroundUpdate`\n    - `didUpdate`\n    - `didSave`\n    \n- Deleting a record (only the `record.delete(_:)` method)\n    - `willDelete`\n    - `aroundDelete`\n    - `didDelete`\n\nFor detailed information about each callback, check the [reference](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/mutablepersistablerecord/).\n\nIn the `MutablePersistableRecord` protocol, `willInsert` and `didInsert` are mutating methods. In `PersistableRecord`, they are not mutating.\n\n> **Note**: The `record.save(_:)` method performs an UPDATE if the record has a non-null primary key, and then, if no row was modified, an INSERT. It directly performs an INSERT if the record has no primary key, or a null primary key. It triggers update and/or insert callbacks accordingly.\n>\n> **Warning**: Callbacks are only invoked from persistence methods called on record instances. Callbacks are not invoked when you call a type method, perform a batch operations, or execute raw SQL.\n>\n> **Warning**: When a `did***` callback is invoked, do not assume that the change is actually persisted on disk, because the database may still be inside an uncommitted transaction. When you need to handle transaction completions, use the [afterNextTransaction(onCommit:onRollback:)](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)). For example:\n>\n> ```swift\n> struct PictureFile: PersistableRecord {\n>     var path: String\n>     \n>     func willDelete(_ db: Database) {\n>         db.afterNextTransaction { _ in\n>             try? deleteFileOnDisk()\n>         }\n>     }\n> }\n> ```\n\n\n## Identifiable Records\n\n**When a record type maps a table with a single-column primary key, it is recommended to have it adopt the standard [Identifiable] protocol.**\n\n```swift\nstruct Player: Identifiable, FetchableRecord, PersistableRecord {\n    var id: Int64 // fulfills the Identifiable requirement\n    var name: String\n    var score: Int\n}\n```\n\nWhen `id` has a [database-compatible type](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible) (Int64, Int, String, UUID, ...), the `Identifiable` conformance unlocks type-safe record and request methods:\n\n```swift\nlet player = try Player.find(db, id: 1)               // Player\nlet player = try Player.fetchOne(db, id: 1)           // Player?\nlet players = try Player.fetchAll(db, ids: [1, 2, 3]) // [Player]\nlet players = try Player.fetchSet(db, ids: [1, 2, 3]) // Set<Player>\n\nlet request = Player.filter(id: 1)\nlet request = Player.filter(ids: [1, 2, 3])\n\ntry Player.deleteOne(db, id: 1)\ntry Player.deleteAll(db, ids: [1, 2, 3])\n```\n\n> **Note**: Not all record types can be made `Identifiable`, and not all tables have a single-column primary key. GRDB provides other methods that deal with primary and unique keys, but they won't check the type of their arguments:\n> \n> ```swift\n> // Available on non-Identifiable types\n> try Player.fetchOne(db, key: 1)\n> try Player.fetchOne(db, key: [\"email\": \"arthur@example.com\"])\n> try Country.fetchAll(db, keys: [\"FR\", \"US\"])\n> try Citizenship.fetchOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n> \n> let request = Player.filter(key: 1)\n> let request = Player.filter(keys: [1, 2, 3])\n> \n> try Player.deleteOne(db, key: 1)\n> try Player.deleteAll(db, keys: [1, 2, 3])\n> ```\n\n> **Note**: It is not recommended to use `Identifiable` on record types that use an auto-incremented primary key:\n>\n> ```swift\n> // AVOID declaring Identifiable conformance when key is auto-incremented\n> struct Player {\n>     var id: Int64? // Not an id suitable for Identifiable\n>     var name: String\n>     var score: Int\n> }\n> \n> extension Player: FetchableRecord, MutablePersistableRecord {\n>     // Update auto-incremented id upon successful insertion\n>     mutating func didInsert(_ inserted: InsertionSuccess) {\n>         id = inserted.rowID\n>     }\n> }\n> ```\n>\n> For a detailed rationale, please see [issue #1435](https://github.com/groue/GRDB.swift/issues/1435#issuecomment-1740857712).\n\nSome database tables have a single-column primary key which is not called \"id\":\n\n```swift\ntry db.create(table: \"country\") { t in\n    t.primaryKey(\"isoCode\", .text)\n    t.column(\"name\", .text).notNull()\n    t.column(\"population\", .integer).notNull()\n}\n```\n\nIn this case, `Identifiable` conformance can be achieved, for example, by returning the primary key column from the `id` property:\n\n```swift\nstruct Country: Identifiable, FetchableRecord, PersistableRecord {\n    var isoCode: String\n    var name: String\n    var population: Int\n    \n    // Fulfill the Identifiable requirement\n    var id: String { isoCode }\n}\n\nlet france = try dbQueue.read { db in\n    try Country.fetchOne(db, id: \"FR\")\n}\n```\n\n\n## Codable Records\n\nRecord types that adopt an archival protocol ([Codable, Encodable or Decodable](https://developer.apple.com/documentation/foundation/archives_and_serialization/encoding_and_decoding_custom_types)) get free database support just by declaring conformance to the desired [record protocols](#record-protocols-overview):\n\n```swift\n// Declare a record...\nstruct Player: Codable, FetchableRecord, PersistableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// ...and there you go:\ntry dbQueue.write { db in\n    try Player(id: 1, name: \"Arthur\", score: 100).insert(db)\n    let players = try Player.order(\\.score.desc).fetchAll(db)\n}\n```\n\nCodable records encode and decode their properties according to their own implementation of the Encodable and Decodable protocols. Yet databases have specific requirements:\n\n- Properties are always coded according to their preferred database representation, when they have one (all [values](#values) that adopt the [`DatabaseValueConvertible`] protocol).\n- You can customize the encoding and decoding of dates and uuids.\n- Complex properties (arrays, dictionaries, nested structs, etc.) are stored as JSON.\n\nFor more information about Codable records, see:\n\n- [JSON Columns]\n- [Column Names Coding Strategies]\n- [Data, Date, and UUID Coding Strategies]\n- [The userInfo Dictionary]\n- [Tip: Derive Columns from Coding Keys](#tip-derive-columns-from-coding-keys)\n\n> :bulb: **Tip**: see the [Demo Applications] for sample code that uses Codable records.\n\n\n### JSON Columns\n\nWhen a [Codable record](#codable-records) contains a property that is not a simple [value](#values) (Bool, Int, String, Date, Swift enums, etc.), that value is encoded and decoded as a **JSON string**. For example:\n\n```swift\nenum AchievementColor: String, Codable {\n    case bronze, silver, gold\n}\n\nstruct Achievement: Codable {\n    var name: String\n    var color: AchievementColor\n}\n\nstruct Player: Codable, FetchableRecord, PersistableRecord {\n    var name: String\n    var score: Int\n    var achievements: [Achievement] // stored in a JSON column\n}\n\ntry dbQueue.write { db in\n    // INSERT INTO player (name, score, achievements)\n    // VALUES (\n    //   'Arthur',\n    //   100,\n    //   '[{\"color\":\"gold\",\"name\":\"Use Codable Records\"}]')\n    let achievement = Achievement(name: \"Use Codable Records\", color: .gold)\n    let player = Player(name: \"Arthur\", score: 100, achievements: [achievement])\n    try player.insert(db)\n}\n```\n\nGRDB uses the standard [JSONDecoder](https://developer.apple.com/documentation/foundation/jsondecoder) and [JSONEncoder](https://developer.apple.com/documentation/foundation/jsonencoder) from Foundation. By default, Data values are handled with the `.base64` strategy, Date with the `.millisecondsSince1970` strategy, and non conforming floats with the `.throw` strategy.\n\nYou can customize the JSON format by implementing those methods:\n\n```swift\nprotocol FetchableRecord {\n    static func databaseJSONDecoder(for column: String) -> JSONDecoder\n}\n\nprotocol EncodableRecord {\n    static func databaseJSONEncoder(for column: String) -> JSONEncoder\n}\n```\n\n> :bulb: **Tip**: Make sure you set the JSONEncoder `sortedKeys` option. This option makes sure that the JSON output is stable. This stability is required for [Record Comparison] to work as expected, and database observation tools such as [ValueObservation] to accurately recognize changed records.\n\n\n### Column Names Coding Strategies\n\nBy default, [Codable Records] store their values into database columns that match their coding keys: the `teamID` property is stored into the `teamID` column.\n\nThis behavior can be overridden, so that you can, for example, store the `teamID` property into the `team_id` column:\n\n```swift\nprotocol FetchableRecord {\n    static var databaseColumnDecodingStrategy: DatabaseColumnDecodingStrategy { get }\n}\n\nprotocol EncodableRecord {\n    static var databaseColumnEncodingStrategy: DatabaseColumnEncodingStrategy { get }\n}\n```\n\nSee [DatabaseColumnDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasecolumndecodingstrategy) and [DatabaseColumnEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasecolumnencodingstrategy/) to learn about all available strategies.\n\n\n### Data, Date, and UUID Coding Strategies\n\nBy default, [Codable Records] encode and decode their Data properties as blobs, and Date and UUID properties as described in the general [Date and DateComponents](#date-and-datecomponents) and [UUID](#uuid) chapters.\n\nTo sum up: dates encode themselves in the \"YYYY-MM-DD HH:MM:SS.SSS\" format, in the UTC time zone, and decode a variety of date formats and timestamps. UUIDs encode themselves as 16-bytes data blobs, and decode both 16-bytes data blobs and strings such as \"E621E1F8-C36C-495A-93FC-0C247A3E6E5F\".\n\nThose behaviors can be overridden:\n\n```swift\nprotocol FetchableRecord {\n    static func databaseDataDecodingStrategy(for column: String) -> DatabaseDataDecodingStrategy\n    static func databaseDateDecodingStrategy(for column: String) -> DatabaseDateDecodingStrategy\n}\n\nprotocol EncodableRecord {\n    static func databaseDataEncodingStrategy(for column: String) -> DatabaseDataEncodingStrategy\n    static func databaseDateEncodingStrategy(for column: String) -> DatabaseDateEncodingStrategy\n    static func databaseUUIDEncodingStrategy(for column: String) -> DatabaseUUIDEncodingStrategy\n}\n```\n\nSee [DatabaseDataDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedatadecodingstrategy/), [DatabaseDateDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedatedecodingstrategy/), [DatabaseDataEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedataencodingstrategy/), [DatabaseDateEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedateencodingstrategy/), and [DatabaseUUIDEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseuuidencodingstrategy/) to learn about all available strategies.\n\nThere is no customization of uuid decoding, because UUID can already decode all its encoded variants (16-bytes blobs and uuid strings, both uppercase and lowercase).\n\nCustomized coding strategies apply:\n\n- When encoding and decoding database rows to and from records (fetching and persistence methods).\n- In requests by single-column primary key: `fetchOne(_:id:)`, `filter(id:)`, `deleteAll(_:keys:)`, etc.\n\n*They do not apply* in other requests based on data, date, or uuid values.\n\nSo make sure that those are properly encoded in your requests. For example:\n\n```swift\nstruct Player: Codable, FetchableRecord, PersistableRecord, Identifiable {\n    // UUIDs are stored as strings\n    static func databaseUUIDEncodingStrategy(for column: String) -> DatabaseUUIDEncodingStrategy {\n        .uppercaseString\n    }\n    \n    var id: UUID\n    ...\n}\n\ntry dbQueue.write { db in\n    let uuid = UUID()\n    let player = Player(id: uuid, ...)\n    \n    // OK: inserts a player in the database, with a string uuid\n    try player.insert(db)\n    \n    // OK: performs a string-based query, finds the inserted player\n    _ = try Player.filter(id: uuid).fetchOne(db)\n\n    // NOT OK: performs a blob-based query, fails to find the inserted player\n    _ = try Player.filter { $0.id == uuid }.fetchOne(db)\n    \n    // OK: performs a string-based query, finds the inserted player\n    _ = try Player.filter { $0.id == uuid.uuidString }.fetchOne(db)\n}\n```\n\n\n### The userInfo Dictionary\n\nYour [Codable Records] can be stored in the database, but they may also have other purposes. In this case, you may need to customize their implementations of `Decodable.init(from:)` and `Encodable.encode(to:)`, depending on the context.\n\nThe standard way to provide such context is the `userInfo` dictionary. Implement those properties:\n\n```swift\nprotocol FetchableRecord {\n    static var databaseDecodingUserInfo: [CodingUserInfoKey: Any] { get }\n}\n\nprotocol EncodableRecord {\n    static var databaseEncodingUserInfo: [CodingUserInfoKey: Any] { get }\n}\n```\n\nFor example, here is a Player type that customizes its decoding:\n\n```swift\n// A key that holds a decoder's name\nlet decoderName = CodingUserInfoKey(rawValue: \"decoderName\")!\n\nstruct Player: FetchableRecord, Decodable {\n    init(from decoder: Decoder) throws {\n        // Print the decoder name\n        let decoderName = decoder.userInfo[decoderName] as? String\n        print(\"Decoded from \\(decoderName ?? \"unknown decoder\")\")\n        ...\n    }\n}\n```\n\nYou can have a specific decoding from JSON...\n\n```swift\n// prints \"Decoded from JSON\"\nlet decoder = JSONDecoder()\ndecoder.userInfo = [decoderName: \"JSON\"]\nlet player = try decoder.decode(Player.self, from: jsonData)\n```\n\n... and another one from database rows:\n\n```swift\nextension Player: FetchableRecord {\n    static var databaseDecodingUserInfo: [CodingUserInfoKey: Any] {\n        [decoderName: \"database row\"]\n    }\n}\n\n// prints \"Decoded from database row\"\nlet player = try Player.fetchOne(db, ...)\n```\n\n> **Note**: make sure the `databaseDecodingUserInfo` and `databaseEncodingUserInfo` properties are explicitly declared as `[CodingUserInfoKey: Any]`. If they are not, the Swift compiler may silently miss the protocol requirement, resulting in sticky empty userInfo.\n\n\n### Tip: Derive Columns from Coding Keys\n\nCodable types are granted with a [CodingKeys](https://developer.apple.com/documentation/foundation/archives_and_serialization/encoding_and_decoding_custom_types) enum. You can use them to safely define database columns:\n\n```swift\nstruct Player: Codable {\n    var id: Int64\n    var name: String\n    var score: Int\n}\n\nextension Player: FetchableRecord, PersistableRecord {\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n```\n\nSee the [query interface](#the-query-interface) and [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices) for further information.\n\n\n## Record Comparison\n\n**Records that adopt the [EncodableRecord] protocol can compare against other records, or against previous versions of themselves.**\n\nThis helps avoiding costly UPDATE statements when a record has not been edited.\n\n- [The `updateChanges` Methods](#the-updatechanges-methods)\n- [The `databaseEquals` Method](#the-databaseequals-method)\n- [The `databaseChanges` and `hasDatabaseChanges` Methods](#the-databasechanges-and-hasdatabasechanges-methods)\n\n\n### The `updateChanges` Methods\n\nThe `updateChanges` methods perform a database update of the changed columns only (and does nothing if record has no change).\n\n- `updateChanges(_:from:)`\n\n    This method lets you compare two records:\n\n    ```swift\n    if let oldPlayer = try Player.fetchOne(db, id: 42) {\n        var newPlayer = oldPlayer\n        newPlayer.score = 100\n        if try newPlayer.updateChanges(db, from: oldPlayer) {\n            print(\"player was modified, and updated in the database\")\n        } else {\n            print(\"player was not modified, and database was not hit\")\n        }\n    }\n    ```\n\n- `updateChanges(_:modify:)`\n    \n    This method lets you update a record in place:\n    \n    ```swift\n    if var player = try Player.fetchOne(db, id: 42) {\n        let modified = try player.updateChanges(db) {\n            $0.score = 100\n        }\n        if modified {\n            print(\"player was modified, and updated in the database\")\n        } else {\n            print(\"player was not modified, and database was not hit\")\n        }\n    }\n    ```\n\n### The `databaseEquals` Method\n\nThis method returns whether two records have the same database representation:\n\n```swift\nlet oldPlayer: Player = ...\nvar newPlayer: Player = ...\nif newPlayer.databaseEquals(oldPlayer) == false {\n    try newPlayer.save(db)\n}\n```\n\n> **Note**: The comparison is performed on the database representation of records. As long as your record type adopts the EncodableRecord protocol, you don't need to care about Equatable.\n\n\n### The `databaseChanges` and `hasDatabaseChanges` Methods\n\n`databaseChanges(from:)` returns a dictionary of differences between two records:\n\n```swift\nlet oldPlayer = Player(id: 1, name: \"Arthur\", score: 100)\nlet newPlayer = Player(id: 1, name: \"Arthur\", score: 1000)\nfor (column, oldValue) in try newPlayer.databaseChanges(from: oldPlayer) {\n    print(\"\\(column) was \\(oldValue)\")\n}\n// prints \"score was 100\"\n```\n\nFor an efficient algorithm which synchronizes the content of a database table with a JSON payload, check [groue/SortedDifference](https://github.com/groue/SortedDifference).\n\n\n## Record Customization Options\n\nGRDB records come with many default behaviors, that are designed to fit most situations. Many of those defaults can be customized for your specific needs:\n\n- [Persistence Callbacks]: define what happens when you call a persistence method such as `player.insert(db)`\n- [Conflict Resolution]: Run `INSERT OR REPLACE` queries, and generally define what happens when a persistence method violates a unique index.\n- [Columns Selected by a Request]: define which columns are selected by requests such as `Player.fetchAll(db)`.\n- [Beyond FetchableRecord]: the FetchableRecord protocol is not the end of the story.\n\n[Codable Records] have a few extra options:\n\n- [JSON Columns]: control the format of JSON columns.\n- [Column Names Coding Strategies]: control how coding keys are turned into column names\n- [Date and UUID Coding Strategies]: control the format of Date and UUID properties in your Codable records.\n- [The userInfo Dictionary]: adapt your Codable implementation for the database.\n\n\n### Conflict Resolution\n\n**Insertions and updates can create conflicts**: for example, a query may attempt to insert a duplicate row that violates a unique index.\n\nThose conflicts normally end with an error. Yet SQLite let you alter the default behavior, and handle conflicts with specific policies. For example, the `INSERT OR REPLACE` statement handles conflicts with the \"replace\" policy which replaces the conflicting row instead of throwing an error.\n\nThe [five different policies](https://www.sqlite.org/lang_conflict.html) are: abort (the default), replace, rollback, fail, and ignore.\n\n**SQLite let you specify conflict policies at two different places:**\n\n- In the definition of the database table:\n    \n    ```swift\n    // CREATE TABLE player (\n    //     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    //     email TEXT UNIQUE ON CONFLICT REPLACE\n    // )\n    try db.create(table: \"player\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"email\", .text).unique(onConflict: .replace) // <--\n    }\n    \n    // Despite the unique index on email, both inserts succeed.\n    // The second insert replaces the first row:\n    try db.execute(sql: \"INSERT INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    try db.execute(sql: \"INSERT INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    ```\n    \n- In each modification query:\n    \n    ```swift\n    // CREATE TABLE player (\n    //     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    //     email TEXT UNIQUE\n    // )\n    try db.create(table: \"player\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"email\", .text).unique()\n    }\n    \n    // Again, despite the unique index on email, both inserts succeed.\n    try db.execute(sql: \"INSERT OR REPLACE INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    try db.execute(sql: \"INSERT OR REPLACE INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    ```\n\nWhen you want to handle conflicts at the query level, specify a custom `persistenceConflictPolicy` in your type that adopts the PersistableRecord protocol. It will alter the INSERT and UPDATE queries run by the `insert`, `update` and `save` [persistence methods]:\n\n```swift\nprotocol MutablePersistableRecord {\n    /// The policy that handles SQLite conflicts when records are\n    /// inserted or updated.\n    ///\n    /// This property is optional: its default value uses the ABORT\n    /// policy for both insertions and updates, so that GRDB generate\n    /// regular INSERT and UPDATE queries.\n    static var persistenceConflictPolicy: PersistenceConflictPolicy { get }\n}\n\nstruct Player : MutablePersistableRecord {\n    static let persistenceConflictPolicy = PersistenceConflictPolicy(\n        insert: .replace,\n        update: .replace)\n}\n\n// INSERT OR REPLACE INTO player (...) VALUES (...)\ntry player.insert(db)\n```\n\n> **Note**: If you specify the `ignore` policy for inserts, the [`didInsert` callback](#persistence-callbacks) will be called with some random id in case of failed insert. You can detect failed insertions with `insertAndFetch`:\n>     \n> ```swift\n> // How to detect failed `INSERT OR IGNORE`:\n> // INSERT OR IGNORE INTO player ... RETURNING *\n> do {\n>     let insertedPlayer = try player.insertAndFetch(db) {\n>     // Successful insertion\n> catch RecordError.recordNotFound {\n>     // Failed insertion due to IGNORE policy\n> }\n> ```\n>\n> **Note**: The `replace` policy may have to delete rows so that inserts and updates can succeed. Those deletions are not reported to [transaction observers](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactionobserver) (this might change in a future release of SQLite).\n\n### Beyond FetchableRecord\n\n**Some GRDB users eventually discover that the [FetchableRecord] protocol does not fit all situations.** Use cases that are not well handled by FetchableRecord include:\n\n- Your application needs polymorphic row decoding: it decodes some type or another, depending on the values contained in a database row.\n\n- Your application needs to decode rows with a context: each decoded value should be initialized with some extra value that does not come from the database.\n\nSince those use cases are not well handled by FetchableRecord, don't try to implement them on top of this protocol: you'll just fight the framework.\n\n\n## Examples of Record Definitions\n\nWe will show below how to declare a record type for the following database table:\n\n```swift\ntry dbQueue.write { db in\n    try db.create(table: \"place\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"title\", .text).notNull()\n        t.column(\"isFavorite\", .boolean).notNull().defaults(to: false)\n        t.column(\"longitude\", .double).notNull()\n        t.column(\"latitude\", .double).notNull()\n    }\n}\n```\n\nEach one of the three examples below is correct. You will pick one or the other depending on your personal preferences and the requirements of your application:\n\n<details>\n  <summary>Define a Codable struct, and adopt the record protocols you need</summary>\n\nThis is the shortest way to define a record type.\n\nSee the [Record Protocols Overview](#record-protocols-overview), and [Codable Records] for more information.\n\n```swift\nstruct Place: Codable {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    private var latitude: CLLocationDegrees\n    private var longitude: CLLocationDegrees\n    \n    var coordinate: CLLocationCoordinate2D {\n        get {\n            CLLocationCoordinate2D(\n                latitude: latitude,\n                longitude: longitude)\n        }\n        set {\n            latitude = newValue.latitude\n            longitude = newValue.longitude\n        }\n    }\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let title = Column(CodingKeys.title)\n        static let isFavorite = Column(CodingKeys.isFavorite)\n        static let latitude = Column(CodingKeys.latitude)\n        static let longitude = Column(CodingKeys.longitude)\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord { }\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n<details>\n  <summary>Define a plain struct, and adopt the record protocols you need</summary>\n\nSee the [Record Protocols Overview](#record-protocols-overview) for more information.\n    \n```swift\nstruct Place {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    var coordinate: CLLocationCoordinate2D\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let isFavorite = Column(\"isFavorite\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord {\n    /// Creates a record from a database row\n    init(row: Row) {\n        id = row[Columns.id]\n        title = row[Columns.title]\n        isFavorite = row[Columns.isFavorite]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[Columns.latitude],\n            longitude: row[Columns.longitude])\n    }\n}\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    /// The values persisted in the database\n    func encode(to container: inout PersistenceContainer) {\n        container[Columns.id] = id\n        container[Columns.title] = title\n        container[Columns.isFavorite] = isFavorite\n        container[Columns.latitude] = coordinate.latitude\n        container[Columns.longitude] = coordinate.longitude\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n<details>\n  <summary>Define a plain struct optimized for fetching performance</summary>\n\nThis struct derives its persistence methods from the standard Encodable protocol (see [Codable Records]), but performs optimized row decoding by accessing database columns with numeric indexes.\n\nSee the [Record Protocols Overview](#record-protocols-overview) for more information.\n    \n```swift\nstruct Place: Encodable {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    private var latitude: CLLocationDegrees\n    private var longitude: CLLocationDegrees\n    \n    var coordinate: CLLocationCoordinate2D {\n        get {\n            CLLocationCoordinate2D(\n                latitude: latitude,\n                longitude: longitude)\n        }\n        set {\n            latitude = newValue.latitude\n            longitude = newValue.longitude\n        }\n    }\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let title = Column(CodingKeys.title)\n        static let isFavorite = Column(CodingKeys.isFavorite)\n        static let latitude = Column(CodingKeys.latitude)\n        static let longitude = Column(CodingKeys.longitude)\n    }\n    \n    /// Arrange the selected columns and lock their order\n    static var databaseSelection: [any SQLSelectable] {\n        [\n            Columns.id,\n            Columns.title,\n            Columns.favorite,\n            Columns.latitude,\n            Columns.longitude,\n        ]\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord {\n    /// Creates a record from a database row\n    init(row: Row) {\n        // For high performance, use numeric indexes that match the\n        // order of Place.databaseSelection\n        id = row[0]\n        title = row[1]\n        isFavorite = row[2]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[3],\n            longitude: row[4])\n    }\n}\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n\nThe Query Interface\n===================\n\n**The query interface lets you write pure Swift instead of SQL:**\n\n```swift\ntry dbQueue.write { db in\n    // Update database schema\n    try db.create(table: \"player\") { t in ... }\n    \n    // Fetch records\n    let bestPlayers = try Player\n        .order(\\.score.desc)\n        .limit(10)\n        .fetchAll(db)\n    \n    // Count\n    let count = try Player\n        .filter { $0.score >= 1000 }\n        .fetchCount(db)\n    \n    // Batch update\n    try Player\n        .filter { $0.team == \"Reds\" }\n        .updateAll(db) { $0.score += 100 }\n    \n    // Batch delete\n    try Player\n        .filter { $0.score == 0 }\n        .deleteAll(db)\n}\n```\n\nYou need to open a [database connection] before you can query the database.\n\nPlease bear in mind that the query interface can not generate all possible SQL queries. You may also *prefer* writing SQL, and this is just OK. From little snippets to full queries, your SQL skills are welcome:\n\n```swift\ntry dbQueue.write { db in\n    // Update database schema (with SQL)\n    try db.execute(sql: \"CREATE TABLE player (...)\")\n    \n    // Fetch records (with SQL)\n    let bestPlayers = try Player.fetchAll(db, sql: \"\"\"\n        SELECT * FROM player ORDER BY score DESC LIMIT 10\n        \"\"\")\n    \n    // Count (with an SQL snippet)\n    let minScore = 1000\n    let count = try Player\n        .filter(sql: \"score >= ?\", arguments: [minScore])\n        .fetchCount(db)\n    \n    // Update (with SQL)\n    try db.execute(sql: \"UPDATE player SET score = score + 100 WHERE team = 'Reds'\")\n    \n    // Delete (with SQL)\n    try db.execute(sql: \"DELETE FROM player WHERE score = 0\")\n}\n```\n\nSo don't miss the [SQL API](#sqlite-api).\n\n> **Note**: the generated SQL may change between GRDB releases, without notice: don't have your application rely on any specific SQL output.\n\n- [The Database Schema](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema)\n- [Requests](#requests)\n- [Expressions](#expressions)\n    - [SQL Operators](#sql-operators)\n    - [SQL Functions](#sql-functions)\n- [Embedding SQL in Query Interface Requests]\n- [Fetching from Requests]\n- [Fetching by Key](#fetching-by-key)\n- [Testing for Record Existence](#testing-for-record-existence)\n- [Fetching Aggregated Values](#fetching-aggregated-values)\n- [Delete Requests](#delete-requests)\n- [Update Requests](#update-requests)\n- [Custom Requests](#custom-requests)\n- :blue_book: [Associations and Joins](Documentation/AssociationsBasics.md)\n- :blue_book: [Common Table Expressions]\n- :blue_book: [Query Interface Organization]\n\n## Requests\n\nüìñ [`QueryInterfaceRequest`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest), [`Table`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/table)\n\n**The query interface requests** let you fetch values from the database:\n\n```swift\nlet request = Player.filter { $0.email != nil }.order(\\.name)\nlet players = try request.fetchAll(db)  // [Player]\nlet count = try request.fetchCount(db)  // Int\n```\n\nQuery interface requests usually start from **a type** that adopts the `TableRecord` protocol:\n\n```swift\nstruct Player: TableRecord { ... }\n\n// The request for all players:\nlet request = Player.all()\nlet players = try request.fetchAll(db) // [Player]\n```\n\nWhen you can not use a record type, use `Table`:\n\n```swift\n// The request for all rows from the player table:\nlet table = Table(\"player\")\nlet request = table.all()\nlet rows = try request.fetchAll(db)    // [Row]\n\n// The request for all players from the player table:\nlet table = Table<Player>(\"player\")\nlet request = table.all()\nlet players = try request.fetchAll(db) // [Player]\n```\n\n> **Note**: all examples in the documentation below use a record type, but you can always substitute a `Table` instead.\n\nNext, declare the table **columns** that you want to use for filtering, or sorting, in a nested type named `Columns`:\n\n```swift\nextension Player {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let name = Column(\"name\")\n    }\n}\n```\n\nWhen `Player` is `Codable`, you'll prefer defining columns from coding keys:\n\n```swift\nextension Player {\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n    }\n}\n```\n\nYou can now build requests with the following methods: `all`, `none`, `select`, `distinct`, `filter`, `matching`, `group`, `having`, `order`, `reversed`, `limit`, `joining`, `including`, `with`. All those methods return another request, which you can further refine by applying another method: `Player.select(...).filter(...).order(...)`.\n\n- [`all()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord/all()), [`none()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord/none()): the requests for all rows, or no row.\n\n    ```swift\n    // SELECT * FROM player\n    Player.all()\n    ```\n    \n    By default, all columns are selected. See [Columns Selected by a Request].\n\n- [`select(...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/selectionrequest/select(_:)-ruzy) and [`select(..., as:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/select(_:as:)-58954) define the selected columns. See [Columns Selected by a Request].\n    \n    ```swift\n    // SELECT name FROM player\n    Player.select(\\.name, as: String.self)\n    ```\n\n- [`selectID()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/selectID()) is available on [Identifiable Records]. It supports all tables that have a single-column primary key:\n\n    ```swift\n    // SELECT id FROM player\n    Player.selectID()\n    \n    // SELECT id FROM player WHERE name IS NOT NULL\n    Player.filter { $0.name != nil }.selectID()\n    ```\n\n- [`annotated(with: expression...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/selectionrequest/annotated(with:)-1satx) extends the selection.\n\n    ```swift\n    // SELECT *, (score + bonus) AS total FROM player\n    Player.annotated { ($0.score + $0.bonus).forKey(\"total\") }\n    ```\n\n- [`annotated(with: aggregate)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/annotated(with:)-74xfs) extends the selection with [association aggregates](Documentation/AssociationsBasics.md#association-aggregates).\n    \n    ```swift\n    // SELECT team.*, COUNT(DISTINCT player.id) AS playerCount\n    // FROM team\n    // LEFT JOIN player ON player.teamId = team.id\n    // GROUP BY team.id\n    Team.annotated(with: Team.players.count)\n    ```\n\n- [`annotated(withRequired: association)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/annotated(withrequired:)) and [`annotated(withOptional: association)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/annotated(withoptional:)) extends the selection with [Associations].\n    \n    ```swift\n    // SELECT player.*, team.color\n    // FROM player\n    // JOIN team ON team.id = player.teamId\n    Player.annotated(withRequired: Player.team.select(\\.color))\n    ```\n\n- [`distinct()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/distinct()) performs uniquing.\n    \n    ```swift\n    // SELECT DISTINCT name FROM player\n    Player.select(\\.name, as: String.self).distinct()\n    ```\n\n- [`filter(expression)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/filteredrequest/filter(_:)-6xr3d) applies conditions.\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (1, 2, 3)\n    Player.filter { [1,2,3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE (name IS NOT NULL) AND (height > 1.75)\n    Player.filter { $0.name != nil && $0.height > 1.75 }\n    ```\n\n- [`filter(id:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(id:)) and [`filter(ids:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(ids:)) are type-safe methods available on [Identifiable Records]:\n    \n    ```swift\n    // SELECT * FROM player WHERE id = 1\n    Player.filter(id: 1)\n    \n    // SELECT * FROM country WHERE isoCode IN ('FR', 'US')\n    Country.filter(ids: [\"FR\", \"US\"])\n    ```\n    \n- [`filter(key:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(key:)-1p9sq) and [`filter(keys:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(keys:)-6ggt1) apply conditions on primary and unique keys:\n    \n    ```swift\n    // SELECT * FROM player WHERE id = 1\n    Player.filter(key: 1)\n    \n    // SELECT * FROM country WHERE isoCode IN ('FR', 'US')\n    Country.filter(keys: [\"FR\", \"US\"])\n    \n    // SELECT * FROM citizenship WHERE citizenId = 1 AND countryCode = 'FR'\n    Citizenship.filter(key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n    \n    // SELECT * FROM player WHERE email = 'arthur@example.com'\n    Player.filter(key: [\"email\": \"arthur@example.com\"])\n    ```\n\n- `matching(pattern)` ([FTS3](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/matching(_:)-3s3zr), [FTS5](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/matching(_:)-7c1e8)) performs [full-text search](Documentation/FullTextSearch.md).\n    \n    ```swift\n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    let pattern = FTS3Pattern(matchingAllTokensIn: \"SQLite database\")\n    Document.matching(pattern)\n    ```\n    \n    When the pattern is nil, no row will match.\n\n- [`group(expression, ...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/aggregatingrequest/group(_:)-2g7br) groups rows.\n    \n    ```swift\n    // SELECT name, MAX(score) FROM player GROUP BY name\n    Player\n        .select { [$0.name, max($0.score)] }\n        .group(\\.name)\n    ```\n\n- [`having(expression)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/aggregatingrequest/having(_:)-2oggh) applies conditions on grouped rows.\n    \n    ```swift\n    // SELECT team, MAX(score) FROM player GROUP BY team HAVING MIN(score) >= 1000\n    Player\n        .select { [$0.team, max($0.score)] }\n        .group(\\.team)\n        .having { min($0.score) >= 1000 }\n    ```\n\n- [`having(aggregate)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/having(_:)) applies conditions on grouped rows, according to an [association aggregate](Documentation/AssociationsBasics.md#association-aggregates).\n    \n    ```swift\n    // SELECT team.*\n    // FROM team\n    // LEFT JOIN player ON player.teamId = team.id\n    // GROUP BY team.id\n    // HAVING COUNT(DISTINCT player.id) >= 5\n    Team.having(Team.players.count >= 5)\n    ```\n\n- [`order(ordering, ...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/orderedrequest/order(_:)-9d0hr) sorts.\n    \n    ```swift\n    // SELECT * FROM player ORDER BY name\n    Player.order(\\.name)\n    \n    // SELECT * FROM player ORDER BY score DESC\n    Player.order(\\.score.desc)\n    \n    // SELECT * FROM player ORDER BY score DESC, name\n    Player.order { [$0.score.desc, $0.name] }\n    ```\n    \n    SQLite considers NULL values to be smaller than any other values for sorting purposes. Hence, NULLs naturally appear at the beginning of an ascending ordering and at the end of a descending ordering. With a [custom SQLite build], this can be changed using `.ascNullsLast` and `.descNullsFirst`:\n    \n    ```swift\n    // SELECT * FROM player ORDER BY score ASC NULLS LAST\n    Player.order(\\.name.ascNullsLast)\n    ```\n    \n    Each `order` call clears any previous ordering:\n    \n    ```swift\n    // SELECT * FROM player ORDER BY name\n    Player.order(\\.score).order(\\.name)\n    ```\n\n- [`reversed()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/orderedrequest/reversed()) reverses the eventual orderings.\n    \n    ```swift\n    // SELECT * FROM player ORDER BY score ASC, name DESC\n    Player.order { [$0.score.desc, $0.name] }.reversed()\n    ```\n    \n    If no ordering was already specified, this method has no effect:\n    \n    ```swift\n    // SELECT * FROM player\n    Player.all().reversed()\n    ```\n\n- [`limit(limit, offset: offset)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/limit(_:offset:)) limits and pages results.\n    \n    ```swift\n    // SELECT * FROM player LIMIT 5\n    Player.limit(5)\n    \n    // SELECT * FROM player LIMIT 5 OFFSET 10\n    Player.limit(5, offset: 10)\n    ```\n\n- [`joining(required:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/joining(required:)), [`joining(optional:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/joining(optional:)), [`including(required:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(required:)), [`including(optional:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(optional:)), and [`including(all:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(all:)) fetch and join records through [Associations].\n    \n    ```swift\n    // SELECT player.*, team.*\n    // FROM player\n    // JOIN team ON team.id = player.teamId\n    Player.including(required: Player.team)\n    ```\n\n- [`with(cte)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/with(_:)) embeds a [common table expression]:\n    \n    ```swift\n    // WITH ... SELECT * FROM player\n    let cte = CommonTableExpression(...)\n    Player.with(cte)\n    ```\n\n- Other requests that involve the primary key:\n    \n    - [`selectPrimaryKey(as:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/selectprimarykey(as:)) selects the primary key.\n    \n        ```swift\n        // SELECT id FROM player\n        Player.selectPrimaryKey(as: Int64.self)    // QueryInterfaceRequest<Int64>\n        \n        // SELECT code FROM country\n        Country.selectPrimaryKey(as: String.self)  // QueryInterfaceRequest<String>\n        \n        // SELECT citizenId, countryCode FROM citizenship\n        Citizenship.selectPrimaryKey(as: Row.self) // QueryInterfaceRequest<Row>\n        ```\n        \n    - [`orderByPrimaryKey()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/orderbyprimarykey()) sorts by primary key.\n        \n        ```swift\n        // SELECT * FROM player ORDER BY id\n        Player.orderByPrimaryKey()\n        \n        // SELECT * FROM country ORDER BY code\n        Country.orderByPrimaryKey()\n        \n        // SELECT * FROM citizenship ORDER BY citizenId, countryCode\n        Citizenship.orderByPrimaryKey()\n        ```\n    \n    - [`groupByPrimaryKey()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/groupbyprimarykey()) groups rows by primary key.\n\n\nYou can refine requests by chaining those methods:\n\n```swift\n// SELECT * FROM player WHERE (email IS NOT NULL) ORDER BY name\nPlayer.order(\\.name).filter { $0.email != nil }\n```\n\nThe `select`, `order`, `group`, and `limit` methods ignore and replace previously applied selection, orderings, grouping, and limits. On the opposite, `filter`, `matching`, and `having` methods extend the query:\n\n```swift\nPlayer                          // SELECT * FROM player\n    .filter { $0.name != nil }  // WHERE (name IS NOT NULL)\n    .filter { $0.email != nil } //        AND (email IS NOT NULL)\n    .order(\\.name)              // - ignored -\n    .reversed()                 // - ignored -\n    .order(\\.score)             // ORDER BY score\n    .limit(20, offset: 40)      // - ignored -\n    .limit(10)                  // LIMIT 10\n```\n\n\nRaw SQL snippets are also accepted, with eventual [arguments](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments):\n\n```swift\n// SELECT DATE(creationDate), COUNT(*) FROM player WHERE name = 'Arthur' GROUP BY date(creationDate)\nPlayer\n    .select(sql: \"DATE(creationDate), COUNT(*)\")\n    .filter(sql: \"name = ?\", arguments: [\"Arthur\"])\n    .group(sql: \"DATE(creationDate)\")\n```\n\n\n### Columns Selected by a Request\n\nBy default, query interface requests select all columns:\n\n```swift\n// SELECT * FROM player\nstruct Player: TableRecord { ... }\nlet request = Player.all()\n\n// SELECT * FROM player\nlet table = Table(\"player\")\nlet request = table.all()\n```\n\n**The selection can be changed for each individual requests, or in the case of record-based requests, for all requests built from this record type.**\n\nThe `select(...)` and `select(..., as:)` methods change the selection of a single request (see [Fetching from Requests] for detailed information):\n\n```swift\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\nlet request = Player.select({ max($0.score) }, as: Int.self)\nlet maxScore = try request.fetchOne(db)      // Int?\n```\n\nThe default selection for a record type is controlled by the `databaseSelection` property. For example:\n\n```swift\n// Select a limited set of columns\nstruct RestrictedPlayer: TableRecord {\n    static let databaseTableName = \"player\"\n    \n    enum Columns {\n        static let id = Column(\"id\")\n        static let name = Column(\"name\")\n    }\n    \n    static var databaseSelection: [any SQLSelectable] {\n        [Columns.id, Columns.name]\n    }\n}\n\n// SELECT id, name FROM player\nlet request = RestrictedPlayer.all()\n```\n\n```swift\n// Select all but a few columns\nstruct Player : TableRecord {\n    static var databaseSelection: [any SQLSelectable] { \n        [.allColumns(excluding: [\"generatedColumn\"])]\n    }\n}\n\n// SELECT id, name FROM player\nlet request = RestrictedPlayer.all()\n```\n\n```swift\n// Select all columns and more\nstruct ExtendedPlayer : TableRecord {\n    static let databaseTableName = \"player\"\n    static var databaseSelection: [any SQLSelectable] {\n        [.allColumns, .rowID]\n    }\n}\n\n// SELECT *, rowid FROM player\nlet request = ExtendedPlayer.all()\n```\n\n> **Note**: make sure the `databaseSelection` property is explicitly declared as `[any SQLSelectable]`. If it is not, the Swift compiler may silently miss the protocol requirement, resulting in sticky `SELECT *` requests. To verify your setup, see the [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql) FAQ.\n\n\n## Expressions\n\nFeed [requests](#requests) with SQL expressions built from your Swift code:\n\n\n### SQL Operators\n\nüìñ [`SQLSpecificExpressible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlspecificexpressible)\n\nGRDB comes with a Swift version of many SQLite [built-in operators](https://sqlite.org/lang_expr.html#operators), listed below. But not all: see [Embedding SQL in Query Interface Requests] for a way to add support for missing SQL operators.\n\n- `=`, `<>`, `<`, `<=`, `>`, `>=`, `IS`, `IS NOT`\n    \n    Comparison operators are based on the Swift operators `==`, `!=`, `===`, `!==`, `<`, `<=`, `>`, `>=`:\n    \n    ```swift\n    // SELECT * FROM player WHERE (name = 'Arthur')\n    Player.filter { $0.name == \"Arthur\" }\n    \n    // SELECT * FROM player WHERE (name IS NULL)\n    Player.filter { $0.name == nil }\n    \n    // SELECT * FROM player WHERE (score IS 1000)\n    Player.filter { $0.score === 1000 }\n    \n    // SELECT * FROM rectangle WHERE width < height\n    Rectangle.filter { $0.width < $0.height }\n    ```\n    \n    Subqueries are supported:\n    \n    ```swift\n    // SELECT * FROM player WHERE score = (SELECT max(score) FROM player)\n    let maximumScore = Player.select { max($0.score) }\n    Player.filter { $0.score == maximumScore }\n    \n    // SELECT * FROM player WHERE score = (SELECT max(score) FROM player)\n    let maximumScore = SQLRequest(\"SELECT max(score) FROM player\")\n    Player.filter { $0.score == maximumScore }\n    ```\n    \n    > **Note**: SQLite string comparison, by default, is case-sensitive and not Unicode-aware. See [string comparison](#string-comparison) if you need more control.\n\n- `*`, `/`, `+`, `-`\n    \n    SQLite arithmetic operators are derived from their Swift equivalent:\n    \n    ```swift\n    // SELECT ((temperature * 1.8) + 32) AS fahrenheit FROM planet\n    Planet.select { ($0.temperature * 1.8 + 32).forKey(\"fahrenheit\") }\n    ```\n    \n    > **Note**: an expression like `nameColumn + \"rrr\"` will be interpreted by SQLite as a numerical addition (with funny results), not as a string concatenation. See the `concat` operator below.\n    \n    When you want to join a sequence of expressions with the `+` or `*` operator, use `joined(operator:)`:\n    \n    ```swift\n    // SELECT score + bonus + 1000 FROM player\n    Player.select {\n        [$0.score, $0.bonus, 1000.databaseValue].joined(operator: .add)\n    }\n    ```\n    \n    Note in the example above how you concatenate raw values: `1000.databaseValue`. A plain `1000` would not compile.\n    \n    When the sequence is empty, `joined(operator: .add)` returns 0, and `joined(operator: .multiply)` returns 1.\n\n- `&`, `|`, `~`, `<<`, `>>`\n    \n    Bitwise operations (bitwise and, or, not, left shift, right shift) are derived from their Swift equivalent:\n    \n    ```swift\n    // SELECT mask & 2 AS isRocky FROM planet\n    Planet.select { ($0.mask & 2).forKey(\"isRocky\") }\n    ```\n\n- `||`\n    \n    Concatenate several strings:\n    \n    ```swift\n    // SELECT firstName || ' ' || lastName FROM player\n    Player.select {\n        [$0.firstName, \" \".databaseValue, $0.lastName].joined(operator: .concat)\n    }\n    ```\n    \n    Note in the example above how you concatenate raw strings: `\" \".databaseValue`. A plain `\" \"` would not compile.\n    \n    When the sequence is empty, `joined(operator: .concat)` returns the empty string.\n\n- `AND`, `OR`, `NOT`\n    \n    The SQL logical operators are derived from the Swift `&&`, `||` and `!`:\n    \n    ```swift\n    // SELECT * FROM player WHERE ((NOT isVerified) OR (score < 1000))\n    Player.filter { !$0.isVerified || $0.score < 1000 }\n    ```\n    \n    When you want to join a sequence of expressions with the `AND` or `OR` operator, use `joined(operator:)`:\n    \n    ```swift\n    // SELECT * FROM player WHERE (isVerified AND (score >= 1000) AND (name IS NOT NULL))\n    Player.filter {\n        [$0.isVerified, $0.score >= 1000, $0.name != nil].joined(operator: .and)\n    }\n    ```\n    \n    When the sequence is empty, `joined(operator: .and)` returns true, and `joined(operator: .or)` returns false:\n\n- `BETWEEN`, `IN`, `NOT IN`\n    \n    To check inclusion in a Swift sequence (array, set, range‚Ä¶), call the `contains` method:\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (1, 2, 3)\n    Player.filter { [1, 2, 3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE id NOT IN (1, 2, 3)\n    Player.filter { ![1, 2, 3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE score BETWEEN 0 AND 1000\n    Player.filter { (0...1000).contains($0.score) }\n    \n    // SELECT * FROM player WHERE (score >= 0) AND (score < 1000)\n    Player.filter { (0..<1000).contains($0.score) }\n    \n    // SELECT * FROM player WHERE initial BETWEEN 'A' AND 'N'\n    Player.filter { (\"A\"...\"N\").contains($0.initial) }\n    \n    // SELECT * FROM player WHERE (initial >= 'A') AND (initial < 'N')\n    Player.filter { (\"A\"..<\"N\").contains($0.initial) }\n    ```\n    \n    To check inclusion inside a subquery, call the `contains` method as well:\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (SELECT playerId FROM playerSelection)\n    let selectedPlayerIds = PlayerSelection.select(\\.playerId)\n    Player.filter { selectedPlayerIds.contains($0.id) }\n    \n    // SELECT * FROM player WHERE id IN (SELECT playerId FROM playerSelection)\n    let selectedPlayerIds = SQLRequest(\"SELECT playerId FROM playerSelection\")\n    Player.filter { selectedPlayerIds.contains($0.id) }\n    ```\n    \n    To check inclusion inside a [common table expression], call the `contains` method as well:\n    \n    ```swift\n    // WITH selectedName AS (...)\n    // SELECT * FROM player WHERE name IN selectedName\n    let cte = CommonTableExpression(named: \"selectedName\", ...)\n    Player\n        .with(cte)\n        .filter { cte.contains($0.name) }\n    ```\n    \n    > **Note**: SQLite string comparison, by default, is case-sensitive and not Unicode-aware. See [string comparison](#string-comparison) if you need more control.\n\n- `EXISTS`, `NOT EXISTS`\n    \n    To check if a subquery would return rows, call the `exists` method:\n    \n    ```swift\n    // Teams that have at least one other player\n    //\n    //  SELECT * FROM team\n    //  WHERE EXISTS (SELECT * FROM player WHERE teamId = team.id)\n    let teamAlias = TableAlias<Team>()\n    let player = Player.filter { $0.teamId == teamAlias.id }\n    let teams = Team.aliased(teamAlias).filter(player.exists())\n    \n    // Teams that have no player\n    //\n    //  SELECT * FROM team\n    //  WHERE NOT EXISTS (SELECT * FROM player WHERE teamId = team.id)\n    let teams = Team.aliased(teamAlias).filter(!player.exists())\n    ```\n    \n    In the above example, you use a `TableAlias` in order to let a subquery refer to a column from another table.\n    \n    In the next example, which involves the same table twice, the table alias requires an explicit disambiguation with `TableAlias(name:)`:\n    \n    ```swift    \n    // Players who coach at least one other player\n    //\n    //  SELECT coach.* FROM player coach\n    //  WHERE EXISTS (SELECT * FROM player WHERE coachId = coach.id)\n    let coachAlias = TableAlias<Player>(name: \"coach\")\n    let coachedPlayer = Player.filter { $0.coachId == coachAlias.id }\n    let coaches = Player.aliased(coachAlias).filter(coachedPlayer.exists())\n    ```\n    \n    Finally, subqueries can also be expressed as SQL, with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT coach.* FROM player coach\n    // WHERE EXISTS (SELECT * FROM player WHERE coachId = coach.id)\n    let coachedPlayer = SQLRequest(\"SELECT * FROM player WHERE coachId = \\(coachAlias.id)\")\n    let coaches = Player.aliased(coachAlias).filter(coachedPlayer.exists())\n    ```\n    \n- `LIKE`\n    \n    The SQLite LIKE operator is available as the `like` method:\n    \n    ```swift\n    // SELECT * FROM player WHERE (email LIKE '%@example.com')\n    Player.filter { $0.email.like(\"%@example.com\") }\n    \n    // SELECT * FROM book WHERE (title LIKE '%10\\%%' ESCAPE '\\')\n    Player.filter { $0.email.like(\"%10\\\\%%\", escape: \"\\\\\") }\n    ```\n    \n    > **Note**: the SQLite LIKE operator is case-insensitive but not Unicode-aware. For example, the expression `'a' LIKE 'A'` is true but `'√¶' LIKE '√Ü'` is false.\n\n- `MATCH`\n    \n    The full-text MATCH operator is available through [FTS3Pattern](Documentation/FullTextSearch.md#fts3pattern) (for FTS3 and FTS4 tables) and [FTS5Pattern](Documentation/FullTextSearch.md#fts5pattern) (for FTS5):\n    \n    FTS3 and FTS4:\n    \n    ```swift\n    let pattern = FTS3Pattern(matchingAllTokensIn: \"SQLite database\")\n    \n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    Document.matching(pattern)\n    \n    // SELECT * FROM document WHERE content MATCH 'sqlite database'\n    Document.filter { $0.content.match(pattern) }\n    ```\n    \n    FTS5:\n    \n    ```swift\n    let pattern = FTS5Pattern(matchingAllTokensIn: \"SQLite database\")\n    \n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    Document.matching(pattern)\n    ```\n- `AS`\n    \n    To give an alias to an expression, use the `forKey` method:\n    \n    ```swift\n    // SELECT (score + bonus) AS total\n    // FROM player\n    Player.select { ($0.score + $0.bonus).forKey(\"total\") }\n    ```\n    \n    If you need to refer to this aliased column in another place of the request, use a detached column:\n    \n    ```swift\n    // SELECT (score + bonus) AS total\n    // FROM player \n    // ORDER BY total\n    Player\n        .select { ($0.score + $0.bonus).forKey(\"total\") }\n        .order(Column(\"total\").detached)\n    ```\n    \n    The detached column `Column(\"total\").detached` is not considered as a part of the \"player\" table, so it is always rendered as `total` in the generated SQL, even when the request involves other tables via an [association](Documentation/AssociationsBasics.md) or a [common table expression].\n\n\n### SQL Functions\n\nüìñ [`SQLSpecificExpressible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlspecificexpressible)\n\nGRDB comes with a Swift version of many SQLite [built-in functions](https://sqlite.org/lang_corefunc.html), listed below. But not all: see [Embedding SQL in Query Interface Requests] for a way to add support for missing SQL functions.\n\n- `ABS`, `AVG`, `COALESCE`, `COUNT`, `DATETIME`, `JULIANDAY`, `LENGTH`, `MAX`, `MIN`, `SUM`, `TOTAL`:\n    \n    Those are based on the `abs`, `average`, `coalesce`, `count`, `dateTime`, `julianDay`, `length`, `max`, `min`, `sum`, and `total` Swift functions:\n    \n    ```swift\n    // SELECT MIN(score), MAX(score) FROM player\n    Player.select { [min($0.score), max($0.score)] }\n    \n    // SELECT COUNT(name) FROM player\n    Player.select { count($0.name) }\n    \n    // SELECT COUNT(DISTINCT name) FROM player\n    Player.select { count(distinct: $0.name) }\n    \n    // SELECT JULIANDAY(date, 'start of year') FROM game\n    Game.select { julianDay($0.date, .startOfYear) }\n    ```\n    \n    For more information about the functions `dateTime` and `julianDay`, see [Date And Time Functions](https://www.sqlite.org/lang_datefunc.html).\n\n- `CAST`\n\n    Use the `cast` Swift function:\n    \n    ```swift\n    // SELECT (CAST(wins AS REAL) / games) AS successRate FROM player\n    Player.select { (cast($0.wins, as: .real) / $0.games).forKey(\"successRate\") }\n    ```\n    \n    See [CAST expressions](https://www.sqlite.org/lang_expr.html#castexpr) for more information about SQLite conversions.\n\n- `IFNULL`\n    \n    Use the Swift `??` operator:\n    \n    ```swift\n    // SELECT IFNULL(name, 'Anonymous') FROM player\n    Player.select { $0.name ?? \"Anonymous\" }\n    \n    // SELECT IFNULL(name, email) FROM player\n    Player.select { $0.name ?? $0.email }\n    ```\n\n- `LOWER`, `UPPER`\n    \n    The query interface does not give access to those SQLite functions. Nothing against them, but they are not unicode aware.\n    \n    Instead, GRDB extends SQLite with SQL functions that call the Swift built-in string functions `capitalized`, `lowercased`, `uppercased`, `localizedCapitalized`, `localizedLowercased` and `localizedUppercased`:\n    \n    ```swift\n    Player.select { $0.name.uppercased() }\n    ```\n    \n    > **Note**: When *comparing* strings, you'd rather use a [collation](#string-comparison):\n    >\n    > ```swift\n    > let name: String = ...\n    >\n    > // Not recommended\n    > Player.filter { $0.name.uppercased() == name.uppercased() }\n    >\n    > // Better\n    > Player.filter { $0.name.collating(.caseInsensitiveCompare) == name }\n    > ```\n\n- Custom SQL functions and aggregates\n    \n    You can apply your own [custom SQL functions and aggregates](#custom-functions-):\n    \n    ```swift\n    let myFunction = DatabaseFunction(\"myFunction\", ...)\n    \n    // SELECT myFunction(name) FROM player\n    Player.select { myFunction($0.name) }\n    ```\n\n## Embedding SQL in Query Interface Requests\n\nYou will sometimes want to extend your query interface requests with SQL snippets. This can happen because GRDB does not provide a Swift interface for some SQL function or operator, or because you want to use an SQLite construct that GRDB does not support.\n\nSupport for extensibility is large, but not unlimited. All the SQL queries built by the query interface request have the shape below. _If you need something else, you'll have to use [raw SQL requests](#sqlite-api)._\n\n```sql\nWITH ...     -- 1\nSELECT ...   -- 2\nFROM ...     -- 3\nJOIN ...     -- 4\nWHERE ...    -- 5\nGROUP BY ... -- 6\nHAVING ...   -- 7\nORDER BY ... -- 8\nLIMIT ...    -- 9\n```\n\n1. `WITH ...`: see [Common Table Expressions].\n\n2. `SELECT ...`\n\n    The selection can be provided as raw SQL:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let request = Player.select(sql: \"IFNULL(name, 'O''Brien'), score\")\n    \n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select(sql: \"IFNULL(name, ?), score\", arguments: [suffix])\n    ```\n\n    The selection can be provided with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select(literal: \"IFNULL(name, \\(defaultName)), score\")\n    ```\n    \n    The selection can be provided with a mix of Swift and [SQL Interpolation]:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien') AS displayName, score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select {\n        let displayName: SQL = \"IFNULL(\\($0.name), \\(defaultName)) AS displayName\"\n        return [displayName, $0.score]\n    }\n    ```\n    \n    When the custom SQL snippet should behave as a full-fledged expression, with support for the `+` Swift operator, the `forKey` aliasing method, and all other [SQL Operators](#sql-operators), build an _expression literal_ with the `SQL.sqlExpression` method:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien') AS displayName, score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select {\n        let displayName = SQL(\"IFNULL(\\($0.name), \\(defaultName))\").sqlExpression\n        return [displayName.forKey(\"displayName\"), $0.score]\n    }\n    ```\n    \n    Such expression literals allow you to build a reusable support library of SQL functions or operators that are missing from the query interface. For example, you can define a Swift `date` function:\n    \n    ```swift\n    func date(_ value: some SQLSpecificExpressible) -> SQLExpression {\n        SQL(\"DATE(\\(value))\").sqlExpression\n    }\n    \n    // SELECT * FROM \"player\" WHERE DATE(\"createdAt\") = '2020-01-23'\n    let request = Player.filter { date($0.createdAt) == \"2020-01-23\" }\n    ```\n    \n    See the [Query Interface Organization] for more information about `SQLSpecificExpressible` and `SQLExpression`.\n    \n3. `FROM ...`: only one table is supported here. You can not customize this SQL part.\n\n4. `JOIN ...`: joins are fully controlled by [Associations]. You can not customize this SQL part.\n\n5. `WHERE ...`\n    \n    The WHERE clause can be provided as raw SQL:\n    \n    ```swift\n    // SELECT * FROM player WHERE score >= 1000\n    let request = Player.filter(sql: \"score >= 1000\")\n    \n    // SELECT * FROM player WHERE score >= 1000\n    let minScore = 1000\n    let request = Player.filter(sql: \"score >= ?\", arguments: [minScore])\n    ```\n\n    The WHERE clause can be provided with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT * FROM player WHERE score >= 1000\n    let minScore = 1000\n    let request = Player.filter(literal: \"score >= \\(minScore)\")\n    ```\n    \n    The WHERE clause can be provided with a mix of Swift and [SQL Interpolation]:\n    \n    ```swift\n    // SELECT * FROM player WHERE (score >= 1000) AND (team = 'red')\n    let minScore = 1000\n    let request = Player.filter { \n        let scoreCondition: SQL = \"\\($0.score) >= \\(minScore)\"\n        return scoreCondition && $0.team == \"red\"\n    }\n    ```\n    \n    See `SELECT ...` above for more SQL Interpolation examples.\n    \n6. `GROUP BY ...`\n\n    The GROUP BY clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n7. `HAVING ...`\n\n    The HAVING clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n8. `ORDER BY ...`\n\n    The ORDER BY clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n    In order to support the `desc` and `asc` query interface operators, and the `reversed()` query interface method, you must provide your orderings as _expression literals_ with the `SQL.sqlExpression` method:\n    \n    ```swift\n    // SELECT * FROM \"player\" \n    // ORDER BY (score + bonus) ASC, name DESC\n    let request = Player\n        .order {\n            let total = SQL(\"(\\($0.score) + \\($0.bonus))\").sqlExpression\n            return [total.desc, $0.name]\n        }\n        .reversed()\n    ```\n    \n9. `LIMIT ...`: use the `limit(_:offset:)` method. You can not customize this SQL part.\n\n\n## Fetching from Requests\n\nOnce you have a request, you can fetch the records at the origin of the request:\n\n```swift\n// Some request based on `Player`\nlet request = Player.filter { ... }... // QueryInterfaceRequest<Player>\n\n// Fetch players:\ntry request.fetchCursor(db) // A Cursor of Player\ntry request.fetchAll(db)    // [Player]\ntry request.fetchSet(db)    // Set<Player>\ntry request.fetchOne(db)    // Player?\n```\n\nFor example:\n\n```swift\nlet allPlayers = try Player.fetchAll(db)                            // [Player]\nlet arthur = try Player.filter { $0.name == \"Arthur\" }.fetchOne(db) // Player?\n```\n\nSee [fetching methods](#fetching-methods) for information about the `fetchCursor`, `fetchAll`, `fetchSet` and `fetchOne` methods.\n\n**You sometimes want to fetch other values**.\n\nThe simplest way is to use the request as an argument to a fetching method of the desired type:\n\n```swift\n// Fetch an Int\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\n// Fetch a Row\nlet request = Player.select { [min($0.score), max($0.score)] }\nlet row = try Row.fetchOne(db, request)!     // Row\nlet minScore = row[0] as Int?\nlet maxScore = row[1] as Int?\n```\n\nYou can also change the request so that it knows the type it has to fetch:\n\n- With `asRequest(of:)`, useful when you use [Associations]:\n    \n    ```swift\n    struct BookInfo: FetchableRecord, Decodable {\n        var book: Book\n        var author: Author\n    }\n    \n    // A request of BookInfo\n    let request = Book\n        .including(required: Book.author)\n        .asRequest(of: BookInfo.self)\n    \n    let bookInfos = try dbQueue.read { db in\n        try request.fetchAll(db) // [BookInfo]\n    }\n    ```\n    \n- With `select(..., as:)`, which is handy when you change the selection:\n    \n    ```swift\n    // A request of Int\n    let request = Player.select({ max($0.score) }, as: Int.self)\n    \n    let maxScore = try dbQueue.read { db in\n        try request.fetchOne(db) // Int?\n    }\n    ```\n\n\n## Fetching by Key\n\n**Fetching records according to their primary key** is a common task.\n\n[Identifiable Records] can use the type-safe methods `find(_:id:)`, `fetchOne(_:id:)`, `fetchAll(_:ids:)` and `fetchSet(_:ids:)`:\n\n```swift\ntry Player.find(db, id: 1)                   // Player\ntry Player.fetchOne(db, id: 1)               // Player?\ntry Country.fetchAll(db, ids: [\"FR\", \"US\"])  // [Countries]\n```\n\nAll record types can use `find(_:key:)`, `fetchOne(_:key:)`, `fetchAll(_:keys:)` and `fetchSet(_:keys:)` that apply conditions on primary and unique keys:\n\n```swift\ntry Player.find(db, key: 1)                  // Player\ntry Player.fetchOne(db, key: 1)              // Player?\ntry Country.fetchAll(db, keys: [\"FR\", \"US\"]) // [Country]\ntry Player.fetchOne(db, key: [\"email\": \"arthur@example.com\"])            // Player?\ntry Citizenship.fetchOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"]) // Citizenship?\n```\n\nWhen the table has no explicit primary key, GRDB uses the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html):\n\n```swift\n// SELECT * FROM document WHERE rowid = 1\ntry Document.fetchOne(db, key: 1)            // Document?\n```\n\n**When you want to build a request and plan to fetch from it later**, use a `filter` method:\n\n```swift\nlet request = Player.filter(id: 1)\nlet request = Country.filter(ids: [\"FR\", \"US\"])\nlet request = Player.filter(key: [\"email\": \"arthur@example.com\"])\nlet request = Citizenship.filter(key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\n\n## Testing for Record Existence\n\n**You can check if a request has matching rows in the database.**\n\n```swift\n// Some request based on `Player`\nlet request = Player.filter { ... }...\n\n// Check for player existence:\nlet noSuchPlayer = try request.isEmpty(db) // Bool\n```\n\nYou should check for emptiness instead of counting:\n\n```swift\n// Correct\nlet noSuchPlayer = try request.fetchCount(db) == 0\n// Even better\nlet noSuchPlayer = try request.isEmpty(db)\n```\n\n**You can also check if a given primary or unique key exists in the database.**\n\n[Identifiable Records] can use the type-safe method `exists(_:id:)`:\n\n```swift\ntry Player.exists(db, id: 1)\ntry Country.exists(db, id: \"FR\")\n```\n\nAll record types can use `exists(_:key:)` that can check primary and unique keys:\n\n```swift\ntry Player.exists(db, key: 1)\ntry Country.exists(db, key: \"FR\")\ntry Player.exists(db, key: [\"email\": \"arthur@example.com\"])\ntry Citizenship.exists(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\nYou should check for key existence instead of fetching a record and checking for nil:\n\n```swift\n// Correct\nlet playerExists = try Player.fetchOne(db, id: 1) != nil\n// Even better\nlet playerExists = try Player.exists(db, id: 1)\n```\n\n\n## Fetching Aggregated Values\n\n**Requests can count.** The `fetchCount()` method returns the number of rows that would be returned by a fetch request:\n\n```swift\n// SELECT COUNT(*) FROM player\nlet count = try Player.fetchCount(db) // Int\n\n// SELECT COUNT(*) FROM player WHERE email IS NOT NULL\nlet count = try Player.filter { $0.email != nil }.fetchCount(db)\n\n// SELECT COUNT(DISTINCT name) FROM player\nlet count = try Player.select(\\.name).distinct().fetchCount(db)\n\n// SELECT COUNT(*) FROM (SELECT DISTINCT name, score FROM player)\nlet count = try Player.select { [$0.name, $0.score] }.distinct().fetchCount(db)\n```\n\n\n**Other aggregated values** can also be selected and fetched (see [SQL Functions](#sql-functions)):\n\n```swift\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\nlet request = Player.select { [min($0.score), max($0.score)] }\nlet row = try Row.fetchOne(db, request)!     // Row\nlet minScore = row[0] as Int?\nlet maxScore = row[1] as Int?\n```\n\n\n## Delete Requests\n\n**Requests can delete records**, with the `deleteAll()` method:\n\n```swift\n// DELETE FROM player\ntry Player.deleteAll(db)\n\n// DELETE FROM player WHERE team = 'Reds'\ntry Player\n    .filter { $0.team == \"Reds\" }\n    .deleteAll(db)\n\n// DELETE FROM player ORDER BY score LIMIT 10\ntry Player\n    .order(\\.score)\n    .limit(10)\n    .deleteAll(db)\n```\n\n> **Note** Deletion methods are available on types that adopt the [TableRecord] protocol, and `Table`:\n>\n> ```swift\n> struct Player: TableRecord { ... }\n> try Player.deleteAll(db)          // Fine\n> try Table(\"player\").deleteAll(db) // Just as fine\n> ```\n\n**Deleting records according to their primary key** is a common task.\n\n[Identifiable Records] can use the type-safe methods `deleteOne(_:id:)` and `deleteAll(_:ids:)`:\n\n```swift\ntry Player.deleteOne(db, id: 1)\ntry Country.deleteAll(db, ids: [\"FR\", \"US\"])\n```\n\nAll record types can use `deleteOne(_:key:)` and `deleteAll(_:keys:)` that apply conditions on primary and unique keys:\n\n```swift\ntry Player.deleteOne(db, key: 1)\ntry Country.deleteAll(db, keys: [\"FR\", \"US\"])\ntry Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\ntry Citizenship.deleteOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\nWhen the table has no explicit primary key, GRDB uses the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html):\n\n```swift\n// DELETE FROM document WHERE rowid = 1\ntry Document.deleteOne(db, id: 1)             // Document?\n```\n\n\n## Update Requests\n\n**Requests can batch update records**. The `updateAll()` method accepts *column assignments* defined with the `set(to:)` method:\n\n```swift\n// UPDATE player SET score = 0, isHealthy = 1, bonus = NULL\ntry Player.updateAll(db) { [\n    $0.score.set(to: 0), \n    $0.isHealthy.set(to: true), \n    $0.bonus.set(to: nil),\n] }\n\n// UPDATE player SET score = 0 WHERE team = 'Reds'\ntry Player\n    .filter { $0.team == \"Reds\" }\n    .updateAll(db) { $0.score.set(to: 0) }\n\n// UPDATE player SET isGreat = 1 ORDER BY score DESC LIMIT 10\ntry Player\n    .order(\\.score.desc)\n    .limit(10)\n    .updateAll(db) { $0.isGreat.set(to: true) }\n\n// UPDATE country SET population = 67848156 WHERE id = 'FR'\ntry Country\n    .filter(id: \"FR\")\n    .updateAll(db) { $0.population.set(to: 67_848_156) }\n```\n\nColumn assignments accept any expression:\n\n```swift\n// UPDATE player SET score = score + (bonus * 2)\ntry Player.updateAll(db) {\n    $0.score.set(to: $0.score + $0.bonus * 2)\n}\n```\n\nAs a convenience, you can also use the `+=`, `-=`, `*=`, or `/=` operators:\n\n```swift\n// UPDATE player SET score = score + (bonus * 2)\ntry Player.updateAll(db) { $0.score += $0.bonus * 2 }\n```\n\nDefault [Conflict Resolution] rules apply, and you may also provide a specific one:\n\n```swift\n// UPDATE OR IGNORE player SET ...\ntry Player.updateAll(db, onConflict: .ignore) { /* assignments... */ }\n```\n\n> **Note** The `updateAll` method is available on types that adopt the [TableRecord] protocol, and `Table`:\n>\n> ```swift\n> struct Player: TableRecord { ... }\n> try Player.updateAll(db, ...)          // Fine\n> try Table(\"player\").updateAll(db, ...) // Just as fine\n> ```\n\n\n## Custom Requests\n\nUntil now, we have seen [requests](#requests) created from any type that adopts the [TableRecord] protocol:\n\n```swift\nlet request = Player.all()  // QueryInterfaceRequest<Player>\n```\n\nThose requests of type `QueryInterfaceRequest` can fetch and count:\n\n```swift\ntry request.fetchCursor(db) // A Cursor of Player\ntry request.fetchAll(db)    // [Player]\ntry request.fetchSet(db)    // Set<Player>\ntry request.fetchOne(db)    // Player?\ntry request.fetchCount(db)  // Int\n```\n\n**When the query interface can not generate the SQL you need**, you can still fallback to [raw SQL](#fetch-queries):\n\n```swift\n// Custom SQL is always welcome\ntry Player.fetchAll(db, sql: \"SELECT ...\")   // [Player]\n```\n\nBut you may prefer to bring some elegance back in, and build custom requests:\n\n```swift\n// No custom SQL in sight\ntry Player.customRequest().fetchAll(db) // [Player]\n```\n\n**To build custom requests**, you can use one of the built-in requests or derive requests from other requests.\n\n- [SQLRequest] is a fetch request built from raw SQL. For example:\n    \n    ```swift\n    extension Player {\n        static func filter(color: Color) -> SQLRequest<Player> {\n            SQLRequest<Player>(\n                sql: \"SELECT * FROM player WHERE color = ?\"\n                arguments: [color])\n        }\n    }\n    \n    // [Player]\n    try Player.filter(color: .red).fetchAll(db)\n    ```\n    \n    SQLRequest supports [SQL Interpolation]:\n    \n    ```swift\n    extension Player {\n        static func filter(color: Color) -> SQLRequest<Player> {\n            \"SELECT * FROM player WHERE color = \\(color)\"\n        }\n    }\n    ```\n    \n- The [`asRequest(of:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/asrequest(of:)) method changes the type fetched by the request. It is useful, for example, when you use [Associations]:\n\n    ```swift\n    struct BookInfo: FetchableRecord, Decodable {\n        var book: Book\n        var author: Author\n    }\n    \n    let request = Book\n        .including(required: Book.author)\n        .asRequest(of: BookInfo.self)\n    \n    // [BookInfo]\n    try request.fetchAll(db)\n    ```\n\n- The [`adapted(_:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/fetchrequest/adapted(_:)) method eases the consumption of complex rows with row adapters. See [`RowAdapter`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter) and [`splittingRowAdapters(columnCounts:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/splittingrowadapters(columncounts:)) for a sample code that uses `adapted(_:)`.\n\n\nEncryption\n==========\n\n**GRDB can encrypt your database with [SQLCipher](http://sqlcipher.net) v3.4+.**\n\nUse [CocoaPods](http://cocoapods.org/), and specify in your `Podfile`:\n\n```ruby\n# GRDB with SQLCipher 4\npod 'GRDB.swift/SQLCipher'\npod 'SQLCipher', '~> 4.0'\n\n# GRDB with SQLCipher 3\npod 'GRDB.swift/SQLCipher'\npod 'SQLCipher', '~> 3.4'\n```\n\nMake sure you remove any existing `pod 'GRDB.swift'` from your Podfile. `GRDB.swift/SQLCipher` must be the only active GRDB pod in your whole project, or you will face linker or runtime errors, due to the conflicts between SQLCipher and the system SQLite.\n\n- [Creating or Opening an Encrypted Database](#creating-or-opening-an-encrypted-database)\n- [Changing the Passphrase of an Encrypted Database](#changing-the-passphrase-of-an-encrypted-database)\n- [Exporting a Database to an Encrypted Database](#exporting-a-database-to-an-encrypted-database)\n- [Security Considerations](#security-considerations)\n\n\n### Creating or Opening an Encrypted Database\n\n**You create and open an encrypted database** by providing a passphrase to your [database connection]:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nIt is also in `prepareDatabase` that you perform other [SQLCipher configuration steps](https://www.zetetic.net/sqlcipher/sqlcipher-api/) that must happen early in the lifetime of a SQLCipher connection. For example:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n    try db.execute(sql: \"PRAGMA cipher_page_size = ...\")\n    try db.execute(sql: \"PRAGMA kdf_iter = ...\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nWhen you want to open an existing SQLCipher 3 database with SQLCipher 4, you may want to run the `cipher_compatibility` pragma:\n\n```swift\n// Open an SQLCipher 3 database with SQLCipher 4\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n    try db.execute(sql: \"PRAGMA cipher_compatibility = 3\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nSee [SQLCipher 4.0.0 Release](https://www.zetetic.net/blog/2018/11/30/sqlcipher-400-release/) and [Upgrading to SQLCipher 4](https://discuss.zetetic.net/t/upgrading-to-sqlcipher-4/3283) for more information.\n\n\n### Changing the Passphrase of an Encrypted Database\n\n**You can change the passphrase** of an already encrypted database.\n\nWhen you use a [database queue](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue), open the database with the old passphrase, and then apply the new passphrase:\n\n```swift\ntry dbQueue.write { db in\n    try db.changePassphrase(\"newSecret\")\n}\n```\n\nWhen you use a [database pool](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool), make sure that no concurrent read can happen by changing the passphrase within the `barrierWriteWithoutTransaction` block. You must also ensure all future reads open a new database connection by calling the `invalidateReadOnlyConnections` method:\n\n```swift\ntry dbPool.barrierWriteWithoutTransaction { db in\n    try db.changePassphrase(\"newSecret\")\n    dbPool.invalidateReadOnlyConnections()\n}\n```\n\n> **Note**: When an application wants to keep on using a database queue or pool after the passphrase has changed, it is responsible for providing the correct passphrase to the `usePassphrase` method called in the database preparation function. Consider:\n>\n> ```swift\n> // WRONG: this won't work across a passphrase change\n> let passphrase = try getPassphrase()\n> var config = Configuration()\n> config.prepareDatabase { db in\n>     try db.usePassphrase(passphrase)\n> }\n>\n> // CORRECT: get the latest passphrase when it is needed\n> var config = Configuration()\n> config.prepareDatabase { db in\n>     let passphrase = try getPassphrase()\n>     try db.usePassphrase(passphrase)\n> }\n> ```\n\n> **Note**: The `DatabasePool.barrierWriteWithoutTransaction` method does not prevent [database snapshots](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasesnapshot) from accessing the database during the passphrase change, or after the new passphrase has been applied to the database. Those database accesses may throw errors. Applications should provide their own mechanism for invalidating open snapshots before the passphrase is changed.\n\n> **Note**: Instead of changing the passphrase \"in place\" as described here, you can also export the database in a new encrypted database that uses the new passphrase. See [Exporting a Database to an Encrypted Database](#exporting-a-database-to-an-encrypted-database).\n\n\n### Exporting a Database to an Encrypted Database\n\nProviding a passphrase won't encrypt a clear-text database that already exists, though. SQLCipher can't do that, and you will get an error instead: `SQLite error 26: file is encrypted or is not a database`.\n\nInstead, create a new encrypted database, at a distinct location, and export the content of the existing database. This can both encrypt a clear-text database, or change the passphrase of an encrypted database.\n\nThe technique to do that is [documented](https://discuss.zetetic.net/t/how-to-encrypt-a-plaintext-sqlite-database-to-use-sqlcipher-and-avoid-file-is-encrypted-or-is-not-a-database-errors/868/1) by SQLCipher.\n\nWith GRDB, it gives:\n\n```swift\n// The existing database\nlet existingDBQueue = try DatabaseQueue(path: \"/path/to/existing.db\")\n\n// The new encrypted database, at some distinct location:\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n}\nlet newDBQueue = try DatabaseQueue(path: \"/path/to/new.db\", configuration: config)\n\ntry existingDBQueue.inDatabase { db in\n    try db.execute(\n        sql: \"\"\"\n            ATTACH DATABASE ? AS encrypted KEY ?;\n            SELECT sqlcipher_export('encrypted');\n            DETACH DATABASE encrypted;\n            \"\"\",\n        arguments: [newDBQueue.path, \"secret\"])\n}\n\n// Now the export is completed, and the existing database can be deleted.\n```\n\n\n### Security Considerations\n\n#### Managing the lifetime of the passphrase string\n\nIt is recommended to avoid keeping the passphrase in memory longer than necessary. To do this, make sure you load the passphrase from the `prepareDatabase` method:\n\n```swift\n// NOT RECOMMENDED: this keeps the passphrase in memory longer than necessary\nlet passphrase = try getPassphrase()\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(passphrase)\n}\n\n// RECOMMENDED: only load the passphrase when it is needed\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    let passphrase = try getPassphrase()\n    try db.usePassphrase(passphrase)\n}\n```\n\nThis technique helps manages the lifetime of the passphrase, although keep in mind that the content of a String may remain intact in memory long after the object has been released.\n\nFor even better control over the lifetime of the passphrase in memory, use a Data object which natively provides the `resetBytes` function.\n\n```swift\n// RECOMMENDED: only load the passphrase when it is needed and reset its content immediately after use\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    var passphraseData = try getPassphraseData() // Data\n    defer {\n        passphraseData.resetBytes(in: 0..<passphraseData.count)\n    }\n    try db.usePassphrase(passphraseData)\n}\n```\n\nSome demanding users will want to go further, and manage the lifetime of the raw passphrase bytes. See below.\n\n\n#### Managing the lifetime of the passphrase bytes\n\nGRDB offers convenience methods for providing the database passphrases as Swift strings: `usePassphrase(_:)` and `changePassphrase(_:)`. Those methods don't keep the passphrase String in memory longer than necessary. But they are as secure as the standard String type: the lifetime of actual passphrase bytes in memory is not under control.\n\nWhen you want to precisely manage the passphrase bytes, talk directly to SQLCipher, using its raw C functions.\n\nFor example:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    ... // Carefully load passphrase bytes\n    let code = sqlite3_key(db.sqliteConnection, /* passphrase bytes */)\n    ... // Carefully dispose passphrase bytes\n    guard code == SQLITE_OK else {\n        throw DatabaseError(\n            resultCode: ResultCode(rawValue: code), \n            message: db.lastErrorMessage)\n    }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\n#### Passphrase availability vs. Database availability\n\nWhen the passphrase is securely stored in the system keychain, your application can protect it using the [`kSecAttrAccessible`](https://developer.apple.com/documentation/security/ksecattraccessible) attribute.\n\nSuch protection prevents GRDB from creating SQLite connections when the passphrase is not available:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    let passphrase = try loadPassphraseFromSystemKeychain()\n    try db.usePassphrase(passphrase)\n}\n\n// Success if and only if the passphrase is available\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nFor the same reason, [database pools], which open SQLite connections on demand, may fail at any time as soon as the passphrase becomes unavailable:\n\n```swift\n// Success if and only if the passphrase is available\nlet dbPool = try DatabasePool(path: dbPath, configuration: config)\n\n// May fail if passphrase has turned unavailable\ntry dbPool.read { ... }\n\n// May trigger value observation failure if passphrase has turned unavailable\ntry dbPool.write { ... }\n```\n\nBecause DatabasePool maintains a pool of long-lived SQLite connections, some database accesses will use an existing connection, and succeed. And some other database accesses will fail, as soon as the pool wants to open a new connection. It is impossible to predict which accesses will succeed or fail.\n\nFor the same reason, a database queue, which also maintains a long-lived SQLite connection, will remain available even after the passphrase has turned unavailable.\n\nApplications are thus responsible for protecting database accesses when the passphrase is unavailable. To this end, they can use [Data Protection](https://developer.apple.com/documentation/uikit/protecting_the_user_s_privacy/encrypting_your_app_s_files). They can also destroy their instances of database queue or pool when the passphrase becomes unavailable.\n\n\n## Backup\n\n**You can backup (copy) a database into another.**\n\nBackups can for example help you copying an in-memory database to and from a database file when you implement NSDocument subclasses.\n\n```swift\nlet source: DatabaseQueue = ...      // or DatabasePool\nlet destination: DatabaseQueue = ... // or DatabasePool\ntry source.backup(to: destination)\n```\n\nThe `backup` method blocks the current thread until the destination database contains the same contents as the source database.\n\nWhen the source is a [database pool](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool), concurrent writes can happen during the backup. Those writes may, or may not, be reflected in the backup, but they won't trigger any error.\n\n`Database` has an analogous `backup` method.\n\n```swift\nlet source: DatabaseQueue = ...      // or DatabasePool\nlet destination: DatabaseQueue = ... // or DatabasePool\ntry source.write { sourceDb in\n    try destination.barrierWriteWithoutTransaction { destDb in\n        try sourceDb.backup(to: destDb)\n    }\n}\n```\n\nThis method allows for the choice of source and destination `Database` handles with which to backup the database.\n\n### Backup Progress Reporting\n\nThe `backup` methods take optional `pagesPerStep` and `progress` parameters. Together these parameters can be used to track a database backup in progress and abort an incomplete backup.\n\nWhen `pagesPerStep` is provided, the database backup is performed in _steps_. At each step, no more than `pagesPerStep` database pages are copied from the source to the destination. The backup proceeds one step at a time until all pages have been copied.\n\nWhen a `progress` callback is provided, `progress` is called after every backup step, including the last. Even if a non-default `pagesPerStep` is specified or the backup is otherwise completed in a single step, the `progress` callback will be called.\n\n```swift\ntry source.backup(\n    to: destination,\n    pagesPerStep: ...)\n    { backupProgress in\n       print(\"Database backup progress:\", backupProgress)\n    }\n```\n\n### Aborting an Incomplete Backup\n\nIf a call to `progress` throws when `backupProgress.isComplete == false`, the backup will be aborted and the error rethrown. However, if a call to `progress` throws when `backupProgress.isComplete == true`, the backup is unaffected and the error is silently ignored.\n\n> **Warning**: Passing non-default values of `pagesPerStep` or `progress` to the backup methods is an advanced API intended to provide additional capabilities to expert users. GRDB's backup API provides a faithful, low-level wrapper to the underlying SQLite online backup API. GRDB's documentation is not a comprehensive substitute for the official SQLite [documentation of their backup API](https://www.sqlite.org/c3ref/backup_finish.html).\n\n## Interrupt a Database\n\n**The `interrupt()` method** causes any pending database operation to abort and return at its earliest opportunity.\n\nIt can be called from any thread.\n\n```swift\ndbQueue.interrupt()\ndbPool.interrupt()\n```\n\nA call to `interrupt()` that occurs when there are no running SQL statements is a no-op and has no effect on SQL statements that are started after `interrupt()` returns.\n\nA database operation that is interrupted will throw a DatabaseError with code `SQLITE_INTERRUPT`. If the interrupted SQL operation is an INSERT, UPDATE, or DELETE that is inside an explicit transaction, then the entire transaction will be rolled back automatically. If the rolled back transaction was started by a transaction-wrapping method such as `DatabaseWriter.write` or `Database.inTransaction`, then all database accesses will throw a DatabaseError with code `SQLITE_ABORT` until the wrapping method returns.\n\nFor example:\n\n```swift\ntry dbQueue.write { db in\n    try Player(...).insert(db)     // throws SQLITE_INTERRUPT\n    try Player(...).insert(db)     // not executed\n}                                  // throws SQLITE_INTERRUPT\n\ntry dbQueue.write { db in\n    do {\n        try Player(...).insert(db) // throws SQLITE_INTERRUPT\n    } catch { }\n}                                  // throws SQLITE_ABORT\n\ntry dbQueue.write { db in\n    do {\n        try Player(...).insert(db) // throws SQLITE_INTERRUPT\n    } catch { }\n    try Player(...).insert(db)     // throws SQLITE_ABORT\n}                                  // throws SQLITE_ABORT\n```\n\nYou can catch both `SQLITE_INTERRUPT` and `SQLITE_ABORT` errors:\n\n```swift\ndo {\n    try dbPool.write { db in ... }\n} catch DatabaseError.SQLITE_INTERRUPT, DatabaseError.SQLITE_ABORT {\n    // Oops, the database was interrupted.\n}\n```\n\nFor more information, see [Interrupt A Long-Running Query](https://www.sqlite.org/c3ref/interrupt.html).\n\n\n## Avoiding SQL Injection\n\nSQL injection is a technique that lets an attacker nuke your database.\n\n> ![XKCD: Exploits of a Mom](https://imgs.xkcd.com/comics/exploits_of_a_mom.png)\n>\n> https://xkcd.com/327/\n\nHere is an example of code that is vulnerable to SQL injection:\n\n```swift\n// BAD BAD BAD\nlet id = 1\nlet name = textField.text\ntry dbQueue.write { db in\n    try db.execute(sql: \"UPDATE students SET name = '\\(name)' WHERE id = \\(id)\")\n}\n```\n\nIf the user enters a funny string like `Robert'; DROP TABLE students; --`, SQLite will see the following SQL, and drop your database table instead of updating a name as intended:\n\n```sql\nUPDATE students SET name = 'Robert';\nDROP TABLE students;\n--' WHERE id = 1\n```\n\nTo avoid those problems, **never embed raw values in your SQL queries**. The only correct technique is to provide [arguments](#executing-updates) to your raw SQL queries:\n\n```swift\nlet name = textField.text\ntry dbQueue.write { db in\n    // Good\n    try db.execute(\n        sql: \"UPDATE students SET name = ? WHERE id = ?\",\n        arguments: [name, id])\n    \n    // Just as good\n    try db.execute(\n        sql: \"UPDATE students SET name = :name WHERE id = :id\",\n        arguments: [\"name\": name, \"id\": id])\n}\n```\n\nWhen you use [records](#records) and the [query interface](#the-query-interface), GRDB always prevents SQL injection for you:\n\n```swift\nlet id = 1\nlet name = textField.text\ntry dbQueue.write { db in\n    if var student = try Student.fetchOne(db, id: id) {\n        student.name = name\n        try student.update(db)\n    }\n}\n```\n\n\n## Error Handling\n\nGRDB can throw [DatabaseError](#databaseerror), [RecordError], [RowDecodingError], or crash your program with a [fatal error](#fatal-errors).\n\nConsidering that a local database is not some JSON loaded from a remote server, GRDB focuses on **trusted databases**. Dealing with [untrusted databases](#how-to-deal-with-untrusted-inputs) requires extra care.\n\n- [DatabaseError](#databaseerror)\n- [RecordError]\n- [RowDecodingError]\n- [Fatal Errors](#fatal-errors)\n- [How to Deal with Untrusted Inputs](#how-to-deal-with-untrusted-inputs)\n- [Error Log](#error-log)\n\n\n### DatabaseError\n\nüìñ [`DatabaseError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseerror)\n\n**DatabaseError** are thrown on SQLite errors:\n\n```swift\ndo {\n    try Pet(masterId: 1, name: \"Bobby\").insert(db)\n} catch let error as DatabaseError {\n    // The SQLite error code: 19 (SQLITE_CONSTRAINT)\n    error.resultCode\n    \n    // The extended error code: 787 (SQLITE_CONSTRAINT_FOREIGNKEY)\n    error.extendedResultCode\n    \n    // The eventual SQLite message: FOREIGN KEY constraint failed\n    error.message\n    \n    // The eventual erroneous SQL query\n    // \"INSERT INTO pet (masterId, name) VALUES (?, ?)\"\n    error.sql\n    \n    // The eventual SQL arguments\n    // [1, \"Bobby\"]\n    error.arguments\n    \n    // Full error description\n    // > SQLite error 19: FOREIGN KEY constraint failed -\n    // > while executing `INSERT INTO pet (masterId, name) VALUES (?, ?)`\n    error.description\n}\n```\n\nIf you want to see statement arguments in the error description, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n**SQLite uses [results codes](https://www.sqlite.org/rescode.html) to distinguish between various errors**.\n\nYou can catch a DatabaseError and match on result codes:\n\n```swift\ndo {\n    try ...\n} catch let error as DatabaseError {\n    switch error {\n    case DatabaseError.SQLITE_CONSTRAINT_FOREIGNKEY:\n        // foreign key constraint error\n    case DatabaseError.SQLITE_CONSTRAINT:\n        // any other constraint error\n    default:\n        // any other database error\n    }\n}\n```\n\nYou can also directly match errors on result codes:\n\n```swift\ndo {\n    try ...\n} catch DatabaseError.SQLITE_CONSTRAINT_FOREIGNKEY {\n    // foreign key constraint error\n} catch DatabaseError.SQLITE_CONSTRAINT {\n    // any other constraint error\n} catch {\n    // any other database error\n}\n```\n\nEach DatabaseError has two codes: an `extendedResultCode` (see [extended result code](https://www.sqlite.org/rescode.html#extended_result_code_list)), and a less precise `resultCode` (see [primary result code](https://www.sqlite.org/rescode.html#primary_result_code_list)). Extended result codes are refinements of primary result codes, as `SQLITE_CONSTRAINT_FOREIGNKEY` is to `SQLITE_CONSTRAINT`, for example.\n\n> **Warning**: SQLite has progressively introduced extended result codes across its versions. The [SQLite release notes](http://www.sqlite.org/changes.html) are unfortunately not quite clear about that: write your handling of extended result codes with care.\n\n\n### RecordError\n\nüìñ [`RecordError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recorderror)\n\n**RecordError** is thrown by the [PersistableRecord] protocol when the `update` method could not find any row to update:\n\n```swift\ndo {\n    try player.update(db)\n} catch let RecordError.recordNotFound(databaseTableName: table, key: key) {\n    print(\"Key \\(key) was not found in table \\(table).\")\n}\n```\n\n**RecordError** is also thrown by the [FetchableRecord] protocol when the `find` method does not find any record:\n\n```swift\ndo {\n    let player = try Player.find(db, id: 42)\n} catch let RecordError.recordNotFound(databaseTableName: table, key: key) {\n    print(\"Key \\(key) was not found in table \\(table).\")\n}\n```\n\n\n### RowDecodingError\n\nüìñ [`RowDecodingError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowdecodingerror)\n\n**RowDecodingError** is thrown when the application can not decode a value from a database row. For example:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT NULL AS name\")!\n// RowDecodingError: could not decode String from database value NULL.\nlet name = try row.decode(String.self, forColumn: \"name\")\n```\n\n### Fatal Errors\n\n**Fatal errors notify that the program, or the database, has to be changed.**\n\nThey uncover programmer errors, false assumptions, and prevent misuses. Here are a few examples:\n\n- **The code asks for a non-optional value, when the database contains NULL:**\n    \n    ```swift\n    // fatal error: could not convert NULL to String.\n    let name: String = row[\"name\"]\n    ```\n    \n    Solution: fix the contents of the database, use [NOT NULL constraints](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/columndefinition/notnull(onconflict:)), or load an optional:\n    \n    ```swift\n    let name: String? = row[\"name\"]\n    ```\n\n- **Conversion from database value to Swift type fails:**\n    \n    ```swift\n    // fatal error: could not convert \"Mom‚Äôs birthday\" to Date.\n    let date: Date = row[\"date\"]\n    \n    // fatal error: could not convert \"\" to URL.\n    let url: URL = row[\"url\"]\n    ```\n    \n    Solution: fix the contents of the database, or use [DatabaseValue](#databasevalue) to handle all possible cases:\n    \n    ```swift\n    let dbValue: DatabaseValue = row[\"date\"]\n    if dbValue.isNull {\n        // Handle NULL\n    } else if let date = Date.fromDatabaseValue(dbValue) {\n        // Handle valid date\n    } else {\n        // Handle invalid date\n    }\n    ```\n\n- **The database can't guarantee that the code does what it says:**\n\n    ```swift\n    // fatal error: table player has no unique index on column email\n    try Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\n    ```\n    \n    Solution: add a unique index to the player.email column, or use the `deleteAll` method to make it clear that you may delete more than one row:\n    \n    ```swift\n    try Player.filter { $0.email == \"arthur@example.com\" }.deleteAll(db)\n    ```\n\n- **Database connections are not reentrant:**\n    \n    ```swift\n    // fatal error: Database methods are not reentrant.\n    dbQueue.write { db in\n        dbQueue.write { db in\n            ...\n        }\n    }\n    ```\n    \n    Solution: avoid reentrancy, and instead pass a database connection along.\n\n\n### How to Deal with Untrusted Inputs\n\nLet's consider the code below:\n\n```swift\nlet sql = \"SELECT ...\"\n\n// Some untrusted arguments for the query\nlet arguments: [String: Any] = ...\nlet rows = try Row.fetchCursor(db, sql: sql, arguments: StatementArguments(arguments))\n\nwhile let row = try rows.next() {\n    // Some untrusted database value:\n    let date: Date? = row[0]\n}\n```\n\nIt has two opportunities to throw fatal errors:\n\n- **Untrusted arguments**: The dictionary may contain values that do not conform to the [DatabaseValueConvertible protocol](#values), or may miss keys required by the statement.\n- **Untrusted database content**: The row may contain a non-null value that can't be turned into a date.\n\nIn such a situation, you can still avoid fatal errors by exposing and handling each failure point, one level down in the GRDB API:\n\n```swift\n// Untrusted arguments\nif let arguments = StatementArguments(arguments) {\n    let statement = try db.makeStatement(sql: sql)\n    try statement.setArguments(arguments)\n    \n    var cursor = try Row.fetchCursor(statement)\n    while let row = try iterator.next() {\n        // Untrusted database content\n        let dbValue: DatabaseValue = row[0]\n        if dbValue.isNull {\n            // Handle NULL\n        if let date = Date.fromDatabaseValue(dbValue) {\n            // Handle valid date\n        } else {\n            // Handle invalid date\n        }\n    }\n}\n```\n\nSee [`Statement`] and [DatabaseValue](#databasevalue) for more information.\n\n\n### Error Log\n\n**SQLite can be configured to invoke a callback function containing an error code and a terse error message whenever anomalies occur.**\n\nThis global error callback must be configured early in the lifetime of your application:\n\n```swift\nDatabase.logError = { (resultCode, message) in\n    NSLog(\"%@\", \"SQLite error \\(resultCode): \\(message)\")\n}\n```\n\n> **Warning**: Database.logError must be set before any database connection is opened. This includes the connections that your application opens with GRDB, but also connections opened by other tools, such as third-party libraries. Setting it after a connection has been opened is an SQLite misuse, and has no effect.\n\nSee [The Error And Warning Log](https://sqlite.org/errlog.html) for more information.\n\n\n## Unicode\n\nSQLite lets you store unicode strings in the database.\n\nHowever, SQLite does not provide any unicode-aware string transformations or comparisons.\n\n\n### Unicode functions\n\nThe `UPPER` and `LOWER` built-in SQLite functions are not unicode-aware:\n\n```swift\n// \"J√©R√¥ME\"\ntry String.fetchOne(db, sql: \"SELECT UPPER('J√©r√¥me')\")\n```\n\nGRDB extends SQLite with [SQL functions](#custom-sql-functions-and-aggregates) that call the Swift built-in string functions `capitalized`, `lowercased`, `uppercased`, `localizedCapitalized`, `localizedLowercased` and `localizedUppercased`:\n\n```swift\n// \"J√âR√îME\"\nlet uppercased = DatabaseFunction.uppercase\ntry String.fetchOne(db, sql: \"SELECT \\(uppercased.name)('J√©r√¥me')\")\n```\n\nThose unicode-aware string functions are also readily available in the [query interface](#sql-functions):\n\n```swift\nPlayer.select { $0.name.uppercased }\n```\n\n\n### String Comparison\n\nSQLite compares strings in many occasions: when you sort rows according to a string column, or when you use a comparison operator such as `=` and `<=`.\n\nThe comparison result comes from a *collating function*, or *collation*. SQLite comes with three built-in collations that do not support Unicode: [binary, nocase, and rtrim](https://www.sqlite.org/datatype3.html#collation).\n\nGRDB comes with five extra collations that leverage unicode-aware comparisons based on the standard Swift String comparison functions and operators:\n\n- `unicodeCompare` (uses the built-in `<=` and `==` Swift operators)\n- `caseInsensitiveCompare`\n- `localizedCaseInsensitiveCompare`\n- `localizedCompare`\n- `localizedStandardCompare`\n\nA collation can be applied to a table column. All comparisons involving this column will then automatically trigger the comparison function:\n    \n```swift\ntry db.create(table: \"player\") { t in\n    // Guarantees case-insensitive email unicity\n    t.column(\"email\", .text).unique().collate(.nocase)\n    \n    // Sort names in a localized case insensitive way\n    t.column(\"name\", .text).collate(.localizedCaseInsensitiveCompare)\n}\n\n// Players are sorted in a localized case insensitive way:\nlet players = try Player.order(\\.name).fetchAll(db)\n```\n\n> **Warning**: SQLite *requires* host applications to provide the definition of any collation other than binary, nocase and rtrim. When a database file has to be shared or migrated to another SQLite library of platform (such as the Android version of your application), make sure you provide a compatible collation.\n\nIf you can't or don't want to define the comparison behavior of a column (see warning above), you can still use an explicit collation in SQL requests and in the [query interface](#the-query-interface):\n\n```swift\nlet collation = DatabaseCollation.localizedCaseInsensitiveCompare\nlet players = try Player.fetchAll(db,\n    sql: \"SELECT * FROM player ORDER BY name COLLATE \\(collation.name))\")\nlet players = try Player.order { $0.name.collating(collation) }.fetchAll(db)\n```\n\n\n**You can also define your own collations**:\n\n```swift\nlet collation = DatabaseCollation(\"customCollation\") { (lhs, rhs) -> NSComparisonResult in\n    // return the comparison of lhs and rhs strings.\n}\n\n// Make the collation available to a database connection\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(collation: collation)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\n\n\n## Memory Management\n\nBoth SQLite and GRDB use non-essential memory that help them perform better.\n\nYou can reclaim this memory with the `releaseMemory` method:\n\n```swift\n// Release as much memory as possible.\ndbQueue.releaseMemory()\ndbPool.releaseMemory()\n```\n\nThis method blocks the current thread until all current database accesses are completed, and the memory collected.\n\n> **Warning**: If `DatabasePool.releaseMemory()` is called while a long read is performed concurrently, then no other read access will be possible until this long read has completed, and the memory has been released. If this does not suit your application needs, look for the asynchronous options below:\n\nYou can release memory in an asynchronous way as well:\n\n```swift\n// On a DatabaseQueue\ndbQueue.asyncWriteWithoutTransaction { db in\n    db.releaseMemory()\n}\n\n// On a DatabasePool\ndbPool.releaseMemoryEventually()\n```\n\n`DatabasePool.releaseMemoryEventually()` does not block the current thread, and does not prevent concurrent database accesses. In exchange for this convenience, you don't know when memory has been freed.\n\n\n### Memory Management on iOS\n\n**The iOS operating system likes applications that do not consume much memory.**\n\n[Database queues] and [pools](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool) automatically free non-essential memory when the application receives a memory warning, and when the application enters background.\n\nYou can opt out of this automatic memory management:\n\n```swift\nvar config = Configuration()\nconfig.automaticMemoryManagement = false\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config) // or DatabasePool\n```\n\nFAQ\n===\n\n**[FAQ: Opening Connections](#faq-opening-connections)**\n\n- [How do I create a database in my application?](#how-do-i-create-a-database-in-my-application)\n- [How do I open a database stored as a resource of my application?](#how-do-i-open-a-database-stored-as-a-resource-of-my-application)\n- [How do I close a database connection?](#how-do-i-close-a-database-connection)\n\n**[FAQ: SQL](#faq-sql)**\n\n- [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql)\n\n**[FAQ: General](#faq-general)**\n\n- [How do I monitor the duration of database statements execution?](#how-do-i-monitor-the-duration-of-database-statements-execution)\n- [What Are Experimental Features?](#what-are-experimental-features)\n- [Does GRDB support library evolution and ABI stability?](#does-grdb-support-library-evolution-and-abi-stability)\n\n**[FAQ: Associations](#faq-associations)**\n\n- [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record)\n- [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record)\n- [How do I select only one column of an associated record?](#how-do-i-select-only-one-column-of-an-associated-record)\n\n**[FAQ: ValueObservation](#faq-valueobservation)**\n\n- [Why is ValueObservation not publishing value changes?](#why-is-valueobservation-not-publishing-value-changes)\n\n**[FAQ: Errors](#faq-errors)**\n\n- [Generic parameter 'T' could not be inferred](#generic-parameter-t-could-not-be-inferred)\n- [Mutation of captured var in concurrently-executing code](#mutation-of-captured-var-in-concurrently-executing-code)\n- [SQLite error 1 \"no such column\"](#sqlite-error-1-no-such-column)\n- [SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"](#sqlite-error-10-disk-io-error-sqlite-error-23-not-authorized)\n- [SQLite error 21 \"wrong number of statement arguments\" with LIKE queries](#sqlite-error-21-wrong-number-of-statement-arguments-with-like-queries)\n\n\n## FAQ: Opening Connections\n\n- :arrow_up: [FAQ]\n- [How do I create a database in my application?](#how-do-i-create-a-database-in-my-application)\n- [How do I open a database stored as a resource of my application?](#how-do-i-open-a-database-stored-as-a-resource-of-my-application)\n- [How do I close a database connection?](#how-do-i-close-a-database-connection)\n\n### How do I create a database in my application?\n\nFirst choose a proper location for the database file. Document-based applications will let the user pick a location. Apps that use the database as a global storage will prefer the Application Support directory.\n\nThe sample code below creates or opens a database file inside its dedicated directory (a [recommended practice](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections)). On the first run, a new empty database file is created. On subsequent runs, the database file already exists, so it just opens a connection:\n\n```swift\n// HOW TO create an empty database, or open an existing database file\n\n// Create the \"Application Support/MyDatabase\" directory\nlet fileManager = FileManager.default\nlet appSupportURL = try fileManager.url(\n    for: .applicationSupportDirectory, in: .userDomainMask,\n    appropriateFor: nil, create: true) \nlet directoryURL = appSupportURL.appendingPathComponent(\"MyDatabase\", isDirectory: true)\ntry fileManager.createDirectory(at: directoryURL, withIntermediateDirectories: true)\n\n// Open or create the database\nlet databaseURL = directoryURL.appendingPathComponent(\"db.sqlite\")\nlet dbQueue = try DatabaseQueue(path: databaseURL.path)\n```\n\n### How do I open a database stored as a resource of my application?\n\nOpen a read-only connection to your resource:\n\n```swift\n// HOW TO open a read-only connection to a database resource\n\n// Get the path to the database resource.\nif let dbPath = Bundle.main.path(forResource: \"db\", ofType: \"sqlite\") {\n    // If the resource exists, open a read-only connection.\n    // Writes are disallowed because resources can not be modified. \n    var config = Configuration()\n    config.readonly = true\n    let dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n} else {\n    // The database resource can not be found.\n    // Fix your setup, or report the problem to the user. \n}\n```\n\n### How do I close a database connection?\n\nDatabase connections are automatically closed when `DatabaseQueue` or `DatabasePool` instances are deinitialized.\n\nIf the correct execution of your program depends on precise database closing, perform an explicit call to [`close()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasereader/close()). This method may fail and create zombie connections, so please check its detailed documentation.\n\n## FAQ: SQL\n\n- :arrow_up: [FAQ]\n- [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql)\n\n### How do I print a request as SQL?\n\nWhen you want to debug a request that does not deliver the expected results, you may want to print the SQL that is actually executed.\n\nYou can compile the request into a prepared [`Statement`]:\n\n```swift\ntry dbQueue.read { db in\n    let request = Player.filter { $0.email == \"arthur@example.com\" }\n    let statement = try request.makePreparedRequest(db).statement\n    print(statement) // SELECT * FROM player WHERE email = ?\n    print(statement.arguments) // [\"arthur@example.com\"]\n}\n```\n\nAnother option is to setup a tracing function that prints out the executed SQL requests. For example, provide a tracing function when you connect to the database:\n\n```swift\n// Prints all SQL statements\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace { print($0) }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // Prints \"SELECT * FROM player WHERE email = ?\"\n    let players = try Player.filter { $0.email == \"arthur@example.com\" }.fetchAll(db)\n}\n```\n\nIf you want to see statement arguments such as `'arthur@example.com'` in the logged statements, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n> **Note**: the generated SQL may change between GRDB releases, without notice: don't have your application rely on any specific SQL output.\n\n\n## FAQ: General\n\n- :arrow_up: [FAQ]\n- [How do I monitor the duration of database statements execution?](#how-do-i-monitor-the-duration-of-database-statements-execution)\n- [What Are Experimental Features?](#what-are-experimental-features)\n- [Does GRDB support library evolution and ABI stability?](#does-grdb-support-library-evolution-and-abi-stability)\n\n### How do I monitor the duration of database statements execution?\n\nUse the `trace(options:_:)` method, with the `.profile` option:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace(options: .profile) { event in\n        // Prints all SQL statements with their duration\n        print(event)\n        \n        // Access to detailed profiling information\n        if case let .profile(statement, duration) = event, duration > 0.5 {\n            print(\"Slow query: \\(statement.sql)\")\n        }\n    }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    let players = try Player.filter { $0.email == \"arthur@example.com\" }.fetchAll(db)\n    // Prints \"0.003s SELECT * FROM player WHERE email = ?\"\n}\n```\n\nIf you want to see statement arguments such as `'arthur@example.com'` in the logged statements, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n### What Are Experimental Features?\n\nSince GRDB 1.0, all backwards compatibility guarantees of [semantic versioning](http://semver.org) apply: no breaking change will happen until the next major version of the library.\n\nThere is an exception, though: *experimental features*, marked with the \"**:fire: EXPERIMENTAL**\" badge. Those are advanced features that are too young, or lack user feedback. They are not stabilized yet.\n\nThose experimental features are not protected by semantic versioning, and may break between two minor releases of the library. To help them becoming stable, [your feedback](https://github.com/groue/GRDB.swift/issues) is greatly appreciated.\n\n### Does GRDB support library evolution and ABI stability?\n\nNo, GRDB does not support library evolution and ABI stability. The only promise is API stability according to [semantic versioning](http://semver.org), with an exception for [experimental features](#what-are-experimental-features).\n\nYet, GRDB can be built with the \"Build Libraries for Distribution\" Xcode option (`BUILD_LIBRARY_FOR_DISTRIBUTION`), so that you can build binary frameworks at your convenience.\n\n## FAQ: Associations\n\n- :arrow_up: [FAQ]\n- [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record)\n- [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record)\n- [How do I select only one column of an associated record?](#how-do-i-select-only-one-column-of-an-associated-record)\n\n### How do I filter records and only keep those that are associated to another record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to only fetch books that have an author, and discard anonymous books.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: TableRecord {\n    ...\n}\n```\n\nAnd then we can write our request and only fetch books that have an author, discarding anonymous ones:\n\n```swift\nlet books: [Book] = try dbQueue.read { db in\n    // SELECT book.* FROM book \n    // JOIN author ON author.id = book.authorID\n    let request = Book.joining(required: Book.author)\n    return try request.fetchAll(db)\n}\n```\n\nNote how this request does not use the `filter` method. Indeed, we don't have any condition to express on any column. Instead, we just need to \"require that a book can be joined to its author\".\n\nSee [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record) below for the opposite question.\n\n\n### How do I filter records and only keep those that are NOT associated to another record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to only fetch anonymous books that do not have any author.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: TableRecord {\n    ...\n}\n```\n\nAnd then we can write our request and only fetch anonymous books that don't have any author:\n\n```swift\nlet books: [Book] = try dbQueue.read { db in\n    // SELECT book.* FROM book\n    // LEFT JOIN author ON author.id = book.authorID\n    // WHERE author.id IS NULL\n    let authorAlias = TableAlias<Author>()\n    let request = Book\n        .joining(optional: Book.author.aliased(authorAlias))\n        .filter(!authorAlias.exists)\n    return try request.fetchAll(db)\n}\n```\n\nThis request uses a TableAlias in order to be able to filter on the eventual associated author. We make sure that the `Author.primaryKey` is nil, which is another way to say it does not exist: the book has no author.\n\nSee [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record) above for the opposite question.\n\n\n### How do I select only one column of an associated record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to fetch all books with their author name, but not the full associated author records.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: Decodable, TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: Decodable, TableRecord {\n    ...\n    enum Columns {\n        static let name = Column(CodingKeys.name)\n    }\n}\n```\n\nAnd then we can write our request and the ad-hoc record that decodes it:\n\n```swift\nstruct BookInfo: Decodable, FetchableRecord {\n    var book: Book\n    var authorName: String? // nil when the book is anonymous\n    \n    static func all() -> QueryInterfaceRequest<BookInfo> {\n        // SELECT book.*, author.name AS authorName\n        // FROM book\n        // LEFT JOIN author ON author.id = book.authorID\n        return Book\n            .annotated(withOptional: Book.author.select { \n                $0.name.forKey(CodingKeys.authorName)\n            })\n            .asRequest(of: BookInfo.self)\n    }\n}\n\nlet bookInfos: [BookInfo] = try dbQueue.read { db in\n    BookInfo.all().fetchAll(db)\n}\n```\n\nBy defining the request as a static method of BookInfo, you have access to the private `CodingKeys.authorName`, and a compiler-checked SQL column name.\n\nBy using the `annotated(withOptional:)` method, you append the author name to the top-level selection that can be decoded by the ad-hoc record.\n\nBy using `asRequest(of:)`, you enhance the type-safety of your request.\n\n\n## FAQ: ValueObservation\n\n- :arrow_up: [FAQ]\n- [Why is ValueObservation not publishing value changes?](#why-is-valueobservation-not-publishing-value-changes)\n\n### Why is ValueObservation not publishing value changes?\n\nSometimes it looks that a [ValueObservation] does not notify the changes you expect.\n\nThere may be four possible reasons for this:\n\n1. The expected changes were not committed into the database.\n2. The expected changes were committed into the database, but were quickly overwritten.\n3. The observation was stopped.\n4. The observation does not track the expected database region.\n\nTo answer the first two questions, look at SQL statements executed by the database. This is done when you open the database connection:\n\n```swift\n// Prints all SQL statements\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace { print(\"SQL: \\($0)\") }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nIf, after that, you are convinced that the expected changes were committed into the database, and not overwritten soon after, trace observation events:\n\n```swift\nlet observation = ValueObservation\n    .tracking { db in ... }\n    .print() // <- trace observation events\nlet cancellable = observation.start(...)\n```\n\nLook at the observation logs which start with `cancel` or `failure`: maybe the observation was cancelled by your app, or did fail with an error.\n\nLook at the observation logs which start with `value`: make sure, again, that the expected value was not actually notified, then overwritten.\n\nFinally, look at the observation logs which start with `tracked region`. Does the printed database region cover the expected changes?\n\nFor example:\n\n- `empty`: The empty region, which tracks nothing and never triggers the observation.\n- `player(*)`: The full `player` table\n- `player(id,name)`: The `id` and `name` columns of the `player` table\n- `player(id,name)[1]`: The `id` and `name` columns of the row with id 1 in the `player` table\n- `player(*),team(*)`: Both the full `player` and `team` tables\n\nIf you happen to use the `ValueObservation.trackingConstantRegion(_:)` method and see a mismatch between the tracked region and your expectation, then change the definition of your observation by using `tracking(_:)`. You should witness that the logs which start with `tracked region` now evolve in order to include the expected changes, and that you get the expected notifications.\n\nIf after all those steps (thanks you!), your observation is still failing you, please [open an issue](https://github.com/groue/GRDB.swift/issues/new) and provide a [minimal reproducible example](https://stackoverflow.com/help/minimal-reproducible-example)!\n\n\n## FAQ: Errors\n\n- :arrow_up: [FAQ]\n- [Generic parameter 'T' could not be inferred](#generic-parameter-t-could-not-be-inferred)\n- [Mutation of captured var in concurrently-executing code](#mutation-of-captured-var-in-concurrently-executing-code)\n- [SQLite error 1 \"no such column\"](#sqlite-error-1-no-such-column)\n- [SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"](#sqlite-error-10-disk-io-error-sqlite-error-23-not-authorized)\n- [SQLite error 21 \"wrong number of statement arguments\" with LIKE queries](#sqlite-error-21-wrong-number-of-statement-arguments-with-like-queries)\n\n### Generic parameter 'T' could not be inferred\n    \nYou may get this error when using the `read` and `write` methods of database queues and pools:\n\n```swift\n// Generic parameter 'T' could not be inferred\nlet string = try dbQueue.read { db in\n    let result = try String.fetchOne(db, ...)\n    return result\n}\n```\n\nThis is a limitation of the Swift compiler.\n\nThe general workaround is to explicitly declare the type of the closure result:\n\n```swift\n// General Workaround\nlet string = try dbQueue.read { db -> String? in\n    let result = try String.fetchOne(db, ...)\n    return result\n}\n```\n\nYou can also, when possible, write a single-line closure:\n\n```swift\n// Single-line closure workaround:\nlet string = try dbQueue.read { db in\n    try String.fetchOne(db, ...)\n}\n```\n\n\n### Mutation of captured var in concurrently-executing code\n\nThe `insert` and `save` [persistence methods](#persistablerecord-protocol) can trigger a compiler error in async contexts:\n\n```swift\nvar player = Player(id: nil, name: \"Arthur\")\ntry await dbWriter.write { db in\n    // Error: Mutation of captured var 'player' in concurrently-executing code\n    try player.insert(db)\n}\nprint(player.id) // A non-nil id\n```\n\nWhen this happens, prefer the `inserted` and `saved` methods instead:\n\n```swift\n// OK\nvar player = Player(id: nil, name: \"Arthur\")\nplayer = try await dbWriter.write { [player] db in\n    return try player.inserted(db)\n}\nprint(player.id) // A non-nil id\n```\n\n\n### SQLite error 1 \"no such column\"\n\nThis error message is self-explanatory: do check for misspelled or non-existing column names.\n\nHowever, sometimes this error only happens when an app runs on a recent operating system (iOS 14+, Big Sur+, etc.) The error does not happen with previous ones.\n\nWhen this is the case, there are two possible explanations:\n\n1. Maybe a column name is *really* misspelled or missing from the database schema.\n    \n    To find it, check the SQL statement that comes with the [DatabaseError](#databaseerror).\n\n2. Maybe the application is using the character `\"` instead of the single quote `'` as the delimiter for string literals in raw SQL queries. Recent versions of SQLite have learned to tell about this deviation from the SQL standard, and this is why you are seeing this error. \n    \n    For example: this is not standard SQL: `UPDATE player SET name = \"Arthur\"`.\n    \n    The standard version is: `UPDATE player SET name = 'Arthur'`.\n    \n    It just happens that old versions of SQLite used to accept the former, non-standard version. Newer versions are able to reject it with an error.\n    \n    The fix is to change the SQL statements run by the application: replace `\"` with `'` in your string literals.\n    \n    It may also be time to learn about statement arguments and [SQL injection](#avoiding-sql-injection):\n    \n    ```swift\n    let name: String = ...\n    \n    // NOT STANDARD (double quote)\n    try db.execute(sql: \"\"\"\n        UPDATE player SET name = \"\\(name)\"\n        \"\"\")\n    \n    // STANDARD, BUT STILL NOT RECOMMENDED (single quote)\n    try db.execute(sql: \"UPDATE player SET name = '\\(name)'\")\n    \n    // STANDARD, AND RECOMMENDED (statement arguments)\n    try db.execute(sql: \"UPDATE player SET name = ?\", arguments: [name])\n    \n    // STANDARD, AND RECOMMENDED (SQL interpolation)\n    try db.execute(literal: \"UPDATE player SET name = \\(name)\")\n    ```\n    \nFor more information, see [Double-quoted String Literals Are Accepted](https://sqlite.org/quirks.html#double_quoted_string_literals_are_accepted), and [Configuration.acceptsDoubleQuotedStringLiterals](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration/acceptsdoublequotedstringliterals).\n    \n\n\n### SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"\n\nThose errors may be the sign that SQLite can't access the database due to [data protection](https://developer.apple.com/documentation/uikit/protecting_the_user_s_privacy/encrypting_your_app_s_files).\n\nWhen your application should be able to run in the background on a locked device, it has to catch this error, and, for example, wait for [UIApplicationDelegate.applicationProtectedDataDidBecomeAvailable(_:)](https://developer.apple.com/reference/uikit/uiapplicationdelegate/1623044-applicationprotecteddatadidbecom) or [UIApplicationProtectedDataDidBecomeAvailable](https://developer.apple.com/reference/uikit/uiapplicationprotecteddatadidbecomeavailable) notification and retry the failed database operation.\n\n```swift\ndo {\n    try ...\n} catch DatabaseError.SQLITE_IOERR, DatabaseError.SQLITE_AUTH {\n    // Handle possible data protection error\n}\n```\n\nThis error can also be prevented altogether by using a more relaxed [file protection](https://developer.apple.com/reference/foundation/filemanager/1653059-file_protection_values).\n\n\n### SQLite error 21 \"wrong number of statement arguments\" with LIKE queries\n\nYou may get the error \"wrong number of statement arguments\" when executing a LIKE query similar to:\n\n```swift\nlet name = textField.text\nlet players = try dbQueue.read { db in\n    try Player.fetchAll(db, sql: \"SELECT * FROM player WHERE name LIKE '%?%'\", arguments: [name])\n}\n```\n\nThe problem lies in the `'%?%'` pattern.\n\nSQLite only interprets `?` as a parameter when it is a placeholder for a whole value (int, double, string, blob, null). In this incorrect query, `?` is just a character in the `'%?%'` string: it is not a query parameter, and is not processed in any way. See [https://www.sqlite.org/lang_expr.html#varparam](https://www.sqlite.org/lang_expr.html#varparam) for more information about SQLite parameters.\n\nTo fix the error, you can feed the request with the pattern itself, instead of the name:\n\n```swift\nlet name = textField.text\nlet players: [Player] = try dbQueue.read { db in\n    let pattern = \"%\\(name)%\"\n    return try Player.fetchAll(db, sql: \"SELECT * FROM player WHERE name LIKE ?\", arguments: [pattern])\n}\n```\n\n\nSample Code\n===========\n\n- The [Documentation](#documentation) is full of GRDB snippets.\n- [Demo Applications]\n- Open `GRDB.xcworkspace`: it contains GRDB-enabled playgrounds to play with.\n- [groue/SortedDifference](https://github.com/groue/SortedDifference): How to synchronize a database table with a JSON payload\n\n\n---\n\n**Thanks**\n\n- [Pierlis](http://pierlis.com), where we write great software.\n- [@alextrob](https://github.com/alextrob), [@alexwlchan](https://github.com/alexwlchan), [@bellebethcooper](https://github.com/bellebethcooper), [@bfad](https://github.com/bfad), [@cfilipov](https://github.com/cfilipov), [@charlesmchen-signal](https://github.com/charlesmchen-signal), [@Chiliec](https://github.com/Chiliec), [@chrisballinger](https://github.com/chrisballinger), [@darrenclark](https://github.com/darrenclark), [@davidkraus](https://github.com/davidkraus), [@eburns-vmware](https://github.com/eburns-vmware), [@felixscheinost](https://github.com/felixscheinost), [@fpillet](https://github.com/fpillet), [@gcox](https://github.com/gcox), [@GetToSet](https://github.com/GetToSet), [@gjeck](https://github.com/gjeck), [@guidedways](https://github.com/guidedways), [@gusrota](https://github.com/gusrota), [@haikusw](https://github.com/haikusw), [@hartbit](https://github.com/hartbit), [@holsety](https://github.com/holsety), [@jroselightricks](https://github.com/jroselightricks), [@kdubb](https://github.com/kdubb), [@kluufger](https://github.com/kluufger), [@KyleLeneau](https://github.com/KyleLeneau), [@layoutSubviews](https://github.com/layoutSubviews), [@mallman](https://github.com/mallman), [@MartinP7r](https://github.com/MartinP7r), [@Marus](https://github.com/Marus), [@mattgallagher](https://github.com/mattgallagher), [@MaxDesiatov](https://github.com/MaxDesiatov), [@michaelkirk-signal](https://github.com/michaelkirk-signal), [@mtancock](https://github.com/mtancock), [@pakko972](https://github.com/pakko972), [@peter-ss](https://github.com/peter-ss), [@pierlo](https://github.com/pierlo), [@pocketpixels](https://github.com/pocketpixels), [@pp5x](https://github.com/pp5x), [@professordeng](https://github.com/professordeng), [@robcas3](https://github.com/robcas3), [@runhum](https://github.com/runhum), [@sberrevoets](https://github.com/sberrevoets), [@schveiguy](https://github.com/schveiguy), [@SD10](https://github.com/SD10), [@sobri909](https://github.com/sobri909), [@sroddy](https://github.com/sroddy), [@steipete](https://github.com/steipete), [@swiftlyfalling](https://github.com/swiftlyfalling), [@Timac](https://github.com/Timac), [@tternes](https://github.com/tternes), [@valexa](https://github.com/valexa), [@wuyuehyang](https://github.com/wuyuehyang), [@ZevEisenberg](https://github.com/ZevEisenberg), and [@zmeyc](https://github.com/zmeyc) for their contributions, help, and feedback on GRDB.\n- [@aymerick](https://github.com/aymerick) and [@kali](https://github.com/kali) because SQL.\n- [ccgus/fmdb](https://github.com/ccgus/fmdb) for its excellency.\n\n---\n\n[URIs don't change: people change them.](https://www.w3.org/Provider/Style/URI)\n\n#### Adding support for missing SQL functions or operators\n\nThis chapter was renamed to [Embedding SQL in Query Interface Requests].\n\n#### Advanced DatabasePool\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### After Commit Hook\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)).\n\n#### Asynchronous APIs\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Changes Tracking\n\nThis chapter has been renamed [Record Comparison].\n\n#### Concurrency\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Custom Value Types\n\nCustom Value Types conform to the [`DatabaseValueConvertible`] protocol.\n\n#### Customized Decoding of Database Rows\n\nThis chapter has been renamed [Beyond FetchableRecord].\n\n#### Customizing the Persistence Methods\n\nThis chapter was replaced with [Persistence Callbacks].\n\n#### Database Changes Observation\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseobservation).\n\n#### Database Configuration\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration).\n\n#### Database Queues\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue).\n\n#### Database Pools\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool).\n\n#### Database Snapshots\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### DatabaseWriter and DatabaseReader Protocols\n\nThis chapter was removed. See the references of [DatabaseReader](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasereader) and [DatabaseWriter](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasewriter).\n\n#### Date and UUID Coding Strategies\n\nThis chapter has been renamed [Data, Date, and UUID Coding Strategies].\n\n#### Dealing with External Connections\n\nThis chapter has been superseded by the [Sharing a Database] guide.\n\n#### Differences between Database Queues and Pools\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Enabling FTS5 Support\n\nFTS5 is enabled by default since GRDB 6.7.0.\n\n#### FetchedRecordsController\n\nFetchedRecordsController has been removed in GRDB 5.\n\nThe [Database Observation] chapter describes the other ways to observe the database.\n\n#### Full-Text Search\n\nThis chapter has [moved](Documentation/FullTextSearch.md).\n\n#### Guarantees and Rules\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Joined Queries Support\n\nThis chapter was replaced with the documentation of [splittingRowAdapters(columnCounts:)](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/splittingrowadapters(columncounts:)).\n\n#### List of Record Methods\n\nSee [Records and the Query Interface](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterface).\n\n#### Migrations\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/migrations).\n\n#### NSNumber and NSDecimalNumber\n\nThis chapter has [moved](#nsnumber-nsdecimalnumber-and-decimal).\n\n#### Persistable Protocol\n\nThis protocol has been renamed [PersistableRecord] in GRDB 3.0.\n\n#### PersistenceError\n\nThis error was renamed to [RecordError].\n\n#### Prepared Statements\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement).\n\n#### Record Class\n\nThe [`Record`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/record) class is a legacy GRDB type. Since GRDB 7, it is not recommended to define record types by subclassing the `Record` class.\n\n#### Row Adapters\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter).\n\n#### RowConvertible Protocol\n\nThis protocol has been renamed [FetchableRecord] in GRDB 3.0.\n\n#### TableMapping Protocol\n\nThis protocol has been renamed [TableRecord] in GRDB 3.0.\n\n#### Transactions and Savepoints\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactions).\n\n#### Transaction Hook\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)).\n\n#### TransactionObserver Protocol\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactionobserver).\n\n#### Unsafe Concurrency APIs\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### ValueObservation\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/valueobservation).\n\n#### ValueObservation and DatabaseRegionObservation\n\nThis chapter has been superseded by [ValueObservation] and [DatabaseRegionObservation].\n\n[Associations]: Documentation/AssociationsBasics.md\n[Beyond FetchableRecord]: #beyond-fetchablerecord\n[Identifiable Records]: #identifiable-records\n[Codable Records]: #codable-records\n[Columns Selected by a Request]: #columns-selected-by-a-request\n[common table expression]: Documentation/CommonTableExpressions.md\n[Common Table Expressions]: Documentation/CommonTableExpressions.md\n[Conflict Resolution]: #conflict-resolution\n[Column Names Coding Strategies]: #column-names-coding-strategies\n[Data, Date, and UUID Coding Strategies]: #data-date-and-uuid-coding-strategies\n[Fetching from Requests]: #fetching-from-requests\n[Embedding SQL in Query Interface Requests]: #embedding-sql-in-query-interface-requests\n[Full-Text Search]: Documentation/FullTextSearch.md\n[Migrations]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/migrations\n[The userInfo Dictionary]: #the-userinfo-dictionary\n[JSON Columns]: #json-columns\n[FetchableRecord]: #fetchablerecord-protocol\n[EncodableRecord]: #persistablerecord-protocol\n[PersistableRecord]: #persistablerecord-protocol\n[Record Comparison]: #record-comparison\n[Record Customization Options]: #record-customization-options\n[Persistence Callbacks]: #persistence-callbacks\n[persistence callbacks]: #persistence-callbacks\n[Record Timestamps and Transaction Date]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordtimestamps\n[TableRecord]: #tablerecord-protocol\n[ValueObservation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/valueobservation\n[DatabaseRegionObservation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseregionobservation\n[RxGRDB]: https://github.com/RxSwiftCommunity/RxGRDB\n[DatabaseRegion]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseregion\n[SQL Interpolation]: Documentation/SQLInterpolation.md\n[custom SQLite build]: Documentation/CustomSQLiteBuilds.md\n[Combine]: https://developer.apple.com/documentation/combine\n[Combine Support]: Documentation/Combine.md\n[Concurrency]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency\n[Demo Applications]: Documentation/DemoApps\n[Sharing a Database]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasesharing\n[FAQ]: #faq\n[Database Observation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseobservation\n[SQLRequest]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlrequest\n[SQL literal]: Documentation/SQLInterpolation.md#sql-literal\n[Identifiable]: https://developer.apple.com/documentation/swift/identifiable\n[Query Interface Organization]: Documentation/QueryInterfaceOrganization.md\n[Database Configuration]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration\n[Persistence Methods]: #persistence-methods\n[persistence methods]: #persistence-methods\n[Persistence Methods and the `RETURNING` clause]: #persistence-methods-and-the-returning-clause\n[RecordError]: #recorderror\n[RowDecodingError]: #rowdecodingerror\n[Transactions and Savepoints]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactions\n[`DatabaseQueue`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue\n[Database queues]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue\n[`DatabasePool`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool\n[database pools]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool\n[`DatabaseValueConvertible`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible\n[`StatementArguments`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments\n[Prepared Statements]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[prepared statements]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[`Statement`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[Database Connections]: #database-connections\n[Database connections]: #database-connections\n[database connection]: #database-connections\n",
      "stars_today": 2
    },
    {
      "id": 129699403,
      "name": "tuist",
      "full_name": "tuist/tuist",
      "description": "A virtual platform team for mobile devs who ship ",
      "html_url": "https://github.com/tuist/tuist",
      "stars": 5464,
      "forks": 688,
      "language": "Swift",
      "topics": [
        "ios",
        "objective-c",
        "productivity",
        "scalability",
        "swift",
        "xcode"
      ],
      "created_at": "2018-04-16T07:02:54Z",
      "updated_at": "2026-01-16T18:28:02Z",
      "pushed_at": "2026-01-16T19:30:10Z",
      "open_issues": 252,
      "owner": {
        "login": "tuist",
        "avatar_url": "https://avatars.githubusercontent.com/u/38419084?v=4"
      },
      "readme": "<div align=\"center\">\n  <div>\n    <a href=\"https://tuist.dev\" target=\"_blank\"><img src=\"assets/header.png\" alt=\"header\"/></a>\n  </div>\n  <img src=\"https://img.shields.io/github/commit-activity/w/tuist/tuist?style=flat-square&label=commits\" alt=\"Commit Activity\">\n  <a href=\"https://fosstodon.org/@tuist\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=mastodon&logoColor=f5f5f5\" alt=\"Mastodon badge\"></a>\n  <a href=\"https://bsky.app/profile/tuist.dev\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=bluesky\" alt=\"Bluesky badge\"></a>\n  <a href=\"https://join.slack.com/t/tuistapp/shared_invite/zt-1lqw355mp-zElRwLeoZ2EQsgGEkyaFgg\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=slack\" alt=\"Slack Workspace\"></a>\n  <a href=\"https://t.me/tuist\"><img src=\"https://img.shields.io/badge/tuist-gray.svg?logo=telegram\" alt=\"Slack Workspace\"></a>\n  <div>\n    <a href=\"https://cal.com/team/tuist/cloud?utm_source=banner&utm_campaign=oss\" target=\"_blank\"><img alt=\"Book us with Cal.com\" src=\"https://cal.com/book-with-cal-dark.svg\" width=\"150\"/></a>\n  </div>\n  <a href=\"https://translate.tuist.dev/engage/tuist/\">\n  <img src=\"https://translate.tuist.dev/widget/tuist/svg-badge.svg\" alt=\"Translation status\" />\n  </a>\n</div>\n\n# Tuist\n\nTuist is a virtual platform team for Swift app devs who ship. Through an integrated platform that integrates with your toolchain and projects, we help you stay focused and productive while building apps.\n\nThe following solutions are part of Tuist:\n\n- [üóÇÔ∏è **Generated projects**](https://docs.tuist.dev/en/guides/develop/projects): A solution for more accessible and easier-to-manage Xcode projects.\n- [üöù **Cache**](https://docs.tuist.dev/en/guides/develop/cache): Speed up builds across environments with a content-addressable store.\n- [‚úÖ **Selective testing**](https://docs.tuist.dev/en/guides/develop/selective-testing): Run tests faster by selecting them based on the file changes.\n- [üì¶ **Registry**](https://docs.tuist.dev/en/guides/develop/registry): Speed up the resolution of [Swift Package Index](https://swiftpackageindex.com/)-indexed packages.\n- [üìà **Build insights**](https://docs.tuist.dev/en/guides/develop/insights): Get actionable insights from your projects, builds, and test runs to make informed decisions.\n- [üì± **Bundle insights**](https://docs.tuist.dev/en/guides/develop/bundle-size): Analyze your built apps and get suggestions to improve them.\n- [üì± **Previews**](https://docs.tuist.dev/en/guides/features/previews): Sharing apps (previews) as easy as sharing a link.\n- [‚úÖ **QA**](https://docs.tuist.dev/en/guides/features/qa): QA your app using LLM-based agents.\n\nOpenness and community are cornerstones in shaping Tuist, as we believe they are the key to building the best solution. We recommend checking out the following resources:\n\n- [üìë **Documentation**](https://docs.tuist.dev)\n- [üìö **Handbook**](https://handbook.tuist.dev)\n- [üí¨ **Community forum**](https://community.tuist.dev)\n\n> [!NOTE]\n> Even though our current focus is on the development phase of Apple native apps, we'll gradually expand our focus to include other ecosystems (e.g., Android, RN, and Flutter), and expand beyond just development.\n\n## Get started\n\nYou can run the following command to get started with [Mise] (check out [this page](https://docs.tuist.dev/en/guides/quick-start/get-started) for other methods):\n\n```bash\nmise x tuist@latest -- tuist init\n```\n\n> [!IMPORTANT]\n> The `init` workflow is designed to integrate with an existing Xcode project or create [a generated project](https://docs.tuist.dev/en/guides/features/projects). If you are migrating an existing Xcode project to a generated project, we recommend [checking out these docs](https://docs.tuist.dev/en/guides/features/projects/adoption/migrate/xcode-project).\n\n## Documentation\n\nDo you want to know more about what Tuist can offer you? Or perhaps want to contribute to the project and you need a starting point?\n\nYou can check out [the project documentation](https://docs.tuist.dev).\n\n### Sample projects\n\nYou can find some sample projects in the [examples folder](examples/xcode) or the [awesome Tuist repo](https://github.com/tuist/awesome-tuist)! üéâ\n\n## Development\n\nThis repository represents a monorepo with the following projects:\n\n| Project | Description |\n| ------ | -------  |\n| [cli](/cli) | The command line interface for Tuist |\n| [app](/app) | The Swift-powered iOS and macOS app |\n| [docs](/docs) | The documentation for Tuist |\n| [handbook](/handbook) | The company's handbook |\n\n## Sponsors\n\nSome companies support our community and open source efforts with contributions through [GitHub Sponsors](https://github.com/sponsors/tuist) and [Open Collective Backers](https://opencollective.com/tuistapp). We'd like to give a special mention to the following sponsors:\n\n<table>\n  <tbody>\n    <tr>\n      <td width=\"30%\" align=\"center\">\n        <a href=\"https://monday.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\" target=\"_blank\">\n          <img width=\"300\" src=\"assets/companies/monday.com.svg\" alt=\"mondaycom_logo\"/>\n        </a>\n      </td>\n      <td><a href=\"https://monday.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\">Monday.com</a> is a cloud-based work operating system (Work OS) that empowers teams to run projects and workflows with confidence. It's a versatile platform that combines features of project management, workflow automation, and team collaboration to streamline the way teams work together.</td>\n    </tr>\n    <tr>\n      <td width=\"30%\" align=\"center\">\n        <a href=\"https://lapse.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\" target=\"_blank\">\n          <img width=\"200\" src=\"assets/companies/lapse.svg\" alt=\"lapse_logo\"/>\n        </a>\n      </td>\n      <td><a href=\"https://lapse.com?utm_source=Github&utm_medium=Github_Repo_Content_Ad&utm_content=Developer&&utm_term=tuist\">Lapse</a> is an app designed to reclaim how we take and share memories. A camera for living in the moment and a private photo journal for friends, not followers.</td>\n    </tr>\n  </tbody>\n</table>\n\n## Companies using Tuist\n\n<table>\n  <tbody>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://play.tv2.no\" target=\"_blank\">\n          <img src=\"assets/companies/tv2.svg\" alt=\"tv2_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.depop.com\" target=\"_blank\">\n          <img src=\"assets/companies/depop.svg\" alt=\"depop_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://bendingspoons.com\" target=\"_blank\">\n          <picture>\n            <source\n              srcset=\"assets/companies/bendingspoons-darkmode.png\"\n              media=\"(prefers-color-scheme: dark)\">\n            <img src=\"assets/companies/bendingspoons.png\" alt=\"bendingspoons_logo\"/>\n          </picture>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://globekeeper.com\" target=\"_blank\">\n          <img src=\"assets/companies/globekeeper.png\" alt=\"globekeeper_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://getyourguide.com\" target=\"_blank\">\n          <img src=\"assets/companies/getyourguide.png\" alt=\"getyourguide_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://emplate.it\" target=\"_blank\">\n          <img src=\"assets/companies/emplate.svg\" alt=\"emplate_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.trendyol.com\" target=\"_blank\">\n          <img src=\"assets/companies/Trendyol.png\" alt=\"trendyol_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://angrynerds.co\" target=\"_blank\">\n          <img src=\"assets/companies/angrynerds.svg\" alt=\"angrynerds_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.compass.com\" target=\"_blank\">\n          <img src=\"assets/companies/compass.png\" alt=\"compass_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.wefox.com\" target=\"_blank\">\n          <img src=\"assets/companies/wefox.png\" alt=\"wefox_logo\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.hedvig.com\" target=\"_blank\">\n            <img src=\"assets/companies/hedvig.svg\" alt=\"hedvig_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.takeoutcentral.com\" target=\"_blank\">\n          <img src=\"assets/companies/takeoutcentral.svg\" alt=\"takeoutcentral_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.olx.com.br\" target=\"_blank\">\n          <img src=\"assets/companies/olx.png\" alt=\"olx_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.justeattakeaway.com\" target=\"_blank\">\n          <img src=\"assets/companies/justeattakeaway.svg\" alt=\"justeattakeaway_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://qnips.io\" target=\"_blank\">\n          <img src=\"assets/companies/qnips.svg\" alt=\"qnips_logo\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.telepass.com\" target=\"_blank\">\n          <img src=\"assets/companies/telepass.svg\" alt=\"telepass_logo\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://www.crunchyroll.com\" target=\"_blank\">\n          <img src=\"assets/companies/crunchyroll.svg\" alt=\"crunchyroll_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://altel.kz\" target=\"_blank\">\n          <img src=\"assets/companies/altel.svg\" alt=\"altel_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://tele2.kz\" target=\"_blank\">\n          <img src=\"assets/companies/tele2.svg\" alt=\"altel_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://izi.me/kz\" target=\"_blank\">\n          <img src=\"assets/companies/izi.svg\" alt=\"izi_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://wise.com\" target=\"_blank\">\n          <img src=\"assets/companies/wise.png\" alt=\"wise_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://zapis.kz/\" target=\"_blank\">\n          <img src=\"assets/companies/zapis.svg\" alt=\"wise_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://apps.apple.com/kz/app/rbk-business/id1466194695\" target=\"_blank\">\n          <img src=\"assets/companies/rbkbusiness.svg\" alt=\"rbkbusiness_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://snoonu.com/\" target=\"_blank\">\n          <img src=\"assets/companies/snoonu.svg\" alt=\"rbkbusiness_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\" align=\"center\">\n        <a href=\"https://get.sajda.app\" target=\"_blank\">\n          <img src=\"assets/companies/sajda_app.svg\" alt=\"sajda_logo\" height=\"75\"/>\n        </a>\n      </td>\n    </tr>\n    <tr>\n     <td width=\"20%\" align=\"center\">\n        <a href=\"https://abb-bank.az\" target=\"_blank\">\n          <img src=\"assets/companies/abb-logo-slogan.png\" alt=\"abb_mobile_logo\" height=\"75\"/>\n        </a>\n      </td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n      <td width=\"20%\"></td>\n    </tr>\n  </tbody>\n</table>\n\n## Want to contribute?\n\nYou can use our [contribution docs](https://docs.tuist.dev/en/contributors/code) to get started. You can find good issues for first-time contributors [here](https://github.com/tuist/tuist/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22).\n\n## Core Alumni\n\nThe following people were once core contributors helping steer the project in the right direction and ensuring we have a reliable foundation we can build new features upon:\n\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"http://www.matrixprojects.net\"><img src=\"https://avatars3.githubusercontent.com/u/11914919?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kas</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/danyf90\"><img src=\"https://avatars.githubusercontent.com/u/2794031?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniele Formichelli</b></sub></a><br /></td>\n    <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/waltflanagan\"><img src=\"https://avatars.githubusercontent.com/u/398293?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mike Simons</b></sub></a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://natanrolnik.me\"><img src=\"https://avatars3.githubusercontent.com/u/1164565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Natan Rolnik</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/andreacipriani\"><img src=\"https://avatars3.githubusercontent.com/u/536929?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrea Cipriani</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/ollieatkinson\"><img src=\"https://avatars1.githubusercontent.com/u/1382565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Oliver Atkinson</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/RomainBoulay\"><img src=\"https://avatars1.githubusercontent.com/u/169323?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Romain Boulay</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/laxmorek\"><img src=\"https://avatars1.githubusercontent.com/u/4774319?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kamil Harasimowicz</b></sub></a><br /></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://www.luispadron.com\"><img src=\"https://avatars3.githubusercontent.com/u/13840545?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luis Padron</b></sub></a></td>\n    <td align=\"center\"><a href=\"https://github.com/adellibovi\"><img src=\"https://avatars3.githubusercontent.com/u/67916?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alfredo Delli Bovi</b></sub></a><br /></td>\n  </tr>\n</table>\n\n## Contributors\n\nThanks goes to these wonderful people:\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kalkwarf\"><img src=\"https://avatars1.githubusercontent.com/u/1033839?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kalkwarf</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/fortmarek\"><img src=\"https://avatars0.githubusercontent.com/u/9371695?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marek Fo≈ôt</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.matrixprojects.net\"><img src=\"https://avatars3.githubusercontent.com/u/11914919?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kas</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://natanrolnik.me\"><img src=\"https://avatars3.githubusercontent.com/u/1164565?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Natan Rolnik</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/svastven\"><img src=\"https://avatars0.githubusercontent.com/u/42235915?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>svastven</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://bhuemer.github.io\"><img src=\"https://avatars2.githubusercontent.com/u/1212480?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Bernhard Huemer</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://djankowski.dev\"><img src=\"https://avatars0.githubusercontent.com/u/10795657?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniel Jankowski</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/facumenzella\"><img src=\"https://avatars1.githubusercontent.com/u/1125252?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Facundo Menzella</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/eito\"><img src=\"https://avatars3.githubusercontent.com/u/775643?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Eric Ito</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/laxmorek\"><img src=\"https://avatars2.githubusercontent.com/u/4774319?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kamil Harasimowicz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/olejnjak\"><img src=\"https://avatars1.githubusercontent.com/u/3148214?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jakub Olejn√≠k</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lakpa\"><img src=\"https://avatars0.githubusercontent.com/u/389328?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ldindu</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gtsifrikas\"><img src=\"https://avatars2.githubusercontent.com/u/8904378?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>George Tsifrikas</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yurapriv\"><img src=\"https://avatars2.githubusercontent.com/u/7814127?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Privezentsev Yura</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ferologics.github.io\"><img src=\"https://avatars2.githubusercontent.com/u/5576161?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Fero</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://heberti.com\"><img src=\"https://avatars0.githubusercontent.com/u/103670?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Heberti Almeida</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://benscheirman.com\"><img src=\"https://avatars0.githubusercontent.com/u/59140?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ben Scheirman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jsorge.net\"><img src=\"https://avatars3.githubusercontent.com/u/2585841?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jared Sorge</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://joeblau.com\"><img src=\"https://avatars1.githubusercontent.com/u/1218847?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Joe Blau</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/dchavezlive\"><img src=\"https://avatars0.githubusercontent.com/u/2475932?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Chavez</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/—Ä–æ–º–∞–Ω-–ø–æ–¥—ã–º–æ–≤-72338ab0/\"><img src=\"https://avatars3.githubusercontent.com/u/10789692?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Roman Podymov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/marcinreliga-fn\"><img src=\"https://avatars0.githubusercontent.com/u/76949651?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marcin Religa</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/adellibovi\"><img src=\"https://avatars3.githubusercontent.com/u/67916?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alfredo Delli Bovi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Jake-Prickett\"><img src=\"https://avatars1.githubusercontent.com/u/26095410?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jake Prickett</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danyf90\"><img src=\"https://avatars.githubusercontent.com/u/2794031?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniele Formichelli</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.facebook.com/PetrachkovSergey\"><img src=\"https://avatars.githubusercontent.com/u/7995896?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sergey Petrachkov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jinuman.github.io/resume\"><img src=\"https://avatars.githubusercontent.com/u/26243835?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jinwoo, Kim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/thedavidharris\"><img src=\"https://avatars.githubusercontent.com/u/5666250?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Harris</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DimaMishchenko\"><img src=\"https://avatars.githubusercontent.com/u/25247301?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmytro Mishchenko</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.sampettersson.com\"><img src=\"https://avatars.githubusercontent.com/u/5459507?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Pettersson</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.joshholtz.com\"><img src=\"https://avatars.githubusercontent.com/u/401294?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Josh Holtz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jierong.dev\"><img src=\"https://avatars.githubusercontent.com/u/7414906?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jierong Li</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/freak4pc\"><img src=\"https://avatars.githubusercontent.com/u/605076?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shai Mishali</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/FranzJBusch\"><img src=\"https://avatars.githubusercontent.com/u/3491887?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Franz Busch</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tiarnann\"><img src=\"https://avatars.githubusercontent.com/u/10522081?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>T√≠arn√°n McGrath</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/softmaxsg\"><img src=\"https://avatars.githubusercontent.com/u/3723817?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vitaly Chupryk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rmnblm\"><img src=\"https://avatars.githubusercontent.com/u/5942764?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Roman Blum</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://nanotek.me\"><img src=\"https://avatars.githubusercontent.com/u/7265334?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Giovanni Filaferro</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/tovkal\"><img src=\"https://avatars.githubusercontent.com/u/5960675?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andr√©s Piz√° B√ºckmann</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://coutinho.dev\"><img src=\"https://avatars.githubusercontent.com/u/17842860?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gabriel Coutinho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@riccardocipolleschi\"><img src=\"https://avatars.githubusercontent.com/u/11162307?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Riccardo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bolismauro\"><img src=\"https://avatars.githubusercontent.com/u/771999?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mauro Bolis</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/iteractive_man\"><img src=\"https://avatars.githubusercontent.com/u/461805?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Peter Weishapl</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://stackoverflow.com/users/1878594/swiftycruz\"><img src=\"https://avatars.githubusercontent.com/u/2609775?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Cruz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/svenmuennich\"><img src=\"https://avatars.githubusercontent.com/u/1932115?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sven M√ºnnich</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/santi-d\"><img src=\"https://avatars.githubusercontent.com/u/993826?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Santiago A. Delgado</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://wojciechkulik.pl\"><img src=\"https://avatars.githubusercontent.com/u/3128467?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Wojciech Kulik</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/iainsmith\"><img src=\"https://avatars.githubusercontent.com/u/993745?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Iain Smith</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/havebeenfitz\"><img src=\"https://avatars.githubusercontent.com/u/31866271?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Max Kraev</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mstfy\"><img src=\"https://avatars.githubusercontent.com/u/5105861?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Yusuf</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/danielbarden\"><img src=\"https://avatars.githubusercontent.com/u/104456?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Daniel Barden</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zzzkk\"><img src=\"https://avatars.githubusercontent.com/u/12541603?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Zofia Kulus</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://randombits.org/\"><img src=\"https://avatars.githubusercontent.com/u/3589315?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>David Peterson</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://bandism.net/\"><img src=\"https://avatars.githubusercontent.com/u/22633385?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ikko Ashimine</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/setoelkahfi\"><img src=\"https://avatars.githubusercontent.com/u/1797197?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Seto Elkahfi / Â°ûÊâò¬∑ÂüÉÂ∞îÂç°Ëè≤</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://apps4everyone.at\"><img src=\"https://avatars.githubusercontent.com/u/1915802?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>apps4everyone</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/LorDisturbia\"><img src=\"https://avatars.githubusercontent.com/u/12445776?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lorenzo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DarkoDamjanovic\"><img src=\"https://avatars.githubusercontent.com/u/11902775?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Darko Damjanovic</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/MarvinNazari\"><img src=\"https://avatars.githubusercontent.com/u/926772?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Marvin Nazari</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://twitter.com/codeOfRobin\"><img src=\"https://avatars.githubusercontent.com/u/5009041?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Robin Malhotra</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/astromonkee\"><img src=\"https://avatars.githubusercontent.com/u/44421303?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Astromonkee</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ezraberch\"><img src=\"https://avatars.githubusercontent.com/u/49635435?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ezraberch</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/cconstable\"><img src=\"https://avatars.githubusercontent.com/u/564781?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Christopher Constable</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/neakor\"><img src=\"https://avatars.githubusercontent.com/u/1827517?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yi Wang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.mustafadur.com\"><img src=\"https://avatars.githubusercontent.com/u/971530?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Dur</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lucabartoletti\"><img src=\"https://avatars.githubusercontent.com/u/838925?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luca Bartoletti</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sujata23\"><img src=\"https://avatars.githubusercontent.com/u/1849089?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sujata Chakraborty</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.viber.com\"><img src=\"https://avatars.githubusercontent.com/u/5096762?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Pavel Trafimuk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://alexsilva.dev/\"><img src=\"https://avatars.githubusercontent.com/u/633535?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alejandro Silva Fern√°ndez</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.jakeadams.co\"><img src=\"https://avatars.githubusercontent.com/u/3605966?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jake Adams</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wattson12\"><img src=\"https://avatars.githubusercontent.com/u/1217873?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Watts</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://erkekin.com\"><img src=\"https://avatars.githubusercontent.com/u/701481?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Erk Ekin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/morozkin\"><img src=\"https://avatars.githubusercontent.com/u/16591888?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Denis Morozov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/orbitekk\"><img src=\"https://avatars.githubusercontent.com/u/4222449?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>orbitekk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.naver.com/wogus3602\"><img src=\"https://avatars.githubusercontent.com/u/46857148?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Park Jae Hyun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/regularberry\"><img src=\"https://avatars.githubusercontent.com/u/565192?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sean Berry</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://hisaac.net\"><img src=\"https://avatars.githubusercontent.com/u/923876?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Isaac Halvorson</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mohitsaxenaknoldus\"><img src=\"https://avatars.githubusercontent.com/u/76725454?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mohit Saxena</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikchmie\"><img src=\"https://avatars.githubusercontent.com/u/15248837?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Miko≈Çaj Chmielewski</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/takinwande\"><img src=\"https://avatars.githubusercontent.com/u/4744429?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Tope Akinwande</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.theinkedengineer.com\"><img src=\"https://avatars.githubusercontent.com/u/13349066?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TheInkedEngineer</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://alexanderweiss.dev\"><img src=\"https://avatars.githubusercontent.com/u/12934015?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander Wei√ü</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kyungpyoda\"><img src=\"https://avatars.githubusercontent.com/u/44656036?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kyungpyoda</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.villewitt.net\"><img src=\"https://avatars.githubusercontent.com/u/522544?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ville Witt</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/paulsamuels\"><img src=\"https://avatars.githubusercontent.com/u/527091?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>paul.s</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aniltaskiran\"><img src=\"https://avatars.githubusercontent.com/u/16738729?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>aniltaskiran</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/unxavi\"><img src=\"https://avatars.githubusercontent.com/u/3817679?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Javier Vieira</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/a-sarris\"><img src=\"https://avatars.githubusercontent.com/u/78614622?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Aris Sarris</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://xxw9999.notion.site/xxw9999/iOS-8585a34b2886419586960c5c02b9d845\"><img src=\"https://avatars.githubusercontent.com/u/67373938?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kimxwan0319</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://florian.codes\"><img src=\"https://avatars.githubusercontent.com/u/7734806?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Florian Fittschen</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jesus-mg-ios\"><img src=\"https://avatars.githubusercontent.com/u/85997060?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jesus (iOS)</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nicholaskim94\"><img src=\"https://avatars.githubusercontent.com/u/7912759?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nicholas Kim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Smponias\"><img src=\"https://avatars.githubusercontent.com/u/14213855?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexandros Smponias</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mangofever\"><img src=\"https://avatars.githubusercontent.com/u/724343?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Go</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AlbGarciam\"><img src=\"https://avatars.githubusercontent.com/u/45308839?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alberto Garcia</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/andreascuderi/\"><img src=\"https://avatars.githubusercontent.com/u/8319309?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrea Scuderi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dogoautilio.wordpress.com/\"><img src=\"https://avatars.githubusercontent.com/u/1487375?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Diogo Autilio</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shahzadmajeed\"><img src=\"https://avatars.githubusercontent.com/u/1209459?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shahzad Majeed</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danrevah\"><img src=\"https://avatars.githubusercontent.com/u/7808742?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nivanchikov\"><img src=\"https://avatars.githubusercontent.com/u/1830010?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nikita Ivanchikov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/xoxo-anastasi-xoxo\"><img src=\"https://avatars.githubusercontent.com/u/28875920?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Anastasia Kazantseva</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/MonocularVision\"><img src=\"https://avatars.githubusercontent.com/u/429790?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Michael McGuire</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.michaelfcollins3.me\"><img src=\"https://avatars.githubusercontent.com/u/104274?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Michael Collins</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/devyhan\"><img src=\"https://avatars.githubusercontent.com/u/45344633?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>YoHan Cho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/euriasb\"><img src=\"https://avatars.githubusercontent.com/u/3721257?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>euriasb</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MontakOleg\"><img src=\"https://avatars.githubusercontent.com/u/1800899?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>MontakOleg</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/oozoofrog\"><img src=\"https://avatars.githubusercontent.com/u/3011832?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>oozoofrog</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MartinStrambach\"><img src=\"https://avatars.githubusercontent.com/u/11178869?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Martin Strambach</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sh-a-n\"><img src=\"https://avatars.githubusercontent.com/u/2219548?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>sh-a-n</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://linkedin.com/in/batuhansaka\"><img src=\"https://avatars.githubusercontent.com/u/9626765?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Batuhan Saka</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jcsoohwancho.github.io\"><img src=\"https://avatars.githubusercontent.com/u/51935215?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>SooHwanCho</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.bouncingball.mobi\"><img src=\"https://avatars.githubusercontent.com/u/798117?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gary Riches</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mustiikhalil.github.io/mustiikhalil/\"><img src=\"https://avatars.githubusercontent.com/u/26250654?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mustiikhalil</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/serejahh\"><img src=\"https://avatars.githubusercontent.com/u/2575555?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Serhii Butenko</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/petrukha-ivan\"><img src=\"https://avatars.githubusercontent.com/u/93926277?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Petrukha Ivan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lo1tuma\"><img src=\"https://avatars.githubusercontent.com/u/169170?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mathias Schreck</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Buju77\"><img src=\"https://avatars.githubusercontent.com/u/266349?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yen-Chia Lin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://coolmathgames.tech\"><img src=\"https://avatars.githubusercontent.com/u/6877780?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mary </b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/woohyunjin06\"><img src=\"https://avatars.githubusercontent.com/u/30452977?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hyunjin</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kevin58332\"><img src=\"https://avatars.githubusercontent.com/u/47673410?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kevin Aguilar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://andrewroan.com\"><img src=\"https://avatars.githubusercontent.com/u/9873566?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrew Roan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/ibrahim-oktay-518b4939/\"><img src=\"https://avatars.githubusercontent.com/u/36792481?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ibrahim oktay</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/navartis\"><img src=\"https://avatars.githubusercontent.com/u/7813723?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmitriy Kulakov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/woin2ee\"><img src=\"https://avatars.githubusercontent.com/u/81426024?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Jaewon-Yun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tatagrigory\"><img src=\"https://avatars.githubusercontent.com/u/5187973?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tatagrigory</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://linkedin.com/in/denilchungath\"><img src=\"https://avatars.githubusercontent.com/u/95201442?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Denil Chungath</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/victor-sarda/\"><img src=\"https://avatars.githubusercontent.com/u/6460866?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Victor Sarda</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tzxdtc\"><img src=\"https://avatars.githubusercontent.com/u/19767846?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tzxdtc10</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ThiemeFM\"><img src=\"https://avatars.githubusercontent.com/u/143395823?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Thieme</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Lilfaen\"><img src=\"https://avatars.githubusercontent.com/u/39119695?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Clemens Beck</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://macpaw.com/\"><img src=\"https://avatars.githubusercontent.com/u/119268?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Paul Taykalo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/in4lio\"><img src=\"https://avatars.githubusercontent.com/u/976061?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vitaly Kravtsov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dc.wtf\"><img src=\"https://avatars.githubusercontent.com/u/643865?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>dc</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/baekteun\"><img src=\"https://avatars.githubusercontent.com/u/74440939?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>baegteun</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://vcoutasso.com\"><img src=\"https://avatars.githubusercontent.com/u/44986513?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vin√≠cius Couto Tasso</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://blog.jihoon.me\"><img src=\"https://avatars.githubusercontent.com/u/68891494?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ÏïàÏßÄÌõà</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dxmvsh\"><img src=\"https://avatars.githubusercontent.com/u/44325936?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dimash</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danibachar\"><img src=\"https://avatars.githubusercontent.com/u/6380777?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>danibachar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dp221125\"><img src=\"https://avatars.githubusercontent.com/u/10572119?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ÌïúÏÑùÌò∏(MilKyo)</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@haifengkaohaifengkao&usg=AOvVaw2_xG-ZLdBawBIyS7m-99RQ\"><img src=\"https://avatars.githubusercontent.com/u/4080524?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hai Feng Kao</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anlaital-oura\"><img src=\"https://avatars.githubusercontent.com/u/133648611?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Antti Laitala</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PushedCrayon\"><img src=\"https://avatars.githubusercontent.com/u/37077444?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>PushedCrayon</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://stefanomondino.com\"><img src=\"https://avatars.githubusercontent.com/u/1691903?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Stefano Mondino</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/leszko11\"><img src=\"https://avatars.githubusercontent.com/u/23533452?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>≈Åukasz Lech</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/costapombo\"><img src=\"https://avatars.githubusercontent.com/u/31352351?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>costapombo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/isavynskyi\"><img src=\"https://avatars.githubusercontent.com/u/18377497?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ihor Savynskyi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kapitoshka438\"><img src=\"https://avatars.githubusercontent.com/u/3232401?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Eduard Miniakhmetov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alexfilimon\"><img src=\"https://avatars.githubusercontent.com/u/19904867?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander Filimonov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rofle100lvl\"><img src=\"https://avatars.githubusercontent.com/u/45801227?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gorbenko Roman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/lucas-paim/\"><img src=\"https://avatars.githubusercontent.com/u/7849484?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lucas Mrowskovsky Paim</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://actuallytaylor.com\"><img src=\"https://avatars.githubusercontent.com/u/32944568?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Taylor Lineman</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nandodelauni\"><img src=\"https://avatars.githubusercontent.com/u/1938501?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Miguel Ferrando</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/barredewe\"><img src=\"https://avatars.githubusercontent.com/u/19188911?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>BarredEwe</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chris-livefront\"><img src=\"https://avatars.githubusercontent.com/u/126101032?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Chris Sessions</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ajkolean\"><img src=\"https://avatars.githubusercontent.com/u/5394701?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andy Kolean</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Binlogo\"><img src=\"https://avatars.githubusercontent.com/u/7845507?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Binlogo</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DevilDimon\"><img src=\"https://avatars.githubusercontent.com/u/10220441?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dmitry Serov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://darrarski.pl\"><img src=\"https://avatars.githubusercontent.com/u/1384684?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dariusz Rybicki</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dansinclair25\"><img src=\"https://avatars.githubusercontent.com/u/2573447?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Dan Sinclair</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.kaioelfke.de\"><img src=\"https://avatars.githubusercontent.com/u/1190948?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Kai Oelfke</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://stackoverflow.com/users/468724/inder-kumar-rathore\"><img src=\"https://avatars.githubusercontent.com/u/352443?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Inder</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kyounh12\"><img src=\"https://avatars.githubusercontent.com/u/25301615?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kyounh12</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alvar-bolt\"><img src=\"https://avatars.githubusercontent.com/u/72379847?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alvar Hansen</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/barakwei\"><img src=\"https://avatars.githubusercontent.com/u/5232161?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Barak Weiss</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hiltonc\"><img src=\"https://avatars.githubusercontent.com/u/470753?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hilton Campbell</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rgnns\"><img src=\"https://avatars.githubusercontent.com/u/811827?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Gabriel Li√©vano</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vijaytholpadi\"><img src=\"https://avatars.githubusercontent.com/u/1171868?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vijay Tholpadi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://withiosdeveloper.blogspot.com/\"><img src=\"https://avatars.githubusercontent.com/u/27220138?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Minhoi Goo</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sphanley\"><img src=\"https://avatars.githubusercontent.com/u/1323769?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Sam Hanley</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ahmdyasser\"><img src=\"https://avatars.githubusercontent.com/u/42544598?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ahmdyasser</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/minhaaan\"><img src=\"https://avatars.githubusercontent.com/u/87178301?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>minhaaan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TamarMilchtaich\"><img src=\"https://avatars.githubusercontent.com/u/49520876?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Tamar Milchtaich Lavi</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rock88\"><img src=\"https://avatars.githubusercontent.com/u/323908?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Andrey K</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://2stable.com\"><img src=\"https://avatars.githubusercontent.com/u/69604865?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alex Vera</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.annalisemariottini.com\"><img src=\"https://avatars.githubusercontent.com/u/14299642?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Annalise Mariottini</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gustn3965\"><img src=\"https://avatars.githubusercontent.com/u/48749182?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>HyunSu Park</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vldalx\"><img src=\"https://avatars.githubusercontent.com/u/13873200?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vladimir</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://rhysmorgan.co\"><img src=\"https://avatars.githubusercontent.com/u/11096937?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Rhys Morgan</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pierrerodgers\"><img src=\"https://avatars.githubusercontent.com/u/48193278?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>pierrerodgers</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/honghoker\"><img src=\"https://avatars.githubusercontent.com/u/50417461?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>eunpyo hong</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@dbstj169\"><img src=\"https://avatars.githubusercontent.com/u/65678579?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yunseo Kang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ilia3546\"><img src=\"https://avatars.githubusercontent.com/u/4445510?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ilya Kharlamov</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/brianvar\"><img src=\"https://avatars.githubusercontent.com/u/115399684?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>brianvar</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/HossamYoussof\"><img src=\"https://avatars.githubusercontent.com/u/6381926?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Hossam Youssof</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/devMinseok\"><img src=\"https://avatars.githubusercontent.com/u/51021614?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Minseok Kang</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alpanyukov\"><img src=\"https://avatars.githubusercontent.com/u/36258478?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Alexander</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sanghyeok-kim\"><img src=\"https://avatars.githubusercontent.com/u/57667738?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Loyle</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vvisionnn\"><img src=\"https://avatars.githubusercontent.com/u/24761186?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ydna</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://brucemcrooster.dev\"><img src=\"https://avatars.githubusercontent.com/u/53529192?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Evan</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.snipnotes.de\"><img src=\"https://avatars.githubusercontent.com/u/5102728?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Felix Lisczyk</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lukaswuerzburger\"><img src=\"https://avatars.githubusercontent.com/u/10812458?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lukas W√ºrzburger</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/GetToSet\"><img src=\"https://avatars.githubusercontent.com/u/8158163?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ethan Wong</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tdkn.dev\"><img src=\"https://avatars.githubusercontent.com/u/1296540?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Shun Tedokon</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://connorricks.com\"><img src=\"https://avatars.githubusercontent.com/u/13373737?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Connor Ricks</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://franciscodiaz.cl\"><img src=\"https://avatars.githubusercontent.com/u/530662?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Francisco Diaz</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ethan-IS\"><img src=\"https://avatars.githubusercontent.com/u/140235921?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ethan Parker</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lukevanin\"><img src=\"https://avatars.githubusercontent.com/u/550579?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Luke Van In</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mustafataibah.vercel.app/\"><img src=\"https://avatars.githubusercontent.com/u/83141712?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Mustafa Taibah</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vkondrashkov\"><img src=\"https://avatars.githubusercontent.com/u/16046780?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Vladislav Kondrashkov</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chrisjrex\"><img src=\"https://avatars.githubusercontent.com/u/4457170?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Christopher Rex</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bahattinkoc\"><img src=\"https://avatars.githubusercontent.com/u/61124759?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>baaddin</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mattjung\"><img src=\"https://avatars.githubusercontent.com/u/19891158?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Matt Jung</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://imaginativeworld.org\"><img src=\"https://avatars.githubusercontent.com/u/1952630?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Md. Mahmudul Hasan Shohag</b></sub></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ma.tyas.cz\"><img src=\"https://avatars.githubusercontent.com/u/6033733?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Matty Cross</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/YIshihara11201\"><img src=\"https://avatars.githubusercontent.com/u/98417271?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>YIshihara11201</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PhilippeWeidmann\"><img src=\"https://avatars.githubusercontent.com/u/5843044?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Philippe Weidmann</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Zentaur0\"><img src=\"https://avatars.githubusercontent.com/u/75909658?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Anton SVTSV</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://johannes.plunien.com\"><img src=\"https://avatars.githubusercontent.com/u/31597?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Johannes Plunien</b></sub></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://emirhankarahan.com\"><img src=\"https://avatars.githubusercontent.com/u/48404459?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Emirhan KARAHAN</b></sub></a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n",
      "stars_today": 2
    },
    {
      "id": 207354223,
      "name": "FreeRTOS-Kernel",
      "full_name": "FreeRTOS/FreeRTOS-Kernel",
      "description": "FreeRTOS kernel files only, submoduled into https://github.com/FreeRTOS/FreeRTOS and various other repos.",
      "html_url": "https://github.com/FreeRTOS/FreeRTOS-Kernel",
      "stars": 3795,
      "forks": 1423,
      "language": "C",
      "topics": [],
      "created_at": "2019-09-09T16:28:01Z",
      "updated_at": "2026-01-16T21:33:59Z",
      "pushed_at": "2026-01-13T21:35:02Z",
      "open_issues": 36,
      "owner": {
        "login": "FreeRTOS",
        "avatar_url": "https://avatars.githubusercontent.com/u/54647343?v=4"
      },
      "readme": "[![CMock Unit Tests](https://github.com/FreeRTOS/FreeRTOS-Kernel/actions/workflows/unit-tests.yml/badge.svg?branch=main&event=push)](https://github.com/FreeRTOS/FreeRTOS-Kernel/actions/workflows/unit-tests.yml?query=branch%3Amain+event%3Apush+workflow%3A%22CMock+Unit+Tests%22++)\n[![codecov](https://app.codecov.io/gh/FreeRTOS/FreeRTOS-Kernel/badge.svg?branch=main)](https://codecov.io/gh/FreeRTOS/FreeRTOS-Kernel)\n\n## Getting started\n\nThis repository contains FreeRTOS kernel source/header files and kernel\nports only. This repository is referenced as a submodule in\n[FreeRTOS/FreeRTOS](https://github.com/FreeRTOS/FreeRTOS)\nrepository, which contains pre-configured demo application projects under\n```FreeRTOS/Demo``` directory.\n\nThe easiest way to use FreeRTOS is to start with one of the pre-configured demo\napplication projects.  That way you will have the correct FreeRTOS source files\nincluded, and the correct include paths configured. Once a demo application is\nbuilding and executing you can remove the demo application files, and start to\nadd in your own application source files.  See the\n[FreeRTOS Kernel Quick Start Guide](https://www.freertos.org/Documentation/01-FreeRTOS-quick-start/01-Beginners-guide/02-Quick-start-guide)\nfor detailed instructions and other useful links.\n\nAdditionally, for FreeRTOS kernel feature information refer to the\n[Developer Documentation](https://www.freertos.org/Documentation/02-Kernel/02-Kernel-features/00-Developer-docs),\nand [API Reference](https://www.freertos.org/Documentation/02-Kernel/04-API-references/01-Task-creation/00-TaskHandle).\n\nAlso for contributing and creating a Pull Request please refer to\n[the instructions here](.github/CONTRIBUTING.md#contributing-via-pull-request).\n\n**FreeRTOS-Kernel V11.1.0\n[source code](https://github.com/FreeRTOS/FreeRTOS-Kernel/tree/V11.1.0) is part\nof the\n[FreeRTOS 202406.00 LTS](https://github.com/FreeRTOS/FreeRTOS-LTS/tree/202406-LTS)\nrelease.**\n\n### Getting help\n\nIf you have any questions or need assistance troubleshooting your FreeRTOS project,\nwe have an active community that can help on the\n[FreeRTOS Community Support Forum](https://forums.freertos.org).\n\n## To consume FreeRTOS-Kernel\n\n### Consume with CMake\n\nIf using CMake, it is recommended to use this repository using FetchContent.\nAdd the following into your project's main or a subdirectory's `CMakeLists.txt`:\n\n- Define the source and version/tag you want to use:\n\n```cmake\nFetchContent_Declare( freertos_kernel\n  GIT_REPOSITORY https://github.com/FreeRTOS/FreeRTOS-Kernel.git\n  GIT_TAG        main #Note: Best practice to use specific git-hash or tagged version\n)\n```\n\nIn case you prefer to add it as a git submodule, do:\n\n```bash\ngit submodule add https://github.com/FreeRTOS/FreeRTOS-Kernel.git <path of the submodule>\ngit submodule update --init\n```\n\n- Add a freertos_config library (typically an INTERFACE library) The following assumes the directory structure:\n  - `include/FreeRTOSConfig.h`\n\n```cmake\nadd_library(freertos_config INTERFACE)\n\ntarget_include_directories(freertos_config SYSTEM\nINTERFACE\n    include\n)\n\ntarget_compile_definitions(freertos_config\n  INTERFACE\n    projCOVERAGE_TEST=0\n)\n```\n\nIn case you installed FreeRTOS-Kernel as a submodule, you will have to add it as a subdirectory:\n\n```cmake\nadd_subdirectory(${FREERTOS_PATH})\n```\n\n- Configure the FreeRTOS-Kernel and make it available\n  - this particular example supports a native and cross-compiled build option.\n\n```cmake\nset( FREERTOS_HEAP \"4\" CACHE STRING \"\" FORCE)\n# Select the native compile PORT\nset( FREERTOS_PORT \"GCC_POSIX\" CACHE STRING \"\" FORCE)\n# Select the cross-compile PORT\nif (CMAKE_CROSSCOMPILING)\n  set(FREERTOS_PORT \"GCC_ARM_CA9\" CACHE STRING \"\" FORCE)\nendif()\n\nFetchContent_MakeAvailable(freertos_kernel)\n```\n\n- In case of cross compilation, you should also add the following to `freertos_config`:\n\n```cmake\ntarget_compile_definitions(freertos_config INTERFACE ${definitions})\ntarget_compile_options(freertos_config INTERFACE ${options})\n```\n\n### Consuming stand-alone - Cloning this repository\n\nTo clone using HTTPS:\n\n```\ngit clone https://github.com/FreeRTOS/FreeRTOS-Kernel.git\n```\n\nUsing SSH:\n\n```\ngit clone git@github.com:FreeRTOS/FreeRTOS-Kernel.git\n```\n\n## Repository structure\n\n- The root of this repository contains the three files that are common to\nevery port - list.c, queue.c and tasks.c.  The kernel is contained within these\nthree files.  croutine.c implements the optional co-routine functionality - which\nis normally only used on very memory limited systems.\n\n- The ```./portable``` directory contains the files that are specific to a particular microcontroller and/or compiler.\nSee the readme file in the ```./portable``` directory for more information.\n\n- The ```./include``` directory contains the real time kernel header files.\n\n- The ```./template_configuration``` directory contains a sample `FreeRTOSConfig.h` to help jumpstart a new project.\nSee the [FreeRTOSConfig.h](examples/template_configuration/FreeRTOSConfig.h) file for instructions.\n\n### Code Formatting\n\nFreeRTOS files are formatted using the\n\"[uncrustify](https://github.com/uncrustify/uncrustify)\" tool.\nThe configuration file used by uncrustify can be found in the\n[FreeRTOS/CI-CD-GitHub-Actions's](https://github.com/FreeRTOS/CI-CD-Github-Actions)\n[uncrustify.cfg](https://github.com/FreeRTOS/CI-CD-Github-Actions/tree/main/formatting)\nfile.\n\n### Line Endings\n\nFile checked into the FreeRTOS-Kernel repository use unix-style LF line endings\nfor the best compatibility with git.\n\nFor optimal compatibility with Microsoft Windows tools, it is best to enable\nthe git autocrlf feature. You can enable this setting for the current\nrepository using the following command:\n\n```\ngit config core.autocrlf true\n```\n\n### Git History Optimizations\n\nSome commits in this repository perform large refactors which touch many lines\nand lead to unwanted behavior when using the `git blame` command. You can\nconfigure git to ignore the list of large refactor commits in this repository\nwith the following command:\n\n```\ngit config blame.ignoreRevsFile .git-blame-ignore-revs\n```\n\n### Spelling and Formatting\n\nWe recommend using [Visual Studio Code](https://code.visualstudio.com),\ncommonly referred to as VSCode, when working on the FreeRTOS-Kernel.\nThe FreeRTOS-Kernel also uses [cSpell](https://cspell.org/) as part of its\nspelling check. The config file for which can be found at [cspell.config.yaml](cspell.config.yaml)\nThere is additionally a\n[cSpell plugin for VSCode](https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker)\nthat can be used as well.\n*[.cSpellWords.txt](.github/.cSpellWords.txt)* contains words that are not\ntraditionally found in an English dictionary. It is used by the spellchecker\nto verify the various jargon, variable names, and other odd words used in the\nFreeRTOS code base are correct. If your pull request fails to pass the spelling\nand you believe this is a mistake, then add the word to\n*[.cSpellWords.txt](.github/.cSpellWords.txt)*. When adding a word please\nthen sort the list, which can be done by running the bash command:\n`sort -u .cSpellWords.txt -o .cSpellWords.txt`\nNote that only the FreeRTOS-Kernel Source Files, [include](include),\n[portable/MemMang](portable/MemMang), and [portable/Common](portable/Common)\nfiles are checked for proper spelling, and formatting at this time.\n\n## Third Party Tools\nVisit [this link](.github/third_party_tools.md) for detailed information about\nthird-party tools with FreeRTOS support.\n",
      "stars_today": 2
    },
    {
      "id": 394089041,
      "name": "spiceai",
      "full_name": "spiceai/spiceai",
      "description": "A portable accelerated SQL query, search, and LLM-inference engine, written in Rust, for data-grounded AI apps and agents.",
      "html_url": "https://github.com/spiceai/spiceai",
      "stars": 2727,
      "forks": 164,
      "language": "Rust",
      "topics": [
        "artificial-intelligence",
        "data",
        "data-federation",
        "developers",
        "full-text-search",
        "infrastructure",
        "llm-inference",
        "machine-learning",
        "sql"
      ],
      "created_at": "2021-08-08T23:26:13Z",
      "updated_at": "2026-01-17T00:10:44Z",
      "pushed_at": "2026-01-17T01:01:58Z",
      "open_issues": 444,
      "owner": {
        "login": "spiceai",
        "avatar_url": "https://avatars.githubusercontent.com/u/73862742?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"https://github.com/user-attachments/assets/13ff4c9d-d6a7-4c20-9408-45573c508c41\" alt=\"spice oss logo\" width=\"600\"/>\n</p>\n<p align=\"center\">\n  <a href=\"https://github.com/spiceai/spiceai/actions/workflows/codeql-analysis.yml\"><img src=\"https://github.com/spiceai/spiceai/actions/workflows/codeql-analysis.yml/badge.svg?branch=trunk&event=push\" alt=\"CodeQL\"/></a>\n  <a href=\"https://opensource.org/licenses/Apache-2.0\"><img src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg\" alt=\"License: Apache-2.0\"/></a>\n  <a href=\"https://spiceai.org/slack\"><img src=\"https://img.shields.io/badge/Slack-Join%20Us-4A154B?logo=slack\" alt=\"Slack\"/></a>\n  <a href=\"https://x.com/intent/follow?screen_name=spice_ai\"><img src=\"https://img.shields.io/twitter/follow/spice_ai.svg?style=social&logo=x\" alt=\"Follow on X\"/></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/spiceai/spiceai/actions/workflows/build_and_release.yml?branch=trunk\"><img alt=\"GitHub Actions Workflow Status - build\" src=\"https://img.shields.io/github/actions/workflow/status/spiceai/spiceai/build_and_release.yml?branch=trunk\" /></a>\n  <a href=\"https://github.com/spiceai/spiceai/actions/workflows/spiced_docker_nightly.yml?branch=trunk\"><img alt=\"GitHub Actions Workflow Status - docker build\" src=\"https://img.shields.io/github/actions/workflow/status/spiceai/spiceai/spiced_docker_nightly.yml?branch=trunk&label=docker%20build\" /></a>\n  <a href=\"https://github.com/spiceai/spiceai/actions/workflows/pr.yml?branch=trunk\"><img alt=\"GitHub Actions Workflow Status - unit tests\" src=\"https://img.shields.io/github/actions/workflow/status/spiceai/spiceai/pr.yml?event=merge_group&label=unit%20tests\" /></a>\n  <a href=\"https://github.com/spiceai/spiceai/actions/workflows/integration.yml?branch=trunk\"><img alt=\"GitHub Actions Workflow Status - integration tests\" src=\"https://img.shields.io/github/actions/workflow/status/spiceai/spiceai/integration.yml?branch=trunk&label=integration%20tests\" /></a>\n  <a href=\"https://github.com/spiceai/spiceai/actions/workflows/integration_models.yml?branch=trunk\"><img alt=\"GitHub Actions Workflow Status - integration tests (models)\" src=\"https://img.shields.io/github/actions/workflow/status/spiceai/spiceai/integration_models.yml?branch=trunk&label=integration%20tests%20(models)\" /></a>\n  <a href=\"https://github.com/spiceai/spiceai/actions/workflows/benchmarks.yml?branch=trunk\"><img alt=\"GitHub Actions Workflow Status - benchmark tests\" src=\"https://img.shields.io/github/actions/workflow/status/spiceai/spiceai/testoperator_run_bench.yml?branch=trunk&label=benchmark%20tests\" /></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://spiceai.org/docs\">üìÑ Docs</a> | <a href=\"#%EF%B8%8F-quickstart-local-machine\">‚ö°Ô∏è Quickstart</a> | <a href=\"https://github.com/spiceai/cookbook\">üßë‚Äçüç≥ Cookbook</a>\n</p>\n\n**Spice** is a SQL query, search, and LLM-inference engine, written in Rust, for data apps and agents.\n\n<img width=\"740\" alt=\"Spice.ai Open Source accelerated data query and LLM-inference engine\" src=\"https://github.com/user-attachments/assets/9db94f9c-10a1-47b0-ab45-05aa964590ff\" />\n\nSpice provides four industry standard APIs in a lightweight, portable runtime (single binary/container):\n\n1. **SQL Query & Search**: HTTP, Arrow Flight, Arrow Flight SQL, ODBC, JDBC, and ADBC APIs; `vector_search` and `text_search` UDTFs.\n2. **OpenAI-Compatible APIs**: HTTP APIs for OpenAI SDK compatibility, local model serving (CUDA/Metal accelerated), and hosted model gateway.\n3. **Iceberg Catalog REST APIs**: A unified Iceberg REST Catalog API.\n4. **MCP HTTP+SSE APIs**: Integration with external tools via Model Context Protocol (MCP) using HTTP and Server-Sent Events (SSE).\n\nüéØ Goal: Developers can focus on building data apps and AI agents confidently, knowing they are grounded in data.\n\nSpice's primary features include:\n\n- **Data Federation**: SQL query across any database, data warehouse, or data lake. Deploy with single-node or distributed multi-node query execution. [Learn More](https://spiceai.org/docs/features/query-federation).\n- **Data Materialization and Acceleration**: Materialize, accelerate, and cache database queries with Arrow, DuckDB, SQLite, PostgreSQL, or Cayenne (Vortex+SQLite) for simplified multi-file acceleration. [Read the MaterializedView interview - Building a CDN for Databases](https://materializedview.io/p/building-a-cdn-for-databases-spice-ai)\n- **Hybrid Search**: Keyword, vector, and full-text search with Tantivy-powered BM25 and petabyte-scale vector similarity search via Amazon S3 Vectors or pgvector for structured and unstructured data.\n- **SQL LLM Inference**: Call LLMs directly from SQL. Generate, summarize, and enrich data using the Spice SQL AI function or Text-to-SQL. Use Spice as an AI-database powering retrieval-augmented generation (RAG) and intelligent agents with OpenAI-compatible APIs and MCP integration. [Learn More](https://spiceai.org/docs/use-cases/rag).\n\nIf you want to build with DataFusion, DuckDB, or Vortex, Spice provides a simple, flexible, and production-ready engine you can just use.\n\nüì£ Read the [Spice.ai 1.0-stable announcement](https://spiceai.org/blog/announcing-1.0-stable).\n\nSpice is built-on industry leading technologies including [Apache DataFusion](https://datafusion.apache.org), Apache Arrow, Arrow Flight, SQLite, and DuckDB.\n\n<div align=\"center\">\n  <picture>\n    <img width=\"600\" alt=\"How Spice works.\" src=\"https://github.com/spiceai/spiceai/assets/80174/7d93ae32-d6d8-437b-88d3-d64fe089e4b7\" />\n  </picture>\n</div>\n\nüé• [Watch the CMU Databases Accelerating Data and AI with Spice.ai Open-Source](https://www.youtube.com/watch?v=tyM-ec1lKfU)\n\nüé• [Watch How to Query Data using Spice, OpenAI, and MCP](https://www.youtube.com/watch?v=TFAu4qxjTPk&list=PLesJrUXEx3U-dQul0PqLV3TGTdUmr3B6e&index=8)\n\nüé• [Watch How to search with Amazon S3 Vectors](https://www.youtube.com/watch?v=QPbqPf5W36g)\n\n## Why Spice?\n\n<div align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/spiceai/spiceai/assets/80174/96b5fcef-a550-4ce8-a74a-83931275e83e\">\n    <img width=\"800\" alt=\"Spice.ai\" src=\"https://github.com/spiceai/spiceai/assets/80174/29e4421d-8942-4f2a-8397-e9d4fdeda36b\" />\n  </picture>\n</div>\n\nSpice simplifies building data-driven AI applications and agents by making it fast and easy to query, federate, and accelerate data from one or more sources using SQL, while grounding AI in real-time, reliable data. Co-locate datasets with apps and AI models to power AI feedback loops, enable RAG and search, and deliver fast, low-latency data-query and AI-inference with full control over cost and performance.\n\n### Latest Capabilities\n\n- **Spice Cayenne Data Accelerator (Beta)**: Simplified multi-file acceleration using the [Vortex columnar format](https://github.com/vortex-data/vortex) + SQLite metadata. Delivers DuckDB-comparable performance without single-file scaling limitations.\n- **Multi-Node Distributed Query (Preview)**: Scale query execution across multiple nodes with Apache Ballista integration for improved performance on large datasets.\n- **Acceleration Snapshots**: Bootstrap accelerations from S3 for fast cold starts (seconds vs. minutes). Supports ephemeral storage with persistent recovery.\n- **Iceberg Table Writes**: Write to Iceberg tables using standard SQL `INSERT INTO` for data ingestion and transformation‚Äîno Spark required.\n- **Petabyte-Scale Vector Search**: Native Amazon S3 Vectors integration manages the full vector lifecycle from ingestion to embedding to querying. SQL-integrated hybrid search with RRF.\n\n### How is Spice different?\n\n1. **AI-Native Runtime**: Spice combines data query and AI inference in a single engine, for data-grounded AI and accurate AI.\n\n2. **Application-Focused**: Designed to run distributed at the application and agent level, often as a 1:1 or 1:N mapping between app and Spice instance, unlike traditional data systems built for many apps on one centralized database. It‚Äôs common to spin up multiple Spice instances‚Äîeven one per tenant or customer.\n\n3. **Dual-Engine Acceleration**: Supports both **OLAP** (Arrow/DuckDB) and **OLTP** (SQLite/PostgreSQL) engines at the dataset level, providing flexible performance across analytical and transactional workloads.\n\n4. **Disaggregated Storage**: Separation of compute from disaggregated storage, co-locating local, materialized working sets of data with applications, dashboards, or ML pipelines while accessing source data in its original storage.\n\n5. **Edge to Cloud Native**: Deploy as a standalone instance, Kubernetes sidecar, microservice, or cluster‚Äîacross edge/POP, on-prem, and public clouds. Chain multiple Spice instances for tier-optimized, distributed deployments.\n\n## How does Spice compare?\n\n### Data Query and Analytics\n\n| Feature                          | **Spice**                              | Trino / Presto       | Dremio                | ClickHouse          | Materialize          |\n| -------------------------------- | -------------------------------------- | -------------------- | --------------------- | ------------------- | -------------------- |\n| **Primary Use-Case**             | Data & AI apps/agents                  | Big data analytics   | Interactive analytics | Real-time analytics | Real-time analytics  |\n| **Primary deployment model**     | Sidecar                                | Cluster              | Cluster               | Cluster             | Cluster              |\n| **Federated Query Support**      | ‚úÖ                                     | ‚úÖ                   | ‚úÖ                    | ‚Äï                   | ‚Äï                    |\n| **Acceleration/Materialization** | ‚úÖ (Arrow, SQLite, DuckDB, PostgreSQL) | Intermediate storage | Reflections (Iceberg) | Materialized views  | ‚úÖ (Real-time views) |\n| **Catalog Support**              | ‚úÖ (Iceberg, Unity Catalog, AWS Glue)  | ‚úÖ                   | ‚úÖ                    | ‚Äï                   | ‚Äï                    |\n| **Query Result Caching**         | ‚úÖ                                     | ‚úÖ                   | ‚úÖ                    | ‚úÖ                  | Limited              |\n| **Multi-Modal Acceleration**     | ‚úÖ (OLAP + OLTP)                       | ‚Äï                    | ‚Äï                     | ‚Äï                   | ‚Äï                    |\n| **Change Data Capture (CDC)**    | ‚úÖ (Debezium)                          | ‚Äï                    | ‚Äï                     | ‚Äï                   | ‚úÖ (Debezium)        |\n\n### AI Apps and Agents\n\n| Feature                       | **Spice**                                | LangChain          | LlamaIndex | AgentOps.ai      | Ollama                        |\n| ----------------------------- | ---------------------------------------- | ------------------ | ---------- | ---------------- | ----------------------------- |\n| **Primary Use-Case**          | Data & AI apps                           | Agentic workflows  | RAG apps   | Agent operations | LLM apps                      |\n| **Programming Language**      | Any language (HTTP interface)            | JavaScript, Python | Python     | Python           | Any language (HTTP interface) |\n| **Unified Data + AI Runtime** | ‚úÖ                                       | ‚Äï                  | ‚Äï          | ‚Äï                | ‚Äï                             |\n| **Federated Data Query**      | ‚úÖ                                       | ‚Äï                  | ‚Äï          | ‚Äï                | ‚Äï                             |\n| **Accelerated Data Access**   | ‚úÖ                                       | ‚Äï                  | ‚Äï          | ‚Äï                | ‚Äï                             |\n| **Tools/Functions**           | ‚úÖ (MCP HTTP+SSE)                        | ‚úÖ                 | ‚úÖ         | Limited          | Limited                       |\n| **LLM Memory**                | ‚úÖ                                       | ‚úÖ                 | ‚Äï          | ‚úÖ               | ‚Äï                             |\n| **Evaluations (Evals)**       | ‚úÖ                                       | Limited            | ‚Äï          | Limited          | ‚Äï                             |\n| **Hybrid Search**             | ‚úÖ (Keyword, Vector, & Full-Text-Search) | ‚úÖ                 | ‚úÖ         | Limited          | Limited                       |\n| **Caching**                   | ‚úÖ (Query and results caching)           | Limited            | ‚Äï          | ‚Äï                | ‚Äï                             |\n| **Embeddings**                | ‚úÖ (Built-in & pluggable models/DBs)     | ‚úÖ                 | ‚úÖ         | Limited          | ‚Äï                             |\n\n‚úÖ = Fully supported\n‚ùå = Not supported\nLimited = Partial or restricted support\n\n## Example Use-Cases\n\n### Data-grounded Agentic AI Applications\n\n- **OpenAI-compatible API**: Connect to hosted models (OpenAI, Anthropic, xAI, Amazon Bedrock) or deploy locally (Llama, NVIDIA NIM) with OpenAI Responses API support for advanced interactions. [AI Gateway Recipe](https://github.com/spiceai/cookbook/blob/trunk/openai_sdk/README.md)\n- **Federated Data Access**: Query using SQL and NSQL (text-to-SQL) across databases, data warehouses, and data lakes with advanced query push-down for fast retrieval. Scale to distributed multi-node query execution with Apache Ballista. [Federated SQL Query Recipe](https://github.com/spiceai/cookbook/blob/trunk/federation/README.md)\n- **Hybrid Search and RAG**: Search and retrieve context with accelerated embeddings for retrieval-augmented generation (RAG) workflows. Native Amazon S3 Vectors integration for petabyte-scale vector search. Full-text search (FTS) via Tantivy-powered BM25 and vector similarity search (VSS) integrated into SQL via `text_search` and `vector_search` UDTFs. Reciprocal rank fusion (RRF) for hybrid search. [Amazon S3 Vectors Cookbook Recipe](https://github.com/spiceai/cookbook/tree/trunk/vectors/s3/README.md)\n- **LLM Memory and Observability**: Store and retrieve history and context for AI agents while gaining deep visibility into data flows, model performance, and traces. [LLM Memory Recipe](https://github.com/spiceai/cookbook/blob/trunk/llm-memory/README.md) | [Observability & Monitoring Features Documentation](https://spiceai.org/docs/features/observability)\n\n### Database CDN and Query Mesh\n\n- **Data Acceleration**: Co-locate materialized datasets in Arrow, SQLite, DuckDB, PostgreSQL, or Cayenne (Vortex+SQLite) with applications for sub-second query. Bootstrap from snapshots stored in S3 for fast cold starts. Write to Iceberg tables with standard SQL `INSERT INTO`. [DuckDB Data Accelerator Recipe](https://github.com/spiceai/cookbook/blob/trunk/duckdb/accelerator/README.md)\n- **Resiliency and Local Dataset Replication**: Maintain application availability with local replicas of critical datasets. Recover from federated source outages using acceleration snapshots. [Local Dataset Replication Recipe](https://github.com/spiceai/cookbook/blob/trunk/localpod/README.md)\n- **Responsive Dashboards**: Enable fast, real-time analytics by accelerating data for frontends and BI tools with configurable refresh schedules. [Sales BI Dashboard Demo](https://github.com/spiceai/cookbook/blob/trunk/sales-bi/README.md)\n- **Simplified Legacy Migration**: Use a single endpoint to unify legacy systems with modern infrastructure, including federated SQL querying across multiple sources. [Federated SQL Query Recipe](https://github.com/spiceai/cookbook/blob/trunk/federation/README.md)\n\n### Retrieval-Augmented Generation (RAG)\n\n- **Unified Search with Vector Similarity**: Perform efficient vector similarity search across structured and unstructured data sources with native Amazon S3 Vectors integration for petabyte-scale vector storage and querying. The Spice runtime manages the vector lifecycle: ingesting data, embedding it using AWS Bedrock (Amazon Titan, Cohere), HuggingFace models, or Model2Vec (500x faster static embeddings), and storing in S3 Vector buckets or pgvector. Supports cosine similarity, Euclidean distance, or dot product. SQL-integrated search via `vector_search` and `text_search` UDTFs with hybrid search using reciprocal rank fusion (RRF). Example: `SELECT * FROM vector_search(my_table, 'search query', 10) WHERE condition ORDER BY score;`. [Amazon S3 Vectors Cookbook Recipe](https://github.com/spiceai/cookbook/tree/trunk/vectors/s3/README.md)\n- **Semantic Knowledge Layer**: Define a semantic context model to enrich data for AI. [Semantic Model Feature Documentation](https://spiceai.org/docs/features/semantic-model)\n- **Text-to-SQL**: Convert natural language queries into SQL using built-in NSQL and sampling tools for accurate query. [Text-to-SQL Recipe](https://github.com/spiceai/cookbook/blob/trunk/text-to-sql/README.md)\n- **Model and Data Evaluations**: Assess model performance and data quality with integrated evaluation tools. [Language Model Evaluations Recipe](https://github.com/spiceai/cookbook/blob/trunk/evals/README.md)\n\n## FAQ\n\n- **Is Spice a cache?** No specifically; you can think of Spice data acceleration as an _active_ cache, materialization, or data prefetcher. A cache would fetch data on a cache-miss while Spice prefetches and materializes filtered data on an interval, trigger, or as data changes using CDC. In addition to acceleration Spice supports [results caching](https://spiceai.org/docs/features/caching).\n\n- **Is Spice a CDN for databases?** Yes, a common use-case for Spice is as a CDN for different data sources. Using CDN concepts, Spice enables you to ship (load) a working set of your database (or data lake, or data warehouse) where it's most frequently accessed, like from a data-intensive application or for AI context.\n\n[‚û°Ô∏è Docs FAQ](https://spiceai.org/docs/faq)\n\n### Watch a 30-sec BI dashboard acceleration demo\n\n<https://github.com/spiceai/spiceai/assets/80174/7735ee94-3f4a-4983-a98e-fe766e79e03a>\n\nSee more demos on [YouTube](https://www.youtube.com/playlist?list=PLesJrUXEx3U9anekJvbjyyTm7r9A26ugK).\n\n## Supported Data Connectors\n\n| Name                               | Description                           | Status            | Protocol/Format              |\n| ---------------------------------- | ------------------------------------- | ----------------- | ---------------------------- |\n| `databricks (mode: delta_lake)`    | [Databricks][databricks]              | Stable            | S3/Delta Lake                |\n| `delta_lake`                       | Delta Lake                            | Stable            | Delta Lake                   |\n| `dremio`                           | [Dremio][dremio]                      | Stable            | Arrow Flight                 |\n| `duckdb`                           | DuckDB                                | Stable            | Embedded                     |\n| `file`                             | File                                  | Stable            | Parquet, CSV                 |\n| `github`                           | GitHub                                | Stable            | GitHub API                   |\n| `postgres`                         | PostgreSQL                            | Stable            |                              |\n| `s3`                               | [S3][s3]                              | Stable            | Parquet, CSV                 |\n| `mysql`                            | MySQL                                 | Stable            |                              |\n| `spice.ai`                         | [Spice.ai][spiceai]                   | Stable            | Arrow Flight                 |\n| `graphql`                          | GraphQL                               | Release Candidate | JSON                         |\n| `dynamodb`                         | Amazon DynamoDB                       | Release Candidate |                              |\n| `databricks (mode: spark_connect)` | [Databricks][databricks]              | Beta              | [Spark Connect][spark]       |\n| `flightsql`                        | FlightSQL                             | Beta              | Arrow Flight SQL             |\n| `iceberg`                          | [Apache Iceberg][iceberg]             | Beta              | Parquet                      |\n| `mssql`                            | Microsoft SQL Server                  | Beta              | Tabular Data Stream (TDS)    |\n| `odbc`                             | ODBC                                  | Beta              | ODBC                         |\n| `snowflake`                        | Snowflake                             | Beta              | Arrow                        |\n| `spark`                            | Spark                                 | Beta              | [Spark Connect][spark]       |\n| `oracle`                           | Oracle                                | Alpha             | [Oracle ODPI-C][ODPIC]       |\n| `abfs`                             | Azure BlobFS                          | Alpha             | Parquet, CSV                 |\n| `clickhouse`                       | Clickhouse                            | Alpha             |                              |\n| `debezium`                         | Debezium CDC                          | Alpha             | Kafka + JSON                 |\n| `kafka`                            | Kafka                                 | Alpha             | Kafka + JSON                 |\n| `ftp`, `sftp`                      | FTP/SFTP                              | Alpha             | Parquet, CSV                 |\n| `glue`                             | [AWS Glue][glue]                      | Alpha             | Iceberg, Parquet, CSV        |\n| `http`, `https`                    | HTTP(s)                               | Alpha             | Parquet, CSV, JSON           |\n| `imap`                             | IMAP                                  | Alpha             | IMAP Emails                  |\n| `localpod`                         | [Local dataset replication][localpod] | Alpha             |                              |\n| `mongodb`                          | MongoDB                               | Alpha             |                              |\n| `sharepoint`                       | Microsoft SharePoint                  | Alpha             | Unstructured UTF-8 documents |\n| `elasticsearch`                    | ElasticSearch                         | Roadmap           |                              |\n\n[databricks]: https://github.com/spiceai/cookbook/blob/trunk/databricks/README.md\n[spark]: https://spark.apache.org/docs/latest/spark-connect-overview.html\n[s3]: https://github.com/spiceai/cookbook/tree/trunk/s3#readme\n[spiceai]: https://github.com/spiceai/cookbook/tree/trunk/spiceai#readme\n[dremio]: https://github.com/spiceai/cookbook/tree/trunk/dremio#readme\n[localpod]: https://github.com/spiceai/cookbook/blob/trunk/localpod/README.md\n[iceberg]: https://github.com/spiceai/cookbook/tree/trunk/catalogs/iceberg#readme\n[glue]: https://github.com/spiceai/cookbook/tree/trunk/glue/README.md\n[ODPIC]: https://oracle.github.io/odpi/\n\n## Supported Data Accelerators\n\n| Name       | Description                       | Status              | Engine Modes     |\n| ---------- | --------------------------------- | ------------------- | ---------------- |\n| `arrow`    | [In-Memory Arrow Records][arrow]  | Stable              | `memory`         |\n| `cayenne`  | [Spice Cayenne (Vortex)][cayenne] | Beta (v1.9.0-rc.2+) | `file`           |\n| `duckdb`   | Embedded [DuckDB][duckdb]         | Stable              | `memory`, `file` |\n| `postgres` | Attached [PostgreSQL][postgres]   | Release Candidate   | N/A              |\n| `sqlite`   | Embedded [SQLite][sqlite]         | Release Candidate   | `memory`, `file` |\n\n[arrow]: https://spiceai.org/docs/components/data-accelerators/arrow\n[cayenne]: https://spiceai.org/docs/components/data-accelerators/cayenne\n[duckdb]: https://spiceai.org/docs/components/data-accelerators/duckdb\n[postgres]: https://spiceai.org/docs/components/data-accelerators/postgres\n[sqlite]: https://spiceai.org/docs/components/data-accelerators/sqlite\n\n## Supported Model Providers\n\n| Name          | Description                                  | Status            | ML Format(s) | LLM Format(s)                   |\n| ------------- | -------------------------------------------- | ----------------- | ------------ | ------------------------------- |\n| `openai`      | OpenAI (or compatible) LLM endpoint          | Release Candidate | -            | OpenAI-compatible HTTP endpoint |\n| `file`        | Local filesystem                             | Release Candidate | ONNX         | GGUF, GGML, SafeTensor          |\n| `huggingface` | Models hosted on HuggingFace                 | Release Candidate | ONNX         | GGUF, GGML, SafeTensor          |\n| `spice.ai`    | Models hosted on the Spice.ai Cloud Platform |                   | ONNX         | OpenAI-compatible HTTP endpoint |\n| `azure`       | Azure OpenAI                                 |                   | -            | OpenAI-compatible HTTP endpoint |\n| `bedrock`     | Amazon Bedrock (Nova models)                 | Alpha             | -            | OpenAI-compatible HTTP endpoint |\n| `anthropic`   | Models hosted on Anthropic                   | Alpha             | -            | OpenAI-compatible HTTP endpoint |\n| `xai`         | Models hosted on xAI                         | Alpha             | -            | OpenAI-compatible HTTP endpoint |\n\n## Supported Embeddings Providers\n\n| Name          | Description                         | Status            | ML Format(s) | LLM Format(s)\\*                 |\n| ------------- | ----------------------------------- | ----------------- | ------------ | ------------------------------- |\n| `openai`      | OpenAI (or compatible) LLM endpoint | Release Candidate | -            | OpenAI-compatible HTTP endpoint |\n| `file`        | Local filesystem                    | Release Candidate | ONNX         | GGUF, GGML, SafeTensor          |\n| `huggingface` | Models hosted on HuggingFace        | Release Candidate | ONNX         | GGUF, GGML, SafeTensor          |\n| `model2vec`   | Static embeddings (500x faster)     | Release Candidate | Model2Vec    | -                               |\n| `azure`       | Azure OpenAI                        | Alpha             | -            | OpenAI-compatible HTTP endpoint |\n| `bedrock`     | AWS Bedrock (e.g., Titan, Cohere)   | Alpha             | -            | OpenAI-compatible HTTP endpoint |\n\n## Supported Vector Stores\n\n| Name            | Description                                                          | Status |\n| --------------- | -------------------------------------------------------------------- | ------ |\n| `s3_vectors`    | Amazon S3 Vectors for petabyte-scale vector storage and querying     | Alpha  |\n| `pgvector`      | PostgreSQL with pgvector extension                                   | Alpha  |\n| `duckdb_vector` | DuckDB with vector extension for efficient vector storage and search | Alpha  |\n| `sqlite_vec`    | SQLite with sqlite-vec extension for lightweight vector operations   | Alpha  |\n\n## Supported Catalogs\n\nCatalog Connectors connect to external catalog providers and make their tables available for federated SQL query in Spice. Configuring accelerations for tables in external catalogs is not supported. The schema hierarchy of the external catalog is preserved in Spice.\n\n| Name            | Description             | Status | Protocol/Format              |\n| --------------- | ----------------------- | ------ | ---------------------------- |\n| `spice.ai`      | Spice.ai Cloud Platform | Stable | Arrow Flight                 |\n| `unity_catalog` | Unity Catalog           | Stable | Delta Lake                   |\n| `databricks`    | Databricks              | Beta   | Spark Connect, S3/Delta Lake |\n| `iceberg`       | Apache Iceberg          | Beta   | Parquet                      |\n| `glue`          | AWS Glue                | Alpha  | CSV, Parquet, Iceberg        |\n\n## ‚ö°Ô∏è Quickstart (Local Machine)\n\n<https://github.com/spiceai/spiceai/assets/88671039/85cf9a69-46e7-412e-8b68-22617dcbd4e0>\n\n### Installation\n\nInstall the Spice CLI:\n\nOn **macOS, Linux, and WSL**:\n\n```bash\ncurl https://install.spiceai.org | /bin/bash\n```\n\nOr using `brew`:\n\n```bash\nbrew install spiceai/spiceai/spice\n```\n\nOn **Windows** using PowerShell:\n\n```powershell\niex ((New-Object System.Net.WebClient).DownloadString(\"https://install.spiceai.org/Install.ps1\"))\n```\n\n### Usage\n\n**Step 1.** Initialize a new Spice app with the `spice init` command:\n\n```bash\nspice init spice_qs\n```\n\nA `spicepod.yaml` file is created in the `spice_qs` directory. Change to that directory:\n\n```bash\ncd spice_qs\n```\n\n**Step 2.** Start the Spice runtime:\n\n```bash\nspice run\n```\n\nExample output will be shown as follows:\n\n```bash\n2025/01/20 11:26:10 INFO Spice.ai runtime starting...\n2025-01-20T19:26:10.679068Z  INFO runtime::init::dataset: No datasets were configured. If this is unexpected, check the Spicepod configuration.\n2025-01-20T19:26:10.679716Z  INFO runtime::flight: Spice Runtime Flight listening on 127.0.0.1:50051\n2025-01-20T19:26:10.679786Z  INFO runtime::metrics_server: Spice Runtime Metrics listening on 127.0.0.1:9090\n2025-01-20T19:26:10.680140Z  INFO runtime::http: Spice Runtime HTTP listening on 127.0.0.1:8090\n2025-01-20T19:26:10.879126Z  INFO runtime::init::results_cache: Initialized sql results cache; max size: 128.00 MiB, item ttl: 1s\n```\n\nThe runtime is now started and ready for queries.\n\n**Step 3.** In a new terminal window, add the `spiceai/quickstart` Spicepod. A Spicepod is a package of configuration defining datasets and ML models.\n\n```bash\nspice add spiceai/quickstart\n```\n\nThe `spicepod.yaml` file will be updated with the `spiceai/quickstart` dependency.\n\n```yaml\nversion: v1\nkind: Spicepod\nname: spice_qs\ndependencies:\n  - spiceai/quickstart\n```\n\nThe `spiceai/quickstart` Spicepod will add a `taxi_trips` data table to the runtime which is now available to query by SQL.\n\n```bash\n2025-01-20T19:26:30.011633Z  INFO runtime::init::dataset: Dataset taxi_trips registered (s3://spiceai-demo-datasets/taxi_trips/2024/), acceleration (arrow), results cache enabled.\n2025-01-20T19:26:30.013002Z  INFO runtime::accelerated_table::refresh_task: Loading data for dataset taxi_trips\n2025-01-20T19:26:40.312839Z  INFO runtime::accelerated_table::refresh_task: Loaded 2,964,624 rows (399.41 MiB) for dataset taxi_trips in 10s 299ms\n```\n\n**Step 4.** Start the Spice SQL REPL:\n\n```bash\nspice sql\n```\n\nThe SQL REPL inferface will be shown:\n\n```bash\nWelcome to the Spice.ai SQL REPL! Type 'help' for help.\n\nshow tables; -- list available tables\nsql>\n```\n\nEnter `show tables;` to display the available tables for query:\n\n```bash\nsql> show tables;\n+---------------+--------------+---------------+------------+\n| table_catalog | table_schema | table_name    | table_type |\n+---------------+--------------+---------------+------------+\n| spice         | public       | taxi_trips    | BASE TABLE |\n| spice         | runtime      | query_history | BASE TABLE |\n| spice         | runtime      | metrics       | BASE TABLE |\n+---------------+--------------+---------------+------------+\n\nTime: 0.022671708 seconds. 3 rows.\n```\n\nEnter a query to display the longest taxi trips:\n\n```sql\nSELECT trip_distance, total_amount FROM taxi_trips ORDER BY trip_distance DESC LIMIT 10;\n```\n\nOutput:\n\n```bash\n+---------------+--------------+\n| trip_distance | total_amount |\n+---------------+--------------+\n| 312722.3      | 22.15        |\n| 97793.92      | 36.31        |\n| 82015.45      | 21.56        |\n| 72975.97      | 20.04        |\n| 71752.26      | 49.57        |\n| 59282.45      | 33.52        |\n| 59076.43      | 23.17        |\n| 58298.51      | 18.63        |\n| 51619.36      | 24.2         |\n| 44018.64      | 52.43        |\n+---------------+--------------+\n\nTime: 0.045150667 seconds. 10 rows.\n```\n\n## ‚öôÔ∏è Runtime Container Deployment\n\nUsing the [Docker image](https://hub.docker.com/r/spiceai/spiceai) locally:\n\n```bash\ndocker pull spiceai/spiceai\n```\n\nIn a Dockerfile:\n\n```dockerfile\nfrom spiceai/spiceai:latest\n```\n\nUsing Helm:\n\n```bash\nhelm repo add spiceai https://helm.spiceai.org\nhelm install spiceai spiceai/spiceai\n```\n\n## üèéÔ∏è Next Steps\n\n### Explore the Spice.ai Cookbook\n\nThe Spice.ai Cookbook is a collection of recipes and examples for using Spice. Find it at [https://github.com/spiceai/cookbook](https://github.com/spiceai/cookbook#readme).\n\n### Using Spice.ai Cloud Platform\n\nAccess ready-to-use Spicepods and datasets hosted on the Spice.ai Cloud Platform using the Spice runtime. A list of public Spicepods is available on Spicerack: [https://spicerack.org/](https://spicerack.org/).\n\nTo use public datasets, create a free account on Spice.ai:\n\n1. Visit [spice.ai](https://spice.ai/) and click **Try for Free**.\n   ![Try for Free](https://github.com/spiceai/spiceai/assets/112157037/27fb47ed-4825-4fa8-94bd-48197406cfaa)\n\n2. After creating an account, create an app to generate an API key.\n   ![Create App](https://github.com/spiceai/spiceai/assets/112157037/d2446406-1f06-40fb-8373-1b6d692cb5f7)\n\nOnce set up, you can access ready-to-use Spicepods including datasets. For this demonstration, use the `taxi_trips` dataset from the [Spice.ai Quickstart](https://spice.ai/spiceai/quickstart).\n\n**Step 1.** Initialize a new project.\n\n```bash\n# Initialize a new Spice app\nspice init spice_app\n\n# Change to app directory\ncd spice_app\n```\n\n**Step 2.** Log in and authenticate from the command line using the `spice login` command. A pop up browser window will prompt you to authenticate:\n\n```bash\nspice login\n```\n\n**Step 3.** Start the runtime:\n\n```bash\n# Start the runtime\nspice run\n```\n\n**Step 4.** Configure the dataset:\n\nIn a new terminal window, configure a new dataset using the `spice dataset configure` command:\n\n```bash\nspice dataset configure\n```\n\nEnter a dataset name that will be used to reference the dataset in queries. This name does not need to match the name in the dataset source.\n\n```bash\ndataset name: (spice_app) taxi_trips\n```\n\nEnter the description of the dataset:\n\n```bash\ndescription: Taxi trips dataset\n```\n\nEnter the location of the dataset:\n\n```bash\nfrom: spice.ai/spiceai/quickstart/datasets/taxi_trips\n```\n\nSelect `y` when prompted whether to accelerate the data:\n\n```bash\nLocally accelerate (y/n)? y\n```\n\nYou should see the following output from your runtime terminal:\n\n```bash\n2024-12-16T05:12:45.803694Z  INFO runtime::init::dataset: Dataset taxi_trips registered (spice.ai/spiceai/quickstart/datasets/taxi_trips), acceleration (arrow, 10s refresh), results cache enabled.\n2024-12-16T05:12:45.805494Z  INFO runtime::accelerated_table::refresh_task: Loading data for dataset taxi_trips\n2024-12-16T05:13:24.218345Z  INFO runtime::accelerated_table::refresh_task: Loaded 2,964,624 rows (8.41 GiB) for dataset taxi_trips in 38s 412ms.\n```\n\n**Step 5.** In a new terminal window, use the Spice SQL REPL to query the dataset\n\n```bash\nspice sql\n```\n\n```bash\nSELECT tpep_pickup_datetime, passenger_count, trip_distance from taxi_trips LIMIT 10;\n```\n\nThe output displays the results of the query along with the query execution time:\n\n```bash\n+----------------------+-----------------+---------------+\n| tpep_pickup_datetime | passenger_count | trip_distance |\n+----------------------+-----------------+---------------+\n| 2024-01-11T12:55:12  | 1               | 0.0           |\n| 2024-01-11T12:55:12  | 1               | 0.0           |\n| 2024-01-11T12:04:56  | 1               | 0.63          |\n| 2024-01-11T12:18:31  | 1               | 1.38          |\n| 2024-01-11T12:39:26  | 1               | 1.01          |\n| 2024-01-11T12:18:58  | 1               | 5.13          |\n| 2024-01-11T12:43:13  | 1               | 2.9           |\n| 2024-01-11T12:05:41  | 1               | 1.36          |\n| 2024-01-11T12:20:41  | 1               | 1.11          |\n| 2024-01-11T12:37:25  | 1               | 2.04          |\n+----------------------+-----------------+---------------+\n\nTime: 0.00538925 seconds. 10 rows.\n```\n\nYou can experiment with the time it takes to generate queries when using non-accelerated datasets. You can change the acceleration setting from `true` to `false` in the datasets.yaml file.\n\n### üìÑ Documentation\n\nComprehensive documentation is available at [spiceai.org/docs](https://spiceai.org/docs/).\n\nOver 45 quickstarts and samples available in the [Spice Cookbook](https://github.com/spiceai/cookbook#spiceai-oss-cookbook).\n\n### üîå Extensibility\n\nSpice.ai is designed to be extensible with extension points documented at [EXTENSIBILITY.md](./docs/EXTENSIBILITY.md). Build custom [Data Connectors](https://spiceai.org/docs/components/data-connectors), [Data Accelerators](https://spiceai.org/docs/components/data-accelerators), [Catalog Connectors](https://spiceai.org/docs/components/catalogs), [Secret Stores](https://spiceai.org/docs/components/secret-stores), [Models](https://spiceai.org/docs/components/models), or [Embeddings](https://spiceai.org/docs/components/embeddings).\n\n### üî® Upcoming Features\n\nüöÄ See the [Roadmap](https://github.com/spiceai/spiceai/blob/trunk/docs/ROADMAP.md) for upcoming features.\n\n### ü§ù Connect with us\n\nWe greatly appreciate and value your support! You can help Spice in a number of ways:\n\n- Build an app with Spice.ai and send us feedback and suggestions at [hey@spice.ai](mailto:hey@spice.ai) or on [Discord](https://discord.gg/kZnTfneP5u), [X](https://twitter.com/spice_ai), or [LinkedIn](https://www.linkedin.com/company/74148478).\n- [File an issue](https://github.com/spiceai/spiceai/issues/new) if you see something not quite working correctly.\n- Join our team ([We‚Äôre hiring!](https://spice.ai/careers))\n- Contribute code or documentation to the project (see [CONTRIBUTING.md](CONTRIBUTING.md)).\n- Follow our blog at [spiceai.org/blog](https://spiceai.org/blog)\n\n‚≠êÔ∏è star this repo! Thank you for your support! üôè\n",
      "stars_today": 2
    },
    {
      "id": 730845987,
      "name": "mlx-swift",
      "full_name": "ml-explore/mlx-swift",
      "description": "Swift API for MLX",
      "html_url": "https://github.com/ml-explore/mlx-swift",
      "stars": 1521,
      "forks": 141,
      "language": "C++",
      "topics": [
        "mlx"
      ],
      "created_at": "2023-12-12T19:58:52Z",
      "updated_at": "2026-01-16T01:56:26Z",
      "pushed_at": "2026-01-16T21:24:31Z",
      "open_issues": 29,
      "owner": {
        "login": "ml-explore",
        "avatar_url": "https://avatars.githubusercontent.com/u/102832242?v=4"
      },
      "readme": "# MLX Swift\n\n[**Installation**](#installation) | [**Documentation**](https://swiftpackageindex.com/ml-explore/mlx-swift/main/documentation/mlx) | [**Examples**](#examples)\n\nMLX Swift is a Swift API for [MLX](https://ml-explore.github.io/mlx/build/html/index.html).\n\nMLX is an array framework for machine learning on Apple silicon. MLX Swift\nexpands MLX to the Swift language, making research and experimentation easier\non Apple silicon.\n\n## Language Models\n\nLLM and VLM implementations are available in [mlx-swift-lm](https://github.com/ml-explore/mlx-swift-lm).\n\n## Examples\n\nMLX Swift has [many\nexamples](https://swiftpackageindex.com/ml-explore/mlx-swift/main/documentation/mlx/examples),\nincluding:\n\n- [MNISTTrainer](https://github.com/ml-explore/mlx-swift-examples/blob/main/Applications/MNISTTrainer/README.md): An example that runs on\n  both iOS and macOS that downloads MNIST training data and trains a\n  [LeNet](https://en.wikipedia.org/wiki/LeNet).\n\n- [MLXChatExample](https://github.com/ml-explore/mlx-swift-examples/blob/main/Applications/MLXChatExample/README.md): An example chat app that runs on both iOS and macOS that supports LLMs and VLMs.\n\n- [LLMEval](https://github.com/ml-explore/mlx-swift-examples/blob/main/Applications/LLMEval/README.md): A simple example that runs on both iOS\n  and macOS that downloads an LLM and tokenizer from Hugging Face and\n  generates text from a given prompt.\n\n- [StableDiffusionExample](https://github.com/ml-explore/mlx-swift-examples/blob/main/Applications/StableDiffusionExample/README.md): An\n  example that runs on both iOS and macOS that downloads a stable diffusion model\n  from Hugging Face and generates an image from a given prompt.\n\n- [llm-tool](https://github.com/ml-explore/mlx-swift-examples/blob/main/Tools/llm-tool/README.md): A command line tool for generating text\n  using a variety of LLMs available on the Hugging Face hub.\n\nThe [MLX Swift Examples repo](https://github.com/ml-explore/mlx-swift-examples)\ncontains the complete code and documentation for these examples, including\n[guidelines on porting models](https://swiftpackageindex.com/ml-explore/mlx-swift-examples/main/documentation/mlxlmcommon/porting)\nfrom MLX Python.\n\n## Installation\n\nThe ``MLX`` Swift package can be built and run from Xcode or SwiftPM. A CMake installation is also provided, featuring a native Linux build option.\n\nMore details are in the [documentation](https://swiftpackageindex.com/ml-explore/mlx-swift/main/documentation/mlx/install).\n\n### Xcode (1)\n\nIn Xcode you can add `https://github.com/ml-explore/mlx-swift.git` as a package\ndependency and link `MLX`, `MLXNN`, `MLXOptimizers` and `MLXRandom` as needed.\n\n### XCode (2)\n\nNote that the SwiftPM and XCode (1) methods build `MLX` as a Library, not as a framework.\nIt is possible to construct a situation where YourApp -> MLX, YourApp -> YourFramework\nand YourFramework -> MLX.  This would give two copies of MLX in the resulting process\nand it may not work as expected.\n\nIf this cannot be avoided, either by making YourFramework a Library or having YourApp\n_not_ link MLX, you can use the `xcode/MLX.xcodeproj` to build MLX as a _Framework_.\nThis will require `mlx-swift` to be checked out adjacent or inside your project,\npossibly using git submodules, and dragging the `mlx-swift/xcode/MLX.xcodeproj` into\nyour project.  Once that is done your application can build and link MLX and related\nas Frameworks.\n\n### SwiftPM\n\nTo use ``MLX`` with SwiftPM you can add this to your `Package.swift`:\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/ml-explore/mlx-swift\", from: \"0.10.0\")\n]\n```\n\nand add the libraries as dependencies:\n\n```swift\ndependencies: [.product(name: \"MLX\", package: \"mlx-swift\"),\n               .product(name: \"MLXNN\", package: \"mlx-swift\"),\n               .product(name: \"MLXOptimizers\", package: \"mlx-swift\")]\n```\n\n> [!Note]\n> SwiftPM (command line) cannot build the Metal shaders so the ultimate build has to be done\n> via Xcode.\n\n### xcodebuild\n\nAlthough `SwiftPM` (command line) cannot build the Metal shaders, `xcodebuild` can and\nit can be used to do command line builds:\n\n```shell\n# build and run tests\nxcodebuild test -scheme mlx-swift-Package -destination 'platform=OS X'\n\n# build Tutorial\nxcodebuild build -scheme Tutorial -destination 'platform=OS X'\n```\n\n### CMake\n\n#### (1) macOS\n\n**Install Dependencies**\n\nBuilding with CMake requires both CMake and Ninja to be installed. You can do\nthis with [Homebrew](https://brew.sh/):\n\n```shell\nbrew install cmake\nbrew install ninja\n```\n\n**Build + Run Examples**\n\n- The examples use the Metal GPU backend by default on macOS.\n- Note that the CUDA GPU backend is exclusive to Linux.\n\n```shell\nmkdir -p build\ncd build\ncmake .. -G Ninja\nninja\n./example1\n./tutorial\n```\n\n#### (2) Linux\n\n**Install Dependencies**\n\n- To build the example binaries, install all dependencies listed in the CI [scripts](.github/scripts/).\n- Note: The CUDA GPU backend requires the CUDA toolkit and additional dependencies.\n- For Swift installation on Linux, visit [swift.org](https://www.swift.org/install/linux/).\n\n**Build + Run Examples (CPU backend)**\n\nOn Linux, the examples use the CPU backend by default.\n\n```shell\nmkdir -p build\npushd build\ncmake -DMLX_BUILD_METAL=OFF .. -G Ninja\nninja\n./example1\n./tutorial\npopd\n```\n\n**Build + Run Examples (GPU CUDA backend)**\n\n```shell\nmkdir -p build\npushd build\ncmake -DMLX_BUILD_METAL=OFF -DMLX_BUILD_CUDA=ON -DMLX_C_BUILD_EXAMPLES=OFF .. -G Ninja\nninja\n./example1 --device gpu\n./tutorial --device gpu\npopd\n```\n\n## Contributing\n\nCheck out the [contribution guidelines](CONTRIBUTING.md) for more information\non contributing to MLX. See the\n[docs](https://swiftpackageindex.com/ml-explore/mlx-swift/main/documentation/mlx/install) for more\ninformation on building from source, and running tests.\n\nWe are grateful for all of [our\ncontributors](ACKNOWLEDGMENTS.md#Individual-Contributors). If you contribute\nto MLX Swift and wish to be acknowledged, please add your name to the list in your\npull request.\n\nMLX Swift was initially developed by David Koski and Ronan Collobert, and is\nnow maintained by David Koski. MLX Swift is built on top of\n[MLX](https://github.com/ml-explore/mlx), which was initially developed with\nequal contribution by Awni Hannun, Jagrit Digani, Angelos Katharopoulos, and\nRonan Collobert.\n\n## Versions\n\nSee [Releases](https://github.com/ml-explore/mlx-swift/releases).  Generally the MLX Swift version number corresponds to the same version number in [MLX](https://github.com/ml-explore/mlx).  Release notes indicate specifics.\n\nAll capabilities in MLX (Python) should be available in MLX Swift.  If you encounter any that are missing please file an issue or feel free to submit a PR.\n",
      "stars_today": 2
    },
    {
      "id": 994992847,
      "name": "tempo",
      "full_name": "tempoxyz/tempo",
      "description": "the blockchain for payments",
      "html_url": "https://github.com/tempoxyz/tempo",
      "stars": 676,
      "forks": 173,
      "language": "Rust",
      "topics": [],
      "created_at": "2025-06-02T19:55:49Z",
      "updated_at": "2026-01-17T00:07:36Z",
      "pushed_at": "2026-01-17T00:54:21Z",
      "open_issues": 164,
      "owner": {
        "login": "tempoxyz",
        "avatar_url": "https://avatars.githubusercontent.com/u/211589300?v=4"
      },
      "readme": "<br>\n<br>\n\n<p align=\"center\">\n  <a href=\"https://tempo.xyz\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/tempoxyz/.github/refs/heads/main/assets/combomark-dark.svg\">\n      <img alt=\"tempo combomark\" src=\"https://raw.githubusercontent.com/tempoxyz/.github/refs/heads/main/assets/combomark-bright.svg\" width=\"auto\" height=\"120\">\n    </picture>\n  </a>\n</p>\n\n<br>\n<br>\n\n# Tempo\n\nThe blockchain for payments at scale.\n\n[Tempo](https://docs.tempo.xyz/) is a blockchain designed specifically for stablecoin payments. Its architecture focuses on high throughput, low cost, and features that financial institutions, payment service providers, and fintech platforms expect from modern payment infrastructure.\n\nYou can get started today by integrating with the [Tempo testnet](https://docs.tempo.xyz/quickstart/integrate-tempo), [building on Tempo](https://docs.tempo.xyz/guide/use-accounts), [running a Tempo node](https://docs.tempo.xyz/guide/node), reading the [Tempo protocol specs](https://docs.tempo.xyz/protocol) or by [building with Tempo SDKs](https://docs.tempo.xyz/sdk).\n\n## What makes Tempo different\n\n- [TIP‚Äë20 token standard](https://docs.tempo.xyz/protocol/tip20/overview) (enshrined ERC‚Äë20 extensions)\n\n  - Predictable payment throughput via dedicated payment lanes reserved for TIP‚Äë20 transfers (eliminates noisy‚Äëneighbor contention).\n  - Native reconciliation with on‚Äëtransfer memos and commitment patterns (hash/locator) for off‚Äëchain PII and large data.\n  - Built‚Äëin compliance through [TIP‚Äë403 Policy Registry](https://docs.tempo.xyz/protocol/tip403/overview): single policy shared across multiple tokens, updated once and enforced everywhere.\n\n- Low, predictable fees in [stablecoins](https://docs.tempo.xyz/learn/stablecoins)\n\n  - Users pay gas directly in USD-stablecoins at launch; the [Fee AMM](https://docs.tempo.xyz/protocol/fees/fee-amm#fee-amm-overview) automatically converts to the validator‚Äôs preferred stablecoin.\n  - TIP‚Äë20 transfers target sub‚Äëmillidollar costs (<$0.001).\n\n- [Tempo Transactions](https://docs.tempo.xyz/guide/tempo-transaction) (native ‚Äúsmart accounts‚Äù)\n\n  - Batched payments: atomic multi‚Äëoperation payouts (payroll, settlements, refunds).\n  - Fee sponsorship: apps can pay users' gas to streamline onboarding and flows.\n  - Scheduled payments: protocol‚Äëlevel time windows for recurring and timed disbursements.\n  - Modern authentication: passkeys via WebAuthn/P256 (biometric sign‚Äëin, secure enclave, cross‚Äëdevice sync).\n\n- Performance and finality\n\n  - Built on the [Reth SDK](https://github.com/paradigmxyz/reth), the most performant and flexible EVM (Ethereum Virtual Machine) execution client.\n  - Simplex Consensus (via [Commonware](https://commonware.xyz/)): fast, sub‚Äësecond finality in normal conditions; graceful degradation under adverse networks.\n\n- Coming soon\n\n  - On‚Äëchain FX and non‚ÄëUSD stablecoin support for direct on‚Äëchain liquidity; pay fees in more currencies.\n  - Native private token standard: opt‚Äëin privacy for balances/transfers coexisting with issuer compliance and auditability.\n\n## What makes Tempo familiar\n\n- Fully compatible with the Ethereum Virtual Machine (EVM), targeting the Osaka hardfork.\n- Deploy and interact with smart contracts using the same tools, languages, and frameworks used on Ethereum, such as Solidity, Foundry, and Hardhat.\n- All Ethereum JSON-RPC methods work out of the box.\n\nWhile the execution environment mirrors Ethereum's, Tempo introduces some differences optimized for payments, described [here](https://docs.tempo.xyz/quickstart/evm-compatibility).\n\n## Getting Started\n\n### As a user\n\nYou can connect to Tempo's public testnet using the following details:\n\n| Property           | Value                              |\n| ------------------ | ---------------------------------- |\n| **Network Name**   | Tempo Testnet (Moderato)           |\n| **Currency**       | `USD`                              |\n| **Chain ID**       | `42431`                            |\n| **HTTP URL**       | `https://rpc.moderato.tempo.xyz`   |\n| **WebSocket URL**  | `wss://rpc.moderato.tempo.xyz`     |\n| **Block Explorer** | `https://explore.tempo.xyz`        |\n\nNext, grab some stablecoins to test with from Tempo's [Faucet](https://docs.tempo.xyz/quickstart/faucet#faucet).\n\nAlternatively, use [`cast`](https://github.com/tempoxyz/tempo-foundry):\n\n```bash\ncast rpc tempo_fundAddress <ADDRESS> --rpc-url https://rpc.moderato.tempo.xyz\n```\n\n### As an operator\n\nWe provide three different installation paths: installing a pre-built binary, building from source or using our provided Docker image.\n\n- [Pre-built Binary](https://docs.tempo.xyz/guide/node/installation#pre-built-binary)\n- [Build from Source](https://docs.tempo.xyz/guide/node/installation#build-from-source)\n- [Docker](https://docs.tempo.xyz/guide/node/installation#docker)\n\nSee the [Tempo documentation](https://docs.tempo.xyz/guide/node) for instructions on how to install and run Tempo.\n\n### As a developer\n\nTempo has several SDKs to help you get started building on Tempo:\n\n- [TypeScript](https://docs.tempo.xyz/sdk/typescript)\n- [Rust](https://docs.tempo.xyz/sdk/rust)\n- [Go](https://docs.tempo.xyz/sdk/go)\n- [Foundry](https://docs.tempo.xyz/sdk/foundry)\n\nWant to contribute?\n\nFirst, clone the repository:\n\n```\ngit clone https://github.com/tempoxyz/tempo\ncd tempo\n```\n\nNext, install [`just`](https://github.com/casey/just?tab=readme-ov-file#packages).\n\nInstall the dependencies:\n\n```bash\njust\n```\n\nBuild Tempo:\n\n```bash\njust build-all\n```\n\nRun the tests:\n\n```bash\ncargo nextest run\n```\n\nStart a `localnet`:\n\n```bash\njust localnet\n```\n\n## Contributing\n\nOur contributor guidelines can be found in [`CONTRIBUTING.md`](https://github.com/tempoxyz/tempo?tab=contributing-ov-file).\n\n## Security\n\nSee [`SECURITY.md`](https://github.com/tempoxyz/tempo?tab=security-ov-file). Note: Tempo is still undergoing audit and does not have an active bug bounty. Submissions will not be eligible for a bounty until audits have concluded.\n\n## License\n\nLicensed under either of [Apache License](./LICENSE-APACHE), Version\n2.0 or [MIT License](./LICENSE-MIT) at your option.\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in these crates by you, as defined in the Apache-2.0 license,\nshall be dual licensed as above, without any additional terms or conditions.\n",
      "stars_today": 2
    },
    {
      "id": 62350380,
      "name": "reqwest",
      "full_name": "seanmonstar/reqwest",
      "description": "An easy and powerful Rust HTTP Client",
      "html_url": "https://github.com/seanmonstar/reqwest",
      "stars": 11335,
      "forks": 1322,
      "language": "Rust",
      "topics": [
        "http",
        "http-client",
        "rust"
      ],
      "created_at": "2016-07-01T00:23:08Z",
      "updated_at": "2026-01-16T21:41:27Z",
      "pushed_at": "2026-01-16T22:16:50Z",
      "open_issues": 444,
      "owner": {
        "login": "seanmonstar",
        "avatar_url": "https://avatars.githubusercontent.com/u/51479?v=4"
      },
      "readme": "# reqwest\n\n[![crates.io](https://img.shields.io/crates/v/reqwest.svg)](https://crates.io/crates/reqwest)\n[![Documentation](https://docs.rs/reqwest/badge.svg)](https://docs.rs/reqwest)\n[![MIT/Apache-2 licensed](https://img.shields.io/crates/l/reqwest.svg)](./LICENSE-APACHE)\n[![CI](https://github.com/seanmonstar/reqwest/actions/workflows/ci.yml/badge.svg)](https://github.com/seanmonstar/reqwest/actions/workflows/ci.yml)\n\nAn ergonomic, batteries-included HTTP Client for Rust.\n\n- Async and blocking `Client`s\n- Plain bodies, JSON, urlencoded, multipart\n- Customizable redirect policy\n- HTTP Proxies\n- HTTPS via rustls (or optionally, system-native TLS)\n- Cookie Store\n- WASM\n\n\n## Example\n\nThis asynchronous example uses [Tokio](https://tokio.rs) and enables some\noptional features, so your `Cargo.toml` could look like this:\n\n```toml\n[dependencies]\nreqwest = { version = \"0.13\", features = [\"json\"] }\ntokio = { version = \"1\", features = [\"full\"] }\n```\n\nAnd then the code:\n\n```rust,no_run\nuse std::collections::HashMap;\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let resp = reqwest::get(\"https://httpbin.org/ip\")\n        .await?\n        .json::<HashMap<String, String>>()\n        .await?;\n    println!(\"{resp:#?}\");\n    Ok(())\n}\n```\n\n## Commercial Support\n\nFor private advice, support, reviews, access to the maintainer, and the like, reach out for [commercial support][sponsor].\n\n## Requirements\n\nBy default, Reqwest uses [rustls](https://github.com/rustls/rustls), but when the `native-tls` feature is enabled\nit will use the operating system TLS framework if available, meaning Windows and macOS.\nOn Linux, it will use the available OpenSSL (see https://docs.rs/openssl for supported versions and more details)\nor fail to build if not found. Alternatively you can enable the `native-tls-vendored` feature to compile a copy of OpenSSL.\n\n## License\n\nLicensed under either of\n\n- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://apache.org/licenses/LICENSE-2.0)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in the work by you, as defined in the Apache-2.0 license, shall\nbe dual licensed as above, without any additional terms or conditions.\n\n## Sponsors\n\nSupport this project by becoming a [sponsor][].\n\n[sponsor]: https://seanmonstar.com/sponsor\n",
      "stars_today": 1
    },
    {
      "id": 153316914,
      "name": "BehaviorTree.CPP",
      "full_name": "BehaviorTree/BehaviorTree.CPP",
      "description": "Behavior Trees Library in C++. Batteries included.",
      "html_url": "https://github.com/BehaviorTree/BehaviorTree.CPP",
      "stars": 3760,
      "forks": 793,
      "language": "C++",
      "topics": [
        "ai",
        "behaviortree",
        "coordination",
        "games",
        "robotics",
        "ros",
        "state-machine"
      ],
      "created_at": "2018-10-16T16:19:58Z",
      "updated_at": "2026-01-16T18:15:04Z",
      "pushed_at": "2026-01-15T14:26:04Z",
      "open_issues": 83,
      "owner": {
        "login": "BehaviorTree",
        "avatar_url": "https://avatars.githubusercontent.com/u/44158496?v=4"
      },
      "readme": "![License MIT](https://img.shields.io/github/license/BehaviorTree/BehaviorTree.CPP?color=blue)\n[![conan Ubuntu](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/cmake_ubuntu.yml/badge.svg)](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/cmake_ubuntu.yml)\n[![conan Windows](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/cmake_windows.yml/badge.svg)](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/cmake_windows.yml)\n[![ros2](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/ros2.yaml/badge.svg)](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/ros2.yaml)\n[![pixi (Conda)](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/pixi.yaml/badge.svg)](https://github.com/BehaviorTree/BehaviorTree.CPP/actions/workflows/pixi.yaml)\n\n# BehaviorTree.CPP 4.8\n\n<p align=\"center\"><img width=350 src=\"animated.svg\"></p>\n\nThis  __C++ 17__ library provides a framework to create BehaviorTrees.\nIt was designed to be flexible, easy to use, reactive and fast.\n\nEven if our main use-case is __robotics__, you can use this library to build\n__AI for games__, or to replace Finite State Machines.\n\nThere are few features which make __BehaviorTree.CPP__ unique, when compared to other implementations:\n\n- It makes __asynchronous Actions__, i.e. non-blocking, a first-class citizen.\n\n- You can build __reactive__ behaviors that execute multiple Actions concurrently (orthogonality).\n\n- Trees are defined using a Domain Specific __scripting language__ (based on XML), and can be loaded at run-time; in other words, even if written in C++, the morphology of the Trees is _not_ hard-coded.\n\n- You can statically link your custom TreeNodes or convert them into __plugins__\nand load them at run-time.\n\n- It provides a type-safe and flexible mechanism to do __Dataflow__ between\n  Nodes of the Tree.\n\n- It includes a __logging/profiling__ infrastructure that allows the user\nto visualize, record, replay and analyze state transitions.\n\n## Documentation and Community\n\nYou can learn about the main concepts, the API and the tutorials here: https://www.behaviortree.dev/\n\nAn automatically generated API documentation can be found here: https://www.behaviortree.dev/\n\nIf the documentation doesn't answer your questions and/or you want to\nconnect with the other **BT.CPP** users, visit [our forum](https://github.com/BehaviorTree/BehaviorTree.CPP/discussions)\n\n# GUI Editor\n\nEditing a BehaviorTree is as simple as editing an XML file in your favorite text editor.\n\nIf you are looking for a more fancy graphical user interface (and I know you do) check\n[Groot2](https://www.behaviortree.dev/groot) out.\n\n![Groot screenshot](docs/groot-screenshot.png)\n\n# How to compile\n\n**BT.CPP** requires a compile that supports c++17.\n\nThree build systems are supported:\n\n- **colcon (ament)**, if you use ROS2\n- **conan** otherwise (Linux/Windows).\n- **straight cmake** if you want to be personally responsible for dependencies :)\n\nCompiling with [conan](https://conan.io/):\n\n> [!NOTE]\n> Conan builds require CMake 3.23 or newer.\n\nAssuming that you are in the **root** directory of `BehaviorTree.CPP`:\n\n```\nconan install . -s build_type=Release --build=missing\ncmake --preset conan-release\ncmake --build --preset conan-release\n```\n\nIf you have dependencies such as ZeroMQ and SQlite already installed and you don't want to\nuse conan, simply type:\n\n```\nmkdir build_release\ncmake -S . -B build_release\ncmake --build build_release --parallel\n```\n\nIf you want to build in a [pixi](https://pixi.sh/) project (conda virtual environment).\n```\npixi run build\n```\n\nIf you want to use BT.CPP in your application, please refer to the\nexample here: https://github.com/BehaviorTree/btcpp_sample .\n\n# Commercial support\n\nAre you using BT.CPP in your commercial product and do you need technical support / consulting?\nYou can contact the primary author, **dfaconti@aurynrobotics.com**, to discuss your use case and needs.\n\n## Previous version\n\nVersion 3.8 of the software can be found in the branch\n[v3.8](https://github.com/BehaviorTree/BehaviorTree.CPP/tree/v3.8).\n\nThat branch might receive bug fixes, but the new features will be implemented\nonly in the master branch.\n\n# Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=BehaviorTree/BehaviorTree.CPP&type=Date)](https://star-history.com/#BehaviorTree/BehaviorTree.CPP&Date)\n\n# Contributors\n\n<a href=\"https://github.com/BehaviorTree/BehaviorTree.CPP/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=BehaviorTree/BehaviorTree.CPP\" />\n</a>\n\n# License\n\nThe MIT License (MIT)\n\nCopyright (c) 2019-2025 Davide Faconti\n\nCopyright (c) 2018-2019 Davide Faconti, Eurecat\n\nCopyright (c) 2014-2018 Michele Colledanchise\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
      "stars_today": 1
    },
    {
      "id": 96496250,
      "name": "swift-snapshot-testing",
      "full_name": "pointfreeco/swift-snapshot-testing",
      "description": "üì∏ Delightful Swift snapshot testing.",
      "html_url": "https://github.com/pointfreeco/swift-snapshot-testing",
      "stars": 4112,
      "forks": 641,
      "language": "Swift",
      "topics": [
        "screenshot-testing",
        "snapshot-testing",
        "swift",
        "testing"
      ],
      "created_at": "2017-07-07T03:38:51Z",
      "updated_at": "2026-01-16T03:47:36Z",
      "pushed_at": "2025-11-17T17:51:33Z",
      "open_issues": 194,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# üì∏ SnapshotTesting\n\n[![CI](https://github.com/pointfreeco/swift-snapshot-testing/workflows/CI/badge.svg)](https://actions-badge.atrox.dev/pointfreeco/swift-snapshot-testing/goto)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](http://pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-snapshot-testing%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-snapshot-testing%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing)\n\nDelightful Swift snapshot testing.\n\n## Usage\n\nOnce [installed](#installation), _no additional configuration is required_. You can import the\n`SnapshotTesting` module and call the `assertSnapshot` function.\n\n``` swift\nimport SnapshotTesting\nimport Testing\n\n@MainActor\nstruct MyViewControllerTests {\n  @Test func myViewController() {\n    let vc = MyViewController()\n\n    assertSnapshot(of: vc, as: .image)\n  }\n}\n```\n\nWhen an assertion first runs, a snapshot is automatically recorded to disk and the test will fail,\nprinting out the file path of any newly-recorded reference.\n\n> ‚ùå failed - No reference was found on disk. Automatically recorded snapshot: ‚Ä¶\n>\n> open \"‚Ä¶/MyAppTests/\\_\\_Snapshots\\_\\_/MyViewControllerTests/testMyViewController.png\"\n>\n> Re-run \"testMyViewController\" to test against the newly-recorded snapshot.\n\nRepeat test runs will load this reference and compare it with the runtime value. If they don't\nmatch, the test will fail and describe the difference. Failures can be inspected from Xcode's Report\nNavigator or by inspecting the file URLs of the failure.\n\nYou can record a new reference by customizing snapshots inline with the assertion, or using the\n`withSnapshotTesting` tool:\n\n```swift\n// Record just this one snapshot\nassertSnapshot(of: vc, as: .image, record: .all)\n\n// Record all snapshots in a scope:\nwithSnapshotTesting(record: .all) {\n  assertSnapshot(of: vc1, as: .image)\n  assertSnapshot(of: vc2, as: .image)\n  assertSnapshot(of: vc3, as: .image)\n}\n\n// Record all snapshot failures in a Swift Testing suite:\n@Suite(.snapshots(record: .failed))\nstruct FeatureTests {}\n\n// Record all snapshot failures in an 'XCTestCase' subclass:\nclass FeatureTests: XCTestCase {\n  override func invokeTest() {\n    withSnapshotTesting(record: .failed) {\n      super.invokeTest()\n    }\n  }\n}\n```\n\n## Snapshot Anything\n\nWhile most snapshot testing libraries in the Swift community are limited to `UIImage`s of `UIView`s,\nSnapshotTesting can work with _any_ format of _any_ value on _any_ Swift platform!\n\nThe `assertSnapshot` function accepts a value and any snapshot strategy that value supports. This\nmeans that a view or view controller can be tested against an image representation _and_ against a\ntextual representation of its properties and subview hierarchy.\n\n``` swift\nassertSnapshot(of: vc, as: .image)\nassertSnapshot(of: vc, as: .recursiveDescription)\n```\n\nView testing is highly configurable. You can override trait collections (for specific size classes\nand content size categories) and generate device-agnostic snapshots, all from a single simulator.\n\n``` swift\nassertSnapshot(of: vc, as: .image(on: .iPhoneSe))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneSe))\n\nassertSnapshot(of: vc, as: .image(on: .iPhoneSe(.landscape)))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneSe(.landscape)))\n\nassertSnapshot(of: vc, as: .image(on: .iPhoneX))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneX))\n\nassertSnapshot(of: vc, as: .image(on: .iPadMini(.portrait)))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPadMini(.portrait)))\n```\n\n> **Warning**\n> Snapshots must be compared using the exact same simulator that originally took the reference to\n> avoid discrepancies between images.\n\nBetter yet, SnapshotTesting isn't limited to views and view controllers! There are a number of\navailable snapshot strategies to choose from.\n\nFor example, you can snapshot test URL requests (_e.g._, those that your API client prepares).\n\n``` swift\nassertSnapshot(of: urlRequest, as: .raw)\n// POST http://localhost:8080/account\n// Cookie: pf_session={\"userId\":\"1\"}\n//\n// email=blob%40pointfree.co&name=Blob\n```\n\nAnd you can snapshot test `Encodable` values against their JSON _and_ property list representations.\n\n``` swift\nassertSnapshot(of: user, as: .json)\n// {\n//   \"bio\" : \"Blobbed around the world.\",\n//   \"id\" : 1,\n//   \"name\" : \"Blobby\"\n// }\n\nassertSnapshot(of: user, as: .plist)\n// <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n// <!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\"\n//  \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n// <plist version=\"1.0\">\n// <dict>\n//   <key>bio</key>\n//   <string>Blobbed around the world.</string>\n//   <key>id</key>\n//   <integer>1</integer>\n//   <key>name</key>\n//   <string>Blobby</string>\n// </dict>\n// </plist>\n```\n\nIn fact, _any_ value can be snapshot-tested by default using its\n[mirror](https://developer.apple.com/documentation/swift/mirror)!\n\n``` swift\nassertSnapshot(of: user, as: .dump)\n// ‚ñø User\n//   - bio: \"Blobbed around the world.\"\n//   - id: 1\n//   - name: \"Blobby\"\n```\n\nIf your data can be represented as an image, text, or data, you can write a snapshot test for it!\n\n## Documentation\n\nThe latest documentation is available\n[here](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting).\n\n## Installation\n\n### Xcode\n\n> **Warning**\n> By default, Xcode will try to add the SnapshotTesting package to your project's main\n> application/framework target. Please ensure that SnapshotTesting is added to a _test_ target\n> instead, as documented in the last step, below.\n\n 1. From the **File** menu, navigate through **Swift Packages** and select\n    **Add Package Dependency‚Ä¶**.\n 2. Enter package repository URL: `https://github.com/pointfreeco/swift-snapshot-testing`.\n 3. Confirm the version and let Xcode resolve the package.\n 4. On the final dialog, update SnapshotTesting's **Add to Target** column to a test target that\n    will contain snapshot tests (if you have more than one test target, you can later add\n    SnapshotTesting to them by manually linking the library in its build phase).\n\n### Swift Package Manager\n\nIf you want to use SnapshotTesting in any other project that uses\n[SwiftPM](https://swift.org/package-manager/), add the package as a dependency in `Package.swift`:\n\n```swift\ndependencies: [\n  .package(\n    url: \"https://github.com/pointfreeco/swift-snapshot-testing\",\n    from: \"1.12.0\"\n  ),\n]\n```\n\nNext, add `SnapshotTesting` as a dependency of your test target:\n\n```swift\ntargets: [\n  .target(name: \"MyApp\"),\n  .testTarget(\n    name: \"MyAppTests\",\n    dependencies: [\n      \"MyApp\",\n      .product(name: \"SnapshotTesting\", package: \"swift-snapshot-testing\"),\n    ]\n  )\n]\n```\n\n## Features\n\n  - [**Dozens of snapshot strategies**][available-strategies]. Snapshot\n    testing isn't just for `UIView`s and `CALayer`s. Write snapshots against _any_ value.\n  - [**Write your own snapshot strategies**][defining-strategies].\n    If you can convert it to an image, string, data, or your own diffable format, you can snapshot\n    test it! Build your own snapshot strategies from scratch or transform existing ones.\n  - **No configuration required.** Don't fuss with scheme settings and environment variables.\n    Snapshots are automatically saved alongside your tests.\n  - **More hands-off.** New snapshots are recorded whether `isRecording` mode is `true` or not.\n  - **Subclass-free.** Assert from any XCTest case or Quick spec.\n  - **Device-agnostic snapshots.** Render views and view controllers for specific devices and trait\n    collections from a single simulator.\n  - **First-class Xcode support.** Image differences are captured as XCTest attachments. Text\n    differences are rendered in inline error messages.\n  - **Supports any platform that supports Swift.** Write snapshot tests for iOS, Linux, macOS, and\n    tvOS.\n  - **SceneKit, SpriteKit, and WebKit support.** Most snapshot testing libraries don't support these\n    view subclasses.\n  - **`Codable` support**. Snapshot encodable data structures into their JSON and property list\n    representations.\n  - **Custom diff tool integration**. Configure failure messages to print diff commands for\n    [Kaleidoscope](https://kaleidoscope.app) or your diff tool of choice.\n    ``` swift\n    SnapshotTesting.diffToolCommand = { \"ksdiff \\($0) \\($1)\" }\n    ```\n\n[available-strategies]: https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting/snapshotting\n[defining-strategies]: https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting/customstrategies\n\n## Plug-ins\n\n  - [AccessibilitySnapshot](https://github.com/cashapp/AccessibilitySnapshot) adds easy regression\n    testing for iOS accessibility.\n    \n  - [AccessibilitySnapshotColorBlindness](https://github.com/Sherlouk/AccessibilitySnapshotColorBlindness)\n    adds snapshot strategies for color blindness simulation on iOS views, view controllers and images.\n\n  - [GRDBSnapshotTesting](https://github.com/SebastianOsinski/GRDBSnapshotTesting) adds snapshot\n    strategy for testing SQLite database migrations made with [GRDB](https://github.com/groue/GRDB.swift).\n\n  - [Nimble-SnapshotTesting](https://github.com/tahirmt/Nimble-SnapshotTesting) adds \n    [Nimble](https://github.com/Quick/Nimble) matchers for SnapshotTesting to be used by Swift\n    Package Manager.\n\n  - [Prefire](https://github.com/BarredEwe/Prefire) generating Snapshot Tests via\n    [Swift Package Plugins](https://github.com/apple/swift-package-manager/blob/main/Documentation/Plugins.md)\n    using SwiftUI `Preview`\n  \n  - [PreviewSnapshots](https://github.com/doordash-oss/swiftui-preview-snapshots) share `View`\n    configurations between SwiftUI Previews and snapshot tests and generate several snapshots with a\n    single test assertion.\n\n  - [swift-html](https://github.com/pointfreeco/swift-html) is a Swift DSL for type-safe,\n    extensible, and transformable HTML documents and includes an `HtmlSnapshotTesting` module to\n    snapshot test its HTML documents.\n\n  - [swift-snapshot-testing-nimble](https://github.com/Killectro/swift-snapshot-testing-nimble) adds\n    [Nimble](https://github.com/Quick/Nimble) matchers for SnapshotTesting.\n\n  - [swift-snapshot-testing-stitch](https://github.com/Sherlouk/swift-snapshot-testing-stitch/) adds\n    the ability to stitch multiple UIView's or UIViewController's together in a single test.\n\n  - [SnapshotTestingDump](https://github.com/tahirmt/swift-snapshot-testing-dump) Adds support to\n    use [swift-custom-dump](https://github.com/pointfreeco/swift-custom-dump/) by using `customDump`\n    strategy for `Any`\n\n  - [SnapshotTestingHEIC](https://github.com/alexey1312/SnapshotTestingHEIC) adds image support\n  using the HEIC storage format which reduces file sizes in comparison to PNG.\n\n  - [SnapshotVision](https://github.com/gregersson/swift-snapshot-testing-vision) adds snapshot\n    strategy for text recognition on views and images. Uses Apples Vision framework.\n\nHave you written your own SnapshotTesting plug-in?\n[Add it here](https://github.com/pointfreeco/swift-snapshot-testing/edit/master/README.md) and\nsubmit a pull request!\n\n## Related Tools\n\n  - [`iOSSnapshotTestCase`](https://github.com/uber/ios-snapshot-test-case/) helped introduce screen\n    shot testing to a broad audience in the iOS community. Experience with it inspired the creation\n    of this library.\n\n  - [Jest](https://jestjs.io) brought generalized snapshot testing to the JavaScript community with\n    a polished user experience. Several features of this library (diffing, automatically capturing\n    new snapshots) were directly influenced.\n\n## Learn More\n\nSnapshotTesting was designed with [witness-oriented programming](https://www.pointfree.co/episodes/ep39-witness-oriented-library-design).\n\nThis concept (and more) are explored thoroughly in a series of episodes on\n[Point-Free](https://www.pointfree.co), a video series exploring functional programming and Swift\nhosted by [Brandon Williams](https://twitter.com/mbrandonw) and\n[Stephen Celis](https://twitter.com/stephencelis).\n\nWitness-oriented programming and the design of this library was explored in the following\n[Point-Free](https://www.pointfree.co) episodes:\n\n  - [Episode 33](https://www.pointfree.co/episodes/ep33-protocol-witnesses-part-1): Protocol Witnesses: Part 1\n  - [Episode 34](https://www.pointfree.co/episodes/ep34-protocol-witnesses-part-1): Protocol Witnesses: Part 2\n  - [Episode 35](https://www.pointfree.co/episodes/ep35-advanced-protocol-witnesses-part-1): Advanced Protocol Witnesses: Part 1\n  - [Episode 36](https://www.pointfree.co/episodes/ep36-advanced-protocol-witnesses-part-2): Advanced Protocol Witnesses: Part 2\n  - [Episode 37](https://www.pointfree.co/episodes/ep37-protocol-oriented-library-design-part-1): Protocol-Oriented Library Design: Part 1\n  - [Episode 38](https://www.pointfree.co/episodes/ep38-protocol-oriented-library-design-part-2): Protocol-Oriented Library Design: Part 2\n  - [Episode 39](https://www.pointfree.co/episodes/ep39-witness-oriented-library-design): Witness-Oriented Library Design\n  - [Episode 40](https://www.pointfree.co/episodes/ep40-async-functional-refactoring): Async Functional Refactoring\n  - [Episode 41](https://www.pointfree.co/episodes/ep41-a-tour-of-snapshot-testing): A Tour of Snapshot Testing üÜì\n\n<a href=\"https://www.pointfree.co/episodes/ep41-a-tour-of-snapshot-testing\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0041.jpeg\" width=\"480\">\n</a>\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n",
      "stars_today": 1
    },
    {
      "id": 6656911,
      "name": "stripe-ios",
      "full_name": "stripe/stripe-ios",
      "description": "Stripe iOS SDK    ",
      "html_url": "https://github.com/stripe/stripe-ios",
      "stars": 2488,
      "forks": 1038,
      "language": "Swift",
      "topics": [
        "stripe",
        "stripe-sdk"
      ],
      "created_at": "2012-11-12T16:55:08Z",
      "updated_at": "2026-01-16T23:40:10Z",
      "pushed_at": "2026-01-17T00:00:55Z",
      "open_issues": 179,
      "owner": {
        "login": "stripe",
        "avatar_url": "https://avatars.githubusercontent.com/u/856813?v=4"
      },
      "readme": "# Stripe iOS SDK\n\n[![CocoaPods](https://img.shields.io/cocoapods/v/Stripe.svg?style=flat)](http://cocoapods.org/?q=author%3Astripe%20name%3Astripe)\n[![License](https://img.shields.io/cocoapods/l/Stripe.svg?style=flat)](https://github.com/stripe/stripe-ios/blob/master/LICENSE)\n[![Platform](https://img.shields.io/cocoapods/p/Stripe.svg?style=flat)](https://github.com/stripe/stripe-ios#)\n\n> [!TIP]\n> Want to chat live with Stripe engineers? Join us on our [Discord server](https://stripe.com/go/developer-chat).\n\nThe Stripe iOS SDK makes it quick and easy to build an excellent payment experience in your iOS app. We provide powerful and customizable UI screens and elements that can be used out-of-the-box to collect your users' payment details. We also expose the low-level APIs that power those UIs so that you can build fully custom experiences.\n\nGet started with our [üìö integration guides](https://stripe.com/docs/payments/accept-a-payment?platform=ios) and [example projects](#Examples), or [üìò browse the SDK reference](https://stripe.dev/stripe-ios/docs/index.html).\n\n> Updating to a newer version of the SDK? See our [migration guide](https://github.com/stripe/stripe-ios/blob/master/MIGRATING.md) and [changelog](https://github.com/stripe/stripe-ios/blob/master/CHANGELOG.md).\n\nTable of contents\n=================\n<!-- NOTE: Use case-sensitive anchor links for docc compatibility -->\n<!--ts-->\n   * [Features](#Features)\n   * [Releases](#Releases)\n   * [Requirements](#Requirements)\n   * [Getting started](#Getting-started)\n      * [Integration](#Integration)\n      * [Examples](#Examples)\n      * [Building from source](#Building-from-source)\n   * [Card scanning](#Card-scanning)\n   * [Contributing](#Contributing)\n   * [Migrating](#Migrating-from-older-versions)\n   * [Code Style](#Code-style)\n   * [Licenses](#Licenses)\n\n<!--te-->\n\n## Features\n\n**Simplified security**: We make it simple for you to collect sensitive data such as credit card numbers and remain [PCI compliant](https://stripe.com/docs/security#pci-dss-guidelines). This means the sensitive data is sent directly to Stripe instead of passing through your server. For more information, see our [integration security guide](https://stripe.com/docs/security).\n\n**Apple Pay**: [StripeApplePay](StripeApplePay/README.md) provides a [seamless integration with Apple Pay](https://stripe.com/docs/apple-pay).\n\n**SCA-ready**: The SDK automatically performs native [3D Secure authentication](https://stripe.com/docs/payments/3d-secure) if needed to comply with [Strong Customer Authentication](https://stripe.com/docs/strong-customer-authentication) regulation in Europe.\n\n**Native UI**: We provide native screens and elements to collect payment details. For example, [PaymentSheet](https://stripe.com/docs/payments/accept-a-payment?platform=ios) is a prebuilt UI that combines all the steps required to pay - collecting payment details, billing details, and confirming the payment - into a single sheet that displays on top of your app.\n\n<img src=\"https://user-images.githubusercontent.com/89988962/153276097-9b3369a0-e732-45c4-96ec-ff9d48ad0fb6.png\" alt=\"PaymentSheet\" align=\"center\"/>\n\n**Stripe API**: [StripePayments](StripePayments/README.md) provides [low-level APIs](https://stripe.dev/stripe-ios/docs/Classes/STPAPIClient.html) that correspond to objects and methods in the Stripe API. You can build your own entirely custom UI on top of this layer, while still taking advantage of utilities like [STPCardValidator](https://stripe.dev/stripe-ios/docs/Classes/STPCardValidator.html) to validate your user‚Äôs input.\n\n**Card scanning**: We support card scanning on iOS 13 and higher. See our [Card scanning](#Card-scanning) section.\n\n**App Clips**: The `StripeApplePay` module provides a [lightweight SDK for offering Apple Pay in an App Clip](https://stripe.com/docs/apple-pay#app-clips).\n\n**Localized**: We support the following localizations: Bulgarian, Catalan, Chinese (Hong Kong), Chinese (Simplified), Chinese (Traditional), Croatian, Czech, Danish, Dutch, English (US), English (United Kingdom), Estonian, Filipino, Finnish, French, French (Canada), German, Greek, Hungarian, Indonesian, Italian, Japanese, Korean, Latvian, Lithuanian, Malay, Maltese, Norwegian Bokm√•l, Norwegian Nynorsk (Norway), Polish, Portuguese, Portuguese (Brazil), Romanian, Russian, Slovak, Slovenian, Spanish, Spanish (Latin America), Swedish, Turkish, Thai and Vietnamese.\n\n**Identity**: Learn about our [Stripe Identity iOS SDK](StripeIdentity/README.md) to verify the identity of your users.\n\n#### Recommended usage\n\nIf you're selling digital products or services that will be consumed within your app, (e.g. subscriptions, in-game currencies, game levels, access to premium content, or unlocking a full version), you must use Apple's in-app purchase APIs. See the [App Store review guidelines](https://developer.apple.com/app-store/review/guidelines/#payments) for more information. For all other scenarios you can use this SDK to process payments via Stripe.\n\n#### Privacy\n\nThe Stripe iOS SDK collects data to help us improve our products and prevent fraud. This data is never used for advertising and is not rented, sold, or given to advertisers. Our full privacy policy is available at [https://stripe.com/privacy](https://stripe.com/privacy).\n\nFor help with Apple's App Privacy Details form in App Store Connect, visit [Stripe iOS SDK Privacy Details](https://support.stripe.com/questions/stripe-ios-sdk-privacy-details).\n\n## Modules\n<!-- \n  EmergeTools project must be made public before adding to this table:\n  https://www.emergetools.com/settings?tab=app-display-options&cards=public_org_apps\n\n  NOTE: Pad `Size` col with &nbsp; to prevent table from shrinking badge images and maintain readability  \n -->\n| Module | Description | Size&nbsp;([Download&nbsp;‚Üí&nbsp;Install](https://docs.emergetools.com/docs/ios-app-size#download-vs-install-size))&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |\n|--------|-------------|------|\n| [StripePaymentSheet](StripePaymentSheet) | Stripe's [prebuilt payment UI](https://stripe.com/docs/payments/accept-a-payment?platform=ios&ui=payment-sheet). | [![StripePaymentSheet size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripePaymentSheetSize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripePaymentSheet&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripePaymentSheetSize/release?utm_campaign=badge-data) |\n| [StripeConnect](StripeConnect) | Connect embedded components to add connected account dashboard functionality to your app. | [![StripeConnect size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripeConnectSize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripeConnect&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripeConnectSize/release?utm_campaign=badge-data) |\n| [StripeIdentity](StripeIdentity) | Securely capture ID documents and selfies on iOS for use with [Stripe's Identity API](https://docs.stripe.com/identity) to confirm the identity of global users. | [![StripeIdentity size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripeIdentitySize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripeIdentity&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripeIdentitySize/release?utm_campaign=badge-data) |\n| [StripeFinancialConnections](StripeFinancialConnections) | Securely connect financial accounts to Stripe's merchant account with [Stripe Financial Connections](https://docs.stripe.com/financial-connections). | [![StripeFinancialConnections size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripeFinancialConnectionsSize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripeFinancialConnections&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripeFinancialConnectionsSize/release?utm_campaign=badge-data) |\n| Stripe | Contains all the below frameworks, plus [Issuing](https://stripe.com/docs/issuing/cards/digital-wallets?platform=iOS). | [![Stripe size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripeSize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=Stripe&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripeSize/release?utm_campaign=badge-data) |\n| [StripeApplePay](StripeApplePay) | [Apple Pay support](/docs/apple-pay), including `STPApplePayContext`. | [![StripeApplePay size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripeApplePaySize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripeApplePay&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripeApplePaySize/release?utm_campaign=badge-data) |\n| [StripePayments](StripePayments) | Bindings for the Stripe Payments API. | [![StripePayments size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripePaymentsSize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripePayments&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripePaymentsSize/release?utm_campaign=badge-data) |\n| [StripePaymentsUI](StripePaymentsUI) | Bindings for the Stripe Payments API, [STPPaymentCardTextField](https://stripe.com/docs/payments/accept-a-payment?platform=ios&ui=custom), STPCardFormView, and other UI elements. | [![StripePaymentsUI size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripePaymentsUISize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripePaymentsUI&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripePaymentsUISize/release?utm_campaign=badge-data) |\n\n## Releases\n\nWe support Cocoapods and Swift Package Manager.\n\nIf you link the library manually, use a version from our [releases](https://github.com/stripe/stripe-ios/releases) page and make sure to embed <ins>all</ins> of the required frameworks.\n\nFor the `Stripe` module, link the following frameworks:\n- `Stripe.xcframework`\n- `Stripe3DS2.xcframework`\n- `StripeApplePay.xcframework`\n- `StripePayments.xcframework`\n- `StripePaymentsUI.xcframework`\n- `StripeIssuing.xcframework`\n- `StripeCore.xcframework`\n- `StripeUICore.xcframework`\n\nFor other modules, follow the instructions below:\n- [StripeApplePay](StripeApplePay/README.md#manual-linking)\n- [StripeConnect](StripeConnect/README.md#manual-linking)\n- [StripeFinancialConnections](StripeFinancialConnections/README.md#manual-linking)\n- [StripeIdentity](StripeIdentity/README.md#manual-linking)\n- [StripeIssuing](StripeIssuing/README.md#manual-linking)\n- [StripePaymentSheet](StripePaymentSheet/README.md#manual-linking)\n- [StripePayments](StripePayments/README.md#manual-linking)\n- [StripePaymentsUI](StripePaymentsUI/README.md#manual-linking)\n\nIf you're reading this on GitHub.com, please make sure you are looking at the [tagged version](https://github.com/stripe/stripe-ios/tags) that corresponds to the release you have installed. Otherwise, the instructions and example code may be mismatched with your copy.\n\n## Requirements\n\nThe Stripe iOS SDK requires Xcode 16 or later and is compatible with apps targeting iOS 13 or above. We support Catalyst on macOS 11 or later.\n\nFor iOS 12 support, please use [v22.8.4](https://github.com/stripe/stripe-ios/tree/v22.8.4). For iOS 11 support, please use [v21.13.0](https://github.com/stripe/stripe-ios/tree/v21.13.0). For iOS 10, please use [v19.4.0](https://github.com/stripe/stripe-ios/tree/v19.4.0). If you need to support iOS 9, use [v17.0.2](https://github.com/stripe/stripe-ios/tree/v17.0.2).\n\n## Getting started\n\n### Integration\n\nGet started with our [üìö integration guides](https://stripe.com/docs/payments/accept-a-payment?platform=ios) and [example projects](/Example), or [üìò browse the SDK reference](https://stripe.dev/stripe-ios/docs/index.html) for fine-grained documentation of all the classes and methods in the SDK.\n\n### Examples\n\n- [Prebuilt UI](Example/PaymentSheet%20Example) (Recommended)\n  - This example demonstrates how to build a payment flow using [`PaymentSheet`](https://stripe.com/docs/payments/accept-a-payment?platform=ios), an embeddable native UI component that lets you accept [10+ payment methods](https://stripe.com/docs/payments/payment-methods/integration-options#payment-method-product-support) with a single integration.\n\n- [Non-Card Payment Examples](Example/Non-Card%20Payment%20Examples)\n  - This example demonstrates how to manually accept various payment methods using the Stripe API.\n\n## Card scanning\n\n[PaymentSheet](https://stripe.com/docs/payments/accept-a-payment?platform=ios) offers built-in card scanning. To enable card scanning, you'll need to set `NSCameraUsageDescription` in your application's plist, and provide a reason for accessing the camera (e.g. \"To scan cards\"). Card scanning is supported on devices with iOS 13 or higher.\n\nYou can demo this feature in our [PaymentSheet example app](Example/PaymentSheet%20Example). When you run the example app on a device, you'll see a \"Scan Card\" button when adding a new card.\n\n## Contributing\n\nWe welcome contributions of any kind including new features, bug fixes, and documentation improvements. Please first open an issue describing what you want to build if it is a major change so that we can discuss how to move forward. Otherwise, go ahead and open a pull request for minor changes such as typo fixes and one liners.\n\n### Running tests\n\n1. From the root of the repo, run `bundle install && bundle exec fastlane stripeios_tests`. This will install the test dependencies and run the tests.\n2. Once you have run this once, you can also run the tests in Xcode from the `StripeiOS` target in `Stripe.xcworkspace`.\n\nTo re-record snapshot tests, use the `bundle exec ruby ci_scripts/snapshots.rb --record`.\n\n## Migrating from older versions\n\nSee [MIGRATING.md](https://github.com/stripe/stripe-ios/blob/master/MIGRATING.md)\n\n## Code style\nWe use [swiftlint](https://github.com/realm/SwiftLint) to enforce code style.\n\nTo install it, run `brew install swiftlint`\n\nTo lint your code before pushing you can run `ci_scripts/lint_modified_files.sh`\n\nYou can also add this script as a pre-push hook by running `ln -s \"$(pwd)/ci_scripts/lint_modified_files.sh\" .git/hooks/pre-push && chmod +x .git/hooks/pre-push`\n\nTo format modified files automatically, you can use `ci_scripts/format_modified_files.sh` and you can add it as a pre-commit hook using `ln -s \"$(pwd)/ci_scripts/format_modified_files.sh\" .git/hooks/pre-commit && chmod +x .git/hooks/pre-commit`\n\n## Licenses\n\n- [Stripe iOS SDK License](LICENSE)\n",
      "stars_today": 1
    },
    {
      "id": 761903377,
      "name": "mlx-swift-examples",
      "full_name": "ml-explore/mlx-swift-examples",
      "description": "Examples using MLX Swift",
      "html_url": "https://github.com/ml-explore/mlx-swift-examples",
      "stars": 2384,
      "forks": 352,
      "language": "Swift",
      "topics": [
        "mlx"
      ],
      "created_at": "2024-02-22T17:47:37Z",
      "updated_at": "2026-01-16T22:34:37Z",
      "pushed_at": "2026-01-14T18:14:59Z",
      "open_issues": 48,
      "owner": {
        "login": "ml-explore",
        "avatar_url": "https://avatars.githubusercontent.com/u/102832242?v=4"
      },
      "readme": "# MLX Swift Examples\n\nExample [MLX Swift](https://github.com/ml-explore/mlx-swift) programs.  The language model\nexamples use models implemented in [MLX Swift LM](https://github.com/ml-explore/mlx-swift-lm).\n\n- [MNISTTrainer](Applications/MNISTTrainer/README.md): An example that runs on\n  both iOS and macOS that downloads MNIST training data and trains a\n  [LeNet](https://en.wikipedia.org/wiki/LeNet).\n\n- [LLMEval](Applications/LLMEval/README.md): An example that runs on both iOS\n  and macOS that downloads an LLM and tokenizer from Hugging Face and\n  generates text from a given prompt.\n\n- [VLMEval](Applications/VLMEval/README.md): An example that runs on iOS, macOS and visionOS to download a VLM and tokenizer from Hugging Face and\n  analyzes the given image and describe it in text.\n\n- [MLXChatExample](Applications/MLXChatExample/README.md): An example chat app that runs on both iOS and macOS that supports LLMs and VLMs.\n\n- [LoRATrainingExample](Applications/LoRATrainingExample/README.md): An example that runs on macOS that downloads an LLM and fine-tunes it using LoRA (Low-Rank Adaptation) with training data.\n\n- [LinearModelTraining](Tools/LinearModelTraining/README.md): An example that\n  trains a simple linear model.\n\n- [StableDiffusionExample](Applications/StableDiffusionExample/README.md): An\n  example that runs on both iOS and macOS that downloads a stable diffusion model\n  from Hugging Face and  and generates an image from a given prompt.\n\n- [llm-tool](Tools/llm-tool/README.md): A command line tool for generating text\n  using a variety of LLMs available on the Hugging Face hub.\n\n- [ExampleLLM](Tools/ExampleLLM/README.md): A command line tool using the simplified API to interact with LLMs.\n\n- [image-tool](Tools/image-tool/README.md): A command line tool for generating images\n  using a stable diffusion model from Hugging Face.\n\n- [mnist-tool](Tools/mnist-tool/README.md): A command line tool for training a\n  a LeNet on MNIST.\n  \n> [!IMPORTANT]\n> `MLXLMCommon`, `MLXLLM`, `MLXVLM` and `MLXEmbedders` have moved to a new repository\n> containing _only_ reusable libraries: [mlx-swift-lm](https://github.com/ml-explore/mlx-swift-lm).\n\nPrevious URLs and tags will continue to work, but going forward all updates to these\nlibraries will be done in the other repository.  Previous tags _are_ supported in\nthe new repository.\n\n> [!TIP]\n> Contributors that wish to edit both `mlx-swift-examples` and `mlx-swift-lm` can\n> use [this technique in Xcode](https://developer.apple.com/documentation/xcode/editing-a-package-dependency-as-a-local-package).\n\n\n# Reusable Libraries\n\nLLM and VLM implementations are available in [MLX Swift LM](https://github.com/ml-explore/mlx-swift-lm):\n\n- [MLXLLMCommon](https://swiftpackageindex.com/ml-explore/mlx-swift-lm/main/documentation/mlxlmcommon) -- common API for LLM and VLM\n- [MLXLLM](https://swiftpackageindex.com/ml-explore/mlx-swift-lm/main/documentation/mlxllm) -- large language model example implementations\n- [MLXVLM](https://swiftpackageindex.com/ml-explore/mlx-swift-lm/main/documentation/mlxvlm) -- vision language model example implementations\n- [MLXEmbedders](https://swiftpackageindex.com/ml-explore/mlx-swift-lm/main/documentation/mlxembedders) -- popular Encoders / Embedding models example implementations\n\nMLX Swift Examples also contains a few reusable libraries that can be imported with this code in your `Package.swift` or by referencing the URL in Xcode:\n\n```swift\n.package(url: \"https://github.com/ml-explore/mlx-swift-examples/\", branch: \"main\"),\n```\n\nThen add one or more libraries to the target as a dependency:\n\n```swift\n.target(\n    name: \"YourTargetName\",\n    dependencies: [\n        .product(name: \"StableDiffusion\", package: \"mlx-libraries\")\n    ]),\n```\n\n- [StableDiffusion](https://swiftpackageindex.com/ml-explore/mlx-swift-examples/main/documentation/stablediffusion) -- SDXL Turbo and Stable Diffusion model example implementations\n- [MLXMNIST](https://swiftpackageindex.com/ml-explore/mlx-swift-examples/main/documentation/mlxmnist) -- MNIST implementation for all your digit recognition needs\n\n## Running\n\nThe application and command line tool examples can be run from Xcode or from\nthe command line:\n\n```\n./mlx-run llm-tool --prompt \"swift programming language\"\n```\n\nNote: `mlx-run` is a shell script that uses `xcode` command line tools to\nlocate the built binaries. It is equivalent to running from Xcode itself.\n\nSee also:\n\n- [MLX troubleshooting](https://swiftpackageindex.com/ml-explore/mlx-swift/main/documentation/mlx/troubleshooting)\n",
      "stars_today": 1
    },
    {
      "id": 629243152,
      "name": "alloy",
      "full_name": "alloy-rs/alloy",
      "description": "Transports, Middleware, and Networks for the Alloy project",
      "html_url": "https://github.com/alloy-rs/alloy",
      "stars": 1192,
      "forks": 552,
      "language": "Rust",
      "topics": [
        "blockchain",
        "ethereum"
      ],
      "created_at": "2023-04-17T23:31:47Z",
      "updated_at": "2026-01-16T15:13:17Z",
      "pushed_at": "2026-01-16T15:13:11Z",
      "open_issues": 95,
      "owner": {
        "login": "alloy-rs",
        "avatar_url": "https://avatars.githubusercontent.com/u/128098468?v=4"
      },
      "readme": "# Alloy\n\nAlloy connects applications to blockchains.\n\nAlloy is a rewrite of [`ethers-rs`] from the ground up, with exciting new\nfeatures, high performance, and excellent [docs](https://docs.rs/alloy).\n\nWe also have a [book](https://alloy.rs/) on all things Alloy and many [examples](https://github.com/alloy-rs/examples) to help you get started.\n\n[![Telegram chat][telegram-badge]][telegram-url]\n\n[`ethers-rs`]: https://github.com/gakonst/ethers-rs\n[telegram-badge]: https://img.shields.io/endpoint?color=neon&style=for-the-badge&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Fethers_rs\n[telegram-url]: https://t.me/ethers_rs\n\n## Installation\n\nAlloy consists of a number of crates that provide a range of functionality essential for interfacing with any Ethereum-based blockchain.\n\nThe easiest way to get started is to add the `alloy` crate with the `full` feature flag from the command-line using Cargo:\n\n```sh\ncargo add alloy --features full\n```\n\nAlternatively, you can add the following to your `Cargo.toml` file:\n\n```toml\nalloy = { version = \"1\", features = [\"full\"] }\n```\n\nFor a more fine-grained control over the features you wish to include, you can add the individual crates to your `Cargo.toml` file, or use the `alloy` crate with the features you need.\n\nA comprehensive list of available features can be found on [docs.rs](https://docs.rs/crate/alloy/latest/features) or in the [`alloy` crate's `Cargo.toml`](https://github.com/alloy-rs/alloy/blob/main/crates/alloy/Cargo.toml).\n\n## Examples\n\n### Connecting to a Provider\n\nHere's a simple example of connecting to an Ethereum node and querying the latest block:\n\n```rust\nuse alloy::providers::{Provider, ProviderBuilder};\n\n# async fn example() -> Result<(), Box<dyn std::error::Error>> {\n// Create a provider with the HTTP transport using the `reqwest` crate.\nlet rpc_url = \"https://eth.llamarpc.com\";\nlet provider = ProviderBuilder::new().connect(rpc_url).await?;\n\n// Get the latest block number.\nlet latest_block = provider.get_block_number().await?;\nprintln!(\"Latest block number: {latest_block}\");\n\n// Get chain ID.\nlet chain_id = provider.get_chain_id().await?;\nprintln!(\"Chain ID: {chain_id}\");\n# Ok(())\n# }\n```\n\n### Network generic\n\nAlloy is network-generic, allowing you to work with any Ethereum-compatible chain. Here's an example using Optimism (see [`op-alloy`](https://docs.rs/op-alloy)) to demonstrate this capability:\n\n```rust,ignore\nuse alloy::providers::{Provider, ProviderBuilder};\nuse op_alloy::network::Optimism;\n\n# async fn example() -> Result<(), Box<dyn std::error::Error>> {\n// Connect to Optimism mainnet.\nlet rpc_url = \"https://mainnet.optimism.io\";\nlet provider = ProviderBuilder::new_with_network::<Optimism>().connect(rpc_url).await?;\n# Ok(())\n# }\n```\n\nFor more examples, check out the [Alloy examples repository](https://github.com/alloy-rs/examples).\n\n## Overview\n\nThis repository contains the following crates:\n\n- [`alloy`]: Meta-crate for the entire project, including [`alloy-core`]\n- [`alloy-consensus`] - Ethereum consensus interface\n  - [`alloy-consensus-any`] - Catch-all consensus interface for multiple networks\n- [`alloy-contract`] - Interact with on-chain contracts\n- [`alloy-eip5792`] - Types for the `wallet_` Ethereum JSON-RPC namespace\n- [`alloy-eip7547`] - EIP-7547: Inclusion Lists types\n- [`alloy-eips`] - Ethereum Improvement Proposal (EIP) implementations\n- [`alloy-genesis`] - Ethereum genesis file definitions\n- [`alloy-json-rpc`] - Core data types for JSON-RPC 2.0 clients\n- [`alloy-ens`] - Ethereum Name Service (ENS) utilities\n- [`alloy-network`] - Network abstraction for RPC types\n  - [`alloy-network-primitives`] - Primitive types for the network abstraction\n- [`alloy-node-bindings`] - Ethereum execution-layer client bindings\n- [`alloy-provider`] - Interface with an Ethereum blockchain\n- [`alloy-pubsub`] - Ethereum JSON-RPC [publish-subscribe] tower service and type definitions\n- [`alloy-rpc-client`] - Low-level Ethereum JSON-RPC client implementation\n- [`alloy-rpc-types`] - Meta-crate for all Ethereum JSON-RPC types\n  - [`alloy-rpc-types-admin`] - Types for the `admin` Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-anvil`] - Types for the [Anvil] development node's Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-any`] - Types for JSON-RPC namespaces across multiple networks\n  - [`alloy-rpc-types-beacon`] - Types for the [Ethereum Beacon Node API][beacon-apis]\n  - [`alloy-rpc-types-debug`] - Types for the `debug` Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-engine`] - Types for the `engine` Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-eth`] - Types for the `eth` Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-mev`] - Types for the MEV bundle JSON-RPC namespace\n  - [`alloy-rpc-types-tenderly`] - Types for the Tenderly node's Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-trace`] - Types for the `trace` Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-txpool`] - Types for the `txpool` Ethereum JSON-RPC namespace\n- [`alloy-serde`] - [Serde]-related utilities\n- [`alloy-signer`] - Ethereum signer abstraction\n  - [`alloy-signer-aws`] - [AWS KMS] signer implementation\n  - [`alloy-signer-gcp`] - [GCP KMS] signer implementation\n  - [`alloy-signer-ledger`] - [Ledger] signer implementation\n  - [`alloy-signer-local`] - Local (private key, keystore, mnemonic, YubiHSM) signer implementations\n  - [`alloy-signer-trezor`] - [Trezor] signer implementation\n  - [`alloy-signer-turnkey`] - [Turnkey] signer implementation\n- [`alloy-transport`] - Low-level Ethereum JSON-RPC transport abstraction\n  - [`alloy-transport-http`] - HTTP transport implementation\n  - [`alloy-transport-ipc`] - IPC transport implementation\n  - [`alloy-transport-ws`] - WS transport implementation\n- [`alloy-tx-macros`] - Derive macro for transaction envelopes\n\n[`alloy`]: https://github.com/alloy-rs/alloy/tree/main/crates/alloy\n[`alloy-core`]: https://docs.rs/alloy-core\n[`alloy-consensus`]: https://github.com/alloy-rs/alloy/tree/main/crates/consensus\n[`alloy-consensus-any`]: https://github.com/alloy-rs/alloy/tree/main/crates/consensus-any\n[`alloy-contract`]: https://github.com/alloy-rs/alloy/tree/main/crates/contract\n[`alloy-eip5792`]: https://github.com/alloy-rs/alloy/tree/main/crates/eip5792\n[`alloy-eip7547`]: https://github.com/alloy-rs/alloy/tree/main/crates/eip7547\n[`alloy-eips`]: https://github.com/alloy-rs/alloy/tree/main/crates/eips\n[`alloy-genesis`]: https://github.com/alloy-rs/alloy/tree/main/crates/genesis\n[`alloy-json-rpc`]: https://github.com/alloy-rs/alloy/tree/main/crates/json-rpc\n[`alloy-network`]: https://github.com/alloy-rs/alloy/tree/main/crates/network\n[`alloy-network-primitives`]: https://github.com/alloy-rs/alloy/tree/main/crates/network-primitives\n[`alloy-node-bindings`]: https://github.com/alloy-rs/alloy/tree/main/crates/node-bindings\n[`alloy-provider`]: https://github.com/alloy-rs/alloy/tree/main/crates/provider\n[`alloy-pubsub`]: https://github.com/alloy-rs/alloy/tree/main/crates/pubsub\n[`alloy-rpc-client`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-client\n[`alloy-rpc-types`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types\n[`alloy-rpc-types-admin`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-admin\n[`alloy-rpc-types-anvil`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-anvil\n[`alloy-rpc-types-any`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-any\n[`alloy-rpc-types-beacon`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-beacon\n[`alloy-rpc-types-debug`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-debug\n[`alloy-rpc-types-engine`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-engine\n[`alloy-rpc-types-eth`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-eth\n[`alloy-rpc-types-mev`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-mev\n[`alloy-rpc-types-tenderly`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-tenderly\n[`alloy-rpc-types-trace`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-trace\n[`alloy-rpc-types-txpool`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-txpool\n[`alloy-serde`]: https://github.com/alloy-rs/alloy/tree/main/crates/serde\n[`alloy-signer`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer\n[`alloy-signer-aws`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer-aws\n[`alloy-signer-gcp`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer-gcp\n[`alloy-signer-ledger`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer-ledger\n[`alloy-signer-local`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer-local\n[`alloy-signer-trezor`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer-trezor\n[`alloy-signer-turnkey`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer-turnkey\n[`alloy-transport`]: https://github.com/alloy-rs/alloy/tree/main/crates/transport\n[`alloy-transport-http`]: https://github.com/alloy-rs/alloy/tree/main/crates/transport-http\n[`alloy-transport-ipc`]: https://github.com/alloy-rs/alloy/tree/main/crates/transport-ipc\n[`alloy-transport-ws`]: https://github.com/alloy-rs/alloy/tree/main/crates/transport-ws\n[`alloy-tx-macros`]: https://github.com/alloy-rs/alloy/tree/main/crates/tx-macros\n[`alloy-ens`]: https://github.com/alloy-rs/alloy/tree/main/crates/ens\n[publish-subscribe]: https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern\n[AWS KMS]: https://aws.amazon.com/kms\n[GCP KMS]: https://cloud.google.com/kms\n[Ledger]: https://www.ledger.com\n[Trezor]: https://trezor.io\n[Turnkey]: https://www.turnkey.com\n[Serde]: https://serde.rs\n[beacon-apis]: https://ethereum.github.io/beacon-APIs\n[Anvil]: https://github.com/foundry-rs/foundry\n\n## Supported Rust Versions (MSRV)\n\n<!--\nWhen updating this, also update:\n- clippy.toml\n- Cargo.toml\n- .github/workflows/ci.yml\n-->\n\nThe current MSRV (minimum supported rust version) is 1.88.\n\nAlloy will keep a rolling MSRV policy of **at least** two versions behind the\nlatest stable release (so if the latest stable release is 1.58, we would\nsupport 1.56).\n\nNote that the MSRV is not increased automatically, and only as part of a patch\n(pre-1.0) or minor (post-1.0) release.\n\n## Contributing\n\nThanks for your help improving the project! We are so happy to have you! We have\n[a contributing guide](./CONTRIBUTING.md) to help you get involved in the\nAlloy project.\n\nPull requests will not be merged unless CI passes, so please ensure that your\ncontribution follows the linting rules and passes clippy.\n\n## Note on `no_std`\n\nBecause these crates are primarily network-focused, we do not intend to support\n`no_std` for most of them at this time.\n\nThe following crates support `no_std`:\n\n| Crate               | Version Badge                                                                                                 |\n| ------------------- | ------------------------------------------------------------------------------------------------------------- |\n| **alloy-eips**      | [![Crates.io](https://img.shields.io/crates/v/alloy-eips.svg)](https://crates.io/crates/alloy-eips)           |\n| **alloy-genesis**   | [![Crates.io](https://img.shields.io/crates/v/alloy-genesis.svg)](https://crates.io/crates/alloy-genesis)     |\n| **alloy-serde**     | [![Crates.io](https://img.shields.io/crates/v/alloy-serde.svg)](https://crates.io/crates/alloy-serde)         |\n| **alloy-consensus** | [![Crates.io](https://img.shields.io/crates/v/alloy-consensus.svg)](https://crates.io/crates/alloy-consensus) |\n\nIf you would like to add `no_std` support to a crate, please make sure to update\n`scripts/check_no_std.sh` as well.\n\n## Credits\n\nNone of these crates would have been possible without the great work done in:\n\n| Project | Description |\n|------------|-------------|\n| [`ethers.js`](https://github.com/ethers-io/ethers.js/) | A complete and compact JavaScript library for interacting with the Ethereum blockchain. |\n| [`rust-web3`](https://github.com/tomusdrw/rust-web3/) | Rust library for Ethereum JSON-RPC client communication, including support for async and WASM. |\n| [`ruint`](https://github.com/recmo/uint) | A fast, no-std, const-friendly implementation of fixed-size unsigned integers in Rust. |\n| [`ethabi`](https://github.com/rust-ethereum/ethabi) | Ethereum ABI encoding/decoding in Rust for contracts and transactions. |\n| [`ethcontract-rs`](https://github.com/gnosis/ethcontract-rs/) | Rust library to generate type-safe bindings to Ethereum smart contracts. |\n| [`guac_rs`](https://github.com/althea-net/guac_rs/) | Rust implementation of the GUAC protocol for Ethereum state channels. |\n\n\n\n#### License\n\n<sup>\nLicensed under either of <a href=\"LICENSE-APACHE\">Apache License, Version\n2.0</a> or <a href=\"LICENSE-MIT\">MIT license</a> at your option.\n</sup>\n\n<br>\n\n<sub>\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in these crates by you, as defined in the Apache-2.0 license,\nshall be dual licensed as above, without any additional terms or conditions.\n</sub>\n",
      "stars_today": 1
    },
    {
      "id": 715842891,
      "name": "Vectras-VM-Android",
      "full_name": "xoureldeen/Vectras-VM-Android",
      "description": "It's a Virtual Machine App for Android Which is Based on QEMU",
      "html_url": "https://github.com/xoureldeen/Vectras-VM-Android",
      "stars": 1874,
      "forks": 160,
      "language": "Java",
      "topics": [
        "android",
        "emulator",
        "limbo",
        "qemu",
        "vectras-android"
      ],
      "created_at": "2023-11-08T00:09:36Z",
      "updated_at": "2026-01-16T10:25:08Z",
      "pushed_at": "2026-01-14T12:45:35Z",
      "open_issues": 11,
      "owner": {
        "login": "xoureldeen",
        "avatar_url": "https://avatars.githubusercontent.com/u/79816069?v=4"
      },
      "readme": "<div align=\"center\">\n<p align=\"center\">\n  <img src=\"resources/vectrasvm.png\" style=\"width: 30%;\" />\n</p>\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/12183\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/12183\" alt=\"xoureldeen%2FVectras-VM-Android | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n</div>\n\n# Vectras VM\n[![Ceasefire Now](https://badge.techforpalestine.org/default)](https://techforpalestine.org/learn-more)\n\n![GitHub Repo stars](https://img.shields.io/github/stars/xoureldeen/Vectras-VM-Android)\n![GitHub watchers](https://img.shields.io/github/watchers/xoureldeen/Vectras-VM-Android)\n![GitHub forks](https://img.shields.io/github/forks/xoureldeen/Vectras-VM-Android)\n[![Total downloads](https://img.shields.io/github/downloads/xoureldeen/Vectras-VM-Android/total)](https://github.com/xoureldeen/Vectras-VM-Android/releases)\n[![Discord server](https://img.shields.io/discord/911060166810681345)][link-discord]\n[![Telegram Channel][ico-telegram]][link-telegram]\n[![Software License][ico-license]](LICENSE)\n\nWelcome to Vectras VM! A virtual machine app for Android based on QEMU that lets you emulate various OSes including: [![Windows](https://custom-icon-badges.demolab.com/badge/Windows-0078D6?logo=windows11&logoColor=white)](https://www.microsoft.com/en-us/windows) [![Linux](https://img.shields.io/badge/Linux-FCC624?logo=linux&logoColor=black)](https://www.linux.org/) [![macOS](https://img.shields.io/badge/macOS-000000?logo=apple&logoColor=F0F0F0)](https://www.apple.com/macos) [![Android](https://img.shields.io/badge/Android-3DDC84?logo=android&logoColor=white)](https://www.android.com/).\n\nIf you need help, check out [our documentation](https://vectras.vercel.app/how.html). For quick answers, join the [Vectras Telegram group](http://t.me/vectras_vm_discussion).\n\n[![Tutorial for beginners](https://img.youtube.com/vi/AlNbverd0xE/mqdefault.jpg)](https://www.youtube.com/watch?v=AlNbverd0xE)\n\n## Device Compatibility\n\nWorks fine on devices manufactured in 2021 or later and devices equipped with Snapdragon 855 CPU or better. You can try running Vectras VM on unsupported devices, but we cannot guarantee stability or support. Here are the devices tested:\n\n| Stable           | Unstable                                        |\n| --------------- | ------------------------------------------- |\n| Samsung      | Oppo      |\n| Google Pixel      | Realme      |\n| Xiaomi      | OnePlus      |\n| Redmi      | Huawei      |\n| Poco      | Honor      |\n| ZTE      | vivo      |\n| RedMagic      | IQOO      |\n\n### Minimum System Requirements\n- Android 6.0 and up.\n- 3GB RAM (1GB of free RAM).\n- A good processor.\n\n### Recommended System Requirements\n- Android 8.1 and up.\n- 8GB RAM (3GB of free RAM).\n- CPU and Android OS support 64-bit.\n- Snapdragon 855 CPU or better.\n- Integrated or removable cooling system (if running operating systems from 2010 to present).\n> [!TIP]\n> If the OS you are trying to emulate crashes, try using an older version.\n\n# Installation\n\n### Stable Releases\n\nYou can download Vectras VM from the [releases](https://github.com/xoureldeen/Vectras-VM-Android/releases) page or the [official website](https://vectras.vercel.app/download.html).\n\nor\n\n\n[![OpenAPK](https://img.shields.io/badge/Get%20it%20on-OpenAPK-3DDC84?style=for-the-badge&logo=android&logoColor=white)](https://www.openapk.net/vectras-vm/com.vectras.vm/)\n\n### Beta Releases\n\nWe publish a **new beta release after every commit** ‚Äî so you can always test the latest features and improvements!\n\n[![Download Beta](https://img.shields.io/badge/Download-Beta-blue?style=for-the-badge&logo=github)](https://github.com/AnBui2004/Vectras-VM-Emu-Android/releases)\n\n### Bootstraps\nQEMU 9.2.4 - 3dfx (only for Vectras VM 3.5.0):\n- [For Android ARM (64-bit)](https://github.com/AnBui2004/Vectras-VM-Emu-Android/releases/download/3.5.0/base-nosve-vectras-vm-arm64-v8a.tar.gz)\n- [For Android x86 (64-bit)](https://github.com/AnBui2004/Vectras-VM-Emu-Android/releases/download/3.5.0/base-vectras-vm-x86_64.tar.gz)\n\nQEMU 9.2.2 - 3dfx (recommended and for Vectras VM 3.5.1+):\n- [For Android ARM (64-bit)](https://github.com/AnBui2004/Vectras-VM-Emu-Android/releases/download/3.5.1/base-genegic-nosve-vectras-vm-arm64-v8a.tar.gz)\n- [For Android ARM (32-bit)](https://github.com/AnBui2004/Vectras-VM-Emu-Android/releases/download/3.5.4/base-vectras-vm-armeabi-v7a.tar.gz)\n- [For Android x86 (64-bit)](https://github.com/AnBui2004/Vectras-VM-Emu-Android/releases/download/3.5.1/base-generic-vectras-vm-x86_64.tar.gz)\n- [For Android x86 (32-bit)](https://github.com/AnBui2004/Vectras-VM-Emu-Android/releases/download/3.5.4/base-vectras-vm-x86.tar.gz)\n\nQEMU 9.2.2 - 3dfx (for Vectras VM 3.2.9 - 3.4.9):\n- [For Android ARM (64-bit)](https://github.com/AnBui2004/Vectras-VM-Emu-Android/releases/download/3.2.9/base-vectras-vm-arm64-v8a.tar.gz)\n- [For Android x86 (64-bit)](https://github.com/AnBui2004/Vectras-VM-Emu-Android/releases/download/3.2.9/base-vectras-vm-x86_64.tar.gz)\n\nQEMU 8.2.0 - 3dfx (only for Vectras VM 2.9.5):\n- [For Android ARM (64-bit)](https://github.com/AnBui2004/Vectras-VM-Emu-Android/releases/download/3.2.9/vectras-vm-arm64-v8a.tar.gz)\n- [For Android x86 (64-bit)](https://github.com/AnBui2004/Vectras-VM-Emu-Android/releases/download/3.2.9/vectras-vm-x86_64.tar.gz)\n\n### 3Dfx Wrappers\n\n- [For QEMU 9.2.x - 3dfx](https://github.com/AnBui2004/Vectras-VM-Emu-Android/blob/master/3dfx/3dfx-wrappers-3.5.0.iso)\n- [For QEMU 8.2.0 - 3dfx](https://github.com/AnBui2004/Vectras-VM-Emu-Android/blob/master/3dfx/3dfx-wrappers-2.9.5.iso)\n\n# Donate\nHelp support the project by contributing!\n\n[![Buy Me a Coffee at ko-fi.com][ico-ko-fi]][link-ko-fi]\n[![Support me on Patreon](https://img.shields.io/endpoint.svg?url=https%3A%2F%2Fshieldsio-patreon.vercel.app%2Fapi%3Fusername%3Dendel%26type%3Dpatrons&style=flat)](https://patreon.com/VectrasTeam)\n\n# Thanks to\n- [3DFX QEMU PATCH](https://github.com/kjliew/qemu-3dfx)\n- [Alpine Linux](https://www.alpinelinux.org/)\n- [Glide](https://github.com/bumptech/glide)\n- [Gson](https://github.com/google/gson)\n- [OkHttp](https://github.com/square/okhttp)\n- [PROOT](https://proot-me.github.io/)\n- [QEMU](https://github.com/qemu/qemu)\n- [Termux](https://github.com/termux)\n- [ZoomImageView](https://github.com/k1slay/ZoomImageView)\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=xoureldeen/Vectras-VM-Android,AnBui2004/Vectras-VM-Emu-Android&type=date&legend=top-left)](https://www.star-history.com/#xoureldeen/Vectras-VM-Android&AnBui2004/Vectras-VM-Emu-Android&type=date&legend=top-left)\n\n[ico-telegram]: https://img.shields.io/badge/Telegram-2CA5E0?logo=telegram&logoColor=white\n[ico-discord]: https://img.shields.io/badge/Discord-%235865F2.svg?&logo=discord&logoColor=white\n[ico-version]: https://img.shields.io/badge/Android-3DDC84?logo=android&logoColor=white\n[ico-license]: https://img.shields.io/badge/License-GPL_v2-blue.svg\n[ico-buymeacoffee]: https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?&logo=buy-me-a-coffee&logoColor=black\n[ico-ko-fi]: https://img.shields.io/badge/Ko--fi-FF5E5B?logo=ko-fi&logoColor=white\n\n[link-discord]: https://discord.gg/t8TACrKSk7\n[link-telegram]: https://t.me/vectras_os\n[link-repo]: https://github.com/xoureldeen/Vectras-VM-Android/\n[link-releases]: https://github.com/xoureldeen/Vectras-VM-Android/releases/\n[link-ko-fi]: https://ko-fi.com/vectrasvm\n",
      "stars_today": 1
    },
    {
      "id": 167440342,
      "name": "monocle3",
      "full_name": "cole-trapnell-lab/monocle3",
      "description": null,
      "html_url": "https://github.com/cole-trapnell-lab/monocle3",
      "stars": 432,
      "forks": 114,
      "language": "R",
      "topics": [
        "single-cell-rna-seq"
      ],
      "created_at": "2019-01-24T21:26:18Z",
      "updated_at": "2026-01-16T22:32:20Z",
      "pushed_at": "2026-01-08T18:32:17Z",
      "open_issues": 259,
      "owner": {
        "login": "cole-trapnell-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8060918?v=4"
      },
      "readme": "MONOCLE 3\n=======================\n\nMonocle 3 is an analysis toolkit for single-cell RNA-Seq experiments.  To use this package, you will need the R statistical computing environment (version 3.0 or later) and several packages available through Bioconductor and CRAN.\n\nDetails on how to install and use Monocle 3 are available on our website:\n\nhttp://cole-trapnell-lab.github.io/monocle3/\n\n## Monocle3 with BPCells counts matrix support\n\nThis development branch version of Monocle3 adds the ability to store the counts matrix on-disk using the BPCells package. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as in previous versions. In order to store the matrix on-disk, you must set the matrix_control list value `matrix_class=\"BPCells\"` in the affected commands. For example, to load a MatrixMarket file as an on-disk matrix, use the command\n\n```\ncds <- load_mm_data(mat_path=<path_to_mtx_file>,\n                    feature_anno_path=<path_to_feature_anno_file>,\n                    cell_anno_path=<path_to_cell_anno_file>,\n                    matrix_control=list(matrix_class='BPCells'))\n```\n\n### Install Monocle3 with BPCells\n\nYou must install BPCells from Github before you can install this Monocle3 version, and BPCells requires an HDF5 object library for installation. After installing the HDF5 library, you install BPCells using the command\n\n```\nremotes::install_github(\"bnprks/BPCells/r\")\n```\n\nThe [BPCells Github site](https://github.com/bnprks/BPCells)  has additional information.\n\nSome Linux distributions provide the HDF5 library as an option. The\nBPCells site has information about installing the HDF5 library on various operating systems.\n\nI used Homebrew to install an HDF5 library on MacOS. I seemed to need to install the pkg-config package as well, and add a pkg-config configuration file for HDF5. Homebrew installed pkg-config in '/opt/homebrew' so I added the hdf5.pc file in\n\n> /opt/homebrew/lib/pkgconfig/hdf5.pc\n\nwith the contents\n\n```\nprefix=/opt/homebrew/Cellar/hdf5/1.12.2_2\nexec_prefix=${prefix}\nincludedir=${prefix}/include\nlibdir=/opt/homebrew/Cellar/hdf5/1.12.2_2/lib\n  \nName: hdf5\nDescription: HDF5\nURL: xx\nVersion: 1.12.2_2\nCflags: -I${includedir}\nLibs: -L${libdir} -lhdf5\n```\n\nYou may need to update the version strings in your hdf5.pc file.\n\nMonocle3 no longer uses the terra package, so it does not need to be installed.\n\n### Notes\n\n- Monocle3 can use the BPCells package to store the feature-cell counts matrix on-disk rather than in-memory, which enables analysis of considerably larger data sets than before. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as it has in the past. To store the counts matrix on-disk, use the parameter `matrix_control=list(matrix_class=\"BPCells\")` when you make the CDS or convert the counts matrix using one of the functions\n  - `load_mm_data()`\n  - `load_mtx_data()`\n  - `load_cellranger_data()`\n  - `load_a549()`\n  - `load_worm_embryo()`\n  - `load_worm_l2()`\n  - `convert_counts_matrix()`\n\n  For example, to convert a dgCMatrix counts matrix to a BPCells on-disk matrix in an existing CDS, use the command `cds <- convert_counts_matrix(cds, matrix_control=list(matrix_class=\"BPCells\"))`.\n- BPCells stores the count matrix information in directories with names similar to `monocle.bpcells.20230830.4c4b1bebe4b4.tmp`. Monocle3 tries to remove those directories when you quit R. Please do not remove them while Monocle3 is running because doing so eliminates the count matrix data. You *can* remove them after quitting R if Monocle3 fails to remove them.\n- The method `new_cell_data_set()` accepts a BPCells on-disk counts matrix.\n- The functions `save_monocle_objects()` and `load_monocle_objects()` store and load BPCells on-disk matrices when the CDS counts matrix is an on-disk BPCells matrix.\n- The Monocle3 `saveRDS()` function warns the user to use `save_monocle_objects()` when saving a CDS with a BPCells on-disk counts matrix. If you insist on using the `saveRDS()` function, the BPCells on-disk matrix directory will not be stored and you will be unable to load it with the `readRDS()` function.\n- The function `combine_cds()` combines CDSes with mixes of dgCMatrix and BPCells on-disk counts matrices into a BPCells on-disk counts matrix. When called with the `matrix_control=list(matrix_class=\"BPCells\")` parameter, `combine_cds()` combines CDSes with all dgCMatrix counts matrices into a BPCells on-disk counts matrix.\n- Note that when the counts matrix is stored as a BPCells on-disk matrix, the `new_cell_data_set()` method stores a second BPCells on-disk copy of the matrix in the CDS assays slot with the name `counts_row_order`. The `counts_row_order` matrix is used by Monocle3 when the counts matrix is accessed intensively by row. The reason is that, by default, BPCells stores the matrix as a one-dimensional vector in column-major order, as does R. As a result, column access is fast and row access is slow. We use BPCell's ability to also store and access matrices in row-major order, which gives fast row access. However, this means that the two copies of the counts matrix must have the same count values. If you replace or change the CDS's counts matrix, you must also update the `counts_row_order` matrix, which you can do using the function `set_cds_row_order_matrix()`.\n  - The CDS assays slot is a named list where the standard, column-major order, matrix is called `counts` and the BPCells row-major order matrix is called `counts_row_order`.\n  - The `counts` matrix getter and setter methods are `counts(cds)` and `counts(cds)<-`.\n  - The Monocle3 setter warns about re-setting the BPCells `counts_row_order` matrix, unless called with the parameter `bpcells_warn=FALSE`.\n  - The `counts_row_order` getter method is called `counts_row_order`.\n  - There is no corresponding `counts_row_order` setter method\n- By default, the BPCells on-disk matrix is stored in a directory that is created where R is started. You can change the directory location using the `matrix_path` value in the `matrix_control` parameter.\n- For more information about the `matrix_control` values, see the help document for the function `set_matrix_control()`.\n- I tested this version using BPCells counts matrices on the examples in the Monocle3 documentation although I did not try all of the plotting functions.\n\n",
      "stars_today": 1
    },
    {
      "id": 248836530,
      "name": "scTenifoldKnk",
      "full_name": "cailab-tamu/scTenifoldKnk",
      "description": " R/MATLAB package to perform virtual knockout experiments on single-cell gene regulatory networks.",
      "html_url": "https://github.com/cailab-tamu/scTenifoldKnk",
      "stars": 127,
      "forks": 13,
      "language": "R",
      "topics": [
        "functional-genomics",
        "gene-function",
        "gene-knockout",
        "gene-regulatory-network",
        "virtual-knockout-experiments"
      ],
      "created_at": "2020-03-20T19:31:03Z",
      "updated_at": "2026-01-16T13:05:17Z",
      "pushed_at": "2025-09-16T19:17:04Z",
      "open_issues": 23,
      "owner": {
        "login": "cailab-tamu",
        "avatar_url": "https://avatars.githubusercontent.com/u/31963060?v=4"
      },
      "readme": "scTenifoldKnk\n=============\n\nA R/MATLAB/Python package to perform virtual knockout experiments on single-cell gene regulatory networks. **scTenifoldKnk** is a machine learning workflow that performs virtual knockout experiments using single-cell RNA sequencing (scRNAseq) data from wild-type (WT) control samples as input. Constructs a single-cell gene regulatory network (scGRN) and knocks out a target gene from the adjacency matrix of the WT scGRN by setting the gene‚Äôs outdegree edges to zero. **scTenifoldKnk** then compares the knocked out scGRN with the WT scGRN to identify differentially regulated genes, called virtual-knockout perturbed genes, which are used to assess the impact of the gene knockout and reveal the gene‚Äôs function in the analyzed cells.\n\nPython version of scTenifoldKnk is available at: https://github.com/qwerty239qwe/scTenifoldpy\n\nMATLAB version is available at: https://github.com/jamesjcai/scGEAToolbox\n\nInstall:\n-------\nYou can install **scTenifoldKnk/R** using the following command:\n\n```{R}\nlibrary(remotes)\ninstall_github('cailab-tamu/scTenifoldKnk')\nlibrary(scTenifoldKnk)\n```\n\nAvailable functions:\n--------------------\n\n|Code| Function |\n|:-|:-|\n|scTenifoldKnk|Perform virtual knockout experiments on single-cell gene regulatory networks|\n\nInput:\n--------\nThe required input for **scTenifoldKnk** is an expression matrix with genes in the rows and cells (barcodes) in the columns. Data is expected to be previously normalized or _not normalized_ if `QC = TRUE`.\n\nRunning time:\n--------\nThe running time of scTenifoldKnk is largely dependent on how long it takes to construct scGRNs from subsampled expression matrices. Time increases proportional to the number of cells and genes in the dataset used as input. Below is a table of running times under different scenarios:\n\n| Number of Cells | Number of Genes | Running Time |\n|-----------------|-----------------|--------------|\n| 300             | 1000            | 3.45 min     |\n| 1000            | 1000            | 4.25 min     |\n| 1000            | 5000            | 171.88 min (2 h 51.6 min) |\n| 2500            | 5000            | 175.29 min (2 h 55.3 min) |\n| 5000            | 5000            | 188.88 min (3 h 8.9 min) |\n| 5000            | 7500            | 189.51 min (3 h 9.5 min)  |\n| 7500            | 5000            | 615.45 min (10 h 15.5 min) |\n| 7500            | 7500            | 616.12 min (10 h 16.1 min)  |\n\n\nOutput:\n--------\nThe output of **scTenifoldKnk** is a list with 3 slots as follows: \n  * **tensorNetworks**: The computed weight-averaged denoised gene regulatory networks after CANDECOMP/PARAFAC (CP) tensor decomposition. It includes two slots with:\n    * **X**: The constructed network for the _X_ sample.\n    * **Y**: The constructed network for the _Y_ sample.\n  * **manifoldAlignment**: The generated low-dimensional features result of the non-linear manifold alignment. It is a data frame with _2 times the number of genes_ in the rows and _d_ (default= 2) dimensions in the columns\n  * **diffRegulation**: The results of the differential regulation analysis. It is a data frame with 6 columns as follows:\n    * **gene**: A character vector with the gene id identified from the manifoldAlignment output.\n    * **distance**: A numeric vector of the Euclidean distance computed between the coordinates of the same gene in both conditions.\n    * **Z**: A numeric vector of the Z-scores computed after Box-Cox power transformation.\n    * **FC**: A numeric vector of the FC computed with respect to the expectation.\n    * **p.value**: A numeric vector of the p-values associated to the fold-changes, probabilities are asigned as P[X > x] using the Chi-square distribution with one degree of freedom.\n    * **p.adj**: A numeric vector of adjusted p-values using Benjamini & Hochberg (1995) FDR correction.\n\n---\nThe function to plot the egocentric KO, the code is available at [https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R](https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R), it requires: The object out of Knk (as X), the gene to knockout (gKO).\n\n\n¬©Ô∏è The Texas A & M University System. All rights reserved.\n",
      "stars_today": 1
    },
    {
      "id": 33569135,
      "name": "RxSwift",
      "full_name": "ReactiveX/RxSwift",
      "description": "Reactive Programming in Swift",
      "html_url": "https://github.com/ReactiveX/RxSwift",
      "stars": 24681,
      "forks": 4175,
      "language": "Swift",
      "topics": [
        "functional",
        "ios",
        "observer",
        "reactive",
        "reactivex",
        "rxswift",
        "swift",
        "unidirectional"
      ],
      "created_at": "2015-04-07T21:25:17Z",
      "updated_at": "2026-01-16T06:45:23Z",
      "pushed_at": "2025-10-25T07:00:10Z",
      "open_issues": 47,
      "owner": {
        "login": "ReactiveX",
        "avatar_url": "https://avatars.githubusercontent.com/u/6407041?v=4"
      },
      "readme": "<p align=\"center\">\n<img src=\"https://github.com/ReactiveX/RxSwift/blob/main/assets/RxSwift_Logo.png?raw=true\" width=\"35%\" alt=\"RxSwift Logo\" />\n<br />\n<a href=\"https://actions-badge.atrox.dev/ReactiveX/RxSwift/goto\" target=\"_blank\"><img src=\"https://github.com/ReactiveX/RxSwift/workflows/RxSwift/badge.svg?branch=main\" alt=\"Build Status\" /></a>\n<img src=\"https://img.shields.io/badge/platforms-iOS%20%7C%20macOS%20%7C%20tvOS%20%7C%20watchOS%20%7C%20Linux-333333.svg\" alt=\"Supported Platforms: iOS, macOS, tvOS, watchOS & Linux\" />\n<br />\n<a href=\"https://cocoapods.org/pods/RxSwift\" alt=\"RxSwift on CocoaPods\" title=\"RxSwift on CocoaPods\"><img src=\"https://img.shields.io/cocoapods/v/RxSwift.svg\" /></a>\n<a href=\"https://github.com/Carthage/Carthage\" alt=\"RxSwift on Carthage\" title=\"RxSwift on Carthage\"><img src=\"https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat\" /></a>\n<a href=\"https://github.com/swiftlang/swift-package-manager\" alt=\"RxSwift on Swift Package Manager\" title=\"RxSwift on Swift Package Manager\"><img src=\"https://img.shields.io/badge/Swift%20Package%20Manager-compatible-brightgreen.svg\" /></a>\n</p>\n\nRx is a [generic abstraction of computation](https://youtu.be/looJcaeboBY) expressed through `Observable<Element>` interface, which lets you broadcast and subscribe to values and other events from an `Observable` stream.\n\nRxSwift is the Swift-specific implementation of the [Reactive Extensions](http://reactivex.io) standard.\n\n<p align=\"center\"><img src=\"https://github.com/ReactiveX/RxSwift/blob/main/assets/example.png?raw=true\" width=\"55%\" alt=\"RxSwift Observable Example of a price constantly changing and updating the app's UI\" /></p>\n\nWhile this version aims to stay true to the original spirit and naming conventions of Rx, this project also aims to provide a true Swift-first API for Rx APIs.\n\nCross platform documentation can be found on [ReactiveX.io](http://reactivex.io/).\n\nLike other Rx implementations, RxSwift's intention is to enable easy composition of asynchronous operations and streams of data in the form of `Observable` objects and a suite of methods to transform and compose these pieces of asynchronous work.\n\nKVO observation, async operations, UI Events and other streams of data are all unified under [abstraction of sequence](Documentation/GettingStarted.md#observables-aka-sequences). This is the reason why Rx is so simple, elegant and powerful.\n\n## I came here because I want to ...\n\n###### ... understand\n\n* [why use rx?](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Why.md)\n* [the basics, getting started with RxSwift](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/GettingStarted.md)\n* [traits](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Traits.md) - what are `Single`, `Completable`, `Maybe`, `Driver`, and `ControlProperty` ... and why do they exist?\n* [testing](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/UnitTests.md)\n* [tips and common errors](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Tips.md)\n* [debugging](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/GettingStarted.md#debugging)\n* [the math behind Rx](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/MathBehindRx.md)\n* [what are hot and cold observable sequences?](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/HotAndColdObservables.md)\n\n###### ... install\n\n* Integrate RxSwift/RxCocoa with my app. [Installation Guide](#installation)\n\n###### ... hack around\n\n* with the example app. [Running Example App](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/ExampleApp.md)\n* with operators in playgrounds. [Playgrounds](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Playgrounds.md)\n\n###### ... interact\n\n* All of this is great, but it would be nice to talk with other people using RxSwift and exchange experiences. <br />[Join Slack Channel](http://slack.rxswift.org)\n* Report a problem using the library. [Open an Issue With Bug Template](https://github.com/ReactiveX/RxSwift/blob/main/.github/ISSUE_TEMPLATE.md)\n* Request a new feature. [Open an Issue With Feature Request Template](Documentation/NewFeatureRequestTemplate.md)\n* Help out [Check out contribution guide](https://github.com/ReactiveX/RxSwift/blob/main/CONTRIBUTING.md)\n\n###### ... compare\n\n* [with Combine and ReactiveSwift](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/ComparisonWithOtherLibraries.md).\n\n###### ... understand the structure\n\nRxSwift is as compositional as the asynchronous work it drives. The core unit is RxSwift itself, while other dependencies can be added for UI Work, testing, and more.\n\nIt comprises five separate components depending on each other in the following way:\n\n```none\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   RxCocoa    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂   RxRelay    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n        ‚îÇ                  ‚îÇ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ             RxSwift              ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n        ‚îÇ                  ‚îÇ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ    RxTest    ‚îÇ    ‚îÇ  RxBlocking  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n* **RxSwift**: The core of RxSwift, providing the Rx standard as (mostly) defined by [ReactiveX](https://reactivex.io). It has no other dependencies.\n* **RxCocoa**: Provides Cocoa-specific capabilities for general iOS/macOS/watchOS & tvOS app development, such as Shared Sequences, Traits, and much more. It depends on both `RxSwift` and `RxRelay`.\n* **RxRelay**: Provides `PublishRelay`, `BehaviorRelay` and `ReplayRelay`, three [simple wrappers around Subjects](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Subjects.md#relays). It depends on `RxSwift`.\n* **RxTest** and **RxBlocking**: Provides testing capabilities for Rx-based systems. It depends on `RxSwift`.\n\n## Usage\n\n<table>\n  <tr>\n    <th width=\"30%\">Here's an example</th>\n    <th width=\"30%\">In Action</th>\n  </tr>\n  <tr>\n    <td>Define search for GitHub repositories ...</td>\n    <th rowspan=\"9\"><img src=\"https://raw.githubusercontent.com/kzaher/rxswiftcontent/master/GithubSearch.gif\"></th>\n  </tr>\n  <tr>\n    <td><div class=\"highlight highlight-source-swift\"><pre>\nlet searchResults = searchBar.rx.text.orEmpty\n    .throttle(.milliseconds(300), scheduler: MainScheduler.instance)\n    .distinctUntilChanged()\n    .flatMapLatest { query -> Observable&lt;[Repository]&gt; in\n        if query.isEmpty {\n            return .just([])\n        }\n        return searchGitHub(query)\n            .catchAndReturn([])\n    }\n    .observe(on: MainScheduler.instance)</pre></div></td>\n  </tr>\n  <tr>\n    <td>... then bind the results to your tableview</td>\n  </tr>\n  <tr>\n    <td width=\"30%\"><div class=\"highlight highlight-source-swift\"><pre>\nsearchResults\n    .bind(to: tableView.rx.items(cellIdentifier: \"Cell\")) {\n        (index, repository: Repository, cell) in\n        cell.textLabel?.text = repository.name\n        cell.detailTextLabel?.text = repository.url\n    }\n    .disposed(by: disposeBag)</pre></div></td>\n  </tr>\n</table>\n\n## Installation\n\nRxSwift doesn't contain any external dependencies.\n\nThese are currently the supported installation options:\n\n### Manual\n\nOpen Rx.xcworkspace, choose `RxExample` and hit run. This method will build everything and run the sample app\n\n### [CocoaPods](https://guides.cocoapods.org/using/using-cocoapods.html)\n\n```ruby\n# Podfile\nuse_frameworks!\n\ntarget 'YOUR_TARGET_NAME' do\n    pod 'RxSwift', '6.9.0'\n    pod 'RxCocoa', '6.9.0'\nend\n\n# RxTest and RxBlocking make the most sense in the context of unit/integration tests\ntarget 'YOUR_TESTING_TARGET' do\n    pod 'RxBlocking', '6.9.0'\n    pod 'RxTest', '6.9.0'\nend\n```\n\nReplace `YOUR_TARGET_NAME` and then, in the `Podfile` directory, type:\n\n```bash\n$ pod install\n```\n\n### XCFrameworks\n\nEach release starting with RxSwift 6 includes `*.xcframework` framework binaries.\n\nSimply drag the needed framework binaries to your **Frameworks, Libraries, and Embedded Content** section under your target's **General** tab.\n\n<img src=\"https://raw.githubusercontent.com/ReactiveX/RxSwift/main/assets/xcframeworks.png\" alt=\"XCFrameworks instructions\" width=\"65%\">\n\n> [!TIP]\n> RxSwift's xcframework(s) are signed with an Apple Developer account, and you can always verify the Team Name: Shai Mishali\n>\n> <img src=\"https://raw.githubusercontent.com/ReactiveX/RxSwift/main/assets/xcframeworks_signing.png\" alt=\"XCFrameworks Signing Team Name Validation\" width=\"65%\">\n\n### [Carthage](https://github.com/Carthage/Carthage)\n\nAdd this to `Cartfile`\n\n```\ngithub \"ReactiveX/RxSwift\" \"6.9.0\"\n```\n\n```bash\n$ carthage update\n```\n\n#### Carthage as a Static Library\n\nCarthage defaults to building RxSwift as a Dynamic Library.\n\nIf you wish to build RxSwift as a Static Library using Carthage you may use the script below to manually modify the framework type before building with Carthage:\n\n```bash\ncarthage update RxSwift --platform iOS --no-build\nsed -i -e 's/MACH_O_TYPE = mh_dylib/MACH_O_TYPE = staticlib/g' Carthage/Checkouts/RxSwift/Rx.xcodeproj/project.pbxproj\ncarthage build RxSwift --platform iOS\n```\n\n### [Swift Package Manager](https://github.com/swiftlang/swift-package-manager)\n\n> **Note**: There is a critical cross-dependency bug affecting many projects including RxSwift in Swift Package Manager. We've [filed a bug (SR-12303)](https://bugs.swift.org/browse/SR-12303) in early 2020 but have no answer yet. Your mileage may vary. A partial workaround can be found [here](https://github.com/ReactiveX/RxSwift/issues/2127#issuecomment-717830502).\n\nCreate a `Package.swift` file.\n\n```swift\n// swift-tools-version:5.0\n\nimport PackageDescription\n\nlet package = Package(\n  name: \"RxProject\",\n  dependencies: [\n    .package(url: \"https://github.com/ReactiveX/RxSwift.git\", .upToNextMajor(from: \"6.0.0\"))\n  ],\n  targets: [\n    .target(name: \"RxProject\", dependencies: [\"RxSwift\", .product(name: \"RxCocoa\", package: \"RxSwift\")]),\n  ]\n)\n```\n\n```bash\n$ swift build\n```\n\nTo build or test a module with RxTest dependency, set `TEST=1`.\n\n```bash\n$ TEST=1 swift test\n```\n\n### Manually using git submodules\n\n* Add RxSwift as a submodule\n\n```bash\n$ git submodule add git@github.com:ReactiveX/RxSwift.git\n```\n\n* Drag `Rx.xcodeproj` into Project Navigator\n* Go to `Project > Targets > Build Phases > Link Binary With Libraries`, click `+` and select `RxSwift`, `RxCocoa` and `RxRelay` targets\n\n## References\n\n* [http://reactivex.io/](http://reactivex.io/)\n* [Reactive Extensions GitHub (GitHub)](https://github.com/Reactive-Extensions)\n* [RxSwift RayWenderlich.com Book](https://store.raywenderlich.com/products/rxswift-reactive-programming-with-swift)\n* [RxSwift: Debunking the myth of hard (YouTube)](https://www.youtube.com/watch?v=GdvLP0ZAhhc)\n* [Boxue.io RxSwift Online Course](https://boxueio.com/series/rxswift-101) (Chinese üá®üá≥)\n* [Expert to Expert: Brian Beckman and Erik Meijer - Inside the .NET Reactive Framework (Rx) (video)](https://youtu.be/looJcaeboBY)\n* [Reactive Programming Overview (Jafar Husain from Netflix)](https://youtu.be/-8Y1-lE6NSA)\n* [Subject/Observer is Dual to Iterator (paper)](http://csl.stanford.edu/~christos/pldi2010.fit/meijer.duality.pdf)\n* [Rx standard sequence operators visualized (visualization tool)](http://rxmarbles.com/)\n* [Haskell](https://www.haskell.org/)\n",
      "stars_today": 0
    },
    {
      "id": 738491,
      "name": "facebook-ios-sdk",
      "full_name": "facebook/facebook-ios-sdk",
      "description": "Used to integrate the Facebook Platform with your iOS & tvOS apps.",
      "html_url": "https://github.com/facebook/facebook-ios-sdk",
      "stars": 8009,
      "forks": 3679,
      "language": "Swift",
      "topics": [],
      "created_at": "2010-06-24T22:11:03Z",
      "updated_at": "2026-01-16T19:40:15Z",
      "pushed_at": "2026-01-05T18:29:31Z",
      "open_issues": 332,
      "owner": {
        "login": "facebook",
        "avatar_url": "https://avatars.githubusercontent.com/u/69631?v=4"
      },
      "readme": "# Facebook SDK for iOS\n\n[![Platforms](https://img.shields.io/cocoapods/p/FBSDKCoreKit.svg)](https://cocoapods.org/pods/FBSDKCoreKit)\n[![circleci](https://circleci.com/gh/facebook/facebook-ios-sdk/tree/main.svg?style=shield)](https://circleci.com/gh/facebook/facebook-ios-sdk/tree/main)\n\n[![CocoaPods](https://img.shields.io/cocoapods/v/FBSDKCoreKit.svg)](https://cocoapods.org/pods/FBSDKCoreKit)\n[![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage)\n\nThis open-source library allows you to integrate Facebook into your iOS app.\n\nLearn more about the provided samples, documentation, integrating the SDK into your app, accessing source code, and more\nat https://developers.facebook.com/docs/ios\n\nPlease take a moment and [subscribe to releases](https://docs.github.com/en/enterprise/2.15/user/articles/watching-and-unwatching-repositories) so that you can be notified about new features, deprecations, and critical fixes. To see information about the latest release, consult our [changelog](CHANGELOG.md).\n\n|:warning: Be Advised :warning:|\n|:---|\n|<p>We have begun rewriting the iOS SDK in Swift in order to modernize the code base.</p><p>Please monitor the changelog for updates to existing interfaces but keep in mind that some interfaces will be unstable during this process. As such, updating to a minor version may introduce compilation issues related to language interoperability. Using symbols now defined in Swift may require using `@import` syntax from Objective-C and using C++ will likely require workarounds like creating wrappers in Objective-C.</p>Please bear with us as we work towards providing an improved experience for integrating with the Facebook platform.|\n\n## TRY IT OUT\n\n### Swift Package Manager\n\n1. In Xcode, select File > Swift Packages > Add Package Dependency.\n1. Follow the prompts using the URL for this repository\n1. Select the `Facebook`-prefixed libraries you want to use\n1. Check-out the tutorials available online at: <https://developers.facebook.com/docs/ios/getting-started>\n1. Start coding! Visit <https://developers.facebook.com/docs/ios> for tutorials and reference documentation.\n\n## iOS 14 CHANGES\n\n### Data Disclosure\n\nDue to the release of iOS 14, tracking events that your app collects and sends to Facebook may require you to disclosed these data types in the App Store Connect questionnaire. It is your responsibility to ensure this is reflected in your application‚Äôs privacy policy. Visit our blogpost for information on affected Facebook SDKs, APIs, and products and the Apple App Store Privacy Details article to learn more about the data types you will need to disclose.\n\nlink to FB blogpost https://developers.facebook.com/blog/post/2020/10/22/preparing-for-apple-app-store-data-disclosure-requirements/\n\napple store details https://developer.apple.com/app-store/app-privacy-details/\n\n## FEATURES\n\n- Login - <https://developers.facebook.com/docs/facebook-login>\n- Sharing - <https://developers.facebook.com/docs/sharing>\n- App Links - <https://developers.facebook.com/docs/applinks>\n- Graph API - <https://developers.facebook.com/docs/ios/graph>\n- Analytics - <https://developers.facebook.com/docs/analytics>\n\n## GIVE FEEDBACK\n\nPlease report bugs or issues to our designated developer support team -- <https://developers.facebook.com/support/bugs/> -- as this will help us resolve them more quickly.\n\nYou can also visit our [Facebook Developer Community Forum](https://developers.facebook.com/community/),\njoin the [Facebook Developers Group on Facebook](https://www.facebook.com/groups/fbdevelopers/),\nask questions on [Stack Overflow](https://stackoverflow.com/questions/tagged/facebook-ios-sdk),\nor open an issue in this repository.\n\n## CONTRIBUTE\n\nFacebook welcomes contributions to our SDKs. Please see the [CONTRIBUTING](CONTRIBUTING.md) file.\n\n## LICENSE\n\nSee the [LICENSE](LICENSE) file.\n\nCopyright ¬© Meta Platforms, Inc\n\n## SECURITY POLICY\n\nSee the [SECURITY POLICY](SECURITY.md) for more info on our bug bounty program.\n\n## DEVELOPER TERMS\n\n- By enabling Facebook integrations, including through this SDK, you can share information with Facebook, including\n  information about people‚Äôs use of your app. Facebook will use information received in accordance with our\n  [Data Use Policy](https://www.facebook.com/about/privacy/), including to provide you with insights about the\n  effectiveness of your ads and the use of your app. These integrations also enable us and our partners to serve ads on\n  and off Facebook.\n- You may limit your sharing of information with us by updating the Insights control in the developer tool\n  `https://developers.facebook.com/apps/{app_id}/settings/advanced`.\n- If you use a Facebook integration, including to share information with us, you agree and confirm that you have\n  provided appropriate and sufficiently prominent notice to and obtained the appropriate consent from your users\n  regarding such collection, use, and disclosure (including, at a minimum, through your privacy policy). You further\n  agree that you will not share information with us about children under the age of 13.\n- You agree to comply with all applicable laws and regulations and also agree to our Terms\n  <https://www.facebook.com/policies/>, including our Platform Policies <https://developers.facebook.com/policy/> and\n  Advertising Guidelines, as applicable <https://www.facebook.com/ad_guidelines.php>.\n\nBy using the Facebook SDK for iOS you agree to these terms.\n",
      "stars_today": 0
    },
    {
      "id": 17101828,
      "name": "swirl_courses",
      "full_name": "swirldev/swirl_courses",
      "description": ":mortar_board: A collection of interactive courses for the swirl R package.",
      "html_url": "https://github.com/swirldev/swirl_courses",
      "stars": 4521,
      "forks": 7243,
      "language": "R",
      "topics": [],
      "created_at": "2014-02-23T04:48:04Z",
      "updated_at": "2026-01-15T13:35:31Z",
      "pushed_at": "2024-01-10T17:38:19Z",
      "open_issues": 206,
      "owner": {
        "login": "swirldev",
        "avatar_url": "https://avatars.githubusercontent.com/u/5671732?v=4"
      },
      "readme": "# swirl courses\n\nThis is a collection of interactive courses for use with the [swirl R package](http://swirlstats.com). You'll find instructions for installing courses further down on this page. Some courses are still in development and we'd love to hear any [suggestions](https://github.com/swirldev/swirl_courses/issues/new) you have as you work through them.\n\nFor more information regarding swirl, visit [swirlstats.com](http://swirlstats.com) or the [swirl GitHub repository](https://github.com/swirldev/swirl). If you'd like to write your own interactive content, please visit the [Instructors page](http://swirlstats.com/instructors.html) of our website.\n\nHere are our current offerings, organized by level of difficulty:\n\n#### Beginner\n\n- **R Programming**: The basics of programming in R\n- [**R Programming E**](https://github.com/swirldev/R_Programming_E): Same as the original, but modified slightly for in-class use (see below ***)\n- [**The R Programming Environment**](https://swirlstats.com/scn/rpe.html)\n<!-- - **Data Analysis**: Basic ideas in statistics and data visualization -->\n<!-- - **Mathematical Biostatistics Boot Camp**: One- and two-sample t-tests, power, and sample size -->\n<!-- - **Open Intro**: A very basic introduction to statistics, data analysis, and data visualization -->\n\n\\*\\*\\* *R Programming E is identical to R Programming, except we've eliminated the prompts for Coursera credentials at the end of each lesson and instead give students the option to send an email to their instructor notifying them of completion. Admittedly, it's sort of a hack until we come up with a more robust solution for in-class use (i.e. an instructor \"dashboard\").*\n\n#### Intermediate\n\n- **Regression Models**: The basics of regression modeling in R\n- **Getting and Cleaning Data**: dplyr, tidyr, lubridate, oh my!\n\n#### Advanced\n\n- **Statistical Inference**: This intermediate to advanced level course closely follows the\n[Statistical Inference course](https://www.coursera.org/course/statinference) of the Johns Hopkins \n[Data Science Specialization](https://www.coursera.org/specialization/jhudatascience/1) on Coursera. It\nintroduces the student to basic concepts of statistical inference\nincluding probability, hypothesis testing, confidence intervals and\np-values. It concludes with an initiation to topics of particular\nrelevance to big data, issues of multiple testing and resampling.\n- [**Advanced R Programming**](https://swirlstats.com/scn/arp.html)\n\nSince our users come from a variety backgrounds, it's very hard to label material as **Beginner**, **Intermediate**, or **Advanced**. If you find something that is labelled **Beginner** to be challenging, please don't be discouraged. The first step of learning anything is to acknowledge that you are capable of understanding it. True understanding will come with time and practice.\n\n#### Course Authors\n\n- **Writing swirl Courses**: An interactive guides and example \n  for swirl course authors. The first group of lessons cover basics. The rest cover \n  special topics useful primarily as samples--points of departure for one's own material.\n  For more comprehensive documentation about writing your own swirl courses see http://swirlstats.com/swirlify/.\n\n## Install and run a course automatically from swirl\n\n**This is the preferred method of installing courses.** It automates the process by allowing you to do everything right from the R console.\n\n1) Make sure you have a recent version version of swirl:\n\n```\ninstall.packages(\"swirl\")\n```\n\n2) Enter the following from the R console, **substituting the name of the course** that you wish to install:\n\n```\nlibrary(swirl)\ninstall_course(\"Course Name Here\")\nswirl()\n```\n\nFor example, `install_course(\"R Programming\")` will install the R Programming course. **Please note that course names are case sensitive!**\n\nIf that doesn't work for you...\n\n## Install and run a course manually\n\nIf the automatic course installation method outlined above does not work for you, then there's a simple alternative.\n\n1. Find the course you want to install on the [Swirl Course network website](https://swirlstats.com/scn/title.html).\n2. Follow the manual installation instructions on the course page.\n\nIf that does not work for you, consider taking a look at the \n[legacy manual install instructions](https://github.com/swirldev/swirl_courses/wiki/Legacy-Manual-Install-Instructions-for-Swirl-Courses).\n\n## Uninstall a course\n\nIf you'd like to remove a course at any time, you can use `uninstall_course(\"Course Name Here\")`.\n\n## Using swirl in the classroom\n\nInstructors around the world are using swirl in their classrooms. We think this is awesome. If you're an instructor, please feel free to do the same -- free of charge. While your students may be paying to take your course or attend your institution, we simply ask that you don't charge people *directly* for the use of our software or instructional content.\n\nIf you are not sure about a particular use case, don't hesitate to post a\nquestion to our [Google Group](https://groups.google.com/forum/#!forum/swirl-discuss).\n",
      "stars_today": 0
    },
    {
      "id": 6427813,
      "name": "dplyr",
      "full_name": "tidyverse/dplyr",
      "description": "dplyr: A grammar of data manipulation",
      "html_url": "https://github.com/tidyverse/dplyr",
      "stars": 4983,
      "forks": 2133,
      "language": "R",
      "topics": [
        "data-manipulation",
        "grammar",
        "r"
      ],
      "created_at": "2012-10-28T13:39:17Z",
      "updated_at": "2026-01-16T23:55:26Z",
      "pushed_at": "2026-01-16T19:18:28Z",
      "open_issues": 76,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# dplyr <a href=\"https://dplyr.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" /></a>\n\n<!-- badges: start -->\n\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/dplyr)](https://cran.r-project.org/package=dplyr)\n[![R-CMD-check](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/dplyr/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/dplyr)\n<!-- badges: end -->\n\n## Overview\n\ndplyr is a grammar of data manipulation, providing a consistent set of\nverbs that help you solve the most common data manipulation challenges:\n\n- `mutate()` adds new variables that are functions of existing variables\n- `select()` picks variables based on their names.\n- `filter()` picks cases based on their values.\n- `summarise()` reduces multiple values down to a single summary.\n- `arrange()` changes the ordering of the rows.\n\nThese all combine naturally with `group_by()` which allows you to\nperform any operation ‚Äúby group‚Äù. You can learn more about them in\n`vignette(\"dplyr\")`. As well as these single-table verbs, dplyr also\nprovides a variety of two-table verbs, which you can learn about in\n`vignette(\"two-table\")`.\n\nIf you are new to dplyr, the best place to start is the [data\ntransformation chapter](https://r4ds.hadley.nz/data-transform) in R for\nData Science.\n\n## Backends\n\nIn addition to data frames/tibbles, dplyr makes working with other\ncomputational backends accessible and efficient. Below is a list of\nalternative backends:\n\n- [arrow](https://arrow.apache.org/docs/r/) for larger-than-memory\n  datasets, including on remote cloud storage like AWS S3, using the\n  Apache Arrow C++ engine,\n  [Acero](https://arrow.apache.org/docs/cpp/acero/overview.html).\n\n- [dbplyr](https://dbplyr.tidyverse.org/) for data stored in a\n  relational database. Translates your dplyr code to SQL.\n\n- [dtplyr](https://dtplyr.tidyverse.org/) for large, in-memory datasets.\n  Translates your dplyr code to high performance\n  [data.table](https://rdatatable.gitlab.io/data.table/) code.\n\n- [duckplyr](https://duckplyr.tidyverse.org/) for large, in-memory\n  datasets. Translates your dplyr code to high performance\n  [duckdb](https://duckdb.org) queries with zero extra copies and an\n  automatic R fallback when translation isn‚Äôt possible.\n\n- [sparklyr](https://spark.posit.co/) for very large datasets stored in\n  [Apache Spark](https://spark.apache.org).\n\n## Installation\n\n``` r\n# The easiest way to get dplyr is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just dplyr:\ninstall.packages(\"dplyr\")\n```\n\n### Development version\n\nTo get a bug fix or to use a feature from the development version, you\ncan install the development version of dplyr from GitHub.\n\n``` r\n# install.packages(\"pak\")\npak::pak(\"tidyverse/dplyr\")\n```\n\n## Cheat Sheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-transformation-cheatsheet-thumbs.png\" width=\"630\" height=\"252\"/></a>\n\n## Usage\n\n``` r\nlibrary(dplyr)\n\nstarwars |>\n  filter(species == \"Droid\")\n#> # A tibble: 6 √ó 14\n#>   name   height  mass hair_color skin_color  eye_color birth_year sex   gender  \n#>   <chr>   <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr> <chr>   \n#> 1 C-3PO     167    75 <NA>       gold        yellow           112 none  masculi‚Ä¶\n#> 2 R2-D2      96    32 <NA>       white, blue red               33 none  masculi‚Ä¶\n#> 3 R5-D4      97    32 <NA>       white, red  red               NA none  masculi‚Ä¶\n#> 4 IG-88     200   140 none       metal       red               15 none  masculi‚Ä¶\n#> 5 R4-P17     96    NA none       silver, red red, blue         NA none  feminine\n#> # ‚Ñπ 1 more row\n#> # ‚Ñπ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  select(name, ends_with(\"color\"))\n#> # A tibble: 87 √ó 4\n#>   name           hair_color skin_color  eye_color\n#>   <chr>          <chr>      <chr>       <chr>    \n#> 1 Luke Skywalker blond      fair        blue     \n#> 2 C-3PO          <NA>       gold        yellow   \n#> 3 R2-D2          <NA>       white, blue red      \n#> 4 Darth Vader    none       white       yellow   \n#> 5 Leia Organa    brown      light       brown    \n#> # ‚Ñπ 82 more rows\n\nstarwars |>\n  mutate(name, bmi = mass / ((height / 100)^2)) |>\n  select(name:mass, bmi)\n#> # A tibble: 87 √ó 4\n#>   name           height  mass   bmi\n#>   <chr>           <int> <dbl> <dbl>\n#> 1 Luke Skywalker    172    77  26.0\n#> 2 C-3PO             167    75  26.9\n#> 3 R2-D2              96    32  34.7\n#> 4 Darth Vader       202   136  33.3\n#> 5 Leia Organa       150    49  21.8\n#> # ‚Ñπ 82 more rows\n\nstarwars |>\n  arrange(desc(mass))\n#> # A tibble: 87 √ó 14\n#>   name      height  mass hair_color skin_color eye_color birth_year sex   gender\n#>   <chr>      <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> \n#> 1 Jabba De‚Ä¶    175  1358 <NA>       green-tan‚Ä¶ orange         600   herm‚Ä¶ mascu‚Ä¶\n#> 2 Grievous     216   159 none       brown, wh‚Ä¶ green, y‚Ä¶       NA   male  mascu‚Ä¶\n#> 3 IG-88        200   140 none       metal      red             15   none  mascu‚Ä¶\n#> 4 Darth Va‚Ä¶    202   136 none       white      yellow          41.9 male  mascu‚Ä¶\n#> 5 Tarfful      234   136 brown      brown      blue            NA   male  mascu‚Ä¶\n#> # ‚Ñπ 82 more rows\n#> # ‚Ñπ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  group_by(species) |>\n  summarise(\n    n = n(),\n    mass = mean(mass, na.rm = TRUE)\n  ) |>\n  filter(\n    n > 1,\n    mass > 50\n  )\n#> # A tibble: 9 √ó 3\n#>   species      n  mass\n#>   <chr>    <int> <dbl>\n#> 1 Droid        6  69.8\n#> 2 Gungan       3  74  \n#> 3 Human       35  81.3\n#> 4 Kaminoan     2  88  \n#> 5 Mirialan     2  53.1\n#> # ‚Ñπ 4 more rows\n```\n\n## Getting help\n\nIf you encounter a clear bug, please file an issue with a minimal\nreproducible example on\n[GitHub](https://github.com/tidyverse/dplyr/issues). For questions and\nother discussion, please use [forum.posit.co](https://forum.posit.co/).\n\n## Code of conduct\n\nPlease note that this project is released with a [Contributor Code of\nConduct](https://dplyr.tidyverse.org/CODE_OF_CONDUCT). By participating\nin this project you agree to abide by its terms.\n",
      "stars_today": 0
    },
    {
      "id": 317887,
      "name": "liferay-portal",
      "full_name": "liferay/liferay-portal",
      "description": null,
      "html_url": "https://github.com/liferay/liferay-portal",
      "stars": 2219,
      "forks": 3733,
      "language": "Java",
      "topics": [],
      "created_at": "2009-09-25T22:55:58Z",
      "updated_at": "2026-01-16T18:31:07Z",
      "pushed_at": "2026-01-17T00:57:42Z",
      "open_issues": 80,
      "owner": {
        "login": "liferay",
        "avatar_url": "https://avatars.githubusercontent.com/u/131436?v=4"
      },
      "readme": "# The Liferay Development Team\n\nLiferay Portal is produced by the worldwide Liferay engineering team and represents many hours of development, testing, writing documentation, and working with the wider Liferay community of customers, partners, and open source developers. We are glad you have chosen Liferay Portal and hope that it meets or exceeds your expectations!\n\nIn addition to Liferay's engineering staff, a special thanks goes to the many open source developers who volunteer their time and energy to help with the release, with bug fixing, idea generation, documentation, translations, or other contributions that helped improve this release.\n\n## License\n\n`SPDX-License-Identifier: (LGPL-2.1-or-later OR LicenseRef-Liferay-DXP-EULA-2.0.0-2023-06)`\n\nSee `LICENSING.md` for details.",
      "stars_today": 0
    },
    {
      "id": 807776416,
      "name": "polaris",
      "full_name": "apache/polaris",
      "description": "Apache Polaris, the interoperable, open source catalog for Apache Iceberg",
      "html_url": "https://github.com/apache/polaris",
      "stars": 1805,
      "forks": 357,
      "language": "Java",
      "topics": [
        "apache",
        "iceberg",
        "polaris"
      ],
      "created_at": "2024-05-29T18:44:27Z",
      "updated_at": "2026-01-17T00:41:43Z",
      "pushed_at": "2026-01-16T22:17:55Z",
      "open_issues": 307,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\n  Licensed to the Apache Software Foundation (ASF) under one\n  or more contributor license agreements.  See the NOTICE file\n  distributed with this work for additional information\n  regarding copyright ownership.  The ASF licenses this file\n  to you under the Apache License, Version 2.0 (the\n  \"License\"); you may not use this file except in compliance\n  with the License.  You may obtain a copy of the License at\n \n   http://www.apache.org/licenses/LICENSE-2.0\n \n  Unless required by applicable law or agreed to in writing,\n  software distributed under the License is distributed on an\n  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n  KIND, either express or implied.  See the License for the\n  specific language governing permissions and limitations\n  under the License.\n-->\n\n# Apache Polaris (incubating)\n\nApache Polaris&trade; is an open-source, fully-featured catalog for Apache Iceberg&trade;. It implements Iceberg's \n[REST API](https://github.com/apache/iceberg/blob/main/open-api/rest-catalog-open-api.yaml),\nenabling seamless multi-engine interoperability across a wide range of platforms, including Apache Doris‚Ñ¢, Apache Flink¬Æ,\nApache Spark‚Ñ¢, Dremio¬Æ OSS, StarRocks, and Trino. \n\nDocumentation is available at https://polaris.apache.org. The REST OpenAPI specifications are available here:\n[Polaris management API doc](https://editor-next.swagger.io/?url=https://raw.githubusercontent.com/apache/polaris/refs/heads/main/spec/polaris-management-service.yml)\nand [Polaris Catalog API doc](https://editor-next.swagger.io/?url=https://raw.githubusercontent.com/apache/polaris/refs/heads/main/spec/generated/bundled-polaris-catalog-service.yaml).\n\n[Subscribe to the dev mailing list][dev-list-subscribe] to join discussions via email or browse [the archives](https://lists.apache.org/list.html?dev@polaris.apache.org). Check out the [CONTRIBUTING guide](CONTRIBUTING.md)\nfor contribution guidelines.\n\n[![Slack](https://img.shields.io/badge/chat-on%20Slack-brightgreen.svg?style=for-the-badge)](https://join.slack.com/t/apache-polaris/shared_invite/zt-2y3l3r0fr-VtoW42ltir~nSzCYOrQgfw)\n[![Build Status](https://img.shields.io/github/actions/workflow/status/apache/polaris/gradle.yml?branch=main&label=Main%20CI&logo=Github&style=for-the-badge)](https://github.com/apache/polaris/actions/workflows/gradle.yml?query=branch%3Amain)\n\n[dev-list-subscribe]: mailto:dev-subscribe@polaris.apache.org\n\n## Polaris Overview\nClick [here](https://polaris.apache.org/in-dev/unreleased/) for a quick overview of Polaris.\n\n## Quickstart\nClick [here](https://polaris.apache.org/in-dev/unreleased/getting-started/) for the quickstart experience, which will help you set up a Polaris instance locally or on any supported cloud provider.\n\n## Project Structure\n\nApache Polaris is organized into the following modules:\n- Primary modules:\n  - [`polaris-core`](./polaris-core/README.md) - The main Polaris entity definitions and core business logic\n  - [API modules](./api/README.md) - Build scripts for generating Java classes from the OpenAPI specifications:\n  - `polaris-api-management-model` - Polaris Management API model classes\n  - `polaris-api-management-service` - Polaris Management API service classes\n  - `polaris-api-iceberg-service` - The Iceberg REST service classes\n  - `polaris-api-catalog-service` - The Polaris Catalog API service classes\n  - Runtime modules:\n      - [`polaris-admin`](./runtime/admin/README.md) - The Polaris Admin Tool; mainly for bootstrapping persistence\n      - [`polaris-runtime-defaults`](./runtime/defaults/README.md) - The runtime configuration defaults\n      - [`polaris-distribution`](./runtime/distribution/README.md) - The Polaris distribution\n      - [`polaris-server`](./runtime/server/README.md) - The Polaris Quarkus Server\n      - [`polaris-runtime-service`](./runtime/service/README.md) - The package containing the Polaris service.\n      - `polaris-runtime-spark-tests` - Integration tests for the Polaris Spark plugin\n      - `polaris-runtime-test-common` - Test utilities\n  - Persistence modules:\n      - `polaris-relational-jdbc` - The JDBC implementation of BasePersistence to be used via AtomicMetaStoreManager\n  - Extensions modules:\n      - `polaris-extensions-federation-hadoop` - The Hadoop federation extension\n      - [`polaris-extensions-federation-hive`](./extensions/federation/hive/README.md) - The Hive federation extension\n- Secondary modules:\n    - `agregated-license-report` - Generates the aggregated license report\n    - `polaris-bom` - The Bill of Materials (BOM) for Polaris\n    - `polaris-build-logic` - Establishes consistent build logic\n    - [`polaris-tests`](./integration-tests/README.md) - Normative integration tests for reuse in downstream projects\n- Tool modules:\n    - Documentation configuration:\n        - `polaris-config-docs-annotations` - Annotations for documentation generator\n        - `polaris-config-docs-generator` - Generates Polaris reference docs\n        - `polaris-config-docs-site` - The configuration documentation site\n    - Other Tools:\n        - `polaris-container-spec-helper` - Helper for container specifications\n        - `polaris-immutables` - Predefined Immutables configuration & annotations for Polaris\n        - `polaris-minio-testcontainer` - Minio test container\n        - `polaris-misc-types` - Miscellaneous types for Polaris\n        - `polaris-version` - Versioning for Polaris\n\nIn addition to modules, there are:\n- [API specifications](./spec/README.md) - The OpenAPI specifications\n- [Python client](./client/python/README.md) - The Python client\n- [codestyle](./codestyle/README.md) - The code style guidelines\n- [getting-started](./getting-started/README.md) - A collection of getting started examples\n- [gradle](./gradle) - The Gradle wrapper and Gradle configuration files including banned dependencies\n- [helm](./helm) - The Helm charts for Polaris.\n- [Spark Plugin](./plugins/spark/README.md) - The Polaris Spark plugin\n- [regtests](./regtests/README.md) - Regression tests\n- [server-templates](./server-templates) - OpenAPI Generator templates to generate the server code\n- [site](./site/README.md) - The Polaris website\n\nOutside of this repository, there are several other tools that can be found in a separate [Polaris-Tools](https://github.com/apache/polaris-tools) repository.\n\n## Building and Running\n\nApache Polaris is built using Gradle with Java 21+ and Docker 27+.\n\n- `./gradlew build` - To build and run tests. Make sure Docker is running, as the integration tests depend on it.\n- `./gradlew assemble` - To skip tests.\n- `./gradlew check` - To run all checks, including unit tests and integration tests.\n- `./gradlew run` - To run the Polaris server locally; the server is reachable at localhost:8181. This is also suitable for running regression tests, or for connecting with Spark. Set your own credentials by specifying system property `./gradlew run -Dpolaris.bootstrap.credentials=POLARIS,root,secret` where:\n  - `POLARIS` is the realm\n  - `root` is the CLIENT_ID\n  - `secret` is the CLIENT_SECRET\n  - If credentials are not set, it will use preset credentials `POLARIS,root,s3cr3t`\n- `./regtests/run_spark_sql.sh` - To connect from Spark SQL. Here are some example commands to run in the Spark SQL shell:\n```sql\ncreate database db1;\nshow databases;\ncreate table db1.table1 (id int, name string);\ninsert into db1.table1 values (1, 'a');\nselect * from db1.table1;\n```\n- `env POLARIS_HOST=localhost ./regtests/run.sh` - To run regression tests locally, see more options [here](./regtests/README.md).\n\n## Makefile Convenience Commands\n\nTo streamline the developer experience, especially for common setup and build tasks, a root-level Makefile is available. This Makefile acts as a convenient wrapper around various Gradle commands and other tooling, simplifying interactions. While Gradle remains the primary build system, the Makefile provides concise shortcuts for frequent operations like:\n  - Building Polaris components: e.g., `make build-server, make build-admin`\n  - Managing development clusters: e.g., `make minikube-start-cluster, make minikube-cleanup`\n  - Automating Helm tasks: e.g., `make helm-doc-generate, make helm-unittest`\n  - Handling dependencies: e.g., `make install-dependencies-brew`\n  - Managing client operations: e.g., `make client-lint, make client-regenerate`\n\nTo see available commands:\n```bash\nmake help\n```\n\nFor example, to build the Polaris server and its container image, you can simply run:\n```bash\nmake build-server\n```\n\n### More build and run options\n\n#### Running in Docker\n\n- To build the image locally:\n  ```bash\n  ./gradlew \\\n    :polaris-server:assemble \\\n    :polaris-server:quarkusAppPartsBuild --rerun \\\n    -Dquarkus.container-image.build=true\n  ```\n- `docker run -p 8181:8181 -p 8182:8182 apache/polaris:latest` - To run the image.\n\nThe Polaris codebase contains some docker compose examples to quickly get started with Polaris,\nusing different configurations. Check the `./getting-started` directory for more information.\n\n#### Running in Kubernetes\n\n- See [README in `helm/polaris`](helm/polaris/README.md) for more information.\n\n#### Configuring Polaris\n\nPolaris Servers can be configured using a variety of ways.\nPlease see the [Configuration Guide](site/content/in-dev/unreleased/configuration.md)\nfor more information.\n\nDefault configuration values can be found in `runtime/defaults/src/main/resources/application.properties`.\n\n#### Building docs\n\n- Docs are generated using [Hugo](https://gohugo.io/) using the [Docsy](https://www.docsy.dev/docs/) theme.\n- To view the site locally, run\n  ```bash\n  site/bin/run-hugo-in-docker.sh\n  ```\n- See [README in `site/`](site/README.md) for more information.\n\n#### Publishing Build Scans to develocity.apache.org\n\nBuild scans of CI builds from a branch or tag in the `apache/polaris` repository on GitHub publish build scans\nto the ASF Develocity instance at\n[develocity.apache.org](https://develocity.apache.org/scans?search.rootProjectNames=polaris), if the workflow runs have access to the Apache organization-level secret \n`DEVELOCITY_ACCESS_KEY`.\n\nBuild scans of local developer builds publish build scans only if the Gradle command line option `--scan` is used.\nThose build scans are published to Gradle's public Develocity instance (see advanced configuration options below).\nNote that build scans on Gradle's public Develocity instance are publicly accessible to anyone.\nYou have to accept Gradle's terms of service to publish to the Gradle's public Develocity instance.\n\nCI builds originating from pull requests against the `apache/polaris` GitHub repository are published to Gradle's\n_public_ Develocity instance. \n\nOther CI build scans do only publish build scans to the Gradle's _public_ Develocity instance, if the environment\nvariable `GRADLE_TOS_ACCEPTED` is set to `true`.\nBy setting this variable you agree to the [Gradle's terms of service](https://gradle.com/terms-of-service), because\naccepting these ToS is your personal decision. \nYou can configure this environment variable for your GitHub repository in the GitHub repository settings under\n`Secrets` > `Secrets and variables` > `Actions` > choose the `Variables` tab > `New repository variable`. \n\nAdvanced configuration options for publishing build scans (only local and non-`apache/polaris` repository CI):\n* The project ID published with the build scan can be specified using the environment variable `DEVELOCITY_PROJECT_ID`.\n  The project ID defaults to the GitHub repository owner/name, for example `octocat/polaris`.\n* The Develocity server can be specified using the environment variable `DEVELOCITY_SERVER` if build scans should be\n  published to another than Gradle's public Develocity instance.\n* If you have to publish build scans to your own Develocity instance, you can configure the access key using a\n  GitHub secret named `DEVELOCITY_ACCESS_KEY`.\n\n## License\n\nApache Polaris is under the Apache License Version 2.0. See the [LICENSE](LICENSE).\n\n## ASF Incubator disclaimer\n\nApache Polaris&trade; is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.\n \n<sub>Apache&reg;, Apache Polaris&trade;, Apache Iceberg&trade;, Apache Spark&trade; are either registered trademarks or trademarks of the Apache Software Foundation in the United States and/or other countries.</sub>\n",
      "stars_today": 0
    },
    {
      "id": 30017750,
      "name": "ComplexHeatmap",
      "full_name": "jokergoo/ComplexHeatmap",
      "description": "Make Complex Heatmaps ",
      "html_url": "https://github.com/jokergoo/ComplexHeatmap",
      "stars": 1458,
      "forks": 243,
      "language": "R",
      "topics": [
        "clustering",
        "complex-heatmaps",
        "heatmap"
      ],
      "created_at": "2015-01-29T11:45:58Z",
      "updated_at": "2026-01-14T17:52:30Z",
      "pushed_at": "2025-06-23T15:51:50Z",
      "open_issues": 227,
      "owner": {
        "login": "jokergoo",
        "avatar_url": "https://avatars.githubusercontent.com/u/449218?v=4"
      },
      "readme": "# Make Complex Heatmaps <a href=\"https://jokergoo.github.io/ComplexHeatmap-reference/book/\"><img src=\"https://jokergoo.github.io/ComplexHeatmap-reference/book/complexheatmap-cover.jpg\" width=240 align=\"right\" style=\"border:2px solid black;\" ></a>\n\n[![R-CMD-check](https://github.com/jokergoo/ComplexHeatmap/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/ComplexHeatmap/actions)\n[![codecov](https://img.shields.io/codecov/c/github/jokergoo/ComplexHeatmap.svg)](https://codecov.io/github/jokergoo/ComplexHeatmap) \n[![bioc](http://www.bioconductor.org/shields/downloads/devel/ComplexHeatmap.svg)](https://bioconductor.org/packages/stats/bioc/ComplexHeatmap/) \n[![bioc](http://www.bioconductor.org/shields/years-in-bioc/ComplexHeatmap.svg)](http://bioconductor.org/packages/devel/bioc/html/ComplexHeatmap.html)\n\n<img src=\"http://jokergoo.github.io/complexheatmap_logo.svg\" width=\"550\">\n\n\nComplex heatmaps are efficient to visualize associations between different\nsources of data sets and reveal potential patterns. Here the\n**ComplexHeatmap** package provides a highly flexible way to arrange multiple\nheatmaps and supports various annotation graphics.\n\nThe [**InteractiveComplexHeatmap**](https://github.com/jokergoo/InteractiveComplexHeatmap) package can directly export static complex heatmaps into an interactive Shiny app. Have a try!\n\n## Citation\n\nZuguang Gu, et al., [Complex heatmaps reveal patterns and correlations in multidimensional genomic data](http://bioinformatics.oxfordjournals.org/content/early/2016/05/20/bioinformatics.btw313.abstract), Bioinformatics, 2016.\n\nZuguang Gu. [Complex Heatmap Visualization](https://doi.org/10.1002/imt2.43), iMeta, 2022. \n\n\n## Install\n\n`ComplexHeatmap` is available on [Bioconductor](http://www.bioconductor.org/packages/devel/bioc/html/ComplexHeatmap.html), you can install it by:\n\n```r\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"ComplexHeatmap\")\n```\n\nIf you want the latest version, install it directly from GitHub:\n\n```r\nlibrary(devtools)\ninstall_github(\"jokergoo/ComplexHeatmap\")\n```\n\n## Usage\n\nMake a single heatmap:\n\n```r\nHeatmap(mat, ...)\n```\n\nA single Heatmap with column annotations:\n\n```r\nha = HeatmapAnnotation(df = anno1, anno_fun = anno2, ...)\nHeatmap(mat, ..., top_annotation = ha)\n```\n\nMake a list of heatmaps:\n\n```r\nHeatmap(mat1, ...) + Heatmap(mat2, ...)\n```\n\nMake a list of heatmaps and row annotations:\n\n```r\nha = HeatmapAnnotation(df = anno1, anno_fun = anno2, ..., which = \"row\")\nHeatmap(mat1, ...) + Heatmap(mat2, ...) + ha\n```\n\n## Documentation\n\nThe full documentations are available at https://jokergoo.github.io/ComplexHeatmap-reference/book/ and the website is at https://jokergoo.github.io/ComplexHeatmap.\n\n## Blog posts\n\nThere are following blog posts focusing on specific topics:\n\n- [Make 3D heatmap](https://jokergoo.github.io/2021/03/24/3d-heatmap/)\n- [Translate from pheatmap to ComplexHeatmap](https://jokergoo.github.io/2020/05/06/translate-from-pheatmap-to-complexheatmap/)\n- [Set cell width/height in the heatmap](https://jokergoo.github.io/2020/05/11/set-cell-width/height-in-the-heatmap/)\n- [Interactive ComplexHeatmap](https://jokergoo.github.io/2020/05/15/interactive-complexheatmap/)\n- [Word cloud as heatmap annotation](https://jokergoo.github.io/2020/05/31/word-cloud-as-heatmap-annotation/)\n- [Which heatmap function is faster?](https://jokergoo.github.io/2020/06/19/which-heatmap-function-is-faster/)\n- [Rasterization in ComplexHeatmap](https://jokergoo.github.io/2020/06/30/rasterization-in-complexheatmap/)\n- [Block annotation over several slices](https://jokergoo.github.io/2020/07/06/block-annotation-over-several-slices/)\n- [Integrate ComplexHeatmap with cowplot package](https://jokergoo.github.io/2020/07/14/integrate-complexheatmap-with-cowplot-package/)\n\n\n## Examples\n\n### Visualize Methylation Profile with Complex Annotations\n\n![complexheatmap_example4](https://user-images.githubusercontent.com/449218/47718635-2ec22980-dc49-11e8-9f01-37becb19e0d5.png)\n\n### Correlations between methylation, expression and other genomic features\n\n![complexheatmap_example3](https://user-images.githubusercontent.com/449218/47718636-2ec22980-dc49-11e8-8db0-1659c27dcf40.png)\n\n### Visualize Cell Heterogeneity from Single Cell RNASeq\n\n![complexheatmap_example2](https://user-images.githubusercontent.com/449218/47718637-2ec22980-dc49-11e8-925e-955c16cfa982.png)\n\n### Making Enhanced OncoPrint\n\n![complexheatmap_example1](https://user-images.githubusercontent.com/449218/47718638-2ec22980-dc49-11e8-845e-21e51d3b8e73.png)\n\n### UpSet plot\n\n<img src=\"https://user-images.githubusercontent.com/449218/102615477-48c76a80-4136-11eb-98d9-3c528844fbe8.png\" width=500 />\n\n### 3D heatmap\n\n![image](https://user-images.githubusercontent.com/449218/112284448-8c77c600-8c89-11eb-8d38-c5538900df20.png)\n\n\n\n## License\n\nMIT @ Zuguang Gu\n\n",
      "stars_today": 0
    },
    {
      "id": 159560389,
      "name": "renv",
      "full_name": "rstudio/renv",
      "description": "renv: Project environments for R.",
      "html_url": "https://github.com/rstudio/renv",
      "stars": 1123,
      "forks": 162,
      "language": "R",
      "topics": [],
      "created_at": "2018-11-28T20:25:39Z",
      "updated_at": "2026-01-16T23:40:58Z",
      "pushed_at": "2026-01-16T23:43:42Z",
      "open_issues": 212,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# renv <img src=\"man/figures/logo.svg\" align=\"right\" height=\"115\"/>\n\n<!-- badges: start -->\n\n[![Lifecycle:\nstable](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/renv)](https://CRAN.R-project.org/package=renv)\n[![R-CMD-check](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml)\n\n<!-- badges: end -->\n\n## Overview\n\nThe renv package[^1] helps you create **r**eproducible **env**ironments\nfor your R projects. Use renv to make your R projects more isolated,\nportable and reproducible.\n\n- **Isolated**: Installing a new or updated package for one project\n  won‚Äôt break your other projects, and vice versa. That‚Äôs because renv\n  gives each project its own private library.\n- **Portable**: Easily transport your projects from one computer to\n  another, even across different platforms. renv makes it easy to\n  install the packages your project depends on.\n- **Reproducible**: renv records the exact package versions you depend\n  on, and ensures those exact versions are the ones that get installed\n  wherever you go.\n\n## Installation\n\nInstall the latest version of renv from CRAN with:\n\n``` r\ninstall.packages(\"renv\")\n```\n\nAlternatively, install the development version from\n[r-universe](https://rstudio.r-universe.dev/renv) with:\n\n``` r\ninstall.packages(\"renv\", repos = \"https://rstudio.r-universe.dev\")\n```\n\n## Workflow\n\n<img src=\"vignettes/renv.png\" alt=\"A diagram showing the most important verbs and nouns of renv. Projects start with init(), which creates a project library using packages from the system library. snapshot() updates the lockfile using the packages installed in the project library, where restore() installs packages into the project library using the metadata from the lockfile, and status() compares the lockfile to the project library. You install and update packages from CRAN and GitHub using install() and update(), but because you'll need to do this for multiple projects, renv uses cache to make this fast.\" width=\"408\" style=\"display: block; margin: auto;\" />\n\nUse `renv::init()` to initialize renv in a new or existing project. This\nwill set up a **project library**, containing all the packages you‚Äôre\ncurrently using. The packages (and all the metadata needed to reinstall\nthem) are recorded into a **lockfile**, `renv.lock`, and a `.Rprofile`\nensures that the library is used every time you open that project.\n\nAs you continue to work on your project, you will install and upgrade\npackages, either using `install.packages()` and `update.packages()` or\n`renv::install()` and `renv::update()`. After you‚Äôve confirmed your code\nworks as expected, use `renv::snapshot()` to record the packages and\ntheir sources in the lockfile.\n\nLater, if you need to share your code with someone else or run your code\non new machine, your collaborator (or you) can call `renv::restore()` to\nreinstall the specific package versions recorded in the lockfile.\n\n## Learning more\n\nIf this is your first time using renv, we strongly recommend starting\nwith the [Introduction to\nrenv](https://rstudio.github.io/renv/articles/renv.html) vignette: this\nwill help you understand the most important verbs and nouns of renv.\n\nIf you have a question about renv, please first check the\n[FAQ](https://rstudio.github.io/renv/articles/faq.html) to see whether\nyour question has already been addressed. If it hasn‚Äôt, please feel free\nto ask on the [Posit Forum](https://forum.posit.co).\n\nIf you believe you‚Äôve found a bug in renv, please file a bug (and, if\npossible, a [reproducible example](https://reprex.tidyverse.org)) at\n<https://github.com/rstudio/renv/issues>.\n\n[^1]: Pronounced ‚ÄúR‚Äù ‚Äúenv‚Äù\n",
      "stars_today": 0
    },
    {
      "id": 259225467,
      "name": "CellChat",
      "full_name": "sqjin/CellChat",
      "description": "R toolkit for inference, visualization and analysis of cell-cell communication from single-cell data",
      "html_url": "https://github.com/sqjin/CellChat",
      "stars": 756,
      "forks": 167,
      "language": "R",
      "topics": [
        "cell-cell-communication",
        "cell-cell-interaction",
        "microenvironment",
        "single-cell-analysis"
      ],
      "created_at": "2020-04-27T06:28:33Z",
      "updated_at": "2026-01-11T17:20:28Z",
      "pushed_at": "2024-01-06T18:23:14Z",
      "open_issues": 455,
      "owner": {
        "login": "sqjin",
        "avatar_url": "https://avatars.githubusercontent.com/u/32399212?v=4"
      },
      "readme": "\n<p align=\"center\">\n  <img width=\"200\"  src=\"https://github.com/sqjin/CellChat/blob/master/CellChat_Logo.png\">\n</p>\n\n# CAUTION\nWe have updated CellChat to v2 and migrated CellChat to a new repository. This repository will be NOT updated and maintained any more. Please check the new repository [jinworks/CellChat](https://github.com/jinworks/CellChat) for the new updates, and the [CellChat v2 paper](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) for a comprehensive protocol of CellChat.  \n\n# About CellChat and CellChatDB\nCellChat is an R package designed for inference, analysis, and visualization of cell-cell communication from single-cell data. CellChat aims to enable users to identify and interpret cell-cell communication within an easily interpretable framework, with the emphasis of clear, attractive, and interpretable visualizations.  \n\nCellChatDB is a manually curated database of literature-supported ligand-receptor interactions in mutiple species, leading to a comprehensive recapitulation of known molecular interaction mechanisms including multi-subunit structure of ligand-receptor complexes and co-factors.\n\nIf you use CellChat in your research, please considering citing our papers: \n- [Suoqin Jin et al., CellChat for systematic analysis of cell-cell communication from single-cell and spatially resolved transcriptomics, bioRxiv 2023](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) [CellChat v2]\n- [Suoqin Jin et al., Inference and analysis of cell-cell communication using CellChat, Nature Communications 2021](https://www.nature.com/articles/s41467-021-21246-9) [CellChat v1]\n\n# Capabilities\nIn addition to infer the intercellular communication from any given single-cell data, CellChat provides functionality for further data exploration, analysis, and visualization. \n\n- It can quantitatively characterize and compare the inferred cell-cell communication networks using a systems approach by combining social network analysis, pattern recognition, and manifold learning approaches.\n- It provides an easy-to-use tool for extracting and visualizing high-order information of the inferred networks. For example, it allows ready prediction of major signaling inputs and outputs for all cell populations and how these populations and signals coordinate together for functions.\n- It enables comparative analysis of cell-cell communication across different conditions and identification of altered signaling and cell populations. \n- It provides several visualization outputs to facilitate intuitive user-guided data interpretation.\n\n<p align=\"center\">\n  <img width=\"700\"  src=\"https://github.com/sqjin/CellChat/blob/master/overview_CellChat.png\">\n</p>\n\n\n<p align=\"center\">\n  <a href=\"https://clustrmaps.com/site/1bpq2\">\n     <img width=\"200\"  src=\"https://clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=n&d=42WqeykSXznN_NSaBlpf6CtSXQxhqmIs6QusUsguFdY\" />\n   </a>\n</p>\n<p align=\"center\">\n  <a href=\"#\">\n     <img src=\"https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fsqjin%2FCellChat&labelColor=%233499cc&countColor=%2370c168\" />\n   </a>\n</p>\n\n\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 2188402,
      "name": "phyloseq",
      "full_name": "joey711/phyloseq",
      "description": "phyloseq is a set of classes, wrappers, and tools (in R) to make it easier to import, store, and analyze phylogenetic sequencing data; and to reproducibly share that data and analysis with others. See the phyloseq front page:",
      "html_url": "https://github.com/joey711/phyloseq",
      "stars": 635,
      "forks": 193,
      "language": "R",
      "topics": [],
      "created_at": "2011-08-11T00:16:34Z",
      "updated_at": "2026-01-12T16:12:10Z",
      "pushed_at": "2024-04-29T20:03:19Z",
      "open_issues": 765,
      "owner": {
        "login": "joey711",
        "avatar_url": "https://avatars.githubusercontent.com/u/841437?v=4"
      },
      "readme": "<link href=\"http://joey711.github.com/phyloseq/markdown.css\" rel=\"stylesheet\"></link>\n\n# [phyloseq](http://joey711.github.com/phyloseq/)\n\n[![Travis-CI Build Status](https://travis-ci.org/joey711/phyloseq.svg?branch=master)](https://travis-ci.org/joey711/phyloseq)\n\n![phyloseq](inst/extdata/phyloseq.png)\n\n## Quick Install\n\nIn R terminal:\n\n```\nif(!requireNamespace(\"BiocManager\")){\n  install.packages(\"BiocManager\")\n}\nBiocManager::install(\"phyloseq\")\n```\n\nSee [the phyloseq installation page](http://joey711.github.io/phyloseq/install.html)\nfor further details, examples.\n\n## Article on Improved Microbiome Analysis\n\nMcMurdie and Holmes (2014)\n[Waste Not, Want Not: Why Rarefying Microbiome Data is Statistically Inadmissible](http://dx.plos.org/10.1371/journal.pcbi.1003531)\n*PLoS Computational Biology*\n10(4): e1003531\n\nPresubmission versions ahead of acceptance (2013):\n[PDF version 2](http://arxiv.org/pdf/1310.0424v2.pdf),\n[PDF version 1](http://arxiv.org/pdf/1310.0424v1.pdf)\n\n\n## Peer-reviewed articles about phyloseq\n\nMcMurdie and Holmes (2014) [Shiny-phyloseq: Web Application for Interactive Microbiome Analysis with Provenance Tracking](http://bioinformatics.oxfordjournals.org/content/early/2014/10/02/bioinformatics.btu616).\n*Bioinformatics (Oxford, England)*\n31(2), 282‚Äì283.\n\nMcMurdie and Holmes (2013)\n[phyloseq: An R package for reproducible interactive analysis and graphics of microbiome census data](http://dx.plos.org/10.1371/journal.pone.0061217)\n*PLoS ONE* \n8(4):e61217\n\n## Other resources\n\nThe phyloseq project also has a number of supporting online resources,\nincluding (but probably not limited to)\n\n### [the phyloseq home page](http://joey711.github.com/phyloseq/)\n\n### [the phyloseq FAQ](https://www.bioconductor.org/packages/release/bioc/vignettes/phyloseq/inst/doc/phyloseq-FAQ.html)\nI recommend checking this page, and the issues tracker,\nbefore posting new issues.\n\n### [Bioconductor stable release](http://bioconductor.org/packages/release/bioc/html/phyloseq.html).\n\n### [the phyloseq Issue Tracker](https://github.com/joey711/phyloseq/issues)\nThis is the recommended location to post\n\n(1) feature requests\n(2) bug reports\n(3) theoretical considerations\n(4) other issues, feedback\n(5) ask for help\n\nSearch previous posts,\nand check [the phyloseq FAQ](https://www.bioconductor.org/packages/release/bioc/vignettes/phyloseq/inst/doc/phyloseq-FAQ.html)\nbefore posting a new issue.\n",
      "stars_today": 0
    },
    {
      "id": 53894616,
      "name": "infercnv",
      "full_name": "broadinstitute/infercnv",
      "description": "Inferring CNV from Single-Cell RNA-Seq",
      "html_url": "https://github.com/broadinstitute/infercnv",
      "stars": 648,
      "forks": 177,
      "language": "R",
      "topics": [],
      "created_at": "2016-03-14T21:53:54Z",
      "updated_at": "2026-01-12T23:27:31Z",
      "pushed_at": "2025-11-14T17:35:17Z",
      "open_issues": 236,
      "owner": {
        "login": "broadinstitute",
        "avatar_url": "https://avatars.githubusercontent.com/u/393552?v=4"
      },
      "readme": "\n***********************************************\n>InferCNV is no longer supported. Please explore alternatives such as InferCNA (https://jlaffy.github.io/infercna/)[https://jlaffy.github.io/infercna/], CopyKAT (https://github.com/navinlabcode/copykat)[https://github.com/navinlabcode/copykat], and Numbat (https://github.com/kharchenkolab/numbat)[https://github.com/kharchenkolab/numbat]\n***********************************************\n\n# Subclustering\n\nSubclustering resolution is one of the primary settings that will need to be adjusted in most runs to avoid oversplitting. The tutorial below explains how it works and details about it can also be found on the [wiki](https://github.com/broadinstitute/infercnv/wiki/infercnv-tumor-subclusters#tumor-subclustering-by-leiden-clustering-preferred).\n\n# Documentation\n### Full documentation\n\nVisit project [wiki](https://github.com/broadinstitute/inferCNV/wiki) for InferCNV documentation.\n\n\n### Infercnv video tutorial\n\nA **video** tutorial giving on overview of infercnv features and how to run an analysis can be found below **(click on the image)**:\n\n[![Tutorial: Running infercnv](http://img.youtube.com/vi/-qOcHAavZT8/0.jpg)](http://www.youtube.com/watch?v=-qOcHAavZT8 \"Tutorial: Running infercnv\")\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 28114218,
      "name": "dada2",
      "full_name": "benjjneb/dada2",
      "description": "Accurate sample inference from amplicon data with single nucleotide resolution",
      "html_url": "https://github.com/benjjneb/dada2",
      "stars": 532,
      "forks": 162,
      "language": "R",
      "topics": [
        "amplicon",
        "bioconductor",
        "bioinformatics",
        "metabarcoding",
        "metagenomics",
        "microbiome",
        "taxonomy"
      ],
      "created_at": "2014-12-17T00:53:58Z",
      "updated_at": "2026-01-07T21:19:32Z",
      "pushed_at": "2025-12-15T19:22:15Z",
      "open_issues": 193,
      "owner": {
        "login": "benjjneb",
        "avatar_url": "https://avatars.githubusercontent.com/u/5797204?v=4"
      },
      "readme": "\n[![Build Status](https://app.travis-ci.com/benjjneb/dada2.svg?branch=master)](https://app.travis-ci.com/benjjneb/dada2)\n\n# dada2\n\nExact sample inference from high-throughput amplicon data. Resolves real variants differing by as little as one nucleotide. Visit [the DADA2 website](https://benjjneb.github.io/dada2/index.html) for the most detailed and up-to-date documentation.\n\n### Installation\n\nThe dada2 package binaries are available through Bioconductor:\n\n```S\n## try http:// if https:// URLs are not supported\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"dada2\")\n```\n\nIn order to install dada2 from source (and get the latest and greatest new features) see our [installation from source instructions](https://benjjneb.github.io/dada2/dada-installation.html).\n\n### Documentation\n\nThe [tutorial walkthrough of the DADA2 pipeline on paired end Illumina Miseq data](https://benjjneb.github.io/dada2/tutorial.html). \n\nThe [dada2 R package manual](https://www.bioconductor.org/packages/3.6/bioc/manuals/dada2/man/dada2.pdf).\n\nFurther documentation is available on [the DADA2 front page](http://benjjneb.github.io/dada2/). \n\n### DADA2 Articles\n\n[DADA2: High resolution sample inference from Illumina amplicon data. Nature Methods, 2016.](http://dx.doi.org/10.1038/nmeth.3869) [(Open Access link.)](http://rdcu.be/ipGh)\n\n[Bioconductor workflow for microbiome data analysis: from raw reads to community analyses. F1000 Research, 2016.](https://f1000research.com/articles/5-1492)\n\n[Exact sequence variants should replace operational taxonomic units in marker-gene data analysis. ISMEJ, 2017.](http://dx.doi.org/10.1038/ismej.2017.119)\n\n[High-throughput amplicon sequencing of the full-length 16S rRNA gene with single-nucleotide resolution. Nucleic Acids Research, 2019.](http://dx.doi.org/10.1093/nar/gkz569)\n\n### Other Resources\n\nPlanned feature improvements are publicly catalogued at the main DADA2 development site on github, specifically on the \"Issues\" page for DADA2:\n\nhttps://github.com/benjjneb/dada2/issues\n\nIf the feature you are hoping for is not listed, you are welcome to add it as a feature request \"issue\" on this page. This request will be publicly available and listed on the page.\n\nBugs and difficulties in using DADA2 are also welcome on [the issue tracker](https://github.com/benjjneb/dada2/issues).\n",
      "stars_today": 0
    },
    {
      "id": 138660553,
      "name": "DoubletFinder",
      "full_name": "chris-mcginnis-ucsf/DoubletFinder",
      "description": "R package for detecting doublets in single-cell RNA sequencing data",
      "html_url": "https://github.com/chris-mcginnis-ucsf/DoubletFinder",
      "stars": 517,
      "forks": 123,
      "language": "R",
      "topics": [],
      "created_at": "2018-06-25T23:32:45Z",
      "updated_at": "2026-01-10T20:29:11Z",
      "pushed_at": "2025-03-21T11:20:52Z",
      "open_issues": 23,
      "owner": {
        "login": "chris-mcginnis-ucsf",
        "avatar_url": "https://avatars.githubusercontent.com/u/40582930?v=4"
      },
      "readme": "~~ Announcement (11/24/21) ~~\nI'm now a postdoc at Stanford and my UCSF email will be decommissioned soon. I also only check my github repos about once per month, so please reach out directly at cmcginni@stanford[dot]edu if you run into any issues. \n\n# DoubletFinder\n\nDoubletFinder is an R package that predicts doublets in single-cell RNA sequencing data. \n\nDoubletFinder is implemented to interface with Seurat >= 2.0 (https://satijalab.org/seurat/) \n\nDoubletFinder was published by Cell Systems in April, 2019: https://www.cell.com/cell-systems/fulltext/S2405-4712(19)30073-0\n\n## Updates\n\n(02/02/2025) Haibo Liu (Senior Bioinformatician at UMass, @haibol2016) added as maintainer after his much-needed improvement updates to the package.\n\n(11/21/2023) Made compatible with Seurat v5 and removed '_v3' flag from relevant function names.\n\n(03/31/2020) Internalized functions normally in 'modes' package to enable compatibility with R v3.6 and highger.\n\n(06/21/2019) Added parallelization to paramSweep_v3 (thanks NathanSkeen!) -- Note: progress no longer updated, but the process is much faster! Fixed bug with smaller datasets. Updated readme.\n\n(04/12/2019) Added SCTransform compatibilities to 'paramSweep_v3' and 'doubletFinder_v3'\n\n(04/08/2019) Added 'PCs' argument to 'doubletFinder', 'doubletFinder_v3', 'paramSweep', and 'paramSweep_v3' to avoid conflicts with dimension reduction preferences. Updated readme.\n\n(01/12/2019) Seurat V3 compatibility: 'doubletFinder_v3' and 'paramSweep_v3' functions added, other functions for parameter estimation remain compatible.  \n\n## DoubletFinder V2.0 (11/28/2018) \n\nNew Features:\n1. Increased computational efficiency during pANN computation\n2. Implemented strategy for determining optimal pK values for any scRNA-seq data using pN-pK parameter sweeps and mean-variance-normalized bimodality coefficient (BCmvn)\n3. Included vignette describing 'best-practices' for applying DoubletFinder to scRNA-seq data generated without sample multiplexing\n\n## Installation (in R/RStudio)\n\n```{r}\nremotes::install_github('chris-mcginnis-ucsf/DoubletFinder', force = TRUE)\n```\n\n## Dependencies\n\nDoubletFinder requires the following R packages: \n* Seurat (>= 2.0) \n* Matrix (1.2.14) \n* fields (9.6) \n* KernSmooth (2.23-15)\n* ROCR (1.0-7)\n* parallel (3.5.1)\n* NOTE: These package versions were used in the bioRxiv paper, but other versions may work, as well.\n\n## Frequently Asked Questions\n\nQuestion: What is my anticipated doublet rate? \nAnswer: This is dependent on your platform (10x, parse, etc.) and will vary with the number of input cells. It will not always be 7.5% as is used in the tutorial. This information is available in the user guides for each technology. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/76 and https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/156\n\nQuestion: Can I run DoubletFinder on merged data from multiple 10x lanes?\nAnswer: Technically yes but I would only do this if you were splitting the same sample across multiple lanes. You want to avoid instances where DoubletFinder is attempting to find doublets that do not actually exist in the data. I would also not advise running DF on integrated Seurat objects. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/101 \n\nQuestion: I see multiple potential pK values when visualizing BCmvn -- what should I do?\nAnswer: I would spot check the results in GEX space to see what makes the most sense given your understanding of the data. See https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/62 and https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/40\n\n# DoubletFinder Overview\n\nDoubletFinder can be broken up into 4 steps:\n\n(1) Generate artificial doublets from existing scRNA-seq data \n\n(2) Pre-process merged real-artificial data\n\n(3) Perform PCA and use the PC distance matrix to find each cell's proportion of artificial k nearest neighbors (pANN)\n\n(4) Rank order and threshold pANN values according to the expected number of doublets\n\n![alternativetext](DF.screenshots/DoubletFinderOverview.png)\n\nDoubletFinder takes the following arguments:\n\nseu ~ This is a fully-processed Seurat object (i.e., after NormalizeData, FindVariableGenes, ScaleData, RunPCA, and RunTSNE have all been run).\n\nPCs ~ The number of statistically-significant principal components, specified as a range (e.g., PCs = 1:10)\n\npN ~ This defines the number of generated artificial doublets, expressed as a proportion of the merged real-artificial data. Default is set to 25%, based on observation that DoubletFinder performance is largely pN-invariant (see McGinnis, Murrow and Gartner 2019, Cell Systems).\n\npK ~ This defines the PC neighborhood size used to compute pANN, expressed as a proportion of the merged real-artificial data. No default is set, as pK should be adjusted for each scRNA-seq dataset. Optimal pK values should be estimated using the strategy described below.\n\nnExp ~ This defines the pANN threshold used to make final doublet/singlet predictions. This value can best be estimated from cell loading densities into the 10X/Drop-Seq device, and adjusted according to the estimated proportion of homotypic doublets.\n\n## Application to Cell Hashing and Demuxlet data\n\nDoubletFinder successfully recapitulates ground-truth doublet classifications determined using antibody-barcode sample multiplexing (Cell Hashing) and SNP deconvolution (Demuxlet). DoubletFinder identifies false-negative Demuxlet classifications caused by doublets formed from cells with identical SNP profiles. DoubletFinder is insensitive to homotypic doublets -- i.e., doublets dervied from transcriptionally-similar cell states. \n\n![alternativetext](DF.screenshots/Results_Demux.png)\n![alternativetext](DF.screenshots/Results_Hashing.png)\n\n# 'Best-Practices' for scRNA-seq data generated without sample multiplexing\n\n## Input scRNA-seq Data\n\n* Do not apply DoubletFinder to aggregated scRNA-seq data representing multiple *distinct* samples (e.g., multiple 10X lanes). For example, if you run DoubletFinder on aggregated data representing WT and mutant cell lines sequenced across different 10X lanes, artificial doublets will be generated from WT and mutant cells, which cannot exist in your data. These artificial doublets will skew results. Notably, it is okay to run DoubletFinder on data generated by splitting a single sample across multiple 10X lanes. \n\n* Ensure that input data is cleared of low-quality cell clusters. There are a variety of ways to do this, but I usually use the following workflow:\n1. Manually threshold raw gene expression matrices according to RNA nUMIs (especially important when dealing with super-loaded 10X data because of the way CellRanger threholds data -- See Lun et al., 2019, Genome Biology.\n2. Pre-process data using standard workflow.\n3. Identify clusters with (A) low RNA UMIs, (B) High % mitochondrial reads, and/or (C) Uninformative marker genes.\n4. Remove clusters, pre-process again, and run DoubletFinder.\n\n## pK Selection\n\nROC analysis across pN-pK parameter sweeps for Cell Hashing and Demuxlet datasets demonstrate that DoubletFinder performance is largely invariant of pN value selection:\n\n![alternativetext](DF.screenshots/ParamSweep_Schematic.png)\n![alternativetext](DF.screenshots/ParamSweep_HeatMap.png)\n\nROC analysis across pN-pK parameter sweeps for simulated scRNA-seq data with (I) Variable numbers of cell states and (II) Variable magnitudes of transcriptional heterogeneity demonstrates that (I) Optimal pK value selection depends on the total number of cell states and (II) DoubletFinder performance suffers when applied to transcriptionally-homogenous data. Simulated data was generated using a strategy similar to as described in Wolock, Lopex & Klein 2019, Cell Systems.\n\n![alternativetext](DF.screenshots/Simulation_Schematic.png)\n![alternativetext](DF.screenshots/Results_Simulation.png)\n\nSimulated and sample-multiplexed data are unique in that ground-truth doublet classifications can be leveraged to characterize how DoubletFinder parameters must be 'fit' to distinct scRNA-seq datasets. However, doublets remain unknown in real-world contexts -- which is likely why you are interested in DoubletFinder, at all!\n\nTo maximize the accuracy of DoubletFinder predictions, we sought a ground-truth-agnostic metric that coincides with pK values that maximize AUC in Cell Hashing and Demuxlet data. Mean-variance normalized bimodality coefficient (BCmvn) achieves this goal, featuring a single, easily-discernible maximum at pK values that optimize AUC. \n\n![alternativetext](DF.screenshots/BCmvn.png)\n\nBCmvn distributions also feature a single maximum for scRNA-seq datasets generated without sample-multiplexing (e.g., Mouse pancreas, Byrnes et al., 2018, Nature Communcations; Mouse kidney, Park et al., 2018, Science), enabling pK selection.\n\n## Doublet Number Estimation\n\nDoubletFinder is sensitive to heterotypic doublets -- i.e., doublets formed from transcriptionally-distinct cell states -- but is insensitive to homotypic doublets -- i.e., doublets formed from transcriptionally-similar cell states. In our original manuscript, we suggested using DoubletFinder to predict the number of doublets expected from Poisson statistical estimates realting to the droplet microfluidics cell loading density. However, Poisson estimates are agnostic of homotypic doublets, and will thus invariably overestimate the number of *detectable* doublets.\n\nTo address this issue, we suggest users utilize literature-supported cell type annotations to model the proportion of homotypic doublets present in their data. As an example, we present an analysis of mouse kidney scRNA-seq data (Park et al., 2018, Science):\n\n![alternativetext](DF.screenshots/HomotypicAdjustment.png)\n\nNotably, it is conceivable that literature-suppoted cell type annotations may not accurately recapitulate the magnitude of transcriptional divergence necessary for DoubletFinder sensitivity. For example, nominally-homogenous cells (e.g., CD4+ T-cells) may exist along a spectrum of gene expression states (e.g., distinct anatomical locations, disease states, naive/Tregs/Th17 cells, etc.), and doublets formed by cell sub-types may be detectable by DoubletFinder. Thus, we consider doublet number estimates based on Poisson statistics with and without homotypic doublet proportion adjustment to 'bookend' the real detectable doublet rate. \n\n## Example code for 'real-world' applications\n\n```R\n## Pre-process Seurat object (standard) --------------------------------------------------------------------------------------\nseu_kidney <- CreateSeuratObject(kidney.data)\nseu_kidney <- NormalizeData(seu_kidney)\nseu_kidney <- FindVariableFeatures(seu_kidney, selection.method = \"vst\", nfeatures = 2000)\nseu_kidney <- ScaleData(seu_kidney)\nseu_kidney <- RunPCA(seu_kidney)\nseu_kidney <- RunUMAP(seu_kidney, dims = 1:10)\n\n## Pre-process Seurat object (sctransform) -----------------------------------------------------------------------------------\nseu_kidney <- CreateSeuratObject(kidney.data)\nseu_kidney <- SCTransform(seu_kidney)\nseu_kidney <- RunPCA(seu_kidney)\nseu_kidney <- RunUMAP(seu_kidney, dims = 1:10)\n\n## pK Identification (no ground-truth) ---------------------------------------------------------------------------------------\nsweep.res.list_kidney <- paramSweep(seu_kidney, PCs = 1:10, sct = FALSE)\nsweep.stats_kidney <- summarizeSweep(sweep.res.list_kidney, GT = FALSE)\nbcmvn_kidney <- find.pK(sweep.stats_kidney)\n\n## pK Identification (ground-truth) ------------------------------------------------------------------------------------------\nsweep.res.list_kidney <- paramSweep(seu_kidney, PCs = 1:10, sct = FALSE)\ngt.calls <- seu_kidney@meta.data[rownames(sweep.res.list_kidney[[1]]), \"GT\"].   ## GT is a vector containing \"Singlet\" and \"Doublet\" calls recorded using sample multiplexing classification and/or in silico geneotyping results \nsweep.stats_kidney <- summarizeSweep(sweep.res.list_kidney, GT = TRUE, GT.calls = gt.calls)\nbcmvn_kidney <- find.pK(sweep.stats_kidney)\n\n## Homotypic Doublet Proportion Estimate -------------------------------------------------------------------------------------\nhomotypic.prop <- modelHomotypic(annotations)           ## ex: annotations <- seu_kidney@meta.data$ClusteringResults\nnExp_poi <- round(0.075*nrow(seu_kidney@meta.data))  ## Assuming 7.5% doublet formation rate - tailor for your dataset\nnExp_poi.adj <- round(nExp_poi*(1-homotypic.prop))\n\n## Run DoubletFinder with varying classification stringencies ----------------------------------------------------------------\nseu_kidney <- doubletFinder(seu_kidney, PCs = 1:10, pN = 0.25, pK = 0.09, nExp = nExp_poi, reuse.pANN = NULL, sct = FALSE)\nseu_kidney <- doubletFinder(seu_kidney, PCs = 1:10, pN = 0.25, pK = 0.09, nExp = nExp_poi.adj, reuse.pANN = \"pANN_0.25_0.09_913\", sct = FALSE)\n```\n\n![alternativetext](DF.screenshots/DFkidney_low.vs.high.png)\n\n## Other Doublet Detection Methods\n[Scrublet (Py)](https://github.com/AllonKleinLab/scrublet)\n[DoubletDecon (R)](https://github.com/EDePasquale/DoubletDecon)\n[DoubletDetection (Py)](https://github.com/JonathanShor/DoubletDetection)\n[Solo (Py)](https://github.com/calico/solo)\n[scds (R)](https://github.com/kostkalab/scds)\n[scDblFinder (R)](https://github.com/plger/scDblFinder)\n\n## References\n\n1.\tStoeckius M, Zheng S, Houck-Loomis B, Hao S, Yeung BZ, Smibert P, Satija R. Cell Hashing with barcoded antibodies enables multiplexing and doublet detection for single cell genomics. Genome Biology. 2018. 19:224.\n\n2.  Kang HM, Subramaniam M, Targ S, Nguyen M, Maliskova L, McCarthy E, Wan E, Wong S, Byrnes L, Lanata CM, Gate RE, Mostafavi S, Marson A, Zaitlen N, Criswell LA, Ye JC. Multiplexed droplet single-cell RNA-sequencing using natural genetic variation. Nature Biotechnology. 2018. 36(1):89-94. \n\n3.  Wolock SL, Lopez R, Klein AM. Scrublet: Computational Identification of Cell Doublets in Single-Cell Transcriptomic Data. Cell Systems. 2019. 8(4):281-291.e9.\n\n4.  Park J, Shrestha R, Qiu C, Kondo A, Huang S, Werth M, Li M, Barasch J, Suszt√°k K. Single-cell transcriptomics of the mouse kidney reveals potential cellular targets of kidney disease. Science. 2018. 360(6390):758-63.\n\n5.  Byrnes LE, Wong DM, Subramaniam M, Meyer NP, Gilchrist CL, Knox SM, Tward AD, Ye CJ, Sneddon JB. Lineage dynamics of murine pancreatic development at single-cell resolution. Nature Communications. 2018; 9:3922.\n\n6.  Bais AS, Kostka D. scds: computational annotation of doublets in single-cell RNA sequencing data. Bioinformatics. 2020. 36(4):1150-8.\n\n7.  Bernstein NJ, Fong NL, Lam I, Roy MA, Hendrickson DG, Kelley DR. Solo: Doublet Identification in Single-Cell RNA-Seq via Semi-Supervised Deep Learning. Cell Systems. 2020. S2405-4712(20)30195-2.\n\n8.  DePasquale EAK, Schnell DJ, Van Camp PJ, Valiente-Alandi I, Blaxall BC, Grimes HL, Singh H, Salomonis N. DoubletDecon: Deconvoluting Doublets from Single-Cell RNA-Sequencing Data. Cell Reports. 2019. 29(6):1718-27.e8.\n",
      "stars_today": 0
    },
    {
      "id": 216123064,
      "name": "ArchR",
      "full_name": "GreenleafLab/ArchR",
      "description": "ArchR : Analysis of Regulatory Chromatin in R (www.ArchRProject.com)",
      "html_url": "https://github.com/GreenleafLab/ArchR",
      "stars": 442,
      "forks": 153,
      "language": "R",
      "topics": [],
      "created_at": "2019-10-18T23:35:41Z",
      "updated_at": "2026-01-06T15:44:55Z",
      "pushed_at": "2025-02-18T21:19:00Z",
      "open_issues": 177,
      "owner": {
        "login": "GreenleafLab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8398169?v=4"
      },
      "readme": "<p align=\"center\"><a href =\"https://www.archrproject.com\"><img src=\"Figures/ArchR_Logo_Integrated.png\" alt=\"\" width=\"350\"></a></p>\n<hr>\n\n[![Lifecycle: maturing](https://img.shields.io/badge/lifecycle-maturing-blue.svg)](https://www.tidyverse.org/lifecycle/#maturing)\n\n### ArchR has new features available for scATAC-seq Analysis\n\n**Paired scATAC-seq and scRNA-seq Analysis**\n\nArchR now supports paired scATAC-seq and scRNA-seq Analysis! <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See updates with importFeatureMatrix, addGeneExpressionMatrix, addIterativeLSI, addCombinedDims <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For a brief tutorial of these features : https://greenleaflab.github.io/ArchR_2020/Ex-Analyze-Multiome.html\n\n**Trajectory Analysis**\n\nArchR now directly supports both monocle3 and Slingshot based trajectory analysis! <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See updates with getMonocleTrajectories, addMonocleTrajectory, addSlingShotTrajectories <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For a brief tutorial of these features : https://greenleaflab.github.io/ArchR_2020/Ex-Analyze-Trajectory.html\n\nAdditionally ArchR now enables export of a peak matrix that is compatible with STREAM!<br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See updates with exportPeakMatrixForSTREAM <br />\n\n### ArchR is currently in Beta and will be in active development through the peer review process.\n\nArchR is a full-featured R package for processing and analyzing single-cell ATAC-seq data. ArchR provides the most extensive suite of scATAC-seq analysis tools of any software available. Additionally, ArchR excels in both speed and resource usage, making it possible to analyze 1 million cells in 8 hours on a MacBook Pro laptop.\n\n### For installation instructions and full documentation, visit www.ArchRProject.com.\n\n<hr>\n\n![](Figures/ArchR_Workflow_Horizontal.png)\n\n# Quick Installation of ArchR\nFor a full walk through of installation and frequently related issues please visit www.ArchRProject.com.\n\n**First, install devtools (for installing GitHub packages) if it isn't already installed:**\n``` r\nif (!requireNamespace(\"devtools\", quietly = TRUE)) install.packages(\"devtools\")\n```\n\n**Then, install BiocManager (for installing bioconductor packages) if it isn't already installed:**\n``` r\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\")\n```\n\n**Then, install ArchR:**\n``` r\ndevtools::install_github(\"GreenleafLab/ArchR\", ref=\"master\", repos = BiocManager::repositories())\n```\n\n**Lastly, install all of the ArchR dependencies that aren't installed by default:**\n``` r\nlibrary(ArchR)\nArchR::installExtraPackages()\n```\nIf any of these steps fails, you should identify the offending package and troubleshoot that individual installation before proceeding. Additionally, please see the ArchR website (www.ArchRProject.com) where we have installation troubleshooting tips.\n\n# Pre-compiled ArchR environment\nWe provide two methods in which a user can manage R dependencies.  \n\n### Using renv to manage dependencies\nThe first is by using renv to manage a project's dependencies. To utilize this, make sure that the renv package is installed and loaded.  Before you are ready to use `renv`, you must ensure that you are working on the same R version that we used for the provided renv environment. \nThe R versions we currently support are:\n```\n- R 4.4\n- R 4.1\n```\nSecondly, make sure that the renv package is installed and loaded.\n```\ninstall.packages(\"renv\")\nlibrary(renv)\n```\nSet a working directory for your project\n```\ndir.create(path = \"./<project_name>\", showWarnings = FALSE)\nsetwd(\"./<project_name>\")\n```\nThen, lets download the lock file for the current master branch of ArchR.\nFor R 4.4:\n```\ndownload.file(url = \"https://pub-9ae435458ecc412abbbc9420a502ec38.r2.dev/renv.lock\", destfile = \"./renv.lock\")\n```\nFor R 4.1:\n```\ndownload.file(url = \"https://pub-9ae435458ecc412abbbc9420a502ec38.r2.dev/renv_4_1.lock\", destfile = \"./renv.lock\")\n```\n\nNow, we can initiate our renv project environment, utilizing the renv.lock to bootstrap a new renv environment.\n```\nrenv::init()\n```\n\n### Using Docker to manage dependencies\nWe also provide Docker images, built off of `rocker/rstudio`, that already have ArchR and all dependencies pre-loaded.\n\nThe latest version can be found at:\n```\ngreenleaflab/archr:latest\n```\nand other versions, including images built with differing R versions, can be found at:\n```\nhttps://hub.docker.com/r/greenleaflab/archr/tags\n```\n\nTo utilize these images, the user can first install Docker as mentioned in their [documentation](https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository)\n\nFollowing, create a container using the following command:\n```\ndocker image pull greenleaflab/archr:latest\ndocker run -it --rm -v <your_workspace>:/workspace -p <your_port_of_interest>:8787\n```\nThis will spin up a container that has Rstudio turned on by default. Rstudio can be accessed through:\n```\nlocalhost:<your_port_of_interest>\n```\nIf you would like an interactive bash console instead, the following command can instead be called:\n```\ndocker run -it --rm -v <your_workspace>:/workspace -p <your_port_of_interest>:8787 bash\n```\n\n# Issues using ArchR?\n\nArchR is currently in __beta__. We expect there to be bumps in the road. If you think you have found a bug, please first install the latest version of ArchR via\n``` r\ndevtools::install_github(\"GreenleafLab/ArchR\", ref=\"master\", repos = BiocManager::repositories())\n```\nIf this does not fix your problem, please [report an issue on Github](https://github.com/GreenleafLab/ArchR/issues) with the __Bug Report__ form.\n\nIf you have questions about ArchR usage, please refer to the [the searchable full user's manual](https://www.archrproject.com/bookdown/index.html), [the FAQ section](https://www.archrproject.com/articles/Articles/faq.html), and the [publication](https://greenleaf.stanford.edu/assets/pdf/). If you think the documentation on this website or in the function annotations is unclear, please [submit an issue on Github](https://github.com/GreenleafLab/ArchR/issues) with the __Documentation Request__ form. If there is a feature that you think is missing from ArchR _and you have already searched the user's manual_, [submit an issue on Github](https://github.com/GreenleafLab/ArchR/issues) with the __Feature Request__ form. If none of these options help, [send us an email](mailto:archr.devs@gmail.com). We will do our best to respond to questions that are not otherwise answered in the documentation.\n\n\n",
      "stars_today": 0
    },
    {
      "id": 50672978,
      "name": "gcam-core",
      "full_name": "JGCRI/gcam-core",
      "description": "GCAM -- The Global Change Analysis Model",
      "html_url": "https://github.com/JGCRI/gcam-core",
      "stars": 377,
      "forks": 203,
      "language": "R",
      "topics": [
        "climate",
        "coupled-human-natural-systems",
        "economics",
        "energy",
        "gcam",
        "human-earth-system",
        "integrated-assessment",
        "land",
        "water"
      ],
      "created_at": "2016-01-29T15:57:28Z",
      "updated_at": "2026-01-16T23:31:26Z",
      "pushed_at": "2025-12-12T20:56:28Z",
      "open_issues": 253,
      "owner": {
        "login": "JGCRI",
        "avatar_url": "https://avatars.githubusercontent.com/u/8431983?v=4"
      },
      "readme": "# Global Change Analysis Model (GCAM)\n\nThe Joint Global Change Research Institute (JGCRI) of the Pacific \nNorthwest National Laboratory (PNNL) is the home and primary \ndevelopment institution for GCAM, a multisector model for exploring \nconsequences of and responses to global to local changes and stressors. \nRegional energy, water, land, and economic systems are connected to the\nrest of the globe through trade and interactions with environmental systems.\nThese systems are also connected with each other.\nMultisector models such as GCAM capture these \ninterconnected impacts in an economic framework in order to explore \nthese dynamic interactions and feedbacks between regions and sectors.\n\nGCAM has been developed at PNNL-JGCRI for over 20 years and is a freely\navailable community model and documented online (See below). The team\nat JGCRI is comprised of physical scientists, engineers, economists, energy\nexperts, forest ecologists, agricultural scientists, and environmental system\nscientists who develop the model and apply it to a range of research questions.\nThe JGCRI team works closely with the developers of other Earth system and\necosystem models to integrate the effects of human actions modeled in GCAM\ninto their research.\n\n## Model Overview\n\nGCAM is a dynamic-recursive model with technology-rich representations\nof the economy, energy sector, land use, and water linked to a reduced complexity\nEarth system model that can be used to explore many science and decision-relevant\nquestions including the effects of changes in trade patterns, critical minerals\n& materials availability, and deployment of energy technologies on human and\nEarth systems. Regional population and labor productivity growth assumptions\ndrive the energy and land-use systems, employing numerous technology options to\nproduce, transform, and provide energy services, as well as to produce\nagriculture and forest products, and to determine land use and land cover.\nUsing a run period extending from 1990 ‚Äì 2100 (historical years through 2021)\nwith annual results computed at 1-5 year intervals, GCAM has been used to\nexplore the potential role of emerging energy supply technologies and\nthe consequences of specific measures or energy technology adoption, including\nbioenergy; critical minerals & materials; hydrogen systems; nuclear energy;\nrenewable energy technologies; carbon capture, storage, and utilization and\nenergy use technology in buildings, industry, and the transportation\nsectors. GCAM outputs include projections of future energy and critical mineral\nsupply, trade, and demand and the resulting radiative forcing and other effects\nof 16 greenhouse gases, aerosols, and short-lived species at 0.5√ó0.5 degree\nresolution, contingent on assumptions about future population, economy, technology,\ntrade and other polices.\n\n## Community guidelines for peer-reviewed journal articles using GCAM\n\nThis section outlines some suggested language which the GCAM user community \ncan employ to describe GCAM in papers in peer-reviewed journal articles,\nreports, or other public documents using GCAM or versions of GCAM. GCAM is\nunder continuous development. The suggested language for the opening paragraphs\nof a methodology or introduction section of a paper describing GCAM is as\nfollows:\n\n\"The Global Change Analysis Model (GCAM) is a multisector model developed and maintained at the Pacific Northwest National Laboratory‚Äôs Joint Global Change Research Institute (JGCRI, 2023) _\\<include additional citations to previous GCAM studies as relevant\\>_. GCAM is an open-source community model. In this study, we use GCAM v NN. The documentation of the model is available at the GCAM documentation page ([http://jgcri.github.io/gcam-doc](http://jgcri.github.io/gcam-doc)) and the description below is a summary. GCAM includes representations of: economy, energy, agriculture, and water supply in 32 geopolitical regions across the globe; their GHG and air pollutant emissions and global GHG concentrations, radiative forcing, and temperature change; and the associated land allocation, water use, and agriculture production across 396 land sub-regions and 235 water basins.  _\\<If using GCAM-USA, include without quotes: \"This study uses a U.S.-focused version of GCAM called GCAM-USA that includes representation of energy, economy, and water systems for the fifty states and the District of Columbia in addition to 31 regions outside of the United States.‚Äù\\>_. The version of GCAM used in this study is available ‚Äì along with full source code and instructions for use ‚Äì in a public repository _\\<include citation including link to the GCAM repository with doi used in paper\\>_. \n\nSubsequent paragraphs of the description might expound on particular capabilities, systems, or sectors of focus in the paper. Details in the GCAM documentation page can be used as a reference to develop these paragraphs.\n\nCommunity users of GCAM might also undertake their own model developments and/or assumptions for papers. It is recommended that these departures from the publicly available version of the model be clearly described. In addition, if these developments are substantial, we suggest making this clear by including an additional phrase (e.g. region name or name of institution) in the name of the model and explicitly calling it out in place of or immediately following the italicized portion in the above paragraphs. For example: _\"This study uses a modified version of GCAM/GCAM-USA called GCAM-\\<institution name\\>/GCAM-USA-\\<institution name\\>. GCAM-\\<institution name\\>/GCAM-USA-\\<institution name\\> incorporates additional details and modified assumptions from GCAM v NN as described subsequently\"_. \n\n## Documentation\n\n* [GCAM Documentation](http://jgcri.github.io/gcam-doc/)\n* [Getting Started with GCAM](http://jgcri.github.io/gcam-doc/user-guide.html)\n* [GCAM Community](https://gcims.pnnl.gov/community)\n* [GCAM Videos and Tutorial Slides](https://gcims.pnnl.gov/community)\n* [GCAM Citation and Co-authorship Guidelines](http://jgcri.github.io/gcam-doc/community-guide.html)\n\n## Selected Publications\n\nCalvin, K., Patel, P., Clarke, L., Asrar, G., Bond-Lamberty, B., Cui, R. Y., Di Vittorio, A., Dorheim, K., Edmonds, J., Hartin, C., Hejazi, M., Horowitz, R., Iyer, G., Kyle, P., Kim, S., Link, R., McJeon, H., Smith, S. J., Snyder, A., Waldhoff, S., and Wise, M.: GCAM v5.1: representing the linkages between energy, water, land, climate, and economic systems, Geosci. Model Dev., 12, 677‚Äì698, https://doi.org/10.5194/gmd-12-677-2019, 2019.\n\nEdmonds, J., and J. Reilly (1985)Global Energy: Assessing the Future (Oxford University Press, New York) pp.317.\n\nEdmonds, J., M. Wise, H. Pitcher, R. Richels, T. Wigley, and C. MacCracken. (1997) ‚ÄúAn Integrated Assessment of Climate Change and the Accelerated Introduction of Advanced Energy Technologies‚Äù, Mitigation and Adaptation Strategies for Global Change, 1, pp. 311-39\n\nKim, S.H., J. Edmonds, J. Lurz, S. J. Smith, and M. Wise (2006) ‚ÄúThe ObjECTS Framework for Integrated Assessment: Hybrid Modeling of Transportation ‚Äù Energy Journal (Special Issue #2) pp 51-80.\n\n[Full list of GCAM publications](http://jgcri.github.io/gcam-doc/references.html)\n",
      "stars_today": 0
    },
    {
      "id": 185880527,
      "name": "signac",
      "full_name": "stuart-lab/signac",
      "description": "R toolkit for the analysis of single-cell chromatin data",
      "html_url": "https://github.com/stuart-lab/signac",
      "stars": 400,
      "forks": 102,
      "language": "R",
      "topics": [
        "atac",
        "bioinformatics",
        "single-cell"
      ],
      "created_at": "2019-05-09T22:32:26Z",
      "updated_at": "2026-01-10T20:34:16Z",
      "pushed_at": "2025-12-11T05:17:49Z",
      "open_issues": 19,
      "owner": {
        "login": "stuart-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/102445397?v=4"
      },
      "readme": "# Signac <img align=\"right\" src=\"man/figures/logo.svg\" style=\"height:100px;\" />\n\n[![R-CMD-check](https://github.com/stuart-lab/signac/workflows/R-CMD-check/badge.svg)](https://github.com/stuart-lab/signac/actions)\n[![CRAN\nVersion](https://www.r-pkg.org/badges/version/Signac)](https://cran.r-project.org/package=Signac)\n[![CRAN\nDownloads](https://cranlogs.r-pkg.org/badges/Signac)](https://cran.r-project.org/package=Signac)\n\n## Overview\n\nSignac is a comprehensive R package for the analysis of single-cell\nchromatin data. Signac includes functions for quality control,\nnormalization, dimension reduction, clustering, differential activity,\nand more.\n\nDocumentation and tutorials can be found at\n<https://stuartlab.org/signac/>\n\n## Installation\n\nTo install the latest release of Signac from CRAN:\n\n``` r\nsetRepositories(ind=1:3) # needed to automatically install Bioconductor dependencies\ninstall.packages(\"Signac\")\n```\n\nTo release the latest develop version from GitHub:\n\n``` r\nif (!requireNamespace(\"remotes\", quietly = TRUE))\n    install.packages(\"remotes\")\nremotes::install_github(\"stuart-lab/signac\", ref = \"develop\")\n```\n\n## Release notes\n\nFor a changelog please see the [NEWS\nfile](https://github.com/stuart-lab/signac/blob/develop/NEWS.md), also\navailable on the [Signac\nwebsite](https://stuartlab.org/signac/news/index.html).\n\n## Contributing\n\nWe welcome contributions to the Signac package. Please see the\n[contribution guide](https://github.com/stuart-lab/signac/blob/develop/CONTRIBUTING.md)\nfor more information.\n\n## Getting help\n\nIf you encounter a bug or have a feature request, please open an\n[issue](https://github.com/stuart-lab/signac/issues).\n\nIf you would like to discuss questions related to single-cell analysis,\nyou can open a\n[discussion](https://github.com/stuart-lab/signac/discussions).\n\n## Citing Signac\n\nIf you use the Signac package in your work please cite [Stuart et\nal. 2021](https://doi.org/10.1038/s41592-021-01282-5)\n\n```\n@ARTICLE{signac,\n  title     = \"Single-cell chromatin state analysis with Signac\",\n  author    = \"Stuart, Tim and Srivastava, Avi and Madad, Shaista and Lareau,\n               Caleb A and Satija, Rahul\",\n  journal   = \"Nat. Methods\",\n  publisher = \"Nature Publishing Group\",\n  pages     = \"1--9\",\n  month     =  nov,\n  year      =  2021,\n  url       = \"https://www.nature.com/articles/s41592-021-01282-5\",\n  language  = \"en\"\n}\n```\n\n## Related packages\n\n-   [Seurat](https://github.com/satijalab/seurat)\n-   [SeuratObject](https://github.com/satijalab/seurat-object)\n-   [SeuratDisk](https://github.com/mojaveazure/seurat-disk)\n-   [SeuratData](https://github.com/satijalab/seurat-data)\n-   [SeuratWrappers](https://github.com/satijalab/seurat-wrappers)\n-   [Azimuth](https://github.com/satijalab/azimuth)\n",
      "stars_today": 0
    },
    {
      "id": 226864362,
      "name": "dd-sdk-ios",
      "full_name": "DataDog/dd-sdk-ios",
      "description": "Datadog SDK for iOS - Swift and Objective-C.",
      "html_url": "https://github.com/DataDog/dd-sdk-ios",
      "stars": 263,
      "forks": 159,
      "language": "Swift",
      "topics": [
        "distributed-tracing",
        "ios",
        "logging",
        "objective-c",
        "real-user-monitoring",
        "rum",
        "swift",
        "tracing",
        "tvos"
      ],
      "created_at": "2019-12-09T12:19:41Z",
      "updated_at": "2026-01-16T16:51:30Z",
      "pushed_at": "2026-01-16T17:29:30Z",
      "open_issues": 14,
      "owner": {
        "login": "DataDog",
        "avatar_url": "https://avatars.githubusercontent.com/u/365230?v=4"
      },
      "readme": "<p>\n    <a href=\"https://swiftpackageindex.com/DataDog/dd-sdk-ios\">\n        <img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2FDataDog%2Fdd-sdk-ios%2Fbadge%3Ftype%3Dplatforms\" />\n    </a>\n    <a href=\"https://swiftpackageindex.com/DataDog/dd-sdk-ios\">\n        <img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2FDataDog%2Fdd-sdk-ios%2Fbadge%3Ftype%3Dswift-versions\" />\n    </a>\n    <a href=\"https://swiftpackageindex.com/DataDog/dd-sdk-ios\">\n        <img src=\"https://img.shields.io/github/v/release/DataDog/dd-sdk-ios?style=flat&label=Swift%20Package%20Index&color=red\" />\n    </a>\n    <a href=\"https://cocoapods.org/pods/DatadogCore\">\n        <img src=\"https://img.shields.io/github/v/release/DataDog/dd-sdk-ios?style=flat&label=CocoaPods\" />\n    </a>\n</p>\n\n\n# Datadog SDK for iOS and tvOS\n\n> Swift and Objective-C libraries to interact with Datadog on iOS and tvOS.\n\n## Getting Started\n\n### Log Collection\n\nSee the dedicated [Datadog iOS Log Collection][1] documentation to learn how to send logs from your iOS application to Datadog.\n\n![Datadog iOS Log Collection](docs/images/logging.png)\n\n### Trace Collection\n\nSee [Datadog iOS Trace Collection][2] documentation to try it out.\n\n![Datadog iOS Log Collection](docs/images/tracing.png)\n\n### RUM Events Collection\n\nSee [Datadog iOS RUM Collection][3] documentation to try it out.\n\n![Datadog iOS RUM Collection](docs/images/rum.png)\n\n#### WebView Tracking\n\nRUM allows you to monitor web views and eliminate blind spots in your hybrid mobile applications. See [WebView Tracking][5] documentation to try it out.\n\n## Integrations\n\nIf you use [Alamofire][7], [Apollo GraphQL][8], [SDWebImage][9], or [OpenAPI Generator][10], see [Integrated Libraries][4] to learn how to instrument requests automatically.\n\n## Contributing\n\nPull requests are welcome. First, open an issue to discuss what you would like to change. For more information, read the [Contributing Guide](CONTRIBUTING.md).\n\n## License\n\n[Apache License, v2.0](LICENSE)\n\n## Supported Versions\n\nSee the [Supported Versions][6] documentation for more details.\n\n[1]: https://docs.datadoghq.com/logs/log_collection/ios\n[2]: https://docs.datadoghq.com/tracing/setup_overview/setup/ios\n[3]: https://docs.datadoghq.com/real_user_monitoring/ios\n[4]: https://docs.datadoghq.com/real_user_monitoring/mobile_and_tv_monitoring/integrated_libraries/ios\n[5]: https://docs.datadoghq.com/real_user_monitoring/mobile_and_tv_monitoring/web_view_tracking?tab=ios\n[6]: https://docs.datadoghq.com/real_user_monitoring/mobile_and_tv_monitoring/supported_versions/ios/\n[7]: https://github.com/Alamofire/Alamofire\n[8]: https://github.com/apollographql/apollo-ios\n[9]: https://github.com/SDWebImage/SDWebImage\n[10]: https://github.com/OpenAPITools/openapi-generator\n",
      "stars_today": 0
    },
    {
      "id": 681989124,
      "name": "duckdb-r",
      "full_name": "duckdb/duckdb-r",
      "description": "The duckdb R package",
      "html_url": "https://github.com/duckdb/duckdb-r",
      "stars": 202,
      "forks": 47,
      "language": "R",
      "topics": [
        "database",
        "duckdb",
        "olap",
        "r"
      ],
      "created_at": "2023-08-23T07:40:02Z",
      "updated_at": "2026-01-16T01:28:23Z",
      "pushed_at": "2026-01-17T01:02:38Z",
      "open_issues": 71,
      "owner": {
        "login": "duckdb",
        "avatar_url": "https://avatars.githubusercontent.com/u/82039556?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://r.duckdb.org/\"><picture>\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://duckdb.org/images/logo-dl/DuckDB_Logo-horizontal.svg\">\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://duckdb.org/images/logo-dl/DuckDB_Logo-horizontal-dark-mode.svg\">\n    <img alt=\"DuckDB logo\" src=\"https://duckdb.org/images/logo-dl/DuckDB_Logo-horizontal.svg\" height=\"100\">\n  </picture></a>\n</div>\n\n# duckdb\n\n[DuckDB](https://duckdb.org/) is an in-process SQL OLAP database management system.\nIt is designed to support analytical query workloads and is optimized for fast query execution.\nThis repository contains the R bindings for DuckDB.\n\n## Installation from CRAN\n\nInstalling the package from source may take up to an hour.\nConsider using binary Windows/macOS packages from CRAN for recent R versions, or [Posit Package Manager](https://p3m.dev/) for various flavors of Linux or older R versions.\n\n``` r\ninstall.packages(\"duckdb\")\n```\n\n## Installation from r-universe\n\nInstalling the package from source may take up to an hour.\nBinaries are available for recent versions of R.\nReview <https://docs.r-universe.dev/install/binaries.html> for configuring installation of binary packages on Linux.\n\n``` r\ninstall.packages(\"duckdb\", repos = c(\"https://duckdb.r-universe.dev\", \"https://cloud.r-project.org\"))\n```\n\n## Installation from GitHub\n\nInstalling the package from GitHub may take up to an hour.\n\n``` r\n# install.packages(\"pak\", repos = sprintf(\"https://r-lib.github.io/p/pak/stable/%s/%s/%s\", .Platform$pkgType, R.Version()$os, R.Version()$arch))\npak::pak(\"duckdb/duckdb-r\")\n```\n\n## User Guide\n\nSee the [R API in the DuckDB documentation](https://duckdb.org/docs/api/r).\n\n## Building\n\nTo build the R package, you first need to clone this repository and install the dependencies:\n\n``` r\n# install.packages(\"pak\", repos = sprintf(\"https://r-lib.github.io/p/pak/stable/%s/%s/%s\", .Platform$pkgType, R.Version()$os, R.Version()$arch))\npak::pak()\n```\n\nThen, install:\n\n``` sh\n~duckdb-r: R CMD INSTALL .\n```\n\nSet the `MAKEFLAGS` environment variable to `-j8` or similar for parallel builds.\nConfigure `ccache` for faster repeated builds.\n\nIf you wish to test new DuckDB functionality with duckdb-r, make sure your clone of `duckdb-r` is one level deeper than your clone of `duckdb` (e.g. `R/duckdb-r` and `duckdb`).\nThen run the following commands:\n\n``` sh\n~ (cd duckdb && git checkout {{desired_branch}})\n~ (cd R/duckdb-r && scripts/vendor.sh)\n~ (cd R/duckdb-r && R CMD INSTALL .)\n```\n\nIt helps if both the duckdb directory and duckdb-r directory are clean.\n\n## Vendoring\n\nThis package includes a vendored copy of the DuckDB C++ library. The vendoring process is automated and runs hourly to synchronize with the upstream DuckDB repository. For detailed information about how vendoring works, the relationship between `main` and `next` branches, and manual vendoring procedures, see `scripts/VENDORING.md`.\n\n## Contributors\n\nThanks to all [contributors](https://github.com/duckdb/duckdb-r/graphs/contributors) to this repository, and to those who contributed when the code was still hosted in the main [duckdb/duckdb](https://github.com/duckdb/duckdb) repository:\n\nMark Raasveldt, Pedro Holanda, Tom Ebergen, Reijo Sund, Nicolas Bennett, Patrik Schratz, Tishj, Laurens Kuiper, Sam Ansmink, Andy Teucher, Hadley Wickham, Jonathan Keane, Lindsay Wray, Richard Wesley, Elliana May, Edwin de Jonge, Dewey Dunnington, Carlo Piovesan, Andre Beckedorf, Tania Bogatsch, Pedro Ferreira, Maximilian Girlich, James Lamb, James Atkins, usurai, Ubuntu, Noam Ross, Michael Antonov, Jeroen Ooms, Jamie Lentin, Jacob, and Chilarai.\n",
      "stars_today": 0
    },
    {
      "id": 308437751,
      "name": "tree-sitter-r",
      "full_name": "r-lib/tree-sitter-r",
      "description": "Tree-sitter grammar for R",
      "html_url": "https://github.com/r-lib/tree-sitter-r",
      "stars": 123,
      "forks": 37,
      "language": "R",
      "topics": [],
      "created_at": "2020-10-29T20:06:05Z",
      "updated_at": "2025-12-29T20:00:02Z",
      "pushed_at": "2025-09-16T20:52:48Z",
      "open_issues": 16,
      "owner": {
        "login": "r-lib",
        "avatar_url": "https://avatars.githubusercontent.com/u/22618716?v=4"
      },
      "readme": "# tree-sitter-r\n\nAn R grammar for [tree-sitter](https://github.com/tree-sitter/tree-sitter).\n\n## R package\n\nThis grammar is available as an [R package](https://cran.r-project.org/web/packages/treesitter.r/index.html).\n\nYou'll also want the [R package providing bindings to tree-sitter](https://davisvaughan.github.io/r-tree-sitter/) itself.\n\n## Rust bindings\n\nThis grammar is available as a [Rust crate on crates.io](https://crates.io/crates/tree-sitter-r).\n\n## Node bindings\n\nThis grammar is available as an [npm package](https://www.npmjs.com/package/@davisvaughan/tree-sitter-r).\n\nNote that it is currently listed as a scoped package under the name `@davisvaughan/tree-sitter-r`.\nWe are working with the npm team to gain ownership of the `tree-sitter-r` package.\nOnce that happens, we will move the npm package there instead.\n\n## References\n\n- [The R Draft Spec](https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf)\n- [gram.y](https://github.com/wch/r-source/blob/trunk/src/main/gram.y)\n\n## Known deviations\n\nThis section describes known deviations from the R grammar.\n\n### `]]` as a literal token\n\nThe following is valid R syntax, note how `]]` has been split over multiple lines.\n\n```r\nx[[\"a\"]\n]\n```\n\nThis applies to `]]`, but not to `[[`, for example, this is not valid R syntax:\n\n```r\nx[\n[\"a\"]]\n```\n\nThe technical reason for this is that [in the grammar](https://github.com/wch/r-source/blob/988774e05497bcf2cfac47bfbec59d551432e3fb/src/main/gram.y#L508) R treats `[[` as a single token, but `]]` is treated as two individual `]` tokens.\nTreating `]]` as two individual `]` tokens allows whitespace, newlines, and even comments to appear between the two `]` tokens:\n\n```r\nx[[\"a\"] # comment\n]\n```\n\nWhile we'd like to precisely support the R grammar, it is also extremely useful to treat all of `(`, `)`, `[`, `]`, `[[`, and `]]` as literal tokens when using the tree-sitter grammar.\nThis allows you to treat call, subset, and subset2 nodes in the same way, since they all have exactly the same node structure.\n\nBecause treating `]]` as a literal token is so useful, and because we've never seen any R code \"in the wild\" written this way, this grammar does not allow whitespace, newlines, or comments between the two `]` tokens.\n",
      "stars_today": 0
    }
  ],
  "created_at": "2026-01-17T01:03:51.213043881Z"
}