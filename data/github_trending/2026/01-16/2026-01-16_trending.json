{
  "date": "2026-01-16",
  "name": "trending",
  "repositories": [
    {
      "id": 1028492186,
      "name": "eigent",
      "full_name": "eigent-ai/eigent",
      "description": "Eigent: The Open Source Cowork Desktop to Unlock Your Exceptional Productivity.",
      "html_url": "https://github.com/eigent-ai/eigent",
      "stars": 6020,
      "forks": 687,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-07-29T15:56:02Z",
      "updated_at": "2026-01-16T01:06:19Z",
      "pushed_at": "2026-01-16T00:16:32Z",
      "open_issues": 117,
      "owner": {
        "login": "eigent-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/163795819?v=4"
      },
      "readme": "<div align=\"center\"><a name=\"readme-top\"></a>\n\n[![][image-head]][eigent-site]\n\n[![][image-seperator]][eigent-site]\n\n### Eigent: The Open Source Cowork Desktop to Unlock Your Exceptional Productivity\n\n<!-- SHIELD GROUP -->\n\n[![][download-shield]][eigent-download]\n[![][github-star]][eigent-github]\n[![][social-x-shield]][social-x-link]\n[![][discord-image]][discord-url]<br>\n[![Reddit][reddit-image]][reddit-url]\n[![Wechat][wechat-image]][wechat-url]\n[![][sponsor-shield]][sponsor-link]\n[![][built-with-camel]][camel-github]\n[![][join-us-image]][join-us]\n\n</div>\n\n<hr/>\n<div align=\"center\">\n\n**English** Â· [ç®€ä½“ä¸­æ–‡](./README_CN.md) Â· [æ—¥æœ¬èª](./README_JA.md) Â· [Official Site][eigent-site] Â· [Documents][docs-site] Â· [Feedback][github-issue-link]\n\n</div>\n<br/>\n\n**Eigent**Â is the open source cowork desktop application, empowering you to build, manage, and deploy a custom AI workforce that can turn your most complex workflows into automated tasks. \n\nBuilt on [CAMEL-AI][camel-site]'s acclaimed open-source project, our system introduces a **Multi-Agent Workforce** that **boosts productivity** through parallel execution, customization, and privacy protection.\n\n### â­ 100% Open Source - ğŸ¥‡ Local Deployment - ğŸ† MCP Integration\n\n- âœ… **Zero Setup** - No technical configuration required\n- âœ… **Multi-Agent Coordination** - Handle complex multi-agent workflows\n- âœ… **Enterprise Feature** - SSO/Access control\n- âœ… **Local Deploymen**t\n- âœ… **Open Source**\n- âœ… **Custom Model Support**\n- âœ… **MCP Integration**\n\n<br/>\n\n[![][image-join-us]][join-us]\n\n<details>\n<summary><kbd>Table of contents</kbd></summary>\n\n#### TOC\n\n- [ğŸš€ Getting Started](#-getting-started)\n  - [ğŸ  Local Deployment (Recommended)](#-local-deployment-recommended)\n  - [âš¡ Quick Start (Cloud-Connected)](#-quick-start-cloud-connected)\n  - [ğŸ¢ Enterprise](#-enterprise)\n  - [â˜ï¸ Cloud Version](#ï¸-cloud-version)\n- [âœ¨ Key features](#-key-features)\n  - [ğŸ­ Workforce](#-workforce)\n  - [ğŸ§  Comprehensive Model Support](#-comprehensive-model-support)\n  - [ğŸ”Œ MCP Tools Integration (MCP)](#-mcp-tools-integration-mcp)\n  - [âœ‹ Human-in-the-Loop](#-human-in-the-loop)\n  - [ğŸ‘ 100% Open Source](#-100-open-source)\n- [ğŸ§© Use Cases](#-use-cases)\n- [ğŸ› ï¸ Tech Stack](#-tech-stack)\n  - [Backend](#backend)\n  - [Frontend](#frontend)\n- [ğŸŒŸÂ Staying ahead](#staying-ahead)\n- [ğŸ—ºï¸ Roadmap](#-roadmap)\n- [ğŸ“–Â Contributing](#-contributing)\n  - [Main Contributors](#main-contributors)\n  - [Distinguished amabssador](#distinguished-amabssador)\n- [Ecosystem](#ecosystem)\n- [ğŸ“„Â Open Source License](#-open-source-license)\n- [ğŸŒÂ Community & contact](#-community--contact)\n\n####\n\n<br/>\n\n</details>\n\n## **ğŸš€ Getting Started**\n\n> **ğŸ”“ Build in Public** â€” Eigent is **100% open source** from day one. Every feature, every commit, every decision is transparent. We believe the best AI tools should be built openly with the community, not behind closed doors.\n\n### ğŸ  Local Deployment (Recommended)\n\nThe recommended way to run Eigent â€” fully standalone with complete control over your data, no cloud account required.\n\nğŸ‘‰ **[Full Local Deployment Guide](./server/README_EN.md)**\n\nThis setup includes:\n- Local backend server with full API\n- Local model integration (vLLM, Ollama, LM Studio, etc.)\n- Complete isolation from cloud services\n- Zero external dependencies\n\n### âš¡ Quick Start (Cloud-Connected)\n\nFor a quick preview using our cloud backend â€” get started in seconds:\n\n#### Prerequisites\n\n- Node.js (version 18-22) and npm\n\n#### Steps\n\n```bash\ngit clone https://github.com/eigent-ai/eigent.git\ncd eigent\nnpm install\nnpm run dev\n```\n\n> Note: This mode connects to Eigent cloud services and requires account registration. For a fully standalone experience, use [Local Deployment](#-local-deployment-recommended) instead.\n\n### ğŸ¢ Enterprise\n\nFor organizations requiring maximum security, customization, and control:\n\n- **Exclusive Features** (like SSO & custom development)\n- **Scalable Enterprise Deployment**\n- **Negotiated SLAs** & implementation services\n\nğŸ“§ For further details, please contact us at [info@eigent.ai](mailto:info@eigent.ai).\n\n### â˜ï¸ Cloud Version\n\nFor teams who prefer managed infrastructure, we also offer a cloud platform. The fastest way to experience Eigent's multi-agent AI capabilities without setup complexity. We'll host the models, APIs, and cloud storage, ensuring Eigent runs flawlessly.\n\n- **Instant Access** - Start building multi-agent workflows in minutes.\n- **Managed Infrastructure** - We handle scaling, updates, and maintenance.\n- **Premium Support** - Subscribe and get priority assistance from our engineering team.\n\n<br/>\n\n[![image-public-beta]][eigent-download]\n\n<div align=\"right\">\n<a href=\"https://www.eigent.ai/download\">Get started at Eigent.ai â†’</a>\n</div>\n\n## **âœ¨ Key features**\nUnlock the full potential of exceptional productivity with Eigentâ€™s powerful featuresâ€”built for seamless integration, smarter task execution, and boundless automation.\n\n### ğŸ­ Workforce \nEmploys a team of specialized AI agents that collaborate to solve complex tasks. Eigent dynamically breaks down tasks and activates multiple agents to workÂ **in parallel.**\n\nEigent pre-defined the following agent workers:\n\n- **Developer Agent:**Â Writes and executes code, runs terminal commands.\n- **Search Agent:**Â Searches the web and extracts content.\n- **Document Agent:**Â Creates and manages documents.\n- **Multi-Modal Agent:**Â Processes images and audio.\n\n![Workforce](https://eigent-ai.github.io/.github/assets/gif/feature_dynamic_workforce.gif)\n\n<br/>\n\n### ğŸ§  Comprehensive Model Support\nDeploy Eigent locally with your preferred models. \n\n![Model](https://eigent-ai.github.io/.github/assets/gif/feature_local_model.gif)\n\n<br/>\n\n### ğŸ”Œ MCP Tools Integration (MCP)\nEigent comes with massive built-inÂ **Model Context Protocol (MCP)**Â tools (for web browsing, code execution, Notion, Google suite, Slack etc.), and also lets youÂ **install your own tools**. Equip agents with exactly the right tools for your scenarios â€“ even integrate internal APIs or custom functions â€“ to enhance their capabilities.\n\n![MCP](https://eigent-ai.github.io/.github/assets/gif/feature_add_mcps.gif)\n\n<br/>\n\n### âœ‹ Human-in-the-Loop\nIf a task gets stuck or encounters uncertainty, Eigent will automatically request human input. \n\n![Human-in-the-loop](https://eigent-ai.github.io/.github/assets/gif/feature_human_in_the_loop.gif)\n\n<br/>\n\n### ğŸ‘ 100% Open Source\nEigent is completely open-sourced. You can download, inspect, and modify the code, ensuring transparency and fostering a community-driven ecosystem for multi-agent innovation.\n\n![Opensource][image-opensource]\n\n<br/>\n\n## ğŸ§© Use Cases\n\n### 1. Palm Springs Tennis Trip Itinerary with Slack Summary [Replay â–¶ï¸](https://www.eigent.ai/download?share_token=IjE[REDACTED_SECRET]__1753435151337-7113)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>We are two tennis fans and want to go see the tennis tournament ... <kbd></summary>\n<br>\nWe are two tennis fans and want to go see the tennis tournament in Palm Springs 2026. I live in SF - please prepare a detailed itinerary with flights, hotels, things to do for 3 days - around the time semifinal/finals are happening. We like hiking, vegan food and spas. Our budget is $5K. The itinerary should be a detailed timeline of time, activity, cost, other details and if applicable a link to buy tickets/make reservations etc. for the item. Some preferences .Spa access would be nice but not necessary. When you finish this task, please generate a html report about this trip; write a summary of this plan and send text summary and report html link to slack #tennis-trip-sf channel.\n</details>\n\n<br>\n\n### 2. Generate Q2 Report from CSV Bank Data [Replay â–¶ï¸](https://www.eigent.ai/download?share_token=IjE[REDACTED_SECRET]__1753526891808-8739)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>Please help me prepare a Q2 financial statement based on my bank ... <kbd></summary>\n<br>\nPlease help me prepare a Q2 financial statement based on my bank transfer record file bank_transacation.csv in my desktop to a html report with chart to investors how much we have spent.\n</details>\n\n<br>\n\n### 3. UK Healthcare Market Research Report Automation [Replay â–¶ï¸](https://www.eigent.ai/download?share_token=IjE3NTMzOTM1NTg3OTctODcwNyI.aIey-Q.Jh9QXzYrRYarY0kz_qsgoj3ewX0__1753393558797-8707)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>Analyze the UK healthcare industry to support the planning ... <kbd></summary>\n<br>\nAnalyze the UK healthcare industry to support the planning of my next company. Provide a comprehensive market overview, including current trends, growth projections, and relevant regulations. Identify the top 5â€“10 major opportunities, gaps, or underserved segments within the market. Present all findings in a well-structured, professional HTML report. Then send a message to slack #eigentr-product-test channel when this task is done to align the report content with my teammates.\n</details>\n\n<br>\n\n### 4. German Electric Skateboard Market Feasibility [Replay â–¶ï¸](https://www.eigent.ai/download?share_token=Ij[REDACTED_SECRET]__1753652826787-696)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>We are a company that produces high-end electric skateboards ... <kbd></summary>\n<br>\nWe are a company that produces high-end electric skateboards, and we are considering entering the German market. Please prepare a detailed market entry feasibility report for me. The report needs to cover the following aspects:\n1. Market Size & Regulations: Research the market size, annual growth rate, key players, and market share for Personal Light Electric Vehicles (PLEVs) in Germany. Simultaneously, provide a detailed breakdown and summary of German laws and regulations concerning the use of electric skateboards on public roads, including certification requirements (such as ABE certification) and insurance policies.\n2. Consumer Profile: Analyze the profile of potential German consumers, including their age, income level, primary usage scenarios (commuting, recreation), key purchasing decision drivers (price, performance, brand, design), and the channels they typically use to gather information (forums, social media, offline retail stores).\n3. Channels & Distribution: Investigate Germanyâ€™s mainstream online electronics sales platforms (e.g., Amazon.de, MediaMarkt.de) and high-end sporting goods offline retail chains. List the top 5 potential online and offline distribution partners and find the contact information for their purchasing departments, if possible.\n4. Costing & Pricing: Based on the product cost structure in my Product_Cost.csv file on my desktop, and taking into account German customs duties, Value Added Tax (VAT), logistics and warehousing costs, and potential marketing expenses, estimate a Manufacturerâ€™s Suggested Retail Price (MSRP) and analyze its competitiveness in the market.\n5. Comprehensive Report & Presentation: Summarize all research findings into an HTML report file. The content should include data charts, key findings, and a final market entry strategy recommendation (Recommended / Not Recommended / Recommended with Conditions).\n</details>\n\n<br>\n\n### 5. SEO Audit for Workforce Multiagent Launch [Replay â–¶ï¸](https://www.eigent.ai/download?share_token=IjE[REDACTED_SECRET]__1753699971144-5696)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>To support the launch of our new Workforce Multiagent product ... <kbd></summary>\n<br>\nTo support the launch of our new Workforce Multiagent product, please run a thorough SEO audit on our official website (https://www.camel-ai.org/) and deliver a detailed optimization report with actionable recommendations.\n</details>\n\n<br>\n\n### 6. Identify Duplicate Files in Downloads [Replay â–¶ï¸](https://www.eigent.ai/download?share_token=Ij[REDACTED_SECRET]__1753760388171-248)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>I have a folder named mydocs inside my Documents directory ... <kbd></summary>\n<br>\nI have a folder named mydocs inside my Documents directory. Please scan it and identify all files that are exact or near duplicates â€” including those with identical content, file size, or format (even if file names or extensions differ). List them clearly, grouped by similarity.\n</details>\n\n<br>\n\n### 7. Add Signature to PDF [Replay â–¶ï¸](https://www.eigent.ai/download?share_token=IjE[REDACTED_SECRET]__1754095483452-5661)\n\n<details>\n<summary><strong>Prompt:</strong> <kbd>Please add this signature image to the Signature Areas in the PDF ... <kbd></summary>\n<br>\nPlease add this signature image to the Signature Areas in the PDF. You could install the CLI tool â€˜tesseractâ€™ (needed for reliable location of â€˜Signature Areasâ€™ via OCR) to help finish this task.\n</details>\n\n<br>\n\n## ğŸ› ï¸ Tech Stack\n\n### Backend\n- **Framework:**Â FastAPI\n- **Package Manager:**Â uv\n- **Async Server:**Â Uvicorn\n- **Authentication:**Â OAuth 2.0,  Passlib.\n- **Multi-agent framework:** CAMEL\n    \n### Frontend\n\n- **Framework:**Â React\n- **Desktop App Framework:**Â Electron\n- **Language:**Â TypeScript\n- **UI:**Â Tailwind CSS, Radix UI, Lucide React, Framer Motion\n- **State Management:**Â Zustand\n- **Flow Editor:**Â React Flow\n\n## ğŸŒŸÂ Staying ahead\n\n> \\[!IMPORTANT]\n>\n> **Star Eigent**, You will receive all release notifications from GitHub without any delay \\~ â­ï¸\n\n![][image-star-us]\n\n## ğŸ—ºï¸ Roadmap\n\n| Topics                   | Issues   | Discord Channel |\n| ------------------------ | -- |-- |\n| **Context Engineering** | - Prompt caching<br> - System prompt optimize<br> - Toolkit docstring optimize<br> - Context compression | [**Join Discord â†’**](https://discord.gg/D2e3rBWD) |\n| **Multi-modal Enhancement** | - More accurate image understanding when using browser<br> - Advanced video generation | [**Join Discord â†’**](https://discord.gg/kyapNCeJ) |\n| **Multi-agent system** | - Workforce support fixed workflow<br> - Workforce support multi-round conversion | [**Join Discord â†’**](https://discord.gg/bFRmPuDB) |\n| **Browser Toolkit** | - BrowseCamp integration<br> - Benchmark improvement<br> - Forbid repeated page visiting<br> - Automatic cache button clicking | [**Join Discord â†’**](https://discord.gg/NF73ze5v) |\n| **Document Toolkit** | - Support dynamic file editing | [**Join Discord â†’**](https://discord.gg/4yAWJxYr) |\n| **Terminal Toolkit** | - Benchmark improvement<br> - Terminal-Bench integration | [**Join Discord â†’**](https://discord.gg/FjQfnsrV) |\n| **Environment & RL** | - Environment design<br> - Data-generation<br> - RL framework integration (VERL, TRL, OpenRLHF) | [**Join Discord â†’**](https://discord.gg/MaVZXEn8) |\n\n\n## [ğŸ¤ Contributing][contribution-link]\n\nWe believe in building trust and embracing all forms of open-source collaborations. Your creative contributions help drive the innovation of `Eigent`. Explore our GitHub issues and projects to dive in and show us what youâ€™ve got ğŸ¤â¤ï¸ [Contribution Guideline][contribution-link]\n\n## [â¤ï¸ Sponsor][sponsor-link]\n\nEigent is built on top of [CAMEL-AI.org][camel-ai-org-github]'s research and infrastructures. [Sponsoring CAMEL-AI.org][sponsor-link] will make `Eigent` better.\n\n## **ğŸ“„Â Open Source License**\n\nThis repository is licensed under the [Apache License 2.0](LICENSE).\n\n## ğŸŒ Community & Contact\nFor more information please contact info@eigent.ai\n\n- **GitHub Issues:** Report bugs, request features, and track development. [Submit an issue][github-issue-link]\n\n- **Discord:** Get real-time support, chat with the community, and stay updated. [Join us](https://discord.camel-ai.org/)\n\n- **X (Twitter):** Follow for updates, AI insights, and key announcements. [Follow us][social-x-link]\n\n- **WeChat Community:** Scan the QR code below to add our WeChat assistant, and join our WeChat community group.\n\n<div align=\"center\">\n  <img src=\"./src/assets/wechat_qr.jpg\" width=\"200\" style=\"display: inline-block; margin: 10px;\">\n</div>\n\n\n\n<!-- LINK GROUP -->\n<!-- Social -->\n[discord-url]: https://discord.camel-ai.org/\n[discord-image]: https://img.shields.io/discord/1082486657678311454?logo=discord&labelColor=%20%235462eb&logoColor=%20%23f5f5f5&color=%20%235462eb\n\n[built-with-camel]:https://img.shields.io/badge/-Built--with--CAMEL-4C19E8.svg?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQ4IiBoZWlnaHQ9IjI3MiIgdmlld0JveD0iMCAwIDI0OCAyNzIiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+CjxwYXRoIGQ9Ik04LjgzMTE3IDE4LjU4NjVMMCAzMC44MjY3QzUuNDY2OTIgMzUuMDQzMiAxNS4xMzkxIDM4LjgyNTggMjQuODExNCAzNi4yOTU5QzMwLjY5ODggNDAuOTM0MSAzOS42NzAyIDQwLjIzMTMgNDQuMTU1OSA0MC4wOTA4QzQzLjQ1NSA0Ny4zOTk0IDQyLjQ3MzcgNzAuOTU1OCA0NC4xNTU5IDEwNi43MTJDNDUuODM4IDE0Mi40NjggNzEuNzcwOCAxNjYuODY4IDg0LjUyNjkgMTc0LjU5OEw3Ni4wMDAyIDIyMEw4NC41MjY5IDI3MkgxMDguOTE4TDk4LjAwMDIgMjIwTDEwOC45MTggMTc0LjU5OEwxMjkuOTQ0IDI3MkgxNTQuNzU2TDEzNC4xNSAxNzQuNTk4SDE4Ny4xMzdMMTY2LjUzMSAyNzJIMTkxLjc2M0wyMTIuMzY5IDE3NC41OThMMjI2IDIyMEwyMTIuMzY5IDI3MkgyMzcuNjAxTDI0OC4wMDEgMjIwTDIzNy4xOCAxNzQuNTk4QzIzOS4yODMgMTY5LjExNyAyNDAuNDAxIDE2Ni45NzYgMjQxLjgwNiAxNjEuMTA1QzI0OS4zNzUgMTI5LjQ4MSAyMzUuMDc3IDEwMy45MDEgMjI2LjY2NyA5NC40ODRMMjA2LjQ4MSA3My44MjNDMTk3LjY1IDY0Ljk2ODMgMTgyLjUxMSA2NC41NDY3IDE3Mi44MzkgNzIuNTU4MUMxNjUuNzI4IDc4LjQ0NzcgMTYxLjcwMSA3OC43NzI3IDE1NC43NTYgNzIuNTU4MUMxNTEuODEyIDcwLjAyODEgMTQ0LjUzNSA2MS40ODg5IDEzNC45OTEgNTMuNTgzN0MxMjUuMzE5IDQ1LjU3MjMgMTA4LjQ5NyA0OC45NDU1IDEwMi4xODkgNTUuNjkxOUw3My41OTMxIDg0LjM2NDRWNy42MjM0OUw3OS4xMjczIDBDNjAuOTA0MiAzLjY1NDMzIDIzLjgwMjEgOS41NjMwOSAxOS43NjUgMTAuNTc1MUMxNS43Mjc5IDExLjU4NyAxMC43OTM3IDE2LjMzNzcgOC44MzExNyAxOC41ODY1WiIgZmlsbD0id2hpdGUiLz4KPHBhdGggZD0iTTQzLjIwMzggMTguNzE4N0w0OS4wOTEyIDEzLjA0OTNMNTQuOTc4NyAxOC43MTg3TDQ5LjA5MTIgMjQuODI0Mkw0My4yMDM4IDE4LjcxODdaIiBmaWxsPSIjNEMxOUU4Ii8+Cjwvc3ZnPgo=\n\n[eigent-github]: https://github.com/eigent-ai/eigent\n[github-star]: https://img.shields.io/github/stars/eigent-ai?color=F5F4F0&labelColor=gray&style=plastic&logo=github\n[camel-ai-org-github]: https://github.com/camel-ai\n\n[camel-github]: https://github.com/camel-ai/camel\n[eigent-github]: https://github.com/eigent-ai/eigent\n[contribution-link]: https://github.com/eigent-ai/eigent/blob/main/CONTRIBUTING.md\n\n[social-x-link]: https://x.com/Eigent_AI\n[social-x-shield]: https://img.shields.io/badge/-%40Eigent_AI-white?labelColor=gray&logo=x&logoColor=white&style=plastic\n\n[reddit-url]: https://www.reddit.com/r/CamelAI/\n[reddit-image]: https://img.shields.io/reddit/subreddit-subscribers/CamelAI?style=plastic&logo=reddit&label=r%2FCAMEL&labelColor=white\n\n[wechat-url]: https://ghli.org/camel/wechat.png\n[wechat-image]: https://img.shields.io/badge/WeChat-CamelAIOrg-brightgreen?logo=wechat&logoColor=white\n\n[sponsor-link]: https://github.com/sponsors/camel-ai\n[sponsor-shield]: https://img.shields.io/badge/-Sponsor%20CAMEL--AI-1d1d1d?logo=github&logoColor=white&style=plastic\n\n[eigent-download]: https://www.eigent.ai/download\n[download-shield]: https://img.shields.io/badge/Download%20Eigent-363AF5?style=plastic\n\n[join-us]:https://eigent-ai.notion.site/eigent-ai-careers\n[join-us-image]:https://img.shields.io/badge/Join%20Us-yellow?style=plastic\n\n<!-- camel & eigent -->\n[camel-site]: https://www.camel-ai.org\n[eigent-site]: https://www.eigent.ai\n[docs-site]: https://docs.eigent.ai\n[github-issue-link]: https://github.com/eigent-ai/eigent/issues\n\n<!-- marketing -->\n[image-seperator]: https://eigent-ai.github.io/.github/assets/seperator.png \n[image-head]: https://eigent-ai.github.io/.github/assets/head.png \n[image-public-beta]: https://eigent-ai.github.io/.github/assets/banner.png\n[image-star-us]: https://eigent-ai.github.io/.github/assets/star-us.gif\n[image-opensource]: https://eigent-ai.github.io/.github/assets/opensource.png\n[image-wechat]: https://eigent-ai.github.io/.github/assets/wechat.png\n[image-join-us]: https://camel-ai.github.io/camel_asset/graphics/join_us.png\n\n<!-- feature -->\n[image-workforce]: https://eigent-ai.github.io/.github/assets/feature_dynamic_workforce.gif\n[image-human-in-the-loop]: https://eigent-ai.github.io/.github/assets/feature_human_in_the_loop.gif\n[image-customise-workers]: https://eigent-ai.github.io/.github/assets/feature_customise_workers.gif\n[image-add-mcps]: https://eigent-ai.github.io/.github/assets/feature_add_mcps.gif\n[image-local-model]: https://eigent-ai.github.io/.github/assets/feature_local_model.gif\n",
      "stars_today": 751
    },
    {
      "id": 943950290,
      "name": "datahaven",
      "full_name": "datahaven-xyz/datahaven",
      "description": "An EVM compatible Substrate chain, powered by StorageHub and secured by EigenLayer",
      "html_url": "https://github.com/datahaven-xyz/datahaven",
      "stars": 3515,
      "forks": 65,
      "language": "Rust",
      "topics": [],
      "created_at": "2025-03-06T14:35:59Z",
      "updated_at": "2026-01-16T00:58:13Z",
      "pushed_at": "2026-01-15T21:39:27Z",
      "open_issues": 10,
      "owner": {
        "login": "datahaven-xyz",
        "avatar_url": "https://avatars.githubusercontent.com/u/207200851?v=4"
      },
      "readme": "# DataHaven ğŸ«\n\nAI-First Decentralized Storage secured by EigenLayer â€” a verifiable storage network for AI training data, machine learning models, and Web3 applications.\n\n## Overview\n\nDataHaven is a decentralized storage and retrieval network designed for applications that need verifiable, production-scale data storage. Built on [StorageHub](https://github.com/Moonsong-Labs/storage-hub) and secured by EigenLayer's restaking protocol, DataHaven separates storage from verification: providers store data off-chain while cryptographic commitments are anchored on-chain for tamper-evident verification.\n\n**Core Capabilities:**\n\n- **Verifiable Storage**: Files are chunked, hashed into Merkle trees, and committed on-chain â€” enabling cryptographic proof that data hasn't been tampered with\n- **Provider Network**: Main Storage Providers (MSPs) serve data with competitive offerings, while Backup Storage Providers (BSPs) ensure redundancy through decentralized replication with on-chain slashing for failed proof challenges\n- **EigenLayer Security**: Validator set secured by Ethereum restaking â€” DataHaven validators register as EigenLayer operators with slashing for misbehavior\n- **EVM Compatibility**: Full Ethereum support via Frontier pallets for smart contracts and familiar Web3 tooling\n- **Cross-chain Bridge**: Native, trustless bridging with Ethereum via Snowbridge for tokens and messages\n\n## Architecture\n\nDataHaven combines EigenLayer's shared security with StorageHub's decentralized storage infrastructure:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                              Ethereum (L1)                                  â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚  â”‚  EigenLayer AVS Contracts                                             â”‚  â”‚\nâ”‚  â”‚  â€¢ DataHavenServiceManager (validator lifecycle & slashing)           â”‚  â”‚\nâ”‚  â”‚  â€¢ RewardsRegistry (validator performance & rewards)                  â”‚  â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\nâ”‚                                    â†•                                        â”‚\nâ”‚                          Snowbridge Protocol                                â”‚\nâ”‚                    (trustless cross-chain messaging)                        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                     â†•\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                          DataHaven (Substrate)                              â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚  â”‚  StorageHub Pallets                     DataHaven Pallets             â”‚  â”‚\nâ”‚  â”‚  â€¢ file-system (file operations)        â€¢ External Validators         â”‚  â”‚\nâ”‚  â”‚  â€¢ providers (MSP/BSP registry)         â€¢ Native Transfer             â”‚  â”‚\nâ”‚  â”‚  â€¢ proofs-dealer (challenge/verify)     â€¢ Rewards                     â”‚  â”‚\nâ”‚  â”‚  â€¢ payment-streams (storage payments)   â€¢ Frontier (EVM)              â”‚  â”‚\nâ”‚  â”‚  â€¢ bucket-nfts (bucket ownership)                                     â”‚  â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                     â†•\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                        Storage Provider Network                             â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\nâ”‚  â”‚  Main Storage Providers     â”‚    â”‚  Backup Storage Providers   â”‚        â”‚\nâ”‚  â”‚  (MSP)                      â”‚    â”‚  (BSP)                      â”‚        â”‚\nâ”‚  â”‚  â€¢ User-selected            â”‚    â”‚  â€¢ Network-assigned         â”‚        â”‚\nâ”‚  â”‚  â€¢ Serve read requests      â”‚    â”‚  â€¢ Replicate data           â”‚        â”‚\nâ”‚  â”‚  â€¢ Anchor bucket roots      â”‚    â”‚  â€¢ Proof challenges         â”‚        â”‚\nâ”‚  â”‚  â€¢ MSP Backend service      â”‚    â”‚  â€¢ On-chain slashing        â”‚        â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\nâ”‚  â”‚  Indexer                    â”‚    â”‚  Fisherman                  â”‚        â”‚\nâ”‚  â”‚  â€¢ Index on-chain events    â”‚    â”‚  â€¢ Audit storage proofs     â”‚        â”‚\nâ”‚  â”‚  â€¢ Query storage metadata   â”‚    â”‚  â€¢ Trigger challenges       â”‚        â”‚\nâ”‚  â”‚  â€¢ PostgreSQL backend       â”‚    â”‚  â€¢ Detect misbehavior       â”‚        â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### How Storage Works\n\n1. **Upload**: User selects an MSP, creates a bucket, and uploads files. Files are chunked (8KB default), hashed into Merkle trees, and the root is anchored on-chain.\n2. **Replication**: The MSP coordinates with BSPs to replicate data across the network based on the bucket's replication policy.\n3. **Retrieval**: MSP returns files with Merkle proofs that users verify against on-chain commitments.\n4. **Verification**: BSPs face periodic proof challenges â€” failure to prove data custody results in on-chain slashing via StorageHub pallets.\n\n## Repository Structure\n\n```\ndatahaven/\nâ”œâ”€â”€ contracts/      # EigenLayer AVS smart contracts\nâ”‚   â”œâ”€â”€ src/       # Service Manager, Rewards Registry, Slasher\nâ”‚   â”œâ”€â”€ script/    # Deployment scripts\nâ”‚   â””â”€â”€ test/      # Foundry test suites\nâ”œâ”€â”€ operator/       # Substrate-based DataHaven node\nâ”‚   â”œâ”€â”€ node/      # Node implementation & chain spec\nâ”‚   â”œâ”€â”€ pallets/   # Custom pallets (validators, rewards, transfers)\nâ”‚   â””â”€â”€ runtime/   # Runtime configurations (mainnet/stagenet/testnet)\nâ”œâ”€â”€ test/           # E2E testing framework\nâ”‚   â”œâ”€â”€ suites/    # Integration test scenarios\nâ”‚   â”œâ”€â”€ framework/ # Test utilities and helpers\nâ”‚   â””â”€â”€ launcher/  # Network deployment automation\nâ”œâ”€â”€ deploy/         # Kubernetes deployment charts\nâ”‚   â”œâ”€â”€ charts/    # Helm charts for nodes and relayers\nâ”‚   â””â”€â”€ environments/ # Environment-specific configurations\nâ”œâ”€â”€ tools/          # GitHub automation and release scripts\nâ””â”€â”€ .github/        # CI/CD workflows\n```\n\nEach directory contains its own README with detailed information. See:\n- [contracts/README.md](contracts/README.md) - Smart contract development\n- [operator/README.md](operator/README.md) - Node building and runtime development\n- [test/README.md](test/README.md) - E2E testing and network deployment\n- [deploy/README.md](deploy/README.md) - Kubernetes deployment\n- [tools/README.md](tools/README.md) - Development tools\n\n## Quick Start\n\n### Prerequisites\n\n- [Kurtosis](https://docs.kurtosis.com/install) - Network orchestration\n- [Bun](https://bun.sh/) v1.3.2+ - TypeScript runtime\n- [Docker](https://www.docker.com/) - Container management\n- [Foundry](https://getfoundry.sh/) - Solidity toolkit\n- [Rust](https://www.rust-lang.org/tools/install) - For building the operator\n- [Helm](https://helm.sh/) - Kubernetes deployments (optional)\n- [Zig](https://ziglang.org/) - For macOS cross-compilation (macOS only)\n\n### Launch Local Network\n\nThe fastest way to get started is with the interactive CLI:\n\n```bash\ncd test\nbun i                    # Install dependencies\nbun cli launch           # Interactive launcher with prompts\n```\n\nThis deploys a complete environment including:\n- **Ethereum network**: 2x EL clients (reth), 2x CL clients (lodestar)\n- **Block explorers**: Blockscout (optional), Dora consensus explorer\n- **DataHaven node**: Single validator with fast block times\n- **Storage providers**: MSP and BSP nodes for decentralized storage\n- **AVS contracts**: Deployed and configured on Ethereum\n- **Snowbridge relayers**: Bidirectional message passing\n\nFor more options and detailed instructions, see the [test README](./test/README.md).\n\n### Run Tests\n\n```bash\ncd test\nbun test:e2e              # Run all integration tests\nbun test:e2e:parallel     # Run with limited concurrency\n```\n\nNOTES: Adding the environment variable `INJECT_CONTRACTS=true` will inject the contracts when starting the tests to speed up setup.\n\n### Development Workflows\n\n**Smart Contract Development**:\n```bash\ncd contracts\nforge build               # Compile contracts\nforge test                # Run contract tests\n```\n\n**Node Development**:\n```bash\ncd operator\ncargo build --release --features fast-runtime\ncargo test\n./scripts/run-benchmarks.sh\n```\n\n**After Making Changes**:\n```bash\ncd test\nbun generate:wagmi        # Regenerate contract bindings\nbun generate:types        # Regenerate runtime types\n```\n\n## Key Features\n\n### Verifiable Decentralized Storage\nProduction-scale storage with cryptographic guarantees:\n- **Buckets**: User-created containers managed by an MSP, summarized by a Merkle-Patricia trie root on-chain\n- **Files**: Deterministically chunked, hashed into Merkle trees, with roots serving as immutable fingerprints\n- **Proofs**: Merkle proofs enable verification of data integrity without trusting intermediaries\n- **Audits**: BSPs prove ongoing data custody via randomized proof challenges\n\n### Storage Provider Network\nTwo-tier provider model balancing performance and reliability:\n- **MSPs**: User-selected providers offering data retrieval with competitive service offerings\n- **BSPs**: Network-assigned backup providers ensuring data redundancy and availability, with on-chain slashing for failed proof challenges\n- **Fisherman**: Auditing service that monitors proofs and triggers challenges for misbehavior\n- **Indexer**: Indexes on-chain storage events for efficient querying\n\n### EigenLayer Security\nDataHaven validators secured through Ethereum restaking:\n- Validators register as operators via `DataHavenServiceManager` contract\n- Economic security through ETH restaking\n- Slashing for validator misbehavior (separate from BSP slashing which is on-chain)\n- Performance-based validator rewards through `RewardsRegistry`\n\n### EVM Compatibility\nFull Ethereum Virtual Machine support via Frontier pallets:\n- Deploy Solidity smart contracts\n- Use existing Ethereum tooling (MetaMask, Hardhat, etc.)\n- Compatible with ERC-20, ERC-721, and other standards\n\n### Cross-chain Communication\nTrustless bridging via Snowbridge:\n- Native token transfers between Ethereum â†” DataHaven\n- Cross-chain message passing\n- Finality proofs via BEEFY consensus\n- Three specialized relayers (beacon, BEEFY, execution)\n\n## Use Cases\n\nDataHaven is designed for applications requiring verifiable, tamper-proof data storage:\n\n- **AI & Machine Learning**: Store training datasets, model weights, and agent configurations with cryptographic proofs of integrity â€” enabling federated learning and verifiable AI pipelines\n- **DePIN (Decentralized Physical Infrastructure)**: Persistent storage for IoT sensor data, device configurations, and operational logs with provable data lineage\n- **Real World Assets (RWAs)**: Immutable storage for asset documentation, ownership records, and compliance data with on-chain verification\n\n## Docker Images\n\nProduction images published to [DockerHub](https://hub.docker.com/r/datahavenxyz/datahaven).\n\n**Build optimizations**:\n- [sccache](https://github.com/mozilla/sccache) - Rust compilation caching\n- [cargo-chef](https://lpalmieri.com/posts/fast-rust-docker-builds/) - Dependency layer caching\n- [BuildKit cache mounts](https://docs.docker.com/build/cache/optimize/#use-cache-mounts) - External cache restoration\n\n**Build locally**:\n```bash\ncd test\nbun build:docker:operator    # Creates datahavenxyz/datahaven:local\n```\n\n## Development Environment\n\n### VS Code Configuration\n\nIDE configurations are excluded from version control for personalization, but these settings are recommended for optimal developer experience. Add to your `.vscode/settings.json`:\n\n**Rust Analyzer**:\n```json\n{\n  \"rust-analyzer.linkedProjects\": [\"./operator/Cargo.toml\"],\n  \"rust-analyzer.cargo.allTargets\": true,\n  \"rust-analyzer.procMacro.enable\": false,\n  \"rust-analyzer.server.extraEnv\": {\n    \"CARGO_TARGET_DIR\": \"target/.rust-analyzer\",\n    \"SKIP_WASM_BUILD\": 1\n  },\n  \"rust-analyzer.diagnostics.disabled\": [\"unresolved-macro-call\"],\n  \"rust-analyzer.cargo.buildScripts.enable\": false\n}\n```\n\nOptimizations:\n- Links `operator/` directory as the primary Rust project\n- Disables proc macros and build scripts for faster analysis (Substrate macros are slow)\n- Uses dedicated target directory to avoid conflicts\n- Skips WASM builds during development\n\n**Solidity** ([Juan Blanco's extension](https://marketplace.visualstudio.com/items?itemName=JuanBlanco.solidity)):\n```json\n{\n  \"solidity.formatter\": \"forge\",\n  \"solidity.compileUsingRemoteVersion\": \"v0.8.28+commit.7893614a\",\n  \"[solidity]\": {\n    \"editor.defaultFormatter\": \"JuanBlanco.solidity\"\n  }\n}\n```\n\nNote: Solidity version must match [foundry.toml](./contracts/foundry.toml)\n\n**TypeScript** ([Biome](https://github.com/biomejs/biome)):\n```json\n{\n  \"biome.lsp.bin\": \"test/node_modules/.bin/biome\",\n  \"[typescript]\": {\n    \"editor.defaultFormatter\": \"biomejs.biome\",\n    \"editor.codeActionsOnSave\": {\n      \"source.organizeImports.biome\": \"always\"\n    }\n  }\n}\n```\n\n## CI/CD\n\n### Local CI Testing\n\nRun GitHub Actions workflows locally using [act](https://github.com/nektos/act):\n\n```bash\n# Run E2E workflow\nact -W .github/workflows/e2e.yml -s GITHUB_TOKEN=\"$(gh auth token)\"\n\n# Run specific job\nact -W .github/workflows/e2e.yml -j test-job-name\n```\n\n### Automated Workflows\n\nThe repository includes GitHub Actions for:\n- **E2E Testing**: Full integration tests on PR and main branch\n- **Contract Testing**: Foundry test suites for smart contracts\n- **Rust Testing**: Unit and integration tests for operator\n- **Docker Builds**: Multi-platform image builds with caching\n- **Release Automation**: Version tagging and changelog generation\n\nSee `.github/workflows/` for workflow definitions.\n\n## Contributing\n\n### Development Cycle\n\n1. **Make Changes**: Edit contracts, runtime, or tests\n2. **Run Tests**: Component-specific tests (`forge test`, `cargo test`)\n3. **Regenerate Types**: Update bindings if contracts/runtime changed\n4. **Integration Test**: Run E2E tests to verify cross-component behavior\n5. **Code Quality**: Format and lint (`cargo fmt`, `forge fmt`, `bun fmt:fix`)\n\n### Common Pitfalls\n\n- **Type mismatches**: Regenerate with `bun generate:types` after runtime changes\n- **Contract changes not reflected**: Run `bun generate:wagmi` after modifications\n- **Kurtosis issues**: Ensure Docker is running and Kurtosis engine is started\n- **Slow development**: Use `--features fast-runtime` for shorter epochs/eras (block time stays 6s)\n- **Network launch hangs**: Check Blockscout - forge output can appear frozen\n\nSee [CLAUDE.md](./CLAUDE.md) for detailed development guidance.\n\n## License\n\nGPL-3.0 - See LICENSE file for details\n\n## Links\n\n- [DataHaven Website](https://datahaven.xyz/)\n- [DataHaven Documentation](https://docs.datahaven.xyz/)\n- [StorageHub Repository](https://github.com/Moonsong-Labs/storage-hub)\n- [EigenLayer Documentation](https://docs.eigenlayer.xyz/)\n- [Substrate Documentation](https://docs.substrate.io/)\n- [Snowbridge Documentation](https://docs.snowbridge.network/)\n- [Foundry Book](https://book.getfoundry.sh/)\n- [Polkadot-API Documentation](https://papi.how/)\n",
      "stars_today": 518
    },
    {
      "id": 615869301,
      "name": "LocalAI",
      "full_name": "mudler/LocalAI",
      "description": ":robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, MCP, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference",
      "html_url": "https://github.com/mudler/LocalAI",
      "stars": 41913,
      "forks": 3432,
      "language": "Go",
      "topics": [
        "ai",
        "api",
        "audio-generation",
        "decentralized",
        "distributed",
        "gemma",
        "image-generation",
        "libp2p",
        "llama",
        "llm",
        "mamba",
        "mcp",
        "mistral",
        "musicgen",
        "object-detection",
        "rerank",
        "rwkv",
        "stable-diffusion",
        "text-generation",
        "tts"
      ],
      "created_at": "2023-03-18T22:58:02Z",
      "updated_at": "2026-01-16T00:59:41Z",
      "pushed_at": "2026-01-15T21:53:17Z",
      "open_issues": 153,
      "owner": {
        "login": "mudler",
        "avatar_url": "https://avatars.githubusercontent.com/u/2420543?v=4"
      },
      "readme": "<h1 align=\"center\">\n  <br>\n  <img width=\"300\" src=\"./core/http/static/logo.png\"> <br>\n<br>\n</h1>\n\n<p align=\"center\">\n<a href=\"https://github.com/go-skynet/LocalAI/fork\" target=\"blank\">\n<img src=\"https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge\" alt=\"LocalAI forks\"/>\n</a>\n<a href=\"https://github.com/go-skynet/LocalAI/stargazers\" target=\"blank\">\n<img src=\"https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge\" alt=\"LocalAI stars\"/>\n</a>\n<a href=\"https://github.com/go-skynet/LocalAI/pulls\" target=\"blank\">\n<img src=\"https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge\" alt=\"LocalAI pull-requests\"/>\n</a>\n<a href='https://github.com/go-skynet/LocalAI/releases'>\n<img src='https://img.shields.io/github/release/go-skynet/LocalAI?&label=Latest&style=for-the-badge'>\n</a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://hub.docker.com/r/localai/localai\" target=\"blank\">\n<img src=\"https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker\" alt=\"LocalAI Docker hub\"/>\n</a>\n<a href=\"https://quay.io/repository/go-skynet/local-ai?tab=tags&tag=latest\" target=\"blank\">\n<img src=\"https://img.shields.io/badge/quay.io-images-important.svg?\" alt=\"LocalAI Quay.io\"/>\n</a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://twitter.com/LocalAI_API\" target=\"blank\">\n<img src=\"https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&logo=X&logoColor=white&label=LocalAI_API\" alt=\"Follow LocalAI_API\"/>\n</a>\n<a href=\"https://discord.gg/uJAeKSAGDy\" target=\"blank\">\n<img src=\"https://img.shields.io/badge/dynamic/json?color=blue&label=Discord&style=for-the-badge&query=approximate_member_count&url=https%3A%2F%2Fdiscordapp.com%2Fapi%2Finvites%2FuJAeKSAGDy%3Fwith_counts%3Dtrue&logo=discord\" alt=\"Join LocalAI Discord Community\"/>\n</a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/5539\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/5539\" alt=\"mudler%2FLocalAI | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n> :bulb: Get help - [â“FAQ](https://localai.io/faq/) [ğŸ’­Discussions](https://github.com/go-skynet/LocalAI/discussions) [:speech_balloon: Discord](https://discord.gg/uJAeKSAGDy) [:book: Documentation website](https://localai.io/)\n>\n> [ğŸ’» Quickstart](https://localai.io/basics/getting_started/) [ğŸ–¼ï¸ Models](https://models.localai.io/) [ğŸš€ Roadmap](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap) [ğŸ›« Examples](https://github.com/mudler/LocalAI-examples) Try on \n[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white)](https://t.me/localaiofficial_bot)\n\n[![tests](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml)[![Build and Release](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml)[![build container images](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml)[![Bump dependencies](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml)[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai)](https://artifacthub.io/packages/search?repo=localai)\n\n**LocalAI** is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by [Ettore Di Giacinto](https://github.com/mudler).\n\n\n## ğŸ“šğŸ†• Local Stack Family\n\nğŸ†• LocalAI is now part of a comprehensive suite of AI tools designed to work together:\n\n<table>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <a href=\"https://github.com/mudler/LocalAGI\">\n        <img src=\"https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png\" width=\"300\" alt=\"LocalAGI Logo\">\n      </a>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <h3><a href=\"https://github.com/mudler/LocalAGI\">LocalAGI</a></h3>\n      <p>A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI's Responses API, enhanced with advanced agentic capabilities.</p>\n    </td>\n  </tr>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <a href=\"https://github.com/mudler/LocalRecall\">\n        <img src=\"https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png\" width=\"300\" alt=\"LocalRecall Logo\">\n      </a>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <h3><a href=\"https://github.com/mudler/LocalRecall\">LocalRecall</a></h3>\n      <p>A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.</p>\n    </td>\n  </tr>\n</table>\n\n## Screenshots / Video\n\n### Youtube video\n\n<h1 align=\"center\">\n  <br>\n  <a href=\"https://www.youtube.com/watch?v=PDqYhB9nNHA\" target=\"_blank\"> <img width=\"300\" src=\"https://img.youtube.com/vi/PDqYhB9nNHA/0.jpg\"> </a><br>\n<br>\n</h1>\n\n\n### Screenshots\n\n| Talk Interface | Generate Audio |\n| --- | --- |\n| ![Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk](./docs/assets/images/screenshots/screenshot_tts.png) | ![Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low](./docs/assets/images/screenshots/screenshot_tts.png) |\n\n| Models Overview | Generate Images |\n| --- | --- |\n| ![Screenshot 2025-03-31 at 12-01-20 LocalAI - Models](./docs/assets/images/screenshots/screenshot_gallery.png) | ![Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev](./docs/assets/images/screenshots/screenshot_image.png) |\n\n| Chat Interface | Home |\n| --- | --- |\n| ![Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5](./docs/assets/images/screenshots/screenshot_chat.png) | ![Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)](./docs/assets/images/screenshots/screenshot_home.png) |\n\n| Login | Swarm |\n| --- | --- |\n|![Screenshot 2025-03-31 at 12-09-59 ](./docs/assets/images/screenshots/screenshot_login.png) | ![Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard](./docs/assets/images/screenshots/screenshot_p2p.png) |\n\n## ğŸ’» Quickstart\n\n> âš ï¸ **Note:** The `install.sh` script is currently experiencing issues due to the heavy changes currently undergoing in LocalAI and may produce broken or misconfigured installations. Please use Docker installation (see below) or manual binary installation until [issue #8032](https://github.com/mudler/LocalAI/issues/8032) is resolved.\n\nRun the installer script:\n\n```bash\n# Basic installation\ncurl https://localai.io/install.sh | sh\n```\n\nFor more installation options, see [Installer Options](https://localai.io/installation/).\n\n### macOS Download:\n\n<a href=\"https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg\">\n  <img src=\"https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&logo=apple&logoColor=white\" alt=\"Download LocalAI for macOS\"/>\n</a>\n\n> Note: the DMGs are not signed by Apple as quarantined. See https://github.com/mudler/LocalAI/issues/6268 for a workaround, fix is tracked here: https://github.com/mudler/LocalAI/issues/6244\n\n### Containers (Docker, podman, ...)\n\n> **ğŸ’¡ Docker Run vs Docker Start**\n> \n> - `docker run` creates and starts a new container. If a container with the same name already exists, this command will fail.\n> - `docker start` starts an existing container that was previously created with `docker run`.\n> \n> If you've already run LocalAI before and want to start it again, use: `docker start -i local-ai`\n\n#### CPU only image:\n\n```bash\ndocker run -ti --name local-ai -p 8080:8080 localai/localai:latest\n```\n\n#### NVIDIA GPU Images:\n\n```bash\n# CUDA 13.0\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-13\n\n# CUDA 12.0\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12\n\n# NVIDIA Jetson (L4T) ARM64\n# CUDA 12 (for Nvidia AGX Orin and similar platforms)\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64\n\n# CUDA 13 (for Nvidia DGX Spark)\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64-cuda-13\n```\n\n#### AMD GPU Images (ROCm):\n\n```bash\ndocker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas\n```\n\n#### Intel GPU Images (oneAPI):\n\n```bash\ndocker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel\n```\n\n#### Vulkan GPU Images:\n\n```bash\ndocker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan\n```\n\n#### AIO Images (pre-downloaded models):\n\n```bash\n# CPU version\ndocker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu\n\n# NVIDIA CUDA 13 version\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-13\n\n# NVIDIA CUDA 12 version\ndocker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12\n\n# Intel GPU version\ndocker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel\n\n# AMD GPU version\ndocker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas\n```\n\nFor more information about the AIO images and pre-downloaded models, see [Container Documentation](https://localai.io/basics/container/).\n\nTo load models:\n\n```bash\n# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)\nlocal-ai run llama-3.2-1b-instruct:q4_k_m\n# Start LocalAI with the phi-2 model directly from huggingface\nlocal-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf\n# Install and run a model from the Ollama OCI registry\nlocal-ai run ollama://gemma:2b\n# Run a model from a configuration file\nlocal-ai run https://gist.githubusercontent.com/.../phi-2.yaml\n# Install and run a model from a standard OCI registry (e.g., Docker Hub)\nlocal-ai run oci://localai/phi-2:latest\n```\n\n> âš¡ **Automatic Backend Detection**: When you install models from the gallery or YAML files, LocalAI automatically detects your system's GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see [GPU Acceleration](https://localai.io/features/gpu-acceleration/#automatic-backend-detection).\n\nFor more information, see [ğŸ’» Getting started](https://localai.io/basics/getting_started/index.html), if you are interested in our roadmap items and future enhancements, you can see the [Issues labeled as Roadmap here](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)\n\n## ğŸ“° Latest project news\n\n- December 2025: [Dynamic Memory Resource reclaimer](https://github.com/mudler/LocalAI/pull/7583), [Automatic fitting of models to multiple GPUS(llama.cpp)](https://github.com/mudler/LocalAI/pull/7584), [Added Vibevoice backend](https://github.com/mudler/LocalAI/pull/7494)\n- November 2025: Major improvements to the UX. Among these: [Import models via URL](https://github.com/mudler/LocalAI/pull/7245) and [Multiple chats and history](https://github.com/mudler/LocalAI/pull/7325)\n- October 2025: ğŸ”Œ [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) support added for agentic capabilities with external tools\n- September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.\n- August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with `development` suffix in the gallery ): https://github.com/mudler/LocalAI/pull/6049 https://github.com/mudler/LocalAI/pull/6119 https://github.com/mudler/LocalAI/pull/6121 https://github.com/mudler/LocalAI/pull/6060\n- July/August 2025: ğŸ” [Object Detection](https://localai.io/features/object-detection/) added to the API featuring [rf-detr](https://github.com/roboflow/rf-detr)\n- July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. [Read the release notes](https://github.com/mudler/LocalAI/releases/tag/v3.2.0)\n- June 2025: [Backend management](https://github.com/mudler/LocalAI/pull/5607) has been added. Attention: extras images are going to be deprecated from the next release! Read [the backend management PR](https://github.com/mudler/LocalAI/pull/5607).\n- May 2025: [Audio input](https://github.com/mudler/LocalAI/pull/5466) and [Reranking](https://github.com/mudler/LocalAI/pull/5396) in llama.cpp backend, [Realtime API](https://github.com/mudler/LocalAI/pull/5392),  Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).\n- May 2025: Important: image name changes [See release](https://github.com/mudler/LocalAI/releases/tag/v2.29.0)\n- Apr 2025: Rebrand, WebUI enhancements\n- Apr 2025: [LocalAGI](https://github.com/mudler/LocalAGI) and [LocalRecall](https://github.com/mudler/LocalRecall) join the LocalAI family stack.\n- Apr 2025: WebUI overhaul, AIO images updates\n- Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images\n- Jan 2025: LocalAI model release: https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3, SANA support in diffusers: https://github.com/mudler/LocalAI/pull/4603\n- Dec 2024: stablediffusion.cpp backend (ggml) added ( https://github.com/mudler/LocalAI/pull/4289 )\n- Nov 2024: Bark.cpp backend added ( https://github.com/mudler/LocalAI/pull/4287 )\n- Nov 2024: Voice activity detection models (**VAD**) added to the API: https://github.com/mudler/LocalAI/pull/4204\n- Oct 2024: examples moved to [LocalAI-examples](https://github.com/mudler/LocalAI-examples)\n- Aug 2024:  ğŸ†• FLUX-1, [P2P Explorer](https://explorer.localai.io)\n- July 2024: ğŸ”¥ğŸ”¥ ğŸ†• P2P Dashboard, LocalAI Federated mode and AI Swarms: https://github.com/mudler/LocalAI/pull/2723. P2P Global community pools: https://github.com/mudler/LocalAI/issues/3113\n- May 2024: ğŸ”¥ğŸ”¥ Decentralized P2P llama.cpp:  https://github.com/mudler/LocalAI/pull/2343 (peer2peer llama.cpp!) ğŸ‘‰ Docs  https://localai.io/features/distribute/\n- May 2024: ğŸ”¥ğŸ”¥ Distributed inferencing: https://github.com/mudler/LocalAI/pull/2324\n- April 2024: Reranker API: https://github.com/mudler/LocalAI/pull/2121\n\nRoadmap items: [List of issues](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)\n\n## ğŸš€ [Features](https://localai.io/features/)\n\n- ğŸ§© [Backend Gallery](https://localai.io/backends/): Install/remove backends on the fly, powered by OCI images â€” fully customizable and API-driven.\n- ğŸ“– [Text generation with GPTs](https://localai.io/features/text-generation/) (`llama.cpp`, `transformers`, `vllm` ... [:book: and more](https://localai.io/model-compatibility/index.html#model-compatibility-table))\n- ğŸ—£ [Text to Audio](https://localai.io/features/text-to-audio/)\n- ğŸ”ˆ [Audio to Text](https://localai.io/features/audio-to-text/) (Audio transcription with `whisper.cpp`)\n- ğŸ¨ [Image generation](https://localai.io/features/image-generation)\n- ğŸ”¥ [OpenAI-alike tools API](https://localai.io/features/openai-functions/) \n- ğŸ§  [Embeddings generation for vector databases](https://localai.io/features/embeddings/)\n- âœï¸ [Constrained grammars](https://localai.io/features/constrained_grammars/)\n- ğŸ–¼ï¸ [Download Models directly from Huggingface ](https://localai.io/models/)\n- ğŸ¥½ [Vision API](https://localai.io/features/gpt-vision/)\n- ğŸ” [Object Detection](https://localai.io/features/object-detection/)\n- ğŸ“ˆ [Reranker API](https://localai.io/features/reranker/)\n- ğŸ†•ğŸ–§ [P2P Inferencing](https://localai.io/features/distribute/)\n- ğŸ†•ğŸ”Œ [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) - Agentic capabilities with external tools and [LocalAGI's Agentic capabilities](https://github.com/mudler/LocalAGI)\n- ğŸ”Š Voice activity detection (Silero-VAD support)\n- ğŸŒ Integrated WebUI!\n\n## ğŸ§© Supported Backends & Acceleration\n\nLocalAI supports a comprehensive range of AI backends with multiple acceleration options:\n\n### Text Generation & Language Models\n| Backend | Description | Acceleration Support |\n|---------|-------------|---------------------|\n| **llama.cpp** | LLM inference in C/C++ | CUDA 12/13, ROCm, Intel SYCL, Vulkan, Metal, CPU |\n| **vLLM** | Fast LLM inference with PagedAttention | CUDA 12/13, ROCm, Intel |\n| **transformers** | HuggingFace transformers framework | CUDA 12/13, ROCm, Intel, CPU |\n| **exllama2** | GPTQ inference library | CUDA 12/13 |\n| **MLX** | Apple Silicon LLM inference | Metal (M1/M2/M3+) |\n| **MLX-VLM** | Apple Silicon Vision-Language Models | Metal (M1/M2/M3+) |\n\n### Audio & Speech Processing\n| Backend | Description | Acceleration Support |\n|---------|-------------|---------------------|\n| **whisper.cpp** | OpenAI Whisper in C/C++ | CUDA 12/13, ROCm, Intel SYCL, Vulkan, CPU |\n| **faster-whisper** | Fast Whisper with CTranslate2 | CUDA 12/13, ROCm, Intel, CPU |\n| **bark** | Text-to-audio generation | CUDA 12/13, ROCm, Intel |\n| **bark-cpp** | C++ implementation of Bark | CUDA, Metal, CPU |\n| **coqui** | Advanced TTS with 1100+ languages | CUDA 12/13, ROCm, Intel, CPU |\n| **kokoro** | Lightweight TTS model | CUDA 12/13, ROCm, Intel, CPU |\n| **chatterbox** | Production-grade TTS | CUDA 12/13, CPU |\n| **piper** | Fast neural TTS system | CPU |\n| **kitten-tts** | Kitten TTS models | CPU |\n| **silero-vad** | Voice Activity Detection | CPU |\n| **neutts** | Text-to-speech with voice cloning | CUDA 12/13, ROCm, CPU |\n| **vibevoice** | Real-time TTS with voice cloning | CUDA 12/13, ROCm, Intel, CPU |\n| **pocket-tts** | Lightweight CPU-based TTS | CUDA 12/13, ROCm, Intel, CPU |\n\n### Image & Video Generation\n| Backend | Description | Acceleration Support |\n|---------|-------------|---------------------|\n| **stablediffusion.cpp** | Stable Diffusion in C/C++ | CUDA 12/13, Intel SYCL, Vulkan, CPU |\n| **diffusers** | HuggingFace diffusion models | CUDA 12/13, ROCm, Intel, Metal, CPU |\n\n### Specialized AI Tasks\n| Backend | Description | Acceleration Support |\n|---------|-------------|---------------------|\n| **rfdetr** | Real-time object detection | CUDA 12/13, Intel, CPU |\n| **rerankers** | Document reranking API | CUDA 12/13, ROCm, Intel, CPU |\n| **local-store** | Vector database | CPU |\n| **huggingface** | HuggingFace API integration | API-based |\n\n### Hardware Acceleration Matrix\n\n| Acceleration Type | Supported Backends | Hardware Support |\n|-------------------|-------------------|------------------|\n| **NVIDIA CUDA 12** | All CUDA-compatible backends | Nvidia hardware |\n| **NVIDIA CUDA 13** | All CUDA-compatible backends | Nvidia hardware |\n| **AMD ROCm** | llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts, vibevoice, pocket-tts | AMD Graphics |\n| **Intel oneAPI** | llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark, vibevoice, pocket-tts | Intel Arc, Intel iGPUs |\n| **Apple Metal** | llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp | Apple M1/M2/M3+ |\n| **Vulkan** | llama.cpp, whisper, stablediffusion | Cross-platform GPUs |\n| **NVIDIA Jetson (CUDA 12)** | llama.cpp, whisper, stablediffusion, diffusers, rfdetr | ARM64 embedded AI (AGX Orin, etc.) |\n| **NVIDIA Jetson (CUDA 13)** | llama.cpp, whisper, stablediffusion, diffusers, rfdetr | ARM64 embedded AI (DGX Spark) |\n| **CPU Optimized** | All backends | AVX/AVX2/AVX512, quantization support |\n\n### ğŸ”— Community and integrations\n\nBuild and deploy custom containers:\n- https://github.com/sozercan/aikit\n\nWebUIs:\n- https://github.com/Jirubizu/localai-admin\n- https://github.com/go-skynet/LocalAI-frontend\n- QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) https://github.com/reid41/QA-Pilot\n\nAgentic Libraries:\n- https://github.com/mudler/cogito\n\nMCPs:\n- https://github.com/mudler/MCPs\n\nModel galleries\n- https://github.com/go-skynet/model-gallery\n\nVoice:\n- https://github.com/richiejp/VoxInput\n\nOther:\n- Helm chart https://github.com/go-skynet/helm-charts\n- VSCode extension https://github.com/badgooooor/localai-vscode-plugin\n- Langchain: https://python.langchain.com/docs/integrations/providers/localai/\n- Terminal utility https://github.com/djcopley/ShellOracle\n- Local Smart assistant https://github.com/mudler/LocalAGI\n- Home Assistant https://github.com/sammcj/homeassistant-localai / https://github.com/drndos/hass-openai-custom-conversation / https://github.com/valentinfrlch/ha-gpt4vision\n- Discord bot https://github.com/mudler/LocalAGI/tree/main/examples/discord\n- Slack bot https://github.com/mudler/LocalAGI/tree/main/examples/slack\n- Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) https://github.com/reid41/shell-pilot\n- Telegram bot https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot\n- Another Telegram Bot https://github.com/JackBekket/Hellper\n- Auto-documentation https://github.com/JackBekket/Reflexia\n- Github bot which answer on issues, with code and documentation as context https://github.com/JackBekket/GitHelper\n- Github Actions: https://github.com/marketplace/actions/start-localai\n- Examples: https://github.com/mudler/LocalAI/tree/master/examples/\n  \n\n### ğŸ”— Resources\n\n- [LLM finetuning guide](https://localai.io/docs/advanced/fine-tuning/)\n- [How to build locally](https://localai.io/basics/build/index.html)\n- [How to install in Kubernetes](https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes)\n- [Projects integrating LocalAI](https://localai.io/docs/integrations/)\n- [How tos section](https://io.midori-ai.xyz/howtos/) (curated by our community)\n\n## :book: ğŸ¥ [Media, Blogs, Social](https://localai.io/basics/news/#media-blogs-social)\n\n- [Run Visual studio code with LocalAI (SUSE)](https://www.suse.com/c/running-ai-locally/)\n- ğŸ†• [Run LocalAI on Jetson Nano Devkit](https://mudler.pm/posts/local-ai-jetson-nano-devkit/)\n- [Run LocalAI on AWS EKS with Pulumi](https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/)\n- [Run LocalAI on AWS](https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance)\n- [Create a slackbot for teams and OSS projects that answer to documentation](https://mudler.pm/posts/smart-slackbot-for-teams/)\n- [LocalAI meets k8sgpt](https://www.youtube.com/watch?v=PKrDNuJ_dfE)\n- [Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All](https://mudler.pm/posts/localai-question-answering/)\n- [Tutorial to use k8sgpt with LocalAI](https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65)\n\n## Citation\n\nIf you utilize this repository, data in a downstream project, please consider citing it with:\n\n```\n@misc{localai,\n  author = {Ettore Di Giacinto},\n  title = {LocalAI: The free, Open source OpenAI alternative},\n  year = {2023},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/go-skynet/LocalAI}},\n```\n\n## â¤ï¸ Sponsors\n\n> Do you find LocalAI useful?\n\nSupport the project by becoming [a backer or sponsor](https://github.com/sponsors/mudler). Your logo will show up here with a link to your website.\n\nA huge thank you to our generous sponsors who support this project covering CI expenses, and our [Sponsor list](https://github.com/sponsors/mudler):\n\n<p align=\"center\">\n  <a href=\"https://www.spectrocloud.com/\" target=\"blank\">\n    <img height=\"200\" src=\"https://github.com/user-attachments/assets/72eab1dd-8b93-4fc0-9ade-84db49f24962\">\n  </a>\n  <a href=\"https://www.premai.io/\" target=\"blank\">\n    <img height=\"200\" src=\"https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6\"> <br>\n  </a>\n</p>\n\n### Individual sponsors\n\nA special thanks to individual sponsors that contributed to the project, a full list is in [Github](https://github.com/sponsors/mudler) and [buymeacoffee](https://buymeacoffee.com/mudler), a special shout out goes to [drikster80](https://github.com/drikster80) for being generous. Thank you everyone!\n\n## ğŸŒŸ Star history\n\n[![LocalAI Star history Chart](https://api.star-history.com/svg?repos=go-skynet/LocalAI&type=Date)](https://star-history.com/#go-skynet/LocalAI&Date)\n\n## ğŸ“– License\n\nLocalAI is a community-driven project created by [Ettore Di Giacinto](https://github.com/mudler/).\n\nMIT - Author Ettore Di Giacinto <mudler@localai.io>\n\n## ğŸ™‡ Acknowledgements\n\nLocalAI couldn't have been built without the help of great software already available from the community. Thank you!\n\n- [llama.cpp](https://github.com/ggerganov/llama.cpp)\n- https://github.com/tatsu-lab/stanford_alpaca\n- https://github.com/cornelk/llama-go for the initial ideas\n- https://github.com/antimatter15/alpaca.cpp\n- https://github.com/EdVince/Stable-Diffusion-NCNN\n- https://github.com/ggerganov/whisper.cpp\n- https://github.com/rhasspy/piper\n\n## ğŸ¤— Contributors\n\nThis is a community project, a special thanks to our contributors! ğŸ¤—\n<a href=\"https://github.com/go-skynet/LocalAI/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=go-skynet/LocalAI\" />\n</a>\n",
      "stars_today": 390
    },
    {
      "id": 753490180,
      "name": "daytona",
      "full_name": "daytonaio/daytona",
      "description": "Daytona is a Secure and Elastic Infrastructure for Running AI-Generated Code",
      "html_url": "https://github.com/daytonaio/daytona",
      "stars": 46773,
      "forks": 3926,
      "language": "TypeScript",
      "topics": [
        "agentic-workflow",
        "ai",
        "ai-agents",
        "ai-runtime",
        "ai-sandboxes",
        "code-execution",
        "code-interpreter",
        "developer-tools"
      ],
      "created_at": "2024-02-06T08:21:20Z",
      "updated_at": "2026-01-15T22:02:59Z",
      "pushed_at": "2026-01-15T21:25:50Z",
      "open_issues": 299,
      "owner": {
        "login": "daytonaio",
        "avatar_url": "https://avatars.githubusercontent.com/u/130513197?v=4"
      },
      "readme": "<div align=\"center\">\n\n[![Documentation](https://img.shields.io/github/v/release/daytonaio/docs?label=Docs&color=23cc71)](https://www.daytona.io/docs)\n![License](https://img.shields.io/badge/License-AGPL--3-blue)\n[![Go Report Card](https://goreportcard.com/badge/github.com/daytonaio/daytona)](https://goreportcard.com/report/github.com/daytonaio/daytona)\n[![Issues - daytona](https://img.shields.io/github/issues/daytonaio/daytona)](https://github.com/daytonaio/daytona/issues)\n![GitHub Release](https://img.shields.io/github/v/release/daytonaio/daytona)\n\n</div>\n\n&nbsp;\n\n<div align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-white.png\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png\">\n    <img alt=\"Daytona logo\" src=\"https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png\" width=\"50%\">\n  </picture>\n</div>\n\n<h3 align=\"center\">\n  Run AI Code.\n  <br/>\n  Secure and Elastic Infrastructure for\n  Running Your AI-Generated Code.\n</h3>\n\n<p align=\"center\">\n    <a href=\"https://www.daytona.io/docs\"> Documentation </a>Â·\n    <a href=\"https://github.com/daytonaio/daytona/issues/new?assignees=&labels=bug&projects=&template=bug_report.md&title=%F0%9F%90%9B+Bug+Report%3A+\"> Report Bug </a>Â·\n    <a href=\"https://github.com/daytonaio/daytona/issues/new?assignees=&labels=enhancement&projects=&template=feature_request.md&title=%F0%9F%9A%80+Feature%3A+\"> Request Feature </a>Â·\n    <a href=\"https://go.daytona.io/slack\"> Join our Slack </a>Â·\n    <a href=\"https://x.com/daytonaio\"> Connect on X </a>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://www.producthunt.com/posts/daytona-2?embed=true&utm_source=badge-top-post-badge&utm_medium=badge&utm_souce=badge-daytona&#0045;2\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=957617&theme=neutral&period=daily&t=1746176740150\" alt=\"Daytona&#0032; - Secure&#0032;and&#0032;elastic&#0032;infra&#0032;for&#0032;running&#0032;your&#0032;AI&#0045;generated&#0032;code&#0046; | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n    <a href=\"https://www.producthunt.com/posts/daytona-2?embed=true&utm_source=badge-top-post-topic-badge&utm_medium=badge&utm_souce=badge-daytona&#0045;2\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=957617&theme=neutral&period=monthly&topic_id=237&t=1746176740150\" alt=\"Daytona&#0032; - Secure&#0032;and&#0032;elastic&#0032;infra&#0032;for&#0032;running&#0032;your&#0032;AI&#0045;generated&#0032;code&#0046; | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n</p>\n\n---\n\n## Installation\n\n### Python SDK\n\n```bash\npip install daytona\n```\n\n### TypeScript SDK\n\n```bash\nnpm install @daytonaio/sdk\n```\n\n---\n\n## Features\n\n- **Lightning-Fast Infrastructure**: Sub-90ms Sandbox creation from code to execution.\n- **Separated & Isolated Runtime**: Execute AI-generated code with zero risk to your infrastructure.\n- **Massive Parallelization for Concurrent AI Workflows**: Fork Sandbox filesystem and memory state (Coming soon!)\n- **Programmatic Control**: File, Git, LSP, and Execute API\n- **Unlimited Persistence**: Your Sandboxes can live forever\n- **OCI/Docker Compatibility**: Use any OCI/Docker image to create a Sandbox\n\n---\n\n## Quick Start\n\n1. Create an account at https://app.daytona.io\n1. Generate a [new API key](https://app.daytona.io/dashboard/keys)\n1. Follow the [Getting Started docs](https://www.daytona.io/docs/getting-started/) to start using the Daytona SDK\n\n## Creating your first Sandbox\n\n### Python SDK\n\n```py\nfrom daytona import Daytona, DaytonaConfig, CreateSandboxBaseParams\n\n# Initialize the Daytona client\ndaytona = Daytona(DaytonaConfig(api_key=\"YOUR_API_KEY\"))\n\n# Create the Sandbox instance\nsandbox = daytona.create(CreateSandboxBaseParams(language=\"python\"))\n\n# Run code securely inside the Sandbox\nresponse = sandbox.process.code_run('print(\"Sum of 3 and 4 is \" + str(3 + 4))')\nif response.exit_code != 0:\n    print(f\"Error running code: {response.exit_code} {response.result}\")\nelse:\n    print(response.result)\n\n# Clean up the Sandbox\ndaytona.delete(sandbox)\n```\n\n### Typescript SDK\n\n```jsx\nimport { Daytona } from '@daytonaio/sdk'\n\nasync function main() {\n  // Initialize the Daytona client\n  const daytona = new Daytona({\n    apiKey: 'YOUR_API_KEY',\n  })\n\n  let sandbox\n  try {\n    // Create the Sandbox instance\n    sandbox = await daytona.create({\n      language: 'typescript',\n    })\n    // Run code securely inside the Sandbox\n    const response = await sandbox.process.codeRun('console.log(\"Sum of 3 and 4 is \" + (3 + 4))')\n    if (response.exitCode !== 0) {\n      console.error('Error running code:', response.exitCode, response.result)\n    } else {\n      console.log(response.result)\n    }\n  } catch (error) {\n    console.error('Sandbox flow error:', error)\n  } finally {\n    if (sandbox) await daytona.delete(sandbox)\n  }\n}\n\nmain().catch(console.error)\n```\n\n---\n\n## Contributing\n\nDaytona is Open Source under the [GNU AFFERO GENERAL PUBLIC LICENSE](LICENSE), and is the [copyright of its contributors](NOTICE). If you would like to contribute to the software, read the Developer Certificate of Origin Version 1.1 (https://developercertificate.org/). Afterwards, navigate to the [contributing guide](CONTRIBUTING.md) to get started.\n",
      "stars_today": 377
    },
    {
      "id": 1033778670,
      "name": "AionUi",
      "full_name": "iOfficeAI/AionUi",
      "description": "Free, local, open-source Cowork for Gemini CLI, Claude Code, Codex, Qwen Code, Goose Cli, Auggie, and more | ğŸŒŸ Star if you like it!",
      "html_url": "https://github.com/iOfficeAI/AionUi",
      "stars": 3887,
      "forks": 322,
      "language": "TypeScript",
      "topics": [
        "acp",
        "ai",
        "ai-agent",
        "banana",
        "chat",
        "chatbot",
        "claude-code",
        "codex",
        "cowork",
        "excel",
        "gemini",
        "gemini-cli",
        "gemini-pro",
        "llm",
        "multi-agent",
        "nano-banana",
        "office",
        "qwen-code",
        "skills",
        "webui"
      ],
      "created_at": "2025-08-07T10:29:51Z",
      "updated_at": "2026-01-16T01:06:06Z",
      "pushed_at": "2026-01-15T15:33:37Z",
      "open_issues": 18,
      "owner": {
        "login": "iOfficeAI",
        "avatar_url": "https://avatars.githubusercontent.com/u/145246968?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"./resources/aionui-banner-1 copy.png\" alt=\"AionUi - Cowork with Your CLI AI Agent\" width=\"100%\">\n</p>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/github/v/release/iOfficeAI/AionUi?style=flat-square&color=32CD32\" alt=\"Version\">\n  &nbsp;\n  <img src=\"https://img.shields.io/badge/license-Apache--2.0-32CD32?style=flat-square&logo=apache&logoColor=white\" alt=\"License\">\n  &nbsp;\n  <img src=\"https://img.shields.io/badge/platform-macOS%20%7C%20Windows%20%7C%20Linux-6C757D?style=flat-square&logo=linux&logoColor=white\" alt=\"Platform\">\n</p>\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/15423\" target=\"_blank\">\n    <img src=\"https://trendshift.io/api/badge/repositories/15423\" alt=\"GitHub Trending\" height=\"80\">\n  </a>\n</p>\n\n---\n\n<p align=\"center\">\n  <strong>ğŸš€ Cowork with Your AI, Gemini CLI, Claude Code, Codex, Qwen Code, Goose CLI, Auggie, and more</strong><br>\n  <em>User-friendly | Visual graphical interface | Multi-model support | Local data security</em>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/iOfficeAI/AionUi/releases\">\n    <img src=\"https://img.shields.io/badge/â¬‡ï¸%20Download%20Now-Latest%20Release-32CD32?style=for-the-badge&logo=github&logoColor=white\" alt=\"Download Latest Release\" height=\"50\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <strong>English</strong> | <a href=\"./readme_ch.md\">ç®€ä½“ä¸­æ–‡</a> | <a href=\"./readme_jp.md\">æ—¥æœ¬èª</a> | <a href=\"https://www.aionui.com\" target=\"_blank\">Official Website</a> | <a href=\"https://twitter.com/AionUI\" target=\"_blank\">Twitter</a>\n</p>\n\n---\n\n## ğŸ“‹ Quick Navigation\n\n<p align=\"center\">\n\n[âœ¨ What Can AionUi Do?](#âœ¨-what-can-aionui-do) Â·\n[ğŸ¤” Why Choose AionUi?](#ğŸ¤”-why-choose-aionui) Â·\n[âœ¨ Core Features](#âœ¨-core-features) Â·\n[ğŸš€ Quick Start](#ğŸš€-quick-start) Â·\n[ğŸ“– Detailed Usage Guide](#ğŸ“–-detailed-usage-guide) Â·\n[ğŸ’¬ Community](#ğŸ¤-community--support)\n\n</p>\n\n---\n\n## âœ¨ What Can AionUi Do?\n\n<p align=\"center\">\n  <img src=\"./resources/offica-ai BANNER-function copy.png\" alt=\"AionUi - Cowork with Your CLI AI Agent\" width=\"800\">\n</p>\n\n### ğŸ¤– **Multi-Agent Mode - Cowork for Your Command-Line AI Tools, Unified Graphical Interface**\n\n_If you have installed command-line tools like Gemini CLI, Claude Code, CodeX, Qwen Code, Goose AI, Augment Code, AionUi can automatically detect them and provide a unified graphical interface_\n\n- âœ… **Auto Detection + Unified Interface** - Automatically recognizes local CLI tools, provides a unified graphical interface, say goodbye to command line\n- âœ… **Local Storage + Multi-Session** - Conversations saved locally, supports multiple parallel sessions, each session with independent context\n\n<p align=\"center\">\n  <img src=\"./resources/acp home page.gif\" alt=\"Multi-Agent Mode Demo\" width=\"800\">\n</p>\n\n---\n\n### ğŸ“ **Smart File Management (AI Cowork)**\n\n_Batch renaming, automatic organization, smart classification, file merging_\n\n- **Auto Organize**: Intelligently identify content and auto-classify, keeping folders tidy.\n- **Efficient Batch**: One-click rename, merge files, say goodbye to tedious manual tasks.\n\n<p align=\"center\">\n  <img src=\"./resources/aionui sort file.gif\" alt=\"Smart File Management Demo\" width=\"800\">\n</p>\n\n---\n\n### ğŸ“„ **Preview Panel - Quickly View AI-Generated Results**\n\n_Supports 9+ formats of visual preview (PDF, Word, Excel, PPT, code, Markdown, images, HTML, Diff, etc.)_\n\n- âœ… **View Results Instantly** - After AI generates files, view preview immediately without switching apps\n- âœ… **Real-time Tracking + Editable** - Automatically tracks file changes, editor and preview sync intelligently; supports real-time editing of Markdown, code, HTML, WYSIWYG\n\n<p align=\"center\">\n  <img src=\"./resources/preview.gif\" alt=\"Preview Panel Demo\" width=\"800\">\n</p>\n\n---\n\n### ğŸ¨ **AI Image Generation & Editing**\n\n_Intelligent image generation, editing, and recognition, powered by Gemini_\n\n<p align=\"center\">\n  <img src=\"./resources/Image_Generation.gif\" alt=\"AI Image Generation Demo\" width=\"800\">\n</p>\n\n---\n\n### ğŸ’¬ **Multi-Task Parallel Processing**\n\n_Open multiple conversations, tasks don't get mixed up, independent memory, double efficiency_\n\n<p align=\"center\">\n  <img src=\"./resources/multichat-side-by-side.gif\" alt=\"Conversation Management Demo\" width=\"800\">\n</p>\n\n---\n\n### ğŸŒ **Access Anywhere - WebUI Mode**\n\n_Remotely control your AI tools - Access AionUi from any device on the network! Securely control local Gemini CLI, Claude Code, Codex, and other tools, data never leaves your device_\n\n```bash\n# Basic startup\nAionUi --webui\n\n# Remote access (accessible from other devices on the local network)\nAionUi --webui --remote\n```\n\n> ğŸ’¡ **Need detailed configuration guide?** Check out the [WebUI Configuration Tutorial](https://github.com/iOfficeAI/AionUi/wiki/WebUI-Configuration-Guide) - includes complete startup commands for all platforms\n\n<p align=\"center\">\n  <img src=\"./resources/webui banner.png\" alt=\"WebUI Remote Access Demo\" width=\"800\">\n</p>\n\n---\n\n## ğŸ¤” Why Choose AionUi?\n\n**Just like Claude Cowork makes Claude Code easier to use, AionUi is the Cowork platform for all your command-line AI tools**\n\nGemini CLI, Claude Code, Codex, Qwen Code are powerful, but share common pain points: conversations can't be saved, single-session limitations, cumbersome file operations, and only support a single model.\n\nAionUi provides unified **Cowork capabilities** for these command-line tools:\n\n- ğŸ¯ **Unified Platform** - One interface to manage all command-line AI tools, no switching needed\n- ğŸš€ **Multi-Tool Support** - Not only supports Claude Code, but also Gemini CLI, Codex, Qwen Code, and more\n- ğŸŒ **Cross-Platform** - Full platform support for macOS, Windows, Linux (Claude Cowork currently only macOS)\n- ğŸ”„ **Multi-Model Switching** - Flexibly switch between different models in the same interface, meeting different task requirements\n- ğŸ“„ **Real-time Preview** - Visual preview for 9+ formats, immediately view the effects of AI-generated files\n- ğŸ’¾ **Local Data Security** - All conversations and files saved locally, data never leaves your device\n\n---\n\n### â“ Quick Q&A\n\n<details>\n<summary><strong>Q: Why is AionUi a great replacement for Claude Cowork?</strong></summary>\nA: AionUi is a **free and open-source** **Multi-AI Agent Desktop**. Compared to the official Cowork which only runs on macOS and is locked to Claude, AionUi is its **full-model, cross-platform enhanced version**, deeply covering **AI Office Automation** scenarios.\n\n| Dimension     | Claude Cowork        | AionUi (This Project)                       |\n| :------------ | :------------------- | :------------------------------------------ |\n| OS            | macOS Only           | ğŸ macOS / ğŸªŸ Windows / ğŸ§ Linux            |\n| Model Support | Claude Only          | ğŸ¤– Gemini, Claude, DeepSeek, OpenAI, Ollama |\n| Interaction   | GUI                  | ğŸ–¥ï¸ Full GUI + WebUI Remote Access           |\n| Cost          | Subscription $100/mo | ğŸ†“ Completely Free & Open Source            |\n\n**Deep AI Office Scenario Support:**\n\n- **File Management**: Intelligently organize messy local folders and batch rename with one click.\n- **Data Processing**: Deeply analyze and automatically beautify Excel reports.\n- **Document Generation**: Automatically write and format PPT, Word, and Markdown documents.\n- **Instant Preview**: Built-in 9+ format preview panels, making AI office collaboration results instantly visible.\n</details>\n\n<details>\n<summary><strong>Q: What can I do with AionUi?</strong></summary>\nA: It can be your **private Cowork workspace**. You can let it help you batch organize folders, deeply beautify Excel, and preview web code in real-time. It's your best graphical choice for exploring office automation workflows and enhancing your experience with Claude Code or Gemini CLI.\n</details>\n\n<details>\n<summary><strong>Q: Is AionUi ready to use out of the box?</strong></summary>\nA: Yes! After installation, you can directly use Google account login, AionUi will automatically associate with Gemini CLI, no additional configuration needed to start using.\n</details>\n\n<details>\n<summary><strong>Q: Is it free?</strong></summary>\nA: AionUi is completely free and open source, but using AI models requires corresponding API Keys.\n</details>\n\n<details>\n<summary><strong>Q: Which AI models are supported?</strong></summary>\nA: Supports mainstream models like Gemini, OpenAI, Claude, Qwen, as well as local models like Ollama, LM Studio.\n\nYou can also run multiple AI Agents simultaneously (such as Gemini CLI, Claude Code, Qwen Code, etc.), see the configuration guide for details.\n\n</details>\n\n<details>\n<summary><strong>Q: Is my data secure?</strong></summary>\nA: All conversation data is stored in a local SQLite database and will not be uploaded to any server.\n</details>\n\n---\n\n## âœ¨ Core Features\n\n### ğŸ’¬ **Multi-Session Chat**\n\n- **Multi-Session + Independent Context** - Open multiple chats simultaneously, each session has independent context memory, no confusion\n- **Local Storage** - All conversations are saved locally and will not be lost\n\n### ğŸ¤– **Multi-Model Support**\n\n- **Multi-Platform Support** - Supports mainstream models like Gemini, OpenAI, Claude, Qwen, flexible switching\n- **Local Model Support** - Supports local model deployment like Ollama, LM Studio, select Custom platform and set local API address (e.g., `http://localhost:11434/v1`) to connect\n- **Gemini 3 Subscription Optimization** - Automatically identifies subscribed users, recommends advanced models\n\n### ğŸ—‚ï¸ **File Management**\n\n- **File Tree Browsing + Drag & Drop Upload** - Browse files like folders, support drag and drop files or folders for one-click import\n- **Smart Organization** - You can let AI help organize folders, automatic classification\n\n### ğŸ“„ **Preview Panel - Give AI Agent a Display**\n\n- **9+ Format Preview** - Supports PDF, Word, Excel, PPT, code, Markdown, images, etc., view results immediately after AI generation\n- **Real-time Tracking + Editable** - Automatically tracks file changes, supports real-time editing and debugging of Markdown, code, HTML\n\n### ğŸ¨ **AI Image Generation & Editing**\n\n- **Intelligent Image Generation** - Supports multiple image generation models like Gemini 2.5 Flash Image Preview, Nano, Banana\n- **Image Recognition & Editing** - AI-driven image analysis and editing features\n\n### ğŸŒ **WebUI Remote Access**\n\n- **Cross-Device Access** - Access from any device on the network via browser, supports mobile devices\n- **Local Data Security** - All data stored locally in SQLite database, suitable for server deployment\n\n### ğŸ¨ **Personalized Interface Customization**\n\n_Customize with your own CSS code, make your interface match your preferences_\n\n<p align=\"center\">\n  <img src=\"./resources/css with skin.gif\" alt=\"CSS Custom Interface Demo\" width=\"800\">\n</p>\n\n- **Fully Customizable** - Freely customize interface colors, styles, layout through CSS code, create your exclusive experience\n\n---\n\n## ğŸ“– Detailed Usage Guide\n\n<details>\n<summary><strong>ğŸ“– Expand to View Complete Usage Guide</strong></summary>\n\n### ğŸš€ Quick Start\n\n- [ğŸ“– Complete Installation Guide](https://github.com/iOfficeAI/AionUi/wiki/Getting-Started) - Detailed steps from download to configuration\n- [âš™ï¸ LLM Configuration Guide](https://github.com/iOfficeAI/AionUi/wiki/LLM-Configuration) - Multi-platform AI model configuration\n- [ğŸ¤– Multi-Agent Mode Setup](https://github.com/iOfficeAI/AionUi/wiki/ACP-Setup) - Integrate terminal AI agents\n- [ğŸ”Œ MCP Tool Configuration](https://github.com/iOfficeAI/AionUi/wiki/MCP-Configuration-Guide) - Model Context Protocol server setup\n- [ğŸ¨ Image Generation Configuration](https://github.com/iOfficeAI/AionUi/wiki/AionUi-Image-Generation-Tool-Model-Configuration-Guide) - AI image generation setup tutorial\n- [ğŸŒ WebUI Configuration Guide](https://github.com/iOfficeAI/AionUi/wiki/WebUI-Configuration-Guide) - Complete WebUI setup and configuration tutorial\n\n### ğŸ¯ Use Cases\n\n- [ğŸ“ File Management](https://github.com/iOfficeAI/AionUi/wiki/file-management) - Smart file organization\n- [ğŸ“Š Excel Processing](https://github.com/iOfficeAI/AionUi/wiki/excel-processing) - AI-driven data processing\n- [ğŸ¨ Image Generation](https://github.com/iOfficeAI/AionUi/wiki/AionUi-Image-Generation-Tool-Model-Configuration-Guide) - AI image creation\n- [ğŸ“š More Use Cases](https://github.com/iOfficeAI/AionUi/wiki/Use-Cases-Overview)\n\n### â“ Support & Help\n\n- [â“ FAQ](https://github.com/iOfficeAI/AionUi/wiki/FAQ) - Questions and troubleshooting\n- [ğŸ”§ Configuration & Usage Tutorials](https://github.com/iOfficeAI/AionUi/wiki/Configuration-Guides) - Complete configuration documentation\n\n</details>\n\n---\n\n## ğŸš€ Quick Start\n\n### ğŸ’» System Requirements\n\n- **macOS**: 10.15 or higher\n- **Windows**: Windows 10 or higher\n- **Linux**: Ubuntu 18.04+ / Debian 10+ / Fedora 32+\n- **Memory**: Recommended 4GB or more\n- **Storage**: At least 500MB available space\n\n### ğŸ“¥ Download\n\n<p>\n  <a href=\"https://github.com/iOfficeAI/AionUi/releases\">\n    <img src=\"https://img.shields.io/badge/Download-Latest%20Release-32CD32?style=for-the-badge&logo=github&logoColor=white\" alt=\"Download Latest Release\" height=\"50\">\n  </a>\n</p>\n\n### ğŸ”§ Simple Installation\n\n1. **Download and install** AionUi application\n2. **Configure AI service** - Support Google account login or API Key authentication\n3. **Start using** - Immediately experience modern AI chat interface\n\n> ğŸ’¡ **Need detailed configuration guide?** Check out our [Complete Installation Tutorial](https://github.com/iOfficeAI/AionUi/wiki/Getting-Started)\n\n---\n\n## ğŸ¤ Community & Support\n\n### ğŸ’¬ Community\n\n**ğŸ’¡ Your ideas matter!** We highly value every user's suggestions and feedback. Whether it's feature ideas, user experience, or issues you encounter, feel free to contact us anytime!\n\n<p align=\"center\">\n  <a href=\"https://x.com/AionUi\" target=\"_blank\">\n    <img src=\"./resources/contactus-x.png\" alt=\"Contact Us on X\" width=\"600\">\n  </a>\n</p>\n\n- [ğŸ’¬ GitHub Discussions](https://github.com/iOfficeAI/AionUi/discussions) - **Share ideas, make suggestions, exchange usage tips**\n- [ğŸ› Report Issues](https://github.com/iOfficeAI/AionUi/issues) - Report bugs or feature requests\n- [ğŸ“¦ Release Updates](https://github.com/iOfficeAI/AionUi/releases) - Get the latest version\n\n### ğŸ¤ Contributing\n\nWelcome to submit Issues and Pull Requests!\n\n1. Fork this project\n2. Create a feature branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n---\n\n## ğŸ“„ License\n\nThis project is licensed under [Apache-2.0](LICENSE).\n\n---\n\n## ğŸ‘¥ Contributors\n\nThanks to all developers who have contributed to AionUi!\n\n<p align=\"center\">\n  <a href=\"https://github.com/iOfficeAI/AionUi/graphs/contributors\">\n    <img src=\"https://contrib.rocks/image?repo=iOfficeAI/AionUi&max=20\" alt=\"Contributors\" />\n  </a>\n</p>\n\n## ğŸ“Š Star History\n\n<p align=\"center\">\n  <a href=\"https://www.star-history.com/#iOfficeAI/aionui&Date\" target=\"_blank\">\n    <img src=\"https://api.star-history.com/svg?repos=iOfficeAI/aionui&type=Date\" alt=\"GitHub Star Trends\" width=\"600\">\n  </a>\n</p>\n\n<div align=\"center\">\n\n**â­ If you like it, give us a star**\n\n[Report Bug](https://github.com/iOfficeAI/AionUi/issues) Â· [Request Feature](https://github.com/iOfficeAI/AionUi/issues)\n\n</div>\n",
      "stars_today": 237
    },
    {
      "id": 1024118326,
      "name": "WeKnora",
      "full_name": "Tencent/WeKnora",
      "description": "LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.",
      "html_url": "https://github.com/Tencent/WeKnora",
      "stars": 11832,
      "forks": 1300,
      "language": "Go",
      "topics": [
        "agent",
        "agentic",
        "ai",
        "chatbot",
        "chatbots",
        "embeddings",
        "evaluation",
        "generative-ai",
        "golang",
        "knowledge-base",
        "llm",
        "multi-tenant",
        "multimodel",
        "ollama",
        "openai",
        "question-answering",
        "rag",
        "reranking",
        "semantic-search",
        "vector-search"
      ],
      "created_at": "2025-07-22T08:01:23Z",
      "updated_at": "2026-01-16T01:05:27Z",
      "pushed_at": "2026-01-15T12:09:20Z",
      "open_issues": 82,
      "owner": {
        "login": "Tencent",
        "avatar_url": "https://avatars.githubusercontent.com/u/18461506?v=4"
      },
      "readme": "<p align=\"center\">\n  <picture>\n    <img src=\"./docs/images/logo.png\" alt=\"WeKnora Logo\" height=\"120\"/>\n  </picture>\n</p>\n\n<p align=\"center\">\n  <picture>\n    <a href=\"https://trendshift.io/repositories/15289\" target=\"_blank\">\n      <img src=\"https://trendshift.io/api/badge/repositories/15289\" alt=\"Tencent%2FWeKnora | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/>\n    </a>\n  </picture>\n</p>\n<p align=\"center\">\n    <a href=\"https://weknora.weixin.qq.com\" target=\"_blank\">\n        <img alt=\"å®˜æ–¹ç½‘ç«™\" src=\"https://img.shields.io/badge/å®˜æ–¹ç½‘ç«™-WeKnora-4e6b99\">\n    </a>\n    <a href=\"https://chatbot.weixin.qq.com\" target=\"_blank\">\n        <img alt=\"å¾®ä¿¡å¯¹è¯å¼€æ”¾å¹³å°\" src=\"https://img.shields.io/badge/å¾®ä¿¡å¯¹è¯å¼€æ”¾å¹³å°-5ac725\">\n    </a>\n    <a href=\"https://github.com/Tencent/WeKnora/blob/main/LICENSE\">\n        <img src=\"https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&color=2e6cc4\" alt=\"License\">\n    </a>\n    <a href=\"./CHANGELOG.md\">\n        <img alt=\"Version\" src=\"https://img.shields.io/badge/version-0.2.6-2e6cc4?labelColor=d4eaf7\">\n    </a>\n</p>\n\n<p align=\"center\">\n| <b>English</b> | <a href=\"./README_CN.md\"><b>ç®€ä½“ä¸­æ–‡</b></a> | <a href=\"./README_JA.md\"><b>æ—¥æœ¬èª</b></a> |\n</p>\n\n<p align=\"center\">\n  <h4 align=\"center\">\n\n  [Overview](#-overview) â€¢ [Architecture](#-architecture) â€¢ [Key Features](#-key-features) â€¢ [Getting Started](#-getting-started) â€¢ [API Reference](#-api-reference) â€¢ [Developer Guide](#-developer-guide)\n  \n  </h4>\n</p>\n\n# ğŸ’¡ WeKnora - LLM-Powered Document Understanding & Retrieval Framework\n\n## ğŸ“Œ Overview\n\n[**WeKnora**](https://weknora.weixin.qq.com) is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents. \n\nIt adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the **RAG (Retrieval-Augmented Generation)** paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.\n\n**Website:** https://weknora.weixin.qq.com\n\n## âœ¨ Latest Updates\n\n**v0.2.0 Highlights:**\n\n- ğŸ¤– **Agent Mode**: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection\n- ğŸ“š **Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry\n- âš™ï¸ **Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior\n- ğŸŒ **Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine\n- ğŸ”Œ **MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods\n- ğŸ¨ **New UI**: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade\n- âš¡ **Infrastructure Upgrade**: Introduced MQ async task management, support for automatic database migration, and fast development mode\n\n## ğŸ”’ Security Notice\n\n**Important:** Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:\n\n- Deploy WeKnora services in internal/private network environments rather than public internet\n- Avoid exposing the service directly to public networks to prevent potential information leakage\n- Configure proper firewall rules and access controls for your deployment environment\n- Regularly update to the latest version for security patches and improvements\n\n## ğŸ—ï¸ Architecture\n\n![weknora-architecture.png](./docs/images/architecture.png)\n\nWeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.\n\n## ğŸ¯ Key Features\n\n- **ğŸ¤– Agent Mode**: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection\n- **ğŸ” Precise Understanding**: Structured content extraction from PDFs, Word documents, images and more into unified semantic views\n- **ğŸ§  Intelligent Reasoning**: Leverages LLMs to understand document context and user intent for accurate Q&A and multi-turn conversations\n- **ğŸ“š Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities\n- **ğŸ”§ Flexible Extension**: All components from parsing and embedding to retrieval and generation are decoupled for easy customization\n- **âš¡ Efficient Retrieval**: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support\n- **ğŸŒ Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine\n- **ğŸ”Œ MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods\n- **âš™ï¸ Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior\n- **ğŸ¯ User-Friendly**: Intuitive web interface and standardized APIs for zero technical barriers\n- **ğŸ”’ Secure & Controlled**: Support for local deployment and private cloud, ensuring complete data sovereignty\n\n## ğŸ“Š Application Scenarios\n\n| Scenario | Applications | Core Value |\n|---------|----------|----------|\n| **Enterprise Knowledge Management** | Internal document retrieval, policy Q&A, operation manual search | Improve knowledge discovery efficiency, reduce training costs |\n| **Academic Research Analysis** | Paper retrieval, research report analysis, scholarly material organization | Accelerate literature review, assist research decisions |\n| **Product Technical Support** | Product manual Q&A, technical documentation search, troubleshooting | Enhance customer service quality, reduce support burden |\n| **Legal & Compliance Review** | Contract clause retrieval, regulatory policy search, case analysis | Improve compliance efficiency, reduce legal risks |\n| **Medical Knowledge Assistance** | Medical literature retrieval, treatment guideline search, case analysis | Support clinical decisions, improve diagnosis quality |\n\n## ğŸ§© Feature Matrix\n\n| Module | Support                                                                        | Description                                                                                                                                                        |\n|---------|--------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Agent Mode | âœ… ReACT Agent Mode                                                             | Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations               |\n| Knowledge Base Types | âœ… FAQ / Document                                                               | Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry                                       |\n| Document Formats | âœ… PDF / Word / Txt / Markdown / Images (with OCR / Caption)                    | Support for structured and unstructured documents with text extraction from images                                                                                 |\n| Model Management | âœ… Centralized configuration, built-in model sharing                            | Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models                                   |\n| Embedding Models | âœ… Local models, BGE / GTE APIs, etc.                                           | Customizable embedding models, compatible with local deployment and cloud vector generation APIs                                                                   |\n| Vector DB Integration | âœ… PostgreSQL (pgvector), Elasticsearch                                         | Support for mainstream vector index backends, flexible switching for different retrieval scenarios                                                                 |\n| Retrieval Strategies | âœ… BM25 / Dense Retrieval / GraphRAG                                            | Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines                                        |\n| LLM Integration | âœ… Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching  | Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration                                                     |\n| Conversation Strategy | âœ… Agent models, normal mode models, retrieval thresholds, Prompt configuration | Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior |\n| Web Search | âœ… Extensible search engines, DuckDuckGo / Google                               | Support for extensible web search engines with built-in DuckDuckGo search engine                                                                                   |\n| MCP Tools | âœ… uvx, npx launchers, Stdio/HTTP Streamable/SSE                                | Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods                                      |\n| QA Capabilities | âœ… Context-aware, multi-turn dialogue, prompt templates                         | Support for complex semantic modeling, instruction control and chain-of-thought Q&A with configurable prompts and context windows                                  |\n| E2E Testing | âœ… Retrieval+generation process visualization and metric evaluation             | End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics                                                            |\n| Deployment Modes | âœ… Support for local deployment / Docker images                                 | Meets private, offline deployment and flexible operation requirements, with fast development mode support                                                          |\n| User Interfaces | âœ… Web UI + RESTful API                                                         | Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display                                              |\n| Task Management | âœ… MQ async tasks, automatic database migration                                 | MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades                                            |\n\n## ğŸš€ Getting Started\n\n### ğŸ›  Prerequisites\n\nMake sure the following tools are installed on your system:\n\n* [Docker](https://www.docker.com/)\n* [Docker Compose](https://docs.docker.com/compose/)\n* [Git](https://git-scm.com/)\n\n### ğŸ“¦ Installation\n\n#### â‘  Clone the repository\n\n```bash\n# Clone the main repository\ngit clone https://github.com/Tencent/WeKnora.git\ncd WeKnora\n```\n\n#### â‘¡ Configure environment variables\n\n```bash\n# Copy example env file\ncp .env.example .env\n\n# Edit .env and set required values\n# All variables are documented in the .env.example comments\n```\n\n#### â‘¢ Start the services (include Ollama)\n\nCheck the images that need to be started in the .env file.\n\n```bash\n./scripts/start_all.sh\n```\n\nor\n\n```bash\nmake start-all\n```\n\n#### â‘¢.0 Start ollama services (Optional)\n\n```bash\nollama serve > /dev/null 2>&1 &\n```\n\n#### â‘¢.1 Activate different combinations of features\n\n- Minimum core services\n```bash\ndocker compose up -d\n```\n\n- All features enabled\n```bash\ndocker-compose --profile full up -d\n```\n\n- Tracing logs required\n```bash\ndocker-compose --profile jaeger up -d\n```\n\n- Neo4j knowledge graph required\n```bash\ndocker-compose --profile neo4j up -d\n```\n\n- Minio file storage service required\n```bash\ndocker-compose --profile minio up -d\n```\n\n- Multiple options combination\n```bash\ndocker-compose --profile neo4j --profile minio up -d\n```\n\n#### â‘£ Stop the services\n\n```bash\n./scripts/start_all.sh --stop\n# Or\nmake stop-all\n```\n\n### ğŸŒ Access Services\n\nOnce started, services will be available at:\n\n* Web UI: `http://localhost`\n* Backend API: `http://localhost:8080`\n* Jaeger Tracing: `http://localhost:16686`\n\n### ğŸ”Œ Using WeChat Dialog Open Platform\n\nWeKnora serves as the core technology framework for the [WeChat Dialog Open Platform](https://chatbot.weixin.qq.com), providing a more convenient usage approach:\n\n- **Zero-code Deployment**: Simply upload knowledge to quickly deploy intelligent Q&A services within the WeChat ecosystem, achieving an \"ask and answer\" experience\n- **Efficient Question Management**: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers\n- **WeChat Ecosystem Integration**: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences\n\n### ğŸ”— Access WeKnora via MCP Server\n\n#### 1ï¸âƒ£ Clone the repository\n```\ngit clone https://github.com/Tencent/WeKnora\n```\n\n#### 2ï¸âƒ£ Configure MCP Server\n> It is recommended to directly refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for configuration.\n\nConfigure the MCP client to connect to the server:\n```json\n{\n  \"mcpServers\": {\n    \"weknora\": {\n      \"args\": [\n        \"path/to/WeKnora/mcp-server/run_server.py\"\n      ],\n      \"command\": \"python\",\n      \"env\":{\n        \"WEKNORA_API_KEY\":\"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk\",\n        \"WEKNORA_BASE_URL\":\"http(s)://your-weknora-address/api/v1\"\n      }\n    }\n  }\n}\n```\n\nRun directly using stdio command:\n```\npip install weknora-mcp-server\npython -m weknora-mcp-server\n```\n\n## ğŸ”§ Initialization Configuration Guide\n\nTo help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows:\nIf this is your first time using this project, you can skip steps â‘ â‘¡ and go directly to steps â‘¢â‘£.\n\n### â‘  Stop the services\n\n```bash\n./scripts/start_all.sh --stop\n```\n\n### â‘¡ Clear existing data tables (recommended when no important data exists)\n\n```bash\nmake clean-db\n```\n\n### â‘¢ Compile and start services\n\n```bash\n./scripts/start_all.sh\n```\n\n### â‘£ Access Web UI\n\nhttp://localhost\n\nOn your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.\n\n## ğŸ“± Interface Showcase\n\n### Web UI Interface\n\n<table>\n  <tr>\n    <td><b>Knowledge Base Management</b><br/><img src=\"./docs/images/knowledgebases.png\" alt=\"Knowledge Base Management\"></td>\n    <td><b>Conversation Settings</b><br/><img src=\"./docs/images/settings.png\" alt=\"Conversation Settings\"></td>\n  </tr>\n  <tr>\n    <td colspan=\"2\"><b>Agent Mode Tool Call Process</b><br/><img src=\"./docs/images/agent-qa.png\" alt=\"Agent Mode Tool Call Process\"></td>\n  </tr>\n</table>\n\n**Knowledge Base Management:** Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.\n\n**Agent Mode:** Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.\n\n**Conversation Strategy:** Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.\n\n### Document Knowledge Graph\n\nWeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.\n\nFor detailed configuration, please refer to the [Knowledge Graph Configuration Guide](./docs/KnowledgeGraph.md).\n\n### MCP Server\n\nPlease refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for the necessary setup.\n\n## ğŸ“˜ API Reference\n\nTroubleshooting FAQ: [Troubleshooting FAQ](./docs/QA.md)\n\nDetailed API documentation is available at: [API Docs](./docs/api/README.md)\n\n## ğŸ§­ Developer Guide\n\n### âš¡ Fast Development Mode (Recommended)\n\nIf you need to frequently modify code, **you don't need to rebuild Docker images every time**! Use fast development mode:\n\n```bash\n# Method 1: Using Make commands (Recommended)\nmake dev-start      # Start infrastructure\nmake dev-app        # Start backend (new terminal)\nmake dev-frontend   # Start frontend (new terminal)\n\n# Method 2: One-click start\n./scripts/quick-dev.sh\n\n# Method 3: Using scripts\n./scripts/dev.sh start     # Start infrastructure\n./scripts/dev.sh app       # Start backend (new terminal)\n./scripts/dev.sh frontend  # Start frontend (new terminal)\n```\n\n**Development Advantages:**\n- âœ… Frontend modifications auto hot-reload (no restart needed)\n- âœ… Backend modifications quick restart (5-10 seconds, supports Air hot-reload)\n- âœ… No need to rebuild Docker images\n- âœ… Support IDE breakpoint debugging\n\n**Detailed Documentation:** [Development Environment Quick Start](./docs/å¼€å‘æŒ‡å—.md)\n\n### ğŸ“ Directory Structure\n\n```\nWeKnora/\nâ”œâ”€â”€ client/      # go client\nâ”œâ”€â”€ cmd/         # Main entry point\nâ”œâ”€â”€ config/      # Configuration files\nâ”œâ”€â”€ docker/      # docker images files\nâ”œâ”€â”€ docreader/   # Document parsing app\nâ”œâ”€â”€ docs/        # Project documentation\nâ”œâ”€â”€ frontend/    # Frontend app\nâ”œâ”€â”€ internal/    # Core business logic\nâ”œâ”€â”€ mcp-server/  # MCP server\nâ”œâ”€â”€ migrations/  # DB migration scripts\nâ””â”€â”€ scripts/     # Shell scripts\n```\n\n## ğŸ¤ Contributing\n\nWe welcome community contributions! For suggestions, bugs, or feature requests, please submit an [Issue](https://github.com/Tencent/WeKnora/issues) or directly create a Pull Request.\n\n### ğŸ¯ How to Contribute\n\n- ğŸ› **Bug Fixes**: Discover and fix system defects\n- âœ¨ **New Features**: Propose and implement new capabilities\n- ğŸ“š **Documentation**: Improve project documentation\n- ğŸ§ª **Test Cases**: Write unit and integration tests\n- ğŸ¨ **UI/UX Enhancements**: Improve user interface and experience\n\n### ğŸ“‹ Contribution Process\n\n1. **Fork the project** to your GitHub account\n2. **Create a feature branch** `git checkout -b feature/amazing-feature`\n3. **Commit changes** `git commit -m 'Add amazing feature'`\n4. **Push branch** `git push origin feature/amazing-feature`\n5. **Create a Pull Request** with detailed description of changes\n\n### ğŸ¨ Code Standards\n\n- Follow [Go Code Review Comments](https://github.com/golang/go/wiki/CodeReviewComments)\n- Format code using `gofmt`\n- Add necessary unit tests\n- Update relevant documentation\n\n### ğŸ“ Commit Guidelines\n\nUse [Conventional Commits](https://www.conventionalcommits.org/) standard:\n\n```\nfeat: Add document batch upload functionality\nfix: Resolve vector retrieval precision issue\ndocs: Update API documentation\ntest: Add retrieval engine test cases\nrefactor: Restructure document parsing module\n```\n\n## ğŸ‘¥ Contributors\n\nThanks to these excellent contributors:\n\n[![Contributors](https://contrib.rocks/image?repo=Tencent/WeKnora)](https://github.com/Tencent/WeKnora/graphs/contributors)\n\n## ğŸ“„ License\n\nThis project is licensed under the [MIT License](./LICENSE).\nYou are free to use, modify, and distribute the code with proper attribution.\n\n## ğŸ“ˆ Project Statistics\n\n<a href=\"https://www.star-history.com/#Tencent/WeKnora&type=date&legend=top-left\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=Tencent/WeKnora&type=date&theme=dark&legend=top-left\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=Tencent/WeKnora&type=date&legend=top-left\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=Tencent/WeKnora&type=date&legend=top-left\" />\n </picture>\n</a>\n",
      "stars_today": 222
    },
    {
      "id": 949523404,
      "name": "cursor-talk-to-figma-mcp",
      "full_name": "grab/cursor-talk-to-figma-mcp",
      "description": "TalkToFigma: MCP integration between Cursor and Figma, allowing Cursor Agentic AI to communicate with Figma for reading designs and modifying them programmatically.",
      "html_url": "https://github.com/grab/cursor-talk-to-figma-mcp",
      "stars": 6113,
      "forks": 643,
      "language": "JavaScript",
      "topics": [
        "agent",
        "agentic",
        "agentic-ai",
        "ai",
        "ai-agents",
        "automation",
        "cursor",
        "design",
        "figma",
        "generative-ai",
        "llm",
        "llms",
        "mcp",
        "model-context-protocol"
      ],
      "created_at": "2025-03-16T16:45:37Z",
      "updated_at": "2026-01-16T00:05:10Z",
      "pushed_at": "2025-11-03T01:00:00Z",
      "open_issues": 73,
      "owner": {
        "login": "grab",
        "avatar_url": "https://avatars.githubusercontent.com/u/17284363?v=4"
      },
      "readme": "# Cursor Talk to Figma MCP\n\nThis project implements a Model Context Protocol (MCP) integration between Cursor AI and Figma, allowing Cursor to communicate with Figma for reading designs and modifying them programmatically.\n\nhttps://github.com/user-attachments/assets/129a14d2-ed73-470f-9a4c-2240b2a4885c\n\n## Project Structure\n\n- `src/talk_to_figma_mcp/` - TypeScript MCP server for Figma integration\n- `src/cursor_mcp_plugin/` - Figma plugin for communicating with Cursor\n- `src/socket.ts` - WebSocket server that facilitates communication between the MCP server and Figma plugin\n\n## Get Started\n\n1. Install Bun if you haven't already:\n\n```bash\ncurl -fsSL https://bun.sh/install | bash\n```\n\n2. Run setup, this will also install MCP in your Cursor's active project\n\n```bash\nbun setup\n```\n\n3. Start the Websocket server\n\n```bash\nbun socket\n```\n\n4. **NEW** Install Figma plugin from [Figma community page](https://www.figma.com/community/plugin/1485687494525374295/cursor-talk-to-figma-mcp-plugin) or [install locally](#figma-plugin)\n\n## Quick Video Tutorial\n\n[Video Link](https://www.linkedin.com/posts/sonnylazuardi_just-wanted-to-share-my-latest-experiment-activity-7307821553654657024-yrh8)\n\n## Design Automation Example\n\n**Bulk text content replacement**\n\nThanks to [@dusskapark](https://github.com/dusskapark) for contributing the bulk text replacement feature. Here is the [demo video](https://www.youtube.com/watch?v=j05gGT3xfCs).\n\n**Instance Override Propagation**\nAnother contribution from [@dusskapark](https://github.com/dusskapark)\nPropagate component instance overrides from a source instance to multiple target instances with a single command. This feature dramatically reduces repetitive design work when working with component instances that need similar customizations. Check out our [demo video](https://youtu.be/uvuT8LByroI).\n\n## Development Setup\n\nTo develop, update your mcp config to direct to your local directory.\n\n```json\n{\n  \"mcpServers\": {\n    \"TalkToFigma\": {\n      \"command\": \"bun\",\n      \"args\": [\"/path-to-repo/src/talk_to_figma_mcp/server.ts\"]\n    }\n  }\n}\n```\n\n## Manual Setup and Installation\n\n### MCP Server: Integration with Cursor\n\nAdd the server to your Cursor MCP configuration in `~/.cursor/mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"TalkToFigma\": {\n      \"command\": \"bunx\",\n      \"args\": [\"cursor-talk-to-figma-mcp@latest\"]\n    }\n  }\n}\n```\n\n### WebSocket Server\n\nStart the WebSocket server:\n\n```bash\nbun socket\n```\n\n### Figma Plugin\n\n1. In Figma, go to Plugins > Development > New Plugin\n2. Choose \"Link existing plugin\"\n3. Select the `src/cursor_mcp_plugin/manifest.json` file\n4. The plugin should now be available in your Figma development plugins\n\n## Windows + WSL Guide\n\n1. Install bun via powershell\n\n```bash\npowershell -c \"irm bun.sh/install.ps1|iex\"\n```\n\n2. Uncomment the hostname `0.0.0.0` in `src/socket.ts`\n\n```typescript\n// uncomment this to allow connections in windows wsl\nhostname: \"0.0.0.0\",\n```\n\n3. Start the websocket\n\n```bash\nbun socket\n```\n\n## Usage\n\n1. Start the WebSocket server\n2. Install the MCP server in Cursor\n3. Open Figma and run the Cursor MCP Plugin\n4. Connect the plugin to the WebSocket server by joining a channel using `join_channel`\n5. Use Cursor to communicate with Figma using the MCP tools\n\n## MCP Tools\n\nThe MCP server provides the following tools for interacting with Figma:\n\n### Document & Selection\n\n- `get_document_info` - Get information about the current Figma document\n- `get_selection` - Get information about the current selection\n- `read_my_design` - Get detailed node information about the current selection without parameters\n- `get_node_info` - Get detailed information about a specific node\n- `get_nodes_info` - Get detailed information about multiple nodes by providing an array of node IDs\n- `set_focus` - Set focus on a specific node by selecting it and scrolling viewport to it\n- `set_selections` - Set selection to multiple nodes and scroll viewport to show them\n\n### Annotations\n\n- `get_annotations` - Get all annotations in the current document or specific node\n- `set_annotation` - Create or update an annotation with markdown support\n- `set_multiple_annotations` - Batch create/update multiple annotations efficiently\n- `scan_nodes_by_types` - Scan for nodes with specific types (useful for finding annotation targets)\n\n### Prototyping & Connections\n\n- `get_reactions` - Get all prototype reactions from nodes with visual highlight animation\n- `set_default_connector` - Set a copied FigJam connector as the default connector style for creating connections (must be set before creating connections)\n- `create_connections` - Create FigJam connector lines between nodes, based on prototype flows or custom mapping\n\n### Creating Elements\n\n- `create_rectangle` - Create a new rectangle with position, size, and optional name\n- `create_frame` - Create a new frame with position, size, and optional name\n- `create_text` - Create a new text node with customizable font properties\n\n### Modifying text content\n\n- `scan_text_nodes` - Scan text nodes with intelligent chunking for large designs\n- `set_text_content` - Set the text content of a single text node\n- `set_multiple_text_contents` - Batch update multiple text nodes efficiently\n\n### Auto Layout & Spacing\n\n- `set_layout_mode` - Set the layout mode and wrap behavior of a frame (NONE, HORIZONTAL, VERTICAL)\n- `set_padding` - Set padding values for an auto-layout frame (top, right, bottom, left)\n- `set_axis_align` - Set primary and counter axis alignment for auto-layout frames\n- `set_layout_sizing` - Set horizontal and vertical sizing modes for auto-layout frames (FIXED, HUG, FILL)\n- `set_item_spacing` - Set distance between children in an auto-layout frame\n\n### Styling\n\n- `set_fill_color` - Set the fill color of a node (RGBA)\n- `set_stroke_color` - Set the stroke color and weight of a node\n- `set_corner_radius` - Set the corner radius of a node with optional per-corner control\n\n### Layout & Organization\n\n- `move_node` - Move a node to a new position\n- `resize_node` - Resize a node with new dimensions\n- `delete_node` - Delete a node\n- `delete_multiple_nodes` - Delete multiple nodes at once efficiently\n- `clone_node` - Create a copy of an existing node with optional position offset\n\n### Components & Styles\n\n- `get_styles` - Get information about local styles\n- `get_local_components` - Get information about local components\n- `create_component_instance` - Create an instance of a component\n- `get_instance_overrides` - Extract override properties from a selected component instance\n- `set_instance_overrides` - Apply extracted overrides to target instances\n\n### Export & Advanced\n\n- `export_node_as_image` - Export a node as an image (PNG, JPG, SVG, or PDF) - limited support on image currently returning base64 as text\n\n### Connection Management\n\n- `join_channel` - Join a specific channel to communicate with Figma\n\n### MCP Prompts\n\nThe MCP server includes several helper prompts to guide you through complex design tasks:\n\n- `design_strategy` - Best practices for working with Figma designs\n- `read_design_strategy` - Best practices for reading Figma designs\n- `text_replacement_strategy` - Systematic approach for replacing text in Figma designs\n- `annotation_conversion_strategy` - Strategy for converting manual annotations to Figma's native annotations\n- `swap_overrides_instances` - Strategy for transferring overrides between component instances in Figma\n- `reaction_to_connector_strategy` - Strategy for converting Figma prototype reactions to connector lines using the output of 'get_reactions', and guiding the use 'create_connections' in sequence\n\n## Development\n\n### Building the Figma Plugin\n\n1. Navigate to the Figma plugin directory:\n\n   ```\n   cd src/cursor_mcp_plugin\n   ```\n\n2. Edit code.js and ui.html\n\n## Best Practices\n\nWhen working with the Figma MCP:\n\n1. Always join a channel before sending commands\n2. Get document overview using `get_document_info` first\n3. Check current selection with `get_selection` before modifications\n4. Use appropriate creation tools based on needs:\n   - `create_frame` for containers\n   - `create_rectangle` for basic shapes\n   - `create_text` for text elements\n5. Verify changes using `get_node_info`\n6. Use component instances when possible for consistency\n7. Handle errors appropriately as all commands can throw exceptions\n8. For large designs:\n   - Use chunking parameters in `scan_text_nodes`\n   - Monitor progress through WebSocket updates\n   - Implement appropriate error handling\n9. For text operations:\n   - Use batch operations when possible\n   - Consider structural relationships\n   - Verify changes with targeted exports\n10. For converting legacy annotations:\n    - Scan text nodes to identify numbered markers and descriptions\n    - Use `scan_nodes_by_types` to find UI elements that annotations refer to\n    - Match markers with their target elements using path, name, or proximity\n    - Categorize annotations appropriately with `get_annotations`\n    - Create native annotations with `set_multiple_annotations` in batches\n    - Verify all annotations are properly linked to their targets\n    - Delete legacy annotation nodes after successful conversion\n11. Visualize prototype noodles as FigJam connectors:\n\n- Use `get_reactions` to extract prototype flows,\n- set a default connector with `set_default_connector`,\n- and generate connector lines with `create_connections` for clear visual flow mapping.\n\n## License\n\nMIT\n",
      "stars_today": 198
    },
    {
      "id": 26337322,
      "name": "rancher",
      "full_name": "rancher/rancher",
      "description": "Complete container management platform",
      "html_url": "https://github.com/rancher/rancher",
      "stars": 25245,
      "forks": 3148,
      "language": "Go",
      "topics": [
        "cattle",
        "containers",
        "docker",
        "kubernetes",
        "orchestration",
        "rancher"
      ],
      "created_at": "2014-11-07T20:49:31Z",
      "updated_at": "2026-01-15T23:37:53Z",
      "pushed_at": "2026-01-15T23:37:46Z",
      "open_issues": 3187,
      "owner": {
        "login": "rancher",
        "avatar_url": "https://avatars.githubusercontent.com/u/9343010?v=4"
      },
      "readme": "# Rancher\n\n[![Docker Pulls](https://img.shields.io/docker/pulls/rancher/rancher.svg)](https://store.docker.com/community/images/rancher/rancher)\n[![Go Report Card](https://goreportcard.com/badge/github.com/rancher/rancher)](https://goreportcard.com/report/github.com/rancher/rancher)\n\nRancher is an open source container management platform built for organizations that deploy containers in production. Rancher makes it easy to run Kubernetes everywhere, meet IT requirements, and empower DevOps teams.\n\n## Stable Release\n\n<!-- stable v2.13.1 DO NOT REMOVE THIS LINE -->\n* v2.13.1 - `rancher/rancher:v2.13.1` / `rancher/rancher:stable` - Read the full release [notes](https://github.com/rancher/rancher/releases/tag/v2.13.1).\n  \nTo get automated notifications of our latest release, you can watch the announcements category in our [forums](http://forums.rancher.com/c/announcements), or subscribe to the RSS feed `https://forums.rancher.com/c/announcements.rss`.\n\n## Quick Start\n\n    sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher\n\nOpen your browser to https://localhost\n\n## Installation\n\nSee [Installing/Upgrading Rancher](https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-and-upgrade) for all installation options.\n\n### Minimum Requirements\n\n* Operating Systems\n  * Please see [Support Matrix](https://rancher.com/support-matrix/) for specific OS versions for each Rancher version. Note that the link will default to the support matrix for the latest version of Rancher. Use the left navigation menu to select a different Rancher version. \n* Hardware & Software\n  * Please see [Installation Requirements](https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-requirements) for hardware and software requirements.\n\n### Using Rancher\n\nTo learn more about using Rancher, please refer to our [Rancher Documentation](https://ranchermanager.docs.rancher.com/v2.8).\n\n## Source Code\n\nThis repo is a meta-repo used for packaging and contains the majority of Rancher codebase. For other Rancher projects and modules, [see go.mod](https://github.com/rancher/rancher/blob/release/v2.8/go.mod) for the full list.\n\nRancher also includes other open source libraries and projects, [see go.mod](https://github.com/rancher/rancher/blob/release/v2.8/go.mod) for the full list.\n\n## Build configuration\n\nRefer to the [build docs](docs/build.md) on how to customize the building and packaging of Rancher.\n\n## Support, Discussion, and Community\nIf you need any help with Rancher, please join us at either our [Rancher forums](http://forums.rancher.com/) or [Slack](https://slack.rancher.io/) where most of our team hangs out at.\n\nPlease submit any Rancher bugs, issues, and feature requests to [rancher/rancher](https://github.com/rancher/rancher/issues).\n\nFor security issues, please first check our [security policy](https://github.com/rancher/rancher/security) and email security-rancher@suse.com instead of posting a public issue in GitHub.  You may (but are not required to) use the GPG key located on [Keybase](https://keybase.io/rancher).\n\n# License\n\nCopyright (c) 2014-2025 [SUSE](http://rancher.com)\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n",
      "stars_today": 177
    },
    {
      "id": 1000362065,
      "name": "awesome-copilot",
      "full_name": "github/awesome-copilot",
      "description": "Community-contributed instructions, prompts, and configurations to help you make the most of GitHub Copilot.",
      "html_url": "https://github.com/github/awesome-copilot",
      "stars": 17715,
      "forks": 2025,
      "language": "JavaScript",
      "topics": [
        "ai",
        "github-copilot",
        "hacktoberfest",
        "prompt-engineering"
      ],
      "created_at": "2025-06-11T16:57:39Z",
      "updated_at": "2026-01-16T00:57:54Z",
      "pushed_at": "2026-01-15T23:56:13Z",
      "open_issues": 15,
      "owner": {
        "login": "github",
        "avatar_url": "https://avatars.githubusercontent.com/u/9919?v=4"
      },
      "readme": "# ğŸ¤– Awesome GitHub Copilot Customizations\n\n[![Powered by Awesome Copilot](https://img.shields.io/badge/Powered_by-Awesome_Copilot-blue?logo=githubcopilot)](https://aka.ms/awesome-github-copilot)\n<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->\n[![All Contributors](https://img.shields.io/badge/all_contributors-93-orange.svg?style=flat-square)](#contributors-)\n<!-- ALL-CONTRIBUTORS-BADGE:END -->\n\nA community created collection of custom agents, prompts, and instructions to supercharge your GitHub Copilot experience across different domains, languages, and use cases.\n\n## ğŸš€ What is Awesome GitHub Copilot?\n\nThis repository provides a comprehensive toolkit for enhancing GitHub Copilot with specialized:\n\n- **ğŸ‘‰ [Awesome Agents](docs/README.agents.md)** - Specialized GitHub Copilot agents that integrate with MCP servers to provide enhanced capabilities for specific workflows and tools\n- **ğŸ‘‰ [Awesome Prompts](docs/README.prompts.md)** - Focused, task-specific prompts for generating code, documentation, and solving specific problems\n- **ğŸ‘‰ [Awesome Instructions](docs/README.instructions.md)** - Comprehensive coding standards and best practices that apply to specific file patterns or entire projects\n- **ğŸ‘‰ [Awesome Skills](docs/README.skills.md)** - Self-contained folders with instructions and bundled resources that enhance AI capabilities for specialized tasks\n- **ğŸ‘‰ [Awesome Collections](docs/README.collections.md)** - Curated collections of related prompts, instructions, and chat modes organized around specific themes and workflows\n\n## ğŸŒŸ Featured Collections\n\nDiscover our curated collections of prompts, instructions, and agents organized around specific themes and workflows.\n\n| Name | Description | Items | Tags |\n| ---- | ----------- | ----- | ---- |\n| [Awesome Copilot](collections/awesome-copilot.md) | Meta prompts that help you discover and generate curated GitHub Copilot chat modes, collections, instructions, prompts, and agents. | 6 items | github-copilot, discovery, meta, prompt-engineering, agents |\n| [Partners](collections/partners.md) | Custom agents that have been created by GitHub partners | 20 items | devops, security, database, cloud, infrastructure, observability, feature-flags, cicd, migration, performance |\n\n\n## MCP Server\n\nTo make it easy to add these customizations to your editor, we have created a [MCP Server](https://developer.microsoft.com/blog/announcing-awesome-copilot-mcp-server) that provides a prompt for searching and installing prompts, instructions, and chat modes directly from this repository. You'll need to have Docker installed and running to run the server.\n\n[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install-0098FF?logo=visualstudiocode&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vscode) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install-24bfa5?logo=visualstudiocode&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vscode-insiders) [![Install in Visual Studio](https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vs)\n\n<details>\n<summary>Show MCP Server JSON configuration</summary>\n\n```json\n{\n  \"servers\": {\n    \"awesome-copilot\": {\n      \"type\": \"stdio\",\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"ghcr.io/microsoft/mcp-dotnet-samples/awesome-copilot:latest\"\n      ]\n    }\n  }\n}\n```\n\n</details>\n\n## ğŸ”§ How to Use\n\n### ğŸ¤– Custom Agents\n\nCustom agents can be used in Copilot coding agent (CCA), VS Code, and Copilot CLI (coming soon). For CCA, when assigning an issue to Copilot, select the custom agent from the provided list. In VS Code, you can activate the custom agent in the agents session, alongside built-in agents like Plan and Agent.\n\n### ğŸ¯ Prompts\n\nUse the `/` command in GitHub Copilot Chat to access prompts:\n\n```plaintext\n/awesome-copilot create-readme\n```\n\n### ğŸ“‹ Instructions\n\nInstructions automatically apply to files based on their patterns and provide contextual guidance for coding standards, frameworks, and best practices.\n\n## ğŸ¯ Why Use Awesome GitHub Copilot?\n\n- **Productivity**: Pre-built agents, prompts and instructions save time and provide consistent results.\n- **Best Practices**: Benefit from community-curated coding standards and patterns.\n- **Specialized Assistance**: Access expert-level guidance through specialized custom agents.\n- **Continuous Learning**: Stay updated with the latest patterns and practices across technologies.\n\n## ğŸ¤ Contributing\n\nWe welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details on how to:\n\n- Add new prompts, instructions, or chat modes\n- Improve existing content\n- Report issues or suggest enhancements\n\nFor AI coding agents working with this project, refer to [AGENTS.md](AGENTS.md) for detailed technical guidance on development workflows, setup commands, and contribution standards.\n\n### Quick Contribution Guide\n\n1. Follow our file naming conventions and frontmatter requirements\n2. Test your contributions thoroughly\n3. Update the appropriate README tables\n4. Submit a pull request with a clear description\n\n## ğŸ“– Repository Structure\n\n```plaintext\nâ”œâ”€â”€ prompts/          # Task-specific prompts (.prompt.md)\nâ”œâ”€â”€ instructions/     # Coding standards and best practices (.instructions.md)\nâ”œâ”€â”€ agents/           # AI personas and specialized modes (.agent.md)\nâ”œâ”€â”€ collections/      # Curated collections of related items (.collection.yml)\nâ”œâ”€â”€ scripts/          # Utility scripts for maintenance\nâ””â”€â”€ skills/           # AI capabilities for specialized tasks\n```\n\n## ğŸ“„ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## ğŸ›¡ï¸ Security & Support\n\n- **Security Issues**: Please see our [Security Policy](SECURITY.md)\n- **Support**: Check our [Support Guide](SUPPORT.md) for getting help\n- **Code of Conduct**: We follow the [Contributor Covenant](CODE_OF_CONDUCT.md)\n\n## â„¹ï¸ Disclaimer\n\nThe customizations in this repository are sourced from and created by third-party developers. GitHub does not verify, endorse, or guarantee the functionality or security of these agents. Please carefully inspect any agent and its documentation before installing to understand permissions it may require and actions it may perform.\n\n---\n\n**Ready to supercharge your coding experience?** Start exploring our [prompts](docs/README.prompts.md), [instructions](docs/README.instructions.md), and [custom agents](docs/README.agents.md)!\n\n## Contributors âœ¨\n\nThanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.aaron-powell.com/\"><img src=\"https://avatars.githubusercontent.com/u/434140?v=4?s=100\" width=\"100px;\" alt=\"Aaron Powell\"/><br /><sub><b>Aaron Powell</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=aaronpowell\" title=\"Code\">ğŸ’»</a> <a href=\"#maintenance-aaronpowell\" title=\"Maintenance\">ğŸš§</a> <a href=\"#projectManagement-aaronpowell\" title=\"Project Management\">ğŸ“†</a> <a href=\"#promotion-aaronpowell\" title=\"Promotion\">ğŸ“£</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mubaidr.js.org/\"><img src=\"https://avatars.githubusercontent.com/u/2222702?v=4?s=100\" width=\"100px;\" alt=\"Muhammad Ubaid Raza\"/><br /><sub><b>Muhammad Ubaid Raza</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=mubaidr\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://digitarald.de/\"><img src=\"https://avatars.githubusercontent.com/u/8599?v=4?s=100\" width=\"100px;\" alt=\"Harald Kirschner\"/><br /><sub><b>Harald Kirschner</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=digitarald\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mbianchidev\"><img src=\"https://avatars.githubusercontent.com/u/37507190?v=4?s=100\" width=\"100px;\" alt=\"Matteo Bianchi\"/><br /><sub><b>Matteo Bianchi</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=mbianchidev\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AungMyoKyaw\"><img src=\"https://avatars.githubusercontent.com/u/9404824?v=4?s=100\" width=\"100px;\" alt=\"Aung Myo Kyaw\"/><br /><sub><b>Aung Myo Kyaw</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=AungMyoKyaw\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://danielscottraynsford.com/\"><img src=\"https://avatars.githubusercontent.com/u/7589164?v=4?s=100\" width=\"100px;\" alt=\"Daniel Scott-Raynsford\"/><br /><sub><b>Daniel Scott-Raynsford</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=PlagueHO\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/burkeholland\"><img src=\"https://avatars.githubusercontent.com/u/686963?v=4?s=100\" width=\"100px;\" alt=\"Burke Holland\"/><br /><sub><b>Burke Holland</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=burkeholland\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://calva.io/\"><img src=\"https://avatars.githubusercontent.com/u/30010?v=4?s=100\" width=\"100px;\" alt=\"Peter StrÃ¶mberg\"/><br /><sub><b>Peter StrÃ¶mberg</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=PEZ\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.devprodlogs.com/\"><img src=\"https://avatars.githubusercontent.com/u/51440732?v=4?s=100\" width=\"100px;\" alt=\"Daniel Meppiel\"/><br /><sub><b>Daniel Meppiel</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=danielmeppiel\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://montemagno.com/\"><img src=\"https://avatars.githubusercontent.com/u/1676321?v=4?s=100\" width=\"100px;\" alt=\"James Montemagno\"/><br /><sub><b>James Montemagno</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=jamesmontemagno\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/VamshiVerma\"><img src=\"https://avatars.githubusercontent.com/u/21999324?v=4?s=100\" width=\"100px;\" alt=\"Vamshi Verma\"/><br /><sub><b>Vamshi Verma</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=VamshiVerma\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sinedied\"><img src=\"https://avatars.githubusercontent.com/u/593151?v=4?s=100\" width=\"100px;\" alt=\"Yohan Lasorsa\"/><br /><sub><b>Yohan Lasorsa</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=sinedied\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/OrenMe\"><img src=\"https://avatars.githubusercontent.com/u/5461862?v=4?s=100\" width=\"100px;\" alt=\"Oren Me\"/><br /><sub><b>Oren Me</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=OrenMe\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mjrousos\"><img src=\"https://avatars.githubusercontent.com/u/10077254?v=4?s=100\" width=\"100px;\" alt=\"Mike Rousos\"/><br /><sub><b>Mike Rousos</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=mjrousos\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/guiopen\"><img src=\"https://avatars.githubusercontent.com/u/94094527?v=4?s=100\" width=\"100px;\" alt=\"Guilherme do Amaral Alves \"/><br /><sub><b>Guilherme do Amaral Alves </b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=guiopen\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.buymeacoffee.com/troystaylor\"><img src=\"https://avatars.githubusercontent.com/u/44444967?v=4?s=100\" width=\"100px;\" alt=\"Troy Simeon Taylor\"/><br /><sub><b>Troy Simeon Taylor</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=troystaylor\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/ambilykk/\"><img src=\"https://avatars.githubusercontent.com/u/10282550?v=4?s=100\" width=\"100px;\" alt=\"Ambily\"/><br /><sub><b>Ambily</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=ambilykk\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://tgrall.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/541250?v=4?s=100\" width=\"100px;\" alt=\"Tugdual Grall\"/><br /><sub><b>Tugdual Grall</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=tgrall\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TianqiZhang\"><img src=\"https://avatars.githubusercontent.com/u/5326582?v=4?s=100\" width=\"100px;\" alt=\"Tianqi Zhang\"/><br /><sub><b>Tianqi Zhang</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=TianqiZhang\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shubham070\"><img src=\"https://avatars.githubusercontent.com/u/5480589?v=4?s=100\" width=\"100px;\" alt=\"Shubham Gaikwad\"/><br /><sub><b>Shubham Gaikwad</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=shubham070\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sdolgin\"><img src=\"https://avatars.githubusercontent.com/u/576449?v=4?s=100\" width=\"100px;\" alt=\"Saul Dolgin\"/><br /><sub><b>Saul Dolgin</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=sdolgin\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nullchimp\"><img src=\"https://avatars.githubusercontent.com/u/58362593?v=4?s=100\" width=\"100px;\" alt=\"NULLchimp\"/><br /><sub><b>NULLchimp</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=nullchimp\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MattVevang\"><img src=\"https://avatars.githubusercontent.com/u/20714898?v=4?s=100\" width=\"100px;\" alt=\"Matt Vevang\"/><br /><sub><b>Matt Vevang</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=MattVevang\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://devkimchi.com/\"><img src=\"https://avatars.githubusercontent.com/u/1538528?v=4?s=100\" width=\"100px;\" alt=\"Justin Yoo\"/><br /><sub><b>Justin Yoo</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=justinyoo\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://hachyderm.io/@0gis0\"><img src=\"https://avatars.githubusercontent.com/u/175379?v=4?s=100\" width=\"100px;\" alt=\"Gisela Torres\"/><br /><sub><b>Gisela Torres</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=0GiS0\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://debbie.codes/\"><img src=\"https://avatars.githubusercontent.com/u/13063165?v=4?s=100\" width=\"100px;\" alt=\"Debbie O'Brien\"/><br /><sub><b>Debbie O'Brien</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=debs-obrien\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/agreaves-ms\"><img src=\"https://avatars.githubusercontent.com/u/111466195?v=4?s=100\" width=\"100px;\" alt=\"Allen Greaves\"/><br /><sub><b>Allen Greaves</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=agreaves-ms\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AmeliaRose802\"><img src=\"https://avatars.githubusercontent.com/u/26167931?v=4?s=100\" width=\"100px;\" alt=\"Amelia Payne\"/><br /><sub><b>Amelia Payne</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=AmeliaRose802\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/SebastienDegodez\"><img src=\"https://avatars.githubusercontent.com/u/2349146?v=4?s=100\" width=\"100px;\" alt=\"Sebastien DEGODEZ\"/><br /><sub><b>Sebastien DEGODEZ</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=SebastienDegodez\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://graef.io/\"><img src=\"https://avatars.githubusercontent.com/u/19261257?v=4?s=100\" width=\"100px;\" alt=\"Sebastian GrÃ¤f\"/><br /><sub><b>Sebastian GrÃ¤f</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=segraef\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://9ssi7.dev/\"><img src=\"https://avatars.githubusercontent.com/u/76786120?v=4?s=100\" width=\"100px;\" alt=\"Salih Ä°brahimbaÅŸ\"/><br /><sub><b>Salih Ä°brahimbaÅŸ</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=9ssi7\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/inquinity\"><img src=\"https://avatars.githubusercontent.com/u/406234?v=4?s=100\" width=\"100px;\" alt=\"Robert Altman\"/><br /><sub><b>Robert Altman</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=inquinity\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pertrai1\"><img src=\"https://avatars.githubusercontent.com/u/442374?v=4?s=100\" width=\"100px;\" alt=\"Rob Simpson\"/><br /><sub><b>Rob Simpson</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=pertrai1\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://ricksm.it/\"><img src=\"https://avatars.githubusercontent.com/u/7207783?v=4?s=100\" width=\"100px;\" alt=\"Rick Smit\"/><br /><sub><b>Rick Smit</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=ricksmit3000\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dotneteers.net/\"><img src=\"https://avatars.githubusercontent.com/u/28162552?v=4?s=100\" width=\"100px;\" alt=\"Peter Smulovics\"/><br /><sub><b>Peter Smulovics</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=psmulovics\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pelikhan\"><img src=\"https://avatars.githubusercontent.com/u/4175913?v=4?s=100\" width=\"100px;\" alt=\"Peli de Halleux\"/><br /><sub><b>Peli de Halleux</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=pelikhan\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.paulomorgado.net/\"><img src=\"https://avatars.githubusercontent.com/u/470455?v=4?s=100\" width=\"100px;\" alt=\"Paulo Morgado\"/><br /><sub><b>Paulo Morgado</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=paulomorgado\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://nickyt.co/\"><img src=\"https://avatars.githubusercontent.com/u/833231?v=4?s=100\" width=\"100px;\" alt=\"Nick Taylor\"/><br /><sub><b>Nick Taylor</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=nickytonline\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikeparker104\"><img src=\"https://avatars.githubusercontent.com/u/12763221?v=4?s=100\" width=\"100px;\" alt=\"Mike Parker\"/><br /><sub><b>Mike Parker</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=mikeparker104\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikekistler\"><img src=\"https://avatars.githubusercontent.com/u/85643503?v=4?s=100\" width=\"100px;\" alt=\"Mike Kistler\"/><br /><sub><b>Mike Kistler</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=mikekistler\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://a11ysupport.io/\"><img src=\"https://avatars.githubusercontent.com/u/498678?v=4?s=100\" width=\"100px;\" alt=\"Michael Fairchild\"/><br /><sub><b>Michael Fairchild</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=mfairchild365\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/michael-volz/\"><img src=\"https://avatars.githubusercontent.com/u/129928?v=4?s=100\" width=\"100px;\" alt=\"Michael A. Volz (Flynn)\"/><br /><sub><b>Michael A. Volz (Flynn)</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=michaelvolz\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/4regab\"><img src=\"https://avatars.githubusercontent.com/u/178603515?v=4?s=100\" width=\"100px;\" alt=\"4regab\"/><br /><sub><b>4regab</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=4regab\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TheovanKraay\"><img src=\"https://avatars.githubusercontent.com/u/24420698?v=4?s=100\" width=\"100px;\" alt=\"Theo van Kraay\"/><br /><sub><b>Theo van Kraay</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=TheovanKraay\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://glsauto.com/\"><img src=\"https://avatars.githubusercontent.com/u/132710946?v=4?s=100\" width=\"100px;\" alt=\"Troy Witthoeft (glsauto)\"/><br /><sub><b>Troy Witthoeft (glsauto)</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=twitthoeft-gls\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/iletai\"><img src=\"https://avatars.githubusercontent.com/u/26614687?v=4?s=100\" width=\"100px;\" alt=\"TÃ i LÃª\"/><br /><sub><b>TÃ i LÃª</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=iletai\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tinyurl.com/3p5j9mwe\"><img src=\"https://avatars.githubusercontent.com/u/9591887?v=4?s=100\" width=\"100px;\" alt=\"Udaya Veeramreddygari\"/><br /><sub><b>Udaya Veeramreddygari</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=udayakumarreddyv\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://bio.warengonzaga.com/\"><img src=\"https://avatars.githubusercontent.com/u/15052701?v=4?s=100\" width=\"100px;\" alt=\"Waren Gonzaga\"/><br /><sub><b>Waren Gonzaga</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=warengonzaga\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.miniasp.com/\"><img src=\"https://avatars.githubusercontent.com/u/88981?v=4?s=100\" width=\"100px;\" alt=\"Will ä¿å“¥\"/><br /><sub><b>Will ä¿å“¥</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=doggy8088\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yukiomoto\"><img src=\"https://avatars.githubusercontent.com/u/38450410?v=4?s=100\" width=\"100px;\" alt=\"Yuki Omoto\"/><br /><sub><b>Yuki Omoto</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=yukiomoto\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hueanmy\"><img src=\"https://avatars.githubusercontent.com/u/20430626?v=4?s=100\" width=\"100px;\" alt=\"Meii\"/><br /><sub><b>Meii</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=hueanmy\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/samqbush\"><img src=\"https://avatars.githubusercontent.com/u/74389839?v=4?s=100\" width=\"100px;\" alt=\"samqbush\"/><br /><sub><b>samqbush</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=samqbush\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sdanzo-hrb\"><img src=\"https://avatars.githubusercontent.com/u/136493100?v=4?s=100\" width=\"100px;\" alt=\"sdanzo-hrb\"/><br /><sub><b>sdanzo-hrb</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=sdanzo-hrb\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/voidfnc\"><img src=\"https://avatars.githubusercontent.com/u/194750710?v=4?s=100\" width=\"100px;\" alt=\"voidfnc\"/><br /><sub><b>voidfnc</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=voidfnc\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/webreidi\"><img src=\"https://avatars.githubusercontent.com/u/55603905?v=4?s=100\" width=\"100px;\" alt=\"Wendy Breiding\"/><br /><sub><b>Wendy Breiding</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=webreidi\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zooav\"><img src=\"https://avatars.githubusercontent.com/u/12625412?v=4?s=100\" width=\"100px;\" alt=\"Ankur Sharma\"/><br /><sub><b>Ankur Sharma</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=zooav\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jianminhuang.cc/\"><img src=\"https://avatars.githubusercontent.com/u/6296280?v=4?s=100\" width=\"100px;\" alt=\"é»ƒå¥æ—» Vincent Huang\"/><br /><sub><b>é»ƒå¥æ—» Vincent Huang</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=Jian-Min-Huang\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dgh06175\"><img src=\"https://avatars.githubusercontent.com/u/77305722?v=4?s=100\" width=\"100px;\" alt=\"ì´ìƒí˜„\"/><br /><sub><b>ì´ìƒí˜„</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=dgh06175\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/abdidaudpropel\"><img src=\"https://avatars.githubusercontent.com/u/51310019?v=4?s=100\" width=\"100px;\" alt=\"Abdi Daud\"/><br /><sub><b>Abdi Daud</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=abdidaudpropel\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.senseof.tech/\"><img src=\"https://avatars.githubusercontent.com/u/50712277?v=4?s=100\" width=\"100px;\" alt=\"Adrien Clerbois\"/><br /><sub><b>Adrien Clerbois</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=AClerbois\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.qreate.it/\"><img src=\"https://avatars.githubusercontent.com/u/1868590?v=4?s=100\" width=\"100px;\" alt=\"Alan Sprecacenere\"/><br /><sub><b>Alan Sprecacenere</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=tegola\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://asilva.dev/\"><img src=\"https://avatars.githubusercontent.com/u/2493377?v=4?s=100\" width=\"100px;\" alt=\"AndrÃ© Silva\"/><br /><sub><b>AndrÃ© Silva</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=askpt\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://javaetmoi.com/\"><img src=\"https://avatars.githubusercontent.com/u/838318?v=4?s=100\" width=\"100px;\" alt=\"Antoine Rey\"/><br /><sub><b>Antoine Rey</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=arey\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/artemsaveliev\"><img src=\"https://avatars.githubusercontent.com/u/15679218?v=4?s=100\" width=\"100px;\" alt=\"Artem Saveliev\"/><br /><sub><b>Artem Saveliev</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=artemsaveliev\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://brunoborges.io/\"><img src=\"https://avatars.githubusercontent.com/u/129743?v=4?s=100\" width=\"100px;\" alt=\"Bruno Borges\"/><br /><sub><b>Bruno Borges</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=brunoborges\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.peug.net/\"><img src=\"https://avatars.githubusercontent.com/u/3845786?v=4?s=100\" width=\"100px;\" alt=\"Christophe Peugnet\"/><br /><sub><b>Christophe Peugnet</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=tossnet\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.movinglive.ca/\"><img src=\"https://avatars.githubusercontent.com/u/14792628?v=4?s=100\" width=\"100px;\" alt=\"Chtive\"/><br /><sub><b>Chtive</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=MovingLive\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/craigbekker\"><img src=\"https://avatars.githubusercontent.com/u/1115912?v=4?s=100\" width=\"100px;\" alt=\"Craig Bekker\"/><br /><sub><b>Craig Bekker</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=craigbekker\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/breakid\"><img src=\"https://avatars.githubusercontent.com/u/1446918?v=4?s=100\" width=\"100px;\" alt=\"Dan\"/><br /><sub><b>Dan</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=breakid\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ewega\"><img src=\"https://avatars.githubusercontent.com/u/26189114?v=4?s=100\" width=\"100px;\" alt=\"Eldrick Wega\"/><br /><sub><b>Eldrick Wega</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=ewega\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.felixarjuna.dev/\"><img src=\"https://avatars.githubusercontent.com/u/79026094?v=4?s=100\" width=\"100px;\" alt=\"Felix Arjuna\"/><br /><sub><b>Felix Arjuna</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=felixarjuna\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/feapaydin\"><img src=\"https://avatars.githubusercontent.com/u/19946639?v=4?s=100\" width=\"100px;\" alt=\"Furkan Enes\"/><br /><sub><b>Furkan Enes</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=feapaydin\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://learn.microsoft.com/dotnet\"><img src=\"https://avatars.githubusercontent.com/u/24882762?v=4?s=100\" width=\"100px;\" alt=\"Genevieve Warren\"/><br /><sub><b>Genevieve Warren</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=gewarren\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/geoder101\"><img src=\"https://avatars.githubusercontent.com/u/145904?v=4?s=100\" width=\"100px;\" alt=\"George Dernikos\"/><br /><sub><b>George Dernikos</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=geoder101\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/giomartinsdev\"><img src=\"https://avatars.githubusercontent.com/u/125399281?v=4?s=100\" width=\"100px;\" alt=\"Giovanni de Almeida Martins\"/><br /><sub><b>Giovanni de Almeida Martins</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=giomartinsdev\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ioana37\"><img src=\"https://avatars.githubusercontent.com/u/69301842?v=4?s=100\" width=\"100px;\" alt=\"Ioana A\"/><br /><sub><b>Ioana A</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=Ioana37\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nohwnd\"><img src=\"https://avatars.githubusercontent.com/u/5735905?v=4?s=100\" width=\"100px;\" alt=\"Jakub JareÅ¡\"/><br /><sub><b>Jakub JareÅ¡</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=nohwnd\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://joe-watkins.io/\"><img src=\"https://avatars.githubusercontent.com/u/3695795?v=4?s=100\" width=\"100px;\" alt=\"Joe Watkins\"/><br /><sub><b>Joe Watkins</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=joe-watkins\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://johnpapa.net/\"><img src=\"https://avatars.githubusercontent.com/u/1202528?v=4?s=100\" width=\"100px;\" alt=\"John Papa\"/><br /><sub><b>John Papa</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=johnpapa\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.sugbo4j.co.nz/\"><img src=\"https://avatars.githubusercontent.com/u/15100839?v=4?s=100\" width=\"100px;\" alt=\"Joseph Gonzales\"/><br /><sub><b>Joseph Gonzales</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=josephgonzales01\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://digio.es/\"><img src=\"https://avatars.githubusercontent.com/u/173672918?v=4?s=100\" width=\"100px;\" alt=\"JosÃ© Antonio Garrido\"/><br /><sub><b>JosÃ© Antonio Garrido</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=josegarridodigio\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ranrar\"><img src=\"https://avatars.githubusercontent.com/u/95967772?v=4?s=100\" width=\"100px;\" alt=\"Kim Skov Rasmussen\"/><br /><sub><b>Kim Skov Rasmussen</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=Ranrar\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/whiteken\"><img src=\"https://avatars.githubusercontent.com/u/20211937?v=4?s=100\" width=\"100px;\" alt=\"Kenny White\"/><br /><sub><b>Kenny White</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=whiteken\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/LouellaCreemers\"><img src=\"https://avatars.githubusercontent.com/u/46204894?v=4?s=100\" width=\"100px;\" alt=\"Louella Creemers\"/><br /><sub><b>Louella Creemers</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=LouellaCreemers\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://linktr.ee/lukemurray\"><img src=\"https://avatars.githubusercontent.com/u/24467442?v=4?s=100\" width=\"100px;\" alt=\"Luke Murray\"/><br /><sub><b>Luke Murray</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=lukemurraynz\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://marknoble.com/\"><img src=\"https://avatars.githubusercontent.com/u/3819700?v=4?s=100\" width=\"100px;\" alt=\"Mark Noble\"/><br /><sub><b>Mark Noble</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=marknoble\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://soderlind.no\"><img src=\"https://avatars.githubusercontent.com/u/1649452?v=4?s=100\" width=\"100px;\" alt=\"Per SÃ¸derlind\"/><br /><sub><b>Per SÃ¸derlind</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=soderlind\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/riqueufmg\"><img src=\"https://avatars.githubusercontent.com/u/108551585?v=4?s=100\" width=\"100px;\" alt=\"Henrique Nunes\"/><br /><sub><b>Henrique Nunes</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=riqueufmg\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jeremiah-snee-openx\"><img src=\"https://avatars.githubusercontent.com/u/113928685?v=4?s=100\" width=\"100px;\" alt=\"Jeremiah Snee\"/><br /><sub><b>Jeremiah Snee</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=jeremiah-snee-openx\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/spectatora\"><img src=\"https://avatars.githubusercontent.com/u/1385755?v=4?s=100\" width=\"100px;\" alt=\"spectatora\"/><br /><sub><b>spectatora</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=spectatora\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Mike-Hanna\"><img src=\"https://avatars.githubusercontent.com/u/50142889?v=4?s=100\" width=\"100px;\" alt=\"Michael\"/><br /><sub><b>Michael</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=Mike-Hanna\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lechnerc77\"><img src=\"https://avatars.githubusercontent.com/u/22294087?v=4?s=100\" width=\"100px;\" alt=\"Christian Lechner\"/><br /><sub><b>Christian Lechner</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=lechnerc77\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jan-v.nl\"><img src=\"https://avatars.githubusercontent.com/u/462356?v=4?s=100\" width=\"100px;\" alt=\"Jan de Vries\"/><br /><sub><b>Jan de Vries</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=Jandev\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n  </tbody>\n  <tfoot>\n    <tr>\n      <td align=\"center\" size=\"13px\" colspan=\"7\">\n        <img src=\"https://raw.githubusercontent.com/all-contributors/all-contributors-cli/1b8533af435da9854653492b1327a23a4dbd0a10/assets/logo-small.svg\">\n          <a href=\"https://all-contributors.js.org/docs/en/bot/usage\">Add your contributions</a>\n        </img>\n      </td>\n    </tr>\n  </tfoot>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!\n\n## ğŸ“š Additional Resources\n\n- [VS Code Copilot Customization Documentation](https://code.visualstudio.com/docs/copilot/copilot-customization) - Official Microsoft documentation\n- [GitHub Copilot Chat Documentation](https://code.visualstudio.com/docs/copilot/chat/copilot-chat) - Complete chat feature guide\n- [Custom Chat Modes](https://code.visualstudio.com/docs/copilot/chat/chat-modes) - Advanced chat configuration\n- [VS Code Settings](https://code.visualstudio.com/docs/getstarted/settings) - General VS Code configuration guide\n\n## â„¢ï¸ Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n",
      "stars_today": 151
    },
    {
      "id": 53305197,
      "name": "go-concurrency-exercises",
      "full_name": "loong/go-concurrency-exercises",
      "description": "Hands on exercises with real-life examples to study and practice Go concurrency patterns. Test-cases are provided to verify your answers.",
      "html_url": "https://github.com/loong/go-concurrency-exercises",
      "stars": 1754,
      "forks": 531,
      "language": "Go",
      "topics": [],
      "created_at": "2016-03-07T07:34:57Z",
      "updated_at": "2026-01-15T23:16:15Z",
      "pushed_at": "2024-09-23T09:40:48Z",
      "open_issues": 10,
      "owner": {
        "login": "loong",
        "avatar_url": "https://avatars.githubusercontent.com/u/1732217?v=4"
      },
      "readme": "# Go Concurrency Exercises [![Build Status](https://travis-ci.org/loong/go-concurrency-exercises.svg?branch=main)](https://travis-ci.org/loong/go-concurrency-exercises) [![Go Report Card](https://goreportcard.com/badge/github.com/loong/go-concurrency-exercises)](https://goreportcard.com/report/github.com/loong/go-concurrency-exercises)\nExercises for Golang's concurrency patterns.\n\n## Why\nThe Go community has plenty resources to read about go's concurrency model and how to use it effectively. But *who actually wants to read all this*!? This repo tries to teach concurrency patterns by following the 'learning by doing' approach.\n\n![Image of excited gopher](https://golang.org/doc/gopher/pkg.png)\n\n## How to take this challenge\n1. *Only edit `main.go`* to solve the problem. Do not touch any of the other files.\n2. If you find a `*_test.go` file, you can test the correctness of your solution with `go test`\n3. If you get stuck, join us on [Discord](https://discord.com/invite/golang) or [Slack](https://invite.slack.golangbridge.org/)! Surely there are people who are happy to give you some code reviews (if not, find me via `@loong` ;) )\n\n## Overview\n| # | Name of the Challenge + URL           | \n| - |:-------------|\n| 0 | [Limit your Crawler](https://github.com/loong/go-concurrency-exercises/tree/main/0-limit-crawler) |\n| 1 | [Producer-Consumer](https://github.com/loong/go-concurrency-exercises/tree/main/1-producer-consumer)  |\n| 2 | [Race Condition in Caching Cache](https://github.com/loong/go-concurrency-exercises/tree/main/2-race-in-cache#race-condition-in-caching-szenario)  |\n| 3 | [Limit Service Time for Free-tier Users](https://github.com/loong/go-concurrency-exercises/tree/main/3-limit-service-time)  |\n| 4 | [Graceful SIGINT Killing](https://github.com/loong/go-concurrency-exercises/tree/main/4-graceful-sigint)  |\n| 5 | [Clean Inactive Sessions to Prevent Memory Overflow](https://github.com/loong/go-concurrency-exercises/tree/main/5-session-cleaner)  |\n\n## License\n\n```\n DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE \n                    Version 2, December 2004 \n\n Copyleft from 2017 Long Hoang\n\n Everyone is permitted to copy and distribute verbatim or modified \n copies of this license document, and changing it is allowed as long \n as the name is changed.\n\n            DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE \n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION \n\n  0. You just DO WHAT THE FUCK YOU WANT TO.\n```\n",
      "stars_today": 125
    },
    {
      "id": 868811259,
      "name": "prek",
      "full_name": "j178/prek",
      "description": "âš¡ Better `pre-commit`, re-engineered in Rust",
      "html_url": "https://github.com/j178/prek",
      "stars": 3522,
      "forks": 105,
      "language": "Rust",
      "topics": [
        "git",
        "git-hooks",
        "pre-commit"
      ],
      "created_at": "2024-10-07T08:21:29Z",
      "updated_at": "2026-01-16T00:25:39Z",
      "pushed_at": "2026-01-15T14:43:09Z",
      "open_issues": 72,
      "owner": {
        "login": "j178",
        "avatar_url": "https://avatars.githubusercontent.com/u/10510431?v=4"
      },
      "readme": "<div align=\"center\">\n\n<h1>\n  <img width=\"180\" alt=\"prek\" src=\"https://raw.githubusercontent.com/j178/prek/master/docs/assets/logo.webp\" />\n  <br/>prek\n</h1>\n\n[![prek](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/j178/prek/master/docs/assets/badge-v0.json)](https://github.com/j178/prek)\n[![codecov](https://codecov.io/github/j178/prek/graph/badge.svg?token=MP6TY24F43)](https://codecov.io/github/j178/prek)\n[![GitHub Downloads](https://img.shields.io/github/downloads/j178/prek/total?logo=github)](https://github.com/j178/prek/releases)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/prek?logo=python)](https://pepy.tech/projects/prek)\n[![Discord](https://img.shields.io/discord/1403581202102878289?logo=discord)](https://discord.gg/3NRJUqJz86)\n\n</div>\n\n<!-- description:start -->\n[pre-commit](https://pre-commit.com/) is a framework to run hooks written in many languages, and it manages the\nlanguage toolchain and dependencies for running the hooks.\n\n*prek* is a reimagined version of pre-commit, built in Rust.\nIt is designed to be a faster, dependency-free and drop-in alternative for it,\nwhile also providing some additional long-requested features.\n<!-- description:end -->\n\n> [!NOTE]\n> Although prek is pretty new, itâ€™s already powering realâ€‘world projects like [Apache Airflow](https://github.com/apache/airflow), [FastAPI](https://github.com/fastapi/fastapi), and more projects are picking it upâ€”see [Who is using prek?](#who-is-using-prek). If youâ€™re looking for an alternative to `pre-commit`, please give it a tryâ€”weâ€™d love your feedback!\n>\n> Please note that some subcommands and languages are still missing for full dropâ€‘in parity with `pre-commit`. Track the remaining gaps here: [TODO](https://prek.j178.dev/todo/).\n\n<!-- features:start -->\n## Features\n\n- ğŸš€ A single binary with no dependencies, does not require Python or any other runtime.\n- âš¡ [Faster](https://prek.j178.dev/benchmark/) than `pre-commit` and more efficient in disk space usage.\n- ğŸ”„ Fully compatible with the original pre-commit configurations and hooks.\n- ğŸ—ï¸ Built-in support for monorepos (i.e. [workspace mode](https://prek.j178.dev/workspace/)).\n- ğŸ Integration with [`uv`](https://github.com/astral-sh/uv) for managing Python virtual environments and dependencies.\n- ğŸ› ï¸ Improved toolchain installations for Python, Node.js, Go, Rust and Ruby, shared between hooks.\n- ğŸ“¦ [Built-in](https://prek.j178.dev/builtin/) Rust-native implementation of some common hooks.\n<!-- features:end -->\n\n## Table of contents\n\n- [Installation](#installation)\n- [Quick start](#quick-start)\n- [Why prek?](#why-prek)\n- [Who is using prek?](#who-is-using-prek)\n- [Acknowledgements](#acknowledgements)\n\n## Installation\n\n<details>\n<summary>Standalone installer</summary>\n\nprek provides a standalone installer script to download and install the tool,\n\nOn Linux and macOS:\n\n<!-- linux-standalone-install:start -->\n```bash\ncurl --proto '=https' --tlsv1.2 -LsSf https://github.com/j178/prek/releases/download/v0.2.28/prek-installer.sh | sh\n```\n<!-- linux-standalone-install:end -->\n\nOn Windows:\n\n<!-- windows-standalone-install:start -->\n```powershell\npowershell -ExecutionPolicy ByPass -c \"irm https://github.com/j178/prek/releases/download/v0.2.28/prek-installer.ps1 | iex\"\n```\n<!-- windows-standalone-install:end -->\n\n</details>\n\n<details>\n<summary>PyPI</summary>\n\n<!-- pypi-install:start -->\nprek is published as Python binary wheel to PyPI, you can install it using `pip`, `uv` (recommended), or `pipx`:\n\n```bash\n# Using uv (recommended)\nuv tool install prek\n\n# Using uvx (install and run in one command)\nuvx prek\n\n# Adding prek to the project dev-dependencies\nuv add --dev prek\n\n# Using pip\npip install prek\n\n# Using pipx\npipx install prek\n```\n<!-- pypi-install:end -->\n\n</details>\n\n<details>\n<summary>Homebrew</summary>\n\n<!-- homebrew-install:start -->\n```bash\nbrew install prek\n```\n<!-- homebrew-install:end -->\n\n</details>\n\n<details>\n<summary>mise</summary>\n\n<!-- mise-install:start -->\nTo use prek with [mise](https://mise.jdx.dev) ([v2025.8.11](https://github.com/jdx/mise/releases/tag/v2025.8.11) or later):\n\n```bash\nmise use prek\n```\n<!-- mise-install:end -->\n\n</details>\n\n<details>\n<summary>Cargo binstall</summary>\n\n<!-- cargo-binstall:start -->\nInstall pre-compiled binaries from GitHub using [cargo-binstall](https://github.com/cargo-bins/cargo-binstall):\n\n```bash\ncargo binstall prek\n```\n<!-- cargo-binstall:end -->\n\n</details>\n\n<details>\n<summary>Cargo</summary>\n\n<!-- cargo-install:start -->\nBuild from source using Cargo (Rust 1.89+ is required):\n\n```bash\ncargo install --locked prek\n```\n<!-- cargo-install:end -->\n\n</details>\n\n<details>\n<summary>npmjs</summary>\n\n<!-- npmjs-install:start -->\nprek is published as a Node.js package, you can install it using `npm`, `pnpm`, or `npx`:\n\n```bash\n# Using npm\nnpm add -D @j178/prek\n\n# Using pnpm\npnpm add -D @j178/prek\n\n# Using npx\nnpx @j178/prek --version\n\n# or install globally\nnpm install -g @j178/prek\n\n# then use `prek` command\nprek --version\n```\n<!-- npmjs-install:end -->\n\n</details>\n\n<details>\n<summary>Nix</summary>\n\n<!-- nix-install:start -->\nprek is available via [Nixpkgs](https://search.nixos.org/packages?channel=unstable&show=prek&query=prek).\n\n```shell\n# Choose what's appropriate for your use case.\n# One-off in a shell:\nnix-shell -p prek\n\n# NixOS or non-NixOS without flakes:\nnix-env -iA nixos.prek\n\n# Non-NixOS with flakes:\nnix profile install nixpkgs#prek\n```\n<!-- nix-install:end -->\n\n</details>\n\n<details>\n<summary>Conda</summary>\n\n<!-- conda-forge-install:start -->\nprek is available as `prek` via [conda-forge](https://anaconda.org/conda-forge/prek).\n\n```shell\nconda install conda-forge::prek\n```\n<!-- conda-forge-install:end -->\n\n</details>\n\n<details>\n<summary>Scoop (Windows)</summary>\n\n<!-- scoop-install:start -->\nprek is available via [Scoop](https://scoop.sh/#/apps?q=prek).\n\n```powershell\nscoop install main/prek\n```\n<!-- scoop-install:end -->\n</details>\n\n<details>\n<summary>MacPorts</summary>\n\n<!-- macports-install:start -->\nprek is available via [MacPorts](https://ports.macports.org/port/prek/).\n\n```bash\nsudo port install prek\n```\n<!-- macports-install:end -->\n</details>\n\n<details>\n<summary>GitHub Releases</summary>\n\n<!-- pre-built-binaries:start -->\nPre-built binaries are available for download from the [GitHub releases](https://github.com/j178/prek/releases) page.\n<!-- pre-built-binaries:end -->\n\n</details>\n\n<details>\n<summary>GitHub Actions</summary>\n\n<!-- github-actions:start -->\nprek can be used in GitHub Actions via the [j178/prek-action](https://github.com/j178/prek-action) repository.\n\nExample workflow:\n\n```yaml\nname: Prek checks\non: [push, pull_request]\n\njobs:\n  prek:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v6\n      - uses: j178/prek-action@v1\n```\n\nThis action installs prek and runs `prek run --all-files` on your repository.\n\nprek is also available via [`taiki-e/install-action`](https://github.com/taiki-e/install-action) for installing various tools.\n<!-- github-actions:end -->\n</details>\n\n<!-- self-update:start -->\nIf installed via the standalone installer, prek can update itself to the latest version:\n\n```bash\nprek self update\n```\n<!-- self-update:end -->\n\n## Quick start\n\n- **I already use pre-commit:** follow the short migration checklist in the [quickstart guide](https://prek.j178.dev/quickstart/#already-using-pre-commit) to swap in `prek` safely.\n- **I'm new to pre-commit-style tools:** learn the basicsâ€”creating a config, running hooks, and installing git hooksâ€”in the [beginner quickstart walkthrough](https://prek.j178.dev/quickstart/#new-to-pre-commit-style-workflows).\n\n<!-- why:start -->\n## Why prek?\n\n### prek is faster\n\n- It is [multiple times faster](https://prek.j178.dev/benchmark/) than `pre-commit` and takes up half the disk space.\n- It redesigned how hook environments and toolchains are managed, they are all shared between hooks, which reduces the disk space usage and speeds up the installation process.\n- Repositories are cloned in parallel, and hooks are installed in parallel if their dependencies are disjoint.\n- Hooks can run in parallel by priority (hooks with the same [`priority`](https://prek.j178.dev/configuration/#priority) may run concurrently), reducing end-to-end runtime.\n- It uses [`uv`](https://github.com/astral-sh/uv) for creating Python virtualenvs and installing dependencies, which is known for its speed and efficiency.\n- It implements some common hooks in Rust, [built in prek](https://prek.j178.dev/builtin/), which are faster than their Python counterparts.\n- It supports `repo: builtin` for offline, zero-setup hooks, which is not available in `pre-commit`.\n\n### prek provides a better user experience\n\n- No need to install Python or any other runtime, just download a single binary.\n- No hassle with your Python version or virtual environments, prek automatically installs the required Python version and creates a virtual environment for you.\n- Built-in support for [workspaces](https://prek.j178.dev/workspace/) (or monorepos), each subproject can have its own `.pre-commit-config.yaml` file.\n- [`prek run`](https://prek.j178.dev/cli/#prek-run) has some nifty improvements over `pre-commit run`, such as:\n  - `prek run --directory <dir>` runs hooks for files in the specified directory, no need to use `git ls-files -- <dir> | xargs pre-commit run --files` anymore.\n  - `prek run --last-commit` runs hooks for files changed in the last commit.\n  - `prek run [HOOK] [HOOK]` selects and runs multiple hooks.\n- [`prek list`](https://prek.j178.dev/cli/#prek-list) command lists all available hooks, their ids, and descriptions, providing a better overview of the configured hooks.\n- [`prek auto-update`](https://prek.j178.dev/cli/#prek-auto-update) supports `--cooldown-days` to mitigate open source supply chain attacks.\n- prek provides shell completions for `prek run <hook_id>` command, making it easier to run specific hooks without remembering their ids.\n\nFor more detailed improvements prek offers, take a look at [Difference from pre-commit](https://prek.j178.dev/diff/).\n\n## Who is using prek?\n\nprek is pretty new, but it is already being used or recommend by some projects and organizations:\n\n- [apache/airflow](https://github.com/apache/airflow/issues/44995)\n- [python/cpython](https://github.com/python/cpython/issues/143148)\n- [pdm-project/pdm](https://github.com/pdm-project/pdm/pull/3593)\n- [fastapi/fastapi](https://github.com/fastapi/fastapi/pull/14572)\n- [fastapi/typer](https://github.com/fastapi/typer/pull/1453)\n- [fastapi/asyncer](https://github.com/fastapi/asyncer/pull/437)\n- [astral-sh/ruff](https://github.com/astral-sh/ruff/pull/22505)\n- [astral-sh/ty](https://github.com/astral-sh/ty/pull/2469)\n- [home-assistant/core](https://github.com/home-assistant/core/pull/160427)\n- [DetachHead/basedpyright](https://github.com/DetachHead/basedpyright/pull/1413)\n- [OpenLineage/OpenLineage](https://github.com/OpenLineage/OpenLineage/pull/3965)\n- [authlib/authlib](https://github.com/authlib/authlib/pull/804)\n- [django/djangoproject.com](https://github.com/django/djangoproject.com/pull/2252)\n- [Future-House/paper-qa](https://github.com/Future-House/paper-qa/pull/1098)\n- [requests-cache/requests-cache](https://github.com/requests-cache/requests-cache/pull/1116)\n- [Goldziher/kreuzberg](https://github.com/Goldziher/kreuzberg/pull/142)\n- [python-attrs/attrs](https://github.com/python-attrs/attrs/commit/c95b177682e76a63478d29d040f9cb36a8d31915)\n- [jlowin/fastmcp](https://github.com/jlowin/fastmcp/pull/2309)\n- [apache/iceberg-python](https://github.com/apache/iceberg-python/pull/2533)\n- [jcrist/msgspec](https://github.com/jcrist/msgspec/pull/918)\n- [python-humanize/humanize](https://github.com/python-humanize/humanize/pull/276)\n- [MoonshotAI/kimi-cli](https://github.com/MoonshotAI/kimi-cli/pull/535)\n- [ZhuoZhuoCrayon/throttled-py](https://github.com/ZhuoZhuoCrayon/throttled-py/pull/119)\n\n<!-- why:end -->\n\n## Acknowledgements\n\nThis project is heavily inspired by the original [pre-commit](https://pre-commit.com/) tool, and it wouldn't be possible without the hard work\nof the maintainers and contributors of that project.\n\nAnd a special thanks to the [Astral](https://github.com/astral-sh) team for their remarkable projects, particularly [uv](https://github.com/astral-sh/uv),\nfrom which I've learned a lot on how to write efficient and idiomatic Rust code.\n",
      "stars_today": 116
    },
    {
      "id": 167694194,
      "name": "frigate",
      "full_name": "blakeblackshear/frigate",
      "description": "NVR with realtime local object detection for IP cameras",
      "html_url": "https://github.com/blakeblackshear/frigate",
      "stars": 29361,
      "forks": 2739,
      "language": "TypeScript",
      "topics": [
        "ai",
        "camera",
        "google-coral",
        "home-assistant",
        "home-automation",
        "homeautomation",
        "mqtt",
        "nvr",
        "object-detection",
        "realtime",
        "rtsp",
        "tensorflow"
      ],
      "created_at": "2019-01-26T13:52:38Z",
      "updated_at": "2026-01-16T00:56:04Z",
      "pushed_at": "2026-01-15T17:31:00Z",
      "open_issues": 144,
      "owner": {
        "login": "blakeblackshear",
        "avatar_url": "https://avatars.githubusercontent.com/u/569905?v=4"
      },
      "readme": "<p align=\"center\">\n  <img align=\"center\" alt=\"logo\" src=\"docs/static/img/branding/frigate.png\">\n</p>\n\n# Frigate NVRâ„¢ - Realtime Object Detection for IP Cameras\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n<a href=\"https://hosted.weblate.org/engage/frigate-nvr/\">\n<img src=\"https://hosted.weblate.org/widget/frigate-nvr/language-badge.svg\" alt=\"Translation status\" />\n</a>\n\n\\[English\\] | [ç®€ä½“ä¸­æ–‡](https://github.com/blakeblackshear/frigate/blob/dev/README_CN.md)\n\nA complete and local NVR designed for [Home Assistant](https://www.home-assistant.io) with AI object detection. Uses OpenCV and Tensorflow to perform realtime object detection locally for IP cameras.\n\nUse of a GPU or AI accelerator is highly recommended. AI accelerators will outperform even the best CPUs with very little overhead. See Frigate's supported [object detectors](https://docs.frigate.video/configuration/object_detectors/).\n\n- Tight integration with Home Assistant via a [custom component](https://github.com/blakeblackshear/frigate-hass-integration)\n- Designed to minimize resource use and maximize performance by only looking for objects when and where it is necessary\n- Leverages multiprocessing heavily with an emphasis on realtime over processing every frame\n- Uses a very low overhead motion detection to determine where to run object detection\n- Object detection with TensorFlow runs in separate processes for maximum FPS\n- Communicates over MQTT for easy integration into other systems\n- Records video with retention settings based on detected objects\n- 24/7 recording\n- Re-streaming via RTSP to reduce the number of connections to your camera\n- WebRTC & MSE support for low-latency live view\n\n## Documentation\n\nView the documentation at https://docs.frigate.video\n\n## Donations\n\nIf you would like to make a donation to support development, please use [Github Sponsors](https://github.com/sponsors/blakeblackshear).\n\n## License\n\nThis project is licensed under the **MIT License**.\n\n- **Code:** The source code, configuration files, and documentation in this repository are available under the [MIT License](LICENSE). You are free to use, modify, and distribute the code as long as you include the original copyright notice.\n- **Trademarks:** The \"Frigate\" name, the \"Frigate NVR\" brand, and the Frigate logo are **trademarks of Frigate, Inc.** and are **not** covered by the MIT License.\n\nPlease see our [Trademark Policy](TRADEMARK.md) for details on acceptable use of our brand assets.\n\n## Screenshots\n\n### Live dashboard\n\n<div>\n<img width=\"800\" alt=\"Live dashboard\" src=\"https://github.com/blakeblackshear/frigate/assets/569905/5e713cb9-9db5-41dc-947a-6937c3bc376e\">\n</div>\n\n### Streamlined review workflow\n\n<div>\n<img width=\"800\" alt=\"Streamlined review workflow\" src=\"https://github.com/blakeblackshear/frigate/assets/569905/6fed96e8-3b18-40e5-9ddc-31e6f3c9f2ff\">\n</div>\n\n### Multi-camera scrubbing\n\n<div>\n<img width=\"800\" alt=\"Multi-camera scrubbing\" src=\"https://github.com/blakeblackshear/frigate/assets/569905/d6788a15-0eeb-4427-a8d4-80b93cae3d74\">\n</div>\n\n### Built-in mask and zone editor\n\n<div>\n<img width=\"800\" alt=\"Built-in mask and zone editor\" src=\"https://github.com/blakeblackshear/frigate/assets/569905/d7885fc3-bfe6-452f-b7d0-d957cb3e31f5\">\n</div>\n\n## Translations\n\nWe use [Weblate](https://hosted.weblate.org/projects/frigate-nvr/) to support language translations. Contributions are always welcome.\n\n<a href=\"https://hosted.weblate.org/engage/frigate-nvr/\">\n<img src=\"https://hosted.weblate.org/widget/frigate-nvr/multi-auto.svg\" alt=\"Translation status\" />\n</a>\n\n---\n\n**Copyright Â© 2026 Frigate, Inc.**\n",
      "stars_today": 96
    },
    {
      "id": 722597620,
      "name": "rustfs",
      "full_name": "rustfs/rustfs",
      "description": "ğŸš€2.3x faster than MinIO for 4KB object payloads. RustFS is an open-source, S3-compatible high-performance object storage system supporting migration and coexistence with other S3-compatible platforms such as MinIO and Ceph.",
      "html_url": "https://github.com/rustfs/rustfs",
      "stars": 19787,
      "forks": 850,
      "language": "Rust",
      "topics": [
        "amazon-s3",
        "bigdata",
        "cloud-native",
        "filesystem",
        "minio",
        "object-storage",
        "objectstorage",
        "rust",
        "s3"
      ],
      "created_at": "2023-11-23T13:45:10Z",
      "updated_at": "2026-01-16T00:15:20Z",
      "pushed_at": "2026-01-16T00:12:05Z",
      "open_issues": 67,
      "owner": {
        "login": "rustfs",
        "avatar_url": "https://avatars.githubusercontent.com/u/151849438?v=4"
      },
      "readme": "[![RustFS](https://rustfs.com/images/rustfs-github.png)](https://rustfs.com)\n\n<p align=\"center\">RustFS is a high-performance, distributed object storage system built in Rust.</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/rustfs/rustfs/actions/workflows/ci.yml\"><img alt=\"CI\" src=\"https://github.com/rustfs/rustfs/actions/workflows/ci.yml/badge.svg\" /></a>\n  <a href=\"https://github.com/rustfs/rustfs/actions/workflows/docker.yml\"><img alt=\"Build and Push Docker Images\" src=\"https://github.com/rustfs/rustfs/actions/workflows/docker.yml/badge.svg\" /></a>\n  <img alt=\"GitHub commit activity\" src=\"https://img.shields.io/github/commit-activity/m/rustfs/rustfs\"/>\n  <img alt=\"Github Last Commit\" src=\"https://img.shields.io/github/last-commit/rustfs/rustfs\"/>\n  <a href=\"https://hellogithub.com/repository/rustfs/rustfs\" target=\"_blank\"><img src=\"https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=b95bcb72bdc340b68f16fdf6790b7d5b&claim_uid=MsbvjYeLDKAH457&theme=small\" alt=\"Featuredï½œHelloGitHub\" /></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/14181\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/14181\" alt=\"rustfs%2Frustfs | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n\n<p align=\"center\">\n  <a href=\"https://docs.rustfs.com/installation/\">Getting Started</a>\n  Â· <a href=\"https://docs.rustfs.com/\">Docs</a>\n  Â· <a href=\"https://github.com/rustfs/rustfs/issues\">Bug reports</a>\n  Â· <a href=\"https://github.com/rustfs/rustfs/discussions\">Discussions</a>\n</p>\n\n<p align=\"center\">\nEnglish | <a href=\"https://github.com/rustfs/rustfs/blob/main/README_ZH.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=de\">Deutsch</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=es\">EspaÃ±ol</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=fr\">franÃ§ais</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=ja\">æ—¥æœ¬èª</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=ko\">í•œêµ­ì–´</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=pt\">Portuguese</a> |\n  <a href=\"https://readme-i18n.com/rustfs/rustfs?lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n</p>\n\nRustFS is a high-performance, distributed object storage system built in Rustâ€”one of the most loved programming languages worldwide. RustFS combines the simplicity of MinIO with the memory safety and raw performance of Rust. It offers full S3 compatibility, is completely open-source, and is optimized for data lakes, AI, and big data workloads.\n\nUnlike other storage systems, RustFS is released under the permissible Apache 2.0 license, avoiding the restrictions of AGPL. With Rust as its foundation, RustFS delivers superior speed and secure distributed features for next-generation object storage.\n\n## Feature & Status\n\n- **High Performance**: Built with Rust to ensure maximum speed and resource efficiency.\n- **Distributed Architecture**: Scalable and fault-tolerant design suitable for large-scale deployments.\n- **S3 Compatibility**: Seamless integration with existing S3-compatible applications and tools.\n- **Data Lake Support**: Optimized for high-throughput big data and AI workloads.\n- **Open Source**: Licensed under Apache 2.0, encouraging unrestricted community contributions and commercial usage.\n- **User-Friendly**: Designed with simplicity in mind for easy deployment and management.\n\n| Feature | Status | Feature | Status |\n| :--- | :--- | :--- | :--- |\n| **S3 Core Features** | âœ… Available | **Bitrot Protection** | âœ… Available |\n| **Upload / Download** | âœ… Available | **Single Node Mode** | âœ… Available |\n| **Versioning** | âœ… Available |  **Bucket Replication** | âœ… Available |\n| **Logging** | âœ… Available |  **Lifecycle Management** | ğŸš§ Under Testing |\n| **Event Notifications** | âœ… Available |  **Distributed Mode** | ğŸš§ Under Testing |\n| **K8s Helm Charts** | âœ… Available |   **RustFS KMS** | ğŸš§ Under Testing | \n\n\n\n\n## RustFS vs MinIO Performance\n\n**Stress Test Environment:**\n\n| Type    | Parameter | Remark                                                   |\n|---------|-----------|----------------------------------------------------------|\n| CPU     | 2 Core    | Intel Xeon (Sapphire Rapids) Platinum 8475B, 2.7/3.2 GHz |\n| Memory  | 4GB       |                                                          |\n| Network | 15Gbps    |                                                          |\n| Drive   | 40GB x 4  | IOPS 3800 / Drive                                        |\n\n<https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a>\n\n### RustFS vs Other Object Storage\n\n| Feature | RustFS | Other Object Storage |\n| :--- | :--- | :--- |\n| **Console Experience** | **Powerful Console**<br>Comprehensive management interface. | **Basic / Limited Console**<br>Often overly simple or lacking critical features. |\n| **Language & Safety** | **Rust-based**<br>Memory safety by design. | **Go or C-based**<br>Potential for memory GC pauses or leaks. |\n| **Data Sovereignty** | **No Telemetry / Full Compliance**<br>Guards against unauthorized cross-border data egress. Compliant with GDPR (EU/UK), CCPA (US), and APPI (Japan). | **Potential Risk**<br>Possible legal exposure and unwanted data telemetry. |\n| **Licensing** | **Permissive Apache 2.0**<br>Business-friendly, no \"poison pill\" clauses. | **Restrictive AGPL v3**<br>Risk of license traps and intellectual property pollution. |\n| **Compatibility** | **100% S3 Compatible**<br>Works with any cloud provider or client, anywhere. | **Variable Compatibility**<br>May lack support for local cloud vendors or specific APIs. |\n| **Edge & IoT** | **Strong Edge Support**<br>Ideal for secure, innovative edge devices. | **Weak Edge Support**<br>Often too heavy for edge gateways. |\n| **Risk Profile** | **Enterprise Risk Mitigation**<br>Clear IP rights and safe for commercial use. | **Legal Risks**<br>Intellectual property ambiguity and usage restrictions. |\n\n\n## Staying ahead\n\nStar RustFS on GitHub and be instantly notified of new releases.\n\n<img src=\"https://github.com/user-attachments/assets/7ee40bb4-3e46-4eac-b0d0-5fbeb85ff8f3\" />\n\n## Quickstart\n\nTo get started with RustFS, follow these steps:\n\n### 1. One-click Installation (Option 1)\n\n  ```bash\n  curl -O https://rustfs.com/install_rustfs.sh && bash install_rustfs.sh\n````\n\n### 2\\. Docker Quick Start (Option 2)\n\nThe RustFS container runs as a non-root user `rustfs` (UID `10001`). If you run Docker with `-v` to mount a host directory, please ensure the host directory owner is set to `10001`, otherwise you will encounter permission denied errors.\n\n```bash\n # Create data and logs directories\n mkdir -p data logs\n\n # Change the owner of these directories\n chown -R 10001:10001 data logs\n\n # Using latest version\n docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:latest\n\n # Using specific version\n docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:1.0.0-alpha.76\n```\n\nYou can also use Docker Compose. Using the `docker-compose.yml` file in the root directory:\n\n```bash\ndocker compose --profile observability up -d\n```\n\n**NOTE**: We recommend reviewing the `docker-compose.yaml` file before running. It defines several services including Grafana, Prometheus, and Jaeger, which are helpful for RustFS observability. If you wish to start Redis or Nginx containers, you can specify the corresponding profiles.\n\n### 3\\. Build from Source (Option 3) - Advanced Users\n\nFor developers who want to build RustFS Docker images from source with multi-architecture support:\n\n```bash\n# Build multi-architecture images locally\n./docker-buildx.sh --build-arg RELEASE=latest\n\n# Build and push to registry\n./docker-buildx.sh --push\n\n# Build specific version\n./docker-buildx.sh --release v1.0.0 --push\n\n# Build for custom registry\n./docker-buildx.sh --registry your-registry.com --namespace yourname --push\n```\n\nThe `docker-buildx.sh` script supports:\n\\- **Multi-architecture builds**: `linux/amd64`, `linux/arm64`\n\\- **Automatic version detection**: Uses git tags or commit hashes\n\\- **Registry flexibility**: Supports Docker Hub, GitHub Container Registry, etc.\n\\- **Build optimization**: Includes caching and parallel builds\n\nYou can also use Make targets for convenience:\n\n```bash\nmake docker-buildx                    # Build locally\nmake docker-buildx-push               # Build and push\nmake docker-buildx-version VERSION=v1.0.0  # Build specific version\nmake help-docker                      # Show all Docker-related commands\n```\n\n> **Heads-up (macOS cross-compilation)**: macOS keeps the default `ulimit -n` at 256, so `cargo zigbuild` or `./build-rustfs.sh --platform ...` may fail with `ProcessFdQuotaExceeded` when targeting Linux. The build script attempts to raise the limit automatically, but if you still see the warning, run `ulimit -n 4096` (or higher) in your shell before building.\n\n### 4\\. Build with Helm Chart (Option 4) - Cloud Native\n\nFollow the instructions in the [Helm Chart README](https://charts.rustfs.com/) to install RustFS on a Kubernetes cluster.\n\n### 5\\. Nix Flake (Option 5)\n\nIf you have [Nix with flakes enabled](https://nixos.wiki/wiki/Flakes#Enable_flakes):\n\n```bash\n# Run directly without installing\nnix run github:rustfs/rustfs\n\n# Build the binary\nnix build github:rustfs/rustfs\n./result/bin/rustfs --help\n\n# Or from a local checkout\nnix build\nnix run\n```\n\n-----\n\n### Accessing RustFS\n\n5.  **Access the Console**: Open your web browser and navigate to `http://localhost:9001` to access the RustFS console.\n      * Default credentials: `rustfsadmin` / `rustfsadmin`\n6.  **Create a Bucket**: Use the console to create a new bucket for your objects.\n7.  **Upload Objects**: You can upload files directly through the console or use S3-compatible APIs/clients to interact with your RustFS instance.\n\n**NOTE**: To access the RustFS instance via `https`, please refer to the [TLS Configuration Docs](https://docs.rustfs.com/integration/tls-configured.html).\n\n## Documentation\n\nFor detailed documentation, including configuration options, API references, and advanced usage, please visit our [Documentation](https://docs.rustfs.com).\n\n## Getting Help\n\nIf you have any questions or need assistance:\n\n  - Check the [FAQ](https://github.com/rustfs/rustfs/discussions/categories/q-a) for common issues and solutions.\n  - Join our [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) to ask questions and share your experiences.\n  - Open an issue on our [GitHub Issues](https://github.com/rustfs/rustfs/issues) page for bug reports or feature requests.\n\n## Links\n\n  - [Documentation](https://docs.rustfs.com) - The manual you should read\n  - [Changelog](https://github.com/rustfs/rustfs/releases) - What we broke and fixed\n  - [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) - Where the community lives\n\n## Contact\n\n  - **Bugs**: [GitHub Issues](https://github.com/rustfs/rustfs/issues)\n  - **Business**: [hello@rustfs.com](mailto:hello@rustfs.com)\n  - **Jobs**: [jobs@rustfs.com](mailto:jobs@rustfs.com)\n  - **General Discussion**: [GitHub Discussions](https://github.com/rustfs/rustfs/discussions)\n  - **Contributing**: [CONTRIBUTING.md](CONTRIBUTING.md)\n\n## Contributors\n\nRustFS is a community-driven project, and we appreciate all contributions. Check out the [Contributors](https://github.com/rustfs/rustfs/graphs/contributors) page to see the amazing people who have helped make RustFS better.\n\n<a href=\"https://github.com/rustfs/rustfs/graphs/contributors\">\n<img src=\"https://opencollective.com/rustfs/contributors.svg?width=890&limit=500&button=false\" alt=\"Contributors\" />\n</a>\n\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=rustfs/rustfs&type=date&legend=top-left)](https://www.star-history.com/#rustfs/rustfs&type=date&legend=top-left)\n\n## License\n\n[Apache 2.0](https://opensource.org/licenses/Apache-2.0)\n\n**RustFS** is a trademark of RustFS, Inc. All other trademarks are the property of their respective owners.\n\n",
      "stars_today": 90
    },
    {
      "id": 501045649,
      "name": "waveterm",
      "full_name": "wavetermdev/waveterm",
      "description": "An open-source, cross-platform terminal for seamless workflows",
      "html_url": "https://github.com/wavetermdev/waveterm",
      "stars": 16440,
      "forks": 708,
      "language": "Go",
      "topics": [
        "command-line",
        "developer-tools",
        "linux",
        "macos",
        "productivity",
        "terminal",
        "terminal-emulators",
        "windows"
      ],
      "created_at": "2022-06-08T00:26:00Z",
      "updated_at": "2026-01-16T01:03:55Z",
      "pushed_at": "2026-01-15T22:35:26Z",
      "open_issues": 427,
      "owner": {
        "login": "wavetermdev",
        "avatar_url": "https://avatars.githubusercontent.com/u/120279640?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://www.waveterm.dev\">\n\t<picture>\n\t\t<source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/wave-dark.png\">\n\t\t<source media=\"(prefers-color-scheme: light)\" srcset=\"./assets/wave-light.png\">\n\t\t<img alt=\"Wave Terminal Logo\" src=\"./assets/wave-light.png\" width=\"240\">\n\t</picture>\n  </a>\n  <br/>\n</p>\n\n# Wave Terminal\n\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield)\n\nWave is an open-source terminal that combines traditional terminal features with graphical capabilities like file previews, web browsing, and AI assistance. It runs on MacOS, Linux, and Windows.\n\nModern development involves constantly switching between terminals and browsers - checking documentation, previewing files, monitoring systems, and using AI tools. Wave brings these graphical tools directly into the terminal, letting you control them from the command line. This means you can stay in your terminal workflow while still having access to the visual interfaces you need.\n\n![WaveTerm Screenshot](./assets/wave-screenshot.webp)\n\n## Key Features\n\n- Flexible drag & drop interface to organize terminal blocks, editors, web browsers, and AI assistants\n- Built-in editor for seamlessly editing remote files with syntax highlighting and modern editor features\n- Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)\n- Quick full-screen toggle for any block - expand terminals, editors, and previews for better visibility, then instantly return to multi-block view\n- Wave AI - Context-aware terminal assistant that reads your terminal output, analyzes widgets, and performs file operations\n- AI chat widget with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)\n- Command Blocks for isolating and monitoring individual commands with auto-close options\n- One-click remote connections with full terminal and file system access\n- Secure secret storage using native system backends - store API keys and credentials locally, access them across SSH sessions\n- Rich customization including tab themes, terminal styles, and background images\n- Powerful `wsh` command system for managing your workspace from the CLI and sharing data between terminal sessions\n- Connected file management with `wsh file` - seamlessly copy and sync files between local, remote SSH hosts, Wave filesystem, and S3\n\n## Wave AI\n\nWave AI is your context-aware terminal assistant with access to your workspace:\n\n- **Terminal Context**: Reads terminal output and scrollback for debugging and analysis\n- **File Operations**: Read, write, and edit files with automatic backups and user approval\n- **CLI Integration**: Use `wsh ai` to pipe output or attach files directly from the command line\n- **Free Beta**: Included AI credits while we refine the experience\n- **Coming Soon**: Command execution (with approval), local model support, and alternate AI providers (BYOK)\n\nLearn more in our [Wave AI documentation](https://docs.waveterm.dev/waveai).\n\n## Installation\n\nWave Terminal works on macOS, Linux, and Windows.\n\nPlatform-specific installation instructions can be found [here](https://docs.waveterm.dev/gettingstarted).\n\nYou can also install Wave Terminal directly from: [www.waveterm.dev/download](https://www.waveterm.dev/download).\n\n### Minimum requirements\n\nWave Terminal runs on the following platforms:\n\n- macOS 11 or later (arm64, x64)\n- Windows 10 1809 or later (x64)\n- Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)\n\nThe WSH helper runs on the following platforms:\n\n- macOS 11 or later (arm64, x64)\n- Windows 10 or later (arm64, x64)\n- Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)\n\n## Roadmap\n\nWave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it [here](./ROADMAP.md).\n\nWant to provide input to our future releases? Connect with us on [Discord](https://discord.gg/XfvZ334gwU) or open a [Feature Request](https://github.com/wavetermdev/waveterm/issues/new/choose)!\n\n## Links\n\n- Homepage &mdash; https://www.waveterm.dev\n- Download Page &mdash; https://www.waveterm.dev/download\n- Documentation &mdash; https://docs.waveterm.dev\n- Legacy Documentation &mdash; https://legacydocs.waveterm.dev\n- Blog &mdash; https://blog.waveterm.dev\n- X &mdash; https://x.com/wavetermdev\n- Discord Community &mdash; https://discord.gg/XfvZ334gwU\n\n## Building from Source\n\nSee [Building Wave Terminal](BUILD.md).\n\n## Contributing\n\nWave uses GitHub Issues for issue tracking.\n\nFind more information in our [Contributions Guide](CONTRIBUTING.md), which includes:\n\n- [Ways to contribute](CONTRIBUTING.md#contributing-to-wave-terminal)\n- [Contribution guidelines](CONTRIBUTING.md#before-you-start)\n\n## License\n\nWave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see [here](./ACKNOWLEDGEMENTS.md).\n",
      "stars_today": 88
    },
    {
      "id": 649170660,
      "name": "anything-llm",
      "full_name": "Mintplex-Labs/anything-llm",
      "description": "The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, MCP compatibility,  and more.",
      "html_url": "https://github.com/Mintplex-Labs/anything-llm",
      "stars": 53376,
      "forks": 5730,
      "language": "JavaScript",
      "topics": [
        "ai-agents",
        "custom-ai-agents",
        "deepseek",
        "kimi",
        "llama3",
        "llm",
        "lmstudio",
        "local-llm",
        "localai",
        "mcp",
        "mcp-servers",
        "moonshot",
        "multimodal",
        "no-code",
        "ollama",
        "qwen3",
        "rag",
        "vector-database",
        "web-scraping"
      ],
      "created_at": "2023-06-04T02:29:14Z",
      "updated_at": "2026-01-16T01:05:09Z",
      "pushed_at": "2026-01-16T00:25:02Z",
      "open_issues": 271,
      "owner": {
        "login": "Mintplex-Labs",
        "avatar_url": "https://avatars.githubusercontent.com/u/134426827?v=4"
      },
      "readme": "<a name=\"readme-top\"></a>\n\n<p align=\"center\">\n  <a href=\"https://anythingllm.com\"><img src=\"https://github.com/Mintplex-Labs/anything-llm/blob/master/images/wordmark.png?raw=true\" alt=\"AnythingLLM logo\"></a>\n</p>\n\n<div align='center'>\n<a href=\"https://trendshift.io/repositories/2415\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/2415\" alt=\"Mintplex-Labs%2Fanything-llm | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</div>\n\n<p align=\"center\">\n    <b>AnythingLLM:</b> The all-in-one AI app you were looking for.<br />\n    Chat with your docs, use AI Agents, hyper-configurable, multi-user, & no frustrating setup required.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://discord.gg/6UyHPeGZAC\" target=\"_blank\">\n      <img src=\"https://img.shields.io/badge/chat-mintplex_labs-blue.svg?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAAIGNIUk0AAHomAACAhAAA+gAAAIDoAAB1MAAA6mAAADqYAAAXcJy6UTwAAAH1UExURQAAAP////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////r6+ubn5+7u7/3+/v39/enq6urq6/v7+97f39rb26eoqT1BQ0pOT4+Rkuzs7cnKykZKS0NHSHl8fdzd3ejo6UxPUUBDRdzc3RwgIh8jJSAkJm5xcvHx8aanqB4iJFBTVezt7V5hYlJVVuLj43p9fiImKCMnKZKUlaaoqSElJ21wcfT09O3u7uvr6zE0Nr6/wCUpK5qcnf7+/nh7fEdKTHx+f0tPUOTl5aipqiouMGtubz5CRDQ4OsTGxufn515hY7a3uH1/gXBydIOFhlVYWvX29qaoqCQoKs7Pz/Pz87/AwUtOUNfY2dHR0mhrbOvr7E5RUy8zNXR2d/f39+Xl5UZJSx0hIzQ3Odra2/z8/GlsbaGjpERHSezs7L/BwScrLTQ4Odna2zM3Obm7u3x/gKSmp9jZ2T1AQu/v71pdXkVISr2+vygsLiInKTg7PaOlpisvMcXGxzk8PldaXPLy8u7u7rm6u7S1tsDBwvj4+MPExbe4ueXm5s/Q0Kyf7ewAAAAodFJOUwAABClsrNjx/QM2l9/7lhmI6jTB/kA1GgKJN+nea6vy/MLZQYeVKK3rVA5tAAAAAWJLR0QB/wIt3gAAAAd0SU1FB+cKBAAmMZBHjXIAAAISSURBVDjLY2CAAkYmZhZWNnYODnY2VhZmJkYGVMDIycXNw6sBBbw8fFycyEoYGfkFBDVQgKAAPyMjQl5IWEQDDYgIC8FUMDKKsmlgAWyiEBWMjGJY5YEqxMAqGMWFNXAAYXGgAkYJSQ2cQFKCkYFRShq3AmkpRgYJbghbU0tbB0Tr6ukbgGhDI10gySfBwCwDUWBsYmpmDqQtLK2sbTQ0bO3sHYA8GWYGWWj4WTs6Obu4ami4OTm7exhqeHp5+4DCVJZBDmqdr7ufn3+ArkZgkJ+fU3CIRmgYWFiOARYGvo5OQUHhEUAFTkF+kVHRsLBgkIeyYmLjwoOc4hMSk5JTnINS06DC8gwcEEZ6RqZGlpOfc3ZObl5+gZ+TR2ERWFyBQQFMF5eklmqUpQb5+ReU61ZUOvkFVVXXQBSAraitq29o1GiKcfLzc29u0mjxBzq0tQ0kww5xZHtHUGeXhkZhdxBYgZ4d0LI6c4gjwd7siQQraOp1AivQ6CuAKZCDBBRQQQNQgUb/BGf3cqCCiZOcnCe3QQIKHNRTpk6bDgpZjRkzg3pBQTBrdtCcuZCgluAD0vPmL1gIdvSixUuWgqNs2YJ+DUhkEYxuggkGmOQUcckrioPTJCOXEnZ5JS5YslbGnuyVERlDDFvGEUPOWvwqaH6RVkHKeuDMK6SKnHlVhTgx8jeTmqy6Eij7K6nLqiGyPwChsa1MUrnq1wAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMy0xMC0wNFQwMDozODo0OSswMDowMB9V0a8AAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjMtMTAtMDRUMDA6Mzg6NDkrMDA6MDBuCGkTAAAAKHRFWHRkYXRlOnRpbWVzdGFtcAAyMDIzLTEwLTA0VDAwOjM4OjQ5KzAwOjAwOR1IzAAAAABJRU5ErkJggg==\" alt=\"Discord\">\n  </a> |\n  <a href=\"https://github.com/Mintplex-Labs/anything-llm/blob/master/LICENSE\" target=\"_blank\">\n      <img src=\"https://img.shields.io/static/v1?label=license&message=MIT&color=white\" alt=\"License\">\n  </a> |\n  <a href=\"https://docs.anythingllm.com\" target=\"_blank\">\n    Docs\n  </a> |\n   <a href=\"https://my.mintplexlabs.com/aio-checkout?product=anythingllm\" target=\"_blank\">\n    Hosted Instance\n  </a>\n</p>\n\n<p align=\"center\">\n  <b>English</b> Â· <a href='./locales/README.zh-CN.md'>ç®€ä½“ä¸­æ–‡</a> Â· <a href='./locales/README.ja-JP.md'>æ—¥æœ¬èª</a>\n</p>\n\n<p align=\"center\">\nğŸ‘‰ AnythingLLM for desktop (Mac, Windows, & Linux)! <a href=\"https://anythingllm.com/download\" target=\"_blank\"> Download Now</a>\n</p>\n\nA full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as a reference during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions.\n\n![Chatting](https://github.com/Mintplex-Labs/anything-llm/assets/16845892/cfc5f47c-bd91-4067-986c-f3f49621a859)\n\n<details>\n<summary><kbd>Watch the demo!</kbd></summary>\n\n[![Watch the video](/images/youtube.png)](https://youtu.be/f95rGD9trL0)\n\n</details>\n\n### Product Overview\n\nAnythingLLM is a full-stack application where you can use commercial off-the-shelf LLMs or popular open source LLMs and vectorDB solutions to build a private ChatGPT with no compromises that you can run locally as well as host remotely and be able to chat intelligently with any documents you provide it.\n\nAnythingLLM divides your documents into objects called `workspaces`. A Workspace functions a lot like a thread, but with the addition of containerization of your documents. Workspaces can share documents, but they do not talk to each other so you can keep your context for each workspace clean.\n\n## Cool features of AnythingLLM\n\n- ğŸ†• [**Full MCP-compatibility**](https://docs.anythingllm.com/mcp-compatibility/overview)\n- ğŸ†• [**No-code AI Agent builder**](https://docs.anythingllm.com/agent-flows/overview)\n- ğŸ–¼ï¸ **Multi-modal support (both closed and open-source LLMs!)**\n- [**Custom AI Agents**](https://docs.anythingllm.com/agent/custom/introduction)\n- ğŸ‘¤ Multi-user instance support and permissioning _Docker version only_\n- ğŸ¦¾ Agents inside your workspace (browse the web, etc)\n- ğŸ’¬ [Custom Embeddable Chat widget for your website](https://github.com/Mintplex-Labs/anythingllm-embed/blob/main/README.md) _Docker version only_\n- ğŸ“– Multiple document type support (PDF, TXT, DOCX, etc)\n- Simple chat UI with Drag-n-Drop functionality and clear citations.\n- 100% Cloud deployment ready.\n- Works with all popular [closed and open-source LLM providers](#supported-llms-embedder-models-speech-models-and-vector-databases).\n- Built-in cost & time-saving measures for managing very large documents compared to any other chat UI.\n- Full Developer API for custom integrations!\n- Much more...install and find out!\n\n### Supported LLMs, Embedder Models, Speech models, and Vector Databases\n\n**Large Language Models (LLMs):**\n\n- [Any open-source llama.cpp compatible model](/server/storage/models/README.md#text-generation-llm-selection)\n- [OpenAI](https://openai.com)\n- [OpenAI (Generic)](https://openai.com)\n- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)\n- [AWS Bedrock](https://aws.amazon.com/bedrock/)\n- [Anthropic](https://www.anthropic.com/)\n- [NVIDIA NIM (chat models)](https://build.nvidia.com/explore/discover)\n- [Google Gemini Pro](https://ai.google.dev/)\n- [Hugging Face (chat models)](https://huggingface.co/)\n- [Ollama (chat models)](https://ollama.ai/)\n- [LM Studio (all models)](https://lmstudio.ai)\n- [LocalAI (all models)](https://localai.io/)\n- [Together AI (chat models)](https://www.together.ai/)\n- [Fireworks AI  (chat models)](https://fireworks.ai/)\n- [Perplexity (chat models)](https://www.perplexity.ai/)\n- [OpenRouter (chat models)](https://openrouter.ai/)\n- [DeepSeek (chat models)](https://deepseek.com/)\n- [Mistral](https://mistral.ai/)\n- [Groq](https://groq.com/)\n- [Cohere](https://cohere.com/)\n- [KoboldCPP](https://github.com/LostRuins/koboldcpp)\n- [LiteLLM](https://github.com/BerriAI/litellm)\n- [Text Generation Web UI](https://github.com/oobabooga/text-generation-webui)\n- [Apipie](https://apipie.ai/)\n- [xAI](https://x.ai/)\n- [Z.AI (chat models)](https://z.ai/model-api)\n- [Novita AI (chat models)](https://novita.ai/model-api/product/llm-api?utm_source=github_anything-llm&utm_medium=github_readme&utm_campaign=link)\n- [PPIO](https://ppinfra.com?utm_source=github_anything-llm)\n- [Gitee AI](https://ai.gitee.com/)\n- [Moonshot AI](https://www.moonshot.ai/)\n- [Microsoft Foundry Local](https://github.com/microsoft/Foundry-Local)\n- [CometAPI (chat models)](https://api.cometapi.com/)\n- [Docker Model Runner](https://docs.docker.com/ai/model-runner/)\n\n**Embedder models:**\n\n- [AnythingLLM Native Embedder](/server/storage/models/README.md) (default)\n- [OpenAI](https://openai.com)\n- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)\n- [LocalAI (all)](https://localai.io/)\n- [Ollama (all)](https://ollama.ai/)\n- [LM Studio (all)](https://lmstudio.ai)\n- [Cohere](https://cohere.com/)\n\n**Audio Transcription models:**\n\n- [AnythingLLM Built-in](https://github.com/Mintplex-Labs/anything-llm/tree/master/server/storage/models#audiovideo-transcription) (default)\n- [OpenAI](https://openai.com/)\n\n**TTS (text-to-speech) support:**\n\n- Native Browser Built-in (default)\n- [PiperTTSLocal - runs in browser](https://github.com/rhasspy/piper)\n- [OpenAI TTS](https://platform.openai.com/docs/guides/text-to-speech/voice-options)\n- [ElevenLabs](https://elevenlabs.io/)\n- Any OpenAI Compatible TTS service.\n\n**STT (speech-to-text) support:**\n\n- Native Browser Built-in (default)\n\n**Vector Databases:**\n\n- [LanceDB](https://github.com/lancedb/lancedb) (default)\n- [PGVector](https://github.com/pgvector/pgvector)\n- [Astra DB](https://www.datastax.com/products/datastax-astra)\n- [Pinecone](https://pinecone.io)\n- [Chroma & ChromaCloud](https://trychroma.com)\n- [Weaviate](https://weaviate.io)\n- [Qdrant](https://qdrant.tech)\n- [Milvus](https://milvus.io)\n- [Zilliz](https://zilliz.com)\n\n### Technical Overview\n\nThis monorepo consists of six main sections:\n\n- `frontend`: A viteJS + React frontend that you can run to easily create and manage all your content the LLM can use.\n- `server`: A NodeJS express server to handle all the interactions and do all the vectorDB management and LLM interactions.\n- `collector`: NodeJS express server that processes and parses documents from the UI.\n- `docker`: Docker instructions and build process + information for building from source.\n- `embed`: Submodule for generation & creation of the [web embed widget](https://github.com/Mintplex-Labs/anythingllm-embed).\n- `browser-extension`: Submodule for the [chrome browser extension](https://github.com/Mintplex-Labs/anythingllm-extension).\n\n## ğŸ›³ Self-Hosting\n\nMintplex Labs & the community maintain a number of deployment methods, scripts, and templates that you can use to run AnythingLLM locally. Refer to the table below to read how to deploy on your preferred environment or to automatically deploy.\n| Docker | AWS | GCP | Digital Ocean | Render.com |\n|----------------------------------------|----|-----|---------------|------------|\n| [![Deploy on Docker][docker-btn]][docker-deploy] | [![Deploy on AWS][aws-btn]][aws-deploy] | [![Deploy on GCP][gcp-btn]][gcp-deploy] | [![Deploy on DigitalOcean][do-btn]][do-deploy] | [![Deploy on Render.com][render-btn]][render-deploy] |\n\n| Railway | RepoCloud | Elestio | Northflank |\n| --- | --- | --- | --- |\n| [![Deploy on Railway][railway-btn]][railway-deploy] | [![Deploy on RepoCloud][repocloud-btn]][repocloud-deploy] | [![Deploy on Elestio][elestio-btn]][elestio-deploy] | [![Deploy on Northflank][northflank-btn]][northflank-deploy] |\n\n[or set up a production AnythingLLM instance without Docker â†’](./BARE_METAL.md)\n\n## How to setup for development\n\n- `yarn setup` To fill in the required `.env` files you'll need in each of the application sections (from root of repo).\n  - Go fill those out before proceeding. Ensure `server/.env.development` is filled or else things won't work right.\n- `yarn dev:server` To boot the server locally (from root of repo).\n- `yarn dev:frontend` To boot the frontend locally (from root of repo).\n- `yarn dev:collector` To then run the document collector (from root of repo).\n\n[Learn about documents](./server/storage/documents/DOCUMENTS.md)\n\n[Learn about vector caching](./server/storage/vector-cache/VECTOR_CACHE.md)\n\n## External Apps & Integrations\n\n_These are apps that are not maintained by Mintplex Labs, but are compatible with AnythingLLM. A listing here is not an endorsement._\n\n- [Midori AI Subsystem Manager](https://io.midori-ai.xyz/subsystem/anythingllm/) - A streamlined and efficient way to deploy AI systems using Docker container technology.\n- [Coolify](https://coolify.io/docs/services/anythingllm/) - Deploy AnythingLLM with a single click.\n- [GPTLocalhost for Microsoft Word](https://gptlocalhost.com/demo/) - A local Word Add-in for you to use AnythingLLM in Microsoft Word.\n\n## Telemetry & Privacy\n\nAnythingLLM by Mintplex Labs Inc contains a telemetry feature that collects anonymous usage information.\n\n<details>\n<summary><kbd>More about Telemetry & Privacy for AnythingLLM</kbd></summary>\n\n### Why?\n\nWe use this information to help us understand how AnythingLLM is used, to help us prioritize work on new features and bug fixes, and to help us improve AnythingLLM's performance and stability.\n\n### Opting out\n\nSet `DISABLE_TELEMETRY` in your server or docker .env settings to \"true\" to opt out of telemetry. You can also do this in-app by going to the sidebar > `Privacy` and disabling telemetry.\n\n### What do you explicitly track?\n\nWe will only track usage details that help us make product and roadmap decisions, specifically:\n\n- Type of your installation (Docker or Desktop)\n\n- When a document is added or removed. No information _about_ the document. Just that the event occurred. This gives us an idea of use.\n\n- Type of vector database in use. This helps us prioritize changes when updates arrive for that provider.\n\n- Type of LLM provider & model tag in use. This helps us prioritize changes when updates arrive for that provider or model, or combination thereof. eg: reasoning vs regular, multi-modal models, etc.\n\n- When a chat is sent. This is the most regular \"event\" and gives us an idea of the daily-activity of this project across all installations. Again, only the **event** is sent - we have no information on the nature or content of the chat itself.\n\nYou can verify these claims by finding all locations `Telemetry.sendTelemetry` is called. Additionally these events are written to the output log so you can also see the specific data which was sent - if enabled. **No IP or other identifying information is collected**. The Telemetry provider is [PostHog](https://posthog.com/) - an open-source telemetry collection service.\n\nWe take privacy very seriously, and we hope you understand that we want to learn how our tool is used, without using annoying popup surveys, so we can build something worth using. The anonymous data is _never_ shared with third parties, ever.\n\n[View all telemetry events in source code](https://github.com/search?q=repo%3AMintplex-Labs%2Fanything-llm%20.sendTelemetry\\(&type=code)\n\n</details>\n\n## ğŸ‘‹ Contributing\n\n- [Contributing to AnythingLLM](./CONTRIBUTING.md) - How to contribute to AnythingLLM.\n\n## ğŸ’– Sponsors\n\n### Premium Sponsors\n\n<!-- premium-sponsors (reserved for $100/mth sponsors who request to be called out here and/or are non-private sponsors) -->\n<a href=\"https://www.dcsdigital.co.uk\" target=\"_blank\">\n  <img src=\"https://a8cforagenciesportfolio.wordpress.com/wp-content/uploads/2024/08/logo-image-232621379.png\" height=\"100px\" alt=\"User avatar: DCS DIGITAL\" />\n</a>\n<!-- premium-sponsors -->\n\n### All Sponsors\n\n<!-- all-sponsors --><a href=\"https://github.com/jaschadub\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;jaschadub.png\" width=\"60px\" alt=\"User avatar: Jascha\" /></a><a href=\"https://github.com/KickingAss2024\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;KickingAss2024.png\" width=\"60px\" alt=\"User avatar: KickAss\" /></a><a href=\"https://github.com/ShadowArcanist\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ShadowArcanist.png\" width=\"60px\" alt=\"User avatar: ShadowArcanist\" /></a><a href=\"https://github.com/AtlasVIA\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;AtlasVIA.png\" width=\"60px\" alt=\"User avatar: Atlas\" /></a><a href=\"https://github.com/cope\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;cope.png\" width=\"60px\" alt=\"User avatar: Predrag StojadinoviÄ‡\" /></a><a href=\"https://github.com/DiegoSpinola\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;DiegoSpinola.png\" width=\"60px\" alt=\"User avatar: Diego Spinola\" /></a><a href=\"https://github.com/PortlandKyGuy\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;PortlandKyGuy.png\" width=\"60px\" alt=\"User avatar: Kyle\" /></a><a href=\"https://github.com/peperunas\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;peperunas.png\" width=\"60px\" alt=\"User avatar: Giulio De Pasquale\" /></a><a href=\"https://github.com/jasoncdavis0\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;jasoncdavis0.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/macstadium\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;macstadium.png\" width=\"60px\" alt=\"User avatar: MacStadium\" /></a><a href=\"https://github.com/armlynobinguar\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;armlynobinguar.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/MikeHago\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;MikeHago.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/maaisde\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;maaisde.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/mhollier117\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;mhollier117.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/pleabargain\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pleabargain.png\" width=\"60px\" alt=\"User avatar: Dennis\" /></a><a href=\"https://github.com/broichan\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;broichan.png\" width=\"60px\" alt=\"User avatar: Michael Hamilton, Ph.D.\" /></a><a href=\"https://github.com/azim-charaniya\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;azim-charaniya.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/gabriellemon\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;gabriellemon.png\" width=\"60px\" alt=\"User avatar: TernaryLabs\" /></a><a href=\"https://github.com/CelaDaniel\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;CelaDaniel.png\" width=\"60px\" alt=\"User avatar: Daniel Cela\" /></a><a href=\"https://github.com/altrsadmin\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;altrsadmin.png\" width=\"60px\" alt=\"User avatar: Alesso\" /></a><a href=\"https://github.com/bitjungle\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;bitjungle.png\" width=\"60px\" alt=\"User avatar: Rune Mathisen\" /></a><a href=\"https://github.com/pcrossleyAC\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pcrossleyAC.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/saroj-pattnaik\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;saroj-pattnaik.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/techmedic5\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;techmedic5.png\" width=\"60px\" alt=\"User avatar: Alan\" /></a><a href=\"https://github.com/ddocta\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ddocta.png\" width=\"60px\" alt=\"User avatar: Damien Peters\" /></a><a href=\"https://github.com/dcsdigital\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;dcsdigital.png\" width=\"60px\" alt=\"User avatar: DCS Digital\" /></a><a href=\"https://github.com/pm7y\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;pm7y.png\" width=\"60px\" alt=\"User avatar: Paul Mcilreavy\" /></a><a href=\"https://github.com/tilwolf\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;tilwolf.png\" width=\"60px\" alt=\"User avatar: Til Wolf\" /></a><a href=\"https://github.com/ozzyoss77\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ozzyoss77.png\" width=\"60px\" alt=\"User avatar: Leopoldo Crhistian Riverin Gomez\" /></a><a href=\"https://github.com/AlphaEcho11\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;AlphaEcho11.png\" width=\"60px\" alt=\"User avatar: AJEsau\" /></a><a href=\"https://github.com/svanomm\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;svanomm.png\" width=\"60px\" alt=\"User avatar: Steven VanOmmeren\" /></a><a href=\"https://github.com/socketbox\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;socketbox.png\" width=\"60px\" alt=\"User avatar: Casey Boettcher\" /></a><a href=\"https://github.com/zebbern\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;zebbern.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/avineetbespin\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;avineetbespin.png\" width=\"60px\" alt=\"User avatar: Avineet\" /></a><a href=\"https://github.com/invictus-1\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;invictus-1.png\" width=\"60px\" alt=\"User avatar: Chris\" /></a><a href=\"https://github.com/mirbyte\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;mirbyte.png\" width=\"60px\" alt=\"User avatar: mirko\" /></a><a href=\"https://github.com/bisonbet\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;bisonbet.png\" width=\"60px\" alt=\"User avatar: Tim Champ\" /></a><a href=\"https://github.com/Sinkingdev\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;Sinkingdev.png\" width=\"60px\" alt=\"User avatar: Peter Mathisen\" /></a><a href=\"https://github.com/Ed-STEM\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;Ed-STEM.png\" width=\"60px\" alt=\"User avatar: Ed di Girolamo\" /></a><a href=\"https://github.com/milkowski\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;milkowski.png\" width=\"60px\" alt=\"User avatar: Wojciech MiÅ‚kowski\" /></a><a href=\"https://github.com/ADS-Fund\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;ADS-Fund.png\" width=\"60px\" alt=\"User avatar: ADS Fund\" /></a><a href=\"https://github.com/arc46-io\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;arc46-io.png\" width=\"60px\" alt=\"User avatar: arc46 GmbH\" /></a><!-- all-sponsors -->\n\n## ğŸŒŸ Contributors\n\n[![anythingllm contributors](https://contrib.rocks/image?repo=mintplex-labs/anything-llm)](https://github.com/mintplex-labs/anything-llm/graphs/contributors)\n\n[![Star History Chart](https://api.star-history.com/svg?repos=mintplex-labs/anything-llm&type=Timeline)](https://star-history.com/#mintplex-labs/anything-llm&Date)\n\n## ğŸ”— More Products\n\n- **[VectorAdmin][vector-admin]:** An all-in-one GUI & tool-suite for managing vector databases.\n- **[OpenAI Assistant Swarm][assistant-swarm]:** Turn your entire library of OpenAI assistants into one single army commanded from a single agent.\n\n<div align=\"right\">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n---\n\nCopyright Â© 2025 [Mintplex Labs][profile-link]. <br />\nThis project is [MIT](./LICENSE) licensed.\n\n<!-- LINK GROUP -->\n\n[back-to-top]: https://img.shields.io/badge/-BACK_TO_TOP-222628?style=flat-square\n[profile-link]: https://github.com/mintplex-labs\n[vector-admin]: https://github.com/mintplex-labs/vector-admin\n[assistant-swarm]: https://github.com/Mintplex-Labs/openai-assistant-swarm\n[docker-btn]: ./images/deployBtns/docker.png\n[docker-deploy]: ./docker/HOW_TO_USE_DOCKER.md\n[aws-btn]: ./images/deployBtns/aws.png\n[aws-deploy]: ./cloud-deployments/aws/cloudformation/DEPLOY.md\n[gcp-btn]: https://deploy.cloud.run/button.svg\n[gcp-deploy]: ./cloud-deployments/gcp/deployment/DEPLOY.md\n[do-btn]: https://www.deploytodo.com/do-btn-blue.svg\n[do-deploy]: ./cloud-deployments/digitalocean/terraform/DEPLOY.md\n[render-btn]: https://render.com/images/deploy-to-render-button.svg\n[render-deploy]: https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=render\n[render-btn]: https://render.com/images/deploy-to-render-button.svg\n[render-deploy]: https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=render\n[railway-btn]: https://railway.app/button.svg\n[railway-deploy]: https://railway.app/template/HNSCS1?referralCode=WFgJkn\n[repocloud-btn]: https://d16t0pc4846x52.cloudfront.net/deploylobe.svg\n[repocloud-deploy]: https://repocloud.io/details/?app_id=276\n[elestio-btn]: https://elest.io/images/logos/deploy-to-elestio-btn.png\n[elestio-deploy]: https://elest.io/open-source/anythingllm\n[northflank-btn]: https://assets.northflank.com/deploy_to_northflank_smm_36700fb050.svg\n[northflank-deploy]: https://northflank.com/stacks/deploy-anythingllm\n",
      "stars_today": 86
    },
    {
      "id": 846698999,
      "name": "goose",
      "full_name": "block/goose",
      "description": "an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM",
      "html_url": "https://github.com/block/goose",
      "stars": 26003,
      "forks": 2355,
      "language": "Rust",
      "topics": [
        "mcp"
      ],
      "created_at": "2024-08-23T19:03:36Z",
      "updated_at": "2026-01-15T23:41:02Z",
      "pushed_at": "2026-01-15T22:31:39Z",
      "open_issues": 276,
      "owner": {
        "login": "block",
        "avatar_url": "https://avatars.githubusercontent.com/u/185116535?v=4"
      },
      "readme": "<div align=\"center\">\n\n# goose\n\n_a local, extensible, open source AI agent that automates engineering tasks_\n\n<p align=\"center\">\n  <a href=\"https://opensource.org/licenses/Apache-2.0\">\n    <img src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg\">\n  </a>\n  <a href=\"https://discord.gg/goose-oss\">\n    <img src=\"https://img.shields.io/discord/1287729918100246654?logo=discord&logoColor=white&label=Join+Us&color=blueviolet\" alt=\"Discord\">\n  </a>\n  <a href=\"https://github.com/block/goose/actions/workflows/ci.yml\">\n     <img src=\"https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main\" alt=\"CI\">\n  </a>\n</p>\n</div>\n\ngoose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.\n\nWhether you're prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.\n\nDesigned for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.\n\n[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)\n\n# Quick Links\n- [Quickstart](https://block.github.io/goose/docs/quickstart)\n- [Installation](https://block.github.io/goose/docs/getting-started/installation)\n- [Tutorials](https://block.github.io/goose/docs/category/tutorials)\n- [Documentation](https://block.github.io/goose/docs/category/getting-started)\n- [Responsible AI-Assisted Coding Guide](https://github.com/block/goose/blob/main/HOWTOAI.md)\n- [Governance](https://github.com/block/goose/blob/main/GOVERNANCE.md)\n\n## Need Help?\n- [Diagnostics & Reporting](https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting)\n- [Known Issues](https://block.github.io/goose/docs/troubleshooting/known-issues)\n\n# a little goose humor ğŸ¦¢\n\n> Why did the developer choose goose as their AI agent?\n> \n> Because it always helps them \"migrate\" their code to production! ğŸš€\n\n# goose around with us  \n- [Discord](https://discord.gg/goose-oss)\n- [YouTube](https://www.youtube.com/@goose-oss)\n- [LinkedIn](https://www.linkedin.com/company/goose-oss)\n- [Twitter/X](https://x.com/goose_oss)\n- [Bluesky](https://bsky.app/profile/opensource.block.xyz)\n- [Nostr](https://njump.me/opensource@block.xyz)\n",
      "stars_today": 84
    },
    {
      "id": 820087727,
      "name": "onlook",
      "full_name": "onlook-dev/onlook",
      "description": "The Cursor for Designers â€¢ An Open-Source AI-First Design tool â€¢ Visually build, style, and edit your React App with AI",
      "html_url": "https://github.com/onlook-dev/onlook",
      "stars": 24391,
      "forks": 1793,
      "language": "TypeScript",
      "topics": [
        "ai",
        "cursor",
        "cursor-ai",
        "design",
        "design-to-code",
        "drizzle",
        "editor",
        "figma",
        "frontend",
        "ide",
        "low-code",
        "nextjs",
        "react",
        "supabase",
        "tailwindcss",
        "typescript",
        "ui",
        "vibe-coding",
        "vibecoding"
      ],
      "created_at": "2024-06-25T19:16:02Z",
      "updated_at": "2026-01-16T00:02:38Z",
      "pushed_at": "2025-12-29T02:49:53Z",
      "open_issues": 352,
      "owner": {
        "login": "onlook-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/157326433?v=4"
      },
      "readme": "<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 -->\n\n<div align=\"center\">\n<img width=\"800\" alt=\"header image\" src=\"assets/web-preview.png\">\n<h3 align=\"center\">Onlook</h3>\n  <p align=\"center\">\n    Cursor for Designers\n    <br />\n    <a href=\"https://docs.onlook.com\"><strong>Explore the docs Â»</strong></a>\n    <br />\n  </p>\n  <p align=\"center\">\n    ğŸ‘¨â€ğŸ’»ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»\n    <a href=\"https://www.ycombinator.com/companies/onlook/jobs/e4gHv1n-founding-engineer-fullstack\">We're hiring engineers in SF!</a>\n    ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»ğŸ‘©â€ğŸ’»\n  </p>\n    <br />\n    <a href=\"https://youtu.be/RSX_3EaO5eU?feature=shared\">View Demo</a>\n    Â·\n    <a href=\"https://github.com/onlook-dev/onlook/issues/new?labels=bug&template=bug-report---.md\">Report Bug</a>\n    Â·\n    <a href=\"https://github.com/onlook-dev/onlook/issues/new?labels=enhancement&template=feature-request---.md\">Request Feature</a>\n  </p>\n  <!-- PROJECT SHIELDS -->\n<!--\n*** I'm using markdown \"reference style\" links for readability.\n*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).\n*** See the bottom of this document for the declaration of the reference variables\n*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.\n*** https://www.markdownguide.org/basic-syntax/#reference-style-links\n-->\n<!-- [![Contributors][contributors-shield]][contributors-url]\n[![Forks][forks-shield]][forks-url]\n[![Stargazers][stars-shield]][stars-url]\n[![Issues][issues-shield]][issues-url]\n[![Apache License][license-shield]][license-url] -->\n\n[![Discord][discord-shield]][discord-url]\n[![LinkedIn][linkedin-shield]][linkedin-url]\n[![Twitter][twitter-shield]][twitter-url]\n\n[ä¸­æ–‡](https://www.readme-i18n.com/onlook-dev/onlook?lang=zh) |\n[EspaÃ±ol](https://www.readme-i18n.com/onlook-dev/onlook?lang=es) |\n[Deutsch](https://www.readme-i18n.com/onlook-dev/onlook?lang=de) |\n[franÃ§ais](https://www.readme-i18n.com/onlook-dev/onlook?lang=fr) |\n[PortuguÃªs](https://www.readme-i18n.com/onlook-dev/onlook?lang=pt) |\n[Ğ ÑƒÑÑĞºĞ¸Ğ¹](https://www.readme-i18n.com/onlook-dev/onlook?lang=ru) |\n[æ—¥æœ¬èª](https://www.readme-i18n.com/onlook-dev/onlook?lang=ja) |\n[í•œêµ­ì–´](https://www.readme-i18n.com/onlook-dev/onlook?lang=ko)\n\n</div>\n\n# An Open-Source, Visual-First Code Editor\n\nCraft websites, prototypes, and designs with AI in Next.js + TailwindCSS. Make\nedits directly in the browser DOM with a visual editor. Design in realtime with\ncode. An open-source alternative to Bolt.new, Lovable, V0, Replit Agent, Figma\nMake, Webflow, etc.\n\n### ğŸš§ ğŸš§ ğŸš§ Onlook is still under development ğŸš§ ğŸš§ ğŸš§\n\nWe're actively looking for contributors to help make Onlook for Web an\nincredible prompt-to-build experience. Check the\n[open issues](https://github.com/onlook-dev/onlook/issues) for a full list of\nproposed features (and known issues), and join our\n[Discord](https://discord.gg/hERDfFZCsH) to collaborate with hundreds of other\nbuilders.\n\n## What you can do with Onlook:\n\n- [x] Create Next.js app in seconds\n  - [x] Start from text or image\n  - [x] Use prebuilt templates\n  - [ ] Import from Figma\n  - [ ] Import from GitHub repo\n  - [ ] Make a PR to a GitHub repo\n- [x] Visually edit your app\n  - [x] Use Figma-like UI\n  - [x] Preview your app in real-time\n  - [x] Manage brand assets and tokens\n  - [x] Create and navigate to Pages\n  - [x] Browse layers\n  - [x] Manage project Images\n  - [x] Detect and use Components â€“ _Previously in\n        [Onlook Desktop](https://github.com/onlook-dev/desktop)_\n  - [ ] Drag-and-drop Components Panel\n  - [x] Use Branching to experiment with designs\n- [x] Development Tools\n  - [x] Real-time code editor\n  - [x] Save and restore from checkpoints\n  - [x] Run commands via CLI\n  - [x] Connect with app marketplace\n- [x] Deploy your app in seconds\n  - [x] Generate sharable links\n  - [x] Link your custom domain    \n- [ ] Collaborate with your team\n  - [x] Real-time editing\n  - [ ] Leave comments\n- [ ] Advanced AI capabilities\n  - [x] Queue multiple messages at once\n  - [ ] Use Images as references and as assets in a project\n  - [ ] Setup and use MCPs in projects\n  - [ ] Allow Onlook to use itself as a toolcall for branch creation and iteration\n- [ ] Advanced project support\n  - [ ] Support non-NextJS projects\n  - [ ] Support non-Tailwind projects\n\n![Onlook-GitHub-Example](https://github.com/user-attachments/assets/642de37a-72cc-4056-8eb7-8eb42714cdc4)\n\n## Getting Started\n\nUse our [hosted app](https://onlook.com) or\n[run locally](https://docs.onlook.com/developers/running-locally).\n\n### Usage\n\nOnlook will run on any Next.js + TailwindCSS project, import your project into\nOnlook or start from scratch within the editor.\n\nUse the AI chat to create or edit a project you're working on. At any time, you\ncan always right-click an element to open up the exact location of the element\nin code.\n\n<img width=\"600\" alt=\"image\" src=\"https://github.com/user-attachments/assets/4ad9f411-b172-4430-81ef-650f4f314666\" />\n\n<br>\n\nDraw-in new divs and re-arrange them within their parent containers by\ndragging-and-dropping.\n\n<img width=\"600\" alt=\"image\" src=\"assets/insert-div.png\">\n\n<br>\n\nPreview the code side-by-side with your site design.\n\n<img width=\"600\" alt=\"image\" src=\"assets/code-connect.png\">\n\n<br>\n\nUse Onlook's editor toolbar to adjust Tailwind styles, directly manipulate\nobjects, and experiment with layouts.\n\n<img width=\"600\" alt=\"image\" src=\"assets/text-styling.png\" />\n\n## Documentation\n\nFor full documentation, visit [docs.onlook.com](https://docs.onlook.com)\n\nTo see how to Contribute, visit\n[Contributing to Onlook](https://docs.onlook.com/developers) in our docs.\n\n## How it works\n\n<img width=\"676\" alt=\"architecture\" src=\"assets/architecture.png\">\n\n1. When you create an app, we load the code into a web container\n2. The container runs and serves the code\n3. Our editor receives the preview link and displays it in an iFrame\n4. Our editor reads and indexes the code from the container\n5. We instrument the code in order to map elements to their place in code\n6. When the element is edited, we edit the element in our iFrame, then in code\n7. Our AI chat also has code access and tools to understand and edit the code\n\nThis architecture can theoretically scale to any language or framework that\ndisplays DOM elements declaratively (e.g. jsx/tsx/html). We are focused on\nmaking it work well with Next.js and TailwindCSS for now.\n\nFor a full walkthrough, check out our\n[Architecture Docs](https://docs.onlook.com/developers/architecture).\n\n### Our Tech Stack\n\n#### Front-end\n\n- [Next.js](https://nextjs.org/) - Full stack\n- [TailwindCSS](https://tailwindcss.com/) - Styling\n- [tRPC](https://trpc.io/) - Server interface\n\n#### Database\n\n- [Supabase](https://supabase.com/) - Auth, Database, Storage\n- [Drizzle](https://orm.drizzle.team/) - ORM\n\n#### AI\n\n- [AI SDK](https://ai-sdk.dev/) - LLM client\n- [OpenRouter](https://openrouter.ai/) - LLM model provider\n- [Morph Fast Apply](https://morphllm.com) - Fast apply model provider\n- [Relace](https://relace.ai) - Fast apply model provider\n\n#### Sandbox and hosting\n\n- [CodeSandboxSDK](https://codesandbox.io/docs/sdk) - Dev sandbox\n- [Freestyle](https://www.freestyle.sh/) - Hosting\n\n#### Runtime\n\n- [Bun](https://bun.sh/) - Monorepo, runtime, bundler\n- [Docker](https://www.docker.com/) - Container management\n\n## Contributing\n\n![image](https://github.com/user-attachments/assets/ecc94303-df23-46ae-87dc-66b040396e0b)\n\nIf you have a suggestion that would make this better, please fork the repo and\ncreate a pull request. You can also\n[open issues](https://github.com/onlook-dev/onlook/issues).\n\nSee the [CONTRIBUTING.md](CONTRIBUTING.md) for instructions and code of conduct.\n\n#### Contributors\n\n<a href=\"https://github.com/onlook-dev/onlook/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=onlook-dev/onlook\" />\n</a>\n\n## Contact\n\n![image](https://github.com/user-attachments/assets/60684b68-1925-4550-8efd-51a1509fc953)\n\n- Team: [Discord](https://discord.gg/hERDfFZCsH) -\n  [Twitter](https://twitter.com/onlookdev) -\n  [LinkedIn](https://www.linkedin.com/company/onlook-dev/) -\n  [Email](mailto:contact@onlook.com)\n- Project:\n  [https://github.com/onlook-dev/onlook](https://github.com/onlook-dev/onlook)\n- Website: [https://onlook.com](https://onlook.com)\n\n## License\n\nDistributed under the Apache 2.0 License. See [LICENSE.md](LICENSE.md) for more\ninformation.\n\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n\n[contributors-shield]: https://img.shields.io/github/contributors/onlook-dev/studio.svg?style=for-the-badge\n[contributors-url]: https://github.com/onlook-dev/onlook/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/onlook-dev/studio.svg?style=for-the-badge\n[forks-url]: https://github.com/onlook-dev/onlook/network/members\n[stars-shield]: https://img.shields.io/github/stars/onlook-dev/studio.svg?style=for-the-badge\n[stars-url]: https://github.com/onlook-dev/onlook/stargazers\n[issues-shield]: https://img.shields.io/github/issues/onlook-dev/studio.svg?style=for-the-badge\n[issues-url]: https://github.com/onlook-dev/onlook/issues\n[license-shield]: https://img.shields.io/github/license/onlook-dev/studio.svg?style=for-the-badge\n[license-url]: https://github.com/onlook-dev/onlook/blob/master/LICENSE.txt\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?logo=linkedin&colorB=555\n[linkedin-url]: https://www.linkedin.com/company/onlook-dev\n[twitter-shield]: https://img.shields.io/badge/-Twitter-black?logo=x&colorB=555\n[twitter-url]: https://x.com/onlookdev\n[discord-shield]: https://img.shields.io/badge/-Discord-black?logo=discord&colorB=555\n[discord-url]: https://discord.gg/hERDfFZCsH\n[React.js]: https://img.shields.io/badge/react-%2320232a.svg?logo=react&logoColor=%2361DAFB\n[React-url]: https://reactjs.org/\n[TailwindCSS]: https://img.shields.io/badge/tailwindcss-%2338B2AC.svg?logo=tailwind-css&logoColor=white\n[Tailwind-url]: https://tailwindcss.com/\n[Electron.js]: https://img.shields.io/badge/Electron-191970?logo=Electron&logoColor=white\n[Electron-url]: https://www.electronjs.org/\n[Vite.js]: https://img.shields.io/badge/vite-%23646CFF.svg?logo=vite&logoColor=white\n[Vite-url]: https://vitejs.dev/\n[product-screenshot]: assets/brand.png\n[weave-shield]: https://img.shields.io/endpoint?url=https%3A%2F%2Fapp.workweave.ai%2Fapi%2Frepository%2Fbadge%2Forg_pWcXBHJo3Li2Te2Y4WkCPA33%2F820087727&cacheSeconds=3600&labelColor=#131313\n[weave-url]: https://app.workweave.ai/reports/repository/org_pWcXBHJo3Li2Te2Y4WkCPA33/820087727\n",
      "stars_today": 77
    },
    {
      "id": 1011253718,
      "name": "FossFLOW",
      "full_name": "stan-smith/FossFLOW",
      "description": "Make beautiful isometric infrastructure diagrams",
      "html_url": "https://github.com/stan-smith/FossFLOW",
      "stars": 16378,
      "forks": 1055,
      "language": "TypeScript",
      "topics": [
        "devops",
        "infra",
        "infrastructure"
      ],
      "created_at": "2025-06-30T14:31:21Z",
      "updated_at": "2026-01-16T00:43:34Z",
      "pushed_at": "2026-01-15T06:45:51Z",
      "open_issues": 21,
      "owner": {
        "login": "stan-smith",
        "avatar_url": "https://avatars.githubusercontent.com/u/37673863?v=4"
      },
      "readme": "# FossFLOW - Isometric Diagramming Tool <img width=\"30\" height=\"30\" alt=\"fossflow\" src=\"https://github.com/user-attachments/assets/56d78887-601c-4336-ab87-76f8ee4cde96\" />\n\n<p align=\"center\">\n <a href=\"README.md\">English</a> | <a href=\"docs/README.cn.md\">ç®€ä½“ä¸­æ–‡</a> | <a href=\"docs/README.es.md\">EspaÃ±ol</a> | <a href=\"docs/README.pt.md\">PortuguÃªs</a> | <a href=\"docs/README.fr.md\">FranÃ§ais</a> | <a href=\"docs/README.hi.md\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a> | <a href=\"docs/README.bn.md\">à¦¬à¦¾à¦‚à¦²à¦¾</a> | <a href=\"docs/README.ru.md\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> | <a href=\"docs/README.id.md\">Bahasa Indonesia</a> | <a href=\"docs/README.de.md\">Deutsch</a>\n</p>\n\n\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/15118\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/15118\" alt=\"stan-smith%2FFossFLOW | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n<b>Hey!</b> Stan here, if you've used FossFLOW and it's helped you, <b>I'd really appreciate if you could donate something small :)</b> I work full time, and finding the time to work on this project is challenging enough.\nIf you've had a feature that I've implemented for you, or fixed a bug it'd be great if you could :) if not, that's not a problem, this software will always remain free!\n\n\n<b>Also!</b> If you haven't yet, please check out the underlying library this is built on by <a href=\"https://github.com/markmanx/isoflow\">@markmanx</a> I truly stand on the shoulders of a giant here ğŸ«¡\n\n[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/P5P61KBXA3)\n\n<a href=\"https://www.buymeacoffee.com/stan.smith\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/default-orange.png\" alt=\"Buy Me A Coffee\" height=\"41\" width=\"174\"></a>\n\nThanks,\n\n-Stan\n\n## Try it online\n<p align=\"center\">\nGo to  <b> --> https://stan-smith.github.io/FossFLOW/ <-- </b>\n</p>\n<p align=\"center\">\n\n <a href=\"https://github.com/stan-smith/SlingShot\">\n  Check out my latest project: <b>SlingShot</b> - Dead easy video streaming over QUIC\n </a>\n</p>\n\n------------------------------------------------------------------------------------------------------------------------------\nFossFLOW is a powerful, open-source Progressive Web App (PWA) for creating beautiful isometric diagrams. Built with React and the <a href=\"https://github.com/markmanx/isoflow\">Isoflow</a> (Now forked and published to NPM as fossflow) library, it runs entirely in your browser with offline support.\n\n![Screenshot_20250630_160954](https://github.com/user-attachments/assets/e7f254ad-625f-4b8a-8efc-5293b5be9d55)\n\n- **ğŸ“ [FOSSFLOW_TODO.md](https://github.com/stan-smith/FossFLOW/blob/master/FOSSFLOW_TODO.md)** - Current issues and roadmap with codebase mappings, most gripes are with the isoflow library itself.\n- **ğŸ¤ [CONTRIBUTING.md](https://github.com/stan-smith/FossFLOW/blob/master/CONTRIBUTING.md)** - How to contribute to the project.\n\n### Performance updates\n - **Reduced frame refresh delay, should look much smoother now**\n\n### Multilingual Support\n- **9 Languages Supported** - Full interface translation in English, Chinese (Simplified), Spanish, Portuguese (Brazilian), French, Hindi, Bengali, Russian, and Indonesian\n- **Language Selector** - Easy-to-use language switcher in the app header\n- **Complete Translation** - All menus, dialogs, settings, tooltips, and help content translated\n- **Locale-Aware** - Automatically detects and remembers your language preference\n\n### Improved Connector Tool\n- **Click-based Creation** - New default mode: click first node, then second node to connect\n- **Drag Mode Option** - Original drag-and-drop still available via settings\n- **Mode Selection** - Switch between click and drag modes in Settings â†’ Connectors tab\n- **Better Reliability** - Click mode provides more predictable connection creation\n\n\n## ğŸ³ Quick Deploy with Docker\n\n```bash\n# Using Docker Compose (recommended - includes persistent storage)\ndocker compose up\n\n# Or run directly from Docker Hub with persistent storage\ndocker run -p 80:80 -v $(pwd)/diagrams:/data/diagrams stnsmith/fossflow:latest\n```\n\nServer storage is enabled by default in Docker. Your diagrams will be saved to `./diagrams` on the host.\n\nTo disable server storage, set `ENABLE_SERVER_STORAGE=false`:\n```bash\ndocker run -p 80:80 -e ENABLE_SERVER_STORAGE=false stnsmith/fossflow:latest\n```\n\n## Quick Start (Local Development)\n\n```bash\n# Clone the repository\ngit clone https://github.com/stan-smith/FossFLOW\ncd FossFLOW\n\n# Install dependencies\nnpm install\n\n# Build the library (required first time)\nnpm run build:lib\n\n# Start development server\nnpm run dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) in your browser.\n\n## Monorepo Structure\n\nThis is a monorepo containing two packages:\n\n- `packages/fossflow-lib` - React component library for drawing network diagrams (built with Webpack)\n- `packages/fossflow-app` - Progressive Web App which wraps the lib and presents it (built with RSBuild)\n\n### Development Commands\n\n```bash\n# Development\nnpm run dev          # Start app development server\nnpm run dev:lib      # Watch mode for library development\n\n# Building\nnpm run build        # Build both library and app\nnpm run build:lib    # Build library only\nnpm run build:app    # Build app only\n\n# Testing & Linting\nnpm test             # Run unit tests\nnpm run lint         # Check for linting errors\n\n# E2E Tests (Selenium)\ncd e2e-tests\n./run-tests.sh       # Run end-to-end tests (requires Docker & Python)\n\n# Publishing\nnpm run publish:lib  # Publish library to npm\n```\n\n## How to Use\n\n### Creating Diagrams\n\n1. **Add Items**:\n   - Press the \"+\" button on the top right menu, the library of components will appear on the left\n   - Drag and drop components from the library onto the canvas\n   - Or right-click on the grid and select \"Add node\"\n\n2. **Connect Items**: \n   - Select the Connector tool (press 'C' or click connector icon)\n   - **Click mode** (default): Click first node, then click second node\n   - **Drag mode** (optional): Click and drag from first to second node\n   - Switch modes in Settings â†’ Connectors tab\n\n3. **Save Your Work**:\n   - **Quick Save** - Saves to browser session\n   - **Export** - Download as JSON file\n   - **Import** - Load from JSON file\n\n### Storage Options\n\n- **Session Storage**: Temporary saves cleared when browser closes\n- **Export/Import**: Permanent storage as JSON files\n- **Auto-Save**: Automatically saves changes every 5 seconds to session\n\n## Contributing\n\nWe welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.\n\n## Documentation\n\n- [FOSSFLOW_ENCYCLOPEDIA.md](FOSSFLOW_ENCYCLOPEDIA.md) - Comprehensive guide to the codebase\n- [FOSSFLOW_TODO.md](FOSSFLOW_TODO.md) - Current issues and roadmap\n- [CONTRIBUTING.md](CONTRIBUTING.md) - Contributing guidelines\n\n## License\n\nMIT\n",
      "stars_today": 77
    },
    {
      "id": 612354784,
      "name": "llama.cpp",
      "full_name": "ggml-org/llama.cpp",
      "description": "LLM inference in C/C++",
      "html_url": "https://github.com/ggml-org/llama.cpp",
      "stars": 93043,
      "forks": 14490,
      "language": "C++",
      "topics": [
        "ggml"
      ],
      "created_at": "2023-03-10T18:58:00Z",
      "updated_at": "2026-01-15T23:56:50Z",
      "pushed_at": "2026-01-16T00:33:55Z",
      "open_issues": 1005,
      "owner": {
        "login": "ggml-org",
        "avatar_url": "https://avatars.githubusercontent.com/u/134263123?v=4"
      },
      "readme": "# llama.cpp\n\n![llama](https://user-images.githubusercontent.com/1991296/230134379-7181e485-c521-4d23-a0d6-f7b3b61ba524.png)\n\n[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![Release](https://img.shields.io/github/v/release/ggml-org/llama.cpp)](https://github.com/ggml-org/llama.cpp/releases)\n[![Server](https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml/badge.svg)](https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml)\n\n[Manifesto](https://github.com/ggml-org/llama.cpp/discussions/205) / [ggml](https://github.com/ggml-org/ggml) / [ops](https://github.com/ggml-org/llama.cpp/blob/master/docs/ops.md)\n\nLLM inference in C/C++\n\n## Recent API changes\n\n- [Changelog for `libllama` API](https://github.com/ggml-org/llama.cpp/issues/9289)\n- [Changelog for `llama-server` REST API](https://github.com/ggml-org/llama.cpp/issues/9291)\n\n## Hot topics\n\n- **[guide : using the new WebUI of llama.cpp](https://github.com/ggml-org/llama.cpp/discussions/16938)**\n- [guide : running gpt-oss with llama.cpp](https://github.com/ggml-org/llama.cpp/discussions/15396)\n- [[FEEDBACK] Better packaging for llama.cpp to support downstream consumers ğŸ¤—](https://github.com/ggml-org/llama.cpp/discussions/15313)\n- Support for the `gpt-oss` model with native MXFP4 format has been added | [PR](https://github.com/ggml-org/llama.cpp/pull/15091) | [Collaboration with NVIDIA](https://blogs.nvidia.com/blog/rtx-ai-garage-openai-oss) | [Comment](https://github.com/ggml-org/llama.cpp/discussions/15095)\n- Multimodal support arrived in `llama-server`: [#12898](https://github.com/ggml-org/llama.cpp/pull/12898) | [documentation](./docs/multimodal.md)\n- VS Code extension for FIM completions: https://github.com/ggml-org/llama.vscode\n- Vim/Neovim plugin for FIM completions: https://github.com/ggml-org/llama.vim\n- Hugging Face Inference Endpoints now support GGUF out of the box! https://github.com/ggml-org/llama.cpp/discussions/9669\n- Hugging Face GGUF editor: [discussion](https://github.com/ggml-org/llama.cpp/discussions/9268) | [tool](https://huggingface.co/spaces/CISCai/gguf-editor)\n\n----\n\n## Quick start\n\nGetting started with llama.cpp is straightforward. Here are several ways to install it on your machine:\n\n- Install `llama.cpp` using [brew, nix or winget](docs/install.md)\n- Run with Docker - see our [Docker documentation](docs/docker.md)\n- Download pre-built binaries from the [releases page](https://github.com/ggml-org/llama.cpp/releases)\n- Build from source by cloning this repository - check out [our build guide](docs/build.md)\n\nOnce installed, you'll need a model to work with. Head to the [Obtaining and quantizing models](#obtaining-and-quantizing-models) section to learn more.\n\nExample command:\n\n```sh\n# Use a local model file\nllama-cli -m my_model.gguf\n\n# Or download and run a model directly from Hugging Face\nllama-cli -hf ggml-org/gemma-3-1b-it-GGUF\n\n# Launch OpenAI-compatible API server\nllama-server -hf ggml-org/gemma-3-1b-it-GGUF\n```\n\n## Description\n\nThe main goal of `llama.cpp` is to enable LLM inference with minimal setup and state-of-the-art performance on a wide\nrange of hardware - locally and in the cloud.\n\n- Plain C/C++ implementation without any dependencies\n- Apple silicon is a first-class citizen - optimized via ARM NEON, Accelerate and Metal frameworks\n- AVX, AVX2, AVX512 and AMX support for x86 architectures\n- RVV, ZVFH, ZFH, ZICBOP and ZIHINTPAUSE support for RISC-V architectures\n- 1.5-bit, 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit integer quantization for faster inference and reduced memory use\n- Custom CUDA kernels for running LLMs on NVIDIA GPUs (support for AMD GPUs via HIP and Moore Threads GPUs via MUSA)\n- Vulkan and SYCL backend support\n- CPU+GPU hybrid inference to partially accelerate models larger than the total VRAM capacity\n\nThe `llama.cpp` project is the main playground for developing new features for the [ggml](https://github.com/ggml-org/ggml) library.\n\n<details>\n<summary>Models</summary>\n\nTypically finetunes of the base models below are supported as well.\n\nInstructions for adding support for new models: [HOWTO-add-model.md](docs/development/HOWTO-add-model.md)\n\n#### Text-only\n\n- [X] LLaMA ğŸ¦™\n- [x] LLaMA 2 ğŸ¦™ğŸ¦™\n- [x] LLaMA 3 ğŸ¦™ğŸ¦™ğŸ¦™\n- [X] [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.1)\n- [x] [Mixtral MoE](https://huggingface.co/models?search=mistral-ai/Mixtral)\n- [x] [DBRX](https://huggingface.co/databricks/dbrx-instruct)\n- [x] [Jamba](https://huggingface.co/ai21labs)\n- [X] [Falcon](https://huggingface.co/models?search=tiiuae/falcon)\n- [X] [Chinese LLaMA / Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) and [Chinese LLaMA-2 / Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)\n- [X] [Vigogne (French)](https://github.com/bofenghuang/vigogne)\n- [X] [BERT](https://github.com/ggml-org/llama.cpp/pull/5423)\n- [X] [Koala](https://bair.berkeley.edu/blog/2023/04/03/koala/)\n- [X] [Baichuan 1 & 2](https://huggingface.co/models?search=baichuan-inc/Baichuan) + [derivations](https://huggingface.co/hiyouga/baichuan-7b-sft)\n- [X] [Aquila 1 & 2](https://huggingface.co/models?search=BAAI/Aquila)\n- [X] [Starcoder models](https://github.com/ggml-org/llama.cpp/pull/3187)\n- [X] [Refact](https://huggingface.co/smallcloudai/Refact-1_6B-fim)\n- [X] [MPT](https://github.com/ggml-org/llama.cpp/pull/3417)\n- [X] [Bloom](https://github.com/ggml-org/llama.cpp/pull/3553)\n- [x] [Yi models](https://huggingface.co/models?search=01-ai/Yi)\n- [X] [StableLM models](https://huggingface.co/stabilityai)\n- [x] [Deepseek models](https://huggingface.co/models?search=deepseek-ai/deepseek)\n- [x] [Qwen models](https://huggingface.co/models?search=Qwen/Qwen)\n- [x] [PLaMo-13B](https://github.com/ggml-org/llama.cpp/pull/3557)\n- [x] [Phi models](https://huggingface.co/models?search=microsoft/phi)\n- [x] [PhiMoE](https://github.com/ggml-org/llama.cpp/pull/11003)\n- [x] [GPT-2](https://huggingface.co/gpt2)\n- [x] [Orion 14B](https://github.com/ggml-org/llama.cpp/pull/5118)\n- [x] [InternLM2](https://huggingface.co/models?search=internlm2)\n- [x] [CodeShell](https://github.com/WisdomShell/codeshell)\n- [x] [Gemma](https://ai.google.dev/gemma)\n- [x] [Mamba](https://github.com/state-spaces/mamba)\n- [x] [Grok-1](https://huggingface.co/keyfan/grok-1-hf)\n- [x] [Xverse](https://huggingface.co/models?search=xverse)\n- [x] [Command-R models](https://huggingface.co/models?search=CohereForAI/c4ai-command-r)\n- [x] [SEA-LION](https://huggingface.co/models?search=sea-lion)\n- [x] [GritLM-7B](https://huggingface.co/GritLM/GritLM-7B) + [GritLM-8x7B](https://huggingface.co/GritLM/GritLM-8x7B)\n- [x] [OLMo](https://allenai.org/olmo)\n- [x] [OLMo 2](https://allenai.org/olmo)\n- [x] [OLMoE](https://huggingface.co/allenai/OLMoE-1B-7B-0924)\n- [x] [Granite models](https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330)\n- [x] [GPT-NeoX](https://github.com/EleutherAI/gpt-neox) + [Pythia](https://github.com/EleutherAI/pythia)\n- [x] [Snowflake-Arctic MoE](https://huggingface.co/collections/Snowflake/arctic-66290090abe542894a5ac520)\n- [x] [Smaug](https://huggingface.co/models?search=Smaug)\n- [x] [Poro 34B](https://huggingface.co/LumiOpen/Poro-34B)\n- [x] [Bitnet b1.58 models](https://huggingface.co/1bitLLM)\n- [x] [Flan T5](https://huggingface.co/models?search=flan-t5)\n- [x] [Open Elm models](https://huggingface.co/collections/apple/openelm-instruct-models-6619ad295d7ae9f868b759ca)\n- [x] [ChatGLM3-6b](https://huggingface.co/THUDM/chatglm3-6b) + [ChatGLM4-9b](https://huggingface.co/THUDM/glm-4-9b) + [GLMEdge-1.5b](https://huggingface.co/THUDM/glm-edge-1.5b-chat) + [GLMEdge-4b](https://huggingface.co/THUDM/glm-edge-4b-chat)\n- [x] [GLM-4-0414](https://huggingface.co/collections/THUDM/glm-4-0414-67f3cbcb34dd9d252707cb2e)\n- [x] [SmolLM](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966)\n- [x] [EXAONE-3.0-7.8B-Instruct](https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct)\n- [x] [FalconMamba Models](https://huggingface.co/collections/tiiuae/falconmamba-7b-66b9a580324dd1598b0f6d4a)\n- [x] [Jais](https://huggingface.co/inceptionai/jais-13b-chat)\n- [x] [Bielik-11B-v2.3](https://huggingface.co/collections/speakleash/bielik-11b-v23-66ee813238d9b526a072408a)\n- [x] [RWKV-6](https://github.com/BlinkDL/RWKV-LM)\n- [x] [QRWKV-6](https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1)\n- [x] [GigaChat-20B-A3B](https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct)\n- [X] [Trillion-7B-preview](https://huggingface.co/trillionlabs/Trillion-7B-preview)\n- [x] [Ling models](https://huggingface.co/collections/inclusionAI/ling-67c51c85b34a7ea0aba94c32)\n- [x] [LFM2 models](https://huggingface.co/collections/LiquidAI/lfm2-686d721927015b2ad73eaa38)\n- [x] [Hunyuan models](https://huggingface.co/collections/tencent/hunyuan-dense-model-6890632cda26b19119c9c5e7)\n- [x] [BailingMoeV2 (Ring/Ling 2.0) models](https://huggingface.co/collections/inclusionAI/ling-v2-68bf1dd2fc34c306c1fa6f86)\n\n#### Multimodal\n\n- [x] [LLaVA 1.5 models](https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e), [LLaVA 1.6 models](https://huggingface.co/collections/liuhaotian/llava-16-65b9e40155f60fd046a5ccf2)\n- [x] [BakLLaVA](https://huggingface.co/models?search=SkunkworksAI/Bakllava)\n- [x] [Obsidian](https://huggingface.co/NousResearch/Obsidian-3B-V0.5)\n- [x] [ShareGPT4V](https://huggingface.co/models?search=Lin-Chen/ShareGPT4V)\n- [x] [MobileVLM 1.7B/3B models](https://huggingface.co/models?search=mobileVLM)\n- [x] [Yi-VL](https://huggingface.co/models?search=Yi-VL)\n- [x] [Mini CPM](https://huggingface.co/models?search=MiniCPM)\n- [x] [Moondream](https://huggingface.co/vikhyatk/moondream2)\n- [x] [Bunny](https://github.com/BAAI-DCAI/Bunny)\n- [x] [GLM-EDGE](https://huggingface.co/models?search=glm-edge)\n- [x] [Qwen2-VL](https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d)\n- [x] [LFM2-VL](https://huggingface.co/collections/LiquidAI/lfm2-vl-68963bbc84a610f7638d5ffa)\n\n</details>\n\n<details>\n<summary>Bindings</summary>\n\n- Python: [ddh0/easy-llama](https://github.com/ddh0/easy-llama)\n- Python: [abetlen/llama-cpp-python](https://github.com/abetlen/llama-cpp-python)\n- Go: [go-skynet/go-llama.cpp](https://github.com/go-skynet/go-llama.cpp)\n- Node.js: [withcatai/node-llama-cpp](https://github.com/withcatai/node-llama-cpp)\n- JS/TS (llama.cpp server client): [lgrammel/modelfusion](https://modelfusion.dev/integration/model-provider/llamacpp)\n- JS/TS (Programmable Prompt Engine CLI): [offline-ai/cli](https://github.com/offline-ai/cli)\n- JavaScript/Wasm (works in browser): [tangledgroup/llama-cpp-wasm](https://github.com/tangledgroup/llama-cpp-wasm)\n- Typescript/Wasm (nicer API, available on npm): [ngxson/wllama](https://github.com/ngxson/wllama)\n- Ruby: [yoshoku/llama_cpp.rb](https://github.com/yoshoku/llama_cpp.rb)\n- Rust (more features): [edgenai/llama_cpp-rs](https://github.com/edgenai/llama_cpp-rs)\n- Rust (nicer API): [mdrokz/rust-llama.cpp](https://github.com/mdrokz/rust-llama.cpp)\n- Rust (more direct bindings): [utilityai/llama-cpp-rs](https://github.com/utilityai/llama-cpp-rs)\n- Rust (automated build from crates.io): [ShelbyJenkins/llm_client](https://github.com/ShelbyJenkins/llm_client)\n- C#/.NET: [SciSharp/LLamaSharp](https://github.com/SciSharp/LLamaSharp)\n- C#/VB.NET (more features - community license): [LM-Kit.NET](https://docs.lm-kit.com/lm-kit-net/index.html)\n- Scala 3: [donderom/llm4s](https://github.com/donderom/llm4s)\n- Clojure: [phronmophobic/llama.clj](https://github.com/phronmophobic/llama.clj)\n- React Native: [mybigday/llama.rn](https://github.com/mybigday/llama.rn)\n- Java: [kherud/java-llama.cpp](https://github.com/kherud/java-llama.cpp)\n- Java: [QuasarByte/llama-cpp-jna](https://github.com/QuasarByte/llama-cpp-jna)\n- Zig: [deins/llama.cpp.zig](https://github.com/Deins/llama.cpp.zig)\n- Flutter/Dart: [netdur/llama_cpp_dart](https://github.com/netdur/llama_cpp_dart)\n- Flutter: [xuegao-tzx/Fllama](https://github.com/xuegao-tzx/Fllama)\n- PHP (API bindings and features built on top of llama.cpp): [distantmagic/resonance](https://github.com/distantmagic/resonance) [(more info)](https://github.com/ggml-org/llama.cpp/pull/6326)\n- Guile Scheme: [guile_llama_cpp](https://savannah.nongnu.org/projects/guile-llama-cpp)\n- Swift [srgtuszy/llama-cpp-swift](https://github.com/srgtuszy/llama-cpp-swift)\n- Swift [ShenghaiWang/SwiftLlama](https://github.com/ShenghaiWang/SwiftLlama)\n- Delphi [Embarcadero/llama-cpp-delphi](https://github.com/Embarcadero/llama-cpp-delphi)\n- Go (no CGo needed): [hybridgroup/yzma](https://github.com/hybridgroup/yzma)\n- Android: [llama.android](/examples/llama.android)\n\n</details>\n\n<details>\n<summary>UIs</summary>\n\n*(to have a project listed here, it should clearly state that it depends on `llama.cpp`)*\n\n- [AI Sublime Text plugin](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) (MIT)\n- [BonzAI App](https://apps.apple.com/us/app/bonzai-your-local-ai-agent/id6752847988) (proprietary)\n- [cztomsik/ava](https://github.com/cztomsik/ava) (MIT)\n- [Dot](https://github.com/alexpinel/Dot) (GPL)\n- [eva](https://github.com/ylsdamxssjxxdd/eva) (MIT)\n- [iohub/collama](https://github.com/iohub/coLLaMA) (Apache-2.0)\n- [janhq/jan](https://github.com/janhq/jan) (AGPL)\n- [johnbean393/Sidekick](https://github.com/johnbean393/Sidekick) (MIT)\n- [KanTV](https://github.com/zhouwg/kantv?tab=readme-ov-file) (Apache-2.0)\n- [KodiBot](https://github.com/firatkiral/kodibot) (GPL)\n- [llama.vim](https://github.com/ggml-org/llama.vim) (MIT)\n- [LARS](https://github.com/abgulati/LARS) (AGPL)\n- [Llama Assistant](https://github.com/vietanhdev/llama-assistant) (GPL)\n- [LLMFarm](https://github.com/guinmoon/LLMFarm?tab=readme-ov-file) (MIT)\n- [LLMUnity](https://github.com/undreamai/LLMUnity) (MIT)\n- [LMStudio](https://lmstudio.ai/) (proprietary)\n- [LocalAI](https://github.com/mudler/LocalAI) (MIT)\n- [LostRuins/koboldcpp](https://github.com/LostRuins/koboldcpp) (AGPL)\n- [MindMac](https://mindmac.app) (proprietary)\n- [MindWorkAI/AI-Studio](https://github.com/MindWorkAI/AI-Studio) (FSL-1.1-MIT)\n- [Mobile-Artificial-Intelligence/maid](https://github.com/Mobile-Artificial-Intelligence/maid) (MIT)\n- [Mozilla-Ocho/llamafile](https://github.com/Mozilla-Ocho/llamafile) (Apache-2.0)\n- [nat/openplayground](https://github.com/nat/openplayground) (MIT)\n- [nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all) (MIT)\n- [ollama/ollama](https://github.com/ollama/ollama) (MIT)\n- [oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) (AGPL)\n- [PocketPal AI](https://github.com/a-ghorbani/pocketpal-ai) (MIT)\n- [psugihara/FreeChat](https://github.com/psugihara/FreeChat) (MIT)\n- [ptsochantaris/emeltal](https://github.com/ptsochantaris/emeltal) (MIT)\n- [pythops/tenere](https://github.com/pythops/tenere) (AGPL)\n- [ramalama](https://github.com/containers/ramalama) (MIT)\n- [semperai/amica](https://github.com/semperai/amica) (MIT)\n- [withcatai/catai](https://github.com/withcatai/catai) (MIT)\n- [Autopen](https://github.com/blackhole89/autopen) (GPL)\n\n</details>\n\n<details>\n<summary>Tools</summary>\n\n- [akx/ggify](https://github.com/akx/ggify) â€“ download PyTorch models from HuggingFace Hub and convert them to GGML\n- [akx/ollama-dl](https://github.com/akx/ollama-dl) â€“ download models from the Ollama library to be used directly with llama.cpp\n- [crashr/gppm](https://github.com/crashr/gppm) â€“ launch llama.cpp instances utilizing NVIDIA Tesla P40 or P100 GPUs with reduced idle power consumption\n- [gpustack/gguf-parser](https://github.com/gpustack/gguf-parser-go/tree/main/cmd/gguf-parser) - review/check the GGUF file and estimate the memory usage\n- [Styled Lines](https://marketplace.unity.com/packages/tools/generative-ai/styled-lines-llama-cpp-model-292902) (proprietary licensed, async wrapper of inference part for game development in Unity3d with pre-built Mobile and Web platform wrappers and a model example)\n- [unslothai/unsloth](https://github.com/unslothai/unsloth) â€“ ğŸ¦¥ exports/saves fine-tuned and trained models to GGUF (Apache-2.0)\n\n</details>\n\n<details>\n<summary>Infrastructure</summary>\n\n- [Paddler](https://github.com/intentee/paddler) - Open-source LLMOps platform for hosting and scaling AI in your own infrastructure\n- [GPUStack](https://github.com/gpustack/gpustack) - Manage GPU clusters for running LLMs\n- [llama_cpp_canister](https://github.com/onicai/llama_cpp_canister) - llama.cpp as a smart contract on the Internet Computer, using WebAssembly\n- [llama-swap](https://github.com/mostlygeek/llama-swap) - transparent proxy that adds automatic model switching with llama-server\n- [Kalavai](https://github.com/kalavai-net/kalavai-client) - Crowdsource end to end LLM deployment at any scale\n- [llmaz](https://github.com/InftyAI/llmaz) - â˜¸ï¸ Easy, advanced inference platform for large language models on Kubernetes.\n</details>\n\n<details>\n<summary>Games</summary>\n\n- [Lucy's Labyrinth](https://github.com/MorganRO8/Lucys_Labyrinth) - A simple maze game where agents controlled by an AI model will try to trick you.\n\n</details>\n\n\n## Supported backends\n\n| Backend | Target devices |\n| --- | --- |\n| [Metal](docs/build.md#metal-build) | Apple Silicon |\n| [BLAS](docs/build.md#blas-build) | All |\n| [BLIS](docs/backend/BLIS.md) | All |\n| [SYCL](docs/backend/SYCL.md) | Intel and Nvidia GPU |\n| [MUSA](docs/build.md#musa) | Moore Threads GPU |\n| [CUDA](docs/build.md#cuda) | Nvidia GPU |\n| [HIP](docs/build.md#hip) | AMD GPU |\n| [ZenDNN](docs/build.md#zendnn) | AMD CPU |\n| [Vulkan](docs/build.md#vulkan) | GPU |\n| [CANN](docs/build.md#cann) | Ascend NPU |\n| [OpenCL](docs/backend/OPENCL.md) | Adreno GPU |\n| [IBM zDNN](docs/backend/zDNN.md) | IBM Z & LinuxONE |\n| [WebGPU [In Progress]](docs/build.md#webgpu) | All |\n| [RPC](https://github.com/ggml-org/llama.cpp/tree/master/tools/rpc) | All |\n| [Hexagon [In Progress]](docs/backend/hexagon/README.md) | Snapdragon |\n\n## Obtaining and quantizing models\n\nThe [Hugging Face](https://huggingface.co) platform hosts a [number of LLMs](https://huggingface.co/models?library=gguf&sort=trending) compatible with `llama.cpp`:\n\n- [Trending](https://huggingface.co/models?library=gguf&sort=trending)\n- [LLaMA](https://huggingface.co/models?sort=trending&search=llama+gguf)\n\nYou can either manually download the GGUF file or directly use any `llama.cpp`-compatible models from [Hugging Face](https://huggingface.co/) or other model hosting sites, such as [ModelScope](https://modelscope.cn/), by using this CLI argument: `-hf <user>/<model>[:quant]`. For example:\n\n```sh\nllama-cli -hf ggml-org/gemma-3-1b-it-GGUF\n```\n\nBy default, the CLI would download from Hugging Face, you can switch to other options with the environment variable `MODEL_ENDPOINT`. For example, you may opt to downloading model checkpoints from ModelScope or other model sharing communities by setting the environment variable, e.g. `MODEL_ENDPOINT=https://www.modelscope.cn/`.\n\nAfter downloading a model, use the CLI tools to run it locally - see below.\n\n`llama.cpp` requires the model to be stored in the [GGUF](https://github.com/ggml-org/ggml/blob/master/docs/gguf.md) file format. Models in other data formats can be converted to GGUF using the `convert_*.py` Python scripts in this repo.\n\nThe Hugging Face platform provides a variety of online tools for converting, quantizing and hosting models with `llama.cpp`:\n\n- Use the [GGUF-my-repo space](https://huggingface.co/spaces/ggml-org/gguf-my-repo) to convert to GGUF format and quantize model weights to smaller sizes\n- Use the [GGUF-my-LoRA space](https://huggingface.co/spaces/ggml-org/gguf-my-lora) to convert LoRA adapters to GGUF format (more info: https://github.com/ggml-org/llama.cpp/discussions/10123)\n- Use the [GGUF-editor space](https://huggingface.co/spaces/CISCai/gguf-editor) to edit GGUF meta data in the browser (more info: https://github.com/ggml-org/llama.cpp/discussions/9268)\n- Use the [Inference Endpoints](https://ui.endpoints.huggingface.co/) to directly host `llama.cpp` in the cloud (more info: https://github.com/ggml-org/llama.cpp/discussions/9669)\n\nTo learn more about model quantization, [read this documentation](tools/quantize/README.md)\n\n## [`llama-cli`](tools/cli)\n\n#### A CLI tool for accessing and experimenting with most of `llama.cpp`'s functionality.\n\n- <details open>\n    <summary>Run in conversation mode</summary>\n\n    Models with a built-in chat template will automatically activate conversation mode. If this doesn't occur, you can manually enable it by adding `-cnv` and specifying a suitable chat template with `--chat-template NAME`\n\n    ```bash\n    llama-cli -m model.gguf\n\n    # > hi, who are you?\n    # Hi there! I'm your helpful assistant! I'm an AI-powered chatbot designed to assist and provide information to users like you. I'm here to help answer your questions, provide guidance, and offer support on a wide range of topics. I'm a friendly and knowledgeable AI, and I'm always happy to help with anything you need. What's on your mind, and how can I assist you today?\n    #\n    # > what is 1+1?\n    # Easy peasy! The answer to 1+1 is... 2!\n    ```\n\n    </details>\n\n- <details>\n    <summary>Run in conversation mode with custom chat template</summary>\n\n    ```bash\n    # use the \"chatml\" template (use -h to see the list of supported templates)\n    llama-cli -m model.gguf -cnv --chat-template chatml\n\n    # use a custom template\n    llama-cli -m model.gguf -cnv --in-prefix 'User: ' --reverse-prompt 'User:'\n    ```\n\n    </details>\n\n- <details>\n    <summary>Constrain the output with a custom grammar</summary>\n\n    ```bash\n    llama-cli -m model.gguf -n 256 --grammar-file grammars/json.gbnf -p 'Request: schedule a call at 8pm; Command:'\n\n    # {\"appointmentTime\": \"8pm\", \"appointmentDetails\": \"schedule a a call\"}\n    ```\n\n    The [grammars/](grammars/) folder contains a handful of sample grammars. To write your own, check out the [GBNF Guide](grammars/README.md).\n\n    For authoring more complex JSON grammars, check out https://grammar.intrinsiclabs.ai/\n\n    </details>\n\n\n## [`llama-server`](tools/server)\n\n#### A lightweight, [OpenAI API](https://github.com/openai/openai-openapi) compatible, HTTP server for serving LLMs.\n\n- <details open>\n    <summary>Start a local HTTP server with default configuration on port 8080</summary>\n\n    ```bash\n    llama-server -m model.gguf --port 8080\n\n    # Basic web UI can be accessed via browser: http://localhost:8080\n    # Chat completion endpoint: http://localhost:8080/v1/chat/completions\n    ```\n\n    </details>\n\n- <details>\n    <summary>Support multiple-users and parallel decoding</summary>\n\n    ```bash\n    # up to 4 concurrent requests, each with 4096 max context\n    llama-server -m model.gguf -c 16384 -np 4\n    ```\n\n    </details>\n\n- <details>\n    <summary>Enable speculative decoding</summary>\n\n    ```bash\n    # the draft.gguf model should be a small variant of the target model.gguf\n    llama-server -m model.gguf -md draft.gguf\n    ```\n\n    </details>\n\n- <details>\n    <summary>Serve an embedding model</summary>\n\n    ```bash\n    # use the /embedding endpoint\n    llama-server -m model.gguf --embedding --pooling cls -ub 8192\n    ```\n\n    </details>\n\n- <details>\n    <summary>Serve a reranking model</summary>\n\n    ```bash\n    # use the /reranking endpoint\n    llama-server -m model.gguf --reranking\n    ```\n\n    </details>\n\n- <details>\n    <summary>Constrain all outputs with a grammar</summary>\n\n    ```bash\n    # custom grammar\n    llama-server -m model.gguf --grammar-file grammar.gbnf\n\n    # JSON\n    llama-server -m model.gguf --grammar-file grammars/json.gbnf\n    ```\n\n    </details>\n\n\n## [`llama-perplexity`](tools/perplexity)\n\n#### A tool for measuring the [perplexity](tools/perplexity/README.md) [^1] (and other quality metrics) of a model over a given text.\n\n- <details open>\n    <summary>Measure the perplexity over a text file</summary>\n\n    ```bash\n    llama-perplexity -m model.gguf -f file.txt\n\n    # [1]15.2701,[2]5.4007,[3]5.3073,[4]6.2965,[5]5.8940,[6]5.6096,[7]5.7942,[8]4.9297, ...\n    # Final estimate: PPL = 5.4007 +/- 0.67339\n    ```\n\n    </details>\n\n- <details>\n    <summary>Measure KL divergence</summary>\n\n    ```bash\n    # TODO\n    ```\n\n    </details>\n\n[^1]: [https://huggingface.co/docs/transformers/perplexity](https://huggingface.co/docs/transformers/perplexity)\n\n## [`llama-bench`](tools/llama-bench)\n\n#### Benchmark the performance of the inference for various parameters.\n\n- <details open>\n    <summary>Run default benchmark</summary>\n\n    ```bash\n    llama-bench -m model.gguf\n\n    # Output:\n    # | model               |       size |     params | backend    | threads |          test |                  t/s |\n    # | ------------------- | ---------: | ---------: | ---------- | ------: | ------------: | -------------------: |\n    # | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         pp512 |      5765.41 Â± 20.55 |\n    # | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         tg128 |        197.71 Â± 0.81 |\n    #\n    # build: 3e0ba0e60 (4229)\n    ```\n\n    </details>\n\n## [`llama-simple`](examples/simple)\n\n#### A minimal example for implementing apps with `llama.cpp`. Useful for developers.\n\n- <details>\n    <summary>Basic text completion</summary>\n\n    ```bash\n    llama-simple -m model.gguf\n\n    # Hello my name is Kaitlyn and I am a 16 year old girl. I am a junior in high school and I am currently taking a class called \"The Art of\n    ```\n\n    </details>\n\n\n## Contributing\n\n- Contributors can open PRs\n- Collaborators will be invited based on contributions\n- Maintainers can push to branches in the `llama.cpp` repo and merge PRs into the `master` branch\n- Any help with managing issues, PRs and projects is very appreciated!\n- See [good first issues](https://github.com/ggml-org/llama.cpp/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) for tasks suitable for first contributions\n- Read the [CONTRIBUTING.md](CONTRIBUTING.md) for more information\n- Make sure to read this: [Inference at the edge](https://github.com/ggml-org/llama.cpp/discussions/205)\n- A bit of backstory for those who are interested: [Changelog podcast](https://changelog.com/podcast/532)\n\n## Other documentation\n\n- [cli](tools/cli/README.md)\n- [completion](tools/completion/README.md)\n- [server](tools/server/README.md)\n- [GBNF grammars](grammars/README.md)\n\n#### Development documentation\n\n- [How to build](docs/build.md)\n- [Running on Docker](docs/docker.md)\n- [Build on Android](docs/android.md)\n- [Performance troubleshooting](docs/development/token_generation_performance_tips.md)\n- [GGML tips & tricks](https://github.com/ggml-org/llama.cpp/wiki/GGML-Tips-&-Tricks)\n\n#### Seminal papers and background on the models\n\nIf your issue is with model generation quality, then please at least scan the following links and papers to understand the limitations of LLaMA models. This is especially important when choosing an appropriate model size and appreciating both the significant and subtle differences between LLaMA models and ChatGPT:\n- LLaMA:\n    - [Introducing LLaMA: A foundational, 65-billion-parameter large language model](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)\n    - [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)\n- GPT-3\n    - [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)\n- GPT-3.5 / InstructGPT / ChatGPT:\n    - [Aligning language models to follow instructions](https://openai.com/research/instruction-following)\n    - [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)\n\n## XCFramework\nThe XCFramework is a precompiled version of the library for iOS, visionOS, tvOS,\nand macOS. It can be used in Swift projects without the need to compile the\nlibrary from source. For example:\n```swift\n// swift-tools-version: 5.10\n// The swift-tools-version declares the minimum version of Swift required to build this package.\n\nimport PackageDescription\n\nlet package = Package(\n    name: \"MyLlamaPackage\",\n    targets: [\n        .executableTarget(\n            name: \"MyLlamaPackage\",\n            dependencies: [\n                \"LlamaFramework\"\n            ]),\n        .binaryTarget(\n            name: \"LlamaFramework\",\n            url: \"https://github.com/ggml-org/llama.cpp/releases/download/b5046/llama-b5046-xcframework.zip\",\n            checksum: \"c19be78b5f00d8d29a25da41042cb7afa094cbf6280a225abe614b03b20029ab\"\n        )\n    ]\n)\n```\nThe above example is using an intermediate build `b5046` of the library. This can be modified\nto use a different version by changing the URL and checksum.\n\n## Completions\nCommand-line completion is available for some environments.\n\n#### Bash Completion\n```bash\n$ build/bin/llama-cli --completion-bash > ~/.llama-completion.bash\n$ source ~/.llama-completion.bash\n```\nOptionally this can be added to your `.bashrc` or `.bash_profile` to load it\nautomatically. For example:\n```console\n$ echo \"source ~/.llama-completion.bash\" >> ~/.bashrc\n```\n\n## Dependencies\n\n- [yhirose/cpp-httplib](https://github.com/yhirose/cpp-httplib) - Single-header HTTP server, used by `llama-server` - MIT license\n- [stb-image](https://github.com/nothings/stb) - Single-header image format decoder, used by multimodal subsystem - Public domain\n- [nlohmann/json](https://github.com/nlohmann/json) - Single-header JSON library, used by various tools/examples - MIT License\n- [minja](https://github.com/google/minja) - Minimal Jinja parser in C++, used by various tools/examples - MIT License\n- [miniaudio.h](https://github.com/mackron/miniaudio) - Single-header audio format decoder, used by multimodal subsystem - Public domain\n- [subprocess.h](https://github.com/sheredom/subprocess.h) - Single-header process launching solution for C and C++ - Public domain\n",
      "stars_today": 73
    },
    {
      "id": 382496361,
      "name": "uptime-kuma",
      "full_name": "louislam/uptime-kuma",
      "description": "A fancy self-hosted monitoring tool",
      "html_url": "https://github.com/louislam/uptime-kuma",
      "stars": 81431,
      "forks": 7267,
      "language": "JavaScript",
      "topics": [
        "docker",
        "monitor",
        "monitoring",
        "responsive",
        "self-hosted",
        "selfhosted",
        "single-page-app",
        "socket-io",
        "uptime",
        "uptime-monitoring",
        "webapp",
        "websocket"
      ],
      "created_at": "2021-07-03T01:02:42Z",
      "updated_at": "2026-01-16T00:07:47Z",
      "pushed_at": "2026-01-15T12:03:29Z",
      "open_issues": 703,
      "owner": {
        "login": "louislam",
        "avatar_url": "https://avatars.githubusercontent.com/u/1336778?v=4"
      },
      "readme": "<div align=\"center\" width=\"100%\">\n    <img src=\"./public/icon.svg\" width=\"128\" alt=\"Uptime Kuma Logo\" />\n</div>\n\n# Uptime Kuma\n\nUptime Kuma is an easy-to-use self-hosted monitoring tool.\n\n<a target=\"_blank\" href=\"https://github.com/louislam/uptime-kuma\"><img src=\"https://img.shields.io/github/stars/louislam/uptime-kuma?style=flat\" /></a> <a target=\"_blank\" href=\"https://hub.docker.com/r/louislam/uptime-kuma\"><img src=\"https://img.shields.io/docker/pulls/louislam/uptime-kuma\" /></a> <a target=\"_blank\" href=\"https://hub.docker.com/r/louislam/uptime-kuma\"><img src=\"https://img.shields.io/docker/v/louislam/uptime-kuma/2?label=docker%20image%20ver.\" /></a> <a target=\"_blank\" href=\"https://github.com/louislam/uptime-kuma\"><img src=\"https://img.shields.io/github/last-commit/louislam/uptime-kuma\" /></a> <a target=\"_blank\" href=\"https://opencollective.com/uptime-kuma\"><img src=\"https://opencollective.com/uptime-kuma/total/badge.svg?label=Open%20Collective%20Backers&color=brightgreen\" /></a>\n[![GitHub Sponsors](https://img.shields.io/github/sponsors/louislam?label=GitHub%20Sponsors)](https://github.com/sponsors/louislam) <a href=\"https://weblate.kuma.pet/projects/uptime-kuma/uptime-kuma/\">\n<img src=\"https://weblate.kuma.pet/widgets/uptime-kuma/-/svg-badge.svg\" alt=\"Translation status\" />\n</a>\n\n<img src=\"https://user-images.githubusercontent.com/1336778/212262296-e6205815-ad62-488c-83ec-a5b0d0689f7c.jpg\" width=\"700\" alt=\"Uptime Kuma Dashboard Screenshot\" />\n\n## ğŸ¥” Live Demo\n\nTry it!\n\nDemo Server (Location: Frankfurt - Germany): <https://demo.kuma.pet/start-demo>\n\nIt is a temporary live demo, all data will be deleted after 10 minutes. Sponsored by [Uptime Kuma Sponsors](https://github.com/louislam/uptime-kuma#%EF%B8%8F-sponsors).\n\n## â­ Features\n\n- Monitoring uptime for HTTP(s) / TCP / HTTP(s) Keyword / HTTP(s) Json Query / Websocket / Ping / DNS Record / Push / Steam Game Server / Docker Containers\n- Fancy, Reactive, Fast UI/UX\n- Notifications via Telegram, Discord, Gotify, Slack, Pushover, Email (SMTP), and [90+ notification services, click here for the full list](https://github.com/louislam/uptime-kuma/tree/master/src/components/notifications)\n- 20-second intervals\n- [Multi Languages](https://github.com/louislam/uptime-kuma/tree/master/src/lang)\n- Multiple status pages\n- Map status pages to specific domains\n- Ping chart\n- Certificate info\n- Proxy support\n- 2FA support\n\n## ğŸ”§ How to Install\n\n### ğŸ³ Docker Compose\n\n```bash\nmkdir uptime-kuma\ncd uptime-kuma\ncurl -o compose.yaml https://raw.githubusercontent.com/louislam/uptime-kuma/master/compose.yaml\ndocker compose up -d\n```\n\nUptime Kuma is now running on all network interfaces (e.g. http://localhost:3001 or http://your-ip:3001).\n\n> [!WARNING]\n> File Systems like **NFS** (Network File System) are **NOT** supported. Please map to a local directory or volume.\n\n### ğŸ³ Docker Command\n\n```bash\ndocker run -d --restart=always -p 3001:3001 -v uptime-kuma:/app/data --name uptime-kuma louislam/uptime-kuma:2\n```\n\nUptime Kuma is now running on all network interfaces (e.g. http://localhost:3001 or http://your-ip:3001).\n\nIf you want to limit exposure to localhost only:\n\n```bash\ndocker run ... -p 127.0.0.1:3001:3001 ...\n```\n\n### ğŸ’ªğŸ» Non-Docker\n\nRequirements:\n\n- Platform\n  - âœ… Major Linux distros such as Debian, Ubuntu, Fedora and ArchLinux etc.\n  - âœ… Windows 10 (x64), Windows Server 2012 R2 (x64) or higher\n  - âŒ FreeBSD / OpenBSD / NetBSD\n  - âŒ Replit / Heroku\n- [Node.js](https://nodejs.org/en/download/) >= 20.4\n- [Git](https://git-scm.com/downloads)\n- [pm2](https://pm2.keymetrics.io/) - For running Uptime Kuma in the background\n\n```bash\ngit clone https://github.com/louislam/uptime-kuma.git\ncd uptime-kuma\nnpm run setup\n\n# Option 1. Try it\nnode server/server.js\n\n# (Recommended) Option 2. Run in the background using PM2\n# Install PM2 if you don't have it:\nnpm install pm2 -g && pm2 install pm2-logrotate\n\n# Start Server\npm2 start server/server.js --name uptime-kuma\n```\n\nUptime Kuma is now running on all network interfaces (e.g. http://localhost:3001 or http://your-ip:3001).\n\nMore useful PM2 Commands\n\n```bash\n# If you want to see the current console output\npm2 monit\n\n# If you want to add it to startup\npm2 startup && pm2 save\n```\n\n### Advanced Installation\n\nIf you need more options or need to browse via a reverse proxy, please read:\n\n<https://github.com/louislam/uptime-kuma/wiki/%F0%9F%94%A7-How-to-Install>\n\n## ğŸ†™ How to Update\n\nPlease read:\n\n<https://github.com/louislam/uptime-kuma/wiki/%F0%9F%86%99-How-to-Update>\n\n## ğŸ†• What's Next?\n\nI will assign requests/issues to the next milestone.\n\n<https://github.com/louislam/uptime-kuma/milestones>\n\n## â¤ï¸ Sponsors\n\nThank you so much! (GitHub Sponsors will be updated manually. OpenCollective sponsors will be updated automatically, the list will be cached by GitHub though. It may need some time to be updated)\n\n<img src=\"https://uptime.kuma.pet/sponsors?v=6\" alt=\"Uptime Kuma Sponsors\" />\n\n## ğŸ–¼ More Screenshots\n\nLight Mode:\n\n<img src=\"https://uptime.kuma.pet/img/light.jpg\" width=\"512\" alt=\"Uptime Kuma Light Mode Screenshot of how the Dashboard looks\" />\n\nStatus Page:\n\n<img src=\"https://user-images.githubusercontent.com/1336778/134628766-a3fe0981-0926-4285-ab46-891a21c3e4cb.png\" width=\"512\" alt=\"Uptime Kuma Status Page Screenshot\" />\n\nSettings Page:\n\n<img src=\"https://louislam.net/uptimekuma/2.jpg\" width=\"400\" alt=\"Uptime Kuma Settings Page Screenshot\" />\n\nTelegram Notification Sample:\n\n<img src=\"https://louislam.net/uptimekuma/3.jpg\" width=\"400\" alt=\"Uptime Kuma Telegram Notification Sample Screenshot\" />\n\n## Motivation\n\n- I was looking for a self-hosted monitoring tool like \"Uptime Robot\", but it is hard to find a suitable one. One of the closest ones is statping. Unfortunately, it is not stable and no longer maintained.\n- Wanted to build a fancy UI.\n- Learn Vue 3 and vite.js.\n- Show the power of Bootstrap 5.\n- Try to use WebSocket with SPA instead of a REST API.\n- Deploy my first Docker image to Docker Hub.\n\nIf you love this project, please consider giving it a â­.\n\n## ğŸ—£ï¸ Discussion / Ask for Help\n\nâš ï¸ For any general or technical questions, please don't send me an email, as I am unable to provide support in that manner. I will not respond if you ask questions there.\n\nI recommend using Google, GitHub Issues, or Uptime Kuma's subreddit for finding answers to your question. If you cannot find the information you need, feel free to ask:\n\n- [GitHub Issues](https://github.com/louislam/uptime-kuma/issues)\n- [Subreddit (r/UptimeKuma)](https://www.reddit.com/r/UptimeKuma/)\n\nMy Reddit account: [u/louislamlam](https://reddit.com/u/louislamlam)\nYou can mention me if you ask a question on the subreddit.\n\n## Contributions\n\n### Create Pull Requests\n\nPull requests are awesome.\nTo keep reviews fast and effective, please make sure youâ€™ve [read our pull request guidelines](https://github.com/louislam/uptime-kuma/blob/master/CONTRIBUTING.md#can-i-create-a-pull-request-for-uptime-kuma).\n\n### Test Pull Requests\n\nThere are a lot of pull requests right now, but I don't have time to test them all.\n\nIf you want to help, you can check this:\n<https://github.com/louislam/uptime-kuma/wiki/Test-Pull-Requests>\n\n### Test Beta Version\n\nCheck out the latest beta release here: <https://github.com/louislam/uptime-kuma/releases>\n\n### Bug Reports / Feature Requests\n\nIf you want to report a bug or request a new feature, feel free to open a [new issue](https://github.com/louislam/uptime-kuma/issues).\n\n### Translations\n\nIf you want to translate Uptime Kuma into your language, please visit [Weblate Readme](https://github.com/louislam/uptime-kuma/blob/master/src/lang/README.md).\n\n### Spelling & Grammar\n\nFeel free to correct the grammar in the documentation or code.\nMy mother language is not English and my grammar is not that great.\n",
      "stars_today": 59
    },
    {
      "id": 114938943,
      "name": "nginx-proxy-manager",
      "full_name": "NginxProxyManager/nginx-proxy-manager",
      "description": "Docker container for managing Nginx proxy hosts with a simple, powerful interface",
      "html_url": "https://github.com/NginxProxyManager/nginx-proxy-manager",
      "stars": 31091,
      "forks": 3529,
      "language": "TypeScript",
      "topics": [
        "nginx",
        "nginx-proxy"
      ],
      "created_at": "2017-12-20T23:01:16Z",
      "updated_at": "2026-01-15T23:31:51Z",
      "pushed_at": "2026-01-14T23:58:07Z",
      "open_issues": 945,
      "owner": {
        "login": "NginxProxyManager",
        "avatar_url": "https://avatars.githubusercontent.com/u/88089605?v=4"
      },
      "readme": "<p align=\"center\">\n\t<img src=\"https://nginxproxymanager.com/github.png\">\n\t<br><br>\n\t<img src=\"https://img.shields.io/badge/version-2.13.6-green.svg?style=for-the-badge\">\n\t<a href=\"https://hub.docker.com/repository/docker/jc21/nginx-proxy-manager\">\n\t\t<img src=\"https://img.shields.io/docker/stars/jc21/nginx-proxy-manager.svg?style=for-the-badge\">\n\t</a>\n\t<a href=\"https://hub.docker.com/repository/docker/jc21/nginx-proxy-manager\">\n\t\t<img src=\"https://img.shields.io/docker/pulls/jc21/nginx-proxy-manager.svg?style=for-the-badge\">\n\t</a>\n</p>\n\nThis project comes as a pre-built docker image that enables you to easily forward to your websites\nrunning at home or otherwise, including free SSL, without having to know too much about Nginx or Letsencrypt.\n\n- [Quick Setup](#quick-setup)\n- [Full Setup](https://nginxproxymanager.com/setup/)\n- [Screenshots](https://nginxproxymanager.com/screenshots/)\n\n## Project Goal\n\nI created this project to fill a personal need to provide users with an easy way to accomplish reverse\nproxying hosts with SSL termination and it had to be so easy that a monkey could do it. This goal hasn't changed.\nWhile there might be advanced options they are optional and the project should be as simple as possible\nso that the barrier for entry here is low.\n\n<a href=\"https://www.buymeacoffee.com/jc21\" target=\"_blank\"><img src=\"http://public.jc21.com/github/by-me-a-coffee.png\" alt=\"Buy Me A Coffee\" style=\"height: 51px !important;width: 217px !important;\" ></a>\n\n\n## Features\n\n- Beautiful and Secure Admin Interface based on [Tabler](https://tabler.github.io/)\n- Easily create forwarding domains, redirections, streams and 404 hosts without knowing anything about Nginx\n- Free SSL using Let's Encrypt or provide your own custom SSL certificates\n- Access Lists and basic HTTP Authentication for your hosts\n- Advanced Nginx configuration available for super users\n- User management, permissions and audit log\n\n\n## Hosting your home network\n\nI won't go in to too much detail here but here are the basics for someone new to this self-hosted world.\n\n1. Your home router will have a Port Forwarding section somewhere. Log in and find it\n2. Add port forwarding for port 80 and 443 to the server hosting this project\n3. Configure your domain name details to point to your home, either with a static ip or a service like DuckDNS or [Amazon Route53](https://github.com/jc21/route53-ddns)\n4. Use the Nginx Proxy Manager as your gateway to forward to your other web based services\n\n## Quick Setup\n\n1. Install Docker and Docker-Compose\n\n- [Docker Install documentation](https://docs.docker.com/install/)\n- [Docker-Compose Install documentation](https://docs.docker.com/compose/install/)\n\n2. Create a docker-compose.yml file similar to this:\n\n```yml\nservices:\n  app:\n    image: 'docker.io/jc21/nginx-proxy-manager:latest'\n    restart: unless-stopped\n    ports:\n      - '80:80'\n      - '81:81'\n      - '443:443'\n    volumes:\n      - ./data:/data\n      - ./letsencrypt:/etc/letsencrypt\n```\n\nThis is the bare minimum configuration required. See the [documentation](https://nginxproxymanager.com/setup/) for more.\n\n3. Bring up your stack by running\n\n```bash\ndocker compose up -d\n```\n\n4. Log in to the Admin UI\n\nWhen your docker container is running, connect to it on port `81` for the admin interface.\nSometimes this can take a little bit because of the entropy of keys.\n\n[http://127.0.0.1:81](http://127.0.0.1:81)\n\n\n## Contributing\n\nAll are welcome to create pull requests for this project, against the `develop` branch. Official releases are created from the `master` branch.\n\nCI is used in this project. All PR's must pass before being considered. After passing,\ndocker builds for PR's are available on dockerhub for manual verifications.\n\nDocumentation within the `develop` branch is available for preview at\n[https://develop.nginxproxymanager.com](https://develop.nginxproxymanager.com)\n\n\n### Contributors\n\nSpecial thanks to [all of our contributors](https://github.com/NginxProxyManager/nginx-proxy-manager/graphs/contributors).\n\n\n## Getting Support\n\n1. [Found a bug?](https://github.com/NginxProxyManager/nginx-proxy-manager/issues)\n2. [Discussions](https://github.com/NginxProxyManager/nginx-proxy-manager/discussions)\n3. [Reddit](https://reddit.com/r/nginxproxymanager)\n",
      "stars_today": 58
    },
    {
      "id": 648629873,
      "name": "puck",
      "full_name": "puckeditor/puck",
      "description": "The visual editor for React",
      "html_url": "https://github.com/puckeditor/puck",
      "stars": 10639,
      "forks": 749,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2023-06-02T12:23:41Z",
      "updated_at": "2026-01-16T01:05:46Z",
      "pushed_at": "2026-01-15T14:22:42Z",
      "open_issues": 173,
      "owner": {
        "login": "puckeditor",
        "avatar_url": "https://avatars.githubusercontent.com/u/153829377?v=4"
      },
      "readme": "<br /><br /><br />\n\n<div align=\"center\">\n\n<a href=\"https://puckeditor.com?utm_source=readme&utm_medium=code&utm_campaign=repo&utm_contents=logo\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://res.cloudinary.com/die3nptcg/image/upload/Puck_Logo_White_RGB_j2rwgg.svg\" height=\"100px\" aria-label=\"Puck logo\">\n    <img src=\"https://res.cloudinary.com/die3nptcg/image/upload/Puck_Logo_Black_RGB_dqsjag.svg\" height=\"100px\" aria-label=\"Puck logo\">\n  </picture>\n</a>\n\n_The visual editor for React_\n\n[Documentation](https://puckeditor.com/docs?utm_source=readme&utm_medium=code&utm_campaign=repo&utm_contents=docs_link) â€¢ [Demo](https://demo.puckeditor.com/edit?utm_source=readme&utm_medium=code&utm_campaign=repo&utm_contents=demo_link) â€¢ [Discord](https://discord.gg/V9mDAhuxyZ) â€¢ [Contributing](https://github.com/puckeditor/puck/blob/main/CONTRIBUTING.md)\n\nâ­ï¸ Enjoying Puck? Please [leave a star](https://github.com/puckeditor/puck)!\n\n<br />\n\n[![GIF showing a page being created in the Puck Editor, with components being added, arranged, and customized in real time](https://github.com/user-attachments/assets/25e1ae25-ca5e-450f-afa0-01816830b731)](https://demo.puckeditor.com/edit)\n\n</div>\n\n## What is Puck?\n\nPuck is a modular, open-source visual editor for React.js. You can use Puck to build custom drag-and-drop experiences with your own application and React components.\n\nBecause Puck is just a React component, it plays well with all React.js environments, including Next.js. You own your data and thereâ€™s no vendor lock-in.\n\nPuck is also [licensed under MIT](https://github.com/puckeditor/puck?tab=MIT-1-ov-file#readme), making it suitable for both internal systems and commercial applications.\n\n## Quick start\n\nInstall the package:\n\n```sh\nnpm i @puckeditor/core --save # or npx create-puck-app my-app\n```\n\nRender the editor:\n\n```jsx\n// Editor.jsx\nimport { Puck } from \"@puckeditor/core\";\nimport \"@puckeditor/core/puck.css\";\n\n// Create Puck component config\nconst config = {\n  components: {\n    HeadingBlock: {\n      fields: {\n        children: {\n          type: \"text\",\n        },\n      },\n      render: ({ children }) => {\n        return <h1>{children}</h1>;\n      },\n    },\n  },\n};\n\n// Describe the initial data\nconst initialData = {};\n\n// Save the data to your database\nconst save = (data) => {};\n\n// Render Puck editor\nexport function Editor() {\n  return <Puck config={config} data={initialData} onPublish={save} />;\n}\n```\n\nRender the page:\n\n```jsx\n// Page.jsx\nimport { Render } from \"@puckeditor/core\";\nimport \"@puckeditor/core/puck.css\";\n\nexport function Page() {\n  return <Render config={config} data={data} />;\n}\n```\n\n## Recipes\n\nUse `create-puck-app` to quickly spin up a a pre-configured app based on our provided [recipes](https://github.com/puckeditor/puck/tree/main/recipes):\n\n```sh\nnpx create-puck-app my-app\n```\n\nAvailable recipes include:\n\n- [**next**](https://github.com/puckeditor/puck/tree/main/recipes/next): Next.js example, using App Router and static page generation\n- [**remix**](https://github.com/puckeditor/puck/tree/main/recipes/remix): Remix Run v2 example, using dynamic routes at root-level\n- [**react-router**](https://github.com/puckeditor/puck/tree/main/recipes/react-router): React Router v7 app example, using dynamic routes to create pages at any level\n\n## Community\n\n- [Discord server](https://discord.gg/D9e4E3MQVZ) for discussions\n- [awesome-puck](https://github.com/puckeditor/awesome-puck) community repo for plugins, custom fields & more\n\n## Get support\n\nIf you have any questions about Puck, please open a [GitHub issue](https://github.com/puckeditor/puck/issues) or join us on [Discord](https://discord.gg/D9e4E3MQVZ).\n\nOr [book a discovery call](https://app.cal.com/chrisvxd/puck-enquiry/) for hands-on support and consultancy.\n\n## License\n\nMIT Â© [The Puck Contributors](https://github.com/puckeditor/puck/graphs/contributors)\n",
      "stars_today": 53
    },
    {
      "id": 198484780,
      "name": "beekeeper-studio",
      "full_name": "beekeeper-studio/beekeeper-studio",
      "description": "Modern and easy to use SQL client for MySQL, Postgres, SQLite, SQL Server, and more. Linux, MacOS, and Windows.",
      "html_url": "https://github.com/beekeeper-studio/beekeeper-studio",
      "stars": 21751,
      "forks": 1412,
      "language": "TypeScript",
      "topics": [
        "bigquery",
        "cassandra",
        "cockroachdb",
        "database",
        "electron",
        "firebird",
        "linux-app",
        "mac-app",
        "mariadb",
        "mssql",
        "mysql",
        "postgresql",
        "sql",
        "sql-server",
        "sqlite",
        "windows-app"
      ],
      "created_at": "2019-07-23T18:12:33Z",
      "updated_at": "2026-01-16T00:43:37Z",
      "pushed_at": "2026-01-15T22:01:30Z",
      "open_issues": 1023,
      "owner": {
        "login": "beekeeper-studio",
        "avatar_url": "https://avatars.githubusercontent.com/u/53234021?v=4"
      },
      "readme": "<!-- Target languages: [\"en\", \"pt-BR\", \"es\", \"de\", \"fr\", \"el\", \"ja\", \"it\", \"ko\", \"id\"] -->\nğŸŒ [ES](README-es.md) | [PT-BR](README.pt-br.md) | [DE](README-de.md) | [FR](README-fr.md) | [EL](README-el.md) | [JA](README-ja.md) | [IT](README-it.md) | [KO](README-ko.md) | [ID](README-id.md)\n\n# Beekeeper Studio\n\nBeekeeper Studio is a cross-platform SQL editor and database manager available for Linux, Mac, and Windows.\n\n\n[Download Beekeeper Studio](https://beekeeperstudio.io/get-community)\n\nWe publish binaries for MacOS, Windows, and Linux.\n\n[![image](https://user-images.githubusercontent.com/279769/203650152-4a34af1f-8a38-47cf-a273-d34d1c84feeb.png)](https://beekeeperstudio.io/get)\n\n\nBeekeeper Studio is free to download and provides a lot of features for free, no sign-up, registration, or credit card required. The app provides some premium features for a reasonable cost license fee. [Learn more here](https://beekeeperstudio.io/pricing)\n\n\nMost of the code in this repo is open source under the GPLv3 license. Paid features are also in this repository under a commercial source-available license.\n\nWe welcome community contributions!\n\n\n## Supported Databases\n\n<!-- Don't edit this, it gets built automatically from docs/includes/supported_databases.md -->\n<!-- SUPPORT_BEGIN -->\n\n| Database                                                 | Support                      | Community | Paid Editions |                             Beekeeper Links |\n| :------------------------------------------------------- | :--------------------------- | :-------: | :------: | -----------------------------------------: |\n| [PostgreSQL](https://postgresql.org)                     | â­ Full Support              |    âœ…     |    âœ…    |  [Features](https://beekeeperstudio.io/db/postgres-client) |\n| [MySQL](https://www.mysql.com/)                          | â­ Full Support              |    âœ…     |    âœ…    |  [Features](https://beekeeperstudio.io/db/mysql-client)|\n| [SQLite](https://sqlite.org)                             | â­ Full Support              |    âœ…     |    âœ…    |   [Features](https://beekeeperstudio.io/db/sqlite-client), [Docs](https://docs.beekeeperstudio.io/user_guide/connecting/sqlite) |\n| [SQL Server](https://www.microsoft.com/en-us/sql-server) | â­ Full Support              |    âœ…     |    âœ…    |   [Features](https://beekeeperstudio.io/db/sql-server-client)  |\n| [Amazon Redshift](https://aws.amazon.com/redshift/)      | â­ Full Support              |    âœ…     |    âœ…    |    [Features](https://beekeeperstudio.io/db/redshift-client) |\n| [CockroachDB](https://www.cockroachlabs.com/)            | â­ Full Support              |    âœ…     |    âœ…    | [Features](https://beekeeperstudio.io/db/cockroachdb-client)|\n| [MariaDB](https://mariadb.org/)                          | â­ Full Support              |    âœ…     |    âœ…    |     [Features](https://beekeeperstudio.io/db/mariadb-client) |\n| [TiDB](https://pingcap.com/products/tidb/)               | â­ Full Support              |    âœ…     |    âœ…    |        [Features](https://beekeeperstudio.io/db/tidb-client) |\n| [Google BigQuery](https://cloud.google.com/bigquery)     | â­ Full Support             |    âœ…      |    âœ…    |    [Features](https://beekeeperstudio.io/db/google-big-query-client), [Docs](https://docs.beekeeperstudio.io/user_guide/connecting/bigquery) |\n| [Redis](https://redis.io/)                               | â­ Full Support               |    âœ…    |    âœ…    |       [Features](https://www.beekeeperstudio.io/db/redis-client/) |\n| [Oracle Database](https://www.oracle.com/database/)      | â­ Full Support              |           |    âœ…    |      [Features](https://beekeeperstudio.io/db/oracle-client), [Docs](https://docs.beekeeperstudio.io/user_guide/connecting/oracle) |\n| [Cassandra](http://cassandra.apache.org/)                | â­ Full Support              |           |    âœ…    |   [Features](https://beekeeperstudio.io/db/cassandra-client) |\n| [Firebird](https://firebirdsql.org/)                     | â­ Full Support              |           |    âœ…    |    [Features](https://beekeeperstudio.io/db/firebird-client), [Docs](https://docs.beekeeperstudio.io/user_guide/connecting/firebird) |\n| [LibSQL](https://libsql.org/)                            | â­ Full Support               |          |    âœ…    |      [Features](https://beekeeperstudio.io/db/libsql-client) |\n| [ClickHouse](https://clickhouse.tech/)                   | â­ Full Support                |         |    âœ…    |  [Features](https://www.beekeeperstudio.io/db/clickhouse-client/), [Docs](https://docs.beekeeperstudio.io/user_guide/connecting/clickhouse) |\n| [DuckDB](https://duckdb.org/)                            | â­ Full Support                |         |    âœ…    |      [Features](https://www.beekeeperstudio.io/db/duckdb-client/), [Docs](https://docs.beekeeperstudio.io/user_guide/connecting/duckdb) |\n| [SQL Anywhere](https://www.sap.com/products/technology-platform/sql-anywhere.html)  | â­ Full Support    |           |    âœ…    |      [Features](https://www.beekeeperstudio.io/db/sql-anywhere-client/) |\n| [MongoDB](https://www.mongodb.com/)                      | â­ Full Support               |          |    âœ…    |     [Features](https://www.beekeeperstudio.io/db/mongodb-client/), [Docs](https://docs.beekeeperstudio.io/user_guide/connecting/mongodb) |\n| [Trino](https://trino.io/) / [Presto](https://prestodb.io/) | â­ Full Support                |           |    âœ…    |    [Features](https://www.beekeeperstudio.io/db/trino-client/), [Docs](https://docs.beekeeperstudio.io/user_guide/connecting/trino/) |\n| [Snowflake](https://www.snowflake.com/)                  | â³ Coming Soon                |           |    âœ…    |   -- |\n| [DynamoDB](https://aws.amazon.com/dynamodb/)             | ğŸ—“ï¸ Planned               |           |    âœ…    |       -- |\n\n\n\n\n<!-- SUPPORT_END -->\n\n## Editions of Beekeeper Studio\n\nBeekeeper Studio is a single download with in-app upgrades for premium features.\n\nWe'd love to make Beekeeper Studio totally free for everyone, but building good software is hard work and expensive. We think our paid editions are fairly priced, I hope you do too.\n\nğŸ‘‰ [Compare Beekeeper Studio Editions](https://beekeeperstudio.io/pricing)\n\n## Beekeeper Studio Features\n\nTop feature: It's smooth ğŸ«, fast ğŸ, and you'll actually enjoy using it ğŸ¥°\n\n- Truly cross-platform: Windows, MacOS, and Linux\n- Autocomplete SQL query editor with syntax highlighting\n- Tabbed interface, so you can multitask\n- Sort and filter table data to find just what you need\n- Sensible keyboard-shortcuts\n- Save queries for later\n- Query run-history, so you can find that one query you got working 3 days ago\n- Great dark theme\n- Import/export\n- Backup/restore\n- View data as JSON\n- Loads more\n\n## Our approach to UX\n\nOne of our frustrations with other open-source SQL editors and database managers is that they take a 'kitchen sink' approach to features, adding so many features that the UI becomes cluttered and hard to navigate. We wanted a good looking, open source SQL workbench that's powerful, but also easy to use. We couldn't find one, so we created Beekeeper Studio!\n\nGenerally our guiding star is to only build software that 'feels good' to use. That means at the very least we value Beekeeper being fast, straightforward to use, and modern. If a new feature compromises this vision, we kill it.\n\n\n## Supporting Beekeeper Studio\n\nWe love working on Beekeeper Studio, and we'd love to keep growing and improving it forever. To do that I need your help.\n\nThe best way to support Beekeeper Studio is to purchase a paid [license](https://beekeeperstudio.io/pricing). Every purchase directly supports our work on Beekeeper Studio.\n\nIf you're at a business and using Beekeeper Studio for your job, you should probably get your boss to [buy you a license](https://beekeeperstudio.io/pricing).\n\nIf you can't afford a license, please use the free version, that's why we make a free version!\n\nThank you for your continued support!\n\n\n## Documentation\n\nCheck out [docs.beekeeperstudio.io](https://docs.beekeeperstudio.io) for user guides, FAQs, troubleshooting tips, and more.\n\n## License\n\nBeekeeper Studio Community Edition (the code in this repository) is licensed under the GPLv3 license.\n\nBeekeeper Studio Ultimate Edition contains extra features and is licensed under a [commercial end user agreement (EULA)](https://beekeeperstudio.io/legal/commercial-eula/).\n\nBeekeeper Studio's trademarks (words marks and logos) are not open source. See our [trademark guidelines](https://beekeeperstudio.io/legal/trademark/) for more information.\n\n## Trademark Guidelines\n\nTrademarks can be complicated with open source projects, so we have adapted a set of standard guidelines for using our trademarks that are common to many open source projects.\n\nIf you are just using the Beekeeper Studio app, and you are not forking or distributing Beekeeper Studio code in any way, these probably don't apply to you.\n\nğŸ‘‰ [Beekeeper Studio Trademark Guidelines](https://beekeeperstudio.io/legal/trademark/)\n\n## Contributing to Beekeeper Studio\n\nWe love *any* community engagement. Even if you're complaining because you don't like something about the app!\n\n\n### Contributor Agreements\n\n- Building an inclusive and welcoming community is important to us, so please follow our [code of conduct](code_of_conduct.md) as you engage with the project.\n\n- By contributing to the project you agree to the terms of our [contributor guidelines](CONTRIBUTING.md).\n\n### Contribute without coding\n\nWe have you covered, read our [guide to contributing in 10 minutes without coding](https://github.com/beekeeper-studio/beekeeper-studio/issues/287).\n\n### Compiling and Running Beekeeper Studio Locally\n\nWant to write some code and improve Beekeeper Studio? Getting set-up is easy on Mac, Linux, or Windows.\n\n```bash\n# First: Install NodeJS 20, NPM, and Yarn\n# ...\n\n# 1. Fork the Beekeeper Studio Repo (click fork button at top right of this screen)\n# 2. Check out your fork:\ngit clone git@github.com:<your-username>/beekeeper-studio.git beekeeper-studio\ncd beekeeper-studio/\nyarn install # installs dependencies\n\n\n# Now you can start the app:\nyarn run electron:serve ## the app will now start\n```\n\n**If you get `error:03000086:digital envelope routines::initialization error`, you'll have to update openssl.**\n\n- On Ubuntu/Debian:\n```\nsudo apt-get update\nsudo apt-get upgrade openssl\n```\n\n- On CentOS/RHEL:\n```\nsudo yum update openssl\n```\n\n- On macOS (using Homebrew):\n```\nbrew update\nbrew upgrade openssl\n```\n\n### Where to make changes?\n\nThis repo is now a monorepo, we have several places with code, but only really a couple of important entry points.\n\nAll app code lives in `apps/studio`, some shared code lives in `shared/src`. This is shared with other apps.\n\nBeekeeper Studio has two entry points:\n- `background.js` - this is the electron-side code that controls native things like showing windows.\n- `main.js` - this is the entry point for the Vue.js app. You can follow the Vue component breadcrumbs from `App.vue` to find the screen you need.\n\n**Generally we have two 'screens':**\n- ConnectionInterface - connecting to a DB\n- CoreInterface - interacting with a database\n\n### How to submit a change?\n\n\n- Push your changes to your repository and open a Pull Request from our github page (this page)\n- Make sure to write some notes about what your change does! A gif is always welcome for visual changes.\n\n## Maintainer notes (casual readers can ignore this stuff)\n\n### Upgrading Electron Gotchas\n\nThis is always a total pain and will break the build 9/10.\n\nSome things you need to consider when upgrading Electron:\n\n1. Does it use a different node version. Eg Electron-18 uses node 14, 22 uses node 16. So everyone needs to upgrade\n2. Does node-abi need to be upgraded to be able to understand the electron version? This is used in the build to fetch prebuilt packages. You need to upgrade this in root/package.json#resolutions\n3. Were any APIs deprecated or removed? Make sure all features that interact with the Electron APIs still work, stuff like - selecting a file, maximizing a window, running a query, etc.\n\n\n### Release Process\n\n1. Up the version number in package.json\n2. Replace `build/release-notes.md` with the latest release notes. Follow the format that is there.\n  - run `git log <last-tag>..HEAD --oneline | grep 'Merge pull'` to find PRs merged\n2. Commit\n3. Push to master\n4. Create a tag `git tag v<version>`. It must start with a 'v'\n5. `git push origin <tagname>`\n  - Now wait for the build/publish action to complete on Github\n6. Push the new release live\n  - Go to the new 'draft' release on the releases tab of github, edit the notes, publish\n  - Log into snapcraft.io, drag the uploaded release into the 'stable' channel for each architecture.\n\nThis should also publish the latest docs\n\nPost Release:\n1. Copy release notes to a blog post, post on website\n2. Tweet link\n3. Share on LinkedIn\n4. Send to mailing list on SendInBlue\n\n\n## Big Thanks\n\nBeekeeper Studio wouldn't exist without [Sqlectron-core](https://github.com/sqlectron/sqlectron-core), the core database libraries from the [Sqlectron project](https://github.com/sqlectron/sqlectron-gui). Beekeeper Studio started as an experimental fork of that repository. A big thanks to @maxcnunes and the rest of the Sqlectron community.\n\nThe original license from sqlectron-core is included here:\n\n```\nCopyright (c) 2015 The SQLECTRON Team\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n'Software'), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n```\n",
      "stars_today": 51
    },
    {
      "id": 234798675,
      "name": "bevy",
      "full_name": "bevyengine/bevy",
      "description": "A refreshingly simple data-driven game engine built in Rust",
      "html_url": "https://github.com/bevyengine/bevy",
      "stars": 44092,
      "forks": 4326,
      "language": "Rust",
      "topics": [
        "bevy",
        "game-development",
        "game-engine",
        "gamedev",
        "open-source",
        "rust"
      ],
      "created_at": "2020-01-18T21:13:55Z",
      "updated_at": "2026-01-16T00:56:32Z",
      "pushed_at": "2026-01-16T00:56:28Z",
      "open_issues": 3174,
      "owner": {
        "login": "bevyengine",
        "avatar_url": "https://avatars.githubusercontent.com/u/60047606?v=4"
      },
      "readme": "# [![Bevy](https://bevy.org/assets/bevy_logo_light_dark_and_dimmed.svg)](https://bevy.org)\n\n[![License](https://img.shields.io/badge/license-MIT%2FApache-blue.svg)](https://github.com/bevyengine/bevy#license)\n[![Crates.io](https://img.shields.io/crates/v/bevy.svg)](https://crates.io/crates/bevy)\n[![Downloads](https://img.shields.io/crates/d/bevy.svg)](https://crates.io/crates/bevy)\n[![Docs](https://docs.rs/bevy/badge.svg)](https://docs.rs/bevy/latest/bevy/)\n[![CI](https://github.com/bevyengine/bevy/workflows/CI/badge.svg)](https://github.com/bevyengine/bevy/actions)\n[![Discord](https://img.shields.io/discord/691052431525675048.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.gg/bevy)\n\n## What is Bevy?\n\nBevy is a refreshingly simple data-driven game engine built in Rust. It is free and open-source forever!\n\n## WARNING\n\nBevy is still in the early stages of development. Important features are missing. Documentation is sparse. A new version of Bevy containing breaking changes to the API is released [approximately once every 3 months](https://bevy.org/news/bevy-0-6/#the-train-release-schedule). We provide [migration guides](https://bevy.org/learn/migration-guides/), but we can't guarantee migrations will always be easy. Use only if you are willing to work in this environment.\n\n**MSRV:** Bevy relies heavily on improvements in the Rust language and compiler.\nAs a result, the Minimum Supported Rust Version (MSRV) is generally close to \"the latest stable release\" of Rust.\n\n## Design Goals\n\n* **Capable**: Offer a complete 2D and 3D feature set\n* **Simple**: Easy for newbies to pick up, but infinitely flexible for power users\n* **Data Focused**: Data-oriented architecture using the Entity Component System paradigm\n* **Modular**: Use only what you need. Replace what you don't like\n* **Fast**: App logic should run quickly, and when possible, in parallel\n* **Productive**: Changes should compile quickly ... waiting isn't fun\n\n## About\n\n* **[Features](https://bevy.org):** A quick overview of Bevy's features.\n* **[News](https://bevy.org/news/)**: A development blog that covers our progress, plans and shiny new features.\n\n## Docs\n\n* **[Quick Start Guide](https://bevy.org/learn/quick-start/introduction):** Bevy's official Quick Start Guide. The best place to start learning Bevy.\n* **[Bevy Rust API Docs](https://docs.rs/bevy):** Bevy's Rust API docs, which are automatically generated from the doc comments in this repo.\n* **[Official Examples](https://github.com/bevyengine/bevy/tree/latest/examples):** Bevy's dedicated, runnable examples, which are great for digging into specific concepts.\n* **[Community-Made Learning Resources](https://bevy.org/assets/#learning)**: More tutorials, documentation, and examples made by the Bevy community.\n\n## Community\n\nBefore contributing or participating in discussions with the community, you should familiarize yourself with our [**Code of Conduct**](./CODE_OF_CONDUCT.md).\n\n* **[Discord](https://discord.gg/bevy):** Bevy's official discord server.\n* **[Reddit](https://reddit.com/r/bevy):** Bevy's official subreddit.\n* **[GitHub Discussions](https://github.com/bevyengine/bevy/discussions):** The best place for questions about Bevy, answered right here!\n* **[Bevy Assets](https://bevy.org/assets/):** A collection of awesome Bevy projects, tools, plugins and learning materials.\n\n### Contributing\n\nIf you'd like to help build Bevy, check out the **[Contributor's Guide](https://bevy.org/learn/contribute/introduction)**.\nFor simple problems, feel free to [open an issue](https://github.com/bevyengine/bevy/issues) or\n[PR](https://github.com/bevyengine/bevy/pulls) and tackle it yourself!\n\nFor more complex architecture decisions and experimental mad science, please open an [RFC](https://github.com/bevyengine/rfcs) (Request For Comments) so we can brainstorm together effectively!\n\n## Getting Started\n\nWe recommend checking out the [Quick Start Guide](https://bevy.org/learn/quick-start/introduction) for a brief introduction.\n\nFollow the [Setup guide](https://bevy.org/learn/quick-start/getting-started/setup) to ensure your development environment is set up correctly.\nOnce set up, you can quickly try out the [examples](https://github.com/bevyengine/bevy/tree/latest/examples) by cloning this repo and running the following commands:\n\n```sh\n# Switch to the correct version (latest release, default is main development branch)\ngit checkout latest\n# Runs the \"breakout\" example\ncargo run --example breakout\n```\n\nTo draw a window with standard functionality enabled, use:\n\n```rust\nuse bevy::prelude::*;\n\nfn main() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .run();\n}\n```\n\n### Fast Compiles\n\nBevy can be built just fine using default configuration on stable Rust. However for really fast iterative compiles, you should enable the \"fast compiles\" setup by [following the instructions here](https://bevy.org/learn/quick-start/getting-started/setup).\n\n## [Bevy Cargo Features][cargo_features]\n\nThis [list][cargo_features] outlines the different cargo features supported by Bevy. These allow you to customize the Bevy feature set for your use-case.\n\n[cargo_features]: docs/cargo_features.md\n\n## Thanks\n\nBevy is the result of the hard work of many people. A huge thanks to all Bevy contributors, the many open source projects that have come before us, the [Rust gamedev ecosystem](https://arewegameyet.rs/), and the many libraries we build on.\n\nA huge thanks to Bevy's [generous sponsors](https://bevy.org). Bevy will always be free and open source, but it isn't free to make. Please consider [sponsoring our work](https://bevy.org/donate/) if you like what we're building.\n\n<!-- This next line need to stay exactly as is. It is required for BrowserStack sponsorship. -->\nThis project is tested with BrowserStack.\n\n## License\n\nBevy is free, open source and permissively licensed!\nExcept where noted (below and/or in individual files), all code in this repository is dual-licensed under either:\n\n* MIT License ([LICENSE-MIT](LICENSE-MIT) or [http://opensource.org/licenses/MIT](http://opensource.org/licenses/MIT))\n* Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0))\n\nat your option.\nThis means you can select the license you prefer!\nThis dual-licensing approach is the de-facto standard in the Rust ecosystem and there are [very good reasons](https://github.com/bevyengine/bevy/issues/2373) to include both.\n\nSome of the engine's code carries additional copyright notices and license terms due to their external origins.\nThese are generally BSD-like, but exact details vary by crate:\nIf the README of a crate contains a 'License' header (or similar), the additional copyright notices and license terms applicable to that crate will be listed.\nThe above licensing requirement still applies to contributions to those crates, and sections of those crates will carry those license terms.\nThe [license](https://doc.rust-lang.org/cargo/reference/manifest.html#the-license-and-license-file-fields) field of each crate will also reflect this.\n\nThe [assets](assets) included in this repository (for our [examples](./examples/README.md)) typically fall under different open licenses.\nThese will not be included in your game (unless copied in by you), and they are not distributed in the published bevy crates.\nSee [CREDITS.md](CREDITS.md) for the details of the licenses of those files.\n\n### Your contributions\n\nUnless you explicitly state otherwise,\nany contribution intentionally submitted for inclusion in the work by you,\nas defined in the Apache-2.0 license,\nshall be dual licensed as above,\nwithout any additional terms or conditions.\n",
      "stars_today": 50
    },
    {
      "id": 191820100,
      "name": "mediapipe",
      "full_name": "google-ai-edge/mediapipe",
      "description": "Cross-platform, customizable ML solutions for live and streaming media.",
      "html_url": "https://github.com/google-ai-edge/mediapipe",
      "stars": 33197,
      "forks": 5735,
      "language": "C++",
      "topics": [
        "android",
        "audio-processing",
        "c-plus-plus",
        "calculator",
        "computer-vision",
        "deep-learning",
        "framework",
        "graph-based",
        "graph-framework",
        "inference",
        "machine-learning",
        "mediapipe",
        "mobile-development",
        "perception",
        "pipeline-framework",
        "stream-processing",
        "video-processing"
      ],
      "created_at": "2019-06-13T19:16:41Z",
      "updated_at": "2026-01-16T01:03:25Z",
      "pushed_at": "2026-01-15T20:56:41Z",
      "open_issues": 614,
      "owner": {
        "login": "google-ai-edge",
        "avatar_url": "https://avatars.githubusercontent.com/u/150697620?v=4"
      },
      "readme": "---\nlayout: forward\ntarget: https://developers.google.com/mediapipe\ntitle: Home\nnav_order: 1\n---\n\n----\n\n**Attention:** *We have moved to\n[https://developers.google.com/mediapipe](https://developers.google.com/mediapipe)\nas the primary developer documentation site for MediaPipe as of April 3, 2023.*\n\n![MediaPipe](https://developers.google.com/static/mediapipe/images/home/hero_01_1920.png)\n\n**Attention**: MediaPipe Solutions Preview is an early release. [Learn\nmore](https://developers.google.com/mediapipe/solutions/about#notice).\n\n**On-device machine learning for everyone**\n\nDelight your customers with innovative machine learning features. MediaPipe\ncontains everything that you need to customize and deploy to mobile (Android,\niOS), web, desktop, edge devices, and IoT, effortlessly.\n\n*   [See demos](https://goo.gle/mediapipe-studio)\n*   [Learn more](https://developers.google.com/mediapipe/solutions)\n\n## Get started\n\nYou can get started with MediaPipe Solutions by by checking out any of the\ndeveloper guides for\n[vision](https://developers.google.com/mediapipe/solutions/vision/object_detector),\n[text](https://developers.google.com/mediapipe/solutions/text/text_classifier),\nand\n[audio](https://developers.google.com/mediapipe/solutions/audio/audio_classifier)\ntasks. If you need help setting up a development environment for use with\nMediaPipe Tasks, check out the setup guides for\n[Android](https://developers.google.com/mediapipe/solutions/setup_android), [web\napps](https://developers.google.com/mediapipe/solutions/setup_web), and\n[Python](https://developers.google.com/mediapipe/solutions/setup_python).\n\n## Solutions\n\nMediaPipe Solutions provides a suite of libraries and tools for you to quickly\napply artificial intelligence (AI) and machine learning (ML) techniques in your\napplications. You can plug these solutions into your applications immediately,\ncustomize them to your needs, and use them across multiple development\nplatforms. MediaPipe Solutions is part of the MediaPipe [open source\nproject](https://github.com/google/mediapipe), so you can further customize the\nsolutions code to meet your application needs.\n\nThese libraries and resources provide the core functionality for each MediaPipe\nSolution:\n\n*   **MediaPipe Tasks**: Cross-platform APIs and libraries for deploying\n    solutions. [Learn\n    more](https://developers.google.com/mediapipe/solutions/tasks).\n*   **MediaPipe models**: Pre-trained, ready-to-run models for use with each\n    solution.\n\nThese tools let you customize and evaluate solutions:\n\n*   **MediaPipe Model Maker**: Customize models for solutions with your data.\n    [Learn more](https://developers.google.com/mediapipe/solutions/model_maker).\n*   **MediaPipe Studio**: Visualize, evaluate, and benchmark solutions in your\n    browser. [Learn\n    more](https://developers.google.com/mediapipe/solutions/studio).\n\n### Legacy solutions\n\nWe have ended support for [these MediaPipe Legacy Solutions](https://developers.google.com/mediapipe/solutions/guide#legacy)\nas of March 1, 2023. All other MediaPipe Legacy Solutions will be upgraded to\na new MediaPipe Solution. See the [Solutions guide](https://developers.google.com/mediapipe/solutions/guide#legacy)\nfor details. The [code repository](https://github.com/google/mediapipe/tree/master/mediapipe)\nand prebuilt binaries for all MediaPipe Legacy Solutions will continue to be\nprovided on an as-is basis.\n\nFor more on the legacy solutions, see the [documentation](https://github.com/google/mediapipe/tree/master/docs/solutions).\n\n## Framework\n\nTo start using MediaPipe Framework, [install MediaPipe\nFramework](https://developers.google.com/mediapipe/framework/getting_started/install)\nand start building example applications in C++, Android, and iOS.\n\n[MediaPipe Framework](https://developers.google.com/mediapipe/framework) is the\nlow-level component used to build efficient on-device machine learning\npipelines, similar to the premade MediaPipe Solutions.\n\nBefore using MediaPipe Framework, familiarize yourself with the following key\n[Framework\nconcepts](https://developers.google.com/mediapipe/framework/framework_concepts/overview.md):\n\n*   [Packets](https://developers.google.com/mediapipe/framework/framework_concepts/packets.md)\n*   [Graphs](https://developers.google.com/mediapipe/framework/framework_concepts/graphs.md)\n*   [Calculators](https://developers.google.com/mediapipe/framework/framework_concepts/calculators.md)\n\n## Community\n\n*   [Slack community](https://mediapipe.page.link/joinslack) for MediaPipe\n    users.\n*   [Discuss](https://groups.google.com/forum/#!forum/mediapipe) - General\n    community discussion around MediaPipe.\n*   [Awesome MediaPipe](https://mediapipe.page.link/awesome-mediapipe) - A\n    curated list of awesome MediaPipe related frameworks, libraries and\n    software.\n\n## Contributing\n\nWe welcome contributions. Please follow these\n[guidelines](https://github.com/google/mediapipe/blob/master/CONTRIBUTING.md).\n\nWe use GitHub issues for tracking requests and bugs. Please post questions to\nthe MediaPipe Stack Overflow with a `mediapipe` tag.\n\n## Resources\n\n### Publications\n\n*   [Bringing artworks to life with AR](https://developers.googleblog.com/2021/07/bringing-artworks-to-life-with-ar.html)\n    in Google Developers Blog\n*   [Prosthesis control via Mirru App using MediaPipe hand tracking](https://developers.googleblog.com/2021/05/control-your-mirru-prosthesis-with-mediapipe-hand-tracking.html)\n    in Google Developers Blog\n*   [SignAll SDK: Sign language interface using MediaPipe is now available for\n    developers](https://developers.googleblog.com/2021/04/signall-sdk-sign-language-interface-using-mediapipe-now-available.html)\n    in Google Developers Blog\n*   [MediaPipe Holistic - Simultaneous Face, Hand and Pose Prediction, on\n    Device](https://ai.googleblog.com/2020/12/mediapipe-holistic-simultaneous-face.html)\n    in Google AI Blog\n*   [Background Features in Google Meet, Powered by Web ML](https://ai.googleblog.com/2020/10/background-features-in-google-meet.html)\n    in Google AI Blog\n*   [MediaPipe 3D Face Transform](https://developers.googleblog.com/2020/09/mediapipe-3d-face-transform.html)\n    in Google Developers Blog\n*   [Instant Motion Tracking With MediaPipe](https://developers.googleblog.com/2020/08/instant-motion-tracking-with-mediapipe.html)\n    in Google Developers Blog\n*   [BlazePose - On-device Real-time Body Pose Tracking](https://ai.googleblog.com/2020/08/on-device-real-time-body-pose-tracking.html)\n    in Google AI Blog\n*   [MediaPipe Iris: Real-time Eye Tracking and Depth Estimation](https://ai.googleblog.com/2020/08/mediapipe-iris-real-time-iris-tracking.html)\n    in Google AI Blog\n*   [MediaPipe KNIFT: Template-based feature matching](https://developers.googleblog.com/2020/04/mediapipe-knift-template-based-feature-matching.html)\n    in Google Developers Blog\n*   [Alfred Camera: Smart camera features using MediaPipe](https://developers.googleblog.com/2020/03/alfred-camera-smart-camera-features-using-mediapipe.html)\n    in Google Developers Blog\n*   [Real-Time 3D Object Detection on Mobile Devices with MediaPipe](https://ai.googleblog.com/2020/03/real-time-3d-object-detection-on-mobile.html)\n    in Google AI Blog\n*   [AutoFlip: An Open Source Framework for Intelligent Video Reframing](https://ai.googleblog.com/2020/02/autoflip-open-source-framework-for.html)\n    in Google AI Blog\n*   [MediaPipe on the Web](https://developers.googleblog.com/2020/01/mediapipe-on-web.html)\n    in Google Developers Blog\n*   [Object Detection and Tracking using MediaPipe](https://developers.googleblog.com/2019/12/object-detection-and-tracking-using-mediapipe.html)\n    in Google Developers Blog\n*   [On-Device, Real-Time Hand Tracking with MediaPipe](https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html)\n    in Google AI Blog\n*   [MediaPipe: A Framework for Building Perception Pipelines](https://arxiv.org/abs/1906.08172)\n\n### Videos\n\n*   [YouTube Channel](https://www.youtube.com/c/MediaPipe)\n",
      "stars_today": 48
    },
    {
      "id": 769023213,
      "name": "convex-backend",
      "full_name": "get-convex/convex-backend",
      "description": "The open-source reactive database for app developers",
      "html_url": "https://github.com/get-convex/convex-backend",
      "stars": 9380,
      "forks": 524,
      "language": "Rust",
      "topics": [
        "backend",
        "convex",
        "database",
        "rust",
        "typescript"
      ],
      "created_at": "2024-03-08T07:23:15Z",
      "updated_at": "2026-01-16T00:13:11Z",
      "pushed_at": "2026-01-15T23:54:50Z",
      "open_issues": 126,
      "owner": {
        "login": "get-convex",
        "avatar_url": "https://avatars.githubusercontent.com/u/81530787?v=4"
      },
      "readme": "<p align=\"center\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://static.convex.dev/logo/convex-logo-light.svg\" width=\"600\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://static.convex.dev/logo/convex-logo.svg\" width=\"600\">\n  <img alt=\"Convex logo\" src=\"https://static.convex.dev/logo/convex-logo.svg\" width=\"600\">\n</picture>\n</p>\n\n[Convex](https://convex.dev) is the open-source reactive database designed to\nmake life easy for web app developers, whether human or LLM. Fetch data and\nperform business logic with strong consistency by writing pure TypeScript.\n\nConvex provides a database, a place to write your server functions, and client\nlibraries. It makes it easy to build and scale dynamic live-updating apps.\n[Read the docs to learn more](https://docs.convex.dev/understanding/).\n\nDevelopment of the Convex backend is led by the Convex team. We\n[welcome bug fixes](./CONTRIBUTING.md) and\n[love receiving feedback](https://discord.gg/convex). We keep this repository\nsynced with any internal development work within a handful of days.\n\n## Getting Started\n\nVisit our [documentation](https://docs.convex.dev/) to learn more about Convex\nand follow our getting started guides.\n\nThe easiest way to build with Convex is through our\n[cloud platform](https://www.convex.dev/plans), which includes a generous free\ntier and lets you focus on building your application without worrying about\ninfrastructure. Many small applications and side-projects can operate entirely\non the free tier with zero cost and zero maintenance.\n\n## Self Hosting\n\nThe self-hosted product includes most features of the cloud product, including\nthe dashboard and CLI. Self-hosted Convex works well with a variety of tools\nincluding Neon, Fly.io, Vercel, Netlify, RDS, Sqlite, Postgres, and more.\n\nYou can either use Docker (recommended) or a prebuilt binary to self host\nConvex. Check out our [self-hosting guide](./self-hosted/README.md) for detailed\ninstructions. Community support for self-hosting is available in the\n`#self-hosted` channel on [Discord](https://discord.gg/convex).\n\n## Community & Support\n\n- Join our [Discord community](https://discord.gg/convex) for help and\n  discussions.\n- Report issues when building and using the open source Convex backend through\n  [GitHub Issues](https://github.com/get-convex/convex-backend/issues)\n- By submitting pull requests, you confirm that Convex can use, modify, copy,\n  and redistribute the contribution, under the terms of its choice.\n\n## Building from source\n\nSee [BUILD.md](./BUILD.md).\n\n## Disclaimers\n\n- If you choose to self-host, we recommend following the self-hosting guide. If\n  you are instead building from source, make sure to change your instance secret\n  and admin key from the defaults in the repo.\n- Convex is battle tested most thoroughly on Linux and Mac. On Windows, it has\n  less experience. If you run into issues, please message us on\n  [Discord](https://convex.dev/community) in the `#self-hosted` channel.\n- Convex self-hosted builds contain a beacon to help Convex improve the product.\n  The information is minimal and anonymous and helpful to Convex, but if you\n  really want to disable it, you can set the `--disable-beacon` flag on the\n  backend binary. The beacon's messages print in the log and only include\n  - A random identifier for your deployment (not used elsewhere)\n  - Migration version of your database\n  - Git rev of the backend\n  - Uptime of the backend\n\n## Repository layout\n\n- `crates/` contains Rust code\n\n  - Main binary\n    - `local_backend/` is an application server on top of the `Runtime`. This is\n      the serving edge for the Convex cloud.\n\n- `npm-packages/` contains both our public and internal TypeScript packages.\n  - Internal packages\n    - `udf-runtime/` sets up the user-defined functions JS environment for\n      queries and mutations\n    - `udf-tests/` is a collection of functions used in testing the isolate\n      layer\n    - `system-udfs/` contains functions used by the Convex system e.g. the CLI\n",
      "stars_today": 48
    },
    {
      "id": 676377723,
      "name": "DevOps-Projects",
      "full_name": "NotHarshhaa/DevOps-Projects",
      "description": "ğ‘«ğ’†ğ’—ğ‘¶ğ’‘ğ’” ğ‘¹ğ’†ğ’‚ğ’ ğ‘¾ğ’ğ’“ğ’ğ’… ğ‘·ğ’“ğ’ğ’‹ğ’†ğ’„ğ’•ğ’” ğ’‡ğ’ğ’“ ğ‘¨ğ’”ğ’‘ğ’Šğ’“ğ’Šğ’ğ’ˆ ğ‘«ğ’†ğ’—ğ‘¶ğ’‘ğ’” ğ‘¬ğ’ğ’ˆğ’Šğ’ğ’†ğ’†ğ’“ğ’” [ğ‘©ğ’†ğ’ˆğ’Šğ’ğ’ğ’†ğ’“ ğ’•ğ’ ğ‘¨ğ’…ğ’—ğ’‚ğ’ğ’„ğ’†ğ’…]",
      "html_url": "https://github.com/NotHarshhaa/DevOps-Projects",
      "stars": 3235,
      "forks": 3373,
      "language": "Java",
      "topics": [
        "devops",
        "devops-learning",
        "devops-poc",
        "devops-project",
        "devops-realtime",
        "devops-tools",
        "practical-devops",
        "projects-list",
        "realtime-devops-projects",
        "realtimeprojects"
      ],
      "created_at": "2023-08-09T04:19:38Z",
      "updated_at": "2026-01-16T00:04:27Z",
      "pushed_at": "2025-12-21T07:30:47Z",
      "open_issues": 15,
      "owner": {
        "login": "NotHarshhaa",
        "avatar_url": "https://avatars.githubusercontent.com/u/112948305?v=4"
      },
      "readme": "# **Real-World DevOps/Cloud Projects For Learning from Beginner to Advanced** â™\n\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/13316\" target=\"_blank\" rel=\"noopener noreferrer\">\n    <img src=\"https://trendshift.io/api/badge/repositories/13316\" alt=\"NotHarshhaa/DevOps-Projects | Trendshift\" style=\"width:350px;height:80px;max-width:100%;\" />\n  </a>\n</p>\n\n[![Forks][forks-shield]][forks-url]\n[![Stars][stars-shield]][stars-url]\n[![Issues][issues-shield]][issues-url]\n[![Last Commit][commit-shield]][commit-url]\n[![Code of Conduct][coc-shield]][coc-url]\n[![Contributing][contrib-shield]][contrib-url]\n\n<!-- MARKDOWN LINKS & IMAGES -->\n[forks-shield]: https://img.shields.io/github/forks/NotHarshhaa/DevOps-Projects?style=for-the-badge&logo=github&logoColor=white&color=orange\n[forks-url]: https://github.com/NotHarshhaa/DevOps-Projects/network/members\n\n[stars-shield]: https://img.shields.io/github/stars/NotHarshhaa/DevOps-Projects.svg?style=for-the-badge&logo=github&logoColor=white&color=brightgreen\n[stars-url]: https://github.com/NotHarshhaa/DevOps-Projects/stargazers\n\n[issues-shield]: https://img.shields.io/github/issues/NotHarshhaa/DevOps-Projects?style=for-the-badge&logo=github&logoColor=white&color=blue\n[issues-url]: https://github.com/NotHarshhaa/DevOps-Projects/issues\n\n[commit-shield]: https://img.shields.io/github/last-commit/NotHarshhaa/DevOps-Projects?style=for-the-badge&logo=git&logoColor=white&color=ff69b4\n[commit-url]: https://github.com/NotHarshhaa/DevOps-Projects/commits/master\n\n[coc-shield]: https://img.shields.io/badge/Code%20of%20Conduct-Enforced-blueviolet?style=for-the-badge&logo=handshake&logoColor=white\n[coc-url]: https://github.com/NotHarshhaa/DevOps-Projects/blob/master/CODE_OF_CONDUCT.md\n\n[contrib-shield]: https://img.shields.io/badge/Contributions-Welcome-ff69b4?style=for-the-badge&logo=gitbook&logoColor=white\n[contrib-url]: https://github.com/NotHarshhaa/DevOps-Projects/blob/master/CONTRIBUTING.md\n\n![DevOps-Projects](https://imgur.com/tlMOmn0.png)\n\n## ğŸ‘¥ **Project Ownership**\n\n<a href=\"https://github.com/NotHarshhaa/DevOps-Projects/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=NotHarshhaa/DevOps-Projects\" />\n</a>\n\n---\n\n## ğŸŒŸ **Star History**\n\n[![Star History Chart](https://api.star-history.com/svg?repos=NotHarshhaa/DevOps-Projects&type=Date)](https://www.star-history.com/#NotHarshhaa/DevOps-Projects&Date)\n\n---\n\n_*Welcome to the ultimate resource for **learning DevOps through hands-on projects!** This repository is designed to cater to aspiring **DevOps engineers** of all skill levels, from beginners taking their first steps in the field to advanced users looking to deepen their knowledge and expertise.*_\n\n![Welcome Badge](https://img.shields.io/badge/ğŸš€%20Welcome-Learn%20DevOps%20Through%20Hands--On%20Projects-10b981?style=for-the-badge&logo=opsgenie&logoColor=white)\n\n---\n\n## ğŸ§  **Purpose of the Repository**\n\nThis repository serves as a comprehensive resource for aspiring DevOps engineers to learn and implement real-world DevOps projects. It includes guides and solutions for deploying scalable systems, such as deploying a Java application on AWS using a 3-tier architecture and setting up scalable VPC architectures in the cloud.\n\nThe README files provide detailed instructions for implementing these projects, emphasizing practical deployment steps, pre-requisites, and validation processes. For example, one project focuses on deploying a Java-based login application integrated with a MySQL database, while another covers creating modular VPC network setups leveraging AWS services.\n\n![Purpose of Repository](https://img.shields.io/badge/ğŸ¯%20Purpose-Comprehensive%20DevOps%20Learning%20Hub-8b5cf6?style=for-the-badge&logo=target&logoColor=white)\n\n---\n\n## ğŸ” **Analysis of Features and Technologies**\n\nThe repository demonstrates extensive use of DevOps concepts and tools, focusing on AWS cloud infrastructure and automation. It features technologies such as:\n\n- **EC2, RDS, VPC, Auto Scaling, IAM roles**\n- **Maven, SonarCloud, JFrog Artifactory**\n- **Monitoring via CloudWatch**\n- **Custom AMIs, automation scripts**\n\nThese elements showcase a robust implementation of scalable, secure, and automated systems aligned with real-world DevOps practices.\n\n![Analysis of Features](https://img.shields.io/badge/ğŸ› ï¸%20Features%20&%20Technologies-AWS%2C%20CI%2FCD%2C%20Automation-10b981?style=for-the-badge&logo=amazonaws&logoColor=white)\n\n---\n\n## ğŸŒ **Real-time DevOps/Cloud Projects Showcase**\n\nTo improve readability and accessibility for users, this repository is also available as a modern and responsive web interface.\n\nA website showcasing a curated list of major real-time DevOps and Cloud projects, ranging from beginner to advanced levels. Built using **Next.js** and styled with **Tailwind CSS**, this project leverages a modern starter template for fast and responsive development. Perfect for learning and exploring hands-on DevOps and Cloud concepts!\n\nğŸ”— **Explore the site**: [projects.prodevopsguytech.com](https://projects.prodevopsguytech.com)\n\n![Showcase Website](https://img.shields.io/badge/ğŸŒ%20Project%20Showcase-Next.js%20+%20Tailwind%20UI-0ea5e9?style=for-the-badge&logo=vercel&logoColor=white)\n\n---\n\n## ğŸ”— **Related AWS Projects Repository**\n\nFor comprehensive AWS-specific projects and hands-on learning experiences, visit our dedicated AWS Projects repository:\n\n**AWS Projects Repository Highlights:**\n\n* **Real-world AWS Projects** from beginner to advanced levels\n* **AWS DevOps Focus** with practical implementation guides\n* **Hands-on Learning** with AWS services and best practices\n* **Industry-Relevant** projects covering EC2, VPC, RDS, Lambda, and more\n* **Community Driven** with active contributions and AWS expertise\n\nğŸ”— **Visit the AWS repository**: [AWS-Projects](https://github.com/NotHarshhaa/AWS-Projects)\n\n![AWS Projects](https://img.shields.io/badge/â˜ï¸%20AWS%20Projects-Dedicated%20AWS%20Learning%20Hub-ff9900?style=for-the-badge&logo=amazonaws&logoColor=white)\n\n---\n\n## **Repository Contents for DevOps Projects from Beginner to Advanced Levels**\n\n> [!IMPORTANT]\n>\n> _This repository contains a comprehensive collection of DevOps projects, each meticulously crafted to provide a hands-on learning experience. The projects are categorized into different skill levels to ensure that everyone, regardless of their current expertise, can find a suitable starting point and progressively enhance their skills._\n>\n> - **Beginner Projects:** Simple, foundational projects that introduce basic DevOps concepts and tools.\n> - **Intermediate Projects:** More complex projects that require a good understanding of DevOps fundamentals.\n> - **Advanced Projects:** Challenging projects designed to push your limits and deepen your understanding of sophisticated DevOps practices.\n\n![DevOps Levels](https://img.shields.io/badge/ğŸ“‚%20DevOps%20Projects-Beginner%20to%20Advanced-blueviolet?style=for-the-badge&logo=github&logoColor=white)\n\n---\n\n## **Integration of DevOps Technology with Other Technologies**\n\n> [!NOTE]\n> _In the modern tech landscape, DevOps doesn't exist in isolation. It intersects with a variety of other technologies, enhancing and being enhanced by them. This repository includes projects that integrate DevOps with several key technologies, allowing you to see how these integrations work in real-world scenarios._\n>\n> - **Machine Learning:** Implement DevOps practices to manage and deploy machine learning models efficiently.\n> - **Version Control with Git & GitHub:** Learn how to manage code versions and collaborate with others using Git and GitHub.\n> - **CI/CD Pipelines:** Set up continuous integration and continuous deployment pipelines to automate the testing and deployment of your applications.\n> - **Cloud Platforms (AWS, Azure, GCP):** Deploy applications on cloud platforms and leverage their services for scalability and reliability.\n> - **Containerization (Docker, Kubernetes):** Use container technologies to ensure that your applications run consistently across different environments.\n\n![Integration](https://img.shields.io/badge/ğŸ”—%20DevOps%20+%20Other%20Technologies-Seamless%20Integration-green?style=for-the-badge&logo=git&logoColor=white)\n\n---\n\n## **Project Scope**\n\n> [!IMPORTANT]\n> The projects span a wide array of topics within the DevOps domain, each designed to provide practical experience and insights into real-world scenarios. Hereâ€™s a detailed look at the areas covered:\n>\n> - **Automated Deployment:** Learn how to automate the deployment process to ensure that your applications are deployed quickly and reliably.\n> - **Continuous Integration & Continuous Deployment (CI/CD):** Understand how to set up and manage CI/CD pipelines to automate the testing and deployment of your code.\n> - **Infrastructure as Code (IaC):** Use tools like Terraform and CloudFormation to manage your infrastructure through code, ensuring consistency and scalability.\n> - **Monitoring & Logging:** Implement monitoring and logging solutions to keep track of your applicationsâ€™ performance and troubleshoot issues.\n> - **Security & Compliance:** Learn how to incorporate security practices into your DevOps workflows to ensure that your applications are secure and compliant with regulations.\n> - **Scalability & Performance Optimization:** Understand how to scale your applications and optimize their performance to handle increasing loads.\n\n![Project Scope](https://img.shields.io/badge/ğŸ› ï¸%20Project%20Scope-Hands--on%20DevOps%20Coverage-blue?style=for-the-badge&logo=vercel&logoColor=white)\n\n---\n\n## **Why Explore This Repository?**\n\n> [!NOTE]\n> This repository is a treasure trove of learning opportunities, tailored to help you grow in the DevOps field. Here's why you should dive in:\n>\n> - **Hands-on Experience:** Each project is designed to provide you with practical, hands-on experience. You'll work through real-world challenges and gain the skills you need to succeed in the industry.\n> - **Skill Enhancement:** Whether you're just starting or looking to build on existing skills, the projects are structured to guide you through a learning path that will enhance your capabilities.\n> - **Industry Relevance:** Stay up-to-date with the latest trends and technologies in DevOps. The projects reflect current industry practices, ensuring that what you learn is relevant and applicable.\n> - **Community Engagement:** Join a community of like-minded learners and professionals. Share your projects, seek feedback, and collaborate on exciting DevOps initiatives.\n\n![Why Explore This Repository](https://img.shields.io/badge/ğŸ“š%20Why%20Explore%20This%20Repository%3F-Unlock%20DevOps%20Mastery-brightgreen?style=for-the-badge&logo=bookstack&logoColor=white)\n\n---\n\n## **Code of Conduct**\n\n> [!CAUTION]\n>\n> We are committed to fostering a welcoming and respectful environment for all contributors. Please take a moment to review our [Code of Conduct](./CODE_OF_CONDUCT.md) before participating in this community.\n\n[![Code of Conduct](https://img.shields.io/badge/Code%20of%20Conduct-Enforced-blueviolet?style=for-the-badge&logo=handshake&logoColor=white)](https://github.com/NotHarshhaa/DevOps-Projects/blob/master/CODE_OF_CONDUCT.md)\n\n---\n\n## **Contribute and Collaborate**\n\n> [!TIP]\n> This repository thrives on community contributions and collaboration. Hereâ€™s how you can get involved:\n>\n> - **Fork the Repository:** Create your own copy of the repository to work on.\n> - **Submit Pull Requests:** Contribute your projects or improvements to existing projects by submitting pull requests.\n> - **Engage with Others:** Participate in discussions, provide feedback on othersâ€™ projects, and collaborate to create better solutions.\n> - **Share Your Knowledge:** If youâ€™ve developed a new project or learned something valuable, share it with the community. Your contributions can help others in their learning journey.\n>\n> **We follow best practices for contribution.**\n\n[![Contributing](https://img.shields.io/badge/Contribute-Guide-ff69b4?style=for-the-badge&logo=gitbook&logoColor=white)](https://github.com/NotHarshhaa/DevOps-Projects/blob/master/CONTRIBUTING.md)\n\n---\n\n## ğŸŒ **Join the Community**\n\n> [!IMPORTANT]\n> Be a part of our active DevOps community:\n\n[![Join Telegram](https://img.shields.io/badge/Join%20Us%20on-Telegram-26A5E4?style=for-the-badge&logo=telegram&logoColor=white)](https://t.me/prodevopsguy) \n[![Follow on GitHub](https://img.shields.io/badge/Follow%20me%20on-GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/NotHarshhaa)\n\n---\n\n## â­ **Hit the Star!**\n\n**If you find this helpful, donâ€™t forget to give this repository a star. Your support matters!** â­\n\n![Star Badge](https://img.shields.io/badge/â­%20Support-Give%20a%20Star%20if%20You%20Like%20It-ffd700?style=for-the-badge&logo=github&logoColor=white)\n\n---\n\n## ğŸ› ï¸ **Author & Community**\n\nThis project is crafted by **[Harshhaa](https://github.com/NotHarshhaa)** ğŸ’¡  \nIâ€™d love to hear your feedback! Feel free to share your thoughts.  \n\n![Author Badge](https://img.shields.io/badge/ğŸ› ï¸%20Author%20&%20Community-Crafted%20with%20Passion%20by%20Harshhaa-8a2be2?style=for-the-badge&logo=github&logoColor=white)\n\n---\n\n## ğŸ“§ **Connect with me:**\n\n[![LinkedIn](https://img.shields.io/badge/LinkedIn-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/harshhaa-vardhan-reddy) [![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/NotHarshhaa) [![Telegram](https://img.shields.io/badge/Telegram-26A5E4?style=for-the-badge&logo=telegram&logoColor=white)](https://t.me/prodevopsguy) [![Dev.to](https://img.shields.io/badge/Dev.to-0A0A0A?style=for-the-badge&logo=dev.to&logoColor=white)](https://dev.to/notharshhaa) [![Hashnode](https://img.shields.io/badge/Hashnode-2962FF?style=for-the-badge&logo=hashnode&logoColor=white)](https://hashnode.com/@prodevopsguy)  \n\n---\n\n## ğŸ“¢ **Stay Connected**\n\n![Follow Me](https://imgur.com/2j7GSPs.png)\n\n![Stay Connected](https://img.shields.io/badge/ğŸ“¢%20Stay%20Connected-Join%20our%20DevOps%20Community-orange?style=for-the-badge&logo=telegram&logoColor=white)\n",
      "stars_today": 45
    },
    {
      "id": 1008713177,
      "name": "qwen-code",
      "full_name": "QwenLM/qwen-code",
      "description": "An open-source AI agent that lives in your terminal.",
      "html_url": "https://github.com/QwenLM/qwen-code",
      "stars": 17410,
      "forks": 1522,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-06-26T01:37:46Z",
      "updated_at": "2026-01-15T23:02:09Z",
      "pushed_at": "2026-01-16T00:14:47Z",
      "open_issues": 454,
      "owner": {
        "login": "QwenLM",
        "avatar_url": "https://avatars.githubusercontent.com/u/141221163?v=4"
      },
      "readme": "<div align=\"center\">\n\n[![npm version](https://img.shields.io/npm/v/@qwen-code/qwen-code.svg)](https://www.npmjs.com/package/@qwen-code/qwen-code)\n[![License](https://img.shields.io/github/license/QwenLM/qwen-code.svg)](./LICENSE)\n[![Node.js Version](https://img.shields.io/badge/node-%3E%3D20.0.0-brightgreen.svg)](https://nodejs.org/)\n[![Downloads](https://img.shields.io/npm/dm/@qwen-code/qwen-code.svg)](https://www.npmjs.com/package/@qwen-code/qwen-code)\n\n**An open-source AI agent that lives in your terminal.**\n\n<a href=\"https://qwenlm.github.io/qwen-code-docs/zh/users/overview\">ä¸­æ–‡</a> |\n<a href=\"https://qwenlm.github.io/qwen-code-docs/de/users/overview\">Deutsch</a> |\n<a href=\"https://qwenlm.github.io/qwen-code-docs/fr/users/overview\">franÃ§ais</a> |\n<a href=\"https://qwenlm.github.io/qwen-code-docs/ja/users/overview\">æ—¥æœ¬èª</a> |\n<a href=\"https://qwenlm.github.io/qwen-code-docs/ru/users/overview\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> |\n<a href=\"https://qwenlm.github.io/qwen-code-docs/pt-BR/users/overview\">PortuguÃªs (Brasil)</a>\n\n</div>\n\nQwen Code is an open-source AI agent for the terminal, optimized for [Qwen3-Coder](https://github.com/QwenLM/Qwen3-Coder). It helps you understand large codebases, automate tedious work, and ship faster.\n\n![](https://gw.alicdn.com/imgextra/i1/O1CN01D2DviS1wwtEtMwIzJ_!!6000000006373-2-tps-1600-900.png)\n\n## Why Qwen Code?\n\n- **OpenAI-compatible, OAuth free tier**: use an OpenAI-compatible API, or sign in with Qwen OAuth to get 2,000 free requests/day.\n- **Open-source, co-evolving**: both the framework and the Qwen3-Coder model are open-sourceâ€”and they ship and evolve together.\n- **Agentic workflow, feature-rich**: rich built-in tools (Skills, SubAgents, Plan Mode) for a full agentic workflow and a Claude Code-like experience.\n- **Terminal-first, IDE-friendly**: built for developers who live in the command line, with optional integration for VS Code, Zed, and JetBrains IDEs.\n\n## Installation\n\n#### Prerequisites\n\n```bash\n# Node.js 20+\ncurl -qL https://www.npmjs.com/install.sh | sh\n```\n\n#### NPM (recommended)\n\n```bash\nnpm install -g @qwen-code/qwen-code@latest\n```\n\n#### Homebrew (macOS, Linux)\n\n```bash\nbrew install qwen-code\n```\n\n## Quick Start\n\n```bash\n# Start Qwen Code (interactive)\nqwen\n\n# Then, in the session:\n/help\n/auth\n```\n\nOn first use, you'll be prompted to sign in. You can run `/auth` anytime to switch authentication methods.\n\nExample prompts:\n\n```text\nWhat does this project do?\nExplain the codebase structure.\nHelp me refactor this function.\nGenerate unit tests for this module.\n```\n\n<details>\n<summary>Click to watch a demo video</summary>\n\n<video src=\"https://cloud.video.taobao.com/vod/HLfyppnCHplRV9Qhz2xSqeazHeRzYtG-EYJnHAqtzkQ.mp4\" controls>\nYour browser does not support the video tag.\n</video>\n\n</details>\n\n## Authentication\n\nQwen Code supports two authentication methods:\n\n- **Qwen OAuth (recommended & free)**: sign in with your `qwen.ai` account in a browser.\n- **OpenAI-compatible API**: use `OPENAI_API_KEY` (and optionally a custom base URL / model).\n\n#### Qwen OAuth (recommended)\n\nStart `qwen`, then run:\n\n```bash\n/auth\n```\n\nChoose **Qwen OAuth** and complete the browser flow. Your credentials are cached locally so you usually won't need to log in again.\n\n#### OpenAI-compatible API (API key)\n\nEnvironment variables (recommended for CI / headless environments):\n\n```bash\nexport OPENAI_API_KEY=\"your-api-key-here\"\nexport OPENAI_BASE_URL=\"https://api.openai.com/v1\"  # optional\nexport OPENAI_MODEL=\"gpt-4o\"                        # optional\n```\n\nFor details (including `.qwen/.env` loading and security notes), see the [authentication guide](https://qwenlm.github.io/qwen-code-docs/en/users/configuration/auth/).\n\n## Usage\n\nAs an open-source terminal agent, you can use Qwen Code in four primary ways:\n\n1. Interactive mode (terminal UI)\n2. Headless mode (scripts, CI)\n3. IDE integration (VS Code, Zed)\n4. TypeScript SDK\n\n#### Interactive mode\n\n```bash\ncd your-project/\nqwen\n```\n\nRun `qwen` in your project folder to launch the interactive terminal UI. Use `@` to reference local files (for example `@src/main.ts`).\n\n#### Headless mode\n\n```bash\ncd your-project/\nqwen -p \"your question\"\n```\n\nUse `-p` to run Qwen Code without the interactive UIâ€”ideal for scripts, automation, and CI/CD. Learn more: [Headless mode](https://qwenlm.github.io/qwen-code-docs/en/users/features/headless).\n\n#### IDE integration\n\nUse Qwen Code inside your editor (VS Code, Zed, and JetBrains IDEs):\n\n- [Use in VS Code](https://qwenlm.github.io/qwen-code-docs/en/users/integration-vscode/)\n- [Use in Zed](https://qwenlm.github.io/qwen-code-docs/en/users/integration-zed/)\n- [Use in JetBrains IDEs](https://qwenlm.github.io/qwen-code-docs/en/users/integration-jetbrains/)\n\n#### TypeScript SDK\n\nBuild on top of Qwen Code with the TypeScript SDK:\n\n- [Use the Qwen Code SDK](./packages/sdk-typescript/README.md)\n\n## Commands & Shortcuts\n\n### Session Commands\n\n- `/help` - Display available commands\n- `/clear` - Clear conversation history\n- `/compress` - Compress history to save tokens\n- `/stats` - Show current session information\n- `/bug` - Submit a bug report\n- `/exit` or `/quit` - Exit Qwen Code\n\n### Keyboard Shortcuts\n\n- `Ctrl+C` - Cancel current operation\n- `Ctrl+D` - Exit (on empty line)\n- `Up/Down` - Navigate command history\n\n> Learn more about [Commands](https://qwenlm.github.io/qwen-code-docs/en/users/features/commands/)\n>\n> **Tip**: In YOLO mode (`--yolo`), vision switching happens automatically without prompts when images are detected. Learn more about [Approval Mode](https://qwenlm.github.io/qwen-code-docs/en/users/features/approval-mode/)\n\n## Configuration\n\nQwen Code can be configured via `settings.json`, environment variables, and CLI flags.\n\n- **User settings**: `~/.qwen/settings.json`\n- **Project settings**: `.qwen/settings.json`\n\nSee [settings](https://qwenlm.github.io/qwen-code-docs/en/users/configuration/settings/) for available options and precedence.\n\n## Benchmark Results\n\n### Terminal-Bench Performance\n\n| Agent     | Model              | Accuracy |\n| --------- | ------------------ | -------- |\n| Qwen Code | Qwen3-Coder-480A35 | 37.5%    |\n| Qwen Code | Qwen3-Coder-30BA3B | 31.3%    |\n\n## Ecosystem\n\nLooking for a graphical interface?\n\n- [**AionUi**](https://github.com/iOfficeAI/AionUi) A modern GUI for command-line AI tools including Qwen Code\n- [**Gemini CLI Desktop**](https://github.com/Piebald-AI/gemini-cli-desktop) A cross-platform desktop/web/mobile UI for Qwen Code\n\n## Troubleshooting\n\nIf you encounter issues, check the [troubleshooting guide](https://qwenlm.github.io/qwen-code-docs/en/users/support/troubleshooting/).\n\nTo report a bug from within the CLI, run `/bug` and include a short title and repro steps.\n\n## Connect with Us\n\n- Discord: https://discord.gg/ycKBjdNd\n- Dingtalk: https://qr.dingtalk.com/action/joingroup?code=v1,k1,+FX6Gf/ZDlTahTIRi8AEQhIaBlqykA0j+eBKKdhLeAE=&_dt_no_comment=1&origin=1\n\n## Acknowledgments\n\nThis project is based on [Google Gemini CLI](https://github.com/google-gemini/gemini-cli). We acknowledge and appreciate the excellent work of the Gemini CLI team. Our main contribution focuses on parser-level adaptations to better support Qwen-Coder models.\n",
      "stars_today": 42
    },
    {
      "id": 1021287722,
      "name": "myclaude",
      "full_name": "cexll/myclaude",
      "description": "Claude Code and Codex orchestration workflow",
      "html_url": "https://github.com/cexll/myclaude",
      "stars": 1858,
      "forks": 223,
      "language": "Go",
      "topics": [],
      "created_at": "2025-07-17T07:13:47Z",
      "updated_at": "2026-01-16T00:01:03Z",
      "pushed_at": "2026-01-15T07:31:20Z",
      "open_issues": 8,
      "owner": {
        "login": "cexll",
        "avatar_url": "https://avatars.githubusercontent.com/u/26520956?v=4"
      },
      "readme": "[ä¸­æ–‡](README_CN.md) [English](README.md)\n\n# Claude Code Multi-Agent Workflow System\n\n[![Run in Smithery](https://smithery.ai/badge/skills/cexll)](https://smithery.ai/skills?ns=cexll&utm_source=github&utm_medium=badge)\n\n\n[![License: AGPL-3.0](https://img.shields.io/badge/License-AGPL_v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)\n[![Claude Code](https://img.shields.io/badge/Claude-Code-blue)](https://claude.ai/code)\n[![Version](https://img.shields.io/badge/Version-5.2-green)](https://github.com/cexll/myclaude)\n\n> AI-powered development automation with multi-backend execution (Codex/Claude/Gemini)\n\n## Core Concept: Multi-Backend Architecture\n\nThis system leverages a **dual-agent architecture** with pluggable AI backends:\n\n| Role | Agent | Responsibility |\n|------|-------|----------------|\n| **Orchestrator** | Claude Code | Planning, context gathering, verification, user interaction |\n| **Executor** | codeagent-wrapper | Code editing, test execution (Codex/Claude/Gemini backends) |\n\n**Why this separation?**\n- Claude Code excels at understanding context and orchestrating complex workflows\n- Specialized backends (Codex for code, Claude for reasoning, Gemini for prototyping) excel at focused execution\n- Backend selection via `--backend codex|claude|gemini` matches the model to the task\n\n## Quick Start(Please execute in Powershell on Windows)\n\n```bash\ngit clone https://github.com/cexll/myclaude.git\ncd myclaude\npython3 install.py --install-dir ~/.claude\n```\n\n## Workflows Overview\n\n### 0. OmO Multi-Agent Orchestrator (Recommended for Complex Tasks)\n\n**Intelligent multi-agent orchestration that routes tasks to specialized agents based on risk signals.**\n\n```bash\n/omo \"analyze and fix this authentication bug\"\n```\n\n**Agent Hierarchy:**\n| Agent | Role | Backend | Model |\n|-------|------|---------|-------|\n| `oracle` | Technical advisor | Claude | claude-opus-4-5 |\n| `librarian` | External research | Claude | claude-sonnet-4-5 |\n| `explore` | Codebase search | OpenCode | grok-code |\n| `develop` | Code implementation | Codex | gpt-5.2 |\n| `frontend-ui-ux-engineer` | UI/UX specialist | Gemini | gemini-3-pro |\n| `document-writer` | Documentation | Gemini | gemini-3-flash |\n\n**Routing Signals (Not Fixed Pipeline):**\n- Code location unclear â†’ `explore`\n- External library/API â†’ `librarian`\n- Risky/multi-file change â†’ `oracle`\n- Implementation needed â†’ `develop` / `frontend-ui-ux-engineer`\n\n**Common Recipes:**\n- Explain code: `explore`\n- Small fix with known location: `develop` directly\n- Bug fix, location unknown: `explore â†’ develop`\n- Cross-cutting refactor: `explore â†’ oracle â†’ develop`\n- External API integration: `explore + librarian â†’ oracle â†’ develop`\n\n**Best For:** Complex bug investigation, multi-file refactoring, architecture decisions\n\n---\n\n### 1. Dev Workflow (Recommended)\n\n**The primary workflow for most development tasks.**\n\n```bash\n/dev \"implement user authentication with JWT\"\n```\n\n**6-Step Process:**\n1. **Requirements Clarification** - Interactive Q&A to clarify scope\n2. **Codex Deep Analysis** - Codebase exploration and architecture decisions\n3. **Dev Plan Generation** - Structured task breakdown with test requirements\n4. **Parallel Execution** - Codex executes tasks concurrently\n5. **Coverage Validation** - Enforce â‰¥90% test coverage\n6. **Completion Summary** - Report with file changes and coverage stats\n\n**Key Features:**\n- Claude Code orchestrates, Codex executes all code changes\n- Automatic task parallelization for speed\n- Mandatory 90% test coverage gate\n- Rollback on failure\n\n**Best For:** Feature development, refactoring, bug fixes with tests\n\n---\n\n### 2. BMAD Agile Workflow\n\n**Full enterprise agile methodology with 6 specialized agents.**\n\n```bash\n/bmad-pilot \"build e-commerce checkout system\"\n```\n\n**Agents:**\n| Agent | Role |\n|-------|------|\n| Product Owner | Requirements & user stories |\n| Architect | System design & tech decisions |\n| Tech Lead | Sprint planning & task breakdown |\n| Developer | Implementation |\n| Code Reviewer | Quality assurance |\n| QA Engineer | Testing & validation |\n\n**Process:**\n```\nRequirements â†’ Architecture â†’ Sprint Plan â†’ Development â†’ Review â†’ QA\n     â†“              â†“             â†“            â†“          â†“       â†“\n   PRD.md      DESIGN.md     SPRINT.md     Code      REVIEW.md  TEST.md\n```\n\n**Best For:** Large features, team coordination, enterprise projects\n\n---\n\n### 3. Requirements-Driven Workflow\n\n**Lightweight requirements-to-code pipeline.**\n\n```bash\n/requirements-pilot \"implement API rate limiting\"\n```\n\n**Process:**\n1. Requirements generation with quality scoring\n2. Implementation planning\n3. Code generation\n4. Review and testing\n\n**Best For:** Quick prototypes, well-defined features\n\n---\n\n### 4. Development Essentials\n\n**Direct commands for daily coding tasks.**\n\n| Command | Purpose |\n|---------|---------|\n| `/code` | Implement a feature |\n| `/debug` | Debug an issue |\n| `/test` | Write tests |\n| `/review` | Code review |\n| `/optimize` | Performance optimization |\n| `/refactor` | Code refactoring |\n| `/docs` | Documentation |\n\n**Best For:** Quick tasks, no workflow overhead needed\n\n## Enterprise Workflow Features\n\n- **Multi-backend execution:** `codeagent-wrapper --backend codex|claude|gemini` (default `codex`) so you can match the model to the task without changing workflows.\n- **GitHub workflow commands:** `/gh-create-issue \"short need\"` creates structured issues; `/gh-issue-implement 123` pulls issue #123, drives development, and prepares the PR.\n- **Skills + hooks activation:** .claude/hooks run automation (tests, reviews), while `.claude/skills/skill-rules.json` auto-suggests the right skills. Keep hooks enabled in `.claude/settings.json` to activate the enterprise workflow helpers.\n\n---\n\n## Version Requirements\n\n### Codex CLI\n**Minimum version:** Check compatibility with your installation\n\nThe codeagent-wrapper uses these Codex CLI features:\n- `codex e` - Execute commands (shorthand for `codex exec`)\n- `--skip-git-repo-check` - Skip git repository validation\n- `--json` - JSON stream output format\n- `-C <workdir>` - Set working directory\n- `resume <session_id>` - Resume previous sessions\n\n**Verify Codex CLI is installed:**\n```bash\nwhich codex\ncodex --version\n```\n\n### Claude CLI\n**Minimum version:** Check compatibility with your installation\n\nRequired features:\n- `--output-format stream-json` - Streaming JSON output format\n- `--setting-sources` - Control setting sources (prevents infinite recursion)\n- `--dangerously-skip-permissions` - Skip permission prompts (use with caution)\n- `-p` - Prompt input flag\n- `-r <session_id>` - Resume sessions\n\n**Security Note:** The wrapper adds `--dangerously-skip-permissions` for Claude by default. Set `CODEAGENT_SKIP_PERMISSIONS=false` to disable if you need permission prompts.\n\n**Verify Claude CLI is installed:**\n```bash\nwhich claude\nclaude --version\n```\n\n### Gemini CLI\n**Minimum version:** Check compatibility with your installation\n\nRequired features:\n- `-o stream-json` - JSON stream output format\n- `-y` - Auto-approve prompts (non-interactive mode)\n- `-r <session_id>` - Resume sessions\n- `-p` - Prompt input flag\n\n**Verify Gemini CLI is installed:**\n```bash\nwhich gemini\ngemini --version\n```\n\n---\n\n## Installation\n\n### Modular Installation (Recommended)\n\n```bash\n# Install all enabled modules (dev + essentials by default)\npython3 install.py --install-dir ~/.claude\n\n# Install specific module\npython3 install.py --module dev\n\n# List available modules\npython3 install.py --list-modules\n\n# Force overwrite existing files\npython3 install.py --force\n```\n\n### Available Modules\n\n| Module | Default | Description |\n|--------|---------|-------------|\n| `dev` | âœ“ Enabled | Dev workflow + Codex integration |\n| `essentials` | âœ“ Enabled | Core development commands |\n| `bmad` | Disabled | Full BMAD agile workflow |\n| `requirements` | Disabled | Requirements-driven workflow |\n\n### What Gets Installed\n\n```\n~/.claude/\nâ”œâ”€â”€ bin/\nâ”‚   â””â”€â”€ codeagent-wrapper    # Main executable\nâ”œâ”€â”€ CLAUDE.md                # Core instructions and role definition\nâ”œâ”€â”€ commands/                # Slash commands (/dev, /code, etc.)\nâ”œâ”€â”€ agents/                  # Agent definitions\nâ”œâ”€â”€ skills/\nâ”‚   â””â”€â”€ codex/\nâ”‚       â””â”€â”€ SKILL.md         # Codex integration skill\nâ”œâ”€â”€ config.json              # Configuration\nâ””â”€â”€ installed_modules.json   # Installation status\n```\n\n### Customizing Installation Directory\n\nBy default, myclaude installs to `~/.claude`. You can customize this using the `INSTALL_DIR` environment variable:\n\n```bash\n# Install to custom directory\nINSTALL_DIR=/opt/myclaude bash install.sh\n\n# Update your PATH accordingly\nexport PATH=\"/opt/myclaude/bin:$PATH\"\n```\n\n**Directory Structure:**\n- `$INSTALL_DIR/bin/` - codeagent-wrapper binary\n- `$INSTALL_DIR/skills/` - Skill definitions\n- `$INSTALL_DIR/config.json` - Configuration file\n- `$INSTALL_DIR/commands/` - Slash command definitions\n- `$INSTALL_DIR/agents/` - Agent definitions\n\n**Note:** When using a custom installation directory, ensure that `$INSTALL_DIR/bin` is added to your `PATH` environment variable.\n\n### Configuration\n\nEdit `config.json` to customize:\n\n```json\n{\n  \"version\": \"1.0\",\n  \"install_dir\": \"~/.claude\",\n  \"modules\": {\n    \"dev\": {\n      \"enabled\": true,\n      \"operations\": [\n        {\"type\": \"merge_dir\", \"source\": \"dev-workflow\"},\n        {\"type\": \"copy_file\", \"source\": \"memorys/CLAUDE.md\", \"target\": \"CLAUDE.md\"},\n        {\"type\": \"copy_file\", \"source\": \"skills/codex/SKILL.md\", \"target\": \"skills/codex/SKILL.md\"},\n        {\"type\": \"run_command\", \"command\": \"bash install.sh\"}\n      ]\n    }\n  }\n}\n```\n\n**Operation Types:**\n| Type | Description |\n|------|-------------|\n| `merge_dir` | Merge subdirs (commands/, agents/) into install dir |\n| `copy_dir` | Copy entire directory |\n| `copy_file` | Copy single file to target path |\n| `run_command` | Execute shell command |\n\n---\n\n## Codex Integration\n\nThe `codex` skill enables Claude Code to delegate code execution to Codex CLI.\n\n### Usage in Workflows\n\n```bash\n# Codex is invoked via the skill\ncodeagent-wrapper - <<'EOF'\nimplement @src/auth.ts with JWT validation\nEOF\n```\n\n### Parallel Execution\n\n```bash\ncodeagent-wrapper --parallel <<'EOF'\n---TASK---\nid: backend_api\nworkdir: /project/backend\n---CONTENT---\nimplement REST endpoints for /api/users\n\n---TASK---\nid: frontend_ui\nworkdir: /project/frontend\ndependencies: backend_api\n---CONTENT---\ncreate React components consuming the API\nEOF\n```\n\n### Install Codex Wrapper\n\n```bash\n# Automatic (via dev module)\npython3 install.py --module dev\n\n# Manual\nbash install.sh\n```\n\n#### Windows\n\nWindows installs place `codeagent-wrapper.exe` in `%USERPROFILE%\\bin`.\n\n```powershell\n# PowerShell (recommended)\npowershell -ExecutionPolicy Bypass -File install.ps1\n\n# Batch (cmd)\ninstall.bat\n```\n\n**Add to PATH** (if installer doesn't detect it):\n\n```powershell\n# PowerShell - persistent for current user\n[Environment]::SetEnvironmentVariable('PATH', \"$HOME\\bin;\" + [Environment]::GetEnvironmentVariable('PATH','User'), 'User')\n\n# PowerShell - current session only\n$Env:PATH = \"$HOME\\bin;$Env:PATH\"\n```\n\n```batch\nREM cmd.exe - persistent for current user (use PowerShell method above instead)\nREM WARNING: This expands %PATH% which includes system PATH, causing duplication\nREM Note: Using reg add instead of setx to avoid 1024-character truncation limit\nreg add \"HKCU\\Environment\" /v Path /t REG_EXPAND_SZ /d \"%USERPROFILE%\\bin;%PATH%\" /f\n```\n\n---\n\n## Workflow Selection Guide\n\n| Scenario | Recommended Workflow |\n|----------|---------------------|\n| New feature with tests | `/dev` |\n| Quick bug fix | `/debug` or `/code` |\n| Large multi-sprint feature | `/bmad-pilot` |\n| Prototype or POC | `/requirements-pilot` |\n| Code review | `/review` |\n| Performance issue | `/optimize` |\n\n---\n\n## Troubleshooting\n\n### Common Issues\n\n**Codex wrapper not found:**\n```bash\n# Installer auto-adds PATH, check if configured\nif [[ \":$PATH:\" != *\":$HOME/.claude/bin:\"* ]]; then\n    echo \"PATH not configured. Reinstalling...\"\n    bash install.sh\nfi\n\n# Or manually add (idempotent command)\n[[ \":$PATH:\" != *\":$HOME/.claude/bin:\"* ]] && echo 'export PATH=\"$HOME/.claude/bin:$PATH\"' >> ~/.zshrc\n```\n\n**Permission denied:**\n```bash\npython3 install.py --install-dir ~/.claude --force\n```\n\n**Module not loading:**\n```bash\n# Check installation status\ncat ~/.claude/installed_modules.json\n\n# Reinstall specific module\npython3 install.py --module dev --force\n```\n\n### Version Compatibility Issues\n\n**Backend CLI not found:**\n```bash\n# Check if backend CLIs are installed\nwhich codex\nwhich claude\nwhich gemini\n\n# Install missing backends\n# Codex: Follow installation instructions at https://codex.docs\n# Claude: Follow installation instructions at https://claude.ai/docs\n# Gemini: Follow installation instructions at https://ai.google.dev/docs\n```\n\n**Unsupported CLI flags:**\n```bash\n# If you see errors like \"unknown flag\" or \"invalid option\"\n\n# Check backend CLI version\ncodex --version\nclaude --version\ngemini --version\n\n# For Codex: Ensure it supports `e`, `--skip-git-repo-check`, `--json`, `-C`, and `resume`\n# For Claude: Ensure it supports `--output-format stream-json`, `--setting-sources`, `-r`\n# For Gemini: Ensure it supports `-o stream-json`, `-y`, `-r`, `-p`\n\n# Update your backend CLI to the latest version if needed\n```\n\n**JSON parsing errors:**\n```bash\n# If you see \"failed to parse JSON output\" errors\n\n# Verify the backend outputs stream-json format\ncodex e --json \"test task\"  # Should output newline-delimited JSON\nclaude --output-format stream-json -p \"test\"  # Should output stream JSON\n\n# If not, your backend CLI version may be too old or incompatible\n```\n\n**Infinite recursion with Claude backend:**\n```bash\n# The wrapper prevents this with `--setting-sources \"\"` flag\n# If you still see recursion, ensure your Claude CLI supports this flag\n\nclaude --help | grep \"setting-sources\"\n\n# If flag is not supported, upgrade Claude CLI\n```\n\n**Session resume failures:**\n```bash\n# Check if session ID is valid\ncodex history  # List recent sessions\nclaude history\n\n# Ensure backend CLI supports session resumption\ncodex resume <session_id> \"test\"  # Should continue from previous session\nclaude -r <session_id> \"test\"\n\n# If not supported, use new sessions instead of resume mode\n```\n\n---\n\n## FAQ (Frequently Asked Questions)\n\n### Q1: `codeagent-wrapper` execution fails with \"Unknown event format\"\n\n**Problem:**\n```\nUnknown event format: {\"type\":\"turn.started\"}\nUnknown event format: {\"type\":\"assistant\", ...}\n```\n\n**Solution:**\nThis is a logging event format display issue and does not affect actual functionality. It will be fixed in the next version. You can ignore these log outputs.\n\n**Related Issue:** [#96](https://github.com/cexll/myclaude/issues/96)\n\n---\n\n### Q2: Gemini cannot read files ignored by `.gitignore`\n\n**Problem:**\nWhen using `codeagent-wrapper --backend gemini`, files in directories like `.claude/` that are ignored by `.gitignore` cannot be read.\n\n**Solution:**\n- **Option 1:** Remove `.claude/` from your `.gitignore` file\n- **Option 2:** Ensure files that need to be read are not in `.gitignore` list\n\n**Related Issue:** [#75](https://github.com/cexll/myclaude/issues/75)\n\n---\n\n### Q3: `/dev` command parallel execution is very slow\n\n**Problem:**\nUsing `/dev` command for simple features takes too long (over 30 minutes) with no visibility into task progress.\n\n**Solution:**\n1. **Check logs:** Review `C:\\Users\\User\\AppData\\Local\\Temp\\codeagent-wrapper-*.log` to identify bottlenecks\n2. **Adjust backend:**\n   - Try faster models like `gpt-5.1-codex-max`\n   - Running in WSL may be significantly faster\n3. **Workspace:** Use a single repository instead of monorepo with multiple sub-projects\n\n**Related Issue:** [#77](https://github.com/cexll/myclaude/issues/77)\n\n---\n\n### Q4: Codex permission denied with new Go version\n\n**Problem:**\nAfter upgrading to the new Go-based Codex implementation, execution fails with permission denied errors.\n\n**Solution:**\nAdd the following configuration to `~/.codex/config.yaml` (Windows: `c:\\user\\.codex\\config.toml`):\n```yaml\nmodel = \"gpt-5.1-codex-max\"\nmodel_reasoning_effort = \"high\"\nmodel_reasoning_summary = \"detailed\"\napproval_policy = \"never\"\nsandbox_mode = \"workspace-write\"\ndisable_response_storage = true\nnetwork_access = true\n```\n\n**Key settings:**\n- `approval_policy = \"never\"` - Remove approval restrictions\n- `sandbox_mode = \"workspace-write\"` - Allow workspace write access\n- `network_access = true` - Enable network access\n\n**Related Issue:** [#31](https://github.com/cexll/myclaude/issues/31)\n\n---\n\n### Q5: How to disable default bypass/skip-permissions mode\n\n**Background:**\nBy default, codeagent-wrapper enables bypass mode for both Codex and Claude backends:\n- `CODEX_BYPASS_SANDBOX=true` - Bypasses Codex sandbox restrictions\n- `CODEAGENT_SKIP_PERMISSIONS=true` - Skips Claude permission prompts\n\n**To disable (if you need sandbox/permission protection):**\n```bash\nexport CODEX_BYPASS_SANDBOX=false\nexport CODEAGENT_SKIP_PERMISSIONS=false\n```\n\nOr add to your shell profile (`~/.zshrc` or `~/.bashrc`):\n```bash\necho 'export CODEX_BYPASS_SANDBOX=false' >> ~/.zshrc\necho 'export CODEAGENT_SKIP_PERMISSIONS=false' >> ~/.zshrc\n```\n\n**Note:** Disabling bypass mode will require manual approval for certain operations.\n\n---\n\n**Still having issues?** Visit [GitHub Issues](https://github.com/cexll/myclaude/issues) to search or report new issues.\n\n---\n\n## Documentation\n- **[Codeagent-Wrapper Guide](docs/CODEAGENT-WRAPPER.md)** - Multi-backend execution wrapper\n- **[Hooks Documentation](docs/HOOKS.md)** - Custom hooks and automation\n\n### Additional Resources\n- **[Installation Log](install.log)** - Installation history and troubleshooting\n\n---\n\n## License\n\nAGPL-3.0 License - see [LICENSE](LICENSE)\n\n## Support\n\n- **Issues**: [GitHub Issues](https://github.com/cexll/myclaude/issues)\n- **Documentation**: [docs/](docs/)\n\n---\n\n**Claude Code + Codex = Better Development** - Orchestration meets execution.\n",
      "stars_today": 41
    },
    {
      "id": 854337508,
      "name": "spring-ai-alibaba",
      "full_name": "alibaba/spring-ai-alibaba",
      "description": "Agentic AI Framework for Java Developers",
      "html_url": "https://github.com/alibaba/spring-ai-alibaba",
      "stars": 7958,
      "forks": 1724,
      "language": "Java",
      "topics": [
        "agentic",
        "artificial-intelligence",
        "context-engineering",
        "graph",
        "java",
        "multi-agent",
        "reactagent",
        "spring-ai",
        "workflow"
      ],
      "created_at": "2024-09-09T01:35:50Z",
      "updated_at": "2026-01-16T00:37:55Z",
      "pushed_at": "2026-01-15T13:50:29Z",
      "open_issues": 325,
      "owner": {
        "login": "alibaba",
        "avatar_url": "https://avatars.githubusercontent.com/u/1961952?v=4"
      },
      "readme": "# [Spring AI Alibaba](https://java2ai.com)\n\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![CI Status](https://github.com/alibaba/spring-ai-alibaba/workflows/%F0%9F%9B%A0%EF%B8%8F%20Build%20and%20Test/badge.svg)](https://github.com/alibaba/spring-ai-alibaba/actions?query=workflow%3A%22%F0%9F%9B%A0%EF%B8%8F+Build+and+Test%22)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/alibaba/spring-ai-alibaba)\n[![Maven central](https://img.shields.io/maven-central/v/com.alibaba.cloud.ai/spring-ai-alibaba.svg)](https://img.shields.io/maven-central/v/com.alibaba.cloud.ai/spring-ai-alibaba)\n<img alt=\"gitleaks badge\" src=\"https://img.shields.io/badge/protected%20by-gitleaks-blue\">\n\n<html>\n    <h3 align=\"center\">\n      A production-ready framework for building Agentic, Workflow, and Multi-agent applications.\n    </h3>\n    <h3 align=\"center\">\n      <a href=\"https://java2ai.com/docs/quick-start/\" target=\"_blank\">Agent Framework Docs</a>,\n      <a href=\"https://java2ai.com/docs/frameworks/graph-core/quick-start/\" target=\"_blank\">Graph Docs</a>,\n      <a href=\"https://java2ai.com/ecosystem/spring-ai/reference/concepts/\" target=\"_blank\">Spring AI</a>,\n      <a href=\"https://github.com/alibaba/spring-ai-alibaba/tree/main/examples\" target=\"_blank\">Examples</a>.\n    </h3>\n</html>\n\n## Architecture\n\n<p align=\"center\">\n    <img src=\"./docs/imgs/architecture-new.png\" alt=\"architecture\" style=\"max-width: 740px; height: auto\" />\n</p>\n\n**Spring AI Alibaba Admin** is a one-stop Agent platform that supports visualized Agent development, observability, evaluation, and MCP management, etc. It also integrates with open-source low-code platforms like Dify, enabling rapid migration from DSL to Spring AI Alibaba project.\n\n**Spring AI Alibaba Agent Framework** is an agent development framework that can quickly develop agents with builtin **Context Engineering** and **Human In The Loop** support. For scenarios requiring more complex process control, Agent Framework offers built-in workflows like `SequentialAgent`, `ParallelAgent`, `RoutingAgent`, `LoopAgent` and `SupervisorAgent`.\n\n**Spring AI Alibaba Graph** serves as the underlying runtime of the Agent Framework, providing essential capabilities such as persistence, workflow orchestration, and streaming required for long-running stateful agents. Compared to the Agent Framework, users can build more flexible multi-agent workflows based on the Graph API.\n\n## Core Features\n\n* **[Multi-Agent Orchestration](https://java2ai.com/docs/frameworks/agent-framework/advanced/multi-agent)**: Compose multiple agents with built-in patterns including `SequentialAgent`, `ParallelAgent`, `LlmRoutingAgent`, and `LoopAgent` for complex task execution.\n\n* **[Context Engineering](https://java2ai.com/docs/frameworks/agent-framework/tutorials/hooks)**: Built-in best practices for context engineering policies to improve agent reliability and performance, including human-in-the-loop, context compaction, context editing, model & tool call limit, tool retry, planning, dynamic tool selection.\n\n* **[Graph-based Workflow](https://java2ai.com/docs/frameworks/graph-core/quick-start)**: Graph based workflow runtime and api for conditional routing, nested graphs, parallel execution, and state management. Export workflows to PlantUML and Mermaid formats.\n\n* **[A2A Support](https://java2ai.com/docs/frameworks/agent-framework/advanced/a2a)**: Agent-to-Agent communication support with Nacos integration, enabling distributed agent coordination and collaboration across services.\n\n* **[Rich Model, Tool and MCP Support](https://java2ai.com/integration/chatmodels/dashScope)**: Leveraging core concepts of Spring AI, supports multiple LLM providers (DashScope, OpenAI, etc.), tool calling, and Model Context Protocol (MCP).\n\n* **[One-stop Agent Platform](https://java2ai.com/ecosystem/admin/quick-start)**: Build agent in a visualized way, deploy agent without code or export as a standalone java project.\n\n<p align=\"center\">\n    <img src=\"./docs/imgs/saa-admin.png\" alt=\"architecture\" style=\"max-width: 740px; height: auto\" />\n</p>\n\n## Getting Started\n\n### Prerequisites\n\n* Requires JDK 17+.\n* Choose your LLM provider and get the API-KEY.\n\n### Quickly Run a ChatBot\n\nThere's a ChatBot example provided by the community at [examples/chatbot](https://github.com/alibaba/spring-ai-alibaba/tree/main/examples/chatbot).\n\n1. Download the code.\n\n\t```shell\n\tgit clone --depth=1 https://github.com/alibaba/spring-ai-alibaba.git\n\tcd spring-ai-alibaba/examples/chatbot\n\t```\n\n2. Start the ChatBot.\n\n\tBefore starting, set API-KEY first (visit <a href=\"https://bailian.console.aliyun.com/?apiKey=1&tab=api#/api\" target=\"_blank\">Aliyun Bailian</a> to get API-KEY):\n\t```shell\n\t# this example uses 'spring-ai-alibaba-starter-dashscope', visit https://java2ai.com to learn how to use OpenAI/DeepSeek.\n\texport AI_DASHSCOPE_API_KEY=your-api-key\n\t```\n\t\n\t```shell\n\tmvn spring-boot:run\n\t```\n\n3. Chat with ChatBot.\n\n\tOpen the browser and visit [http://localhost:8080/chatui/index.html](http://localhost:8080/chatui/index.html) to chat with the ChatBot.\n\t\n<p align=\"center\">\n\t<img src=\"./docs/imgs/chatbot-chat-ui.gif\" alt=\"chatbot-ui\" style=\"max-width: 740px; height: auto\" />\n</p>\n\n## Chatbot Code Explained\n\n1. Add dependencies\n\n\t```xml\n\t<dependencies>\n\t  <dependency>\n\t    <groupId>com.alibaba.cloud.ai</groupId>\n\t    <artifactId>spring-ai-alibaba-agent-framework</artifactId>\n\t    <version>1.1.0.0</version>\n\t  </dependency>\n\t  <!-- Assume you are going to use DashScope Model. Refer to docs for how to choose model.-->\n\t  <dependency>\n\t    <groupId>com.alibaba.cloud.ai</groupId>\n\t    <artifactId>spring-ai-alibaba-starter-dashscope</artifactId>\n\t    <version>1.1.0.0</version>\n\t  </dependency>\n\t</dependencies>\n\t```\n\n2. Define Chatbot\n   \n\tFor more details of how to write a Chatbot, please check the [Quick Start](https://java2ai.com/docs/quick-start) on our official website.\n\n## ğŸ“š Documentation\n* [Overview](https://java2ai.com/docs/overview) - High level overview of the framework\n* [Quick Start](https://java2ai.com/docs/quick-start) - Get started with a simple agent\n* [Agent Framework Tutorials](https://java2ai.com/docs/frameworks/agent-framework/tutorials/agents) - Step by step tutorials\n* [Use Graph API to Build Complex Workflows](https://java2ai.com/docs/frameworks/agent-framework/advanced/context-engineering) - In-depth user guide for building multi-agent and workflows\n* [Spring AI Basics](https://java2ai.com/ecosystem/spring-ai/reference/concepts) - Ai Application basic concepts, including ChatModel, MCP, Tool, Messages, etc.\n\n## Project Structure\n\nThis project consists of several core components:\n\n* spring-ai-alibaba-agent-framework: A multi-agent framework designed for building intelligent agents with built-in context engineering best practices.\n* spring-ai-alibaba-graph: The underlying runtime for Agent Framework. We recommend developers to use Agent Framework but it's totally fine to use the Graph API directly.\n* spring-ai-alibaba-admin: A one-stop Agent platform that supports visualized Agent development, observability, evaluation, and MCP management, etc.\n* spring-ai-alibaba-studio: The embedded ui for quickly debugging agent in a visualized way.\n* spring-boot-starters: Starters integrating Agent Framework with Nacos to provide A2A and dynamic config features.\n\n## Spring AI Alibaba Ecosystem\n Repository | Description | â­\n  --- | --- | ---\n| [Spring AI Alibaba Graph](https://github.com/alibaba/spring-ai-alibaba/tree/main/spring-ai-alibaba-graph-core) | A low-level orchestration framework and runtime for building, managing, and deploying long-running, stateful agents. | ![GitHub Repo stars](https://img.shields.io/github/stars/alibaba/spring-ai-alibaba?style=for-the-badge&label=)\n| [Spring AI Alibaba Admin](https://github.com/spring-ai-alibaba/spring-ai-alibaba-admin) |  Local visualization toolkit for the development of agent applications, supporting project management, runtime visualization, tracing, and agent evaluation. | ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/spring-ai-alibaba-admin?style=for-the-badge&label=)\n| [Spring AI Extensions](https://github.com/spring-ai-alibaba/spring-ai-extensions) | Extended implementations for Spring AI core concepts, including DashScopeChatModel, MCP registry, etc. |  ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/spring-ai-extensions?style=for-the-badge&label=)\n| [Spring AI Alibaba Examples](https://github.com/spring-ai-alibaba/examples) | Spring AI Alibaba Examples. |  ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/examples?style=for-the-badge&label=)\n| [JManus](https://github.com/spring-ai-alibaba/jmanus) | A Java implementation of Manus built with Spring AI Alibaba, currently used in many applications within Alibaba Group. | ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/jmanus?style=for-the-badge&label=)\n| [DataAgent](https://github.com/spring-ai-alibaba/dataagent) | A natural language to SQL project based on Spring AI Alibaba, enabling you to query databases directly with natural language without writing complex SQL. | ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/dataagent?style=for-the-badge&label=)\n| [DeepResearch](https://github.com/spring-ai-alibaba/deepresearch) |  Deep Research implemented based on spring-ai-alibaba-graph. | ![GitHub Repo stars](https://img.shields.io/github/stars/spring-ai-alibaba/deepresearch?style=for-the-badge&label=)\n\n## Contact Us\n\n* Dingtalk Group (é’‰é’‰ç¾¤), search `130240015687` and join.\n* WeChat Group (å¾®ä¿¡å…¬ä¼—å·), scan the QR code below and follow us.\n\n<img src=\"./docs/imgs/wechat-account.jpg\" style=\"width: 260px; height: auto\"/>\n\n## Resources\n* [AI-Native Application Architecture White Paper](https://developer.aliyun.com/ebook/8479)ï¼šCo-authored by 40 frontline engineers and endorsed by 15 industry experts, this 200,000+ word white paper is the first comprehensive guide dedicated to the full DevOps lifecycle of AI-native applications. It systematically breaks down core concepts and key challenges, offering practical problem-solving approaches and architectural insights.\n\n\n## Star History\n\n[![Star History Chart](https://starchart.cc/alibaba/spring-ai-alibaba.svg?variant=adaptive)](https://starchart.cc/alibaba/spring-ai-alibaba)\n\n---\n\n<p align=\"center\">\n    Made with â¤ï¸ by the Spring AI Alibaba Team\n\n",
      "stars_today": 37
    },
    {
      "id": 274495425,
      "name": "remotion",
      "full_name": "remotion-dev/remotion",
      "description": "ğŸ¥      Make videos programmatically with React",
      "html_url": "https://github.com/remotion-dev/remotion",
      "stars": 25325,
      "forks": 1443,
      "language": "TypeScript",
      "topics": [
        "javascript",
        "react",
        "video"
      ],
      "created_at": "2020-06-23T19:49:10Z",
      "updated_at": "2026-01-16T00:07:49Z",
      "pushed_at": "2026-01-15T20:37:33Z",
      "open_issues": 89,
      "owner": {
        "login": "remotion-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/85344006?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://github.com/remotion-dev/logo\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-dark.apng\">\n      <img alt=\"Animated Remotion Logo\" src=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-light.gif\">\n    </picture>\n  </a>\n</p>\n\n[![Discord Shield](https://img.shields.io/discord/809501355504959528?color=000000&label=Discord&logo=fdgssdf)](https://remotion.dev/discord)\n[![NPM Version](https://img.shields.io/npm/v/remotion.svg?style=flat&color=black)](https://www.npmjs.org/package/remotion)\n[![NPM Downloads](https://img.shields.io/npm/dm/remotion.svg?style=flat&color=black&label=Downloads)](https://npmcharts.com/compare/remotion?minimal=true)\n[![Open Bounties](https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2Fremotion%2Fbounties%3Fstatus%3Dopen&style=flat&color=black&labelColor=grey&label=Open+Bounties)](https://github.com/remotion-dev/remotion/issues?q=is%3Aopen+label%3A%22%F0%9F%92%8E+Bounty%22+sort%3Aupdated-desc)\n<a href=\"https://twitter.com/remotion\"><img src=\"https://img.shields.io/twitter/follow/remotion?label=Twitter&color=black\" alt=\"Twitter\"></a>\n\nRemotion is a framework for **creating videos programmatically using React.**\n\n## Why create videos in React?\n\n- **Leverage web technologies**: Use all of CSS, Canvas, SVG, WebGL, etc.\n- **Leverage programming**: Use variables, functions, APIs, math and algorithms to create new effects\n- **Leverage React**: Reusable components, Powerful composition, Fast Refresh, Package ecosystem\n\n## Created with Remotion\n\n<table>\n<tr>\n<td align=\"center\">\n<img style=\"width: 290px\" src=\"https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/fireship-quick.gif\" />\n<p>\"This video was made with code\" <em>- Fireship</em> <a href=\"https://youtu.be/deg8bOoziaE\">Watch</a> â€¢ <a href=\"https://github.com/wcandillon/remotion-fireship\">Source</a></p>\n</td>\n<td align=\"center\">\n<img style=\"width: 240px\" src=\"https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/unwrapped-2023.gif\" />\n<p>GitHub Unwrapped - Personalized Year in Review <a href=\"https://www.githubunwrapped.com\">Try</a> â€¢ <a href=\"https://github.com/remotion-dev/github-unwrapped\">Source</a></p>\n</td>\n<td align=\"center\">\n<em>View more in the <a href=\"https://remotion.dev/showcase\">Remotion Showcase</a>!</em>\n</td>\n</tr>\n</table>\n\n## Get started\n\nIf you already have Node.JS installed, type\n\n```console\nnpx create-video@latest\n```\n\nto get started. Otherwise, read the [installation page](https://www.remotion.dev/docs/) in the documentation.\n\n## Documentation\n\nDocumentation: [**remotion.dev/docs**](https://www.remotion.dev/docs)  \nAPI Reference: [**remotion.dev/api**](https://www.remotion.dev/api)\n\n## License\n\nBe aware of that Remotion has a special license and requires obtaining a company license in some cases. Read the [LICENSE](LICENSE.md) page for more information.\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) to learn about contributing to this project.\n",
      "stars_today": 35
    },
    {
      "id": 464415161,
      "name": "lago",
      "full_name": "getlago/lago",
      "description": "Open Source Metering and Usage Based Billing API â­ï¸ Consumption tracking, Subscription management, Pricing iterations, Payment orchestration & Revenue analytics",
      "html_url": "https://github.com/getlago/lago",
      "stars": 9091,
      "forks": 515,
      "language": "Go",
      "topics": [
        "analytics",
        "billing",
        "clickhouse",
        "events",
        "fintech",
        "go",
        "ingestion",
        "invoices",
        "metering",
        "open-source",
        "payments",
        "pricing",
        "pricing-data-science",
        "react",
        "ruby",
        "self-hosted",
        "subscriptions",
        "usage-based-billing"
      ],
      "created_at": "2022-02-28T09:22:45Z",
      "updated_at": "2026-01-16T00:46:46Z",
      "pushed_at": "2026-01-15T13:22:44Z",
      "open_issues": 25,
      "owner": {
        "login": "getlago",
        "avatar_url": "https://avatars.githubusercontent.com/u/75492405?v=4"
      },
      "readme": "<!-- PROJECT LOGO -->\n<p align=\"center\">\n  <a href=\"https://github.com/getlago/lago\">\n    <img src=\"https://uploads-ssl.webflow.com/635119506e36baf5c267fecd/635b6df0ee8effaa54c1fa42_banner-open-graph.jpg\" alt=\"Lago\">\n  </a>\n\n  <h1 align=\"center\">Lago</h2>\n\n  <p align=\"center\">\n    Open Source Metering & Usage-Based Billing\n    <br />\n    <br />\n    The best alternative to Chargebee, Recurly or Stripe Billing.\n    <br />\n    For usage-based, subscription-based, and all the nuances of pricing in between.\n    <br />\n    <br />\n    <a href=\"https://www.getlago.com/slack\">Slack</a>\n    Â·\n    <a href=\"https://getlago.com\">Website</a>\n    Â·\n    <a href=\"https://github.com/getlago/lago/issues\">Issues</a>\n    Â·\n    <a href=\"https://getlago.canny.io/\">Roadmap</a>\n  </p>\n</p>\n<p align=\"center\">\n    <a href=\"https://www.producthunt.com/posts/lago?utm_source=badge-top-post-badge&utm_medium=badge&utm_souce=badge-lago\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=386328&theme=light&period=monthly\" alt=\"Lago - Open&#0045;source&#0032;alternative&#0032;to&#0032;Stripe&#0032;Billing&#0032;and&#0032;Chargebee | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" />\n    </a>\n</p>\n<p align=\"center\">\n    <a href=\"https://www.producthunt.com/posts/lago?utm_source=badge-top-post-topic-badge&utm_medium=badge&utm_souce=badge-lago\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=386328&theme=light&period=monthly&topic_id=267\" alt=\"Lago - Open&#0045;source&#0032;alternative&#0032;to&#0032;Stripe&#0032;Billing&#0032;and&#0032;Chargebee | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n</p>\n\n<p align=\"center\">\n   <a href=\"https://www.getlago.com/slack\"><img src=\"https://img.shields.io/badge/Lago%20Slack%20Community-lago.slack.com-%234A154B\" alt=\"Join Lago on Slack\"></a>\n   <a href=\"https://github.com/getlago/lago/stargazers\"><img src=\"https://img.shields.io/github/stars/getlago/lago\" alt=\"Github Stars\"></a>\n   <a href=\"https://news.ycombinator.com/item?id=31424450\"><img src=\"https://img.shields.io/badge/Hacker%20News-777-%23FF6600\" alt=\"Hacker News\"></a>\n   <a href=\"https://github.com/getlago/lago/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/license-AGPLv3-purple\" alt=\"License\"></a>\n   <a href=\"https://twitter.com/getlago\"><img src=\"https://img.shields.io/twitter/follow/getlago?style=flat\"></a>\n   <a href=\"https://www.ycombinator.com\"><img src=\"https://img.shields.io/badge/Backed%20by-Y%20Combinator-%23f26625\"></a>\n</p>\n\n<!-- ABOUT THE PROJECT -->\n## The programmable API for usage-based billing\n[![Lago Billing System Presentation](https://img.youtube.com/vi/dXnoMRetsr4/0.jpg)](https://www.youtube.com/watch?v=dXnoMRetsr4)\n\n### The problem: Billing systems are still a nightmare for engineers\n![Billing nightmare](https://uploads-ssl.webflow.com/6244531a40ad7ef5475ad9b3/62827b2f6fa52239b0db0fa4_Blog%20Post%20Image%20Standalone.png)\nEngineers be likeâ€¦\n\nRead more first-hand experiences from Qonto, Algolia, Pleo, Segment, or the 350+. Hackernews comments [here](https://news.ycombinator.com/item?id=31424450).\n\n**The Solution:** Lago, the open-source billing API for product-led SaaS\n- Event-based: if you can track it, you can charge for it;\n- Built for product-led growth companies;\n- Hybrid pricing: subscription and usage;\n- Hybrid go-to-market motion: self-serve and sales-led.\n\n**Open-source, open architecture:**\n- Composable: connect Lago to any of your internal systems or tools (i.e. any payment gateway, CRM, CPQ, accounting software);\n- Pricing: weâ€™re not rent seekers, weâ€™re not asking for a % of your revenue. Our self-hosted version is free. Our cloud version is priced like a SaaS;\n- Privacy: your data never has to leave your infrastructure.\n\n## âœ¨ Features\n- **[Usage metering](https://www.getlago.com/products/metering)**: Lago's event-based architecture provides a solid foundation for building a fair pricing model that scales with your business.\n- **[Price plans](https://www.getlago.com/products/plans)**: Lago supports all pricing models. Create pay-as-you-go and hybrid plans in no time with our intuitive user interface or API.\n- **[Coupons](https://www.getlago.com/products/coupons)**: Create engaging marketing campaigns and increase conversion with coupons that customers can redeem to get a discount.\n- **[Add-ons](https://www.getlago.com/products/add-on)**: Why wait until the end of the billing cycle to get paid? Lago allows you to create one-time charges that are invoiced on the fly.\n- **[Invoicing](https://www.getlago.com/products/invoicing)**: Depending on the configuration of your plans, Lago automatically calculates what each customer owes you and generates invoices.\n- **[Prepaid credits](https://www.getlago.com/products/prepaid-credits)**: Unlock recurring revenue opportunities for pay-as-you-go pricing models with Lago's prepaid credit features.\n\n## ğŸ“š Documentation\n- **[Development Environment](./docs/dev_environment.md)**: Learn how to set up and run Lago locally for development\n- **[Architecture](./docs/architecture.md)**: Understand Lago's technical architecture and flows\n\n## ğŸ”” Stay up to date\nLago launched its v0.1 on June 2nd, 2022. Lots of new features are coming, and are generally released on a bi-weekly basis. Watch updates of this repository to be notified of future updates.\n\n[Check out our public roadmap](https://getlago.canny.io/)\n\n## ğŸ”– License\nDistributed under the AGPLv3 License. Read more [here](https://www.getlago.com/blog/open-source-licensing-and-why-lago-chose-agplv3).\n\n## Current Releases\n\n| Project            | Release Badge                                                                                       |\n|--------------------|-----------------------------------------------------------------------------------------------------|\n| **Lago**           | [![Lago Release](https://img.shields.io/github/v/release/getlago/lago)](https://github.com/getlago/lago/releases) |\n| **Lago API**     | [![Lago API Release](https://img.shields.io/github/v/release/getlago/lago-api)](https://github.com/getlago/lago-api/releases) |\n| **Lago front**     | [![Lago front Testing Release](https://img.shields.io/github/v/release/getlago/lago-front)](https://github.com/getlago/lago-front/releases) |\n| **Lago Go Client**     | [![Lago Go Client Testing Release](https://img.shields.io/github/v/release/getlago/lago-go-client)](https://github.com/getlago/lago-go-client/releases) |\n| **lago-gotenberg**     | [![lago-gotenberg Release](https://img.shields.io/github/v/release/getlago/lago-gotenberg)](https://github.com/getlago/lago-gotenberg/releases) |\n| **Lago JavaScript Client**     | [![Lago JavaScript Client Release](https://img.shields.io/github/v/release/getlago/lago-javascript-client)](https://github.com/getlago/lago-javascript-client/releases) |\n| **Lago OpenAPI**     | [![Lago OpenAPI Release](https://img.shields.io/github/v/release/getlago/lago-openapi)](https://github.com/getlago/lago-openapi/releases) |\n| **Lago Python Client**     | [![Lago Python Client Release](https://img.shields.io/github/v/release/getlago/lago-python-client)](https://github.com/getlago/lago-python-client/releases) |\n| **Lago Ruby Client**     | [![Lago Ruby Client Release](https://img.shields.io/github/v/release/getlago/lago-ruby-client)](https://github.com/getlago/lago-ruby-client/releases) |\n\n\n## ğŸ’» Deploy locally\n\n### Requirements\n1. Install Docker on your machine;\n2. Make sure Docker Compose is installed and available (it should be the case if you have chosen to install Docker via Docker Desktop); and\n3. Make sure Git is installed on your machine.\n\n### Run the app\nTo start using Lago, run the following commands in a shell:\n\n\n#### On a fresh install\n```bash\n# Get the code\ngit clone --depth 1 https://github.com/getlago/lago.git\n\n# Go to Lago folder\ncd lago\n\n# Set up environment configuration\necho \"LAGO_RSA_PRIVATE_KEY=\\\"`openssl genrsa 2048 | openssl base64 -A`\\\"\" >> .env\nsource .env\n\n# Start all the components\ndocker compose up\n```\n\n#### After an update\n\n```bash\ndocker compose up\n```\n\nYou can now open your browser and go to http://localhost to connect to the application. Lago's API is exposed at http://localhost:3000.\n\nNote that if our docker server is not at http://localhost, the following env variables must be set: `LAGO_API_URL`. This may be on the command line or in your .env file. For example:\n\n```\nLAGO_API_URL=\"http://192.168.122.71:3000\"\nLAGO_FRONT_URL=\"http://192.168.122.71\"\n```\n\n### Find your API key\nYour API Key can be found directly in the UI:\n\n1. Access the **Developer** section from the sidebar;\n2. The first tab of this section is related to your **API keys**; and\n3. Click the **Copy** button to copy it to clipboard.\n\n### Analytics and tracking\nPlease note that Lago, by default, tracks basic actions performed on your self-hosted instance. If you do not disable tracking, you may receive specific communications or product updates. However, rest assured that Lago will not collect any personal information about your customers or financial information about your invoices.\n\nIf you would like to know more about Lago's analytics or remove the entire tracking, please refer to [this page](https://doc.getlago.com/guide/self-hosted/tracking-analytics) for comprehensive information.\n\n### Version, environment variables and components\nDocker images are always updated to the last stable version in the docker-compose.yml file. You can use a different tag if needed by checking the releases list.\n\nLago uses the following environment variables to configure the components of the application. You can override them to customise your setup. Take a closer look are our [documentation](https://doc.getlago.com/docs/guide/self-hosting/docker#configuration).\n\n## â˜ï¸ Use our cloud-based product\nContact our team at hello@getlago.com to get started with Lago Cloud. More information on [our website](https://www.getlago.com/pricing).\n\n## ğŸš€ Getting the most out of Lago\n- See the [documentation](https://doc.getlago.com) to learn more about all the features;\n- Use our [templates](https://getlago.com/docs/templates/introduction) to get inspiration and learn how to reproduce Algoliaâ€™s, Segmentâ€™s and Klaviyoâ€™s pricing models;\n- Join our [Slack community](https://www.getlago.com/slack) if you need help, or want to chat, weâ€™re here to help;\n- Contribute on GitHub: read our [guidelines](https://github.com/getlago/lago/blob/main/CONTRIBUTING.md);\n- Follow us on [Twitter](https://twitter.com/GetLago) for the latest news;\n- You can email us as well: hello@getlago.com.\n\n## ğŸ§‘â€ğŸ’» Contributions and development environment\n\nYou can follow this [guide](./docs/dev_environment.md) to set up a Lago development environment on your machine. This guide is intended for people willing to contribute to Lago. If you want to try Lago on your local system, we recommend that you take a look at Lago's public documentation.\n\nYou can contribute by following our [guidelines](https://github.com/getlago/lago/blob/main/CONTRIBUTING.md).\n\n## ğŸ’¡ Philosophy\nB2B SaaS has evolved, but billing has not yet.\n\n### 1- Weâ€™re not in the â€œsubscription economyâ€ anymore. And we wonâ€™t go â€œfull usage-based pricingâ€ quite yet\nPricings are now mostly hybrid: they include a usage-based component (i.e. â€œif you use more you pay moreâ€) and a subscription component (i.e. a recurring fee for basic usage).\n\nNot all software companies will go full â€œusage-basedâ€ like Snowflake for instance. This model is the new standard for cloud infrastructure products. However, in other areas of SaaS, users want to know beforehand how much they will pay to control their spending and software companies want to be able to predict recurring revenues.\n\n### 2- Go-to-market is not either bottom-up or top-down anymore\nSaaS used to be either self-service (SMBs) or sales-led (Enterprises).\nGo-to-market now mixes the self-service (all customers access the same price plans) and sales-led (customers get a custom quote from a sales representative) motions.\nA typical journey involves an individual contributor in a company who tests a new tool, puts their corporate credit card in, and starts spreading the use of the tool within the organization. At that point, the VP or head of department might want to upgrade to a custom plan tailored to the needs of the whole organization.\nAs a result, billing needs to be flexible, automated, and transparent enough to embrace this hybrid go-to-market motion as well.\n\n### 3- The â€œrent seekerâ€ pricing of current billing solutions needs to stop\nWhy do payment companies take a cut on revenues?\nBecause the higher the amount, the higher the risk for them (e.g. fraud, disputes, etc.).\n\nWhy did billing companies adopt the same pricing structure? Weâ€™re not able to provide an answer that makes sense. Itâ€™s been said on the internet that they did this because they could (read more [here](https://news.ycombinator.com/item?id=16766846)).\n\n### One last thingâ€¦\nLago is agnostic and we aim at being as transparent as possible, so we wonâ€™t nudge or lock you into using a specific tool in exchange for using our billing API ([learn more](https://www.gmass.co/blog/negotiating-stripe-fees/)).\n",
      "stars_today": 34
    },
    {
      "id": 1016267036,
      "name": "bitchat-android",
      "full_name": "permissionlesstech/bitchat-android",
      "description": "bluetooth mesh chat, IRC vibes",
      "html_url": "https://github.com/permissionlesstech/bitchat-android",
      "stars": 4376,
      "forks": 616,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2025-07-08T18:36:23Z",
      "updated_at": "2026-01-15T22:57:45Z",
      "pushed_at": "2026-01-15T21:14:25Z",
      "open_issues": 215,
      "owner": {
        "login": "permissionlesstech",
        "avatar_url": "https://avatars.githubusercontent.com/u/220183803?v=4"
      },
      "readme": "<p align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/188c42f8-d249-4a72-b27a-e2b4f10a00a8\" alt=\"Bitchat Android Logo\" width=\"480\">\n</p>\n\n> [!WARNING]\n> This software has not received external security review and may contain vulnerabilities and may not necessarily meet its stated security goals. Do not use it for sensitive use cases, and do not rely on its security until it has been reviewed. Work in progress.\n\n# bitchat for Android\n\nA secure, decentralized, peer-to-peer messaging app that works over Bluetooth mesh networks. No internet required for mesh chats, no servers, no phone numbers - just pure encrypted communication. Bitchat also supports geohash channels, which use an internet connection to connect you with others in your geographic area.\n\nThis is the **Android port** of the original [bitchat iOS app](https://github.com/jackjackbits/bitchat), maintaining 100% protocol compatibility for cross-platform communication.\n\n## Install bitchat\n\nYou can download the latest version of bitchat for Android from the [GitHub Releases page](https://github.com/permissionlesstech/bitchat-android/releases).\n\nOr you can:\n\n[<img alt=\"Get it on Google Play\" height=\"60\" src=\"https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png\"/>](https://play.google.com/store/apps/details?id=com.bitchat.droid)\n\n**Instructions:**\n\n1.  **Download the APK:** On your Android device, navigate to the link above and download the latest `.apk` file. Open it.\n2.  **Allow Unknown Sources:** On some devices, before you can install the APK, you may need to enable \"Install from unknown sources\" in your device's settings. This is typically found under **Settings > Security** or **Settings > Apps & notifications > Special app access**.\n3.  **Install:** Open the downloaded `.apk` file to begin the installation.\n\n## License\n\nThis project is released into the public domain. See the [LICENSE](LICENSE.md) file for details.\n\n## Features\n\n- **âœ… Cross-Platform Compatible**: Full protocol compatibility with iOS bitchat\n- **âœ… Decentralized Mesh Network**: Automatic peer discovery and multi-hop message relay over Bluetooth LE\n- **âœ… End-to-End Encryption**: X25519 key exchange + AES-256-GCM for private messages\n- **âœ… Channel-Based Chats**: Topic-based group messaging with optional password protection\n- **âœ… Store & Forward**: Messages cached for offline peers and delivered when they reconnect\n- **âœ… Privacy First**: No accounts, no phone numbers, no persistent identifiers\n- **âœ… IRC-Style Commands**: Familiar `/join`, `/msg`, `/who` style interface\n- **âœ… Message Retention**: Optional channel-wide message saving controlled by channel owners\n- **âœ… Emergency Wipe**: Triple-tap logo to instantly clear all data\n- **âœ… Modern Android UI**: Jetpack Compose with Material Design 3\n- **âœ… Dark/Light Themes**: Terminal-inspired aesthetic matching iOS version\n- **âœ… Battery Optimization**: Adaptive scanning and power management\n\n## Android Setup\n\n### Prerequisites\n\n- **Android Studio**: Arctic Fox (2020.3.1) or newer\n- **Android SDK**: API level 26 (Android 8.0) or higher\n- **Kotlin**: 1.8.0 or newer\n- **Gradle**: 7.0 or newer\n\n### Build Instructions\n\n1. **Clone the repository:**\n   ```bash\n   git clone https://github.com/permissionlesstech/bitchat-android.git\n   cd bitchat-android\n   ```\n\n2. **Open in Android Studio:**\n   ```bash\n   # Open Android Studio and select \"Open an Existing Project\"\n   # Navigate to the bitchat-android directory\n   ```\n\n3. **Build the project:**\n   ```bash\n   ./gradlew build\n   ```\n\n4. **Install on device:**\n   ```bash\n   ./gradlew installDebug\n   ```\n\n### Development Build\n\nFor development builds with debugging enabled:\n\n```bash\n./gradlew assembleDebug\nadb install -r app/build/outputs/apk/debug/app-debug.apk\n```\n\n### Release Build\n\nFor production releases:\n\n```bash\n./gradlew assembleRelease\n```\n\n## Android-Specific Requirements\n\n### Permissions\n\nThe app requires the following permissions (automatically requested):\n\n- **Bluetooth**: Core BLE functionality\n- **Location**: Required for BLE scanning on Android\n- **Network**: Expand your mesh through public internet relays\n- **Notifications**: Message alerts and background updates\n\n### Hardware Requirements\n\n- **Bluetooth LE (BLE)**: Required for mesh networking\n- **Android 8.0+**: API level 26 minimum\n- **RAM**: 2GB recommended for optimal performance\n\n## Usage\n\n### Basic Commands\n\n- `/j #channel` - Join or create a channel\n- `/m @name message` - Send a private message\n- `/w` - List online users\n- `/channels` - Show all discovered channels\n- `/block @name` - Block a peer from messaging you\n- `/block` - List all blocked peers\n- `/unblock @name` - Unblock a peer\n- `/clear` - Clear chat messages\n- `/pass [password]` - Set/change channel password (owner only)\n- `/transfer @name` - Transfer channel ownership\n- `/save` - Toggle message retention for channel (owner only)\n\n### Getting Started\n\n1. **Install the app** on your Android device (requires Android 8.0+)\n2. **Grant permissions** for Bluetooth and location when prompted\n3. **Launch bitchat** - it will auto-start mesh networking\n4. **Set your nickname** or use the auto-generated one\n5. **Connect automatically** to nearby iOS and Android bitchat users\n6. **Join a channel** with `/j #general` or start chatting in public\n7. **Messages relay** through the mesh network to reach distant peers\n\n### Android UI Features\n\n- **Jetpack Compose UI**: Modern Material Design 3 interface\n- **Dark/Light Themes**: Terminal-inspired aesthetic matching iOS\n- **Haptic Feedback**: Vibrations for interactions and notifications\n- **Adaptive Layout**: Optimized for various Android screen sizes\n- **Message Status**: Real-time delivery and read receipts\n- **RSSI Indicators**: Signal strength colors for each peer\n\n### Channel Features\n\n- **Password Protection**: Channel owners can set passwords with `/pass`\n- **Message Retention**: Owners can enable mandatory message saving with `/save`\n- **@ Mentions**: Use `@nickname` to mention users (with autocomplete)\n- **Ownership Transfer**: Pass control to trusted users with `/transfer`\n\n## Security & Privacy\n\n### Encryption\n- **Private Messages**: X25519 key exchange + AES-256-GCM encryption\n- **Channel Messages**: Argon2id password derivation + AES-256-GCM\n- **Digital Signatures**: Ed25519 for message authenticity\n- **Forward Secrecy**: New key pairs generated each session\n\n### Privacy Features\n- **No Registration**: No accounts, emails, or phone numbers required\n- **Ephemeral by Default**: Messages exist only in device memory\n- **Cover Traffic**: Random delays and dummy messages prevent traffic analysis\n- **Emergency Wipe**: Triple-tap logo to instantly clear all data\n- **Bundled Tor Support**: Built-in Tor network integration for enhanced privacy when internet connectivity is available\n\n## Performance & Efficiency\n\n### Message Compression\n- **LZ4 Compression**: Automatic compression for messages >100 bytes\n- **30-70% bandwidth savings** on typical text messages\n- **Smart compression**: Skips already-compressed data\n\n### Battery Optimization\n- **Adaptive Power Modes**: Automatically adjusts based on battery level\n  - Performance mode: Full features when charging or >60% battery\n  - Balanced mode: Default operation (30-60% battery)\n  - Power saver: Reduced scanning when <30% battery\n  - Ultra-low power: Emergency mode when <10% battery\n- **Background efficiency**: Automatic power saving when app backgrounded\n- **Configurable scanning**: Duty cycle adapts to battery state\n\n### Network Efficiency\n- **Optimized Bloom filters**: Faster duplicate detection with less memory\n- **Message aggregation**: Batches small messages to reduce transmissions\n- **Adaptive connection limits**: Adjusts peer connections based on power mode\n\n## Technical Architecture\n\n### Binary Protocol\nbitchat uses an efficient binary protocol optimized for Bluetooth LE:\n- Compact packet format with 1-byte type field\n- TTL-based message routing (max 7 hops)\n- Automatic fragmentation for large messages\n- Message deduplication via unique IDs\n\n### Mesh Networking\n- Each device acts as both client and peripheral\n- Automatic peer discovery and connection management\n- Store-and-forward for offline message delivery\n- Adaptive duty cycling for battery optimization\n\n### Android-Specific Optimizations\n- **Coroutine Architecture**: Asynchronous operations for mesh networking\n- **Kotlin Coroutines**: Thread-safe concurrent mesh operations\n- **EncryptedSharedPreferences**: Secure storage for user settings\n- **Lifecycle-Aware**: Proper handling of Android app lifecycle\n- **Battery Optimization**: Foreground service and adaptive scanning\n\n## Android Technical Architecture\n\n### Core Components\n\n1. **BitchatApplication.kt**: Application-level initialization and dependency injection\n2. **MainActivity.kt**: Main activity handling permissions and UI hosting\n3. **ChatViewModel.kt**: MVVM pattern managing app state and business logic\n4. **BluetoothMeshService.kt**: Core BLE mesh networking (central + peripheral roles)\n5. **EncryptionService.kt**: Cryptographic operations using BouncyCastle\n6. **BinaryProtocol.kt**: Binary packet encoding/decoding matching iOS format\n7. **ChatScreen.kt**: Jetpack Compose UI with Material Design 3\n\n### Dependencies\n\n- **Jetpack Compose**: Modern declarative UI\n- **BouncyCastle**: Cryptographic operations (X25519, Ed25519, AES-GCM)\n- **Nordic BLE Library**: Reliable Bluetooth LE operations\n- **Kotlin Coroutines**: Asynchronous programming\n- **LZ4**: Message compression (when enabled)\n- **EncryptedSharedPreferences**: Secure local storage\n\n### Binary Protocol Compatibility\n\nThe Android implementation maintains 100% binary protocol compatibility with iOS:\n- **Header Format**: Identical 13-byte header structure\n- **Packet Types**: Same message types and routing logic\n- **Encryption**: Identical cryptographic algorithms and key exchange\n- **UUIDs**: Same Bluetooth service and characteristic identifiers\n- **Fragmentation**: Compatible message fragmentation for large content\n\n## Publishing to Google Play\n\n### Preparation\n\n1. **Update version information:**\n   ```kotlin\n   // In app/build.gradle.kts\n   defaultConfig {\n       versionCode = 2  // Increment for each release\n       versionName = \"1.1.0\"  // User-visible version\n   }\n   ```\n\n2. **Create a signed release build:**\n   ```bash\n   ./gradlew assembleRelease\n   ```\n\n3. **Generate app bundle (recommended for Play Store):**\n   ```bash\n   ./gradlew bundleRelease\n   ```\n\n### Play Store Requirements\n\n- **Target API**: Latest Android API (currently 34)\n- **Privacy Policy**: Required for apps requesting sensitive permissions\n- **App Permissions**: Justify Bluetooth and location usage\n- **Content Rating**: Complete questionnaire for age-appropriate content\n\n### Distribution\n\n- **Google Play Store**: Main distribution channel\n- **F-Droid**: For open-source distribution\n- **Direct APK**: For testing and development\n\n## Cross-Platform Communication\n\nThis Android port enables seamless communication with the original iOS bitchat app:\n\n- **iPhone â†” Android**: Full bidirectional messaging\n- **Mixed Groups**: iOS and Android users in same channels\n- **Feature Parity**: All commands and encryption work across platforms\n- **Protocol Sync**: Identical message format and routing behavior\n\n**iOS Version**: For iPhone/iPad users, get the original bitchat at [github.com/jackjackbits/bitchat](https://github.com/jackjackbits/bitchat)\n\n## Contributing\n\nContributions are welcome! Key areas for enhancement:\n\n1. **Performance**: Battery optimization and connection reliability\n2. **UI/UX**: Additional Material Design 3 features\n3. **Security**: Enhanced cryptographic features\n4. **Testing**: Unit and integration test coverage\n5. **Documentation**: API documentation and development guides\n\n## Support & Issues\n\n- **Bug Reports**: [Create an issue](../../issues) with device info and logs\n- **Feature Requests**: [Start a discussion](https://github.com/orgs/permissionlesstech/discussions)\n- **Security Issues**: Email security concerns privately\n- **iOS Compatibility**: Cross-reference with [original iOS repo](https://github.com/jackjackbits/bitchat)\n\nFor iOS-specific issues, please refer to the [original iOS bitchat repository](https://github.com/jackjackbits/bitchat).\n",
      "stars_today": 32
    },
    {
      "id": 15216217,
      "name": "kityminder",
      "full_name": "fex-team/kityminder",
      "description": "ç™¾åº¦è„‘å›¾",
      "html_url": "https://github.com/fex-team/kityminder",
      "stars": 4731,
      "forks": 1929,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2013-12-16T03:28:40Z",
      "updated_at": "2026-01-16T00:35:05Z",
      "pushed_at": "2019-08-10T08:29:01Z",
      "open_issues": 128,
      "owner": {
        "login": "fex-team",
        "avatar_url": "https://avatars.githubusercontent.com/u/6668906?v=4"
      },
      "readme": "Kity Minder\n==========\n\n## ç®€ä»‹\n\nKityMinder æ˜¯ç™¾åº¦ FEX å›¢é˜Ÿçš„ f-cube å°ç»„ï¼ˆåŸ UEditor å°ç»„ï¼‰çš„åˆä¸€åŠ›ä½œã€‚ä½œä¸ºä¸€æ¬¾åœ¨çº¿çš„è„‘å›¾ç¼–è¾‘å·¥å…·ï¼Œå®ƒæœ‰ç€ä¸äºšäº native è„‘å›¾å·¥å…·çš„äº¤äº’ä½“éªŒã€‚åŒæ—¶ï¼Œå®ƒå……åˆ†å‘æŒ¥äº† Web äº‘å­˜å‚¨çš„ä¼˜åŠ¿ï¼Œå¯ä»¥ç›´æ¥å°†ç¼–è¾‘ä¸­çš„è„‘å›¾åŒæ­¥åˆ°äº‘ç«¯ã€‚æ­¤å¤–ï¼Œå€Ÿç”±ç‹¬åˆ›çš„ â€œäº‘ç›˜åˆ†äº«â€åŠŸèƒ½ï¼Œç”¨æˆ·å¯ä»¥ä¸€é”®å°†å½“å‰ç¼–è¾‘çš„è„‘å›¾ç›´æ¥ç”Ÿæˆåœ¨çº¿é“¾æ¥å…±äº«ç»™å…¶ä»–ç”¨æˆ·ï¼Œå®ç°æ— ç¼æ²Ÿé€šã€‚\n\n![KityMinder](snap.png \"KityMinder ç•Œé¢\")\n\nKityMinder åŸºäº SVG æŠ€æœ¯å®ç°ï¼Œæ”¯æŒç»å¤§å¤šæ•°çš„ä¸»æµæµè§ˆå™¨ï¼ŒåŒ…æ‹¬ï¼š\n\n1. Chrome\n2. Firefox\n3. Safari\n4. Internet Explorer 10 æˆ–ä»¥ä¸Š\n\n## çº¿ä¸Šç‰ˆæœ¬\n\näº§å“åœ°å€ï¼š[http://naotu.baidu.com](http://naotu.baidu.com)\n\n## äºŒæ¬¡å¼€å‘\n\n> ä¸å»ºè®®ç›´æ¥ä½¿ç”¨ç™¾åº¦è„‘å›¾ä»“åº“è¿›è¡ŒäºŒæ¬¡å¼€å‘ã€‚\n>\n> éœ€è¦è„‘å›¾å¯è§†åŒ–éœ€æ±‚çš„ï¼Œå¯ä»¥åŸºäº [kityminder-core](https://github.com/fex-team/kityminder-core) è¿›è¡ŒäºŒæ¬¡å¼€å‘ï¼›\n> éœ€è¦è„‘å›¾ç¼–è¾‘éœ€æ±‚çš„ï¼Œå¯ä»¥ä½¿ç”¨ [kityminder-editor](https://github.com/fex-team/kityminder-editor) è¿›è¡ŒäºŒæ¬¡å¼€å‘ã€‚\n\n### ä¾èµ–\n\nç™¾åº¦è„‘å›¾ä¾èµ–åˆ—è¡¨å¦‚ä¸‹ã€‚\n\n* `lib/bower/codemirror` - å¤‡æ³¨çª—å£ä½¿ç”¨çš„ä»£ç ç¼–è¾‘å™¨\n* `lib/fio` - å‰ç«¯ IO æ“ä½œä¸­é—´ä»¶\n* `lib/fui` - åŸºç¡€ UI ç»„ä»¶åº“\n* `lib/kity` - å‰ç«¯ SVG åº“\n* `lib/marked` - Markdown æ¸²æŸ“æ”¯æŒ\n\n```bash\ngit clone https://github.com/fex-team/kityminder.git\n```\n\n### å®‰è£…\n\nè¦åœ¨æœ¬åœ°è¿è¡Œç™¾åº¦è„‘å›¾ï¼Œéœ€è¦å…ˆå®‰è£…ä¸€ä¸‹å¼€å‘å·¥å…·ï¼š[git](http://git-scm.com)ã€[node](http://nodejs.org/)ã€[bower](http://bower.io/)\n\nå»ºè®® `fork` æœ¬ä»“åº“åè¿›è¡ŒäºŒæ¬¡å¼€å‘ã€‚`fork` æ“ä½œå®Œæˆåï¼Œä¼šåœ¨æ‚¨çš„ github è´¦æˆ·ä¸‹åˆ›å»ºä¸€ä¸ª kityminder çš„å‰¯æœ¬ã€‚æ¥ä¸‹æ¥å¯ä»¥å…‹éš†åˆ°æœ¬åœ°ã€‚\n\n```bash\ncd {YOUR_WORKING_DIRECTORY}\ngit clone https://github.com/{YOUR_GITHUB_USERNAME}/kityminder.git\n```\n\nä»£ç å…‹éš†å®Œæˆï¼Œéœ€è¦åˆå§‹åŒ–å­æ¨¡å—ã€‚\n\n```bash\ngit submodule init\ngit submodule update\n```\n\nç„¶åå®‰è£…é¡¹ç›®çš„ä¾èµ–é¡¹ã€‚\n\n```bash\nnpm install\nbower install\n```\n\n### æ„å»º\n\nä¾èµ–å®‰è£…å®Œæˆï¼Œä½¿ç”¨ `grunt` è¿›è¡Œæ„å»ºï¼š\n\n```bash\ngrunt\n```\n\nè¿è¡Œå®Œæˆåï¼Œä¼šå‘ç°ç”Ÿæˆäº† `dist` ç›®å½•ï¼Œé‡Œé¢å°±æ˜¯å¯è¿è¡Œçš„ kityminderã€‚\n\n## è”ç³»æˆ‘ä»¬\n\né—®é¢˜å’Œå»ºè®®åé¦ˆï¼š[Github Issues](https://github.com/fex-team/kityminder/issues/new)\né‚®ä»¶ç»„: kity@baidu.com\nQQ è®¨è®ºç¾¤: 374918234\n",
      "stars_today": 31
    },
    {
      "id": 72056048,
      "name": "fx",
      "full_name": "uber-go/fx",
      "description": "A dependency injection based application framework for Go.",
      "html_url": "https://github.com/uber-go/fx",
      "stars": 7272,
      "forks": 328,
      "language": "Go",
      "topics": [
        "app-framework",
        "dependency-injection",
        "framework",
        "go",
        "golang",
        "service"
      ],
      "created_at": "2016-10-27T00:25:00Z",
      "updated_at": "2026-01-15T23:36:42Z",
      "pushed_at": "2025-12-27T14:09:36Z",
      "open_issues": 69,
      "owner": {
        "login": "uber-go",
        "avatar_url": "https://avatars.githubusercontent.com/u/19262598?v=4"
      },
      "readme": "# :unicorn: Fx [![GoDoc](https://pkg.go.dev/badge/go.uber.org/fx)](https://pkg.go.dev/go.uber.org/fx) [![Github release](https://img.shields.io/github/release/uber-go/fx.svg)](https://github.com/uber-go/fx/releases) [![Build Status](https://github.com/uber-go/fx/actions/workflows/go.yml/badge.svg)](https://github.com/uber-go/fx/actions/workflows/go.yml) [![Coverage Status](https://codecov.io/gh/uber-go/fx/branch/master/graph/badge.svg)](https://codecov.io/gh/uber-go/fx/branch/master) [![Go Report Card](https://goreportcard.com/badge/go.uber.org/fx)](https://goreportcard.com/report/go.uber.org/fx)\n\nFx is a dependency injection system for Go.\n\n**Benefits**\n\n- Eliminate globals: Fx helps you remove global state from your application.\n  No more `init()` or global variables. Use Fx-managed singletons.\n- Code reuse: Fx lets teams within your organization build loosely-coupled\n  and well-integrated shareable components.\n- Battle tested: Fx is the backbone of nearly all Go services at Uber.\n\nSee our [docs](https://uber-go.github.io/fx/) to get started and/or\nlearn more about Fx.\n\n## Installation\n\nUse Go modules to install Fx in your application.\n\n```shell\ngo get go.uber.org/fx@v1\n```\n\n## Getting started\n\nTo get started with Fx, [start here](https://uber-go.github.io/fx/get-started/).\n\n## Stability\n\nThis library is `v1` and follows [SemVer](https://semver.org/) strictly.\n\nNo breaking changes will be made to exported APIs before `v2.0.0`.\n\nThis project follows the [Go Release Policy](https://golang.org/doc/devel/release.html#policy). Each major\nversion of Go is supported until there are two newer major releases.\n\n## Stargazers over time\n\n[![Stargazers over time](https://starchart.cc/uber-go/fx.svg)](https://starchart.cc/uber-go/fx)\n\n",
      "stars_today": 31
    },
    {
      "id": 311315731,
      "name": "Xray-core",
      "full_name": "XTLS/Xray-core",
      "description": "Xray, Penetrates Everything. Also the best v2ray-core. Where the magic happens. An open platform for various uses.",
      "html_url": "https://github.com/XTLS/Xray-core",
      "stars": 34151,
      "forks": 4870,
      "language": "Go",
      "topics": [
        "anticensorship",
        "dns",
        "network",
        "proxy",
        "reality",
        "shadowsocks",
        "socks5",
        "tls",
        "trojan",
        "tunnel",
        "utls",
        "vision",
        "vless",
        "vmess",
        "vpn",
        "wireguard",
        "xhttp",
        "xray",
        "xtls",
        "xudp"
      ],
      "created_at": "2020-11-09T11:23:10Z",
      "updated_at": "2026-01-15T20:15:24Z",
      "pushed_at": "2026-01-14T13:31:43Z",
      "open_issues": 39,
      "owner": {
        "login": "XTLS",
        "avatar_url": "https://avatars.githubusercontent.com/u/71564206?v=4"
      },
      "readme": "# Project X\n\n[Project X](https://github.com/XTLS) originates from XTLS protocol, providing a set of network tools such as [Xray-core](https://github.com/XTLS/Xray-core) and [REALITY](https://github.com/XTLS/REALITY).\n\n[README](https://github.com/XTLS/Xray-core#readme) is open, so feel free to submit your project [here](https://github.com/XTLS/Xray-core/pulls).\n\n## Sponsors\n\n[![Remnawave](https://github.com/user-attachments/assets/a22d34ae-01ee-441c-843a-85356748ed1e)](https://docs.rw)\n\n[![Happ](https://github.com/user-attachments/assets/14055dab-e8bb-48bd-89e8-962709e4098e)](https://happ.su)\n\n[**Sponsor Xray-core**](https://github.com/XTLS/Xray-core/issues/3668)\n\n## Donation & NFTs\n\n### [Collect a Project X NFT to support the development of Project X!](https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1)\n\n[<img alt=\"Project X NFT\" width=\"150px\" src=\"https://raw2.seadn.io/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/7fa9ce900fb39b44226348db330e32/8b7fa9ce900fb39b44226348db330e32.svg\" />](https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1)\n\n- **TRX(Tron)/USDT/USDC: `TNrDh5VSfwd4RPrwsohr6poyNTfFefNYan`**\n- **TON: `UQApeV-u2gm43aC1uP76xAC1m6vCylstaN1gpfBmre_5IyTH`**\n- **BTC: `1JpqcziZZuqv3QQJhZGNGBVdCBrGgkL6cT`**\n- **XMR: `4ABHQZ3yJZkBnLoqiKvb3f8eqUnX4iMPb6wdant5ZLGQELctcerceSGEfJnoCk6nnyRZm73wrwSgvZ2WmjYLng6R7sR67nq`**\n- **SOL/USDT/USDC: `3x5NuXHzB5APG6vRinPZcsUv5ukWUY1tBGRSJiEJWtZa`**\n- **ETH/USDT/USDC: `0xDc3Fe44F0f25D13CACb1C4896CD0D321df3146Ee`**\n- **Project X NFT: https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1**\n- **VLESS NFT: https://opensea.io/collection/vless**\n- **REALITY NFT: https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/2**\n- **Related links: [VLESS Post-Quantum Encryption](https://github.com/XTLS/Xray-core/pull/5067), [XHTTP: Beyond REALITY](https://github.com/XTLS/Xray-core/discussions/4113), [Announcement of NFTs by Project X](https://github.com/XTLS/Xray-core/discussions/3633)**\n\n## License\n\n[Mozilla Public License Version 2.0](https://github.com/XTLS/Xray-core/blob/main/LICENSE)\n\n## Documentation\n\n[Project X Official Website](https://xtls.github.io)\n\n## Telegram\n\n[Project X](https://t.me/projectXray)\n\n[Project X Channel](https://t.me/projectXtls)\n\n[Project VLESS](https://t.me/projectVless) (Ğ ÑƒÑÑĞºĞ¸Ğ¹)\n\n[Project XHTTP](https://t.me/projectXhttp) (Persian)\n\n## Installation\n\n- Linux Script\n  - [XTLS/Xray-install](https://github.com/XTLS/Xray-install) (**Official**)\n  - [tempest](https://github.com/team-cloudchaser/tempest) (supports [`systemd`](https://systemd.io) and [OpenRC](https://github.com/OpenRC/openrc); Linux-only)\n- Docker\n  - [ghcr.io/xtls/xray-core](https://ghcr.io/xtls/xray-core) (**Official**)\n  - [teddysun/xray](https://hub.docker.com/r/teddysun/xray)\n  - [wulabing/xray_docker](https://github.com/wulabing/xray_docker)\n- Web Panel\n  - [Remnawave](https://github.com/remnawave/panel)\n  - [3X-UI](https://github.com/MHSanaei/3x-ui)\n  - [PasarGuard](https://github.com/PasarGuard/panel)\n  - [Xray-UI](https://github.com/qist/xray-ui)\n  - [X-Panel](https://github.com/xeefei/X-Panel)\n  - [Marzban](https://github.com/Gozargah/Marzban)\n  - [Hiddify](https://github.com/hiddify/Hiddify-Manager)\n  - [TX-UI](https://github.com/AghayeCoder/tx-ui)\n- One Click\n  - [Xray-REALITY](https://github.com/zxcvos/Xray-script), [xray-reality](https://github.com/sajjaddg/xray-reality), [reality-ezpz](https://github.com/aleskxyz/reality-ezpz)\n  - [Xray_bash_onekey](https://github.com/hello-yunshu/Xray_bash_onekey), [XTool](https://github.com/LordPenguin666/XTool), [VPainLess](https://github.com/vpainless/vpainless)\n  - [v2ray-agent](https://github.com/mack-a/v2ray-agent), [Xray_onekey](https://github.com/wulabing/Xray_onekey), [ProxySU](https://github.com/proxysu/ProxySU)\n- Magisk\n  - [Xray4Magisk](https://github.com/Asterisk4Magisk/Xray4Magisk)\n  - [Xray_For_Magisk](https://github.com/E7KMbb/Xray_For_Magisk)\n- Homebrew\n  - `brew install xray`\n\n## Usage\n\n- Example\n  - [VLESS-XTLS-uTLS-REALITY](https://github.com/XTLS/REALITY#readme)\n  - [VLESS-TCP-XTLS-Vision](https://github.com/XTLS/Xray-examples/tree/main/VLESS-TCP-XTLS-Vision)\n  - [All-in-One-fallbacks-Nginx](https://github.com/XTLS/Xray-examples/tree/main/All-in-One-fallbacks-Nginx)\n- Xray-examples\n  - [XTLS/Xray-examples](https://github.com/XTLS/Xray-examples)\n  - [chika0801/Xray-examples](https://github.com/chika0801/Xray-examples)\n  - [lxhao61/integrated-examples](https://github.com/lxhao61/integrated-examples)\n- Tutorial\n  - [XTLS Vision](https://github.com/chika0801/Xray-install)\n  - [REALITY (English)](https://cscot.pages.dev/2023/03/02/Xray-REALITY-tutorial/)\n  - [XTLS-Iran-Reality (English)](https://github.com/SasukeFreestyle/XTLS-Iran-Reality)\n  - [Xray REALITY with 'steal oneself' (English)](https://computerscot.github.io/vless-xtls-utls-reality-steal-oneself.html)\n  - [Xray with WireGuard inbound (English)](https://g800.pages.dev/wireguard)\n\n## GUI Clients\n\n- OpenWrt\n  - [PassWall](https://github.com/xiaorouji/openwrt-passwall), [PassWall 2](https://github.com/xiaorouji/openwrt-passwall2)\n  - [ShadowSocksR Plus+](https://github.com/fw876/helloworld)\n  - [luci-app-xray](https://github.com/yichya/luci-app-xray) ([openwrt-xray](https://github.com/yichya/openwrt-xray))\n- Asuswrt-Merlin\n  - [XRAYUI](https://github.com/DanielLavrushin/asuswrt-merlin-xrayui)\n- Windows\n  - [v2rayN](https://github.com/2dust/v2rayN)\n  - [Furious](https://github.com/LorenEteval/Furious)\n  - [Invisible Man - Xray](https://github.com/InvisibleManVPN/InvisibleMan-XRayClient)\n  - [AnyPortal](https://github.com/AnyPortal/AnyPortal)\n- Android\n  - [v2rayNG](https://github.com/2dust/v2rayNG)\n  - [X-flutter](https://github.com/XTLS/X-flutter)\n  - [SaeedDev94/Xray](https://github.com/SaeedDev94/Xray)\n  - [SimpleXray](https://github.com/lhear/SimpleXray)\n  - [AnyPortal](https://github.com/AnyPortal/AnyPortal)\n- iOS & macOS arm64 & tvOS\n  - [Happ](https://apps.apple.com/app/happ-proxy-utility/id6504287215) ([tvOS](https://apps.apple.com/us/app/happ-proxy-utility-for-tv/id6748297274))\n  - [Streisand](https://apps.apple.com/app/streisand/id6450534064)\n  - [OneXray](https://github.com/OneXray/OneXray)\n- macOS arm64 & x64\n  - [Happ](https://apps.apple.com/app/happ-proxy-utility/id6504287215)\n  - [V2rayU](https://github.com/yanue/V2rayU)\n  - [V2RayXS](https://github.com/tzmax/V2RayXS)\n  - [Furious](https://github.com/LorenEteval/Furious)\n  - [OneXray](https://github.com/OneXray/OneXray)\n  - [GoXRay](https://github.com/goxray/desktop)\n  - [AnyPortal](https://github.com/AnyPortal/AnyPortal)\n  - [v2rayN](https://github.com/2dust/v2rayN)\n- Linux\n  - [v2rayA](https://github.com/v2rayA/v2rayA)\n  - [Furious](https://github.com/LorenEteval/Furious)\n  - [GorzRay](https://github.com/ketetefid/GorzRay)\n  - [GoXRay](https://github.com/goxray/desktop)\n  - [AnyPortal](https://github.com/AnyPortal/AnyPortal)\n  - [v2rayN](https://github.com/2dust/v2rayN)\n\n## Others that support VLESS, XTLS, REALITY, XUDP, PLUX...\n\n- iOS & macOS arm64 & tvOS\n  - [Shadowrocket](https://apps.apple.com/app/shadowrocket/id932747118)\n  - [Loon](https://apps.apple.com/us/app/loon/id1373567447)\n- Xray Tools\n  - [xray-knife](https://github.com/lilendian0x00/xray-knife)\n  - [xray-checker](https://github.com/kutovoys/xray-checker)\n- Xray Wrapper\n  - [XTLS/libXray](https://github.com/XTLS/libXray)\n  - [xtls-sdk](https://github.com/remnawave/xtls-sdk)\n  - [xtlsapi](https://github.com/hiddify/xtlsapi)\n  - [AndroidLibXrayLite](https://github.com/2dust/AndroidLibXrayLite)\n  - [Xray-core-python](https://github.com/LorenEteval/Xray-core-python)\n  - [xray-api](https://github.com/XVGuardian/xray-api)\n- [XrayR](https://github.com/XrayR-project/XrayR)\n  - [XrayR-release](https://github.com/XrayR-project/XrayR-release)\n  - [XrayR-V2Board](https://github.com/missuo/XrayR-V2Board)\n- Cores\n  - [Amnezia VPN](https://github.com/amnezia-vpn)\n  - [mihomo](https://github.com/MetaCubeX/mihomo)\n  - [sing-box](https://github.com/SagerNet/sing-box)\n\n## Contributing\n\n[Code of Conduct](https://github.com/XTLS/Xray-core/blob/main/CODE_OF_CONDUCT.md)\n\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/XTLS/Xray-core)\n\n## Credits\n\n- [Xray-core v1.0.0](https://github.com/XTLS/Xray-core/releases/tag/v1.0.0) was forked from [v2fly-core 9a03cc5](https://github.com/v2fly/v2ray-core/commit/9a03cc5c98d04cc28320fcee26dbc236b3291256), and we have made & accumulated a huge number of enhancements over time, check [the release notes for each version](https://github.com/XTLS/Xray-core/releases).\n- For third-party projects used in [Xray-core](https://github.com/XTLS/Xray-core), check your local or [the latest go.mod](https://github.com/XTLS/Xray-core/blob/main/go.mod).\n\n## One-line Compilation\n\n### Windows (PowerShell)\n\n```powershell\n$env:CGO_ENABLED=0\ngo build -o xray.exe -trimpath -buildvcs=false -ldflags=\"-s -w -buildid=\" -v ./main\n```\n\n### Linux / macOS\n\n```bash\nCGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -ldflags=\"-s -w -buildid=\" -v ./main\n```\n\n### Reproducible Releases\n\nMake sure that you are using the same Go version, and remember to set the git commit id (7 bytes):\n\n```bash\nCGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -gcflags=\"all=-l=4\" -ldflags=\"-X github.com/xtls/xray-core/core.build=REPLACE -s -w -buildid=\" -v ./main\n```\n\nIf you are compiling a 32-bit MIPS/MIPSLE target, use this command instead:\n\n```bash\nCGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -gcflags=\"-l=4\" -ldflags=\"-X github.com/xtls/xray-core/core.build=REPLACE -s -w -buildid=\" -v ./main\n```\n\n## Stargazers over time\n\n[![Stargazers over time](https://starchart.cc/XTLS/Xray-core.svg)](https://starchart.cc/XTLS/Xray-core)\n",
      "stars_today": 29
    },
    {
      "id": 3390243,
      "name": "servo",
      "full_name": "servo/servo",
      "description": "Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.",
      "html_url": "https://github.com/servo/servo",
      "stars": 35020,
      "forks": 3441,
      "language": "Rust",
      "topics": [
        "browser",
        "rust",
        "servo",
        "web",
        "webbrowser",
        "webengine",
        "webplatform"
      ],
      "created_at": "2012-02-08T19:07:25Z",
      "updated_at": "2026-01-16T00:28:07Z",
      "pushed_at": "2026-01-16T01:04:03Z",
      "open_issues": 3025,
      "owner": {
        "login": "servo",
        "avatar_url": "https://avatars.githubusercontent.com/u/2566135?v=4"
      },
      "readme": "# The Servo Parallel Browser Engine Project\n\nServo is a prototype web browser engine written in the\n[Rust](https://github.com/rust-lang/rust) language. It is currently developed on\n64-bit macOS, 64-bit Linux, 64-bit Windows, 64-bit OpenHarmony, and Android.\n\nServo welcomes contribution from everyone. Check out:\n\n- The [Servo Book](https://book.servo.org) for documentation\n- [servo.org](https://servo.org/) for news and guides\n\nCoordination of Servo development happens:\n- Here in the Github Issues\n- On the [Servo Zulip](https://servo.zulipchat.com/)\n- In video calls advertised in the [Servo Project](https://github.com/servo/project/issues) repo.\n\n## Getting started\n\nFor more detailed build instructions, see the Servo Book under [Getting the Code] and [Building Servo].\n\n[Getting the Code]: https://book.servo.org/building/getting-the-code.html\n[Building Servo]: https://book.servo.org/building/building.html\n\n### macOS\n\n- Download and install [Xcode](https://developer.apple.com/xcode/) and [`brew`](https://brew.sh/).\n- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` \n- Install `rustup`: `curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh`\n- Restart your shell to make sure `cargo` is available\n- Install the other dependencies: `./mach bootstrap`\n- Build servoshell: `./mach build`\n\n### Linux\n\n- Install `curl`:\n  - Arch: `sudo pacman -S --needed curl`\n  - Debian, Ubuntu: `sudo apt install curl`\n  - Fedora: `sudo dnf install curl`\n  - Gentoo: `sudo emerge net-misc/curl`\n- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` \n- Install `rustup`: `curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh`\n- Restart your shell to make sure `cargo` is available\n- Install the other dependencies: `./mach bootstrap`\n- Build servoshell: `./mach build`\n\n### Windows\n\n- Download [`uv`](https://docs.astral.sh/uv/getting-started/installation/#standalone-installer), [`choco`](https://chocolatey.org/install#individual), and [`rustup`](https://win.rustup.rs/)\n  - Be sure to select *Quick install via the Visual Studio Community installer*\n- In the Visual Studio Installer, ensure the following components are installed:\n  - **Windows 10/11 SDK (anything >= 10.0.19041.0)** (`Microsoft.VisualStudio.Component.Windows{10, 11}SDK.{>=19041}`)\n  - **MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)** (`Microsoft.VisualStudio.Component.VC.Tools.x86.x64`)\n  - **C++ ATL for latest v143 build tools (x86 & x64)** (`Microsoft.VisualStudio.Component.VC.ATL`)\n- Restart your shell to make sure `cargo` is available\n- Install the other dependencies: `.\\mach bootstrap`\n- Build servoshell: `.\\mach build`\n\n### Android\n\n- Ensure that the following environment variables are set:\n  - `ANDROID_SDK_ROOT`\n  - `ANDROID_NDK_ROOT`: `$ANDROID_SDK_ROOT/ndk/28.2.13676358/`\n `ANDROID_SDK_ROOT` can be any directory (such as `~/android-sdk`).\n  All of the Android build dependencies will be installed there.\n- Install the latest version of the [Android command-line\n  tools](https://developer.android.com/studio#command-tools) to\n  `$ANDROID_SDK_ROOT/cmdline-tools/latest`.\n- Run the following command to install the necessary components:\n  ```shell\n  sudo $ANDROID_SDK_ROOT/cmdline-tools/latest/bin/sdkmanager --install \\\n   \"build-tools;34.0.0\" \\\n   \"emulator\" \\\n   \"ndk;28.2.13676358\" \\\n   \"platform-tools\" \\\n   \"platforms;android-33\" \\\n   \"system-images;android-33;google_apis;x86_64\"\n  ```\n- Follow the instructions above for the platform you are building on\n\n### OpenHarmony\n\n- Follow the instructions above for the platform you are building on to prepare the environment.\n- Depending on the target distribution (e.g. `HarmonyOS NEXT` vs pure `OpenHarmony`) the build configuration will differ slightly.\n- Ensure that the following environment variables are set\n  - `DEVECO_SDK_HOME` (Required when targeting `HarmonyOS NEXT`)\n  - `OHOS_BASE_SDK_HOME` (Required when targeting `OpenHarmony`)\n  - `OHOS_SDK_NATIVE` (e.g. `${DEVECO_SDK_HOME}/default/openharmony/native` or `${OHOS_BASE_SDK_HOME}/${API_VERSION}/native`)\n  - `SERVO_OHOS_SIGNING_CONFIG`: Path to json file containing a valid signing configuration for the demo app.\n- Review the detailed instructions at [Building for OpenHarmony].\n- The target distribution can be modified by passing `--flavor=<default|harmonyos>` to `mach <build|package|install>`.\n",
      "stars_today": 29
    },
    {
      "id": 810861466,
      "name": "rig",
      "full_name": "0xPlaygrounds/rig",
      "description": "âš™ï¸ğŸ¦€ Build modular and scalable LLM Applications in Rust",
      "html_url": "https://github.com/0xPlaygrounds/rig",
      "stars": 5516,
      "forks": 627,
      "language": "Rust",
      "topics": [
        "agent",
        "ai",
        "artificial-intelligence",
        "automation",
        "generative-ai",
        "large-language-model",
        "llm",
        "llmops",
        "rust",
        "scalable-ai"
      ],
      "created_at": "2024-06-05T13:42:28Z",
      "updated_at": "2026-01-15T23:01:09Z",
      "pushed_at": "2026-01-15T18:27:32Z",
      "open_issues": 123,
      "owner": {
        "login": "0xPlaygrounds",
        "avatar_url": "https://avatars.githubusercontent.com/u/93353392?v=4"
      },
      "readme": "<p align=\"center\">\n<picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"img/rig-rebranded-logo-white.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"img/rig-rebranded-logo-black.svg\">\n    <img src=\"img/rig-rebranded-logo-white.svg\" style=\"width: 40%; height: 40%;\" alt=\"Rig logo\">\n</picture>\n<br>\n<br>\n<a href=\"https://docs.rig.rs\"><img src=\"https://img.shields.io/badge/ğŸ“– docs-rig.rs-dca282.svg\" /></a> &nbsp;\n<a href=\"https://docs.rs/rig-core/latest/rig/\"><img src=\"https://img.shields.io/badge/docs-API Reference-dca282.svg\" /></a> &nbsp;\n<a href=\"https://crates.io/crates/rig-core\"><img src=\"https://img.shields.io/crates/v/rig-core.svg?color=dca282\" /></a>\n&nbsp;\n<a href=\"https://crates.io/crates/rig-core\"><img src=\"https://img.shields.io/crates/d/rig-core.svg?color=dca282\" /></a>\n</br>\n<a href=\"https://discord.gg/playgrounds\"><img src=\"https://img.shields.io/discord/511303648119226382?color=%236d82cc&label=Discord&logo=discord&logoColor=white\" /></a>\n&nbsp;\n<a href=\"\"><img src=\"https://img.shields.io/badge/built_with-Rust-dca282.svg?logo=rust\" /></a>\n&nbsp;\n<a href=\"https://github.com/0xPlaygrounds/rig\"><img src=\"https://img.shields.io/github/stars/0xPlaygrounds/rig?style=social\" alt=\"stars - rig\" /></a>\n<br>\n\n<br>\n</p>\n&nbsp;\n\n\n<div align=\"center\">\n\n[ğŸ“‘ Docs](https://docs.rig.rs)\n<span>&nbsp;&nbsp;â€¢&nbsp;&nbsp;</span>\n[ğŸŒ Website](https://rig.rs)\n<span>&nbsp;&nbsp;â€¢&nbsp;&nbsp;</span>\n[ğŸ¤ Contribute](https://github.com/0xPlaygrounds/rig/issues/new)\n<span>&nbsp;&nbsp;â€¢&nbsp;&nbsp;</span>\n[âœğŸ½ Blogs](https://docs.rig.rs/guides)\n\n</div>\n\nâœ¨ If you would like to help spread the word about Rig, please consider starring the repo!\n\n> [!WARNING]\n> Here be dragons! As we plan to ship a torrent of features in the following months, future updates **will** contain **breaking changes**. With Rig evolving, we'll annotate changes and highlight migration paths as we encounter them.\n\n## Table of contents\n\n- [Table of contents](#table-of-contents)\n- [What is Rig?](#what-is-rig)\n- [High-level features](#high-level-features)\n- [Who's using Rig?](#who-is-using-rig)\n- [Get Started](#get-started)\n  - [Simple example](#simple-example)\n- [Integrations](#supported-integrations)\n\n## What is Rig?\nRig is a Rust library for building scalable, modular, and ergonomic **LLM-powered** applications.\n\nMore information about this crate can be found in the [official](https://docs.rig.rs) & [crate](https://docs.rs/rig-core/latest/rig/) (API Reference) documentations.\n\n## Features\n- Agentic workflows that can handle multi-turn streaming and prompting\n- Full [GenAI Semantic Convention](https://opentelemetry.io/docs/specs/semconv/gen-ai/) compatibility\n- 20+ model providers, all under one singular unified interface\n- 10+ vector store integrations, all under one singular unified interface\n- Full support for LLM completion and embedding workflows\n- Support for transcription, audio generation and image generation model capabilities\n- Integrate LLMs in your app with minimal boilerplate\n- Full WASM compatibility (core library only)\n\n## Who is using Rig?\nBelow is a non-exhaustive list of companies and people who are using Rig:\n- [St Jude](https://www.stjude.org/) - Using Rig for a chatbot utility as part of [`proteinpaint`](https://github.com/stjude/proteinpaint), a genomics visualisation tool.\n- [Coral Protocol](https://www.coralprotocol.org/) - Using Rig extensively, both internally as well as part of the [Coral Rust SDK.](https://github.com/Coral-Protocol/coral-rs)\n- [VT Code](https://github.com/vinhnx/vtcode) - VT Code is a Rust-based terminal coding agent with semantic code intelligence via Tree-sitter and ast-grep. VT Code uses `rig` for simplifying LLM calls and implement model picker.\n- [Dria](https://dria.co/) - a decentralised AI network. Currently using Rig as part of their [compute node.](https://github.com/firstbatchxyz/dkn-compute-node)\n- [Nethermind](https://www.nethermind.io/) - Using Rig as part of their [Neural Interconnected Nodes Engine](https://github.com/NethermindEth/nine) framework.\n- [Neon](https://neon.com) - Using Rig for their [app.build](https://github.com/neondatabase/appdotbuild-agent) V2 reboot in Rust.\n- [Listen](https://github.com/piotrostr/listen) - A framework aiming to become the go-to framework for AI portfolio management agents. Powers [the Listen app.](https://app.listen-rs.com/)\n- [Cairnify](https://cairnify.com/) - helps users find documents, links, and information instantly through an intelligent search bar. Rig provides the agentic foundation behind Cairnifyâ€™s AI search experience, enabling tool-calling, reasoning, and retrieval workflows.\n- [Ryzome](https://ryzome.ai) - Ryzome is a visual AI workspace that lets you build interconnected canvases of thoughts, research, and AI agents to orchestrate complex knowledge work.\n\nFor a full list, check out our [ECOSYSTEM.md file.](https://www.github.com/0xPlaygrounds/rig/tree/main/ECOSYSTEM.md)\n\nAre you also using Rig? [Open an issue](https://www.github.com/0xPlaygrounds/rig/issues) to have your name added!\n\n## Get Started\n```bash\ncargo add rig-core\n```\n\n### Simple example\n```rust\nuse rig::{client::CompletionClient, completion::Prompt, providers::openai};\n\n#[tokio::main]\nasync fn main() {\n    // Create OpenAI client and model\n    // This requires the `OPENAI_API_KEY` environment variable to be set.\n    let openai_client = openai::Client::from_env();\n\n    let gpt4 = openai_client.agent(\"gpt-4\").build();\n\n    // Prompt the model and print its response\n    let response = gpt4\n        .prompt(\"Who are you?\")\n        .await\n        .expect(\"Failed to prompt GPT-4\");\n\n    println!(\"GPT-4: {response}\");\n}\n```\nNote using `#[tokio::main]` requires you enable tokio's `macros` and `rt-multi-thread` features\nor just `full` to enable all features (`cargo add tokio --features macros,rt-multi-thread`).\n\nYou can find more examples each crate's `examples` (ie. [`rig-core/examples`](./rig-core/examples)) directory. More detailed use cases walkthroughs are regularly published on our [Dev.to Blog](https://dev.to/0thtachi) and added to Rig's official documentation [(docs.rig.rs)](http://docs.rig.rs).\n\n## Supported Integrations\n\nVector stores are available as separate companion-crates:\n- MongoDB: [`rig-mongodb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-mongodb)\n- LanceDB: [`rig-lancedb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-lancedb)\n- Neo4j: [`rig-neo4j`](https://github.com/0xPlaygrounds/rig/tree/main/rig-neo4j)\n- Qdrant: [`rig-qdrant`](https://github.com/0xPlaygrounds/rig/tree/main/rig-qdrant)\n- SQLite: [`rig-sqlite`](https://github.com/0xPlaygrounds/rig/tree/main/rig-sqlite)\n- SurrealDB: [`rig-surrealdb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-surrealdb)\n- Milvus: [`rig-milvus`](https://github.com/0xPlaygrounds/rig/tree/main/rig-milvus)\n- ScyllaDB: [`rig-scylladb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-scylladb)\n- AWS S3Vectors: [`rig-s3vectors`](https://github.com/0xPlaygrounds/rig/tree/main/rig-s3vectors)\n- HelixDB: [`rig-helixdb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-helixdb)\n\nThe following providers are available as separate companion-crates:\n- AWS Bedrock: [`rig-bedrock`](https://github.com/0xPlaygrounds/rig/tree/main/rig-bedrock)\n- Fastembed: [`rig-fastembed`](https://github.com/0xPlaygrounds/rig/tree/main/rig-fastembed)\n- Eternal AI: [`rig-eternalai`](https://github.com/0xPlaygrounds/rig/tree/main/rig-eternalai)\n- Google Vertex: [`rig-vertexai`](https://github.com/0xPlaygrounds/rig/tree/main/rig-vertexai)\n\nWe also have some other associated crates that have additional functionality you may find helpful when using Rig:\n- `rig-onchain-kit` - the [Rig Onchain Kit.](https://github.com/0xPlaygrounds/rig-onchain-kit) Intended to make interactions between Solana/EVM and Rig much easier to implement.\n\n\n<p align=\"center\">\n<br>\n<br>\n<img src=\"img/built-by-playgrounds.svg\" alt=\"Build by Playgrounds\" width=\"30%\">\n</p>\n",
      "stars_today": 29
    },
    {
      "id": 904534974,
      "name": "go-stock",
      "full_name": "ArvinLovegood/go-stock",
      "description": "ğŸ¦„ğŸ¦„ğŸ¦„AIèµ‹èƒ½è‚¡ç¥¨åˆ†æï¼šAIåŠ æŒçš„è‚¡ç¥¨åˆ†æ/é€‰è‚¡å·¥å…·ã€‚è‚¡ç¥¨è¡Œæƒ…è·å–ï¼ŒAIçƒ­ç‚¹èµ„è®¯åˆ†æï¼ŒAIèµ„é‡‘/è´¢åŠ¡åˆ†æï¼Œæ¶¨è·ŒæŠ¥è­¦æ¨é€ã€‚æ”¯æŒAè‚¡ï¼Œæ¸¯è‚¡ï¼Œç¾è‚¡ã€‚æ”¯æŒå¸‚åœºæ•´ä½“/ä¸ªè‚¡æƒ…ç»ªåˆ†æï¼ŒAIè¾…åŠ©é€‰è‚¡ç­‰ã€‚æ•°æ®å…¨éƒ¨ä¿ç•™åœ¨æœ¬åœ°ã€‚æ”¯æŒDeepSeekï¼ŒOpenAIï¼Œ Ollamaï¼ŒLMStudioï¼ŒAnythingLLMï¼Œç¡…åŸºæµåŠ¨ï¼Œç«å±±æ–¹èˆŸï¼Œé˜¿é‡Œäº‘ç™¾ç‚¼ç­‰å¹³å°æˆ–æ¨¡å‹ã€‚",
      "html_url": "https://github.com/ArvinLovegood/go-stock",
      "stars": 3813,
      "forks": 623,
      "language": "Go",
      "topics": [
        "anythingllm",
        "deepseek",
        "golang",
        "lmstudio",
        "naiveui",
        "ollama",
        "openai",
        "stock",
        "wails"
      ],
      "created_at": "2024-12-17T04:46:28Z",
      "updated_at": "2026-01-16T00:16:43Z",
      "pushed_at": "2026-01-15T08:42:18Z",
      "open_issues": 19,
      "owner": {
        "login": "ArvinLovegood",
        "avatar_url": "https://avatars.githubusercontent.com/u/7401917?v=4"
      },
      "readme": "# go-stock : åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„AIèµ‹èƒ½è‚¡ç¥¨åˆ†æå·¥å…·\n## ![go-stock](./build/appicon.png)\n![GitHub Release](https://img.shields.io/github/v/release/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases&link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases)\n[![GitHub Repo stars](https://img.shields.io/github/stars/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock)](https://github.com/ArvinLovegood/go-stock)\n[![star](https://gitee.com/arvinlovegood_admin/go-stock/badge/star.svg?theme=dark)](https://gitee.com/arvinlovegood_admin/go-stock)\n\n[//]: # ([![star]&#40;https://gitcode.com/ArvinLovegood/go-stock/star/badge.svg&#41;]&#40;https://gitcode.com/ArvinLovegood/go-stock&#41;)\n\n### ğŸŒŸå…¬ä¼—å·\n![æ‰«ç _æœç´¢è”åˆä¼ æ’­æ ·å¼-ç™½è‰²ç‰ˆ.png](build/screenshot/%E6%89%AB%E7%A0%81_%E6%90%9C%E7%B4%A2%E8%81%94%E5%90%88%E4%BC%A0%E6%92%AD%E6%A0%B7%E5%BC%8F-%E7%99%BD%E8%89%B2%E7%89%88.png)\n\n### ğŸ“ˆ äº¤æµç¾¤\n\n[//]: # (- QQäº¤æµç¾¤2ï¼š[ç‚¹å‡»é“¾æ¥åŠ å…¥ç¾¤èŠã€go-stockäº¤æµç¾¤2ã€‘ï¼š892666282]&#40;https://qm.qq.com/q/5mYiy6Yxh0&#41;)\n- QQäº¤æµç¾¤ï¼š[ç‚¹å‡»é“¾æ¥åŠ å…¥ç¾¤èŠã€go-stockäº¤æµç¾¤ã€‘ï¼š491605333(å®šæœŸæ¸…ç†ï¼Œéšç¼˜å…¥ç¾¤)](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=0YQ8qD3exahsD4YLNhzQTWe5ssstWC89&authKey=usOMMRFtIQDC%2FYcatHYapcxQbJ7PwXPHK9OypTXWzNjAq%2FRVvQu9bj2lRgb%2BSZ3p&noverify=0&group_code=491605333)\n\n###  âœ¨ ç®€ä»‹\n- æœ¬é¡¹ç›®åŸºäºWailså’ŒNaiveUIå¼€å‘ï¼Œç»“åˆAIå¤§æ¨¡å‹æ„å»ºçš„è‚¡ç¥¨åˆ†æå·¥å…·ã€‚\n- ç›®å‰å·²æ”¯æŒAè‚¡ï¼Œæ¸¯è‚¡ï¼Œç¾è‚¡ï¼Œæœªæ¥è®¡åˆ’åŠ å…¥åŸºé‡‘ï¼ŒETFç­‰æ”¯æŒã€‚\n- æ”¯æŒå¸‚åœºæ•´ä½“/ä¸ªè‚¡æƒ…ç»ªåˆ†æï¼ŒKçº¿æŠ€æœ¯æŒ‡æ ‡åˆ†æç­‰åŠŸèƒ½ã€‚\n- æœ¬é¡¹ç›®ä»…ä¾›å¨±ä¹ï¼Œä¸å–œå‹¿å–·ï¼ŒAIåˆ†æè‚¡ç¥¨ç»“æœä»…ä¾›å­¦ä¹ ç ”ç©¶ï¼ŒæŠ•èµ„æœ‰é£é™©ï¼Œè¯·è°¨æ…ä½¿ç”¨ã€‚\n- å¼€å‘ç¯å¢ƒä¸»è¦åŸºäºWindows10+ï¼Œå…¶ä»–å¹³å°æœªæµ‹è¯•æˆ–åŠŸèƒ½å—é™ã€‚\n\n### ğŸ“¦ ç«‹å³ä½“éªŒ\n[//]: # (- å®‰è£…ç‰ˆï¼š[go-stock-amd64-installer.exe]&#40;https://github.com/ArvinLovegood/go-stock/releases&#41;)\n- ç»¿è‰²ç‰ˆï¼š[go-stock-windows-amd64.exe](https://github.com/ArvinLovegood/go-stock/releases)\n- MACOSç»¿è‰²ç‰ˆï¼š[go-stock-darwin-universal](https://github.com/ArvinLovegood/go-stock/releases)\n\n[//]: # (- MACOSå®‰è£…ç‰ˆï¼š[go-stock-darwin-universal.pkg]&#40;https://github.com/ArvinLovegood/go-stock/releases&#41;)\n\n\n### ğŸ’¬ æ”¯æŒå¤§æ¨¡å‹/å¹³å°\n| æ¨¡å‹ | çŠ¶æ€ | å¤‡æ³¨                                                                                                                                                                                                                                                                |\n| --- | --- |-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [OpenAI](https://platform.openai.com/) | âœ… | å¯æ¥å…¥ä»»ä½• OpenAI æ¥å£æ ¼å¼æ¨¡å‹                                                                                                                                                                                                                                               |\n| [Ollama](https://ollama.com/) | âœ… | æœ¬åœ°å¤§æ¨¡å‹è¿è¡Œå¹³å°                                                                                                                                                                                                                                                         |\n| [LMStudio](https://lmstudio.ai/) | âœ… | æœ¬åœ°å¤§æ¨¡å‹è¿è¡Œå¹³å°                                                                                                                                                                                                                                                         |\n| [AnythingLLM](https://anythingllm.com/) | âœ… | æœ¬åœ°çŸ¥è¯†åº“                                                                                                                                                                                                                                                             |\n| [DeepSeek](https://www.deepseek.com/) | âœ… | deepseek-reasoner,deepseek-chat                                                                                                                                                                                                                                   |\n| [å¤§æ¨¡å‹èšåˆå¹³å°](https://cloud.siliconflow.cn/i/foufCerk) | âœ… | å¦‚ï¼š[ç¡…åŸºæµåŠ¨](https://cloud.siliconflow.cn/i/foufCerk)ï¼Œ[ç«å±±æ–¹èˆŸ](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&ac=DSASUQY5&rc=IJSE43PZ) |\n\n### <span style=\"color: #568DF4;\">å„ä½äº²çˆ±çš„æœ‹å‹ä»¬ï¼Œå¦‚æœæ‚¨å¯¹è¿™ä¸ªé¡¹ç›®æ„Ÿå…´è¶£ï¼Œè¯·å…ˆç»™æˆ‘ä¸€ä¸ª<i style=\"color: #EA2626;\">star</i>å§ï¼Œè°¢è°¢ï¼</span>ğŸ’•\n[//]: # (- ä¼˜äº‘æ™ºç®—ï¼ˆby UCloudï¼‰ï¼šä¸‡å¡è§„æ¨¡4090å…è´¹ç”¨10å°æ—¶ï¼Œæ–°äººæ³¨å†Œå¦å¢50ä¸‡tokensï¼Œæµ·é‡çƒ­é—¨æºé¡¹ç›®é•œåƒä¸€é”®éƒ¨ç½²ï¼Œ[æ³¨å†Œé“¾æ¥]&#40;https://www.compshare.cn/image-community?ytag=GPU_YY-gh_gostock&#41;)\n- ç«å±±æ–¹èˆŸï¼šæ–°ç”¨æˆ·æ¯ä¸ªæ¨¡å‹æ³¨å†Œå³é€50ä¸‡tokensï¼Œ[æ³¨å†Œé“¾æ¥](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&ac=DSASUQY5&rc=IJSE43PZ)\n- ç¡…åŸºæµåŠ¨(siliconflow)ï¼Œæ³¨å†Œå³é€2000ä¸‡Tokensï¼Œ[æ³¨å†Œé“¾æ¥](https://cloud.siliconflow.cn/i/foufCerk)\n- Tushareå¤§æ•°æ®å¼€æ”¾ç¤¾åŒº,å…è´¹æä¾›å„ç±»é‡‘èæ•°æ®,åŠ©åŠ›è¡Œä¸šå’Œé‡åŒ–ç ”ç©¶(æ³¨æ„ï¼šTushareåªéœ€è¦120ç§¯åˆ†å³å¯ï¼Œæ³¨å†Œå®Œæˆä¸ªäººèµ„æ–™è¡¥å……å³å¯å¾—120ç§¯åˆ†ï¼ï¼ï¼)ï¼Œ[æ³¨å†Œé“¾æ¥](https://tushare.pro/register?reg=701944)\n- è½¯ä»¶å¿«é€Ÿè¿­ä»£å¼€å‘ä¸­,è¯·å¤§å®¶ä¼˜å…ˆæµ‹è¯•å’Œä½¿ç”¨æœ€æ–°å‘å¸ƒçš„ç‰ˆæœ¬ã€‚\n- æ¬¢è¿å¤§å®¶æå‡ºå®è´µçš„å»ºè®®ï¼Œæ¬¢è¿æissue,PRã€‚å½“ç„¶æ›´æ¬¢è¿[èµåŠ©æˆ‘](#éƒ½åˆ’åˆ°è¿™äº†å¦‚æœæˆ‘çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©è¯·èµåŠ©æˆ‘å§)ã€‚ğŸ’•\n\n\n### æ”¯æŒå¼€æºğŸ’•è®¡åˆ’\n| èµåŠ©è®¡åˆ’\t                           | èµåŠ©ç­‰çº§\t          | æƒç›Šè¯´æ˜                                                   |\n|:--------------------------------|----------------|:-------------------------------------------------------|\n| æ¯æœˆ 0 RMB\t                       | vip0\t          | ğŸŒŸ å…¨éƒ¨åŠŸèƒ½,è½¯ä»¶è‡ªåŠ¨æ›´æ–°(ä»GitHubä¸‹è½½),è‡ªè¡Œè§£å†³githubå¹³å°ç½‘ç»œé—®é¢˜ã€‚            |\n| æ¯æœˆèµåŠ© 18.8 RMB<br>æ¯å¹´èµåŠ© 120 RMB\t\t | vip1\t          | ğŸ’• å…¨éƒ¨åŠŸèƒ½,è½¯ä»¶è‡ªåŠ¨æ›´æ–°(ä»CDNä¸‹è½½),æ›´æ–°å¿«é€Ÿä¾¿æ·ã€‚AIé…ç½®æŒ‡å¯¼ï¼Œæç¤ºè¯å‚è€ƒç­‰            |\n| æ¯æœˆèµåŠ© 28.8 RMB<br>æ¯å¹´èµåŠ© 240 RMB\t\t | vip2\t          | ğŸ’• ğŸ’• vip1å…¨éƒ¨åŠŸèƒ½,èµ é€ç¡…åŸºæµåŠ¨AIåˆ†ææœåŠ¡,å¯åŠ¨æ—¶è‡ªåŠ¨åŒæ­¥æœ€è¿‘24å°æ—¶å¸‚åœºèµ„è®¯(åŒ…æ‹¬å¤–åª’ç®€è®¯)  |\n| æ¯æœˆèµåŠ© X RMB\t\t\t                   | vipX\t          | ğŸ§© æ›´å¤šè®¡åˆ’ï¼Œè§†go-stockå¼€æºé¡¹ç›®å‘å±•æƒ…å†µè€Œå®š...(æ‰¿æ¥GitHubé¡¹ç›®READMEå¹¿å‘Šæ¨å¹¿ğŸ’–) |\n\n## ğŸ§© é‡å¤§åŠŸèƒ½å¼€å‘è®¡åˆ’\n| åŠŸèƒ½è¯´æ˜            | çŠ¶æ€ | å¤‡æ³¨                                                                                                       |\n|-----------------|----|----------------------------------------------------------------------------------------------------------|\n| è‚¡ç¥¨åˆ†æçŸ¥è¯†åº“         | ğŸš§ | æœªæ¥è®¡åˆ’                                                                                                     |\n| Aiæ™ºèƒ½é€‰è‚¡          | âœ… | Aiæ™ºèƒ½é€‰è‚¡åŠŸèƒ½(å¸‚åœºè¡Œæƒ…-ã€‹AIæ€»ç»“/AIæ™ºèƒ½ä½“åŠŸèƒ½)                                                                             |\n| ETFæ”¯æŒ           | ğŸš§ | ETFæ•°æ®æ”¯æŒ (ç›®å‰å¯ä»¥æŸ¥çœ‹å‡€å€¼å’Œä¼°å€¼)                                                                                    |\n| ç¾è‚¡æ”¯æŒ            | âœ…  | ç¾è‚¡æ•°æ®æ”¯æŒ                                                                                                   |\n| æ¸¯è‚¡æ”¯æŒ            | âœ…  | æ¸¯è‚¡æ•°æ®æ”¯æŒ                                                                                                   |\n| å¤šè½®å¯¹è¯            | âœ…  | AIåˆ†æåå¯ç»§ç»­å¯¹è¯æé—®                                                                                             |\n| è‡ªå®šä¹‰AIåˆ†ææé—®æ¨¡æ¿     | âœ…  | å¯é…ç½®çš„æé—®æ¨¡æ¿ [v2025.2.12.7-alpha](https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha) |\n| ä¸å†å¼ºåˆ¶ä¾èµ–Chromeæµè§ˆå™¨ | âœ…  | é»˜è®¤ä½¿ç”¨edgeæµè§ˆå™¨æŠ“å–æ–°é—»èµ„è®¯                                                                                        |\n\n## ğŸ‘€ æ›´æ–°æ—¥å¿—\n### 2025.12.16 æ–°å¢AIæ€è€ƒæ¨¡å¼ä¸çƒ­é—¨é€‰è‚¡ç­–ç•¥åŠŸèƒ½\n### 2025.11.21 æ–°å¢å¸¦é¢‘ç‡æƒé‡çš„æƒ…æ„Ÿåˆ†æåŠŸèƒ½\n### 2025.10.30 æ·»åŠ AIæ™ºèƒ½ä½“åŠŸèƒ½å¼€å…³(é»˜è®¤å…³é—­ï¼Œå› ä¸ºä½¿ç”¨ä½“éªŒä¸ç†æƒ³)ï¼Œç§»é™¤é¡µé¢æ°´å°\n### 2025.09.27 æ·»åŠ æœºæ„/åˆ¸å•†çš„ç ”ç©¶æŠ¥å‘ŠAIå·¥å…·å‡½æ•°\n### 2025.08.09 æ·»åŠ AIæ™ºèƒ½ä½“èŠå¤©åŠŸèƒ½\n### 2025.07.08 å®ç°è½¯ä»¶è‡ªåŠ¨æ›´æ–°åŠŸèƒ½\n### 2025.07.07 å¡ç‰‡æ·»åŠ è¿·ä½ åˆ†æ—¶å›¾\n### 2025.07.05 MacOsæ”¯æŒ\n### 2025.07.01 AIåˆ†æé›†æˆå·¥å…·å‡½æ•°ï¼ŒAIåˆ†æå°†æ›´åŠ æ™ºèƒ½\n### 2025.06.30 æ·»åŠ æŒ‡æ ‡é€‰è‚¡åŠŸèƒ½\n### 2025.06.27 æ·»åŠ è´¢ç»æ—¥å†å’Œé‡å¤§äº‹ä»¶æ—¶é—´è½´åŠŸèƒ½\n### 2025.06.25 æ·»åŠ çƒ­é—¨è‚¡ç¥¨ã€äº‹ä»¶å’Œè¯é¢˜åŠŸèƒ½\n### 2025.06.18 æ›´æ–°å†…ç½®è‚¡ç¥¨åŸºç¡€æ•°æ®,è½¯ä»¶å†…å®æ—¶å¸‚åœºèµ„è®¯ä¿¡æ¯æé†’ï¼Œæ·»åŠ è¡Œä¸šç ”ç©¶åŠŸèƒ½\n### 2025.06.15 æ·»åŠ å…¬å¸å…¬å‘Šä¿¡æ¯æœç´¢/æŸ¥çœ‹åŠŸèƒ½\n### 2025.06.15 æ·»åŠ ä¸ªè‚¡ç ”æŠ¥åˆ°å¼¹å‡ºèœå•\n### 2025.06.13 æ·»åŠ ä¸ªè‚¡ç ”æŠ¥åŠŸèƒ½\n### 2025.06.12 æ·»åŠ é¾™è™æ¦œåŠŸèƒ½ï¼Œæ–°å¢è¡Œä¸šæ’ååˆ†ç±»\n### 2025.05.30 ä¼˜åŒ–è‚¡ç¥¨åˆ†æ—¶å›¾æ˜¾ç¤º\n### 2025.05.20 ä¿®å¤è´¢è”ç¤¾ç”µæŠ¥è·å–é—®é¢˜\n### 2025.05.16 ä¼˜åŒ–èµ„é‡‘è¶‹åŠ¿å›¾è¡¨ç»„ä»¶\n### 2025.05.15 é‡æ„åº”ç”¨åŠ è½½å’Œæ•°æ®åˆå§‹åŒ–é€»è¾‘ï¼Œæ·»åŠ è‚¡ç¥¨èµ„é‡‘è¶‹åŠ¿åŠŸèƒ½ï¼Œèµ„é‡‘è¶‹åŠ¿å›¾è¡¨å¢åŠ ä¸»åŠ›å½“æ—¥å‡€æµå…¥æ•°æ®å¹¶ä¼˜åŒ–å±•ç¤ºæ•ˆæœ\n### 2025.05.14 æ·»åŠ ä¸ªè‚¡èµ„é‡‘æµå‘åŠŸèƒ½ï¼Œæ’è¡Œæ¦œå¢åŠ è‚¡ç¥¨è¡Œæƒ…Kçº¿å›¾å¼¹çª—\n### 2025.05.13 æ·»åŠ è¡Œä¸šæ’ååŠŸèƒ½\n### 2025.05.09 æ·»åŠ Aè‚¡ç›˜å£æ•°æ®è§£æå’Œå±•ç¤ºåŠŸèƒ½\n### 2025.05.07 ä¼˜åŒ–åˆ†æ—¶å›¾çš„å±•ç¤º\n### 2025.04.29 è¡¥å…¨æ¸¯è‚¡/ç¾è‚¡åŸºç¡€æ•°æ®ï¼Œä¼˜åŒ–æ¸¯è‚¡è‚¡ä»·å»¶è¿Ÿé—®é¢˜ï¼Œä¼˜åŒ–åˆå§‹åŒ–é€»è¾‘\n### 2025.04.25 å¸‚åœºèµ„è®¯æ”¯æŒAIåˆ†æå’Œæ€»ç»“ï¼šè®©AIå¸®ä½ è¯»å¸‚åœºï¼\n### 2025.04.24 æ–°å¢å¸‚åœºè¡Œæƒ…æ¨¡å—ï¼šå³æ—¶æŒæ¡å…¨çƒå¸‚åœºè¡Œæƒ…èµ„è®¯/åŠ¨æ€ï¼Œä»æ­¤å†ä¹Ÿä¸ç”¨å·æ‘¸å»å„å¤§è´¢ç»ç½‘ç«™å•¦ã€‚go-stockä¸€é”®å¸®ä½ æå®šï¼\n### 2025.04.22 ä¼˜åŒ–Kçº¿å›¾å±•ç¤ºï¼Œæ”¯æŒæ‹‰ä¼¸æ”¾å¤§ï¼Œçœ‹å¾—æ›´èˆ’æœå•¦ï¼\n### 2025.04.21 æ¸¯è‚¡ï¼Œç¾è‚¡Kçº¿æ•°æ®è·å–ä¼˜åŒ–\n### 2025.04.01 ä¼˜åŒ–éƒ¨åˆ†è®¾ç½®é€‰é¡¹ï¼Œé¿å…é‡å¯è½¯ä»¶\n### 2025.03.31 ä¼˜åŒ–æ•°æ®çˆ¬å–\n### 2025.03.30 AIè‡ªåŠ¨å®šæ—¶åˆ†æåŠŸèƒ½\n### 2025.03.29 å¤šæç¤ºè¯æ¨¡æ¿ç®¡ç†ï¼ŒAIåˆ†ææ—¶æ”¯æŒé€‰æ‹©ä¸åŒæç¤ºè¯æ¨¡æ¿\n### 2025.03.28 AIåˆ†æç»“æœä¿å­˜ä¸ºmarkdownæ–‡ä»¶æ—¶ï¼Œæ”¯æŒä¿å­˜ä½ç½®ç›®å½•é€‰æ‹©\n### 2025.03.15 è‡ªå®šä¹‰çˆ¬è™«ä½¿ç”¨çš„æµè§ˆå™¨è·¯å¾„é…ç½®\n### 2025.03.14 ä¼˜åŒ–ç¼–è¯‘æ„å»ºï¼Œå¤§å¹…å‡å°‘ç¼–è¯‘åçš„ç¨‹åºæ–‡ä»¶å¤§å°\n### 2025.03.09 åŸºé‡‘ä¼°å€¼å’Œå‡€å€¼ç›‘æ§æŸ¥çœ‹\n### 2025.03.06 é¡¹ç›®ç¤¾åŒºåˆ†äº«åŠŸèƒ½\n### 2025.02.28 ç¾è‚¡æ•°æ®æ”¯æŒ\n### 2025.02.23 å¼¹å¹•åŠŸèƒ½ï¼Œç›¯ç›˜ä¸å†å­¤å•ï¼Œæ— èŠåˆ’ä¸ªæ°´ï¼ğŸ˜\n### 2025.02.22 æ¸¯è‚¡æ•°æ®æ”¯æŒ(ç›®å‰æœ‰å»¶è¿Ÿ)\n\n### 2025.02.16 AIåˆ†æåå¯ç»§ç»­å¯¹è¯æé—®\n- [v2025.2.16.1-alpha](https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.16.1-alpha)\n\n### 2025.02.12 å¯é…ç½®çš„æé—®æ¨¡æ¿\n- [v2025.2.12.7-alpha](https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha)\n\n\n## ğŸ¦„ é‡å¤§æ›´æ–°\n### BIG NEWS !!! é‡å¤§æ›´æ–°ï¼ï¼ï¼\n- 2025.11.21 æ–°å¢å¸¦é¢‘ç‡æƒé‡çš„æƒ…æ„Ÿåˆ†æåŠŸèƒ½\n![img_1.png](build/screenshot/img15.png)\n- 2025.04.25 å¸‚åœºèµ„è®¯æ”¯æŒAIåˆ†æå’Œæ€»ç»“ï¼šè®©AIå¸®ä½ è¯»å¸‚åœºï¼\n![img.png](img.png)\n- 2025.04.24 æ–°å¢å¸‚åœºè¡Œæƒ…æ¨¡å—ï¼šå³æ—¶æŒæ¡å…¨çƒå¸‚åœºè¡Œæƒ…èµ„è®¯/åŠ¨æ€ï¼Œä»æ­¤å†ä¹Ÿä¸ç”¨å·æ‘¸å»å„å¤§è´¢ç»ç½‘ç«™å•¦ã€‚go-stockä¸€é”®å¸®ä½ æå®šï¼\n![img.png](build/screenshot/img13.png)\n![img_13.png](build/screenshot/img_13.png)\n- ![img_14.png](build/screenshot/img_14.png)\n- 2025.01.17 æ–°å¢AIå¤§æ¨¡å‹åˆ†æè‚¡ç¥¨åŠŸèƒ½\n  ![img_5.png](build/screenshot/img.png)\n## ğŸ“¸ åŠŸèƒ½æˆªå›¾\n![img_1.png](build/screenshot/img_6.png)\n### è®¾ç½®\n![img_12.png](build/screenshot/img_4.png)\n### æˆæœ¬è®¾ç½®\n![img.png](build/screenshot/img_7.png)\n### æ—¥K\n![img_12.png](build/screenshot/img_12.png)\n### åˆ†æ—¶\n![img_3.png](build/screenshot/img_9.png)\n### é’‰é’‰æŠ¥è­¦é€šçŸ¥\n![img_4.png](build/screenshot/img_5.png)\n### AIåˆ†æè‚¡ç¥¨\n![img_5.png](build/screenshot/img.png)\n### ç‰ˆæœ¬ä¿¡æ¯æç¤º\n![img_11.png](build/screenshot/img_11.png)\n\n## ğŸ’• æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®\n- [NaiveUI](https://www.naiveui.com/)\n- [Wails](https://wails.io/)\n- [Vue](https://vuejs.org/)\n- [Vite](https://vitejs.dev/)\n- [Tushare](https://tushare.pro/register?reg=701944)\n\n## ğŸ˜˜ èµåŠ©æˆ‘\n### éƒ½åˆ’åˆ°è¿™äº†ï¼Œå¦‚æœæˆ‘çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·èµåŠ©æˆ‘å§ï¼ğŸ˜ŠğŸ˜ŠğŸ˜Š\n| æ”¯ä»˜å® | å¾®ä¿¡  |\n|-----|-----| \n| ![alipay.jpg](build/screenshot/alipay.jpg)  | ![wxpay.jpg](build/screenshot/wxpay.jpg) |\n\n\n## â­ Star History\n[![Star History Chart](https://api.star-history.com/svg?repos=ArvinLovegood/go-stock&type=Date)](https://star-history.com/#ArvinLovegood/go-stock&Date)\n## ğŸ¤– çŠ¶æ€\n![Alt](https://repobeats.axiom.co/api/embed/40b07d415a42c2264a18c4fe1b6f182ff1470687.svg \"Repobeats analytics image\")\n\n## ğŸ³ å…³äºæŠ€æœ¯æ”¯æŒç”³æ˜\n- æœ¬è½¯ä»¶åŸºäºå¼€æºæŠ€æœ¯æ„å»ºï¼Œä½¿ç”¨Wailsã€NaiveUIã€Vueã€AIå¤§æ¨¡å‹ç­‰å¼€æºé¡¹ç›®ã€‚ æŠ€æœ¯ä¸Šå¦‚æœ‰é—®é¢˜ï¼Œå¯ä»¥å…ˆå‘å¯¹åº”çš„å¼€æºç¤¾åŒºè¯·æ±‚å¸®åŠ©ã€‚\n- å¼€æºä¸æ˜“ï¼Œæœ¬äººç²¾åŠ›å’Œæ—¶é—´æœ‰é™ï¼Œå¦‚éœ€ä¸€å¯¹ä¸€æŠ€æœ¯æ”¯æŒï¼Œè¯·å…ˆèµåŠ©ã€‚è”ç³»QQ(å¤‡æ³¨ æŠ€æœ¯æ”¯æŒ)ï¼š506808970\n\n[//]: # (<img src=\"./build/wx.jpg\" width=\"301px\" height=\"402px\" alt=\"ArvinLovegood\">)\n\n\n| æŠ€æœ¯æ”¯æŒæ–¹å¼                          | èµåŠ©(å…ƒ) | \n|:--------------------------------|:-----:|\n| åŠ  QQï¼š506808970                  | 100/æ¬¡ |\n| é•¿æœŸæŠ€æœ¯æ”¯æŒï¼ˆä¸é™æ¬¡æ•°ï¼Œæ–°åŠŸèƒ½ä¼˜å…ˆä½“éªŒç­‰ï¼‰           | 5000  |                  \n\n\n\n## License\n[Apache License 2.0](LICENSE)\n\n",
      "stars_today": 29
    },
    {
      "id": 576201,
      "name": "three.js",
      "full_name": "mrdoob/three.js",
      "description": "JavaScript 3D Library.",
      "html_url": "https://github.com/mrdoob/three.js",
      "stars": 110360,
      "forks": 36232,
      "language": "JavaScript",
      "topics": [
        "3d",
        "augmented-reality",
        "canvas",
        "html5",
        "javascript",
        "svg",
        "virtual-reality",
        "webaudio",
        "webgl",
        "webgl2",
        "webgpu",
        "webxr"
      ],
      "created_at": "2010-03-23T18:58:01Z",
      "updated_at": "2026-01-16T00:48:17Z",
      "pushed_at": "2026-01-15T23:32:44Z",
      "open_issues": 612,
      "owner": {
        "login": "mrdoob",
        "avatar_url": "https://avatars.githubusercontent.com/u/97088?v=4"
      },
      "readme": "# three.js\n\n[![NPM Package][npm]][npm-url]\n[![Build Size][build-size]][build-size-url]\n[![NPM Downloads][npm-downloads]][npmtrends-url]\n[![jsDelivr Downloads][jsdelivr-downloads]][jsdelivr-url]\n[![Discord][discord]][discord-url]\n\n#### JavaScript 3D library\n\nThe aim of the project is to create an easy-to-use, lightweight, cross-browser, general-purpose 3D library. The current builds only include WebGL and WebGPU renderers but SVG and CSS3D renderers are also available as addons.\n\n[Examples](https://threejs.org/examples/) &mdash;\n[Docs](https://threejs.org/docs/) &mdash;\n[Manual](https://threejs.org/manual/) &mdash;\n[Wiki](https://github.com/mrdoob/three.js/wiki) &mdash;\n[Migrating](https://github.com/mrdoob/three.js/wiki/Migration-Guide) &mdash;\n[Questions](https://stackoverflow.com/questions/tagged/three.js) &mdash;\n[Forum](https://discourse.threejs.org/) &mdash;\n[Discord](https://discord.gg/56GBJwAnUS)\n\n### Usage\n\nThis code creates a scene, a camera, and a geometric cube, and it adds the cube to the scene. It then creates a `WebGL` renderer for the scene and camera, and it adds that viewport to the `document.body` element. Finally, it animates the cube within the scene for the camera.\n\n```javascript\nimport * as THREE from 'three';\n\nconst width = window.innerWidth, height = window.innerHeight;\n\n// init\n\nconst camera = new THREE.PerspectiveCamera( 70, width / height, 0.01, 10 );\ncamera.position.z = 1;\n\nconst scene = new THREE.Scene();\n\nconst geometry = new THREE.BoxGeometry( 0.2, 0.2, 0.2 );\nconst material = new THREE.MeshNormalMaterial();\n\nconst mesh = new THREE.Mesh( geometry, material );\nscene.add( mesh );\n\nconst renderer = new THREE.WebGLRenderer( { antialias: true } );\nrenderer.setSize( width, height );\nrenderer.setAnimationLoop( animate );\ndocument.body.appendChild( renderer.domElement );\n\n// animation\n\nfunction animate( time ) {\n\n\tmesh.rotation.x = time / 2000;\n\tmesh.rotation.y = time / 1000;\n\n\trenderer.render( scene, camera );\n\n}\n```\n\nIf everything goes well, you should see [this](https://jsfiddle.net/w43x5Lgh/).\n\n### Cloning this repository\n\nCloning the repo with all its history results in a ~2 GB download. If you don't need the whole history you can use the `depth` parameter to significantly reduce download size.\n\n```sh\ngit clone --depth=1 https://github.com/mrdoob/three.js.git\n```\n\n### Change log\n\n[Releases](https://github.com/mrdoob/three.js/releases)\n\n\n[npm]: https://img.shields.io/npm/v/three\n[npm-url]: https://www.npmjs.com/package/three\n[build-size]: https://badgen.net/bundlephobia/minzip/three\n[build-size-url]: https://bundlephobia.com/result?p=three\n[npm-downloads]: https://img.shields.io/npm/dw/three\n[npmtrends-url]: https://www.npmtrends.com/three\n[jsdelivr-downloads]: https://data.jsdelivr.com/v1/package/npm/three/badge?style=rounded\n[jsdelivr-url]: https://www.jsdelivr.com/package/npm/three\n[discord]: https://img.shields.io/discord/685241246557667386\n[discord-url]: https://discord.gg/56GBJwAnUS\n",
      "stars_today": 27
    },
    {
      "id": 22887094,
      "name": "tesseract",
      "full_name": "tesseract-ocr/tesseract",
      "description": "Tesseract Open Source OCR Engine (main repository)",
      "html_url": "https://github.com/tesseract-ocr/tesseract",
      "stars": 71907,
      "forks": 10465,
      "language": "C++",
      "topics": [
        "hacktoberfest",
        "lstm",
        "machine-learning",
        "ocr",
        "ocr-engine",
        "tesseract",
        "tesseract-ocr"
      ],
      "created_at": "2014-08-12T18:04:59Z",
      "updated_at": "2026-01-16T01:05:28Z",
      "pushed_at": "2026-01-08T02:30:46Z",
      "open_issues": 462,
      "owner": {
        "login": "tesseract-ocr",
        "avatar_url": "https://avatars.githubusercontent.com/u/8401422?v=4"
      },
      "readme": "# Tesseract OCR\n\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/tesseract-ocr/badge.svg)](https://scan.coverity.com/projects/tesseract-ocr)\n[![CodeQL](https://github.com/tesseract-ocr/tesseract/workflows/CodeQL/badge.svg)](https://github.com/tesseract-ocr/tesseract/security/code-scanning)\n[![OSS-Fuzz](https://img.shields.io/badge/oss--fuzz-fuzzing-brightgreen)](https://issues.oss-fuzz.com/issues?q=is:open%20title:tesseract-ocr)\n\\\n[![GitHub license](https://img.shields.io/badge/license-Apache--2.0-blue.svg)](https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/LICENSE)\n[![Downloads](https://img.shields.io/badge/download-all%20releases-brightgreen.svg)](https://github.com/tesseract-ocr/tesseract/releases/)\n\n## Table of Contents\n\n* [Tesseract OCR](#tesseract-ocr)\n  * [About](#about)\n  * [Brief history](#brief-history)\n  * [Installing Tesseract](#installing-tesseract)\n  * [Running Tesseract](#running-tesseract)\n  * [For developers](#for-developers)\n  * [Support](#support)\n  * [License](#license)\n  * [Dependencies](#dependencies)\n  * [Latest Version of README](#latest-version-of-readme)\n\n## About\n\nThis package contains an **OCR engine** - `libtesseract` and a **command line program** - `tesseract`.\n\nTesseract 4 adds a new neural net (LSTM) based [OCR engine](https://en.wikipedia.org/wiki/Optical_character_recognition) which is focused on line recognition, but also still supports the legacy Tesseract OCR engine of Tesseract 3 which works by recognizing character patterns. Compatibility with Tesseract 3 is enabled by using the Legacy OCR Engine mode (--oem 0).\nIt also needs [traineddata](https://tesseract-ocr.github.io/tessdoc/Data-Files.html) files which support the legacy engine, for example those from the [tessdata](https://github.com/tesseract-ocr/tessdata) repository.\n\nStefan Weil is the current lead developer. Ray Smith was the lead developer until 2017. The maintainer is Zdenko Podobny. For a list of contributors see [AUTHORS](https://github.com/tesseract-ocr/tesseract/blob/main/AUTHORS)\nand GitHub's log of [contributors](https://github.com/tesseract-ocr/tesseract/graphs/contributors).\n\nTesseract has **unicode (UTF-8) support**, and can **recognize [more than 100 languages](https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html)** \"out of the box\".\n\nTesseract supports **[various image formats](https://tesseract-ocr.github.io/tessdoc/InputFormats)** including PNG, JPEG and TIFF.\n\nTesseract supports **various output formats**: plain text, hOCR (HTML), PDF, invisible-text-only PDF, TSV, ALTO and PAGE.\n\nYou should note that in many cases, in order to get better OCR results, you'll need to **[improve the quality](https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html) of the image** you are giving Tesseract.\n\nThis project **does not include a GUI application**. If you need one, please see the [3rdParty](https://tesseract-ocr.github.io/tessdoc/User-Projects-%E2%80%93-3rdParty.html) documentation.\n\nTesseract **can be trained to recognize other languages**.\nSee [Tesseract Training](https://tesseract-ocr.github.io/tessdoc/Training-Tesseract.html) for more information.\n\n## Brief history\n\nTesseract was originally developed at Hewlett-Packard Laboratories Bristol UK and at Hewlett-Packard Co, Greeley Colorado USA between 1985 and 1994, with some more changes made in 1996 to port to Windows, and some C++izing in 1998. In 2005 Tesseract was open sourced by HP. From 2006 until August 2017 it was developed by Google.\n\nMajor version 5 is the current stable version and started with release\n[5.0.0](https://github.com/tesseract-ocr/tesseract/releases/tag/5.0.0) on November 30, 2021. Newer minor versions and bugfix versions are available from\n[GitHub](https://github.com/tesseract-ocr/tesseract/releases/).\n\nLatest source code is available from [main branch on GitHub](https://github.com/tesseract-ocr/tesseract/tree/main).\nOpen issues can be found in [issue tracker](https://github.com/tesseract-ocr/tesseract/issues),\nand [planning documentation](https://tesseract-ocr.github.io/tessdoc/Planning.html).\n\nSee **[Release Notes](https://tesseract-ocr.github.io/tessdoc/ReleaseNotes.html)**\nand **[Change Log](https://github.com/tesseract-ocr/tesseract/blob/main/ChangeLog)** for more details of the releases.\n\n## Installing Tesseract\n\nYou can either [Install Tesseract via pre-built binary package](https://tesseract-ocr.github.io/tessdoc/Installation.html)\nor [build it from source](https://tesseract-ocr.github.io/tessdoc/Compiling.html).\n\nBefore building Tesseract from source, please check that your system has a compiler which is one of the [supported compilers](https://tesseract-ocr.github.io/tessdoc/supported-compilers.html).\n\n## Running Tesseract\n\nBasic **[command line usage](https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html)**:\n\n    tesseract imagename outputbase [-l lang] [--oem ocrenginemode] [--psm pagesegmode] [configfiles...]\n\nFor more information about the various command line options use `tesseract --help` or `man tesseract`.\n\nExamples can be found in the [documentation](https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html#simplest-invocation-to-ocr-an-image).\n\n## For developers\n\nDevelopers can use `libtesseract` [C](https://github.com/tesseract-ocr/tesseract/blob/main/include/tesseract/capi.h) or\n[C++](https://github.com/tesseract-ocr/tesseract/blob/main/include/tesseract/baseapi.h) API to build their own application. If you need bindings to `libtesseract` for other programming languages, please see the\n[wrapper](https://tesseract-ocr.github.io/tessdoc/AddOns.html#tesseract-wrappers) section in the AddOns documentation.\n\nDocumentation of Tesseract generated from source code by doxygen can be found on [tesseract-ocr.github.io](https://tesseract-ocr.github.io/).\n\n## Support\n\nBefore you submit an issue, please review **[the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/main/CONTRIBUTING.md)**.\n\nFor support, first read the [documentation](https://tesseract-ocr.github.io/tessdoc/),\nparticularly the [FAQ](https://tesseract-ocr.github.io/tessdoc/FAQ.html) to see if your problem is addressed there.\nIf not, search the [Tesseract user forum](https://groups.google.com/g/tesseract-ocr), the [Tesseract developer forum](https://groups.google.com/g/tesseract-dev) and [past issues](https://github.com/tesseract-ocr/tesseract/issues), and if you still can't find what you need, ask for support in the mailing-lists.\n\nMailing-lists:\n\n* [tesseract-ocr](https://groups.google.com/g/tesseract-ocr) - For tesseract users.\n* [tesseract-dev](https://groups.google.com/g/tesseract-dev) - For tesseract developers.\n\nPlease report an issue only for a **bug**, not for asking questions.\n\n## License\n\n    The code in this repository is licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n\n**NOTE**: This software depends on other packages that may be licensed under different open source licenses.\n\nTesseract uses [Leptonica library](http://leptonica.com/) which essentially\nuses a [BSD 2-clause license](http://leptonica.com/about-the-license.html).\n\n## Dependencies\n\nTesseract uses [Leptonica library](https://github.com/DanBloomberg/leptonica)\nfor opening input images (e.g. not documents like pdf).\nIt is suggested to use leptonica with built-in support for [zlib](https://zlib.net),\n[png](https://sourceforge.net/projects/libpng) and\n[tiff](http://www.simplesystems.org/libtiff) (for multipage tiff).\n\n## Latest Version of README\n\nFor the latest online version of the README.md see:\n\n<https://github.com/tesseract-ocr/tesseract/blob/main/README.md>\n",
      "stars_today": 26
    },
    {
      "id": 498083946,
      "name": "tulipcc",
      "full_name": "shorepine/tulipcc",
      "description": "The Tulip Creative Computer - a portable Python synthesizer for music and graphics",
      "html_url": "https://github.com/shorepine/tulipcc",
      "stars": 815,
      "forks": 40,
      "language": "C",
      "topics": [
        "computer",
        "esp32",
        "hardware",
        "micropython",
        "music",
        "portable",
        "python",
        "synthesizer"
      ],
      "created_at": "2022-05-30T20:12:37Z",
      "updated_at": "2026-01-15T22:20:43Z",
      "pushed_at": "2026-01-16T00:01:09Z",
      "open_issues": 41,
      "owner": {
        "login": "shorepine",
        "avatar_url": "https://avatars.githubusercontent.com/u/173280013?v=4"
      },
      "readme": "# Tulip Creative Computer - a portable programmable device for music, graphics, code and writing\n\n![Tulip](https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/tulip_hero.jpg)\n\nWelcome to the Tulip Creative Computer (Tulip CC)!\n \nTulip is a low power and affordable self-contained portable computer, with a touchscreen display and sound. It's fully programmable - you write code to define your music, games or anything else you can think of. It boots instantaneously into a Python prompt with a lot of built in support for music synthesis, fast graphics and text, hardware MIDI, network access and external sensors. Dive right into making something without distractions or complications. \n\nThe entire system is dedicated to your code, the display and sound, running in real time, on specialized hardware. The hardware and software are fully open source and anyone can [buy one](https://tulip.computer/) or [build one](docs/tulip_build.md). You can use Tulip to make music, code, art, games, or just write. \n\nYou can now even [run Tulip on the web](https://tulip.computer/run) and share your creations with anyone!\n\nTulip is powered by [MicroPython](https://micropython.org), [AMY](https://github.com/shorepine/amy), and [LVGL](https://lvgl.io). The Tulip hardware runs on the ESP32-S3 chip using the [ESP-IDF](https://github.com/espressif/esp-idf).\n\n * [**Get a Tulip** from our friends at Makerfabs for only US$59](https://tulip.computer)\n * [Just got a Tulip CC? **Check out our getting started guide!**](docs/getting_started.md)\n * [Want to make music with your Tulip? **See our music tutorial**](docs/music.md)\n * [See the full **Tulip API**](docs/tulip_api.md)\n * [**Try out Tulip on the web!**](https://tulip.computer/run/)\n\n [![shore pine sound systems discord](https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/shorepine100.png) **Chat about Tulip on our Discord!**](https://discord.gg/TzBFkUb8pG)\n\n**Check out this video!**\n\n[![Tulip, a musical computer based on Micropython\n](https://i.ytimg.com/vi/1lYFjQp7Xrw/maxresdefault.jpg)](https://www.youtube.com/watch?v=1lYFjQp7Xrw \"Tulip, a musical computer based on Micropython\")\n\nYou can use Tulip one of three ways:\n * Tulip is available both as an [off the shelf or DIY hardware project (Tulip CC)](https://tulip.computer/)\n * [Tulip runs on the web](https://tulip.computer/run) with (almost) all the same features. \n * Tulip can also run as a native app for Mac or Linux (or WSL in Windows) as [Tulip Desktop](docs/tulip_desktop.md)\n\nIf you're nervous about getting or building the hardware, [try it out on the web!](https://tulip.computer/run)\n\n[![Tulip Web](https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/tulipweb.png)](https://tulip.computer/run/)\n\nThe hardware Tulip CC supports:\n\n- 8.5MB of RAM - 2MB is available to MicroPython, and 1.5MB is available for OS memory. The rest is used for the graphics framebuffers (which you can use as storage) and the firmware cache. \n- 32MB flash storage, as a filesystem accesible in Python (24MB left over after OS in ROM)\n- An [AMY](https://github.com/shorepine/amy) stereo 120-voice synthesizer engine running locally, or as a wireless controller for an [Alles](https://github.com/shorepine/alles) mesh. Tulip's synth supports additive and subtractive oscillators, an excellent FM synthesis engine, samplers, karplus-strong, high quality analog style filters, a sequencer, and much more. We ship Tulip with a drum machine, voices / patch app, and Juno-6 editor.\n- Text frame buffer layer, 128 x 50, with ANSI support for 256 colors, inverse, bold, underline, background color\n- Up to 32 sprites on screen, drawn per scanline, with collision detection, from a total of 32KB of bitmap memory (1 byte per pixel)\n- A 1024 (+128 overscan) by 600 (+100 overscan) background frame buffer to draw arbitrary bitmaps to, or use as RAM, and which can scroll horizontally / vertically\n- WiFi, access http via Python requests or TCP / UDP sockets \n- Adjustable display clock and resolution, defaults to 30 FPS at 1024x600.\n- 256 colors\n- Can load PNGs from disk to set sprites or background, or generate bitmap data from code\n- Built in code and text editor\n- Built in BBS chat room and file transfer area called **TULIP ~ WORLD**\n- USB keyboard, MIDI and mouse support, including hubs \n- Capactive multi-touch support (mouse on Tulip Desktop and Tulip Web)\n- MIDI input and output\n- I2C / Grove / Mabee connector, compatible with [many I2C devices like joysticks, keyboard, GPIO, DACs, ADCs, hubs](docs/tulip_api.md#i2c--grove--mabee)\n- 575mA power usage @ 5V including display, at medium display brightness, can last for hours on LiPo, 18650s, or USB battery pack \n\nI've been working on Tulip on and off for years over many hardware iterations and hope that someone out there finds it as fun as I have, either making things with Tulip or working on Tulip itself. I'd love feedback, your own Tulip experiments or pull requests to improve the system.\n\n![Tulip](https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/tulip4.png)\n\n\n * [**Any issues with your Tulip CC? Here's our troubleshooting guide**](docs/troubleshooting.md)\n * [**Learn about our roadmap and find out what we're working on next**](https://github.com/orgs/shorepine/projects/1)\n * [**Build your own Tulip**](docs/tulip_build.md)\n * **[You can read more about the \"why\" or \"how\" of Tulip on my website!](https://notes.variogram.com/2024/07/30/tulip-available/)** \n\n\n## T-Deck Tulip CC\n\n![T-Deck](docs/pics/tdeck_editor.jpg)\n\nA **new** small option: get yourself a [T-Deck](https://www.aliexpress.us/item/3256805505920840.html?gatewayAdapt=glo2usa4itemAdapt) and install Tulip CC on it directly! [Check out our T-Deck page for more detail.](tulip/tdeck/README.md)\n\n\n## Getting started\n\nOnce you've [bought a Tulip](https://tulip.computer), [opened Tulip Web](https://tulip.computer/run), [built a Tulip](docs/tulip_build.md) or [installed Tulip Desktop](docs/tulip_desktop.md), you'll see that Tulip boots right into a Python prompt and all interaction with the system happens there. You can make your own Python programs with Tulip's built in editor and execute them, or just experiment on the Tulip REPL prompt in real time.\n\n[**See the full Tulip API**](docs/tulip_api.md) for more details on all the graphics, sound and input functions.\n\nBelow are a few getting started tips and small examples. The [full API](docs/tulip_api.md) page has more detail on everything you can do on a Tulip. [**See a more complete getting started page**](docs/getting_started.md) or [**a music making tutorial**](docs/music.md) as well!\n\n\n\n```python\n# Run a saved Python file. Control-C stops it\ncd('ex') # The ex folder has a few examples and graphics in it\nexecfile(\"parallax.py\")\n# If you want to run a Tulip package (folder with other files in it)\nrun(\"game\")\n```\n\n### The Tulip Editor\n\nTulip ships with a text editor, based on pico/nano. It supports syntax highlighting, search, save/save-as. \n\n```python\n# Opens the Tulip editor to the given filename. \nedit(\"game.py\")\n```\n\n![Editor](https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/editor.png)\n\n\n### Input and user interface\n\nTulip supports USB keyboard and mice input as well as touch input. (On Tulip Desktop and Web, mouse clicks act as touch points.) It also comes with UI elements like buttons and sliders to use in your applications, and a way to run mulitple applications as once using callbacks. More in the [full API](docs/tulip_api.md).\n\n```python\n(x0, y0, x1, y1, x2, y2) = tulip.touch()\n```\n\n![UI demo](https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/sliders.png)\n\n\n### Network\n\nTulip CC has the capability to connect to a Wi-Fi network, and Python's native requests library will work to access TCP and UDP. We ship a few convenience functions to grab data from URLs as well. More in the [full API](docs/tulip_api.md).\n\n```python\n# Join a wifi network (not needed on Tulip Desktop or Web)\ntulip.wifi(\"ssid\", \"password\")\n\n# Get IP address or check if connected\nip_address = tulip.ip() # returns None if not connected\n\n# Save the contents of a URL to disk (needs wifi)\nbytes_read = tulip.url_save(\"https://url\", \"filename.ext\")\n```\n\n\n### Music / sound\n\nTulip comes with the AMY synthesizer, a very full featured 120-oscillator synth that supports FM, PCM, additive synthesis, partial synthesis, filters, and much more. We also provide a useful \"music computer\" for scales, chords and progressions. More in the [full API](docs/tulip_api.md) and in the [music tutorial.](docs/music.md) Tulip's version of AMY comes with stereo sound, which you can set per oscillator with the `pan` parameter.\n\n```python\namy.drums() # plays a test song\namy.send(volume=4) # change volume\namy.reset() # stops all music / sounds playing\n```\nhttps://user-images.githubusercontent.com/76612/215893940-658144b7-0c6f-42e2-9836-bd271597aab3.mov\n\n\n### MIDI\n\nTulip supports MIDI in and out to connect to external music hardware. You can set up a Python callback to respond immediately to any incoming MIDI message. You can also send messages out to MIDI out. More in the [full API](docs/tulip_api.md) and [music tutorial](docs/music.md).\n\n```python\nm = tulip.midi_in() # returns bytes of the last MIDI message received\ntulip.midi_out((144,60,127)) # sends a note on message\ntulip.midi_out(bytes) # Can send bytes or list\n```\n\n### Graphics system\n\nThe Tulip GPU supports a scrolling background layer, hardware sprites, and a text layer. Much more in the [full API](docs/tulip_api.md).\n\n```python\n# Set or get a pixel on the BG\npal_idx = tulip.bg_pixel(x,y)\n\n# Set the contents of a PNG file on the background.\ntulip.bg_png(png_filename, x, y)\n\ntulip.bg_scroll(line, x_offset, y_offset, x_speed, y_speed)\n```\n\nhttps://user-images.githubusercontent.com/76612/215895305-7b02ad27-b02a-429a-92ef-f13136e9f9d2.mov\n\n\nHardware sprites are supported. They draw over the background and text layer per scanline per frame:\n\n```python\n(w, h, bytes) = tulip.sprite_png(\"filename.png\", mem_pos)\n\n...\n\n# Set a sprite x and y position\ntulip.sprite_move(12, x, y)\n```\n\nhttps://user-images.githubusercontent.com/76612/215896311-fc0823aa-44bc-4305-85db-a6773db11a98.mov\n\n\n### Tulip World\n\nStill very much early days, but Tulip supports a native chat and file sharing BBS called **TULIP ~ WORLD** where you can hang out with other Tulip owners. You're able to pull down the latest messages and files and send messages and files yourself. More in the [full API](docs/tulip_api.md).\n\n```python\nimport world\nworld.post_message(\"hello!!\") # Sends a message to Tulip World. username required. will prompt if not set\nworld.upload(filename) # Uploads a file to Tulip World. username required\nworld.ls() # lists most recent unique filenames/usernames\n```\n\n## How to build, compile and help develop Tulip\n\n * [Get a Tulip!](https://tulip.computer)\n * [Build your own Tulip Creative Computer](docs/tulip_build.md) with FOUR different options.\n * [How to compile and flash Tulip hardware](docs/tulip_flashing.md)\n * [How to run or compile Tulip Desktop](docs/tulip_desktop.md)\n * [The full Tulip API](docs/tulip_api.md)\n * [File any code issues or pull requests!](https://github.com/shorepine/tulipcc/issues)\n\n[![shore pine sound systems discord](https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/shorepine100.png) **Chat about Tulip on our Discord!**](https://discord.gg/TzBFkUb8pG)\n\nTwo important development guidelines if you'd like to help contribute!\n\n * Be nice and helpful and don't be afraid to ask questions! We're all doing this for fun and to learn. \n * Any change or feature must be equivalent across Tulip Desktop and Tulip CC. There are of course limited exceptions to this rule, but please test on hardware before proposing a new feature / change. \n\nHave fun!\n\n![Tulip](https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/tulip4.png)\n\n\n\n\n\n\n\n\n",
      "stars_today": 25
    },
    {
      "id": 942756187,
      "name": "easy-dataset",
      "full_name": "ConardLi/easy-dataset",
      "description": "A powerful tool for creating datasets for LLM fine-tuning ã€RAG and Eval",
      "html_url": "https://github.com/ConardLi/easy-dataset",
      "stars": 12825,
      "forks": 1254,
      "language": "JavaScript",
      "topics": [
        "dataset",
        "fine-tuning",
        "javascript",
        "llm",
        "rag"
      ],
      "created_at": "2025-03-04T16:14:14Z",
      "updated_at": "2026-01-15T20:59:10Z",
      "pushed_at": "2026-01-14T14:54:21Z",
      "open_issues": 106,
      "owner": {
        "login": "ConardLi",
        "avatar_url": "https://avatars.githubusercontent.com/u/30708545?v=4"
      },
      "readme": "<div align=\"center\">\n\n![](./public//imgs/bg2.png)\n\n<img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/ConardLi/easy-dataset\">\n<img alt=\"GitHub Downloads (all assets, all releases)\" src=\"https://img.shields.io/github/downloads/ConardLi/easy-dataset/total\">\n<img alt=\"GitHub Release\" src=\"https://img.shields.io/github/v/release/ConardLi/easy-dataset\">\n<img src=\"https://img.shields.io/badge/license-AGPL--3.0-green.svg\" alt=\"AGPL 3.0 License\"/>\n<img alt=\"GitHub contributors\" src=\"https://img.shields.io/github/contributors/ConardLi/easy-dataset\">\n<img alt=\"GitHub last commit\" src=\"https://img.shields.io/github/last-commit/ConardLi/easy-dataset\">\n<a href=\"https://arxiv.org/abs/2507.04009v1\" target=\"_blank\">\n  <img src=\"https://img.shields.io/badge/arXiv-2507.04009-b31b1b.svg\" alt=\"arXiv:2507.04009\">\n</a>\n\n<a href=\"https://trendshift.io/repositories/13944\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13944\" alt=\"ConardLi%2Feasy-dataset | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n**A powerful tool for creating fine-tuning datasets for Large Language Models**\n\n[ç®€ä½“ä¸­æ–‡](./README.zh-CN.md) | [English](./README.md) | [TÃ¼rkÃ§e](./README.tr.md)\n\n[Features](#features) â€¢ [Quick Start](#local-run) â€¢ [Documentation](https://docs.easy-dataset.com/ed/en) â€¢ [Contributing](#contributing) â€¢ [License](#license)\n\nIf you like this project, please give it a Starâ­ï¸, or buy the author a coffee => [Donate](./public/imgs/aw.jpg) â¤ï¸!\n\n</div>\n\n## Overview\n\nEasy Dataset is an application specifically designed for building large language model (LLM) datasets. It features an intuitive interface, along with built-in powerful document parsing tools, intelligent segmentation algorithms, data cleaning and augmentation capabilities. The application can convert domain-specific documents in various formats into high-quality structured datasets, which are applicable to scenarios such as model fine-tuning, retrieval-augmented generation (RAG), and model performance evaluation.\n\n![](./public/imgs/arc3.png)\n\n## News\n\nğŸ‰ğŸ‰ Easy Dataset Version 1.7.0 launches brand-new evaluation capabilities! You can effortlessly convert domain-specific documents into evaluation datasets (test sets) and automatically run multi-dimensional evaluation tasks. Additionally, it comes with a human blind test system, enabling you to easily meet needs such as vertical domain model evaluation, post-fine-tuning model performance assessment, and RAG recall rate evaluation. Tutorial: [https://www.bilibili.com/video/BV1CRrVB7Eb4/](https://www.bilibili.com/video/BV1CRrVB7Eb4/)\n\n## Features\n\n### ğŸ“„ Document Processing & Data Generation\n\n- **Intelligent Document Processing**: Supports PDF, Markdown, DOCX, TXT, EPUB and more formats with intelligent recognition\n- **Intelligent Text Splitting**: Multiple splitting algorithms (Markdown structure, recursive separators, fixed length, code-aware chunking), with customizable visual segmentation\n- **Intelligent Question Generation**: Auto-extract relevant questions from text segments, with question templates and batch generation\n- **Domain Label Tree**: Intelligently builds global domain label trees based on document structure, with auto-tagging capabilities\n- **Answer Generation**: Uses LLM API to generate comprehensive answers and Chain of Thought (COT), with AI optimization\n- **Data Cleaning**: Intelligent text cleaning to remove noise and improve data quality\n\n### ğŸ”„ Multiple Dataset Types\n\n- **Single-Turn QA Datasets**: Standard question-answer pairs for basic fine-tuning\n- **Multi-Turn Dialogue Datasets**: Customizable roles and scenarios for conversational format\n- **Image QA Datasets**: Generate visual QA data from images, with multiple import methods (directory, PDF, ZIP)\n- **Data Distillation**: Generate label trees and questions directly from domain topics without uploading documents\n\n### ğŸ“Š Model Evaluation System\n\n- **Evaluation Datasets**: Generate true/false, single-choice, multiple-choice, short-answer, and open-ended questions\n- **Automated Model Evaluation**: Use Judge Model to automatically evaluate model answer quality with customizable scoring rules\n- **Human Blind Test (Arena)**: Double-blind comparison of two models' answers for unbiased evaluation\n- **AI Quality Assessment**: Automatic quality scoring and filtering of generated datasets\n\n### ğŸ› ï¸ Advanced Features\n\n- **Custom Prompts**: Project-level customization of all prompt templates (question generation, answer generation, data cleaning, etc.)\n- **GA Pair Generation**: Genre-Audience pair generation to enrich data diversity\n- **Task Management Center**: Background batch task processing with monitoring and interruption support\n- **Resource Monitoring Dashboard**: Token consumption statistics, API call tracking, model performance analysis\n- **Model Testing Playground**: Compare up to 3 models simultaneously\n\n### ğŸ“¤ Export & Integration\n\n- **Multiple Export Formats**: Alpaca, ShareGPT, Multilingual-Thinking formats with JSON/JSONL file types\n- **Balanced Export**: Configure export counts per tag for dataset balancing\n- **LLaMA Factory Integration**: One-click LLaMA Factory configuration file generation\n- **Hugging Face Upload**: Direct upload datasets to Hugging Face Hub\n\n### ğŸ¤– Model Support\n\n- **Wide Model Compatibility**: Compatible with all LLM APIs that follow the OpenAI format\n- **Multi-Provider Support**: OpenAI, Ollama (local models), Zhipu AI, Alibaba Bailian, OpenRouter, and more\n- **Vision Models**: Support Gemini, Claude, etc. for PDF parsing and image QA\n\n### ğŸŒ User Experience\n\n- **User-Friendly Interface**: Modern, intuitive UI designed for both technical and non-technical users\n- **Multi-Language Support**: Complete Chinese, English, and Turkish language support ğŸ‡¹ğŸ‡·\n- **Dataset Square**: Discover and explore public dataset resources\n- **Desktop Clients**: Available for Windows, macOS, and Linux\n\n## Quick Demo\n\nhttps://github.com/user-attachments/assets/6ddb1225-3d1b-4695-90cd-aa4cb01376a8\n\n## Local Run\n\n### Download Client\n\n<table style=\"width: 100%\">\n  <tr>\n    <td width=\"20%\" align=\"center\">\n      <b>Windows</b>\n    </td>\n    <td width=\"30%\" align=\"center\" colspan=\"2\">\n      <b>MacOS</b>\n    </td>\n    <td width=\"20%\" align=\"center\">\n      <b>Linux</b>\n    </td>\n  </tr>\n  <tr style=\"text-align: center\">\n    <td align=\"center\" valign=\"middle\">\n      <a href='https://github.com/ConardLi/easy-dataset/releases/latest'>\n        <img src='./public/imgs/windows.png' style=\"height:24px; width: 24px\" />\n        <br />\n        <b>Setup.exe</b>\n      </a>\n    </td>\n    <td align=\"center\" valign=\"middle\">\n      <a href='https://github.com/ConardLi/easy-dataset/releases/latest'>\n        <img src='./public/imgs/mac.png' style=\"height:24px; width: 24px\" />\n        <br />\n        <b>Intel</b>\n      </a>\n    </td>\n    <td align=\"center\" valign=\"middle\">\n      <a href='https://github.com/ConardLi/easy-dataset/releases/latest'>\n        <img src='./public/imgs/mac.png' style=\"height:24px; width: 24px\" />\n        <br />\n        <b>M</b>\n      </a>\n    </td>\n    <td align=\"center\" valign=\"middle\">\n      <a href='https://github.com/ConardLi/easy-dataset/releases/latest'>\n        <img src='./public/imgs/linux.png' style=\"height:24px; width: 24px\" />\n        <br />\n        <b>AppImage</b>\n      </a>\n    </td>\n  </tr>\n</table>\n\n### Install with NPM\n\n1. Clone the repository:\n\n```bash\n   git clone https://github.com/ConardLi/easy-dataset.git\n   cd easy-dataset\n```\n\n2. Install dependencies:\n\n```bash\n   npm install\n```\n\n3. Start the development server:\n\n```bash\n   npm run build\n\n   npm run start\n```\n\n4. Open your browser and visit `http://localhost:1717`\n\n### Using the Official Docker Image\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/ConardLi/easy-dataset.git\ncd easy-dataset\n```\n\n2. Modify the `docker-compose.yml` file:\n\n```yml\nservices:\n  easy-dataset:\n    image: ghcr.io/conardli/easy-dataset\n    container_name: easy-dataset\n    ports:\n      - '1717:1717'\n    volumes:\n      - ./local-db:/app/local-db\n      - ./prisma:/app/prisma\n    restart: unless-stopped\n```\n\n> **Note:** It is recommended to use the `local-db` and `prisma` folders in the current code repository directory as mount paths to maintain consistency with the database paths when starting via NPM.\n\n> **Note:** The database file will be automatically initialized on first startup, no need to manually run `npm run db:push`.\n\n3. Start with docker-compose:\n\n```bash\ndocker-compose up -d\n```\n\n4. Open a browser and visit `http://localhost:1717`\n\n### Building with a Local Dockerfile\n\nIf you want to build the image yourself, use the Dockerfile in the project root directory:\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/ConardLi/easy-dataset.git\ncd easy-dataset\n```\n\n2. Build the Docker image:\n\n```bash\ndocker build -t easy-dataset .\n```\n\n3. Run the container:\n\n```bash\ndocker run -d \\\n  -p 1717:1717 \\\n  -v ./local-db:/app/local-db \\\n  -v ./prisma:/app/prisma \\\n  --name easy-dataset \\\n  easy-dataset\n```\n\n> **Note:** It is recommended to use the `local-db` and `prisma` folders in the current code repository directory as mount paths to maintain consistency with the database paths when starting via NPM.\n\n> **Note:** The database file will be automatically initialized on first startup, no need to manually run `npm run db:push`.\n\n4. Open a browser and visit `http://localhost:1717`\n\n## Documentation\n\n- View the demo video of this project: [Easy Dataset Demo Video](https://www.bilibili.com/video/BV1y8QpYGE57/)\n- For detailed documentation on all features and APIs, visit our [Documentation Site](https://docs.easy-dataset.com/ed/en)\n- View the paper of this project: [Easy Dataset: A Unified and Extensible Framework for Synthesizing LLM Fine-Tuning Data from Unstructured Documents](https://arxiv.org/abs/2507.04009v1)\n\n## Community Practice\n\n- [Complete test set generation and model evaluation with Easy Dataset](https://www.bilibili.com/video/BV1CRrVB7Eb4/)\n- [Easy Dataset Ã— LLaMA Factory: Enabling LLMs to Efficiently Learn Domain Knowledge](https://buaa-act.feishu.cn/wiki/GVzlwYcRFiR8OLkHbL6cQpYin7g)\n- [Easy Dataset Practical Guide: How to Build High-Quality Datasets?](https://www.bilibili.com/video/BV1MRMnz1EGW)\n- [Interpretation of Key Feature Updates in Easy Dataset](https://www.bilibili.com/video/BV1fyJhzHEb7/)\n- [Foundation Models Fine-tuning Datasets: Basic Knowledge Popularization](https://docs.easy-dataset.com/zhi-shi-ke-pu)\n\n## Contributing\n\nWe welcome contributions from the community! If you'd like to contribute to Easy Dataset, please follow these steps:\n\n1. Fork the repository\n2. Create a new branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Commit your changes (`git commit -m 'Add some amazing feature'`)\n5. Push to the branch (`git push origin feature/amazing-feature`)\n6. Open a Pull Request (submit to the DEV branch)\n\nPlease ensure that tests are appropriately updated and adhere to the existing coding style.\n\n## Join Discussion Group & Contact the Author\n\nhttps://docs.easy-dataset.com/geng-duo/lian-xi-wo-men\n\n## License\n\nThis project is licensed under the AGPL 3.0 License - see the [LICENSE](LICENSE) file for details.\n\n## Citation\n\nIf this work is helpful, please kindly cite as:\n\n```bibtex\n@misc{miao2025easydataset,\n  title={Easy Dataset: A Unified and Extensible Framework for Synthesizing LLM Fine-Tuning Data from Unstructured Documents},\n  author={Ziyang Miao and Qiyu Sun and Jingyuan Wang and Yuchen Gong and Yaowei Zheng and Shiqi Li and Richong Zhang},\n  year={2025},\n  eprint={2507.04009},\n  archivePrefix={arXiv},\n  primaryClass={cs.CL},\n  url={https://arxiv.org/abs/2507.04009}\n}\n```\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=ConardLi/easy-dataset&type=Date)](https://www.star-history.com/#ConardLi/easy-dataset&Date)\n\n<div align=\"center\">\n  <sub>Built with â¤ï¸ by <a href=\"https://github.com/ConardLi\">ConardLi</a> â€¢ Follow me: <a href=\"./public/imgs/weichat.jpg\">WeChat Official Account</a>ï½œ<a href=\"https://space.bilibili.com/474921808\">Bilibili</a>ï½œ<a href=\"https://juejin.cn/user/3949101466785709\">Juejin</a>ï½œ<a href=\"https://www.zhihu.com/people/wen-ti-chao-ji-duo-de-xiao-qi\">Zhihu</a>ï½œ<a href=\"https://www.youtube.com/@garden-conard\">Youtube</a></sub>\n</div>\n",
      "stars_today": 24
    },
    {
      "id": 27193779,
      "name": "node",
      "full_name": "nodejs/node",
      "description": "Node.js JavaScript runtime âœ¨ğŸ¢ğŸš€âœ¨",
      "html_url": "https://github.com/nodejs/node",
      "stars": 115219,
      "forks": 34384,
      "language": "JavaScript",
      "topics": [
        "javascript",
        "js",
        "linux",
        "macos",
        "mit",
        "node",
        "nodejs",
        "runtime",
        "windows"
      ],
      "created_at": "2014-11-26T19:57:11Z",
      "updated_at": "2026-01-16T00:31:26Z",
      "pushed_at": "2026-01-15T23:20:50Z",
      "open_issues": 2440,
      "owner": {
        "login": "nodejs",
        "avatar_url": "https://avatars.githubusercontent.com/u/9950313?v=4"
      },
      "readme": "# Node.js\n\nNode.js is an open-source, cross-platform JavaScript runtime environment.\n\nFor information on using Node.js, see the [Node.js website][].\n\nThe Node.js project uses an [open governance model](./GOVERNANCE.md). The\n[OpenJS Foundation][] provides support for the project.\n\nContributors are expected to act in a collaborative manner to move\nthe project forward. We encourage the constructive exchange of contrary\nopinions and compromise. The [TSC](./GOVERNANCE.md#technical-steering-committee)\nreserves the right to limit or block contributors who repeatedly act in ways\nthat discourage, exhaust, or otherwise negatively affect other participants.\n\n**This project has a [Code of Conduct][].**\n\n## Table of contents\n\n* [Support](#support)\n* [Release types](#release-types)\n  * [Download](#download)\n    * [Current and LTS releases](#current-and-lts-releases)\n    * [Nightly releases](#nightly-releases)\n    * [API documentation](#api-documentation)\n  * [Verifying binaries](#verifying-binaries)\n* [Building Node.js](#building-nodejs)\n* [Security](#security)\n* [Contributing to Node.js](#contributing-to-nodejs)\n* [Current project team members](#current-project-team-members)\n  * [TSC (Technical Steering Committee)](#tsc-technical-steering-committee)\n  * [Collaborators](#collaborators)\n  * [Triagers](#triagers)\n  * [Release keys](#release-keys)\n* [License](#license)\n\n## Support\n\nLooking for help? Check out the\n[instructions for getting support](.github/SUPPORT.md).\n\n## Release types\n\n* **Current**: Under active development. Code for the Current release is in the\n  branch for its major version number (for example,\n  [v22.x](https://github.com/nodejs/node/tree/v22.x)). Node.js releases a new\n  major version every 6 months, allowing for breaking changes. This happens in\n  April and October every year. Releases appearing each October have a support\n  life of 8 months. Releases appearing each April convert to LTS (see below)\n  each October.\n* **LTS**: Releases that receive Long Term Support, with a focus on stability\n  and security. Every even-numbered major version will become an LTS release.\n  LTS releases receive 12 months of _Active LTS_ support and a further 18 months\n  of _Maintenance_. LTS release lines have alphabetically-ordered code names,\n  beginning with v4 Argon. There are no breaking changes or feature additions,\n  except in some special circumstances.\n* **Nightly**: Code from the Current branch built every 24-hours when there are\n  changes. Use with caution.\n\nCurrent and LTS releases follow [semantic versioning](https://semver.org). A\nmember of the Release Team [signs](#release-keys) each Current and LTS release.\nFor more information, see the\n[Release README](https://github.com/nodejs/Release#readme).\n\n### Download\n\nBinaries, installers, and source tarballs are available at\n<https://nodejs.org/en/download/>.\n\n#### Current and LTS releases\n\n<https://nodejs.org/download/release/>\n\nThe [latest](https://nodejs.org/download/release/latest/) directory is an\nalias for the latest Current release. The latest-_codename_ directory is an\nalias for the latest release from an LTS line. For example, the\n[latest-hydrogen](https://nodejs.org/download/release/latest-hydrogen/)\ndirectory contains the latest Hydrogen (Node.js 18) release.\n\n#### Nightly releases\n\n<https://nodejs.org/download/nightly/>\n\nEach directory and filename includes the version (e.g., `v22.0.0`),\nfollowed by the UTC date (e.g., `20240424` for April 24, 2024),\nand the short commit SHA of the HEAD of the release (e.g., `ddd0a9e494`).\nFor instance, a full directory name might look like `v22.0.0-nightly20240424ddd0a9e494`.\n\n#### API documentation\n\nDocumentation for the latest Current release is at <https://nodejs.org/api/>.\nVersion-specific documentation is available in each release directory in the\n_docs_ subdirectory. Version-specific documentation is also at\n<https://nodejs.org/download/docs/>.\n\n### Verifying binaries\n\nDownload directories contain a `SHASUMS256.txt.asc` file with SHA checksums for the\nfiles and the releaser PGP signature.\n\nYou can get a trusted keyring from nodejs/release-keys, e.g. using `curl`:\n\n```bash\ncurl -fsLo \"/path/to/nodejs-keyring.kbx\" \"https://github.com/nodejs/release-keys/raw/HEAD/gpg/pubring.kbx\"\n```\n\nAlternatively, you can import the releaser keys in your default keyring, see\n[Release keys](#release-keys) for commands to how to do that.\n\nThen, you can verify the files you've downloaded locally\n(if you're using your default keyring, pass `--keyring=\"${GNUPGHOME:-~/.gnupg}/pubring.kbx\"`):\n\n```bash\ncurl -fsO \"https://nodejs.org/dist/${VERSION}/SHASUMS256.txt.asc\" \\\n&& gpgv --keyring=\"/path/to/nodejs-keyring.kbx\" --output SHASUMS256.txt < SHASUMS256.txt.asc \\\n&& shasum --check SHASUMS256.txt --ignore-missing\n```\n\n## Building Node.js\n\nSee [BUILDING.md](BUILDING.md) for instructions on how to build Node.js from\nsource and a list of supported platforms.\n\n## Security\n\nFor information on reporting security vulnerabilities in Node.js, see\n[SECURITY.md](./SECURITY.md).\n\n## Contributing to Node.js\n\n* [Contributing to the project][]\n* [Working Groups][]\n* [Strategic initiatives][]\n* [Technical values and prioritization][]\n\n## Current project team members\n\nFor information about the governance of the Node.js project, see\n[GOVERNANCE.md](./GOVERNANCE.md).\n\n<!-- node-core-utils and find-inactive-tsc.mjs depend on the format of the TSC\n     list. If the format changes, those utilities need to be tested and\n     updated. -->\n\n### TSC (Technical Steering Committee)\n\n#### TSC voting members\n\n<!--lint disable prohibited-strings-->\n\n* [aduh95](https://github.com/aduh95) -\n  **Antoine du Hamel** <<duhamelantoine1995@gmail.com>> (he/him)\n* [anonrig](https://github.com/anonrig) -\n  **Yagiz Nizipli** <<yagiz@nizipli.com>> (he/him)\n* [benjamingr](https://github.com/benjamingr) -\n  **Benjamin Gruenbaum** <<benjamingr@gmail.com>>\n* [BridgeAR](https://github.com/BridgeAR) -\n  **Ruben Bridgewater** <<ruben@bridgewater.de>> (he/him)\n* [gireeshpunathil](https://github.com/gireeshpunathil) -\n  **Gireesh Punathil** <<gpunathi@in.ibm.com>> (he/him)\n* [jasnell](https://github.com/jasnell) -\n  **James M Snell** <<jasnell@gmail.com>> (he/him)\n* [joyeecheung](https://github.com/joyeecheung) -\n  **Joyee Cheung** <<joyeec9h3@gmail.com>> (she/her)\n* [legendecas](https://github.com/legendecas) -\n  **Chengzhong Wu** <<legendecas@gmail.com>> (he/him)\n* [marco-ippolito](https://github.com/marco-ippolito) -\n  **Marco Ippolito** <<marcoippolito54@gmail.com>> (he/him)\n* [mcollina](https://github.com/mcollina) -\n  **Matteo Collina** <<matteo.collina@gmail.com>> (he/him)\n* [panva](https://github.com/panva) -\n  **Filip Skokan** <<panva.ip@gmail.com>> (he/him)\n* [RafaelGSS](https://github.com/RafaelGSS) -\n  **Rafael Gonzaga** <<rafael.nunu@hotmail.com>> (he/him)\n* [RaisinTen](https://github.com/RaisinTen) -\n  **Darshan Sen** <<raisinten@gmail.com>> (he/him)\n* [richardlau](https://github.com/richardlau) -\n  **Richard Lau** <<richard.lau@ibm.com>>\n* [ronag](https://github.com/ronag) -\n  **Robert Nagy** <<ronagy@icloud.com>>\n* [ruyadorno](https://github.com/ruyadorno) -\n  **Ruy Adorno** <<ruy@vlt.sh>> (he/him)\n* [ShogunPanda](https://github.com/ShogunPanda) -\n  **Paolo Insogna** <<paolo@cowtech.it>> (he/him)\n* [targos](https://github.com/targos) -\n  **MichaÃ«l Zasso** <<targos@protonmail.com>> (he/him)\n* [tniessen](https://github.com/tniessen) -\n  **Tobias NieÃŸen** <<tniessen@tnie.de>> (he/him)\n\n#### TSC regular members\n\n* [BethGriggs](https://github.com/BethGriggs) -\n  **Beth Griggs** <<bethanyngriggs@gmail.com>> (she/her)\n* [bnoordhuis](https://github.com/bnoordhuis) -\n  **Ben Noordhuis** <<info@bnoordhuis.nl>>\n* [cjihrig](https://github.com/cjihrig) -\n  **Colin Ihrig** <<cjihrig@gmail.com>> (he/him)\n* [codebytere](https://github.com/codebytere) -\n  **Shelley Vohr** <<shelley.vohr@gmail.com>> (she/her)\n* [GeoffreyBooth](https://github.com/GeoffreyBooth) -\n  **Geoffrey Booth** <<webadmin@geoffreybooth.com>> (he/him)\n* [MoLow](https://github.com/MoLow) -\n  **Moshe Atlow** <<moshe@atlow.co.il>> (he/him)\n* [Trott](https://github.com/Trott) -\n  **Rich Trott** <<rtrott@gmail.com>> (he/him)\n\n<details>\n\n<summary>TSC emeriti members</summary>\n\n#### TSC emeriti members\n\n* [addaleax](https://github.com/addaleax) -\n  **Anna Henningsen** <<anna@addaleax.net>> (she/her)\n* [apapirovski](https://github.com/apapirovski) -\n  **Anatoli Papirovski** <<apapirovski@mac.com>> (he/him)\n* [ChALkeR](https://github.com/ChALkeR) -\n  **Ğ¡ĞºĞ¾Ğ²Ğ¾Ñ€Ğ¾Ğ´Ğ° ĞĞ¸ĞºĞ¸Ñ‚Ğ° ĞĞ½Ğ´Ñ€ĞµĞµĞ²Ğ¸Ñ‡** <<chalkerx@gmail.com>> (he/him)\n* [chrisdickinson](https://github.com/chrisdickinson) -\n  **Chris Dickinson** <<christopher.s.dickinson@gmail.com>>\n* [danbev](https://github.com/danbev) -\n  **Daniel Bevenius** <<daniel.bevenius@gmail.com>> (he/him)\n* [danielleadams](https://github.com/danielleadams) -\n  **Danielle Adams** <<adamzdanielle@gmail.com>> (she/her)\n* [evanlucas](https://github.com/evanlucas) -\n  **Evan Lucas** <<evanlucas@me.com>> (he/him)\n* [fhinkel](https://github.com/fhinkel) -\n  **Franziska Hinkelmann** <<franziska.hinkelmann@gmail.com>> (she/her)\n* [Fishrock123](https://github.com/Fishrock123) -\n  **Jeremiah Senkpiel** <<fishrock123@rocketmail.com>> (he/they)\n* [gabrielschulhof](https://github.com/gabrielschulhof) -\n  **Gabriel Schulhof** <<gabrielschulhof@gmail.com>>\n* [gibfahn](https://github.com/gibfahn) -\n  **Gibson Fahnestock** <<gibfahn@gmail.com>> (he/him)\n* [indutny](https://github.com/indutny) -\n  **Fedor Indutny** <<fedor@indutny.com>>\n* [isaacs](https://github.com/isaacs) -\n  **Isaac Z. Schlueter** <<i@izs.me>>\n* [joshgav](https://github.com/joshgav) -\n  **Josh Gavant** <<josh.gavant@outlook.com>>\n* [mhdawson](https://github.com/mhdawson) -\n  **Michael Dawson** <<midawson@redhat.com>> (he/him)\n* [mmarchini](https://github.com/mmarchini) -\n  **Mary Marchini** <<oss@mmarchini.me>> (she/her)\n* [mscdex](https://github.com/mscdex) -\n  **Brian White** <<mscdex@mscdex.net>>\n* [MylesBorins](https://github.com/MylesBorins) -\n  **Myles Borins** <<myles.borins@gmail.com>> (he/him)\n* [nebrius](https://github.com/nebrius) -\n  **Bryan Hughes** <<bryan@nebri.us>>\n* [ofrobots](https://github.com/ofrobots) -\n  **Ali Ijaz Sheikh** <<ofrobots@google.com>> (he/him)\n* [orangemocha](https://github.com/orangemocha) -\n  **Alexis Campailla** <<orangemocha@nodejs.org>>\n* [piscisaureus](https://github.com/piscisaureus) -\n  **Bert Belder** <<bertbelder@gmail.com>>\n* [rvagg](https://github.com/rvagg) -\n  **Rod Vagg** <<r@va.gg>>\n* [sam-github](https://github.com/sam-github) -\n  **Sam Roberts** <<vieuxtech@gmail.com>>\n* [shigeki](https://github.com/shigeki) -\n  **Shigeki Ohtsu** <<ohtsu@ohtsu.org>> (he/him)\n* [thefourtheye](https://github.com/thefourtheye) -\n  **Sakthipriyan Vairamani** <<thechargingvolcano@gmail.com>> (he/him)\n* [TimothyGu](https://github.com/TimothyGu) -\n  **Tiancheng \"Timothy\" Gu** <<timothygu99@gmail.com>> (he/him)\n* [trevnorris](https://github.com/trevnorris) -\n  **Trevor Norris** <<trev.norris@gmail.com>>\n\n</details>\n\n<!-- node-core-utils and find-inactive-collaborators.mjs depend on the format\n     of the collaborator list. If the format changes, those utilities need to be\n     tested and updated. -->\n\n### Collaborators\n\n* [abmusse](https://github.com/abmusse) -\n  **Abdirahim Musse** <<abdirahim.musse@ibm.com>>\n* [addaleax](https://github.com/addaleax) -\n  **Anna Henningsen** <<anna@addaleax.net>> (she/her)\n* [Aditi-1400](https://github.com/Aditi-1400) -\n  **Aditi Singh** <<aditisingh1400@gmail.com>> (she/her)\n* [aduh95](https://github.com/aduh95) -\n  **Antoine du Hamel** <<duhamelantoine1995@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/aduh95)\n* [anonrig](https://github.com/anonrig) -\n  **Yagiz Nizipli** <<yagiz@nizipli.com>> (he/him) - [Support me](https://github.com/sponsors/anonrig)\n* [atlowChemi](https://github.com/atlowChemi) -\n  **Chemi Atlow** <<chemi@atlow.co.il>> (he/him)\n* [avivkeller](https://github.com/avivkeller) -\n  **Aviv Keller** <<me@aviv.sh>> (he/him) - [Support me](https://github.com/sponsors/avivkeller)\n* [Ayase-252](https://github.com/Ayase-252) -\n  **Qingyu Deng** <<i@ayase-lab.com>>\n* [bengl](https://github.com/bengl) -\n  **Bryan English** <<bryan@bryanenglish.com>> (he/him)\n* [benjamingr](https://github.com/benjamingr) -\n  **Benjamin Gruenbaum** <<benjamingr@gmail.com>>\n* [BethGriggs](https://github.com/BethGriggs) -\n  **Beth Griggs** <<bethanyngriggs@gmail.com>> (she/her)\n* [bnb](https://github.com/bnb) -\n  **Tierney Cyren** <<hello@bnb.im>> (they/them)\n* [bnoordhuis](https://github.com/bnoordhuis) -\n  **Ben Noordhuis** <<info@bnoordhuis.nl>>\n* [BridgeAR](https://github.com/BridgeAR) -\n  **Ruben Bridgewater** <<ruben@bridgewater.de>> (he/him)\n* [cclauss](https://github.com/cclauss) -\n  **Christian Clauss** <<cclauss@me.com>> (he/him)\n* [cjihrig](https://github.com/cjihrig) -\n  **Colin Ihrig** <<cjihrig@gmail.com>> (he/him)\n* [codebytere](https://github.com/codebytere) -\n  **Shelley Vohr** <<shelley.vohr@gmail.com>> (she/her)\n* [cola119](https://github.com/cola119) -\n  **Kohei Ueno** <<kohei.ueno119@gmail.com>> (he/him)\n* [daeyeon](https://github.com/daeyeon) -\n  **Daeyeon Jeong** <<daeyeon.dev@gmail.com>> (he/him)\n* [dario-piotrowicz](https://github.com/dario-piotrowicz) -\n  **Dario Piotrowicz** <<dario.piotrowicz@gmail.com>> (he/him)\n* [debadree25](https://github.com/debadree25) -\n  **Debadree Chatterjee** <<debadree333@gmail.com>> (he/him)\n* [deokjinkim](https://github.com/deokjinkim) -\n  **Deokjin Kim** <<deokjin81.kim@gmail.com>> (he/him)\n* [edsadr](https://github.com/edsadr) -\n  **Adrian Estrada** <<edsadr@gmail.com>> (he/him)\n* [ErickWendel](https://github.com/ErickWendel) -\n  **Erick Wendel** <<erick.workspace@gmail.com>> (he/him)\n* [Ethan-Arrowood](https://github.com/Ethan-Arrowood) -\n  **Ethan Arrowood** <<ethan@arrowood.dev>> (he/him)\n* [fhinkel](https://github.com/fhinkel) -\n  **Franziska Hinkelmann** <<franziska.hinkelmann@gmail.com>> (she/her)\n* [Flarna](https://github.com/Flarna) -\n  **Gerhard StÃ¶bich** <<deb2001-github@yahoo.de>> (he/they)\n* [gabrielschulhof](https://github.com/gabrielschulhof) -\n  **Gabriel Schulhof** <<gabrielschulhof@gmail.com>>\n* [geeksilva97](https://github.com/geeksilva97) -\n  **Edy Silva** <<edigleyssonsilva@gmail.com>> (he/him)\n* [gengjiawen](https://github.com/gengjiawen) -\n  **Jiawen Geng** <<technicalcute@gmail.com>>\n* [GeoffreyBooth](https://github.com/GeoffreyBooth) -\n  **Geoffrey Booth** <<webadmin@geoffreybooth.com>> (he/him)\n* [gireeshpunathil](https://github.com/gireeshpunathil) -\n  **Gireesh Punathil** <<gpunathi@in.ibm.com>> (he/him)\n* [gurgunday](https://github.com/gurgunday) -\n  **GÃ¼rgÃ¼n DayÄ±oÄŸlu** <<hey@gurgun.day>> (he/him)\n* [guybedford](https://github.com/guybedford) -\n  **Guy Bedford** <<guybedford@gmail.com>> (he/him)\n* [H4ad](https://github.com/H4ad) -\n  **VinÃ­cius LourenÃ§o Claro Cardoso** <<contact@viniciusl.com.br>> (he/him)\n* [HarshithaKP](https://github.com/HarshithaKP) -\n  **Harshitha K P** <<harshitha014@gmail.com>> (she/her)\n* [himself65](https://github.com/himself65) -\n  **Zeyu \"Alex\" Yang** <<himself65@outlook.com>> (he/him)\n* [hybrist](https://github.com/hybrist) -\n  **Jan Martin** <<jan.krems@gmail.com>> (he/him)\n* [IlyasShabi](https://github.com/IlyasShabi) -\n  **Ilyas Shabi** <<ilyasshabi94@gmail.com>> (he/him)\n* [islandryu](https://github.com/islandryu) -\n  **Ryuhei Shima** <<shimaryuhei@gmail.com>> (he/him)\n* [jakecastelli](https://github.com/jakecastelli) -\n  **Jake Yuesong Li** <<jake.yuesong@gmail.com>> (he/him)\n* [JakobJingleheimer](https://github.com/JakobJingleheimer) -\n  **Jacob Smith** <<jacob@frende.me>> (he/him)\n* [jasnell](https://github.com/jasnell) -\n  **James M Snell** <<jasnell@gmail.com>> (he/him)\n* [jazelly](https://github.com/jazelly) -\n  **Jason Zhang** <<xzha4350@gmail.com>> (he/him)\n* [JonasBa](https://github.com/JonasBa) -\n  **Jonas Badalic** <<jonas.badalic@gmail.com>> (he/him)\n* [joyeecheung](https://github.com/joyeecheung) -\n  **Joyee Cheung** <<joyeec9h3@gmail.com>> (she/her)\n* [juanarbol](https://github.com/juanarbol) -\n  **Juan JosÃ© Arboleda** <<soyjuanarbol@gmail.com>> (he/him)\n* [JungMinu](https://github.com/JungMinu) -\n  **Minwoo Jung** <<nodecorelab@gmail.com>> (he/him)\n* [KhafraDev](https://github.com/KhafraDev) -\n  **Matthew Aitken** <<maitken033380023@gmail.com>> (he/him)\n* [legendecas](https://github.com/legendecas) -\n  **Chengzhong Wu** <<legendecas@gmail.com>> (he/him)\n* [lemire](https://github.com/lemire) -\n  **Daniel Lemire** <<daniel@lemire.me>>\n* [LiviaMedeiros](https://github.com/LiviaMedeiros) -\n  **LiviaMedeiros** <<livia@cirno.name>>\n* [ljharb](https://github.com/ljharb) -\n  **Jordan Harband** <<ljharb@gmail.com>>\n* [lpinca](https://github.com/lpinca) -\n  **Luigi Pinca** <<luigipinca@gmail.com>> (he/him)\n* [Lxxyx](https://github.com/Lxxyx) -\n  **Zijian Liu** <<lxxyxzj@gmail.com>> (he/him)\n* [marco-ippolito](https://github.com/marco-ippolito) -\n  **Marco Ippolito** <<marcoippolito54@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/marco-ippolito)\n* [marsonya](https://github.com/marsonya) -\n  **Akhil Marsonya** <<akhil.marsonya27@gmail.com>> (he/him)\n* [MattiasBuelens](https://github.com/MattiasBuelens) -\n  **Mattias Buelens** <<mattias@buelens.com>> (he/him)\n* [mcollina](https://github.com/mcollina) -\n  **Matteo Collina** <<matteo.collina@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/mcollina)\n* [meixg](https://github.com/meixg) -\n  **Xuguang Mei** <<meixuguang@gmail.com>> (he/him)\n* [mhdawson](https://github.com/mhdawson) -\n  **Michael Dawson** <<midawson@redhat.com>> (he/him)\n* [MoLow](https://github.com/MoLow) -\n  **Moshe Atlow** <<moshe@atlow.co.il>> (he/him)\n* [MrJithil](https://github.com/MrJithil) -\n  **Jithil P Ponnan** <<jithil@outlook.com>> (he/him)\n* [ovflowd](https://github.com/ovflowd) -\n  **Claudio Wunder** <<cwunder@gnome.org>> (he/they)\n* [panva](https://github.com/panva) -\n  **Filip Skokan** <<panva.ip@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/panva)\n* [pimterry](https://github.com/pimterry) -\n  **Tim Perry** <<pimterry@gmail.com>> (he/him)\n* [pmarchini](https://github.com/pmarchini) -\n  **Pietro Marchini** <<pietro.marchini94@gmail.com>> (he/him)\n* [puskin](https://github.com/puskin) -\n  **Giovanni Bucci** <<github@puskin.it>> (he/him)\n* [Qard](https://github.com/Qard) -\n  **Stephen Belanger** <<admin@stephenbelanger.com>> (he/him)\n* [RafaelGSS](https://github.com/RafaelGSS) -\n  **Rafael Gonzaga** <<rafael.nunu@hotmail.com>> (he/him) - [Support me](https://github.com/sponsors/RafaelGSS)\n* [RaisinTen](https://github.com/RaisinTen) -\n  **Darshan Sen** <<raisinten@gmail.com>> (he/him) - [Support me](https://github.com/sponsors/RaisinTen)\n* [Renegade334](https://github.com/Renegade334) -\n  **RenÃ©** <<contact.9a5d6388@renegade334.me.uk>>\n* [richardlau](https://github.com/richardlau) -\n  **Richard Lau** <<richard.lau@ibm.com>>\n* [rluvaton](https://github.com/rluvaton) -\n  **Raz Luvaton** <<rluvaton@gmail.com>> (he/him)\n* [ronag](https://github.com/ronag) -\n  **Robert Nagy** <<ronagy@icloud.com>>\n* [ruyadorno](https://github.com/ruyadorno) -\n  **Ruy Adorno** <<ruy@vlt.sh>> (he/him)\n* [santigimeno](https://github.com/santigimeno) -\n  **Santiago Gimeno** <<santiago.gimeno@gmail.com>>\n* [ShogunPanda](https://github.com/ShogunPanda) -\n  **Paolo Insogna** <<paolo@cowtech.it>> (he/him)\n* [srl295](https://github.com/srl295) -\n  **Steven R Loomis** <<srl295@gmail.com>>\n* [StefanStojanovic](https://github.com/StefanStojanovic) -\n  **Stefan Stojanovic** <<stefan.stojanovic@janeasystems.com>> (he/him)\n* [sxa](https://github.com/sxa) -\n  **Stewart X Addison** <<sxa@redhat.com>> (he/him)\n* [targos](https://github.com/targos) -\n  **MichaÃ«l Zasso** <<targos@protonmail.com>> (he/him)\n* [theanarkh](https://github.com/theanarkh) -\n  **theanarkh** <<theratliter@gmail.com>> (he/him)\n* [tniessen](https://github.com/tniessen) -\n  **Tobias NieÃŸen** <<tniessen@tnie.de>> (he/him)\n* [trivikr](https://github.com/trivikr) -\n  **Trivikram Kamat** <<trivikr.dev@gmail.com>>\n* [Trott](https://github.com/Trott) -\n  **Rich Trott** <<rtrott@gmail.com>> (he/him)\n* [UlisesGascon](https://github.com/UlisesGascon) -\n  **Ulises GascÃ³n** <<ulisesgascongonzalez@gmail.com>> (he/him)\n* [vmoroz](https://github.com/vmoroz) -\n  **Vladimir Morozov** <<vmorozov@microsoft.com>> (he/him)\n* [VoltrexKeyva](https://github.com/VoltrexKeyva) -\n  **Mohammed Keyvanzadeh** <<mohammadkeyvanzade94@gmail.com>> (he/him)\n* [watilde](https://github.com/watilde) -\n  **Daijiro Wachi** <<daijiro.wachi@gmail.com>> (he/him)\n* [zcbenz](https://github.com/zcbenz) -\n  **Cheng Zhao** <<zcbenz@gmail.com>> (he/him)\n* [ZYSzys](https://github.com/ZYSzys) -\n  **Yongsheng Zhang** <<zyszys98@gmail.com>> (he/him)\n\n<details>\n\n<summary>Emeriti</summary>\n\n<!-- find-inactive-collaborators.mjs depends on the format of the emeriti list.\n     If the format changes, those utilities need to be tested and updated. -->\n\n### Collaborator emeriti\n\n* [ak239](https://github.com/ak239) -\n  **Aleksei Koziatinskii** <<ak239spb@gmail.com>>\n* [andrasq](https://github.com/andrasq) -\n  **Andras** <<andras@kinvey.com>>\n* [AndreasMadsen](https://github.com/AndreasMadsen) -\n  **Andreas Madsen** <<amwebdk@gmail.com>> (he/him)\n* [AnnaMag](https://github.com/AnnaMag) -\n  **Anna M. Kedzierska** <<anna.m.kedzierska@gmail.com>>\n* [antsmartian](https://github.com/antsmartian) -\n  **Anto Aravinth** <<anto.aravinth.cse@gmail.com>> (he/him)\n* [apapirovski](https://github.com/apapirovski) -\n  **Anatoli Papirovski** <<apapirovski@mac.com>> (he/him)\n* [aqrln](https://github.com/aqrln) -\n  **Alexey Orlenko** <<eaglexrlnk@gmail.com>> (he/him)\n* [AshCripps](https://github.com/AshCripps) -\n  **Ash Cripps** <<email@ashleycripps.co.uk>>\n* [bcoe](https://github.com/bcoe) -\n  **Ben Coe** <<bencoe@gmail.com>> (he/him)\n* [bmeck](https://github.com/bmeck) -\n  **Bradley Farias** <<bradley.meck@gmail.com>>\n* [bmeurer](https://github.com/bmeurer) -\n  **Benedikt Meurer** <<benedikt.meurer@gmail.com>>\n* [boneskull](https://github.com/boneskull) -\n  **Christopher Hiller** <<boneskull@boneskull.com>> (he/him)\n* [brendanashworth](https://github.com/brendanashworth) -\n  **Brendan Ashworth** <<brendan.ashworth@me.com>>\n* [bzoz](https://github.com/bzoz) -\n  **Bartosz Sosnowski** <<bartosz@janeasystems.com>>\n* [calvinmetcalf](https://github.com/calvinmetcalf) -\n  **Calvin Metcalf** <<calvin.metcalf@gmail.com>>\n* [ChALkeR](https://github.com/ChALkeR) -\n  **Ğ¡ĞºĞ¾Ğ²Ğ¾Ñ€Ğ¾Ğ´Ğ° ĞĞ¸ĞºĞ¸Ñ‚Ğ° ĞĞ½Ğ´Ñ€ĞµĞµĞ²Ğ¸Ñ‡** <<chalkerx@gmail.com>> (he/him)\n* [chrisdickinson](https://github.com/chrisdickinson) -\n  **Chris Dickinson** <<christopher.s.dickinson@gmail.com>>\n* [claudiorodriguez](https://github.com/claudiorodriguez) -\n  **Claudio Rodriguez** <<cjrodr@yahoo.com>>\n* [danbev](https://github.com/danbev) -\n  **Daniel Bevenius** <<daniel.bevenius@gmail.com>> (he/him)\n* [danielleadams](https://github.com/danielleadams) -\n  **Danielle Adams** <<adamzdanielle@gmail.com>> (she/her)\n* [DavidCai1111](https://github.com/DavidCai1111) -\n  **David Cai** <<davidcai1993@yahoo.com>> (he/him)\n* [davisjam](https://github.com/davisjam) -\n  **Jamie Davis** <<davisjam@vt.edu>> (he/him)\n* [devnexen](https://github.com/devnexen) -\n  **David Carlier** <<devnexen@gmail.com>>\n* [devsnek](https://github.com/devsnek) -\n  **Gus Caplan** <<me@gus.host>> (they/them)\n* [digitalinfinity](https://github.com/digitalinfinity) -\n  **Hitesh Kanwathirtha** <<digitalinfinity@gmail.com>> (he/him)\n* [dmabupt](https://github.com/dmabupt) -\n  **Xu Meng** <<dmabupt@gmail.com>> (he/him)\n* [dnlup](https://github.com/dnlup) -\n  **dnlup** <<dnlup.dev@gmail.com>>\n* [eljefedelrodeodeljefe](https://github.com/eljefedelrodeodeljefe) -\n  **Robert Jefe Lindstaedt** <<robert.lindstaedt@gmail.com>>\n* [estliberitas](https://github.com/estliberitas) -\n  **Alexander Makarenko** <<estliberitas@gmail.com>>\n* [eugeneo](https://github.com/eugeneo) -\n  **Eugene Ostroukhov** <<eostroukhov@google.com>>\n* [evanlucas](https://github.com/evanlucas) -\n  **Evan Lucas** <<evanlucas@me.com>> (he/him)\n* [F3n67u](https://github.com/F3n67u) -\n  **Feng Yu** <<F3n67u@outlook.com>> (he/him)\n* [firedfox](https://github.com/firedfox) -\n  **Daniel Wang** <<wangyang0123@gmail.com>>\n* [Fishrock123](https://github.com/Fishrock123) -\n  **Jeremiah Senkpiel** <<fishrock123@rocketmail.com>> (he/they)\n* [gdams](https://github.com/gdams) -\n  **George Adams** <<gadams@microsoft.com>> (he/him)\n* [geek](https://github.com/geek) -\n  **Wyatt Preul** <<wpreul@gmail.com>>\n* [gibfahn](https://github.com/gibfahn) -\n  **Gibson Fahnestock** <<gibfahn@gmail.com>> (he/him)\n* [glentiki](https://github.com/glentiki) -\n  **Glen Keane** <<glenkeane.94@gmail.com>> (he/him)\n* [hashseed](https://github.com/hashseed) -\n  **Yang Guo** <<yangguo@chromium.org>> (he/him)\n* [hiroppy](https://github.com/hiroppy) -\n  **Yuta Hiroto** <<hello@hiroppy.me>> (he/him)\n* [iansu](https://github.com/iansu) -\n  **Ian Sutherland** <<ian@iansutherland.ca>>\n* [iarna](https://github.com/iarna) -\n  **Rebecca Turner** <<me@re-becca.org>>\n* [imran-iq](https://github.com/imran-iq) -\n  **Imran Iqbal** <<imran@imraniqbal.org>>\n* [imyller](https://github.com/imyller) -\n  **Ilkka Myller** <<ilkka.myller@nodefield.com>>\n* [indutny](https://github.com/indutny) -\n  **Fedor Indutny** <<fedor@indutny.com>>\n* [isaacs](https://github.com/isaacs) -\n  **Isaac Z. Schlueter** <<i@izs.me>>\n* [italoacasas](https://github.com/italoacasas) -\n  **Italo A. Casas** <<me@italoacasas.com>> (he/him)\n* [JacksonTian](https://github.com/JacksonTian) -\n  **Jackson Tian** <<shyvo1987@gmail.com>>\n* [jasongin](https://github.com/jasongin) -\n  **Jason Ginchereau** <<jasongin@microsoft.com>>\n* [jbergstroem](https://github.com/jbergstroem) -\n  **Johan BergstrÃ¶m** <<bugs@bergstroem.nu>>\n* [jdalton](https://github.com/jdalton) -\n  **John-David Dalton** <<john.david.dalton@gmail.com>>\n* [jhamhader](https://github.com/jhamhader) -\n  **Yuval Brik** <<yuval@brik.org.il>>\n* [joaocgreis](https://github.com/joaocgreis) -\n  **JoÃ£o Reis** <<reis@janeasystems.com>>\n* [joesepi](https://github.com/joesepi) -\n  **Joe Sepi** <<sepi@joesepi.com>> (he/him)\n* [joshgav](https://github.com/joshgav) -\n  **Josh Gavant** <<josh.gavant@outlook.com>>\n* [julianduque](https://github.com/julianduque) -\n  **Julian Duque** <<julianduquej@gmail.com>> (he/him)\n* [kfarnung](https://github.com/kfarnung) -\n  **Kyle Farnung** <<kfarnung@microsoft.com>> (he/him)\n* [kunalspathak](https://github.com/kunalspathak) -\n  **Kunal Pathak** <<kunal.pathak@microsoft.com>>\n* [kuriyosh](https://github.com/kuriyosh) -\n  **Yoshiki Kurihara** <<yosyos0306@gmail.com>> (he/him)\n* [kvakil](https://github.com/kvakil) -\n  **Keyhan Vakil** <<kvakil@sylph.kvakil.me>>\n* [lance](https://github.com/lance) -\n  **Lance Ball** <<lball@redhat.com>> (he/him)\n* [Leko](https://github.com/Leko) -\n  **Shingo Inoue** <<leko.noor@gmail.com>> (he/him)\n* [Linkgoron](https://github.com/Linkgoron) -\n  **Nitzan Uziely** <<linkgoron@gmail.com>>\n* [lucamaraschi](https://github.com/lucamaraschi) -\n  **Luca Maraschi** <<luca.maraschi@gmail.com>> (he/him)\n* [lukekarrys](https://github.com/lukekarrys) -\n  **Luke Karrys** <<luke@lukekarrys.com>> (he/him)\n* [lundibundi](https://github.com/lundibundi) -\n  **Denys Otrishko** <<shishugi@gmail.com>> (he/him)\n* [lxe](https://github.com/lxe) -\n  **Aleksey Smolenchuk** <<lxe@lxe.co>>\n* [maclover7](https://github.com/maclover7) -\n  **Jon Moss** <<me@jonathanmoss.me>> (he/him)\n* [mafintosh](https://github.com/mafintosh) -\n  **Mathias Buus** <<mathiasbuus@gmail.com>> (he/him)\n* [matthewloring](https://github.com/matthewloring) -\n  **Matthew Loring** <<mattloring@google.com>>\n* [Mesteery](https://github.com/Mesteery) -\n  **Mestery** <<mestery@protonmail.com>> (he/him)\n* [micnic](https://github.com/micnic) -\n  **Nicu MicleuÈ™anu** <<micnic90@gmail.com>> (he/him)\n* [mikeal](https://github.com/mikeal) -\n  **Mikeal Rogers** <<mikeal.rogers@gmail.com>>\n* [miladfarca](https://github.com/miladfarca) -\n  **Milad Fa** <<mfarazma@redhat.com>> (he/him)\n* [mildsunrise](https://github.com/mildsunrise) -\n  **Alba Mendez** <<me@alba.sh>> (she/her)\n* [misterdjules](https://github.com/misterdjules) -\n  **Julien Gilli** <<jgilli@netflix.com>>\n* [mmarchini](https://github.com/mmarchini) -\n  **Mary Marchini** <<oss@mmarchini.me>> (she/her)\n* [monsanto](https://github.com/monsanto) -\n  **Christopher Monsanto** <<chris@monsan.to>>\n* [MoonBall](https://github.com/MoonBall) -\n  **Chen Gang** <<gangc.cxy@foxmail.com>>\n* [mscdex](https://github.com/mscdex) -\n  **Brian White** <<mscdex@mscdex.net>>\n* [MylesBorins](https://github.com/MylesBorins) -\n  **Myles Borins** <<myles.borins@gmail.com>> (he/him)\n* [not-an-aardvark](https://github.com/not-an-aardvark) -\n  **Teddy Katz** <<teddy.katz@gmail.com>> (he/him)\n* [ofrobots](https://github.com/ofrobots) -\n  **Ali Ijaz Sheikh** <<ofrobots@google.com>> (he/him)\n* [Olegas](https://github.com/Olegas) -\n  **Oleg Elifantiev** <<oleg@elifantiev.ru>>\n* [orangemocha](https://github.com/orangemocha) -\n  **Alexis Campailla** <<orangemocha@nodejs.org>>\n* [othiym23](https://github.com/othiym23) -\n  **Forrest L Norvell** <<ogd@aoaioxxysz.net>> (they/them/themself)\n* [oyyd](https://github.com/oyyd) -\n  **Ouyang Yadong** <<oyydoibh@gmail.com>> (he/him)\n* [petkaantonov](https://github.com/petkaantonov) -\n  **Petka Antonov** <<petka_antonov@hotmail.com>>\n* [phillipj](https://github.com/phillipj) -\n  **Phillip Johnsen** <<johphi@gmail.com>>\n* [piscisaureus](https://github.com/piscisaureus) -\n  **Bert Belder** <<bertbelder@gmail.com>>\n* [pmq20](https://github.com/pmq20) -\n  **Minqi Pan** <<pmq2001@gmail.com>>\n* [PoojaDurgad](https://github.com/PoojaDurgad) -\n  **Pooja D P** <<Pooja.D.P@ibm.com>> (she/her)\n* [princejwesley](https://github.com/princejwesley) -\n  **Prince John Wesley** <<princejohnwesley@gmail.com>>\n* [psmarshall](https://github.com/psmarshall) -\n  **Peter Marshall** <<petermarshall@chromium.org>> (he/him)\n* [puzpuzpuz](https://github.com/puzpuzpuz) -\n  **Andrey Pechkurov** <<apechkurov@gmail.com>> (he/him)\n* [refack](https://github.com/refack) -\n  **Refael Ackermann (×¨×¤××œ ×¤×œ×—×™)** <<refack@gmail.com>> (he/him/×”×•×/××ª×”)\n* [rexagod](https://github.com/rexagod) -\n  **Pranshu Srivastava** <<rexagod@gmail.com>> (he/him)\n* [rickyes](https://github.com/rickyes) -\n  **Ricky Zhou** <<0x19951125@gmail.com>> (he/him)\n* [rlidwka](https://github.com/rlidwka) -\n  **Alex Kocharin** <<alex@kocharin.ru>>\n* [rmg](https://github.com/rmg) -\n  **Ryan Graham** <<r.m.graham@gmail.com>>\n* [robertkowalski](https://github.com/robertkowalski) -\n  **Robert Kowalski** <<rok@kowalski.gd>>\n* [romankl](https://github.com/romankl) -\n  **Roman Klauke** <<romaaan.git@gmail.com>>\n* [ronkorving](https://github.com/ronkorving) -\n  **Ron Korving** <<ron@ronkorving.nl>>\n* [RReverser](https://github.com/RReverser) -\n  **Ingvar Stepanyan** <<me@rreverser.com>>\n* [rubys](https://github.com/rubys) -\n  **Sam Ruby** <<rubys@intertwingly.net>>\n* [rvagg](https://github.com/rvagg) -\n  **Rod Vagg** <<rod@vagg.org>>\n* [ryzokuken](https://github.com/ryzokuken) -\n  **Ujjwal Sharma** <<ryzokuken@disroot.org>> (he/him)\n* [saghul](https://github.com/saghul) -\n  **SaÃºl Ibarra CorretgÃ©** <<s@saghul.net>>\n* [sam-github](https://github.com/sam-github) -\n  **Sam Roberts** <<vieuxtech@gmail.com>>\n* [sebdeckers](https://github.com/sebdeckers) -\n  **Sebastiaan Deckers** <<sebdeckers83@gmail.com>>\n* [seishun](https://github.com/seishun) -\n  **Nikolai Vavilov** <<vvnicholas@gmail.com>>\n* [shigeki](https://github.com/shigeki) -\n  **Shigeki Ohtsu** <<ohtsu@ohtsu.org>> (he/him)\n* [shisama](https://github.com/shisama) -\n  **Masashi Hirano** <<shisama07@gmail.com>> (he/him)\n* [silverwind](https://github.com/silverwind) -\n  **Roman Reiss** <<me@silverwind.io>>\n* [starkwang](https://github.com/starkwang) -\n  **Weijia Wang** <<starkwang@126.com>>\n* [stefanmb](https://github.com/stefanmb) -\n  **Stefan Budeanu** <<stefan@budeanu.com>>\n* [tellnes](https://github.com/tellnes) -\n  **Christian Tellnes** <<christian@tellnes.no>>\n* [thefourtheye](https://github.com/thefourtheye) -\n  **Sakthipriyan Vairamani** <<thechargingvolcano@gmail.com>> (he/him)\n* [thlorenz](https://github.com/thlorenz) -\n  **Thorsten Lorenz** <<thlorenz@gmx.de>>\n* [TimothyGu](https://github.com/TimothyGu) -\n  **Tiancheng \"Timothy\" Gu** <<timothygu99@gmail.com>> (he/him)\n* [trevnorris](https://github.com/trevnorris) -\n  **Trevor Norris** <<trev.norris@gmail.com>>\n* [tunniclm](https://github.com/tunniclm) -\n  **Mike Tunnicliffe** <<m.j.tunnicliffe@gmail.com>>\n* [vdeturckheim](https://github.com/vdeturckheim) -\n  **Vladimir de Turckheim** <<vlad2t@hotmail.com>> (he/him)\n* [vkurchatkin](https://github.com/vkurchatkin) -\n  **Vladimir Kurchatkin** <<vladimir.kurchatkin@gmail.com>>\n* [vsemozhetbyt](https://github.com/vsemozhetbyt) -\n  **Vse Mozhet Byt** <<vsemozhetbyt@gmail.com>> (he/him)\n* [watson](https://github.com/watson) -\n  **Thomas Watson** <<w@tson.dk>>\n* [whitlockjc](https://github.com/whitlockjc) -\n  **Jeremy Whitlock** <<jwhitlock@apache.org>>\n* [XadillaX](https://github.com/XadillaX) -\n  **Khaidi Chu** <<i@2333.moe>> (he/him)\n* [yashLadha](https://github.com/yashLadha) -\n  **Yash Ladha** <<yash@yashladha.in>> (he/him)\n* [yhwang](https://github.com/yhwang) -\n  **Yihong Wang** <<yh.wang@ibm.com>>\n* [yorkie](https://github.com/yorkie) -\n  **Yorkie Liu** <<yorkiefixer@gmail.com>>\n* [yosuke-furukawa](https://github.com/yosuke-furukawa) -\n  **Yosuke Furukawa** <<yosuke.furukawa@gmail.com>>\n\n</details>\n\n<!--lint enable prohibited-strings-->\n\nCollaborators follow the [Collaborator Guide](./doc/contributing/collaborator-guide.md) in\nmaintaining the Node.js project.\n\n### Triagers\n\n* [1ilsang](https://github.com/1ilsang) -\n  **Sangchul Lee** <<1ilsang.dev@gmail.com>> (he/him)\n* [atlowChemi](https://github.com/atlowChemi) -\n  **Chemi Atlow** <<chemi@atlow.co.il>> (he/him)\n* [Ayase-252](https://github.com/Ayase-252) -\n  **Qingyu Deng** <<i@ayase-lab.com>>\n* [bjohansebas](https://github.com/bjohansebas) -\n  **Sebastian Beltran** <<bjohansebas@gmail.com>>\n* [bmuenzenmeyer](https://github.com/bmuenzenmeyer) -\n  **Brian Muenzenmeyer** <<brian.muenzenmeyer@gmail.com>> (he/him)\n* [CanadaHonk](https://github.com/CanadaHonk) -\n  **Oliver Medhurst** <<honk@goose.icu>> (they/them)\n* [daeyeon](https://github.com/daeyeon) -\n  **Daeyeon Jeong** <<daeyeon.dev@gmail.com>> (he/him)\n* [gireeshpunathil](https://github.com/gireeshpunathil) -\n  **Gireesh Punathil** <<gpunathi@in.ibm.com>> (he/him)\n* [gurgunday](https://github.com/gurgunday) -\n  **GÃ¼rgÃ¼n DayÄ±oÄŸlu** <<hey@gurgun.day>>\n* [haramj](https://github.com/haramj) -\n  **Haram Jeong** <<haramj.dev@gmail.com>>\n* [HBSPS](https://github.com/HBSPS) -\n  **Wiyeong Seo** <<hbsps.dev@gmail.com>>\n* [iam-frankqiu](https://github.com/iam-frankqiu) -\n  **Frank Qiu** <<iam.frankqiu@gmail.com>> (he/him)\n* [KevinEady](https://github.com/KevinEady) -\n  **Kevin Eady** <<kevin.c.eady@gmail.com>> (he/him)\n* [marsonya](https://github.com/marsonya) -\n  **Akhil Marsonya** <<akhil.marsonya27@gmail.com>> (he/him)\n* [meixg](https://github.com/meixg) -\n  **Xuguang Mei** <<meixuguang@gmail.com>> (he/him)\n* [milesguicent](https://github.com/milesguicent) -\n  **Miles Guicent** <<guicent@pm.me>> (he/him)\n* [preveen-stack](https://github.com/preveen-stack) -\n  **Preveen Padmanabhan** <<wide4head@gmail.com>> (he/him)\n* [RaisinTen](https://github.com/RaisinTen) -\n  **Darshan Sen** <<raisinten@gmail.com>> (he/him)\n* [VoltrexKeyva](https://github.com/VoltrexKeyva) -\n  **Mohammed Keyvanzadeh** <<mohammadkeyvanzade94@gmail.com>> (he/him)\n\nTriagers follow the [Triage Guide](./doc/contributing/issues.md#triaging-a-bug-report) when\nresponding to new issues.\n\n### Release keys\n\nPrimary GPG keys for Node.js Releasers (some Releasers sign with subkeys):\n\n* **Antoine du Hamel** <<duhamelantoine1995@gmail.com>>\n  `5BE8A3F6C8A5C01D106C0AD820B1A390B168D356`\n* **Juan JosÃ© Arboleda** <<soyjuanarbol@gmail.com>>\n  `DD792F5973C6DE52C432CBDAC77ABFA00DDBF2B7`\n* **Marco Ippolito** <<marcoippolito54@gmail.com>>\n  `CC68F5A3106FF448322E48ED27F5E38D5B0A215F`\n* **MichaÃ«l Zasso** <<targos@protonmail.com>>\n  `8FCCA13FEF1D0C2E91008E09770F7A9A5AE15600`\n* **Rafael Gonzaga** <<rafael.nunu@hotmail.com>>\n  `890C08DB8579162FEE0DF9DB8BEAB4DFCF555EF4`\n* **Richard Lau** <<richard.lau@ibm.com>>\n  `C82FA3AE1CBEDC6BE46B9360C43CEC45C17AB93C`\n* **Ruy Adorno** <<ruyadorno@hotmail.com>>\n  `108F52B48DB57BB0CC439B2997B01419BD92F80A`\n* **Ulises GascÃ³n** <<ulisesgascongonzalez@gmail.com>>\n  `A363A499291CBBC940DD62E41F10027AF002F8B0`\n\nYou can use the keyring the project maintains at\n<https://github.com/nodejs/release-keys/raw/refs/heads/main/gpg-only-active-keys/pubring.kbx>.\nAlternatively, you can import them from a public key server. Have in mind that\nthe project cannot guarantee the availability of the server nor the keys on\nthat server.\n\n```bash\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 5BE8A3F6C8A5C01D106C0AD820B1A390B168D356 # Antoine du Hamel\ngpg --keyserver hkps://keys.openpgp.org --recv-keys DD792F5973C6DE52C432CBDAC77ABFA00DDBF2B7 # Juan JosÃ© Arboleda\ngpg --keyserver hkps://keys.openpgp.org --recv-keys CC68F5A3106FF448322E48ED27F5E38D5B0A215F # Marco Ippolito\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 8FCCA13FEF1D0C2E91008E09770F7A9A5AE15600 # MichaÃ«l Zasso\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 890C08DB8579162FEE0DF9DB8BEAB4DFCF555EF4 # Rafael Gonzaga\ngpg --keyserver hkps://keys.openpgp.org --recv-keys C82FA3AE1CBEDC6BE46B9360C43CEC45C17AB93C # Richard Lau\ngpg --keyserver hkps://keys.openpgp.org --recv-keys 108F52B48DB57BB0CC439B2997B01419BD92F80A # Ruy Adorno\ngpg --keyserver hkps://keys.openpgp.org --recv-keys A363A499291CBBC940DD62E41F10027AF002F8B0 # Ulises GascÃ³n\n```\n\nSee [Verifying binaries](#verifying-binaries) for how to use these keys to\nverify a downloaded file.\n\n<details>\n\n<summary>Other keys used to sign some previous releases</summary>\n\n* **Antoine du Hamel** <<duhamelantoine1995@gmail.com>>\n  `C0D6248439F1D5604AAFFB4021D900FFDB233756`\n* **Beth Griggs** <<bethanyngriggs@gmail.com>>\n  `4ED778F539E3634C779C87C6D7062848A1AB005C`\n* **Bryan English** <<bryan@bryanenglish.com>>\n  `141F07595B7B3FFE74309A937405533BE57C7D57`\n* **Chris Dickinson** <<christopher.s.dickinson@gmail.com>>\n  `9554F04D7259F04124DE6B476D5A82AC7E37093B`\n* **Colin Ihrig** <<cjihrig@gmail.com>>\n  `94AE36675C464D64BAFA68DD7434390BDBE9B9C5`\n* **Danielle Adams** <<adamzdanielle@gmail.com>>\n  `1C050899334244A8AF75E53792EF661D867B9DFA`\n  `74F12602B6F1C4E913FAA37AD3A89613643B6201`\n* **Evan Lucas** <<evanlucas@me.com>>\n  `B9AE9905FFD7803F25714661B63B535A4C206CA9`\n* **Gibson Fahnestock** <<gibfahn@gmail.com>>\n  `77984A986EBC2AA786BC0F66B01FBB92821C587A`\n* **Isaac Z. Schlueter** <<i@izs.me>>\n  `93C7E9E91B49E432C2F75674B0A78B0A6C481CF6`\n* **Italo A. Casas** <<me@italoacasas.com>>\n  `56730D5401028683275BD23C23EFEFE93C4CFFFE`\n* **James M Snell** <<jasnell@keybase.io>>\n  `71DCFD284A79C3B38668286BC97EC7A07EDE3FC1`\n* **Jeremiah Senkpiel** <<fishrock@keybase.io>>\n  `FD3A5288F042B6850C66B31F09FE44734EB7990E`\n* **Juan JosÃ© Arboleda** <<soyjuanarbol@gmail.com>>\n  `61FC681DFB92A079F1685E77973F295594EC4689`\n* **Julien Gilli** <<jgilli@fastmail.fm>>\n  `114F43EE0176B71C7BC219DD50A3051F888C628D`\n* **Myles Borins** <<myles.borins@gmail.com>>\n  `C4F0DFFF4E8C1A8236409D08E73BC641CC11F4C8`\n* **Rod Vagg** <<rod@vagg.org>>\n  `DD8F2338BAE7501E3DD5AC78C273792F7D83545D`\n* **Ruben Bridgewater** <<ruben@bridgewater.de>>\n  `A48C2BEE680E841632CD4E44F07496B3EB3C1762`\n* **Shelley Vohr** <<shelley.vohr@gmail.com>>\n  `B9E2F5981AA6E0CD28160D9FF13993A75599653C`\n* **Timothy J Fontaine** <<tjfontaine@gmail.com>>\n  `7937DFD2AB06298B2293C3187D33FF9D0246406D`\n\nThe project maintains a keyring able to verify all past releases of Node.js at\n<https://github.com/nodejs/release-keys/raw/refs/heads/main/gpg/pubring.kbx>.\n\n</details>\n\n### Security release stewards\n\nWhen possible, the commitment to take slots in the\nsecurity release steward rotation is made by companies in order\nto ensure individuals who act as security stewards have the\nsupport and recognition from their employer to be able to\nprioritize security releases. Security release stewards manage security\nreleases on a rotation basis as outlined in the\n[security release process](./doc/contributing/security-release-process.md).\n\n* [Datadog](https://www.datadoghq.com/)\n  * [bengl](https://github.com/bengl) -\n    **Bryan English** <<bryan@bryanenglish.com>> (he/him)\n* [HeroDevs](https://www.herodevs.com/)\n  * [marco-ippolito](https://github.com/marco-ippolito) -\n    **Marco Ippolito** <<marcoippolito54@gmail.com>> (he/him)\n* [NodeSource](https://nodesource.com/)\n  * [juanarbol](https://github.com/juanarbol) -\n    **Juan JosÃ© Arboleda** <<soyjuanarbol@gmail.com>> (he/him)\n  * [RafaelGSS](https://github.com/RafaelGSS) -\n    **Rafael Gonzaga** <<rafael.nunu@hotmail.com>> (he/him)\n* [Platformatic](https://platformatic.dev/)\n  * [mcollina](https://github.com/mcollina) -\n    **Matteo Collina** <<matteo.collina@gmail.com>> (he/him)\n* [Red Hat](https://redhat.com) / [IBM](https://ibm.com)\n  * [joesepi](https://github.com/joesepi) -\n    **Joe Sepi** <<joesepi@ibm.com>> (he/him)\n  * [mhdawson](https://github.com/mhdawson) -\n    **Michael Dawson** <<midawson@redhat.com>> (he/him)\n\n## License\n\nNode.js is licensed under the [MIT License](https://opensource.org/licenses/MIT).\n\nThis project also depends on external libraries that may use different open-source\nlicenses. For a complete list of included licenses, please see the\n[LICENSE](https://github.com/nodejs/node/blob/main/LICENSE) file.\n\nIf you are contributing documentation or source changes, please ensure your\nadditions comply with the projectâ€™s license guidelines.\n\n[Code of Conduct]: https://github.com/nodejs/admin/blob/HEAD/CODE_OF_CONDUCT.md\n[Contributing to the project]: CONTRIBUTING.md\n[Node.js website]: https://nodejs.org/\n[OpenJS Foundation]: https://openjsf.org/\n[Strategic initiatives]: doc/contributing/strategic-initiatives.md\n[Technical values and prioritization]: doc/contributing/technical-values.md\n[Working Groups]: https://github.com/nodejs/TSC/blob/HEAD/WORKING_GROUPS.md\n",
      "stars_today": 23
    },
    {
      "id": 916507415,
      "name": "go-interview-practice",
      "full_name": "RezaSi/go-interview-practice",
      "description": "Interactive Go Interview Platform - 30+ coding challenges with instant feedback, AI interview simulation, competitive leaderboards, and automated testing. From beginner to advanced levels with real-world scenarios.",
      "html_url": "https://github.com/RezaSi/go-interview-practice",
      "stars": 1733,
      "forks": 855,
      "language": "Go",
      "topics": [
        "ai-interview",
        "ai-interview-platform",
        "ai-interview-preparation",
        "ai-interview-questions",
        "ai-interview-simulator",
        "ai-interviewer",
        "go-interview-questions",
        "go-practice",
        "golang",
        "golang-interview-questions",
        "golang-practice",
        "hacktoberfest",
        "interview",
        "interview-practice",
        "interview-preparation",
        "interview-questions",
        "learn-to-code",
        "learning-exercise",
        "learning-resources",
        "tutorial-exercises"
      ],
      "created_at": "2025-01-14T08:28:01Z",
      "updated_at": "2026-01-16T00:03:10Z",
      "pushed_at": "2026-01-15T16:18:35Z",
      "open_issues": 165,
      "owner": {
        "login": "RezaSi",
        "avatar_url": "https://avatars.githubusercontent.com/u/6655338?v=4"
      },
      "readme": "\n# Go Interview Practice\n\n<div align=\"center\">\n\n[![GitHub Stars](https://img.shields.io/github/stars/RezaSi/go-interview-practice?style=for-the-badge&logo=github&color=yellow)](https://github.com/RezaSi/go-interview-practice/stargazers)\n[![Go Version](https://img.shields.io/badge/Go-1.19+-00ADD8?style=for-the-badge&logo=go)](https://golang.org/)\n[![Challenges](https://img.shields.io/badge/Challenges-30+-brightgreen?style=for-the-badge&logo=checkmarx)](https://github.com/RezaSi/go-interview-practice)\n<!-- [![Discord](https://img.shields.io/badge/Discord-Join%20Community-5865F2?style=for-the-badge&logo=discord)](https://discord.gg/G2DH2qpF) -->\n\n<a href=\"https://trendshift.io/repositories/14255\" target=\"_blank\">\n<img src=\"https://trendshift.io/api/badge/repositories/14255\" alt=\"RezaSi%2Fgo-interview-practice | Trendshift\" style=\"width: 250px;\" width=\"250\"/>\n</a>\n\n**â­ Star the repo if itâ€™s useful to you**\n<br/>\n<br/>\n</div>\n\n\n\nWelcome to the **Go Interview Practice** repository! Master Go programming and ace your technical interviews with our interactive coding challenges.\n\nOur interactive platform is now live at **[app.gointerview.dev](https://app.gointerview.dev/)** ğŸ‰ Explore challenges, track your progress, and elevate your Go skills with AI-powered mentorship.\n\n<div align=\"center\">\n  <a href=\"https://app.gointerview.dev/\" target=\"_blank\">\n    <img src=\"https://img.shields.io/badge/Start%20Practicing-Now-blue?style=for-the-badge&logo=go\" alt=\"Start Practicing Now\">\n  </a>\n</div>\n\n---\n\n## Visual Overview\n\n### Interactive Challenge Platform\nOur comprehensive web interface provides everything you need to practice and master Go programming:\n\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/23468aab-a032-4326-9d05-84de86c9128c\" controls width=\"90%\"></video>\n  <p><em>A brief introduction to the project</em></p>\n</div>\n\n---\n\n### Code & Test Experience\n\n<div align=\"center\">\n  <img src=\"./images/challenge.png\" alt=\"Go Interview Practice Web UI - challenge\" width=\"48%\" style=\"margin-right: 2%;\">\n  <img src=\"./images/result.png\" alt=\"Go Interview Practice Web UI - result\" width=\"48%\">\n</div>\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\" width=\"48%\">\n        <strong>Interactive Code Editor</strong><br>\n        <em>Write, edit, and test your Go solutions<br>with syntax highlighting and real-time feedback</em>\n      </td>\n      <td width=\"4%\"></td>\n      <td align=\"center\" width=\"48%\">\n        <strong>Instant Results & Analytics</strong><br>\n        <em>Get immediate test results, performance metrics,<br>and detailed execution analysis</em>\n      </td>\n    </tr>\n  </table>\n</div>\n\n---\n\n### Competitive Leaderboard\n\n<div align=\"center\">\n  <img src=\"./images/scoreboard.png\" alt=\"Go Interview Practice - Main Leaderboard\" width=\"90%\">\n  <p><em>Beautiful leaderboard showcasing top developers with challenge completion indicators, rankings, and achievements</em></p>\n</div>\n\n---\n\n## ğŸ† Top 10 Leaderboard\n\nOur most accomplished Go developers, ranked by number of challenges completed:\n\n> **Note**: The data below is automatically updated by GitHub Actions when challenge scoreboards change.\n\n| ğŸ… | Developer | Solved | Rate | Achievement | Progress |\n|:---:|:---:|:---:|:---:|:---:|:---|\n| ğŸ¥‡ | <img src=\"https://github.com/PolinaSvet.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[PolinaSvet](https://github.com/PolinaSvet)** | **30**/30 | **100.0%** | Master | âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…<br/>âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ… |\n| ğŸ¥ˆ | <img src=\"https://github.com/nzamulov.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[nzamulov](https://github.com/nzamulov)** | **30**/30 | **100.0%** | Master | âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…<br/>âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ… |\n| ğŸ¥‰ | <img src=\"https://github.com/odelbos.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[odelbos](https://github.com/odelbos)** | **30**/30 | **100.0%** | Master | âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…<br/>âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ… |\n| 4 | <img src=\"https://github.com/mick4711.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[mick4711](https://github.com/mick4711)** | **23**/30 | **76.7%** | Master | âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…â¬œâ¬œâœ…âœ…â¬œ<br/>âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…â¬œâ¬œâœ…âœ…â¬œâ¬œâœ… |\n| 5 | <img src=\"https://github.com/Gandook.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[Gandook](https://github.com/Gandook)** | **22**/30 | **73.3%** | Master | âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…â¬œâ¬œâœ…â¬œâ¬œ<br/>â¬œâœ…âœ…âœ…â¬œâœ…âœ…âœ…âœ…âœ…âœ…âœ…â¬œâ¬œâœ… |\n| 6 | <img src=\"https://github.com/y1hao.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[y1hao](https://github.com/y1hao)** | **21**/30 | **70.0%** | Master | âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…â¬œâœ…â¬œâ¬œâœ…âœ…â¬œ<br/>âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…â¬œâ¬œâ¬œâœ…â¬œâ¬œâœ… |\n| 7 | <img src=\"https://github.com/JackDalberg.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[JackDalberg](https://github.com/JackDalberg)** | **20**/30 | **66.7%** | Master | âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…â¬œâœ…â¬œâ¬œâœ…âœ…â¬œ<br/>â¬œâœ…âœ…âœ…âœ…âœ…âœ…âœ…â¬œâ¬œâ¬œâœ…â¬œâ¬œâœ… |\n| 8 | <img src=\"https://github.com/Ali-Fartoot.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[Ali-Fartoot](https://github.com/Ali-Fartoot)** | **19**/30 | **63.3%** | Expert | âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…â¬œâœ…â¬œâ¬œâœ…â¬œâ¬œ<br/>âœ…âœ…âœ…âœ…â¬œâœ…âœ…âœ…â¬œâ¬œâ¬œâœ…â¬œâ¬œâœ… |\n| 9 | <img src=\"https://github.com/Cpoing.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[Cpoing](https://github.com/Cpoing)** | **17**/30 | **56.7%** | Expert | âœ…âœ…âœ…âœ…â¬œâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…<br/>â¬œâœ…âœ…â¬œâ¬œâœ…â¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œ |\n| 10 | <img src=\"https://github.com/ashwinipatankar.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[ashwinipatankar](https://github.com/ashwinipatankar)** â¤ï¸ | **17**/30 | **56.7%** | Expert | âœ…âœ…âœ…â¬œâœ…âœ…âœ…â¬œâœ…âœ…â¬œâ¬œâœ…âœ…â¬œ<br/>â¬œâœ…âœ…âœ…â¬œâ¬œâœ…âœ…â¬œâ¬œâ¬œâœ…â¬œâ¬œâœ… |\n\n<div align=\"center\">\n\nâœ… Completed â€¢ â¬œ Not Completed\n\n*All 30 challenges shown in two rows*\n\n</div>\n\n*Updated automatically based on 30 available challenges*\n\n### Challenge Progress Overview\n\n- **Total Challenges Available**: 30\n- **Active Developers**: 230\n- **Most Challenges Solved**: 30 by PolinaSvet\n\n<!-- END_CLASSIC_LEADERBOARD -->\n## ğŸš€ Package Challenges Leaderboard\n\nMaster Go packages through hands-on challenges! Each package offers a structured learning path with real-world scenarios.\n\n> **Note**: The data below is automatically updated by GitHub Actions when package challenge scoreboards change.\n\n| ğŸ… | Developer | Total Solved | Packages | Achievement | Challenge Distribution |\n|:---:|:---:|:---:|:---:|:---:|:---|\n| ğŸ¥‡ | <img src=\"https://github.com/odelbos.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[odelbos](https://github.com/odelbos)** | **17** | **4** pkgs | ğŸ”¥ Package Master | **cobra**: 4 â€¢ **fiber**: 4 â€¢ **gin**: 4 â€¢ **gorm**: 5 |\n| ğŸ¥ˆ | <img src=\"https://github.com/PolinaSvet.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[PolinaSvet](https://github.com/PolinaSvet)** | **8** | **2** pkgs | ğŸ’ª Package Advanced | **cobra**: 4 â€¢ **gin**: 4 |\n| ğŸ¥‰ | <img src=\"https://github.com/RezaSi.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[RezaSi](https://github.com/RezaSi)** | **7** | **6** pkgs | ğŸ’ª Package Advanced | **cobra**: 1 â€¢ **echo**: 1 â€¢ **fiber**: 1 â€¢ **gin**: 1 â€¢ **gorm**: 1 â€¢ **mongodb**: 2 |\n| 4 | <img src=\"https://github.com/22-7-co.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[22-7-co](https://github.com/22-7-co)** | **5** | **2** pkgs | ğŸ’ª Package Advanced | **gin**: 4 â€¢ **gorm**: 1 |\n| 5 | <img src=\"https://github.com/father-frog.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[father-frog](https://github.com/father-frog)** | **4** | **1** pkg | ğŸš€ Package Intermediate | **gin**: 4 |\n| 6 | <img src=\"https://github.com/q1ngy.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[q1ngy](https://github.com/q1ngy)** | **4** | **1** pkg | ğŸš€ Package Intermediate | **gin**: 4 |\n| 7 | <img src=\"https://github.com/BrianHuang813.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[BrianHuang813](https://github.com/BrianHuang813)** | **3** | **1** pkg | ğŸš€ Package Intermediate | **gin**: 3 |\n| 8 | <img src=\"https://github.com/Kinsue.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[Kinsue](https://github.com/Kinsue)** | **3** | **2** pkgs | ğŸš€ Package Intermediate | **gin**: 2 â€¢ **gorm**: 1 |\n| 9 | <img src=\"https://github.com/ashwinipatankar.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[ashwinipatankar](https://github.com/ashwinipatankar)** â¤ï¸ | **3** | **1** pkg | ğŸš€ Package Intermediate | **cobra**: 3 |\n| 10 | <img src=\"https://github.com/aswinsreeraj.png\" width=\"24\" height=\"24\" style=\"border-radius: 50%;\"><br/>**[aswinsreeraj](https://github.com/aswinsreeraj)** | **3** | **1** pkg | ğŸš€ Package Intermediate | **gorm**: 3 |\n\n<div align=\"center\">\n\nğŸš€ **Package Challenges** - Learn Go packages through practical, real-world scenarios\n\n</div>\n\n### ğŸ“¦ Per-Package Progress\n\n#### Cobra Package\n\n| Rank | Developer | Completed | Progress |\n|:---:|:---:|:---:|:---|\n| ğŸ¥‡ | **[PolinaSvet](https://github.com/PolinaSvet)** | 4/4 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ© 100% |\n| ğŸ¥ˆ | **[odelbos](https://github.com/odelbos)** | 4/4 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ© 100% |\n| ğŸ¥‰ | **[ashwinipatankar](https://github.com/ashwinipatankar)** | 3/4 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œ 75% |\n| 4 | **[RezaSi](https://github.com/RezaSi)** | 1/4 | ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œ 25% |\n\n#### Echo Package\n\n| Rank | Developer | Completed | Progress |\n|:---:|:---:|:---:|:---|\n| ğŸ¥‡ | **[RezaSi](https://github.com/RezaSi)** | 1/4 | ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œ 25% |\n\n#### Fiber Package\n\n| Rank | Developer | Completed | Progress |\n|:---:|:---:|:---:|:---|\n| ğŸ¥‡ | **[odelbos](https://github.com/odelbos)** | 4/4 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ© 100% |\n| ğŸ¥ˆ | **[RezaSi](https://github.com/RezaSi)** | 1/4 | ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œ 25% |\n\n#### Gin Package\n\n| Rank | Developer | Completed | Progress |\n|:---:|:---:|:---:|:---|\n| ğŸ¥‡ | **[22-7-co](https://github.com/22-7-co)** | 4/4 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ© 100% |\n| ğŸ¥ˆ | **[PolinaSvet](https://github.com/PolinaSvet)** | 4/4 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ© 100% |\n| ğŸ¥‰ | **[father-frog](https://github.com/father-frog)** | 4/4 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ© 100% |\n| 4 | **[odelbos](https://github.com/odelbos)** | 4/4 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ© 100% |\n| 5 | **[q1ngy](https://github.com/q1ngy)** | 4/4 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ© 100% |\n\n#### Gorm Package\n\n| Rank | Developer | Completed | Progress |\n|:---:|:---:|:---:|:---|\n| ğŸ¥‡ | **[odelbos](https://github.com/odelbos)** | 5/5 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ© 100% |\n| ğŸ¥ˆ | **[aswinsreeraj](https://github.com/aswinsreeraj)** | 3/5 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œâ¬œ 60% |\n| ğŸ¥‰ | **[grozdovk](https://github.com/grozdovk)** | 2/5 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œâ¬œâ¬œâ¬œ 40% |\n| 4 | **[22-7-co](https://github.com/22-7-co)** | 1/5 | ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œ 20% |\n| 5 | **[Kinsue](https://github.com/Kinsue)** | 1/5 | ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œ 20% |\n\n#### Mongodb Package\n\n| Rank | Developer | Completed | Progress |\n|:---:|:---:|:---:|:---|\n| ğŸ¥‡ | **[RezaSi](https://github.com/RezaSi)** | 2/5 | ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œâ¬œâ¬œâ¬œ 40% |\n\n### ğŸ“Š Package Challenge Statistics\n\n- **Total Package Challenges Available**: 26\n- **Active Package Learners**: 27\n- **Available Packages**: 6 (cobra, echo, fiber, gin, gorm, mongodb)\n\n- **Most Package Challenges Solved**: 17 by odelbos\n\n<!-- END_PACKAGE_LEADERBOARD -->\n## Key Features\n\n- **Interactive Web UI** - Code, test, and submit solutions in your browser\n- **Automated Testing** - Get immediate feedback on your solutions\n- **Automated Scoreboards** - Solutions are automatically scored and ranked\n- **Profile Badges** - Beautiful auto-updating badges for GitHub profiles, LinkedIn, and portfolios\n- **Performance Analytics** - Track execution time and memory usage for your solutions\n- **Comprehensive Learning** - Each challenge includes detailed explanations and resources\n- **Progressive Difficulty** - From beginner to advanced Go concepts\n- **AI Interview Simulation** - Practice with AI-powered code review and interviewer questions\n\n## AI Interview Simulation\n\nTransform your coding practice into realistic interview scenarios with our AI-powered features:\n\n**Real-Time Code Review** - Get instant feedback on code quality, complexity analysis, and improvement suggestions\n\n**Dynamic Interview Questions** - AI generates follow-up questions based on your solution approach\n\n**Progressive Hints** - 4-level hint system from subtle nudges to detailed explanations\n\n**Multi-LLM Support** - Works with Gemini (recommended), OpenAI, or Claude\n\nSimply add your API key to experience interview-style feedback that adapts to your code and challenges you with realistic technical questions.\n\n### AI Interview Experience\n\n<div align=\"center\">\n  <img src=\"./images/interview-code-review.png\" alt=\"AI Code Review - Real-time feedback and analysis\" width=\"48%\" style=\"margin-right: 2%;\">\n  <img src=\"./images/interview-questions.png\" alt=\"AI Interview Questions - Dynamic follow-up questions\" width=\"48%\">\n</div>\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\" width=\"48%\">\n        <strong>AI Code Review</strong><br>\n        <em>Get instant feedback on code quality, complexity analysis,<br>and improvement suggestions from AI</em>\n      </td>\n      <td align=\"center\" width=\"48%\">\n        <strong>Dynamic Interview Questions</strong><br>\n        <em>AI generates follow-up questions based on your<br>solution approach and coding patterns</em>\n      </td>\n    </tr>\n  </table>\n</div>\n\n---\n\n## Quick Start\n\n> **Important**: You must fork this repository first before cloning, otherwise you won't be able to push your solutions or create pull requests!\n\n### Option 1: Web UI (Recommended)\n\n```bash\n# 1. First, fork this repository on GitHub\n#    Go to https://github.com/RezaSi/go-interview-practice\n#    Click the \"Fork\" button in the top-right corner\n\n# 2. Clone your forked repository (replace 'yourusername' with your GitHub username)\ngit clone https://github.com/yourusername/go-interview-practice.git\ncd go-interview-practice\n\n# 3. Start the web interface\ncd web-ui\ngo run main.go\n\n# 4. Open http://localhost:8080 in your browser\n\n# 5. Optional: Enable AI Features (Recommended) ğŸ¤–\n# Add your free Gemini API key to enable AI interview simulation\necho \"AI_PROVIDER=gemini\" > web-ui/.env\necho \"GEMINI_API_KEY=your_actual_api_key_here\" >> web-ui/.env\n# Get your free API key: https://makersuite.google.com/app/apikey\n# Note: .env files are automatically ignored by git for security\n```\n\n**After solving challenges and submitting solutions:**\n- Your solutions will be automatically saved to your local repository\n- Follow the provided Git commands to commit and push your changes\n- Create a pull request to contribute your solutions back to the main project\n\n### Option 2: GitHub Codespaces (Cloud Development + Web UI)\n\nWant to get started instantly without setting up anything locally? Use GitHub Codespaces!\n\n1. **Fork this repository** (if you haven't already)\n2. **Open in Codespaces**: Click the green \"Code\" button on your forked repository, then select \"Codespaces\" tab\n3. **Create Codespace**: Click \"Create codespace on main\"\n4. **Start the Web UI**: Once the codespace loads, open a terminal and run:\n   ```bash\n   cd web-ui\n   go run main.go\n   ```\n5. **Optional: Enable AI Features**: Add your Gemini API key:\n   ```bash\n   echo \"AI_PROVIDER=gemini\" > .env\n   echo \"GEMINI_API_KEY=your_actual_api_key_here\" >> .env\n   ```\n6. **Access the Web UI**: Click on the \"Ports\" tab in the bottom panel, then click the \"Open in Browser\" button next to port 8080\n\n**Benefits of using Codespaces:**\n- No local setup required\n- Pre-configured Go environment\n- Full VS Code experience in the browser\n- Automatic port forwarding for the web UI\n- All dependencies pre-installed\n- Works on any device with a browser\n\n<!--\n### Option 3: Railway Deployment (One-Click Cloud Hosting)\n\nDeploy your own instance of the platform to the cloud with Railway!\n\n[![Deploy on Railway](https://railway.com/button.svg)](https://railway.com/deploy/go-interview-practice?referralCode=F6emx6&utm_medium=integration&utm_source=template&utm_campaign=generic)\n\n**Perfect for:**\n- **Teams & Organizations**: Private instance for internal use\n- **Educators**: Custom environment for students\n- **Customization**: Fork and modify for specific needs\n- **Always Available**: 24/7 cloud hosting with automatic scaling\n\n**Setup Steps:**\n1. **Click Deploy Button** above\n2. **Configure AI Features** (optional but recommended):\n   - Choose AI provider: `gemini` (recommended - free tier)\n   - Add API key: [Get free Gemini key](https://makersuite.google.com/app/apikey)\n3. **Access Your Platform**: Railway provides instant public URL\n4. **Start Using**: Full platform with all challenges immediately available\n-->\n\n### Option 3: Command Line\n\n```bash\n# 1. Fork the repository first (see step 1 above)\n# 2. Clone your fork and set up a challenge workspace\ngit clone https://github.com/yourusername/go-interview-practice.git\ncd go-interview-practice\n./create_submission.sh 1  # For challenge #1\n\n# 3. Implement your solution in the editor of your choice\n\n# 4. Run tests\ncd challenge-1\n./run_tests.sh\n```\n\n## Profile Badges for Contributors\n\nShowcase your Go programming achievements with auto-updating profile badges for GitHub profiles, portfolios, and personal websites.\n\n### Examples\n\n[![Go Interview Practice Achievement](https://raw.githubusercontent.com/RezaSi/go-interview-practice/main/badges/RezaSi.svg)](https://github.com/RezaSi/go-interview-practice)\n\n[![Go Interview Practice Compact](https://raw.githubusercontent.com/RezaSi/go-interview-practice/main/badges/RezaSi_compact.svg)](https://github.com/RezaSi/go-interview-practice)\n\n### Quick Usage\n\n```markdown\n[![Go Interview Practice Achievement](https://raw.githubusercontent.com/RezaSi/go-interview-practice/main/badges/YOUR_USERNAME.svg)](https://github.com/RezaSi/go-interview-practice)\n```\n\nAfter contributing solutions, your badges are automatically generated in [`badges/YOUR_USERNAME_badges.md`](badges/) with multiple formats ready to use.\n\n**[Complete Badge Guide & Examples â†’](docs/profile-badges-guide.md)**\n\n## Challenge Categories\n\n### Beginner\nPerfect for those new to Go or brushing up on fundamentals\n- **[Challenge 1](./challenge-1)**: Sum of Two Numbers\n- **[Challenge 2](./challenge-2)**: Reverse a String\n- **[Challenge 3](./challenge-3)**: Employee Data Management\n- **[Challenge 6](./challenge-6)**: Word Frequency Counter\n- **[Challenge 18](./challenge-18)**: Temperature Converter\n- **[Challenge 21](./challenge-21)**: Binary Search Implementation\n- **[Challenge 22](./challenge-22)**: Greedy Coin Change\n\n### Intermediate\nFor developers familiar with Go who want to deepen their knowledge\n- **[Challenge 4](./challenge-4)**: Concurrent Graph BFS Queries\n- **[Challenge 5](./challenge-5)**: HTTP Authentication Middleware\n- **[Challenge 7](./challenge-7)**: Bank Account with Error Handling\n- **[Challenge 10](./challenge-10)**: Polymorphic Shape Calculator\n- **[Challenge 13](./challenge-13)**: SQL Database Operations\n- **[Challenge 14](./challenge-14)**: Microservices with gRPC\n- **[Challenge 16](./challenge-16)**: Performance Optimization\n- **[Challenge 17](./challenge-17)**: Interactive Debugging Tutorial\n- **[Challenge 19](./challenge-19)**: Slice Operations\n- **[Challenge 20](./challenge-20)**: Circuit Breaker Pattern\n- **[Challenge 23](./challenge-23)**: String Pattern Matching\n- **[Challenge 27](./challenge-27)**: Go Generics Data Structures\n- **[Challenge 30](./challenge-30)**: Context Management Implementation\n\n### Advanced\nChallenging problems that test mastery of Go and computer science concepts\n- **[Challenge 8](./challenge-8)**: Chat Server with Channels\n- **[Challenge 9](./challenge-9)**: RESTful Book Management API\n- **[Challenge 11](./challenge-11)**: Concurrent Web Content Aggregator\n- **[Challenge 12](./challenge-12)**: File Processing Pipeline\n- **[Challenge 15](./challenge-15)**: OAuth2 Authentication\n- **[Challenge 24](./challenge-24)**: Dynamic Programming - Longest Increasing Subsequence\n- **[Challenge 25](./challenge-25)**: Graph Algorithms - Shortest Path\n- **[Challenge 26](./challenge-26)**: Regular Expression Text Processor\n- **[Challenge 28](./challenge-28)**: Cache Implementation with Multiple Eviction Policies\n- **[Challenge 29](./challenge-29)**: Rate Limiter Implementation\n\n## How to Use This Repository\n\n### 1. Explore Challenges\nBrowse challenges through the web UI or in the code repository. Each challenge includes:\n- Detailed problem statement\n- Function signature to implement\n- Comprehensive test cases\n- Learning resources\n\n### 2. Implement Your Solution\nWrite code that solves the challenge requirements and passes all test cases.\n\n### 3. Test & Refine\nUse the built-in testing tools to validate your solution, then refine it for:\n- Correctness\n- Efficiency\n- Code quality\n\n### 4. Submit & Compare\nSubmit your passing solution to be added to the scoreboard:\n- Your solution is automatically tested and scored\n- Execution time and resource usage are recorded\n- Your solution is ranked among other submissions\n- Access detailed performance metrics to optimize further\n\n### 5. Learn & Progress\nReview the learning materials to deepen your understanding of the concepts used.\n\n## Contributing\n\nWe welcome contributions! You can contribute in several ways:\n\n**Submit Solutions:**\n- Solve existing classic or package challenges\n- Submit your solutions via pull request\n\n**Add New Challenges:**\n- **Package Challenges:** Framework-specific practical applications (Gin, Cobra, GORM, etc.)\n\n**Quick Steps:**\n1. Fork the repository\n2. Choose challenge type (classic or package-based)\n3. Follow our template structure\n4. Submit a pull request\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines on both challenge types.\n\n---\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Stargazers over time\n[![Stargazers over time](https://starchart.cc/RezaSi/go-interview-practice.svg?variant=adaptive)](https://starchart.cc/RezaSi/go-interview-practice)\n\n---\n\n## ğŸ¢ Premium Sponsors\n\n*Thank you to our premium sponsors who make this project possible!*\n\n### ğŸ¥ˆ Silver Sponsors\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\">\n        <a href=\"https://coderabbit.ai\" target=\"_blank\">\n          <img src=\"https://github.com/coderabbitai.png\" alt=\"CodeRabbit\" width=\"80\" height=\"80\" style=\"border-radius: 20px; border: 2px solid #e1e5e9;\">\n        </a>\n        <br>\n      </td>\n    </tr>\n  </table>\n</div>\n\n### ğŸ—ï¸ Infrastructure Sponsors\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\">\n        <a href=\"https://sentry.io\" target=\"_blank\">\n          <img src=\"https://github.com/sentry.png\" alt=\"Sentry\" width=\"80\" height=\"80\" style=\"border-radius: 20px; border: 2px solid #e1e5e9;\">\n        </a>\n        <br>\n      </td>\n    </tr>\n  </table>\n</div>\n\n\n###### Interested in premium sponsorship? [Contact us](https://github.com/sponsors/RezaSi) to feature your company logo here and on our platform!\n\n---\n\n\n**Happy Coding!** ğŸ’»\n",
      "stars_today": 21
    },
    {
      "id": 48109239,
      "name": "cilium",
      "full_name": "cilium/cilium",
      "description": "eBPF-based Networking, Security, and Observability",
      "html_url": "https://github.com/cilium/cilium",
      "stars": 23351,
      "forks": 3537,
      "language": "Go",
      "topics": [
        "bpf",
        "cncf",
        "cni",
        "containers",
        "ebpf",
        "k8s",
        "kernel",
        "kubernetes",
        "kubernetes-networking",
        "loadbalancing",
        "monitoring",
        "networking",
        "observability",
        "security",
        "troubleshooting",
        "xdp"
      ],
      "created_at": "2015-12-16T12:33:31Z",
      "updated_at": "2026-01-16T00:59:26Z",
      "pushed_at": "2026-01-15T19:59:38Z",
      "open_issues": 980,
      "owner": {
        "login": "cilium",
        "avatar_url": "https://avatars.githubusercontent.com/u/21054566?v=4"
      },
      "readme": ".. raw:: html\n\n   <picture>\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://cdn.jsdelivr.net/gh/cilium/cilium@main/Documentation/images/logo.png\" width=\"350\" alt=\"Cilium Logo\">\n      <img src=\"https://cdn.jsdelivr.net/gh/cilium/cilium@main/Documentation/images/logo-dark.png\" width=\"350\" alt=\"Cilium Logo\">\n   </picture>\n\n|cii| |go-report| |clomonitor| |artifacthub| |slack| |go-doc| |rtd| |apache| |bsd| |gpl| |fossa| |gateway-api| |codespaces|\n\nCilium is a networking, observability, and security solution with an eBPF-based\ndataplane. It provides a simple flat Layer 3 network with the ability to span\nmultiple clusters in either a native routing or overlay mode. It is L7-protocol\naware and can enforce network policies on L3-L7 using an identity based security\nmodel that is decoupled from network addressing.\n\nCilium implements distributed load balancing for traffic between pods and to\nexternal services, and is able to fully replace kube-proxy, using efficient\nhash tables in eBPF allowing for almost unlimited scale. It also supports\nadvanced functionality like integrated ingress and egress gateway, bandwidth\nmanagement and service mesh, and provides deep network and security visibility and monitoring.\n\nA new Linux kernel technology called eBPF_ is at the foundation of Cilium. It\nsupports dynamic insertion of eBPF bytecode into the Linux kernel at various\nintegration points such as: network IO, application sockets, and tracepoints to\nimplement security, networking and visibility logic. eBPF is highly efficient\nand flexible. To learn more about eBPF, visit `eBPF.io`_.\n\n.. image:: Documentation/images/cilium-overview.png\n   :alt: Overview of Cilium features for networking, observability, service mesh, and runtime security\n\n.. raw:: html\n\n   <a href=\"https://cncf.io/\">\n      <picture>\n         <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/cncf/artwork/blob/main/other/cncf-member/graduated/color/cncf-graduated-color.svg\" />\n         <img src=\"https://github.com/cncf/artwork/blob/main/other/cncf-member/graduated/white/cncf-graduated-white.svg\" alt=\"CNCF Graduated Project\" height=\"80\" />\n      </picture>\n   </a>\n   <a href=\"https://ebpf.io/\">\n      <picture>\n         <source media=\"(prefers-color-scheme: light)\" srcset=\".github/assets/ebpf-horizontal.svg\" />\n         <img src=\".github/assets/ebpf-horizontal-dark-back.svg\" alt=\"eBPF Logo\" height=\"80\" align=\"right\" />\n      </picture>\n   </a>\n\nStable Releases\n===============\n\nThe Cilium community maintains minor stable releases for the last three minor\nCilium versions. Older Cilium stable versions from minor releases prior to that\nare considered EOL.\n\nFor upgrades to new minor releases please consult the `Cilium Upgrade Guide`_.\n\nListed below are the actively maintained release branches along with their latest\npatch release, corresponding image pull tags and their release notes:\n\n+---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+\n| `v1.18 <https://github.com/cilium/cilium/tree/v1.18>`__ | 2026-01-13 | ``quay.io/cilium/cilium:v1.18.6``  | `Release Notes <https://github.com/cilium/cilium/releases/tag/v1.18.6>`__  |\n+---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+\n| `v1.17 <https://github.com/cilium/cilium/tree/v1.17>`__ | 2026-01-13 | ``quay.io/cilium/cilium:v1.17.12`` | `Release Notes <https://github.com/cilium/cilium/releases/tag/v1.17.12>`__ |\n+---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+\n| `v1.16 <https://github.com/cilium/cilium/tree/v1.16>`__ | 2026-01-13 | ``quay.io/cilium/cilium:v1.16.19`` | `Release Notes <https://github.com/cilium/cilium/releases/tag/v1.16.19>`__ |\n+---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+\n\nArchitectures\n-------------\n\nCilium images are distributed for AMD64 and AArch64 architectures.\n\nSoftware Bill of Materials\n--------------------------\n\nStarting with Cilium version 1.13.0, all images include a Software Bill of\nMaterials (SBOM). The SBOM is generated in `SPDX`_ format. More information\non this is available on `Cilium SBOM`_.\n\n.. _`SPDX`: https://spdx.dev/\n.. _`Cilium SBOM`: https://docs.cilium.io/en/latest/configuration/sbom/\n\nDevelopment\n===========\n\nFor development and testing purpose, the Cilium community publishes snapshots,\nearly release candidates (RC) and CI container images build from the `main\nbranch <https://github.com/cilium/cilium/commits/main>`_. These images are\nnot for use in production.\n\nFor testing upgrades to new development releases please consult the latest\ndevelopment build of the `Cilium Upgrade Guide`_.\n\nListed below are branches for testing along with their snapshots or RC releases,\ncorresponding image pull tags and their release notes where applicable:\n\n+----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+\n| `main <https://github.com/cilium/cilium/commits/main>`__                   | daily      | ``quay.io/cilium/cilium-ci:latest``     | N/A                                                                             |\n+----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+\n| `v1.19.0-rc.0 <https://github.com/cilium/cilium/commits/v1.19.0-rc.0>`__   | 2026-01-15 | ``quay.io/cilium/cilium:v1.19.0-rc.0``  | `Release Notes <https://github.com/cilium/cilium/releases/tag/v1.19.0-rc.0>`__  |\n+----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+\n\nFunctionality Overview\n======================\n\n.. begin-functionality-overview\n\nCNI (Container Network Interface)\n---------------------------------\n\n`Cilium as a CNI plugin <https://cilium.io/use-cases/cni/>`_ provides a\nfast, scalable, and secure networking layer for Kubernetes clusters. Built\non eBPF, it offers several deployment options:\n\n* **Overlay networking:** encapsulation-based virtual network spanning all\n  hosts with support for VXLAN and Geneve. It works on almost any network\n  infrastructure as the only requirement is IP connectivity between hosts\n  which is typically already given.\n\n* **Native routing mode:** Use of the regular routing table of the Linux\n  host. The network is required to be capable of routing the IP addresses\n  of the application containers. It integrates with cloud routers, routing\n  daemons, and IPv6-native infrastructure.\n\n* **Flexible routing options:** Cilium can automate route learning and\n  advertisement in common topologies such as using L2 neighbor discovery\n  when nodes share a layer 2 domain, or BGP when routing across layer 3\n  boundaries.\n\nEach mode is designed for maximum interoperability with existing\ninfrastructure while minimizing operational burden.\n\nLoad Balancing\n--------------\n\nCilium implements distributed load balancing for traffic between application\ncontainers and to/from external services. The load balancing is implemented\nin eBPF using efficient hashtables enabling high service density and low\nlatency at scale.\n\n* **East-west load balancing** rewrites service connections at the socket\n  level (``connect()``), avoiding the overhead of per-packet NAT and fully\n  `replacing kube-proxy <https://cilium.io/use-cases/kube-proxy/>`_.\n\n* **North-south load balancing** supports XDP for high-throughput scenarios\n  and `layer 4 load balancing <https://cilium.io/use-cases/load-balancer/>`_\n  including Direct Server Return (DSR), and Maglev consistent hashing.\n\nCluster Mesh\n------------\n\nCilium `Cluster Mesh <https://cilium.io/use-cases/cluster-mesh/>`_ enables\nsecure, seamless connectivity across multiple Kubernetes clusters. For\noperators running hybrid or multi-cloud environments, Cluster Mesh ensures\na consistent security and connectivity experience.\n\n* **Global service discovery**: Workloads across clusters can discover and\n  connect to services as if they were local. This enables fault tolerance,\n  like automatically failing over to backends in another cluster, and\n  exposes shared services like logging, auth, or databases across\n  environments.\n\n* **Unified identity model:** Security policies are enforced based on\n  identity, not IP address, across all clusters.\n\nNetwork Policy\n--------------\n\nCilium `Network Policy <https://cilium.io/use-cases/network-policy/>`_\nprovides identity-aware enforcement across L3-L7. Typical container\nfirewalls secure workloads by filtering on source IP addresses and\ndestination ports. This concept requires the firewalls on all servers to be\nmanipulated whenever a container is started anywhere in the cluster.\n\nIn order to avoid this situation which limits scale, Cilium assigns a\nsecurity identity to groups of application containers which share identical\nsecurity policies. The identity is then associated with all network packets\nemitted by the application containers, allowing to validate the identity at\nthe receiving node.\n\n* **Identity-based security** removes reliance on brittle IP addresses.\n\n* **L3/L4 policies** restrict traffic based on labels, protocols, and ports.\n\n* **DNS-based policies:** Allow or deny traffic to FQDNs or wildcard domains\n   (e.g., ``api.example.com``, ``*.trusted.com``). This is especially useful\n   for securing egress traffic to third-party services.\n\n* **L7-aware policies** allow filtering by HTTP method, URL path, gRPC call,\n  and more:\n\n  * Example: Allow only GET requests to ``/public/.*``.\n\n  * Enforce the presence of headers like ``X-Token: [0-9]+``.\n\nCIDR-based egress and ingress policies are also supported for controlling\naccess to external IPs, ideal for integrating with legacy systems or\nregulatory boundaries.\n\nService Mesh\n------------\n\nWith Cilium `Service Mesh <https://cilium.io/use-cases/service-mesh/>`_,\noperators gain the benefits of fine-grained traffic control, encryption, observability,\naccess control, without the cost and complexity of traditional proxy-based\ndesigns. Key features include:\n\n* **Mutual authentication** with automatic identity-based encryption between\n  workloads using IPSec or WireGuard.\n\n* **L7-aware policy enforcement** for security and compliance.\n\n* **Deep integration with the Kubernetes Gateway API :** Acts as a\n  `Gateway API <https://cilium.io/use-cases/gateway-api/>`_ compliant data\n  plane, allowing you to declaratively manage ingress, traffic splitting, and\n  routing behavior using Kubernetes-native CRDs.\n\nObservability and Troubleshooting\n---------------------------------\n\nObservability is built into Cilium from the ground up, providing rich\nvisibility that helps operators diagnose and understand system behavior\nincluding:\n\n* **Hubble**: A fully integrated observability platform that offers\n  real-time service maps, flow visibility with identity and label metadata,\n  and DNS-aware filtering and protocol-specific insights\n\n* **Metrics and alerting**: Integration with Prometheus, Grafana, and other\n  monitoring systems.\n\n* **Drop reasons and audit trails**: Get actionable insights into why traffic\n  was dropped, including policy or port violations and issues like failed\n  DNS lookups.\n\n.. end-functionality-overview\n\nGetting Started\n===============\n\n* `Why Cilium?`_\n* `Getting Started`_\n* `Architecture and Concepts`_\n* `Installing Cilium`_\n* `Frequently Asked Questions`_\n* Contributing_\n\nCommunity\n=========\n\nSlack\n-----\n\nJoin the Cilium `Slack channel <https://slack.cilium.io>`_ to chat with\nCilium developers and other Cilium users. This is a good place to learn about\nCilium, ask questions, and share your experiences.\n\nSpecial Interest Groups (SIG)\n-----------------------------\n\nSee `Special Interest groups\n<https://github.com/cilium/community/blob/main/sigs.yaml>`_ for a list of all SIGs and their meeting times.\n\nDeveloper meetings\n------------------\nThe Cilium developer community hangs out on Zoom to chat. Everybody is welcome.\n\n* Weekly, Wednesday,\n  5:00 pm `Europe/Zurich time <https://time.is/Canton_of_Zurich>`__ (CET/CEST),\n  usually equivalent to 8:00 am PT, or 11:00 am ET. `Meeting Notes and Zoom Info`_\n* Third Wednesday of each month, 9:00 am `Japan time <https://time.is/Tokyo>`__ (JST). `APAC Meeting Notes and Zoom Info`_\n\neBPF & Cilium Office Hours livestream\n-------------------------------------\nWe host a weekly community `YouTube livestream called eCHO <https://www.youtube.com/channel/UCJFUxkVQTBJh3LD1wYBWvuQ>`_ which (very loosely!) stands for eBPF & Cilium Office Hours. Join us live, catch up with past episodes, or head over to the `eCHO repo <https://github.com/isovalent/eCHO>`_ and let us know your ideas for topics we should cover.\n\nGovernance\n----------\nThe Cilium project is governed by a group of `Maintainers and Committers <https://raw.githubusercontent.com/cilium/cilium/main/MAINTAINERS.md>`__.\nHow they are selected and govern is outlined in our `governance document <https://github.com/cilium/community/blob/main/GOVERNANCE.md>`__.\n\nAdopters\n--------\nA list of adopters of the Cilium project who are deploying it in production, and of their use cases,\ncan be found in file `USERS.md <https://github.com/cilium/cilium/blob/main/USERS.md>`__.\n\nLicense\n=======\n\n.. _apache-license: LICENSE\n.. _bsd-license: bpf/LICENSE.BSD-2-Clause\n.. _gpl-license: bpf/LICENSE.GPL-2.0\n\nThe Cilium user space components are licensed under the\n`Apache License, Version 2.0 <apache-license_>`__.\nThe BPF code templates are dual-licensed under the\n`General Public License, Version 2.0 (only) <gpl-license_>`__\nand the `2-Clause BSD License <bsd-license_>`__\n(you can use the terms of either license, at your option).\n\n.. _`Cilium Upgrade Guide`: https://docs.cilium.io/en/stable/operations/upgrade/\n.. _`Why Cilium?`: https://docs.cilium.io/en/stable/overview/intro\n.. _`Getting Started`: https://docs.cilium.io/en/stable/#getting-started\n.. _`Architecture and Concepts`: https://docs.cilium.io/en/stable/overview/component-overview/\n.. _`Installing Cilium`: https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/\n.. _`Frequently Asked Questions`: https://github.com/cilium/cilium/issues?utf8=%E2%9C%93&q=is%3Aissue+label%3Akind%2Fquestion+\n.. _Contributing: https://docs.cilium.io/en/stable/contributing/development/\n.. _Prerequisites: https://docs.cilium.io/en/stable/operations/system_requirements/\n.. _`eBPF`: https://ebpf.io\n.. _`eBPF.io`: https://ebpf.io\n.. _`Meeting Notes and Zoom Info`: https://docs.google.com/document/d/1Y_4chDk4rznD6UgXPlPvn3Dc7l-ZutGajUv1eF0VDwQ/edit#\n.. _`APAC Meeting Notes and Zoom Info`: https://docs.google.com/document/d/1egv4qLydr0geP-GjQexYKm4tz3_tHy-LCBjVQcXcT5M/edit#\n\n.. |go-report| image:: https://goreportcard.com/badge/github.com/cilium/cilium\n    :alt: Go Report Card\n    :target: https://goreportcard.com/report/github.com/cilium/cilium\n\n.. |go-doc| image:: https://godoc.org/github.com/cilium/cilium?status.svg\n    :alt: GoDoc\n    :target: https://godoc.org/github.com/cilium/cilium\n\n.. |rtd| image:: https://readthedocs.org/projects/docs/badge/?version=latest\n    :alt: Read the Docs\n    :target: https://docs.cilium.io/\n\n.. |apache| image:: https://img.shields.io/badge/license-Apache-blue.svg\n    :alt: Apache licensed\n    :target: apache-license_\n\n.. |bsd| image:: https://img.shields.io/badge/license-BSD-blue.svg\n    :alt: BSD licensed\n    :target: bsd-license_\n\n.. |gpl| image:: https://img.shields.io/badge/license-GPL-blue.svg\n    :alt: GPL licensed\n    :target: gpl-license_\n\n.. |slack| image:: https://img.shields.io/badge/slack-cilium-brightgreen.svg?logo=slack\n    :alt: Join the Cilium slack channel\n    :target: https://slack.cilium.io\n\n.. |cii| image:: https://bestpractices.coreinfrastructure.org/projects/1269/badge\n    :alt: CII Best Practices\n    :target: https://bestpractices.coreinfrastructure.org/projects/1269\n\n.. |clomonitor| image:: https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/cilium/badge\n    :alt: CLOMonitor\n    :target: https://clomonitor.io/projects/cncf/cilium\n\n.. |artifacthub| image:: https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/cilium\n    :alt: Artifact Hub\n    :target: https://artifacthub.io/packages/helm/cilium/cilium\n\n.. |fossa| image:: https://app.fossa.com/api/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git.svg?type=shield\n    :alt: FOSSA Status\n    :target: https://app.fossa.com/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git?ref=badge_shield\n\n.. |gateway-api| image:: https://img.shields.io/badge/Gateway%20API%20Conformance%20v1.2.0-Cilium-green\n    :alt: Gateway API Status\n    :target: https://github.com/kubernetes-sigs/gateway-api/tree/main/conformance/reports/v1.2.0/cilium-cilium\n\n.. |codespaces| image:: https://img.shields.io/badge/Open_in_GitHub_Codespaces-gray?logo=github\n    :alt: Github Codespaces\n    :target: https://github.com/codespaces/new?hide_repo_select=true&ref=master&repo=48109239&machine=standardLinux32gb&location=WestEurope\n",
      "stars_today": 20
    },
    {
      "id": 599431918,
      "name": "oxc",
      "full_name": "oxc-project/oxc",
      "description": "âš“ A collection of high-performance JavaScript tools.",
      "html_url": "https://github.com/oxc-project/oxc",
      "stars": 18396,
      "forks": 788,
      "language": "Rust",
      "topics": [
        "compiler",
        "javascript",
        "linter",
        "minifier",
        "parser",
        "transpiler",
        "typescript"
      ],
      "created_at": "2023-02-09T05:46:51Z",
      "updated_at": "2026-01-16T00:48:23Z",
      "pushed_at": "2026-01-16T00:48:21Z",
      "open_issues": 491,
      "owner": {
        "login": "oxc-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/149946238?v=4"
      },
      "readme": "<p align=\"center\">\n  <br>\n  <br>\n  <a href=\"https://oxc.rs\" target=\"_blank\" rel=\"noopener noreferrer\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://oxc.rs/oxc-light.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://oxc.rs/oxc-dark.svg\">\n      <img alt=\"Oxc logo\" src=\"https://oxc.rs/oxc-dark.svg\" height=\"60\">\n    </picture>\n  </a>\n  <br>\n  <br>\n  <br>\n</p>\n\n<div align=\"center\">\n\n[![MIT licensed][license-badge]][license-url]\n[![Build Status][ci-badge]][ci-url]\n[![Code Coverage][code-coverage-badge]][code-coverage-url]\n[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/oxc-project/oxc)\n[![Sponsors][sponsors-badge]][sponsors-url]\n\n[![Discord chat][discord-badge]][discord-url]\n[![Playground][playground-badge]][playground-url]\n[![Website][website-badge]][website-url]\n\n</div>\n\n## âš“ Oxc\n\n_/oÊŠ É›ks siË/_\n\nThe Oxidation Compiler is a collection of high-performance tools for JavaScript and TypeScript written in Rust.\n\nOxc is part of [VoidZero](https://voidzero.dev/)'s vision for a unified, high-performance toolchain for JavaScript. It powers [Rolldown](https://rolldown.rs) ([Vite]'s future bundler) and enables the next generation of ultra-fast development tools that work seamlessly together.\n\nFor more information, check out our website at [oxc.rs](https://oxc.rs).\n\n<sub>\\* Oxidation is the chemical process that creates rust</sub>\n\n## ğŸ—ï¸ Design Principles\n\n- **Performance**: Through rigorous performance engineering.\n- **Correctness**: Through conformance testing to standards and similar projects.\n- **Developer Experience**: Clear APIs, comprehensive documentation, and sensible configuration.\n- **Modular composability**: Use individual components independently or compose them into complete toolchains.\n\nRead more about our [architecture](https://oxc.rs/docs/learn/architecture/parser.html) and [performance philosophy](https://oxc.rs/docs/learn/performance).\n\n## ğŸ“¦ Tools & Packages\n\n| Tool        | npm                                                          | crates.io                                                   |\n| ----------- | ------------------------------------------------------------ | ----------------------------------------------------------- |\n| Linter      | [oxlint](https://www.npmjs.com/package/oxlint)               | -                                                           |\n| Formatter   | [oxfmt](https://www.npmjs.com/package/oxfmt)                 | -                                                           |\n| Parser      | [oxc-parser](https://www.npmjs.com/package/oxc-parser)       | [oxc_parser](https://crates.io/crates/oxc_parser)           |\n| Transformer | [oxc-transform](https://www.npmjs.com/package/oxc-transform) | [oxc_transformer](https://crates.io/crates/oxc_transformer) |\n| Minifier    | [oxc-minify](https://www.npmjs.com/package/oxc-minify)       | [oxc_minifier](https://crates.io/crates/oxc_minifier)       |\n| Resolver    | [oxc-resolver](https://www.npmjs.com/package/oxc-resolver)   | [oxc_resolver](https://crates.io/crates/oxc_resolver)       |\n\nSee [documentation](https://oxc.rs/) for detailed usage guides for each tool.\n\n## âš¡ï¸ Quick Start\n\n### Linter\n\nThe production-ready linter catches mistakes for you with sensible defaults and optional configuration:\n\n```bash\nnpx oxlint@latest\n```\n\nTo give you an idea of its capabilities, here is an example from the [vscode] repository, which finishes linting 4800+ files in 0.7 seconds:\n\n<p float=\"left\" align=\"left\">\n  <img src=\"https://cdn.jsdelivr.net/gh/oxc-project/oxc-assets/linter-screenshot.png\" width=\"60%\">\n</p>\n\nâ†’ [oxlint documentation](https://oxc.rs/docs/guide/usage/linter/cli.html)\n\n### Formatter\n\nFast, opinionated code formatter compatible with [Prettier]:\n\n```bash\nnpx oxfmt@latest\n```\n\nâ†’ [Formatter documentation](https://oxc.rs/docs/guide/usage/formatter)\n\n### Parser (Node.js)\n\nThe fastest JavaScript/TypeScript parser written in Rust:\n\n```bash\nnpm install oxc-parser\n```\n\n```js\nimport { parseSync } from \"oxc-parser\";\nconst result = parseSync(\"const x = 1;\");\n```\n\nâ†’ [Parser documentation](https://oxc.rs/docs/guide/usage/parser)\n\n### Transformer (Node.js)\n\nTypeScript, React, and modern JavaScript transformation:\n\n```bash\nnpm install oxc-transform\n```\n\n```js\nimport { transform } from \"oxc-transform\";\nconst result = transform(\"source.tsx\", code, { typescript: true });\n```\n\nâ†’ [Transformer documentation](https://oxc.rs/docs/guide/usage/transformer)\n\n### Minifier (Node.js)\n\nHigh-performance JavaScript minifier:\n\n```bash\nnpm install oxc-minify\n```\n\n```js\nimport { minify } from \"oxc-minify\";\nconst result = minify(code, { mangle: true });\n```\n\nâ†’ [Minifier documentation](https://oxc.rs/docs/guide/usage/minifier)\n\n### Rust\n\nIndividual crates are published for building your own JavaScript tools:\n\n```toml\n[dependencies]\noxc = \"0.x\"\n```\n\nâ†’ [Rust documentation](https://docs.rs/oxc)\n\n## VoidZero Inc.\n\nOxc is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/blog).\n\nIf you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!\n\n## ğŸ™‹ Who's using Oxc?\n\n[Rolldown] and [Nuxt] use Oxc for parsing. [Rolldown] also uses Oxc for transformation and minification. [Nova], [swc-node], and [knip] use [oxc_resolver][docs-resolver-url] for module resolution. [Preact], [Shopify], [ByteDance], and [Shopee] use oxlint for linting.\n\n[See more projects using Oxc â†’](https://oxc.rs/docs/guide/projects.html)\n\n## âœï¸ Contribute\n\nCheck out some of the [good first issues](https://github.com/oxc-project/oxc/contribute) or ask us on [Discord][discord-url].\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for guidance, or read the complete [contributing guide on our website â†’](https://oxc.rs/docs/contribute/introduction.html)\n\nIf you are unable to contribute by code, you can still participate by:\n\n- Add a [GitHub Star](https://github.com/oxc-project/oxc/stargazers) to the project\n- Join us on [Discord][discord-url]\n- [Follow me on X](https://x.com/boshen_c) and post about this project\n\n## ğŸ¤ Credits\n\nThis project was incubated with the assistance of these exceptional mentors and their projects:\n\n- [Biome][biome] - [@ematipico](https://github.com/ematipico)\n- [Ruff][ruff] - [@charliermarsh](https://github.com/charliermarsh), [@MichaReiser](https://github.com/MichaReiser)\n- [quick-lint-js](https://github.com/quick-lint/quick-lint-js) - [@strager](https://github.com/strager)\n- [elm-review](https://package.elm-lang.org/packages/jfmengels/elm-review/latest) - [@jfmengels](https://github.com/jfmengels)\n\nSpecial thanks go to:\n\n- [@domonji](https://github.com/domonji) for bootstrapping this project together and also completing the TypeScript parser\n- [@tongtong-lu](https://github.com/tongtong-lu) and [@guan-wy](https://github.com/guan-wy) for designing the [project logo](https://github.com/oxc-project/oxc-assets)\n\n## â¤ Who's [Sponsoring Oxc](https://github.com/sponsors/Boshen)?\n\n<p align=\"center\">\n  <a href=\"https://github.com/sponsors/Boshen\">\n    <img src=\"https://raw.githubusercontent.com/Boshen/sponsors/main/sponsors.svg\" alt=\"My sponsors\" />\n  </a>\n</p>\n\n## ğŸ“– License\n\nOxc is free and open-source software licensed under the [MIT License](./LICENSE).\n\nOxc ports or copies code from other open source projects, their licenses are listed in [**Third-party library licenses**](./THIRD-PARTY-LICENSE).\n\n[discord-badge]: https://img.shields.io/discord/1079625926024900739?logo=discord&label=Discord\n[discord-url]: https://discord.gg/9uXCAwqQZW\n[license-badge]: https://img.shields.io/badge/license-MIT-blue.svg\n[license-url]: https://github.com/oxc-project/oxc/blob/main/LICENSE\n[ci-badge]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml/badge.svg?event=push&branch=main\n[ci-url]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml?query=event%3Apush+branch%3Amain\n[code-coverage-badge]: https://codecov.io/gh/oxc-project/oxc/graph/badge.svg?token=FVHEH0BQLJ\n[code-coverage-url]: https://codecov.io/gh/oxc-project/oxc\n[sponsors-badge]: https://img.shields.io/github/sponsors/Boshen\n[sponsors-url]: https://github.com/sponsors/Boshen\n[playground-badge]: https://img.shields.io/badge/Playground-blue?color=9BE4E0\n[playground-url]: https://playground.oxc.rs/\n[website-badge]: https://img.shields.io/badge/Website-blue\n[website-url]: https://oxc.rs\n[docs-resolver-url]: https://docs.rs/oxc_resolver\n[biome]: https://biomejs.dev/\n[ruff]: https://beta.ruff.rs\n[vscode]: https://github.com/microsoft/vscode\n[rolldown]: https://rolldown.rs\n[vite]: https://vitejs.dev/\n[nuxt]: https://nuxt.com/\n[nova]: https://trynova.dev/\n[swc-node]: https://github.com/swc-project/swc-node\n[knip]: https://github.com/webpro/knip\n[preact]: https://preactjs.com/\n[shopify]: https://shopify.com/\n[bytedance]: https://www.bytedance.com/\n[shopee]: https://shopee.com/\n[prettier]: https://prettier.io/\n",
      "stars_today": 20
    },
    {
      "id": 507775,
      "name": "elasticsearch",
      "full_name": "elastic/elasticsearch",
      "description": "Free and Open Source, Distributed, RESTful Search Engine",
      "html_url": "https://github.com/elastic/elasticsearch",
      "stars": 75878,
      "forks": 25785,
      "language": "Java",
      "topics": [
        "elasticsearch",
        "java",
        "search-engine"
      ],
      "created_at": "2010-02-08T13:20:56Z",
      "updated_at": "2026-01-16T00:49:03Z",
      "pushed_at": "2026-01-16T00:48:55Z",
      "open_issues": 5370,
      "owner": {
        "login": "elastic",
        "avatar_url": "https://avatars.githubusercontent.com/u/6764390?v=4"
      },
      "readme": "= Elasticsearch\n\nElasticsearch is a distributed search and analytics engine, scalable data store and vector database optimized for speed and relevance on production-scale workloads. Elasticsearch is the foundation of Elastic's open Stack platform. Search in near real-time over massive datasets, perform vector searches, integrate with generative AI applications, and much more.\n\nUse cases enabled by Elasticsearch include:\n\n* https://www.elastic.co/search-labs/blog/articles/retrieval-augmented-generation-rag[Retrieval Augmented Generation (RAG)]\n* https://www.elastic.co/search-labs/blog/categories/vector-search[Vector search]\n* Full-text search\n* Logs\n* Metrics\n* Application performance monitoring (APM)\n* Security logs\n\n\\... and more!\n\nTo learn more about Elasticsearch's features and capabilities, see our\nhttps://www.elastic.co/products/elasticsearch[product page].\n\nTo access information on https://www.elastic.co/search-labs/blog/categories/ml-research[machine learning innovations] and the latest https://www.elastic.co/search-labs/blog/categories/lucene[Lucene contributions from Elastic], more information can be found in https://www.elastic.co/search-labs[Search Labs].\n\n[[get-started]]\n== Get started\n\nThe simplest way to set up Elasticsearch is to create a managed deployment with\nhttps://www.elastic.co/cloud/as-a-service[Elasticsearch Service on Elastic\nCloud].\n\nIf you prefer to install and manage Elasticsearch yourself, you can download\nthe latest version from\nhttps://www.elastic.co/downloads/elasticsearch[elastic.co/downloads/elasticsearch].\n\n=== Run Elasticsearch locally\n\n////\nIMPORTANT: This content is replicated in the Elasticsearch repo. See `run-elasticsearch-locally.asciidoc`.\nEnsure both files are in sync.\n\nhttps://github.com/elastic/start-local is the source of truth.\n////\n\n[WARNING]\n====\nDO NOT USE THESE INSTRUCTIONS FOR PRODUCTION DEPLOYMENTS.\n\nThis setup is intended for local development and testing only.\n====\n\nQuickly set up Elasticsearch and Kibana in Docker for local development or testing, using the https://github.com/elastic/start-local?tab=readme-ov-file#-try-elasticsearch-and-kibana-locally[`start-local` script].\n\nâ„¹ï¸ For more detailed information about the `start-local` setup, refer to the https://github.com/elastic/start-local[README on GitHub].\n\n==== Prerequisites\n\n- If you don't have Docker installed, https://www.docker.com/products/docker-desktop[download and install Docker Desktop] for your operating system.\n- If you're using Microsoft Windows, then install https://learn.microsoft.com/en-us/windows/wsl/install[Windows Subsystem for Linux (WSL)].\n\n==== Trial license\nThis setup comes with a one-month trial license that includes all Elastic features.\n\nAfter the trial period, the license reverts to *Free and open - Basic*.\nRefer to https://www.elastic.co/subscriptions[Elastic subscriptions] for more information.\n\n==== Run `start-local`\n\nTo set up Elasticsearch and Kibana locally, run the `start-local` script:\n\n[source,sh]\n----\ncurl -fsSL https://elastic.co/start-local | sh\n----\n// NOTCONSOLE\n\nThis script creates an `elastic-start-local` folder containing configuration files and starts both Elasticsearch and Kibana using Docker.\n\nAfter running the script, you can access Elastic services at the following endpoints:\n\n* *Elasticsearch*: http://localhost:9200\n* *Kibana*: http://localhost:5601\n\nThe script generates a random password for the `elastic` user, which is displayed at the end of the installation and stored in the `.env` file.\n\n[CAUTION]\n====\nThis setup is for local testing only. HTTPS is disabled, and Basic authentication is used for Elasticsearch. For security, Elasticsearch and Kibana are accessible only through `localhost`.\n====\n\n==== API access\n\nAn API key for Elasticsearch is generated and stored in the `.env` file as `ES_LOCAL_API_KEY`.\nUse this key to connect to Elasticsearch with a https://www.elastic.co/guide/en/elasticsearch/client/index.html[programming language client] or the https://www.elastic.co/guide/en/elasticsearch/reference/current/rest-apis.html[REST API].\n\nFrom the `elastic-start-local` folder, check the connection to Elasticsearch using `curl`:\n\n[source,sh]\n----\nsource .env\ncurl $ES_LOCAL_URL -H \"Authorization: ApiKey ${ES_LOCAL_API_KEY}\"\n----\n\nTo use the password for the `elastic` user, set and export the `ES_LOCAL_PASSWORD` environment variable. For example:\n\n[source,sh]\n----\nsource .env\nexport ES_LOCAL_PASSWORD\n----\n\n// NOTCONSOLE\n\n=== Send requests to Elasticsearch\n\nYou send data and other requests to Elasticsearch through REST APIs.\nYou can interact with Elasticsearch using any client that sends HTTP requests,\nsuch as the https://www.elastic.co/guide/en/elasticsearch/client/index.html[Elasticsearch\nlanguage clients] and https://curl.se[curl].\n\n==== Using curl\n\nHere's an example curl command to create a new Elasticsearch index, using basic auth:\n\n[source,sh]\n----\ncurl -u elastic:$ES_LOCAL_PASSWORD \\\n  -X PUT \\\n  http://localhost:9200/my-new-index \\\n  -H 'Content-Type: application/json'\n----\n\n// NOTCONSOLE\n\n==== Using a language client\n\nTo connect to your local dev Elasticsearch cluster with a language client, you can use basic authentication with the `elastic` username and the password stored in the `ES_LOCAL_PASSWORD` environment variable.\n\nYou'll use the following connection details:\n\n* **Elasticsearch endpoint**: `http://localhost:9200`\n* **Username**: `elastic`\n* **Password**: `$ES_LOCAL_PASSWORD` (Value you set in the environment variable)\n\nFor example, to connect with the Python `elasticsearch` client:\n\n[source,python]\n----\nimport os\nfrom elasticsearch import Elasticsearch\n\nusername = 'elastic'\npassword = os.getenv('ES_LOCAL_PASSWORD') # Value you set in the environment variable\n\nclient = Elasticsearch(\n    \"http://localhost:9200\",\n    basic_auth=(username, password)\n)\n\nprint(client.info())\n----\n\n==== Using the Dev Tools Console\n\nKibana's developer console provides an easy way to experiment and test requests.\nTo access the console, open Kibana, then go to **Management** > **Dev Tools**.\n\n**Add data**\n\nYou index data into Elasticsearch by sending JSON objects (documents) through the REST APIs.\nWhether you have structured or unstructured text, numerical data, or geospatial data,\nElasticsearch efficiently stores and indexes it in a way that supports fast searches.\n\nFor timestamped data such as logs and metrics, you typically add documents to a\ndata stream made up of multiple auto-generated backing indices.\n\nTo add a single document to an index, submit an HTTP post request that targets the index.\n\n----\nPOST /customer/_doc/1\n{\n  \"firstname\": \"Jennifer\",\n  \"lastname\": \"Walters\"\n}\n----\n\nThis request automatically creates the `customer` index if it doesn't exist,\nadds a new document that has an ID of 1, and\nstores and indexes the `firstname` and `lastname` fields.\n\nThe new document is available immediately from any node in the cluster.\nYou can retrieve it with a GET request that specifies its document ID:\n\n----\nGET /customer/_doc/1\n----\n\nTo add multiple documents in one request, use the `_bulk` API.\nBulk data must be newline-delimited JSON (NDJSON).\nEach line must end in a newline character (`\\n`), including the last line.\n\n----\nPUT customer/_bulk\n{ \"create\": { } }\n{ \"firstname\": \"Monica\",\"lastname\":\"Rambeau\"}\n{ \"create\": { } }\n{ \"firstname\": \"Carol\",\"lastname\":\"Danvers\"}\n{ \"create\": { } }\n{ \"firstname\": \"Wanda\",\"lastname\":\"Maximoff\"}\n{ \"create\": { } }\n{ \"firstname\": \"Jennifer\",\"lastname\":\"Takeda\"}\n----\n\n**Search**\n\nIndexed documents are available for search in near real-time.\nThe following search matches all customers with a first name of _Jennifer_\nin the `customer` index.\n\n----\nGET customer/_search\n{\n  \"query\" : {\n    \"match\" : { \"firstname\": \"Jennifer\" }\n  }\n}\n----\n\n**Explore**\n\nYou can use Discover in Kibana to interactively search and filter your data.\nFrom there, you can start creating visualizations and building and sharing dashboards.\n\nTo get started, create a _data view_ that connects to one or more Elasticsearch indices,\ndata streams, or index aliases.\n\n. Go to **Management > Stack Management > Kibana > Data Views**.\n. Select **Create data view**.\n. Enter a name for the data view and a pattern that matches one or more indices,\nsuch as _customer_.\n. Select **Save data view to Kibana**.\n\nTo start exploring, go to **Analytics > Discover**.\n\n[[upgrade]]\n== Upgrade\n\nTo upgrade from an earlier version of Elasticsearch, see the\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/setup-upgrade.html[Elasticsearch upgrade\ndocumentation].\n\n[[build-source]]\n== Build from source\n\nElasticsearch uses https://gradle.org[Gradle] for its build system.\n\nTo build a distribution for your local OS and print its output location upon\ncompletion, run:\n----\n./gradlew localDistro\n----\n\nTo build a distribution for another platform, run the related command:\n----\n./gradlew :distribution:archives:linux-tar:assemble\n./gradlew :distribution:archives:darwin-tar:assemble\n./gradlew :distribution:archives:windows-zip:assemble\n----\n\nDistributions are output to `distribution/archives`.\n\nTo run the test suite, see xref:TESTING.asciidoc[TESTING].\n\n[[docs]]\n== Documentation\n\nFor the complete Elasticsearch documentation visit\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/index.html[elastic.co].\n\nFor information about our documentation processes, see the\nxref:https://github.com/elastic/elasticsearch/blob/main/docs/README.md[docs README].\n\n[[examples]]\n== Examples and guides\n\nThe https://github.com/elastic/elasticsearch-labs[`elasticsearch-labs`] repo contains executable Python notebooks, sample apps, and resources to test out Elasticsearch for vector search, hybrid search and generative AI use cases.\n\n\n[[contribute]]\n== Contribute\n\nFor contribution guidelines, see xref:CONTRIBUTING.md[CONTRIBUTING].\n\n[[questions]]\n== Questions? Problems? Suggestions?\n\n* To report a bug or request a feature, create a\nhttps://github.com/elastic/elasticsearch/issues/new/choose[GitHub Issue]. Please\nensure someone else hasn't created an issue for the same topic.\n\n* Need help using Elasticsearch? Reach out on the\nhttps://discuss.elastic.co[Elastic Forum] or https://ela.st/slack[Slack]. A\nfellow community member or Elastic engineer will be happy to help you out.\n",
      "stars_today": 19
    },
    {
      "id": 169529567,
      "name": "ChromeAppHeroes",
      "full_name": "zhaoolee/ChromeAppHeroes",
      "description": "ğŸŒˆè°·ç²’-Chromeæ’ä»¶è‹±é›„æ¦œ, ä¸ºä¼˜ç§€çš„Chromeæ’ä»¶å†™ä¸€æœ¬ä¸­æ–‡è¯´æ˜ä¹¦, è®©Chromeæ’ä»¶è‹±é›„ä»¬é€ ç¦äººç±»~  ChromePluginHeroes, Write a Chinese manual for the excellent Chrome plugin, let the Chrome plugin heroes benefit the human~ å…¬ä¼—å·ã€Œ0åŠ 1ã€åŒæ­¥æ›´æ–°",
      "html_url": "https://github.com/zhaoolee/ChromeAppHeroes",
      "stars": 24173,
      "forks": 2499,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2019-02-07T06:35:24Z",
      "updated_at": "2026-01-15T21:07:28Z",
      "pushed_at": "2025-10-28T06:14:35Z",
      "open_issues": 39,
      "owner": {
        "login": "zhaoolee",
        "avatar_url": "https://avatars.githubusercontent.com/u/15868458?v=4"
      },
      "readme": "![è°·ç²’-Chromeæ’ä»¶è‹±é›„æ¦œ](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676801228PCyiDZRQ.jpeg)\n\n[![LICENSE](https://img.shields.io/badge/license-Anti%20996-blue.svg)](https://github.com/996icu/996.ICU/blob/master/LICENSE) [![996.icu](https://img.shields.io/badge/link-996.icu-red.svg)](https://996.icu) ![https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square](https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square) ![https://v2fy.com/asset/README/ChromeAppHeroes.svg?style=popout-square](https://img.shields.io/github/stars/zhaoolee/ChromeAppHeroes.svg?style=popout-square)\n\n# è°·ç²’-Chromeæ’ä»¶è‹±é›„æ¦œ\n\nğŸŒˆè°·ç²’-Chromeæ’ä»¶è‹±é›„æ¦œ, ä¸ºä¼˜ç§€çš„Chromeæ’ä»¶å†™ä¸€æœ¬ä¸­æ–‡è¯´æ˜ä¹¦, è®©Chromeæ’ä»¶è‹±é›„ä»¬é€ ç¦äººç±»~\nChromeAppHeroes, Write a Chinese manual for the excellent Chrome plugin, let the Chrome plugin heroes benefit the human~\n\n![è°·ç²’VIè®¾è®¡.png](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106763830728faCQ0DR.png)\n\n**æ„Ÿè°¢[è€ç½—å·´æ‰å˜¿](https://github.com/LuoJiangYong)ä¸ºæœ¬é¡¹ç›®è®¾è®¡çš„æ–°çš„Logo | [è°·ç²’æ–‡åŒ–(è€ç½—å·´æ‰å˜¿è¯­å½•)](https://zhaoolee.com/ChromeAppHeroes/#/meaning_of_gu_li)**\n\nè°·ç²’-Chromeæ’ä»¶è‹±é›„æ¦œä½¿ç”¨**å¼€æºé­”æ³•æ–‡æ¡£å·¥å…·[docsify](https://github.com/docsifyjs/docsify/)æ„å»º**, æ‰˜ç®¡åœ¨Github Pages, å®Œå…¨å¼€æº!\n\n**ä»˜è´¹VPNç§‘å­¦ä¸Šç½‘å·¥å…·æ¨è**:  é€šç”¨ç½‘ç»œåŠ é€Ÿå™¨, ä¸ºç§‘æŠ€å·¥ä½œè€…åˆ›é€ ä»·å€¼, å¦‚æœä½ æƒ³è·å¾—ç¨³å®šé«˜é€Ÿçš„ç§‘å­¦ä¸Šç½‘ä½“éªŒ,zhaooleeæ¨èä¸€å®¶å°ä¼—ä½†éå¸¸ç¨³å®šçš„VPNä¾›åº”å•†GLaDOS(æä¾›vmessæ–¹å¼)çœ‹Youtube1080Pä¸å¡,æ³¨å†Œç™»å½•å, åå°æä¾›iOSç«¯ç¾åŒºAPPçš„ä¸‹è½½è´¦å·, [ç‚¹å‡»é“¾æ¥](https://glados.rocks/landing/OFQTF-AA9NU-I0JVK-11AY8) å¯ä»¥è·å¾—çš„é«˜é€ŸVPNä½“éªŒ [http://i.v2fy.com/vpn](http://i.v2fy.com/vpn)\n\n## ç›®å½•(ç‚¹å‡»ä»¥ä¸‹æ ‡é¢˜, å¯ä»¥è¿›å…¥æ–‡ç« é¡µ~)\n\n- [130ã€ŠGet cookies.txt LOCALLYã€‹ è·å–æ²¹ç®¡cookiesï¼Œè‡ªåŠ¨åŒ–ä¸‹è½½æ²¹ç®¡è§†é¢‘](https://zhaoolee.com/ChromeAppHeroes/#/130-get-cookiestxt-locally.md)\n\n- [129ã€ŠYouTube Subtitle Downloaderã€‹ä¸‹è½½Youtubeè§†é¢‘çš„å­—å¹•ï¼Œæ”¯æŒä¸­è‹±å¯¹ç…§](https://zhaoolee.com/ChromeAppHeroes/#/129-youtube-subtitle-downloader.md)\n\n- [128ã€ŠWayback Machineã€‹ä¼˜é›…æŸ¥çœ‹ä»»æ„ç½‘é¡µçš„å†å²è®°å½•](https://zhaoolee.com/ChromeAppHeroes/#/128-wayback-machine.md)\n\n- [127ã€ŠZ-Library Finderã€‹ä¼˜é›…è¿›å…¥å…¨çƒæœ€å¤§çš„Z-Libraryè‡ªç”±å…è´¹Freeå›¾ä¹¦é¦†](https://zhaoolee.com/ChromeAppHeroes/#/127-z-library-finder.md)\n\n- [126ã€ŠFile Management - WebDavã€‹ä¼˜é›…ä½¿ç”¨æµè§ˆå™¨é€šè¿‡WebDavä¸Šä¼ ä¸‹è½½ç®¡ç†è‡ªå»ºç½‘ç›˜çš„æ–‡ä»¶](https://zhaoolee.com/ChromeAppHeroes/#/126-file-management-webdav.md)\n\n- [125ã€ŠRedirect Pathã€‹æŸ¥çœ‹ä¸€ä¸ªé¡µé¢æ˜¯å¦‚ä½•è·³è½¬è¿‡æ¥çš„](https://zhaoolee.com/ChromeAppHeroes/#/125-redirect-path.md)\n\n- [124ã€ŠHackerNews New Tabã€‹è‡ªåŠ¨ä½¿ç”¨æ–°æ ‡ç­¾é¡µæ‰“å¼€Hacker Newså†…å®¹](https://zhaoolee.com/ChromeAppHeroes/#/124-hackernews-new-tab.md)\n\n- [123ã€ŠLanguage Learning with Netflix & YouTube-AFLã€‹å¬åŸæ±åŸå‘³çš„è¯»éŸ³ï¼Œç”¨å¥ˆé£YoutubeåŒå­—å¹•å­¦è‹±è¯­](https://zhaoolee.com/ChromeAppHeroes/#/123-language-learning-with-netflix-2024-03-16)\n\n\n- [122ã€ŠVideo Screenshotã€‹ä¸ºå¥ˆé£Netflixç²¾å½©ç”»é¢æˆªå›¾ï¼Œå£çº¸çˆ±å¥½è€…å¿…å¤‡ç¥å™¨](https://zhaoolee.com/ChromeAppHeroes/#/122-video-screenshot-2024-03-16)\n\n- [121ã€ŠConsole Importerã€‹åœ¨Chromeç›´æ¥ä½¿ç”¨npmå†›ç«åº“, åœ¨æ§åˆ¶å°åŠ¨æ€å±•ç¤ºä¸€å¼ çŒ«çŒ«å›¾](https://zhaoolee.com/ChromeAppHeroes/#/121-console-importer-2023-12-20)\n\n- [120ã€ŠWikiwandã€‹æå‡ç»´åŸºç™¾ç§‘çš„ä½¿ç”¨ä½“éªŒ](https://zhaoolee.com/ChromeAppHeroes/#/120-wikiwand-2023-10-12)\n\n- [119ã€ŠInsPopã€‹ç”¨è‹±è¯­ç»å…¸è¯­å½•åŸéŸ³å­¦è‹±è¯­](https://zhaoolee.com/ChromeAppHeroes/#/119-inspop-2023-10-12)\n\n- [118ã€ŠImmersive Translateã€‹æ²‰æµ¸å¼é˜…è¯»è‹±è¯­çš„å…è´¹å·¥å…·ï¼Œæ¨¡ç³Šä¸­æ–‡æ„‰æ‚¦é˜…è¯»è‹±è¯­æ–‡ç« ](https://zhaoolee.com/ChromeAppHeroes/#/118-immersive-translate-2023-05-12)\n\n- [117ã€ŠChatGPT HeartBeatã€‹è®©ChatGPT WebæœåŠ¡ä¿æŒè¿æ¥ï¼Œé¿å…åå¤åˆ·æ–°ChatGPT Webç‰ˆé¡µé¢](https://zhaoolee.com/ChromeAppHeroes/#/117-chatgpt-heartbeat-2023-04-21)\n\n- [116ã€ŠEXIF Viewer Classicã€‹æŸ¥çœ‹ç½‘é¡µä¸­æ‘„å½±å›¾ç‰‡çš„æ‹æ‘„æ—¶é—´å…‰åœˆå¿«é—¨ç­‰Exifå‚æ•°ä¿¡æ¯](https://zhaoolee.com/ChromeAppHeroes/#/116-exif-viewer-classic-2022-10-22)\n\n- [115ã€ŠLinkclumpã€‹åœ¨ç½‘é¡µç”»ä¸ªé•¿æ–¹å½¢ï¼Œæ‰“å¼€é•¿æ–¹å½¢å†…æ‰€æœ‰è¶…é“¾æ¥](https://zhaoolee.com/ChromeAppHeroes/#/115-linkclump-2022-10-22)\n\n- [114ã€ŠWordPress SideBarã€‹ä¸ºWordPressç½‘ç«™æ·»åŠ ç±»ä¼¼GitBookçš„ä¾§è¾¹æ ç›®å½•](https://zhaoolee.com/ChromeAppHeroes/#/114-wordpress-sidebar-2022-07-10)\n\n- [113ã€ŠSVG Exportã€‹å°†SVGçŸ¢é‡å›¾å¯¼å‡ºä¸ºä»»æ„å°ºå¯¸çš„PNGå›¾ç‰‡](https://zhaoolee.com/ChromeAppHeroes/#/113-svg-exprot-2022-05-05)\n\n- [112ã€ŠSmart TOCã€‹èŠ‚çº¦æ»šåŠ¨ç½‘é¡µæ—¶é—´, ä¸ºä»»æ„ç½‘é¡µè‡ªåŠ¨æ·»åŠ ç´¢å¼•ï¼Œç”Ÿæˆæµ®åŠ¨æ™ºèƒ½å°ç›®å½•](https://zhaoolee.com/ChromeAppHeroes/#/112-smart-toc-2021-09-09)\n\n- [111ã€ŠUnsplash For Chromeã€‹æŸ¥æ‰¾å…è´¹æ— ç‰ˆæƒè¶…æ¸…å›¾å¹¶ç›´æ¥æ’å…¥ä»»æ„åœ¨çº¿ç¼–è¾‘å™¨](https://zhaoolee.com/ChromeAppHeroes/#/111-unsplash-for-chrome-2021-07-22)\n\n- [110ã€Šå¾®ä¿¡å…¬ä¼—å·åŒæ­¥åŠ©æ‰‹ã€‹å¿«é€Ÿå°†å¾®ä¿¡æ–‡ç« åŒæ­¥åˆ°çŸ¥ä¹Bç«™ç­‰åˆ›ä½œå¹³å°](https://zhaoolee.com/ChromeAppHeroes/#/110-wechatsync-2021-06-13)\n\n- [109ã€ŠGLaDOSã€‹ä¸€æ¬¾å¿«æ·ç­¾åˆ°é¢†é­”æ³•ä¸Šç½‘å¤©æ•°çš„å°å·¥å…·æ–‡ç« ä½œè€…](https://zhaoolee.com/ChromeAppHeroes/#/109-glados-2021-06-09)\n\n- [108ã€ŠGraboxã€‹æ‰“é€šChromeï¼ŒEdgeï¼ŒFireFoxï¼Œ360ï¼Œ2345ï¼ŒQQï¼Œæœç‹—ç­‰æµè§ˆå™¨ä»¬çš„ä¹¦ç­¾ç›®å½•](https://zhaoolee.com/ChromeAppHeroes/#/108-grabox-2021-06-08)\n\n- [107ã€ŠI don't care about cookiesã€‹å±è”½æ‰€æœ‰ç½‘ç«™è¯¢é—®Cookiesæˆæƒçš„å¼¹çª—](https://zhaoolee.com/ChromeAppHeroes/#/107-i-dont-care-about-cookies-2021-06-05)\n\n- [106ã€ŠBrowser Desktopã€‹ä¸€æ¬¾MacOSé£æ ¼çš„æµè§ˆå™¨æ¡Œé¢](https://zhaoolee.com/ChromeAppHeroes/#/106-browser-desktop-2021-06-05)\n\n- [105ã€Šæ½®æ±ã€‹æç®€ç•ªèŒ„é’Ÿä¸ç™½å™ªéŸ³,å’Œå¤§è‡ªç„¶ä¸€èµ·ï¼Œå¹³é™èº«å¿ƒ](https://zhaoolee.com/ChromeAppHeroes/#/105-tide-2021-05-29)\n\n- [104ã€Šç‰¹åˆ«ç¯‡ï¼šæ˜Ÿæ„¿æµè§ˆå™¨ã€‹ä¸‹è½½ä¸€åˆ‡å¯ä¸‹è½½çš„è§†é¢‘](https://zhaoolee.com/ChromeAppHeroes/#/104-twinkstar-2021-05-17)\n\n- [103ã€ŠMarinara ç•ªèŒ„å·¥ä½œæ³•ï¼ˆPomodoroÂ®ï¼‰åŠ©ç†ã€‹å¥‡å¦™ç•ªèŒ„é’Ÿ, æé†’æ‰“å·¥äººåŠæ—¶ä¼‘æ¯](https://zhaoolee.com/ChromeAppHeroes/#/103-marinara-2021-05-14)\n\n- [102ã€Šç‰¹åˆ«ç¯‡ï¼šæ‰‹æœºå¦‚ä½•ä½¿ç”¨Chromeæ’ä»¶ã€‹æ‰‹æœºç«¯å¦‚ä½•å±è”½çŸ¥ä¹å¹¿å‘Š](https://zhaoolee.com/ChromeAppHeroes/#/102-mobile-2021-05-13)\n\n- [101ã€ŠScroll To Top Buttonã€‹ä¸€é”®æ»šåŠ¨åˆ°é¡µé¢é¡¶éƒ¨æˆ–åº•éƒ¨](https://zhaoolee.com/ChromeAppHeroes/#/101-scroll-to-top-button-2021-05-13)\n\n- [100ã€ŠVolume masterã€‹å®Œç¾æ§åˆ¶æ¯ä¸ªç½‘é¡µçš„éŸ³é‡](https://zhaoolee.com/ChromeAppHeroes/#/100-volume-master-2021-03-25)\n\n- [099ã€ŠGet Faviconã€‹ä¸€é”®è·å–ç½‘ç«™çš„è¶…æ¸…å›¾æ ‡](https://zhaoolee.com/ChromeAppHeroes/#/099-get-favicon-2021-03-22)\n\n- [098ã€ŠRSSHub Radarã€‹å¯ä»¥å¸®åŠ©ä½ å¿«é€Ÿå‘ç°å’Œè®¢é˜…å½“å‰ç½‘ç«™RSSçš„æµè§ˆå™¨æ‰©å±•](https://zhaoolee.com/ChromeAppHeroes/#/098-rsshub-radar-2021-03-02)\n\n- [097ã€Šå‡è£…æ°´å¢¨å±ã€‹è®©ç½‘é¡µå†…å®¹å˜æˆæ°´å¢¨å±æ•ˆæœ](https://zhaoolee.com/ChromeAppHeroes/#/097-fake-ink-screen-2021-02-27)\n\n- [096ã€ŠFeedbroã€‹åœ¨Chromeä¸­è®¢é˜…RSSä¿¡æ¯æµ](https://zhaoolee.com/ChromeAppHeroes/#/096-feedbro-2021-02-27)\n\n- [095ã€ŠJsonFormatterã€‹è½»é‡åŒ–Jsonå¼€æºæ ¼å¼åŒ–å·¥å…·æŸ¥çœ‹ä¸€è¨€apiæ¥å£å­—æ®µæ•°æ®ç»“æ„](https://zhaoolee.com/ChromeAppHeroes/#/095-json-formatter-2021-02-18)\n\n- [094ã€ŠSmoothScrollã€‹è®©ç½‘é¡µæ»šåŠ¨å¦‚å¥¶æ²¹èˆ¬é¡ºæ»‘çš„å¥‡å¦™å°å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/094-smoothscroll-2021-02-14)\n\n- [093ã€ŠSearch to Play the Songã€‹åœ¨æµè§ˆå™¨ä¸­éšæ—¶å¬æˆ‘æƒ³å¬çš„æ­Œ~(å‘¨æ°ä¼¦çš„ä¹Ÿè¡Œ)](https://zhaoolee.com/ChromeAppHeroes/#/093-sps-2021-02-09)\n\n- [092ã€ŠCopyfish ğŸŸ Free OCR Softwareã€‹è‡ªåŠ¨æˆªå›¾è¯†åˆ«ç½‘é¡µä¸­çš„æ–‡å­—](https://zhaoolee.com/ChromeAppHeroes/#/092-copyfish-ocr-2021-02-08)\n\n- [091ã€ŠFasterChromeã€‹é¼ æ ‡æ‚¬åœé¢„åŠ è½½é“¾æ¥è®©ä½ çš„Chromeèµ·é£](https://zhaoolee.com/ChromeAppHeroes/#/091-faster-chrome-2020-12-28)\n\n- [090ã€Šæ‹’ç»äºŒç»´ç ç™»å½•ã€‹è®©æ·˜å®ã€äº¬ä¸œã€é˜¿é‡Œäº‘ç­‰ç½‘ç«™é»˜è®¤ä½¿ç”¨è´¦å·å¯†ç ç™»å½•](https://zhaoolee.com/ChromeAppHeroes/#/090-no-qr-login-2020-12-21)\n\n- [089ã€Šæœ¬åœ°YouTubeä¸‹è½½å™¨ã€‹å®ç°è¢«Googleç¦æ­¢çš„åŠŸèƒ½](https://zhaoolee.com/ChromeAppHeroes/#/089-youtube-2020-12-20)\n\n- [088ã€ŠçŸ¥ä¹ç½‘é¡µåŠ©æ‰‹ã€‹è®©ç½‘é¡µç‰ˆçŸ¥ä¹æ›´å¥½ç”¨](https://zhaoolee.com/ChromeAppHeroes/#/088-zhihu-2020-12-19)\n\n- [087ã€Šè±†ç“£èµ„æºä¸‹è½½å¤§å¸ˆã€‹1ç§’æå®šè±†ç“£ç”µå½±|éŸ³ä¹|å›¾ä¹¦ä¸‹è½½](https://zhaoolee.com/ChromeAppHeroes/#/087-douban-2020-12-19)\n\n- [086ã€ŠCSDNå¼€å‘åŠ©æ‰‹ã€‹CSDNå®˜æ–¹åˆæ³•å…å¹¿å‘Šå·¥å…·,å†…å«å¤§é‡å®ç”¨å¼€å‘å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/086-csdn-2020-12-18)\n\n- [085ã€Šnonstopã€‹æ— æ„Ÿè·³è½¬åˆ°çŸ¥ä¹ï¼Œå¾®åšï¼Œç®€ä¹¦ï¼Œqq é‚®ç®±ç­‰æ— æ³•ç›´æ¥è·³è½¬çš„å¤–é“¾](https://zhaoolee.com/ChromeAppHeroes/#/085-nonstop-2020-12-15)\n\n- [084ã€ŠWeb for TikTokã€‹ç”¨Chromeåˆ·æµ·å¤–ç‰ˆæŠ–éŸ³TikTokï¼Œä¸‹è½½TiktokçŸ­è§†é¢‘](https://zhaoolee.com/ChromeAppHeroes/#/084-tiktok-2020-11-07)\n\n- [083ã€ŠAPK Downloader for Google Play Storeã€‹ä»è°·æ­Œå•†åº—è·å–apkå®‰è£…åŒ…](https://zhaoolee.com/ChromeAppHeroes/#/083-apk-downloader-for-google-2020-11-02)\n\n- [082ã€ŠiGGè°·æ­Œè®¿é—®åŠ©æ‰‹ã€‹å¦‚ä½•ä»Chromeå•†åº—ä¸‹è½½æ‰©å±•å·¥å…·ï¼Ÿ](https://zhaoolee.com/ChromeAppHeroes/#/082-iguge-2020-11-02)\n\n- [081ã€ŠGitHubåŠ é€Ÿã€‹æé«˜ä¸­å›½å¼€å‘è€…è®¿é—®GitHubçš„é€Ÿåº¦](https://zhaoolee.com/ChromeAppHeroes/#/081-fast-github-2020-10-20)\n\n- [080ã€Šå°ç çŸ­é“¾æ¥ã€‹å…è´¹ä¸ºç›¸åŒurlç”Ÿæˆå¤šä¸ªæ°¸ä¹…çŸ­é“¾æ¥](https://zhaoolee.com/ChromeAppHeroes/#/080-xiaomark)\n\n- [079ã€ŠSearch the current site(ç«™å†…æœç´¢)ã€‹è¶…å®ç”¨çš„ç«™å†…æœç´¢å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/079-search-the-current-site)\n\n- [078ã€ŠBookmarks clean upã€‹é«˜æ•ˆæ¸…ç†é‡å¤å’ŒæŸåçš„ä¹¦ç­¾](https://zhaoolee.com/ChromeAppHeroes/#/078-bookmarks-clean-up)\n\n- [077ã€ŠSourcegraphã€‹é˜®ä¸€å³°å¤§ä½¬æ¨èçš„githubä»“åº“å…³é”®è¯æœç´¢å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/077-sourcegraph)\n\n- [076ã€ŠListen1ã€‹Chromeå¬ä»˜è´¹æ­Œæ›²å·¥å…·ï¼å…è´¹å¬å‘¨æ°ä¼¦çš„æ­Œï¼Œç½‘æ˜“äº‘éŸ³ä¹,QQéŸ³ä¹,è™¾ç±³éŸ³ä¹,é…·ç‹—,é…·æˆ‘,å“”å“©å“”å“©,å’ªå’•,ä¸€ä¸ªæ‰©å±•å…¨æå®š](https://zhaoolee.com/ChromeAppHeroes/#/076-listen1)\n\n- [075ã€ŠLink to Text Fragmentã€‹è¿™æ¬¾è°·æ­Œå‘å¸ƒçš„åˆ†äº«å·¥å…·ï¼Œè®©3ä¸‡æ–°åª’ä½“äººç›´å‘¼ç»æ´»å„¿â€¦](https://zhaoolee.com/ChromeAppHeroes/#/075-link-to-text-fragment)\n\n- [074ã€Šç ´è§£å³é”®é”ã€‹å¦‚ä½•è‡ªç”±å¤åˆ¶ç™¾åº¦æ–‡åº“ç½‘é¡µå†…å®¹?](https://zhaoolee.com/ChromeAppHeroes/#/074-enable-right-click)\n\n- [073ã€ŠChrome Better Historyã€‹å¦‚ä½•è®©ChromeæŸ¥æ‰¾å†å²è®°å½•æ›´æ–¹ä¾¿?](https://zhaoolee.com/ChromeAppHeroes/#/073_chrome_better_history)\n\n- [072ã€ŠOneNote Web Clipperã€‹å¾®è½¯å…è´¹è·¨å¹³å°ç¬”è®°OneNoteæ‰©å±•ç¨‹åº](https://zhaoolee.com/ChromeAppHeroes/#/072_one_note_web_clipper)\n- [071ã€ŠColor Tabã€‹è‰²å½©çŒäººä¼˜è´¨é…è‰²æå‡ä½ çš„å®¡ç¾](https://zhaoolee.com/ChromeAppHeroes/#/071_color_tab)\n- [070ã€Šç½‘ç›˜åŠ©æ‰‹ã€‹ç½‘ç›˜ä¸‡èƒ½é’¥åŒ™,è‡ªå®šä¹‰æå–ç ,è·å–æ–‡ä»¶ä¸‹è½½ç›´é“¾](https://zhaoolee.com/ChromeAppHeroes/#/070_pan_zhushou)\n- [069ã€Šublock originã€‹å…é™¤ä¼˜é…·ï¼Œè…¾è®¯ï¼Œçˆ±å¥‡è‰ºï¼ŒYouTubeè§†é¢‘å¹¿å‘Š](https://zhaoolee.com/ChromeAppHeroes/#/069_ublock_origin)\n- [068ã€Špakku å“”å“©å“”å“©å¼¹å¹•è¿‡æ»¤å™¨ã€‹æå‡ä½ çš„å“”å“©å“”å“©å¼¹å¹•ä½“éªŒ](https://zhaoolee.com/ChromeAppHeroes/#/068_pakku)\n- [067 ã€Šbilibiliå“”å“©å“”å“©Bç«™ä¸‹è½½åŠ©æ‰‹ã€‹ä¸‹è½½åœ¨Bç«™å¯ä»¥è§‚çœ‹çš„è§†é¢‘](https://zhaoolee.com/ChromeAppHeroes/#/067_bilibili_downloader)\n- [066 ã€ŠPowerfulPixivDownloaderã€‹ç¦åˆ©å·¥å…·! Pixivå›¾ç‰‡æ‰¹é‡ä¸‹è½½å™¨](https://zhaoolee.com/ChromeAppHeroes/#/066_powerful_pixiv_downloader)\n- [065 ã€ŠHTML5è§†é¢‘æˆªå›¾å™¨ã€‹ç²¾ç¡®æˆªå–æ¯ä¸€å¸§è§†é¢‘,è®©è”¡å¾å¤åŠ¨èµ·æ¥](https://zhaoolee.com/ChromeAppHeroes/#/065_html5_jietu)\n- [064ã€Šæµ®å›¾ç§€ã€‹ä¼˜é›…æŸ¥çœ‹Bç«™è§†é¢‘å°é¢](https://zhaoolee.com/ChromeAppHeroes/#/064_photoshow)\n- [063ã€ŠPicviewer CE+ã€‹åŠŸèƒ½ä¸°å¯Œçš„ç½‘é¡µçœ‹å›¾ç¥å™¨](https://zhaoolee.com/ChromeAppHeroes/#/063_picviewer-ce)\n- [062ã€Šå½©äº‘å°è¯‘ã€‹ä¸€é”®å®ç°ç½‘é¡µä¸­è‹±æ–‡å¯¹ç…§çš„ç¿»è¯‘å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/062_caiyun)\n- [061ã€ŠImageAssistantã€‹å›¾ç‰‡åŠ©æ‰‹æ‰¹é‡å›¾ç‰‡ä¸‹è½½å™¨](https://zhaoolee.com/ChromeAppHeroes/#/061-image-assistant)\n- [060ã€ŠTabagotchiã€‹ä¸ºå‡ç¼“å…¨çƒå˜æš–åšå‡ºè´¡çŒ®](https://zhaoolee.com/ChromeAppHeroes/#/060_tabagotchi)\n- [059ã€ŠPageSpeed Insight and CheckListã€‹ä¸ºç½‘é¡µä¼˜åŒ–æä¾›å»ºè®®å’Œé‡åŒ–æŒ‡æ ‡](https://zhaoolee.com/ChromeAppHeroes/#/059_page_speed_insight_and_check_list)\n- [058ã€ŠIP-Addressã€‹å¿«é€ŸæŸ¥çœ‹å½“å‰è®¾å¤‡IP](https://zhaoolee.com/ChromeAppHeroes/#/058_ip_address) \n- [057ã€Šå›¾ç‰‡å¦å­˜ä¸ºJPG/PNG/WebPã€‹è®©WebPå›¾ç‰‡ä¸‹è½½ä¸ºPNGæ ¼å¼](https://zhaoolee.com/ChromeAppHeroes/#/057_webp_save_as_png)\n- [056ã€ŠSearchã€‹ä¸ºChromeè®¾ç½®æœç´¢å¼•æ“å…³é”®è¯](https://zhaoolee.com/ChromeAppHeroes/#/056_search)\n- [055ã€ŠKeylinesã€‹ä¸ºç½‘é¡µå…ƒç´ æ·»åŠ éšæœºæè¾¹é¢œè‰²](https://zhaoolee.com/ChromeAppHeroes/#/055_keylines)\n- [054ã€ŠäºŒç®± ä»¥å›¾æœå›¾ã€‹è®©ä½ åœ¨æœå›¾æ–¹é¢éšå¿ƒæ‰€æ¬²ï¼ˆä¸ºæ‰€æ¬²ä¸ºï¼‰](https://zhaoolee.com/ChromeAppHeroes/#/054_er_xiang_yi_tu_sou_tu)\n- [053ã€Šé¼ æ ‡ç‚¹å‡»ç‰¹æ•ˆ (à¹‘â€¢Ì âˆ€ â€¢Ì€à¹‘)ã€‹ä¸ºé¼ æ ‡ç‚¹å‡»æ·»åŠ æœ‰è¶£çš„ç‰¹æ•ˆ](https://zhaoolee.com/ChromeAppHeroes/#/053_shu_biao_dian_ji_te_xiao)\n- [052ã€ŠSite Paletteã€‹è‡ªåŠ¨æå–ç½‘ç«™é…è‰²](https://zhaoolee.com/ChromeAppHeroes/#/052_site_palette)\n\n\n- [051ã€ŠCustom Cursor for Chromeâ„¢ã€‹ä¸ºChromeæ¢ä¸Šå¯çˆ±åˆéŸ³å…‰æ ‡](https://zhaoolee.com/ChromeAppHeroes/#/051_custom_cursor_for_chrome)\n\n- [050ã€ŠGoogle Results Previewerã€‹æ— ç‚¹å‡»æŸ¥çœ‹è°·æ­Œæœç´¢ç»“æœ](https://zhaoolee.com/ChromeAppHeroes/#/050_google_results_previewer)\n\n- [049ã€ŠWeb Server for Chromeã€‹æ­å»ºæœ¬åœ°WebæœåŠ¡å™¨, å®ç°å±€åŸŸç½‘å…±äº«æ–‡ä»¶å¤¹](https://zhaoolee.com/ChromeAppHeroes/#/049_web_server_for_chrome)\n\n- [048ã€ŠWords Discovererã€‹é«˜äº®æ ‡æ³¨å•è¯,æå‡ä½ çš„è¯æ±‡é‡](https://zhaoolee.com/ChromeAppHeroes/#/048_words_discoverer)\n\n- [047ã€ŠGo to Tabã€‹å¿«é€Ÿè·³è½¬åˆ°æ‰“å¼€çš„ç½‘é¡µ](https://zhaoolee.com/ChromeAppHeroes/#/047_go_to_tab)\n\n- [046ã€ŠWhatFontã€‹å­—ä½“çˆ±å¥½è€…ä¼˜é›…æŸ¥çœ‹ç½‘é¡µå­—ä½“](https://zhaoolee.com/ChromeAppHeroes/#/046_whatfont)\n\n- [045ã€ŠRestlet Clientã€‹ä¼˜ç§€çš„Apiæµ‹è¯•å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/045_restlet_client)\n\n- [044ã€Šè°·æ­Œè®¿é—®åŠ©æ‰‹ã€‹è®¿é—®Chromeå•†åº— Gmail è°·æ­Œæœç´¢](https://zhaoolee.com/ChromeAppHeroes/#/044_gu_ge_fang_wen_zhu_shou)\n\n- [043ã€ŠDream Afar New Tabã€‹æ¢ç´¢ä¸–ç•Œçš„æ–°æ–¹å¼](https://zhaoolee.com/ChromeAppHeroes/#/043_dream_afar_new_tab)\n\n- [042 åœ¨Edgeä¸­å®‰è£…Chromeæ‰©å±•ç¨‹åº](https://zhaoolee.com/ChromeAppHeroes/#/042_edge)\n\n- [041ã€ŠCopy All Urlsã€‹ä¼˜é›…åœ°ä¿å­˜-å¼€å¯å¤šä¸ªæ ‡ç­¾é¡µ](https://zhaoolee.com/ChromeAppHeroes/#/041_copy_all_urls)\n\n- [040ã€ŠGitZip for githubã€‹ä»Githubæ‰¹é‡ä¸‹è½½è¡¨æƒ…åŒ…](https://zhaoolee.com/ChromeAppHeroes/#/040_gitzip_for_github)\n\n- [039ã€ŠSimplify Gmailã€‹è®©ç½‘é¡µç‰ˆGmailæ›´æ¸…çˆ½](https://zhaoolee.com/ChromeAppHeroes/#/039_simplify_gmail)\n\n- [038ã€ŠAlexa Traffic Rankã€‹ä¸€é”®æŸ¥çœ‹ç½‘ç«™å…¨çƒæ’å](https://zhaoolee.com/ChromeAppHeroes/#/038_alexa_traffic_rank)\n\n- [037ã€ŠSaladictã€‹è°·æ­Œ!æœ‰é“!æˆ‘å…¨éƒ½è¦! èšåˆè¯å…¸, å¹¶è¡Œç¿»è¯‘](https://zhaoolee.com/ChromeAppHeroes/#/037_saladict)\n\n- [036ã€ŠScreen Shaderã€‹æŠŠç½‘é¡µè°ƒæˆæš–è‰²ï¼Œä½ çš„çœ¼ç›ä¼šæ„Ÿè°¢ä½ ğŸ™](https://zhaoolee.com/ChromeAppHeroes/#/036_screen_shader)\n\n- [035ã€ŠPrint Friendly & PDFã€‹è®©ä½ æ‹¥æœ‰æœ€ä½³çš„æ‰“å°é˜…è¯»ä½“éªŒ](https://zhaoolee.com/ChromeAppHeroes/#/035_print_friendly_and_pdf)\n\n- [034ã€ŠAstro Botã€‹ç”¨æ–°æ ‡ç­¾é¡µåˆ·ç¼–ç¨‹é¢˜](https://zhaoolee.com/ChromeAppHeroes/#/034_astro_bot)\n\n- [033ã€Šä¸€å¶ã€‹åœ¨ä»»æ„ç½‘é¡µå¼€å¯å®æ—¶å¼¹å¹• èŠå¤©çª—å£ ç•™è¨€æ¿](https://zhaoolee.com/ChromeAppHeroes/#/033_yi_ye)\n\n- [032ã€ŠSmallpdfã€‹ç®€å•å¥½ç”¨çš„çº¿ä¸ŠPDFå·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/032_smallpdf)\n\n- [031ã€ŠOneTabã€‹æŠŠå¤šä¸ªTabè½¬æ¢ä¸ºä¸€ä¸ªåˆ—è¡¨](https://zhaoolee.com/ChromeAppHeroes/#/031_onetab)\n\n- [030ã€Šæ˜é‡‘ã€‹ç›¸ä¿¡ä¼˜è´¨æŠ€æœ¯å†…å®¹çš„åŠ›é‡](https://zhaoolee.com/ChromeAppHeroes/#/030_jue_jin)\n\n- [029 ã€ŠSimpReadã€‹ä¸ºä»»æ„ç½‘é¡µå¼€å¯é˜…è¯»æ¨¡å¼](https://zhaoolee.com/ChromeAppHeroes/#/029_simread)\n\n- [028ã€ŠAdBlockã€‹Adblockè‡ªå®šä¹‰å±è”½ç®€ä¹¦å¹¿å‘Š](https://zhaoolee.com/ChromeAppHeroes/#/028_adblock)\n\n- [027ã€ŠTextã€‹æ¥è‡ªChromeå®éªŒå®¤çš„è·¨å¹³å°è®°äº‹æœ¬](https://zhaoolee.com/ChromeAppHeroes/#/027_text)\n\n- [026ã€ŠQuickey Launcherã€‹æ‰“å¼€ç½‘ç«™åªéœ€ä¸€é”®](https://zhaoolee.com/ChromeAppHeroes/#/026_quickey_launcher)\n\n- [025ã€ŠConsoleã€‹Chromeè‡ªå¸¦å¥½ç”¨çš„è®¡ç®—å™¨](https://zhaoolee.com/ChromeAppHeroes/#/025_console)\n\n- [024ã€ŠDark Readerã€‹ä¸ºä»»æ„ç½‘ç«™å¯ç”¨å¤œé—´æ¨¡å¼](https://zhaoolee.com/ChromeAppHeroes/#/024_dark_reader)\n\n* [023ã€ŠFireShotã€‹ä¸€é”®æ»šåŠ¨æˆªå±æ•´ä¸ªç½‘é¡µ](https://zhaoolee.com/ChromeAppHeroes/#/023_fireshot)\n\n* [022ã€Šæ‰©å±•ç®¡ç†å™¨ã€‹ç®¡ç†ä½ çš„Chromeæ‰©å±•](https://zhaoolee.com/ChromeAppHeroes/#/022kuo_zhan_guan_li_qi)\n\n* [021ã€Šå“”å“©å“”å“©åŠ©æ‰‹ã€‹åŠ©ä½ å¿«é€Ÿæˆä¸ºBç«™è€å¸æœº](https://zhaoolee.com/ChromeAppHeroes/#/021_bi_li_bi_li_zhu_shou)\n\n* [020ã€ŠBoxel Reboundã€‹â€œå—¨åˆ°ä¸­æ¯’â€çš„å¼¹è·³å°æ–¹å—(é™„è‡ªåˆ¶èµ›é“åˆ†äº«æ–¹æ³•)](https://zhaoolee.com/ChromeAppHeroes/#/020_boxel_rebound)\n\n* [019ã€ŠMEGAã€‹ç½‘ç›˜å¯ä»¥è‰¯å¿ƒåˆ°ä»€ä¹ˆç¨‹åº¦? è¯•è¯•MEGAå§!](https://zhaoolee.com/ChromeAppHeroes/#/019_mega)\n\n* [018ã€ŠEnhanced Githubã€‹ä»â€œå†°æŸœâ€åˆ°â€œå†°æ£å„¿â€,ä¸‹è½½Githubå•ä¸ªæ–‡ä»¶](https://zhaoolee.com/ChromeAppHeroes/#/018_enhanced_github)\n\n* [017ã€Šæ–°æµªå¾®åšå›¾åºŠã€‹æœ¬åœ°Markdownç¼–å†™æ›´æµç•…, æ–°æµªå¾®åšå›¾åºŠæ¥å¸®å¿™](https://zhaoolee.com/ChromeAppHeroes/#/017_xin_lang_wei_bo_tu_chuang)\n\n\n* [016ã€Šè§£é™¤Bç«™åŒºåŸŸé™åˆ¶ã€‹æŸ¥çœ‹è¿›å‡»çš„å·¨äººç¬¬ä¸‰å­£](https://zhaoolee.com/ChromeAppHeroes/#/016_jie_chu_b_zhan_qu_yu_xian_zhi)\n\n* [015 ã€ŠXPath Helperã€‹å®ŒæˆBingæ¯æ—¥å£çº¸çš„å°çˆ¬è™«](https://zhaoolee.com/ChromeAppHeroes/#/015_xpath_helper)\n\n* [014ã€Šè¶…çº§é©¬é‡Œå¥¥æ¸¸æˆã€‹Chromeå˜èº«å°éœ¸ç‹](https://zhaoolee.com/ChromeAppHeroes/#/014_chao_ji_ma_li_ao_you_xi)\n\n* [013ã€ŠQuick QRã€‹ç”¨äºŒç»´ç å®ç°äº‘ç²˜è´´](https://zhaoolee.com/ChromeAppHeroes/#/013_quick_qr)\n\n* [012ã€ŠOurStickysã€‹Chromeç‰¹è‰²ç½‘é¡µä¾¿ç­¾çº¸](https://zhaoolee.com/ChromeAppHeroes/#/012_ourstickys)\n\n* [011 ã€Šwhatrunsã€‹ä¸€é”®åˆ†æç½‘ç«™æŠ€æœ¯æ ˆ](https://zhaoolee.com/ChromeAppHeroes/#/011_whatruns)\n\n* [010ã€Šspeedtestã€‹ç½‘ç»œæµ‹é€Ÿæ’ä»¶speedtest](https://zhaoolee.com/ChromeAppHeroes/#/010_speedtest)\n\n* [009ã€Švimiumã€‹Chromeä¸vimåŒç¥å™¨èåˆ](https://zhaoolee.com/ChromeAppHeroes/#/009_vimium)\n\n* [008ã€ŠChrome Cleaner Proã€‹ä¸ºChromeåŠ é€Ÿ](https://zhaoolee.com/ChromeAppHeroes/#/008_chrome_cleaner_pro)\n\n* [007ã€Šloomã€‹ Chromeç¿»å½•ç½‘é¡µè§†é¢‘ç¥å™¨](https://zhaoolee.com/ChromeAppHeroes/#/007_loom)\n\n* [006ã€ŠSimilarSitesã€‹ ä¸€é”®æŸ¥æ‰¾å§Šå¦¹ç½‘ç«™ SimilarSites](https://zhaoolee.com/ChromeAppHeroes/#/006_similarsites)\n\n* [005ã€ŠVideo Speed Controllerã€‹ åˆ·è¯¾ï¼ˆåˆ·å‰§ï¼‰ç¥å™¨ï¼ç»™ç½‘é¡µè§†é¢‘åŠ ä¸ªé€Ÿ(æœ€å¿«å¯è¾¾16å€!)](https://zhaoolee.com/ChromeAppHeroes/#/005_video_speed_controller)\n\n* [004ã€ŠTampermonkeyã€‹ æ²¹çŒ´å­! ç»™æµè§ˆå™¨å¼€ä¸ªæŒ‚](https://zhaoolee.com/ChromeAppHeroes/#/004_tampermonkey)\n\n* [003ã€ŠSecure Shell Appã€‹ Chromeä¸­å¼€å¯sshä¸€ç§ä»€ä¹ˆä½“éªŒ](https://zhaoolee.com/ChromeAppHeroes/#/003_secure_shell_app)\n\n* [002ã€Šchronoã€‹ è®©Chromeä¸‹è½½èµ„æºæ›´å®¹æ˜“](https://zhaoolee.com/ChromeAppHeroes/#/002_chrono)\n\n* [001ã€Šmarkdown-hereã€‹ Markdownä¸€é”®è½¬æ¢åˆ°\"å¯Œæ–‡æœ¬æ ¼å¼\"](https://zhaoolee.com/ChromeAppHeroes/#/001_markdown_here)\n\n\n## å¼€æºæ’ä»¶æ¨å¹¿(ä½œè€…è‡ªè)\n\n| åç§° | ä½œè€…ä¸»é¡µ | å¼€æºä¿¡æ¯ | ç®€ä»‹ |\n| -- | -- | -- | -- |\n| [Make Zero](https://chrome.google.com/webstore/detail/make-zero-%E6%96%87%E5%AD%97%E5%8A%A0%E5%AF%86%E5%99%A8/ihpcojcdiclghnggnlkcinbmfpomefcc?hl=zh-CN) | [sheepzh](https://github.com/sheepzh) |  [Githubä»“åº“åœ°å€](https://github.com/sheepzh/make-zero) | åŠ è§£å¯†æ–‡æœ¬ |\n| [ç½‘è´¹å¾ˆè´µ](https://chrome.google.com/webstore/detail/%E7%BD%91%E8%B4%B9%E5%BE%88%E8%B4%B5-%E4%B8%8A%E7%BD%91%E6%97%B6%E9%97%B4%E7%BB%9F%E8%AE%A1/dkdhhcbjijekmneelocdllcldcpmekmm)  | [sheepzh](https://github.com/sheepzh) | [Githubä»“åº“åœ°å€](https://github.com/sheepzh/timer) | ç»Ÿè®¡ç½‘é¡µçš„è¿è¡Œæ—¶é—´ã€ç”¨æˆ·çš„æµè§ˆæ—¶é—´å’Œç”¨æˆ·æ‰“å¼€ç½‘ç«™çš„æ¬¡æ•° |\n| [The Fucking Github](https://chrome.google.com/webstore/detail/the-fucking-github/agajobpbaphiohkbkjigcalebbfmofdo)| [lvxianchao](https://github.com/lvxianchao) | [Githubä»“åº“åœ°å€](https://github.com/lvxianchao/the-fucking-github) | å¾ˆæ–¹ä¾¿åœ°æŸ¥çœ‹ã€æ•´ç†ã€æœç´¢ä½ å·²ç» Star è¿‡çš„é¡¹ç›®å’Œæœç´¢ Github ä¸Šçš„é¡¹ç›®ã€‚ |\n| [HitUP](https://chrome.google.com/webstore/detail/hitup/eiokaohkigpbonodjcbjpecbnccijkjb)| [wonderbeyond](https://github.com/wonderbeyond) | [Githubä»“åº“åœ°å€](https://github.com/wonderbeyond/HitUP) | åˆ©ç”¨ New Tab â€œç©ºç™½é¡µâ€ åŠ©æ‚¨ä¿æŒå¯¹æµè¡ŒæŠ€æœ¯è¶‹åŠ¿çš„è·Ÿè¿›ï¼Œé™„å¸¦å…¶å®ƒç¦åˆ©ã€‚ |\n| [Gitako - Github file tree](https://chrome.google.com/webstore/detail/gitako-github-file-tree/giljefjcheohhamkjphiebfjnlphnokk)| [EnixCoda](https://github.com/EnixCoda) | [Githubä»“åº“åœ°å€](https://github.com/EnixCoda/Gitako) | åŠŸèƒ½ä¸Šç±»ä¼¼äºå¤§åé¼é¼çš„ Octotree ï¼Œä½†æ˜¯ç”¨äº†æ›´ç°ä»£åŒ–çš„å‰ç«¯å·¥å…·ï¼Œæ€§èƒ½å¥½å¾ˆå¤šã€‚ |\n| [GITHUBER](https://chrome.google.com/webstore/detail/githuber/janmcneaglgklfljjcpihkkomeghljnf)| [zhuowenli](https://github.com/zhuowenli) | [Githubä»“åº“åœ°å€](https://github.com/zhuowenli/githuber) | è¿™æ˜¯ä¸€ä¸ªå¸®åŠ© GitHub å¼€å‘è€…æ¯æ—¥å‘ç°ä¼˜è´¨å†…å®¹çš„ Chrome ä¸»é¡µæ‹“å±•ã€‚ |\n| [GLaDOS](https://chrome.google.com/webstore/detail/glados/dhjjibbeddglobeoapgppnlnmijajfbb) | [glados-network](https://github.com/glados-network) | [Github ä»“åº“åœ°å€](https://github.com/glados-network/GLaDOS) | GLaDOS is trustable networking manager, a system to master your network. |\n\n\n![é€ ç¦äººç±».png](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710679297967C1J1dW7b.png)\n\n\n#### [130ã€ŠGet cookies.txt LOCALLYã€‹ è·å–æ²¹ç®¡cookiesï¼Œè‡ªåŠ¨åŒ–ä¸‹è½½æ²¹ç®¡è§†é¢‘](https://zhaoolee.com/ChromeAppHeroes/#/130-get-cookiestxt-locally.md)\n\n![Get cookies.txt LOCALLY](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17616313074085BiMnXxi.gif)\n\nCookiesï¼Œæ˜¯äº’è”ç½‘æ—¶ä»£æœ€å°çš„è®°å¿†å•å…ƒã€‚åœ¨ä¸Šä¸–çºªä¹åå¹´ä»£ï¼Œå·¥ç¨‹å¸ˆ Lou Montulli å‘æ˜ Cookieï¼Œåªä¸ºè§£å†³ä¸€ä¸ªæœ´ç´ çš„é—®é¢˜â€”â€”è®©ç½‘é¡µâ€œè®°ä½â€ä½ æ˜¯è°ã€‚\n\næˆ‘ä»¬ç”¨ã€ŠGet cookies.txt LOCALLYã€‹å¯¼å‡ºæ²¹ç®¡ Cookieï¼Œåªæ˜¯ä¸ºäº†è®© youtube èƒ½è¯†åˆ«å‡ºæˆ‘ä»¬çš„èº«ä»½ï¼Œè¿™ä¸€åˆ»ï¼Œæˆ‘ä»¬æ—¢åœ¨å€ŸåŠ©æŠ€æœ¯çš„åŠ›é‡çªç ´ä¸‹è½½çš„å£å’ï¼Œä¹Ÿåœ¨å¤åˆ»äº’è”ç½‘æœ€åˆçš„æµªæ¼«ï¼šåœ¨æ— çŠ¶æ€çš„ä¸–ç•Œä¸­ï¼Œè®©ç¨‹åºè®¤å¾—ä½ ã€‚\n\n#### [129ã€ŠYouTube Subtitle Downloaderã€‹ä¸‹è½½Youtubeè§†é¢‘çš„å­—å¹•ï¼Œæ”¯æŒä¸­è‹±å¯¹ç…§](https://zhaoolee.com/ChromeAppHeroes/#/129-youtube-subtitle-downloader.md)\n\n![YouTube Subtitle Downloader](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1757225908885NWGMxraD.gif)\n\nYoutube çš„ç²¾å½©è§†é¢‘æ˜¯æå¥½çš„è‹±è¯­æ•™æï¼Œé‡Œé¢åŒ…å«äº†è‹±è¯­æ¯è¯­åˆ›ä½œè€…æœ€åœ°é“çš„è¡¨è¾¾ï¼Œæœ¬æ–‡æ¨èä¸€ä¸ªå¯ä»¥å¿«é€Ÿä¸‹è½½çº¯è‹±è¯­å­—å¹•ï¼Œä»¥åŠä¸­è‹±å¯¹ç…§å­—å¹•çš„æ’ä»¶ï¼Œä¸ºè‹±è¯­å­¦ä¹ è€…æä¾›ç”ŸåŠ¨æœ‰è¶£çš„å­¦ä¹ æ•™æã€‚\n\n#### [128ã€ŠWayback Machineã€‹ä¼˜é›…æŸ¥çœ‹ä»»æ„ç½‘é¡µçš„å†å²è®°å½•](https://zhaoolee.com/ChromeAppHeroes/#/128-wayback-machine.md)\n\n![Wayback Machine](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1753606084381J4ywJ3f4.gif)\n\n#### [127ã€ŠZ-Library Finderã€‹ä¼˜é›…è¿›å…¥å…¨çƒæœ€å¤§çš„Z-Libraryè‡ªç”±å…è´¹Freeå›¾ä¹¦é¦†](https://zhaoolee.com/ChromeAppHeroes/#/127-z-library-finder.md)\n\n![Z-Library Finder](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1745653529726SDeiZM4J.gif)\n\næŸ¥æ‰¾ä¸‹è½½è¿‡ç¨‹ä¸­ï¼Œæ²¡æœ‰ä»»ä½•å¼¹çª—ï¼Œç‚¹å‡»å³å¯ä¸‹è½½ï¼Œé™¤äº†ä¸‹è½½æœ‰ç‚¹æ…¢ï¼Œæ²¡ä»€ä¹ˆç¼ºç‚¹ï¼Œä¸‹è½½åçš„epubæ ¼å¼ï¼Œå¯ä»¥è¢«å„ç±»ä¸»æµç”µå­ä¹¦è½¯ä»¶æ‰“å¼€ï¼Œæˆ‘ä¸ªäººæ¯”è¾ƒå–œæ¬¢Appleçš„Booksï¼Œå¯ä»¥é€šè¿‡iCloudåŒæ­¥é˜…è¯»è¿›åº¦ã€‚\n\n#### [126ã€ŠFile Management - WebDavã€‹ä¼˜é›…ä½¿ç”¨æµè§ˆå™¨é€šè¿‡WebDavä¸Šä¼ ä¸‹è½½ç®¡ç†è‡ªå»ºç½‘ç›˜çš„æ–‡ä»¶](https://zhaoolee.com/ChromeAppHeroes/#/126-file-management-webdav.md)\n\n\n![File Management - WebDav](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17335591577897PxbtfiP.gif)\n\n\nwebdavä¸smbåè®®ä¸€æ ·æµè¡Œï¼Œåœ¨å„å¤§æ“ä½œç³»ç»Ÿä¸­è¢«å¹¿æ³›æ”¯æŒï¼ŒwebdavåŸºäºhttp, åœ¨ä¸ç¨³å®šçš„ç½‘ç»œç¯å¢ƒä¸‹è¡¨ç°æ›´å¥½ï¼Œå› ä¸ºhttpåè®®æœ¬èº«å°±è®¾è®¡ç”¨äºå¤„ç†è¿™ç§æƒ…å†µã€‚åœ¨ä¸­å›½å„ç±»å±€åŸŸç½‘çš„ç¯å¢ƒä¸‹ï¼Œå®ƒå¯ä»¥è½»æ¾ç©¿é€é˜²ç«å¢™ï¼Œå› ä¸ºå¤§å¤šæ•°é˜²ç«å¢™é»˜è®¤å…è®¸HTTP/HTTPSæµé‡ã€‚\n\n\n\n#### [125ã€ŠRedirect Pathã€‹æŸ¥çœ‹ä¸€ä¸ªé¡µé¢æ˜¯å¦‚ä½•è·³è½¬è¿‡æ¥çš„](https://zhaoolee.com/ChromeAppHeroes/#/125-redirect-path.md)\n\n\n![redirect-path](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1728903164776wcACwmse.gif)\n\nä»å·¨é‡ç™¾åº”åˆ°æŠ–éŸ³ç½—ç›˜ï¼Œä¸­é—´æœ‰ä¸€ä¸ªé‡å®šå‘é¡µé¢ï¼Œè®°å½•ç”¨æˆ·è¡Œä¸ºï¼ŒåŒæ—¶å®Œæˆä¸¤ä¸ªå¹³å°è”åˆæˆæƒç™»å½•çš„æ“ä½œï¼Œä½œä¸ºä¸€ä¸ªå¼€å‘è€…ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦è·å–è¿™ä¸ªè®°å½•é¡µçš„ä¿¡æ¯ï¼Œé‚£Redirect Pathæ˜¯æå¥½çš„å·¥å…·\n\n\n\n####  [124ã€ŠHackerNews New Tabã€‹è‡ªåŠ¨ä½¿ç”¨æ–°æ ‡ç­¾é¡µæ‰“å¼€Hacker Newså†…å®¹](https://zhaoolee.com/ChromeAppHeroes/#/124-hackernews-new-tab.md)\n\n![new-tab](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1728880192420BeDdDWfs.gif)\n\nHackerNewsæ¯å¤©éƒ½ä¼šå±•ç¤ºå¤§é‡é«˜è´¨é‡çš„å†…å®¹ç´¢å¼•ï¼Œä½†æ˜¯æ¯æ¬¡ç‚¹å‡»ä»»æ„ç´¢å¼•ï¼Œå½“å‰çš„HackerNewsé¡µé¢å°±ä¼šè¢«è¦†ç›–ï¼Œè€ŒHackerNews New Tab è¿™æ¬¾æ‰©å±•å·¥å…·ï¼Œå¯ä»¥è®©æˆ‘ä»¬è‡ªåŠ¨ä½¿ç”¨æ–°æ ‡ç­¾é¡µæ‰“å¼€ç´¢å¼•ï¼Œæˆ‘ä¸ªäººæ„Ÿè§‰è¿™æ ·éå¸¸èˆ’æœï¼Œæ¨èç»™å¤§å®¶ã€‚\n\n#### [123ã€ŠLanguage Learning with Netflix & YouTube-AFLã€‹å¬åŸæ±åŸå‘³çš„è¯»éŸ³ï¼Œç”¨å¥ˆé£YoutubeåŒå­—å¹•å­¦è‹±è¯­](https://zhaoolee.com/ChromeAppHeroes/#/123-language-learning-with-netflix-2024-03-16)\n\n![2024-03-17 14.58.16](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676386850a6rSekF6.gif)\n\nç”¨ Netflix è¿™ç§å¹³å°å­¦è‹±è¯­ï¼Œèƒ½å¬åˆ°åŸæ±åŸå‘³çš„è‹±è¯­è¯»éŸ³ï¼Œé…åˆå‰§æƒ…ï¼Œä¹Ÿä¸ä¼šæ„Ÿè§‰æ— èŠï¼Œè€Œä¸”é…åˆæè¯å™¨å¯ä»¥ç²¾å¬ï¼Œç®—å¾—ä¸Šæ€§ä»·æ¯”è¶…é«˜çš„å­¦ä¹ æ–¹å¼ã€‚\n\n#### [122ã€ŠVideo Screenshotã€‹ä¸ºå¥ˆé£Netflixç²¾å½©ç”»é¢æˆªå›¾ï¼Œå£çº¸çˆ±å¥½è€…å¿…å¤‡ç¥å™¨](https://zhaoolee.com/ChromeAppHeroes/#/122-video-screenshot-2024-03-16)\n\n![2024-03-16 16.27.41](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676390807BzmndPRB.gif)\n\nNetflixæœ‰å¾ˆå¤šä¼˜è´¨èŠ‚ç›®ï¼Œé‡åˆ°ç²¾å½©çš„ç”»é¢ï¼Œå¦‚æœä½¿ç”¨æˆªå±ï¼ŒNetflixå°±ä¼šè‡ªåŠ¨é»‘å±ï¼Œè¿™é‡Œæ¨èä¸€ä¸ªé€‚ç”¨äºWebç‰ˆå¯ä»¥å¯¹Netflixæˆªå›¾çš„å°å·¥å…·ï¼Œå®‰è£…å·¥å…·åï¼ŒNetflixçš„æ’­æ”¾å™¨åº•éƒ¨ä¼šå‡ºç°ä¸€ä¸ªå°ç›¸æœºå›¾æ ‡ï¼Œç‚¹å‡»å³å¯è‡ªåŠ¨è‡ªåŠ¨æˆªå–å½“å‰ç”»é¢ï¼Œå¹¶ä¸‹è½½åˆ°æœ¬åœ°\n\n\n#### [121ã€ŠConsole Importerã€‹åœ¨Chromeç›´æ¥ä½¿ç”¨npmå†›ç«åº“, åœ¨æ§åˆ¶å°åŠ¨æ€å±•ç¤ºä¸€å¼ çŒ«çŒ«å›¾](https://zhaoolee.com/ChromeAppHeroes/#/121-console-importer-2023-12-20)\n\n\n![Consoleæ§åˆ¶å°æ‰“å°å›¾ç‰‡](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676398205anameQfW.gif)\n\n\nä¸€ä¸ªå¾ˆä¸é”™çš„å¼€å‘è€…æ‰©å±•ç¨‹åºã€ŠConsole Importerã€‹ï¼Œ è®©javascriptç¨‹åºå‘˜ä»¬ï¼Œå¯ä»¥ç›´æ¥åœ¨æµè§ˆå™¨å¿«é€Ÿå®‰è£…å„ç§å¥½ç”¨çš„npmä¾èµ–åŒ…ï¼ˆnpmåŒ…çš„ä¸°å¯Œç¨‹åº¦å ªç§°å†›ç«åº“ï¼‰ï¼Œå¹¶è¿›è¡Œç¼–ç¨‹ã€‚\n\nã€ŠConsole Importerã€‹ä¼šè®©Webå·¥ç¨‹å¸ˆæ„Ÿè§‰å¾ˆçˆ½ï¼Œä½†é¡¹ç›®æœ¬èº«è¿˜æœ‰ä¸€äº›éœ€è¦å®Œå–„çš„ç‚¹ï¼Œæˆ‘è®¤ä¸ºä½œè€…å¯ä»¥æ·»åŠ å¸è½½npmåŒ…çš„åŠŸèƒ½ï¼Œå¯¹äºå›½å†…çš„ç¨‹åºå‘˜è€Œè¨€ï¼Œå…è®¸è®¾ç½®npmè½¯ä»¶æºä¹Ÿæ˜¯åˆšéœ€ã€‚\n\n#### [120ã€ŠWikiwandã€‹æå‡ç»´åŸºç™¾ç§‘çš„ä½¿ç”¨ä½“éªŒ](https://zhaoolee.com/ChromeAppHeroes/#/120-wikiwand-2023-10-12)\n\n\n\n![Wikiwand](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676398583cEnmKaNh.gif)\n\n\n\nWikiwandæ˜¯ç»å…¸çš„è®¾è®¡å‘å·¥å…·ï¼ŒWikiçš„å®˜æ–¹ç½‘é¡µè®¾è®¡æœ´å®ï¼Œæ•°æ®å¼€æºï¼ŒWikiwandåŸºäºWikiå·²æœ‰çš„æ•°æ®è¿›è¡Œäº†é¡µé¢ä¼˜åŒ–ï¼Œç›¸å½“äºå¢å¼ºä¸»é¢˜ï¼Œç»™ç”¨æˆ·æ›´å¥½çš„é˜…è¯»ä½“éªŒï¼Œå¦‚æœç”¨æˆ·ä½¿ç”¨Wikiwandé¡µé¢è¿›è¡Œé•¿æ—¶é—´æµè§ˆ, Wikiwandè¿˜èƒ½è·å¾—å¾ˆå¥½çš„SEOï¼ŒWikiwandè¿™ä¸ªäº§å“å±äºç«™åœ¨äº†å·¨äººçš„è‚©è†€ä¸Šã€‚\n\n####  [119ã€ŠInsPopã€‹ç”¨è‹±è¯­ç»å…¸è¯­å½•åŸéŸ³å­¦è‹±è¯­](https://zhaoolee.com/ChromeAppHeroes/#/119-inspop-2023-10-12)\n\n\n![InsPop](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710679299729r55B1bZF.gif)\n\nInsPopæ”¶å½•å„ç§ç»å…¸ç”µå½±ï¼Œç”µè§†å‰§ï¼Œçºªå½•ç‰‡ç»å…¸è¯­å½•çš„ä¸­è‹±æ–‡é‡Šä¹‰ï¼ŒåŸç‰ˆéŸ³é¢‘ï¼Œé…ä¸Šç²¾ç¾æµ·æŠ¥ï¼Œæ¯æ¬¡æ‰“å¼€æµè§ˆå™¨æ–°Tabï¼Œèƒ½çœ‹åˆ°ç»å…¸å¥å­ä»¥åŠæµ·æŠ¥ï¼Œåˆ©ç”¨ç¢ç‰‡åŒ–æ—¶é—´æ— ç—›å­¦è‹±è¯­ã€‚\n\n#### [118ã€ŠImmersive Translateã€‹æ²‰æµ¸å¼é˜…è¯»è‹±è¯­çš„å…è´¹å·¥å…·ï¼Œæ¨¡ç³Šä¸­æ–‡æ„‰æ‚¦é˜…è¯»è‹±è¯­æ–‡ç« ](https://zhaoolee.com/ChromeAppHeroes/#/118-immersive-translate-2023-05-12)\n\n![ImmersiveTranslate](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676399885iG8d35Kc.gif)\n\nImmersive Translate æ˜¯å­¦ä¹ è‹±è¯­çš„å¥½å·¥å…·ï¼Œå¼€å¯ä¸­æ–‡æ¨¡ç³ŠåŒ–å¤„ç†åï¼Œèƒ½è®©ç”¨æˆ·æ— éšœç¢åœ°é›¶æˆæœ¬é˜…è¯»å¤§é‡äº’è”ç½‘æ–‡ç« ï¼Œå¯“æ•™äºä¹ï¼Œå­¦ç»ƒä¸€ä½“ã€‚\n\n#### [117ã€ŠChatGPT HeartBeatã€‹è®©ChatGPT WebæœåŠ¡ä¿æŒè¿æ¥ï¼Œé¿å…åå¤åˆ·æ–°ChatGPT Webç‰ˆé¡µé¢](https://zhaoolee.com/ChromeAppHeroes/#/117-chatgpt-heartbeat-2023-04-21)\n\n\n\n![ChatGPT HeartBeat](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676402220YbxsF5JW.gif)\n\n\n\nChatGPT HeartBeat è¿™ä¸ªæ²¹çŒ´è„šæœ¬ï¼Œå¯ä»¥æ¯éš”30ç§’ï¼ˆå…·ä½“çš„ç§’æ•°å¯ä»¥è‡ªå®šä¹‰ï¼‰ï¼Œè¯·æ±‚ `_ssgManifest.js` æ–‡ä»¶ï¼Œ åŸç†ç±»ä¼¼æœåŠ¡å™¨sshè¿æ¥ç™»å½•æœåŠ¡å™¨çš„å¿ƒè·³åŒ…ï¼Œå‘æœåŠ¡å™¨è¡¨æ˜ï¼Œç”¨æˆ·ä»åœ¨æ´»è·ƒï¼Œä¸è¦æ–­å¼€è¿æ¥\n\n####  [116ã€ŠEXIF Viewer Classicã€‹æŸ¥çœ‹ç½‘é¡µä¸­æ‘„å½±å›¾ç‰‡çš„æ‹æ‘„æ—¶é—´å…‰åœˆå¿«é—¨ç­‰Exifå‚æ•°ä¿¡æ¯](https://zhaoolee.com/ChromeAppHeroes/#/116-exif-viewer-classic-2022-10-22)\n\n![ä½¿ç”¨æ•ˆæœ](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676404101Yw7K16AX.gif)\n\nã€ŠEXIF Viewer Classicã€‹å¹¶ä¸ä¼šå¯¹æ‰€æœ‰ç½‘é¡µå›¾ç‰‡è¿›è¡Œå¤„ç†ï¼Œåªæœ‰å½“ç”¨æˆ·çš„æ‰‹æŸ„æµ®åŠ¨åˆ°ç…§ç‰‡ä¹‹ä¸Šï¼Œæ‰ä¼šè¯•è¯•è¯»å–å›¾ç‰‡Exifä¿¡æ¯ï¼Œå¹¶ä»¥æ–‡å­—æµ®å±‚çš„å½¢å¼ï¼Œå±•ç¤ºåˆ°ç…§ç‰‡é¡¶éƒ¨ï¼Œå¦‚æœç…§ç‰‡åŒ…å«GPSä¿¡æ¯ï¼Œä¼šå‡ºç°ä¸€ä¸ªGPSçº¢è‰²æ ‡è¯†ï¼Œç‚¹å‡»çº¢è‰²æ ‡è¯†ï¼Œä¼šåœ¨Google åœ°å›¾ä¸­å±•ç¤ºå‡ºåœ°ç‚¹ã€‚\n\n#### [115ã€ŠLinkclumpã€‹åœ¨ç½‘é¡µç”»ä¸ªé•¿æ–¹å½¢ï¼Œæ‰“å¼€é•¿æ–¹å½¢å†…æ‰€æœ‰è¶…é“¾æ¥](https://zhaoolee.com/ChromeAppHeroes/#/115-linkclump-2022-10-22)\n\n![ä¸»æ’­é¢œå€¼åŒº](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676406541kCJkiwHh.gif)\n\nLinkclumpæ˜¯ä¸€æ¬¾å¾ˆé…·çš„å°å·¥å…·ï¼Œå¼€æºåœ°å€ https://github.com/benblack86/linkclump ï¼ŒLinkclumpèƒ½è®©ç”¨æˆ·ä»¥æ›´å°‘çš„æ—¶é—´æµè§ˆæ›´å¤šçš„ç½‘é¡µï¼Œéå¸¸é€‚åˆé«˜å¼ºåº¦ä¸Šç½‘å†²æµªçš„æ–°åª’ä½“å·¥ä½œè€…ã€‚\n\n#### [114ã€ŠWordPress SideBarã€‹ä¸ºWordPressç½‘ç«™æ·»åŠ ç±»ä¼¼GitBookçš„ä¾§è¾¹æ ç›®å½•](https://zhaoolee.com/ChromeAppHeroes/#/114-wordpress-sidebar-2022-07-10)\n\n![WordPressSideBar](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676408220Knsaj3Wf.gif)\n\nå¯¹äºä¸ªäººåšå®¢è€Œè¨€, GitBookçš„ä¾§è¾¹æ æ–‡ç« ç›®å½•, éå¸¸é€‚åˆå¹¿å¤§è¯»è€…é˜…è¯», äºæ˜¯zhaooleeç ”ç©¶äº†ä¸€ä¸‹WordPressçš„å¼€æ”¾apiæ¥å£, ç„¶åå†™äº†ä¸ªå·¥å…·, å¯ä»¥ä½¿ç”¨çº¯å‰ç«¯çš„æ–¹å¼, ä»¥WordPressæ ‡å‡†Apiè·å–æ•°æ®, æ„å»ºä¸€ä¸ªç±»ä¼¼GitBookçš„ä¾§è¾¹ç›®å½•;\n\n#### [113ã€ŠSVG Exportã€‹å°†SVGçŸ¢é‡å›¾å¯¼å‡ºä¸ºä»»æ„å°ºå¯¸çš„PNGå›¾ç‰‡](https://zhaoolee.com/ChromeAppHeroes/#/113-svg-exprot-2022-05-05)\n\n![å°†svgè½¬æ¢ä¸ºä»»æ„å°ºå¯¸çš„png](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676414286GRb2hwih.gif)\n\nSVGéå¸¸é€‚åˆä½œä¸ºå“ç‰ŒLogo, å› ä¸ºæ— è®ºæ”¾å¤§å¤šå°‘å€, éƒ½ä¸ä¼šå¤±çœŸ, è€Œåœ¨åˆ¶ä½œPPTæˆ–Wordçš„è¿‡ç¨‹ä¸­, å¾€å¾€éœ€è¦PNGæ ¼å¼çš„å›¾ç‰‡, ã€ŠSVG Exportã€‹è¿™æ¬¾æ‰©å±•ç¨‹åº,å¯ä»¥å°†ç½‘é¡µä¸Šçš„SVGçŸ¢é‡å›¾å¯¼å‡ºä¸ºä»»æ„å°ºå¯¸çš„PNGå›¾ç‰‡.\n\n#### [112ã€ŠSmart TOCã€‹èŠ‚çº¦æ»šåŠ¨ç½‘é¡µæ—¶é—´, ä¸ºä»»æ„ç½‘é¡µè‡ªåŠ¨æ·»åŠ ç´¢å¼•ï¼Œç”Ÿæˆæµ®åŠ¨æ™ºèƒ½å°ç›®å½•](https://zhaoolee.com/ChromeAppHeroes/#/112-smart-toc-2021-09-09)\n\n![æµ®åŠ¨æ™ºèƒ½å°ç›®å½•](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676417246w3xPaGD0.gif)\n\n####  [111ã€ŠUnsplash For Chromeã€‹æŸ¥æ‰¾å…è´¹æ— ç‰ˆæƒè¶…æ¸…å›¾å¹¶ç›´æ¥æ’å…¥ä»»æ„åœ¨çº¿ç¼–è¾‘å™¨](https://zhaoolee.com/ChromeAppHeroes/#/111-unsplash-for-chrome-2021-07-22)\n\n\n\n![edit](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676419371xWe8Hxd8.gif)\n\n\n\néšç€è‡ªåª’ä½“çš„å…´è¶£, å†…å®¹åˆ›é€ è€…æ•°é‡ä¹Ÿè¶Šæ¥è¶Šå¤š, è€Œä¸€å¼ å¥½å›¾ç‰‡, èƒ½æå¤§æå‡è¯»è€…çš„è§‚æ„Ÿ. \n\nåœ¨äº’è”ç½‘æ—¶ä»£, å¹¶éæ‰€æœ‰çš„å›¾ç‰‡éƒ½éœ€è¦ä»˜è´¹ä½¿ç”¨, ä½†ä¹±ç”¨å›¾ç‰‡äº§ç”Ÿçš„ç‰ˆæƒçº çº·, çš„ç¡®ä¼šéå¸¸éº»çƒ¦.\n\nUnsplashè¿™æ¬¾æ‰©å±•ç¨‹åº, çš„ç¡®æå‡äº†ç”¨æˆ·æŸ¥æ‰¾å’Œä½¿ç”¨æ— ç‰ˆæƒå›¾ç‰‡çš„æ•ˆç‡, å€¼å¾—ä¸€è¯•~ \n\n#### [110ã€Šå¾®ä¿¡å…¬ä¼—å·åŒæ­¥åŠ©æ‰‹ã€‹å¿«é€Ÿå°†å¾®ä¿¡æ–‡ç« åŒæ­¥åˆ°çŸ¥ä¹Bç«™ç­‰åˆ›ä½œå¹³å°](https://zhaoolee.com/ChromeAppHeroes/#/110-wechatsync-2021-06-13)\n\n![åŒæ­¥åˆ°çŸ¥ä¹](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676426314mCbTdftz.gif)\n\nå¾®ä¿¡å…¬ä¼—å·çš„å†…å®¹ï¼Œæ— æ³•è¢«å¤§å¤šæ•°æœç´¢å¼•æ“çˆ¬å–ï¼Œå¸Œæœ›ã€Šå¾®ä¿¡å…¬ä¼—å·åŒæ­¥åŠ©æ‰‹ã€‹å·¥å…·ï¼Œèƒ½è®©æ›´å¤šçš„å†…å®¹åˆ›ä½œè€…ï¼ŒæŠŠå†…å®¹åˆ†å‘åˆ°æ•´ä¸ªäº’è”ç½‘ï¼Œä¸ºå†…å®¹è·å¾—æ›´å¤šæ›å…‰çš„åŒæ—¶ï¼Œä¹Ÿèƒ½è®©åæ¥äººèƒ½å¤Ÿåœ¨äº’è”ç½‘è½»æ¾æœç´¢è‡ªå·±éœ€è¦çš„èµ„æºã€‚\n\n\n####  [109ã€ŠGLaDOSã€‹ä¸€æ¬¾å¿«æ·ç­¾åˆ°é¢†é­”æ³•ä¸Šç½‘å¤©æ•°çš„å°å·¥å…·æ–‡ç« ä½œè€…](https://zhaoolee.com/ChromeAppHeroes/#/109-glados-2021-06-09)\n\n![ç­¾åˆ°ç™½å«–æœåŠ¡å¤©æ•°](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676427936PdRHeRf4.gif)\n\nGLaDOSæ˜¯ä¸€æ¬¾å¾ˆç¨³å®šçš„é­”æ³•ä¸Šç½‘å·¥å…·ï¼Œæ”¯æŒClashï¼ŒiOSï¼ŒWireguard VPNï¼Œ Surgeå®¢æˆ·ç«¯ï¼Œè·¯ç”±å™¨OpenWRT/LEDE and Padavanï¼ŒV2Rayï¼ŒSwitchä¸‹è½½åŠ é€Ÿï¼Œé…åˆGLaDOSæ’ä»¶ï¼Œå¯ä»¥å¿«æ·ç™½å«–æœåŠ¡å¤©æ•°ï¼Œå¹¶èƒ½é˜²å¤±è”ã€‚å¯ä»¥é€šè¿‡ http://i.v2fy.com/vpn ç”¨QQé‚®ç®±æˆ–Gmailé‚®ç®±æ³¨å†Œä½“éªŒ\n\n#### [108ã€ŠGraboxã€‹æ‰“é€šChromeï¼ŒEdgeï¼ŒFireFoxï¼Œ360ï¼Œ2345ï¼ŒQQï¼Œæœç‹—ç­‰æµè§ˆå™¨ä»¬çš„ä¹¦ç­¾ç›®å½•](https://zhaoolee.com/ChromeAppHeroes/#/108-grabox-2021-06-08)\n\n![graboxå…±äº«ä¿¡æ¯](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676428961ZZs5i5Qc.gif)\n\næ¯æ¬¡å®‰è£…å¯ç”¨ä¸€ä¸ªæ–°çš„æµè§ˆå™¨ï¼Œæ–°æµè§ˆå™¨éƒ½ä¼šå»ºè®®ç”¨æˆ·æŠŠChromeæµè§ˆå™¨çš„ä¹¦ç­¾å¯¼å…¥åˆ°æ–°æµè§ˆå™¨ä¸­ï¼Œä½†è¿™ç§å¯¼å…¥æ–¹å¼ï¼Œå§‹ç»ˆæ— æ³•å®ç°åŒå‘åŒæ­¥ï¼Œåœ¨Edgeä¸­æ·»åŠ çš„ä¹¦ç­¾ï¼Œ æ— æ³•åœ¨Chromeä¸­æ‰¾åˆ°ï¼Œä¹Ÿæ— æ³•é€šè¿‡å„å®¶å‚å•†çš„äº‘æœåŠ¡åŒæ­¥ï¼Œè€ŒGraboxçš„å‡ºç°ï¼Œå½»åº•è§£å†³äº†è·¨æµè§ˆå™¨åŒæ­¥ä¹¦ç­¾çš„é—®é¢˜ï¼Œæ˜¯çœŸæ­£è§£å†³ç”¨æˆ·ç—›ç‚¹çš„äº§å“ã€‚\n\n#### [107ã€ŠI don't care about cookiesã€‹å±è”½æ‰€æœ‰ç½‘ç«™è¯¢é—®Cookiesæˆæƒçš„å¼¹çª—](https://zhaoolee.com/ChromeAppHeroes/#/107-i-dont-care-about-cookies-2021-06-05)\n\n![I don't care about cookies](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676436197DJQZ65yF.gif)\n\nç”¨æˆ·å¹¶ä¸å…³å¿ƒCookiesæ˜¯å¦è¢«ä½¿ç”¨ï¼Œ ç½‘ç«™å¼¹çª—è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½¿ç”¨Cookiesï¼Œé‚£è¿™ä¸ªç½‘ç«™æ‘†æ˜äº†å°±æ˜¯è¦æ”¶é›†ç”¨æˆ·åœ¨æœ¬ç½‘ç«™çš„æµè§ˆè®°å½•ï¼Œè¿™ç§å¼¹çª—ç›´æ¥é€šè¿‡ã€ŠI don't care about cookiesã€‹å±è”½å°±å¥½ï½\n\n#### [106ã€ŠBrowser Desktopã€‹ä¸€æ¬¾MacOSé£æ ¼çš„æµè§ˆå™¨æ¡Œé¢](https://zhaoolee.com/ChromeAppHeroes/#/106-browser-desktop-2021-06-05)\n\n\n![æ”¯æŒæ›´æ¢æ›´å¤šMacOSé£æ ¼çš„å£çº¸](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676437542T4DKjb3J.gif)\n\nMacOSçš„å£çº¸ç¡®å®èµå¿ƒæ‚¦ç›®ï¼ŒBrowser Desktop è®©Windowsç”¨æˆ·å’ŒLinuxç”¨æˆ·ï¼Œä¹Ÿèƒ½è½»æ˜“ä½“éªŒMacOSå£çº¸å¸¦æ¥çš„ç¾æ„Ÿã€‚\n\n#### [105ã€Šæ½®æ±ã€‹æç®€ç•ªèŒ„é’Ÿä¸ç™½å™ªéŸ³,å’Œå¤§è‡ªç„¶ä¸€èµ·ï¼Œå¹³é™èº«å¿ƒ](https://zhaoolee.com/ChromeAppHeroes/#/105-tide-2021-05-29)\n\n![æ½®æ±](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676442380Z7GjMKat.gif)\n\nå·¥ä½œæ—¶, å¬é­”æ€§éŸ³ä¹å®¹æ˜“åˆ†æ•£ç²¾åŠ›, å¬ä¸€äº›ç™½å™ªéŸ³, å¯ä»¥è®©å¿ƒå¢ƒå¹³å’Œ, æå‡å·¥ä½œä¸“æ³¨åº¦, å¦‚æœæ™šä¸Šç¡ä¸ç€, å¬ä¸€äº›ç™½å™ªéŸ³, æœ‰åŠ©çœ çš„å¥‡æ•ˆ~\n\n\n#### [104ã€Šç‰¹åˆ«ç¯‡ï¼šæ˜Ÿæ„¿æµè§ˆå™¨ã€‹ä¸‹è½½ä¸€åˆ‡å¯ä¸‹è½½çš„è§†é¢‘](https://zhaoolee.com/ChromeAppHeroes/#/104-twinkstar-2021-05-17)\n\n\n![æ˜Ÿæ„¿](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676449303Ssy1icTc.gif)\n\n\n\n\nã€Šæ˜Ÿæ„¿æµè§ˆå™¨ã€‹æ˜¯ä¸€æ¬¾è‡ªå¸¦è§†é¢‘ä¸‹è½½åŠŸèƒ½çš„æµè§ˆå™¨ï¼Œç½‘é¡µæ²¡æœ‰ç‰¹æ®ŠåŠ å¯†çš„è§†é¢‘ï¼Œéƒ½å¯ä»¥ä¸‹è½½åˆ°æœ¬åœ°ã€‚\n\n#### [103ã€ŠMarinara ç•ªèŒ„å·¥ä½œæ³•ï¼ˆPomodoroÂ®ï¼‰åŠ©ç†ã€‹å¥‡å¦™ç•ªèŒ„é’Ÿ, æé†’æ‰“å·¥äººåŠæ—¶ä¼‘æ¯](https://zhaoolee.com/ChromeAppHeroes/#/103-marinara-2021-05-14)\n\n\n\n![åŸºæœ¬æ“ä½œ](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676452294ZrEBKcaa.gif)\n\n\nç•ªèŒ„å·¥ä½œæ³•ï¼ˆPomodoroÂ®ï¼‰åŠ©ç†æ˜¯ä¸€ä¸ªå¥½ç”¨çš„å°å·¥å…·, å¼€æºå…è´¹è·¨å¹³å°, ä½¿ç”¨ç•ªèŒ„å·¥ä½œæ³•, èƒ½è®©æ‰“å·¥äººçš„ç²¾åŠ›å¾—åˆ°åˆç†åˆ©ç”¨, é¿å…è¿‡åº¦ç–²åŠ³.\n\n#### [102ã€Šç‰¹åˆ«ç¯‡ï¼šæ‰‹æœºå¦‚ä½•ä½¿ç”¨Chromeæ’ä»¶ã€‹æ‰‹æœºç«¯å¦‚ä½•å±è”½çŸ¥ä¹å¹¿å‘Š](https://zhaoolee.com/ChromeAppHeroes/#/102-mobile-2021-05-13)\n\n\n![æ„‰å¿«åˆ·æ— å¹¿å‘Šçš„çŸ¥ä¹](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106764537332Tn1Q6TK.gif)\n\nå®‰è£…æ‰©å±•ç¨‹åºåçš„kiwiæµè§ˆå™¨ï¼Œ åŸºæœ¬è®¿é—®ä»»ä½•ç½‘ç«™éƒ½çœ‹ä¸åˆ°å¹¿å‘Šï½\n\n#### [101ã€ŠScroll To Top Buttonã€‹ä¸€é”®æ»šåŠ¨åˆ°é¡µé¢é¡¶éƒ¨æˆ–åº•éƒ¨](https://zhaoolee.com/ChromeAppHeroes/#/101-scroll-to-top-button-2021-05-13)\n\n![ä½¿ç”¨æµ®åŠ¨æŒ‰é’®](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676458234KYHsp6Re.gif)\n\nPCç½‘ç«™çš„å¯¼èˆªæ åœ¨é¡µé¢é¡¶éƒ¨ï¼Œä¸”ä¸ä¼šä¿æŒåœ¨çª—å£é¡¶éƒ¨ï¼Œå½“ç”¨æˆ·çœ‹å®Œé¡µé¢ï¼Œæƒ³ä½¿ç”¨å¯¼èˆªåˆ‡æ¢é¡µé¢æ—¶ï¼Œéœ€è¦æ»šè½®æ»‘åŠ¨å¤šæ¬¡ï¼Œè¿”å›é¡¶éƒ¨ï¼Œéå¸¸ä¸æ–¹ä¾¿ã€‚è€ŒScroll To Top Buttonè¿™æ¬¾å·¥å…·ï¼Œå°±å¯ä»¥ä¸€é”®è¿”å›é¡µé¢é¡¶éƒ¨ï¼Œæˆ–é¡µé¢åº•éƒ¨ï¼Œéå¸¸æ–¹ä¾¿ï¼\n\n\n####  [100ã€ŠVolume masterã€‹å®Œç¾æ§åˆ¶æ¯ä¸ªç½‘é¡µçš„éŸ³é‡](https://zhaoolee.com/ChromeAppHeroes/#/100-volume-master-2021-03-25)\n\n![Volume master](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676465319YHWS4ZMj.gif)\n\nVolume master æ˜¯ä¸€æ¬¾åŠŸèƒ½å•ä¸€ï¼Œé£è¯„å´å¾ˆå¥½çš„å°å·¥å…·ï¼›å®ƒçš„è°ƒæ•´æ˜¯ä¸€æ¬¡æ€§çš„ï¼Œå¹¶ä¸”åªé’ˆå¯¹ä¸€ä¸ªç½‘é¡µï¼Œç½‘é¡µé»˜è®¤éŸ³é‡å€¼æ˜¯100%ï¼Œ ä½ å¯ä»¥æŠŠå®ƒè°ƒæ•´åˆ°200%ï¼Œè¿™ä¸ª200%åªå¯¹å½“å‰ç½‘é¡µæœ‰æ•ˆï¼Œç½‘é¡µå†…æ¢è§†é¢‘ä¹Ÿå¯ä¿ç•™200%çš„æ•ˆæœï¼Œä¸ä¼šå½±å“å…¶å®ƒç½‘é¡µã€‚\n\n#### [099ã€ŠGet Faviconã€‹ä¸€é”®è·å–ç½‘ç«™çš„è¶…æ¸…å›¾æ ‡](https://zhaoolee.com/ChromeAppHeroes/#/099-get-favicon-2021-03-22)\n\n![GetFavicon](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676465791K8kKKf4M.gif)\n\nå¦‚æœä½ éœ€è¦å¯¹ä¸€äº›åŒè¡Œä¸šçš„ç½‘ç«™å†…å®¹æˆ–æ•°æ®ï¼Œåšä¸€äº›è°ƒç ”ï¼Œå¯ä»¥å°†Faviconæ”¾åˆ°PPTçš„å›¾è¡¨ä¸­ï¼Œå±•ç¤ºçš„æ•ˆæœä¼šä¸€ç›®äº†ç„¶ï¼ŒFaviconå°†æˆä¸ºä½ PPTçš„åŠ åˆ†é¡¹\n\n#### [098ã€ŠRSSHub Radarã€‹å¯ä»¥å¸®åŠ©ä½ å¿«é€Ÿå‘ç°å’Œè®¢é˜…å½“å‰ç½‘ç«™RSSçš„æµè§ˆå™¨æ‰©å±•](https://zhaoolee.com/ChromeAppHeroes/#/098-rsshub-radar-2021-03-02)\n\n\n![å¿«é€Ÿè·å–å½“å‰ç½‘ç«™çš„feed](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676468800sYSkcEm3.gif)\n\nRSSæ˜¯ä¸Šä¸ªä¸–ä»£çš„ä¸œè¥¿ï¼Œéšç€å†…å®¹å¹³å°ä»¬æ¨èç®—æ³•çš„å„ç§éªšæ“ä½œï¼ŒRSSåˆè¢«ç¿»äº†å‡ºæ¥ï¼›ä»¥ç°åœ¨çš„çœ¼å…‰çœ‹ï¼ŒRSSç›¸å½“äºæŠŠæ¯ä¸ªç½‘ç«™å½“æˆäº†å…¬ä¼—å·ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡RSSé˜…è¯»å™¨ï¼Œè®¢é˜…è‡ªå·±å–œæ¬¢çš„ç½‘ç«™æ›´æ–°ï¼Œä¸å…¬ä¼—å·ä¸åŒçš„æ˜¯ï¼ŒRSSæ— å¹¿å‘Šï¼Œæ— éœ€ç™»å½•ï¼Œä¸”æ— æ³•æ”¶é›†ç”¨æˆ·ä¿¡æ¯ï¼Œç”¨æˆ·ä¹Ÿä¸ä¼šè¢«åŒè´¨åŒ–ä¿¡æ¯å°é—­è‡ªå·±çš„çŸ¥è¯†ä½“ç³»ã€‚\n\n\n#### [097ã€Šå‡è£…æ°´å¢¨å±ã€‹è®©ç½‘é¡µå†…å®¹å˜æˆæ°´å¢¨å±æ•ˆæœ](https://zhaoolee.com/ChromeAppHeroes/#/097-fake-ink-screen-2021-02-27)\n\n![å‡è£…æ°´å¢¨å±](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676475049frfspbnR.gif)\n\n\nå‡è£…å¢¨æ°´å±ç›¸å½“äºæŠŠå±å¹•å½©è‰²å˜æˆäº†èˆ’é€‚çš„é»‘ç™½ï¼Œçœ¼ç›ä¼šèˆ’æœä¸€äº›ã€‚\n\n#### [096ã€ŠFeedbroã€‹åœ¨Chromeä¸­è®¢é˜…RSSä¿¡æ¯æµ](https://zhaoolee.com/ChromeAppHeroes/#/096-feedbro-2021-02-27)\n\n![Chromeæ’ä»¶è‹±é›„æ¦œ-åœ¨Feedbroä¸­æ·»åŠ RSSè®¢é˜…](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106764795883ZYFjMDH.gif)\n\nåœ¨ä¿¡æ¯çˆ†ç‚¸çš„ä»Šå¤©ï¼Œæ¯ä¸ªäººè·å–çš„ä¿¡æ¯å¾ˆå¤šï¼Œä½†ç”±äºæ¨èç®—æ³•çš„æ»¥ç”¨, å¤§å¤šæ•°ä¿¡æ¯æ˜¯åŒè´¨åŒ–çš„ï¼›åå¬åˆ™æš—ï¼Œå…¼å¬åˆ™æ˜ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è®¢é˜…å¤šç«™ç‚¹çš„RSS, è®©è‡ªå·±æ¥å—çš„ä¿¡æ¯ä¸åé¢‡ï¼Œå¬ç™¾å®¶ä¹‹è¨€ï¼Œè¡Œç¨³å¦¥ä¹‹äº‹ã€‚\n\n#### [095ã€ŠJsonFormatterã€‹è½»é‡åŒ–Jsonå¼€æºæ ¼å¼åŒ–å·¥å…·æŸ¥çœ‹ä¸€è¨€apiæ¥å£å­—æ®µæ•°æ®ç»“æ„](https://zhaoolee.com/ChromeAppHeroes/#/095-json-formatter-2021-02-18)\n\n![å¯ç”¨JsonFormatter](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676482796tWSNiQsF.gif)\n\n\n####  [094ã€ŠSmoothScrollã€‹è®©ç½‘é¡µæ»šåŠ¨å¦‚å¥¶æ²¹èˆ¬é¡ºæ»‘çš„å¥‡å¦™å°å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/094-smoothscroll-2021-02-14)\n\n![SmoothScroll](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676484256H0z7WP08.gif)\n\nã€ŠSmoothScrollã€‹æ˜¯ä¸€ä¸ªç®€å•å®ç”¨çš„å°å·¥å…·ï¼Œè®©æ»šè½®é¼ æ ‡ä¹Ÿèƒ½æ‹¥æœ‰ç±»ä¼¼è§¦æ§æ¿å¥¶æ²¹èˆ¬çš„é¡ºæ»‘.\n\n\n#### [093ã€ŠSearch to Play the Songã€‹åœ¨æµè§ˆå™¨ä¸­éšæ—¶å¬æˆ‘æƒ³å¬çš„æ­Œ~(å‘¨æ°ä¼¦çš„ä¹Ÿè¡Œ)](https://zhaoolee.com/ChromeAppHeroes/#/093-sps-2021-02-09)\n\n![Chromeæ’ä»¶è‹±é›„æ¦œ-Search to Play the Song](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106764896015hrxEY8k.gif)\n\nã€ŠSearch to Play the Songã€‹ æŠŠæµè§ˆå™¨å˜æˆäº†æœ€æ–¹ä¾¿çš„å¬æ­Œè½¯ä»¶ï¼Œæ— è®ºä½ æ˜¯Macï¼Œè¿˜æ˜¯Windowsï¼Œ Linuxéƒ½èƒ½é€šè¿‡å®‰è£…è¿™æ¬¾å·¥å…·ï¼Œè·å¾—è‰¯å¥½çš„å¬æ­Œä½“éªŒï½\n\n#### [092ã€ŠCopyfish ğŸŸ Free OCR Softwareã€‹è‡ªåŠ¨æˆªå›¾è¯†åˆ«ç½‘é¡µä¸­çš„æ–‡å­—](https://zhaoolee.com/ChromeAppHeroes/#/092-copyfish-ocr-2021-02-08)\n\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676491775hBB3YDdF.gif)\n\n\nCopyFishOCRæ˜¯ä¸€ä¸ªè¯†åˆ«ç‡å¾ˆé«˜çš„å·¥å…·ï¼Œå¯ä»¥é€‰æ‹©è¯†åˆ«å¤šç§è¯­è¨€ï¼Œæ”¯æŒChromeï¼ŒEdgeï¼ŒFireFoxç­‰ä¸»æµæµè§ˆå™¨ï¼Œå¦‚æœä½ æ˜¯ä¸€ä¸ªç»å¸¸æ‰¾æ–‡æ¡£èµ„æºçš„äººï¼Œä¸€å®šä¸è¦é”™è¿‡å®ƒï½\n\n#### [091ã€ŠFasterChromeã€‹é¼ æ ‡æ‚¬åœé¢„åŠ è½½é“¾æ¥è®©ä½ çš„Chromeèµ·é£](https://zhaoolee.com/ChromeAppHeroes/#/091-faster-chrome-2020-12-28)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676496810X4yJbADP.gif)\n\näººç±»ä»æŒ‡å‘è¶…é“¾æ¥åˆ°ç‚¹å‡»ï¼Œå¹³å‡éœ€è¦300msçš„ååº”æ—¶é—´ï¼Œè€ŒFasterChromeè®©æ—¶é—´ç¼©çŸ­ä¸º65mmï¼Œæ¯ä¸ªé¡µé¢ç›¸å½“äºæå‰æŠ¢è·‘äº†235msï¼Œå¯¹äºä½¿ç”¨äº†CDNçš„ç½‘ç«™ï¼Œ235mså¯ä»¥ä¸‹è½½100KBï½300KBå·¦å³çš„èµ„æºæ–‡ä»¶ï¼Œå½“äººç±»ç‚¹å‡»ä¸‹é¼ æ ‡çš„æ—¶å€™ï¼Œé¡µé¢çš„htmlå·²ç»åŸºæœ¬ä¸‹è½½å®Œæˆäº†ï¼Œè½»æ¾å®ç°äº†é¡µé¢ç§’å¼€çš„æ•ˆæœã€‚\n\n####  [090ã€Šæ‹’ç»äºŒç»´ç ç™»å½•ã€‹è®©æ·˜å®ã€äº¬ä¸œã€é˜¿é‡Œäº‘ç­‰ç½‘ç«™é»˜è®¤ä½¿ç”¨è´¦å·å¯†ç ç™»å½•](https://zhaoolee.com/ChromeAppHeroes/#/090-no-qr-login-2020-12-21)\n\n![æ‹’ç»äºŒç»´ç ç™»å½•](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676499971pxQ08h2R.gif)\n\näºŒç»´ç ç™»å½•æœ€åˆçš„è®¾è®¡æ˜¯ä¸ºäº†å®‰å…¨ï¼Œç°åœ¨æ˜¯ä¸ºäº†æå‡ç”¨æˆ·æ—¥æ´»è·ƒé‡ï¼Œç™»å½•PCç‰ˆæ–°æµªå¾®åšï¼Œå³ä½¿ä½ è¾“å…¥äº†æ­£ç¡®çš„è´¦æˆ·å¯†ç ï¼Œä¹Ÿè¦æ‰“å¼€æ–°æµªå¾®åšAppå†æ‰«ä¸€éç ï¼ŒçœŸæ˜¯æ¶å¿ƒäººçš„è®¾è®¡ã€‚\n\n#### [089ã€Šæœ¬åœ°YouTubeä¸‹è½½å™¨ã€‹å®ç°è¢«Googleç¦æ­¢çš„åŠŸèƒ½](https://zhaoolee.com/ChromeAppHeroes/#/089-youtube-2020-12-20)\n\n\n![089-youtube-001](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676502387k1wzZEYm.gif)\n\n\nã€Šæœ¬åœ°YouTubeä¸‹è½½å™¨ã€‹ä½œè€…è‡ªå·±ä¹Ÿæ‰¿è®¤youtube-dlè¦æ¯”ã€Šæœ¬åœ°YouTubeä¸‹è½½å™¨ã€‹æ›´å¥½ç”¨ä¸€äº›ï¼Œä½†ã€Šæœ¬åœ°YouTubeä¸‹è½½å™¨ã€‹æ˜¯ä¸€ä¸ªè„šæœ¬ï¼Œæ— éœ€å®‰è£…Pythonå¼€å‘ç¯å¢ƒï¼Œå¯ä»¥åœ¨æµè§ˆå™¨ç›´æ¥ä½¿ç”¨ï¼Œå¯¹æ™®é€šç”¨æˆ·æå…¶å‹å¥½ï¼Œæ‰€ä»¥æ‡’å¾—æŠ˜è…¾çš„éä¸“ä¸šç”¨æˆ·ï¼Œè¿˜æ˜¯å»ºè®®ä½¿ç”¨ã€Šæœ¬åœ°YouTubeä¸‹è½½å™¨ã€‹ã€‚\n\n\n\n#### [088ã€ŠçŸ¥ä¹ç½‘é¡µåŠ©æ‰‹ã€‹è®©ç½‘é¡µç‰ˆçŸ¥ä¹æ›´å¥½ç”¨](https://zhaoolee.com/ChromeAppHeroes/#/088-zhihu-2020-12-19)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676509481eR8sK3C3.gif)\n\nã€ŠçŸ¥ä¹ç½‘é¡µåŠ©æ‰‹ã€‹è®©çŸ¥ä¹ä½“éªŒæ›´é¡ºæ»‘ï¼Œå·¥å…·æœ¬èº«è§£å†³çš„ç”¨æˆ·ç—›ç‚¹ï¼Œæ˜¯çŸ¥ä¹å®˜æ–¹å¯ä»¥åšï¼Œä½†ä¸ºäº†å¹³å°åˆ©ç›Šï¼Œè€Œä¸ä¼šå»åšçš„ã€‚\n\n#### [087ã€Šè±†ç“£èµ„æºä¸‹è½½å¤§å¸ˆã€‹1ç§’æå®šè±†ç“£ç”µå½±|éŸ³ä¹|å›¾ä¹¦ä¸‹è½½](https://zhaoolee.com/ChromeAppHeroes/#/087-douban-2020-12-19)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676513762KPwzmcCM.gif)\n\nã€Šè±†ç“£èµ„æºä¸‹è½½å¤§å¸ˆã€‹æ˜¯ä¸€æ¬¾å¥½ç”¨çš„æœç´¢èšåˆå·¥å…·ï¼Œè®©ç”¨æˆ·ä»¥ä½œå“çš„è±†ç“£è¯„è®ºè¯¦æƒ…é¡µä¸ºå…¥å£ï¼Œç›´è¾¾å„ç§èµ„æºç½‘ç«™çš„ä½œå“ä¸‹è½½é¡µï¼Œæå¤§å‡è½»äº†æ‰¾èµ„æºçš„å·¥ä½œé‡ï¼\n\n\n#### [086ã€ŠCSDNå¼€å‘åŠ©æ‰‹ã€‹CSDNå®˜æ–¹åˆæ³•å…å¹¿å‘Šå·¥å…·,å†…å«å¤§é‡å®ç”¨å¼€å‘å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/086-csdn-2020-12-18)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676516905ysWBEHBP.gif)\n\nã€ŠCSDNå¼€å‘åŠ©æ‰‹ã€‹æ˜¯ä¸€æ¬¾ä¾æ‰˜å¼€å‘è€…ç¤¾åŒºå¼€å‘çš„å°å·¥å…·ï¼Œè¿è¥å¾—å½“ï¼Œä¼šæœ‰æå¥½çš„å‘å±•å‰æ™¯ï¼Œæœ‰äººè¯´ã€ŠCSDNå¼€å‘åŠ©æ‰‹ã€‹å°±æ˜¯ä¸€ä¸ªç¼åˆæ€ªï¼Œä½†å¦‚æœã€ŠCSDNå¼€å‘åŠ©æ‰‹ã€‹æ„¿æ„æŠŠ tampermonkey çš„åŠŸèƒ½ä¹Ÿèƒ½ç¼åˆè¿›æ¥ï¼ŒçœŸçš„ä¼šæˆä¸ºä¸€æ¬¾è€å°‘çš†å®œï¼Œå‰é€”æ— é‡çš„å°å·¥å…·ã€‚\n\n\n#### [085ã€Šnonstopã€‹æ— æ„Ÿè·³è½¬åˆ°çŸ¥ä¹ï¼Œå¾®åšï¼Œç®€ä¹¦ï¼Œqq é‚®ç®±ç­‰æ— æ³•ç›´æ¥è·³è½¬çš„å¤–é“¾](https://zhaoolee.com/ChromeAppHeroes/#/085-nonstop-2020-12-15)\n\n![chromeappheroes-nonstop](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676521938RrnQCp1Q.gif)\n\n\nnonstop ç”¨ä¸åˆ°30è¡Œä»£ç è§£å†³äº†ç”¨æˆ·è·³è½¬ç¡®è®¤çš„é—®é¢˜, æ˜¯æå…¶ä¼˜ç§€çš„å°å·¥å…·.\n\n#### [084ã€ŠWeb for TikTokã€‹ç”¨Chromeåˆ·æµ·å¤–ç‰ˆæŠ–éŸ³TikTokï¼Œä¸‹è½½TiktokçŸ­è§†é¢‘](https://zhaoolee.com/ChromeAppHeroes/#/084-tiktok-2020-11-07)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106765254834Y61hze7.gif)\n\n\n\n\nTikTokæ˜¯ç›®å‰æœ€å—å¹´è½»äººå–œæ¬¢çš„appä¹‹ä¸€ï¼Œé€šè¿‡Chromeå®ç°äº†PC+ç§»åŠ¨ç«¯çš„å…¨è¦†ç›–ï¼Œçš„ç¡®æ˜¯ä¸€æ¬¾å¥½äº§å“!\n\n#### [083ã€ŠAPK Downloader for Google Play Storeã€‹ä»è°·æ­Œå•†åº—è·å–apkå®‰è£…åŒ…](https://zhaoolee.com/ChromeAppHeroes/#/083-apk-downloader-for-google-2020-11-02)\n\n\n![20201102-google-play](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106765299143xmsbBAf.gif)\n\nGoogle Playé‡Œé¢æœ‰å¾ˆå¤šæœ‰è¶£çš„APKå®‰è£…åŒ…ï¼ŒAPKæ—©æœŸçš„ç‰ˆæœ¬éƒ½æ¯”è¾ƒç»å…¸ï¼Œå¹¿å‘Šå°‘ï¼ŒåŠŸèƒ½å¼ºå¤§ï¼Œå¦‚æœä½ æƒ³çè—è¿™äº›APKç‰¹å®šç‰ˆæœ¬çš„å®‰è£…åŒ…ï¼Œä¸å¦¨ä½¿ç”¨ã€ŠAPK Downloader for Google Play Storeã€‹å°†çè—ç‰ˆAPKç•™åˆ°æœ¬åœ°ç¡¬ç›˜\n\n\n#### [082ã€ŠiGGè°·æ­Œè®¿é—®åŠ©æ‰‹ã€‹å¦‚ä½•ä»Chromeå•†åº—ä¸‹è½½æ‰©å±•å·¥å…·ï¼Ÿ](https://zhaoolee.com/ChromeAppHeroes/#/082-iguge-2020-11-02)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676532573xE0rA015.gif)\n\n\nã€ŠiGGè°·æ­Œè®¿é—®åŠ©æ‰‹ã€‹å¯ä»¥è®©ä½ çš„Chromeæµè§ˆå™¨ä½¿ç”¨è°·æ­Œæœç´¢ï¼ŒGmailï¼Œè®¿é—®Chromeæ‰©å±•å•†åº—\n\n#### [081ã€ŠGitHubåŠ é€Ÿã€‹æé«˜ä¸­å›½å¼€å‘è€…è®¿é—®GitHubçš„é€Ÿåº¦](https://zhaoolee.com/ChromeAppHeroes/#/081-fast-github-2020-10-20)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676535448CtNwsMBT.gif)\n\n#### [080ã€Šå°ç çŸ­é“¾æ¥ã€‹å…è´¹ä¸ºç›¸åŒurlç”Ÿæˆå¤šä¸ªæ°¸ä¹…çŸ­é“¾æ¥](https://zhaoolee.com/ChromeAppHeroes/#/080-xiaomark)\n\n\n![20201013-xiaomark001](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676537948DnyTWZ55.gif)\n\nå°ç çŸ­é“¾æ¥è¿™æ¬¾å…è´¹æ‰©å±•ï¼Œå¯ä»¥ä¸€é”®ç”Ÿæˆå„ç§ç½‘å€çš„å¤šä¸ªçŸ­é“¾æ¥ï¼Œå¹¶ä¸”è¿˜åŒæ­¥æä¾›äº†çŸ­é“¾æ¥äºŒç»´ç ï¼Œå¯¹äºæ–°åª’ä½“å·¥ä½œè€…è€Œè¨€ï¼Œæ˜¯æµ‹é‡å†…å®¹åœ¨å„æ¸ é“é˜…è¯»é‡ï¼ˆè½¬åŒ–ç‡ï¼‰çš„å¥½å·¥å…·ï¼\n\n\n#### [079ã€ŠSearch the current site(ç«™å†…æœç´¢)ã€‹è¶…å®ç”¨çš„ç«™å†…æœç´¢å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/079-search-the-current-site)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676540887s2mXSBYk.gif)\n\n\n\nä¸“ä¸šçš„äº‹è¦ä¸“ä¸šçš„å·¥å…·æ¥åšï¼Œæœç´¢å¼•æ“çš„æ ¸å¿ƒåŠŸèƒ½å°±æ˜¯å¯¹ç½‘é¡µå†…å®¹è¿›è¡Œç´¢å¼•ï¼Œå³ä½¿ç½‘ç«™æœ‰ç™¾ä¸‡ç½‘é¡µï¼Œ é€šè¿‡æœç´¢å¼•æ“è¯­æ³•è¿›è¡Œå…³é”®è¯çš„æŸ¥æ‰¾ï¼Œå‡ºç»“æœåªéœ€è¦ä¸€ç¬é—´ã€‚\n\n\n####  [078ã€ŠBookmarks clean upã€‹é«˜æ•ˆæ¸…ç†é‡å¤å’ŒæŸåçš„ä¹¦ç­¾](https://zhaoolee.com/ChromeAppHeroes/#/078-bookmarks-clean-up)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676550275MjdadxCx.gif)\n\nè®¾è®¡éœ€è¦åšå‡æ³•ï¼Œæµè§ˆå™¨ä¹¦ç­¾ä¹Ÿæ˜¯ï¼å¦‚æœä½ çš„æµè§ˆå™¨ä¹¦ç­¾é•¿æ—¶é—´æœªæ•´ç†ï¼ŒæŸ¥æ‰¾ç½‘å€ä¼šå˜å¾—éå¸¸è€—æ—¶ï¼Œ Bookmarks clean upä¸ä»…å¯ä»¥å°†é‡å¤ä¹¦ç­¾åˆ—å‡ºï¼Œè¿˜èƒ½æ¸…ç†å·²ç»å¤±æ•ˆçš„ç½‘é¡µï¼Œç¡®å®ç®—å¾—ä¸Šä¸€æ¬¾ä¼˜è´¨å·¥å…·ï½\n\n####  [077ã€ŠSourcegraphã€‹é˜®ä¸€å³°å¤§ä½¬æ¨èçš„githubä»“åº“å…³é”®è¯æœç´¢å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/077-sourcegraph)\n\n![077-sourcegraph](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/171067655246208YxcyFs.gif)\n\n\n#### [076ã€ŠListen1ã€‹Chromeå¬ä»˜è´¹æ­Œæ›²å·¥å…·ï¼å…è´¹å¬å‘¨æ°ä¼¦çš„æ­Œï¼Œç½‘æ˜“äº‘éŸ³ä¹,QQéŸ³ä¹,è™¾ç±³éŸ³ä¹,é…·ç‹—,é…·æˆ‘,å“”å“©å“”å“©,å’ªå’•,ä¸€ä¸ªæ‰©å±•å…¨æå®š](https://zhaoolee.com/ChromeAppHeroes/#/076-listen1)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676555198kyf8zPzy.gif)\n\næœ‰æ²¡æœ‰ä¸€æ¬¾å¯ä»¥ç•…å¬å›½å†…éŸ³ä¹å¹³å°æ‰€æœ‰ä»˜è´¹éŸ³ä¹çš„Chromeæ‰©å±•ï¼Ÿ ç­”æ¡ˆæ˜¯æœ‰çš„ï¼\n\n#### [075ã€ŠLink to Text Fragmentã€‹è¿™æ¬¾è°·æ­Œå‘å¸ƒçš„åˆ†äº«å·¥å…·ï¼Œè®©3ä¸‡æ–°åª’ä½“äººç›´å‘¼ç»æ´»å„¿â€¦](https://zhaoolee.com/ChromeAppHeroes/#/075-link-to-text-fragment)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106765575672RmKfEf4.gif)\n\nLink to Text Fragmentæ˜¯ä¸€ä¸ªè®©äººçœ¼å‰ä¸€äº®çš„æ’ä»¶ï¼Œå®ƒä½¿ç”¨ç®€å•ï¼Œæ•ˆæœæ˜æ˜¾ï¼Œä»¥é“¾æ¥çš„æ–¹å¼å­˜å‚¨å¼•ç”¨çš„æ–‡å­—ï¼Œä½ç‰ˆæœ¬æµè§ˆå™¨ä¹Ÿèƒ½é¡ºåˆ©æ‰“å¼€ç½‘é¡µï¼Œå¯¹äºå†™æŠ€æœ¯æ–‡çš„ä½œè€…è€Œè¨€ï¼Œå ªç§°å®Œç¾çš„å¼•ç”¨æ–¹å¼ã€‚\n\n\n#### [074ã€Šç ´è§£å³é”®é”ã€‹å¦‚ä½•è‡ªç”±å¤åˆ¶ç™¾åº¦æ–‡åº“ç½‘é¡µå†…å®¹?](https://zhaoolee.com/ChromeAppHeroes/#/074-enable-right-click)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676560318TKS4nErA.gif)\n\n\n\nç½‘é¡µç¦æ­¢å³é”®å¤åˆ¶çš„åŠŸèƒ½, æ ¹æœ¬é˜²ä¸ä½å¼€å‘è€…, æ‰“å¼€å¼€å‘è€…å·¥å…·, ä¸€åˆ‡å†…å®¹å°½æ”¶çœ¼åº•\n\nè€Œç ´è§£å³é”®é”è¿™æ¬¾å·¥å…·, å¯ä»¥è®©æ™®é€šåƒç“œç¾¤ä¼—,ä¹Ÿèƒ½è½»æ˜“ç ´è§£å³é”®é”\n\n####  [073ã€ŠChrome Better Historyã€‹å¦‚ä½•è®©ChromeæŸ¥æ‰¾å†å²è®°å½•æ›´æ–¹ä¾¿?](https://zhaoolee.com/ChromeAppHeroes/#/073_chrome_better_history)\n\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106765628365nHGzfA1.gif)\n\n\n\n\n\nChrome Better Historyç”¨æ—¥å†çš„æ–¹å¼ç»™å†å²è®°å½•åŠ äº†ç´¢å¼•, å®ç°ä¸€é”®ç›´è¾¾ä»»æ„æ—¥æœŸçš„å†å²è®°å½•, åŠŸèƒ½å®ç”¨, æŸ¥æ‰¾æ•ˆç‡æå¤§æå‡\n\n\n\n#### [072ã€ŠOneNote Web Clipperã€‹å¾®è½¯å…è´¹è·¨å¹³å°ç¬”è®°OneNoteæ‰©å±•ç¨‹åº](https://zhaoolee.com/ChromeAppHeroes/#/072_one_note_web_clipper)\n\n![on003](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106765647018d5yW0s1.gif)\n\nOneNote Web Clipperæ˜¯OneNoteé…å¥—çš„æ‰©å±•å·¥å…·ï¼Œä»¥å¤šç§æ–¹å¼ä»ç½‘é¡µé‡‡é›†ç´ æï¼Œå¹¶è‡ªåŠ¨ä¿å­˜åˆ°OneNoteä»»æ„ç¬”è®°æœ¬\n\n\n\n\n\n#### [071ã€ŠColor Tabã€‹è‰²å½©çŒäººä¼˜è´¨é…è‰²æå‡ä½ çš„å®¡ç¾](https://zhaoolee.com/ChromeAppHeroes/#/071_color_tab)\n\n![nice](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676566907NT5m8hG2.gif)\n\n\n\nColor Tabåœ¨ä¼—å¤šæ ‡ç­¾é¡µæ‰©å±•ç¨‹åºä¸­ç‹¬è¾Ÿè¹Šå¾„, ç”¨ä¼˜è´¨çš„é…è‰²æ–¹æ¡ˆ, æ½œç§»é»˜åŒ–æå‡ç”¨æˆ·çš„å®¡ç¾, å¹¶é€šè¿‡æ‰©å±•ç¨‹åºä¸ºç½‘ç«™å¼•æµ, è®©ä¼˜è´¨çš„é…è‰²ç†å¿µæ·±å…¥äººå¿ƒ, ç®—çš„ä¸Šä¸€æ¬¾å°ä¼—ä¸”ä¼˜é›…çš„åº”ç”¨\n\n\n\n#### [070ã€Šç½‘ç›˜åŠ©æ‰‹ã€‹ç½‘ç›˜ä¸‡èƒ½é’¥åŒ™,è‡ªå®šä¹‰æå–ç ,è·å–æ–‡ä»¶ä¸‹è½½ç›´é“¾](https://zhaoolee.com/ChromeAppHeroes/#/070_pan_zhushou)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676569908wmxzWPKz.gif)\n\n\n\nä¸å¯ç”¨ç½‘ç›˜åŠ©æ‰‹çš„æµè§ˆå™¨çª—å£, éœ€è¦æ‰‹åŠ¨è¾“å…¥æå–ç \n\nå¯ç”¨ç½‘ç›˜åŠ©æ‰‹çš„æµè§ˆå™¨çª—å£, æå–ç ä¼šè‡ªåŠ¨å¡«å……\n\n#### [069ã€Šublock originã€‹å…é™¤ä¼˜é…·ï¼Œè…¾è®¯ï¼Œçˆ±å¥‡è‰ºï¼ŒYouTubeè§†é¢‘å¹¿å‘Š](https://zhaoolee.com/ChromeAppHeroes/#/069_ublock_origin)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106765720518B8QccZa.gif)\n\nublock_originå¯ä»¥å°†60ç§’å€’è®¡æ—¶ç›´æ¥åŠ é€Ÿè¿‡æ»¤æ‰ï¼Œå¯ä»¥æ„‰å¿«çš„åˆ·ç«å½±äº†\n\n#### [068ã€Špakku å“”å“©å“”å“©å¼¹å¹•è¿‡æ»¤å™¨ã€‹æå‡ä½ çš„å“”å“©å“”å“©å¼¹å¹•ä½“éªŒ](https://zhaoolee.com/ChromeAppHeroes/#/068_pakku)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676579985BjCAAhbe.gif)\n\nPakkuæ˜¯ä¸€ä¸ªå¼¹å¹•åŠŸèƒ½å¢å¼ºç±»çš„æ‰©å±•å·¥å…·ï¼Œå¯ä»¥è®©æˆ‘ä»¬æ¬£èµå¼¹å¹•çš„åŒæ—¶ï¼Œåˆä¸è¢«å¤è¯»æœºåˆ·å±\nPakkuå€ŸåŠ©å¼¹å¹•é¢‘è°±å›¾å®ç°äº†ã€Œé«˜èƒ½è¿›åº¦æ¡ã€çš„åŠŸèƒ½ï¼Œä»¥ååˆ·ä¸€äº›è§†é¢‘çš„æ—¶å€™ï¼Œå¯ä»¥æ”¾å¿ƒçš„æ‹–åŠ¨è¿›åº¦æ¡ï¼Œè·³è¿‡å¼¹å¹•è¾ƒå°‘çš„åŒºåŸŸï¼Œå®ç°å¿«é€Ÿåˆ·è§†é¢‘\n\n\n#### [067 ã€Šbilibiliå“”å“©å“”å“©Bç«™ä¸‹è½½åŠ©æ‰‹ã€‹ä¸‹è½½åœ¨Bç«™å¯ä»¥è§‚çœ‹çš„è§†é¢‘](https://zhaoolee.com/ChromeAppHeroes/#/067_bilibili_downloader)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676586272jN8W2cXz.gif)\n\nã€Šbilibiliå“”å“©å“”å“©Bç«™ä¸‹è½½åŠ©æ‰‹ã€‹æ˜¯çœŸæ­£å°è€Œç¾çš„æ‰©å±•ç¨‹åºï¼Œå®‰è£…æ‰©å±•ç¨‹åºåï¼Œç‚¹å‡»é¡µé¢åº•éƒ¨æŒ‰é’®ï¼Œæ‰“å¼€æŠ˜å é¢æ¿ï¼Œç„¶ååªéœ€ç‚¹å‡»ä¸‹è½½æŒ‰é’®ï¼Œå³å¯å®Œæˆå®Œæ•´æ•´ä¸ªè§†é¢‘ä¸‹è½½ï¼Œè€Œä¸”æ’ä»¶æ‰¿è¯ºæ°¸ä¹…å…è´¹ï¼ŒçœŸçš„æ˜¯è‰¯å¿ƒè½¯ä»¶!\n\n\n####  [066 ã€ŠPowerfulPixivDownloaderã€‹ç¦åˆ©å·¥å…·! Pixivå›¾ç‰‡æ‰¹é‡ä¸‹è½½å™¨](https://zhaoolee.com/ChromeAppHeroes/#/066_powerful_pixiv_downloader)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106765913195kdn3KbX.gif)\n\n\nPowerfulPixivDownloaderæ˜¯ä¸€ä¸ªç»å…¸çš„å®šå‘çˆ¬è™«å°ç¨‹åºï¼Œå¯¹äºPixivçš„çˆ±å¥½è€…ç®€ç›´æ˜¯ç¥å™¨, å¯¹æ–°åª’ä½“å·¥ä½œè€…è€Œè¨€, ä¹Ÿæ˜¯å±¯é›†å›¾ç‰‡çš„åˆ©å™¨, ç‚¹ä¸€ä¸‹æŒ‰é’®,å‡ ç™¾å¼ è¶…æ¸…æ’ç”»åˆ°æ‰‹! \n\n\n\n#### [065 ã€ŠHTML5è§†é¢‘æˆªå›¾å™¨ã€‹ç²¾ç¡®æˆªå–æ¯ä¸€å¸§è§†é¢‘,è®©è”¡å¾å¤åŠ¨èµ·æ¥](https://zhaoolee.com/ChromeAppHeroes/#/065_html5_jietu)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676594982etQxfcrw.gif)\n\n\néšç€html5æ ‡å‡†çš„æ—¥ç›Šæ¨å¹¿, æ”¯æŒhtml5æ’­æ”¾å™¨çš„è§†é¢‘ç½‘ç«™ä¹Ÿè¶Šæ¥è¶Šå¤š,èƒ½æ­£ç¡®ä½¿ç”¨ã€ŠHTML5è§†é¢‘æˆªå›¾å™¨ã€‹,å½“ä½ æƒ³è¦è§†é¢‘æˆªå›¾æ—¶,æ— éœ€å¡ç‚¹ç‚¹æš‚åœæŒ‰é’®, ä¹Ÿå¯ä»¥ç²¾ç¡®æˆªå–æ¯ä¸€å¸§çš„è¶…æ¸…è§†é¢‘å†…å®¹\n\n#### [064ã€Šæµ®å›¾ç§€ã€‹ä¼˜é›…æŸ¥çœ‹Bç«™è§†é¢‘å°é¢](https://zhaoolee.com/ChromeAppHeroes/#/064_photoshow)\n\næµ®å›¾ç§€(PhotoShow)æ˜¯ä¸€æ¬¾çœ‹å¤§å›¾å·¥å…·, åªéœ€å°†é¼ æ ‡æ”¾åˆ°å›¾ç‰‡ä¸Šæ–¹,å³å¯æŸ¥çœ‹åˆ°å›¾ç‰‡çš„æœ€å¤§å°ºå¯¸\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676597126DypnGwWK.gif)\n\n\n#### [063ã€ŠPicviewer CE+ã€‹åŠŸèƒ½ä¸°å¯Œçš„ç½‘é¡µçœ‹å›¾ç¥å™¨](https://zhaoolee.com/ChromeAppHeroes/#/063_picviewer-ce)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676600809EcPtYFZW.gif)\n\n\nPicviewer CE+æ˜¯ä¸€æ¬¾ä¼˜ç§€çš„çœ‹å›¾å·¥å…·,å¯ä»¥å¯¹å›¾ç‰‡è¿›è¡Œè·å–åŸå›¾, ç¼©æ”¾,æ—‹è½¬,åœ¨çº¿ç¼–è¾‘, æ‰¹é‡æŸ¥çœ‹, æ‰¹é‡ä¸‹è½½ç­‰å¸¸è§æ“ä½œ\n\n\n#### [062ã€Šå½©äº‘å°è¯‘ã€‹ä¸€é”®å®ç°ç½‘é¡µä¸­è‹±æ–‡å¯¹ç…§çš„ç¿»è¯‘å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/062_caiyun)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676603236xXQSeKxr.gif)\n\nå½©äº‘å°è¯‘æ‰©å±•ç¨‹åºé»˜è®¤çš„ ä¸­è‹±æ–‡å¯¹ç…§ è®©äººçœ¼å‰ä¸€äº®, è€Œä¸”å®˜ç½‘æä¾›äº†å…è´¹çš„api(æ¯æœˆ100ä¸‡å­—)\n\n\n#### [061ã€ŠImageAssistantã€‹å›¾ç‰‡åŠ©æ‰‹æ‰¹é‡å›¾ç‰‡ä¸‹è½½å™¨](https://zhaoolee.com/ChromeAppHeroes/#/061-image-assistant) \n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676605410mFGaCAT5.gif)\n\nã€ŠImageAssistantã€‹å›¾ç‰‡åŠ©æ‰‹æ‰¹é‡å›¾ç‰‡ä¸‹è½½å™¨,åœ¨æå–ç½‘é¡µå›¾ç‰‡çš„æ–¹é¢,åŠŸèƒ½éå¸¸å…¨é¢, èƒ½æå–ç»å¤§å¤šæ•°å›¾ç‰‡ç½‘ç«™çš„èµ„æº, å¦‚æœä½ ç»å¸¸ä¸ºæ— æ³•æå–ç½‘é¡µå›¾ç‰‡èµ„æºå‘æ„, ç›¸ä¿¡è¿™æ¬¾æ‰©å±•ç¨‹åºèƒ½ä¸ºä½ å¸¦æ¥æƒŠå–œ\n\n\n#### [060ã€ŠTabagotchiã€‹ä¸ºå‡ç¼“å…¨çƒå˜æš–åšå‡ºè´¡çŒ®](https://zhaoolee.com/ChromeAppHeroes/#/060_tabagotchi)\n\n![tabagotchi](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676608207rshEskXH.gif)\n\nTabagotchiæ‰©å±•ä»¥ä¸€ç§æœ‰è¶£çš„æ–¹å¼, æé†’æˆ‘ä»¬å‡å°‘æ ‡ç­¾é¡µæ•°é‡, å‡å°‘äº†è®¡ç®—æœºäº§ç”Ÿçš„çƒ­é‡, ä¸ºé˜»æ­¢å…¨çƒå˜æš–åšå‡ºäº†è´¡çŒ®~\n\n\n#### [059ã€ŠPageSpeed Insight and CheckListã€‹ä¸ºç½‘é¡µä¼˜åŒ–æä¾›å»ºè®®å’Œé‡åŒ–æŒ‡æ ‡](https://zhaoolee.com/ChromeAppHeroes/#/059_page_speed_insight_and_check_list)\n\n\n![pag_speed](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106766102301y4iScf7.gif)\n![001](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676612282YSJK3tNn.png)\n\nPageSpeed Insight and CheckList å’Œ Google Page Speed ç»“åˆä½¿ç”¨, èƒ½å¤Ÿä¸ºç½‘é¡µè´¨é‡è¯„åˆ†,é‡åŒ–ç½‘é¡µä¼˜åŒ–çš„æ•ˆæœ,ä¹Ÿä¸ºä¼˜åŒ–ç½‘é¡µæŒ‡æ˜äº†æ–¹å‘,å¯¹å‰ç«¯å·¥ç¨‹å¸ˆè€Œè¨€,æ˜¯éå¸¸é‡è¦çš„å·¥å…·\n\n\n#### [058ã€ŠIP-Addressã€‹å¿«é€ŸæŸ¥çœ‹å½“å‰è®¾å¤‡IP](https://zhaoolee.com/ChromeAppHeroes/#/058_ip_address)\n\n\n![ip_address](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710678458328GTzAcQ31.gif)\n\nè·å–å½“å‰è®¾å¤‡çš„IPåœ°å€,å¯¹äºå¼€å‘è€…è€Œè¨€,æ˜¯ä¸€ä¸ªç»å¸¸é‡åˆ°çš„é—®é¢˜,è€Œã€ŠIP-Addressã€‹è¿™æ¬¾ç®€æ´å°å·§çš„è½¯ä»¶, èƒ½æ»¡è¶³æˆ‘ä»¬çš„éœ€æ±‚\n\n\n#### [057ã€Šå›¾ç‰‡å¦å­˜ä¸ºJPG/PNG/WebPã€‹è®©WebPå›¾ç‰‡ä¸‹è½½ä¸ºPNGæ ¼å¼](https://zhaoolee.com/ChromeAppHeroes/#/057_webp_save_as_png)\n\n![save_as_png](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676616875CrmzTkxP.gif)\n\nWebPæ˜¯éå¸¸å…ˆè¿›çš„æ ¼å¼, ä½†ç”±äºPhotoshopè¿™ç±»å…ƒè€çº§å›¾åƒç¼–è¾‘è½¯ä»¶ä¸æ”¯æŒ, æˆ‘ä»¬åªèƒ½å°†å›¾ç‰‡ä¸ºpngæ ¼å¼,å†è¿›è¡Œç¼–è¾‘, å…ˆè¿›æŠ€æœ¯æ”¹å˜ä¸–ç•Œ, éœ€è¦ä¸€ä¸ªè¿‡ç¨‹, è€Œåœ¨è¿‡ç¨‹ä¸­æä¾›ä¸€ä¸ªæŠ˜ä¸­çš„æ–¹æ¡ˆ(æŠŠWebPè£…æ¢ä¸ºpng, å†å°†pngå›¾ç‰‡è£…æ¢ä¸ºWebP), ä¹Ÿæ˜¯ä¸€ä»¶æœ‰ä»·å€¼çš„äº‹~\n\n#### [056ã€ŠSearchã€‹ä¸ºChromeè®¾ç½®æœç´¢å¼•æ“å…³é”®è¯](https://zhaoolee.com/ChromeAppHeroes/#/056_search)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676620710SsGtidm2.gif)\n\nåœ¨æ—©æœŸçš„ç½‘å€å¯¼èˆªä¸»é¡µä¸Š, å¯ä»¥é€šè¿‡ç‚¹å‡»é€‰æ‹©ä¸åŒçš„æœç´¢å¼•æ“è¿›è¡Œæœç´¢(æ•°é‡æœ‰é™, è€Œä¸”ä¸æ”¯æŒè‡ªå®šä¹‰), è€ŒChromeæœç´¢æ›´æå®¢ä¸€äº›, é€šè¿‡**è‡ªå®šä¹‰å…³é”®è¯åŠ ç©ºæ ¼**çš„æ–¹æ³•, åœ¨æœç´¢å¼•æ“ä¹‹é—´è‡ªç”±åˆ‡æ¢, æ˜¯ä¸€ç§å…¼å…·æ‰©å±•æ€§ä¸æ˜“ç”¨æ€§çš„åšæ³•\n\n\n#### [055ã€ŠKeylinesã€‹ä¸ºç½‘é¡µå…ƒç´ æ·»åŠ éšæœºæè¾¹é¢œè‰² ](https://zhaoolee.com/ChromeAppHeroes/#/055_keylines)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676622640RrAkADhc.gif)\n\nKeylinesçš„å®ç°åŸç†éå¸¸ç®€å•(ä¸ºç½‘é¡µdomå…ƒç´ æ·»åŠ äº†outlineå±æ€§), ä½†å±•ç¤ºçš„æ•ˆæœå´éå¸¸æƒŠè‰³, è¿™åº”è¯¥å½’åŠŸäºKeylinesä½œè€…ä¼˜ç§€çš„æƒ³æ³•, å¾ˆå¤šæ—¶å€™, ä¼˜ç§€çš„è½¯ä»¶å¹¶ä¸ä¸€å®šä½¿ç”¨äº†å¾ˆéš¾æŒæ¡çš„æŠ€æœ¯, è€Œæ˜¯åŒ…å«äº†ä½œè€…ä¼˜ç§€çš„æƒ³æ³•~\n\n\n#### [054ã€ŠäºŒç®±+ä»¥å›¾æœå›¾ã€‹è®©ä½ åœ¨æœå›¾æ–¹é¢éšå¿ƒæ‰€æ¬²ï¼ˆä¸ºæ‰€æ¬²ä¸ºï¼‰](https://zhaoolee.com/ChromeAppHeroes/#/054_er_xiang_yi_tu_sou_tu)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676624690xtPzYyX4.gif)\n\n\nã€ŠäºŒç®± ä»¥å›¾æœå›¾ã€‹æ˜¯ä¸€æ¬¾ç®€å•å®ç”¨çš„æœå›¾å°å·¥å…·ï¼Œå¦‚æœä½ æ˜¯ä¸€åè®¾è®¡å¸ˆ, å¯ä»¥å¸®ä½ å¿«é€ŸæŸ¥æ‰¾ä»–äººè®¾è®¡ä½œå“ä¸­æ‰€ç”¨çš„ç´ ææ¥æº, æå‡ä½ çš„å·¥ä½œæ•ˆç‡~\n\n\n#### [053ã€Šé¼ æ ‡ç‚¹å‡»ç‰¹æ•ˆ (à¹‘â€¢Ì âˆ€ â€¢Ì€à¹‘)ã€‹ä¸ºé¼ æ ‡ç‚¹å‡»æ·»åŠ æœ‰è¶£çš„ç‰¹æ•ˆ](https://zhaoolee.com/ChromeAppHeroes/#/053_shu_biao_dian_ji_te_xiao)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676626673DxQZJbMk.gif)\n\n\nã€Šé¼ æ ‡ç‚¹å‡»ç‰¹æ•ˆ (à¹‘â€¢Ì âˆ€ â€¢Ì€à¹‘)ã€‹æ˜¯ä¸€æ¬¾ä¸ºé¼ æ ‡ç‚¹å‡»æ·»åŠ æœ‰è¶£çš„ç‰¹æ•ˆçš„æ‰©å±•ç¨‹åº,è™½ç„¶æ²¡å•¥å®é™…ç”¨é€”,ä½†å¾ˆå¥½ç©, å½•åˆ¶ä¸€äº›æœ‰è¶£çš„ç½‘é¡µå°ç¨‹åºæ—¶, ä¼šéå¸¸å‡ºå½©~\n\n#### [052ã€ŠSite Paletteã€‹è‡ªåŠ¨æå–ç½‘ç«™é…è‰²](https://zhaoolee.com/ChromeAppHeroes/#/052_site_palette)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676628984NNHSSG7d.gif)\n\nSite Paletteä½¿ç”¨ç®€å•, åŠŸèƒ½å®ç”¨, æ²¡æœ‰å¹¿å‘Š, æ˜¯å…¸å‹çš„å°è€Œç¾çš„æ‰©å±•ç¨‹åº, è¿™ç±»æ‰©å±•ç¨‹åºè¶Šå¤š, Chromeçš„ç”¨æˆ·ä½“éªŒä¹Ÿå°±è¶Šå¥½~\n\n\n#### [051ã€ŠCustom Cursor for Chromeâ„¢ã€‹ä¸ºChromeæ¢ä¸Šå¯çˆ±åˆéŸ³å…‰æ ‡](https://zhaoolee.com/ChromeAppHeroes/#/051_custom_cursor_for_chrome)\n\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106766309974rZHEfBB.gif)\n\n\næ—©æœŸçš„QQç©ºé—´å’Œä¸ªäººåšå®¢, æˆ‘ä»¬ä¼šç»™é¡µé¢åŠ å„ç§å„æ ·çš„è£…é¥°, è¿é¼ æ ‡æŒ‡é’ˆä¹Ÿè¦å®šåˆ¶ä¸€ä¸‹, å½“æ—¶æ„Ÿè§‰ä¹è¶£æ— ç©·, åé¢å°±å¤±å»äº†å…´è¶£, å¯¹äºä¸ªäººåšå®¢, æ„Ÿè§‰è¶Šç®€æ´è¶Šå¥½, äºæ˜¯å°±æœ‰äº†Nextè¿™äº›å¤§é‡ç•™ç™½çš„åšå®¢ä¸»é¢˜,ä½†æˆ‘æ„Ÿè§‰åœ¨Nextè¿™ç±»ä¸»é¢˜ä¸­åŠ ä¸€äº›å®šåˆ¶åŒ–çš„å°ç‰©ä»¶ä¹Ÿæ˜¯ä¸é”™çš„, åœ¨ç®€æ´ä¸èŠ±å“¨ä¹‹é—´æ‰¾åˆ°å¹³è¡¡, ä¸æ­£æ˜¯ç”Ÿæ´»çš„ä¹è¶£ä¹‹æºä¹ˆ~\n\n\n\n#### [050ã€ŠGoogle Results Previewerã€‹æ— ç‚¹å‡»æŸ¥çœ‹è°·æ­Œæœç´¢ç»“æœ](https://zhaoolee.com/ChromeAppHeroes/#/050_google_results_previewer)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676633298mBfYbrht.gif)\n\nGoogle Results Previewerçš„åŠŸèƒ½ç®€å•å®ç”¨, ä¹Ÿæ²¡æœ‰å¤šä½™çš„è®¾ç½®, å±äºæ–°æ‰‹å‹å¥½å‹å·¥å…·\n\n\n#### [049ã€ŠWeb Server for Chromeã€‹æ­å»ºæœ¬åœ°WebæœåŠ¡å™¨, å®ç°å±€åŸŸç½‘å…±äº«æ–‡ä»¶å¤¹](https://zhaoolee.com/ChromeAppHeroes/#/049_web_server_for_chrome)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676635603G53JG5yf.gif)\n\nWeb Server for Chromeå¯ä»¥å¸®æˆ‘ä»¬åœ¨æœ¬åœ°å¿«é€Ÿå¼€å¯httpæœåŠ¡,è®©å¼€å‘å’Œæµ‹è¯•å˜å¾—æ›´åŠ ç®€å•, å¦‚æœä½ æƒ³å’ŒåŒå¤„æŸä¸ªå±€åŸŸç½‘çš„å°ä¼™ä¼´, å»ºç«‹ä¸€ä¸ªå…±äº«æ–‡ä»¶å¤¹, Web Server for Chromeæˆ–è®¸æ˜¯ä½ æœ€ç®€å•çš„å®ç°æ–¹æ³•~ \n\n\n#### [048ã€ŠWords Discovererã€‹èƒŒå•è¯æ–°å§¿åŠ¿,æå‡ä½ çš„è¯æ±‡é‡](https://zhaoolee.com/ChromeAppHeroes/#/048_words_discoverer)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676638085KTSDPEQe.gif)\n\nWords Discoverer(ä¸­æ–‡è¯‘å: å•è¯å‘ç°è€…),**å¯ä»¥çªå‡ºæ˜¾ç¤ºç½‘é¡µä¸Šç½•è§çš„è‹±è¯­å­—å…¸è¯æ±‡å’Œæƒ¯ç”¨è¯­ã€‚ä¿ƒè¿›è‹±è¯­è¯­è¨€å­¦ä¹ å¹¶æ‰©å¤§è¯æ±‡é‡**,é€šè¿‡è‡ªåŠ¨é«˜äº®ç½‘é¡µå•è¯, è¾…åŠ©å•è¯è®°å¿†æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è·¯å­, å»ºè®®è¿‡ä¸€æ®µæ—¶é—´,å°±ç¨å¾®è°ƒé«˜**ä¸çªå‡ºæ˜¾ç¤º æœ€å¸¸ç”¨çš„è‹±è¯­å•è¯**çš„æ•°é‡, æ¯”å¦‚ä»é»˜è®¤çš„15%è°ƒæ•´åˆ°16%,  å•è¯å‘ç°è€…ä¸æ²™æ‹‰æŸ¥è¯ç»“åˆä½¿ç”¨, çœŸçš„æ˜¯ä½“éªŒæä½³~\n\n#### [047ã€ŠGo to Tabã€‹å¿«é€Ÿè·³è½¬åˆ°æ‰“å¼€çš„ç½‘é¡µ](https://zhaoolee.com/ChromeAppHeroes/#/047_go_to_tab)\n\n![2019-06-15-18 54 23](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676640065MXKApBHx.gif)\n\nGo to Tabå¯¹äºå·¥ä½œæœŸé—´å¤§é‡æ‰“å¼€é¡µé¢, åˆé•¿æ—¶é—´ä¸å…³æœºçš„ç¨‹åºå‘˜ä»¬, æ˜¯éå¸¸æœ‰å¸®åŠ©çš„\n\n\n#### [046ã€ŠWhatFontã€‹å­—ä½“çˆ±å¥½è€…ä¼˜é›…æŸ¥çœ‹ç½‘é¡µå­—ä½“](https://zhaoolee.com/ChromeAppHeroes/#/046_whatfont)\n\n![font 2019-06-15 16_04_10](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676643005G1dbb2xm.gif)\n\nWhatFontå±äºåŠŸèƒ½éå¸¸å•ä¸€çš„å°å·¥å…·, è®©å­—ä½“çˆ±å¥½è€…ä¼˜é›…æŸ¥çœ‹ç½‘é¡µå­—ä½“å±æ€§, å¦‚æœä½ å¯¹æ¼‚äº®å­—ä½“æœ‰ä¸€ä»½æ‰§å¿µ, æ¨èåˆ°[https://fonts.google.com/](https://fonts.google.com/), [https://www.myfonts.com/](https://www.myfonts.com/)\n ç­‰å­—ä½“ç½‘ç«™,æ‰¾å¯»æ›´å¤šå¯çˆ±çš„å­—ä½“~\n\n\n#### [045ã€ŠRestlet Clientã€‹ä¼˜ç§€çš„Apiæµ‹è¯•å·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/045_restlet_client)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676644999r6zxWC1T.gif)\n\n- Restlet Clientæ˜¯ä¸€æ¬¾å¼€å‘å®ç”¨å·¥å…·, æ”¯æŒä¸€é”®å¯¼å…¥Postmanç­‰apiæµ‹è¯•å·¥å…·çš„æµ‹è¯•ç”¨ä¾‹ \n- è¿‘æ¥, Postmanå¼€å§‹ä¸»æ¨è‡ªå·±çš„70Må·¦å³çš„å®¢æˆ·ç«¯å®‰è£…åŒ…, åŠŸèƒ½æ²¡ä»€ä¹ˆæ”¹è¿›, ä½“ç§¯å´å˜å¾—è¶…å¤§,è€Œä¸”Postmançš„Chromeæ‰©å±•ç¨‹åº, å¯¹macOSçš„æ”¯æŒä¸å¤ªå¥½(æ¯æ¬¡æ‰“å¼€, éƒ½ä¼šå¼¹çª—æŠ¥ä¸€ä¸ªé”™)\n- Restlet Clientä¾ç„¶åªæ˜¯ä¸€ä¸ªå¼€ç®±å³ç”¨çš„Chromeæ‰©å±•ç¨‹åº, éå¸¸é€‚åˆç¡¬ç›˜ç©ºé—´æœ‰é™çš„å°ä¼™ä¼´ä½¿ç”¨(è½¯ä»¶åŠŸèƒ½å¤Ÿç”¨å°±å¯ä»¥äº†~)\n\n#### [044ã€Šè°·æ­Œè®¿é—®åŠ©æ‰‹ã€‹è®¿é—®Chromeå•†åº— Gmail è°·æ­Œæœç´¢](https://zhaoolee.com/ChromeAppHeroes/#/044_gu_ge_fang_wen_zhu_shou)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676647107QM62HjRh.gif)\n\nã€Šè°·æ­Œè®¿é—®åŠ©æ‰‹ã€‹å¯ä»¥è®©æˆ‘ä»¬è®¿é—®Chromeå•†åº—, ä»¥åŠè°·æ­Œæœç´¢, è°·æ­ŒGmailç­‰æœåŠ¡\n`ä»…ä¸ºé¦™æ¸¯åœ°åŒºç”¨æˆ·æï¼Œä¾›æ–¹ä¾¿ç§‘ç ”,å¤–è´¸æä¾›å¸®åŠ©,ä¸è‰¯ç”¨æˆ·,å°†å°é”è®¿é—®IP,åæœè‡ªè´Ÿ`, è°·æ­Œè®¿é—®åŠ©æ‰‹éœ€è¦ä½ è®¾ç½®ä¸»é¡µä¸º`https://2018.hao245.com/`æ‰èƒ½ä½¿ç”¨, æœ‰ç™¾åº¦å…¨å®¶æ¡¶, 360å…¨å®¶æ¡¶çš„æµæ°“å†…æ¶µ~\n\n#### [043ã€ŠDream Afar New Tabã€‹æ¢ç´¢ä¸–ç•Œçš„æ–°æ–¹å¼](https://zhaoolee.com/ChromeAppHeroes/#/043_dream_afar_new_tab)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676649632tZ2s6rTX.gif)\n\nã€ŠDream Afar New Tabã€‹çš„è®¾è®¡éå¸¸æ¼‚äº®, åŠŸèƒ½è°ƒèŠ‚ä¹Ÿéå¸¸ç®€å•, åªæœ‰ä¸¤çº§èœå•, å£çº¸ä¹Ÿéå¸¸ç²¾ç¾, å¯¹æµè§ˆå™¨é¢œå€¼æœ‰è¦æ±‚çš„å°ä¼™ä¼´, å¯ä»¥è¯•ä¸€è¯•~\n\n#### [042 åœ¨Edgeä¸­å®‰è£…Chromeæ‰©å±•ç¨‹åº](https://zhaoolee.com/ChromeAppHeroes/#/042_edge)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676651842Y4CibC1j.gif)\n\nEdgeå¯ä»¥å®‰è£…ç»å¤§å¤šæ•°Chromeå•†åº—ä¸­çš„æ‰©å±•, ä½†Chromeä¸­çš„è°·æ­Œå¼€å‘Appç¨‹åº, ç±»ä¼¼[Secure Shell App](https://chrome.google.com/webstore/detail/secure-shell-app/pnhechapfaindjhompbnflcldabbghjo), ç›®å‰æ˜¯æ— æ³•å®‰è£…çš„, æ–°ç‰ˆEdgeä½¿ç”¨äº†Chromeçš„Chromiumå†…æ ¸, å¯ä»¥å…¼å®¹å®‰è£…Chromeç”Ÿæ€ä¸­çš„å„ç§åº”ç”¨ç¨‹åº,ä¸ºEdgeæœªæ¥çš„å‘å±•å¸¦æ¥äº†æ— é™å¯èƒ½~\n\n\n#### [041ã€ŠCopy All Urlsã€‹ä¼˜é›…åœ°ä¿å­˜-å¼€å¯å¤šä¸ªæ ‡ç­¾é¡µ](https://zhaoolee.com/ChromeAppHeroes/#/041_copy_all_urls)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676654661AcRRmBh7.gif)\n\nCopy All Urlså±äºå°è€Œç¾åœ°å·¥å…·ï¼Œå¦‚æœä½ æ¯å¤©éƒ½éœ€è¦æŸ¥çœ‹å‡ ä¸ªå›ºå®šçš„ç½‘é¡µ, Copy All Urlsèƒ½å¸®ä½ çœå¾ˆå¤šæ—¶é—´~\n\n\n#### [040ã€ŠGitZip for githubã€‹ä»Githubæ‰¹é‡ä¸‹è½½è¡¨æƒ…åŒ…](https://zhaoolee.com/ChromeAppHeroes/#/040_gitzip_for_github)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676656478Znhb8nzd.gif)\n\n\nä»¥å‰ä»‹ç»è¿‡Githubå¿«é€Ÿä¸‹è½½å•ä¸ªæ–‡ä»¶çš„æ‰©å±•å·¥å…·[ã€ŠEnhanced Githubã€‹](https://zhaoolee.gitbooks.io/chrome/content/018enhanced-github300b-cong-201c-bing-gui-201d-dao-201c-bing-gun-er-201d2c-xia-zai-github-dan-ge-wen-jian.html) , ã€ŠEnhanced Githubã€‹ å’Œ ã€ŠGitZip for githubã€‹ ç»“åˆåˆ°ä¸€èµ·, å°±å¯ä»¥è®©æˆ‘ä»¬å¿«é€Ÿä¸‹è½½, githubä»»æ„ä»“åº“ä»»æ„æ–‡ä»¶å¤¹çš„ä¼˜è´¨èµ„æºäº†~\n\n\n#### [039ã€ŠSimplify Gmailã€‹è®©ç½‘é¡µç‰ˆGmailæ›´æ¸…çˆ½](https://zhaoolee.com/ChromeAppHeroes/#/039_simplify_gmail)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676658848kRCWN5nx.gif)\n\nå¥½çš„æ‰©å±•ç¨‹åºå°±åº”è¯¥è¿™æ ·, è®©äººè§åˆ°åè€³ç›®ä¸€æ–°, ä½¿ç”¨çš„æ–¹æ³•å´éå¸¸ç®€å•ã€‚\nå¦‚æœä½ å¹¶æ²¡æœ‰æ³¨å†Œè¿‡Gmailé‚®ç®±, å¯ä»¥å°è¯•æ³¨å†Œä¸€ä¸ª, Gmailæ˜¯éå¸¸å¥½ç”¨çš„, æ‹¥æœ‰è§„èŒƒçš„æ¥å£, ä¸ä¼šéšä¾¿æ‹¦æˆªé‚®ä»¶, ä¹Ÿä¸ä¼šåœ¨é¡µé¢é“ºæ»¡å¹¿å‘Š\n\n\n\n#### [038ã€ŠAlexa Traffic Rankã€‹ä¸€é”®æŸ¥çœ‹ç½‘ç«™å…¨çƒæ’å](https://zhaoolee.com/ChromeAppHeroes/#/038_alexa_traffic_rank)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676661407DkWdE4BB.webp)\n\nAlexaç»™å‡ºçš„ç½‘ç«™æ’å, æ˜¯ç›®å‰å…¬è®¤æœ€å…·å‚è€ƒä»·å€¼çš„æ’å, æ‰“å¼€ä¸€ä¸ªæ–°ç«™ç‚¹, æŸ¥ä¸€ä¸‹æ–°ç«™ç‚¹çš„Alexaæ’å, ä»¥åŠä¸å®ƒç±»ä¼¼çš„ç«™ç‚¹, è®©æˆ‘ä»¬å¾ˆå¿«å¯¹æ–°ç«™ç‚¹çš„å®šä½, æœ‰ä¸€ä¸ªå¤§è‡´çš„è®¤çŸ¥~\n\n#### [037ã€ŠSaladictã€‹è°·æ­Œ!æœ‰é“!æˆ‘å…¨éƒ½è¦! èšåˆè¯å…¸, å¹¶è¡Œç¿»è¯‘](https://zhaoolee.com/ChromeAppHeroes/#/037_saladict)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676664679BSy0DdiW.gif)\n\næ²™æ‹‰æŸ¥è¯(Saladict)æ˜¯ä¸€æ¬¾éå¸¸ä¼˜ç§€çš„æŸ¥è¯æ‰©å±•, ä¸Šæ–‡åªæ˜¯æåŠäº†å®ƒæœ€å¸¸ç”¨çš„ä¸€äº›åŠŸèƒ½, æ²™æ‹‰æŸ¥è¯çš„åå°ç®¡ç†é€‰é¡¹éå¸¸ä¸°å¯Œ, æ„Ÿå…´è¶£çš„å°ä¼™ä¼´å¯ä»¥æ…¢æ…¢æ¢ç´¢\n\n\n#### [036ã€ŠScreen Shaderã€‹æŠŠå±å¹•è°ƒæˆæš–è‰²ï¼Œä½ çš„çœ¼ç›ä¼šæ„Ÿè°¢ä½ ğŸ™](https://zhaoolee.com/ChromeAppHeroes/#/036_screen_shader)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676666670XSnjF8Ej.gif)\n\nå¯¹äºé•¿æ—¶é—´çœ‹ç”µè„‘çš„åŠå…¬äººå‘˜, å¯ä»¥å°è¯•å§å±å¹•è°ƒæˆæš–è‰², å¼€å§‹å¯èƒ½ä¼šä¸ä¹ æƒ¯, ä½†åé¢ä¼šæ„Ÿè§‰çœ¼ç›ä¼šèˆ’æœå¾ˆå¤š, ä½ çš„çœ¼ç›ä¹Ÿä¼šæ„Ÿè°¢ä½ çš„~\n\n\n#### [035ã€ŠPrint Friendly & PDFã€‹è®©ä½ æ‹¥æœ‰æœ€ä½³çš„æ‰“å°é˜…è¯»ä½“éªŒ](https://zhaoolee.com/ChromeAppHeroes/#/035_print_friendly_and_pdf)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106766690875dkGC2Dt.gif)\n\nã€ŠPrint Friendly & PDFã€‹æ˜¯ä¸€æ¬¾æ–‡ä»¶æ‰“å°chromeæ’ä»¶ï¼Œä¼šåœ¨æ‰“å°ä¹‹å‰åˆ é™¤åƒåœ¾å¹¿å‘Šï¼Œå¯¼èˆªå’Œæ— ç”¨æµ®çª—ä»è€Œå®ç°é¡µé¢ä¼˜åŒ–ï¼Œè®©ä½ æ‹¥æœ‰æœ€ä½³çš„æ‰“å°é˜…è¯»ä½“éªŒ, å¦‚æœä½ ç»å¸¸éœ€è¦æ‰“å°ç½‘é¡µ, å¯ä»¥é€šè¿‡ã€ŠPrint Friendly & PDFã€‹è®©ä½ çš„æ‰“å°å·¥ä½œå˜å¾—çœæ—¶çœåŠ›~\n\n\n#### [034ã€ŠAstro Botã€‹ç”¨æ–°æ ‡ç­¾é¡µåˆ·ç¼–ç¨‹é¢˜](https://zhaoolee.com/ChromeAppHeroes/#/034_astro_bot)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676670985y5iFaD7Z.gif)\n\nAstro Botå¯ä»¥åœ¨æ–°æ ‡ç­¾é¡µ,å±•ç¤ºä¸€é“ä¸ç¨‹åºç›¸å…³çš„é—®é¢˜æˆ–ç›¸å…³æ–°é—»\n\n\n#### [033ã€Šä¸€å¶ã€‹åœ¨ä»»æ„ç½‘é¡µå¼€å¯å®æ—¶å¼¹å¹• èŠå¤©çª—å£ ç•™è¨€æ¿](https://zhaoolee.com/ChromeAppHeroes/#/033_yi_ye)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676672985Kjeyahw2.gif)\n\nä¸€å¶æ˜¯ä¸€æ¬¾å¾ˆæœ‰æƒ³æ³•çš„äº§å“,ä½†ç›®å‰ç”¨æˆ·é‡è¿˜æ˜¯å¾ˆå°‘, å¯¹æ­¤,æˆ‘ä¸ªäººä¹Ÿæœ‰ä¸€äº›æƒ³æ³•,å¦‚æœå®˜æ–¹å¯ä»¥æ•ˆä»¿pokemongoè¿™ç±»å¯»å®æ¸¸æˆ,åœ¨å„å¤§ç½‘ç«™çš„ä¸»é¡µå¯¹åº”çš„ç•™è¨€æ¿å†…,åŸ‹ä¸‹ä¸€äº›æœ‰æ„æ€çš„å½©è›‹,è®©ç”¨æˆ·å»å¯»å®,æˆ–è®¸ä¼šæœ‰åˆ©äºäº§å“çš„æ¨å¹¿~\n\n\n#### [032ã€ŠSmallpdfã€‹ç®€å•å¥½ç”¨çš„çº¿ä¸ŠPDFå·¥å…·](https://zhaoolee.com/ChromeAppHeroes/#/032_smallpdf)\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676675162GXbJPaMw.gif)\n\n\nSmallpdfæ˜¯ä¸€ä¸ªéå¸¸å¥½ç”¨çš„PDFå·¥å…·,å¯ä»¥æ”¶è—èµ·æ¥,ä½œä¸ºæ—¥å¸¸åŠå…¬çš„å·¥å…·, Smallpdfå¯ä»¥è¿›è¡Œå¤šä»½pdfåœ¨çº¿åˆå¹¶, pdfåœ¨çº¿ç¼–è¾‘, å¦‚æœä½ æ˜¯ä¸€ä¸ªç»å¸¸å’ŒPDFæ‰“äº¤é“çš„äºº, å¯ä¸è¦é”™è¿‡å®ƒ~\n\n\n#### [031ã€ŠOneTabã€‹æŠŠå¤šä¸ªTabè½¬æ¢ä¸ºä¸€ä¸ªåˆ—è¡¨](https://zhaoolee.com/ChromeAppHeroes/#/031_onetab)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106766778557RfeaSey.png)\n\n\nå½“ä½ å‘ç°è‡ªå·±æœ‰å¤ªå¤šçš„æ ‡ç­¾é¡µæ—¶,å•å‡»OneTabå›¾æ ‡,æ‰€æœ‰æ ‡ç­¾é¡µä¼šè½¬æ¢æˆä¸€ä¸ªåˆ—è¡¨,å½“ä½ éœ€è¦å†æ¬¡è®¿é—®è¿™äº›æ ‡ç­¾é¡µæ—¶,ç‚¹å‡»OneTabå›¾æ ‡å”¤å‡ºåˆ—è¡¨,ç‚¹å‡»åˆ—è¡¨æ¢å¤æ ‡ç­¾é¡µ\n\n#### [030ã€Šæ˜é‡‘ã€‹ç›¸ä¿¡ä¼˜è´¨æŠ€æœ¯å†…å®¹çš„åŠ›é‡](https://zhaoolee.com/ChromeAppHeroes/#/030_jue_jin)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676679321DxpDN38h.gif)\n\nå¦‚æœä½ æƒ³å¯¹ ç¨‹åºå‘˜, äº§å“ç»ç†, è®¾è®¡å¸ˆçš„è¡Œä¸šçŸ¥è¯†æœ‰æ‰€äº†è§£, å¯ä»¥æ²¡äº‹å„¿æ‰“å¼€æ˜é‡‘æ’ä»¶çœ‹ä¸€çœ‹, å¦‚æœä½ æ„Ÿè§‰å¾ˆå–œæ¬¢é‡Œé¢çš„å†…å®¹, å¯ä»¥åˆ°æ˜é‡‘å®˜ç½‘ [https://juejin.im/](https://juejin.im/) é€›ä¸€é€›\n\n\n#### [029 ã€ŠSimpReadã€‹ä¸ºä»»æ„ç½‘é¡µå¼€å¯é˜…è¯»æ¨¡å¼](https://zhaoolee.com/ChromeAppHeroes/#/029_simread)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676682420KWrt5ChX.gif)\nä¸ºç½‘é¡µå¼€å¯é˜…è¯»æ¨¡å¼, èƒ½è®©æˆ‘ä»¬æ›´ä¸“æ³¨äºå†…å®¹, ä¸ä¼šè¢«èŠ±èŠ±ç»¿ç»¿çš„å¹¿å‘Šæ¨å¹¿åˆ†æ•£ç²¾åŠ›, è€ŒSimpReadå°±æ˜¯ä¸€æ­€ä¸ºç½‘é¡µå¼€å¯**é˜…è¯»æ¨¡å¼**çš„æ’ä»¶\n\n\n\n#### [028ã€ŠAdBlockã€‹Adblockå±è”½ç®€ä¹¦å¹¿å‘Š](https://zhaoolee.com/ChromeAppHeroes/#/028_adblock)\n\n![å±è”½ç®€ä¹¦å¹¿å‘Š](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676685305ZJS0Yzhi.gif)\nAdblockçš„åŠŸèƒ½éå¸¸ä¸°å¯Œ, ä½†å¾ˆå¤šåŠŸèƒ½åŸºæœ¬ç”¨ä¸åˆ°, æ™®é€šç”¨æˆ·åªéœ€è¦å¼€å¯Adblock, èƒ½ä½¿ç”¨å³é”®å·¥å…·å±è”½ä¸å–œæ¬¢çš„å¹¿å‘Š, ä¹Ÿå°±å¤Ÿç”¨äº†~\n\n#### [027ã€ŠTextã€‹æ¥è‡ªChromeå®éªŒå®¤çš„è·¨å¹³å°è®°äº‹æœ¬](https://zhaoolee.com/ChromeAppHeroes/#/027_text)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676687137CS8CJ0C3.gif)\n\nTextç”±è°·æ­ŒChromeå®éªŒå®¤ç ”å‘å¹¶å¼€æº, å¼€æºåœ°å€https://github.com/GoogleChromeLabs/text-app , Textå±äºå°è€Œç¾çš„äº§å“, åŠŸèƒ½ä¸ç®—å¼ºå¤§, ä½†æ˜¯å¤Ÿç”¨, è€Œä¸”å€ŸåŠ©Chromeå®Œæˆäº†è·¨å¹³å°(åœ¨Linuxä¹Ÿå¯ä»¥ä½¿ç”¨å“¦~)\n\n#### [026ã€ŠQuickey Launcherã€‹æ‰“å¼€ç½‘ç«™åªéœ€ä¸€é”®](https://zhaoolee.com/ChromeAppHeroes/#/026_quickey_launcher)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676690004HrxG5h0S.gif)\nQuickey Launcherä»¥ä¼˜é›…çš„æ–¹å¼, ä¸ºä»»æ„ç½‘é¡µç»‘å®šä¸€ä¸ªå¿«æ·é”®, ç»‘å®šå®Œæˆå, å³å¯é€šè¿‡å¿«æ·é”®,æ‰“å¼€ç½‘é¡µ\n\n\n#### [025ã€ŠConsoleã€‹Chromeè‡ªå¸¦å¥½ç”¨çš„è®¡ç®—å™¨](https://zhaoolee.com/ChromeAppHeroes/#/025_console)\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676691853DAfTJ26E.gif)\n\nChromeè®¡ç®—æœºçš„å¥½ç”¨ä¹‹å¤„: æ—¢å¯ä»¥çœ‹åˆ°åŠ æ•°å­—çš„è®°å½•,ä¹Ÿå¯ä»¥å®æ—¶é¢„è§ˆè¿ç®—çš„ç»“æœ, è¾“å…¥å®Œæˆåè¿˜å¯ä»¥å¾ˆæ–¹ä¾¿çš„æ ¸æŸ¥ä¸€é, è¿˜æœ‰ä¸€ç‚¹: Chromeè®¡ç®—å™¨è§‚èµæ€§å¼º(é€¼æ ¼å¾ˆé«˜)\n\n\n#### [024ã€ŠDark Readerã€‹ä¸ºä»»æ„ç½‘ç«™å¯ç”¨å¤œé—´æ¨¡å¼](https://zhaoolee.com/ChromeAppHeroes/#/024_dark_reader)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676695063tJA2EFcr.gif)\n\nå–œæ¬¢å¤œé—´æ¨¡å¼çš„å°ä¼™ä¼´, Dark Readeråº”è¯¥å¯ä»¥æ»¡è¶³ä½ äº†~\n\n\n\n\n##### [023ã€ŠFireShotã€‹ä¸€é”®æ»šåŠ¨æˆªå±æ•´ä¸ªç½‘é¡µ](https://zhaoolee.com/ChromeAppHeroes/#/023_fireshot)\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676697725ebZTbKKP.gif)\næ€»ä½“æ¥è®², FireShotæ˜¯ä¸€æ¬¾ä¸é”™çš„è½¯ä»¶, å…è´¹ä¸”åŠŸèƒ½å¤Ÿç”¨, æ»šåŠ¨æˆªå›¾çš„åŠŸèƒ½æ¯”åŒç±»è½¯ä»¶åšçš„éƒ½è¦å¥½\n\n\n#### [022ã€Šæ‰©å±•ç®¡ç†å™¨ã€‹ç®¡ç†ä½ çš„Chromeæ‰©å±•](https://zhaoolee.com/ChromeAppHeroes/#/022kuo_zhan_guan_li_qi)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676700587D3zDFxpT.gif)\nå¦‚æœChromeå®‰è£…çš„æ’ä»¶å¾ˆå¤š, æˆ‘ä»¬å¯ä»¥å¯¹æ’ä»¶è¿›è¡Œåˆ†ç»„, æŒ‰ç…§åœºæ™¯,å¯ç”¨ä¸åŒç»„çš„æ’ä»¶\n\n\n#### [021ã€Šå“”å“©å“”å“©åŠ©æ‰‹ã€‹åŠ©ä½ å¿«é€Ÿæˆä¸ºBç«™è€å¸æœº](https://zhaoolee.com/ChromeAppHeroes/#/021_bi_li_bi_li_zhu_shou)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676704299frysKHiN.gif)\n\nå“”å“©å“”å“©åŠ©æ‰‹, åŠŸèƒ½å®ç”¨,å¼€å‘è€…ä¹Ÿä¸€ç›´ä¿æŒç€è¾ƒé«˜é¢‘ç‡çš„æ›´æ–°,å¯ä»¥æ”¾å¿ƒé£Ÿç”¨~\n\n\n\n\n#### [020ã€ŠBoxel Reboundã€‹â€œå—¨åˆ°ä¸­æ¯’â€çš„å¼¹è·³å°æ–¹å—\\(é™„è‡ªåˆ¶èµ›é“åˆ†äº«æ–¹æ³•\\)](https://zhaoolee.com/ChromeAppHeroes/#/020_boxel_rebound)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676706878ze3TkWxJ.gif)\nBoxel Reboundæ˜¯ä¸€ä¸ªåæå®¢çš„å°æ¸¸æˆ, ç©æ³•ç®€å•, å¯ä»¥è‡ªç”±åˆ›å»ºèµ›é“, åˆ†äº«èµ›é“, è·å–åˆ«äººçš„èµ›é“è¿›è¡ŒäºŒæ¬¡å¼€å‘; æ— è®ºä½ æ˜¯Macç”¨æˆ·,Windowsç”¨æˆ·,Linuxç”¨æˆ·, åªè¦å®‰è£…äº†Chromeæµè§ˆå™¨, å°±å¯ä»¥ç©è€Boxel Rebound\n\n\n\n#### [019ã€ŠMEGAã€‹ç½‘ç›˜å¯ä»¥è‰¯å¿ƒåˆ°ä»€ä¹ˆç¨‹åº¦? è¯•è¯•MEGAå§!](https://zhaoolee.com/ChromeAppHeroes/#/019_mega)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106767094208BDNXpQp.png)\n\n* æ²¡æœ‰é™é€Ÿçš„æ¦‚å¿µ(çœŸçš„è¢«ç™¾åº¦ç›˜çš„é™é€Ÿç­–ç•¥æ¶å¿ƒåˆ°äº†)\n* åœ¨å›½å†…å¯ç”¨(googleè™½å¥½, ä½†å›½å†…ç”¨ä¸äº†, MEGAsyncäº²æµ‹å›½å†…å¯ç”¨)\n* äº‘ç«¯åŠ å¯†, èµ„æºä¸ä¼šè¢«å°æ€\n* å®˜æ–¹æä¾›äº†Linuxå®¢æˆ·ç«¯\n\n\n\n#### [018ã€ŠEnhanced Githubã€‹ä»â€œå†°æŸœâ€åˆ°â€œå†°æ£å„¿â€,ä¸‹è½½Githubå•ä¸ªæ–‡ä»¶](https://zhaoolee.com/ChromeAppHeroes/#/018_enhanced_github)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676711242KtfQSCT2.png)\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676713232c87kebNc.png)\næˆ‘éœ€è¦Githubç»™æˆ‘ä¸€æ ¹å†°æ£è§£æš‘,Githubå´åšæŒæŠŠè£…æœ‰å†°æ£çš„å†°æŸœä¹Ÿé€ç»™æˆ‘ï¼ˆå“¥ä»¬å„¿çœŸå¤Ÿæ„æ€ï¼‰... æœ‰äº†Enhanced Githubè¿™æ¬¾æ’ä»¶, æˆ‘ä»¬å¯ä»¥ä¸‹è½½Githubä¼˜ç§€é¡¹ç›®ä¸­æœ€æ ¸å¿ƒçš„ä»£ç æ–‡ä»¶è¿›è¡Œå­¦ä¹ , è€Œä¸æ˜¯ ä¸‹è½½ æ•´ä¸ªä»“åº“ä½œä¸ºè—å“\n\n\n#### [017ã€Šæ–°æµªå¾®åšå›¾åºŠã€‹æœ¬åœ°Markdownç¼–å†™æ›´æµç•…, æ–°æµªå¾®åšå›¾åºŠæ¥å¸®å¿™](https://zhaoolee.com/ChromeAppHeroes/#/017_xin_lang_wei_bo_tu_chuang)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106767148458xJfk6jS.gif)\nç”¨Markdownå†™æ–‡ç« , å¦‚æœæ–‡ç« ä¸­ä½¿ç”¨äº†æœ¬åœ°é…å›¾, é‚£æœ¬åœ°é…å›¾å°±è¦å’Œæ–‡ç« ä¸€èµ·æ‰“åŒ…,å¦åˆ™åˆ«äººæ˜¯çœ‹ä¸åˆ°å›¾ç‰‡çš„,å¦‚æœæŠŠæœ¬åœ°å›¾ç‰‡æ”¾åˆ°ç½‘ç»œæœåŠ¡å™¨, ç„¶åç›´æ¥æŠŠå›¾ç‰‡çš„urlç²˜è´´åˆ°æ–‡ç« é‡Œé¢, å°±å¯ä»¥å…é™¤å›¾ç‰‡æ‰“åŒ…çš„æ­¥éª¤\n\n\n\n#### [016ã€Šè§£é™¤Bç«™åŒºåŸŸé™åˆ¶ã€‹æŸ¥çœ‹è¿›å‡»çš„å·¨äººç¬¬ä¸‰å­£](https://zhaoolee.com/ChromeAppHeroes/#/016_jie_chu_b_zhan_qu_yu_xian_zhi)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676717502BrR0TxxW.png)\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676719391bDH6cn5d.png)\nè§£é™¤Bç«™åŒºåŸŸé™åˆ¶,Bç«™è€å¸æœºå¿…å¤‡æŠ€èƒ½\n\n\n#### [015ã€ŠXPath Helperã€‹å®ŒæˆBingæ¯æ—¥å£çº¸çš„å°çˆ¬è™«](https://zhaoolee.com/ChromeAppHeroes/#/015_xpath_helper)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676720811KPJwW1DR.png)\n\nXPathæ˜¯ä¸€ä¸ªè¾…åŠ©æˆ‘ä»¬å†™çˆ¬è™«çš„å°æ’ä»¶, æˆ‘ä»¬å¯ä»¥ç”¨XPathè¾…åŠ©æˆ‘ä»¬å®Œæˆä¸€ä¸ªBingå£çº¸çš„å°çˆ¬è™«~\n\n#### [014ã€Šè¶…çº§é©¬é‡Œå¥¥æ¸¸æˆã€‹Chromeå˜èº«å°éœ¸ç‹](https://zhaoolee.com/ChromeAppHeroes/#/014_chao_ji_ma_li_ao_you_xi)\n\n![è¶…çº§ç›ä¸½.gif](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106767233073TCZ8J2B.gif)\n\nç”¨Chromeç©è¶…çº§é©¬é‡Œå¥¥æ˜¯ä¸€ç§ä»€ä¹ˆä½“éªŒ? å“ˆå“ˆ, å¥½ç©! ã€Šè¶…çº§é©¬é‡Œå¥¥æ¸¸æˆã€‹è¿™æ¬¾æ’ä»¶,å¯ä»¥è®©ä½ æ‰“å¼€Chrome, éšæ—¶ç©ä¸€å±€è¶…çº§ç›ä¸½, å˜¿å˜¿ğŸ˜‹\n\n\n\n#### [013ã€ŠQuick QRã€‹ç”¨äºŒç»´ç å®ç°äº‘ç²˜è´´](https://zhaoolee.com/ChromeAppHeroes/#/013_quick_qr)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676725849BZ2zcAmG.png)\n\né€šè¿‡Quick QR, æˆ‘ä»¬å¯ä»¥ä¸å€ŸåŠ©ä»»ä½•é€šè®¯è½¯ä»¶,é€šè¿‡æ‰‹æœºæ‰«ç ,è·å–PCæµè§ˆå™¨ä¸Šä»»æ„ä¸€æ®µæ–‡å­—ä¿¡æ¯\\(äº‘ç²˜è´´æ¿å“¦~\\)\n\n#### [012ã€ŠOurStickysã€‹Chromeç‰¹è‰²ç½‘é¡µä¾¿ç­¾çº¸](https://zhaoolee.com/ChromeAppHeroes/#/012_ourstickys)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676727445FdnCKZXp.gif)\n\nå‘ä¼—äººä»‹ç»å–œæ¬¢çš„ç½‘é¡µåŠŸèƒ½æ—¶,å¯ä»¥è¾¹è®²,è¾¹å‘ç½‘é¡µæ‰“ä¾¿ç­¾,è¿™æ ·æ—¢èƒ½è®©äººçœ¼å‰ä¸€äº®,ä¹Ÿè®©å¬ä¼—å®¹æ˜“æŠ“ä½é‡ç‚¹~\n\n\n#### [011 ã€Šwhatrunsã€‹ä¸€é”®åˆ†æç½‘ç«™æŠ€æœ¯æ ˆ](https://zhaoolee.com/ChromeAppHeroes/#/011_whatruns)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676734950pmRfpHy4.png)\n\nå¦‚æœä½ å¯¹å½“å‰æµè§ˆçš„ç½‘ç«™éå¸¸æ„Ÿå…´è¶£, å¯ä»¥é€šè¿‡whatrunsäº†è§£è½¯ä»¶çš„æŠ€æœ¯æ ˆ, æ¯”å¦‚çœ‹çœ‹è¿™ä¸ªåä¸ºfacebookç”¨äº†ä»€ä¹ˆæŠ€æœ¯\n\n\n#### [010ã€Šspeedtestã€‹ç½‘ç»œæµ‹é€Ÿæ’ä»¶speedtest](https://zhaoolee.com/ChromeAppHeroes/#/010_speedtest)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106767375368554kYjN.png)\n\nå½“ä¸Šç½‘é€Ÿåº¦å¾ˆæ…¢çš„æ—¶å€™, äººä»¬æƒ³åˆ°çš„ç¬¬ä¸€ä»¶äº‹å°±è¿›è¡Œç½‘ç»œæµ‹é€Ÿ,åœ¨windowä¸Š, åªè¦ä½ å®‰è£…äº†360å…¨å®¶æ¡¶, æµ‹é€ŸåŠŸèƒ½å°±æ˜¯é»˜è®¤å®‰è£…çš„, ä½†æµ‹é€Ÿè¿™ç§åŠŸèƒ½æ ¹æœ¬ä¸éœ€è¦å®‰è£…åˆ°æœ¬åœ°, äº¤ç»™æµè§ˆå™¨å°±å¥½äº†\n\n\n\n#### [009ã€Švimiumã€‹Chromeä¸vimåŒç¥å™¨èåˆ](https://zhaoolee.com/ChromeAppHeroes/#/009_vimium)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106767389985HFNmxi2.gif)\n\nvimiumå¯ä»¥è®©æˆ‘ä»¬åªä½¿ç”¨é”®ç›˜å°±å¯ä»¥æµè§ˆç½‘é¡µ, å¦‚æœä½ ç¬¬ä¸€æ¬¡çœ‹åˆ°æœ‰äººä½¿ç”¨vimium, å®ƒçš„æ“ä½œæ–¹å¼ç»å¯¹èƒ½è®©ä½ æ„Ÿåˆ°æƒŠè‰³~\n\n\n#### [008ã€ŠChrome Cleaner Proã€‹ä¸ºChromeåŠ é€Ÿ](https://zhaoolee.com/ChromeAppHeroes/#/008_chrome_cleaner_pro)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676741849BXk12ky1.png)\n\nChromeç»è¿‡æœ€è¿‘å‡ å¹´çš„å‘å±•, å¼ºåŠ›çš„æ‰©å±•è¶Šæ¥è¶Šå¤š, ç¦»Chrome OSçš„ç›®æ ‡ä¹Ÿè¶Šæ¥è¶Šè¿‘, è½¯ä»¶åšå¤§äº†å°±ä¼šæœ‰ç±»ä¼¼Windowsçš„é€šç—…, è½¯ä»¶ä¼šå˜æ…¢, è®©Chromeå˜å¿«çš„æœ€ç®€å•æ–¹å¼å°±æ˜¯æ¸…ç†åƒåœ¾, è€ŒChrome Cleaner Proèµ°çš„æ˜¯ä¸€é”®æ¸…ç†çš„è·¯å­~\n\n\n#### [007ã€Šloomã€‹ Chromeç¿»å½•ç½‘é¡µè§†é¢‘ç¥å™¨](https://zhaoolee.com/ChromeAppHeroes/#/007_loom)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676743780ii1QP2B5.png)\n\nLoomå¯ä»¥ä¸€é”®å½•åˆ¶æµè§ˆå™¨çš„å•ä¸ªæ ‡ç­¾é¡µ(ç›—ç‰ˆç¿»å½•è§†é¢‘çš„ç¥å™¨), å½•åˆ¶å®Œæˆåè‡ªåŠ¨ç”Ÿæˆåœ¨çº¿ç½‘é¡µ,è¿›è¡Œè§†é¢‘æ’­æ”¾, å¯ä»¥ä¸‹è½½åˆšåˆšå½•åˆ¶çš„è§†é¢‘, ä¹Ÿå¯ä»¥ä¸ºåˆšåˆšç”Ÿæˆçš„åœ¨çº¿è§†é¢‘è®¾ç½®å¯†ç (ç›—ç‰ˆå½•å±åŠ å‘å¸ƒä¸€æ¡é¾™æœåŠ¡~)\n\n#### [006ã€ŠSimilarSitesã€‹ ä¸€é”®æŸ¥æ‰¾å§Šå¦¹ç½‘ç«™ SimilarSites](https://zhaoolee.com/ChromeAppHeroes/#/006_similarsites)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676745696J7JZ0hEx.png)\n\nå½“ä½ æµè§ˆä¸€ä¸ªå¾ˆæ£’çš„ç«™ç‚¹çš„æ—¶å€™, æˆ–è®¸ä½ ä¼šæƒ³åˆ°, å’Œå®ƒ\"å·®ä¸å¤š\"çš„ç«™ç‚¹æœ‰å“ªäº›, å°¤å…¶æ˜¯é’ˆå¯¹ä¸€äº›èµ„æºç«™ç‚¹, è¿™ä¸ªç«™ç‚¹æ²¡æœ‰, è€Œå®ƒåŒç±»çš„ç«™ç‚¹\"å¾€å¾€æœ‰\"! SimilarSites, å®ƒçš„ä½œç”¨åªæœ‰ä¸€ä¸ª, å‘ç°åŒç±»ç«™ç‚¹!\n\n\n#### [005ã€ŠVideo Speed Controllerã€‹ åˆ·è¯¾ï¼ˆåˆ·å‰§ï¼‰ç¥å™¨ï¼ç»™ç½‘é¡µè§†é¢‘åŠ ä¸ªé€Ÿ(æœ€å¿«å¯è¾¾16å€!)](https://zhaoolee.com/ChromeAppHeroes/#/005_video_speed_controller)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676749966N5Wk2xSG.png)\n\nåˆ·ä¸€äº›æ²¡è¥å…»è§†é¢‘çš„æ—¶å€™, æˆ‘ä»¬ä¼šæœ‰å€é€Ÿæ’­æ”¾è§†é¢‘çš„éœ€æ±‚, è€Œç½‘ç«™çš„åœ¨çº¿æ’­æ”¾å™¨ä¸€èˆ¬åªæä¾›ä¸é«˜äº4å€çš„æ’­æ”¾é€Ÿåº¦, è€ŒVideo Speed Controllerå¯ä»¥å°†è§†é¢‘æ’­æ”¾é€Ÿåº¦æé«˜åˆ°16å€é€Ÿ~\n\n\n#### [004ã€ŠTampermonkeyã€‹ æ²¹çŒ´å­! ç»™æµè§ˆå™¨å¼€ä¸ªæŒ‚](https://zhaoolee.com/ChromeAppHeroes/#/004_tampermonkey)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676751723sZJTfmcQ.png)\n\næ²¹çŒ´å­å¿…å¤‡æˆä¸ºChromeçš„ç¬¬äºŒåº”ç”¨å•†åº—, æœ‰äº†æ²¹çŒ´å­, ä½ å¯ä»¥å…è´¹æŸ¥çœ‹VIPè§†é¢‘, æ¸…é™¤å„ç§ç½‘é¡µå¹¿å‘Š, åœ¨è±†ç“£å½±è¯„é¡µé¢æ˜¾ç¤ºç”µå½±èµ„æºçš„ä¸‹è½½åœ°å€~\n\n#### [003ã€ŠSecure Shell Appã€‹ Chromeä¸­å¼€å¯sshä¸€ç§ä»€ä¹ˆä½“éªŒ](https://zhaoolee.com/ChromeAppHeroes/#/003_secure_shell_app)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676753552ifzyRrpc.png)\n\nå¾ˆå¤šå°ç™½æƒ³è¦é€šè¿‡è´­ä¹°æœåŠ¡å™¨æ­å»ºè‡ªå·±çš„VPN, è´­ä¹°æœåŠ¡å™¨å, ç¬¬ä¸€æ­¥å°±æ˜¯è¦é€šè¿‡sshç™»å½•æœåŠ¡å™¨, è€ŒWindowså¹¶æ²¡æœ‰è‡ªå¸¦sshè½¯ä»¶,ç°åœ¨ä½ æ— éœ€ä¸‹è½½puttyæˆ–xshell ,å¯ä»¥é€šè¿‡è¿™æ¬¾Secure Shell Appåœ¨chromeç›´æ¥å®ç°sshç™»å½•æœåŠ¡å™¨äº†\n\n\n\n#### [002 ã€Šchronoã€‹ è®©Chromeä¸‹è½½èµ„æºæ›´å®¹æ˜“](https://zhaoolee.com/ChromeAppHeroes/#/002_chrono)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676755041BK8t3n6n.png)\n\nchronoå¯ä»¥éå¸¸æ–¹ä¾¿çš„å—…æ¢è¯†åˆ«ç½‘é¡µä¸­çš„èµ„æº, ç„¶åä¸€é”®ä¸‹è½½æ‰€æœ‰èµ„æº(æ”¶å›¾å–½!)\n\n\n#### [001ã€Šmarkdown-hereã€‹ Markdownä¸€é”®è½¬æ¢åˆ°\"å¯Œæ–‡æœ¬æ ¼å¼\"](https://zhaoolee.com/ChromeAppHeroes/#/001_markdown_here)\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676756815SkrMNH17.gif)\n\næœ‰äº†markdown-hereè¿™ä¸ªæ’ä»¶, å¯ä»¥åœ¨ç½‘é¡µç‰ˆ QQé‚®ç®±, Gmail, æ–°æµªå¤´æ¡æ–‡ç« , é‡Œé¢ä½¿ç”¨mardownæ ¼å¼è¿›è¡Œä¹¦å†™,ç„¶åä¸€é”®è½¬æ¢ä¸ºå¯Œæ–‡æœ¬\n\n\n## ä»–äººçœ¼ä¸­çš„ Chromeæ’ä»¶è‹±é›„æ¦œ(å•†ä¸šäº’å¹æ¨¡å—)\n\n- [ã€Šè¿™ä»½â€œæ’ä»¶è‹±é›„æ¦œTop20â€æ‰æ˜¯Chromeçš„æ­£ç¡®æ‰“å¼€æ–¹å¼ï¼ã€‹](https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/88386634) ä½œè€…: [AIç§‘æŠ€å¤§æœ¬è¥](https://me.csdn.net/dQCFKyQDXYm3F8rB0)\n- [ã€ŠChrome æ’ä»¶è‹±é›„æ¦œã€‹](https://zhuanlan.zhihu.com/p/58636515) ä½œè€…: [éè‘—åç¨‹åºå‘˜](https://www.zhihu.com/people/loonggg/activities)\n- [ã€Šé–‹æºæ—¥å ±ç¬¬363æœŸã€‹](https://openingsource.org/6190/zh-tw/) ä½œè€…: [å¼€æºå·¥å‚](https://openingsource.org/)\n- [ã€Šä¸€æ ¹ç«æŸ´çš„Nç§æ‰“å¼€æ–¹å¼ã€‹](https://mp.weixin.qq.com/s/Y-9ht-E7-OdJOEDDb3yyWw) ä½œè€…: [è€ç½—å·´æ‰å˜¿](https://github.com/LuoJiangYong)\n\n## åå­—èµ·å•¥å¥½?\n\nå°†è¿™ä¸ªä»“åº“å‘½åä¸º**Chromeæ‰©å±•è‹±é›„æ¦œ**å¯èƒ½æ›´å‡†ç¡®äº›,ä½†**æ’ä»¶**è¿™ä¸ªåè¯, æ›´é€šä¿—æ˜“æ‡‚, æ‰€ä»¥å°±ä½¿ç”¨äº†**Chromeæ’ä»¶è‹±é›„æ¦œ**è¿™ä¸ªå‘½å ,æ„Ÿè°¢@[hjthjthjt](https://github.com/hjthjthjt) ç»™å‡ºçš„[issue](https://github.com/zhaoolee/ChromeAppHeroes/issues/14)çº æ­£\n\n## [æ¨èå§Šå¦¹ä»“åº“](https://github.com/zhaoolee/StarsAndClown)\n\næœ¬ä»“åº“çš„å§Šå¦¹ç¯‡:**[ã€ŠGithubæ˜Ÿèšå¼ƒç–—æ¦œã€‹](https://github.com/zhaoolee/StarsAndClown)**ä¸ºGithubåˆ›æ„é¡¹ç›®å†™ä¸€æœ¬æ¨èä¹¦ï¼Œè®©Githubä¼˜ç§€é¡¹ç›®é€ ç¦äººç±»~ å·²å¼€æºåˆ°Github: [https://github.com/zhaoolee/StarsAndClown](https://github.com/zhaoolee/StarsAndClown) åŒæ ·æœ‰è¶£æœ‰æ–™å“¦~\n\n## æ„Ÿè°¢\n\n- æ„Ÿè°¢ æ˜é‡‘æ²¸ç‚¹è¿è¥ [@æ¸…è’¸ä¸æ˜¯æ°´ç…®](https://juejin.im/user/5b39bd7de51d4558d43ff06d) ç»™å‡ºçš„ **æ­£é¢æœ€å¼€å§‹æ”¾ä¸ªç´¢å¼•ç›®å½•æ¯”è¾ƒå¥½** çš„å°å»ºè®®\n\n- æ„Ÿè°¢[ç®€ä¹¦](https://www.jianshu.com/)ç¤¾åŒºæä¾›è¶…æ£’çš„Markdownç¼–è¾‘å™¨,**Chromeæ’ä»¶è‹±é›„æ¦œ**çš„ç¼–è¾‘å·¥ä½œ,å‡ ä¹å…¨éƒ¨ç”±é€šè¿‡ç®€ä¹¦ç¼–è¾‘å™¨å®Œæˆ\n\n---\n\n\n**[ä»å®˜æ–¹å•†åº—ä¸‹è½½Chromeæ’ä»¶çš„æ–¹æ³•](https://zhaoolee.com/ChromeAppHeroes/download_the_chrome_extension_from_the_store.html)**\n\n\n## ç›¸å…³èµ„æºé“¾æ¥\n\n[æ‰©å±•ç¨‹åºç¦»çº¿ä¸‹è½½](https://chrome-extension-downloader.com/)\n\n[Chromeæ‰©å±•èµ„æºç«™ç‚¹æ¨è](https://zhaoolee.com/ChromeAppHeroes/chrome_extended_resources_site.html)\n\n\n## Chromeæ‰©å±•ç¨‹åºç›¸å…³ç½‘ç«™æ¨è\n\n\n[chajian5: æ”¶è—å¥½ç”¨çš„Chromeæ’ä»¶ï¼Œä¸æ¨èè¯„åˆ†ä½çš„è¿˜æœ‰å¤šå¹´ä¸æ›´æ–°çš„æ’ä»¶ã€‚æ”¯æŒç™¾åº¦ç½‘ç›˜å’Œ360äº‘ç›˜è½¬å­˜æˆ–ä¸‹è½½ï¼Œæ–¹ä¾¿å¿«æ·ã€‚](https://www.chajian5.com/)\n\n**Chromeæ’ä»¶è‹±é›„æ¦œ** Githubåœ°å€: [https://github.com/zhaoolee/ChromeAppHeroes](https://github.com/zhaoolee/ChromeAppHeroes)\næˆ‘éœ€è¦ä½ çš„æ”¯æŒ, å¸Œæœ›ä½ èƒ½ä¸ºæœ¬é¡¹ç›®å¡«åŠ ä¸€ä¸ª ğŸŒŸæ˜Ÿ.\nI need your support, I hope you can add a star ğŸŒŸ to this project.\n\n\n## [ä¸€æ ¹ç«æŸ´çš„Nç§æ‰“å¼€æ–¹å¼(è°·ç²’æ–‡åŒ–)](https://zhaoolee.com/ChromeAppHeroes/meaning_of_gu_li.html)\n\n![smartmockups_juunlhbe.jpg](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676801228PCyiDZRQ.jpeg)\n\n\n![2.png](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/17106767592500R8t4diH.png)\n\n\n\n## èµåŠ©æ‰“èµ\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676761163b7CWJNkr.png)\n\n| èµèµé‡‘é¢ | èµèµè€… | èµèµæ—¶é—´ |\n| --- | --- | --- |\n| 5.00 | è™šæ‹Ÿä¸–ç•Œ | 2002-04-27 |\n| 1.00 | é˜¿ä¹Ÿ | 2020-04-26 |\n| 5.00 | æ— åé›ç¾½ | 2020-04-24 |\n| 30.00 | å¼ æ˜è¾‰(æç®€æ’ä»¶ç«™é•¿) | 2020-04-21 |\n| 1.00 | é›¨ç”° | 2020-04-09 |\n| 1.00 | 2020æˆ‘ä»æ˜¯å°‘å¹´ | 2020-03-24 |\n| 1.00 | Will | 2020-03-12 |\n| 1.00 | (æœªç•™å§“å) | 2020-02-28 |\n| 1.00 | (æœªç•™å§“å) | 2020-02-16 |\n| 5.00 | å—åæ„šåŸ | 2020-02-02 |\n| 1.00 | è§ç£Š | 2020-01-02 |\n| 1.00 | é”¦é¥­ | 2019-12-15 |\n| 1.00 | ç‹ä¸–æ–‡ | 2019-11-22 |\n| 10.00 | è´ºä¹¾æ˜(å…¬ä¼—å·é‡å­ä½ç¼–è¾‘) | 2019-11-20 |\n| 20.00 | å¼ æ˜è¾‰(æç®€æ’ä»¶ç«™é•¿) | 2019-11-16 |\n| 20.00 | Sakura0428 | 2019-11-02 |\n| 1.00 | (æœªç•™å§“å) | 2019-09-26 |\n| 1.00 | å¤å¤©çš„å°è™«å­ | 2019-09-23 |\n| 20.00 | enjoy lift | 2019-09-20 |\n| 5.00 | L__hooåŸ | 2019-09-20 |\n\n<details>\n<summary>ç‚¹å‡»å±•å¼€å†å²æèµ </summary>\n<pre>\n<table>\n<thead>\n</thead>\n<tbody>\n<tr>\n<td>5.00</td>\n<td>åŠå²›é“ç›’</td>\n<td>2019-09-14</td>\n</tr>\n<tr>\n<td>12.34</td>\n<td>å¼ æ˜è¾‰</td>\n<td>2019-08-20</td>\n</tr>\n<tr>\n<td>10.00</td>\n<td>å…­å°ç™»ç™»</td>\n<td>2019-09-05</td>\n</tr>\n<tr>\n<td>10.00</td>\n<td>äº‘æ·¡é£æ™´</td>\n<td>2019-07-24</td>\n</tr>\n<tr>\n<td>10.00</td>\n<td>é‡‘ä¸‰å¤æœˆ</td>\n<td>2019-06-02</td>\n</tr>\n<tr>\n<td>10.00</td>\n<td>Azuno</td>\n<td>2019-06-01</td>\n</tr>\n<tr>\n<td>10.00</td>\n<td>é‚¦å¦¥</td>\n<td>2019-05-22</td>\n</tr>\n<tr>\n<td>5.00</td>\n<td>enjoy life</td>\n<td>2019-09-20</td>\n</tr>\n<tr>\n<td>5.00</td>\n<td>L__hooåŸ</td>\n<td>2019-09-20</td>\n</tr>\n<tr>\n<td>5.00</td>\n<td>æ¢¦æƒ³æ—…ç¨‹(å…¬ä¼—å·:è‹ç”Ÿä¸æƒ‘)</td>\n<td>2019-09-14</td>\n</tr>\n<tr>\n<td>5.00</td>\n<td>1111</td>\n<td>2019-07-27</td>\n</tr>\n<tr>\n<td>5.00</td>\n<td>é‚£éƒ½ä¸é‡è¦</td>\n<td>2019-05-19</td>\n</tr>\n<tr>\n<td>5.00</td>\n<td>Lismg</td>\n<td>2019-06-05</td>\n</tr>\n<tr>\n<td>5.00</td>\n<td>smallèƒ–</td>\n<td>2019-07-09</td>\n</tr>\n<tr>\n<td>2.00</td>\n<td>è‰¯è¾°ç¾</td>\n<td>2019-07-20</td>\n</tr>\n<tr>\n<td>2.00</td>\n<td>@Coolstar</td>\n<td>2019-07-06</td>\n</tr>\n<tr>\n<td>1.00</td>\n<td>(æœªç•™å§“å)</td>\n<td>2019-09-26</td>\n</tr>\n<tr>\n<td>1.00</td>\n<td>å¤å¤©çš„å°è™«å­</td>\n<td>2019-09-23</td>\n</tr>\n<tr>\n<td>1.00</td>\n<td>(æœªç•™å§“å)</td>\n<td>2019-07-26</td>\n</tr>\n<tr>\n<td>1.00</td>\n<td>17</td>\n<td>2019-07-12</td>\n</tr>\n<tr>\n<td>1.00</td>\n<td>(æœªç•™å§“å)</td>\n<td>2019-06-13</td>\n</tr>\n<tr>\n<td>1.00</td>\n<td>Walter Wu</td>\n<td>2019-06-01</td>\n</tr>\n<tr>\n<td>1.00</td>\n<td>Joseph</td>\n<td>2019-04-24</td>\n</tr>\n<tr>\n<td>1.00</td>\n<td>(æœªç•™å§“å)</td>\n<td>2019-04-12</td>\n</tr>\n<tr>\n<td>1.00</td>\n<td>äºäº‘é¹Edward</td>\n<td>2019-04-12</td>\n</tr>\n<tr>\n<td>1.00</td>\n<td>é»„é‡‘æ˜Ÿ</td>\n<td>2019-04-11</td>\n</tr>\n</tbody>\n</table>\n</pre>\n</details>\n\n\n![](https://raw.githubusercontent.com/zhaoolee/ChromeAppHeroes/master/README/1710676763111bcyRpSAN.png)\n\n[æ„Ÿè°¢JetBrainså¯¹æœ¬é¡¹ç›®çš„èµ„åŠ©æ”¯æŒ](https://www.jetbrains.com/?from=ChromeAppHeroes)\n\n**æ„Ÿè°¢ä»¥ä¸Šèµèµè€…å¯¹æœ¬å¼€æºé¡¹ç›®çš„æ”¯æŒ[æ‰‹åŠ¨æ»‘ç¨½]**\n\n## Chromeæ’ä»¶è‹±é›„æ¦œå®˜æ–¹Telegramé¢‘é“\n\nhttps://t.me/ChromeAppHeroes",
      "stars_today": 19
    },
    {
      "id": 15111821,
      "name": "grafana",
      "full_name": "grafana/grafana",
      "description": "The open and composable observability and data visualization platform. Visualize metrics, logs, and traces from multiple sources like Prometheus, Loki, Elasticsearch, InfluxDB, Postgres and many more. ",
      "html_url": "https://github.com/grafana/grafana",
      "stars": 71719,
      "forks": 13371,
      "language": "TypeScript",
      "topics": [
        "alerting",
        "analytics",
        "business-intelligence",
        "dashboard",
        "data-visualization",
        "elasticsearch",
        "go",
        "grafana",
        "hacktoberfest",
        "influxdb",
        "metrics",
        "monitoring",
        "mysql",
        "postgres",
        "prometheus"
      ],
      "created_at": "2013-12-11T15:59:56Z",
      "updated_at": "2026-01-15T23:24:15Z",
      "pushed_at": "2026-01-16T01:06:06Z",
      "open_issues": 3653,
      "owner": {
        "login": "grafana",
        "avatar_url": "https://avatars.githubusercontent.com/u/7195757?v=4"
      },
      "readme": "![Grafana Logo (Light)](docs/logo-horizontal.png#gh-light-mode-only)\n![Grafana Logo (Dark)](docs/logo-horizontal-dark.png#gh-dark-mode-only)\n\nThe open-source platform for monitoring and observability\n\n[![License](https://img.shields.io/github/license/grafana/grafana)](LICENSE)\n[![Go Report Card](https://goreportcard.com/badge/github.com/grafana/grafana)](https://goreportcard.com/report/github.com/grafana/grafana)\n\nGrafana allows you to query, visualize, alert on and understand your metrics no matter where they are stored. Create, explore, and share dashboards with your team and foster a data-driven culture:\n\n- **Visualizations:** Fast and flexible client side graphs with a multitude of options. Panel plugins offer many different ways to visualize metrics and logs.\n- **Dynamic Dashboards:** Create dynamic & reusable dashboards with template variables that appear as dropdowns at the top of the dashboard.\n- **Explore Metrics:** Explore your data through ad-hoc queries and dynamic drilldown. Split view and compare different time ranges, queries and data sources side by side.\n- **Explore Logs:** Experience the magic of switching from metrics to logs with preserved label filters. Quickly search through all your logs or streaming them live.\n- **Alerting:** Visually define alert rules for your most important metrics. Grafana will continuously evaluate and send notifications to systems like Slack, PagerDuty, VictorOps, OpsGenie.\n- **Mixed Data Sources:** Mix different data sources in the same graph! You can specify a data source on a per-query basis. This works for even custom datasources.\n\n## Get started\n\n- [Get Grafana](https://grafana.com/get)\n- [Installation guides](https://grafana.com/docs/grafana/latest/setup-grafana/installation/)\n\nUnsure if Grafana is for you? Watch Grafana in action on [play.grafana.org](https://play.grafana.org/)!\n\n## Documentation\n\nThe Grafana documentation is available at [grafana.com/docs](https://grafana.com/docs/).\n\n## Contributing\n\nIf you're interested in contributing to the Grafana project:\n\n- Start by reading the [Contributing guide](https://github.com/grafana/grafana/blob/HEAD/CONTRIBUTING.md).\n- Learn how to set up your local environment, in our [Developer guide](https://github.com/grafana/grafana/blob/HEAD/contribute/developer-guide.md).\n- Explore our [beginner-friendly issues](https://github.com/grafana/grafana/issues?q=is%3Aopen+is%3Aissue+label%3A%22beginner+friendly%22).\n- Look through our [style guide and Storybook](https://developers.grafana.com/ui/latest/index.html).\n\n> Share your contributor experience in our [feedback survey](https://gra.fan/ome) to help us improve.\n\n## Get involved\n\n- Follow [@grafana on X (formerly Twitter)](https://x.com/grafana/).\n- Read and subscribe to the [Grafana blog](https://grafana.com/blog/).\n- If you have a specific question, check out our [discussion forums](https://community.grafana.com/).\n- For general discussions, join us on the [official Slack](https://slack.grafana.com) team.\n\nThis project is tested with [BrowserStack](https://www.browserstack.com/).\n\n## License\n\nGrafana is distributed under [AGPL-3.0-only](LICENSE). For Apache-2.0 exceptions, see [LICENSING.md](https://github.com/grafana/grafana/blob/HEAD/LICENSING.md).\n",
      "stars_today": 18
    },
    {
      "id": 42408804,
      "name": "traefik",
      "full_name": "traefik/traefik",
      "description": "The Cloud Native Application Proxy",
      "html_url": "https://github.com/traefik/traefik",
      "stars": 61077,
      "forks": 5778,
      "language": "Go",
      "topics": [
        "consul",
        "docker",
        "etcd",
        "go",
        "golang",
        "kubernetes",
        "letsencrypt",
        "load-balancer",
        "marathon",
        "mesos",
        "microservice",
        "reverse-proxy",
        "traefik",
        "zookeeper"
      ],
      "created_at": "2015-09-13T19:04:02Z",
      "updated_at": "2026-01-16T01:01:10Z",
      "pushed_at": "2026-01-15T17:58:07Z",
      "open_issues": 740,
      "owner": {
        "login": "traefik",
        "avatar_url": "https://avatars.githubusercontent.com/u/14280338?v=4"
      },
      "readme": "\n<p align=\"center\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/content/assets/img/traefik.logo-dark.png\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"docs/content/assets/img/traefik.logo.png\">\n      <img alt=\"Traefik\" title=\"Traefik\" src=\"docs/content/assets/img/traefik.logo.png\">\n    </picture>\n</p>\n\n[![Docs](https://img.shields.io/badge/docs-current-brightgreen.svg)](https://doc.traefik.io/traefik)\n[![Go Report Card](https://goreportcard.com/badge/traefik/traefik)](https://goreportcard.com/report/traefik/traefik)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/traefik/traefik/blob/master/LICENSE.md)\n[![Join the community support forum at https://community.traefik.io/](https://img.shields.io/badge/style-register-green.svg?style=social&label=Discourse)](https://community.traefik.io/)\n[![Twitter](https://img.shields.io/twitter/follow/traefik.svg?style=social)](https://twitter.com/intent/follow?screen_name=traefik)\n\nTraefik (pronounced _traffic_) is a modern HTTP reverse proxy and load balancer that makes deploying microservices easy.\nTraefik integrates with your existing infrastructure components ([Docker](https://www.docker.com/), [Swarm mode](https://docs.docker.com/engine/swarm/), [Kubernetes](https://kubernetes.io), [Consul](https://www.consul.io/), [Etcd](https://coreos.com/etcd/), [Rancher v2](https://rancher.com), [Amazon ECS](https://aws.amazon.com/ecs), ...) and configures itself automatically and dynamically.\nPointing Traefik at your orchestrator should be the _only_ configuration step you need.\n\n---\n\n. **[Overview](#overview)** .\n**[Features](#features)** .\n**[Supported backends](#supported-backends)** .\n**[Quickstart](#quickstart)** .\n**[Web UI](#web-ui)** .\n**[Documentation](#documentation)** .\n\n. **[Support](#support)** .\n**[Release cycle](#release-cycle)** .\n**[Contributing](#contributing)** .\n**[Maintainers](#maintainers)** .\n**[Credits](#credits)** .\n\n---\n\n:warning: When migrating to a new major version of Traefik, please refer to the [migration guide](https://doc.traefik.io/traefik/migrate/v2-to-v3/) to ensure a smooth transition and to be aware of any breaking changes.\n\n\n## Overview\n\nImagine that you have deployed a bunch of microservices with the help of an orchestrator (like Swarm or Kubernetes) or a service registry (like etcd or consul).\nNow you want users to access these microservices, and you need a reverse proxy.\n\nTraditional reverse-proxies require that you configure _each_ route that will connect paths and subdomains to _each_ microservice. \nIn an environment where you add, remove, kill, upgrade, or scale your services _many_ times a day, the task of keeping the routes up to date becomes tedious. \n\n**This is when Traefik can help you!**\n\nTraefik listens to your service registry/orchestrator API and instantly generates the routes so your microservices are connected to the outside world -- without further intervention from your part. \n\n**Run Traefik and let it do the work for you!** \n_(But if you'd rather configure some of your routes manually, Traefik supports that too!)_\n\n![Architecture](docs/content/assets/img/traefik-architecture.png)\n\n## Features\n\n- Continuously updates its configuration (No restarts!)\n- Supports multiple load balancing algorithms\n- Provides HTTPS to your microservices by leveraging [Let's Encrypt](https://letsencrypt.org) (wildcard certificates support)\n- Circuit breakers, retry\n- See the magic through its clean web UI\n- WebSocket, HTTP/2, gRPC ready\n- Provides metrics (Rest, Prometheus, Datadog, Statsd, InfluxDB 2.X)\n- Keeps access logs (JSON, CLF)\n- Fast\n- Exposes a Rest API\n- Packaged as a single binary file (made with :heart: with go) and available as an [official](https://hub.docker.com/r/_/traefik/) docker image\n\n## Supported Backends\n\n- [Docker](https://doc.traefik.io/traefik/providers/docker/) / [Swarm mode](https://doc.traefik.io/traefik/providers/docker/)\n- [Kubernetes](https://doc.traefik.io/traefik/providers/kubernetes-crd/)\n- [ECS](https://doc.traefik.io/traefik/providers/ecs/)\n- [File](https://doc.traefik.io/traefik/providers/file/)\n\n## Quickstart\n\nTo get your hands on Traefik, you can use the [5-Minute Quickstart](https://doc.traefik.io/traefik/getting-started/quick-start/) in our documentation (you will need Docker).\n\n## Web UI\n\nYou can access the simple HTML frontend of Traefik.\n\n![Web UI Providers](docs/content/assets/img/webui-dashboard.png)\n\n## Documentation\n\nYou can find the complete documentation of Traefik v3 at [https://doc.traefik.io/traefik/](https://doc.traefik.io/traefik/).\n\n## Support\n\nTo get community support, you can:\n\n- join the Traefik community forum: [![Join the chat at https://community.traefik.io/](https://img.shields.io/badge/style-register-green.svg?style=social&label=Discourse)](https://community.traefik.io/)\n\nIf you need commercial support, please contact [Traefik.io](https://traefik.io) by mail: <mailto:support@traefik.io>.\n\n## Download\n\n- Grab the latest binary from the [releases](https://github.com/traefik/traefik/releases) page and run it with the [sample configuration file](https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml):\n\n```shell\n./traefik --configFile=traefik.toml\n```\n\n- Or use the official tiny Docker image and run it with the [sample configuration file](https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml):\n\n```shell\ndocker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik\n```\n\n- Or get the sources:\n\n```shell\ngit clone https://github.com/traefik/traefik\n```\n\n## Introductory Videos\n\nYou can find high level and deep dive videos on [videos.traefik.io](https://videos.traefik.io).\n\n## Maintainers\n\nWe are strongly promoting a philosophy of openness and sharing, and firmly standing against the elitist closed approach. Being part of the core team should be accessible to anyone who is motivated and want to be part of that journey!\nThis [document](docs/content/contributing/maintainers-guidelines.md) describes how to be part of the [maintainers' team](docs/content/contributing/maintainers.md) as well as various responsibilities and guidelines for Traefik maintainers.\nYou can also find more information on our process to review pull requests and manage issues [in this document](https://github.com/traefik/contributors-guide/blob/master/issue_triage.md).\n\n## Contributing\n\nIf you'd like to contribute to the project, refer to the [contributing documentation](CONTRIBUTING.md).\n\nPlease note that this project is released with a [Contributor Code of Conduct](CODE_OF_CONDUCT.md).\nBy participating in this project, you agree to abide by its terms.\n\n## Release Cycle\n\n- We usually release 3/4 new versions (e.g. 1.1.0, 1.2.0, 1.3.0) per year.\n- Release Candidates are available before the release (e.g. 1.1.0-rc1, 1.1.0-rc2, 1.1.0-rc3, 1.1.0-rc4, before 1.1.0).\n- Bug-fixes (e.g. 1.1.1, 1.1.2, 1.2.1, 1.2.3) are released as needed (no additional features are delivered in those versions, bug-fixes only).\n\nEach version is supported until the next one is released (e.g. 1.1.x will be supported until 1.2.0 is out).\n\nWe use [Semantic Versioning](https://semver.org/).\n\n## Mailing Lists\n\n- General announcements, new releases: mail at news+subscribe@traefik.io or on [the online viewer](https://groups.google.com/a/traefik.io/forum/#!forum/news).\n- Security announcements: mail at security+subscribe@traefik.io or on [the online viewer](https://groups.google.com/a/traefik.io/forum/#!forum/security).\n\n## Credits\n\nKudos to [Peka](https://www.instagram.com/pierroks/) for his awesome work on the gopher's logo!.\n\nThe gopher's logo of Traefik is licensed under the Creative Commons 3.0 Attributions license.\n\nThe gopher's logo of Traefik was inspired by the gopher stickers made by [Takuya Ueda](https://twitter.com/tenntenn).\nThe original Go gopher was designed by [Renee French](https://reneefrench.blogspot.com/).\n",
      "stars_today": 18
    },
    {
      "id": 23007417,
      "name": "colmap",
      "full_name": "colmap/colmap",
      "description": "COLMAP - Structure-from-Motion and Multi-View Stereo",
      "html_url": "https://github.com/colmap/colmap",
      "stars": 10714,
      "forks": 1868,
      "language": "C++",
      "topics": [
        "computer-vision",
        "geometry",
        "multi-view-stereo",
        "reconstruction",
        "structure-from-motion"
      ],
      "created_at": "2014-08-16T00:55:31Z",
      "updated_at": "2026-01-15T16:00:08Z",
      "pushed_at": "2026-01-15T17:04:07Z",
      "open_issues": 1079,
      "owner": {
        "login": "colmap",
        "avatar_url": "https://avatars.githubusercontent.com/u/8461936?v=4"
      },
      "readme": "COLMAP\n======\n\nAbout\n-----\n\nCOLMAP is a general-purpose Structure-from-Motion (SfM) and Multi-View Stereo\n(MVS) pipeline with a graphical and command-line interface. It offers a wide\nrange of features for reconstruction of ordered and unordered image collections.\nThe software is licensed under the new BSD license. If you use this project for\nyour research, please cite:\n\n    @inproceedings{schoenberger2016sfm,\n        author={Sch\\\"{o}nberger, Johannes Lutz and Frahm, Jan-Michael},\n        title={Structure-from-Motion Revisited},\n        booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},\n        year={2016},\n    }\n\n    @inproceedings{schoenberger2016mvs,\n        author={Sch\\\"{o}nberger, Johannes Lutz and Zheng, Enliang and Pollefeys, Marc and Frahm, Jan-Michael},\n        title={Pixelwise View Selection for Unstructured Multi-View Stereo},\n        booktitle={European Conference on Computer Vision (ECCV)},\n        year={2016},\n    }\n\nIf you use the image retrieval / vocabulary tree engine, please also cite:\n\n    @inproceedings{schoenberger2016vote,\n        author={Sch\\\"{o}nberger, Johannes Lutz and Price, True and Sattler, Torsten and Frahm, Jan-Michael and Pollefeys, Marc},\n        title={A Vote-and-Verify Strategy for Fast Spatial Verification in Image Retrieval},\n        booktitle={Asian Conference on Computer Vision (ACCV)},\n        year={2016},\n    }\n\nThe latest source code is available at https://github.com/colmap/colmap. COLMAP\nbuilds on top of existing works and when using specific algorithms within\nCOLMAP, please also cite the original authors, as specified in the source code,\nand consider citing relevant third-party dependencies (most notably\nceres-solver, poselib, sift-gpu, vlfeat).\n\n\nDownload\n--------\n\n* Binaries for **Windows** and other resources can be downloaded\n  from https://github.com/colmap/colmap/releases.\n* Binaries for **Linux/Unix/BSD** are available at\n  https://repology.org/metapackage/colmap/versions.\n* Pre-built **Docker** images are available at\n  https://hub.docker.com/r/colmap/colmap.\n* Conda packages are available at https://anaconda.org/conda-forge/colmap and\n  can be installed with `conda install colmap`\n* **Python bindings** are available at https://pypi.org/project/pycolmap.\n  CUDA-enabled wheels are available at https://pypi.org/project/pycolmap-cuda12.\n* To **build from source**, please see https://colmap.github.io/install.html.\n\n\nGetting Started\n---------------\n\n1. Download pre-built binaries or build from source.\n2. Download one of the provided datasets at https://demuc.de/colmap/datasets/\n   or use your own images.\n3. Use the **automatic reconstruction** to easily build models\n   with a single click or command.\n\n\nDocumentation\n-------------\n\nThe documentation is available at https://colmap.github.io/.\n\nTo build and update the documentation at the documentation website, follow these steps:\n\n1. Build the documentation locally following [these instructions](https://colmap.github.io/install.html#documentation).\n2. Clone the website repository [colmap/colmap.github.io](https://github.com/colmap/colmap.github.io).\n3. Copy the contents of the generated files at `_build/html` to the cloned respository root.\n4. Create a pull request to the [colmap/colmap.github.io](https://github.com/colmap/colmap.github.io) repository with the updated files.\n5. (optional if main release) Copy the previous release as legacy to the \"legacy\" folder, under a folder with the release number [as seen here](https://github.com/colmap/colmap.github.io/tree/master/legacy)\n\nSupport\n-------\n\nPlease, use GitHub Discussions at https://github.com/colmap/colmap/discussions\nfor questions and the GitHub issue tracker at https://github.com/colmap/colmap\nfor bug reports, feature requests/additions, etc.\n\n\nAcknowledgments\n---------------\n\nCOLMAP was originally written by [Johannes SchÃ¶nberger](https://demuc.de/) with\nfunding provided by his PhD advisors Jan-Michael Frahm and Marc Pollefeys.\nThe team of core project maintainers currently includes\n[Johannes SchÃ¶nberger](https://github.com/ahojnnes),\n[Paul-Edouard Sarlin](https://github.com/sarlinpe), and\n[Shaohui Liu](https://github.com/B1ueber2y).\n\nThe Python bindings in PyCOLMAP were originally added by\n[Mihai Dusmanu](https://github.com/mihaidusmanu),\n[Philipp Lindenberger](https://github.com/Phil26AT), and\n[Paul-Edouard Sarlin](https://github.com/sarlinpe).\n\nThe project has also benefitted from countless community contributions, including\nbug fixes, improvements, new features, third-party tooling, and community\nsupport (special credits to [Torsten Sattler](https://tsattler.github.io)).\n\n\nContribution\n------------\n\nContributions (bug reports, bug fixes, improvements, etc.) are very welcome and\nshould be submitted in the form of new issues and/or pull requests on GitHub.\n\n\nLicense\n-------\n\nThe COLMAP library is licensed under the new BSD license. Note that this text\nrefers only to the license for COLMAP itself, independent of its thirdparty\ndependencies, which are separately licensed. Building COLMAP with these\ndependencies may affect the resulting COLMAP license.\n\n    Copyright (c), ETH Zurich and UNC Chapel Hill.\n    All rights reserved.\n\n    Redistribution and use in source and binary forms, with or without\n    modification, are permitted provided that the following conditions are met:\n\n        * Redistributions of source code must retain the above copyright\n          notice, this list of conditions and the following disclaimer.\n\n        * Redistributions in binary form must reproduce the above copyright\n          notice, this list of conditions and the following disclaimer in the\n          documentation and/or other materials provided with the distribution.\n\n        * Neither the name of ETH Zurich and UNC Chapel Hill nor the names of\n          its contributors may be used to endorse or promote products derived\n          from this software without specific prior written permission.\n\n    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n    AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n    ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE\n    LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n    CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n    SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n    INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n    CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n    ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n    POSSIBILITY OF SUCH DAMAGE.\n",
      "stars_today": 18
    },
    {
      "id": 263727855,
      "name": "polars",
      "full_name": "pola-rs/polars",
      "description": "Extremely fast Query Engine for DataFrames, written in Rust",
      "html_url": "https://github.com/pola-rs/polars",
      "stars": 36994,
      "forks": 2559,
      "language": "Rust",
      "topics": [
        "arrow",
        "dataframe",
        "dataframe-library",
        "dataframes",
        "out-of-core",
        "polars",
        "python",
        "rust"
      ],
      "created_at": "2020-05-13T19:45:33Z",
      "updated_at": "2026-01-16T00:59:06Z",
      "pushed_at": "2026-01-15T17:15:24Z",
      "open_issues": 2707,
      "owner": {
        "login": "pola-rs",
        "avatar_url": "https://avatars.githubusercontent.com/u/83768144?v=4"
      },
      "readme": "<h1 align=\"center\">\n  <a href=\"https://pola.rs\">\n    <img src=\"https://raw.githubusercontent.com/pola-rs/polars-static/master/banner/polars_github_banner.svg\" alt=\"Polars logo\">\n  </a>\n</h1>\n\n<div align=\"center\">\n  <a href=\"https://crates.io/crates/polars\">\n    <img src=\"https://img.shields.io/crates/v/polars.svg\" alt=\"crates.io Latest Release\"/>\n  </a>\n  <a href=\"https://pypi.org/project/polars/\">\n    <img src=\"https://img.shields.io/pypi/v/polars.svg\" alt=\"PyPi Latest Release\"/>\n  </a>\n  <a href=\"https://www.npmjs.com/package/nodejs-polars\">\n    <img src=\"https://img.shields.io/npm/v/nodejs-polars.svg\" alt=\"NPM Latest Release\"/>\n  </a>\n  <a href=\"https://community.r-multiverse.org/polars\">\n    <img src=\"https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fcommunity.r-multiverse.org%2Fapi%2Fpackages%2Fpolars&query=%24.Version&label=r-multiverse\" alt=\"R-multiverse Latest Release\"/>\n  </a>\n  <a href=\"https://doi.org/10.5281/zenodo.7697217\">\n    <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.7697217.svg\" alt=\"DOI Latest Release\"/>\n  </a>\n</div>\n\n<p align=\"center\">\n  <b>Documentation</b>:\n  <a href=\"https://docs.pola.rs/api/python/stable/reference/index.html\">Python</a>\n  -\n  <a href=\"https://docs.rs/polars/latest/polars/\">Rust</a>\n  -\n  <a href=\"https://pola-rs.github.io/nodejs-polars/index.html\">Node.js</a>\n  -\n  <a href=\"https://pola-rs.github.io/r-polars/index.html\">R</a>\n  |\n  <b>StackOverflow</b>:\n  <a href=\"https://stackoverflow.com/questions/tagged/python-polars\">Python</a>\n  -\n  <a href=\"https://stackoverflow.com/questions/tagged/rust-polars\">Rust</a>\n  -\n  <a href=\"https://stackoverflow.com/questions/tagged/nodejs-polars\">Node.js</a>\n  -\n  <a href=\"https://stackoverflow.com/questions/tagged/r-polars\">R</a>\n  |\n  <a href=\"https://docs.pola.rs/\">User guide</a>\n  |\n  <a href=\"https://discord.gg/4UfP5cfBE7\">Discord</a>\n</p>\n\n## Polars: Extremely fast Query Engine for DataFrames, written in Rust\n\nPolars is an analytical query engine written for DataFrames. It is designed to be fast, easy to use\nand expressive. Key features are:\n\n- Lazy | Eager execution\n- Streaming (larger-than-RAM datasets)\n- Query optimization\n- Multi-threaded\n- Written in Rust\n- SIMD\n- Powerful expression API\n- Front end in Python | Rust | NodeJS | R | SQL\n- [Apache Arrow Columnar Format](https://arrow.apache.org/docs/format/Columnar.html)\n\nTo learn more, read the [user guide](https://docs.pola.rs/).\n\n## Performance ğŸš€ğŸš€\n\n### Blazingly fast\n\nPolars is very fast. In fact, it is one of the best performing solutions available. See the\n[PDS-H benchmarks](https://www.pola.rs/benchmarks.html) results.\n\n### Lightweight\n\nPolars is also very lightweight. It comes with zero required dependencies, and this shows in the\nimport times:\n\n- polars: 70ms\n- numpy: 104ms\n- pandas: 520ms\n\n### Handles larger-than-RAM data\n\nIf you have data that does not fit into memory, Polars' query engine is able to process your query\n(or parts of your query) in a streaming fashion. This drastically reduces memory requirements, so\nyou might be able to process your 250GB dataset on your laptop. Collect with\n`collect(engine='streaming')` to run the query streaming.\n\n## Setup\n\n### Python\n\nInstall the latest Polars version with:\n\n```sh\npip install polars\n```\n\nSee the [User Guide](https://docs.pola.rs/user-guide/installation/#feature-flags) for more details\non optional dependencies\n\nTo see the current Polars version and a full list of its optional dependencies, run:\n\n```python\npl.show_versions()\n```\n\n## Contributing\n\nWant to contribute? Read our [contributing guide](https://docs.pola.rs/development/contributing/).\n\n## Managed/Distributed Polars\n\nDo you want a managed solution or scale out to distributed clusters? Consider our\n[offering](https://cloud.pola.rs/) and help the project!\n\n## Python: compile Polars from source\n\nIf you want a bleeding edge release or maximal performance you should compile Polars from source.\n\nThis can be done by going through the following steps in sequence:\n\n1. Install the latest [Rust compiler](https://www.rust-lang.org/tools/install)\n2. Install [maturin](https://maturin.rs/): `pip install maturin`\n3. `cd py-polars` and choose one of the following:\n   - `make build`, slow binary with debug assertions and symbols, fast compile times\n   - `make build-release`, fast binary without debug assertions, minimal debug symbols, long compile\n     times\n   - `make build-nodebug-release`, same as build-release but without any debug symbols, slightly\n     faster to compile\n   - `make build-debug-release`, same as build-release but with full debug symbols, slightly slower\n     to compile\n   - `make build-dist-release`, fastest binary, extreme compile times\n\nBy default the binary is compiled with optimizations turned on for a modern CPU. Specify `LTS_CPU=1`\nwith the command if your CPU is older and does not support e.g. AVX2.\n\nNote that the Rust crate implementing the Python bindings is called `py-polars` to distinguish from\nthe wrapped Rust crate `polars` itself. However, both the Python package and the Python module are\nnamed `polars`, so you can `pip install polars` and `import polars`.\n\n## Using custom Rust functions in Python\n\nExtending Polars with UDFs compiled in Rust is easy. We expose PyO3 extensions for `DataFrame` and\n`Series` data structures. See more in https://github.com/pola-rs/polars/tree/main/pyo3-polars.\n\n## Going big...\n\nDo you expect more than 2^32 (~4.2 billion) rows? Compile Polars with the `bigidx` feature flag or,\nfor Python users, install `pip install polars[rt64]`.\n\nDon't use this unless you hit the row boundary as the default build of Polars is faster and consumes\nless memory.\n\n## Legacy\n\nDo you want Polars to run on an old CPU (e.g. dating from before 2011), or on an `x86-64` build of\nPython on Apple Silicon under Rosetta? Install `pip install polars[rtcompat]`. This version of\nPolars is compiled without [AVX](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions) target\nfeatures.\n",
      "stars_today": 17
    },
    {
      "id": 171072967,
      "name": "whatsapp-web.js",
      "full_name": "pedroslopez/whatsapp-web.js",
      "description": "A WhatsApp client library for NodeJS that connects through the WhatsApp Web browser app",
      "html_url": "https://github.com/pedroslopez/whatsapp-web.js",
      "stars": 20552,
      "forks": 4750,
      "language": "JavaScript",
      "topics": [
        "api",
        "bot",
        "bot-api",
        "hacktoberfest",
        "whatsapp",
        "whatsapp-api",
        "whatsapp-bot",
        "whatsapp-web",
        "whatsapp-web-api"
      ],
      "created_at": "2019-02-17T02:16:02Z",
      "updated_at": "2026-01-15T22:17:08Z",
      "pushed_at": "2026-01-16T00:42:23Z",
      "open_issues": 183,
      "owner": {
        "login": "pedroslopez",
        "avatar_url": "https://avatars.githubusercontent.com/u/4368928?v=4"
      },
      "readme": "<div align=\"center\">\n    <br />\n    <p>\n        <a href=\"https://wwebjs.dev\"><img src=\"https://github.com/wwebjs/assets/blob/main/Collection/GitHub/wwebjs.png?raw=true\" title=\"whatsapp-web.js\" alt=\"WWebJS Website\" width=\"500\" /></a>\n    </p>\n    <br />\n    <p>\n\t\t<a href=\"https://www.npmjs.com/package/whatsapp-web.js\"><img src=\"https://img.shields.io/npm/v/whatsapp-web.js.svg\" alt=\"npm\" /></a>\n        <a href=\"https://depfu.com/github/pedroslopez/whatsapp-web.js?project_id=9765\"><img src=\"https://badges.depfu.com/badges/4a65a0de96ece65fdf39e294e0c8dcba/overview.svg\" alt=\"Depfu\" /></a>\n        <img src=\"https://img.shields.io/badge/WhatsApp_Web-2.3000.1017054665-brightgreen.svg\" alt=\"WhatsApp_Web 2.2346.52\" />\n        <a href=\"https://discord.gg/H7DqQs4\"><img src=\"https://img.shields.io/discord/698610475432411196.svg?logo=discord\" alt=\"Discord server\" /></a>\n\t</p>\n    <br />\n</div>\n\n## About\n**A WhatsApp API client that operates via the WhatsApp Web browser.**\n\nThe library launches the WhatsApp Web browser app via Puppeteer, accessing its internal functions and creating a managed instance to reduce the risk of being blocked. This gives the API client nearly all WhatsApp Web features for dynamic use in a Node.js application.\n\n> [!IMPORTANT]\n> **It is not guaranteed you will not be blocked by using this method. WhatsApp does not allow bots or unofficial clients on their platform, so this shouldn't be considered totally safe.**\n\n## Links\n\n* [GitHub][gitHub]\n* [Guide][guide] ([source][guide-source])\n* [Documentation][documentation] ([source][documentation-source])\n* [Discord Server][discord]\n* [npm][npm]\n\n## Installation\n\nThe module is available on [npm][npm] via `npm i whatsapp-web.js`!\n\n> [!NOTE]\n> **Node ``v18`` or higher, is required.**  \n> See the [Guide][guide] for quick upgrade instructions.\n\n## Example usage\n\n```js\nconst { Client } = require('whatsapp-web.js');\n\nconst client = new Client();\n\nclient.on('qr', (qr) => {\n    // Generate and scan this code with your phone\n    console.log('QR RECEIVED', qr);\n});\n\nclient.on('ready', () => {\n    console.log('Client is ready!');\n});\n\nclient.on('message', msg => {\n    if (msg.body == '!ping') {\n        msg.reply('pong');\n    }\n});\n\nclient.initialize();\n```\n\nTake a look at [example.js][examples] for another examples with additional use cases.  \nFor further details on saving and restoring sessions, explore the provided [Authentication Strategies][auth-strategies].\n\n\n## Supported features\n\n| Feature  | Status |\n| ------------- | ------------- |\n| Multi Device  | âœ…  |\n| Send messages  | âœ…  |\n| Receive messages  | âœ…  |\n| Send media (images/audio/documents)  | âœ…  |\n| Send media (video)  | âœ… [(requires Google Chrome)][google-chrome]  |\n| Send stickers | âœ… |\n| Receive media (images/audio/video/documents)  | âœ…  |\n| Send contact cards | âœ… |\n| Send location | âœ… |\n| Send buttons | âŒ  [(DEPRECATED)][deprecated-video] |\n| Send lists | âŒ  [(DEPRECATED)][deprecated-video] |\n| Receive location | âœ… | \n| Message replies | âœ… |\n| Join groups by invite  | âœ… |\n| Get invite for group  | âœ… |\n| Modify group info (subject, description)  | âœ…  |\n| Modify group settings (send messages, edit info)  | âœ…  |\n| Add group participants  | âœ…  |\n| Kick group participants  | âœ…  |\n| Promote/demote group participants | âœ… |\n| Mention users | âœ… |\n| Mention groups | âœ… |\n| Mute/unmute chats | âœ… |\n| Block/unblock contacts | âœ… |\n| Get contact info | âœ… |\n| Get profile pictures | âœ… |\n| Set user status message | âœ… |\n| React to messages | âœ… |\n| Create polls | âœ… |\n| Channels | âœ… |\n| Vote in polls | ğŸ”œ |\n| Communities | ğŸ”œ |\n\nSomething missing? Make an issue and let us know!\n\n## Contributing\n\nFeel free to open pull requests; we welcome contributions! However, for significant changes, it's best to open an issue beforehand. Make sure to review our [contribution guidelines][contributing] before creating a pull request. Before creating your own issue or pull request, always check to see if one already exists!\n\n## Supporting the project\n\nYou can support the maintainer of this project through the links below\n\n- [Support via GitHub Sponsors][gitHub-sponsors]\n- [Support via PayPal][support-payPal]\n- [Sign up for DigitalOcean][digitalocean] and get $200 in credit when you sign up (Referral)\n\n## Disclaimer\n\nThis project is not affiliated, associated, authorized, endorsed by, or in any way officially connected with WhatsApp or any of its subsidiaries or its affiliates. The official WhatsApp website can be found at [whatsapp.com][whatsapp]. \"WhatsApp\" as well as related names, marks, emblems and images are registered trademarks of their respective owners. Also it is not guaranteed you will not be blocked by using this method. WhatsApp does not allow bots or unofficial clients on their platform, so this shouldn't be considered totally safe.\n\n## License\n\nCopyright 2019 Pedro S Lopez  \n\nLicensed under the Apache License, Version 2.0 (the \"License\");  \nyou may not use this project except in compliance with the License.  \nYou may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0.  \n\nUnless required by applicable law or agreed to in writing, software  \ndistributed under the License is distributed on an \"AS IS\" BASIS,  \nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \nSee the License for the specific language governing permissions and  \nlimitations under the License.  \n\n\n[guide]: https://guide.wwebjs.dev/guide\n[guide-source]: https://github.com/wwebjs/wwebjs.dev/tree/main\n[documentation]: https://docs.wwebjs.dev/\n[documentation-source]: https://github.com/pedroslopez/whatsapp-web.js/tree/main/docs\n[discord]: https://discord.gg/H7DqQs4\n[gitHub]: https://github.com/pedroslopez/whatsapp-web.js\n[npm]: https://npmjs.org/package/whatsapp-web.js\n[nodejs]: https://nodejs.org/en/download/\n[examples]: https://github.com/pedroslopez/whatsapp-web.js/blob/master/example.js\n[auth-strategies]: https://wwebjs.dev/guide/creating-your-bot/authentication.html\n[google-chrome]: https://wwebjs.dev/guide/creating-your-bot/handling-attachments.html#caveat-for-sending-videos-and-gifs\n[deprecated-video]: https://www.youtube.com/watch?v=hv1R1rLeVVE\n[gitHub-sponsors]: https://github.com/sponsors/pedroslopez\n[support-payPal]: https://www.paypal.me/psla/\n[digitalocean]: https://m.do.co/c/73f906a36ed4\n[contributing]: https://github.com/pedroslopez/whatsapp-web.js/blob/main/CODE_OF_CONDUCT.md\n[whatsapp]: https://whatsapp.com\n",
      "stars_today": 16
    },
    {
      "id": 743704912,
      "name": "mihon",
      "full_name": "mihonapp/mihon",
      "description": "Free and open source manga reader for Android",
      "html_url": "https://github.com/mihonapp/mihon",
      "stars": 18023,
      "forks": 906,
      "language": "Kotlin",
      "topics": [
        "android",
        "kotlin",
        "manga",
        "manga-downloader",
        "manga-reader",
        "mangadownloader",
        "mangareader",
        "tachiyomi",
        "tachiyomi-alternative"
      ],
      "created_at": "2024-01-15T20:03:57Z",
      "updated_at": "2026-01-16T00:17:01Z",
      "pushed_at": "2026-01-15T13:50:16Z",
      "open_issues": 529,
      "owner": {
        "login": "mihonapp",
        "avatar_url": "https://avatars.githubusercontent.com/u/156513628?v=4"
      },
      "readme": "<div align=\"center\">\n\n<a href=\"https://mihon.app\">\n    <img src=\"./.github/assets/logo.png\" alt=\"Mihon logo\" title=\"Mihon logo\" width=\"80\"/>\n</a>\n\n# Mihon [App](#)\n\n### Full-featured reader\nDiscover and read manga, webtoons, comics, and more â€“ easier than ever on your Android device.\n\n[![Discord server](https://img.shields.io/discord/1195734228319617024.svg?label=&labelColor=6A7EC2&color=7389D8&logo=discord&logoColor=FFFFFF)](https://discord.gg/mihon)\n[![GitHub downloads](https://img.shields.io/github/downloads/mihonapp/mihon/total?label=downloads&labelColor=27303D&color=0D1117&logo=github&logoColor=FFFFFF&style=flat)](https://mihon.app/download)\n\n[![CI](https://img.shields.io/github/actions/workflow/status/mihonapp/mihon/build.yml?labelColor=27303D)](https://github.com/mihonapp/mihon/actions/workflows/build_push.yml)\n[![License: Apache-2.0](https://img.shields.io/github/license/mihonapp/mihon?labelColor=27303D&color=0877d2)](/LICENSE)\n[![Translation status](https://img.shields.io/weblate/progress/mihon?labelColor=27303D&color=946300)](https://hosted.weblate.org/engage/mihon/)\n\n## Download\n\n[![Mihon Stable](https://img.shields.io/github/release/mihonapp/mihon.svg?maxAge=3600&label=Stable&labelColor=06599d&color=043b69)](https://mihon.app/download)\n[![Mihon Beta](https://img.shields.io/github/v/release/mihonapp/mihon-preview.svg?maxAge=3600&label=Beta&labelColor=2c2c47&color=1c1c39)](https://mihon.app/download)\n\n*Requires Android 8.0 or higher.*\n\n## Features\n\n<div align=\"left\">\n\n* Local reading of content.\n* A configurable reader with multiple viewers, reading directions and other settings.\n* Tracker support: [MyAnimeList](https://myanimelist.net/), [AniList](https://anilist.co/), [Kitsu](https://kitsu.app/), [MangaUpdates](https://mangaupdates.com), [Shikimori](https://shikimori.one), and [Bangumi](https://bgm.tv/) support.\n* Categories to organize your library.\n* Light and dark themes.\n* Schedule updating your library for new chapters.\n* Create backups locally to read offline or to your desired cloud service.\n* Plus much more...\n\n</div>\n\n## Contributing\n\n[Code of conduct](./CODE_OF_CONDUCT.md) Â· [Contributing guide](./CONTRIBUTING.md)\n\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\nBefore reporting a new issue, take a look at the [FAQ](https://mihon.app/docs/faq/general), the [changelog](https://mihon.app/changelogs/) and the already opened [issues](https://github.com/mihonapp/mihon/issues); if you got any questions, join our [Discord server](https://discord.gg/mihon).\n\n\n### Repositories\n\n[![mihonapp/website - GitHub](https://github-readme-stats.vercel.app/api/pin/?username=mihonapp&repo=website&bg_color=161B22&text_color=c9d1d9&title_color=0877d2&icon_color=0877d2&border_radius=8&hide_border=true&description_lines_count=2)](https://github.com/mihonapp/website/)\n[![mihonapp/bitmap.kt - GitHub](https://github-readme-stats.vercel.app/api/pin/?username=mihonapp&repo=bitmap.kt&bg_color=161B22&text_color=c9d1d9&title_color=0877d2&icon_color=0877d2&border_radius=8&hide_border=true&description_lines_count=2)](https://github.com/mihonapp/bitmap.kt/)\n\n### Credits\n\nThank you to all the people who have contributed!\n\n<a href=\"https://github.com/mihonapp/mihon/graphs/contributors\">\n    <img src=\"https://contrib.rocks/image?repo=mihonapp/mihon\" alt=\"Mihon app contributors\" title=\"Mihon app contributors\" width=\"800\"/>\n</a>\n\n### Disclaimer\n\nThe developer(s) of this application does not have any affiliation with the content providers available, and this application hosts zero content.\n\n### License\n\n<pre>\nCopyright Â© 2015 Javier TomÃ¡s\nCopyright Â© 2024 Mihon Open Source Project\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</pre>\n\n</div>\n",
      "stars_today": 16
    },
    {
      "id": 11171548,
      "name": "json",
      "full_name": "nlohmann/json",
      "description": "JSON for Modern C++",
      "html_url": "https://github.com/nlohmann/json",
      "stars": 48556,
      "forks": 7292,
      "language": "C++",
      "topics": [
        "bson",
        "cbor",
        "header-only",
        "json",
        "json-diff",
        "json-merge-patch",
        "json-parser",
        "json-patch",
        "json-pointer",
        "json-serialization",
        "messagepack",
        "msgpack",
        "rfc-6901",
        "rfc-6902",
        "rfc-7049",
        "rfc-7159",
        "rfc-8259",
        "stl-containers",
        "ubjson"
      ],
      "created_at": "2013-07-04T08:47:49Z",
      "updated_at": "2026-01-15T23:32:49Z",
      "pushed_at": "2026-01-13T16:19:39Z",
      "open_issues": 97,
      "owner": {
        "login": "nlohmann",
        "avatar_url": "https://avatars.githubusercontent.com/u/159488?v=4"
      },
      "readme": "[![JSON for Modern C++](docs/mkdocs/docs/images/json.gif)](https://github.com/nlohmann/json/releases)\n\n[![Build Status](https://ci.appveyor.com/api/projects/status/1acb366xfyg3qybk/branch/develop?svg=true)](https://ci.appveyor.com/project/nlohmann/json)\n[![Ubuntu](https://github.com/nlohmann/json/workflows/Ubuntu/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AUbuntu)\n[![macOS](https://github.com/nlohmann/json/workflows/macOS/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AmacOS)\n[![Windows](https://github.com/nlohmann/json/workflows/Windows/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AWindows)\n[![Coverage Status](https://coveralls.io/repos/github/nlohmann/json/badge.svg?branch=develop)](https://coveralls.io/github/nlohmann/json?branch=develop)\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/5550/badge.svg)](https://scan.coverity.com/projects/nlohmann-json)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/e0d1a9d5d6fd46fcb655c4cb930bb3e8)](https://app.codacy.com/gh/nlohmann/json/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n[![Cirrus CI](https://api.cirrus-ci.com/github/nlohmann/json.svg)](https://cirrus-ci.com/github/nlohmann/json)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/json.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:json)\n[![Try online](https://img.shields.io/badge/try-online-blue.svg)](https://wandbox.org/permlink/1mp10JbaANo6FUc7)\n[![Documentation](https://img.shields.io/badge/docs-mkdocs-blue.svg)](https://json.nlohmann.me)\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/nlohmann/json/master/LICENSE.MIT)\n[![GitHub Releases](https://img.shields.io/github/release/nlohmann/json.svg)](https://github.com/nlohmann/json/releases)\n[![Packaging status](https://repology.org/badge/tiny-repos/nlohmann-json.svg)](https://repology.org/project/nlohmann-json/versions)\n[![GitHub Downloads](https://img.shields.io/github/downloads/nlohmann/json/total)](https://github.com/nlohmann/json/releases)\n[![GitHub Issues](https://img.shields.io/github/issues/nlohmann/json.svg)](https://github.com/nlohmann/json/issues)\n[![Average time to resolve an issue](https://isitmaintained.com/badge/resolution/nlohmann/json.svg)](https://isitmaintained.com/project/nlohmann/json \"Average time to resolve an issue\")\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/289/badge)](https://bestpractices.coreinfrastructure.org/projects/289)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/nlohmann/json/badge)](https://scorecard.dev/viewer/?uri=github.com/nlohmann/json)\n[![Backup Status](https://app.cloudback.it/badge/nlohmann/json)](https://cloudback.it)\n[![GitHub Sponsors](https://img.shields.io/badge/GitHub-Sponsors-ff69b4)](https://github.com/sponsors/nlohmann)\n[![REUSE status](https://api.reuse.software/badge/github.com/nlohmann/json)](https://api.reuse.software/info/github.com/nlohmann/json)\n[![Discord](https://img.shields.io/discord/1003743314341793913)](https://discord.gg/6mrGXKvX7y)\n\n- [Design goals](#design-goals)\n- [Sponsors](#sponsors)\n- [Support](#support) ([documentation](https://json.nlohmann.me), [FAQ](https://json.nlohmann.me/home/faq/), [discussions](https://github.com/nlohmann/json/discussions), [API](https://json.nlohmann.me/api/basic_json/), [bug issues](https://github.com/nlohmann/json/issues))\n- [Quick reference](#quick-reference)\n- [Examples](#examples)\n  - [Read JSON from a file](#read-json-from-a-file)\n  - [Creating `json` objects from JSON literals](#creating-json-objects-from-json-literals)\n  - [JSON as a first-class data type](#json-as-a-first-class-data-type)\n  - [Serialization / Deserialization](#serialization--deserialization)\n  - [STL-like access](#stl-like-access)\n  - [Conversion from STL containers](#conversion-from-stl-containers)\n  - [JSON Pointer and JSON Patch](#json-pointer-and-json-patch)\n  - [JSON Merge Patch](#json-merge-patch)\n  - [Implicit conversions](#implicit-conversions)\n  - [Conversions to/from arbitrary types](#arbitrary-types-conversions)\n  - [Specializing enum conversion](#specializing-enum-conversion)\n  - [Binary formats (BSON, CBOR, MessagePack, UBJSON, and BJData)](#binary-formats-bson-cbor-messagepack-ubjson-and-bjdata)\n- [Customers](#customers)\n- [Supported compilers](#supported-compilers)\n- [Integration](#integration)\n  - [CMake](#cmake)\n  - [Package Managers](#package-managers)\n  - [Pkg-config](#pkg-config)\n- [License](#license)\n- [Contact](#contact)\n- [Thanks](#thanks)\n- [Used third-party tools](#used-third-party-tools)\n- [Notes](#notes)\n- [Execute unit tests](#execute-unit-tests)\n\n## Design goals\n\nThere are myriads of [JSON](https://json.org) libraries out there, and each may even have its reason to exist. Our class had these design goals:\n\n- **Intuitive syntax**. In languages such as Python, JSON feels like a first-class data type. We used all the operator magic of modern C++ to achieve the same feeling in your code. Check out the [examples below](#examples) and you'll know what I mean.\n\n- **Trivial integration**. Our whole code consists of a single header file [`json.hpp`](https://github.com/nlohmann/json/blob/develop/single_include/nlohmann/json.hpp). That's it. No library, no subproject, no dependencies, no complex build system. The class is written in vanilla C++11. All in all, everything should require no adjustment of your compiler flags or project settings. The library is also included in all popular [package managers](https://json.nlohmann.me/integration/package_managers/).\n\n- **Serious testing**. Our code is heavily [unit-tested](https://github.com/nlohmann/json/tree/develop/tests/src) and covers [100%](https://coveralls.io/r/nlohmann/json) of the code, including all exceptional behavior. Furthermore, we checked with [Valgrind](https://valgrind.org) and the [Clang Sanitizers](https://clang.llvm.org/docs/index.html) that there are no memory leaks. [Google OSS-Fuzz](https://github.com/google/oss-fuzz/tree/master/projects/json) additionally runs fuzz tests against all parsers 24/7, effectively executing billions of tests so far. To maintain high quality, the project is following the [Core Infrastructure Initiative (CII) best practices](https://bestpractices.coreinfrastructure.org/projects/289). See the [quality assurance](https://json.nlohmann.me/community/quality_assurance) overview documentation.\n\nOther aspects were not so important to us:\n\n- **Memory efficiency**. Each JSON object has an overhead of one pointer (the maximal size of a union) and one enumeration element (1 byte). The default generalization uses the following C++ data types: `std::string` for strings, `int64_t`, `uint64_t` or `double` for numbers, `std::map` for objects, `std::vector` for arrays, and `bool` for Booleans. However, you can template the generalized class `basic_json` to your needs.\n\n- **Speed**. There are certainly [faster JSON libraries](https://github.com/miloyip/nativejson-benchmark#parsing-time) out there. However, if your goal is to speed up your development by adding JSON support with a single header, then this library is the way to go. If you know how to use a `std::vector` or `std::map`, you are already set.\n\nSee the [contribution guidelines](https://github.com/nlohmann/json/blob/master/.github/CONTRIBUTING.md#please-dont) for more information.\n\n## Sponsors\n\nYou can sponsor this library at [GitHub Sponsors](https://github.com/sponsors/nlohmann).\n\n### :raising_hand: Priority Sponsor\n\n- [Martti Laine](https://github.com/codeclown)\n- [Paul Harrington](https://github.com/phrrngtn)\n\n### :label: Named Sponsors\n\n- [Michael Hartmann](https://github.com/reFX-Mike)\n- [Stefan Hagen](https://github.com/sthagen)\n- [Steve Sperandeo](https://github.com/homer6)\n- [Robert Jefe LindstÃ¤dt](https://github.com/eljefedelrodeodeljefe)\n- [Steve Wagner](https://github.com/ciroque)\n- [Lion Yang](https://github.com/LionNatsu)\n\n### Further support\n\nThe development of the library is further supported by JetBrains by providing free access to their IDE tools.\n\n[![JetBrains logo.](https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg)](https://jb.gg/OpenSourceSupport)\n\nThanks everyone!\n\n## Support\n\n:question: If you have a **question**, please check if it is already answered in the [**FAQ**](https://json.nlohmann.me/home/faq/) or the [**Q&A**](https://github.com/nlohmann/json/discussions/categories/q-a) section. If not, please [**ask a new question**](https://github.com/nlohmann/json/discussions/new) there.\n\n:books: If you want to **learn more** about how to use the library, check out the rest of the [**README**](#examples), have a look at [**code examples**](https://github.com/nlohmann/json/tree/develop/docs/mkdocs/docs/examples), or browse through the [**help pages**](https://json.nlohmann.me).\n\n:construction: If you want to understand the **API** better, check out the [**API Reference**](https://json.nlohmann.me/api/basic_json/) or have a look at the [quick reference](#quick-reference) below.\n\n:bug: If you found a **bug**, please check the [**FAQ**](https://json.nlohmann.me/home/faq/) if it is a known issue or the result of a design decision. Please also have a look at the [**issue list**](https://github.com/nlohmann/json/issues) before you [**create a new issue**](https://github.com/nlohmann/json/issues/new/choose). Please provide as much information as possible to help us understand and reproduce your issue.\n\nThere is also a [**docset**](https://github.com/Kapeli/Dash-User-Contributions/tree/master/docsets/JSON_for_Modern_C%2B%2B) for the documentation browsers [Dash](https://kapeli.com/dash), [Velocity](https://velocity.silverlakesoftware.com), and [Zeal](https://zealdocs.org) that contains the full [documentation](https://json.nlohmann.me) as an offline resource.\n\n## Quick reference\n\n- **Constructors** [basic_json](https://json.nlohmann.me/api/basic_json/basic_json), [array](https://json.nlohmann.me/api/basic_json/array), [binary](https://json.nlohmann.me/api/basic_json/binary), [object](https://json.nlohmann.me/api/basic_json/object)\n- **Object inspection**: [type](https://json.nlohmann.me/api/basic_json/type), [operator value_t](https://json.nlohmann.me/api/basic_json/operator_value_t), [type_name](https://json.nlohmann.me/api/basic_json/type_name), [is_primitive](https://json.nlohmann.me/api/basic_json/is_primitive), [is_structured](https://json.nlohmann.me/api/basic_json/is_structured), [is_null](https://json.nlohmann.me/api/basic_json/is_null), [is_boolean](https://json.nlohmann.me/api/basic_json/is_boolean), [is_number](https://json.nlohmann.me/api/basic_json/is_number), [is_number_integer](https://json.nlohmann.me/api/basic_json/is_number_integer), [is_number_unsigned](https://json.nlohmann.me/api/basic_json/is_number_unsigned), [is_number_float](https://json.nlohmann.me/api/basic_json/is_number_float), [is_object](https://json.nlohmann.me/api/basic_json/is_object), [is_array](https://json.nlohmann.me/api/basic_json/is_array), [is_string](https://json.nlohmann.me/api/basic_json/is_string), [is_binary](https://json.nlohmann.me/api/basic_json/is_binary), [is_discarded](https://json.nlohmann.me/api/basic_json/is_discarded)\n- **Value access**; [get](https://json.nlohmann.me/api/basic_json/get), [get_to](https://json.nlohmann.me/api/basic_json/get_to), [get_ptr](https://json.nlohmann.me/api/basic_json/get_ptr), [get_ref](https://json.nlohmann.me/api/basic_json/get_ref), [operator ValueType](https://json.nlohmann.me/api/basic_json/operator_ValueType), [get_binary](https://json.nlohmann.me/api/basic_json/get_binary)\n- **Element access**: [at](https://json.nlohmann.me/api/basic_json/at), [operator[]](https://json.nlohmann.me/api/basic_json/operator[]), [value](https://json.nlohmann.me/api/basic_json/value), [front](https://json.nlohmann.me/api/basic_json/front), [back](https://json.nlohmann.me/api/basic_json/back)\n- **Lookup**: [find](https://json.nlohmann.me/api/basic_json/find), [count](https://json.nlohmann.me/api/basic_json/count), [contains](https://json.nlohmann.me/api/basic_json/contains)\n- **Iterators**: [begin](https://json.nlohmann.me/api/basic_json/begin), [cbegin](https://json.nlohmann.me/api/basic_json/cbegin), [end](https://json.nlohmann.me/api/basic_json/end), [cend](https://json.nlohmann.me/api/basic_json/cend), [rbegin](https://json.nlohmann.me/api/basic_json/rbegin), [rend](https://json.nlohmann.me/api/basic_json/rend), [crbegin](https://json.nlohmann.me/api/basic_json/crbegin), [crend](https://json.nlohmann.me/api/basic_json/crend), [items](https://json.nlohmann.me/api/basic_json/items)\n- **Capacity**: [empty](https://json.nlohmann.me/api/basic_json/empty), [size](https://json.nlohmann.me/api/basic_json/size), [max_size](https://json.nlohmann.me/api/basic_json/max_size)\n- **Modifiers**: [clear](https://json.nlohmann.me/api/basic_json/clear), [push_back](https://json.nlohmann.me/api/basic_json/push_back), [operator+=](https://json.nlohmann.me/api/basic_json/operator+=), [emplace_back](https://json.nlohmann.me/api/basic_json/emplace_back), [emplace](https://json.nlohmann.me/api/basic_json/emplace), [erase](https://json.nlohmann.me/api/basic_json/erase), [insert](https://json.nlohmann.me/api/basic_json/insert), [update](https://json.nlohmann.me/api/basic_json/update), [swap](https://json.nlohmann.me/api/basic_json/swap)\n- **Lexicographical comparison operators**: [operator==](https://json.nlohmann.me/api/basic_json/operator_eq), [operator!=](https://json.nlohmann.me/api/basic_json/operator_ne), [operator<](https://json.nlohmann.me/api/basic_json/operator_lt), [operator>](https://json.nlohmann.me/api/basic_json/operator_gt), [operator<=](https://json.nlohmann.me/api/basic_json/operator_le), [operator>=](https://json.nlohmann.me/api/basic_json/operator_ge), [operator<=>](https://json.nlohmann.me/api/basic_json/operator_spaceship)\n- **Serialization / Dumping**: [dump](https://json.nlohmann.me/api/basic_json/dump)\n- **Deserialization / Parsing**: [parse](https://json.nlohmann.me/api/basic_json/parse), [accept](https://json.nlohmann.me/api/basic_json/accept), [sax_parse](https://json.nlohmann.me/api/basic_json/sax_parse)\n- **JSON Pointer functions**: [flatten](https://json.nlohmann.me/api/basic_json/flatten), [unflatten](https://json.nlohmann.me/api/basic_json/unflatten)\n- **JSON Patch functions**: [patch](https://json.nlohmann.me/api/basic_json/patch), [patch_inplace](https://json.nlohmann.me/api/basic_json/patch_inplace), [diff](https://json.nlohmann.me/api/basic_json/diff), [merge_patch](https://json.nlohmann.me/api/basic_json/merge_patch)\n- **Static functions**: [meta](https://json.nlohmann.me/api/basic_json/meta), [get_allocator](https://json.nlohmann.me/api/basic_json/get_allocator)\n- **Binary formats**: [from_bjdata](https://json.nlohmann.me/api/basic_json/from_bjdata), [from_bson](https://json.nlohmann.me/api/basic_json/from_bson), [from_cbor](https://json.nlohmann.me/api/basic_json/from_cbor), [from_msgpack](https://json.nlohmann.me/api/basic_json/from_msgpack), [from_ubjson](https://json.nlohmann.me/api/basic_json/from_ubjson), [to_bjdata](https://json.nlohmann.me/api/basic_json/to_bjdata), [to_bson](https://json.nlohmann.me/api/basic_json/to_bson), [to_cbor](https://json.nlohmann.me/api/basic_json/to_cbor), [to_msgpack](https://json.nlohmann.me/api/basic_json/to_msgpack), [to_ubjson](https://json.nlohmann.me/api/basic_json/to_ubjson)\n- **Non-member functions**: [operator<<](https://json.nlohmann.me/api/operator_ltlt/), [operator>>](https://json.nlohmann.me/api/operator_gtgt/), [to_string](https://json.nlohmann.me/api/basic_json/to_string)\n- **Literals**: [operator\"\"_json](https://json.nlohmann.me/api/operator_literal_json)\n- **Helper classes**: [std::hash&lt;basic_json&gt;](https://json.nlohmann.me/api/basic_json/std_hash), [std::swap&lt;basic_json&gt;](https://json.nlohmann.me/api/basic_json/std_swap)\n\n[**Full API documentation**](https://json.nlohmann.me/api/basic_json/)\n\n## Examples\n\nHere are some examples to give you an idea how to use the class.\n\nBesides the examples below, you may want to:\n\nâ†’ Check the [documentation](https://json.nlohmann.me/)\\\nâ†’ Browse the [standalone example files](https://github.com/nlohmann/json/tree/develop/docs/mkdocs/docs/examples)\\\nâ†’ Read the full [API Documentation](https://json.nlohmann.me/api/basic_json/) with self-contained examples for every function\n\n### Read JSON from a file\n\nThe `json` class provides an API for manipulating a JSON value. To create a `json` object by reading a JSON file:\n\n```cpp\n#include <fstream>\n#include <nlohmann/json.hpp>\nusing json = nlohmann::json;\n\n// ...\n\nstd::ifstream f(\"example.json\");\njson data = json::parse(f);\n```\n\nIf using modules (enabled with `NLOHMANN_JSON_BUILD_MODULES`), this example becomes:\n```cpp\nimport std;\nimport nlohmann.json;\n\nusing json = nlohmann::json;\n\n// ...\n\nstd::ifstream f(\"example.json\");\njson data = json::parse(f);\n```\n\n### Creating `json` objects from JSON literals\n\nAssume you want to create hard-code this literal JSON value in a file, as a `json` object:\n\n```json\n{\n  \"pi\": 3.141,\n  \"happy\": true\n}\n```\n\nThere are various options:\n\n```cpp\n// Using (raw) string literals and json::parse\njson ex1 = json::parse(R\"(\n  {\n    \"pi\": 3.141,\n    \"happy\": true\n  }\n)\");\n\n// Using user-defined (raw) string literals\nusing namespace nlohmann::literals;\njson ex2 = R\"(\n  {\n    \"pi\": 3.141,\n    \"happy\": true\n  }\n)\"_json;\n\n// Using initializer lists\njson ex3 = {\n  {\"happy\", true},\n  {\"pi\", 3.141},\n};\n```\n\n### JSON as a first-class data type\n\nHere are some examples to give you an idea how to use the class.\n\nAssume you want to create the JSON object\n\n```json\n{\n  \"pi\": 3.141,\n  \"happy\": true,\n  \"name\": \"Niels\",\n  \"nothing\": null,\n  \"answer\": {\n    \"everything\": 42\n  },\n  \"list\": [1, 0, 2],\n  \"object\": {\n    \"currency\": \"USD\",\n    \"value\": 42.99\n  }\n}\n```\n\nWith this library, you could write:\n\n```cpp\n// create an empty structure (null)\njson j;\n\n// add a number stored as double (note the implicit conversion of j to an object)\nj[\"pi\"] = 3.141;\n\n// add a Boolean stored as bool\nj[\"happy\"] = true;\n\n// add a string stored as std::string\nj[\"name\"] = \"Niels\";\n\n// add another null object by passing nullptr\nj[\"nothing\"] = nullptr;\n\n// add an object inside the object\nj[\"answer\"][\"everything\"] = 42;\n\n// add an array stored as std::vector (using an initializer list)\nj[\"list\"] = { 1, 0, 2 };\n\n// add another object (using an initializer list of pairs)\nj[\"object\"] = { {\"currency\", \"USD\"}, {\"value\", 42.99} };\n\n// instead, you could also write (which looks very similar to the JSON above)\njson j2 = {\n  {\"pi\", 3.141},\n  {\"happy\", true},\n  {\"name\", \"Niels\"},\n  {\"nothing\", nullptr},\n  {\"answer\", {\n    {\"everything\", 42}\n  }},\n  {\"list\", {1, 0, 2}},\n  {\"object\", {\n    {\"currency\", \"USD\"},\n    {\"value\", 42.99}\n  }}\n};\n```\n\nNote that in all these cases, you never need to \"tell\" the compiler which JSON value type you want to use. If you want to be explicit or express some edge cases, the functions [`json::array()`](https://json.nlohmann.me/api/basic_json/array/) and [`json::object()`](https://json.nlohmann.me/api/basic_json/object/) will help:\n\n```cpp\n// a way to express the empty array []\njson empty_array_explicit = json::array();\n\n// ways to express the empty object {}\njson empty_object_implicit = json({});\njson empty_object_explicit = json::object();\n\n// a way to express an _array_ of key/value pairs [[\"currency\", \"USD\"], [\"value\", 42.99]]\njson array_not_object = json::array({ {\"currency\", \"USD\"}, {\"value\", 42.99} });\n```\n\n### Serialization / Deserialization\n\n#### To/from strings\n\nYou can create a JSON value (deserialization) by appending `_json` to a string literal:\n\n```cpp\n// create object from string literal\njson j = \"{ \\\"happy\\\": true, \\\"pi\\\": 3.141 }\"_json;\n\n// or even nicer with a raw string literal\nauto j2 = R\"(\n  {\n    \"happy\": true,\n    \"pi\": 3.141\n  }\n)\"_json;\n```\n\nNote that without appending the `_json` suffix, the passed string literal is not parsed, but just used as JSON string\nvalue. That is, `json j = \"{ \\\"happy\\\": true, \\\"pi\\\": 3.141 }\"` would just store the string\n`\"{ \"happy\": true, \"pi\": 3.141 }\"` rather than parsing the actual object.\n\nThe string literal should be brought into scope with `using namespace nlohmann::literals;`\n(see [`json::parse()`](https://json.nlohmann.me/api/operator_literal_json/)).\n\nThe above example can also be expressed explicitly using [`json::parse()`](https://json.nlohmann.me/api/basic_json/parse/):\n\n```cpp\n// parse explicitly\nauto j3 = json::parse(R\"({\"happy\": true, \"pi\": 3.141})\");\n```\n\nYou can also get a string representation of a JSON value (serialize):\n\n```cpp\n// explicit conversion to string\nstd::string s = j.dump();    // {\"happy\":true,\"pi\":3.141}\n\n// serialization with pretty printing\n// pass in the amount of spaces to indent\nstd::cout << j.dump(4) << std::endl;\n// {\n//     \"happy\": true,\n//     \"pi\": 3.141\n// }\n```\n\nNote the difference between serialization and assignment:\n\n```cpp\n// store a string in a JSON value\njson j_string = \"this is a string\";\n\n// retrieve the string value\nauto cpp_string = j_string.get<std::string>();\n// retrieve the string value (alternative when a variable already exists)\nstd::string cpp_string2;\nj_string.get_to(cpp_string2);\n\n// retrieve the serialized value (explicit JSON serialization)\nstd::string serialized_string = j_string.dump();\n\n// output of original string\nstd::cout << cpp_string << \" == \" << cpp_string2 << \" == \" << j_string.get<std::string>() << '\\n';\n// output of serialized value\nstd::cout << j_string << \" == \" << serialized_string << std::endl;\n```\n\n[`.dump()`](https://json.nlohmann.me/api/basic_json/dump/) returns the originally stored string value.\n\nNote the library only supports UTF-8. When you store strings with different encodings in the library, calling [`dump()`](https://json.nlohmann.me/api/basic_json/dump/) may throw an exception unless `json::error_handler_t::replace` or `json::error_handler_t::ignore` are used as error handlers.\n\n#### To/from streams (e.g., files, string streams)\n\nYou can also use streams to serialize and deserialize:\n\n```cpp\n// deserialize from standard input\njson j;\nstd::cin >> j;\n\n// serialize to standard output\nstd::cout << j;\n\n// the setw manipulator was overloaded to set the indentation for pretty printing\nstd::cout << std::setw(4) << j << std::endl;\n```\n\nThese operators work for any subclasses of `std::istream` or `std::ostream`. Here is the same example with files:\n\n```cpp\n// read a JSON file\nstd::ifstream i(\"file.json\");\njson j;\ni >> j;\n\n// write prettified JSON to another file\nstd::ofstream o(\"pretty.json\");\no << std::setw(4) << j << std::endl;\n```\n\nPlease note that setting the exception bit for `failbit` is inappropriate for this use case. It will result in program termination due to the `noexcept` specifier in use.\n\n#### Read from iterator range\n\nYou can also parse JSON from an iterator range; that is, from any container accessible by iterators whose `value_type` is an integral type of 1, 2, or 4 bytes, which will be interpreted as UTF-8, UTF-16, and UTF-32 respectively. For instance, a `std::vector<std::uint8_t>`, or a `std::list<std::uint16_t>`:\n\n```cpp\nstd::vector<std::uint8_t> v = {'t', 'r', 'u', 'e'};\njson j = json::parse(v.begin(), v.end());\n```\n\nYou may leave the iterators for the range [begin, end):\n\n```cpp\nstd::vector<std::uint8_t> v = {'t', 'r', 'u', 'e'};\njson j = json::parse(v);\n```\n\n#### Custom data source\n\nSince the parse function accepts arbitrary iterator ranges, you can provide your own data sources by implementing the `LegacyInputIterator` concept.\n\n```cpp\nstruct MyContainer {\n  void advance();\n  const char& get_current();\n};\n\nstruct MyIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = char;\n    using pointer = const char*;\n    using reference = const char&;\n    using iterator_category = std::input_iterator_tag;\n\n    MyIterator& operator++() {\n        target->advance();\n        return *this;\n    }\n\n    bool operator!=(const MyIterator& rhs) const {\n        return rhs.target != target;\n    }\n\n    reference operator*() const {\n        return target->get_current();\n    }\n\n    MyContainer* target = nullptr;\n};\n\nMyIterator begin(MyContainer& tgt) {\n    return MyIterator{&tgt};\n}\n\nMyIterator end(const MyContainer&) {\n    return {};\n}\n\nvoid foo() {\n    MyContainer c;\n    json j = json::parse(c);\n}\n```\n\n#### SAX interface\n\nThe library uses a SAX-like interface with the following functions:\n\n```cpp\n// called when null is parsed\nbool null();\n\n// called when a boolean is parsed; value is passed\nbool boolean(bool val);\n\n// called when a signed or unsigned integer number is parsed; value is passed\nbool number_integer(number_integer_t val);\nbool number_unsigned(number_unsigned_t val);\n\n// called when a floating-point number is parsed; value and original string is passed\nbool number_float(number_float_t val, const string_t& s);\n\n// called when a string is parsed; value is passed and can be safely moved away\nbool string(string_t& val);\n// called when a binary value is parsed; value is passed and can be safely moved away\nbool binary(binary_t& val);\n\n// called when an object or array begins or ends, resp. The number of elements is passed (or -1 if not known)\nbool start_object(std::size_t elements);\nbool end_object();\nbool start_array(std::size_t elements);\nbool end_array();\n// called when an object key is parsed; value is passed and can be safely moved away\nbool key(string_t& val);\n\n// called when a parse error occurs; byte position, the last token, and an exception is passed\nbool parse_error(std::size_t position, const std::string& last_token, const detail::exception& ex);\n```\n\nThe return value of each function determines whether parsing should proceed.\n\nTo implement your own SAX handler, proceed as follows:\n\n1. Implement the SAX interface in a class. You can use class `nlohmann::json_sax<json>` as base class, but you can also use any class where the functions described above are implemented and public.\n2. Create an object of your SAX interface class, e.g. `my_sax`.\n3. Call `bool json::sax_parse(input, &my_sax)`; where the first parameter can be any input like a string or an input stream and the second parameter is a pointer to your SAX interface.\n\nNote the `sax_parse` function only returns a `bool` indicating the result of the last executed SAX event. It does not return a  `json` value - it is up to you to decide what to do with the SAX events. Furthermore, no exceptions are thrown in case of a parse error -- it is up to you what to do with the exception object passed to your `parse_error` implementation. Internally, the SAX interface is used for the DOM parser (class `json_sax_dom_parser`) as well as the acceptor (`json_sax_acceptor`), see file [`json_sax.hpp`](https://github.com/nlohmann/json/blob/develop/include/nlohmann/detail/input/json_sax.hpp).\n\n### STL-like access\n\nWe designed the JSON class to behave just like an STL container. In fact, it satisfies the [**ReversibleContainer**](https://en.cppreference.com/w/cpp/named_req/ReversibleContainer) requirement.\n\n```cpp\n// create an array using push_back\njson j;\nj.push_back(\"foo\");\nj.push_back(1);\nj.push_back(true);\n\n// also use emplace_back\nj.emplace_back(1.78);\n\n// iterate the array\nfor (json::iterator it = j.begin(); it != j.end(); ++it) {\n  std::cout << *it << '\\n';\n}\n\n// range-based for\nfor (auto& element : j) {\n  std::cout << element << '\\n';\n}\n\n// getter/setter\nconst auto tmp = j[0].get<std::string>();\nj[1] = 42;\nbool foo = j.at(2);\n\n// comparison\nj == R\"([\"foo\", 1, true, 1.78])\"_json;  // true\n\n// other stuff\nj.size();     // 4 entries\nj.empty();    // false\nj.type();     // json::value_t::array\nj.clear();    // the array is empty again\n\n// convenience type checkers\nj.is_null();\nj.is_boolean();\nj.is_number();\nj.is_object();\nj.is_array();\nj.is_string();\n\n// create an object\njson o;\no[\"foo\"] = 23;\no[\"bar\"] = false;\no[\"baz\"] = 3.141;\n\n// also use emplace\no.emplace(\"weather\", \"sunny\");\n\n// special iterator member functions for objects\nfor (json::iterator it = o.begin(); it != o.end(); ++it) {\n  std::cout << it.key() << \" : \" << it.value() << \"\\n\";\n}\n\n// the same code as range for\nfor (auto& el : o.items()) {\n  std::cout << el.key() << \" : \" << el.value() << \"\\n\";\n}\n\n// even easier with structured bindings (C++17)\nfor (auto& [key, value] : o.items()) {\n  std::cout << key << \" : \" << value << \"\\n\";\n}\n\n// find an entry\nif (o.contains(\"foo\")) {\n  // there is an entry with key \"foo\"\n}\n\n// or via find and an iterator\nif (o.find(\"foo\") != o.end()) {\n  // there is an entry with key \"foo\"\n}\n\n// or simpler using count()\nint foo_present = o.count(\"foo\"); // 1\nint fob_present = o.count(\"fob\"); // 0\n\n// delete an entry\no.erase(\"foo\");\n```\n\n### Conversion from STL containers\n\nAny sequence container (`std::array`, `std::vector`, `std::deque`, `std::forward_list`, `std::list`) whose values can be used to construct JSON values (e.g., integers, floating point numbers, Booleans, string types, or again STL containers described in this section) can be used to create a JSON array. The same holds for similar associative containers (`std::set`, `std::multiset`, `std::unordered_set`, `std::unordered_multiset`), but in these cases the order of the elements of the array depends on how the elements are ordered in the respective STL container.\n\n```cpp\nstd::vector<int> c_vector {1, 2, 3, 4};\njson j_vec(c_vector);\n// [1, 2, 3, 4]\n\nstd::deque<double> c_deque {1.2, 2.3, 3.4, 5.6};\njson j_deque(c_deque);\n// [1.2, 2.3, 3.4, 5.6]\n\nstd::list<bool> c_list {true, true, false, true};\njson j_list(c_list);\n// [true, true, false, true]\n\nstd::forward_list<int64_t> c_flist {12345678909876, 23456789098765, 34567890987654, 45678909876543};\njson j_flist(c_flist);\n// [12345678909876, 23456789098765, 34567890987654, 45678909876543]\n\nstd::array<unsigned long, 4> c_array {{1, 2, 3, 4}};\njson j_array(c_array);\n// [1, 2, 3, 4]\n\nstd::set<std::string> c_set {\"one\", \"two\", \"three\", \"four\", \"one\"};\njson j_set(c_set); // only one entry for \"one\" is used\n// [\"four\", \"one\", \"three\", \"two\"]\n\nstd::unordered_set<std::string> c_uset {\"one\", \"two\", \"three\", \"four\", \"one\"};\njson j_uset(c_uset); // only one entry for \"one\" is used\n// maybe [\"two\", \"three\", \"four\", \"one\"]\n\nstd::multiset<std::string> c_mset {\"one\", \"two\", \"one\", \"four\"};\njson j_mset(c_mset); // both entries for \"one\" are used\n// maybe [\"one\", \"two\", \"one\", \"four\"]\n\nstd::unordered_multiset<std::string> c_umset {\"one\", \"two\", \"one\", \"four\"};\njson j_umset(c_umset); // both entries for \"one\" are used\n// maybe [\"one\", \"two\", \"one\", \"four\"]\n```\n\nLikewise, any associative key-value containers (`std::map`, `std::multimap`, `std::unordered_map`, `std::unordered_multimap`) whose keys can construct an `std::string` and whose values can be used to construct JSON values (see examples above) can be used to create a JSON object. Note that in case of multimaps, only one key is used in the JSON object and the value depends on the internal order of the STL container.\n\n```cpp\nstd::map<std::string, int> c_map { {\"one\", 1}, {\"two\", 2}, {\"three\", 3} };\njson j_map(c_map);\n// {\"one\": 1, \"three\": 3, \"two\": 2 }\n\nstd::unordered_map<const char*, double> c_umap { {\"one\", 1.2}, {\"two\", 2.3}, {\"three\", 3.4} };\njson j_umap(c_umap);\n// {\"one\": 1.2, \"two\": 2.3, \"three\": 3.4}\n\nstd::multimap<std::string, bool> c_mmap { {\"one\", true}, {\"two\", true}, {\"three\", false}, {\"three\", true} };\njson j_mmap(c_mmap); // only one entry for key \"three\" is used\n// maybe {\"one\": true, \"two\": true, \"three\": true}\n\nstd::unordered_multimap<std::string, bool> c_ummap { {\"one\", true}, {\"two\", true}, {\"three\", false}, {\"three\", true} };\njson j_ummap(c_ummap); // only one entry for key \"three\" is used\n// maybe {\"one\": true, \"two\": true, \"three\": true}\n```\n\n### JSON Pointer and JSON Patch\n\nThe library supports **JSON Pointer** ([RFC 6901](https://tools.ietf.org/html/rfc6901)) as an alternative means to address structured values. On top of this, **JSON Patch** ([RFC 6902](https://tools.ietf.org/html/rfc6902)) allows describing differences between two JSON values -- effectively allowing patch and diff operations known from Unix.\n\n```cpp\n// a JSON value\njson j_original = R\"({\n  \"baz\": [\"one\", \"two\", \"three\"],\n  \"foo\": \"bar\"\n})\"_json;\n\n// access members with a JSON pointer (RFC 6901)\nj_original[\"/baz/1\"_json_pointer];\n// \"two\"\n\n// a JSON patch (RFC 6902)\njson j_patch = R\"([\n  { \"op\": \"replace\", \"path\": \"/baz\", \"value\": \"boo\" },\n  { \"op\": \"add\", \"path\": \"/hello\", \"value\": [\"world\"] },\n  { \"op\": \"remove\", \"path\": \"/foo\"}\n])\"_json;\n\n// apply the patch\njson j_result = j_original.patch(j_patch);\n// {\n//    \"baz\": \"boo\",\n//    \"hello\": [\"world\"]\n// }\n\n// calculate a JSON patch from two JSON values\njson::diff(j_result, j_original);\n// [\n//   { \"op\":\" replace\", \"path\": \"/baz\", \"value\": [\"one\", \"two\", \"three\"] },\n//   { \"op\": \"remove\",\"path\": \"/hello\" },\n//   { \"op\": \"add\", \"path\": \"/foo\", \"value\": \"bar\" }\n// ]\n```\n\n### JSON Merge Patch\n\nThe library supports **JSON Merge Patch** ([RFC 7386](https://tools.ietf.org/html/rfc7386)) as a patch format. Instead of using JSON Pointer (see above) to specify values to be manipulated, it describes the changes using a syntax that closely mimics the document being modified.\n\n```cpp\n// a JSON value\njson j_document = R\"({\n  \"a\": \"b\",\n  \"c\": {\n    \"d\": \"e\",\n    \"f\": \"g\"\n  }\n})\"_json;\n\n// a patch\njson j_patch = R\"({\n  \"a\":\"z\",\n  \"c\": {\n    \"f\": null\n  }\n})\"_json;\n\n// apply the patch\nj_document.merge_patch(j_patch);\n// {\n//  \"a\": \"z\",\n//  \"c\": {\n//    \"d\": \"e\"\n//  }\n// }\n```\n\n### Implicit conversions\n\nSupported types can be implicitly converted to JSON values.\n\nIt is recommended to **NOT USE** implicit conversions **FROM** a JSON value.\nYou can find more details about this recommendation [here](https://www.github.com/nlohmann/json/issues/958).\nYou can switch off implicit conversions by defining `JSON_USE_IMPLICIT_CONVERSIONS` to `0` before including the `json.hpp` header. When using CMake, you can also achieve this by setting the option `JSON_ImplicitConversions` to `OFF`.\n\n```cpp\n// strings\nstd::string s1 = \"Hello, world!\";\njson js = s1;\nauto s2 = js.get<std::string>();\n// NOT RECOMMENDED\nstd::string s3 = js;\nstd::string s4;\ns4 = js;\n\n// Booleans\nbool b1 = true;\njson jb = b1;\nauto b2 = jb.get<bool>();\n// NOT RECOMMENDED\nbool b3 = jb;\nbool b4;\nb4 = jb;\n\n// numbers\nint i = 42;\njson jn = i;\nauto f = jn.get<double>();\n// NOT RECOMMENDED\ndouble f2 = jb;\ndouble f3;\nf3 = jb;\n\n// etc.\n```\n\nNote that `char` types are not automatically converted to JSON strings, but to integer numbers. A conversion to a string must be specified explicitly:\n\n```cpp\nchar ch = 'A';                       // ASCII value 65\njson j_default = ch;                 // stores integer number 65\njson j_string = std::string(1, ch);  // stores string \"A\"\n```\n\n### Arbitrary types conversions\n\nEvery type can be serialized in JSON, not just STL containers and scalar types. Usually, you would do something along those lines:\n\n```cpp\nnamespace ns {\n    // a simple struct to model a person\n    struct person {\n        std::string name;\n        std::string address;\n        int age;\n    };\n}\n\nns::person p = {\"Ned Flanders\", \"744 Evergreen Terrace\", 60};\n\n// convert to JSON: copy each value into the JSON object\njson j;\nj[\"name\"] = p.name;\nj[\"address\"] = p.address;\nj[\"age\"] = p.age;\n\n// ...\n\n// convert from JSON: copy each value from the JSON object\nns::person p {\n    j[\"name\"].get<std::string>(),\n    j[\"address\"].get<std::string>(),\n    j[\"age\"].get<int>()\n};\n```\n\nIt works, but that's quite a lot of boilerplate... Fortunately, there's a better way:\n\n```cpp\n// create a person\nns::person p {\"Ned Flanders\", \"744 Evergreen Terrace\", 60};\n\n// conversion: person -> json\njson j = p;\n\nstd::cout << j << std::endl;\n// {\"address\":\"744 Evergreen Terrace\",\"age\":60,\"name\":\"Ned Flanders\"}\n\n// conversion: json -> person\nauto p2 = j.get<ns::person>();\n\n// that's it\nassert(p == p2);\n```\n\n#### Basic usage\n\nTo make this work with one of your types, you only need to provide two functions:\n\n```cpp\nusing json = nlohmann::json;\n\nnamespace ns {\n    void to_json(json& j, const person& p) {\n        j = json{{\"name\", p.name}, {\"address\", p.address}, {\"age\", p.age}};\n    }\n\n    void from_json(const json& j, person& p) {\n        j.at(\"name\").get_to(p.name);\n        j.at(\"address\").get_to(p.address);\n        j.at(\"age\").get_to(p.age);\n    }\n} // namespace ns\n```\n\nThat's all! When calling the `json` constructor with your type, your custom `to_json` method will be automatically called.\nLikewise, when calling `get<your_type>()` or `get_to(your_type&)`, the `from_json` method will be called.\n\nSome important things:\n\n- Those methods **MUST** be in your type's namespace (which can be the global namespace), or the library will not be able to locate them (in this example, they are in namespace `ns`, where `person` is defined).\n- Those methods **MUST** be available (e.g., proper headers must be included) everywhere you use these conversions. Look at [issue 1108](https://github.com/nlohmann/json/issues/1108) for errors that may occur otherwise.\n- When using `get<your_type>()`, `your_type` **MUST** be [DefaultConstructible](https://en.cppreference.com/w/cpp/named_req/DefaultConstructible). (There is a way to bypass this requirement described later.)\n- In function `from_json`, use function [`at()`](https://json.nlohmann.me/api/basic_json/at/) to access the object values rather than `operator[]`. In case a key does not exist, `at` throws an exception that you can handle, whereas `operator[]` exhibits undefined behavior.\n- You do not need to add serializers or deserializers for STL types like `std::vector`: the library already implements these.\n\n#### Simplify your life with macros\n\nIf you just want to serialize/deserialize some structs, the `to_json`/`from_json` functions can be a lot of boilerplate. There are [**several macros**](https://json.nlohmann.me/features/arbitrary_types/#simplify-your-life-with-macros) to make your life easier as long as you (1) want to use a JSON object as serialization and (2) want to use the member variable names as object keys in that object.\n\nWhich macro to choose depends on whether private member variables need to be accessed, a deserialization is needed, missing values should yield an error or should be replaced by default values, and if derived classes are used. See [this overview to choose the right one for your use case](https://json.nlohmann.me/api/macros/#serializationdeserialization-macros).\n\n##### Example usage of macros\n\nThe `to_json`/`from_json` functions for the `person` struct above can be created with [`NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`](https://json.nlohmann.me/api/macros/nlohmann_define_type_non_intrusive/). In all macros, the first parameter is the name of the class/struct, and all remaining parameters name the members.\n\n```cpp\nnamespace ns {\n    NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE(person, name, address, age)\n}\n```\n\nHere is another example with private members, where [`NLOHMANN_DEFINE_TYPE_INTRUSIVE`](https://json.nlohmann.me/api/macros/nlohmann_define_type_intrusive/) is needed:\n\n```cpp\nnamespace ns {\n    class address {\n      private:\n        std::string street;\n        int housenumber;\n        int postcode;\n  \n      public:\n        NLOHMANN_DEFINE_TYPE_INTRUSIVE(address, street, housenumber, postcode)\n    };\n}\n```\n\n#### How do I convert third-party types?\n\nThis requires a bit more advanced technique. But first, let's see how this conversion mechanism works:\n\nThe library uses **JSON Serializers** to convert types to JSON.\nThe default serializer for `nlohmann::json` is `nlohmann::adl_serializer` (ADL means [Argument-Dependent Lookup](https://en.cppreference.com/w/cpp/language/adl)).\n\nIt is implemented like this (simplified):\n\n```cpp\ntemplate <typename T>\nstruct adl_serializer {\n    static void to_json(json& j, const T& value) {\n        // calls the \"to_json\" method in T's namespace\n    }\n\n    static void from_json(const json& j, T& value) {\n        // same thing, but with the \"from_json\" method\n    }\n};\n```\n\nThis serializer works fine when you have control over the type's namespace. However, what about `boost::optional` or `std::filesystem::path` (C++17)? Hijacking the `boost` namespace is pretty bad, and it's illegal to add something other than template specializations to `std`...\n\nTo solve this, you need to add a specialization of `adl_serializer` to the `nlohmann` namespace, here's an example:\n\n```cpp\n// partial specialization (full specialization works too)\nnamespace nlohmann {\n    template <typename T>\n    struct adl_serializer<boost::optional<T>> {\n        static void to_json(json& j, const boost::optional<T>& opt) {\n            if (opt == boost::none) {\n                j = nullptr;\n            } else {\n              j = *opt; // this will call adl_serializer<T>::to_json which will\n                        // find the free function to_json in T's namespace!\n            }\n        }\n\n        static void from_json(const json& j, boost::optional<T>& opt) {\n            if (j.is_null()) {\n                opt = boost::none;\n            } else {\n                opt = j.get<T>(); // same as above, but with\n                                  // adl_serializer<T>::from_json\n            }\n        }\n    };\n}\n```\n\n#### How can I use `get()` for non-default constructible/non-copyable types?\n\nThere is a way if your type is [MoveConstructible](https://en.cppreference.com/w/cpp/named_req/MoveConstructible). You will need to specialize the `adl_serializer` as well, but with a special `from_json` overload:\n\n```cpp\nstruct move_only_type {\n    move_only_type() = delete;\n    move_only_type(int ii): i(ii) {}\n    move_only_type(const move_only_type&) = delete;\n    move_only_type(move_only_type&&) = default;\n\n    int i;\n};\n\nnamespace nlohmann {\n    template <>\n    struct adl_serializer<move_only_type> {\n        // note: the return type is no longer 'void', and the method only takes\n        // one argument\n        static move_only_type from_json(const json& j) {\n            return {j.get<int>()};\n        }\n\n        // Here's the catch! You must provide a to_json method! Otherwise, you\n        // will not be able to convert move_only_type to json, since you fully\n        // specialized adl_serializer on that type\n        static void to_json(json& j, move_only_type t) {\n            j = t.i;\n        }\n    };\n}\n```\n\n#### Can I write my own serializer? (Advanced use)\n\nYes. You might want to take a look at [`unit-udt.cpp`](https://github.com/nlohmann/json/blob/develop/tests/src/unit-udt.cpp) in the test suite, to see a few examples.\n\nIf you write your own serializer, you'll need to do a few things:\n\n- use a different `basic_json` alias than `nlohmann::json` (the last template parameter of `basic_json` is the `JSONSerializer`)\n- use your `basic_json` alias (or a template parameter) in all your `to_json`/`from_json` methods\n- use `nlohmann::to_json` and `nlohmann::from_json` when you need ADL\n\nHere is an example, without simplifications, that only accepts types with a size <= 32, and uses ADL.\n\n```cpp\n// You should use void as a second template argument\n// if you don't need compile-time checks on T\ntemplate<typename T, typename SFINAE = typename std::enable_if<sizeof(T) <= 32>::type>\nstruct less_than_32_serializer {\n    template <typename BasicJsonType>\n    static void to_json(BasicJsonType& j, T value) {\n        // we want to use ADL, and call the correct to_json overload\n        using nlohmann::to_json; // this method is called by adl_serializer,\n                                 // this is where the magic happens\n        to_json(j, value);\n    }\n\n    template <typename BasicJsonType>\n    static void from_json(const BasicJsonType& j, T& value) {\n        // same thing here\n        using nlohmann::from_json;\n        from_json(j, value);\n    }\n};\n```\n\nBe **very** careful when reimplementing your serializer, you can stack overflow if you don't pay attention:\n\n```cpp\ntemplate <typename T, void>\nstruct bad_serializer\n{\n    template <typename BasicJsonType>\n    static void to_json(BasicJsonType& j, const T& value) {\n      // this calls BasicJsonType::json_serializer<T>::to_json(j, value)\n      // if BasicJsonType::json_serializer == bad_serializer ... oops!\n      j = value;\n    }\n\n    template <typename BasicJsonType>\n    static void to_json(const BasicJsonType& j, T& value) {\n      // this calls BasicJsonType::json_serializer<T>::from_json(j, value)\n      // if BasicJsonType::json_serializer == bad_serializer ... oops!\n      value = j.get<T>(); // oops!\n    }\n};\n```\n\n### Specializing enum conversion\n\nBy default, enum values are serialized to JSON as integers. In some cases, this could result in undesired behavior. If an enum is modified or re-ordered after data has been serialized to JSON, the later deserialized JSON data may be undefined or a different enum value than was originally intended.\n\nIt is possible to more precisely specify how a given enum is mapped to and from JSON as shown below:\n\n```cpp\n// example enum type declaration\nenum TaskState {\n    TS_STOPPED,\n    TS_RUNNING,\n    TS_COMPLETED,\n    TS_INVALID=-1,\n};\n\n// map TaskState values to JSON as strings\nNLOHMANN_JSON_SERIALIZE_ENUM( TaskState, {\n    {TS_INVALID, nullptr},\n    {TS_STOPPED, \"stopped\"},\n    {TS_RUNNING, \"running\"},\n    {TS_COMPLETED, \"completed\"},\n})\n```\n\nThe `NLOHMANN_JSON_SERIALIZE_ENUM()` macro declares a set of `to_json()` / `from_json()` functions for type `TaskState` while avoiding repetition and boilerplate serialization code.\n\n**Usage:**\n\n```cpp\n// enum to JSON as string\njson j = TS_STOPPED;\nassert(j == \"stopped\");\n\n// json string to enum\njson j3 = \"running\";\nassert(j3.get<TaskState>() == TS_RUNNING);\n\n// undefined json value to enum (where the first map entry above is the default)\njson jPi = 3.14;\nassert(jPi.get<TaskState>() == TS_INVALID);\n```\n\nJust as in [Arbitrary Type Conversions](#arbitrary-types-conversions) above,\n\n- `NLOHMANN_JSON_SERIALIZE_ENUM()` MUST be declared in your enum type's namespace (which can be the global namespace), or the library will not be able to locate it, and it will default to integer serialization.\n- It MUST be available (e.g., proper headers must be included) everywhere you use the conversions.\n\nOther Important points:\n\n- When using `get<ENUM_TYPE>()`, undefined JSON values will default to the first pair specified in your map. Select this default pair carefully.\n- If an enum or JSON value is specified more than once in your map, the first matching occurrence from the top of the map will be returned when converting to or from JSON.\n\n### Binary formats (BSON, CBOR, MessagePack, UBJSON, and BJData)\n\nThough JSON is a ubiquitous data format, it is not a very compact format suitable for data exchange, for instance over a network. Hence, the library supports [BSON](https://bsonspec.org) (Binary JSON), [CBOR](https://cbor.io) (Concise Binary Object Representation), [MessagePack](https://msgpack.org), [UBJSON](https://ubjson.org) (Universal Binary JSON Specification) and [BJData](https://neurojson.org/bjdata) (Binary JData) to efficiently encode JSON values to byte vectors and to decode such vectors.\n\n```cpp\n// create a JSON value\njson j = R\"({\"compact\": true, \"schema\": 0})\"_json;\n\n// serialize to BSON\nstd::vector<std::uint8_t> v_bson = json::to_bson(j);\n\n// 0x1B, 0x00, 0x00, 0x00, 0x08, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0x00, 0x01, 0x10, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n\n// roundtrip\njson j_from_bson = json::from_bson(v_bson);\n\n// serialize to CBOR\nstd::vector<std::uint8_t> v_cbor = json::to_cbor(j);\n\n// 0xA2, 0x67, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0xF5, 0x66, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00\n\n// roundtrip\njson j_from_cbor = json::from_cbor(v_cbor);\n\n// serialize to MessagePack\nstd::vector<std::uint8_t> v_msgpack = json::to_msgpack(j);\n\n// 0x82, 0xA7, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0xC3, 0xA6, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00\n\n// roundtrip\njson j_from_msgpack = json::from_msgpack(v_msgpack);\n\n// serialize to UBJSON\nstd::vector<std::uint8_t> v_ubjson = json::to_ubjson(j);\n\n// 0x7B, 0x69, 0x07, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0x54, 0x69, 0x06, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x69, 0x00, 0x7D\n\n// roundtrip\njson j_from_ubjson = json::from_ubjson(v_ubjson);\n```\n\nThe library also supports binary types from BSON, CBOR (byte strings), and MessagePack (bin, ext, fixext). They are stored by default as `std::vector<std::uint8_t>` to be processed outside the library.\n\n```cpp\n// CBOR byte string with payload 0xCAFE\nstd::vector<std::uint8_t> v = {0x42, 0xCA, 0xFE};\n\n// read value\njson j = json::from_cbor(v);\n\n// the JSON value has type binary\nj.is_binary(); // true\n\n// get reference to stored binary value\nauto& binary = j.get_binary();\n\n// the binary value has no subtype (CBOR has no binary subtypes)\nbinary.has_subtype(); // false\n\n// access std::vector<std::uint8_t> member functions\nbinary.size(); // 2\nbinary[0]; // 0xCA\nbinary[1]; // 0xFE\n\n// set subtype to 0x10\nbinary.set_subtype(0x10);\n\n// serialize to MessagePack\nauto cbor = json::to_msgpack(j); // 0xD5 (fixext2), 0x10, 0xCA, 0xFE\n```\n\n## Customers\n\nThe library is used in multiple projects, applications, operating systems, etc. The list below is not exhaustive, but the result of an internet search. If you know further customers of the library, please let me know, see [contact](#contact).\n\n[![logos of customers using the library](docs/mkdocs/docs/images/customers.png)](https://json.nlohmann.me/home/customers/)\n\n## Supported compilers\n\nThough it's 2026 already, the support for C++11 is still a bit sparse. Currently, the following compilers are known to work:\n\n- GCC 4.8 - 14.2 (and possibly later)\n- Clang 3.4 - 21.0 (and possibly later)\n- Apple Clang 9.1 - 16.0 (and possibly later)\n- Intel C++ Compiler 17.0.2 (and possibly later)\n- Nvidia CUDA Compiler 11.0.221 (and possibly later)\n- Microsoft Visual C++ 2015 / Build Tools 14.0.25123.0 (and possibly later)\n- Microsoft Visual C++ 2017 / Build Tools 15.5.180.51428 (and possibly later)\n- Microsoft Visual C++ 2019 / Build Tools 16.3.1+1def00d3d (and possibly later)\n- Microsoft Visual C++ 2022 / Build Tools 19.30.30709.0 (and possibly later)\n\nI would be happy to learn about other compilers/versions.\n\nPlease note:\n\n- GCC 4.8 has a bug [57824](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=57824): multiline raw strings cannot be the arguments to macros. Don't use multiline raw strings directly in macros with this compiler.\n- Android defaults to using very old compilers and C++ libraries. To fix this, add the following to your `Application.mk`. This will switch to the LLVM C++ library, the Clang compiler, and enable C++11 and other features disabled by default.\n\n    ```makefile\n    APP_STL := c++_shared\n    NDK_TOOLCHAIN_VERSION := clang3.6\n    APP_CPPFLAGS += -frtti -fexceptions\n    ```\n\n    The code compiles successfully with [Android NDK](https://developer.android.com/ndk/index.html?hl=ml), Revision 9 - 11 (and possibly later) and [CrystaX's Android NDK](https://www.crystax.net/en/android/ndk) version 10.\n\n- For GCC running on MinGW or Android SDK, the error `'to_string' is not a member of 'std'` (or similarly, for `strtod` or `strtof`) may occur. Note this is not an issue with the code, but rather with the compiler itself. On Android, see above to build with a newer environment.  For MinGW, please refer to [this site](https://tehsausage.com/mingw-to-string) and [this discussion](https://github.com/nlohmann/json/issues/136) for information on how to fix this bug. For Android NDK using `APP_STL := gnustl_static`, please refer to [this discussion](https://github.com/nlohmann/json/issues/219).\n\n- Unsupported versions of GCC and Clang are rejected by `#error` directives. This can be switched off by defining `JSON_SKIP_UNSUPPORTED_COMPILER_CHECK`. Note that you can expect no support in this case.\n\nSee the page [quality assurance](https://json.nlohmann.me/community/quality_assurance) on the compilers used to check the library in the CI.\n\n## Integration\n\n[`json.hpp`](https://github.com/nlohmann/json/blob/develop/single_include/nlohmann/json.hpp) is the single required file in `single_include/nlohmann` or [released here](https://github.com/nlohmann/json/releases). You need to add\n\n```cpp\n#include <nlohmann/json.hpp>\n\n// for convenience\nusing json = nlohmann::json;\n```\n\nto the files you want to process JSON and set the necessary switches to enable C++11 (e.g., `-std=c++11` for GCC and Clang).\n\nYou can further use file [`include/nlohmann/json_fwd.hpp`](https://github.com/nlohmann/json/blob/develop/include/nlohmann/json_fwd.hpp) for forward-declarations. The installation of `json_fwd.hpp` (as part of cmake's install step) can be achieved by setting `-DJSON_MultipleHeaders=ON`.\n\n### CMake\n\nYou can also use the `nlohmann_json::nlohmann_json` interface target in CMake.  This target populates the appropriate usage requirements for `INTERFACE_INCLUDE_DIRECTORIES` to point to the appropriate include directories and `INTERFACE_COMPILE_FEATURES` for the necessary C++11 flags.\n\n#### External\n\nTo use this library from a CMake project, you can locate it directly with `find_package()` and use the namespaced imported target from the generated package configuration:\n\n```cmake\n# CMakeLists.txt\nfind_package(nlohmann_json 3.12.0 REQUIRED)\n...\nadd_library(foo ...)\n...\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\nThe package configuration file, `nlohmann_jsonConfig.cmake`, can be used either from an install tree or directly out of the build tree.\n\n#### Embedded\n\nTo embed the library directly into an existing CMake project, place the entire source tree in a subdirectory and call `add_subdirectory()` in your `CMakeLists.txt` file:\n\n```cmake\n# Typically you don't care so much for a third party library's tests to be\n# run from your own project's code.\nset(JSON_BuildTests OFF CACHE INTERNAL \"\")\n\n# If you only include this third party in PRIVATE source files, you do not\n# need to install it when your main project gets installed.\n# set(JSON_Install OFF CACHE INTERNAL \"\")\n\n# Don't use include(nlohmann_json/CMakeLists.txt) since that carries with it\n# unintended consequences that will break the build.  It's generally\n# discouraged (although not necessarily well documented as such) to use\n# include(...) for pulling in other CMake projects anyways.\nadd_subdirectory(nlohmann_json)\n...\nadd_library(foo ...)\n...\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n##### Embedded (FetchContent)\n\nSince CMake v3.11,\n[FetchContent](https://cmake.org/cmake/help/v3.11/module/FetchContent.html) can\nbe used to automatically download a release as a dependency at configure time.\n\nExample:\n\n```cmake\ninclude(FetchContent)\n\nFetchContent_Declare(json URL https://github.com/nlohmann/json/releases/download/v3.12.0/json.tar.xz)\nFetchContent_MakeAvailable(json)\n\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n**Note**: It is recommended to use the URL approach described above, which is supported as of version 3.10.0. See\n<https://json.nlohmann.me/integration/cmake/#fetchcontent> for more information.\n\n#### Supporting Both\n\nTo allow your project to support either an externally supplied or an embedded JSON library, you can use a pattern akin to the following:\n\n``` cmake\n# Top level CMakeLists.txt\nproject(FOO)\n...\noption(FOO_USE_EXTERNAL_JSON \"Use an external JSON library\" OFF)\n...\nadd_subdirectory(thirdparty)\n...\nadd_library(foo ...)\n...\n# Note that the namespaced target will always be available regardless of the\n# import method\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n```cmake\n# thirdparty/CMakeLists.txt\n...\nif(FOO_USE_EXTERNAL_JSON)\n  find_package(nlohmann_json 3.12.0 REQUIRED)\nelse()\n  set(JSON_BuildTests OFF CACHE INTERNAL \"\")\n  add_subdirectory(nlohmann_json)\nendif()\n...\n```\n\n`thirdparty/nlohmann_json` is then a complete copy of this source tree.\n\n### Package Managers\n\nUse your favorite [**package manager**](https://json.nlohmann.me/integration/package_managers/) to use the library.\n\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/homebrew.svg\" height=\"20\">&nbsp;[**Homebrew**](https://json.nlohmann.me/integration/package_managers/#homebrew) `nlohmann-json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/meson.svg\" height=\"20\">&nbsp;[**Meson**](https://json.nlohmann.me/integration/package_managers/#meson) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/bazel.svg\" height=\"20\">&nbsp;[**Bazel**](https://json.nlohmann.me/integration/package_managers/#bazel) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/conan.svg\" height=\"20\">&nbsp;[**Conan**](https://json.nlohmann.me/integration/package_managers/#conan) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/spack.svg\" height=\"20\">&nbsp;[**Spack**](https://json.nlohmann.me/integration/package_managers/#spack) `nlohmann-json`\n- [**Hunter**](https://json.nlohmann.me/integration/package_managers/#hunter) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/vcpkg.png\" height=\"20\">&nbsp;[**vcpkg**](https://json.nlohmann.me/integration/package_managers/#vcpkg) `nlohmann-json`\n- [**cget**](https://json.nlohmann.me/integration/package_managers/#cget) `nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/swift.svg\" height=\"20\">&nbsp;[**Swift Package Manager**](https://json.nlohmann.me/integration/package_managers/#swift-package-manager) `nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/nuget.svg\" height=\"20\">&nbsp;[**Nuget**](https://json.nlohmann.me/integration/package_managers/#nuget) `nlohmann.json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/conda.svg\" height=\"20\">&nbsp;[**Conda**](https://json.nlohmann.me/integration/package_managers/#conda) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/macports.svg\" height=\"20\">&nbsp;[**MacPorts**](https://json.nlohmann.me/integration/package_managers/#macports) `nlohmann-json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/CPM.png\" height=\"20\">&nbsp;[**cpm.cmake**](https://json.nlohmann.me/integration/package_managers/#cpmcmake) `gh:nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/xmake.svg\" height=\"20\">&nbsp;[**xmake**](https://json.nlohmann.me/integration/package_managers/#xmake) `nlohmann_json`\n\nThe library is part of many package managers. See the [**documentation**](https://json.nlohmann.me/integration/package_managers/) for detailed descriptions and examples.\n\n### Pkg-config\n\nIf you are using bare Makefiles, you can use `pkg-config` to generate the include flags that point to where the library is installed:\n\n```sh\npkg-config nlohmann_json --cflags\n```\n\n## License\n\n<img align=\"right\" src=\"https://149753425.v2.pressablecdn.com/wp-content/uploads/2009/06/OSIApproved_100X125.png\" alt=\"OSI approved license\">\n\nThe class is licensed under the [MIT License](https://opensource.org/licenses/MIT):\n\nCopyright &copy; 2013-2026 [Niels Lohmann](https://nlohmann.me)\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the â€œSoftwareâ€), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED â€œAS ISâ€, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n* * *\n\n- The class contains the UTF-8 Decoder from Bjoern Hoehrmann which is licensed under the [MIT License](https://opensource.org/licenses/MIT) (see above). Copyright &copy; 2008-2009 [BjÃ¶rn Hoehrmann](https://bjoern.hoehrmann.de/) <bjoern@hoehrmann.de>\n- The class contains a slightly modified version of the Grisu2 algorithm from Florian Loitsch which is licensed under the [MIT License](https://opensource.org/licenses/MIT) (see above). Copyright &copy; 2009 [Florian Loitsch](https://florian.loitsch.com/)\n- The class contains a copy of [Hedley](https://nemequ.github.io/hedley/) from Evan Nemerson which is licensed as [CC0-1.0](https://creativecommons.org/publicdomain/zero/1.0/).\n- The class contains parts of [Google Abseil](https://github.com/abseil/abseil-cpp) which is licensed under the [Apache 2.0 License](https://opensource.org/licenses/Apache-2.0).\n\n<img align=\"right\" src=\"https://git.fsfe.org/reuse/reuse-ci/raw/branch/master/reuse-horizontal.png\" alt=\"REUSE Software\">\n\nThe library is compliant to version 3.3 of the [**REUSE specification**](https://reuse.software):\n\n- Every source file contains an SPDX copyright header.\n- The full text of all licenses used in the repository can be found in the `LICENSES` folder.\n- File `.reuse/dep5` contains an overview of all files' copyrights and licenses.\n- Run `pipx run reuse lint` to verify the project's REUSE compliance and `pipx run reuse spdx` to generate a SPDX SBOM.\n\n## Contact\n\nIf you have questions regarding the library, I would like to invite you to [open an issue at GitHub](https://github.com/nlohmann/json/issues/new/choose). Please describe your request, problem, or question as detailed as possible, and also mention the version of the library you are using as well as the version of your compiler and operating system. Opening an issue at GitHub allows other users and contributors to this library to collaborate. For instance, I have little experience with MSVC, and most issues in this regard have been solved by a growing community. If you have a look at the [closed issues](https://github.com/nlohmann/json/issues?q=is%3Aissue+is%3Aclosed), you will see that we react quite timely in most cases.\n\nOnly if your request would contain confidential information, please [send me an email](mailto:mail@nlohmann.me). For encrypted messages, please use [this key](https://keybase.io/nlohmann/pgp_keys.asc).\n\n## Security\n\n[Commits by Niels Lohmann](https://github.com/nlohmann/json/commits) and [releases](https://github.com/nlohmann/json/releases) are signed with this [PGP Key](https://keybase.io/nlohmann/pgp_keys.asc?fingerprint=797167ae41c0a6d9232e48457f3cea63ae251b69).\n\n## Thanks\n\nI deeply appreciate the help of the following people.\n\n<img src=\"https://raw.githubusercontent.com/nlohmann/json/develop/docs/avatars.png\" align=\"right\" alt=\"GitHub avatars of the contributors\">\n\n1. [Teemperor](https://github.com/Teemperor) implemented CMake support and lcov integration, realized escape and Unicode handling in the string parser, and fixed the JSON serialization.\n2. [elliotgoodrich](https://github.com/elliotgoodrich) fixed an issue with double deletion in the iterator classes.\n3. [kirkshoop](https://github.com/kirkshoop) made the iterators of the class composable to other libraries.\n4. [wancw](https://github.com/wanwc) fixed a bug that hindered the class to compile with Clang.\n5. Tomas Ã…blad found a bug in the iterator implementation.\n6. [Joshua C. Randall](https://github.com/jrandall) fixed a bug in the floating-point serialization.\n7. [Aaron Burghardt](https://github.com/aburgh) implemented code to parse streams incrementally. Furthermore, he greatly improved the parser class by allowing the definition of a filter function to discard undesired elements while parsing.\n8. [Daniel KopeÄek](https://github.com/dkopecek) fixed a bug in the compilation with GCC 5.0.\n9. [Florian Weber](https://github.com/Florianjw) fixed a bug in and improved the performance of the comparison operators.\n10. [Eric Cornelius](https://github.com/EricMCornelius) pointed out a bug in the handling with NaN and infinity values. He also improved the performance of the string escaping.\n11. [æ˜“æ€é¾™](https://github.com/likebeta) implemented a conversion from anonymous enums.\n12. [kepkin](https://github.com/kepkin) patiently pushed forward the support for Microsoft Visual Studio.\n13. [gregmarr](https://github.com/gregmarr) simplified the implementation of reverse iterators and helped with numerous hints and improvements. In particular, he pushed forward the implementation of user-defined types.\n14. [Caio Luppi](https://github.com/caiovlp) fixed a bug in the Unicode handling.\n15. [dariomt](https://github.com/dariomt) fixed some typos in the examples.\n16. [Daniel Frey](https://github.com/d-frey) cleaned up some pointers and implemented exception-safe memory allocation.\n17. [Colin Hirsch](https://github.com/ColinH) took care of a small namespace issue.\n18. [Huu Nguyen](https://github.com/whoshuu) corrected a variable name in the documentation.\n19. [Silverweed](https://github.com/silverweed) overloaded `parse()` to accept an rvalue reference.\n20. [dariomt](https://github.com/dariomt) fixed a subtlety in MSVC type support and implemented the `get_ref()` function to get a reference to stored values.\n21. [ZahlGraf](https://github.com/ZahlGraf) added a workaround that allows compilation using Android NDK.\n22. [whackashoe](https://github.com/whackashoe) replaced a function that was marked as unsafe by Visual Studio.\n23. [406345](https://github.com/406345) fixed two small warnings.\n24. [Glen Fernandes](https://github.com/glenfe) noted a potential portability problem in the `has_mapped_type` function.\n25. [Corbin Hughes](https://github.com/nibroc) fixed some typos in the contribution guidelines.\n26. [twelsby](https://github.com/twelsby) fixed the array subscript operator, an issue that failed the MSVC build, and floating-point parsing/dumping. He further added support for unsigned integer numbers and implemented better roundtrip support for parsed numbers.\n27. [Volker Diels-Grabsch](https://github.com/vog) fixed a link in the README file.\n28. [msm-](https://github.com/msm-) added support for American Fuzzy Lop.\n29. [Annihil](https://github.com/Annihil) fixed an example in the README file.\n30. [Themercee](https://github.com/Themercee) noted a wrong URL in the README file.\n31. [Lv Zheng](https://github.com/lv-zheng) fixed a namespace issue with `int64_t` and `uint64_t`.\n32. [abc100m](https://github.com/abc100m) analyzed the issues with GCC 4.8 and proposed a [partial solution](https://github.com/nlohmann/json/pull/212).\n33. [zewt](https://github.com/zewt) added useful notes to the README file about Android.\n34. [RÃ³bert MÃ¡rki](https://github.com/robertmrk) added a fix to use move iterators and improved the integration via CMake.\n35. [Chris Kitching](https://github.com/ChrisKitching) cleaned up the CMake files.\n36. [Tom Needham](https://github.com/06needhamt) fixed a subtle bug with MSVC 2015 which was also proposed by [Michael K.](https://github.com/Epidal).\n37. [MÃ¡rio Feroldi](https://github.com/thelostt) fixed a small typo.\n38. [duncanwerner](https://github.com/duncanwerner) found a really embarrassing performance regression in the 2.0.0 release.\n39. [Damien](https://github.com/dtoma) fixed one of the last conversion warnings.\n40. [Thomas Braun](https://github.com/t-b) fixed a warning in a test case and adjusted MSVC calls in the CI.\n41. [ThÃ©o DELRIEU](https://github.com/theodelrieu) patiently and constructively oversaw the long way toward [iterator-range parsing](https://github.com/nlohmann/json/issues/290). He also implemented the magic behind the serialization/deserialization of user-defined types and split the single header file into smaller chunks.\n42. [Stefan](https://github.com/5tefan) fixed a minor issue in the documentation.\n43. [Vasil Dimov](https://github.com/vasild) fixed the documentation regarding conversions from `std::multiset`.\n44. [ChristophJud](https://github.com/ChristophJud) overworked the CMake files to ease project inclusion.\n45. [Vladimir Petrigo](https://github.com/vpetrigo) made a SFINAE hack more readable and added Visual Studio 17 to the build matrix.\n46. [Denis Andrejew](https://github.com/seeekr) fixed a grammar issue in the README file.\n47. [Pierre-Antoine Lacaze](https://github.com/palacaze) found a subtle bug in the `dump()` function.\n48. [TurpentineDistillery](https://github.com/TurpentineDistillery) pointed to [`std::locale::classic()`](https://en.cppreference.com/w/cpp/locale/locale/classic) to avoid too much locale joggling, found some nice performance improvements in the parser, improved the benchmarking code, and realized locale-independent number parsing and printing.\n49. [cgzones](https://github.com/cgzones) had an idea how to fix the Coverity scan.\n50. [Jared Grubb](https://github.com/jaredgrubb) silenced a nasty documentation warning.\n51. [Yixin Zhang](https://github.com/qwename) fixed an integer overflow check.\n52. [Bosswestfalen](https://github.com/Bosswestfalen) merged two iterator classes into a smaller one.\n53. [Daniel599](https://github.com/Daniel599) helped to get Travis to execute the tests with Clang's sanitizers.\n54. [Jonathan Lee](https://github.com/vjon) fixed an example in the README file.\n55. [gnzlbg](https://github.com/gnzlbg) supported the implementation of user-defined types.\n56. [Alexej Harm](https://github.com/qis) helped to get the user-defined types working with Visual Studio.\n57. [Jared Grubb](https://github.com/jaredgrubb) supported the implementation of user-defined types.\n58. [EnricoBilla](https://github.com/EnricoBilla) noted a typo in an example.\n59. [Martin HoÅ™eÅˆovskÃ½](https://github.com/horenmar) found a way for a 2x speedup for the compilation time of the test suite.\n60. [ukhegg](https://github.com/ukhegg) found proposed an improvement for the examples section.\n61. [rswanson-ihi](https://github.com/rswanson-ihi) noted a typo in the README.\n62. [Mihai Stan](https://github.com/stanmihai4) fixed a bug in the comparison with `nullptr`s.\n63. [Tushar Maheshwari](https://github.com/tusharpm) added [cotire](https://github.com/sakra/cotire) support to speed up the compilation.\n64. [TedLyngmo](https://github.com/TedLyngmo) noted a typo in the README, removed unnecessary bit arithmetic, and fixed some `-Weffc++` warnings.\n65. [Krzysztof WoÅ›](https://github.com/krzysztofwos) made exceptions more visible.\n66. [ftillier](https://github.com/ftillier) fixed a compiler warning.\n67. [tinloaf](https://github.com/tinloaf) made sure all pushed warnings are properly popped.\n68. [Fytch](https://github.com/Fytch) found a bug in the documentation.\n69. [Jay Sistar](https://github.com/Type1J) implemented a Meson build description.\n70. [Henry Lee](https://github.com/HenryRLee) fixed a warning in ICC and improved the iterator implementation.\n71. [Vincent Thiery](https://github.com/vthiery) maintains a package for the Conan package manager.\n72. [Steffen](https://github.com/koemeet) fixed a potential issue with MSVC and `std::min`.\n73. [Mike Tzou](https://github.com/Chocobo1) fixed some typos.\n74. [amrcode](https://github.com/amrcode) noted misleading documentation about comparison of floats.\n75. [Oleg Endo](https://github.com/olegendo) reduced the memory consumption by replacing `<iostream>` with `<iosfwd>`.\n76. [dan-42](https://github.com/dan-42) cleaned up the CMake files to simplify including/reusing of the library.\n77. [Nikita Ofitserov](https://github.com/himikof) allowed for moving values from initializer lists.\n78. [Greg Hurrell](https://github.com/wincent) fixed a typo.\n79. [Dmitry Kukovinets](https://github.com/DmitryKuk) fixed a typo.\n80. [kbthomp1](https://github.com/kbthomp1) fixed an issue related to the Intel OSX compiler.\n81. [Markus Werle](https://github.com/daixtrose) fixed a typo.\n82. [WebProdPP](https://github.com/WebProdPP) fixed a subtle error in a precondition check.\n83. [Alex](https://github.com/leha-bot) noted an error in a code sample.\n84. [Tom de Geus](https://github.com/tdegeus) reported some warnings with ICC and helped to fix them.\n85. [Perry Kundert](https://github.com/pjkundert) simplified reading from input streams.\n86. [Sonu Lohani](https://github.com/sonulohani) fixed a small compilation error.\n87. [Jamie Seward](https://github.com/jseward) fixed all MSVC warnings.\n88. [Nate Vargas](https://github.com/eld00d) added a Doxygen tag file.\n89. [pvleuven](https://github.com/pvleuven) helped to fix a warning in ICC.\n90. [Pavel](https://github.com/crea7or) helped to fix some warnings in MSVC.\n91. [Jamie Seward](https://github.com/jseward) avoided unnecessary string copies in `find()` and `count()`.\n92. [Mitja](https://github.com/Itja) fixed some typos.\n93. [Jorrit Wronski](https://github.com/jowr) updated the Hunter package links.\n94. [Matthias MÃ¶ller](https://github.com/TinyTinni) added a `.natvis` for the MSVC debug view.\n95. [bogemic](https://github.com/bogemic) fixed some C++17 deprecation warnings.\n96. [Eren Okka](https://github.com/erengy) fixed some MSVC warnings.\n97. [abolz](https://github.com/abolz) integrated the Grisu2 algorithm for proper floating-point formatting, allowing more roundtrip checks to succeed.\n98. [Vadim Evard](https://github.com/Pipeliner) fixed a Markdown issue in the README.\n99. [zerodefect](https://github.com/zerodefect) fixed a compiler warning.\n100. [Kert](https://github.com/kaidokert) allowed to template the string type in the serialization and added the possibility to override the exceptional behavior.\n101. [mark-99](https://github.com/mark-99) helped fix an ICC error.\n102. [Patrik Huber](https://github.com/patrikhuber) fixed links in the README file.\n103. [johnfb](https://github.com/johnfb) found a bug in the implementation of CBOR's indefinite length strings.\n104. [Paul Fultz II](https://github.com/pfultz2) added a note on the cget package manager.\n105. [Wilson Lin](https://github.com/wla80) made the integration section of the README more concise.\n106. [RalfBielig](https://github.com/ralfbielig) detected and fixed a memory leak in the parser callback.\n107. [agrianius](https://github.com/agrianius) allowed dumping JSON to an alternative string type.\n108. [Kevin Tonon](https://github.com/ktonon) overworked the C++11 compiler checks in CMake.\n109. [Axel Huebl](https://github.com/ax3l) simplified a CMake check and added support for the [Spack package manager](https://spack.io).\n110. [Carlos O'Ryan](https://github.com/coryan) fixed a typo.\n111. [James Upjohn](https://github.com/jammehcow) fixed a version number in the compilers section.\n112. [Chuck Atkins](https://github.com/chuckatkins) adjusted the CMake files to the CMake packaging guidelines and provided documentation for the CMake integration.\n113. [Jan SchÃ¶ppach](https://github.com/dns13) fixed a typo.\n114. [martin-mfg](https://github.com/martin-mfg) fixed a typo.\n115. [Matthias MÃ¶ller](https://github.com/TinyTinni) removed the dependency from `std::stringstream`.\n116. [agrianius](https://github.com/agrianius) added code to use alternative string implementations.\n117. [Daniel599](https://github.com/Daniel599) allowed to use more algorithms with the `items()` function.\n118. [Julius Rakow](https://github.com/jrakow) fixed the Meson include directory and fixed the links to [cppreference.com](https://cppreference.com).\n119. [Sonu Lohani](https://github.com/sonulohani) fixed the compilation with MSVC 2015 in debug mode.\n120. [grembo](https://github.com/grembo) fixed the test suite and re-enabled several test cases.\n121. [Hyeon Kim](https://github.com/simnalamburt) introduced the macro `JSON_INTERNAL_CATCH` to control the exception handling inside the library.\n122. [thyu](https://github.com/thyu) fixed a compiler warning.\n123. [David Guthrie](https://github.com/LEgregius) fixed a subtle compilation error with Clang 3.4.2.\n124. [Dennis Fischer](https://github.com/dennisfischer) allowed to call `find_package` without installing the library.\n125. [Hyeon Kim](https://github.com/simnalamburt) fixed an issue with a double macro definition.\n126. [Ben Berman](https://github.com/rivertam) made some error messages more understandable.\n127. [zakalibit](https://github.com/zakalibit) fixed a compilation problem with the Intel C++ compiler.\n128. [mandreyel](https://github.com/mandreyel) fixed a compilation problem.\n129. [Kostiantyn Ponomarenko](https://github.com/koponomarenko) added version and license information to the Meson build file.\n130. [Henry Schreiner](https://github.com/henryiii) added support for GCC 4.8.\n131. [knilch](https://github.com/knilch0r) made sure the test suite does not stall when run in the wrong directory.\n132. [Antonio Borondo](https://github.com/antonioborondo) fixed an MSVC 2017 warning.\n133. [Dan Gendreau](https://github.com/dgendreau) implemented the `NLOHMANN_JSON_SERIALIZE_ENUM` macro to quickly define an enum/JSON mapping.\n134. [efp](https://github.com/efp) added line and column information to parse errors.\n135. [julian-becker](https://github.com/julian-becker) added BSON support.\n136. [Pratik Chowdhury](https://github.com/pratikpc) added support for structured bindings.\n137. [David Avedissian](https://github.com/davedissian) added support for Clang 5.0.1 (PS4 version).\n138. [Jonathan Dumaresq](https://github.com/dumarjo) implemented an input adapter to read from `FILE*`.\n139. [kjpus](https://github.com/kjpus) fixed a link in the documentation.\n140. [Manvendra Singh](https://github.com/manu-chroma) fixed a typo in the documentation.\n141. [ziggurat29](https://github.com/ziggurat29) fixed an MSVC warning.\n142. [Sylvain Corlay](https://github.com/SylvainCorlay) added code to avoid an issue with MSVC.\n143. [mefyl](https://github.com/mefyl) fixed a bug when JSON was parsed from an input stream.\n144. [Millian Poquet](https://github.com/mpoquet) allowed to install the library via Meson.\n145. [Michael Behrns-Miller](https://github.com/moodboom) found an issue with a missing namespace.\n146. [Nasztanovics Ferenc](https://github.com/naszta) fixed a compilation issue with libc 2.12.\n147. [Andreas Schwab](https://github.com/andreas-schwab) fixed the endian conversion.\n148. [Mark-Dunning](https://github.com/Mark-Dunning) fixed a warning in MSVC.\n149. [Gareth Sylvester-Bradley](https://github.com/garethsb-sony) added `operator/` for JSON Pointers.\n150. [John-Mark](https://github.com/johnmarkwayve) noted a missing header.\n151. [Vitaly Zaitsev](https://github.com/xvitaly) fixed compilation with GCC 9.0.\n152. [Laurent Stacul](https://github.com/stac47) fixed compilation with GCC 9.0.\n153. [Ivor Wanders](https://github.com/iwanders) helped to reduce the CMake requirement to version 3.1.\n154. [njlr](https://github.com/njlr) updated the Buckaroo instructions.\n155. [Lion](https://github.com/lieff) fixed a compilation issue with GCC 7 on CentOS.\n156. [Isaac Nickaein](https://github.com/nickaein) improved the integer serialization performance and implemented the `contains()` function.\n157. [past-due](https://github.com/past-due) suppressed an unfixable warning.\n158. [Elvis Oric](https://github.com/elvisoric) improved Meson support.\n159. [MatÄ›j Plch](https://github.com/Afforix) fixed an example in the README.\n160. [Mark Beckwith](https://github.com/wythe) fixed a typo.\n161. [scinart](https://github.com/scinart) fixed a bug in the serializer.\n162. [Patrick Boettcher](https://github.com/pboettch) implemented `push_back()` and `pop_back()` for JSON Pointers.\n163. [Bruno Oliveira](https://github.com/nicoddemus) added support for Conda.\n164. [Michele Caini](https://github.com/skypjack) fixed links in the README.\n165. [Hani](https://github.com/hnkb) documented how to install the library with NuGet.\n166. [Mark Beckwith](https://github.com/wythe) fixed a typo.\n167. [yann-morin-1998](https://github.com/yann-morin-1998) helped to reduce the CMake requirement to version 3.1.\n168. [Konstantin Podsvirov](https://github.com/podsvirov) maintains a package for the MSYS2 software distro.\n169. [remyabel](https://github.com/remyabel) added GNUInstallDirs to the CMake files.\n170. [Taylor Howard](https://github.com/taylorhoward92) fixed a unit test.\n171. [Gabe Ron](https://github.com/Macr0Nerd) implemented the `to_string` method.\n172. [Watal M. Iwasaki](https://github.com/heavywatal) fixed a Clang warning.\n173. [Viktor Kirilov](https://github.com/onqtam) switched the unit tests from [Catch](https://github.com/philsquared/Catch) to [doctest](https://github.com/onqtam/doctest)\n174. [Juncheng E](https://github.com/ejcjason) fixed a typo.\n175. [tete17](https://github.com/tete17) fixed a bug in the `contains` function.\n176. [Xav83](https://github.com/Xav83) fixed some cppcheck warnings.\n177. [0xflotus](https://github.com/0xflotus) fixed some typos.\n178. [Christian Deneke](https://github.com/chris0x44) added a const version of `json_pointer::back`.\n179. [Julien Hamaide](https://github.com/crazyjul) made the `items()` function work with custom string types.\n180. [Evan Nemerson](https://github.com/nemequ) updated fixed a bug in Hedley and updated this library accordingly.\n181. [Florian Pigorsch](https://github.com/flopp) fixed a lot of typos.\n182. [Camille BÃ©guÃ©](https://github.com/cbegue) fixed an issue in the conversion from  `std::pair` and `std::tuple` to `json`.\n183. [Anthony VH](https://github.com/AnthonyVH) fixed a compile error in an enum deserialization.\n184. [Yuriy Vountesmery](https://github.com/ua-code-dragon) noted a subtle bug in a preprocessor check.\n185. [Chen](https://github.com/dota17) fixed numerous issues in the library.\n186. [Antony Kellermann](https://github.com/aokellermann) added a CI step for GCC 10.1.\n187. [Alex](https://github.com/gistrec) fixed an MSVC warning.\n188. [Rainer](https://github.com/rvjr) proposed an improvement in the floating-point serialization in CBOR.\n189. [Francois Chabot](https://github.com/FrancoisChabot) made performance improvements in the input adapters.\n190. [Arthur Sonzogni](https://github.com/ArthurSonzogni) documented how the library can be included via `FetchContent`.\n191. [Rimas MiseviÄius](https://github.com/rmisev) fixed an error message.\n192. [Alexander Myasnikov](https://github.com/alexandermyasnikov) fixed some examples and a link in the README.\n193. [Hubert Chathi](https://github.com/uhoreg) made CMake's version config file architecture-independent.\n194. [OmnipotentEntity](https://github.com/OmnipotentEntity) implemented the binary values for CBOR, MessagePack, BSON, and UBJSON.\n195. [ArtemSarmini](https://github.com/ArtemSarmini) fixed a compilation issue with GCC 10 and fixed a leak.\n196. [Evgenii Sopov](https://github.com/sea-kg) integrated the library to the wsjcpp package manager.\n197. [Sergey Linev](https://github.com/linev) fixed a compiler warning.\n198. [Miguel MagalhÃ£es](https://github.com/magamig) fixed the year in the copyright.\n199. [Gareth Sylvester-Bradley](https://github.com/garethsb-sony) fixed a compilation issue with MSVC.\n200. [Alexander â€œweejâ€ Jones](https://github.com/alex-weej) fixed an example in the README.\n201. [Antoine CÅ“ur](https://github.com/Coeur) fixed some typos in the documentation.\n202. [jothepro](https://github.com/jothepro) updated links to the Hunter package.\n203. [Dave Lee](https://github.com/kastiglione) fixed a link in the README.\n204. [JoÃ«l Lamotte](https://github.com/Klaim) added instruction for using Build2's package manager.\n205. [Paul Jurczak](https://github.com/pauljurczak) fixed an example in the README.\n206. [Sonu Lohani](https://github.com/sonulohani) fixed a warning.\n207. [Carlos Gomes Martinho](https://github.com/gocarlos) updated the Conan package source.\n208. [Konstantin Podsvirov](https://github.com/podsvirov) fixed the MSYS2 package documentation.\n209. [Tridacnid](https://github.com/Tridacnid) improved the CMake tests.\n210. [Michael](https://github.com/MBalszun) fixed MSVC warnings.\n211. [Quentin Barbarat](https://github.com/quentin-dev) fixed an example in the documentation.\n212. [XyFreak](https://github.com/XyFreak) fixed a compiler warning.\n213. [TotalCaesar659](https://github.com/TotalCaesar659) fixed links in the README.\n214. [Tanuj Garg](https://github.com/tanuj208) improved the fuzzer coverage for UBSAN input.\n215. [AODQ](https://github.com/AODQ) fixed a compiler warning.\n216. [jwittbrodt](https://github.com/jwittbrodt) made `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE` inline.\n217. [pfeatherstone](https://github.com/pfeatherstone) improved the upper bound of arguments of the `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`/`NLOHMANN_DEFINE_TYPE_INTRUSIVE` macros.\n218. [Jan ProchÃ¡zka](https://github.com/jprochazk) fixed a bug in the CBOR parser for binary and string values.\n219. [T0b1-iOS](https://github.com/T0b1-iOS) fixed a bug in the new hash implementation.\n220. [Matthew Bauer](https://github.com/matthewbauer) adjusted the CBOR writer to create tags for binary subtypes.\n221. [gatopeich](https://github.com/gatopeich) implemented an ordered map container for `nlohmann::ordered_json`.\n222. [Ã‰rico Nogueira Rolim](https://github.com/ericonr) added support for pkg-config.\n223. [KonanM](https://github.com/KonanM) proposed an implementation for the `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`/`NLOHMANN_DEFINE_TYPE_INTRUSIVE` macros.\n224. [Guillaume Racicot](https://github.com/gracicot) implemented `string_view` support and allowed C++20 support.\n225. [Alex Reinking](https://github.com/alexreinking) improved CMake support for `FetchContent`.\n226. [Hannes Domani](https://github.com/ssbssa) provided a GDB pretty printer.\n227. Lars Wirzenius reviewed the README file.\n228. [Jun Jie](https://github.com/ongjunjie) fixed a compiler path in the CMake scripts.\n229. [Ronak Buch](https://github.com/rbuch) fixed typos in the documentation.\n230. [Alexander Karzhenkov](https://github.com/karzhenkov) fixed a move constructor and the Travis builds.\n231. [Leonardo Lima](https://github.com/leozz37) added CPM.Cmake support.\n232. [Joseph Blackman](https://github.com/jbzdarkid) fixed a warning.\n233. [Yaroslav](https://github.com/YarikTH) updated doctest and implemented unit tests.\n234. [Martin Stump](https://github.com/globberwops) fixed a bug in the CMake files.\n235. [Jaakko Moisio](https://github.com/jasujm) fixed a bug in the input adapters.\n236. [bl-ue](https://github.com/bl-ue) fixed some Markdown issues in the README file.\n237. [William A. Wieselquist](https://github.com/wawiesel) fixed an example from the README.\n238. [abbaswasim](https://github.com/abbaswasim) fixed an example from the README.\n239. [Remy Jette](https://github.com/remyjette) fixed a warning.\n240. [Fraser](https://github.com/frasermarlow) fixed the documentation.\n241. [Ben Beasley](https://github.com/musicinmybrain) updated doctest.\n242. [Doron Behar](https://github.com/doronbehar) fixed pkg-config.pc.\n243. [raduteo](https://github.com/raduteo) fixed a warning.\n244. [David Pfahler](https://github.com/theShmoo) added the possibility to compile the library without I/O support.\n245. [Morten Fyhn Amundsen](https://github.com/mortenfyhn) fixed a typo.\n246. [jpl-mac](https://github.com/jpl-mac) allowed treating the library as a system header in CMake.\n247. [Jason Dsouza](https://github.com/jasmcaus) fixed the indentation of the CMake file.\n248. [offa](https://github.com/offa) added a link to Conan Center to the documentation.\n249. [TotalCaesar659](https://github.com/TotalCaesar659) updated the links in the documentation to use HTTPS.\n250. [Rafail Giavrimis](https://github.com/grafail) fixed the Google Benchmark default branch.\n251. [Louis Dionne](https://github.com/ldionne) fixed a conversion operator.\n252. [justanotheranonymoususer](https://github.com/justanotheranonymoususer) made the examples in the README more consistent.\n253. [Finkman](https://github.com/Finkman) suppressed some `-Wfloat-equal` warnings.\n254. [Ferry Huberts](https://github.com/fhuberts) fixed `-Wswitch-enum` warnings.\n255. [Arseniy Terekhin](https://github.com/senyai) made the GDB pretty-printer robust against unset variable names.\n256. [Amir Masoud Abdol](https://github.com/amirmasoudabdol) updated the Homebrew command as nlohmann/json is now in homebrew-core.\n257. [Hallot](https://github.com/Hallot) fixed some `-Wextra-semi-stmt warnings`.\n258. [Giovanni Cerretani](https://github.com/gcerretani) fixed `-Wunused` warnings on `JSON_DIAGNOSTICS`.\n259. [Bogdan Popescu](https://github.com/Kapeli) hosts the [docset](https://github.com/Kapeli/Dash-User-Contributions/tree/master/docsets/JSON_for_Modern_C%2B%2B) for offline documentation viewers.\n260. [Carl Smedstad](https://github.com/carlsmedstad) fixed an assertion error when using `JSON_DIAGNOSTICS`.\n261. [miikka75](https://github.com/miikka75) provided an important fix to compile C++17 code with Clang 9.\n262. [Maarten Becker](https://github.com/kernie) fixed a warning for shadowed variables.\n263. [Cristi VÃ®jdea](https://github.com/axnsan12) fixed typos in the `operator[]` documentation.\n264. [Alex Beregszaszi](https://github.com/axic) fixed spelling mistakes in comments.\n265. [Dirk Stolle](https://github.com/striezel) fixed typos in documentation.\n266. [Daniel Albuschat](https://github.com/daniel-kun) corrected the parameter name in the `parse` documentation.\n267. [Prince Mendiratta](https://github.com/Prince-Mendiratta) fixed a link to the FAQ.\n268. [Florian Albrechtskirchinger](https://github.com/falbrechtskirchinger) implemented `std::string_view` support for object keys and made dozens of other improvements.\n269. [Qianqian Fang](https://github.com/fangq) implemented the Binary JData (BJData) format.\n270. [pketelsen](https://github.com/pketelsen) added macros `NLOHMANN_DEFINE_TYPE_INTRUSIVE_WITH_DEFAULT` and `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE_WITH_DEFAULT`.\n271. [DarkZeros](https://github.com/DarkZeros) adjusted to code to not clash with Arduino defines.\n272. [flagarde](https://github.com/flagarde) fixed the output of `meta()` for MSVC.\n273. [Giovanni Cerretani](https://github.com/gcerretani) fixed a check for `std::filesystem`.\n274. [Dimitris Apostolou](https://github.com/rex4539) fixed a typo.\n275. [Ferry Huberts](https://github.com/fhuberts) fixed a typo.\n276. [Michael Nosthoff](https://github.com/heinemml) fixed a typo.\n277. [JungHoon Lee](https://github.com/jhnlee) fixed a typo.\n278. [Faruk D.](https://github.com/fdiblen) fixed the CITATION.CFF file.\n279. [Andrea Cocito](https://github.com/puffetto) added a clarification on macro usage to the documentation.\n280. [Krzysiek Karbowiak](https://github.com/kkarbowiak) refactored the tests to use `CHECK_THROWS_WITH_AS`.\n281. [Chaoqi Zhang](https://github.com/prncoprs) fixed a typo.\n282. [ivanovmp](https://github.com/ivanovmp) fixed a whitespace error.\n283. [KsaNL](https://github.com/KsaNL) fixed a build error when including `<windows.h>`.\n284. [Andrea Pappacoda](https://github.com/Tachi107) moved `.pc` and `.cmake` files to `share` directory.\n285. [Wolf Vollprecht](https://github.com/wolfv) added the `patch_inplace` function.\n286. [Jake Zimmerman](https://github.com/jez) highlighted common usage patterns in the README file.\n287. [NN](https://github.com/NN---) added the Visual Studio output directory to `.gitignore`.\n288. [Romain Reignier](https://github.com/romainreignier) improved the performance of the vector output adapter.\n289. [Mike](https://github.com/Mike-Leo-Smith) fixed the `std::iterator_traits`.\n290. [Richard HozÃ¡k](https://github.com/zxey) added macro `JSON_NO_ENUM` to disable default enum conversions.\n291. [vakokako](https://github.com/vakokako) fixed tests when compiling with C++20.\n292. [Alexander â€œweejâ€ Jones](https://github.com/alexweej) fixed an example in the README.\n293. [Eli Schwartz](https://github.com/eli-schwartz) added more files to the `include.zip` archive.\n294. [Kevin Lu](https://github.com/kevinlul) fixed a compilation issue when typedefs with certain names were present.\n295. [Trevor Hickey](https://github.com/luxe) improved the description of an example.\n296. [Jef LeCompte](https://github.com/jef) updated the year in the README file.\n297. [Alexandre Hamez](https://github.com/ahamez) fixed a warning.\n298. [Maninderpal Badhan](https://github.com/mbadhan) fixed a typo.\n299. [kevin--](https://github.com/kevin--) added a note to an example in the README file.\n300. [I](https://github.com/wx257osn2) fixed a typo.\n301. [Gregorio Litenstein](https://github.com/Lord-Kamina) fixed the Clang detection.\n302. [Andreas Smas](https://github.com/andoma) added a Doozer badge.\n303. [WanCW](https://github.com/wancw) fixed the string conversion with Clang.\n304. [zhaohuaxishi](https://github.com/zhaohuaxishi) fixed a Doxygen error.\n305. [emvivre](https://github.com/emvivre) removed an invalid parameter from CMake.\n306. [Tobias Hermann](https://github.com/Dobiasd) fixed a link in the README file.\n307. [Michael](https://github.com/traits) fixed a warning.\n308. [Ryan Mulder](https://github.com/ryanjmulder) added `ensure_ascii` to the `dump` function.\n309. [Muri Nicanor](https://github.com/murinicanor) fixed the `sed` discovery in the Makefile.\n310. [David Avedissian](https://github.com/dgavedissian) implemented SFINAE-friendly `iterator_traits`.\n311. [AQNOUCH Mohammed](https://github.com/aqnouch) fixed a typo in the README.\n312. [Gareth Sylvester-Bradley](https://github.com/garethsb) added `operator/=` and `operator/` to construct JSON pointers.\n313. [Michael Macnair](https://github.com/mykter) added support for afl-fuzz testing.\n314. [Berkus Decker](https://github.com/berkus) fixed a typo in the README.\n315. [Illia Polishchuk](https://github.com/effolkronium) improved the CMake testing.\n316. [Ikko Ashimine](https://github.com/eltociear) fixed a typo.\n317. [Raphael Grimm](https://github.com/barcode) added the possibility to define a custom base class.\n318. [tocic](https://github.com/tocic) fixed typos in the documentation.\n319. [Vertexwahn](https://github.com/Vertexwahn) added Bazel build support.\n320. [Dirk Stolle](https://github.com/striezel) fixed typos in the documentation.\n321. [DavidKorczynski](https://github.com/DavidKorczynski) added a CIFuzz CI GitHub action.\n322. [Finkman](https://github.com/Finkman) fixed the debug pretty-printer.\n323. [Florian Segginger](https://github.com/floriansegginger) bumped the years in the README.\n324. [haadfida](https://github.com/haadfida) cleaned up the badges of used services.\n325. [Arsen ArsenoviÄ‡](https://github.com/ArsenArsen) fixed a build error.\n326. [theevilone45](https://github.com/theevilone45) fixed a typo in a CMake file.\n327. [Sergei Trofimovich](https://github.com/trofi) fixed the custom allocator support.\n328. [Joyce](https://github.com/joycebrum) fixed some security issues in the GitHub workflows.\n329. [Nicolas Jakob](https://github.com/njakob) add vcpkg version badge.\n330. [Tomerkm](https://github.com/Tomerkm) added tests.\n331. [No.](https://github.com/tusooa) fixed the use of `get<>` calls.\n332. [taro](https://github.com/tarolling) fixed a typo in the `CODEOWNERS` file.\n333. [Ikko Eltociear Ashimine](https://github.com/eltociear) fixed a typo.\n334. [Felix Yan](https://github.com/felixonmars) fixed a typo in the README.\n335. [HO-COOH](https://github.com/HO-COOH) fixed a parenthesis in the documentation.\n336. [Ivor Wanders](https://github.com/iwanders) fixed the examples to catch exception by `const&`.\n337. [miny1233](https://github.com/miny1233) fixed a parenthesis in the documentation.\n338. [tomalakgeretkal](https://github.com/tomalakgeretkal) fixed a compilation error.\n339. [alferov](https://github.com/ALF-ONE) fixed a compilation error.\n340. [Craig Scott](https://github.com/craigscott-crascit) fixed a deprecation warning in CMake.\n341. [Vyacheslav Zhdanovskiy](https://github.com/ZeronSix) added macros for serialization-only types.\n342. [Mathieu Westphal](https://github.com/mwestphal) fixed typos.\n343. [scribam](https://github.com/scribam) fixed the MinGW workflow.\n344. [Aleksei Sapitskii](https://github.com/aleksproger) added support for Apple's Swift Package Manager.\n345. [Benjamin Buch](https://github.com/bebuch) fixed the installation path in CMake.\n346. [Colby Haskell](https://github.com/colbychaskell) clarified the parse error message in case a file cannot be opened.\n347. [Juan Carlos Arevalo Baeza](https://github.com/TheJCAB) fixed the enum conversion.\n348. [alferov](https://github.com/ALF-ONE) fixed a version in the documentation.\n349. [ss](https://github.com/serge-s) fixed the amalgamation call.\n350. [AniketDhemare](https://github.com/AniketDhemare) fixed a version in the documentation.\n351. [Philip MÃ¼ller](https://github.com/philip-paul-mueller) fixed an example.\n352. [Leila Shcheglova](https://github.com/LeilaShcheglova) fixed a warning in a test.\n353. [Alex Prabhat Bara](https://github.com/alexprabhat99) fixed a function name in the documentation.\n354. [laterlaugh](https://github.com/laterlaugh) fixed some typos.\n355. [Yuanhao Jia](https://github.com/MrJia1997) fixed the GDB pretty printer.\n356. [Fallen_Breath](https://github.com/Fallen-Breath) fixed an example for JSON Pointer.\n357. [Nikhil Idiculla](https://github.com/tsnl) fixed some typos.\n358. [Griffin Myers](https://github.com/gmyers18) updated the Natvis file.\n359. [thetimr](https://github.com/thetimr) fixed a typo in the documentation.\n360. [Balazs Erseki](https://github.com/zerocukor287) fixed a URL in the contribution guidelines.\n361. [NiccolÃ² Iardella](https://github.com/rotolof) added `NLOHMANN_DEFINE_DERIVED_TYPE_*` macros.\n362. [Borislav Stanimirov](https://github.com/iboB) allowed overriding the CMake target name.\n363. [Captain Crutches](https://github.com/captaincrutches) made `iterator_proxy_value` a `std::forward_iterator`.\n364. [Fredrik Sandhei](https://github.com/fsandhei) added type conversion support for `std::optional`.\n365. [jh96](https://github.com/jordan-hoang) added exceptions when `nullptr` is passed to `parse`.\n366. [Stuart Gorman](https://github.com/StuartGorman) fixed number parsing when `EINTR` set in `errno`.\n367. [Dylan Baker](https://github.com/dcbaker) generated a pkg-config file that follows the pkg-config conventions.\n368. [Tianyi Chen](https://github.com/TianyiChen) optimized the binary `get_number` implementation.\n369. [peng-wang-cn](https://github.com/peng-wang-cn) added type conversion support for multidimensional arrays.\n370. [Einars Netlis-Galejs](https://github.com/EinarsNG) added `ONLY_SERIALIZE` for `NLOHMANN_DEFINE_DERIVED_TYPE_*` macros.\n371. [Marcel](https://github.com/mering) removed `alwayslink=True` Bazel flag.\n372. [Harinath Nampally](https://github.com/hnampally) added diagnostic positions to exceptions.\n373. [Nissim Armand Ben Danan](https://github.com/NissimBendanan) fixed `NLOHMANN_DEFINE_TYPE_INTRUSIVE_WITH_DEFAULT` with an empty JSON instance.\n374. [Michael Valladolid](https://github.com/codenut) added support for BSON uint64 serialization/deserialization.\n375. [Nikhil](https://github.com/nikhilreddydev) updated the documentation.\n376. [NebojÅ¡a CvetkoviÄ‡](https://github.com/nebkat) added support for BJDATA optimized binary array type.\n377. [Sushrut Shringarputale](https://github.com/sushshring) added support for diagnostic positions. \n378. [kimci86](https://github.com/kimci86) templated to `NLOHMANN_DEFINE_TYPE` macros to also support `ordered_json`.\n379. [Richard Topchii](https://github.com/richardtop) added support for VisionOS in the Swift Package Manager.\n380. [Robert Chisholm](https://github.com/Robadob) fixed a typo.\n381. [zjyhjqs](https://github.com/zjyhjqs) added CPack support.\n382. [bitFiedler](https://github.com/bitFiedler) made GDB pretty printer work with Python 3.8.\n383. [Gianfranco Costamagna](https://github.com/LocutusOfBorg) fixed a compiler warning.\n384. [risa2000](https://github.com/risa2000) made `std::filesystem::path` conversion to/from UTF-8 encoded string explicit.\n\nThanks a lot for helping out! Please [let me know](mailto:mail@nlohmann.me) if I forgot someone.\n\n## Used third-party tools\n\nThe library itself consists of a single header file licensed under the MIT license. However, it is built, tested, documented, and whatnot using a lot of third-party tools and services. Thanks a lot!\n\n- [**amalgamate.py - Amalgamate C source and header files**](https://github.com/edlund/amalgamate) to create a single header file\n- [**American fuzzy lop**](https://lcamtuf.coredump.cx/afl/) for fuzz testing\n- [**AppVeyor**](https://www.appveyor.com) for [continuous integration](https://ci.appveyor.com/project/nlohmann/json) on Windows\n- [**Artistic Style**](http://astyle.sourceforge.net) for automatic source code indentation\n- [**Clang**](https://clang.llvm.org) for compilation with code sanitizers\n- [**CMake**](https://cmake.org) for build automation\n- [**Codacy**](https://www.codacy.com) for further [code analysis](https://app.codacy.com/gh/nlohmann/json/dashboard)\n- [**Coveralls**](https://coveralls.io) to measure [code coverage](https://coveralls.io/github/nlohmann/json)\n- [**Coverity Scan**](https://scan.coverity.com) for [static analysis](https://scan.coverity.com/projects/nlohmann-json)\n- [**cppcheck**](http://cppcheck.sourceforge.net) for static analysis\n- [**doctest**](https://github.com/onqtam/doctest) for the unit tests\n- [**GitHub Changelog Generator**](https://github.com/skywinder/github-changelog-generator) to generate the [ChangeLog](https://github.com/nlohmann/json/blob/develop/ChangeLog.md)\n- [**Google Benchmark**](https://github.com/google/benchmark) to implement the benchmarks\n- [**Hedley**](https://nemequ.github.io/hedley/) to avoid re-inventing several compiler-agnostic feature macros\n- [**lcov**](https://github.com/linux-test-project/lcov) to process coverage information and create an HTML view\n- [**libFuzzer**](https://llvm.org/docs/LibFuzzer.html) to implement fuzz testing for OSS-Fuzz\n- [**Material for MkDocs**](https://squidfunk.github.io/mkdocs-material/) for the style of the documentation site\n- [**MkDocs**](https://www.mkdocs.org) for the documentation site\n- [**OSS-Fuzz**](https://github.com/google/oss-fuzz) for continuous fuzz testing of the library ([project repository](https://github.com/google/oss-fuzz/tree/master/projects/json))\n- [**Probot**](https://probot.github.io) for automating maintainer tasks such as closing stale issues, requesting missing information, or detecting toxic comments.\n- [**Valgrind**](https://valgrind.org) to check for correct memory management\n\n## Notes\n\n### Character encoding\n\nThe library supports **Unicode input** as follows:\n\n- Only **UTF-8** encoded input is supported, which is the default encoding for JSON according to [RFC 8259](https://tools.ietf.org/html/rfc8259.html#section-8.1).\n- `std::u16string` and `std::u32string` can be parsed, assuming UTF-16 and UTF-32 encoding, respectively. These encodings are not supported when reading from files or other input containers.\n- Other encodings such as Latin-1 or ISO 8859-1 are **not** supported and will yield parse or serialization errors.\n- [Unicode noncharacters](https://www.unicode.org/faq/private_use.html#nonchar1) will not be replaced by the library.\n- Invalid surrogates (e.g., incomplete pairs such as `\\uDEAD`) will yield parse errors.\n- The strings stored in the library are UTF-8 encoded. When using the default string type (`std::string`), note that its length/size functions return the number of stored bytes rather than the number of characters or glyphs.\n- When you store strings with different encodings in the library, calling [`dump()`](https://json.nlohmann.me/api/basic_json/dump/) may throw an exception unless `json::error_handler_t::replace` or `json::error_handler_t::ignore` are used as error handlers.\n- To store wide strings (e.g., `std::wstring`), you need to convert them to a UTF-8 encoded `std::string` before, see [an example](https://json.nlohmann.me/home/faq/#wide-string-handling).\n\n### Comments in JSON\n\nThis library does not support comments by default. It does so for three reasons:\n\n1. Comments are not part of the [JSON specification](https://tools.ietf.org/html/rfc8259). You may argue that `//` or `/* */` are allowed in JavaScript, but JSON is not JavaScript.\n2. This was not an oversight: Douglas Crockford [wrote on this](https://plus.google.com/118095276221607585885/posts/RK8qyGVaGSr) in May 2012:\n  \n    > I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability.  I know that the lack of comments makes some people sad, but it shouldn't.\n    >\n    > Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.\n  \n3. It is dangerous for interoperability if some libraries would add comment support while others don't. Please check [The Harmful Consequences of the Robustness Principle](https://tools.ietf.org/html/draft-iab-protocol-maintenance-01) on this.\n\nHowever, you can set set parameter `ignore_comments` to true in the `parse` function to ignore `//` or `/* */` comments. Comments will then be treated as whitespace.\n\n### Trailing commas\n\nThe JSON specification does not allow trailing commas in arrays and objects, and hence this library is treating them as parsing errors by default.\n\nLike comments, you can set parameter `ignore_trailing_commas` to true in the `parse` function to ignore trailing commas in arrays and objects. Note that a single comma as the only content of the array or object (`[,]` or `{,}`) is not allowed, and multiple trailing commas (`[1,,]`) are not allowed either.\n\nThis library does not add trailing commas when serializing JSON data.\n\nFor more information, see [JSON With Commas and Comments (JWCC)](https://nigeltao.github.io/blog/2021/json-with-commas-comments.html).\n\n### Order of object keys\n\nBy default, the library does not preserve the **insertion order of object elements**. This is standards-compliant, as the [JSON standard](https://tools.ietf.org/html/rfc8259.html) defines objects as \"an unordered collection of zero or more name/value pairs\".\n\nIf you do want to preserve the insertion order, you can try the type [`nlohmann::ordered_json`](https://github.com/nlohmann/json/issues/2179). Alternatively, you can use a more sophisticated ordered map like [`tsl::ordered_map`](https://github.com/Tessil/ordered-map) ([integration](https://github.com/nlohmann/json/issues/546#issuecomment-304447518)) or [`nlohmann::fifo_map`](https://github.com/nlohmann/fifo_map) ([integration](https://github.com/nlohmann/json/issues/485#issuecomment-333652309)).\n\nSee the [**documentation on object order**](https://json.nlohmann.me/features/object_order/) for more information.\n\n### Memory Release\n\nWe checked with Valgrind and the Address Sanitizer (ASAN) that there are no memory leaks.\n\nIf you find that a parsing program with this library does not release memory, please consider the following case, and it may be unrelated to this library.\n\n**Your program is compiled with glibc.** There is a tunable threshold that glibc uses to decide whether to actually return memory to the system or whether to cache it for later reuse. If in your program you make lots of small allocations and those small allocations are not a contiguous block and are presumably below the threshold, then they will not get returned to the OS.\nHere is a related issue [#1924](https://github.com/nlohmann/json/issues/1924).\n\n### Further notes\n\n- The code contains numerous debug **assertions** which can be switched off by defining the preprocessor macro `NDEBUG`, see the [documentation of `assert`](https://en.cppreference.com/w/cpp/error/assert). In particular, note [`operator[]`](https://json.nlohmann.me/api/basic_json/operator%5B%5D/) implements **unchecked access** for const objects: If the given key is not present, the behavior is undefined (think of a dereferenced null pointer) and yields an [assertion failure](https://github.com/nlohmann/json/issues/289) if assertions are switched on. If you are not sure whether an element in an object exists, use checked access with the [`at()` function](https://json.nlohmann.me/api/basic_json/at/). Furthermore, you can define `JSON_ASSERT(x)` to replace calls to `assert(x)`. See the [**documentation on runtime assertions**](https://json.nlohmann.me/features/assertions/) for more information.\n- As the exact number type is not defined in the [JSON specification](https://tools.ietf.org/html/rfc8259.html), this library tries to choose the best fitting C++ number type automatically. As a result, the type `double` may be used to store numbers which may yield [**floating-point exceptions**](https://github.com/nlohmann/json/issues/181) in certain rare situations if floating-point exceptions have been unmasked in the calling code. These exceptions are not caused by the library and need to be fixed in the calling code, such as by re-masking the exceptions prior to calling library functions.\n- The code can be compiled without C++ **runtime type identification** features; that is, you can use the `-fno-rtti` compiler flag.\n- **Exceptions** are used widely within the library. They can, however, be switched off with either using the compiler flag `-fno-exceptions` or by defining the symbol `JSON_NOEXCEPTION`. In this case, exceptions are replaced by `abort()` calls. You can further control this behavior by defining `JSON_THROW_USER` (overriding `throw`), `JSON_TRY_USER` (overriding `try`), and `JSON_CATCH_USER` (overriding `catch`). Note that `JSON_THROW_USER` should leave the current scope (e.g., by throwing or aborting), as continuing after it may yield undefined behavior. Note the explanatory [`what()`](https://en.cppreference.com/w/cpp/error/exception/what) string of exceptions is not available for MSVC if exceptions are disabled, see [#2824](https://github.com/nlohmann/json/discussions/2824). See the [**documentation of exceptions**](https://json.nlohmann.me/home/exceptions/) for more information.\n\n## Execute unit tests\n\nTo compile and run the tests, you need to execute\n\n```shell\nmkdir build\ncd build\ncmake .. -DJSON_BuildTests=On\ncmake --build .\nctest --output-on-failure\n```\n\nNote that during the `ctest` stage, several JSON test files are downloaded from an [external repository](https://github.com/nlohmann/json_test_data). If policies forbid downloading artifacts during testing, you can download the files yourself and pass the directory with the test files via `-DJSON_TestDataDirectory=path` to CMake. Then, no Internet connectivity is required. See [issue #2189](https://github.com/nlohmann/json/issues/2189) for more information.\n\nIf the testdata is not found, several test suites will fail like this:\n\n```\n===============================================================================\njson/tests/src/make_test_data_available.hpp:21:\nTEST CASE:  check test suite is downloaded\n\njson/tests/src/make_test_data_available.hpp:23: FATAL ERROR: REQUIRE( utils::check_testsuite_downloaded() ) is NOT correct!\n  values: REQUIRE( false )\n  logged: Test data not found in 'json/cmake-build-debug/json_test_data'.\n          Please execute target 'download_test_data' before running this test suite.\n          See <https://github.com/nlohmann/json#execute-unit-tests> for more information.\n\n===============================================================================\n```\n\nIn case you have downloaded the library rather than checked out the code via Git, test `cmake_fetch_content_configure` will fail. Please execute `ctest -LE git_required` to skip these tests. See [issue #2189](https://github.com/nlohmann/json/issues/2189) for more information.\n\nSome tests are requiring network to be properly execute. They are labeled as `git_required`. Please execute `ctest -LE git_required` to skip these tests. See [issue #4851](https://github.com/nlohmann/json/issues/4851) for more information.\n\nSome tests change the installed files and hence make the whole process not reproducible. Please execute `ctest -LE not_reproducible` to skip these tests. See [issue #2324](https://github.com/nlohmann/json/issues/2324) for more information. Furthermore, assertions must be switched off to ensure reproducible builds (see [discussion 4494](https://github.com/nlohmann/json/discussions/4494)).\n\nNote you need to call `cmake -LE \"not_reproducible|git_required\"` to exclude both labels. See [issue #2596](https://github.com/nlohmann/json/issues/2596) for more information.\n\nAs Intel compilers use unsafe floating point optimization by default, the unit tests may fail. Use flag [`/fp:precise`](https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/2021-8/fp-model-fp.html) then.\n",
      "stars_today": 15
    },
    {
      "id": 214011414,
      "name": "WindTerm",
      "full_name": "kingToolbox/WindTerm",
      "description": "A professional cross-platform SSH/Sftp/Shell/Telnet/Tmux/Serial terminal.",
      "html_url": "https://github.com/kingToolbox/WindTerm",
      "stars": 29392,
      "forks": 2271,
      "language": "C",
      "topics": [
        "bash",
        "client",
        "cmd",
        "linux",
        "mac",
        "powershell",
        "serial",
        "sftp",
        "shell",
        "ssh",
        "telnet",
        "terminal",
        "tmux",
        "windows",
        "wsl",
        "x11",
        "xmodem",
        "xterm",
        "ymodem",
        "zmodem"
      ],
      "created_at": "2019-10-09T19:56:09Z",
      "updated_at": "2026-01-16T00:39:43Z",
      "pushed_at": "2025-03-11T19:12:09Z",
      "open_issues": 2431,
      "owner": {
        "login": "kingToolbox",
        "avatar_url": "https://avatars.githubusercontent.com/u/51009775?v=4"
      },
      "readme": "# WindTerm\nA Quicker and better SSH/Telnet/Serial/Shell/Sftp client for DevOps.\n\n_Hello WindTerm :rose:, hello world!_\n\n**We're just beginning! If you want a high performance text editor, you can try [WindEdit](https://www.github.com/kingToolbox/WindEdit/).**\n\n# License\n**Completely FREE for commercial and non-commercial use without limitations.**\n**All released source codes (except thirdparty directory) are provided under the terms of Apache-2.0 license.**\n\n# Introduction\n\nSee [Intro Videos](https://kingtoolbox.github.io)\n\n# Download\n\n**Linux binary**, **MacOS binary** and **Windows binary**: https://github.com/kingToolbox/WindTerm/releases\n\n# Source Code\n\nWindTerm is a **partial** open source project, and the source will be gradually opened.\n\nOpen source code includes, but is not limited to, the classes that can be used independently, such as functional, algorithms, gui widgets, etc., as well as functional libraries, such as network, protocols, etc., as well as all types that require open source according to the license.\n\n# Issues and feature requests\n\nAny issues and feature requests are welcome.\n\nPlease click [issues](https://github.com/kingToolbox/WindTerm/issues) to commit an issue or a feature request.\n\nPlease click [Discussion](https://github.com/kingToolbox/WindTerm/discussions) to discuss anything about SSH, SFtp, Shell(Linux shell, Windows cmd and powershell), Telnet, Serial and WindTerm.\n\n# Screenshots\n\nMain Window (zsh):\n\n![MainWindow](https://github.com/kingToolbox/WindTerm/blob/master/images/screenshots/WindTerm.png)\n\nSplit views:\n\n![SplitView](https://github.com/kingToolbox/WindTerm/blob/master/images/screenshots/SplitView.png)\n\nDigeWhite Theme:\n\n![DigeWhite Theme](https://github.com/kingToolbox/WindTerm/blob/master/images/screenshots/WindTerm_DigeWhite_Theme.png)\n\n# Features\n\n### SSH, Telnet, Tcp, Shell, Serial, Tmux\n- SSH v2, Telnet, Raw Tcp, Serial, Shell protocols implemented. [Intro Video](https://kingtoolbox.github.io/2020/01/22/new-session/)\n- Supports SSH auto execution when session authenticated.\n- Supports SSH ControlMaster.\n- Supports SSH ProxyCommand or ProxyJump. [Intro Video](https://kingtoolbox.github.io/2021/03/11/proxycommand/)\n- Supports SSH agent. [Intro Video](https://kingtoolbox.github.io/2020/08/22/ssh_agent/)\n- Supports SSH agent forwarding.\n- Supports SSH auto login with password, public-key, keyboard-interactive, gssapi-with-mic. [Intro Video](https://kingtoolbox.github.io/2020/01/23/auto-login/)\n- Supports X11 forwarding. [Intro Video](https://kingtoolbox.github.io/2020/07/21/x11_forwarding/)\n- Supports direct/local port forwarding, reverse/remote port forwarding and dynamic port forwarding. [Intro Video](https://kingtoolbox.github.io/2020/07/21/port_forwarding/)\n- Supports XModem, YModem and ZModem. [Intro Video](https://kingtoolbox.github.io/tags/modem/)\n- Integrated sftp, scp client, supports download, upload, remove, rename, make new file/directory and so on. [Intro Video](https://kingtoolbox.github.io/tags/transfer/)\n- Integrated local file manager, supports move to, copy to, copy from, remove, rename, make new file/directory and so on.\n- Supports Windows Cmd, PowerShell and Cmd, PowerShell as administrator.\n- Supports Linux bash, zsh, powershell core and so on.\n- Supports MacOS bash, zsh, powershell core and so on.\n- **Supports `tmux integration`**. [Intro Video](https://kingtoolbox.github.io/2025/01/05/tmux-integration/)\n### GUI\n- **Supports Windows, MacOS and Linux.**\n- **Supports Multilingual User Interface.**\n- Supports Unicode 13.\n- Session dialog and session tree. [Intro Video](https://kingtoolbox.github.io/2020/01/22/manage-sessions/)\n- **Auto Completion.** [Intro Video](https://kingtoolbox.github.io/tags/auto-completion/)\n- **Free Type Mode.** [Intro Video](https://kingtoolbox.github.io/2022/04/12/free_type_mode/)\n- **Focus Mode.** [Intro Video](https://kingtoolbox.github.io/2021/06/28/ui_focus_mode/)\n- **Sync Input.** [Intro Video](https://kingtoolbox.github.io/2021/05/27/sync-input/)\n- **Enhanced protection of the session username and password.** [Intro Video](https://kingtoolbox.github.io/2021/03/11/protection-username-password/)\n- **Command palette.** [Intro Video](https://kingtoolbox.github.io/tags/command-palette/)\n- **Command sender.** [Intro Video](https://kingtoolbox.github.io/tags/sender/)\n- **Explorer Pane.** [Intro Video](https://kingtoolbox.github.io/2021/05/27/explorer/)\n- **Shell Pane.**\n- **Quick Bar.** [Intro Video](https://kingtoolbox.github.io/2020/08/22/quickbar/)\n- **Paste Dialog.** [Intro Video](https://kingtoolbox.github.io/2020/08/22/paste_dialog/)\n- **Local and remote modes with vim keybindings. (Using Shift+Enter key to switch between remote and local mode**) [Intro Video](https://kingtoolbox.github.io/2020/06/21/keyboard-modes/)\n- Supports time stamp, folding, outlining, split views.\n- **Supports powerline in Linux and PowerShell, e.g. Oh-My-Zsh, Oh-My-Posh.** [Intro Image](https://github.com/kingToolbox/WindTerm#screenshots)\n- Supports color schemes like vscode. [Intro Video](https://kingtoolbox.github.io/2020/01/23/highlight/)\n- Supports searching and previewing. [Intro Video](https://kingtoolbox.github.io/2020/01/22/search-and-mark/)\n- Supports highlighting the opening and closing delimiter, such as (), [], {} and the customed delimiters. [Intro Video](https://kingtoolbox.github.io/2020/06/28/pair/)\n- Supports changing the UI theme. [Intro Video](https://kingtoolbox.github.io/2020/09/18/theme/)\n- Supports setting the tab color. [Intro Video](https://kingtoolbox.github.io/2020/09/18/tabbar-change-tabcolor/)\n- Supports searching over the opened tabs. [Intro Video](https://kingtoolbox.github.io/2021/03/11/tabbar-search-tab/)\n- Supports closing tabs to the right.\n- Supports setting the windows transparency. [Intro video](https://kingtoolbox.github.io/2020/11/13/windows-opacity/)\n- Supports select-to-copy, right-click-to-paste or middle-click-to-paste.\n- Supports searching text online with Google, Bing, Github, Stackoverflow, Wikipedia and DuckDuckGo. [Intro video](https://kingtoolbox.github.io/2020/11/13/search-online/)\n- Supports hiding mouse cursor while typing.\n- **Supports locking screen.** [Intro video](https://kingtoolbox.github.io/2021/04/23/lock-screen/)\n### Term\n- Supports vt100, vt220, vt340, vt420, vt520, xterm, xterm-256-colors.\n- Supports unicode, emojis, true-color, mouse protocol, etc.\n- Supports auto wrap mode. [Intro Video](https://kingtoolbox.github.io/2020/01/22/auto-wrap/)\n- Protocols and terms can be customed.\n- All vttest tests have passed except Tektronix 4014.\n### Session\n- **Supports HTTP and SOCKS5 proxy.** [Intro Video](https://kingtoolbox.github.io/2021/03/11/proxy-http-socks5/)\n- **Supports Jump Server proxy.** [Intro Video](https://kingtoolbox.github.io/2021/03/11/proxy-jump-server/)\n- Supports manual and automated session logging. [Intro Video](https://kingtoolbox.github.io/tags/logging/)\n- Rename and duplicate session. [Intro Video](https://kingtoolbox.github.io/tags/tabbar/)\n- Restore last sessions and layouts when restart. [Intro Video](https://kingtoolbox.github.io/2020/01/22/restore-sessions/)\n- Supports opening a specific session or set of sessions on startup.\n### Performance\n- Dynamic memory compression, typically `20%` to `90%` of the working memory load can be reduced.\n- High performance, low memory, low latency. [Intro Video](https://kingtoolbox.github.io/2020/01/23/windterm-putty-performance/)\n\n# Sftp Performance\n\nThe hardware used for generating the data in these benchmarks was\n\n    windows 10 - 2.3 GHz Intel Core i5 and 8GB memory.\n\n**WindTerm1.72, WindTerm 1.2, FileZilla 3.48.1, WinSCP 5.17.2 (Build 10278)** tests are performed on WSL(Ubuntu 18.04.2). \n\nThe version of clients:\n\n| Application | Version | Release Date |\n| --- | --- | --- |\n| windterm | v1.72 | 2020-10-25 |\n| windterm | v1.2 | 2020-06-15 |\n| FileZilla | v3.48.1 | 2020-05-19 |\n| WinScp | v5.17.2 (Build 10278) | 2020-03-09 |\n\n**All test data is for reference only.**\n\n### 5GB huge file (5,154,830 KB), generated by random data\n\n| | Download Time | Download Rate | Upload Time | Upload Rate |\n| --- | --- | --- | --- | --- |\n| WindTerm 1.72 (Use high speed transfer) | **23s** | **216.3 MB/s** | **20s** | **247.0 MB/s** |\n| WindTerm 1.72 | **23s** | **214.7 MB/s** | **20s** | **244.0 MB/s** |\n| WindTerm 1.2 | 37s | 139.3 MB/s | 43s | 119.9 MB/s |\n| FileZilla | 32s | 161.1 MB/s | 30s | 171.8 MB/s |\n| WinSCP | 81s | 63.7 MB/s | 91s | 56.7 MB/s |\n\n### 4400 files, 16 folders (107,042 KB), unzipped from [vim-7.4.1049.zip](https://github.com/vim/vim/archive/v7.4.1049.zip)\n\n| | Download Time | Download Rate | Upload Time | Upload Rate |\n| --- | --- | --- | --- | --- |\n| WindTerm 1.7 | **26s** | **3.9 MB/s** | 13s | 8.1 MB/s |\n| WindTerm 1.2 | 32s | 3.4 MB/s | **10s** | **10.7 MB/s** |\n| FileZilla | 48s | 2.2 MB/s | 35s | 3.1 MB/s |\n| WinSCP | 42s | 2.6 MB/s | 12s | 8.9 MB/s |\n\n# Terminal Performance\n\nThe hardware used for generating the data in these benchmarks was\n\n    windows 10 - 2.3 GHz Intel Core i5 and 8GB memory.\n    MacOs 10.13 - 2.3 GHz Intel Core i5 and 8GB memory.\n\n**WindTerm 1.72, rxvt, putty, xterm, Windows Terminal** tests are performed on WSL(Ubuntu 18.04.2). \n\n**Iterm2, kitty, Alacritty** tests are performed on MacOS shell, \n\n    For WindTerm: No color scheme used in windterm. Color scheme will result in approximately 2% loss and more memory usage.\n\n    For Alacritty: Only supports up to 100,000 scrollback lines, so every test use \"history: 100000\" setting and no memory usage measured.\n\n    For Windows Terminal: Only supports up to 65,535 scrollback lines, so every test use \"historySize: 65535\" setting and no memory usage measured. \n\nThe version of terminals:\n\n| Application | Version | Release Date |\n| --- | --- | --- |\n| windterm | v1.72 | 2020-10-25 |\n| rxvt-unicode | v9.2.2 | 2016-05-14 |\n| putty | v0.71 | 2019-03-16 |\n| xterm | v3.30 | 2017-06-20 |\n| iterm2 | v3.3.6 | 2019-10-09 |\n| alacritty | v0.5.0 | 2020-07-21 |\n| kitty | v0.14.6 | 2019-09-25 |\n| Windows Terminal | v1.3.2651.0 | 2020-09-22 |\n\n**All test data is for reference only.**\n\n## Test Command: \"cat ./benchmark_randomdata\"\n\nThe benchmark_randomdata contains 97.6MB random text (102,401,504 bytes, 1,329,878 lines, generated and tested by [random_test.sh](https://github.com/kingToolbox/WindTerm/blob/master/benchmark/urandom_test.sh))\n\nIn all cases, three runs were made to warm system caches. The reported numbers are the median of five runs. \n\n1. Telnet:\n\n| | Lines of scrollback | Data Rate(MB/sec) | Memory Usage(MB) |\n| --- | --- | --- | --- |\n| WindTerm | unlimited | **52.1** | **106.6** |\n| rxvt | 1,350,000 | 37.8 | 842.2 | \n| Putty | 1,350,000 | 4.9 | 733.4 |\n| xterm | 1,350,000 | 2.2 | 3328.4 |\n| Windows Terminal + telnet.exe | 65,535 | 0.1 | Not measured, use 65,535 scrollback lines setting |\n\n2. SSH:\n\n| | Lines of scrollback | Data Rate(MB/sec) | Memory Usage(MB) |\n| --- | --- | --- | --- |\n| WindTerm | unlimited | **41.8** | **108.5** |\n| rxvt | 1,350,000 | 40.2 | 842.2 | \n| Putty | 1,350,000 | 4.8 | 734.9 |\n| xterm | 1,350,000 | 2.3 | 3328.4 |\n| Windows Terminal + ssh.exe | 65,535 | 2.1 | Not measured, use 65,535 scrollback lines setting |\n\n3. Shell:\n\n| | Lines of scrollback | Data Rate(MB/sec) | Memory Usage(MB) |\n| --- | --- | --- | --- |\n| iterm2 | unlimited | - (Take too long time) | more than 1300 |\n| kitty | unlimited | 17.2 | 2655 |\n| Alacritty | 100,000 | 41.3 | - |\n\n## Test command: \"time seq 1 n\" (n = [1000000, 2000000, 5000000, 10000000], scrollback lines: unlimited)\n\n### n = 1,000,000\n\n| | Time(sec) | Memory Usage(MB) |\n| --- | --- | --- |\n| WindTerm | 1.236 | **16.1** |\n| rxvt | 5.082 | 633.3 |\n| putty | 4.161 | 551.1 |\n| xterm | 40.421 | 2500.7 |\n| iterm2 | 2.116 | 146.3 |\n| Kitty | 2.535 | 2376.5 |\n| Alacritty | **1.162** | Not measured, use 100,000 scrollback lines setting |\n| Windows Terminal + ssh.exe | 23.246 | Not measured, use 65,535 scrollback lines setting |\n\n### n = 2,000,000\n\n| | Time(sec) | Memory Usage(MB) |\n| --- | --- | --- |\n| WindTerm | **2.287** | **24.1** |\n| rxvt | 10.896 | 1266.6 |\n| putty | 16.045 | 1102.6 |\n| xterm | 68.154 | 5005.5 |\n| iterm2 | 4.181 | 383.2 |\n| Kitty | 5.620 | 4749.9 |\n| Alacritty | 2.322 | Not measured, use 100,000 scrollback lines setting |\n| Windows Terminal + ssh.exe | 50.381 | Not measured, use 65,535 scrollback lines setting |\n\n### n = 5,000,000\n\n| | Time(sec) | Memory Usage(MB) |\n| --- | --- | --- |\n| WindTerm | **5.520** | **68.2** |\n| rxvt | 27.533 | 3166.2 |\n| putty | 45.911 | 2757.1 |\n| xterm | - | Out of memory |\n| iterm2 | 10.805 | 1048.3 |\n| Kitty | - | Out of memory |\n| Alacritty | 5.799 | Not measured, use 100,000 scrollback lines setting |\n| Windows Terminal + ssh.exe | 130.371 | Not measured, use 65,535 scrollback lines setting |\n\n### n = 10,000,000\n\n| | Time(sec) | Memory Usage(MB) |\n| --- | --- | --- |\n| WindTerm | **10.674** | **133.3** |\n| rxvt | - | Out of memory |\n| putty | - | Out of memory |\n| xterm | - | Out of memory |\n| iterm2 | 20.468 | 2231.3 |\n| Kitty | - | Out of memory |\n| Alacritty | 11.598 | Not measured, use 100,000 scrollback lines setting |\n| Windows Terminal + ssh.exe | 264.739 | Not measured, use 65,535 scrollback lines setting |\n\n### n = 10,000,000 scrollback = 30 Lines\n\n| | Time(sec) | Memory Usage(MB) |\n| --- | --- | --- |\n| WindTerm | 10.167 | 0.7 |\n| rxvt | **9.687** | **0.1** |\n| putty | 95.382 | 0.4 |\n| xterm | 286.510 | **0.1** |\n| iterm2 | 25.448 | 7.4 |\n| Kitty | 16.104 | 0.5 |\n| Alacritty | 11.798 | Not measured, use zero scrollback lines setting |\n| Windows Terminal + ssh.exe | 261.096 | Not measured, use zero scrollback lines setting |\n\n# Linux Terminal Performance\n\nThe hardware used for generating the data in these benchmarks was\n\n    Debian 10 Vm - 4cpu and 4GB memory.\n\n    For WindTerm: No color scheme used in windterm. Color scheme will result in approximately 2% loss and more memory usage.\n\n    For other terminals: No memory usage measured because most of them write the history to disk or only support a limited number of lines in memory..\n\nThe version of terminals:\n\n| Application | Version | Release Date |\n| --- | --- | --- |\n| Windterm | v1.9 | 2020-12-22 |\n| Gnome | v3.30.2 | 2018-10-22 |\n| Mate Terminal | v1.20.2 | 2019-02-11 |\n| Konsole | v18.04.0 | 2019-04-12 |\n| Xfce4 Terminal | v0.8.7.4 | 2018-5-15 |\n| QTerminal | v0.14.1 | 2019-01-26 |\n\n**All test data is for reference only.**\n\n## Test Command: \"cat ./benchmark_randomdata\"\n\nThe benchmark_randomdata contains 97.6MB random text (102,401,504 bytes, 1,329,878 lines, generated and tested by [random_test.sh](https://github.com/kingToolbox/WindTerm/blob/master/benchmark/urandom_test.sh))\n\nIn all cases, three runs were made to warm system caches. The reported numbers are the median of five runs. \n\n| | Cost Time |\n| --- | --- |\n| WindTerm | **1.976s** |\n| Gnome Terminal  | 9.781s |\n| Mate Terminal  | 9.841s |\n| Konsole | 25.050s |\n| xfce4 Terminal | 10.520s |\n| QTerminal | 20.763s |\n\n## Test command: \"time seq 1 n\" (n = [1000000, 2000000, 5000000, 10000000], scrollback lines: unlimited)\n\n| n | 1,000,000 | 2,000,000 | 5,000,000 | 10,000,000 | 10,000,000<br>(scrollback lines: 100) |\n| --- | --- | --- | --- | --- | --- |\n| WindTerm | 0.846s (18.6MB) | **1.574s** (26.6MB) | **4.046s** (56.4MB) | **8.232s** (102.2MB) | **7.748s** (3.4MB) | \n| Gnome Terminal  | 0.920s | 2.152s | 5.271s | 11.111s | 13.109s |\n| Mate Terminal  | **0.822s** | 1.698s | 5.943s | 10.920s | 12.290s |\n| Konsole | 1.612s | 3.199s | 8.157s | 16.029s | 15.650s |\n| xfce4 Terminal | 0.870s | 2.160s | 5.866s | 12.089s | 13.304s |\n| QTerminal | 9.272s | 18.391s | 45.999s | 104.277s | 17.208s |\n\n# Latency\n\nConsidering the network influence on the latency, the following data is from [WindEdit](https://github.com/kingToolbox/digedit).\nDIGEdit is the text component of WindTerm.\n\n|   | Min | Max | Avg | SD |\n| --- | --- | --- | --- | --- |\n|WindEdit| 1.9 | 7.6 | 2.9 | 0.8 |\n|Windows Notepad | 0.9 | 16.5 | 7.8 | 1.8 |\n|GVim | 0.9 | 10.4 | 2.8 | 1.2 |\n\n# Shortcuts\n\n[Shortcut Keys List](https://kingtoolbox.github.io/tags/keyboard/)\n\n# Roadmap\n\n**Release cycle:**\n\n  2-3 months.\n  \n**Prerelease cycle:**\n\n  4~6 weeks\n\n# Roadmap of v2.7 (February 2025, for reference only)\n- **Resolve issues as much as possible**\n- SSH Agent Forwaring\n- Tmux integration\n- Command Snippet [Description](https://github.com/kingToolbox/WindTerm/issues/239#issuecomment-951934488)  (Postponed to a later version )\n- SSH GSSAPI Authentication (Postponed to a later version )\n- Search in sessions (Postponed to a later version )\n\nDownload: [WindTerm 2.7.0 Prerelease 3](https://github.com/kingToolbox/WindTerm/releases/tag/2.7-prerelease-3) (2025-2-10)\n\n**Roadmap of version 2.x:**\n- External tools\n- Protocols:\n  - Mosh\n  - Rlogin\n- Session:\n  - Auto Complete\n  - Chat mode\n  - Log viewer\n- File transfer:\n  - ftp, ftps\n- Script, macro and plugin stystem\n- More ...\n\n**Release Schedule:**\nVersion | Level | Target | Status | Timeline\n------------ | ------------- | -------------- | ---------- | -----------\nv0.x | Basic | Basic framework and basic features, but complete a high-performance text editor ([WindEdit](https://github.com/kingToolbox/WindEdit))  as the base, and be able to use them normally.  | Finished | Long long ago ~ Sprint of 2020\nv1.x | Manual | Perfect features and can be used by most developers in their daily work | Finished | Spring of 2020 ~ Winter of 2020 \n**v2.x** | **Semi automatic** | **Through triggers, macros, events, notifications and so on, developers can be assisted to complete some operations.** | **Developing** | **Spring of 2021 ~ Summer of 2022**\nv3.x | Fully automatic | Through plugins, scripts, machine learning and so on, automatically operating with achieving non-attended | Planning | Summer of 2022 ~ Winter of 2023\n\n# Acknowledgement\n|            | Contribution  |\n| ---------- | ------------- |\n| [EvoWebFrance](https://github.com/EvoWebFrance) | French translation |\n| [kvnklk](https://github.com/kvnklk) | German translation |\n| [Lemonawa](https://github.com/Lemonawa) | Simplified Chinese translation |\n| [LuxNegra](https://github.com/LuxNegra) | French translation |\n| [MosamXu](https://github.com/MosamXu) | Simplified Chinese translation |\n",
      "stars_today": 15
    },
    {
      "id": 607441698,
      "name": "lancedb",
      "full_name": "lancedb/lancedb",
      "description": "Developer-friendly OSS embedded retrieval library for multimodal AI. Search More; Manage Less.",
      "html_url": "https://github.com/lancedb/lancedb",
      "stars": 8501,
      "forks": 705,
      "language": "Rust",
      "topics": [
        "approximate-nearest-neighbor-search",
        "image-search",
        "nearest-neighbor-search",
        "recommender-system",
        "search-engine",
        "semantic-search",
        "similarity-search",
        "vector-database"
      ],
      "created_at": "2023-02-28T01:15:17Z",
      "updated_at": "2026-01-16T00:10:46Z",
      "pushed_at": "2026-01-15T17:46:55Z",
      "open_issues": 533,
      "owner": {
        "login": "lancedb",
        "avatar_url": "https://avatars.githubusercontent.com/u/108903835?v=4"
      },
      "readme": "<a href=\"https://cloud.lancedb.com\" target=\"_blank\">\n  <img src=\"https://github.com/user-attachments/assets/92dad0a2-2a37-4ce1-b783-0d1b4f30a00c\" alt=\"LanceDB Cloud Public Beta\" width=\"100%\" style=\"max-width: 100%;\">\n</a>\n<div align=\"center\">\n\n[![LanceDB](docs/src/assets/hero-header.png)](https://lancedb.com)\n[![Website](https://img.shields.io/badge/-Website-100000?style=for-the-badge&labelColor=645cfb&color=645cfb)](https://lancedb.com/)\n[![Blog](https://img.shields.io/badge/Blog-100000?style=for-the-badge&labelColor=645cfb&color=645cfb)](https://blog.lancedb.com/)\n[![Discord](https://img.shields.io/badge/-Discord-100000?style=for-the-badge&logo=discord&logoColor=white&labelColor=645cfb&color=645cfb)](https://discord.gg/zMM32dvNtd)\n[![Twitter](https://img.shields.io/badge/-Twitter-100000?style=for-the-badge&logo=x&logoColor=white&labelColor=645cfb&color=645cfb)](https://twitter.com/lancedb)\n[![LinkedIn](https://img.shields.io/badge/-LinkedIn-100000?style=for-the-badge&logo=linkedin&logoColor=white&labelColor=645cfb&color=645cfb)](https://www.linkedin.com/company/lancedb/)\n\n\n<img src=\"docs/src/assets/lancedb.png\" alt=\"LanceDB\" width=\"50%\">\n\n# **The Multimodal AI Lakehouse**\n\n[**How to Install** ](#how-to-install) âœ¦ [**Detailed Documentation**](https://lancedb.com/docs) âœ¦ [**Tutorials and Recipes**](https://github.com/lancedb/vectordb-recipes/tree/main) âœ¦  [**Contributors**](#contributors) \n\n**The ultimate multimodal data platform for AI/ML applications.** \n\nLanceDB is designed for fast, scalable, and production-ready vector search. It is built on top of the Lance columnar format. You can store, index, and search over petabytes of multimodal data and vectors with ease. \nLanceDB is a central location where developers can build, train and analyze their AI workloads.\n\n</div>\n\n<br>\n\n## **Demo: Multimodal Search by Keyword, Vector or with SQL**\n<img max-width=\"750px\" alt=\"LanceDB Multimodal Search\" src=\"https://github.com/lancedb/lancedb/assets/917119/09c5afc5-7816-4687-bae4-f2ca194426ec\">\n\n## **Star LanceDB to get updates!**\n\n<details>\n<summary>â­ Click here â­  to see how fast we're growing!</summary>\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=lancedb/lancedb&theme=dark&type=Date\">\n  <img width=\"100%\" src=\"https://api.star-history.com/svg?repos=lancedb/lancedb&theme=dark&type=Date\">\n</picture>\n</details>\n\n## **Key Features**:\n\n- **Fast Vector Search**: Search billions of vectors in milliseconds with state-of-the-art indexing.\n- **Comprehensive Search**: Support for vector similarity search, full-text search and SQL.\n- **Multimodal Support**: Store, query and filter vectors, metadata and multimodal data (text, images, videos, point clouds, and more).\n- **Advanced Features**: Zero-copy, automatic versioning, manage versions of your data without needing extra infrastructure. GPU support in building vector index.\n\n### **Products**:\n- **Open Source & Local**: 100% open source, runs locally or in your cloud. No vendor lock-in.\n- **Cloud and Enterprise**: Production-scale vector search with no servers to manage. Complete data sovereignty and security.\n\n### **Ecosystem**:\n- **Columnar Storage**: Built on the Lance columnar format for efficient storage and analytics.\n- **Seamless Integration**: Python, Node.js, Rust, and REST APIs for easy integration. Native Python and Javascript/Typescript support.\n- **Rich Ecosystem**: Integrations with [**LangChain** ğŸ¦œï¸ğŸ”—](https://python.langchain.com/docs/integrations/vectorstores/lancedb/), [**LlamaIndex** ğŸ¦™](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/LanceDBIndexDemo.html), Apache-Arrow, Pandas, Polars, DuckDB and more on the way.\n\n## **How to Install**:\n\nFollow the [Quickstart](https://lancedb.com/docs/quickstart/) doc to set up LanceDB locally. \n\n**API & SDK:** We also support Python, Typescript and Rust SDKs\n\n| Interface | Documentation |\n|-----------|---------------|\n| Python SDK | https://lancedb.github.io/lancedb/python/python/ |\n| Typescript SDK | https://lancedb.github.io/lancedb/js/globals/ |\n| Rust SDK | https://docs.rs/lancedb/latest/lancedb/index.html |\n| REST API | https://docs.lancedb.com/api-reference/introduction |\n\n## **Join Us and Contribute**\n\nWe welcome contributions from everyone! Whether you're a developer, researcher, or just someone who wants to help out. \n\nIf you have any suggestions or feature requests, please feel free to open an issue on GitHub or discuss it on our [**Discord**](https://discord.gg/G5DcmnZWKB) server.\n\n[**Check out the GitHub Issues**](https://github.com/lancedb/lancedb/issues) if you would like to work on the features that are planned for the future. If you have any suggestions or feature requests, please feel free to open an issue on GitHub. \n\n## **Contributors**\n\n<a href=\"https://github.com/lancedb/lancedb/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=lancedb/lancedb\" />\n</a>\n\n\n## **Stay in Touch With Us**\n<div align=\"center\">\n\n</br>\n\n[![Website](https://img.shields.io/badge/-Website-100000?style=for-the-badge&labelColor=645cfb&color=645cfb)](https://lancedb.com/)\n[![Blog](https://img.shields.io/badge/Blog-100000?style=for-the-badge&labelColor=645cfb&color=645cfb)](https://blog.lancedb.com/)\n[![Discord](https://img.shields.io/badge/-Discord-100000?style=for-the-badge&logo=discord&logoColor=white&labelColor=645cfb&color=645cfb)](https://discord.gg/zMM32dvNtd)\n[![Twitter](https://img.shields.io/badge/-Twitter-100000?style=for-the-badge&logo=x&logoColor=white&labelColor=645cfb&color=645cfb)](https://twitter.com/lancedb)\n[![LinkedIn](https://img.shields.io/badge/-LinkedIn-100000?style=for-the-badge&logo=linkedin&logoColor=white&labelColor=645cfb&color=645cfb)](https://www.linkedin.com/company/lancedb/)\n\n</div>\n",
      "stars_today": 15
    },
    {
      "id": 860100131,
      "name": "typescript-go",
      "full_name": "microsoft/typescript-go",
      "description": "Staging repo for development of native port of TypeScript",
      "html_url": "https://github.com/microsoft/typescript-go",
      "stars": 23747,
      "forks": 796,
      "language": "Go",
      "topics": [],
      "created_at": "2024-09-19T20:25:12Z",
      "updated_at": "2026-01-16T00:05:41Z",
      "pushed_at": "2026-01-16T00:05:39Z",
      "open_issues": 264,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# TypeScript 7\n\n[Not sure what this is? Read the announcement post!](https://devblogs.microsoft.com/typescript/typescript-native-port/)\n\n## Preview\n\nA preview build is available on npm as [`@typescript/native-preview`](https://www.npmjs.com/package/@typescript/native-preview).\n\n```sh\nnpm install @typescript/native-preview\nnpx tsgo # Use this as you would tsc.\n```\n\nA preview VS Code extension is [available on the VS Code marketplace](https://marketplace.visualstudio.com/items?itemName=TypeScriptTeam.native-preview).\n\nTo use this, set this in your VS Code settings:\n\n```json\n{\n    \"typescript.experimental.useTsgo\": true\n}\n```\n\n## What Works So Far?\n\nThis is still a work in progress and is not yet at full feature parity with TypeScript. Bugs may exist. Please check this list carefully before logging a new issue or assuming an intentional change.\n\n| Feature | Status | Notes |\n|---------|--------|-------|\n| Program creation | done | Same files and module resolution as TS 5.9. Not all resolution modes supported yet. |\n| Parsing/scanning | done | Exact same syntax errors as TS 5.9 |\n| Commandline and `tsconfig.json` parsing | done | Done, though `tsconfig` errors may not be as helpful. |\n| Type resolution | done | Same types as TS 5.9. |\n| Type checking | done | Same errors, locations, and messages as TS 5.9. Types printback in errors may display differently. |\n| JavaScript-specific inference and JSDoc | in progress | Mostly complete, but intentionally lacking some features. Declaration emit not complete. |\n| JSX | done | - |\n| Declaration emit | in progress | Most common features are in place, but some edge cases and feature flags are still unhandled. |\n| Emit (JS output) | in progress | `target: esnext` well-supported, other targets may have gaps. |\n| Watch mode | prototype | Watches files and rebuilds, but no incremental rechecking. Not optimized. |\n| Build mode / project references | done | - |\n| Incremental build | done | - |\n| Language service (LSP) | in progress | Most functionality. More features coming soon. |\n| API | not ready | - |\n\nDefinitions:\n\n * **done** aka \"believed done\": We're not currently aware of any deficits or major left work to do. OK to log bugs\n * **in progress**: currently being worked on; some features may work and some might not. OK to log panics, but nothing else please\n * **prototype**: proof-of-concept only; do not log bugs\n * **not ready**: either haven't even started yet, or far enough from ready that you shouldn't bother messing with it yet\n\n## Other Notes\n\nLong-term, we expect that this repo and its contents will be merged into `microsoft/TypeScript`.\nAs a result, the repo and issue tracker for typescript-go will eventually be closed, so treat discussions/issues accordingly.\n\nFor a list of intentional changes with respect to TypeScript 5.9, see CHANGES.md.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit [Contributor License Agreements](https://cla.opensource.microsoft.com).\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n",
      "stars_today": 14
    },
    {
      "id": 117948953,
      "name": "Atmosphere",
      "full_name": "Atmosphere-NX/Atmosphere",
      "description": "AtmosphÃ¨re is a work-in-progress customized firmware for the Nintendo Switch.",
      "html_url": "https://github.com/Atmosphere-NX/Atmosphere",
      "stars": 17719,
      "forks": 1374,
      "language": "C++",
      "topics": [],
      "created_at": "2018-01-18T07:36:33Z",
      "updated_at": "2026-01-15T22:40:22Z",
      "pushed_at": "2026-01-15T22:40:16Z",
      "open_issues": 40,
      "owner": {
        "login": "Atmosphere-NX",
        "avatar_url": "https://avatars.githubusercontent.com/u/37918415?v=4"
      },
      "readme": "\n![Banner](img/banner.png?raw=true)\n=====\n\n![License](https://img.shields.io/badge/License-GPLv2-blue.svg)\n[![Chat on Discord](https://img.shields.io/badge/Discord-5865f2?logo=discord&logoColor=white)](https://discordapp.com/invite/ZdqEhed)\n![Made with Notepad++](img/np++.png?raw=true)\n\nAtmosphÃ¨re is a work-in-progress customized firmware for the Nintendo Switch.\n\nComponents\n=====\n\nAtmosphÃ¨re consists of multiple components, each of which replaces/modifies a different component of the system:\n\n* FusÃ©e: First-stage Loader, responsible for loading and validating stage 2 (custom TrustZone) plus package2 (Kernel/FIRM sysmodules), and patching them as needed. This replaces all functionality normally in Package1loader/NX Bootloader.\n* ExosphÃ¨re: Customized TrustZone, to run a customized Secure Monitor\n* ThermosphÃ¨re: EL2 EmuNAND support, i.e. backing up and using virtualized/redirected NAND images\n* StratosphÃ¨re: Custom Sysmodule(s), both Rosalina style to extend the kernel/provide new features, and of the loader reimplementation style to hook important system actions\n* TroposphÃ¨re: Application-level Horizon OS patches, used to implement desirable CFW features\n\nLicensing\n=====\n\nThis software is licensed under the terms of the GPLv2, with exemptions for specific projects noted below.\n\nYou can find a copy of the license in the [LICENSE file](LICENSE).\n\nExemptions:\n* [Nintendo](https://github.com/Nintendo) is exempt from GPLv2 licensing and may (at its option) instead license any source code authored for the AtmosphÃ¨re project under the Zero-Clause BSD license.\n\nCredits\n=====\n\nAtmosphÃ¨re is currently being developed and maintained by __SciresM__, __TuxSH__, __hexkyz__, and __fincs__.<br>\nIn no particular order, we credit the following for their invaluable contributions:\n\n* __switchbrew__ for the [libnx](https://github.com/switchbrew/libnx) project and the extensive [documentation, research and tool development](http://switchbrew.org) pertaining to the Nintendo Switch.\n* __devkitPro__ for the [devkitA64](https://devkitpro.org/) toolchain and libnx support.\n* __ReSwitched Team__ for additional [documentation, research and tool development](https://reswitched.github.io/) pertaining to the Nintendo Switch.\n* __ChaN__ for the [FatFs](http://elm-chan.org/fsw/ff/00index_e.html) module.\n* __Marcus Geelnard__ for the [bcl-1.2.0](https://sourceforge.net/projects/bcl/files/bcl/bcl-1.2.0) library.\n* __naehrwert__ and __st4rk__ for the original [hekate](https://github.com/nwert/hekate) project and its hwinit code base.\n* __CTCaer__ for the continued [hekate](https://github.com/CTCaer/hekate) project's fork and the [minerva_tc](https://github.com/CTCaer/minerva_tc) project.\n* __m4xw__ for development of the [emuMMC](https://github.com/m4xw/emummc) project.\n* __Riley__ for suggesting \"Atmosphere\" as a Horizon OS reimplementation+customization project name.\n* __hedgeberg__ for research and hardware testing.\n* __lioncash__ for code cleanup and general improvements.\n* __jaames__ for designing and providing AtmosphÃ¨re's graphical resources.\n* Everyone who submitted entries for AtmosphÃ¨re's [splash design contest](https://github.com/Atmosphere-NX/Atmosphere-splashes).\n* _All those who actively contribute to the AtmosphÃ¨re repository._\n",
      "stars_today": 14
    },
    {
      "id": 126178683,
      "name": "halo",
      "full_name": "halo-dev/halo",
      "description": "å¼ºå¤§æ˜“ç”¨çš„å¼€æºå»ºç«™å·¥å…·ã€‚",
      "html_url": "https://github.com/halo-dev/halo",
      "stars": 37816,
      "forks": 10187,
      "language": "Java",
      "topics": [
        "blog",
        "blog-engine",
        "cms",
        "content-management-system",
        "halo",
        "halocms",
        "website-builder"
      ],
      "created_at": "2018-03-21T12:56:52Z",
      "updated_at": "2026-01-15T22:20:32Z",
      "pushed_at": "2026-01-15T15:24:22Z",
      "open_issues": 287,
      "owner": {
        "login": "halo-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/48195280?v=4"
      },
      "readme": "<p align=\"center\">\n    <a href=\"https://www.halo.run\" target=\"_blank\" rel=\"noopener noreferrer\">\n        <img width=\"100\" src=\"https://www.halo.run/logo\" alt=\"Halo logo\" />\n    </a>\n</p>\n\n<p align=\"center\"><b>Halo</b> [ËˆheÉªloÊŠ]ï¼Œå¼ºå¤§æ˜“ç”¨çš„å¼€æºå»ºç«™å·¥å…·ã€‚</p>\n<p align=\"center\">\n<a href=\"https://github.com/halo-dev/halo/releases\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/halo-dev/halo.svg?style=flat-square&include_prereleases\" /></a>\n<a href=\"https://hub.docker.com/r/halohub/halo\"><img alt=\"Docker pulls\" src=\"https://img.shields.io/docker/pulls/halohub/halo?style=flat-square\" /></a>\n<a href=\"https://github.com/halo-dev/halo/commits\"><img alt=\"GitHub last commit\" src=\"https://img.shields.io/github/last-commit/halo-dev/halo.svg?style=flat-square\" /></a>\n<a href=\"https://github.com/halo-dev/halo/actions\"><img alt=\"GitHub Workflow Status\" src=\"https://img.shields.io/github/actions/workflow/status/halo-dev/halo/halo.yaml?branch=main&style=flat-square\" /></a>\n<a href=\"https://codecov.io/gh/halo-dev/halo\"><img alt=\"Codecov percentage\" src=\"https://img.shields.io/codecov/c/github/halo-dev/halo/main?style=flat-square&token=YsRUg9fall\"/></a>\n<a href=\"https://gitcode.com/feizhiyun/Halo\"><img src=\"https://gitcode.com/feizhiyun/Halo/star/badge.svg\" alt=\"GitCode Stars\"></a>\n<a href=\"https://www.producthunt.com/posts/halo-6b401e75-bb58-4dff-9fe9-2ada3323c874?utm_source=badge-featured&utm_medium=badge&utm_souce=badge-halo&#0045;6b401e75&#0045;bb58&#0045;4dff&#0045;9fe9&#0045;2ada3323c874\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=407442&theme=light\" alt=\"Halo - Powerful&#0032;and&#0032;easy&#0045;to&#0045;use&#0032;Open&#0045;Source&#0032;website&#0032;building&#0032;tool | Product Hunt\" style=\"height: 20px;\" height=\"20px\" /></a>\n<br />\n<a href=\"https://www.halo.run\">å®˜ç½‘</a>\n<a href=\"https://docs.halo.run\">æ–‡æ¡£</a>\n<a href=\"https://bbs.halo.run\">ç¤¾åŒº</a>\n<a href=\"https://gitee.com/halo-dev\">Gitee</a>\n<a href=\"https://t.me/halo_dev\">Telegram é¢‘é“</a>\n</p>\n\n[![Watch the video](https://www.halo.run/upload/halo-github-screenshot.png)](https://www.bilibili.com/video/BV15x4y1U7RU/?share_source=copy_web&vd_source=0ab6cf86ca512a363f04f18b86f55b86)\n\n------------------------------\n\n## å¿«é€Ÿå¼€å§‹\n\nå¦‚æœä½ çš„è®¾å¤‡æœ‰ Docker ç¯å¢ƒï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¿«é€Ÿå¯åŠ¨ä¸€ä¸ª Halo çš„ä½“éªŒç¯å¢ƒï¼š\n\n```bash\ndocker run -d --name halo -p 8090:8090 -v ~/.halo2:/root/.halo2 halohub/halo:2.22\n```\n\næˆ–è€…ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä½¿ç”¨ [Gitpod](https://gitpod.io/) æˆ– [ClawCloud Run](https://template.us-west-1.run.claw.cloud/deploy?templateName=halo) å¯åŠ¨ä¸€ä¸ªä½“éªŒç¯å¢ƒï¼š\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/halo-sigs/gitpod-demo)\n\n[![Run on ClawCloud](https://raw.githubusercontent.com/ClawCloud/Run-Template/refs/heads/main/Run-on-ClawCloud.svg)](https://template.us-west-1.run.claw.cloud/deploy?templateName=halo)\n\n**ä»¥ä¸Šæ–¹å¼ä»…ä½œä¸ºä½“éªŒä½¿ç”¨ï¼Œæ¨èä½¿ç”¨å¼€æº Linux æœåŠ¡å™¨è¿ç»´ç®¡ç†é¢æ¿ [1Panel](https://github.com/1Panel-dev/1Panel) è¿›è¡Œéƒ¨ç½²ï¼ˆ[æŸ¥çœ‹æ–‡æ¡£](https://docs.halo.run/getting-started/install/1panel)ï¼‰ï¼Œè½»æ¾æå®šåå‘ä»£ç†ã€SSL è¯ä¹¦åŠå‡çº§å¤‡ä»½ä»»åŠ¡ã€‚æ›´å¤šéƒ¨ç½²æ–¹å¼ï¼Œè¯·[æŸ¥çœ‹æ–‡æ¡£](https://docs.halo.run/category/%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97)ã€‚**\n\n## åœ¨çº¿ä½“éªŒ\n\n- ç¯å¢ƒåœ°å€ï¼š<https://demo.halo.run>\n- åå°åœ°å€ï¼š<https://demo.halo.run/console>\n- ç”¨æˆ·åï¼š`demo`\n- å¯†ç ï¼š`P@ssw0rd123..`\n\n## ä»˜è´¹ç‰ˆ\n\nç›¸æ¯”äºç¤¾åŒºç‰ˆï¼ŒHalo ä»˜è´¹ç‰ˆä¸ºç”¨æˆ·æä¾›äº†å¤§é‡å¢å¼ºåŠŸèƒ½åŠæŠ€æœ¯æ”¯æŒæœåŠ¡ï¼Œå¢å¼ºåŠŸèƒ½åŒ…æ‹¬å•†åŸã€çŸ­ä¿¡éªŒè¯ç æ³¨å†Œç™»å½•ã€å…¨ç«™ç§æœ‰åŒ–ã€LDAP ç™»å½•ã€ä¸‰æ–¹è´¦å·ç™»å½•åŠè‡ªå®šä¹‰ Logo ç­‰ã€‚ [ç‚¹å‡»æŸ¥çœ‹ä»˜è´¹ç‰ˆè¯¦ç»†ä»‹ç»](https://www.lxware.cn/halo)ã€‚\n\n## ç”Ÿæ€\n\nå¯è®¿é—® [å®˜æ–¹åº”ç”¨å¸‚åœº](https://www.halo.run/store/apps) æˆ– [awesome-halo ä»“åº“](https://github.com/halo-sigs/awesome-halo) æŸ¥çœ‹é€‚ç”¨äº Halo 2.x çš„ä¸»é¢˜å’Œæ’ä»¶ã€‚\n\n## è®¸å¯è¯\n\n[![license](https://img.shields.io/github/license/halo-dev/halo.svg?style=flat-square)](https://github.com/halo-dev/halo/blob/master/LICENSE)\n\nHalo ä½¿ç”¨ GPL-v3.0 åè®®å¼€æºï¼Œè¯·éµå®ˆå¼€æºåè®®ã€‚\n\n## è´¡çŒ®\n\nå‚è€ƒ [CONTRIBUTING](https://github.com/halo-dev/halo/blob/main/CONTRIBUTING.md)ã€‚\n\n<a href=\"https://github.com/halo-dev/halo/graphs/contributors\"><img src=\"https://opencollective.com/halo/contributors.svg?width=890&button=false\" /></a>\n\n## çŠ¶æ€\n\n![Repobeats analytics](https://repobeats.axiom.co/api/embed/ad008b2151c22e7cf734d2688befaa795d593b95.svg \"Repobeats analytics image\")\n",
      "stars_today": 13
    },
    {
      "id": 29759715,
      "name": "zstd",
      "full_name": "facebook/zstd",
      "description": "Zstandard - Fast real-time compression algorithm",
      "html_url": "https://github.com/facebook/zstd",
      "stars": 26406,
      "forks": 2379,
      "language": "C",
      "topics": [],
      "created_at": "2015-01-24T00:22:38Z",
      "updated_at": "2026-01-15T14:38:29Z",
      "pushed_at": "2025-12-22T05:05:20Z",
      "open_issues": 244,
      "owner": {
        "login": "facebook",
        "avatar_url": "https://avatars.githubusercontent.com/u/69631?v=4"
      },
      "readme": "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/facebook/zstd/dev/doc/images/zstd_logo86.png\" alt=\"Zstandard\"></p>\n\n__Zstandard__, or `zstd` as short version, is a fast lossless compression algorithm,\ntargeting real-time compression scenarios at zlib-level and better compression ratios.\nIt's backed by a very fast entropy stage, provided by [Huff0 and FSE library](https://github.com/Cyan4973/FiniteStateEntropy).\n\nZstandard's format is stable and documented in [RFC8878](https://datatracker.ietf.org/doc/html/rfc8878). Multiple independent implementations are already available.\nThis repository represents the reference implementation, provided as an open-source dual [BSD](LICENSE) OR [GPLv2](COPYING) licensed **C** library,\nand a command line utility producing and decoding `.zst`, `.gz`, `.xz` and `.lz4` files.\nShould your project require another programming language,\na list of known ports and bindings is provided on [Zstandard homepage](https://facebook.github.io/zstd/#other-languages).\n\n**Development branch status:**\n\n[![Build Status][travisDevBadge]][travisLink]\n[![Build status][CircleDevBadge]][CircleLink]\n[![Build status][CirrusDevBadge]][CirrusLink]\n[![Fuzzing Status][OSSFuzzBadge]][OSSFuzzLink]\n\n[travisDevBadge]: https://api.travis-ci.com/facebook/zstd.svg?branch=dev \"Continuous Integration test suite\"\n[travisLink]: https://travis-ci.com/facebook/zstd\n[CircleDevBadge]: https://circleci.com/gh/facebook/zstd/tree/dev.svg?style=shield \"Short test suite\"\n[CircleLink]: https://circleci.com/gh/facebook/zstd\n[CirrusDevBadge]: https://api.cirrus-ci.com/github/facebook/zstd.svg?branch=dev\n[CirrusLink]: https://cirrus-ci.com/github/facebook/zstd\n[OSSFuzzBadge]: https://oss-fuzz-build-logs.storage.googleapis.com/badges/zstd.svg\n[OSSFuzzLink]: https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:zstd\n\n## Benchmarks\n\nFor reference, several fast compression algorithms were tested and compared\non a desktop featuring a Core i7-9700K CPU @ 4.9GHz\nand running Ubuntu 24.04 (`Linux 6.8.0-53-generic`),\nusing [lzbench], an open-source in-memory benchmark by @inikep\ncompiled with [gcc] 14.2.0,\non the [Silesia compression corpus].\n\n[lzbench]: https://github.com/inikep/lzbench\n[Silesia compression corpus]: https://sun.aei.polsl.pl//~sdeor/index.php?page=silesia\n[gcc]: https://gcc.gnu.org/\n\n| Compressor name         | Ratio | Compression| Decompress.|\n| ---------------         | ------| -----------| ---------- |\n| **zstd 1.5.7 -1**       | 2.896 |   510 MB/s |  1550 MB/s |\n| brotli 1.1.0 -1         | 2.883 |   290 MB/s |   425 MB/s |\n| [zlib] 1.3.1 -1         | 2.743 |   105 MB/s |   390 MB/s |\n| **zstd 1.5.7 --fast=1** | 2.439 |   545 MB/s |  1850 MB/s |\n| quicklz 1.5.0 -1        | 2.238 |   520 MB/s |   750 MB/s |\n| **zstd 1.5.7 --fast=4** | 2.146 |   665 MB/s |  2050 MB/s |\n| lzo1x 2.10 -1           | 2.106 |   650 MB/s |   780 MB/s |\n| [lz4] 1.10.0            | 2.101 |   675 MB/s |  3850 MB/s |\n| snappy 1.2.1            | 2.089 |   520 MB/s |  1500 MB/s |\n| lzf 3.6 -1              | 2.077 |   410 MB/s |   820 MB/s |\n\n[zlib]: https://www.zlib.net/\n[lz4]: https://lz4.github.io/lz4/\n\nThe negative compression levels, specified with `--fast=#`,\noffer faster compression and decompression speed\nat the cost of compression ratio.\n\nZstd can also offer stronger compression ratios at the cost of compression speed.\nSpeed vs Compression trade-off is configurable by small increments.\nDecompression speed is preserved and remains roughly the same at all settings,\na property shared by most LZ compression algorithms, such as [zlib] or lzma.\n\nThe following tests were run\non a server running Linux Debian (`Linux version 4.14.0-3-amd64`)\nwith a Core i7-6700K CPU @ 4.0GHz,\nusing [lzbench], an open-source in-memory benchmark by @inikep\ncompiled with [gcc] 7.3.0,\non the [Silesia compression corpus].\n\nCompression Speed vs Ratio | Decompression Speed\n---------------------------|--------------------\n![Compression Speed vs Ratio](doc/images/CSpeed2.png \"Compression Speed vs Ratio\") | ![Decompression Speed](doc/images/DSpeed3.png \"Decompression Speed\")\n\nA few other algorithms can produce higher compression ratios at slower speeds, falling outside of the graph.\nFor a larger picture including slow modes, [click on this link](doc/images/DCspeed5.png).\n\n\n## The case for Small Data compression\n\nPrevious charts provide results applicable to typical file and stream scenarios (several MB). Small data comes with different perspectives.\n\nThe smaller the amount of data to compress, the more difficult it is to compress. This problem is common to all compression algorithms, and reason is, compression algorithms learn from past data how to compress future data. But at the beginning of a new data set, there is no \"past\" to build upon.\n\nTo solve this situation, Zstd offers a __training mode__, which can be used to tune the algorithm for a selected type of data.\nTraining Zstandard is achieved by providing it with a few samples (one file per sample). The result of this training is stored in a file called \"dictionary\", which must be loaded before compression and decompression.\nUsing this dictionary, the compression ratio achievable on small data improves dramatically.\n\nThe following example uses the `github-users` [sample set](https://github.com/facebook/zstd/releases/tag/v1.1.3), created from [github public API](https://developer.github.com/v3/users/#get-all-users).\nIt consists of roughly 10K records weighing about 1KB each.\n\nCompression Ratio | Compression Speed | Decompression Speed\n------------------|-------------------|--------------------\n![Compression Ratio](doc/images/dict-cr.png \"Compression Ratio\") | ![Compression Speed](doc/images/dict-cs.png \"Compression Speed\") | ![Decompression Speed](doc/images/dict-ds.png \"Decompression Speed\")\n\n\nThese compression gains are achieved while simultaneously providing _faster_ compression and decompression speeds.\n\nTraining works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient it is (there is no _universal dictionary_).\nHence, deploying one dictionary per type of data will provide the greatest benefits.\nDictionary gains are mostly effective in the first few KB. Then, the compression algorithm will gradually use previously decoded content to better compress the rest of the file.\n\n### Dictionary compression How To:\n\n1. Create the dictionary\n\n   `zstd --train FullPathToTrainingSet/* -o dictionaryName`\n\n2. Compress with dictionary\n\n   `zstd -D dictionaryName FILE`\n\n3. Decompress with dictionary\n\n   `zstd -D dictionaryName --decompress FILE.zst`\n\n\n## Build instructions\n\n`make` is the main build system of this project.\nIt is the reference, and other build systems are periodically updated to stay compatible.\nHowever, small drifts and feature differences can be present, since perfect synchronization is difficult.\nFor this reason, when your build system allows it, prefer employing `make`.\n\n### Makefile\n\nAssuming your system supports standard `make` (or `gmake`),\njust invoking `make` in root directory generates `zstd` cli at root,\nand also generates `libzstd` into `lib/`.\n\nOther standard targets include:\n- `make install` : install zstd cli, library and man pages\n- `make check` : run `zstd`, test its essential behavior on local platform\n\nThe `Makefile` follows the [GNU Standard Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html),\nallowing staged install, standard compilation flags, directory variables and command variables.\n\nFor advanced use cases, specialized flags which control binary generation and installation paths are documented\nin [`lib/README.md`](lib/README.md#modular-build) for the `libzstd` library\nand in [`programs/README.md`](programs/README.md#compilation-variables) for the `zstd` CLI.\n\n### cmake\n\nA `cmake` project generator is available for generating Makefiles or other build scripts\nto create the `zstd` binary as well as `libzstd` dynamic and static libraries.\nThe repository root now contains a minimal `CMakeLists.txt` that forwards to `build/cmake`,\nso you can configure the project with a standard `cmake -S .` invocation,\nwhile the historical `cmake -S build/cmake` entry point remains fully supported.\n\n```bash\ncmake -S . -B build-cmake\ncmake --build build-cmake\n```\n\nBy default, `CMAKE_BUILD_TYPE` is set to `Release`.\n\n#### Support for Fat (Universal2) Output\n\n`zstd` can be built and installed with support for both Apple Silicon (M1/M2) as well as Intel by using CMake's Universal2 support.\nTo perform a Fat/Universal2 build and install use the following commands:\n\n```bash\ncmake -S . -B build-cmake-debug -G Ninja -DCMAKE_OSX_ARCHITECTURES=\"x86_64;x86_64h;arm64\"\ncd build-cmake-debug\nninja\nsudo ninja install\n```\n\n### Meson\n\nA Meson project is provided within [`build/meson`](build/meson). Follow\nbuild instructions in that directory.\n\nYou can also take a look at [`.travis.yml`](.travis.yml) file for an\nexample about how Meson is used to build this project.\n\nNote that default build type is **release**.\n\n### VCPKG\nYou can build and install zstd [vcpkg](https://github.com/Microsoft/vcpkg/) dependency manager:\n\n    git clone https://github.com/Microsoft/vcpkg.git\n    cd vcpkg\n    ./bootstrap-vcpkg.sh\n    ./vcpkg integrate install\n    ./vcpkg install zstd\n\nThe zstd port in vcpkg is kept up to date by Microsoft team members and community contributors.\nIf the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n### Conan\n\nYou can install pre-built binaries for zstd or build it from source using [Conan](https://conan.io/). Use the following command:\n\n```bash\nconan install --requires=\"zstd/[*]\" --build=missing\n```\n\nThe zstd Conan recipe is kept up to date by Conan maintainers and community contributors.\nIf the version is out of date, please [create an issue or pull request](https://github.com/conan-io/conan-center-index) on the ConanCenterIndex repository.\n\n### Visual Studio (Windows)\n\nGoing into `build` directory, you will find additional possibilities:\n- Projects for Visual Studio 2008 and 2010.\n  + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.\n- Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,\n  which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution.\n- It is now recommended to generate Visual Studio solutions from `cmake`\n\n### Buck\n\nYou can build the zstd binary via buck by executing: `buck build programs:zstd` from the root of the repo.\nThe output binary will be in `buck-out/gen/programs/`.\n\n### Bazel\n\nYou can integrate zstd into your Bazel project by using the module hosted on the [Bazel Central Repository](https://registry.bazel.build/modules/zstd).\n\n## Testing\n\nYou can run quick local smoke tests by running `make check`.\nIf you can't use `make`, execute the `playTest.sh` script from the `src/tests` directory.\nTwo env variables `$ZSTD_BIN` and `$DATAGEN_BIN` are needed for the test script to locate the `zstd` and `datagen` binary.\nFor information on CI testing, please refer to `TESTING.md`.\n\n## Status\n\nZstandard is deployed within Meta and many other large cloud infrastructures,\nto compress humongous amounts of data in various formats and use cases.\nIt is also continuously fuzzed for security issues by Google's [oss-fuzz](https://github.com/google/oss-fuzz/tree/master/projects/zstd) program.\n\n## License\n\nZstandard is dual-licensed under [BSD](LICENSE) OR [GPLv2](COPYING).\n\n## Contributing\n\nThe `dev` branch is the one where all contributions are merged before reaching `release`.\nDirect commit to `release` are not permitted.\nFor more information, please read [CONTRIBUTING](CONTRIBUTING.md).\n",
      "stars_today": 13
    },
    {
      "id": 784788673,
      "name": "CookLikeHOC",
      "full_name": "Gar-b-age/CookLikeHOC",
      "description": "ğŸ¥¢åƒè€ä¹¡é¸¡ğŸ”é‚£æ ·åšé¥­ã€‚ä¸»è¦éƒ¨åˆ†äº2024å¹´å®Œå·¥ï¼Œéè€ä¹¡é¸¡å®˜æ–¹ä»“åº“ã€‚æ–‡å­—æ¥è‡ªã€Šè€ä¹¡é¸¡èœå“æº¯æºæŠ¥å‘Šã€‹ï¼Œå¹¶åšå½’çº³ã€ç¼–è¾‘ä¸æ•´ç†ã€‚CookLikeHOC.",
      "html_url": "https://github.com/Gar-b-age/CookLikeHOC",
      "stars": 22846,
      "forks": 2308,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2024-04-10T15:01:12Z",
      "updated_at": "2026-01-15T16:03:56Z",
      "pushed_at": "2025-10-17T20:04:04Z",
      "open_issues": 135,
      "owner": {
        "login": "Gar-b-age",
        "avatar_url": "https://avatars.githubusercontent.com/u/167223032?v=4"
      },
      "readme": "![pic](/banner.png)\n\n<div align=\"center\">\n\n[**Docker Support**](./docker_support/README.md) | [**Development**](./docs/development.md)\n\n</div>\n\n# åƒè€ä¹¡é¸¡é‚£æ ·åšé¥­\n\n[**ä¸€äº›è¯´æ˜**](https://github.com/Gar-b-age/CookLikeHOC/issues/26)\n\nä»“åº“ä¸»ä½“éƒ¨åˆ†äº2024å¹´å®Œå·¥ï¼Œå’Œ2025å¹´9æœˆä»½çš„èˆ†è®ºäº‹ä»¶æ— å…³ã€‚æˆªæ­¢æäº¤æ—¶ï¼Œä»“åº“çš„è´¡çŒ®è€…ä»¬ä¸è€ä¹¡é¸¡çš„å”¯ä¸€å…³ç³»åªæœ‰æ¶ˆè´¹è€…å’Œå•†å®¶çš„å…³ç³»ã€‚æœ¬ä»“åº“ä¸æ˜¯è€ä¹¡é¸¡çš„å®˜æ–¹ä»“åº“ã€‚å¦‚æœæœ‰ä»»ä½•é—®é¢˜æˆ–æ„è§å»ºè®®ï¼Œæ¬¢è¿æŒ‡å‡º\n\n## æ–°æ›´æ–°\n\n- æ¬¢è¿å¤§å®¶æ¥è´¡çŒ®å®æ‹å›¾\n\n- ç°å·²ä¸Šçº¿ç½‘é¡µç«¯ï¼Œ[ç‚¹å‡»è®¿é—®](https://cooklikehoc.soilzhu.su)\n\n- Run with Docker? Check it out [here](https://github.com/Gar-b-age/CookLikeHOC/tree/main/docker_support), supported by [@honestAnt](https://github.com/honestAnt) in [PR #141](https://github.com/Gar-b-age/CookLikeHOC/pull/141)\n\n- AI ç»˜åˆ¶çš„æ‰‹ç»˜å›¾ç‰ˆåŠAIé…å›¾æµç¨‹ç‰ˆç½‘é¡µï¼š [ç‚¹å‡»è®¿é—®](https://ai.cooklikehoc.soilzhu.su), æ‰‹ç»˜å›¾ç”± [@liucongg](https://github.com/liucongg) è´¡çŒ®ï¼Œè§ [PR #143](https://github.com/Gar-b-age/CookLikeHOC/pull/143)\n\n---\n\n[![link](/tg.png)](https://t.me/cooklikehoc)\n\nã€Šè€ä¹¡é¸¡èœå“æº¯æºæŠ¥å‘Šã€‹ä¸­å…¬å¸ƒçš„æ‰€æœ‰èœå“å·²ç»å…¨éƒ¨å½•å…¥å®Œï¼Œæ¬¢è¿å¤§å®¶æŸ¥é˜…å’Œè¡¥å……ã€‚\n\næ–‡å­—è¶…å¤§æ®µcopyè‡ª[ã€Šè€ä¹¡é¸¡èœå“æº¯æºæŠ¥å‘Šã€‹](https://www.lxjchina.com.cn/display.asp?id=4226)ï¼Œæœ‰ç¼–è¾‘ä¸æ•´ç†\n\næŒ‡è·¯éš”å£ [How To Cook](https://cook.aiursoft.cn/)\n\nè‡³äºä¸ºä»€ä¹ˆä»“åº“åè¦å«CookLikeHOCï¼Œå› ä¸ºç›´æ¥å†™Laoxiangjiå¤§æ¦‚ä¸æ–¹ä¾¿é˜…è¯»ï¼Œè€ŒHome Original Chickenæ˜¯china dailyæŠ¥é“ä¸­æ‰€ä½¿ç”¨çš„è€ä¹¡é¸¡çš„è‹±æ–‡åï¼Œæ•…ç®€å†™æˆHOCã€‚\n\n\n## Contributor\n\n![cr](https://contrib.rocks/image?repo=Gar-b-age/CookLikeHOC)\n\n## Logo\n![pic](/logo.png) \n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Gar-b-age/CookLikeHOC&type=Date)](https://star-history.com/#Gar-b-age/CookLikeHOC&Date)",
      "stars_today": 13
    },
    {
      "id": 476427476,
      "name": "Maestro",
      "full_name": "mobile-dev-inc/Maestro",
      "description": "Painless E2E Automation for Mobile and Web",
      "html_url": "https://github.com/mobile-dev-inc/Maestro",
      "stars": 10050,
      "forks": 565,
      "language": "Kotlin",
      "topics": [
        "android",
        "blackbox-testing",
        "ios",
        "ui-automation"
      ],
      "created_at": "2022-03-31T18:17:40Z",
      "updated_at": "2026-01-16T00:59:18Z",
      "pushed_at": "2026-01-12T11:25:13Z",
      "open_issues": 482,
      "owner": {
        "login": "mobile-dev-inc",
        "avatar_url": "https://avatars.githubusercontent.com/u/65870663?v=4"
      },
      "readme": "> [!TIP]\n> Great things happen when testers connect â€” [Join the Maestro Community](https://maestrodev.typeform.com/to/FelIEe8A)\n\n\n<p align=\"center\">\n  <a href=\"https://www.maestro.dev\">\n    <img width=\"1200\" alt=\"Maestro logo\" src=\"https://github.com/mobile-dev-inc/Maestro/blob/main/assets/banne_logo.png\" />\n  </a>\n</p>\n\n\n<p align=\"center\">\n  <strong>Maestro</strong> is an open-source framework that makes UI and end-to-end testing for Android, iOS, and web apps simple and fast.<br/>\n  Write your first test in under five minutes using YAML flows and run them on any emulator, simulator, or browser.\n</p>\n\n<img src=\"https://user-images.githubusercontent.com/847683/187275009-ddbdf963-ce1d-4e07-ac08-b10f145e8894.gif\" />\n\n---\n\n## Table of Contents\n\n- [Why Maestro?](#why-maestro)\n- [Getting Started](#getting-started)\n- [Resources & Community](#resources--community)\n- [Contributing](#contributing)\n- [Maestro Studio â€“ Test IDE](#maestro-studio--test-ide)\n- [Maestro Cloud â€“ Parallel Execution & Scalability](#maestro-cloud--parallel-execution--scalability)\n\n\n---\n\n## Why Maestro?\n\nMaestro is built on learnings from its predecessors (Appium, Espresso, UIAutomator, XCTest, Selenium, Playwright) and allows you to easily define and test your Flows.\n\nBy combining a human-readable YAML syntax with an interpreted execution engine, it lets you write, run, and scale cross-platform end-to-end tests for mobile and web with ease.\n\n- **Cross-platform coverage** â€“ test Android, iOS, and web apps (React Native, Flutter, hybrid) on emulators, simulators, or real devices.  \n- **Human-readable YAML flows** â€“ express interactions as commands like `launchApp`, `tapOn`, and `assertVisible`.  \n- **Resilience & smart waiting** â€“ built-in flakiness tolerance and automatic waiting handle dynamic UIs without manual `sleep()` calls.  \n- **Fast iteration & simple install** â€“ flows are interpreted (no compilation) and installation is a single script.\n\n**Simple Example:**\n```\n# flow_contacts_android.yaml\n\nappId: com.android.contacts\n---\n- launchApp\n- tapOn: \"Create new contact\"\n- tapOn: \"First Name\"\n- inputText: \"John\"\n- tapOn: \"Last Name\"\n- inputText: \"Snow\"\n- tapOn: \"Save\"\n```\n\n---\n## Getting Started\n\nMaestro requires Java 17 or higher to be installed on your system. You can verify your Java version by running:\n\n```\njava -version\n```\n\nInstalling the CLI:\n\nRun the following command to install Maestro on macOS, Linux or Windows (WSL):\n\n```\ncurl -fsSL \"https://get.maestro.mobile.dev\" | bash\n```\n\nThe links below will guide you through the next steps.\n\n- [Installing Maestro](https://docs.maestro.dev/getting-started/installing-maestro) (includes regular Windows installation)\n- [Build and install your app](https://docs.maestro.dev/getting-started/build-and-install-your-app)\n- [Run a sample flow](https://docs.maestro.dev/getting-started/run-a-sample-flow)\n- [Writing your first flow](https://docs.maestro.dev/getting-started/writing-your-first-flow)\n\n\n---\n\n## Resources & Community\n\n- ğŸ’¬ [Join the Slack Community](https://maestrodev.typeform.com/to/FelIEe8A)\n- ğŸ“˜ [Documentation](https://docs.maestro.dev)  \n- ğŸ“° [Blog](https://maestro.dev/blog?utm_source=github-readme) \n- ğŸ¦ [Follow us on X](https://twitter.com/maestro__dev)\n\n---\n\n## Contributing\n\nMaestro is open-source under the Apache 2.0 license â€” contributions are welcome!\n\n- Check [good first issues](https://github.com/mobile-dev-inc/maestro/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n- Read the [Contribution Guide](https://github.com/mobile-dev-inc/Maestro/blob/main/CONTRIBUTING.md) \n- Fork, create a branch, and open a Pull Request.\n\nIf you find Maestro useful, â­ star the repository to support the project.\n\n---\n\n## Maestro Studio â€“ Test IDE\n\n**Maestro Studio Desktop** is a lightweight IDE that lets you design and execute tests visually â€” no terminal needed. \nIt is also free, even though Studio is not an open-source project. So you won't find the Maestro Studio code here.\n\n- **Simple setup** â€“ just download the native app for macOS, Windows, or Linux.  \n- **Visual flow builder & inspector** â€“ record interactions, inspect elements, and build flows visually.  \n- **AI assistance** â€“ use MaestroGPT to generate commands and answer questions while authoring tests.\n\n[Download Maestro Studio](https://maestro.dev/?utm_source=github-readme#maestro-studio)\n\n---\n\n## Maestro Cloud â€“ Parallel Execution & Scalability\n\nWhen your test suite grows, run hundreds of tests in parallel on dedicated infrastructure, cutting execution times by up to 90%. Includes built-in notifications, deterministic environments, and complete debugging tools.\n\nPricing for Maestro Cloud is completely transparent and can be found on the [pricing page](https://maestro.dev/pricing?utm_source=github-readme).\n\nğŸ‘‰ [Start your free 7-day trial](https://maestro.dev/cloud?utm_source=github-readme)\n\n\n\n```\n  Built with â¤ï¸ by Maestro.dev\n```\n\n\n",
      "stars_today": 13
    },
    {
      "id": 809906907,
      "name": "DockDoor",
      "full_name": "ejbills/DockDoor",
      "description": "Window peeking, alt-tab and other enhancements for macOS",
      "html_url": "https://github.com/ejbills/DockDoor",
      "stars": 3629,
      "forks": 98,
      "language": "Swift",
      "topics": [],
      "created_at": "2024-06-03T17:18:17Z",
      "updated_at": "2026-01-15T22:43:08Z",
      "pushed_at": "2026-01-15T22:43:04Z",
      "open_issues": 76,
      "owner": {
        "login": "ejbills",
        "avatar_url": "https://avatars.githubusercontent.com/u/74191134?v=4"
      },
      "readme": "<a id=\"readme-top\"></a>\n\n<div align=\"center\">\n\n<img src=\"Assets/Assets.xcassets/AppIcon.appiconset/AppIcon-iOS-Default-512x512@1x.png\" alt=\"DockDoor Logo\" width=\"128\"/>\n\n</div>\n\n<h1 align=\"center\">DockDoor</h1>\n\n<div align=\"center\">\n\n<p>\n  <a href=\"https://github.com/ejbills/DockDoor/releases/latest/download/DockDoor.dmg\">\n    <img src=\"https://img.shields.io/github/downloads/ejbills/DockDoor/latest/total?style=flat&label=Downloads%20%40latest&labelColor=444&logo=hack-the-box&logoColor=white&cacheSeconds=600\" alt=\"Latest downloads\">\n  </a>\n  <a href=\"https://github.com/ejbills/DockDoor/releases\">\n    <img src=\"https://img.shields.io/github/downloads/ejbills/DockDoor/total?label=Total%20Downloads\" alt=\"Total downloads\">\n  </a>\n</p>\n\n![Swift](https://img.shields.io/badge/Swift-FA7343?style=for-the-badge&logo=swift&logoColor=white)\n![XCode](https://img.shields.io/badge/Xcode-007ACC?style=for-the-badge&logo=Xcode&logoColor=white)\n![Git](https://img.shields.io/badge/GIT-E44C30?style=for-the-badge&logo=git&logoColor=white)\n![MacOS](https://img.shields.io/badge/mac%20os-000000?style=for-the-badge&logo=apple&logoColor=white)\n\nEffortless Alt+Tab switching and dock previews that respect your privacy.\n\n</div>\n\n![Screenshot](/resources/dockdoorHero.png)\n\n## Table of Contents\n\n  <ol>\n    <li><a href=\"#about-the-project\">About The Project</a></li>\n    <li><a href=\"#features\">Features</a></li>\n    <li><a href=\"#contributing\">Contributing</a></li>\n    <li><a href=\"#license\">License</a></li>\n  </ol>\n\n## About The Project\n\n**DockDoor** reintroduces the missing \"Window Peeking\" functionality to macOS, inspired by the utility found in Windows and Linux environments.\n\nWhile the native macOS Dock is iconic, it often lacks context when multiple windows of the same application are open. DockDoor solves this by allowing you to visualize, manage, and switch between your open windows simply by hovering over your Dock icons.\n\nBuilt entirely open-source, DockDoor is designed to feel like a native extension of the operating system. Fast, lightweight, and seamlessly integrated!\n\nFor full details, features, and documentation, please visit **[dockdoor.net](https://dockdoor.net)** â­\n\n<p align=\"right\"><a href=\"#readme-top\">Back to top â¬†ï¸</a></p>\n\n## Features\n\n### Dock Previews\n\n![Dock Previews](/resources/dockdoorHero.png)\n\n### Alt+Tab Switching\n\n![Alt+Tab Switching](/resources/dockdoorSwitcherHero.png)\n\n### Cmd+Tab Enhancements\n\n![Cmd+Tab Enhancements](/resources/cmd-tab-enhancements.png)\n\n### Dock Preview Layouts\n\n![Dock Preview Layouts 1](/resources/variations/dockpreview1.png)\n![Dock Preview Layouts 2](/resources/variations/dockpreview2.png)\n\n### Window Switcher Layouts\n\n![Window Switcher Layouts 1](/resources/variations/windowswitcher1.png)\n![Window Switcher Layouts 2](/resources/variations/windowswitcher2.png)\n\n### Calendar Integration\n\n![Window Switcher Layouts](/resources/calendar.png)\n\n### Compact List View\n\n![Compact List View](/resources/listView.png)\n\n### Enhanced Previews\n![Enhanced Previews](/resources/largePreviewDemo.png)\n\n### For more awesome features please visit **[dockdoor.net](https://dockdoor.net)** â­\n\n<p align=\"right\"><a href=\"#readme-top\">Back to top â¬†ï¸</a></p>\n\n## Contributing\n\n- â­ [Star on Github: Help others discover DockDoor](https://github.com/ejbills/DockDoor)\n\n- ğŸ› [Report Issues: Help us improve the app](https://github.com/ejbills/DockDoor/issues)\n\n- ğŸŒ [Help Translate: Make DockDoor global](https://crowdin.com/project/dockdoor)\n\n<p align=\"right\"><a href=\"#readme-top\">Back to top â¬†ï¸</a></p>\n\n## License\n\nThis project is licensed under the GNU General Public License v3.0 - see the [LICENSE](LICENSE) file for details.\n\n<p align=\"right\"><a href=\"#readme-top\">Back to top â¬†ï¸</a></p>\n",
      "stars_today": 13
    },
    {
      "id": 6296790,
      "name": "spring-boot",
      "full_name": "spring-projects/spring-boot",
      "description": "Spring Boot helps you to create Spring-powered, production-grade applications and services with absolute minimum fuss.",
      "html_url": "https://github.com/spring-projects/spring-boot",
      "stars": 79679,
      "forks": 41805,
      "language": "Java",
      "topics": [
        "framework",
        "java",
        "spring",
        "spring-boot"
      ],
      "created_at": "2012-10-19T15:02:57Z",
      "updated_at": "2026-01-16T00:26:52Z",
      "pushed_at": "2026-01-15T18:48:29Z",
      "open_issues": 493,
      "owner": {
        "login": "spring-projects",
        "avatar_url": "https://avatars.githubusercontent.com/u/317776?v=4"
      },
      "readme": "= Spring Boot image:https://github.com/spring-projects/spring-boot/actions/workflows/build-and-deploy-snapshot.yml/badge.svg?branch=main[\"Build Status\", link=\"https://github.com/spring-projects/spring-boot/actions/workflows/build-and-deploy-snapshot.yml?query=branch%3Amain\"] image:https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A[\"Revved up by Develocity\", link=\"https://ge.spring.io/scans?&search.rootProjectNames=Spring%20Boot%20Build&search.rootProjectNames=spring-boot-build\"]\n\n:docs: https://docs.spring.io/spring-boot\n:github: https://github.com/spring-projects/spring-boot\n\nSpring Boot helps you to create Spring-powered, production-grade applications and services with absolute minimum fuss.\nIt takes an opinionated view of the Spring platform so that new and existing users can quickly get to the bits they need.\n\nYou can use Spring Boot to create stand-alone Java applications that can be started using `java -jar` or more traditional WAR deployments.\nWe also provide a command-line tool that runs Spring scripts.\n\nOur primary goals are:\n\n* Provide a radically faster and widely accessible getting started experience for all Spring development.\n* Be opinionated, but get out of the way quickly as requirements start to diverge from the defaults.\n* Provide a range of non-functional features common to large classes of projects (for example, embedded servers, security, metrics, health checks, externalized configuration).\n* Absolutely no code generation and no requirement for XML configuration.\n\n\n\n== Installation and Getting Started\n\nThe {docs}[reference documentation] includes detailed {docs}/installing.html[installation instructions] as well as a comprehensive {docs}/tutorial/first-application/index.html[``getting started``] guide.\n\nHere is a quick teaser of a complete Spring Boot application in Java:\n\n[source,java]\n----\nimport org.springframework.boot.*;\nimport org.springframework.boot.autoconfigure.*;\nimport org.springframework.web.bind.annotation.*;\n\n@RestController\n@SpringBootApplication\npublic class Example {\n\n\t@RequestMapping(\"/\")\n\tString home() {\n\t\treturn \"Hello World!\";\n\t}\n\n\tpublic static void main(String[] args) {\n\t\tSpringApplication.run(Example.class, args);\n\t}\n\n}\n----\n\n\n\n== Getting Help\n\nAre you having trouble with Spring Boot? We want to help!\n\n* Check the {docs}/[reference documentation], especially the {docs}/how-to/index.html[How-to's] -- they provide solutions to the most common questions.\n* Learn the Spring basics -- Spring Boot builds on many other Spring projects; check the https://spring.io[spring.io] website for a wealth of reference documentation.\n  If you are new to Spring, try one of the https://spring.io/guides[guides].\n* If you are upgrading, read the {github}/wiki[release notes] for upgrade instructions and \"new and noteworthy\" features.\n* Ask a question -- we monitor https://stackoverflow.com[stackoverflow.com] for questions tagged with https://stackoverflow.com/tags/spring-boot[`spring-boot`].\n* Report bugs with Spring Boot at {github}/issues[github.com/spring-projects/spring-boot/issues].\n\n\n\n== Contributing\n\nWe welcome contributions of all kinds!\nPlease read our link:CONTRIBUTING.adoc[contribution guidelines] before submitting a pull request.\n\n\n\n== Reporting Issues\n\nSpring Boot uses GitHub's integrated issue tracking system to record bugs and feature requests.\nIf you want to raise an issue, please follow the recommendations below:\n\n* Before you log a bug, please search the {github}/issues[issue tracker] to see if someone has already reported the problem.\n* If the issue doesn't already exist, {github}/issues/new[create a new issue].\n* Please provide as much information as possible with the issue report.\nWe like to know the Spring Boot version, operating system, and JVM version you're using.\n* If you need to paste code or include a stack trace, use Markdown.\n+++```+++ escapes before and after your text.\n* If possible, try to create a test case or project that replicates the problem and attach it to the issue.\n\n\n\n== Building from Source\n\nYou don't need to build from source to use Spring Boot.\nIf you want to try out the latest and greatest, Spring Boot can be built and published to your local Maven cache using the https://docs.gradle.org/current/userguide/gradle_wrapper.html[Gradle wrapper].\nYou also need JDK 25.\n\n[source,shell]\n----\n$ ./gradlew publishToMavenLocal\n----\n\nThis command builds all modules and publishes them to your local Maven cache.\nIt won't run any of the tests.\nIf you want to build everything, use the `build` task:\n\n[source,shell]\n----\n$ ./gradlew build\n----\n\n\n\n== Guides\n\nThe https://spring.io/[spring.io] site contains several guides that show how to use Spring Boot step-by-step:\n\n* https://spring.io/guides/gs/spring-boot/[Building an Application with Spring Boot] is an introductory guide that shows you how to create an application, run it, and add some management services.\n* https://spring.io/guides/gs/actuator-service/[Building a RESTful Web Service with Spring Boot Actuator] is a guide to creating a REST web service and also shows how the server can be configured.\n\n\n\n== License\n\nSpring Boot is Open Source software released under the https://www.apache.org/licenses/LICENSE-2.0.html[Apache 2.0 license].\n",
      "stars_today": 12
    },
    {
      "id": 156018,
      "name": "redis",
      "full_name": "redis/redis",
      "description": "For developers, who are building real-time data-driven applications, Redis is the preferred, fastest, and most feature-rich cache, data structure server, and document and vector query engine.",
      "html_url": "https://github.com/redis/redis",
      "stars": 72527,
      "forks": 24433,
      "language": "C",
      "topics": [
        "cache",
        "caching",
        "database",
        "distributed-systems",
        "in-memory",
        "in-memory-database",
        "json",
        "key-value",
        "key-value-store",
        "message-broker",
        "message-queue",
        "no-sql",
        "nosql",
        "open-source",
        "real-time",
        "realtime",
        "redis",
        "time-series",
        "vector-databases",
        "vector-search"
      ],
      "created_at": "2009-03-21T22:32:25Z",
      "updated_at": "2026-01-15T22:14:56Z",
      "pushed_at": "2026-01-15T21:11:17Z",
      "open_issues": 2741,
      "owner": {
        "login": "redis",
        "avatar_url": "https://avatars.githubusercontent.com/u/1529926?v=4"
      },
      "readme": "[![codecov](https://codecov.io/github/redis/redis/graph/badge.svg?token=6bVHb5fRuz)](https://codecov.io/github/redis/redis)\n\nThis document serves as both a quick start guide to Redis and a detailed resource for building it from source.\n\n- New to Redis? Start with [What is Redis](#what-is-redis) and [Getting Started](#getting-started)\n- Ready to build from source? Jump to [Build Redis from Source](#build-redis-from-source)\n- Want to contribute? See the [Code contributions](#code-contributions) section\n  and [CONTRIBUTING.md](./CONTRIBUTING.md)\n- Looking for detailed documentation? Navigate to [redis.io/docs](https://redis.io/docs/)\n\n## Table of contents\n\n- [What is Redis?](#what-is-redis)\n  - [Key use cases](#key-use-cases)\n- [Why choose Redis?](#why-choose-redis)\n- [What is Redis Open Source?](#what-is-redis-open-source)\n- [Getting started](#getting-started)\n  - [Redis starter projects](#redis-starter-projects)\n  - [Using Redis with client libraries](#using-redis-with-client-libraries)\n  - [Using Redis with redis-cli](#using-redis-with-redis-cli)\n  - [Using Redis with Redis Insight](#using-redis-with-redis-insight)\n- [Redis data types, processing engines, and capabilities](#redis-data-types-processing-engines-and-capabilities)\n- [Cloud hosted Redis](#cloud-hosted-redis)\n- [Community](#community)\n- [Build Redis from source](#build-redis-from-source)\n  - [Build and run Redis with all data structures - Ubuntu 20.04 (Focal)](#build-and-run-redis-with-all-data-structures---ubuntu-2004-focal)\n  - [Build and run Redis with all data structures - Ubuntu 22.04 (Jammy)](#build-and-run-redis-with-all-data-structures---ubuntu-2204-jammy)\n  - [Build and run Redis with all data structures - Ubuntu 24.04 (Noble)](#build-and-run-redis-with-all-data-structures---ubuntu-2404-noble)\n  - [Build and run Redis with all data structures - Debian 11 (Bullseye) / 12 (Bookworm)](#build-and-run-redis-with-all-data-structures---debian-11-bullseye--12-bookworm)\n  - [Build and run Redis with all data structures - AlmaLinux 8.10 / Rocky Linux 8.10](#build-and-run-redis-with-all-data-structures---almalinux-810--rocky-linux-810)\n  - [Build and run Redis with all data structures - AlmaLinux 9.5 / Rocky Linux 9.5](#build-and-run-redis-with-all-data-structures---almalinux-95--rocky-linux-95)\n  - [Build and run Redis with all data structures - macOS 13 (Ventura) and macOS 14 (Sonoma)](#build-and-run-redis-with-all-data-structures---macos-13-ventura-and-macos-14-sonoma)\n  - [Build and run Redis with all data structures - macOS 15 (Sequoia)](#build-and-run-redis-with-all-data-structures---macos-15-sequoia)\n  - [Building Redis - flags and general notes](#building-redis---flags-and-general-notes)\n  - [Fixing build problems with dependencies or cached build options](#fixing-build-problems-with-dependencies-or-cached-build-options)\n  - [Fixing problems building 32 bit binaries](#fixing-problems-building-32-bit-binaries)\n  - [Allocator](#allocator)\n  - [Monotonic clock](#monotonic-clock)\n  - [Verbose build](#verbose-build)\n  - [Running Redis with TLS](#running-redis-with-tls)\n- [Code contributions](#code-contributions)\n- [Redis Trademarks](#redis-trademarks)\n\n## What is Redis?\n\nFor developers, who are building real-time data-driven applications, Redis is the preferred, fastest, and most feature-rich cache, data structure server, and document and vector query engine.\n\n### Key use cases\n\nRedis excels in various applications, including:\n\n- **Caching:** Supports multiple eviction policies, key expiration, and hash-field expiration.\n- **Distributed Session Store:** Offers flexible session data modeling (string, JSON, hash).\n- **Data Structure Server:** Provides low-level data structures (strings, lists, sets, hashes, sorted sets, JSON, etc.) with high-level semantics (counters, queues, leaderboards, rate limiters) and supports transactions & scripting.\n- **NoSQL Data Store:** Key-value, document, and time series data storage.\n- **Search and Query Engine:** Indexing for hash/JSON documents, supporting vector search, full-text search, geospatial queries, ranking, and aggregations via Redis Query Engine.\n- **Event Store & Message Broker:** Implements queues (lists), priority queues (sorted sets), event deduplication (sets), streams, and pub/sub with probabilistic stream processing capabilities.\n- **Vector Store for GenAI:** Integrates with AI applications (e.g. LangGraph, mem0) for short-term memory, long-term memory, LLM response caching (semantic caching), and retrieval augmented generation (RAG).\n- **Real-Time Analytics:** Powers personalization, recommendations, fraud detection, and risk assessment.\n\n## Why choose Redis?\n\nRedis is a popular choice for developers worldwide due to its combination of speed, flexibility, and rich feature set. Here's why people choose Redis for:\n\n- **Performance:** Because Redis keeps data primarily in memory and uses efficient data structures, it achieves extremely low latency (often sub-millisecond) for both read and write operations. This makes it ideal for applications demanding real-time responsiveness.\n- **Flexibility:** Redis isn't just a key-value store, it provides native support for a wide range of data structures and capabilities listed in [What is Redis?](#what-is-redis)\n- **Extensibility:** Redis is not limited to the built-in data structures, it has a [modules API](https://redis.io/docs/latest/develop/reference/modules/) that makes it possible to extend Redis functionality and rapidly implement new Redis commands\n- **Simplicity:** Redis has a simple, text-based protocol and [well-documented command set](https://redis.io/docs/latest/commands/)\n- **Ubiquity:** Redis is battle tested in production workloads at a massive scale. There is a good chance you indirectly interact with Redis several times daily\n- **Versatility**: Redis is the de facto standard for use cases such as:\n  - **Caching:** quickly access frequently used data without needing to query your primary database\n  - **Session management:** read and write user session data without hurting user experience or slowing down every API call\n  - **Querying, sorting, and analytics:** perform deduplication, full text search, and secondary indexing on in-memory data as fast as possible\n  - **Messaging and interservice communication:** job queues, message brokering, pub/sub, and streams for communicating between services\n  - **Vector operations:** Long-term and short-term LLM memory, RAG content retrieval, semantic caching, semantic routing, and vector similarity search\n\nIn summary, Redis provides a powerful, fast, and flexible toolkit for solving a wide variety of data management challenges. If you want to know more, here is a list of starting points:\n\n- [**Introduction to Redis data types**](https://redis.io/docs/latest/develop/data-types/)\n- [**The full list of Redis commands**](https://redis.io/commands/)\n- [**Redis for AI**](https://redis.io/docs/latest/develop/ai/)\n- [**Redis documentation**](https://redis.io/documentation/)\n\n## What is Redis Open Source?\n\nRedis Community Edition (Redis CE) was renamed Redis Open Source with the v8.0 release.\n\nRedis Ltd. also offers [Redis Software](https://redis.io/enterprise/), a self-managed software with additional compliance, reliability, and resiliency for enterprise scaling,\nand [Redis Cloud](https://redis.io/cloud/), a fully managed service integrated with Google Cloud, Azure, and AWS for production-ready apps.\n\nRead more about the differences between Redis Open Source and Redis [here](https://redis.io/technology/advantages/).\n\n## Getting started\n\nIf you want to get up and running with Redis quickly without needing to build from source, use one of the following methods:\n\n- [**Redis Cloud**](https://cloud.redis.io/)\n- [**Official Redis Docker images (Alpine/Debian)**](https://hub.docker.com/_/redis)\n  ```sh\n  docker run -d -p 6379:6379 redis:latest\n  ```\n- **Redis binary distributions**\n  - [**Snap**](https://github.com/redis/redis-snap)\n  - [**Homebrew**](https://github.com/redis/homebrew-redis)\n  - [**RPM**](https://github.com/redis/redis-rpm)\n  - [**Debian**](https://github.com/redis/redis-debian)\n- [**Redis quick start guides**](https://redis.io/docs/latest/develop/get-started/)\n\nIf you prefer to [build Redis from source](#build-redis-from-source) - see instructions below.\n\n### Redis starter projects\n\nTo get started as quickly as possible in your language of choice, use one of the following starter projects:\n\n- [**Python (redis-py)**](https://github.com/redis-developer/redis-starter-python)\n- [**C#/.NET (NRedisStack/StackExchange.Redis)**](https://github.com/redis-developer/redis-starter-csharp)\n- [**Go (go-redis)**](https://github.com/redis-developer/redis-starter-go)\n- [**JavaScript (node-redis)**](https://github.com/redis-developer/redis-starter-js)\n- [**Java/Spring (Jedis)**](https://github.com/redis-developer/redis-starter-java)\n\n### Using Redis with client libraries\n\nTo connect your application to Redis, you will need a client library. Redis has documented client libraries in most popular languages, with community-supported client libraries in additional languages.\n\n- [**Python (redis-py)**](https://redis.io/docs/latest/develop/clients/redis-py/)\n- [**Python (RedisVL)**](https://redis.io/docs/latest/integrate/redisvl/)\n- [**C#/.NET (NRedisStack/StackExchange.Redis)**](https://redis.io/docs/latest/develop/clients/dotnet/)\n- [**JavaScript (node-redis)**](https://redis.io/docs/latest/develop/clients/nodejs/)\n- [**Java (Jedis)**](https://redis.io/docs/latest/develop/clients/jedis/)\n- [**Java (Lettuce)**](https://redis.io/docs/latest/develop/clients/lettuce/)\n- [**Go (go-redis)**](https://redis.io/docs/latest/develop/clients/go/)\n- [**PHP (Predis)**](https://redis.io/docs/latest/develop/clients/php/)\n- [**C (hiredis)**](https://redis.io/docs/latest/develop/clients/hiredis/)\n- [**Full list of client libraries**](https://redis.io/docs/latest/develop/clients/)\n\n### Using Redis with redis-cli\n\n[`redis-cli`](https://redis.io/docs/latest/develop/tools/cli/) is Redis' command line interface. It is available as part of all the binary distributions and when you build Redis from source.\n\nYou can start a redis-server instance, and then, in another terminal try the following:\n\n```sh\ncd src\n./redis-cli\n```\n\n```text\nredis> ping\nPONG\nredis> set foo bar\nOK\nredis> get foo\n\"bar\"\nredis> incr mycounter\n(integer) 1\nredis> incr mycounter\n(integer) 2\nredis>\n```\n\n### Using Redis with Redis Insight\n\nFor a more visual and user-friendly experience, use [Redis Insight](https://redis.io/docs/latest/develop/tools/insight/) - a tool that lets you explore data, design, develop, and optimize your applications while also serving as a platform for Redis education and onboarding. Redis Insight integrates [Redis Copilot](https://redis.io/chat), a natural language AI assistant that improves the experience when working with data and commands.\n\n- [**Redis Insight documentation**](https://redis.io/docs/latest/develop/tools/insight/)\n- [**Redis Insight GitHub repository**](https://github.com/RedisInsight/RedisInsight)\n\n## Redis data types, processing engines, and capabilities\n\nRedis provides a variety of data types, processing engines, and capabilities to support a wide range of use cases:\n\n**Important:** Features marked with an asterisk (\\*) require Redis to be compiled with the `BUILD_WITH_MODULES=yes` flag when [building Redis from source](#build-redis-from-source)\n\n- [**String:**](https://redis.io/docs/latest/develop/data-types/strings) Sequences of bytes, including text, serialized objects, and binary arrays used for caching, counters, and bitwise operations.\n- [**JSON:**](https://redis.io/docs/latest/develop/data-types/json/) Nested JSON documents that are indexed and searchable using JSONPath expressions and with [Redis Query Engine](https://redis.io/docs/latest/develop/interact/search-and-query/)\n- [**Hash:**](https://redis.io/docs/latest/develop/data-types/hashes/) Field-value maps used to represent basic objects and store groupings of key-value pairs with support for [hash field expiration (TTL)](https://redis.io/docs/latest/develop/data-types/hashes/#field-expiration)\n- [**Redis Query Engine:**](https://redis.io/docs/latest/develop/interact/search-and-query/) Use Redis as a document database, a vector database, a secondary index, and a search engine. Define indexes for hash and JSON documents and then use a rich query language for vector search, full-text search, geospatial queries, and aggregations.\n- [**List:**](https://redis.io/docs/latest/develop/data-types/lists/) Linked lists of string values used as stacks, queues, and for queue management.\n- [**Set:**](https://redis.io/docs/latest/develop/data-types/sets/) Unordered collection of unique strings used for tracking unique items, relations, and common set operations (intersections, unions, differences).\n- [**Sorted set:**](https://redis.io/docs/latest/develop/data-types/sorted-sets/) Collection of unique strings ordered by an associated score used for leaderboards and rate limiters.\n- [**Vector set (beta):**](https://redis.io/docs/latest/develop/data-types/vector-sets/) Collection of vector embeddings used for semantic similarity search, semantic caching, semantic routing, and Retrieval Augmented Generation (RAG).\n- [**Geospatial indexes:**](https://redis.io/docs/latest/develop/data-types/geospatial/) Coordinates used for finding nearby points within a given radius or bounding box.\n- [**Bitmap:**](https://redis.io/docs/latest/develop/data-types/bitmaps/) A set of bit-oriented operations defined on the string type used for efficient set representations and object permissions.\n- [**Bitfield:**](https://redis.io/docs/latest/develop/data-types/bitfields/) Binary-encoded strings that let you set, increment, and get integer values of arbitrary bit length used for limited-range counters, numeric values, and multi-level object permissions such as role-based access control (RBAC)\n- [**Hyperloglog:**](https://redis.io/docs/latest/develop/data-types/probabilistic/hyperloglogs/) A probabilistic data structure for approximating the cardinality of a set used for analytics such as counting unique visits, form fills, etc.\n- \\*[**Bloom filter:**](https://redis.io/docs/latest/develop/data-types/probabilistic/bloom-filter/) A probabilistic data structure to check if a given value is present in a set. Used for fraud detection, ad placement, and unique column (i.e. username/email/slug) checks.\n- \\*[**Cuckoo filter:**](https://redis.io/docs/latest/develop/data-types/probabilistic/cuckoo-filter/) A probabilistic data structure for checking if a given value is present in a set while also allowing limited counting and deletions used in targeted advertising and coupon code validation.\n- \\*[**t-digest:**](https://redis.io/docs/latest/develop/data-types/probabilistic/t-digest/) A probabilistic data structure used for estimating the percentile of a large dataset without having to store and order all the data points. Used for hardware/software monitoring, online gaming, network traffic monitoring, and predictive maintenance.\n- \\*[**Top-k:**](https://redis.io/docs/latest/develop/data-types/probabilistic/top-k/) A probabilistic data structure for finding the most frequent values in a data stream used for trend discovery.\n- \\*[**Count-min sketch:**](https://redis.io/docs/latest/develop/data-types/probabilistic/count-min-sketch/) A probabilistic data structure for estimating how many times a given value appears in a data stream used for sales volume calculations.\n- [**Time series:**](https://redis.io/docs/latest/develop/data-types/timeseries/) Data points indexed in time order used for monitoring sensor data, asset\n  tracking, and predictive analytics\n- [**Pub/sub**:](https://redis.io/docs/latest/develop/interact/pubsub/) A lightweight messaging capability. Publishers send messages to a channel, and subscribers receive messages from that channel.\n- [**Stream**:](https://redis.io/docs/latest/develop/data-types/streams/) An append-only log with random access capabilities and complex consumption strategies such as consumer groups. Used for event sourcing, sensor monitoring, and notifications.\n- [**Transaction:**](https://redis.io/docs/latest/develop/interact/transactions/) Allows the execution of a group of commands in a single step. A request sent by another client will never be served in the middle of the execution of a transaction. This guarantees that the commands are executed as a single isolated operation.\n- [**Programmability:**](https://redis.io/docs/latest/develop/interact/programmability/eval-intro/) Upload and execute Lua scripts on the server. Scripts can employ programmatic control structures and use most of the commands while executing to access the database. Because scripts are executed on the server, reading and writing data from scripts is very efficient.\n\n## Cloud hosted Redis\n\nFully-managed Redis with real-time performance at scale.\n\n[**Redis Cloud**](https://redis.io/cloud/)\n\n## Community\n\n[**Redis Community Resources**](https://redis.io/community/)\n\n## Build Redis from source\n\nThis section refers to building Redis from source. If you want to get up and running with Redis quickly without needing to build from source see the [Getting started section](#getting-started).\n\n### Build and run Redis with all data structures - Ubuntu 20.04 (Focal)\n\nTested with the following Docker image:\n\n- ubuntu:20.04\n\n1. Install required dependencies\n\n   Update your package lists and install the necessary development tools and libraries:\n\n   ```sh\n   apt-get update\n   apt-get install -y sudo\n   sudo apt-get install -y --no-install-recommends ca-certificates wget dpkg-dev gcc g++ libc6-dev libssl-dev make git python3 python3-pip python3-venv python3-dev unzip rsync clang automake autoconf gcc-10 g++-10 libtool\n   ```\n\n2. Use GCC 10 as the default compiler\n\n   Update the system's default compiler to GCC 10:\n\n   ```sh\n   sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-10 100 --slave /usr/bin/g++ g++ /usr/bin/g++-10\n   ```\n\n3. Install CMake\n\n   Install CMake using `pip3` and link it for system-wide access:\n\n   ```sh\n   pip3 install cmake==3.31.6\n   sudo ln -sf /usr/local/bin/cmake /usr/bin/cmake\n   cmake --version\n   ```\n\n   Note: CMake version 3.31.6 is the latest supported version. Newer versions cannot be used.\n\n4. Download the Redis source\n\n   Download a specific version of the Redis source code archive from GitHub.\n\n   Replace `<version>` with the Redis version, for example: `8.0.0`.\n\n   ```sh\n   cd /usr/src\n   wget -O redis-<version>.tar.gz https://github.com/redis/redis/archive/refs/tags/<version>.tar.gz\n   ```\n\n5. Extract the source archive\n\n   Create a directory for the source code and extract the contents into it:\n\n   ```sh\n   cd /usr/src\n   tar xvf redis-<version>.tar.gz\n   rm redis-<version>.tar.gz\n   ```\n\n6. Build Redis\n\n   Set the necessary environment variables and compile Redis:\n\n   ```sh\n   cd /usr/src/redis-<version>\n   export BUILD_TLS=yes BUILD_WITH_MODULES=yes INSTALL_RUST_TOOLCHAIN=yes DISABLE_WERRORS=yes\n   make -j \"$(nproc)\" all\n   ```\n\n7. Run Redis\n\n   ```sh\n   cd /usr/src/redis-<version>\n   ./src/redis-server redis-full.conf\n   ```\n\n### Build and run Redis with all data structures - Ubuntu 22.04 (Jammy)\n\nTested with the following Docker image:\n\n- ubuntu:22.04\n\n1. Install required dependencies\n\n   Update your package lists and install the necessary development tools and libraries:\n\n   ```sh\n   apt-get update\n   apt-get install -y sudo\n   sudo apt-get install -y --no-install-recommends ca-certificates wget dpkg-dev gcc g++ libc6-dev libssl-dev make git cmake python3 python3-pip python3-venv python3-dev unzip rsync clang automake autoconf libtool\n   ```\n\n2. Install CMake\n\n   Install CMake using `pip3` and link it for system-wide access:\n\n   ```sh\n   pip3 install cmake==3.31.6\n   sudo ln -sf /usr/local/bin/cmake /usr/bin/cmake\n   cmake --version\n   ```\n\n   Note: CMake version 3.31.6 is the latest supported version. Newer versions cannot be used.\n\n3. Download the Redis source\n\n   Download a specific version of the Redis source code archive from GitHub.\n\n   Replace `<version>` with the Redis version, for example: `8.0.0`.\n\n   ```sh\n   cd /usr/src\n   wget -O redis-<version>.tar.gz https://github.com/redis/redis/archive/refs/tags/<version>.tar.gz\n   ```\n\n4. Extract the source archive\n\n   Create a directory for the source code and extract the contents into it:\n\n   ```sh\n   cd /usr/src\n   tar xvf redis-<version>.tar.gz\n   rm redis-<version>.tar.gz\n   ```\n\n5. Build Redis\n\n   Set the necessary environment variables and build Redis:\n\n   ```sh\n   cd /usr/src/redis-<version>\n   export BUILD_TLS=yes BUILD_WITH_MODULES=yes INSTALL_RUST_TOOLCHAIN=yes DISABLE_WERRORS=yes\n   make -j \"$(nproc)\" all\n   ```\n\n6. Run Redis\n\n   ```sh\n   cd /usr/src/redis-<version>\n   ./src/redis-server redis-full.conf\n   ```\n\n### Build and run Redis with all data structures - Ubuntu 24.04 (Noble)\n\nTested with the following Docker image:\n\n- ubuntu:24.04\n\n1. Install required dependencies\n\n   Update your package lists and install the necessary development tools and libraries:\n\n   ```sh\n   apt-get update\n   apt-get install -y sudo\n   sudo apt-get install -y --no-install-recommends ca-certificates wget dpkg-dev gcc g++ libc6-dev libssl-dev make git cmake python3 python3-pip python3-venv python3-dev unzip rsync clang automake autoconf libtool\n   ```\n\n2. Download the Redis source\n\n   Download a specific version of the Redis source code archive from GitHub.\n\n   Replace `<version>` with the Redis version, for example: `8.0.0`.\n\n   ```sh\n   cd /usr/src\n   wget -O redis-<version>.tar.gz https://github.com/redis/redis/archive/refs/tags/<version>.tar.gz\n   ```\n\n3. Extract the source archive\n\n   Create a directory for the source code and extract the contents into it:\n\n   ```sh\n   cd /usr/src\n   tar xvf redis-<version>.tar.gz\n   rm redis-<version>.tar.gz\n   ```\n\n4. Build Redis\n\n   Set the necessary environment variables and build Redis:\n\n   ```sh\n   cd /usr/src/redis-<version>\n   export BUILD_TLS=yes BUILD_WITH_MODULES=yes INSTALL_RUST_TOOLCHAIN=yes DISABLE_WERRORS=yes\n   make -j \"$(nproc)\" all\n   ```\n\n5. Run Redis\n\n   ```sh\n   cd /usr/src/redis-<version>\n   ./src/redis-server redis-full.conf\n   ```\n\n### Build and run Redis with all data structures - Debian 11 (Bullseye) / 12 (Bookworm)\n\nTested with the following Docker images:\n\n- debian:bullseye\n- debian:bullseye-slim\n- debian:bookworm\n- debian:bookworm-slim\n\n1. Install required dependencies\n\n   Update your package lists and install the necessary development tools and libraries:\n\n   ```sh\n   apt-get update\n   apt-get install -y sudo\n   sudo apt-get install -y --no-install-recommends ca-certificates wget dpkg-dev gcc g++ libc6-dev libssl-dev make git cmake python3 python3-pip python3-venv python3-dev unzip rsync clang automake autoconf libtool\n   ```\n\n2. Download the Redis source\n\n   Download a specific version of the Redis source code archive from GitHub.\n\n   Replace `<version>` with the Redis version, for example: `8.0.0`.\n\n   ```sh\n   cd /usr/src\n   wget -O redis-<version>.tar.gz https://github.com/redis/redis/archive/refs/tags/<version>.tar.gz\n   ```\n\n3. Extract the source archive\n\n   Create a directory for the source code and extract the contents into it:\n\n   ```sh\n   cd /usr/src\n   tar xvf redis-<version>.tar.gz\n   rm redis-<version>.tar.gz\n   ```\n\n4. Build Redis\n\n   Set the necessary environment variables and build Redis:\n\n   ```sh\n   cd /usr/src/redis-<version>\n   export BUILD_TLS=yes BUILD_WITH_MODULES=yes INSTALL_RUST_TOOLCHAIN=yes DISABLE_WERRORS=yes\n   make -j \"$(nproc)\" all\n   ```\n\n5. Run Redis\n\n   ```sh\n   cd /usr/src/redis-<version>\n   ./src/redis-server redis-full.conf\n   ```\n\n### Build and run Redis with all data structures - AlmaLinux 8.10 / Rocky Linux 8.10\n\nTested with the following Docker images:\n\n- almalinux:8.10\n- almalinux:8.10-minimal\n- rockylinux/rockylinux:8.10\n- rockylinux/rockylinux:8.10-minimal\n\n1. Prepare the system\n\n   For 8.10-minimal, install `sudo` and `dnf` as follows:\n\n   ```sh\n   microdnf install dnf sudo -y\n   ```\n\n   For 8.10 (regular), install sudo as follows:\n\n   ```sh\n   dnf install sudo -y\n   ```\n\n   Clean the package metadata, enable required repositories, and install development tools:\n\n   ```sh\n   sudo dnf clean all\n   sudo tee /etc/yum.repos.d/goreleaser.repo > /dev/null <<EOF\n   [goreleaser]\n   name=GoReleaser\n   baseurl=https://repo.goreleaser.com/yum/\n   enabled=1\n   gpgcheck=0\n   EOF\n   sudo dnf update -y\n   sudo dnf groupinstall \"Development Tools\" -y\n   sudo dnf config-manager --set-enabled powertools\n   sudo dnf install -y epel-release\n   ```\n\n2. Install required dependencies\n\n   Update your package lists and install the necessary development tools and libraries:\n\n   ```sh\n   sudo dnf install -y --nobest --skip-broken pkg-config wget gcc-toolset-13-gcc gcc-toolset-13-gcc-c++ git make openssl openssl-devel python3.11 python3.11-pip python3.11-devel unzip rsync clang curl libtool automake autoconf jq systemd-devel\n   ```\n\n   Create a Python virtual environment:\n\n   ```sh\n   python3.11 -m venv /opt/venv\n   ```\n\n   Enable the GCC toolset:\n\n   ```sh\n   sudo cp /opt/rh/gcc-toolset-13/enable /etc/profile.d/gcc-toolset-13.sh\n   echo \"source /etc/profile.d/gcc-toolset-13.sh\" | sudo tee -a /etc/bashrc\n   ```\n\n3. Install CMake\n\n   Install CMake 3.25.1 manually:\n\n   ```sh\n   CMAKE_VERSION=3.25.1\n   ARCH=$(uname -m)\n   if [ \"$ARCH\" = \"x86_64\" ]; then\n     CMAKE_FILE=cmake-${CMAKE_VERSION}-linux-x86_64.sh\n   else\n     CMAKE_FILE=cmake-${CMAKE_VERSION}-linux-aarch64.sh\n   fi\n   wget https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION}/${CMAKE_FILE}\n   chmod +x ${CMAKE_FILE}\n   ./${CMAKE_FILE} --skip-license --prefix=/usr/local --exclude-subdir\n   rm ${CMAKE_FILE}\n   cmake --version\n   ```\n\n4. Download the Redis source\n\n   Download a specific version of the Redis source code archive from GitHub.\n\n   Replace `<version>` with the Redis version, for example: `8.0.0`.\n\n   ```sh\n   cd /usr/src\n   wget -O redis-<version>.tar.gz https://github.com/redis/redis/archive/refs/tags/<version>.tar.gz\n   ```\n\n5. Extract the source archive\n\n   Create a directory for the source code and extract the contents into it:\n\n   ```sh\n   cd /usr/src\n   tar xvf redis-<version>.tar.gz\n   rm redis-<version>.tar.gz\n   ```\n\n6. Build Redis\n\n   Enable the GCC toolset, set the necessary environment variables, and build Redis:\n\n   ```sh\n   source /etc/profile.d/gcc-toolset-13.sh\n   cd /usr/src/redis-<version>\n   export BUILD_TLS=yes BUILD_WITH_MODULES=yes INSTALL_RUST_TOOLCHAIN=yes DISABLE_WERRORS=yes\n   make -j \"$(nproc)\" all\n   ```\n\n7. Run Redis\n\n   ```sh\n   cd /usr/src/redis-<version>\n   ./src/redis-server redis-full.conf\n   ```\n\n### Build and run Redis with all data structures - AlmaLinux 9.5 / Rocky Linux 9.5\n\nTested with the following Docker images:\n\n- almalinux:9.5\n- almalinux:9.5-minimal\n- rockylinux/rockylinux:9.5\n- rockylinux/rockylinux:9.5-minimal\n\n1. Prepare the system\n\n   For 9.5-minimal, install `sudo` and `dnf` as follows:\n\n   ```sh\n   microdnf install dnf sudo -y\n   ```\n\n   For 9.5 (regular), install sudo as follows:\n\n   ```sh\n   dnf install sudo -y\n   ```\n\n   Clean the package metadata, enable required repositories, and install development tools:\n\n   ```sh\n   sudo tee /etc/yum.repos.d/goreleaser.repo > /dev/null <<EOF\n   [goreleaser]\n   name=GoReleaser\n   baseurl=https://repo.goreleaser.com/yum/\n   enabled=1\n   gpgcheck=0\n   EOF\n   sudo dnf clean all\n   sudo dnf makecache\n   sudo dnf update -y\n   ```\n\n2. Install required dependencies\n\n   Update your package lists and install the necessary development tools and libraries:\n\n   ```sh\n   sudo dnf install -y --nobest --skip-broken pkg-config xz wget which gcc-toolset-13-gcc gcc-toolset-13-gcc-c++ git make openssl openssl-devel python3 python3-pip python3-devel unzip rsync clang curl libtool automake autoconf jq systemd-devel\n   ```\n\n   Create a Python virtual environment:\n\n   ```sh\n   python3 -m venv /opt/venv\n   ```\n\n   Enable the GCC toolset:\n\n   ```sh\n   sudo cp /opt/rh/gcc-toolset-13/enable /etc/profile.d/gcc-toolset-13.sh\n   echo \"source /etc/profile.d/gcc-toolset-13.sh\" | sudo tee -a /etc/bashrc\n   ```\n\n3. Install CMake\n\n   Install CMake 3.25.1 manually:\n\n   ```sh\n   CMAKE_VERSION=3.25.1\n   ARCH=$(uname -m)\n   if [ \"$ARCH\" = \"x86_64\" ]; then\n     CMAKE_FILE=cmake-${CMAKE_VERSION}-linux-x86_64.sh\n   else\n     CMAKE_FILE=cmake-${CMAKE_VERSION}-linux-aarch64.sh\n   fi\n   wget https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION}/${CMAKE_FILE}\n   chmod +x ${CMAKE_FILE}\n   ./${CMAKE_FILE} --skip-license --prefix=/usr/local --exclude-subdir\n   rm ${CMAKE_FILE}\n   cmake --version\n   ```\n\n4. Download the Redis source\n\n   Download a specific version of the Redis source code archive from GitHub.\n\n   Replace `<version>` with the Redis version, for example: `8.0.0`.\n\n   ```sh\n   cd /usr/src\n   wget -O redis-<version>.tar.gz https://github.com/redis/redis/archive/refs/tags/<version>.tar.gz\n   ```\n\n5. Extract the source archive\n\n   Create a directory for the source code and extract the contents into it:\n\n   ```sh\n   cd /usr/src\n   tar xvf redis-<version>.tar.gz\n   rm redis-<version>.tar.gz\n   ```\n\n6. Build Redis\n\n   Enable the GCC toolset, set the necessary environment variables, and build Redis:\n\n   ```sh\n   source /etc/profile.d/gcc-toolset-13.sh\n   cd /usr/src/redis-<version>\n   export BUILD_TLS=yes BUILD_WITH_MODULES=yes INSTALL_RUST_TOOLCHAIN=yes DISABLE_WERRORS=yes\n   make -j \"$(nproc)\" all\n   ```\n\n7. Run Redis\n\n   ```sh\n   cd /usr/src/redis-<version>\n   ./src/redis-server redis-full.conf\n   ```\n\n### Build and run Redis with all data structures - macOS 13 (Ventura) and macOS 14 (Sonoma)\n\n1. Install Homebrew\n\n   If Homebrew is not already installed, follow the installation instructions on the [Homebrew home page](https://brew.sh/).\n\n2. Install required packages\n\n   ```sh\n   export HOMEBREW_NO_AUTO_UPDATE=1\n   brew update\n   brew install coreutils\n   brew install make\n   brew install openssl\n   brew install llvm@18\n   brew install cmake\n   brew install gnu-sed\n   brew install automake\n   brew install libtool\n   brew install wget\n   ```\n\n3. Install Rust\n\n   Rust is required to build the JSON package.\n\n   ```sh\n   RUST_INSTALLER=rust-1.80.1-$(if [ \"$(uname -m)\" = \"arm64\" ]; then echo \"aarch64\"; else echo \"x86_64\"; fi)-apple-darwin\n   wget --quiet -O ${RUST_INSTALLER}.tar.xz https://static.rust-lang.org/dist/${RUST_INSTALLER}.tar.xz\n   tar -xf ${RUST_INSTALLER}.tar.xz\n   (cd ${RUST_INSTALLER} && sudo ./install.sh)\n   ```\n\n4. Download the Redis source\n\n   Download a specific version of the Redis source code archive from GitHub.\n\n   Replace `<version>` with the Redis version, for example: `8.0.0`.\n\n   ```sh\n   cd ~/src\n   wget -O redis-<version>.tar.gz https://github.com/redis/redis/archive/refs/tags/<version>.tar.gz\n   ```\n\n5. Extract the source archive\n\n   Create a directory for the source code and extract the contents into it:\n\n   ```sh\n   cd ~/src\n   tar xvf redis-<version>.tar.gz\n   rm redis-<version>.tar.gz\n   ```\n\n6. Build Redis\n\n   ```sh\n   cd ~/src/redis-<version>\n   export HOMEBREW_PREFIX=\"$(brew --prefix)\"\n   export BUILD_WITH_MODULES=yes\n   export BUILD_TLS=yes\n   export DISABLE_WERRORS=yes\n   PATH=\"$HOMEBREW_PREFIX/opt/libtool/libexec/gnubin:$HOMEBREW_PREFIX/opt/llvm@18/bin:$HOMEBREW_PREFIX/opt/make/libexec/gnubin:$HOMEBREW_PREFIX/opt/gnu-sed/libexec/gnubin:$HOMEBREW_PREFIX/opt/coreutils/libexec/gnubin:$PATH\"\n   export LDFLAGS=\"-L$HOMEBREW_PREFIX/opt/llvm@18/lib\"\n   export CPPFLAGS=\"-I$HOMEBREW_PREFIX/opt/llvm@18/include\"\n   mkdir -p build_dir/etc\n   make -C redis-8.0 -j \"$(nproc)\" all OS=macos\n   make -C redis-8.0 install PREFIX=$(pwd)/build_dir OS=macos\n   ```\n\n7. Run Redis\n\n   ```sh\n   export LC_ALL=en_US.UTF-8\n   export LANG=en_US.UTF-8\n   build_dir/bin/redis-server redis-full.conf\n   ```\n\n### Build and run Redis with all data structures - macOS 15 (Sequoia)\n\nSupport and instructions will be provided at a later date.\n\n### Building Redis - flags and general notes\n\nRedis can be compiled and used on Linux, OSX, OpenBSD, NetBSD, FreeBSD.\nWe support big endian and little endian architectures, and both 32 bit and 64-bit systems.\n\nIt may compile on Solaris derived systems (for instance SmartOS) but our support for this platform is _best effort_ and Redis is not guaranteed to work as well as on Linux, OSX, and \\*BSD.\n\nTo build Redis with all the data structures (including JSON, time series, Bloom filter, cuckoo filter, count-min sketch, top-k, and t-digest) and with Redis Query Engine, make sure first that all the prerequisites are installed (see build instructions above, per operating system). You need to use the following flag in the make command:\n\n```sh\nmake BUILD_WITH_MODULES=yes\n```\n\nNote: `BUILD_WITH_MODULES=yes` is not supported on 32 bit systems.\n\nTo build Redis with just the core data structures, use:\n\n```sh\nmake\n```\n\nTo build with TLS support, you need OpenSSL development libraries (e.g. libssl-dev on Debian/Ubuntu) and the following flag in the make command:\n\n```sh\nmake BUILD_TLS=yes\n```\n\nTo build with systemd support, you need systemd development libraries (such as libsystemd-dev on Debian/Ubuntu or systemd-devel on CentOS), and the following flag:\n\n```sh\nmake USE_SYSTEMD=yes\n```\n\nTo append a suffix to Redis program names, add the following flag:\n\n```sh\nmake PROG_SUFFIX=\"-alt\"\n```\n\nYou can build a 32 bit Redis binary using:\n\n```sh\nmake 32bit\n```\n\nAfter building Redis, it is a good idea to test it using:\n\n```sh\nmake test\n```\n\nIf TLS is built, running the tests with TLS enabled (you will need `tcl-tls` installed):\n\n```sh\n./utils/gen-test-certs.sh\n./runtest --tls\n```\n\n### Fixing build problems with dependencies or cached build options\n\nRedis has some dependencies which are included in the `deps` directory. `make` does not automatically rebuild dependencies even if something in the source code of dependencies changes.\n\nWhen you update the source code with `git pull` or when code inside the dependencies tree is modified in any other way, make sure to use the following command in order to really clean everything and rebuild from scratch:\n\n```sh\nmake distclean\n```\n\nThis will clean: jemalloc, lua, hiredis, linenoise and other dependencies.\n\nAlso, if you force certain build options like 32bit target, no C compiler optimizations (for debugging purposes), and other similar build time options, those options are cached indefinitely until you issue a `make distclean`\ncommand.\n\n### Fixing problems building 32 bit binaries\n\nIf after building Redis with a 32 bit target you need to rebuild it\nwith a 64 bit target, or the other way around, you need to perform a `make distclean` in the root directory of the Redis distribution.\n\nIn case of build errors when trying to build a 32 bit binary of Redis, try the following steps:\n\n- Install the package libc6-dev-i386 (also try g++-multilib).\n- Try using the following command line instead of `make 32bit`:\n  `make CFLAGS=\"-m32 -march=native\" LDFLAGS=\"-m32\"`\n\n### Allocator\n\nSelecting a non-default memory allocator when building Redis is done by setting the `MALLOC` environment variable. Redis is compiled and linked against libc malloc by default, except for jemalloc being the default on Linux systems. This default was picked because jemalloc has proven to have fewer fragmentation problems than libc malloc.\n\nTo force compiling against libc malloc, use:\n\n```sh\nmake MALLOC=libc\n```\n\nTo compile against jemalloc on Mac OS X systems, use:\n\n```sh\nmake MALLOC=jemalloc\n```\n\n### Monotonic clock\n\nBy default, Redis will build using the POSIX clock_gettime function as the monotonic clock source. On most modern systems, the internal processor clock can be used to improve performance. Cautions can be found here: http://oliveryang.net/2015/09/pitfalls-of-TSC-usage/\n\nOn ARM aarch64 systems, the hardware clock is enabled by default because the ARM Generic Timer is architecturally guaranteed to be available and monotonic on all ARMv8-A processors (see the *â€œThe Generic Timer in AArch64 stateâ€* section of the *Arm Architecture Reference Manual for Armv8-A*).\n\nTo build with support for the processor's internal instruction clock on other architectures, use:\n\n```sh\nmake CFLAGS=\"-DUSE_PROCESSOR_CLOCK\"\n```\n\n### Verbose build\n\nRedis will build with a user-friendly colorized output by default.\nIf you want to see a more verbose output, use the following:\n\n```sh\nmake V=1\n```\n\n### Running Redis with TLS\n\nPlease consult the [TLS.md](TLS.md) file for more information on how to use Redis with TLS.\n\n### Running Redis with the Query Engine and optional proprietary Intel SVS-VAMANA optimisations\n\n**License Disclaimer**\nIf you are using Redis Open Source under AGPLv3 or SSPLv1, you cannot use it together with the Intel Optimizations (Leanvec and LVQ binaries). The reason is that the Intel SVS license is not compatible with those licenses.\nThe Leanvec and LVQ techniques are closed source and are only available for use with Redis Open Source when distributed under the RSALv2 license.\nFor more details, please refer to the information provided by Intel [here](https://github.com/intel/ScalableVectorSearch).\n\nBy default, Redis with the Redis Query Engine supports SVS-VAMANA index with global 8-bit quantisation. To compile Redis with the Intel SVS-VAMANA optimisations, LeanVec and LVQ, use the following:\n\n```sh\nmake BUILD_INTEL_SVS_OPT=yes\n```\n\nAlternatively, you can export the variable before running the build step for your platform:\n\n```sh\nexport BUILD_INTEL_SVS_OPT=yes\nmake\n```\n\n\n## Code contributions\n\nBy contributing code to the Redis project in any form, including sending a pull request via GitHub, a code fragment or patch via private email or public discussion groups, you agree to release your code under the terms of the Redis Software Grant and Contributor License Agreement. Please see the CONTRIBUTING.md file in this source distribution for more information. For security bugs and vulnerabilities, please see SECURITY.md and the description of the ability of users to backport security patches under Redis Open Source 7.4+ under BSDv3. Open Source Redis releases are subject to the following licenses:\n\n1. Version 7.2.x and prior releases are subject to BSDv3. These contributions to the original Redis core project are owned by their contributors and licensed under the 3BSDv3 license as referenced in the REDISCONTRIBUTIONS.txt file. Any copy of that license in this repository applies only to those contributions;\n\n2. Versions 7.4.x to 7.8.x are subject to your choice of RSALv2 or SSPLv1; and\n\n3. Version 8.0.x and subsequent releases are subject to the tri-license RSALv2/SSPLv1/AGPLv3 at your option as referenced in the LICENSE.txt file.\n\n## Redis Trademarks\n\nThe purpose of a trademark is to identify the goods and services of a person or company without causing confusion. As the registered owner of its name and logo, Redis accepts certain limited uses of its trademarks, but it has requirements that must be followed as described in its Trademark Guidelines available at: https://redis.io/legal/trademark-policy/.\n",
      "stars_today": 12
    },
    {
      "id": 7691631,
      "name": "moby",
      "full_name": "moby/moby",
      "description": "The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems",
      "html_url": "https://github.com/moby/moby",
      "stars": 71365,
      "forks": 18881,
      "language": "Go",
      "topics": [
        "containers",
        "docker",
        "go",
        "golang"
      ],
      "created_at": "2013-01-18T18:10:57Z",
      "updated_at": "2026-01-15T19:28:46Z",
      "pushed_at": "2026-01-15T16:39:40Z",
      "open_issues": 3775,
      "owner": {
        "login": "moby",
        "avatar_url": "https://avatars.githubusercontent.com/u/27259197?v=4"
      },
      "readme": "The Moby Project\n================\n\n[![PkgGoDev](https://pkg.go.dev/badge/github.com/moby/moby/v2)](https://pkg.go.dev/github.com/moby/moby/v2)\n![GitHub License](https://img.shields.io/github/license/moby/moby)\n[![Go Report Card](https://goreportcard.com/badge/github.com/moby/moby/v2)](https://goreportcard.com/report/github.com/moby/moby/v2)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/moby/moby/badge)](https://scorecard.dev/viewer/?uri=github.com/moby/moby)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10989/badge)](https://www.bestpractices.dev/projects/10989)\n\n\n![Moby Project logo](docs/static_files/moby-project-logo.png \"The Moby Project\")\n\nMoby is an open-source project created by Docker to enable and accelerate software containerization.\n\nIt provides a \"Lego set\" of toolkit components, the framework for assembling them into custom container-based systems, and a place for all container enthusiasts and professionals to experiment and exchange ideas.\nComponents include container build tools, a container registry, orchestration tools, a runtime and more, and these can be used as building blocks in conjunction with other tools and projects.\n\n## Principles\n\nMoby is an open project guided by strong principles, aiming to be modular, flexible and without too strong an opinion on user experience.\nIt is open to the community to help set its direction.\n\n- Modular: the project includes lots of components that have well-defined functions and APIs that work together.\n- Batteries included but swappable: Moby includes enough components to build fully featured container systems, but its modular architecture ensures that most of the components can be swapped by different implementations.\n- Usable security: Moby provides secure defaults without compromising usability.\n- Developer focused: The APIs are intended to be functional and useful to build powerful tools.\nThey are not necessarily intended as end user tools but as components aimed at developers.\nDocumentation and UX is aimed at developers not end users.\n\n## Audience\n\nThe Moby Project is intended for engineers, integrators and enthusiasts looking to modify, hack, fix, experiment, invent and build systems based on containers.\nIt is not for people looking for a commercially supported system, but for people who want to work and learn with open source code.\n\n## Relationship with Docker\n\nThe components and tools in the Moby Project are initially the open source components that Docker and the community have built for the Docker Project.\nNew projects can be added if they fit with the community goals. Docker is committed to using Moby as the upstream for the Docker Product.\nHowever, other projects are also encouraged to use Moby as an upstream, and to reuse the components in diverse ways, and all these uses will be treated in the same way. External maintainers and contributors are welcomed.\n\nThe Moby project is not intended as a location for support or feature requests for Docker products, but as a place for contributors to work on open source code, fix bugs, and make the code more useful.\nThe releases are supported by the maintainers, community and users, on a best efforts basis only. For customers who want enterprise or commercial support, [Docker Desktop](https://www.docker.com/products/docker-desktop/) and [Mirantis Container Runtime](https://www.mirantis.com/software/mirantis-container-runtime/) are the appropriate products for these use cases.\n\n-----\n\nLegal\n=====\n\n*Brought to you courtesy of our legal counsel. For more context,\nplease see the [NOTICE](https://github.com/moby/moby/blob/master/NOTICE) document in this repo.*\n\nUse and transfer of Moby may be subject to certain restrictions by the\nUnited States and other governments.\n\nIt is your responsibility to ensure that your use and/or transfer does not\nviolate applicable laws.\n\nFor more information, please see https://www.bis.doc.gov\n\nLicensing\n=========\nMoby is licensed under the Apache License, Version 2.0. See\n[LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full\nlicense text.\n",
      "stars_today": 12
    },
    {
      "id": 23357588,
      "name": "protobuf",
      "full_name": "protocolbuffers/protobuf",
      "description": "Protocol Buffers - Google's data interchange format",
      "html_url": "https://github.com/protocolbuffers/protobuf",
      "stars": 70317,
      "forks": 16009,
      "language": "C++",
      "topics": [
        "marshalling",
        "protobuf",
        "protobuf-runtime",
        "protoc",
        "protocol-buffers",
        "protocol-compiler",
        "rpc",
        "serialization"
      ],
      "created_at": "2014-08-26T15:52:15Z",
      "updated_at": "2026-01-16T00:22:01Z",
      "pushed_at": "2026-01-15T22:46:34Z",
      "open_issues": 246,
      "owner": {
        "login": "protocolbuffers",
        "avatar_url": "https://avatars.githubusercontent.com/u/26310541?v=4"
      },
      "readme": "Protocol Buffers - Google's data interchange format\n===================================================\n\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/protocolbuffers/protobuf/badge)](https://securityscorecards.dev/viewer/?uri=github.com/protocolbuffers/protobuf)\n\nCopyright 2008 Google LLC\n\nOverview\n--------\n\nProtocol Buffers (a.k.a., protobuf) are Google's language-neutral,\nplatform-neutral, extensible mechanism for serializing structured data. You\ncan learn more about it in [protobuf's documentation](https://protobuf.dev).\n\nThis README file contains protobuf installation instructions. To install\nprotobuf, you need to install the protocol compiler (used to compile .proto\nfiles) and the protobuf runtime for your chosen programming language.\n\nWorking With Protobuf Source Code\n---------------------------------\n\nMost users will find working from\n[supported releases](https://github.com/protocolbuffers/protobuf/releases) to be\nthe easiest path.\n\nIf you choose to work from the head revision of the main branch your build will\noccasionally be broken by source-incompatible changes and insufficiently-tested\n(and therefore broken) behavior.\n\nIf you are using C++ or otherwise need to build protobuf from source as a part\nof your project, you should pin to a release commit on a release branch.\n\nThis is because even release branches can experience some instability in between\nrelease commits.\n\n### Bazel with Bzlmod\n\nProtobuf supports\n[Bzlmod](https://bazel.build/external/module) with Bazel 7 +.\nUsers should specify a dependency on protobuf in their MODULE.bazel file as\nfollows.\n\n```\nbazel_dep(name = \"protobuf\", version = <VERSION>)\n```\n\nUsers can optionally override the repo name, such as for compatibility with\nWORKSPACE.\n\n```\nbazel_dep(name = \"protobuf\", version = <VERSION>, repo_name = \"com_google_protobuf\")\n```\n\n### Bazel with WORKSPACE\n\nUsers can also add the following to their legacy\n[WORKSPACE](https://bazel.build/external/overview#workspace-system) file.\n\nNote that with the release of 30.x there are a few more load statements to\nproperly set up rules_java and rules_python.\n\n```\nhttp_archive(\n    name = \"com_google_protobuf\",\n    strip_prefix = \"protobuf-VERSION\",\n    sha256 = ...,\n    url = ...,\n)\n\nload(\"@com_google_protobuf//:protobuf_deps.bzl\", \"protobuf_deps\")\n\nprotobuf_deps()\n\nload(\"@rules_java//java:rules_java_deps.bzl\", \"rules_java_dependencies\")\n\nrules_java_dependencies()\n\nload(\"@rules_java//java:repositories.bzl\", \"rules_java_toolchains\")\n\nrules_java_toolchains()\n\nload(\"@rules_python//python:repositories.bzl\", \"py_repositories\")\n\npy_repositories()\n```\n\nProtobuf Compiler Installation\n------------------------------\n\nThe protobuf compiler is written in C++. If you are using C++, please follow\nthe [C++ Installation Instructions](src/README.md) to install protoc along\nwith the C++ runtime.\n\nFor non-C++ users, the simplest way to install the protocol compiler is to\ndownload a pre-built binary from our [GitHub release page](https://github.com/protocolbuffers/protobuf/releases).\n\nIn the downloads section of each release, you can find pre-built binaries in\nzip packages: `protoc-$VERSION-$PLATFORM.zip`. It contains the protoc binary\nas well as a set of standard `.proto` files distributed along with protobuf.\n\nIf you are looking for an old version that is not available in the release\npage, check out the [Maven repository](https://repo1.maven.org/maven2/com/google/protobuf/protoc/).\n\nThese pre-built binaries are only provided for released versions. If you want\nto use the github main version at HEAD, or you need to modify protobuf code,\nor you are using C++, it's recommended to build your own protoc binary from\nsource.\n\nIf you would like to build protoc binary from source, see the [C++ Installation Instructions](src/README.md).\n\nProtobuf Runtime Installation\n-----------------------------\n\nProtobuf supports several different programming languages. For each programming\nlanguage, you can find instructions in the corresponding source directory about\nhow to install protobuf runtime for that specific language:\n\n| Language                             | Source                                                      |\n|--------------------------------------|-------------------------------------------------------------|\n| C++ (include C++ runtime and protoc) | [src](src)                                                  |\n| Java                                 | [java](java)                                                |\n| Python                               | [python](python)                                            |\n| Objective-C                          | [objectivec](objectivec)                                    |\n| C#                                   | [csharp](csharp)                                            |\n| Ruby                                 | [ruby](ruby)                                                |\n| Go                                   | [protocolbuffers/protobuf-go](https://github.com/protocolbuffers/protobuf-go)|\n| PHP                                  | [php](php)                                                  |\n| Dart                                 | [dart-lang/protobuf](https://github.com/dart-lang/protobuf) |\n| JavaScript                           | [protocolbuffers/protobuf-javascript](https://github.com/protocolbuffers/protobuf-javascript)|\n\nQuick Start\n-----------\n\nThe best way to learn how to use protobuf is to follow the [tutorials in our\ndeveloper guide](https://protobuf.dev/getting-started).\n\nIf you want to learn from code examples, take a look at the examples in the\n[examples](examples) directory.\n\nDocumentation\n-------------\n\nThe complete documentation is available at the [Protocol Buffers doc site](https://protobuf.dev).\n\nSupport Policy\n--------------\n\nRead about our [version support policy](https://protobuf.dev/version-support/)\nto stay current on support timeframes for the language libraries.\n\nDeveloper Community\n-------------------\n\nTo be alerted to upcoming changes in Protocol Buffers and connect with protobuf developers and users,\n[join the Google Group](https://groups.google.com/g/protobuf).\n",
      "stars_today": 12
    },
    {
      "id": 9852918,
      "name": "Ghost",
      "full_name": "TryGhost/Ghost",
      "description": "Independent technology for modern publishing, memberships, subscriptions and newsletters.",
      "html_url": "https://github.com/TryGhost/Ghost",
      "stars": 51602,
      "forks": 11286,
      "language": "JavaScript",
      "topics": [
        "blogging",
        "cms",
        "ghost",
        "javascript",
        "journalism",
        "nodejs",
        "publishing",
        "web-application"
      ],
      "created_at": "2013-05-04T11:09:13Z",
      "updated_at": "2026-01-16T00:39:08Z",
      "pushed_at": "2026-01-16T00:42:01Z",
      "open_issues": 259,
      "owner": {
        "login": "TryGhost",
        "avatar_url": "https://avatars.githubusercontent.com/u/2178663?v=4"
      },
      "readme": "&nbsp;\n<p align=\"center\">\n  <a href=\"https://ghost.org/#gh-light-mode-only\" target=\"_blank\">\n    <img src=\"https://user-images.githubusercontent.com/65487235/157884383-1b75feb1-45d8-4430-b636-3f7e06577347.png\" alt=\"Ghost\" width=\"200px\">\n  </a>\n  <a href=\"https://ghost.org/#gh-dark-mode-only\" target=\"_blank\">\n    <img src=\"https://user-images.githubusercontent.com/65487235/157849205-aa24152c-4610-4d7d-b752-3a8c4f9319e6.png\" alt=\"Ghost\" width=\"200px\">\n  </a>\n</p>\n&nbsp;\n\n<p align=\"center\">\n    <a href=\"https://ghost.org/\">Ghost.org</a> â€¢\n    <a href=\"https://forum.ghost.org\">Forum</a> â€¢\n    <a href=\"https://ghost.org/docs/\">Docs</a> â€¢\n    <a href=\"https://github.com/TryGhost/Ghost/blob/main/.github/CONTRIBUTING.md\">Contributing</a> â€¢\n    <a href=\"https://twitter.com/ghost\">Twitter</a>\n    <br /><br />\n    <a href=\"https://ghost.org/\">\n        <img src=\"https://img.shields.io/badge/downloads-100M+-brightgreen.svg\" alt=\"Downloads\" />\n    </a>\n    <a href=\"https://github.com/TryGhost/Ghost/releases/\">\n        <img src=\"https://img.shields.io/github/release/TryGhost/Ghost.svg\" alt=\"Latest release\" />\n    </a>\n    <a href=\"https://github.com/TryGhost/Ghost/actions\">\n        <img src=\"https://github.com/TryGhost/Ghost/workflows/CI/badge.svg?branch=main\" alt=\"Build status\" />\n    </a>\n    <a href=\"https://github.com/TryGhost/Ghost/contributors/\">\n        <img src=\"https://img.shields.io/github/contributors/TryGhost/Ghost.svg\" alt=\"Contributors\" />\n    </a>\n</p>\n\n&nbsp;\n\n> [!NOTE]\n> Love open source? We're hiring! Ghost is looking staff engineers to [join the team](https://careers.ghost.org) and work with us full-time\n\n<a href=\"https://ghost.org/\"><img src=\"https://user-images.githubusercontent.com/353959/169805900-66be5b89-0859-4816-8da9-528ed7534704.png\" alt=\"Fiercely independent, professional publishing. Ghost is the most popular open source, headless Node.js CMS which already works with all the tools you know and love.\" /></a>\n\n&nbsp;\n\n<a href=\"https://ghost.org/pricing/#gh-light-mode-only\" target=\"_blank\"><img src=\"https://user-images.githubusercontent.com/65487235/157849437-9b8fcc48-1920-4b26-a1e8-5806db0e6bb9.png\" alt=\"Ghost(Pro)\" width=\"165px\" /></a>\n<a href=\"https://ghost.org/pricing/#gh-dark-mode-only\" target=\"_blank\"><img src=\"https://user-images.githubusercontent.com/65487235/157849438-79889b04-b7b6-4ba7-8de6-4c1e4b4e16a5.png\" alt=\"Ghost(Pro)\" width=\"165px\" /></a>\n\nThe easiest way to get a production instance deployed is with our official **[Ghost(Pro)](https://ghost.org/pricing/)** managed service. It takes about 2 minutes to launch a new site with worldwide CDN, backups, security and maintenance all done for you.\n\nFor most people this ends up being the best value option because of [how much time it saves](https://ghost.org/docs/hosting/) â€” and 100% of revenue goes to the Ghost Foundation; funding the maintenance and further development of the project itself. So youâ€™ll be supporting open source software *and* getting a great service!\n\n&nbsp;\n\n# Quickstart install\n\nIf you want to run your own instance of Ghost, in most cases the best way is to use our **CLI tool**\n\n```\nnpm install ghost-cli -g\n```\n\n&nbsp;\n\nThen, if installing locally add the `local` flag to get up and running in under a minute - [Local install docs](https://ghost.org/docs/install/local/)\n\n```\nghost install local\n```\n\n&nbsp;\n\nor on a server run the full install, including automatic SSL setup using LetsEncrypt - [Production install docs](https://ghost.org/docs/install/ubuntu/)\n\n```\nghost install\n```\n\n&nbsp;\n\nCheck out our [official documentation](https://ghost.org/docs/) for more information about our [recommended hosting stack](https://ghost.org/docs/hosting/) & properly [upgrading Ghost](https://ghost.org/docs/update/), plus everything you need to develop your own Ghost [themes](https://ghost.org/docs/themes/) or work with [our API](https://ghost.org/docs/content-api/).\n\n### Contributors & advanced developers\n\nFor anyone wishing to contribute to Ghost or to hack/customize core files we recommend following our full development setup guides: [Contributor guide](https://ghost.org/docs/contributing/) â€¢ [Developer setup](https://ghost.org/docs/install/source/)\n\n&nbsp;\n\n# Ghost sponsors\n\nA big thanks to our sponsors and partners who make Ghost possible. If you're interested in sponsoring Ghost and supporting the project, please check out our profile on [GitHub sponsors](https://github.com/sponsors/TryGhost) :heart:\n\n**[DigitalOcean](https://m.do.co/c/9ff29836d717)** â€¢ **[Fastly](https://www.fastly.com/)** â€¢ **[Tinybird](https://tbrd.co/ghost)**\n\n&nbsp;\n\n# Getting help\n\nEveryone can get help and support from a large community of developers over on the [Ghost forum](https://forum.ghost.org/). **Ghost(Pro)** customers have access to 24/7 email support.\n\nTo stay up to date with all the latest news and product updates, make sure you [subscribe to our changelog newsletter](https://ghost.org/changelog/) â€” or follow us [on Twitter](https://twitter.com/Ghost), if you prefer your updates bite-sized and facetious. :saxophone::turtle:\n\n&nbsp;\n\n# License & trademark\n\nCopyright (c) 2013-2025 Ghost Foundation - Released under the [MIT license](LICENSE).\nGhost and the Ghost Logo are trademarks of Ghost Foundation Ltd. Please see our [trademark policy](https://ghost.org/trademark/) for info on acceptable usage.\n",
      "stars_today": 12
    },
    {
      "id": 118105436,
      "name": "migrate",
      "full_name": "golang-migrate/migrate",
      "description": "Database migrations. CLI and Golang library.",
      "html_url": "https://github.com/golang-migrate/migrate",
      "stars": 17955,
      "forks": 1541,
      "language": "Go",
      "topics": [
        "aws-s3",
        "cassandra",
        "database",
        "databases",
        "go",
        "golang",
        "google-cloud-spanner",
        "google-cloud-storage",
        "hacktoberfest",
        "mariadb",
        "migration",
        "migrations",
        "mongodb",
        "mysql",
        "neo4j",
        "postgres",
        "spanner",
        "sql",
        "sqlite"
      ],
      "created_at": "2018-01-19T09:30:58Z",
      "updated_at": "2026-01-15T22:15:13Z",
      "pushed_at": "2025-12-14T23:16:48Z",
      "open_issues": 448,
      "owner": {
        "login": "golang-migrate",
        "avatar_url": "https://avatars.githubusercontent.com/u/35595841?v=4"
      },
      "readme": "[![GitHub Workflow Status (branch)](https://img.shields.io/github/actions/workflow/status/golang-migrate/migrate/ci.yaml?branch=master)](https://github.com/golang-migrate/migrate/actions/workflows/ci.yaml?query=branch%3Amaster)\n[![GoDoc](https://pkg.go.dev/badge/github.com/golang-migrate/migrate)](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)\n[![Coverage Status](https://img.shields.io/coveralls/github/golang-migrate/migrate/master.svg)](https://coveralls.io/github/golang-migrate/migrate?branch=master)\n[![packagecloud.io](https://img.shields.io/badge/deb-packagecloud.io-844fec.svg)](https://packagecloud.io/golang-migrate/migrate?filter=debs)\n[![Docker Pulls](https://img.shields.io/docker/pulls/migrate/migrate.svg)](https://hub.docker.com/r/migrate/migrate/)\n![Supported Go Versions](https://img.shields.io/badge/Go-1.24%2C%201.25-lightgrey.svg)\n[![GitHub Release](https://img.shields.io/github/release/golang-migrate/migrate.svg)](https://github.com/golang-migrate/migrate/releases)\n[![Go Report Card](https://goreportcard.com/badge/github.com/golang-migrate/migrate/v4)](https://goreportcard.com/report/github.com/golang-migrate/migrate/v4)\n\n# migrate\n\n__Database migrations written in Go. Use as [CLI](#cli-usage) or import as [library](#use-in-your-go-project).__\n\n* Migrate reads migrations from [sources](#migration-sources)\n   and applies them in correct order to a [database](#databases).\n* Drivers are \"dumb\", migrate glues everything together and makes sure the logic is bulletproof.\n   (Keeps the drivers lightweight, too.)\n* Database drivers don't assume things or try to correct user input. When in doubt, fail.\n\nForked from [mattes/migrate](https://github.com/mattes/migrate)\n\n## Databases\n\nDatabase drivers run migrations. [Add a new database?](database/driver.go)\n\n* [PostgreSQL](database/postgres)\n* [PGX v4](database/pgx)\n* [PGX v5](database/pgx/v5)\n* [Redshift](database/redshift)\n* [Ql](database/ql)\n* [Cassandra / ScyllaDB](database/cassandra)\n* [SQLite](database/sqlite)\n* [SQLite3](database/sqlite3) ([todo #165](https://github.com/mattes/migrate/issues/165))\n* [SQLCipher](database/sqlcipher)\n* [MySQL / MariaDB](database/mysql)\n* [Neo4j](database/neo4j)\n* [MongoDB](database/mongodb)\n* [CrateDB](database/crate) ([todo #170](https://github.com/mattes/migrate/issues/170))\n* [Shell](database/shell) ([todo #171](https://github.com/mattes/migrate/issues/171))\n* [Google Cloud Spanner](database/spanner)\n* [CockroachDB](database/cockroachdb)\n* [YugabyteDB](database/yugabytedb)\n* [ClickHouse](database/clickhouse)\n* [Firebird](database/firebird)\n* [MS SQL Server](database/sqlserver)\n* [rqlite](database/rqlite)\n\n### Database URLs\n\nDatabase connection strings are specified via URLs. The URL format is driver dependent but generally has the form: `dbdriver://username:password@host:port/dbname?param1=true&param2=false`\n\nAny [reserved URL characters](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters) need to be escaped. Note, the `%` character also [needs to be escaped](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_the_percent_character)\n\nExplicitly, the following characters need to be escaped:\n`!`, `#`, `$`, `%`, `&`, `'`, `(`, `)`, `*`, `+`, `,`, `/`, `:`, `;`, `=`, `?`, `@`, `[`, `]`\n\nIt's easiest to always run the URL parts of your DB connection URL (e.g. username, password, etc) through an URL encoder. See the example Python snippets below:\n\n```bash\n$ python3 -c 'import urllib.parse; print(urllib.parse.quote(input(\"String to encode: \"), \"\"))'\nString to encode: FAKEpassword!#$%&'()*+,/:;=?@[]\nFAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D\n$ python2 -c 'import urllib; print urllib.quote(raw_input(\"String to encode: \"), \"\")'\nString to encode: FAKEpassword!#$%&'()*+,/:;=?@[]\nFAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D\n$\n```\n\n## Migration Sources\n\nSource drivers read migrations from local or remote sources. [Add a new source?](source/driver.go)\n\n* [Filesystem](source/file) - read from filesystem\n* [io/fs](source/iofs) - read from a Go [io/fs](https://pkg.go.dev/io/fs#FS)\n* [Go-Bindata](source/go_bindata) - read from embedded binary data ([jteeuwen/go-bindata](https://github.com/jteeuwen/go-bindata))\n* [pkger](source/pkger) - read from embedded binary data ([markbates/pkger](https://github.com/markbates/pkger))\n* [GitHub](source/github) - read from remote GitHub repositories\n* [GitHub Enterprise](source/github_ee) - read from remote GitHub Enterprise repositories\n* [Bitbucket](source/bitbucket) - read from remote Bitbucket repositories\n* [Gitlab](source/gitlab) - read from remote Gitlab repositories\n* [AWS S3](source/aws_s3) - read from Amazon Web Services S3\n* [Google Cloud Storage](source/google_cloud_storage) - read from Google Cloud Platform Storage\n\n## CLI usage\n\n* Simple wrapper around this library.\n* Handles ctrl+c (SIGINT) gracefully.\n* No config search paths, no config files, no magic ENV var injections.\n\n[CLI Documentation](cmd/migrate) (includes CLI install instructions)\n\n### Basic usage\n\n```bash\n$ migrate -source file://path/to/migrations -database postgres://localhost:5432/database up 2\n```\n\n### Docker usage\n\n```bash\n$ docker run -v {{ migration dir }}:/migrations --network host migrate/migrate\n    -path=/migrations/ -database postgres://localhost:5432/database up 2\n```\n\n## Use in your Go project\n\n* API is stable and frozen for this release (v3 & v4).\n* Uses [Go modules](https://golang.org/cmd/go/#hdr-Modules__module_versions__and_more) to manage dependencies.\n* To help prevent database corruptions, it supports graceful stops via `GracefulStop chan bool`.\n* Bring your own logger.\n* Uses `io.Reader` streams internally for low memory overhead.\n* Thread-safe and no goroutine leaks.\n\n__[Go Documentation](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)__\n\n```go\nimport (\n    \"github.com/golang-migrate/migrate/v4\"\n    _ \"github.com/golang-migrate/migrate/v4/database/postgres\"\n    _ \"github.com/golang-migrate/migrate/v4/source/github\"\n)\n\nfunc main() {\n    m, err := migrate.New(\n        \"github://mattes:personal-access-token@mattes/migrate_test\",\n        \"postgres://localhost:5432/database?sslmode=enable\")\n    m.Steps(2)\n}\n```\n\nWant to use an existing database client?\n\n```go\nimport (\n    \"database/sql\"\n    _ \"github.com/lib/pq\"\n    \"github.com/golang-migrate/migrate/v4\"\n    \"github.com/golang-migrate/migrate/v4/database/postgres\"\n    _ \"github.com/golang-migrate/migrate/v4/source/file\"\n)\n\nfunc main() {\n    db, err := sql.Open(\"postgres\", \"postgres://localhost:5432/database?sslmode=enable\")\n    driver, err := postgres.WithInstance(db, &postgres.Config{})\n    m, err := migrate.NewWithDatabaseInstance(\n        \"file:///migrations\",\n        \"postgres\", driver)\n    m.Up() // or m.Steps(2) if you want to explicitly set the number of migrations to run\n}\n```\n\n## Getting started\n\nGo to [getting started](GETTING_STARTED.md)\n\n## Tutorials\n\n* [CockroachDB](database/cockroachdb/TUTORIAL.md)\n* [PostgreSQL](database/postgres/TUTORIAL.md)\n\n(more tutorials to come)\n\n## Migration files\n\nEach migration has an up and down migration. [Why?](FAQ.md#why-two-separate-files-up-and-down-for-a-migration)\n\n```bash\n1481574547_create_users_table.up.sql\n1481574547_create_users_table.down.sql\n```\n\n[Best practices: How to write migrations.](MIGRATIONS.md)\n\n## Coming from another db migration tool?\n\nCheck out [migradaptor](https://github.com/musinit/migradaptor/).\n*Note: migradaptor is not affiliated or supported by this project*\n\n## Versions\n\nVersion | Supported? | Import | Notes\n--------|------------|--------|------\n**master** | :white_check_mark: | `import \"github.com/golang-migrate/migrate/v4\"` | New features and bug fixes arrive here first |\n**v4** | :white_check_mark: | `import \"github.com/golang-migrate/migrate/v4\"` | Used for stable releases |\n**v3** | :x: | `import \"github.com/golang-migrate/migrate\"` (with package manager) or `import \"gopkg.in/golang-migrate/migrate.v3\"` (not recommended) | **DO NOT USE** - No longer supported |\n\n## Development and Contributing\n\nYes, please! [`Makefile`](Makefile) is your friend,\nread the [development guide](CONTRIBUTING.md).\n\nAlso have a look at the [FAQ](FAQ.md).\n\n---\n\nLooking for alternatives? [https://awesome-go.com/#database](https://awesome-go.com/#database).\n",
      "stars_today": 12
    },
    {
      "id": 479289739,
      "name": "rerun",
      "full_name": "rerun-io/rerun",
      "description": "An open source SDK for logging, storing, querying, and visualizing multimodal and multi-rate data",
      "html_url": "https://github.com/rerun-io/rerun",
      "stars": 9971,
      "forks": 620,
      "language": "Rust",
      "topics": [
        "computer-vision",
        "cpp",
        "multimodal",
        "python",
        "robotics",
        "rust",
        "visualization"
      ],
      "created_at": "2022-04-08T07:30:05Z",
      "updated_at": "2026-01-16T00:46:28Z",
      "pushed_at": "2026-01-15T22:12:17Z",
      "open_issues": 1363,
      "owner": {
        "login": "rerun-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/99407368?v=4"
      },
      "readme": "<h1 align=\"center\">\n  <a href=\"https://www.rerun.io/\">\n    <img alt=\"banner\" src=\"https://user-images.githubusercontent.com/1148717/218142418-1d320929-6b7a-486e-8277-fbeef2432529.png\">\n  </a>\n</h1>\n\n<h1 align=\"center\">\n  <a href=\"https://pypi.org/project/rerun-sdk/\">                        <img alt=\"PyPi\"           src=\"https://img.shields.io/pypi/v/rerun-sdk.svg\">                              </a>\n  <a href=\"https://crates.io/crates/rerun\">                             <img alt=\"crates.io\"      src=\"https://img.shields.io/crates/v/rerun.svg\">                                </a>\n  <a href=\"https://github.com/rerun-io/rerun/blob/main/LICENSE-MIT\">    <img alt=\"MIT\"            src=\"https://img.shields.io/badge/license-MIT-blue.svg\">                        </a>\n  <a href=\"https://github.com/rerun-io/rerun/blob/main/LICENSE-APACHE\"> <img alt=\"Apache\"         src=\"https://img.shields.io/badge/license-Apache-blue.svg\">                     </a>\n  <a href=\"https://discord.gg/Gcm8BbTaAj\">                              <img alt=\"Rerun Discord\"  src=\"https://img.shields.io/discord/1062300748202921994?label=Rerun%20Discord\"> </a>\n</h1>\n\n# Time-aware multimodal data stack and visualizations\nRerun is building the multimodal data stack to model, ingest, store, query and view robotics-style data.\nIt's used in areas like robotics, spatial and embodied AI, generative media, industrial processing, simulation, security, and health.\n\nRerun is easy to use!\nUse the Rerun SDK (available for C++, Python and Rust) to log data like images, tensors, point clouds, and text.\nLogs are streamed to the Rerun Viewer for live visualization or to file for later use.\nYou can also query the logged data through [our dataframe API](https://rerun.io/docs/howto/dataframe-api).\n\n[Get started](#getting-started) in minutes â€“ no account needed.\n\n* [Run the Rerun Viewer in your browser](https://www.rerun.io/viewer)\n* [Read about what Rerun is and who it is for](https://www.rerun.io/docs/getting-started/what-is-rerun)\n\n### A short taste\n```py\nimport rerun as rr  # pip install rerun-sdk\n\nrr.init(\"rerun_example_app\")\n\nrr.spawn()  # Spawn a child process with a viewer and connect\n# rr.save(\"recording.rrd\")  # Stream all logs to disk\n# rr.connect_grpc()  # Connect to a remote viewer\n\n# Associate subsequent data with 42 on the â€œframeâ€ timeline\nrr.set_time(\"frame\", sequence=42)\n\n# Log colored 3D points to the entity at `path/to/points`\nrr.log(\"path/to/points\", rr.Points3D(positions, colors=colors))\nâ€¦\n```\n\n<p align=\"center\">\n  <picture>\n    <img src=\"https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/full.png\" alt=\"\">\n    <source media=\"(max-width: 480px)\" srcset=\"https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/480w.png\">\n    <source media=\"(max-width: 768px)\" srcset=\"https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/768w.png\">\n    <source media=\"(max-width: 1024px)\" srcset=\"https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/1024w.png\">\n    <source media=\"(max-width: 1200px)\" srcset=\"https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/1200w.png\">\n  </picture>\n</p>\n\n## Getting started\n* [**C++**](https://www.rerun.io/docs/getting-started/data-in/cpp)\n* [**Python**](https://www.rerun.io/docs/getting-started/data-in/python): `pip install rerun-sdk` or on [`conda`](https://github.com/conda-forge/rerun-sdk-feedstock)\n* [**Rust**](https://www.rerun.io/docs/getting-started/data-in/rust): `cargo add rerun`\n\n### Installing the Rerun Viewer binary\nTo stream log data over the network or load our `.rrd` data files you also need the `rerun` binary.\nIt can be installed with `pip install rerun-sdk` or with `cargo install rerun-cli --locked --features nasm` (see note below).\nNote that only the Python SDK comes bundled with the Viewer whereas C++ & Rust always rely on a separate install.\n\n**Note**: the `nasm` Cargo feature requires the [`nasm`](https://github.com/netwide-assembler/nasm) CLI to be installed and available in your path.\nAlternatively, you may skip enabling this feature, but this may result in inferior video decoding performance.\n\nYou should now be able to run `rerun --help` in any terminal.\n\n\n### Documentation\n- ğŸ“š [High-level docs](http://rerun.io/docs)\n- âƒ [Loggable Types](https://www.rerun.io/docs/reference/types)\n- âš™ï¸ [Examples](http://rerun.io/examples)\n- ğŸ“– [Code snippets](./docs/snippets/INDEX.md)\n- ğŸŒŠ [C++ API docs](https://ref.rerun.io/docs/cpp)\n- ğŸ [Python API docs](https://ref.rerun.io/docs/python)\n- ğŸ¦€ [Rust API docs](https://docs.rs/rerun/)\n- â‰ï¸ [Troubleshooting](https://www.rerun.io/docs/getting-started/troubleshooting)\n\n\n## Status\nWe are in active development.\nThere are many features we want to add, and the API is still evolving.\n_Expect breaking changes!_\n\nSome shortcomings:\n* [The viewer slows down when there are too many entities](https://github.com/rerun-io/rerun/issues/7115)\n* [We don't support transparency yet](https://github.com/rerun-io/rerun/issues/1611)\n* The data you want to visualize must fit in RAM\n  - See <https://www.rerun.io/docs/howto/limit-ram> for how to bound memory use.\n  - We plan on having a disk-based data store some time in the future.\n* [Multi-million point clouds can be slow](https://github.com/rerun-io/rerun/issues/1136)\n\n\n## What is Rerun for?\n\nRerun is built to help you understand and improve complex processes that include rich multimodal data, like 2D, 3D, text, time series, tensors, etc.\nIt is used in many industries, including robotics, simulation, computer vision,\nor anything that involves a lot of sensors or other signals that evolve over time.\n\n### Example use case\nSay you're building a vacuum cleaning robot and it keeps running into walls. Why is it doing that? You need some tool to debug it, but a normal debugger isn't gonna be helpful. Similarly, just logging text won't be very helpful either. The robot may log \"Going through doorway\" but that won't explain why it thinks the wall is a door.\n\nWhat you need is a visual and temporal debugger, that can log all the different representations of the world the robots holds in its little head, such as:\n\n* RGB camera feed\n* depth images\n* lidar scan\n* segmentation image (how the robot interprets what it sees)\n* its 3D map of the apartment\n* all the objects the robot has detected (or thinks it has detected), as 3D shapes in the 3D map\n* its confidence in its prediction\n* etc\n\nYou also want to see how all these streams of data evolve over time so you can go back and pinpoint exactly what went wrong, when and why.\n\nMaybe it turns out that a glare from the sun hit one of the sensors in the wrong way, confusing the segmentation network leading to bad object detection. Or maybe it was a bug in the lidar scanning code. Or maybe the robot thought it was somewhere else in the apartment, because its odometry was broken. Or it could be one of a thousand other things. Rerun will help you find out!\n\nBut seeing the world from the point of the view of the robot is not just for debugging - it will also give you ideas on how to improve the algorithms, new test cases to set up, or datasets to collect. It will also let you explain the brains of the robot to your colleagues, boss, and customers. And so on. Seeing is believing, and an image is worth a thousand words, and multimodal temporal logging is worth a thousand images :)\n\nWhile seeing and understanding your data is core to making progress in robotics, there is one more thing:\nYou can also use the data you collected for visualization to create new datasets for training and evaluating the models and algorithms that run on your robot.\nRerun provides query APIs to make it easy to extract clean datasets from your recording for exactly that purpose.\n\nOf course, Rerun is useful for much more than just robots. Any time you have any form of sensors, or 2D or 3D state evolving over time, Rerun is a great tool.\n\n\n## Business model\nRerun uses an open-core model. Everything in this repository will stay open source and free (both as in beer and as in freedom).\n\nWe are also building a commercial data platform.\nRight now that is only available for a few select design partners.\n[Click here if you're interested](https://rerun.io/pricing).\n\nThe Rerun open source project targets the needs of individual developers.\nThe commercial product targets the needs specific to teams that build and run computer vision and robotics products.\n\n## How to cite Rerun\n\nWhen using Rerun in your research, please cite it to acknowledge its contribution to your work. This can be done by\nincluding a reference to Rerun in the software or methods section of your paper.\n\nSuggested citation format:\n\n```bibtex\n@software{RerunSDK,\n  title = {Rerun: A Visualization SDK for Multimodal Data},\n  author = {{Rerun Development Team}},\n  url = {https://www.rerun.io},\n  version = {insert version number},\n  date = {insert date of usage},\n  year = {2024},\n  publisher = {{Rerun Technologies AB}},\n  address = {Online},\n  note = {Available from https://www.rerun.io/ and https://github.com/rerun-io/rerun}\n}\n```\n\nPlease replace \"insert version number\" with the version of Rerun you used and \"insert date of usage\" with the date(s)\nyou used the tool in your research.\nThis citation format helps ensure that Rerun's development team receives appropriate credit for their work and\nfacilitates the tool's discovery by other researchers.\n\n# Development\n* [`ARCHITECTURE.md`](ARCHITECTURE.md)\n* [`CODE_OF_CONDUCT.md`](CODE_OF_CONDUCT.md)\n* [`CODE_STYLE.md`](CODE_STYLE.md)\n* [`CONTRIBUTING.md`](CONTRIBUTING.md)\n* [`BUILD.md`](BUILD.md)\n* [`rerun_py/README.md`](rerun_py/README.md) - instructions for Python SDK\n* [`rerun_cpp/README.md`](rerun_cpp/README.md) - instructions for C++ SDK\n\n\n## Installing a pre-release Python SDK\n\n1. Download the correct `.whl` from [GitHub Releases](https://github.com/rerun-io/rerun/releases)\n2. Run `pip install rerun_sdk<â€¦>.whl` (replace `<â€¦>` with the actual filename)\n3. Test it: `rerun --version`\n",
      "stars_today": 12
    },
    {
      "id": 964473113,
      "name": "yourtv",
      "full_name": "horsemail/yourtv",
      "description": "å®‰å“ç”µè§†ç›´æ’­APKï¼šIPTV/ç¶²é è¦–é »æ”¯æŒX5ï¼Œå¯è‡ªå®šç¾©æº(æ”¯æŒwebview://æ ¼å¼)ï¼ŒIPTVæ”¯æŒç•«ä¸­ç•«å’Œç†„å±æ’­æ”¾ã€‚ Android TV Live APK: IPTV/web video supports X5, customizable sources (support webview:// format), IPTV supports picture-in-picture and off-screen playback.",
      "html_url": "https://github.com/horsemail/yourtv",
      "stars": 917,
      "forks": 108,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2025-04-11T09:12:13Z",
      "updated_at": "2026-01-15T22:50:18Z",
      "pushed_at": "2026-01-15T01:54:47Z",
      "open_issues": 14,
      "owner": {
        "login": "horsemail",
        "avatar_url": "https://avatars.githubusercontent.com/u/91647741?v=4"
      },
      "readme": "## ğŸŒ èªè¨€ / Languages\n\n- [ğŸ‡¨ğŸ‡³ ä¸­æ–‡èªªæ˜](README.MD)\n- [ğŸ‡ºğŸ‡¸ English Version](README.en.md)\n# ä½ çš„é›»è¦–ï¼šå®‰å“é›»è¦–/æ‰‹æœºç›´æ’­APK\næ”¯æŒå®‰å“6.0(API23)ç´šä»¥ä¸Šç‰ˆæœ¬<br>\nç¶œåˆmy-tv/my-tv-0/my-tv-1/mytv-android/WebViewTVLiveç­‰é …ç›®çš„åŠŸèƒ½ã€‚<br>  \nIPTV/ç¶²é è¦–é »æ’­æ”¾å®‰å“APKè»Ÿä»¶ï¼Œæ”¯æŒè…¾è®¯webview x5ï¼Œ<br>\nå¯è‡ªå®šç¾©æº(æ”¯æŒwebview://æ ¼å¼ç¶²é è¦–é »æº)ï¼Œæ”¯æŒæ‰‹æ©Ÿç•«ä¸­ç•«ï¼ŒIPTVæ”¯æŒæ‰‹æ©Ÿç†„å±æ’­æ”¾ã€‚<br>\n[yourtv](https://github.com/horsemail/yourtv)\n<br>\n## **è«‹ä»”ç´°é–±è®€å¾Œé¢çš„[ä½¿ç”¨èªªæ˜](#ä½¿ç”¨)ã€‚**\n## åœ¨ç·šåŠ å¯†è§£å¯†ï¼šï¼ˆå…¼å®¹Tvboxçš„æ¥å£æºåŠ å¯†è§£å¯†ï¼‰\nhttps://yourtvcrypto.horsenma.net<br>\nèˆ‡é …ç›®å…§åŠ å¯†è§£å¯†é‚è¼¯å®Œå…¨ä¸€è‡´<br>\n\né›»å ±ç¾¤çµ„<br>\nhttps://t.me/yourtvapp<br>\n<img src=\"./screenshots/appreciate.jpg\" alt=\"image\" width=200 /><br><br>\n<img src=\"./screenshots/527.jpg\" alt=\"image\"/><br><br>\n<img src=\"./screenshots/090901.jpg\" alt=\"image\"/><br><br>\n<img src=\"./screenshots/090902.jpg\" alt=\"image\"/><br><br>\n\næ³¨æ„ï¼š\n\n* é‡åˆ°å•é¡Œå¯ä»¥å…ˆè€ƒæ…®é‡å•Ÿ/æ¢å¾©é»˜èª/æ¸…é™¤æ•¸æ“š/é‡æ–°å®‰è£ç­‰æ–¹å¼è‡ªåŠ©è§£æ±º\n\nä¸‹è¼‰å®‰è£ [releases](https://github.com/horsemail/yourtv)\n\n## å…¶ä»–\n\nå»ºè­°é€šéADBé€²è¡Œå®‰è£ï¼š\n\n```shell\nadb install YourTV.apk\n```\n\nå°ç±³é›»è¦–å¯ä»¥ä½¿ç”¨å°ç±³é›»è¦–åŠ©æ‰‹é€²è¡Œå®‰è£\n\n## å¸¸è¦‹å•é¡Œ\n\n* ç‚ºä»€éº¼é ç¨‹é…ç½®è¦–é »æºæ–‡æœ¬å¾Œï¼Œå†æ¬¡æ‰“é–‹æ‡‰ç”¨å¾Œåˆæ¢å¾©åˆ°åŸä¾†çš„é…ç½®ï¼Ÿ<br>\n\n  å¦‚æœâ€œæ‡‰ç”¨å•Ÿå‹•åæ›´æ–°è¦–é »æºâ€é–‹å•Ÿå¾Œï¼Œä¸”å­˜åœ¨è¦–é »æºåœ°å€ï¼Œå‰‡æœƒè‡ªå‹•æ›´æ–°ï¼Œå¯èƒ½æœƒè¦†è“‹å·²ä¿å­˜çš„è¦–é »æºæ–‡æœ¬ã€‚<br>\n\n* è‡ªå·±ç·¨è­¯APPæ³¨æ„äº‹é …ï¼š<br>\n  1ã€è³‡æºæ–‡ä»¶éœ€è¦è‡ªå·±é€å€‹ç¢ºèªè¨­ç½®ç‚ºè‡ªå·±çš„ä¿¡æ¯ï¼Œç‰¹åˆ¥æ˜¯cloudflare.txt/github_private.txt/sources.txt<br>\n  éœ€ä½¿ç”¨åŠ å¯†è§£å¯†å·¥å…·ç¶²ç«™ https://yourtvcrypto.horsenma.net  åŠ å¯†å¾Œå­˜å„²ã€‚<br>\n  2ã€æˆ‘ä¸Šå‚³çš„APKæ–‡ä»¶èˆ‡æºç¢¼å¯èƒ½ä¸åŒæ­¥ï¼ŒAPKæ–‡ä»¶æ¯”è¼ƒæ–°ï¼Œæºç¢¼æ›´æ–°ä¸€èˆ¬è½å¾Œå¹¾å¤©ï¼Œè«‹æ³¨æ„æŸ¥çœ‹ï¼Œ<br>\n  3ã€æˆ‘ä¸Šå‚³çš„APKæ–‡ä»¶ä½¿ç”¨çš„åŠ å¯†è§£å¯†é‚è¼¯èˆ‡é …ç›®å…§åŠ å¯†è§£å¯†é‚è¼¯ï¼šhttps://yourtvcrypto.horsenma.net  ä¸åŒï¼Œç›®çš„ä¿è­·æˆ‘çš„ç§æœ‰è³‡æºä¿¡æ¯ã€‚<br>\n* æ—§ç”µè§†æœºæ— æ³•è§‚çœ‹webviewç½‘é¡µè§†é¢‘é¢‘é“çš„ï¼Œæ‰‹åŠ¨å¼ºåˆ¶å®‰è£…<br>\n**[Android System WebView 6.0+ ä¸‹è½½](https://ftp.horsenma.net/tv/Android_System_WebView_Android_6_0.apk)**<br>\n\n## æ„Ÿè¬\n\n[live](https://github.com/fanmingming/live)<br>\n[my-tv-0](https://github.com/lizongying/my-tv-0)<br>\n[my-tv-1](https://github.com/lizongying/my-tv-1)<br>\n\n",
      "stars_today": 12
    },
    {
      "id": 679421146,
      "name": "opentofu",
      "full_name": "opentofu/opentofu",
      "description": "OpenTofu lets you declaratively manage your cloud infrastructure.",
      "html_url": "https://github.com/opentofu/opentofu",
      "stars": 27582,
      "forks": 1143,
      "language": "Go",
      "topics": [],
      "created_at": "2023-08-16T20:01:36Z",
      "updated_at": "2026-01-15T23:37:28Z",
      "pushed_at": "2026-01-15T21:05:15Z",
      "open_issues": 351,
      "owner": {
        "login": "opentofu",
        "avatar_url": "https://avatars.githubusercontent.com/u/142061836?v=4"
      },
      "readme": "# OpenTofu\n\n- [HomePage](https://opentofu.org/)\n- [How to install](https://opentofu.org/docs/intro/install)\n- [Join our Slack community!](https://opentofu.org/slack)\n\n![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-dark.svg#gh-dark-mode-only)\n![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-light.svg#gh-light-mode-only)\n\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10508/badge)](https://www.bestpractices.dev/projects/10508)\n\nOpenTofu is an OSS tool for building, changing, and versioning infrastructure safely and efficiently. OpenTofu can manage existing and popular service providers as well as custom in-house solutions.\n\nThe key features of OpenTofu are:\n\n- **Infrastructure as Code**: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.\n\n- **Execution Plans**: OpenTofu has a \"planning\" step where it generates an execution plan. The execution plan shows what OpenTofu will do when you call apply. This lets you avoid any surprises when OpenTofu manipulates infrastructure.\n\n- **Resource Graph**: OpenTofu builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, OpenTofu builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.\n\n- **Change Automation**: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what OpenTofu will change and in what order, avoiding many possible human errors.\n\n## Getting help and contributing\n\n- Have a question?\n  - Post it in [GitHub Discussions](https://github.com/orgs/opentofu/discussions)\n  - Open a [GitHub issue](https://github.com/opentofu/opentofu/issues/new/choose)\n  - Join the [OpenTofu Slack](https://opentofu.org/slack/)!\n- Want to contribute?\n  - Please read the [Contribution Guide](CONTRIBUTING.md).\n- Recurring Events\n  - [Community Meetings](https://meet.google.com/xfm-cgms-has) on Wednesdays at 12:30 UTC at this link: https://meet.google.com/xfm-cgms-has ([ğŸ“… calendar link](https://calendar.google.com/calendar/event?eid=NDg0aWl2Y3U1aHFva3N0bGhyMHBhNzdpZmsgY18zZjJkZDNjMWZlMGVmNGU5M2VmM2ZjNDU2Y2EyZGQyMTlhMmU4ZmQ4NWY2YjQwNzUwYWYxNmMzZGYzNzBiZjkzQGc))\n  - [Technical Steering Committee Meetings](https://meet.google.com/cry-houa-qbk) every other Tuesday at 4pm UTC at this link: https://meet.google.com/cry-houa-qbk ([ğŸ“… calendar link](https://calendar.google.com/calendar/u/0/event?eid=M3JyMWtuYWptdXI0Zms4ZnJpNmppcDczb3RfMjAyNTA1MjdUMTYwMDAwWiBjXzNmMmRkM2MxZmUwZWY0ZTkzZWYzZmM0NTZjYTJkZDIxOWEyZThmZDg1ZjZiNDA3NTBhZjE2YzNkZjM3MGJmOTNAZw))\n\n> [!TIP]\n> For more OpenTofu events, subscribe to the [OpenTofu Events Calendar](https://calendar.google.com/calendar/embed?src=c_3f2dd3c1fe0ef4e93ef3fc456ca2dd219a2e8fd85f6b40750af16c3df370bf93%40group.calendar.google.com)!\n\n## Reporting security vulnerabilities\nIf you've found a vulnerability or a potential vulnerability in OpenTofu please follow [Security Policy](https://github.com/opentofu/opentofu/security/policy). We'll send a confirmation email to acknowledge your report, and we'll send an additional email when we've identified the issue positively or negatively.\n\n## Reporting possible copyright issues\n\nIf you believe you have found any possible copyright or intellectual property issues, please contact liaison@opentofu.org. We'll send a confirmation email to acknowledge your report.\n\n## Registry Access\n\nIn an effort to comply with applicable sanctions, we block access from specific countries of origin.\n\n## License\n\n[Mozilla Public License v2.0](https://github.com/opentofu/opentofu/blob/main/LICENSE)\n\n",
      "stars_today": 11
    },
    {
      "id": 6860771,
      "name": "tinyusb",
      "full_name": "hathach/tinyusb",
      "description": "An open source  cross-platform USB stack for embedded system",
      "html_url": "https://github.com/hathach/tinyusb",
      "stars": 6403,
      "forks": 1343,
      "language": "C",
      "topics": [
        "embedded",
        "midi",
        "msc",
        "tinyusb",
        "usb",
        "usb-cdc",
        "usb-devices",
        "usb-drive",
        "usb-hid",
        "usb-host",
        "webusb"
      ],
      "created_at": "2012-11-26T06:24:00Z",
      "updated_at": "2026-01-15T22:49:25Z",
      "pushed_at": "2026-01-15T19:59:59Z",
      "open_issues": 232,
      "owner": {
        "login": "hathach",
        "avatar_url": "https://avatars.githubusercontent.com/u/249515?v=4"
      },
      "readme": "TinyUSB\n=======\n\n|Build Status| |CircleCI Status| |Documentation Status| |Static Analysis| |Fuzzing Status| |License|\n\nSponsors\n--------\n\nTinyUSB is funded by: Adafruit. Purchasing products from them helps to support this project.\n\n.. figure:: docs/assets/adafruit_logo.svg\n   :alt: Adafruit Logo\n   :align: left\n   :target: https://www.adafruit.com\n\n.. raw:: html\n\n   <div class=\"clear-both\"></div>\n\nOverview\n--------\n\n.. figure:: docs/assets/logo.svg\n   :alt: TinyUSB\n   :align: left\n\n.. raw:: html\n\n   <div class=\"clear-both\"></div>\n\nTinyUSB is an open-source cross-platform USB Host/Device stack for embedded systems. Itâ€™s designed for memory safety\n(no dynamic allocation) and thread safety (all interrupts deferred to non-ISR task functions). The stack emphasizes portability,\nsmall footprint, and real-time performance across 50+ MCU families.\n\nKey Features\n------------\n\n* **Thread-safe:** USB interrupts deferred to task context\n* **Memory-safe:** No dynamic allocation, all buffers static\n* **Portable:** Supports 50+ MCU families\n* **Comprehensive:** Includes CDC, HID, MSC, Audio, and Host support\n* **RTOS-friendly:** Works with bare metal, FreeRTOS, RT-Thread, and Mynewt\n\n.. figure:: docs/assets/stack.svg\n   :width: 500px\n   :align: left\n   :alt: stackup\n\n.. raw:: html\n\n   <div class=\"clear-both\"></div>\n\n::\n\n    .\n    â”œâ”€â”€ docs            # Documentation\n    â”œâ”€â”€ examples        # Examples with make and cmake build system\n    â”œâ”€â”€ hw\n    â”‚   â”œâ”€â”€ bsp         # Supported boards source files\n    â”‚   â””â”€â”€ mcu         # Low level mcu core & peripheral drivers\n    â”œâ”€â”€ lib             # Sources from 3rd party such as FreeRTOS, FatFs ...\n    â”œâ”€â”€ src             # All sources files for TinyUSB stack itself.\n    â”œâ”€â”€ test            # Tests: unit test, fuzzing, hardware test\n    â””â”€â”€ tools           # Files used internally\n\n\nGetting started\n---------------\n\nSee the `online documentation <https://docs.tinyusb.org>`_ for information about using TinyUSB and how it is implemented.\n\nCheck out `Getting Started`_ guide for adding TinyUSB to your project or building the examples. If you are new to TinyUSB, we recommend starting with the ``cdc_msc`` example. There is a handful of `Supported Boards`_ that should work out of the box.\n\nWe use `GitHub Discussions <https://github.com/hathach/tinyusb/discussions>`_ as our forum. It is a great place to ask questions and advice from the community or to discuss your TinyUSB-based projects.\n\nFor bugs and feature requests, please `raise an issue <https://github.com/hathach/tinyusb/issues>`_ and follow the templates there.\n\nSee `Porting`_ guide for adding support for new MCUs and boards.\n\nDevice Stack\n------------\n\nSupports multiple device configurations by dynamically changing USB descriptors, low power functions such like suspend, resume, and remote wakeup. The following device classes are supported:\n\n-  Audio Class 2.0 (UAC2)\n-  Bluetooth Host Controller Interface (BTH HCI)\n-  Communication Device Class (CDC)\n-  Device Firmware Update (DFU): DFU mode (WIP) and Runtime\n-  Human Interface Device (HID): Generic (In & Out), Keyboard, Mouse, Gamepad etc ...\n-  Mass Storage Class (MSC): with multiple LUNs\n-  Musical Instrument Digital Interface (MIDI)\n-  Media Transfer Protocol (MTP/PTP)\n-  Network with RNDIS, Ethernet Control Model (ECM), Network Control Model (NCM)\n-  Test and Measurement Class (USBTMC)\n-  Video class 1.5 (UVC): work in progress\n-  Vendor-specific class support with generic In & Out endpoints. Can be used with MS OS 2.0 compatible descriptor to load winUSB driver without INF file.\n-  `WebUSB <https://github.com/WICG/webusb>`__ with vendor-specific class\n\nIf you have a special requirement, ``usbd_app_driver_get_cb()`` can be used to write your own class driver without modifying the stack. Here is how the RPi team added their reset interface `raspberrypi/pico-sdk#197 <https://github.com/raspberrypi/pico-sdk/pull/197>`_\n\nHost Stack\n----------\n\n- Human Interface Device (HID): Keyboard, Mouse, Generic\n- Mass Storage Class (MSC)\n- Communication Device Class: CDC-ACM\n- Vendor serial over USB: FTDI, CP210x, CH34x, PL2303\n- Hub with multiple-level support\n\nSimilar to the Device Stack, if you have a special requirement, ``usbh_app_driver_get_cb()`` can be used to write your own class driver without modifying the stack.\n\nPower Delivery Stack\n--------------------\n\n- Power Delivery 3.0 (PD3.0) with USB Type-C support (WIP)\n- Super early stage, only for testing purpose\n- Only support STM32 G4\n\nOS Abstraction layer\n--------------------\n\nTinyUSB is completely thread-safe by pushing all Interrupt Service Request (ISR) events into a central queue, then processing them later in the non-ISR context task function. It also uses semaphore/mutex to access shared resources such as Communication Device Class (CDC) FIFO. Therefore the stack needs to use some of the OS's basic APIs. Following OSes are already supported out of the box.\n\n- **No OS**\n- **FreeRTOS**\n- `RT-Thread <https://github.com/RT-Thread/rt-thread>`_: `repo <https://github.com/RT-Thread-packages/tinyusb>`_\n- **Mynewt** Due to the newt package build system, Mynewt examples are better to be on its `own repo <https://github.com/hathach/mynewt-tinyusb-example>`_\n\nSupported CPUs\n--------------\n\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Manufacturer | Family                      | Device | Host | Highspeed | Driver                 | Note               |\n+==============+=============================+========+======+===========+========================+====================+\n| Allwinner    | F1C100s/F1C200s             | âœ”      |      | âœ”         | sunxi                  | musb variant       |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Analog       | MAX3421E                    |        | âœ”    | âœ–         | max3421                | via SPI            |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | MAX32 650, 666, 690,        | âœ”      |      | âœ”         | musb                   | 1-dir ep           |\n|              | MAX78002                    |        |      |           |                        |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Artery AT32  | F403a_407, F413             | âœ”      |      |           | fsdev                  | 512 USB RAM        |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | F415, F435_437, F423,       | âœ”      | âœ”    |           | dwc2                   |                    |\n|              | F425, F45x                  |        |      |           |                        |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | F402_F405                   | âœ”      | âœ”    | âœ”         | dwc2                   | F405 is HS         |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Bridgetek    | FT90x                       | âœ”      |      | âœ”         | ft9xx                  | 1-dir ep           |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Broadcom     | BCM2711, BCM2837            | âœ”      |      | âœ”         | dwc2                   |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Dialog       | DA1469x                     | âœ”      | âœ–    | âœ–         | da146xx                |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Espressif    | S2, S3                      | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n| ESP32        +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | P4                          | âœ”      | âœ”    | âœ”         | dwc2                   |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | H4                          | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| GigaDevice   | GD32VF103                   | âœ”      |      | âœ–         | dwc2                   |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| HPMicro      | HPM6750                     | âœ”      | âœ”    | âœ”         | ci_hs, ehci            |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Infineon     | XMC4500                     | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n+--------------+-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n| MicroChip    | SAM | D11, D21, L21, L22    | âœ”      |      | âœ–         | samd                   |                    |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | D51, E5x              | âœ”      |      | âœ–         | samd                   |                    |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | G55                   | âœ”      |      | âœ–         | samg                   | 1-dir ep           |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | E70,S70,V70,V71       | âœ”      |      | âœ”         | samx7x                 | 1-dir ep           |\n|              +-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n|              | PIC | 24                    | âœ”      |      |           | pic                    | ci_fs variant      |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | 32 mm, mk, mx         | âœ”      |      |           | pic                    | ci_fs variant      |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | dsPIC33               | âœ”      |      |           | pic                    | ci_fs variant      |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | 32mz                  | âœ”      |      |           | pic32mz                | musb variant       |\n+--------------+-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n| MindMotion   | mm32                        | âœ”      |      | âœ–         | mm32f327x_otg          | ci_fs variant      |\n+--------------+-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n| NordicSemi   | nRF 52833, 52840, 5340      | âœ”      | âœ–    | âœ–         | nrf5x                  | only ep8 is ISO    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Nuvoton      | NUC120                      | âœ”      | âœ–    | âœ–         | nuc120                 |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | NUC121/NUC125, NUC126       | âœ”      | âœ–    | âœ–         | nuc121                 |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | NUC505                      | âœ”      |      | âœ”         | nuc505                 |                    |\n+--------------+---------+-------------------+--------+------+-----------+------------------------+--------------------+\n| NXP          | iMXRT   | RT 10xx, 11xx     | âœ”      | âœ”    | âœ”         | ci_hs, ehci            |                    |\n|              +---------+-------------------+--------+------+-----------+------------------------+--------------------+\n|              | Kinetis | KL                | âœ”      | âš     | âœ–         | ci_fs, khci            |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | K32L2             | âœ”      |      | âœ–         | khci                   | ci_fs variant      |\n|              +---------+-------------------+--------+------+-----------+------------------------+--------------------+\n|              | LPC     | 11u, 13, 15       | âœ”      | âœ–    | âœ–         | lpc_ip3511             |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | 17, 40            | âœ”      | âš     | âœ–         | lpc17_40, ohci         |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | 18, 43            | âœ”      | âœ”    | âœ”         | ci_hs, ehci            |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | 51u               | âœ”      | âœ–    | âœ–         | lpc_ip3511             |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | 54, 55            | âœ”      |      | âœ”         | lpc_ip3511             |                    |\n|              +---------+-------------------+--------+------+-----------+------------------------+--------------------+\n|              | MCX     | N9                | âœ”      |      | âœ”         | ci_fs, ci_hs, ehci     |                    |\n|              |         +-------------------+--------+------+-----------+------------------------+--------------------+\n|              |         | A15               | âœ”      |      |           | ci_fs                  |                    |\n|              +---------+-------------------+--------+------+-----------+------------------------+--------------------+\n|              | RW61x                       | âœ”      | âœ”    | âœ”         | ci_hs, ehci            |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Raspberry Pi | RP2040, RP2350              | âœ”      | âœ”    | âœ–         | rp2040, pio_usb        |                    |\n+--------------+-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n| Renesas      | RX  | 63N, 65N, 72N         | âœ”      | âœ”    | âœ–         | rusb2                  |                    |\n|              +-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n|              | RA  | 4M1, 4M3, 6M1         | âœ”      | âœ”    | âœ–         | rusb2                  |                    |\n|              |     +-----------------------+--------+------+-----------+------------------------+--------------------+\n|              |     | 6M5                   | âœ”      | âœ”    | âœ”         | rusb2                  |                    |\n+--------------+-----+-----------------------+--------+------+-----------+------------------------+--------------------+\n| Silabs       | EFM32GG12                   | âœ”      |      | âœ–         | dwc2                   |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| Sony         | CXD56                       | âœ”      | âœ–    | âœ”         | cxd56                  |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| ST STM32     | F0, F3, L0, L1, L5, WBx5    | âœ”      | âœ–    | âœ–         | stm32_fsdev            |                    |\n|              +----+------------------------+--------+------+-----------+------------------------+--------------------+\n|              | F1 | 102, 103               | âœ”      | âœ–    | âœ–         | stm32_fsdev            | 512 USB RAM        |\n|              |    +------------------------+--------+------+-----------+------------------------+--------------------+\n|              |    | 105, 107               | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n|              +----+------------------------+--------+------+-----------+------------------------+--------------------+\n|              | F2, F4, F7, H7, H7RS        | âœ”      | âœ”    | âœ”         | dwc2                   |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | C0, G0, H5, U3              | âœ”      | âœ”    | âœ–         | stm32_fsdev            | 2KB USB RAM        |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | G4                          | âœ”      | âœ–    | âœ–         | stm32_fsdev            | 1KB USB RAM        |\n|              +----+------------------------+--------+------+-----------+------------------------+--------------------+\n|              | L4 | 4x2, 4x3               | âœ”      | âœ–    | âœ–         | stm32_fsdev            | 1KB USB RAM        |\n|              |    +------------------------+--------+------+-----------+------------------------+--------------------+\n|              |    | 4x5, 4x6, 4+           | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n|              +----+------------------------+--------+------+-----------+------------------------+--------------------+\n|              | N6                          | âœ”      | âœ”    | âœ”         | dwc2                   |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | U0                          | âœ”      | âœ–    | âœ–         | stm32_fsdev            | 1KB USB RAM        |\n|              +----+------------------------+--------+------+-----------+------------------------+--------------------+\n|              | U5 | 535, 545               | âœ”      | âœ”    | âœ–         | stm32_fsdev            | 2KB USB RAM        |\n|              |    +------------------------+--------+------+-----------+------------------------+--------------------+\n|              |    | 575, 585               | âœ”      | âœ”    | âœ–         | dwc2                   |                    |\n|              |    +------------------------+--------+------+-----------+------------------------+--------------------+\n|              |    | 59x,5Ax,5Fx,5Gx        | âœ”      | âœ”    | âœ”         | dwc2                   |                    |\n+--------------+----+------------------------+--------+------+-----------+------------------------+--------------------+\n| TI           | MSP430                      | âœ”      | âœ–    | âœ–         | msp430x5xx             |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | MSP432E4, TM4C123           | âœ”      |      | âœ–         | musb                   |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| ValentyUSB   | eptri                       | âœ”      | âœ–    | âœ–         | eptri                  |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n| WCH          | CH32F20x                    | âœ”      |      | âœ”         | ch32_usbhs             |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | CH32V20x                    | âœ”      |      | âœ–         | stm32_fsdev/ch32_usbfs |                    |\n|              +-----------------------------+--------+------+-----------+------------------------+--------------------+\n|              | CH32V305, CH32V307          | âœ”      |      | âœ”         | ch32_usbfs/hs          |                    |\n+--------------+-----------------------------+--------+------+-----------+------------------------+--------------------+\n\nTable Legend\n^^^^^^^^^^^^\n\n========= =========================\nâœ”         Supported\nâš          Partial support\nâœ–         Not supported by hardware\n\\[empty\\] Unknown\n========= =========================\n\nDevelopment Tools\n-----------------\n\nThe following tools are provided freely to support the development of the TinyUSB project:\n\n- `IAR Build Tools (CX) <https://iar.com>`_ Professional IDE and compiler for embedded development.\n- `JetBrains CLion <https://www.jetbrains.com/clion/>`_ Cross-platform IDE for C and C++ development.\n- `PVS-Studio <https://pvs-studio.com/en/pvs-studio/?utm_source=website&utm_medium=github&utm_campaign=open_source>`_ static analyzer for C, C++, C#, and Java code.\n\n\n.. |Build Status| image:: https://github.com/hathach/tinyusb/actions/workflows/build.yml/badge.svg\n   :target: https://github.com/hathach/tinyusb/actions/workflows/build.yml\n.. |CircleCI Status| image:: https://dl.circleci.com/status-badge/img/circleci/4AYHvUhFxdnY4rA7LEsdqW/QmrpoL2AjGqetvFQNqtWyq/tree/master.svg?style=svg\n   :target: https://dl.circleci.com/status-badge/redirect/circleci/4AYHvUhFxdnY4rA7LEsdqW/QmrpoL2AjGqetvFQNqtWyq/tree/master\n.. |Documentation Status| image:: https://readthedocs.org/projects/tinyusb/badge/?version=latest\n   :target: https://docs.tinyusb.org/en/latest/?badge=latest\n.. |Static Analysis| image:: https://github.com/hathach/tinyusb/actions/workflows/static_analysis.yml/badge.svg\n   :target: https://github.com/hathach/tinyusb/actions/workflows/static_analysis.yml\n.. |Fuzzing Status| image:: https://oss-fuzz-build-logs.storage.googleapis.com/badges/tinyusb.svg\n   :target: https://oss-fuzz-build-logs.storage.googleapis.com/index.html#tinyusb\n.. |License| image:: https://img.shields.io/badge/license-MIT-brightgreen.svg\n   :target: https://opensource.org/licenses/MIT\n\n\n.. _Changelog: docs/info/changelog.rst\n.. _Contributors: CONTRIBUTORS.rst\n.. _Getting Started: docs/getting_started.rst\n.. _Supported Boards: docs/reference/boards.rst\n.. _Dependencies: docs/reference/dependencies.rst\n.. _Concurrency: docs/reference/concurrency.rst\n.. _Code of Conduct: CODE_OF_CONDUCT.rst\n.. _Porting: docs/porting.rst\n",
      "stars_today": 11
    },
    {
      "id": 3777210,
      "name": "squirrel",
      "full_name": "rime/squirrel",
      "description": "ã€é¼ é¬šç®¡ã€‘Rime for macOS",
      "html_url": "https://github.com/rime/squirrel",
      "stars": 5637,
      "forks": 460,
      "language": "Swift",
      "topics": [],
      "created_at": "2012-03-20T16:17:18Z",
      "updated_at": "2026-01-15T14:49:03Z",
      "pushed_at": "2026-01-14T00:24:56Z",
      "open_issues": 192,
      "owner": {
        "login": "rime",
        "avatar_url": "https://avatars.githubusercontent.com/u/10554324?v=4"
      },
      "readme": "    é¼ é¬šç®¡\n    çˆ²ç‰©é›–å¾®æƒ…ä¸æ·º\n    æ–°è©©é†‰å¢¨æ™‚ä¸€æ®\n    åˆ¥å¾Œå¯„æˆ‘ç„¡è¾­é \n\n    ã€€ã€€ã€€â€”â€”æ­é™½ä¿®\n\nä»Šç”±ã€€[ä¸­å·éŸ»è¼¸å…¥æ³•å¼•æ“ï¼Rime Input Method Engine](https://rime.im)\nåŠå…¶ä»–é–‹æºæŠ€è¡“å¼·åŠ›é©…å‹•\n\nã€é¼ é¬šç®¡ã€‘è¼¸å…¥æ³•\n===\n[![Download](https://img.shields.io/github/v/release/rime/squirrel)](https://github.com/rime/squirrel/releases/latest)\n[![Build Status](https://github.com/rime/squirrel/actions/workflows/commit-ci.yml/badge.svg)](https://github.com/rime/squirrel/actions/workflows)\n[![GitHub Tag](https://img.shields.io/github/tag/rime/squirrel.svg)](https://github.com/rime/squirrel)\n\nå¼æ•å ‚ ç‰ˆæ¬Šæ‰€ç„¡\n\næˆæ¬Šæ¢æ¬¾ï¼š[GPL v3](https://www.gnu.org/licenses/gpl-3.0.en.html)\n\né …ç›®ä¸»é ï¼š[rime.im](https://rime.im)\n\næ‚¨å¯èƒ½é‚„éœ€è¦ Rime ç”¨æ–¼å…¶ä»–æ“ä½œç³»çµ±çš„ç™¼è¡Œç‰ˆï¼š\n\n  * ã€ä¸­å·éŸ»ã€‘ï¼ˆibus-rimeã€fcitx-rimeï¼‰ç”¨æ–¼ Linux\n  * ã€å°ç‹¼æ¯«ã€‘ç”¨æ–¼ Windows\n\nå®‰è£è¼¸å…¥æ³•\n---\n\næœ¬å“é©ç”¨æ–¼ macOS 13.0+\n\nåˆæ¬¡å®‰è£ï¼Œå¦‚æœåœ¨éƒ¨ä»½æ‡‰ç”¨ç¨‹åºä¸­æ‰“ä¸å‡ºå­—ï¼Œè«‹è¨»éŠ·ä¸¦é‡æ–°ç™»éŒ„ã€‚\n\nä½¿ç”¨è¼¸å…¥æ³•\n---\n\né¸å–è¼¸å…¥æ³•æŒ‡ç¤ºå™¨èœå–®è£çš„ã€ã„“ã€‘å­—æ¨£åœ–æ¨™ï¼Œé–‹å§‹ç”¨é¼ é¬šç®¡å¯«å­—ã€‚\né€šéå¿«æ·éµ `` Ctrl+` `` æˆ– `F4` å‘¼å‡ºæ–¹æ¡ˆé¸å–®ã€åˆ‡æ›è¼¸å…¥æ–¹å¼ã€‚\n\nå®šè£½è¼¸å…¥æ³•\n---\n\nå®šè£½æ–¹æ³•ï¼Œè«‹åƒè€ƒç·šä¸Š [å¹«åŠ©æ–‡æª”](https://rime.im/docs/)ã€‚\n\nä½¿ç”¨ç³»çµ±è¼¸å…¥æ³•èœå–®ï¼š\n\n  * é¸ä¸­ã€Œåœ¨ç·šæ–‡æª”ã€å¯æ‰“é–‹ä»¥ä¸Šç¶²å€\n  * ç·¨è¼¯ç”¨æˆ¶è¨­å®šå¾Œï¼Œé¸æ“‡ã€Œé‡æ–°éƒ¨ç½²ã€ä»¥ä»¤ä¿®æ”¹ç”Ÿæ•ˆ\n\nå®‰è£è¼¸å…¥æ–¹æ¡ˆ\n---\n\nä½¿ç”¨ [/plum/](https://github.com/rime/plum) é…ç½®ç®¡ç†å™¨ç²å–æ›´å¤šè¼¸å…¥æ–¹æ¡ˆã€‚\n\nè‡´è¬\n---\n\nè¼¸å…¥æ–¹æ¡ˆè¨­è¨ˆï¼š\n\n  * ã€æœ™æœˆæ‹¼éŸ³ã€‘ç³»åˆ—\n\n    æ„Ÿè¬ CC-CEDICTã€Android æ‹¼éŸ³ã€æ–°é…·éŸ³ã€opencc ç­‰é–‹æºé …ç›®\n\nç¨‹åºè¨­è¨ˆï¼š\n\n  * ä½›æŒ¯\n  * Linghua Zhang\n  * Chongyu Zhu\n  * é›ªé½‹\n  * faberii\n  * Chun-wei Kuo\n  * Junlu Cheng\n  * Jak Wings\n  * xiehuc\n\nç¾è¡“ï¼š\n\n  * åœ–æ¨™è¨­è¨ˆ ä½›æŒ¯ã€æ¢æµ·ã€é›¨éä¹‹å¾Œ\n  * é…è‰²æ–¹æ¡ˆ Abenã€Chongyu Zhuã€skojã€Superoutmanã€ä½›æŒ¯ã€æ¢æµ·\n\næœ¬å“å¼•ç”¨äº†ä»¥ä¸‹é–‹æºè»Ÿä»¶ï¼š\n\n  * Boost C++ Libraries  (Boost Software License)\n  * capnproto (MIT License)\n  * darts-clone  (New BSD License)\n  * google-glog  (New BSD License)\n  * Google Test  (New BSD License)\n  * LevelDB  (New BSD License)\n  * librime  (New BSD License)\n  * OpenCC / é–‹æ”¾ä¸­æ–‡è½‰æ›  (Apache License 2.0)\n  * plum / æ±é¢¨ç ´ (GNU Lesser General Public License 3.0)\n  * Sparkle  (MIT License)\n  * UTF8-CPP  (Boost Software License)\n  * yaml-cpp  (MIT License)\n\næ„Ÿè¬ç‹å…¬å­æè´ˆé–‹ç™¼ç”¨æ©Ÿã€‚\n\nå•é¡Œèˆ‡åé¥‹\n---\n\nç™¼ç¾ç¨‹åºæœ‰ BUGï¼Œæˆ–å»ºè­°ï¼Œæˆ–æ„Ÿæƒ³ï¼Œè«‹åé¥‹åˆ° [Rime ä»£ç¢¼ä¹‹å®¶è¨è«–å€](https://github.com/rime/home/discussions)\n\nè¯ç¹«æ–¹å¼\n---\n\næŠ€è¡“äº¤æµï¼Œæ­¡è¿å…‰è‡¨ [Rime ä»£ç¢¼ä¹‹å®¶](https://github.com/rime/home)ï¼Œ\næˆ–è‡´ä¿¡ Rime é–‹ç™¼è€… <rimeime@gmail.com>ã€‚\n\nè¬è¬\n",
      "stars_today": 11
    },
    {
      "id": 10744183,
      "name": "netdata",
      "full_name": "netdata/netdata",
      "description": "The fastest path to AI-powered full stack observability, even for lean teams.",
      "html_url": "https://github.com/netdata/netdata",
      "stars": 77357,
      "forks": 6301,
      "language": "C",
      "topics": [
        "ai",
        "alerting",
        "cncf",
        "data-visualization",
        "database",
        "devops",
        "docker",
        "grafana",
        "influxdb",
        "kubernetes",
        "linux",
        "machine-learning",
        "mcp",
        "mongodb",
        "monitoring",
        "mysql",
        "netdata",
        "observability",
        "postgresql",
        "prometheus"
      ],
      "created_at": "2013-06-17T18:39:10Z",
      "updated_at": "2026-01-16T00:26:08Z",
      "pushed_at": "2026-01-16T00:16:59Z",
      "open_issues": 247,
      "owner": {
        "login": "netdata",
        "avatar_url": "https://avatars.githubusercontent.com/u/43390781?v=4"
      },
      "readme": "<p align=\"center\">\n<a href=\"https://www.netdata.cloud#gh-light-mode-only\">\n  <img src=\"https://www.netdata.cloud/img/readme-images/netdata_readme_logo_light.png\" alt=\"Netdata\" width=\"300\"/>\n</a>\n<a href=\"https://www.netdata.cloud#gh-dark-mode-only\">\n  <img src=\"https://www.netdata.cloud/img/readme-images/netdata_readme_logo_dark.png\" alt=\"Netdata\" width=\"300\"/>\n</a>\n</p>\n<h3 align=\"center\">X-Ray Vision for your infrastructure!</h3>\n<h4 align=\"center\">Every Metric, Every Second. No BS.</h4>\n\n<br />\n<p align=\"center\">\n  <a href=\"https://github.com/netdata/netdata/\"><img src=\"https://img.shields.io/github/stars/netdata/netdata?style=social\" alt=\"GitHub Stars\"></a>\n  <br />\n  <a href=\"https://app.netdata.cloud/spaces/netdata-demo?utm_campaign=github_readme_demo_badge\"><img src=\"https://img.shields.io/badge/Live%20Demo-green\" alt=\"Live Demo\"></a>\n  <a href=\"https://github.com/netdata/netdata/releases/latest\"><img src=\"https://img.shields.io/github/release/netdata/netdata.svg\" alt=\"Latest release\"></a>\n  <a href=\"https://github.com/netdata/netdata-nightlies/releases/latest\"><img src=\"https://img.shields.io/github/release/netdata/netdata-nightlies.svg\" alt=\"Latest nightly build\"></a>\n  <br/>\n  <a href=\"https://community.netdata.cloud\"><img alt=\"Discourse topics\" src=\"https://img.shields.io/discourse/topics?server=https%3A%2F%2Fcommunity.netdata.cloud%2F&logo=discourse&label=discourse%20forum\"></a>\n  <a href=\"https://github.com/netdata/netdata/discussions\"><img alt=\"GitHub Discussions\" src=\"https://img.shields.io/github/discussions/netdata/netdata?logo=github&label=github%20discussions\"></a>\n  <br/>\n  <a href=\"https://bestpractices.coreinfrastructure.org/projects/2231\"><img src=\"https://bestpractices.coreinfrastructure.org/projects/2231/badge\" alt=\"CII Best Practices\"></a>\n  <a href=\"https://scan.coverity.com/projects/netdata-netdata?tab=overview\"><img alt=\"Coverity Scan\" src=\"https://img.shields.io/coverity/scan/netdata\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://registry.my-netdata.io/#menu_netdata_submenu_registry\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=netdata.registry_entries&dimensions=persons&label=user%20base&units=M&value_color=blue&precision=2&divide=1000000&options=unaligned&tier=1&v44\" alt=\"User base\"></a>\n  <a href=\"https://registry.my-netdata.io/#menu_netdata_submenu_registry\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=netdata.registry_entries&dimensions=machines&label=servers%20monitored&units=M&divide=1000000&value_color=orange&precision=2&options=unaligned&tier=1&v44\" alt=\"Servers monitored\"></a>\n  <a href=\"https://registry.my-netdata.io/#menu_netdata_submenu_registry\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=netdata.registry_sessions&label=sessions%20served&units=M&value_color=yellowgreen&precision=2&divide=1000000&options=unaligned&tier=1&v44\" alt=\"Sessions served\"></a>\n  <a href=\"https://hub.docker.com/r/netdata/netdata\"><img src=\"https://registry.my-netdata.io/api/v3/badge.svg?chart=dockerhub.pulls_sum&divide=1000000&precision=1&units=M&label=docker+hub+pulls&options=unaligned&tier=1&v44\" alt=\"Docker Hub pulls\"></a>\n</p>\n<p align=\"center\"><b>Visit our <a href=\"https://www.netdata.cloud\">Home Page</a></b></p>\n\n<hr class=\"solid\">\n\nMENU: **[WHO WE ARE](#who-we-are)** | **[KEY FEATURES](#key-features)** | **[GETTING STARTED](#getting-started)** | **[HOW IT WORKS](#how-it-works)** | **[FAQ](#faq)** | **[DOCS](#book-documentation)** | **[COMMUNITY](#tada-community)** | **[CONTRIBUTE](#pray-contribute)** | **[LICENSE](#scroll-license)**\n\n\n> [!WARNING]\n> People **get addicted to Netdata.**\n> Once you use it on your systems, *there's no going back.*\n\n[![Platforms](https://img.shields.io/badge/Platforms-Linux%20%7C%20macOS%20%7C%20FreeBSD%20%7C%20Windows-blue)]()\n\n---\n\n## WHO WE ARE\n\nNetdata is an open-source, real-time infrastructure monitoring platform. Monitor, detect, and act across your entire infrastructure.\n\n**Core Advantages:**\n\n* **Instant Insights** â€“ With Netdata you can access per-second metrics and visualizations.\n* **Zero Configuration** â€“ You can deploy immediately without complex setup.\n* **ML-Powered** â€“ You can detect anomalies, predict issues, and automate analysis.\n* **Efficient** â€“ You can monitor with minimal resource usage and maximum scalability.\n* **Secure & Distributed** â€“ You can keep your data local with no central collection needed.\n\nWith Netdata, you get real-time, per-second updates. Clear **insights at a glance**, no complexity.\n\n<details>\n  <summary><strong>All heroes have a great origin story. Click to discover ours.</strong></summary>\n  <br/>\n\nIn 2013, at the company where Costa Tsaousis was COO, a significant percentage of their cloud-based transactions failed silently, severely impacting business performance.\n\nCosta and his team tried every troubleshooting tool available at the time. None could identify the root cause. As Costa later wrote:\n\nâ€œ*I couldnâ€™t believe that monitoring systems provide so few metrics and with such low resolution, scale so badly, and cost so much to run.*â€\n\nFrustrated, he decided to build his own monitoring tool, starting from scratch.\n\nThat decision led to countless late nights and weekends. It also sparked a fundamental shift in how infrastructure monitoring and troubleshooting are approached, both in method and in cost.\n</details>\n\n### Most Energy-Efficient Monitoring Tool\n\n<p align=\"center\">\n<a href=\"https://www.ivanomalavolta.com/files/papers/ICSOC_2023.pdf#gh-dark-mode-only\">\n  <img src=\"https://github.com/netdata/netdata/assets/139226121/7118757a-38fb-48d7-b12a-53e709a8e8c0\" alt=\"Energy Efficiency\" width=\"800\"/>\n</a>\n<a href=\"https://www.ivanomalavolta.com/files/papers/ICSOC_2023.pdf#gh-light-mode-only\">\n  <img src=\"https://github.com/netdata/netdata/assets/139226121/4f64cbb6-05e4-48e3-b7c0-d1b79e37e219\" alt=\"Energy efficiency\" width=\"800\"/>\n</a>\n</p>\n\nAccording to the [University of Amsterdam study](https://www.ivanomalavolta.com/files/papers/ICSOC_2023.pdf), Netdata is the most energy-efficient tool for monitoring Docker-based systems. The study also shows Netdata excels in CPU usage, RAM usage, and execution time compared to other monitoring solutions.\n\n---\n\n## Key Features\n\n| Feature                    | Description                               | What Makes It Unique                                     |\n|----------------------------|-------------------------------------------|----------------------------------------------------------|\n| **Real-Time**              | Per-second data collection and processing | Works in a beat â€“ click and see results instantly        |\n| **Zero-Configuration**     | Automatic detection and discovery         | Auto-discovers everything on the nodes it runs           |\n| **ML-Powered**             | Unsupervised anomaly detection            | Trains multiple ML models per metric at the edge         |\n| **Long-Term Retention**    | High-performance storage                  | ~0.5 bytes per sample with tiered storage for archiving  |\n| **Advanced Visualization** | Rich, interactive dashboards              | Slice and dice data without query language               |\n| **Extreme Scalability**    | Native horizontal scaling                 | Parent-Child centralization with multi-million samples/s |\n| **Complete Visibility**    | From infrastructure to applications       | Simplifies operations and eliminates silos               |\n| **Edge-Based**             | Processing at your premises               | Distributes code instead of centralizing data            |\n\n> [!NOTE]  \n> Want to put Netdata to the test against Prometheus?\n> Explore the [full comparison](https://www.netdata.cloud/blog/netdata-vs-prometheus-2025/).\n\n---\n\n## Netdata Ecosystem\n\nThis three-part architecture enables you to scale from single nodes to complex multi-cloud environments:\n\n| Component         | Description                                                                                                                                                 | License                                         |\n|-------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------|\n| **Netdata Agent** | â€¢ Core monitoring engine<br>â€¢ Handles collection, storage, ML, alerts, exports<br>â€¢ Runs on servers, cloud, K8s, IoT<br>â€¢ Zero production impact            | [GPL v3+](https://www.gnu.org/licenses/gpl-3.0) |\n| **Netdata Cloud** | â€¢ Enterprise features<br>â€¢ User management, RBAC, horizontal scaling<br>â€¢ Centralized alerts<br>â€¢ Free community tier<br>â€¢ No metric storage centralization |                                                 |\n| **Netdata UI**    | â€¢ Dashboards and visualizations<br>â€¢ Free to use<br>â€¢ Included in standard packages<br>â€¢ Latest version via CDN                                             | [NCUL1](https://app.netdata.cloud/LICENSE.txt)  |\n\n## What You Can Monitor\n\nWith Netdata you can monitor all these components across platforms:\n\n|                                                                                                   Component |              Linux               | FreeBSD | macOS |                      Windows                      |\n|------------------------------------------------------------------------------------------------------------:|:--------------------------------:|:-------:|:-----:|:-------------------------------------------------:|\n|                             **System Resources**<small><br/>CPU, Memory and system shared resources</small> |               Full               |   Yes   |  Yes  |                        Yes                        |\n|                                **Storage**<small><br/>Disks, Mount points, Filesystems, RAID arrays</small> |               Full               |   Yes   |  Yes  |                        Yes                        |\n|                                 **Network**<small><br/>Network Interfaces, Protocols, Firewall, etc</small> |               Full               |   Yes   |  Yes  |                        Yes                        |\n|                        **Hardware & Sensors**<small><br/>Fans, Temperatures, Controllers, GPUs, etc</small> |               Full               |  Some   | Some  |                       Some                        |\n|                                       **O/S Services**<small><br/>Resources, Performance and Status</small> | Yes<small><br/>`systemd`</small> |    -    |   -   |                         -                         |\n|                                      **Processes**<small><br/>Resources, Performance, OOM, and more</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n|                                                                             System and Application **Logs** | Yes<small><br/>`systemd`-journal |    -    |   -   | Yes<small><br/>`Windows Event Log`, `ETW`</small> |\n|                                 **Network Connections**<small><br/>Live TCP and UDP sockets per PID</small> |               Yes                |    -    |   -   |                         -                         |\n|                               **Containers**<small><br/>Docker/containerd, LXC/LXD, Kubernetes, etc</small> |               Yes                |    -    |   -   |                         -                         |\n|                                 **VMs** (from the host)<small><br/>KVM, qemu, libvirt, Proxmox, etc</small> | Yes<small><br/>`cgroups`</small> |    -    |   -   |         Yes<small><br/>`Hyper-V`</small>          |\n|                       **Synthetic Checks**<small><br/>Test APIs, TCP ports, Ping, Certificates, etc</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n| **Packaged Applications**<small><br/>nginx, apache, postgres, redis, mongodb,<br/>and hundreds more</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n|                              **Cloud Provider Infrastructure**<small><br/>AWS, GCP, Azure, and more</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n|                       **Custom Applications**<small><br/>OpenMetrics, StatsD and soon OpenTelemetry</small> |               Yes                |   Yes   |  Yes  |                        Yes                        |\n\nOn Linux, you can continuously monitor all kernel features and hardware sensors for errors, including Intel/AMD/Nvidia GPUs, PCI AER, RAM EDAC, IPMI, S.M.A.R.T, Intel RAPL, NVMe, fans, power supplies, and voltage readings.\n\n---\n\n## Getting Started\n\nYou can install Netdata on all major operating systems. To begin:\n\n### 1. Install Netdata\n\nChoose your platform and follow the installation guide:\n\n* [Linux Installation](https://learn.netdata.cloud/docs/installing/one-line-installer-for-all-linux-systems)\n* [macOS](https://learn.netdata.cloud/docs/installing/macos)\n* [FreeBSD](https://learn.netdata.cloud/docs/installing/freebsd)\n* [Windows](https://learn.netdata.cloud/docs/netdata-agent/installation/windows)\n* [Docker Guide](/packaging/docker/README.md)\n* [Kubernetes Setup](https://learn.netdata.cloud/docs/installation/install-on-specific-environments/kubernetes)\n\n> [!NOTE]\n> You can access the Netdata UI at `http://localhost:19999` (or `http://NODE:19999` if remote).\n\n### 2. Configure Collectors\n\nNetdata auto-discovers most metrics, but you can manually configure some collectors:\n\n* [All collectors](https://learn.netdata.cloud/docs/data-collection/)\n* [SNMP monitoring](https://learn.netdata.cloud/docs/data-collection/monitor-anything/networking/snmp)\n\n### 3. Configure Alerts\n\nYou can use hundreds of built-in alerts and integrate with:\n\n`email`, `Slack`, `Telegram`, `PagerDuty`, `Discord`, `Microsoft Teams`, and more.\n\n> [!NOTE]  \n> Email alerts work by default if there's a configured MTA.\n\n### 4. Configure Parents\n\nYou can centralize dashboards, alerts, and storage with Netdata Parents:\n\n* [Streaming Reference](https://learn.netdata.cloud/docs/streaming/streaming-configuration-reference)\n\n> [!NOTE]  \n> You can use Netdata Parents for central dashboards, longer retention, and alert configuration.\n\n### 5. Connect to Netdata Cloud\n\n[Sign in to Netdata Cloud](https://app.netdata.cloud/sign-in) and connect your nodes for:\n\n* Access from anywhere\n* Horizontal scalability and multi-node dashboards\n* UI configuration for alerts and data collection\n* Role-based access control\n* Free tier available\n\n> [!NOTE]  \n> Netdata Cloud is optional. Your data stays in your infrastructure.\n\n## Live Demo Sites\n\n<p align=\"center\">\n  <b>See Netdata in action</b><br/>\n  <a href=\"https://frankfurt.netdata.rocks\"><b>FRANKFURT</b></a> |\n  <a href=\"https://newyork.netdata.rocks\"><b>NEWYORK</b></a> |\n  <a href=\"https://atlanta.netdata.rocks\"><b>ATLANTA</b></a> |\n  <a href=\"https://sanfrancisco.netdata.rocks\"><b>SANFRANCISCO</b></a> |\n  <a href=\"https://toronto.netdata.rocks\"><b>TORONTO</b></a> |\n  <a href=\"https://singapore.netdata.rocks\"><b>SINGAPORE</b></a> |\n  <a href=\"https://bangalore.netdata.rocks\"><b>BANGALORE</b></a>\n  <br/>\n  <i>These demo clusters run with default configuration and show real monitoring data.</i>\n  <br/>\n  <i>Choose the instance closest to you for the best performance.</i>\n</p>\n\n---\n\n## How It Works\n\nWith Netdata you can run a modular pipeline for metrics collection, processing, and visualization.\n\n```mermaid\nflowchart TB\n  A[Netdata Agent]:::mainNode\n  A1(Collect):::green --> A\n  A2(Store):::green --> A\n  A3(Learn):::green --> A\n  A4(Detect):::green --> A\n  A5(Check):::green --> A\n  A6(Stream):::green --> A\n  A7(Archive):::green --> A\n  A8(Query):::green --> A\n  A9(Score):::green --> A\n\n  classDef green fill:#bbf3bb,stroke:#333,stroke-width:1px,color:#000\n  classDef mainNode fill:#f0f0f0,stroke:#333,stroke-width:1px,color:#333\n```\n\nWith each Agent you can:\n\n1. **Collect** â€“ Gather metrics from systems, containers, apps, logs, APIs, and synthetic checks.\n2. **Store** â€“ Save metrics to a high-efficiency, tiered time-series database.\n3. **Learn** â€“ Train ML models per metric using recent behavior.\n4. **Detect** â€“ Identify anomalies using trained ML models.\n5. **Check** â€“ Evaluate metrics against pre-set or custom alert rules.\n6. **Stream** â€“ Send metrics to Netdata Parents in real time.\n7. **Archive** â€“ Export metrics to Prometheus, InfluxDB, OpenTSDB, Graphite, and others.\n8. **Query** â€“ Access metrics via an API for dashboards or third-party tools.\n9. **Score** â€“ Use a scoring engine to find patterns and correlations across metrics.\n\n> [!NOTE]  \n> Learn more: [Netdata's architecture](https://learn.netdata.cloud/docs/netdata-agent/#distributed-observability-pipeline)\n\n## Agent Capabilities\n\nWith the Netdata Agent, you can use these core capabilities out-of-the-box:\n\n| Capability                   | Description                                                                                                                                   |\n|------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|\n| **Comprehensive Collection** | â€¢ 800+ integrations<br>â€¢ Systems, containers, VMs, hardware sensors<br>â€¢ OpenMetrics, StatsD, and logs<br>â€¢ OpenTelemetry support coming soon |\n| **Performance & Precision**  | â€¢ Per-second collection<br>â€¢ Real-time visualization with 1-second latency<br>â€¢ High-resolution metrics                                       |\n| **Edge-Based ML**            | â€¢ ML models trained at the edge<br>â€¢ Automatic anomaly detection per metric<br>â€¢ Pattern recognition based on historical behavior             |\n| **Advanced Log Management**  | â€¢ Direct systemd-journald and Windows Event Log integration<br>â€¢ Process logs at the edge<br>â€¢ Rich log visualization                         |\n| **Observability Pipeline**   | â€¢ Parent-Child relationships<br>â€¢ Flexible centralization<br>â€¢ Multi-level replication and retention                                          |\n| **Automated Visualization**  | â€¢ NIDL data model<br>â€¢ Auto-generated dashboards<br>â€¢ No query language needed                                                                |\n| **Smart Alerting**           | â€¢ Pre-configured alerts<br>â€¢ Multiple notification methods<br>â€¢ Proactive detection                                                           |\n| **Low Maintenance**          | â€¢ Auto-detection<br>â€¢ Zero-touch ML<br>â€¢ Easy scalability<br>â€¢ CI/CD friendly                                                                 |\n| **Open & Extensible**        | â€¢ Modular architecture<br>â€¢ Easy to customize<br>â€¢ Integrates with existing tools                                                             |\n\n---\n\n## CNCF Membership\n\n<p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/white/cncf-white.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/color/cncf-color.svg\">\n    <img alt=\"CNCF Logo\" src=\"https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/color/cncf-color.svg\" width=\"300\">\n  </picture>\n  <br />\n  Netdata actively supports and is a member of the Cloud Native Computing Foundation (CNCF).<br />\n  It is one of the most starred projects in the <a href=\"https://landscape.cncf.io/?item=observability-and-analysis--observability--netdata\">CNCF landscape</a>.\n</p>\n\n---\n\n## FAQ\n\n<details>\n<summary><strong>Is Netdata secure?</strong></summary>\n<br/>\n\nYes. Netdata follows [OpenSSF best practices](https://bestpractices.coreinfrastructure.org/en/projects/2231), has a security-first design, and is regularly audited by the community.\n\n* [Security design](https://learn.netdata.cloud/docs/security-and-privacy-design)\n* [Security policies and advisories](https://github.com/netdata/netdata/security)\n\n</details>\n\n<details>\n<summary><strong>Does Netdata use a lot of resources?</strong></summary>\n<br/>\n\nNo. Even with ML and per-second metrics, Netdata uses minimal resources.\n\n* \\~5% CPU and 150MiB RAM by default on production systems\n* <1% CPU and \\~100MiB RAM when ML and alerts are disabled and using ephemeral storage\n* Parents scale to millions of metrics per second with appropriate hardware\n\n> You can use the **Netdata Monitoring** section in the dashboard to inspect its resource usage.\n\n</details>\n\n<details>\n<summary><strong>How much data retention is possible?</strong></summary>\n<br/>\n\nAs much as your disk allows.\n\nWith Netdata you can use tiered retention:\n\n* Tier 0: per-second resolution\n* Tier 1: per-minute resolution\n* Tier 2: per-hour resolution\n\nThese are queried automatically based on the zoom level.\n</details>\n\n<details>\n<summary><strong>Can Netdata scale to many servers?</strong></summary>\n<br/>\n\nYes. With Netdata you can:\n\n* Scale horizontally with many Agents\n* Scale vertically with powerful Parents\n* Scale infinitely via Netdata Cloud\n\n> You can use Netdata Cloud to merge many independent infrastructures into one logical view.\n\n</details>\n\n<details>\n<summary><strong>Is disk I/O a concern?</strong></summary>\n<br/>\n\nNo. Netdata minimizes disk usage:\n\n* Metrics are flushed to disk every 17 minutes, spread out evenly\n* Uses direct I/O and compression (ZSTD)\n* Can run entirely in RAM or stream to a Parent\n\n> You can use `alloc` or `ram` mode for no disk writes.\n\n</details>\n\n<details>\n<summary><strong>How is Netdata different from Prometheus + Grafana?</strong></summary>\n<br/>\n\nWith Netdata you get a complete monitoring solutionâ€”not just tools.\n\n* No manual setup or dashboards needed\n* Built-in ML, alerts, dashboards, and correlations\n* More efficient and easier to deploy\n\n> [Performance comparison](https://blog.netdata.cloud/netdata-vs-prometheus-performance-analysis/)\n\n</details>\n\n<details>\n<summary><strong>How is Netdata different from commercial SaaS tools?</strong></summary>\n<br/>\n\nWith Netdata you can store all metrics on your infrastructureâ€”no sampling, no aggregation, no loss.\n\n* High-resolution metrics by default\n* ML per metric, not shared models\n* Unlimited scalability without skyrocketing cost\n\n</details>\n\n<details>\n<summary><strong>Can Netdata run alongside Nagios, Zabbix, etc.?</strong></summary>\n<br/>\n\nYes. You can use Netdata together with traditional tools.\n\nWith Netdata you get:\n\n* Real-time, high-resolution monitoring\n* Zero configuration and auto-generated dashboards\n* Anomaly detection and advanced visualization\n\n</details>\n\n<details>\n<summary><strong>What if I feel overwhelmed?</strong></summary>\n<br/>\n\nYou can start small:\n\n* Use the dashboard's table of contents and search\n* Explore anomaly scoring (\"AR\" toggle)\n* Create custom dashboards in Netdata Cloud\n\n> [Docs and guides](https://learn.netdata.cloud/guides)\n\n</details>\n\n<details>\n<summary><strong>Do I have to use Netdata Cloud?</strong></summary>\n<br/>\n\nNo. Netdata Cloud is optional.\n\nNetdata works without it, but with Cloud you can:\n\n* Access remotely with SSO\n* Save dashboard customizations\n* Configure alerts centrally\n* Collaborate with role-based access\n\n</details>\n\n<details>\n<summary><strong>What telemetry does Netdata collect?</strong></summary>\n<br/>\n\nAnonymous telemetry helps improve the product. You can disable it:\n\n* Add `--disable-telemetry` to the installer, or\n* Create `/etc/netdata/.opt-out-from-anonymous-statistics` and restart Netdata\n\n> Telemetry helps us understand usage, not track users. No private data is collected.\n\n</details>\n\n<details>\n<summary><strong>Who uses Netdata?</strong></summary>\n<br/>\n\nYou'll join users including:\n\n* Major companies (Amazon, ABN AMRO Bank, Facebook, Google, IBM, Intel, Netflix, Samsung)\n* Universities (NYU, Columbia, Seoul National, UCL)\n* Government organizations worldwide\n* Infrastructure-intensive organizations\n* Technology operators\n* Startups and freelancers\n* SysAdmins and DevOps professionals\n\n</details>\n\n---\n\n## \\:book: Documentation\n\nVisit [Netdata Learn](https://learn.netdata.cloud) for full documentation and guides.\n\n> [!NOTE]  \n> Includes deployment, configuration, alerting, exporting, troubleshooting, and more.\n\n---\n\n## \\:tada: Community\n\nJoin the Netdata community:\n\n* [Discord](https://discord.com/invite/2mEmfW735j)\n* [Forum](https://community.netdata.cloud)\n* [GitHub Discussions](https://github.com/netdata/netdata/discussions)\n\n> [!NOTE]  \n> [Code of Conduct](https://github.com/netdata/.github/blob/main/CODE_OF_CONDUCT.md)\n\nFollow us on:\n[Twitter](https://twitter.com/netdatahq) | [Reddit](https://www.reddit.com/r/netdata/) | [YouTube](https://www.youtube.com/c/Netdata) | [LinkedIn](https://www.linkedin.com/company/netdata-cloud/)\n\n---\n\n## \\:pray: Contribute\n\nWe welcome your contributions.\n\nWays you help us stay sharp:\n\n* Share best practices and monitoring insights\n* Report issues or missing features\n* Improve documentation\n* Develop new integrations or collectors\n* Help users in forums and chats\n\n> [!NOTE]  \n> [Contribution guide](https://github.com/netdata/.github/blob/main/CONTRIBUTING.md)\n\n---\n\n## \\:scroll: License\n\nThe Netdata ecosystem includes:\n\n* **Netdata Agent** â€“ Open-source core (GPLv3+). **Includes** data collection, storage, ML, alerting, APIs and **redistributes** several other open-source tools and libraries.\n    * [Netdata Agent License](https://github.com/netdata/netdata/blob/master/LICENSE)\n    * [Netdata Agent Redistributed](https://github.com/netdata/netdata/blob/master/REDISTRIBUTED.md)\n* **Netdata UI** â€“ Closed-source but free to use with Netdata Agent and Cloud. Delivered via CDN. It integrates third-party open-source components.\n    * [Netdata Cloud UI License](https://app.netdata.cloud/LICENSE.txt)\n    * [Netdata UI third-party licenses](https://app.netdata.cloud/3D_PARTY_LICENSES.txt)\n* **Netdata Cloud** â€“ Closed-source, with free and paid tiers. Adds remote access, SSO, scalability.\n",
      "stars_today": 10
    },
    {
      "id": 569041,
      "name": "curl",
      "full_name": "curl/curl",
      "description": "A command line tool and library for transferring data with URL syntax, supporting DICT, FILE, FTP, FTPS, GOPHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, TFTP, WS and WSS. libcurl offers a myriad of powerful features",
      "html_url": "https://github.com/curl/curl",
      "stars": 40376,
      "forks": 7016,
      "language": "C",
      "topics": [
        "c",
        "client",
        "curl",
        "ftp",
        "gopher",
        "hacktoberfest",
        "http",
        "https",
        "imaps",
        "ldap",
        "libcurl",
        "library",
        "mqtt",
        "pop3",
        "scp",
        "sftp",
        "transfer-data",
        "transferring-data",
        "user-agent",
        "websocket"
      ],
      "created_at": "2010-03-18T22:32:22Z",
      "updated_at": "2026-01-16T00:47:42Z",
      "pushed_at": "2026-01-15T22:33:21Z",
      "open_issues": 43,
      "owner": {
        "login": "curl",
        "avatar_url": "https://avatars.githubusercontent.com/u/16928085?v=4"
      },
      "readme": "<!--\nCopyright (C) Daniel Stenberg, <daniel@haxx.se>, et al.\n\nSPDX-License-Identifier: curl\n-->\n\n# [![curl logo](https://curl.se/logo/curl-logo.svg)](https://curl.se/)\n\ncurl is a command-line tool for transferring data from or to a server using\nURLs. It supports these protocols: DICT, FILE, FTP, FTPS, GOPHER, GOPHERS,\nHTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP,\nSCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, TFTP, WS and WSS.\n\nLearn how to use curl by reading [the\nman page](https://curl.se/docs/manpage.html) or [everything\ncurl](https://everything.curl.dev/).\n\nFind out how to install curl by reading [the INSTALL\ndocument](https://curl.se/docs/install.html).\n\nlibcurl is the library curl is using to do its job. It is readily available to\nbe used by your software. Read [the libcurl\nman page](https://curl.se/libcurl/c/libcurl.html) to learn how.\n\n## Open Source\n\ncurl is Open Source and is distributed under an MIT-like\n[license](https://curl.se/docs/copyright.html).\n\n## Contact\n\nContact us on a suitable [mailing list](https://curl.se/mail/) or\nuse GitHub [issues](https://github.com/curl/curl/issues)/\n[pull requests](https://github.com/curl/curl/pulls)/\n[discussions](https://github.com/curl/curl/discussions).\n\nAll contributors to the project are listed in [the THANKS\ndocument](https://curl.se/docs/thanks.html).\n\n## Commercial support\n\nFor commercial support, maybe private and dedicated help with your problems or\napplications using (lib)curl visit [the support page](https://curl.se/support.html).\n\n## Website\n\nVisit the [curl website](https://curl.se/) for the latest news and downloads.\n\n## Source code\n\nDownload the latest source from the Git server:\n\n    git clone https://github.com/curl/curl\n\n## Security problems\n\nReport suspected security problems via [our HackerOne\npage](https://hackerone.com/curl) and not in public.\n\n## Backers\n\nThank you to all our backers :pray: [Become a backer](https://opencollective.com/curl#section-contribute).\n\n## Sponsors\n\nSupport this project by becoming a [sponsor](https://curl.se/sponsors.html).\n",
      "stars_today": 10
    },
    {
      "id": 53370988,
      "name": "lighthouse",
      "full_name": "GoogleChrome/lighthouse",
      "description": "Automated auditing, performance metrics, and best practices for the web.",
      "html_url": "https://github.com/GoogleChrome/lighthouse",
      "stars": 29724,
      "forks": 9636,
      "language": "JavaScript",
      "topics": [
        "audit",
        "best-practices",
        "chrome-devtools",
        "developer-tools",
        "performance-analysis",
        "performance-metrics",
        "pwa",
        "web"
      ],
      "created_at": "2016-03-08T01:03:11Z",
      "updated_at": "2026-01-15T22:26:31Z",
      "pushed_at": "2026-01-12T23:55:18Z",
      "open_issues": 491,
      "owner": {
        "login": "GoogleChrome",
        "avatar_url": "https://avatars.githubusercontent.com/u/1778935?v=4"
      },
      "readme": "# Lighthouse  [![GitHub Actions Status Badge](https://github.com/GoogleChrome/lighthouse/workflows/CI/badge.svg)](https://github.com/GoogleChrome/lighthouse/actions/workflows/ci.yml) [![GitHub Actions Status Badge](https://github.com/GoogleChrome/lighthouse/workflows/unit/badge.svg)](https://github.com/GoogleChrome/lighthouse/actions/workflows/unit.yml) [![GitHub Actions Status Badge](https://github.com/GoogleChrome/lighthouse/workflows/smoke/badge.svg)](https://github.com/GoogleChrome/lighthouse/actions/workflows/smoke.yml) [![Coverage Status](https://codecov.io/gh/GoogleChrome/lighthouse/branch/main/graph/badge.svg)](https://codecov.io/gh/GoogleChrome/lighthouse) [![Build tracker for Lighthouse](https://img.shields.io/badge/buildtracker-ok-blue)](https://lh-build-tracker.herokuapp.com/) [![NPM lighthouse package](https://img.shields.io/npm/v/lighthouse.svg)](https://npmjs.org/package/lighthouse)\n\n> Lighthouse analyzes web apps and web pages, collecting modern performance metrics and insights on developer best practices.\n\n- Using Lighthouse\n  - [Using Lighthouse in Chrome DevTools](#using-lighthouse-in-chrome-devtools)\n  - [Using the Chrome extension](#using-the-chrome-extension)\n  - [Using the Node CLI](#using-the-node-cli)\n    * [CLI options](#cli-options)\n  - [Using the Node module](#using-the-node-module)\n  - [Viewing a report](#viewing-a-report)\n    * [Online Viewer](#online-viewer)\n  - [Docs & Recipes](#docs--recipes)\n  - [Developing Lighthouse](#develop)\n    * [Setup](#setup)\n    * [Run](#run)\n    * [Tests](#tests)\n    * [Docs](#docs)\n- Associated Products and Projects\n  - [Lighthouse Integrations in Web Perf services](#lighthouse-integrations-in-web-perf-services)\n  - [Lighthouse Integrations in non-Web Perf services](#lighthouse-integrations-in-non-web-perf-services)\n  - [Plugins](#plugins)\n  - [Related projects](#related-projects)\n- [FAQ](#faq)\n  * [How does Lighthouse work?](#how-does-lighthouse-work)\n  * [Can I configure the lighthouse run?](#can-i-configure-the-lighthouse-run)\n  * [How does Lighthouse use network throttling, and how can I make it better?](#how-does-lighthouse-use-network-throttling-and-how-can-i-make-it-better)\n  * [Are results sent to a remote server?](#are-results-sent-to-a-remote-server)\n  * [How do I get localized Lighthouse results?](#how-do-i-get-localized-lighthouse-results-via-the-cli)\n  * [How do I author custom audits to extend Lighthouse?](#how-do-i-author-custom-audits-to-extend-lighthouse)\n  * [How do I contribute?](#how-do-i-contribute)\n\n## Using Lighthouse in Chrome DevTools\n\nLighthouse is integrated directly into the Chrome DevTools, under the \"Lighthouse\" panel.\n\n**Installation**: install [Chrome](https://www.google.com/chrome/browser).\n\n**Run it**: open Chrome DevTools, select the Lighthouse panel, and hit \"Generate report\".\n\n<img width=\"550\" alt=\"Lighthouse integration in Chrome DevTools.\" src=\"https://user-images.githubusercontent.com/2766281/204185043-9c49abe5-baee-4b26-b5ce-ece410661213.png\">\n\n## Using the Chrome extension\n\nThe Chrome extension was available prior to Lighthouse being available in Chrome Developer Tools, and offers similar functionality.\n\n**Installation**: [install the extension](https://chrome.google.com/webstore/detail/lighthouse/blipmdconlkpinefehnmjammfjpmpbjk) from the Chrome Web Store.\n\n**Run it**: follow the [extension quick-start guide](https://developers.google.com/web/tools/lighthouse/#extension).\n\n## Using the Node CLI\n\nThe Node CLI provides the most flexibility in how Lighthouse runs can be configured and reported. Users who want more advanced usage, or want to run Lighthouse in an automated fashion should use the Node CLI.\n\n> [!NOTE]\n> Lighthouse requires Node 22 (LTS) or later.\n\n**Installation**:\n\n```sh\nnpm install -g lighthouse\n# or use yarn:\n# yarn global add lighthouse\n```\n\n**Run it**: `lighthouse https://airhorner.com/`\n\nBy default, Lighthouse writes the report to an HTML file. You can control the output format by passing flags.\n\n### CLI options\n\n<!-- To update the help output:\n  node cli --help | pbcopy\n-->\n\n```\n$ lighthouse --help\n\nlighthouse <url> <options>\n\nLogging:\n  --verbose  Displays verbose logging  [boolean] [default: false]\n  --quiet    Displays no progress, debug logs, or errors  [boolean] [default: false]\n\nConfiguration:\n  --save-assets                  Save the trace contents & devtools logs to disk  [boolean] [default: false]\n  --list-all-audits              Prints a list of all available audits and exits  [boolean] [default: false]\n  --list-trace-categories        Prints a list of all required trace categories and exits  [boolean] [default: false]\n  --additional-trace-categories  Additional categories to capture with the trace (comma-delimited).  [string]\n  --config-path                  The path to the config JSON.\n                                 An example config file: core/config/lr-desktop-config.js  [string]\n  --preset                       Use a built-in configuration.\n                                 WARNING: If the --config-path flag is provided, this preset will be ignored.  [string] [choices: \"perf\", \"experimental\", \"desktop\"]\n  --chrome-flags                 Custom flags to pass to Chrome (space-delimited). For a full list of flags, see https://bit.ly/chrome-flags\n                                 Additionally, use the CHROME_PATH environment variable to use a specific Chrome binary. Requires Chromium version 66.0 or later. If omitted, any detected Chrome Canary or Chrome stable will be used.  [string] [default: \"\"]\n  --port                         The port to use for the debugging protocol. Use 0 for a random port  [number] [default: 0]\n  --hostname                     The hostname to use for the debugging protocol.  [string] [default: \"localhost\"]\n  --form-factor                  Determines how performance metrics are scored and if mobile-only audits are skipped. For desktop, use --preset=desktop instead.  [string] [choices: \"mobile\", \"desktop\"]\n  --screenEmulation              Sets screen emulation parameters. See also --preset. Use --screenEmulation.disabled to disable. Otherwise set these 4 parameters individually: --screenEmulation.mobile --screenEmulation.width=360 --screenEmulation.height=640 --screenEmulation.deviceScaleFactor=2\n  --emulatedUserAgent            Sets useragent emulation  [string]\n  --max-wait-for-load            The timeout (in milliseconds) to wait before the page is considered done loading and the run should continue. WARNING: Very high values can lead to large traces and instability  [number]\n  --enable-error-reporting       Enables error reporting, overriding any saved preference. --no-enable-error-reporting will do the opposite. More: https://github.com/GoogleChrome/lighthouse/blob/main/docs/error-reporting.md  [boolean]\n  --gather-mode, -G              Collect artifacts from a connected browser and save to disk. (Artifacts folder path may optionally be provided). If audit-mode is not also enabled, the run will quit early.\n  --audit-mode, -A               Process saved artifacts from disk. (Artifacts folder path may be provided, otherwise defaults to ./latest-run/)\n  --only-audits                  Only run the specified audits  [array]\n  --only-categories              Only run the specified categories. Available categories: accessibility, best-practices, performance, seo  [array]\n  --skip-audits                  Run everything except these audits  [array]\n  --disable-full-page-screenshot Disables collection of the full page screenshot, which can be quite large  [boolean]\n\nOutput:\n  --output       Reporter for the results, supports multiple values. choices: \"json\", \"html\", \"csv\"  [array] [default: [\"html\"]]\n  --output-path  The file path to output the results. Use 'stdout' to write to stdout.\n                   If using JSON output, default is stdout.\n                   If using HTML or CSV output, default is a file in the working directory with a name based on the test URL and date.\n                   If using multiple outputs, --output-path is appended with the standard extension for each output type. \"reports/my-run\" -> \"reports/my-run.report.html\", \"reports/my-run.report.json\", etc.\n                   Example: --output-path=./lighthouse-results.html  [string]\n  --view         Open HTML report in your browser  [boolean] [default: false]\n\nOptions:\n  --version                            Show version number  [boolean]\n  --help                               Show help  [boolean]\n  --cli-flags-path                     The path to a JSON file that contains the desired CLI flags to apply. Flags specified at the command line will still override the file-based ones.\n  --locale                             The locale/language the report should be formatted in\n  --blocked-url-patterns               Block any network requests to the specified URL patterns  [array]\n  --disable-storage-reset              Disable clearing the browser cache and other storage APIs before a run  [boolean]\n  --throttling-method                  Controls throttling method  [string] [choices: \"devtools\", \"provided\", \"simulate\"]\n  --throttling\n  --throttling.rttMs                   Controls simulated network RTT (TCP layer)\n  --throttling.throughputKbps          Controls simulated network download throughput\n  --throttling.requestLatencyMs        Controls emulated network RTT (HTTP layer)\n  --throttling.downloadThroughputKbps  Controls emulated network download throughput\n  --throttling.uploadThroughputKbps    Controls emulated network upload throughput\n  --throttling.cpuSlowdownMultiplier   Controls simulated + emulated CPU throttling\n  --extra-headers                      Set extra HTTP Headers to pass with request\n  --precomputed-lantern-data-path      Path to the file where lantern simulation data should be read from, overwriting the lantern observed estimates for RTT and server latency.  [string]\n  --lantern-data-output-path           Path to the file where lantern simulation data should be written to, can be used in a future run with the `precomputed-lantern-data-path` flag.  [string]\n  --plugins                            Run the specified plugins  [array]\n  --channel  [string] [default: \"cli\"]\n  --chrome-ignore-default-flags  [boolean] [default: false]\n\nExamples:\n  lighthouse <url> --view                                                                          Opens the HTML report in a browser after the run completes\n  lighthouse <url> --config-path=./myconfig.js                                                     Runs Lighthouse with your own configuration: custom audits, report generation, etc.\n  lighthouse <url> --output=json --output-path=./report.json --save-assets                         Save trace, screenshots, and named JSON report.\n  lighthouse <url> --screenEmulation.disabled --throttling-method=provided --no-emulatedUserAgent  Disable device emulation and all throttling\n  lighthouse <url> --chrome-flags=\"--window-size=412,660\"                                          Launch Chrome with a specific window size\n  lighthouse <url> --quiet --chrome-flags=\"--headless\"                                             Launch Headless Chrome, turn off logging\n  lighthouse <url> --extra-headers \"{\\\"Cookie\\\":\\\"monster=blue\\\", \\\"x-men\\\":\\\"wolverine\\\"}\"        Stringify'd JSON HTTP Header key/value pairs to send in requests\n  lighthouse <url> --extra-headers=./path/to/file.json                                             Path to JSON file of HTTP Header key/value pairs to send in requests\n  lighthouse <url> --only-categories=performance,seo                                               Only run the specified categories. Available categories: accessibility, best-practices, performance, seo\n\nFor more information on Lighthouse, see https://developers.google.com/web/tools/lighthouse/.\n```\n\n##### Output Examples\n\n```sh\nlighthouse\n# saves `./<HOST>_<DATE>.report.html`\n\nlighthouse --output json\n# json output sent to stdout\n\nlighthouse --output html --output-path ./report.html\n# saves `./report.html`\n\n# NOTE: specifying an output path with multiple formats ignores your specified extension for *ALL* formats\nlighthouse --output json --output html --output-path ./myfile.json\n# saves `./myfile.report.json` and `./myfile.report.html`\n\nlighthouse --output json --output html\n# saves `./<HOST>_<DATE>.report.json` and `./<HOST>_<DATE>.report.html`\n\nlighthouse --output-path=~/mydir/foo.out --save-assets\n# saves `~/mydir/foo.report.html`\n# saves `~/mydir/foo-0.trace.json` and `~/mydir/foo-0.devtoolslog.json`\n\nlighthouse --output-path=./report.json --output json\n# saves `./report.json`\n```\n\n##### Lifecycle Examples\nYou can run a subset of Lighthouse's lifecycle if desired via the `--gather-mode` (`-G`) and  `--audit-mode` (`-A`) CLI flags.\n\n```sh\nlighthouse http://example.com -G\n# launches browser, collects artifacts, saves them to disk (in `./latest-run/`) and quits\n\nlighthouse http://example.com -A\n# skips browser interaction, loads artifacts from disk (in `./latest-run/`), runs audits on them, generates report\n\nlighthouse http://example.com -GA\n# Normal gather + audit run, but also saves collected artifacts to disk for subsequent -A runs.\n\n\n# You can optionally provide a custom folder destination to -G/-A/-GA. Without a value, the default will be `$PWD/latest-run`.\nlighthouse -GA=./gmailartifacts https://gmail.com\n```\n\n\n#### Notes on Error Reporting\n\nThe first time you run the CLI you will be prompted with a message asking you if Lighthouse can anonymously report runtime exceptions. The Lighthouse team uses this information to detect new bugs and avoid regressions. Opting out will not affect your ability to use Lighthouse in any way. [Learn more](https://github.com/GoogleChrome/lighthouse/blob/main/docs/error-reporting.md).\n\n## Using the Node module\nYou can also use Lighthouse programmatically with the Node module.\n\nRead [Using Lighthouse programmatically](./docs/readme.md#using-programmatically) for help getting started.\\\nRead [Lighthouse Configuration](./docs/configuration.md) to learn more about the configuration options available.\n\n## Viewing a report\n\nLighthouse can produce a report as JSON or HTML.\n\nHTML report:\n\n<img src=\"https://raw.githubusercontent.com/GoogleChrome/lighthouse/443ff2c8a297dfd2297dfaca86c4966a87c8574a/assets/example_audit.png\" alt=\"Lighthouse example audit\" width=\"500px\">\n\n### Online Viewer\n\nRunning Lighthouse with the `--output=json` flag generates a JSON dump of the run.\nYou can view this report online by visiting <https://googlechrome.github.io/lighthouse/viewer/>\nand dragging the file onto the app. You can also use the \"Export\" button from the\ntop of any Lighthouse HTML report and open the report in the\n[Lighthouse Viewer](https://googlechrome.github.io/lighthouse/viewer/).\n\nIn the Viewer, reports can be shared by clicking the share icon in the top\nright corner and signing in to GitHub.\n\n> [!NOTE]\n>  shared reports are stashed as a secret Gist in GitHub, under your account.\n\n## Docs & Recipes\n\nUseful documentation, examples, and recipes to get you started.\n\n**Docs**\n\n- [Dealing with variance](./docs/variability.md)\n- [Using Lighthouse programmatically](./docs/readme.md#using-programmatically)\n- [Testing a site with authentication](./docs/authenticated-pages.md)\n- [Developing Plugins](./docs/plugins.md)\n- [Making a New Audit](./docs/new-audits.md)\n- [Testing on a mobile device](./docs/readme.md#testing-on-a-mobile-device)\n- [Lighthouse Architecture](./docs/architecture.md)\n\n**Recipes**\n\n- [Plugin](./docs/recipes/lighthouse-plugin-example) - example Lighthouse plugin\n- [Custom Audit example](./docs/recipes/custom-audit) - extend Lighthouse, run your own audits\n\n**Videos**\n\nThe session from Google I/O 2018 covers the new performance engine, upcoming Lighthouse REST API, and using the Chrome UX report to evaluate real-user data.\n\n[![Watch the Lighthouse @ Google I/O 2018 session.](https://img.youtube.com/vi/UvK9zAsSM8Q/0.jpg)](https://www.youtube.com/watch?v=UvK9zAsSM8Q)\n\nThe session from Google I/O 2017 covers architecture, writing custom audits,\nGitHub/Travis/CI integration, headless Chrome, and more:\n\n[![Watch the Lighthouse @ Google I/O 2017 session.](https://img.youtube.com/vi/NoRYn6gOtVo/0.jpg)](https://www.youtube.com/watch?v=NoRYn6gOtVo)\n\n_Click the image to watch the video on YouTube._\n\n## Develop\n\nRead on for the basics of hacking on Lighthouse. Also, see [Contributing](./CONTRIBUTING.md)\nfor detailed information.\n\n### Setup\n\n```sh\n# yarn should be installed first\n\ngit clone https://github.com/GoogleChrome/lighthouse\n\ncd lighthouse\nyarn\nyarn build-all\n```\n\n### Run\n\n```sh\nnode cli http://example.com\n# append --chrome-flags=\"--no-sandbox --headless --disable-gpu\" if you run into problems connecting to Chrome\n```\n\n> **Getting started tip**: `node --inspect-brk cli http://example.com` to open up Chrome DevTools and step\nthrough the entire app. See [Debugging Node.js with Chrome\nDevTools](https://medium.com/@paul_irish/debugging-node-js-nightlies-with-chrome-devtools-7c4a1b95ae27#.59rma3ukm)\nfor more info.\n\n### Tests\n\n```sh\n# lint and test all files\nyarn test\n\n# run all unit tests\nyarn unit\n\n# run a given unit test (e.g. core/test/audits/byte-efficiency/uses-long-cache-ttl-test.js)\nyarn mocha uses-long-cache-ttl\n\n# watch for file changes and run tests\n#   Requires http://entrproject.org : brew install entr\nyarn watch\n\n## run linting, unit, and smoke tests separately\nyarn lint\nyarn unit\nyarn smoke\n\n## run tsc compiler\nyarn type-check\n```\n\n### Docs\n\nSome of our docs have tests that run only in CI by default. To modify our documentation, you'll need to run `yarn build-pack && yarn test-docs` locally to make sure they pass.\n\n**Additional Dependencies**\n- `brew install jq`\n\n## Lighthouse Integrations in Web Perf services\n\nThis section details services that have integrated Lighthouse data. If you're working on a cool project integrating Lighthouse and would like to be featured here, file an issue to this repo or tweet at us [@_____lighthouse](https://twitter.com/____lighthouse)!\n\n* **[Web Page Test](https://www.webpagetest.org)** â€” An [open source](https://github.com/WPO-Foundation/webpagetest) tool for measuring and analyzing the performance of web pages on real devices. Users can choose to produce a Lighthouse report alongside the analysis of WebPageTest results.\n\n* **[HTTPArchive](http://httparchive.org/)** - HTTPArchive tracks how the web is built by crawling 500k pages with Web Page Test, including Lighthouse results, and stores the information in BigQuery where it is [publicly available](https://discuss.httparchive.org/t/quickstart-guide-to-exploring-the-http-archive/682).\n\n* **[Calibre](https://calibreapp.com)** - Calibre is a comprehensive performance monitoring platform running on Lighthouse. See the performance impact of your work before it hits production with GitHub Pull Request Reviews. Track the impact of Third Party scripts. Automate your performance system with a developer-first Node.js API. Try Calibre with a free 15-day trial.\n\n* **[DebugBear](https://www.debugbear.com/)** - DebugBear is a website monitoring tool based on Lighthouse. See how your scores and metrics changed over time, with a focus on understanding what caused each change. DebugBear is a paid product with a free 30-day trial.\n\n* **[Treo](https://treo.sh)** - Treo is Lighthouse as a Service. It provides regression testing, geographical regions, custom networks, and integrations with GitHub & Slack. Treo is a paid product with plans for solo-developers and teams.\n\n* **[PageVitals](https://pagevitals.com)** - PageVitals combines Lighthouse, CrUX and field testing to monitor the performance of websites. See how your website performs over time and get alerted if it gets too slow. Drill down and find the real cause of any performance issue. PageVitals is a paid product with a free 14-day trial.\n\n* **[Screpy](https://screpy.com)** - Screpy is a web analysis tool that can analyze all pages of your websites in one dashboard and monitor them with your team. It's powered by Lighthouse and it also includes some different analysis tools (SERP, W3C, Uptime, etc). Screpy has free and paid plans.\n\n* **[Siteimprove Performance](https://siteimprove.com/en/performance/)** â€” Siteimprove Performance is a web Performance monitoring solution that enables a marketer, manager or decision maker to understand and optimize website load times. Get easy-to-use insights with a focus on quick and impactful wins. Siteimprove Performance is a paid product with a free 14-day trial.\n\n* **[SpeedCurve](https://speedcurve.com)** â€” SpeedCurve is a tool for continuously monitoring web performance across different browsers, devices, and regions. It can aggregate any metric including Lighthouse scores across multiple pages and sites, and allows you to set performance budgets with Slack or email alerts. SpeedCurve is a paid product with a free 30-day trial.\n\n* **[Foo](https://www.foo.software/lighthouse)** - Lighthouse-as-a-service offering free and premium plans. Provides monitoring and historical reporting of Lighthouse audits with CircleCI, GitHub, and other integrations. Features include Slack notifications, PR comment reporting and more.\n\n* **[Apdex](https://apdex.co)** - Apdex is a website performance service. The main features are historical Lighthouse report visualizations, mobile/desktop options, alerts, uptime monitoring, and more. There are flexible paid plans and a 30-day free trial.\n\n* **[Websu](https://websu.io)** - Websu is an open source project to provide Lighthouse-as-a-Service through a simple HTTP REST API. The main features are ability to host and deploy in your own environment and historical Lighthouse report summaries.\n\n* **[DTEKT.IO](https://dtekt.io)** - DTEKT is a website performance and uptime monitoring service. It uses lighthouse to provide visibility into the performance of websites from multiple locations on multiple devices. It offers three months free trial and paid plans.\n\n* **[SpeedVitals](https://speedvitals.com)** - SpeedVitals is a Lighthouse powered tool to measure web performance across multiple devices and locations. It has various features like Layout Shift Visualization, Waterfall Chart, Field Data and Resource Graphs. SpeedVitals offers both free and paid plans.\n\n* **[Lighthouse Metrics](https://lighthouse-metrics.com/)** - Lighthouse Metrics gives you global performance insights with a single test. You can also monitor your websites on a daily or hourly base. Lighthouse Metrics offers free global one-time tests and performance monitoring as a paid feature with a free 14-day trial.\n\n* **[Auditzy](https://auditzy.com)** - Auditzyâ„¢ is a robust website auditing & monitoring tool which lets you analyze your web page(s) pre-user journey. Analyze the Competitor Health Metric, Core Web Vitals, and Technology. Compare your web pages with your competitors to understand where you are leading or lagging. Real-time notification with Slack. Have Seamless Collaboration with Multiple Teams. Automate your Audits hourly, daily, weekly, and so on. It has a free trial with pay as you go plans.\n\n* **[Lighthouse Metrics China](http://lighthousemetricschina.com)** - The first Lighthouse metrics tool specifically designed for China. Experience unparalleled website monitoring capabilities with Lighthouse. Gain insights into the fluctuations of your scores and metrics within the realm of the [Great Firewall of China](https://www.chinafirewalltest.co), enabling a comprehensive understanding of the factors influencing each change. Lighthouse Metrics China offers both free and paid plans.\n\n* **[DeploymentHawk](https://deploymenthawk.com)** - DeploymentHawk is an automated site auditing tool powered by Lighthouse. Effortlessly catch performance, accessibility, and SEO issues before they impact your users. DeploymentHawk is a paid product with a free 7-day trial.\n\n* **[Guardius](https://guardius.io)** - Guardius is a DevOps and DevSecOps SaaS platform that integrates Lighthouse to deliver automated web performance analysis. It not only provides metrics evaluation and automatic scanning but also enables performance comparisons across different periods and ongoing observation over time. Additionally, Guardius offers predefined and customized alerts tailored to your specific requirements. A free version of Guardius is available for users to explore its features.\n\n* **[SonÄ](https://getsona.io)** - Powered by Lighthouse amongst others, SonÄ delivers in-depth insights into your websiteâ€™s health. Track changes over time, share reports, and receive actionable recommendations to improve performance, accessibility, SEO, best practices, and security. SonÄ is free during its beta period.\n\n* **[FERU](https://feru.app)** - Run Google Lighthouse speed tests from multiple regions worldwide. Lighthouse scores, Core Web Vitals, and mobile performance metrics to easily test your site's speed, accessibility, and SEO. FERU offers an always-free plan alongside premium features for advanced analysis and monitoring.\n\n* **[LightKeeper](https://www.lightkeeper.cloud)** - Lighthouse testing service with free HAR Matrix view and multi-region testing (3 free regions, 25+ paid), supporting authenticated pages and cross-region performance comparison\n\n## Lighthouse Integrations in non-Web Perf services\n\n* **[PageWatch](https://pagewatch.dev/)** â€” PageWatch is a tool to find problem pages on your website.  It provides insights into spelling errors, layout issues, slow pages (powered by Lighthouse) and more.  PageWatch is offered via free and paid plans.\n\n* **[Fluxguard](https://fluxguard.com/)** - Fluxguard provides website DOM change monitoring orchestrated with Google Puppeteer, and audited by Lighthouse. Fluxguard is a freemium product, with monthly monitoring of up to 75 pages for free.\n\n* **[Microlink](https://microlink.io)** â€” Microlink is a cloud browser as API. It offers Lighthouse reports on demand, making it easy to build any service on top. Similar functionality is available via the underlying open-source project named browserless.\n\n* **[Wattspeed](https://wattspeed.com/)** â€” Wattspeed is a free tool that generates snapshots - historical captures of your web pages that include Lighthouse scores, a list of technologies, W3C HTML validator results, DOM size, mixed content info, and more.\n\n## Plugins\n\n* **[lighthouse-plugin-field-performance](https://github.com/treosh/lighthouse-plugin-field-performance)** - a plugin that adds real-user performance metrics for the URL using the data from [Chrome UX Report](https://developers.google.com/web/tools/chrome-user-experience-report/).\n\n* **[lighthouse-plugin-publisher-ads](https://github.com/googleads/publisher-ads-lighthouse-plugin)** - a tool to improve ad speed and overall quality through a series of automated audits. At the moment, this is primarily targeted at sites using Google Ad Manager. This tool will aid in resolving discovered problems, providing a tool to be used to evaluate effectiveness of iterative changes while suggesting actionable feedback.\n\n* **[lighthouse-plugin-crux](https://github.com/dvelasquez/lighthouse-plugin-crux)** - a plugin that quickly gathers real-user-metrics data from the [Chrome UX Report API](https://developers.google.com/web/tools/chrome-user-experience-report/api/reference).\n\n## Related projects\n\nOther awesome open source projects that use Lighthouse.\n\n* **[auto-lighthouse](https://github.com/TGiles/auto-lighthouse)** - a CLI for crawling a domain and generating mobile and desktop reports for each page.\n* **[Exthouse](https://github.com/treosh/exthouse)** - Analyze the impact of a browser extension on web performance.\n* **[Gimbal](https://labs.moduscreate.com/gimbal-web-performance-audit-budgeting)** - An [open source (MIT licensed)](https://github.com/ModusCreateOrg/gimbal) tool used to measure, analyze, and budget aspects of a web application. Gimbal also integrates reports with GitHub pull requests.\n* **[Gradle Lighthouse Plugin](https://github.com/Cognifide/gradle-lighthouse-plugin)** - An open source Gradle plugin that runs Lighthouse tests on multiple URLs and asserts category score thresholds (useful in continuous integration).\n* **[lighthouse-badges](https://github.com/emazzotta/lighthouse-badges)** - Generate gh-badges (shields.io) based on Lighthouse performance.\n* **[lighthouse-batch](https://github.com/mikestead/lighthouse-batch)** - Run Lighthouse over a number of sites and generate a summary of their metrics/scores.\n* **[lighthouse-batch-parallel](https://github.com/Carr1005/lighthouse-batch-parallel)** - Run multiple Lighthouse runs in parallel to accelerate the data collecting process, get the result stream (csv, json, js object) in your own process (warning: performance results may be volatile).\n* **[lighthouse-check-action](https://github.com/foo-software/lighthouse-check-action)** - A GitHub Action to run Lighthouse in a workflow, featuring Slack notifications and report upload to S3.\n* **[lighthouse-check-orb](https://circleci.com/orbs/registry/orb/foo-software/lighthouse-check)** - A CircleCI Orb to run Lighthouse in a workflow, featuring Slack notifications and report upload to S3.\n* **[andreasonny83/lighthouse-ci](https://github.com/andreasonny83/lighthouse-ci)** - Run Lighthouse and assert scores satisfy your custom thresholds.\n* **[GoogleChrome/lighthouse-ci](https://github.com/GoogleChrome/lighthouse-ci)** - (**official**) Automate running Lighthouse for every commit, viewing the changes, and preventing regressions.\n* **[lighthouse-ci-action](https://github.com/treosh/lighthouse-ci-action)** - A GitHub Action that makes it easy to run Lighthouse in CI and keep your pages small using performance budgets.\n* **[lighthouse-gh-reporter](https://github.com/carlesnunez/lighthouse-gh-reporter)** - Run Lighthouse in CI and report back in a comment on your pull requests\n* **[lighthouse-jest-example](https://github.com/justinribeiro/lighthouse-jest-example)** - Gather performance metrics via Lighthouse and assert results with Jest; uses Puppeteer to start Chrome with network emulation settings defined by WebPageTest.\n* **[lighthouse-lambda](https://github.com/Otterseer/lighthouse-lambda)** - Run Lighthouse on AWS Lambda with prebuilt stable desktop Headless Chrome.\n* **[lighthouse-matchers](https://github.com/ackama/lighthouse-matchers)** - Provides RSpec matchers for executing and evaluating Google Chrome Lighthouse audit scores.\n* **[lighthouse-mocha-example](https://github.com/rishichawda/lighthouse-mocha-example)** - Run Lighthouse performance tests with Mocha and chrome-launcher.\n* **[lighthouse-monitor](https://github.com/verivox/lighthouse-monitor)** - Run Lighthouse against all your URLs. Send metrics to any backend you want, save all reports with automatic data retention, and compare any two results in a web UI.\n* **[lighthouse-persist](https://github.com/foo-software/lighthouse-persist)** - Run Lighthouse and upload HTML reports to an AWS S3 bucket.\n* **[lighthouse-viewer](https://github.com/dvelasquez/lighthouse-viewer/tree/main/packages/lighthouse-viewer)** - Render the Lighthouse JSON into a report, using the Lighthouse Report Renderer repackaged as UMD and ESM. Also available with React, Svelte and Vue wrappers.\n* **[lighthouse4u](https://github.com/godaddy/lighthouse4u)** - LH4U provides Google Lighthouse as a service, surfaced by both a friendly UI+API, and backed by Elastic Search for easy querying and visualization.\n* **[react-lighthouse-viewer](https://www.npmjs.com/package/react-lighthouse-viewer)** - Render a Lighthouse JSON report in a React Component.\n* **[site-audit-seo](https://github.com/viasite/site-audit-seo)** - CLI tool for SEO site audit, crawl site, lighthouse each page. Output to console and tables in csv, xlsx, json, web or Google Drive.\n* **[webpack-lighthouse-plugin](https://github.com/addyosmani/webpack-lighthouse-plugin)** - Run Lighthouse from a Webpack build.\n* **[cypress-audit](https://github.com/mfrachet/cypress-audit)** - Run Lighthouse and Pa11y audits directly in your E2E test suites.\n* **[laravel-lighthouse](https://github.com/adityadees/laravel-lighthouse)** - Google Lighthouse wrapper for laravel framework to run Google Lighthouse CLI with custom option and can automatically save result in your server directory.\n* **[Neodymium](https://github.com/Xceptance/neodymium/wiki/Accessibility)** - The Neodymium test automation framework integrates Lighthouse for accessibility and Web Vitals verification, allowing programmatic validation and assertion of all audit values.\n\n## FAQ\n\n### How does Lighthouse work?\n\nSee [Lighthouse Architecture](./docs/architecture.md).\n\n### Why is the performance score so low? It looks fine to me.\n\nLighthouse reports the performance metrics as they would be experienced by a typical mobile user on a 4G connection and a mid-tier ~$200 phone. Even if it loads quickly on your device and network, users in other environments will experience the site very differently.\n\nRead more in our [guide to throttling](./docs/throttling.md).\n\n### Why does the performance score change so much?\n\nLighthouse performance scores will change due to inherent variability in web and network technologies, even if there hasn't been a code change. Test in consistent environments, run Lighthouse multiple times, and beware of variability before drawing conclusions about a performance-impacting change.\n\nRead more in our [guide to reducing variability](./docs/variability.md).\n\n### Can I configure the lighthouse run?\n\nYes! Details in [Lighthouse configuration](./docs/configuration.md).\n\n### How does Lighthouse use network throttling, and how can I make it better?\n\nGood question. Network and CPU throttling are applied by default in a Lighthouse run. The network\nattempts to emulate slow 4G connectivity and the CPU is slowed down 4x from your machine's default speed. If you\nprefer to run Lighthouse without throttling, you'll have to use the CLI and disable it with the\n`--throttling.*` flags mentioned above.\n\nRead more in our [guide to network throttling](./docs/throttling.md).\n\n### Are results sent to a remote server?\n\nNope. Lighthouse runs locally, auditing a page using a local version of the Chrome browser installed on the\nmachine. Report results are never processed or beaconed to a remote server.\n\n### How do I get localized Lighthouse results via the CLI?\n\nStarting in Lighthouse 8.0, Lighthouse relies entirely on native `Intl` support and no longer uses an `Intl` polyfill. If you're using Node 14 or later, there should be no issue because Node is now [built with `full-icu` by default](https://nodejs.medium.com/node-js-12-to-lts-and-node-js-13-is-here-e28d6a4a2bd#9514).\n\nHowever, if you're using a `small-icu` Node build, you may see Lighthouse log messages about your locale not being available. To remedy this, you can manually install ICU data by using the [`full-icu`](https://www.npmjs.com/package/full-icu) module and the [`--icu-data-dir` node flag](https://nodejs.org/api/intl.html#intl_providing_icu_data_at_runtime) at launch.\n\n### How do I author custom audits to extend Lighthouse?\n\n> **Tip**: see [Lighthouse Architecture](./docs/architecture.md) for more information\non terminology and architecture.\n\nLighthouse can be extended to run custom audits and gatherers that you author.\nThis is great if you're already tracking performance metrics in your site and\nwant to surface those metrics within a Lighthouse report.\n\nIf you're interested in running your own custom audits, check out our\n[Custom Audit Example](./docs/recipes/custom-audit) over in recipes.\n\n### How do I contribute?\n\nWe'd love help writing audits, fixing bugs, and making the tool more useful!\nSee [Contributing](./CONTRIBUTING.md) to get started.\n\n---\n<p align=\"center\">\n  <img src=\"./assets/lighthouse-logo_512px.png\" alt=\"Lighthouse logo\" height=\"150\">\n  <br>\n  <b>Lighthouse</b>, ËˆlÄ«tËŒhous (n): a <s>tower or other structure</s> tool containing a beacon light\n  to warn or guide <s>ships at sea</s> developers.\n</p>\n",
      "stars_today": 10
    },
    {
      "id": 65214191,
      "name": "envoy",
      "full_name": "envoyproxy/envoy",
      "description": "Cloud-native high-performance edge/middle/service proxy",
      "html_url": "https://github.com/envoyproxy/envoy",
      "stars": 27335,
      "forks": 5216,
      "language": "C++",
      "topics": [
        "cars",
        "cats",
        "cats-over-dogs",
        "cncf",
        "corgis",
        "more-cats",
        "nanoservices",
        "rocket-ships"
      ],
      "created_at": "2016-08-08T15:07:24Z",
      "updated_at": "2026-01-16T00:27:06Z",
      "pushed_at": "2026-01-16T00:27:01Z",
      "open_issues": 1682,
      "owner": {
        "login": "envoyproxy",
        "avatar_url": "https://avatars.githubusercontent.com/u/30125649?v=4"
      },
      "readme": "![Envoy Logo](https://github.com/envoyproxy/artwork/blob/main/PNG/Envoy_Logo_Final_PANTONE.png)\n\n[Cloud-native high-performance edge/middle/service proxy](https://www.envoyproxy.io/)\n\nEnvoy is hosted by the [Cloud Native Computing Foundation](https://cncf.io) (CNCF). If you are a\ncompany that wants to help shape the evolution of technologies that are container-packaged,\ndynamically-scheduled and microservices-oriented, consider joining the CNCF. For details about who's\ninvolved and how Envoy plays a role, read the CNCF\n[announcement](https://www.cncf.io/blog/2017/09/13/cncf-hosts-envoy/).\n\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1266/badge)](https://bestpractices.coreinfrastructure.org/projects/1266)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/envoyproxy/envoy/badge)](https://securityscorecards.dev/viewer/?uri=github.com/envoyproxy/envoy)\n[![CLOMonitor](https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/envoy/badge)](https://clomonitor.io/projects/cncf/envoy)\n[![Azure Pipelines](https://dev.azure.com/cncf/envoy/_apis/build/status/11?branchName=main)](https://dev.azure.com/cncf/envoy/_build/latest?definitionId=11&branchName=main)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/envoy.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:envoy)\n[![Jenkins](https://powerci.osuosl.org/buildStatus/icon?job=build-envoy-static-master&subject=ppc64le%20build)](https://powerci.osuosl.org/job/build-envoy-static-master/)\n[![Jenkins](https://ibmz-ci.osuosl.org/buildStatus/icon?job=Envoy_IBMZ_CI&subject=s390x%20build)](https://ibmz-ci.osuosl.org/job/Envoy_IBMZ_CI/)\n\n## Documentation\n\n* [Official documentation](https://www.envoyproxy.io/)\n* [FAQ](https://www.envoyproxy.io/docs/envoy/latest/faq/overview)\n* [Example documentation](https://github.com/envoyproxy/examples/)\n* [Blog](https://medium.com/@mattklein123/envoy-threading-model-a8d44b922310) about the threading model\n* [Blog](https://medium.com/@mattklein123/envoy-hot-restart-1d16b14555b5) about hot restart\n* [Blog](https://medium.com/@mattklein123/envoy-stats-b65c7f363342) about stats architecture\n* [Blog](https://medium.com/@mattklein123/the-universal-data-plane-api-d15cec7a) about universal data plane API\n* [Blog](https://medium.com/@mattklein123/lyfts-envoy-dashboards-5c91738816b1) on Lyft's Envoy dashboards\n\n## Related\n\n* [data-plane-api](https://github.com/envoyproxy/data-plane-api): v2 API definitions as a standalone\n  repository. This is a read-only mirror of [api](api/).\n* [envoy-perf](https://github.com/envoyproxy/envoy-perf): Performance testing framework.\n* [envoy-filter-example](https://github.com/envoyproxy/envoy-filter-example): Example of how to add new filters\n  and link to the main repository.\n\n## Contact\n\n* [envoy-announce](https://groups.google.com/forum/#!forum/envoy-announce): Low frequency mailing\n  list where we will email announcements only.\n* [envoy-security-announce](https://groups.google.com/forum/#!forum/envoy-security-announce): Low frequency mailing\n  list where we will email security related announcements only.\n* [envoy-users](https://groups.google.com/forum/#!forum/envoy-users): General user discussion.\n* [envoy-dev](https://groups.google.com/forum/#!forum/envoy-dev): Envoy developer discussion (APIs,\n  feature design, etc.).\n* [envoy-maintainers](https://groups.google.com/forum/#!forum/envoy-maintainers): Use this list\n  to reach all core Envoy maintainers.\n* [Twitter](https://twitter.com/EnvoyProxy/): Follow along on Twitter!\n* [Slack](https://envoyproxy.slack.com/): Slack, to get invited go [here](https://communityinviter.com/apps/envoyproxy/envoy).\n  * NOTE: Response to user questions is best effort on Slack. For a \"guaranteed\" response please email\n    envoy-users@ per the guidance in the following linked thread.\n\nPlease see [this](https://groups.google.com/forum/#!topic/envoy-announce/l9zjYsnS3TY) email thread\nfor information on email list usage.\n\n## Contributing\n\nContributing to Envoy is fun and modern C++ is a lot less scary than you might think if you don't\nhave prior experience. To get started:\n\n* [Contributing guide](CONTRIBUTING.md)\n* [Beginner issues](https://github.com/envoyproxy/envoy/issues?q=is%3Aopen+is%3Aissue+label%3Abeginner)\n* [Build/test quick start using docker](ci#building-and-running-tests-as-a-developer)\n* [Developer guide](DEVELOPER.md)\n* Consider installing the Envoy [development support toolchain](https://github.com/envoyproxy/envoy/blob/main/support/README.md), which helps automate parts of the development process, particularly those involving code review.\n* Please make sure that you let us know if you are working on an issue so we don't duplicate work!\n\n## Community Meeting\n\nThe Envoy team has a scheduled meeting time twice per month on Tuesday at 9am PT. The public\nGoogle calendar is [here](https://goo.gl/PkDijT).  The meeting will only be held\nif there are agenda items listed in the [meeting\nminutes](https://goo.gl/5Cergb).  Any member of the community should be able to\npropose agenda items by adding to the minutes.  The maintainers will either confirm\nthe additions to the agenda, or will cancel the meeting within 24 hours of the scheduled\ndate if there is no confirmed agenda.\n\n## Security\n\n### Security Audit\n\nThere has been several third party engagements focused on Envoy security:\n* In 2018 Cure53 performed a security audit, [full report](docs/security/audit_cure53_2018.pdf).\n* In 2021 Ada Logics performed an audit on our fuzzing infrastructure with recommendations for improvements, [full report](docs/security/audit_fuzzer_adalogics_2021.pdf).\n\n### Reporting security vulnerabilities\n\nIf you've found a vulnerability or a potential vulnerability in Envoy please let us know at\n[envoy-security](mailto:envoy-security@googlegroups.com). We'll send a confirmation\nemail to acknowledge your report, and we'll send an additional email when we've identified the issue\npositively or negatively.\n\nFor further details please see our complete [security release process](SECURITY.md).\n\n### ppc64le builds\n\nBuilds for the ppc64le architecture or using aws-lc are not covered by the envoy security policy. The ppc64le architecture is currently best-effort and not maintained by the Envoy maintainers.\n\n## Releases\n\nFor further details please see our [release process](https://github.com/envoyproxy/envoy/blob/main/RELEASES.md).\n",
      "stars_today": 10
    },
    {
      "id": 335164964,
      "name": "dataease",
      "full_name": "dataease/dataease",
      "description": "ğŸ”¥ äººäººå¯ç”¨çš„å¼€æº BI å·¥å…·ï¼Œæ•°æ®å¯è§†åŒ–ç¥å™¨ã€‚An open-source BI tool alternative to Tableau.",
      "html_url": "https://github.com/dataease/dataease",
      "stars": 23154,
      "forks": 3977,
      "language": "Java",
      "topics": [
        "apache-doris",
        "business-intelligence",
        "data-analysis",
        "data-visualization",
        "echarts",
        "kettle",
        "superset",
        "tableau"
      ],
      "created_at": "2021-02-02T04:10:21Z",
      "updated_at": "2026-01-15T14:58:24Z",
      "pushed_at": "2026-01-15T14:17:04Z",
      "open_issues": 96,
      "owner": {
        "login": "dataease",
        "avatar_url": "https://avatars.githubusercontent.com/u/75054108?v=4"
      },
      "readme": "<p align=\"center\"><a href=\"https://dataease.cn\"><img src=\"https://dataease.oss-cn-hangzhou.aliyuncs.com/img/dataease-logo.png\" alt=\"DataEase\" width=\"300\" /></a></p>\n<h3 align=\"center\">äººäººå¯ç”¨çš„å¼€æº BI å·¥å…·</h3>\n<p align=\"center\">\n  <a href=\"https://www.gnu.org/licenses/gpl-3.0.html\"><img src=\"https://img.shields.io/github/license/dataease/dataease?color=%231890FF\" alt=\"License: GPL v3\"></a>\n  <a href=\"https://app.codacy.com/gh/dataease/dataease?utm_source=github.com&utm_medium=referral&utm_content=dataease/dataease&utm_campaign=Badge_Grade_Dashboard\"><img src=\"https://app.codacy.com/project/badge/Grade/da67574fd82b473992781d1386b937ef\" alt=\"Codacy\"></a>\n  <a href=\"https://github.com/dataease/dataease\"><img src=\"https://img.shields.io/github/stars/dataease/dataease?color=%231890FF&style=flat-square\" alt=\"GitHub Stars\"></a>\n  <a href=\"https://github.com/dataease/dataease/releases\"><img src=\"https://img.shields.io/github/v/release/dataease/dataease\" alt=\"GitHub release\"></a>\n  <a href=\"https://gitee.com/fit2cloud-feizhiyun/DataEase\"><img src=\"https://gitee.com/fit2cloud-feizhiyun/DataEase/badge/star.svg?theme=gvp\" alt=\"Gitee Stars\"></a>\n  <a href=\"https://gitcode.com/feizhiyun/DataEase\"><img src=\"https://gitcode.com/feizhiyun/DataEase/star/badge.svg\" alt=\"GitCode Stars\"></a>\n</p>\n<p align=\"center\">\n  <a href=\"/README.md\"><img alt=\"ä¸­æ–‡(ç®€ä½“)\" src=\"https://img.shields.io/badge/ä¸­æ–‡(ç®€ä½“)-d9d9d9\"></a>\n  <a href=\"/docs/README.en.md\"><img alt=\"English\" src=\"https://img.shields.io/badge/English-d9d9d9\"></a>\n  <a href=\"/docs/README.zh-Hant.md\"><img alt=\"ä¸­æ–‡(ç¹é«”)\" src=\"https://img.shields.io/badge/ä¸­æ–‡(ç¹é«”)-d9d9d9\"></a>\n  <a href=\"/docs/README.ja.md\"><img alt=\"æ—¥æœ¬èª\" src=\"https://img.shields.io/badge/æ—¥æœ¬èª-d9d9d9\"></a>\n  <a href=\"/docs/README.pt-br.md\"><img alt=\"PortuguÃªs (Brasil)\" src=\"https://img.shields.io/badge/PortuguÃªs (Brasil)-d9d9d9\"></a>\n  <a href=\"/docs/README.ar.md\"><img alt=\"Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\" src=\"https://img.shields.io/badge/Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©-d9d9d9\"></a>\n  <a href=\"/docs/README.de.md\"><img alt=\"Deutsch\" src=\"https://img.shields.io/badge/Deutsch-d9d9d9\"></a>\n  <a href=\"/docs/README.es.md\"><img alt=\"EspaÃ±ol\" src=\"https://img.shields.io/badge/EspaÃ±ol-d9d9d9\"></a>\n  <a href=\"/docs/README.fr.md\"><img alt=\"franÃ§ais\" src=\"https://img.shields.io/badge/franÃ§ais-d9d9d9\"></a>\n  <a href=\"/docs/README.ko.md\"><img alt=\"í•œêµ­ì–´\" src=\"https://img.shields.io/badge/í•œêµ­ì–´-d9d9d9\"></a>\n  <a href=\"/docs/README.id.md\"><img alt=\"Bahasa Indonesia\" src=\"https://img.shields.io/badge/Bahasa Indonesia-d9d9d9\"></a>\n  <a href=\"/docs/README.tr.md\"><img alt=\"TÃ¼rkÃ§e\" src=\"https://img.shields.io/badge/TÃ¼rkÃ§e-d9d9d9\"></a>\n</p>\n<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/1563\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/1563\" alt=\"dataease%2Fdataease | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n------------------------------\n\n## ä»€ä¹ˆæ˜¯ DataEaseï¼Ÿ\n\nDataEase æ˜¯å¼€æºçš„ BI å·¥å…·ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿåˆ†ææ•°æ®å¹¶æ´å¯Ÿä¸šåŠ¡è¶‹åŠ¿ï¼Œä»è€Œå®ç°ä¸šåŠ¡çš„æ”¹è¿›ä¸ä¼˜åŒ–ã€‚DataEase æ”¯æŒä¸°å¯Œçš„æ•°æ®æºè¿æ¥ï¼Œèƒ½å¤Ÿé€šè¿‡æ‹–æ‹‰æ‹½æ–¹å¼å¿«é€Ÿåˆ¶ä½œå›¾è¡¨ï¼Œå¹¶å¯ä»¥æ–¹ä¾¿çš„ä¸ä»–äººåˆ†äº«ã€‚\n\n**DataEase çš„ä¼˜åŠ¿ï¼š**\n\n-   å¼€æºå¼€æ”¾ï¼šé›¶é—¨æ§›ï¼Œçº¿ä¸Šå¿«é€Ÿè·å–å’Œå®‰è£…ï¼ŒæŒ‰æœˆè¿­ä»£ï¼›\n-   ç®€å•æ˜“ç”¨ï¼šææ˜“ä¸Šæ‰‹ï¼Œé€šè¿‡é¼ æ ‡ç‚¹å‡»å’Œæ‹–æ‹½å³å¯å®Œæˆåˆ†æï¼›\n-   å…¨åœºæ™¯æ”¯æŒï¼šå¤šå¹³å°å®‰è£…å’Œå¤šæ ·åŒ–åµŒå…¥æ”¯æŒï¼›\n-   å®‰å…¨åˆ†äº«ï¼šæ”¯æŒå¤šç§æ•°æ®åˆ†äº«æ–¹å¼ï¼Œç¡®ä¿æ•°æ®å®‰å…¨ï¼›\n-   AI åŠ æŒï¼šæ— ç¼é›†æˆ [SQLBot](https://github.com/dataease/SQLBot) å®ç°æ™ºèƒ½é—®æ•°ã€‚\n\n**DataEase æ”¯æŒçš„æ•°æ®æºï¼š**\n\n-   OLTP æ•°æ®åº“ï¼š MySQLã€Oracleã€SQL Serverã€PostgreSQLã€MariaDBã€Db2ã€TiDBã€MongoDB-BI ç­‰ï¼›\n-   OLAP æ•°æ®åº“ï¼š ClickHouseã€Apache Dorisã€Apache Impalaã€StarRocks ç­‰ï¼›\n-   æ•°æ®ä»“åº“/æ•°æ®æ¹–ï¼š Amazon RedShift ç­‰ï¼›\n-   æ•°æ®æ–‡ä»¶ï¼š Excelã€CSV ç­‰ï¼›\n-   API æ•°æ®æºã€‚\n\nå¦‚æœæ‚¨éœ€è¦å‘å›¢é˜Ÿä»‹ç» DataEaseï¼Œå¯ä»¥ä½¿ç”¨è¿™ä¸ª [å®˜æ–¹ PPT ææ–™](https://fit2cloud.com/dataease/download/introduce-dataease_202511.pdf)ï¼Œæˆ–è€…è´­ä¹°ç”±åä¸œå¸ˆå¤§å’Œ DataEase è”åˆå‡ºå“çš„å›¾ä¹¦ï¼š [ã€Šæ•°æ®å¯è§†åŒ–åˆ†æä¸å®è·µã€‹](https://item.jd.com/10207058297099.html)ã€‚\n\n\n\n## å¿«é€Ÿå¼€å§‹\n\n**æ¡Œé¢ç‰ˆï¼š**\n\nä½ å¯ä»¥åœ¨ PC ä¸Šå®‰è£… DataEasae æ¡Œé¢ç‰ˆï¼Œä¸‹è½½åœ°å€ä¸ºï¼šhttps://dataease.cn/desktop/index.html\n\n**æœåŠ¡å™¨ç‰ˆï¼š**\n\n```\n# å‡†å¤‡ä¸€å° 2 æ ¸ 4G ä»¥ä¸Šçš„ Linux æœåŠ¡å™¨ï¼Œå¹¶ä»¥ root ç”¨æˆ·è¿è¡Œä»¥ä¸‹ä¸€é”®å®‰è£…è„šæœ¬ï¼š\n\ncurl -sSL https://dataease.oss-cn-hangzhou.aliyuncs.com/quick_start_v2.sh | bash\n\n# ç”¨æˆ·å: admin\n# å¯†ç : DataEase@123456\n```\n\nä½ ä¹Ÿå¯ä»¥é€šè¿‡ [1Panel åº”ç”¨å•†åº—](https://dataease.io/docs/v2/installation/1panel_installation/) å¿«é€Ÿéƒ¨ç½² DataEaseã€‚å¦‚æœæ˜¯ç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œæ¨èä½¿ç”¨ [ç¦»çº¿å®‰è£…åŒ…æ–¹å¼](https://dataease.io/docs/v2/installation/offline_INSTL_and_UPG/) è¿›è¡Œå®‰è£…éƒ¨ç½²ã€‚\n\nå¦‚ä½ æœ‰æ›´å¤šé—®é¢˜ï¼Œå¯ä»¥æŸ¥çœ‹åœ¨çº¿æ–‡æ¡£ï¼Œæˆ–è€…é€šè¿‡è®ºå›å’Œäº¤æµç¾¤ä¸æˆ‘ä»¬äº¤æµã€‚\n\n-   [è§†é¢‘ä»‹ç»](https://www.bilibili.com/video/BV1Y8dAYLErb/)\n-   [åœ¨çº¿æ–‡æ¡£](https://dataease.io/docs/)\n-   [ç¤¾åŒºè®ºå›](https://bbs.fit2cloud.com/c/de/6)\n-   å¾®ä¿¡äº¤æµç¾¤\n\n  <img width=\"150\" height=\"150\" alt=\"image\" src=\"https://github.com/user-attachments/assets/a8e4cd48-ed0f-4754-ba34-d047063b1633\" />\n\n\n## UI å±•ç¤º\n\n<table style=\"border-collapse: collapse; border: 1px solid black;\">\n  <tr>\n    <td style=\"padding: 5px;background-color:#fff;\"><img src= \"https://github.com/dataease/dataease/assets/41712985/8dbed4e1-39f0-4392-aa8c-d1fd83ba42eb\" alt=\"DataEase å·¥ä½œå°\"   /></td>\n    <td style=\"padding: 5px;background-color:#fff;\"><img src= \"https://github.com/dataease/dataease/assets/41712985/7c54cb07-51ef-4bb6-a931-8a95c64c7e11\" alt=\"DataEase ä»ªè¡¨æ¿\"   /></td>\n  </tr>\n\n  <tr>\n    <td style=\"padding: 5px;background-color:#fff;\"><img src= \"https://github.com/dataease/dataease/assets/41712985/ffa79361-a7b3-4486-b14a-f3fd3a28f01a\" alt=\"DataEase æ•°æ®æº\"   /></td>\n    <td style=\"padding: 5px;background-color:#fff;\"><img src= \"https://github.com/dataease/dataease/assets/41712985/bb28f4e4-636e-4ab0-85c5-1dfbd7a5397e\" alt=\"DataEase æ¨¡æ¿ä¸­å¿ƒ\"   /></td>\n  </tr>\n</table>\n\n## æŠ€æœ¯æ ˆ\n\n-   å‰ç«¯ï¼š[Vue.js](https://vuejs.org/)ã€[Element](https://element.eleme.cn/)\n-   å›¾åº“ï¼š[AntV](https://antv.vision/zh)\n-   åç«¯ï¼š[Spring Boot](https://spring.io/projects/spring-boot)\n-   æ•°æ®åº“ï¼š[MySQL](https://www.mysql.com/)\n-   æ•°æ®å¤„ç†ï¼š[Apache Calcite](https://github.com/apache/calcite/)ã€[Apache SeaTunnel](https://github.com/apache/seatunnel)\n-   åŸºç¡€è®¾æ–½ï¼š[Docker](https://www.docker.com/)\n\n## é£è‡´äº‘çš„å…¶ä»–æ˜æ˜Ÿé¡¹ç›®\n\n- [1Panel](https://github.com/1panel-dev/1panel/) - ç°ä»£åŒ–ã€å¼€æºçš„ Linux æœåŠ¡å™¨è¿ç»´ç®¡ç†é¢æ¿\n- [MaxKB](https://github.com/1panel-dev/MaxKB/) - åŸºäº LLM å¤§è¯­è¨€æ¨¡å‹çš„å¼€æºçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ\n- [JumpServer](https://github.com/jumpserver/jumpserver/) - å¹¿å—æ¬¢è¿çš„å¼€æºå ¡å’æœº\n- [Cordys CRM](https://github.com/1Panel-dev/CordysCRM) - æ–°ä¸€ä»£çš„å¼€æº AI CRM ç³»ç»Ÿ\n- [Halo](https://github.com/halo-dev/halo/) - å¼ºå¤§æ˜“ç”¨çš„å¼€æºå»ºç«™å·¥å…·\n- [MeterSphere](https://github.com/metersphere/metersphere/) - æ–°ä¸€ä»£çš„å¼€æºæŒç»­æµ‹è¯•å·¥å…·\n\n## License\n\nCopyright (c) 2014-2026 [FIT2CLOUD é£è‡´äº‘](https://fit2cloud.com/), All rights reserved.\n\nLicensed under The GNU General Public License version 3 (GPLv3)  (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n\n<https://www.gnu.org/licenses/gpl-3.0.html>\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
      "stars_today": 10
    },
    {
      "id": 55626935,
      "name": "WSL",
      "full_name": "microsoft/WSL",
      "description": "Windows Subsystem for Linux",
      "html_url": "https://github.com/microsoft/WSL",
      "stars": 30881,
      "forks": 1582,
      "language": "C++",
      "topics": [],
      "created_at": "2016-04-06T17:32:56Z",
      "updated_at": "2026-01-16T00:59:44Z",
      "pushed_at": "2026-01-15T23:07:24Z",
      "open_issues": 947,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# Welcome to the Windows Subsystem for Linux (WSL) repository\n\n<p align=\"center\">\n  <img src=\"./Images/Square44x44Logo.targetsize-256.png\" alt=\"WSL logo\"/>\n</p>\n\n[Learn more about WSL](https://aka.ms/wsldocs) | [Downloads & Release notes](https://github.com/microsoft/WSL/releases) | [Contributing to WSL](./CONTRIBUTING.md)\n\n## About\n\nWindows Subsystem for Linux (WSL) is a powerful way for you to run your Linux command-line tools, utilities and applications, all unmodified and directly on Windows without the overhead of a traditional virtual machine or dual boot setup.\n\nYou can install WSL right away by running this command inside of your Windows command line:\n\n```powershell\nwsl --install\n```\n\nYou can learn more about [best practices for setup](https://learn.microsoft.com/windows/wsl/setup/environment), [overviews of WSL](https://learn.microsoft.com/windows/wsl/about) and more at our [WSL documentation page](https://learn.microsoft.com/windows/wsl/).\n\n## Related repositories\n\nWSL also has related open source repositories:\n\n- [microsoft/WSL2-Linux-Kernel](https://github.com/microsoft/WSL2-Linux-Kernel) - The Linux kernel shipped with WSL\n- [microsoft/WSLg](https://github.com/microsoft/wslg) - Support for Linux GUI apps in WSL\n- [microsoftdocs/wsl](https://github.com/microsoftdocs/wsl) - WSL documentation at aka.ms/wsldocs\n\n## Contributing\n\nThis project welcomes contributions of all types, including coding features / bug fixes, documentation fixes, design proposals and more. \n\nWe ask that before you start working on a contribution, please read our [Contributor's Guide](./CONTRIBUTING.md).\n\nFor guidance on developing for WSL, please read the [developer docs](./doc/docs/dev-loop.md) for instructions on how to build WSL from source and details on its architecture.\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](./CODE_OF_CONDUCT.md)\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoftâ€™s Trademark & Brand Guidelines](https://www.microsoft.com/legal/intellectualproperty/trademarks). Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-partyâ€™s policies.\n\n## Privacy and telemetry\n\nThe application logs basic diagnostic data (telemetry). For more information on privacy and what we collect, see our [data and privacy documentation](DATA_AND_PRIVACY.md).\n\nThe software may collect information about you and your use of the software and send it to Microsoft. Microsoft may use this information to provide services and improve our products and services. You may turn off the telemetry as described in the repository. There are also some features in the software that may enable you and Microsoft to collect data from users of your applications. If you use these features, you must comply with applicable law, including providing appropriate notices to users of your applications together with a copy of Microsoftâ€™s privacy statement. Our privacy statement is located at https://go.microsoft.com/fwlink/?LinkID=824704. You can learn more about data collection and use in the help documentation and our privacy statement. Your use of the software operates as your consent to these practices.",
      "stars_today": 10
    },
    {
      "id": 19330466,
      "name": "xxHash",
      "full_name": "Cyan4973/xxHash",
      "description": "Extremely fast non-cryptographic hash algorithm",
      "html_url": "https://github.com/Cyan4973/xxHash",
      "stars": 10740,
      "forks": 878,
      "language": "C",
      "topics": [
        "c",
        "dispersion",
        "hash",
        "hash-checksum",
        "hash-functions",
        "smhasher",
        "xxhash"
      ],
      "created_at": "2014-04-30T23:32:49Z",
      "updated_at": "2026-01-15T23:12:26Z",
      "pushed_at": "2025-12-17T19:23:32Z",
      "open_issues": 25,
      "owner": {
        "login": "Cyan4973",
        "avatar_url": "https://avatars.githubusercontent.com/u/750081?v=4"
      },
      "readme": "\nxxHash - Extremely fast hash algorithm\n======================================\n\nxxHash is an Extremely fast Hash algorithm, processing at RAM speed limits.\nCode is highly portable, and produces hashes identical across all platforms (little / big endian).\nThe library includes the following algorithms :\n- XXH32 : generates 32-bit hashes, using 32-bit arithmetic\n- XXH64 : generates 64-bit hashes, using 64-bit arithmetic\n- XXH3 (since `v0.8.0`): generates 64 or 128-bit hashes, using vectorized arithmetic.\n  The 128-bit variant is called XXH128.\n\nAll variants successfully complete the [SMHasher](https://code.google.com/p/smhasher/wiki/SMHasher) test suite\nwhich evaluates the quality of hash functions (collision, dispersion and randomness).\nAdditional tests, which evaluate more thoroughly speed and collision properties of 64-bit hashes, [are also provided](https://github.com/Cyan4973/xxHash/tree/dev/tests).\n\n|Branch      |Status   |\n|------------|---------|\n|release     | [![Build Status](https://github.com/Cyan4973/xxHash/actions/workflows/ci.yml/badge.svg?branch=release)](https://github.com/Cyan4973/xxHash/actions?query=branch%3Arelease+) |\n|dev         | [![Build Status](https://github.com/Cyan4973/xxHash/actions/workflows/ci.yml/badge.svg?branch=dev)](https://github.com/Cyan4973/xxHash/actions?query=branch%3Adev+) |\n\n\nBenchmarks\n-------------------------\n\nThe benchmarked reference system uses an Intel i7-9700K cpu, and runs Ubuntu x64 20.04.\nThe [open source benchmark program] is compiled with `clang` v10.0 using `-O3` flag.\n\n| Hash Name     | Width | Bandwidth (GB/s) | Small Data Velocity | Quality | Comment |\n| ---------     | ----- | ---------------- | ----- | --- | --- |\n| __XXH3__ (SSE2) |  64 | 31.5 GB/s        | 133.1 | 10\n| __XXH128__ (SSE2) | 128 | 29.6 GB/s      | 118.1 | 10\n| _RAM sequential read_ | N/A | 28.0 GB/s  |   N/A | N/A | _for reference_\n| City64        |    64 | 22.0 GB/s        |  76.6 | 10\n| T1ha2         |    64 | 22.0 GB/s        |  99.0 |  9 | Slightly worse [collisions]\n| City128       |   128 | 21.7 GB/s        |  57.7 | 10\n| __XXH64__     |    64 | 19.4 GB/s        |  71.0 | 10\n| SpookyHash    |    64 | 19.3 GB/s        |  53.2 | 10\n| Mum           |    64 | 18.0 GB/s        |  67.0 |  9 | Slightly worse [collisions]\n| __XXH32__     |    32 |  9.7 GB/s        |  71.9 | 10\n| City32        |    32 |  9.1 GB/s        |  66.0 | 10\n| Murmur3       |    32 |  3.9 GB/s        |  56.1 | 10\n| SipHash       |    64 |  3.0 GB/s        |  43.2 | 10\n| FNV64         |    64 |  1.2 GB/s        |  62.7 |  5 | Poor avalanche properties\n| Blake2        |   256 |  1.1 GB/s        |   5.1 | 10 | Cryptographic\n| SHA1          |   160 |  0.8 GB/s        |   5.6 | 10 | Cryptographic but broken\n| MD5           |   128 |  0.6 GB/s        |   7.8 | 10 | Cryptographic but broken\n\n[open source benchmark program]: https://github.com/Cyan4973/xxHash/tree/release/tests/bench\n[collisions]: https://github.com/Cyan4973/xxHash/wiki/Collision-ratio-comparison#collision-study\n\nnote 1: Small data velocity is a _rough_ evaluation of algorithm's efficiency on small data. For more detailed analysis, please refer to next paragraph.\n\nnote 2: some algorithms feature _faster than RAM_ speed. In which case, they can only reach their full speed potential when input is already in CPU cache (L3 or better). Otherwise, they max out on RAM speed limit.\n\n### Small data\n\nPerformance on large data is only one part of the picture.\nHashing is also very useful in constructions like hash tables and bloom filters.\nIn these use cases, it's frequent to hash a lot of small data (starting at a few bytes).\nAlgorithm's performance can be very different for such scenarios, since parts of the algorithm,\nsuch as initialization or finalization, become fixed cost.\nThe impact of branch mis-prediction also becomes much more present.\n\nXXH3 has been designed for excellent performance on both long and small inputs,\nwhich can be observed in the following graph:\n\n![XXH3, latency, random size](https://user-images.githubusercontent.com/750081/61976089-aedeab00-af9f-11e9-9239-e5375d6c080f.png)\n\nFor a more detailed analysis, please visit the wiki :\nhttps://github.com/Cyan4973/xxHash/wiki/Performance-comparison#benchmarks-concentrating-on-small-data-\n\nQuality\n-------------------------\n\nSpeed is not the only property that matters.\nProduced hash values must respect excellent dispersion and randomness properties,\nso that any sub-section of it can be used to maximally spread out a table or index,\nas well as reduce the amount of collisions to the minimal theoretical level, following the [birthday paradox].\n\n`xxHash` has been tested with Austin Appleby's excellent SMHasher test suite,\nand passes all tests, ensuring reasonable quality levels.\nIt also passes extended tests from [newer forks of SMHasher], featuring additional scenarios and conditions.\n\nFinally, xxHash provides its own [massive collision tester](https://github.com/Cyan4973/xxHash/tree/dev/tests/collisions),\nable to generate and compare billions of hashes to test the limits of 64-bit hash algorithms.\nOn this front too, xxHash features good results, in line with the [birthday paradox].\nA more detailed analysis is documented [in the wiki](https://github.com/Cyan4973/xxHash/wiki/Collision-ratio-comparison).\n\n[birthday paradox]: https://en.wikipedia.org/wiki/Birthday_problem\n[newer forks of SMHasher]: https://github.com/rurban/smhasher\n\n\n### Build modifiers\n\nThe following macros can be set at compilation time to modify `libxxhash`'s behavior. They are generally disabled by default.\n\n- `XXH_INLINE_ALL`: Make all functions `inline`, implementation is directly included within `xxhash.h`.\n                    Inlining functions is beneficial for speed, notably for small keys.\n                    It's _extremely effective_ when key's length is expressed as _a compile time constant_,\n                    with performance improvements observed in the +200% range .\n                    See [this article](https://fastcompression.blogspot.com/2018/03/xxhash-for-small-keys-impressive-power.html) for details.\n- `XXH_PRIVATE_API`: same outcome as `XXH_INLINE_ALL`. Still available for legacy support.\n                     The name underlines that `XXH_*` symbol names will not be exported.\n- `XXH_STATIC_LINKING_ONLY`: gives access to internal state declaration, required for static allocation.\n                             Incompatible with dynamic linking, due to risks of ABI changes.\n- `XXH_NAMESPACE`: Prefixes all symbols with the value of `XXH_NAMESPACE`.\n                   This macro can only use compilable character set.\n                   Useful to evade symbol naming collisions,\n                   in case of multiple inclusions of xxHash's source code.\n                   Client applications still use the regular function names,\n                   as symbols are automatically translated through `xxhash.h`.\n- `XXH_FORCE_ALIGN_CHECK`: Use a faster direct read path when input is aligned.\n                           This option can result in dramatic performance improvement on architectures unable to load memory from unaligned addresses\n                           when input to hash happens to be aligned on 32 or 64-bit boundaries.\n                           It is (slightly) detrimental on platform with good unaligned memory access performance (same instruction for both aligned and unaligned accesses).\n                           This option is automatically disabled on `x86`, `x64` and `aarch64`, and enabled on all other platforms.\n- `XXH_FORCE_MEMORY_ACCESS`: The default method `0` uses a portable `memcpy()` notation.\n                             Method `1` uses a gcc-specific `packed` attribute, which can provide better performance for some targets.\n                             Method `2` forces unaligned reads, which is not standard compliant, but might sometimes be the only way to extract better read performance.\n                             Method `3` uses a byteshift operation, which is best for old compilers which don't inline `memcpy()` or big-endian systems without a byteswap instruction.\n- `XXH_CPU_LITTLE_ENDIAN`: By default, endianness is determined by a runtime test resolved at compile time.\n                           If, for some reason, the compiler cannot simplify the runtime test, it can cost performance.\n                           It's possible to skip auto-detection and simply state that the architecture is little-endian by setting this macro to 1.\n                           Setting it to 0 states big-endian.\n- `XXH_ENABLE_AUTOVECTORIZE`: Auto-vectorization may be triggered for XXH32 and XXH64, depending on cpu vector capabilities and compiler version.\n                              Note: auto-vectorization tends to be triggered more easily with recent versions of `clang`.\n                              For XXH32, SSE4.1 or equivalent (NEON) is enough, while XXH64 requires AVX512.\n                              Unfortunately, auto-vectorization is generally detrimental to XXH performance.\n                              For this reason, the xxhash source code tries to prevent auto-vectorization by default.\n                              That being said, systems evolve, and this conclusion is not forthcoming.\n                              For example, it has been reported that recent Zen4 cpus are more likely to improve performance with vectorization.\n                              Therefore, should you prefer or want to test vectorized code, you can enable this flag:\n                              it will remove the no-vectorization protection code, thus making it more likely for XXH32 and XXH64 to be auto-vectorized.\n- `XXH32_ENDJMP`: Switch multi-branch finalization stage of XXH32 by a single jump.\n                  This is generally undesirable for performance, especially when hashing inputs of random sizes.\n                  But depending on exact architecture and compiler, a jump might provide slightly better performance on small inputs. Disabled by default.\n- `XXH_IMPORT`: MSVC specific: should only be defined for dynamic linking, as it prevents linkage errors.\n- `XXH_NO_STDLIB`: Disable invocation of `<stdlib.h>` functions, notably `malloc()` and `free()`.\n                   `libxxhash`'s `XXH*_createState()` will always fail and return `NULL`.\n                   But one-shot hashing (like `XXH32()`) or streaming using statically allocated states\n                   still work as expected.\n                   This build flag is useful for embedded environments without dynamic allocation.\n- `XXH_memcpy`, `XXH_memset`, `XXH_memcmp` : redirect `memcpy()`, `memset()` and `memcmp()` to some user-selected symbol at compile time.\n                   Redirecting all 3 removes the need to include `<string.h>` standard library.\n- `XXH_NO_EXTERNC_GUARD`: When `xxhash.h` is compiled in C++ mode, removes the `extern \"C\" { .. }` block guard.\n- `XXH_DEBUGLEVEL` : When set to any value >= 1, enables `assert()` statements.\n                     This (slightly) slows down execution, but may help finding bugs during debugging sessions.\n\n#### Binary size control\n- `XXH_NO_XXH3` : removes symbols related to `XXH3` (both 64 & 128 bits) from generated binary.\n                  `XXH3` is by far the largest contributor to `libxxhash` size,\n                  so it's useful to reduce binary size for applications which do not employ `XXH3`.\n- `XXH_NO_LONG_LONG`: removes compilation of algorithms relying on 64-bit `long long` types\n                      which include `XXH3` and `XXH64`.\n                      Only `XXH32` will be compiled.\n                      Useful for targets (architectures and compilers) without 64-bit support.\n- `XXH_NO_STREAM`: Disables the streaming API, limiting the library to single shot variants only.\n- `XXH_NO_INLINE_HINTS`: By default, xxHash uses `__attribute__((always_inline))` and `__forceinline` to improve performance at the cost of code size.\n                         Defining this macro to 1 will mark all internal functions as `static`, allowing the compiler to decide whether to inline a function or not.\n                         This is very useful when optimizing for smallest binary size,\n                         and is automatically defined when compiling with `-O0`, `-Os`, `-Oz`, or `-fno-inline` on GCC and Clang.\n                         It may also be required to successfully compile using `-Og`, depending on compiler version.\n- `XXH_SIZE_OPT`: `0`: default, optimize for speed\n                  `1`: default for `-Os` and `-Oz`: disables some speed hacks for size optimization\n                  `2`: makes code as small as possible, performance may cry\n\n#### Build modifiers specific for XXH3\n- `XXH_VECTOR` : manually select a vector instruction set (default: auto-selected at compilation time). Available instruction sets are `XXH_SCALAR`, `XXH_SSE2`, `XXH_AVX2`, `XXH_AVX512`, `XXH_NEON` and `XXH_VSX`. Compiler may require additional flags to ensure proper support (for example, `gcc` on x86_64 requires `-mavx2` for `AVX2`, or `-mavx512f` for `AVX512`).\n- `XXH_PREFETCH_DIST` : select prefetching distance. For close-to-metal adaptation to specific hardware platforms. XXH3 only.\n- `XXH_NO_PREFETCH` : disable prefetching. Some platforms or situations may perform better without prefetching. XXH3 only.\n\n#### Build modifiers for `xxhsum` CLI\n- `XXH_1ST_SPEED_TARGET` : select an initial speed target, expressed in MB/s, for the first speed test in benchmark mode. Benchmark will adjust the target at subsequent iterations, but the first test is made \"blindly\" by targeting this speed. Currently conservatively set to 10 MB/s, to support very slow (emulated) platforms.\n\n#### Makefile variables\nWhen compiling the Command Line Interface `xxhsum` using `make`, the following environment variables can also be set :\n- `DISPATCH=1` : use `xxh_x86dispatch.c`, select at runtime between `scalar`, `sse2`, `avx2` or `avx512` instruction set. This option is only valid for `x86`/`x64` systems. It is enabled by default when target `x86`/`x64` is detected. It can be forcefully turned off using `DISPATCH=0`.\n- `LIBXXH_DISPATCH=1` : same idea, implemented a runtime vector extension detector, but within `libxxhash`. This parameter is disabled by default. When enabled (only valid for `x86`/`x64` systems), new symbols published in `xxh_x86dispatch.h` become accessible. At the time of this writing, it's required to include `xxh_x86dispatch.h` in order to access the symbols with runtime vector extension detection.\n- `NODE_JS=1` : When compiling `xxhsum` for Node.js with Emscripten, this links the `NODERAWFS` library for unrestricted filesystem access and patches `isatty` to make the command line utility correctly detect the terminal. This does make the binary specific to Node.js.\n\n### Building xxHash - Using vcpkg\n\nYou can download and install xxHash using the [vcpkg](https://github.com/Microsoft/vcpkg) dependency manager:\n\n    git clone https://github.com/Microsoft/vcpkg.git\n    cd vcpkg\n    ./bootstrap-vcpkg.sh\n    ./vcpkg integrate install\n    ./vcpkg install xxhash\n\nThe xxHash port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n### Example\n\nThe simplest example calls xxhash 64-bit variant as a one-shot function\ngenerating a hash value from a single buffer, and invoked from a C/C++ program:\n\n```C\n#include \"xxhash.h\"\n\n    (...)\n    XXH64_hash_t hash = XXH64(buffer, size, seed);\n}\n```\n\nStreaming variant is more involved, but makes it possible to provide data incrementally:\n\n```C\n#include \"stdlib.h\"   /* abort() */\n#include \"xxhash.h\"\n\n\nXXH64_hash_t calcul_hash_streaming(FileHandler fh)\n{\n    /* create a hash state */\n    XXH64_state_t* const state = XXH64_createState();\n    if (state==NULL) abort();\n\n    size_t const bufferSize = SOME_SIZE;\n    void* const buffer = malloc(bufferSize);\n    if (buffer==NULL) abort();\n\n    /* Initialize state with selected seed */\n    XXH64_hash_t const seed = 0;   /* or any other value */\n    if (XXH64_reset(state, seed) == XXH_ERROR) abort();\n\n    /* Feed the state with input data, any size, any number of times */\n    (...)\n    while ( /* some data left */ ) {\n        size_t const length = get_more_data(buffer, bufferSize, fh);\n        if (XXH64_update(state, buffer, length) == XXH_ERROR) abort();\n        (...)\n    }\n    (...)\n\n    /* Produce the final hash value */\n    XXH64_hash_t const hash = XXH64_digest(state);\n\n    /* State could be re-used; but in this example, it is simply freed  */\n    free(buffer);\n    XXH64_freeState(state);\n\n    return hash;\n}\n```\n\n\n### License\n\nThe library files `xxhash.c` and `xxhash.h` are BSD licensed.\nThe utility `xxhsum` is GPL licensed.\n\n\n### Other programming languages\n\nBeyond the C reference version,\nxxHash is also available from many different programming languages,\nthanks to great contributors.\nThey are [listed here](http://www.xxhash.com/#other-languages).\n\n\n### Packaging status\n\nMany distributions bundle a package manager\nwhich allows easy xxhash installation as both a `libxxhash` library\nand `xxhsum` command line interface.\n\n[![Packaging status](https://repology.org/badge/vertical-allrepos/xxhash.svg)](https://repology.org/project/xxhash/versions)\n\n\n### Special Thanks\n\n- Takayuki Matsuoka, aka @t-mat, for creating `xxhsum -c` and great support during early xxh releases\n- Mathias Westerdahl, aka @JCash, for introducing the first version of `XXH64`\n- Devin Hussey, aka @easyaspi314, for incredible low-level optimizations on `XXH3` and `XXH128`\n",
      "stars_today": 10
    },
    {
      "id": 815904141,
      "name": "ReVancedXposed",
      "full_name": "chsbuffer/ReVancedXposed",
      "description": "ReVanced LSPosed module. YouTube & YT Music Remove ads, Background playback",
      "html_url": "https://github.com/chsbuffer/ReVancedXposed",
      "stars": 1970,
      "forks": 84,
      "language": "Kotlin",
      "topics": [
        "android",
        "revanced",
        "xposed-module",
        "youtube",
        "youtube-music"
      ],
      "created_at": "2024-06-16T13:36:30Z",
      "updated_at": "2026-01-15T23:34:09Z",
      "pushed_at": "2026-01-15T09:58:50Z",
      "open_issues": 14,
      "owner": {
        "login": "chsbuffer",
        "avatar_url": "https://avatars.githubusercontent.com/u/33744752?v=4"
      },
      "readme": "<div align=\"center\">\n  <h1>ReVanced Xposed</h1>\n  <a href=\"https://discord.gg/QWUrAA2mKq\"><img alt=\"Discord Server\" src=\"https://img.shields.io/badge/Discord%20Server-5865F2.svg?logo=discord&logoColor=white\"></a>\n  <a href=\"https://t.me/revancedxposed\"><img alt=\"Telegram Channel\" src=\"https://img.shields.io/badge/Telegram_Channel-blue.svg?logo=telegram&logoColor=white\"></a>\n  <a href=\"https://github.com/chsbuffer/ReVancedXposed/releases/latest\"><img alt=\"GitHub Downloads\" src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fshields.chsbuffer.workers.dev%2F%3Frepos%3Dchsbuffer%2FReVancedXposed%2CXposed-Modules-Repo%2Fio.github.chsbuffer.revancedxposed&cacheSeconds=3600\"></a>\n  <a href=\"https://github.com/chsbuffer/ReVancedXposed\"><img alt=\"GitHub Stars\" src=\"https://img.shields.io/github/stars/chsbuffer/ReVancedXposed\"></a>  \n  <br>\n</div>\n\n**ReVanced LSPosed module by ChsBuffer.**  \n>[!IMPORTANT]  \n> - This is **NOT an official ReVanced project**, do not ask the ReVanced developers for help.  \n> - **Root access** is strictly **required** to use this module!\n> - **Spotify is no longer supported!** Get the new module [here](https://github.com/chsbuffer/ReVancedXposed_Spotify)\n> - **Having issues?** Check the **[FAQ](https://github.com/chsbuffer/ReVancedXposed/wiki/Frequently-Asked-Questions)** before reporting.\n\n## Downloads\n- **Release build**: [Download](https://github.com/chsbuffer/ReVancedXposed/releases/latest)\n- **Nightly build**: [Download](https://nightly.link/chsbuffer/ReVancedXposed/workflows/android/main)\n\n<sub>If you've joined the YouTube beta program, please try the nightly build before reporting an issue.</sub>\n\n## Patches\n\n### Youtube\n- Remove ads\n- SponsorBlock\n- Remove background playback restrictions\n- Remove share links tracking query parameter\n- Hide and change navigation buttons\n- Swipe controls\n- Remember video quality changes\n- Show video quality button\n- Show advanced video quality menu\n- Copy video url video player button\n- Open external downloader app\n- Custom playback speed\n- Remember playback speed\n- Playback speed dialog button\n- Hide layout components\n- Hide video action buttons\n- Disable resuming Shorts on startup\n- Disable video codecs\n- Disable auto captions\n- Alternative thumbnails\n- Bypass image region restrictions\n\n### Spotify (Moved to Dedicated Repository)\n\n[ReVancedXposed_Spotify](https://github.com/chsbuffer/ReVancedXposed_Spotify)\n\n### Google Photos\n- Spoof Pixel XL\n\n### Youtube Music\n- Remove music video ads\n- Remove background playback restrictions\n- Hide upgrade button\n- Hide 'Get Music Premium' label\n- Enable exclusive audio playback\n\n### Instagram\n- Hide ads\n\n### Threads\n- Hide ads\n\n### Reddit\n- Hide ads\n- Sanitize sharing links\n\n### Strava\n- Unlock subscription features\n- Disable subscription suggestions\n\n### Photomath\n- Unlock plus\n\n## Supports\n[![Discord Server](https://img.shields.io/badge/Join-Discord-5865F2.svg?logo=discord)](https://discord.gg/QWUrAA2mKq)  \n[![FAQ](https://img.shields.io/badge/Read-FAQ-orange.svg?logo=github)](https://github.com/chsbuffer/ReVancedXposed/wiki/Frequently-Asked-Questions)  \nor [Create an issue](https://github.com/chsbuffer/ReVancedXposed/issues/new/choose)\n\n## â­ Credits\n\n[DexKit](https://luckypray.org/DexKit/en/): a high-performance dex runtime parsing library.  \n[ReVanced](https://revanced.app): Continuing the legacy of Vanced at [revanced.app](https://revanced.app)  \n",
      "stars_today": 10
    },
    {
      "id": 930678258,
      "name": "kubernetes-mcp-server",
      "full_name": "containers/kubernetes-mcp-server",
      "description": "Model Context Protocol (MCP) server for Kubernetes and OpenShift",
      "html_url": "https://github.com/containers/kubernetes-mcp-server",
      "stars": 999,
      "forks": 221,
      "language": "Go",
      "topics": [
        "containers",
        "context",
        "kubernetes",
        "kubernetes-mcp",
        "mcp",
        "model",
        "modelcontextprotocol",
        "openshift",
        "protocol"
      ],
      "created_at": "2025-02-11T02:57:36Z",
      "updated_at": "2026-01-15T22:24:41Z",
      "pushed_at": "2026-01-15T08:07:44Z",
      "open_issues": 56,
      "owner": {
        "login": "containers",
        "avatar_url": "https://avatars.githubusercontent.com/u/5874934?v=4"
      },
      "readme": "# Kubernetes MCP Server\n\n[![GitHub License](https://img.shields.io/github/license/containers/kubernetes-mcp-server)](https://github.com/containers/kubernetes-mcp-server/blob/main/LICENSE)\n[![npm](https://img.shields.io/npm/v/kubernetes-mcp-server)](https://www.npmjs.com/package/kubernetes-mcp-server)\n[![PyPI - Version](https://img.shields.io/pypi/v/kubernetes-mcp-server)](https://pypi.org/project/kubernetes-mcp-server/)\n[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/containers/kubernetes-mcp-server?sort=semver)](https://github.com/containers/kubernetes-mcp-server/releases/latest)\n[![Build](https://github.com/containers/kubernetes-mcp-server/actions/workflows/build.yaml/badge.svg)](https://github.com/containers/kubernetes-mcp-server/actions/workflows/build.yaml)\n\n[âœ¨ Features](#features) | [ğŸš€ Getting Started](#getting-started) | [ğŸ¥ Demos](#demos) | [âš™ï¸ Configuration](#configuration) | [ğŸ› ï¸ Tools](#tools-and-functionalities) | [ğŸ§‘â€ğŸ’» Development](#development)\n\nhttps://github.com/user-attachments/assets/be2b67b3-fc1c-4d11-ae46-93deba8ed98e\n\n## âœ¨ Features <a id=\"features\"></a>\n\nA powerful and flexible Kubernetes [Model Context Protocol (MCP)](https://blog.marcnuri.com/model-context-protocol-mcp-introduction) server implementation with support for **Kubernetes** and **OpenShift**.\n\n- **âœ… Configuration**:\n  - Automatically detect changes in the Kubernetes configuration and update the MCP server.\n  - **View** and manage the current [Kubernetes `.kube/config`](https://blog.marcnuri.com/where-is-my-default-kubeconfig-file) or in-cluster configuration.\n- **âœ… Generic Kubernetes Resources**: Perform operations on **any** Kubernetes or OpenShift resource.\n  - Any CRUD operation (Create or Update, Get, List, Delete).\n- **âœ… Pods**: Perform Pod-specific operations.\n  - **List** pods in all namespaces or in a specific namespace.\n  - **Get** a pod by name from the specified namespace.\n  - **Delete** a pod by name from the specified namespace.\n  - **Show logs** for a pod by name from the specified namespace.\n  - **Top** gets resource usage metrics for all pods or a specific pod in the specified namespace.\n  - **Exec** into a pod and run a command.\n  - **Run** a container image in a pod and optionally expose it.\n- **âœ… Namespaces**: List Kubernetes Namespaces.\n- **âœ… Events**: View Kubernetes events in all namespaces or in a specific namespace.\n- **âœ… Projects**: List OpenShift Projects.\n- **â˜¸ï¸ Helm**:\n  - **Install** a Helm chart in the current or provided namespace.\n  - **List** Helm releases in all namespaces or in a specific namespace.\n  - **Uninstall** a Helm release in the current or provided namespace.\n\nUnlike other Kubernetes MCP server implementations, this **IS NOT** just a wrapper around `kubectl` or `helm` command-line tools.\nIt is a **Go-based native implementation** that interacts directly with the Kubernetes API server.\n\nThere is **NO NEED** for external dependencies or tools to be installed on the system.\nIf you're using the native binaries you don't need to have Node or Python installed on your system.\n\n- **âœ… Lightweight**: The server is distributed as a single native binary for Linux, macOS, and Windows.\n- **âœ… High-Performance / Low-Latency**: Directly interacts with the Kubernetes API server without the overhead of calling and waiting for external commands.\n- **âœ… Multi-Cluster**: Can interact with multiple Kubernetes clusters simultaneously (as defined in your kubeconfig files).\n- **âœ… Cross-Platform**: Available as a native binary for Linux, macOS, and Windows, as well as an npm package, a Python package, and container/Docker image.\n- **âœ… Configurable**: Supports [command-line arguments](#configuration)  to configure the server behavior.\n- **âœ… Well tested**: The server has an extensive test suite to ensure its reliability and correctness across different Kubernetes environments.\n\n## ğŸš€ Getting Started <a id=\"getting-started\"></a>\n\n### Requirements\n\n- Access to a Kubernetes cluster.\n\n<details>\n<summary><b>Claude Code</b></summary>\n\nFollow the [dedicated Claude Code getting started guide](docs/GETTING_STARTED_CLAUDE_CODE.md) in our [user documentation](docs/).\n\nFor a secure production setup with dedicated ServiceAccount and read-only access, also review the [Kubernetes setup guide](docs/GETTING_STARTED_KUBERNETES.md).\n\n</details>\n\n### Claude Desktop\n\n#### Using npx\n\nIf you have npm installed, this is the fastest way to get started with `kubernetes-mcp-server` on Claude Desktop.\n\nOpen your `claude_desktop_config.json` and add the mcp server to the list of `mcpServers`:\n``` json\n{\n  \"mcpServers\": {\n    \"kubernetes\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"kubernetes-mcp-server@latest\"\n      ]\n    }\n  }\n}\n```\n\n### VS Code / VS Code Insiders\n\nInstall the Kubernetes MCP server extension in VS Code Insiders by pressing the following link:\n\n[<img src=\"https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&label=Install%20Server&color=0098FF\" alt=\"Install in VS Code\">](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522kubernetes%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522kubernetes-mcp-server%2540latest%2522%255D%257D)\n[<img alt=\"Install in VS Code Insiders\" src=\"https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&label=Install%20Server&color=24bfa5\">](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522kubernetes%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522kubernetes-mcp-server%2540latest%2522%255D%257D)\n\nAlternatively, you can install the extension manually by running the following command:\n\n```shell\n# For VS Code\ncode --add-mcp '{\"name\":\"kubernetes\",\"command\":\"npx\",\"args\":[\"kubernetes-mcp-server@latest\"]}'\n# For VS Code Insiders\ncode-insiders --add-mcp '{\"name\":\"kubernetes\",\"command\":\"npx\",\"args\":[\"kubernetes-mcp-server@latest\"]}'\n```\n\n### Cursor\n\nInstall the Kubernetes MCP server extension in Cursor by pressing the following link:\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=kubernetes-mcp-server&config=eyJjb21tYW5kIjoibnB4IC15IGt1YmVybmV0ZXMtbWNwLXNlcnZlckBsYXRlc3QifQ%3D%3D)\n\nAlternatively, you can install the extension manually by editing the `mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"kubernetes-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"kubernetes-mcp-server@latest\"]\n    }\n  }\n}\n```\n\n### Goose CLI\n\n[Goose CLI](https://blog.marcnuri.com/goose-on-machine-ai-agent-cli-introduction) is the easiest (and cheapest) way to get rolling with artificial intelligence (AI) agents.\n\n#### Using npm\n\nIf you have npm installed, this is the fastest way to get started with `kubernetes-mcp-server`.\n\nOpen your goose `config.yaml` and add the mcp server to the list of `mcpServers`:\n```yaml\nextensions:\n  kubernetes:\n    command: npx\n    args:\n      - -y\n      - kubernetes-mcp-server@latest\n\n```\n\n## ğŸ¥ Demos <a id=\"demos\"></a>\n\n### Diagnosing and automatically fixing an OpenShift Deployment\n\nDemo showcasing how Kubernetes MCP server is leveraged by Claude Desktop to automatically diagnose and fix a deployment in OpenShift without any user assistance.\n\nhttps://github.com/user-attachments/assets/a576176d-a142-4c19-b9aa-a83dc4b8d941\n\n### _Vibe Coding_ a simple game and deploying it to OpenShift\n\nIn this demo, I walk you through the process of _Vibe Coding_ a simple game using VS Code and how to leverage [Podman MCP server](https://github.com/manusa/podman-mcp-server) and Kubernetes MCP server to deploy it to OpenShift.\n\n<a href=\"https://www.youtube.com/watch?v=l05jQDSrzVI\" target=\"_blank\">\n <img src=\"docs/images/vibe-coding.jpg\" alt=\"Vibe Coding: Build & Deploy a Game on Kubernetes\" width=\"240\"  />\n</a>\n\n### Supercharge GitHub Copilot with Kubernetes MCP Server in VS Code - One-Click Setup!\n\nIn this demo, I'll show you how to set up Kubernetes MCP server in VS code just by clicking a link.\n\n<a href=\"https://youtu.be/AI4ljYMkgtA\" target=\"_blank\">\n <img src=\"docs/images/kubernetes-mcp-server-github-copilot.jpg\" alt=\"Supercharge GitHub Copilot with Kubernetes MCP Server in VS Code - One-Click Setup!\" width=\"240\"  />\n</a>\n\n## âš™ï¸ Configuration <a id=\"configuration\"></a>\n\nThe Kubernetes MCP server can be configured using command line (CLI) arguments.\n\nYou can run the CLI executable either by using `npx`, `uvx`, or by downloading the [latest release binary](https://github.com/containers/kubernetes-mcp-server/releases/latest).\n\n```shell\n# Run the Kubernetes MCP server using npx (in case you have npm and node installed)\nnpx kubernetes-mcp-server@latest --help\n```\n\n```shell\n# Run the Kubernetes MCP server using uvx (in case you have uv and python installed)\nuvx kubernetes-mcp-server@latest --help\n```\n\n```shell\n# Run the Kubernetes MCP server using the latest release binary\n./kubernetes-mcp-server --help\n```\n\n### Configuration Options\n\n| Option                    | Description                                                                                                                                                                                                                                                                                   |\n|---------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `--port`                  | Starts the MCP server in Streamable HTTP mode (path /mcp) and Server-Sent Event (SSE) (path /sse) mode and listens on the specified port .                                                                                                                                                    |\n| `--log-level`             | Sets the logging level (values [from 0-9](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md)). Similar to [kubectl logging levels](https://kubernetes.io/docs/reference/kubectl/quick-reference/#kubectl-output-verbosity-and-debugging). |\n| `--config`                | (Optional) Path to the main TOML configuration file. See [Drop-in Configuration](#drop-in-configuration) section below for details.                                                                                                                                                          |\n| `--config-dir`            | (Optional) Path to drop-in configuration directory. Files are loaded in lexical (alphabetical) order. Defaults to `conf.d` relative to the main config file if `--config` is specified. See [Drop-in Configuration](#drop-in-configuration) section below for details.                       |\n| `--kubeconfig`            | Path to the Kubernetes configuration file. If not provided, it will try to resolve the configuration (in-cluster, default location, etc.).                                                                                                                                                    |\n| `--list-output`           | Output format for resource list operations (one of: yaml, table) (default \"table\")                                                                                                                                                                                                            |\n| `--read-only`             | If set, the MCP server will run in read-only mode, meaning it will not allow any write operations (create, update, delete) on the Kubernetes cluster. This is useful for debugging or inspecting the cluster without making changes.                                                          |\n| `--disable-destructive`   | If set, the MCP server will disable all destructive operations (delete, update, etc.) on the Kubernetes cluster. This is useful for debugging or inspecting the cluster without accidentally making changes. This option has no effect when `--read-only` is used.                            |\n| `--stateless`             | If set, the MCP server will run in stateless mode, disabling tool and prompt change notifications. This is useful for container deployments, load balancing, and serverless environments where maintaining client state is not desired. |\n| `--toolsets`              | Comma-separated list of toolsets to enable. Check the [ğŸ› ï¸ Tools and Functionalities](#tools-and-functionalities) section for more information.                                                                                                                                               |\n| `--disable-multi-cluster` | If set, the MCP server will disable multi-cluster support and will only use the current context from the kubeconfig file. This is useful if you want to restrict the MCP server to a single cluster.                                                                                          |\n\n### Drop-in Configuration <a id=\"drop-in-configuration\"></a>\n\nThe Kubernetes MCP server supports flexible configuration through both a main config file and drop-in files. **Both are optional** - you can use either, both, or neither (server will use built-in defaults).\n\n#### Configuration Loading Order\n\nConfiguration values are loaded and merged in the following order (later sources override earlier ones):\n\n1. **Internal Defaults** - Always loaded (hardcoded default values)\n2. **Main Configuration File** - Optional, loaded via `--config` flag\n3. **Drop-in Files** - Optional, loaded from `--config-dir` in **lexical (alphabetical) order**\n\n#### How Drop-in Files Work\n\n- **Default Directory**: If `--config-dir` is not specified, the server looks for drop-in files in `conf.d/` relative to the main config file's directory (when `--config` is provided)\n- **File Naming**: Use numeric prefixes to control loading order (e.g., `00-base.toml`, `10-cluster.toml`, `99-override.toml`)\n- **File Extension**: Only `.toml` files are processed; dotfiles (starting with `.`) are ignored\n- **Partial Configuration**: Drop-in files can contain only a subset of configuration options\n- **Merge Behavior**: Values present in a drop-in file override previous values; missing values are preserved\n\n#### Dynamic Configuration Reload\n\nTo reload configuration after modifying config files, send a `SIGHUP` signal to the running server process.\n\n**Prerequisite**: SIGHUP reload requires the server to be started with either the `--config` flag or `--config-dir` flag (or both). If neither is specified, SIGHUP signals will be ignored.\n\n**How to reload:**\n\n```shell\n# Find the process ID\nps aux | grep kubernetes-mcp-server\n\n# Send SIGHUP to reload configuration\nkill -HUP <pid>\n\n# Or use pkill\npkill -HUP kubernetes-mcp-server\n```\n\nThe server will:\n- Reload the main config file and all drop-in files\n- Update configuration values (log level, output format, etc.)\n- Rebuild the toolset registry with new tool configurations\n- Log the reload status\n\n**Note**: Changing `kubeconfig` or cluster-related settings requires a server restart. Only tool configurations, log levels, and output formats can be reloaded dynamically.\n\n**Note**: SIGHUP reload is not available on Windows. On Windows, restart the server to reload configuration.\n\n#### Example: Using Both Config Methods\n\n**Command (using default `conf.d` directory):**\n```shell\nkubernetes-mcp-server --config /etc/kubernetes-mcp-server/config.toml\n```\n\n**Directory structure:**\n```\n/etc/kubernetes-mcp-server/\nâ”œâ”€â”€ config.toml              # Main configuration\nâ””â”€â”€ conf.d/                  # Default drop-in directory (automatically loaded)\n    â”œâ”€â”€ 00-base.toml         # Base overrides\n    â”œâ”€â”€ 10-toolsets.toml     # Toolset-specific config\n    â””â”€â”€ 99-local.toml        # Local overrides\n```\n\n**Command (with explicit `--config-dir`):**\n```shell\nkubernetes-mcp-server --config /etc/kubernetes-mcp-server/config.toml \\\n                      --config-dir /etc/kubernetes-mcp-server/config.d/\n```\n\n**Example drop-in file** (`10-toolsets.toml`):\n```toml\n# Override only the toolsets - all other config preserved\ntoolsets = [\"core\", \"config\", \"helm\", \"logs\"]\n```\n\n**Example drop-in file** (`99-local.toml`):\n```toml\n# Local development overrides\nlog_level = 9\nread_only = true\n```\n\n**To apply changes:**\n```shell\n# Edit config files\nvim /etc/kubernetes-mcp-server/conf.d/99-local.toml\n\n# Reload without restarting\npkill -HUP kubernetes-mcp-server\n```\n\n### MCP Prompts\n\n1. The server supports MCP prompts for workflow templates. Define custom prompts in `config.toml`:\n\n```toml\n[[prompts]]\nname = \"my-workflow\"\ntitle = \"my workflow\"\ndescription = \"Custom workflow\"\n\n[[prompts.arguments]]\nname = \"resource_name\"\nrequired = true\n\n[[prompts.messages]]\nrole = \"user\"\ncontent = \"Help me with {{resource_name}}\"\n```\n\n2. Toolset prompts implemented by toolset developers\n\nSee docs/PROMPTS.md for detailed documentation.\n\n## ğŸ“Š MCP Logging <a id=\"mcp-logging\"></a>\n\nThe server supports the MCP logging capability, allowing clients to receive debugging information via structured log messages.\n\n### For Clients\n\nClients can control log verbosity by sending a `logging/setLevel` request:\n\n```json\n{\n  \"method\": \"logging/setLevel\",\n  \"params\": { \"level\": \"info\" }\n}\n```\n\n**Available log levels** (in order of increasing severity):\n- `debug` - Detailed debugging information\n- `info` - General informational messages (default)\n- `notice` - Normal but significant events\n- `warning` - Warning messages\n- `error` - Error conditions\n- `critical` - Critical conditions\n- `alert` - Action must be taken immediately\n- `emergency` - System is unusable\n\n### For Developers\n\nToolsets can optionally send debug information to clients using helper functions from the `mcplog` package:\n\n**Recommended approach for Kubernetes errors** (automatically categorizes errors and sends appropriate messages):\n\n```go\nimport \"github.com/containers/kubernetes-mcp-server/pkg/mcplog\"\n\n// In your tool handler:\nret, err := client.CoreV1().Pods(namespace).Get(ctx, name, metav1.GetOptions{})\nif err != nil {\n    mcplog.HandleK8sError(ctx, err, \"pod access\")\n    return api.NewToolCallResult(\"\", fmt.Errorf(\"failed to get pod: %v\", err)), nil\n}\n```\n\n**Manual logging** (for custom messages):\n\n```go\nimport \"github.com/containers/kubernetes-mcp-server/pkg/mcplog\"\n\n// In your tool handler:\nif err != nil {\n    mcplog.SendMCPLog(ctx, \"error\", \"Operation failed - check permissions\")\n    return api.NewToolCallResult(\"\", err)\n}\n```\n\n**Key Points:**\n- Logging is **optional** - toolsets work fine without sending MCP logs\n- Uses a dedicated named logger (`logger=\"mcp\"`) for complete separation from server logs\n- Server logs (klog) remain detailed and unaffected\n- Client logs are high-level, helpful hints for debugging\n- Authentication failures send generic messages to clients (no security info leaked)\n- Sensitive data is automatically redacted with 28 pattern types:\n  - Generic fields (password, token, secret, api_key, etc.)\n  - Authorization headers (Bearer, Basic)\n  - Cloud credentials (AWS, GCP, Azure)\n  - API tokens (GitHub, GitLab, OpenAI, Anthropic)\n  - Cryptographic keys (JWT, SSH, PGP, RSA)\n  - Database connection strings (PostgreSQL, MySQL, MongoDB)\n\n## ğŸ› ï¸ Tools and Functionalities <a id=\"tools-and-functionalities\"></a>\n\nThe Kubernetes MCP server supports enabling or disabling specific groups of tools and functionalities (tools, resources, prompts, and so on) via the `--toolsets` command-line flag or `toolsets` configuration option.\nThis allows you to control which Kubernetes functionalities are available to your AI tools.\nEnabling only the toolsets you need can help reduce the context size and improve the LLM's tool selection accuracy.\n\n### Available Toolsets\n\nThe following sets of tools are available (toolsets marked with âœ“ in the Default column are enabled by default):\n\n<!-- AVAILABLE-TOOLSETS-START -->\n\n| Toolset  | Description                                                                                                                                                          | Default |\n|----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------|\n| config   | View and manage the current local Kubernetes configuration (kubeconfig)                                                                                              | âœ“       |\n| core     | Most common tools for Kubernetes management (Pods, Generic Resources, Events, etc.)                                                                                  | âœ“       |\n| kiali    | Most common tools for managing Kiali, check the [Kiali documentation](https://github.com/containers/kubernetes-mcp-server/blob/main/docs/KIALI.md) for more details. |         |\n| kubevirt | KubeVirt virtual machine management tools                                                                                                                            |         |\n| helm     | Tools for managing Helm charts and releases                                                                                                                          | âœ“       |\n\n<!-- AVAILABLE-TOOLSETS-END -->\n\n### Tools\n\nIn case multi-cluster support is enabled (default) and you have access to multiple clusters, all applicable tools will include an additional `context` argument to specify the Kubernetes context (cluster) to use for that operation.\n\n<!-- AVAILABLE-TOOLSETS-TOOLS-START -->\n\n<details>\n\n<summary>config</summary>\n\n- **configuration_contexts_list** - List all available context names and associated server urls from the kubeconfig file\n\n- **targets_list** - List all available targets\n\n- **configuration_view** - Get the current Kubernetes configuration content as a kubeconfig YAML\n  - `minified` (`boolean`) - Return a minified version of the configuration. If set to true, keeps only the current-context and the relevant pieces of the configuration for that context. If set to false, all contexts, clusters, auth-infos, and users are returned in the configuration. (Optional, default true)\n\n</details>\n\n<details>\n\n<summary>core</summary>\n\n- **events_list** - List all the Kubernetes events in the current cluster from all namespaces\n  - `namespace` (`string`) - Optional Namespace to retrieve the events from. If not provided, will list events from all namespaces\n\n- **namespaces_list** - List all the Kubernetes namespaces in the current cluster\n\n- **projects_list** - List all the OpenShift projects in the current cluster\n\n- **nodes_log** - Get logs from a Kubernetes node (kubelet, kube-proxy, or other system logs). This accesses node logs through the Kubernetes API proxy to the kubelet\n  - `name` (`string`) **(required)** - Name of the node to get logs from\n  - `query` (`string`) **(required)** - query specifies services(s) or files from which to return logs (required). Example: \"kubelet\" to fetch kubelet logs, \"/<log-file-name>\" to fetch a specific log file from the node (e.g., \"/var/log/kubelet.log\" or \"/var/log/kube-proxy.log\")\n  - `tailLines` (`integer`) - Number of lines to retrieve from the end of the logs (Optional, 0 means all logs)\n\n- **nodes_stats_summary** - Get detailed resource usage statistics from a Kubernetes node via the kubelet's Summary API. Provides comprehensive metrics including CPU, memory, filesystem, and network usage at the node, pod, and container levels. On systems with cgroup v2 and kernel 4.20+, also includes PSI (Pressure Stall Information) metrics that show resource pressure for CPU, memory, and I/O. See https://kubernetes.io/docs/reference/instrumentation/understand-psi-metrics/ for details on PSI metrics\n  - `name` (`string`) **(required)** - Name of the node to get stats from\n\n- **nodes_top** - List the resource consumption (CPU and memory) as recorded by the Kubernetes Metrics Server for the specified Kubernetes Nodes or all nodes in the cluster\n  - `label_selector` (`string`) - Kubernetes label selector (e.g. 'node-role.kubernetes.io/worker=') to filter nodes by label (Optional, only applicable when name is not provided)\n  - `name` (`string`) - Name of the Node to get the resource consumption from (Optional, all Nodes if not provided)\n\n- **pods_list** - List all the Kubernetes pods in the current cluster from all namespaces\n  - `fieldSelector` (`string`) - Optional Kubernetes field selector to filter pods by field values (e.g. 'status.phase=Running', 'spec.nodeName=node1'). Supported fields: metadata.name, metadata.namespace, spec.nodeName, spec.restartPolicy, spec.schedulerName, spec.serviceAccountName, status.phase (Pending/Running/Succeeded/Failed/Unknown), status.podIP, status.nominatedNodeName. Note: CrashLoopBackOff is a container state, not a pod phase, so it cannot be filtered directly. See https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/\n  - `labelSelector` (`string`) - Optional Kubernetes label selector (e.g. 'app=myapp,env=prod' or 'app in (myapp,yourapp)'), use this option when you want to filter the pods by label\n\n- **pods_list_in_namespace** - List all the Kubernetes pods in the specified namespace in the current cluster\n  - `fieldSelector` (`string`) - Optional Kubernetes field selector to filter pods by field values (e.g. 'status.phase=Running', 'spec.nodeName=node1'). Supported fields: metadata.name, metadata.namespace, spec.nodeName, spec.restartPolicy, spec.schedulerName, spec.serviceAccountName, status.phase (Pending/Running/Succeeded/Failed/Unknown), status.podIP, status.nominatedNodeName. Note: CrashLoopBackOff is a container state, not a pod phase, so it cannot be filtered directly. See https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/\n  - `labelSelector` (`string`) - Optional Kubernetes label selector (e.g. 'app=myapp,env=prod' or 'app in (myapp,yourapp)'), use this option when you want to filter the pods by label\n  - `namespace` (`string`) **(required)** - Namespace to list pods from\n\n- **pods_get** - Get a Kubernetes Pod in the current or provided namespace with the provided name\n  - `name` (`string`) **(required)** - Name of the Pod\n  - `namespace` (`string`) - Namespace to get the Pod from\n\n- **pods_delete** - Delete a Kubernetes Pod in the current or provided namespace with the provided name\n  - `name` (`string`) **(required)** - Name of the Pod to delete\n  - `namespace` (`string`) - Namespace to delete the Pod from\n\n- **pods_top** - List the resource consumption (CPU and memory) as recorded by the Kubernetes Metrics Server for the specified Kubernetes Pods in the all namespaces, the provided namespace, or the current namespace\n  - `all_namespaces` (`boolean`) - If true, list the resource consumption for all Pods in all namespaces. If false, list the resource consumption for Pods in the provided namespace or the current namespace\n  - `label_selector` (`string`) - Kubernetes label selector (e.g. 'app=myapp,env=prod' or 'app in (myapp,yourapp)'), use this option when you want to filter the pods by label (Optional, only applicable when name is not provided)\n  - `name` (`string`) - Name of the Pod to get the resource consumption from (Optional, all Pods in the namespace if not provided)\n  - `namespace` (`string`) - Namespace to get the Pods resource consumption from (Optional, current namespace if not provided and all_namespaces is false)\n\n- **pods_exec** - Execute a command in a Kubernetes Pod in the current or provided namespace with the provided name and command\n  - `command` (`array`) **(required)** - Command to execute in the Pod container. The first item is the command to be run, and the rest are the arguments to that command. Example: [\"ls\", \"-l\", \"/tmp\"]\n  - `container` (`string`) - Name of the Pod container where the command will be executed (Optional)\n  - `name` (`string`) **(required)** - Name of the Pod where the command will be executed\n  - `namespace` (`string`) - Namespace of the Pod where the command will be executed\n\n- **pods_log** - Get the logs of a Kubernetes Pod in the current or provided namespace with the provided name\n  - `container` (`string`) - Name of the Pod container to get the logs from (Optional)\n  - `name` (`string`) **(required)** - Name of the Pod to get the logs from\n  - `namespace` (`string`) - Namespace to get the Pod logs from\n  - `previous` (`boolean`) - Return previous terminated container logs (Optional)\n  - `tail` (`integer`) - Number of lines to retrieve from the end of the logs (Optional, default: 100)\n\n- **pods_run** - Run a Kubernetes Pod in the current or provided namespace with the provided container image and optional name\n  - `image` (`string`) **(required)** - Container Image to run in the Pod\n  - `name` (`string`) - Name of the Pod (Optional, random name if not provided)\n  - `namespace` (`string`) - Namespace to run the Pod in\n  - `port` (`number`) - TCP/IP port to expose from the Pod container (Optional, no port exposed if not provided)\n\n- **resources_list** - List Kubernetes resources and objects in the current cluster by providing their apiVersion and kind and optionally the namespace and label selector\n(common apiVersion and kind include: v1 Pod, v1 Service, v1 Node, apps/v1 Deployment, networking.k8s.io/v1 Ingress, route.openshift.io/v1 Route)\n  - `apiVersion` (`string`) **(required)** - apiVersion of the resources (examples of valid apiVersion are: v1, apps/v1, networking.k8s.io/v1)\n  - `fieldSelector` (`string`) - Optional Kubernetes field selector to filter resources by field values (e.g. 'status.phase=Running', 'metadata.name=myresource'). Supported fields vary by resource type. For Pods: metadata.name, metadata.namespace, spec.nodeName, spec.restartPolicy, spec.schedulerName, spec.serviceAccountName, status.phase (Pending/Running/Succeeded/Failed/Unknown), status.podIP, status.nominatedNodeName. See https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/\n  - `kind` (`string`) **(required)** - kind of the resources (examples of valid kind are: Pod, Service, Deployment, Ingress)\n  - `labelSelector` (`string`) - Optional Kubernetes label selector (e.g. 'app=myapp,env=prod' or 'app in (myapp,yourapp)'), use this option when you want to filter the resources by label\n  - `namespace` (`string`) - Optional Namespace to retrieve the namespaced resources from (ignored in case of cluster scoped resources). If not provided, will list resources from all namespaces\n\n- **resources_get** - Get a Kubernetes resource in the current cluster by providing its apiVersion, kind, optionally the namespace, and its name\n(common apiVersion and kind include: v1 Pod, v1 Service, v1 Node, apps/v1 Deployment, networking.k8s.io/v1 Ingress, route.openshift.io/v1 Route)\n  - `apiVersion` (`string`) **(required)** - apiVersion of the resource (examples of valid apiVersion are: v1, apps/v1, networking.k8s.io/v1)\n  - `kind` (`string`) **(required)** - kind of the resource (examples of valid kind are: Pod, Service, Deployment, Ingress)\n  - `name` (`string`) **(required)** - Name of the resource\n  - `namespace` (`string`) - Optional Namespace to retrieve the namespaced resource from (ignored in case of cluster scoped resources). If not provided, will get resource from configured namespace\n\n- **resources_create_or_update** - Create or update a Kubernetes resource in the current cluster by providing a YAML or JSON representation of the resource\n(common apiVersion and kind include: v1 Pod, v1 Service, v1 Node, apps/v1 Deployment, networking.k8s.io/v1 Ingress, route.openshift.io/v1 Route)\n  - `resource` (`string`) **(required)** - A JSON or YAML containing a representation of the Kubernetes resource. Should include top-level fields such as apiVersion,kind,metadata, and spec\n\n- **resources_delete** - Delete a Kubernetes resource in the current cluster by providing its apiVersion, kind, optionally the namespace, and its name\n(common apiVersion and kind include: v1 Pod, v1 Service, v1 Node, apps/v1 Deployment, networking.k8s.io/v1 Ingress, route.openshift.io/v1 Route)\n  - `apiVersion` (`string`) **(required)** - apiVersion of the resource (examples of valid apiVersion are: v1, apps/v1, networking.k8s.io/v1)\n  - `kind` (`string`) **(required)** - kind of the resource (examples of valid kind are: Pod, Service, Deployment, Ingress)\n  - `name` (`string`) **(required)** - Name of the resource\n  - `namespace` (`string`) - Optional Namespace to delete the namespaced resource from (ignored in case of cluster scoped resources). If not provided, will delete resource from configured namespace\n\n- **resources_scale** - Get or update the scale of a Kubernetes resource in the current cluster by providing its apiVersion, kind, name, and optionally the namespace. If the scale is set in the tool call, the scale will be updated to that value. Always returns the current scale of the resource\n  - `apiVersion` (`string`) **(required)** - apiVersion of the resource (examples of valid apiVersion are apps/v1)\n  - `kind` (`string`) **(required)** - kind of the resource (examples of valid kind are: StatefulSet, Deployment)\n  - `name` (`string`) **(required)** - Name of the resource\n  - `namespace` (`string`) - Optional Namespace to get/update the namespaced resource scale from (ignored in case of cluster scoped resources). If not provided, will get/update resource scale from configured namespace\n  - `scale` (`integer`) - Optional scale to update the resources scale to. If not provided, will return the current scale of the resource, and not update it\n\n</details>\n\n<details>\n\n<summary>kiali</summary>\n\n- **kiali_mesh_graph** - Returns the topology of a specific namespaces, health, status of the mesh and namespaces. Includes a mesh health summary overview with aggregated counts of healthy, degraded, and failing apps, workloads, and services. Use this for high-level overviews\n  - `graphType` (`string`) - Optional type of graph to return: 'versionedApp', 'app', 'service', 'workload', 'mesh'\n  - `namespace` (`string`) - Optional single namespace to include in the graph (alternative to namespaces)\n  - `namespaces` (`string`) - Optional comma-separated list of namespaces to include in the graph\n  - `rateInterval` (`string`) - Optional rate interval for fetching (e.g., '10m', '5m', '1h').\n\n- **kiali_manage_istio_config** - Manages Istio configuration objects (Gateways, VirtualServices, etc.). Can list (objects and validations), get, create, patch, or delete objects\n  - `action` (`string`) **(required)** - Action to perform: list, get, create, patch, or delete\n  - `group` (`string`) - API group of the Istio object (e.g., 'networking.istio.io', 'gateway.networking.k8s.io')\n  - `json_data` (`string`) - JSON data to apply or create the object\n  - `kind` (`string`) - Kind of the Istio object (e.g., 'DestinationRule', 'VirtualService', 'HTTPRoute', 'Gateway')\n  - `name` (`string`) - Name of the Istio object\n  - `namespace` (`string`) - Namespace containing the Istio object\n  - `version` (`string`) - API version of the Istio object (e.g., 'v1', 'v1beta1')\n\n- **kiali_get_resource_details** - Gets lists or detailed info for Kubernetes resources (services, workloads) within the mesh\n  - `namespaces` (`string`) - Comma-separated list of namespaces to get services from (e.g. 'bookinfo' or 'bookinfo,default'). If not provided, will list services from all accessible namespaces\n  - `resource_name` (`string`) - Name of the resource to get details for (optional string - if provided, gets details; if empty, lists all).\n  - `resource_type` (`string`) - Type of resource to get details for (service, workload)\n\n- **kiali_get_metrics** - Gets lists or detailed info for Kubernetes resources (services, workloads) within the mesh\n  - `byLabels` (`string`) - Comma-separated list of labels to group metrics by (e.g., 'source_workload,destination_service'). Optional\n  - `direction` (`string`) - Traffic direction: 'inbound' or 'outbound'. Optional, defaults to 'outbound'\n  - `duration` (`string`) - Time range to get metrics for (optional string - if provided, gets metrics (e.g., '1m', '5m', '1h'); if empty, get default 30m).\n  - `namespace` (`string`) **(required)** - Namespace to get resources from\n  - `quantiles` (`string`) - Comma-separated list of quantiles for histogram metrics (e.g., '0.5,0.95,0.99'). Optional\n  - `rateInterval` (`string`) - Rate interval for metrics (e.g., '1m', '5m'). Optional, defaults to '10m'\n  - `reporter` (`string`) - Metrics reporter: 'source', 'destination', or 'both'. Optional, defaults to 'source'\n  - `requestProtocol` (`string`) - Filter by request protocol (e.g., 'http', 'grpc', 'tcp'). Optional\n  - `resource_name` (`string`) **(required)** - Name of the resource to get details for (optional string - if provided, gets details; if empty, lists all).\n  - `resource_type` (`string`) **(required)** - Type of resource to get details for (service, workload)\n  - `step` (`string`) - Step between data points in seconds (e.g., '15'). Optional, defaults to 15 seconds\n\n- **kiali_workload_logs** - Get logs for a specific workload's pods in a namespace. Only requires namespace and workload name - automatically discovers pods and containers. Optionally filter by container name, time range, and other parameters. Container is auto-detected if not specified.\n  - `container` (`string`) - Optional container name to filter logs. If not provided, automatically detects and uses the main application container (excludes istio-proxy and istio-init)\n  - `namespace` (`string`) **(required)** - Namespace containing the workload\n  - `since` (`string`) - Time duration to fetch logs from (e.g., '5m', '1h', '30s'). If not provided, returns recent logs\n  - `tail` (`integer`) - Number of lines to retrieve from the end of logs (default: 100)\n  - `workload` (`string`) **(required)** - Name of the workload to get logs for\n\n- **kiali_get_traces** - Gets traces for a specific resource (app, service, workload) in a namespace, or gets detailed information for a specific trace by its ID. If traceId is provided, it returns detailed trace information and other parameters are not required.\n  - `clusterName` (`string`) - Cluster name for multi-cluster environments (optional, only used when traceId is not provided)\n  - `endMicros` (`string`) - End time for traces in microseconds since epoch (optional, defaults to 10 minutes after startMicros if not provided, only used when traceId is not provided)\n  - `limit` (`integer`) - Maximum number of traces to return (default: 100, only used when traceId is not provided)\n  - `minDuration` (`integer`) - Minimum trace duration in microseconds (optional, only used when traceId is not provided)\n  - `namespace` (`string`) - Namespace to get resources from. Required if traceId is not provided.\n  - `resource_name` (`string`) - Name of the resource to get traces for. Required if traceId is not provided.\n  - `resource_type` (`string`) - Type of resource to get traces for (app, service, workload). Required if traceId is not provided.\n  - `startMicros` (`string`) - Start time for traces in microseconds since epoch (optional, defaults to 10 minutes before current time if not provided, only used when traceId is not provided)\n  - `tags` (`string`) - JSON string of tags to filter traces (optional, only used when traceId is not provided)\n  - `traceId` (`string`) - Unique identifier of the trace to retrieve detailed information for. If provided, this will return detailed trace information and other parameters (resource_type, namespace, resource_name) are not required.\n\n</details>\n\n<details>\n\n<summary>kubevirt</summary>\n\n- **vm_create** - Create a VirtualMachine in the cluster with the specified configuration, automatically resolving instance types, preferences, and container disk images. VM will be created in Halted state by default; use autostart parameter to start it immediately.\n  - `autostart` (`boolean`) - Optional flag to automatically start the VM after creation (sets runStrategy to Always instead of Halted). Defaults to false.\n  - `instancetype` (`string`) - Optional instance type name for the VM (e.g., 'u1.small', 'u1.medium', 'u1.large')\n  - `name` (`string`) **(required)** - The name of the virtual machine\n  - `namespace` (`string`) **(required)** - The namespace for the virtual machine\n  - `performance` (`string`) - Optional performance family hint for the VM instance type (e.g., 'u1' for general-purpose, 'o1' for overcommitted, 'c1' for compute-optimized, 'm1' for memory-optimized). Defaults to 'u1' (general-purpose) if not specified.\n  - `preference` (`string`) - Optional preference name for the VM\n  - `size` (`string`) - Optional workload size hint for the VM (e.g., 'small', 'medium', 'large', 'xlarge'). Used to auto-select an appropriate instance type if not explicitly specified.\n  - `storage` (`string`) - Optional storage size for the VM's root disk when using DataSources (e.g., '30Gi', '50Gi', '100Gi'). Defaults to 30Gi. Ignored when using container disks.\n  - `workload` (`string`) - The workload for the VM. Accepts OS names (e.g., 'fedora' (default), 'ubuntu', 'centos', 'centos-stream', 'debian', 'rhel', 'opensuse', 'opensuse-tumbleweed', 'opensuse-leap') or full container disk image URLs\n\n- **vm_lifecycle** - Manage VirtualMachine lifecycle: start, stop, or restart a VM\n  - `action` (`string`) **(required)** - The lifecycle action to perform: 'start' (changes runStrategy to Always), 'stop' (changes runStrategy to Halted), or 'restart' (stops then starts the VM)\n  - `name` (`string`) **(required)** - The name of the virtual machine\n  - `namespace` (`string`) **(required)** - The namespace of the virtual machine\n\n</details>\n\n<details>\n\n<summary>helm</summary>\n\n- **helm_install** - Install a Helm chart in the current or provided namespace\n  - `chart` (`string`) **(required)** - Chart reference to install (for example: stable/grafana, oci://ghcr.io/nginxinc/charts/nginx-ingress)\n  - `name` (`string`) - Name of the Helm release (Optional, random name if not provided)\n  - `namespace` (`string`) - Namespace to install the Helm chart in (Optional, current namespace if not provided)\n  - `values` (`object`) - Values to pass to the Helm chart (Optional)\n\n- **helm_list** - List all the Helm releases in the current or provided namespace (or in all namespaces if specified)\n  - `all_namespaces` (`boolean`) - If true, lists all Helm releases in all namespaces ignoring the namespace argument (Optional)\n  - `namespace` (`string`) - Namespace to list Helm releases from (Optional, all namespaces if not provided)\n\n- **helm_uninstall** - Uninstall a Helm release in the current or provided namespace\n  - `name` (`string`) **(required)** - Name of the Helm release to uninstall\n  - `namespace` (`string`) - Namespace to uninstall the Helm release from (Optional, current namespace if not provided)\n\n</details>\n\n\n<!-- AVAILABLE-TOOLSETS-TOOLS-END -->\n\n## Helm Chart\n\nA [Helm Chart](https://helm.sh) is available to simplify the deployment of the Kubernetes MCP server. Additional details can be found in the [chart README](./charts/kubernetes-mcp-server/README.md).\n\n## ğŸ§‘â€ğŸ’» Development <a id=\"development\"></a>\n\n### Running with mcp-inspector\n\nCompile the project and run the Kubernetes MCP server with [mcp-inspector](https://modelcontextprotocol.io/docs/tools/inspector) to inspect the MCP server.\n\n```shell\n# Compile the project\nmake build\n# Run the Kubernetes MCP server with mcp-inspector\nnpx @modelcontextprotocol/inspector@latest $(pwd)/kubernetes-mcp-server\n```\n\n---\n\nmcp-name: io.github.containers/kubernetes-mcp-server",
      "stars_today": 10
    },
    {
      "id": 4151993,
      "name": "openvpn",
      "full_name": "OpenVPN/openvpn",
      "description": "OpenVPN  is  an open source VPN daemon",
      "html_url": "https://github.com/OpenVPN/openvpn",
      "stars": 13083,
      "forks": 3243,
      "language": "C",
      "topics": [
        "security",
        "vpn"
      ],
      "created_at": "2012-04-26T20:42:48Z",
      "updated_at": "2026-01-15T22:42:15Z",
      "pushed_at": "2026-01-15T22:29:41Z",
      "open_issues": 200,
      "owner": {
        "login": "OpenVPN",
        "avatar_url": "https://avatars.githubusercontent.com/u/1569141?v=4"
      },
      "readme": "OpenVPN -- A Secure tunneling daemon\n\nCopyright (C) 2002-2022 OpenVPN Inc. This program is free software;\nyou can redistribute it and/or modify\nit under the terms of the GNU General Public License version 2\nas published by the Free Software Foundation.\n\n*************************************************************************\n\nTo get the latest release of OpenVPN, go to:\n\n\thttps://openvpn.net/community-downloads/\n\nTo Build and Install,\n\n\ttar -zxf openvpn-<version>.tar.gz\n\tcd openvpn-<version>\n\t./configure\n\tmake\n\tmake install\n\nor see the file INSTALL for more info.\n\nFor information on how to build OpenVPN on/for Windows with MinGW\nor MSVC see README.cmake.md.\n\n*************************************************************************\n\nFor detailed information on OpenVPN, including examples, see the man page\n  http://openvpn.net/man.html\n\nFor a sample VPN configuration, see\n  http://openvpn.net/howto.html\n\nTo report an issue, see\n  https://github.com/OpenVPN/openvpn/issues/new\n\nFor a description of OpenVPN's underlying protocol,\n  see the file ssl.h included in the source distribution.\n\n*************************************************************************\n\nOther Files & Directories:\n\n* configure.ac -- script to rebuild our configure\n  script and makefile.\n\n* sample/sample-scripts/verify-cn\n\n  A sample perl script which can be used with OpenVPN's\n  --tls-verify option to provide a customized authentication\n  test on embedded X509 certificate fields.\n\n* sample/sample-keys/\n\n  Sample RSA keys and certificates.  DON'T USE THESE FILES\n  FOR ANYTHING OTHER THAN TESTING BECAUSE THEY ARE TOTALLY INSECURE.\n\n* sample/sample-config-files/\n\n  A collection of OpenVPN config files and scripts from\n  the HOWTO at http://openvpn.net/howto.html\n\n*************************************************************************\n\nNote that easy-rsa and tap-windows are now maintained in their own subprojects.\nTheir source code is available here:\n\n  https://github.com/OpenVPN/easy-rsa\n  https://github.com/OpenVPN/tap-windows6\n\nCommunity-provided Windows installers (MSI) and Debian packages are built from\n\n  https://github.com/OpenVPN/openvpn-build\n\nSee the INSTALL file for usage information.\n",
      "stars_today": 9
    },
    {
      "id": 693187866,
      "name": "rolldown",
      "full_name": "rolldown/rolldown",
      "description": "Fast Rust bundler for JavaScript/TypeScript with Rollup-compatible API.",
      "html_url": "https://github.com/rolldown/rolldown",
      "stars": 12638,
      "forks": 683,
      "language": "Rust",
      "topics": [
        "bundler",
        "javascript",
        "typescript"
      ],
      "created_at": "2023-09-18T14:20:28Z",
      "updated_at": "2026-01-15T20:49:17Z",
      "pushed_at": "2026-01-15T19:09:40Z",
      "open_issues": 232,
      "owner": {
        "login": "rolldown",
        "avatar_url": "https://avatars.githubusercontent.com/u/94954945?v=4"
      },
      "readme": "<p align=\"center\">\n  <br>\n  <br>\n  <a href=\"https://rolldown.rs\" target=\"_blank\" rel=\"noopener noreferrer\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://rolldown.rs/rolldown-light.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://rolldown.rs/rolldown-dark.svg\">\n      <img alt=\"rolldown logo\" src=\"https://rolldown.rs/rolldown-dark.svg\" height=\"60\">\n    </picture>\n  </a>\n  <br>\n  <br>\n  <br>\n</p>\n\n<div align=\"center\">\n\n[![MIT licensed][badge-license]][url-license]\n[![NPM version][badge-npm-version]][url-npm]\n[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/rolldown/rolldown)\n[![Discord chat][badge-discord]][discord-url]\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/rolldown/rolldown)\n\n</div>\n\n<div align=\"center\">\n\n[![NPM Unpacked Size (with version)](https://img.shields.io/npm/unpacked-size/rolldown/latest?label=npm)][url-npm]\n[![NPM Unpacked Size darwin-arm64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest?label=darwin-arm64)](https://www.npmjs.com/package/@rolldown/binding-darwin-arm64)\n[![NPM Unpacked Size darwin-x64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-x64/latest?label=darwin-x64)](https://www.npmjs.com/package/@rolldown/binding-darwin-x64)\n[![NPM Unpacked Size linux-x64-gnu](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-linux-x64-gnu/latest?label=linux-x64-gnu)](https://www.npmjs.com/package/@rolldown/binding-linux-x64-gnu)\n[![NPM Unpacked Size win32-x64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest?label=win32-x64)](https://www.npmjs.com/package/@rolldown/binding-win32-x64-msvc)\n[![NPM Unpacked Size wasm32-wasi](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-wasm32-wasi/latest?label=wasm32-wasi)](https://www.npmjs.com/package/@rolldown/binding-wasm32-wasi)\n\n</div>\n\n<div align=\"center\">\n\n[![pkg.pr.new](https://pkg.pr.new/badge/pkg.pr.new/pkg.pr.new?style=flat&color=000&logoSize=auto)](https://pkg.pr.new/~/rolldown/rolldown)\n\n</div>\n\n<div align=\"center\">\n\n[![rolldown-starter-stackblitz](https://developer.stackblitz.com/img/open_in_stackblitz.svg)](https://stackblitz.com/fork/github/rolldown/rolldown-starter-stackblitz)\n\n</div>\n\n> ğŸš§ **Beta Software**\n>\n> Rolldown is currently in beta status. While it can already handle most production use cases, there may still be bugs and rough edges. Most notably, the built-in minification feature is still in alpha status.\n\n# Rolldown\n\nRolldown is a JavaScript/TypeScript bundler written in Rust intended to serve as the future bundler used in [Vite](https://vitejs.dev/). It provides Rollup-compatible APIs and plugin interface, but will be more similar to esbuild in scope.\n\nFor more information, please check out the documentation at [rolldown.rs](https://rolldown.rs/guide/getting-started).\n\n## VoidZero Inc.\n\nRolldown is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/posts/announcing-voidzero-inc).\n\nIf you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!\n\n## Contributing\n\nWe would love to have more contributors involved!\n\nTo get started, please read our [Contributing Guide](https://rolldown.rs/contribution-guide/).\n\n## Credits\n\nThe Rolldown project is heavily inspired by:\n\n- [Rollup](https://github.com/rollup/rollup), created by [Rich Harris](https://github.com/Rich-Harris) and maintained by [Lukas Taegert-Atkinson](https://github.com/lukastaegert).\n- [esbuild](https://github.com/evanw/esbuild), created by [Evan Wallace](https://github.com/evanw).\n\nAnd supported by:\n\n- [napi-rs](https://github.com/napi-rs/napi-rs) for Node.js add-ons in Rust via Node-API.\n- [oxc](https://github.com/oxc-project/oxc) for the underlying parser, resolver, and sourcemap support.\n\n## Licenses\n\nThis project is licensed under the [MIT License](LICENSE).\n\nThis project also partially contains code derived or copied from the following projects:\n\n- [rollup(MIT)](https://github.com/rollup/rollup/blob/680912e2ceb42c8d5e571e01c6ece0e4889aecbb/LICENSE-CORE.md)\n- [esbuild(MIT)](https://github.com/evanw/esbuild/blob/0c8a0a901d9a6c7bbff9b4dd347c8a3f65f6c6dd/LICENSE.md)\n\nLicenses of these projects are listed in [THIRD-PARTY-LICENSE](/THIRD-PARTY-LICENSE)\n\n[badge-discord]: https://img.shields.io/discord/1079625926024900739?logo=discord&label=Discord\n[discord-url]: https://chat.rolldown.rs\n[badge-license]: https://img.shields.io/badge/license-MIT-blue.svg\n[url-license]: https://github.com/rolldown/rolldown/blob/main/LICENSE\n[badge-npm-version]: https://img.shields.io/npm/v/rolldown/latest?color=brightgreen\n[url-npm]: https://www.npmjs.com/package/rolldown/v/latest\n\n[badge-binary-size-windows]: [https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest]\n[badge-binary-size-macos]: [https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest]\n",
      "stars_today": 9
    },
    {
      "id": 334274271,
      "name": "OpenSearch",
      "full_name": "opensearch-project/OpenSearch",
      "description": "ğŸ” Open source distributed and RESTful search engine.",
      "html_url": "https://github.com/opensearch-project/OpenSearch",
      "stars": 12214,
      "forks": 2374,
      "language": "Java",
      "topics": [
        "analytics",
        "apache2",
        "foss",
        "java",
        "search",
        "search-engine"
      ],
      "created_at": "2021-01-29T22:10:00Z",
      "updated_at": "2026-01-15T21:11:56Z",
      "pushed_at": "2026-01-15T20:43:48Z",
      "open_issues": 2528,
      "owner": {
        "login": "opensearch-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/80134844?v=4"
      },
      "readme": "<a href=\"https://opensearch.org/\">\n  <img src=\"https://opensearch.org/assets/img/opensearch-logo-themed.svg\" height=\"64px\">\n</a>\n\n[![License](https://img.shields.io/badge/license-Apache%20v2-blue.svg)](https://github.com/opensearch-project/OpenSearch/blob/main/LICENSE.txt)\n[![LFX Health Score](https://insights.linuxfoundation.org/api/badge/health-score?project=opensearch-foundation)](https://insights.linuxfoundation.org/project/opensearch-foundation)\n[![LFX Active Contributors](https://insights.linuxfoundation.org/api/badge/active-contributors?project=opensearch-foundation)](https://insights.linuxfoundation.org/project/opensearch-foundation)\n[![Code Coverage](https://codecov.io/gh/opensearch-project/OpenSearch/branch/main/graph/badge.svg)](https://codecov.io/gh/opensearch-project/OpenSearch)\n![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/opensearch-project/OpenSearch?sort=semver)\n[![Linkedin](https://img.shields.io/badge/Follow-Linkedin-blue)](https://www.linkedin.com/company/opensearch-project)\n\n- [Welcome!](#welcome)\n- [Project Resources](#project-resources)\n- [Code of Conduct](#code-of-conduct)\n- [Security](#security)\n- [License](#license)\n- [Copyright](#copyright)\n- [Trademark](#trademark)\n\n## Welcome!\n\nOpenSearch is an open-source, enterprise-grade search and observability suite that brings order to unstructured data at scale.\n\n## Project Resources\n\n* [Project Website](https://opensearch.org/)\n* [Downloads](https://opensearch.org/downloads/)\n* [Documentation](https://docs.opensearch.org/)\n* Need help? Try [Forums](https://discuss.opendistrocommunity.dev/) or [Slack](https://opensearch.org/slack/)\n* [Contributing to OpenSearch](CONTRIBUTING.md)\n* [Maintainer Responsibilities](MAINTAINERS.md)\n* [Release Management](RELEASING.md)\n* [Admin Responsibilities](ADMINS.md)\n* [Testing](TESTING.md)\n* [Security](SECURITY.md)\n\n## Code of Conduct\n\nThe project's [Code of Conduct](CODE_OF_CONDUCT.md) outlines our expectations for all participants in our community, based on the [OpenSearch Code of Conduct](https://opensearch.org/code-of-conduct/). Please contact [conduct@opensearch.foundation](mailto:conduct@opensearch.foundation) with any additional questions or comments.\n\n## Security\nIf you discover a potential security issue in this project we ask that you notify OpenSearch Security directly via email to security@opensearch.org. Please do **not** create a public GitHub issue.\n\n## License\n\nThis project is licensed under the [Apache v2.0 License](LICENSE.txt).\n\n## Copyright\n\nCopyright OpenSearch Contributors. See [NOTICE](NOTICE.txt) for details.\n\n## Trademark\n\nOpenSearch is a registered trademark of LF Projects, LLC.\n\nOpenSearch includes certain Apache-licensed Elasticsearch code from Elasticsearch B.V. and other source code. Elasticsearch B.V. is not the source of that other source code. ELASTICSEARCH is a registered trademark of Elasticsearch B.V.\n\n",
      "stars_today": 8
    },
    {
      "id": 57452143,
      "name": "android",
      "full_name": "bitwarden/android",
      "description": "Bitwarden mobile apps (Password Manager and Authenticator) for Android.",
      "html_url": "https://github.com/bitwarden/android",
      "stars": 8267,
      "forks": 930,
      "language": "Kotlin",
      "topics": [
        "android",
        "bitwarden",
        "compose",
        "jetpack",
        "kotlin"
      ],
      "created_at": "2016-04-30T16:43:17Z",
      "updated_at": "2026-01-16T01:04:03Z",
      "pushed_at": "2026-01-15T21:42:41Z",
      "open_issues": 145,
      "owner": {
        "login": "bitwarden",
        "avatar_url": "https://avatars.githubusercontent.com/u/15990069?v=4"
      },
      "readme": "# Bitwarden Android\n\n## Contents\n\n- [Compatibility](#compatibility)\n- [Setup](#setup)\n- [Dependencies](#dependencies)\n\n## Compatibility\n\n- **Minimum SDK**: 29 (Android 10)\n- **Target SDK**: 36 (Android 16)\n- **Device Types Supported**: Phone and Tablet\n- **Orientations Supported**: Portrait and Landscape\n\n## Setup\n\n1. Clone the repository:\n\n    ```sh\n    $ git clone https://github.com/bitwarden/android\n    ```\n\n2. Create a `user.properties` file in the root directory of the project and add the following properties:\n\n    - `gitHubToken`: A \"classic\" Github Personal Access Token (PAT) with the `read:packages` scope (ex: `gitHubToken=gph_xx...xx`). These can be generated by going to the [Github tokens page](https://github.com/settings/tokens). See [the Github Packages user documentation concerning authentication](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-gradle-registry#authenticating-to-github-packages) for more details.\n    - `localSdk`: A boolean value to determine if the SDK should be loaded from the local maven artifactory (ex: `localSdk=true`). This is particularly useful when developing new SDK capabilities. Review [Linking SDK to clients](https://contributing.bitwarden.com/getting-started/sdk/#linking-the-sdk-to-clients) for more details.\n\n3. Setup the code style formatter:\n\n    All code must follow the guidelines described in the [Code Style Guidelines document](docs/STYLE_AND_BEST_PRACTICES.md). To aid in adhering to these rules, all contributors should apply `docs/bitwarden-style.xml` as their code style scheme. In IntelliJ / Android Studio:\n\n    - Navigate to `Preferences > Editor > Code Style`.\n    - Hit the `Manage` button next to `Scheme`.\n    - Select `Import`.\n    - Find the `bitwarden-style.xml` file in the project's `docs/` directory.\n    - Import \"from\" `BitwardenStyle` \"to\" `BitwardenStyle`.\n    - Hit `Apply` and `OK` to save the changes and exit Preferences.\n\n    Note that in some cases you may need to restart Android Studio for the changes to take effect.\n\n    All code should be formatted before submitting a pull request. This can be done manually but it can also be helpful to create a macro with a custom keyboard binding to auto-format when saving. In Android Studio on OS X:\n\n    - Select `Edit > Macros > Start Macro Recording`\n    - Select `Code > Optimize Imports`\n    - Select `Code > Reformat Code`\n    - Select `File > Save All`\n    - Select `Edit > Macros > Stop Macro Recording`\n\n    This can then be mapped to a set of keys by navigating to `Android Studio > Preferences` and editing the macro under `Keymap` (ex : shift + command + s).\n\n    Please avoid mixing formatting and logical changes in the same commit/PR. When possible, fix any large formatting issues in a separate PR before opening one to make logical changes to the same code. This helps others focus on the meaningful code changes when reviewing the code.\n\n4. Setup JDK `Version` `21`:\n\n    - Navigate to `Preferences > Build, Execution, Deployment > Build Tools > Gradle`.\n    - Hit the selected Gradle JDK next to `Gradle JDK:`.\n    - Select a `21.x` version or hit `Download JDK...` if not present.\n    - Select `Version` `21`.\n    - Select your preferred `Vendor`.\n    - Hit `Download`.\n    - Hit `Apply`.\n\n5. Setup `detekt` pre-commit hook (optional):\n\nRun the following script from the root of the repository to install the hook. This will overwrite any existing pre-commit hook if present.\n\n```shell\necho \"Writing detekt pre-commit hook...\"\ncat << 'EOL' > .git/hooks/pre-commit\n#!/usr/bin/env bash\n\necho \"Running detekt check...\"\nOUTPUT=\"/tmp/detekt-$(date +%s)\"\n./gradlew -Pprecommit=true detekt > $OUTPUT\nEXIT_CODE=$?\nif [ $EXIT_CODE -ne 0 ]; then\n  cat $OUTPUT\n  rm $OUTPUT\n  echo \"***********************************************\"\n  echo \"                 detekt failed                 \"\n  echo \" Please fix the above issues before committing \"\n  echo \"***********************************************\"\n  exit $EXIT_CODE\nfi\nrm $OUTPUT\nEOL\necho \"detekt pre-commit hook written to .git/hooks/pre-commit\"\necho \"Making the hook executable\"\nchmod +x .git/hooks/pre-commit\n\necho \"detekt pre-commit hook installed successfully to .git/hooks/pre-commit\"\n```\n\n## Dependencies\n\n### Application Dependencies\n\nThe following is a list of all third-party dependencies included as part of the application beyond the standard Android SDK.\n\n- **AndroidX Activity**\n    - https://developer.android.com/jetpack/androidx/releases/activity\n    - Purpose: Allows access composable APIs built on top of Activity.\n    - License: Apache 2.0\n\n- **AndroidX Appcompat**\n    - https://developer.android.com/jetpack/androidx/releases/appcompat\n    - Purpose: Allows access to new APIs on older API versions.\n    - License: Apache 2.0\n\n- **AndroidX Autofill**\n    - https://developer.android.com/jetpack/androidx/releases/autofill\n    - Purpose: Allows access to tools for building inline autofill UI.\n    - License: Apache 2.0\n\n- **AndroidX Biometrics**\n    - https://developer.android.com/jetpack/androidx/releases/biometric\n    - Purpose: Authenticate with biometrics or device credentials.\n    - License: Apache 2.0\n\n- **AndroidX Browser**\n    - https://developer.android.com/jetpack/androidx/releases/browser\n    - Purpose: Displays webpages with the user's default browser.\n    - License: Apache 2.0\n\n- **AndroidX Camera**\n    - https://developer.android.com/jetpack/androidx/releases/camera\n    - Purpose: Display and capture images for barcode scanning.\n    - License: Apache 2.0\n\n- **AndroidX Compose**\n    - https://developer.android.com/jetpack/androidx/releases/compose\n    - Purpose: A Kotlin-based declarative UI framework.\n    - License: Apache 2.0\n\n- **AndroidX Core**\n    - https://developer.android.com/jetpack/androidx/releases/core\n    - Purpose: Backwards compatible platform features and APIs.\n    - License: Apache 2.0\n\n- **AndroidX Credentials**\n    - https://developer.android.com/jetpack/androidx/releases/credentials\n    - Purpose: Unified access to user's credentials.\n    - License: Apache 2.0\n\n- **AndroidX Lifecycle**\n    - https://developer.android.com/jetpack/androidx/releases/lifecycle\n    - Purpose: Lifecycle aware components and tooling.\n    - License: Apache 2.0\n\n- **AndroidX Navigation**\n    - https://developer.android.com/jetpack/androidx/releases/navigation\n    - Purpose: Provides a consistent API for navigating between Android components.\n    - License: Apache 2.0\n\n- **AndroidX Room**\n    - https://developer.android.com/jetpack/androidx/releases/room\n    - Purpose: A convenient SQLite-based persistence layer for Android.\n    - License: Apache 2.0\n\n- **AndroidX Security**\n    - https://developer.android.com/jetpack/androidx/releases/security\n    - Purpose: Safely manage keys and encrypt files and sharedpreferences.\n    - License: Apache 2.0\n\n- **AndroidX WorkManager**\n    - https://developer.android.com/jetpack/androidx/releases/work\n    - Purpose: The WorkManager is used to schedule deferrable, asynchronous tasks that must be run reliably.\n    - License: Apache 2.0\n\n- **Dagger Hilt**\n    - https://github.com/google/dagger\n    - Purpose: Dependency injection framework.\n    - License: Apache 2.0\n\n- **Glide**\n    - https://github.com/bumptech/glide\n    - Purpose: Image loading and caching.\n    - License: BSD, part MIT and Apache 2.0\n\n- **kotlinx.collections.immutable**\n    - https://github.com/Kotlin/kotlinx.collections.immutable\n    - Purpose: Immutable collection interfaces and implementation prototypes for Kotlin.\n    - License: Apache 2.0\n\n- **kotlinx.coroutines**\n    - https://github.com/Kotlin/kotlinx.coroutines\n    - Purpose: Kotlin coroutines library for asynchronous and reactive code.\n    - License: Apache 2.0\n\n- **kotlinx.serialization**\n    - https://github.com/Kotlin/kotlinx.serialization/\n    - Purpose: JSON serialization library for Kotlin.\n    - License: Apache 2.0\n\n- **OkHttp 3**\n    - https://github.com/square/okhttp\n    - Purpose: An HTTP client used by the library to intercept and log traffic.\n    - License: Apache 2.0\n\n- **Retrofit 2**\n    - https://github.com/square/retrofit\n    - Purpose: A networking layer interface.\n    - License: Apache 2.0\n\n- **Timber**\n    - https://github.com/JakeWharton/timber\n    - Purpose: Extensible logging library for Android.\n    - License: Apache 2.0\n\n- **ZXing**\n    - https://github.com/zxing/zxing\n    - Purpose: Barcode scanning and generation.\n    - License: Apache 2.0\n\nThe following is an additional list of third-party dependencies that are only included in the non-F-Droid build variants of the application.\n\n- **Firebase Cloud Messaging**\n    - https://github.com/firebase/firebase-android-sdk\n    - Purpose: Allows for push notification support.\n    - License: Apache 2.0\n\n- **Firebase Crashlytics**\n    - https://github.com/firebase/firebase-android-sdk\n    - Purpose: SDK for crash and non-fatal error reporting.\n    - License: Apache 2.0\n\n- **Google Play Reviews**\n    - https://developer.android.com/reference/com/google/android/play/core/release-notes\n    - Purpose: On standard builds provide an interface to add a review for the password manager application in Google Play.\n    - License: Apache 2.0\n\n### Development Environment Dependencies\n\nThe following is a list of additional third-party dependencies used as part of the local development environment. This includes test-related artifacts as well as tools related to code quality and linting. These are not present in the final packaged application.\n\n- **detekt**\n    - https://github.com/detekt/detekt\n    - Purpose: A static code analysis tool for the Kotlin programming language.\n    - License: Apache 2.0\n\n- **JUnit 5**\n    - https://github.com/junit-team/junit5\n    - Purpose: Unit Testing framework for testing application code.\n    - License: Eclipse Public License 2.0\n\n- **MockK**\n    - https://github.com/mockk/mockk\n    - Purpose: Kotlin-friendly mocking library.\n    - License: Apache 2.0\n\n- **Robolectric**\n    - https://github.com/robolectric/robolectric\n    - Purpose: A unit testing framework for code directly depending on the Android framework.\n    - License: MIT\n\n- **Turbine**\n    - https://github.com/cashapp/turbine\n    - Purpose: A small testing library for kotlinx.coroutine's Flow.\n    - License: Apache 2.0\n\n### CI/CD Dependencies\n\nThe following is a list of additional third-party dependencies used as part of the CI/CD workflows. These are not present in the final packaged application.\n\n- **Fastlane**\n    - https://fastlane.tools/\n    - Purpose: Automates building, signing, and distributing applications.\n    - License: MIT\n\n- **Kover**\n    - https://github.com/Kotlin/kotlinx-kover\n    - Purpose: Kotlin code coverage toolset.\n    - License: Apache 2.0\n",
      "stars_today": 8
    },
    {
      "id": 535010087,
      "name": "arnis",
      "full_name": "louis-e/arnis",
      "description": "Generate any location from the real world in Minecraft with a high level of detail.",
      "html_url": "https://github.com/louis-e/arnis",
      "stars": 8182,
      "forks": 762,
      "language": "Rust",
      "topics": [
        "maps",
        "minecraft",
        "openstreetmap",
        "osm",
        "overpass-api",
        "rust",
        "tauri"
      ],
      "created_at": "2022-09-10T13:42:29Z",
      "updated_at": "2026-01-15T22:49:21Z",
      "pushed_at": "2026-01-11T13:38:27Z",
      "open_issues": 73,
      "owner": {
        "login": "louis-e",
        "avatar_url": "https://avatars.githubusercontent.com/u/44675238?v=4"
      },
      "readme": "<img src=\"assets/git/banner.png\" width=\"100%\" alt=\"Banner\">\n\n# Arnis [![CI Build Status](https://github.com/louis-e/arnis/actions/workflows/ci-build.yml/badge.svg)](https://github.com/louis-e/arnis/actions) [<img alt=\"GitHub Release\" src=\"https://img.shields.io/github/v/release/louis-e/arnis\" />](https://github.com/louis-e/arnis/releases) [<img alt=\"GitHub Downloads (all assets, all releases\" src=\"https://img.shields.io/github/downloads/louis-e/arnis/total\" />](https://github.com/louis-e/arnis/releases) [![Download here](https://img.shields.io/badge/Download-here-green)](https://github.com/louis-e/arnis/releases) [![Discord](https://img.shields.io/discord/1326192999738249267?label=Discord&color=%237289da)](https://discord.gg/mA2g69Fhxq)\n\nArnis creates complex and accurate Minecraft Java Edition (1.17+) and Bedrock Edition worlds that reflect real-world geography, topography, and architecture.\n\nThis free and open source project is designed to handle large-scale geographic data from the real world and generate detailed Minecraft worlds. The algorithm processes geospatial data from OpenStreetMap as well as elevation data to create an accurate Minecraft representation of terrain and architecture.\nGenerate your hometown, big cities, and natural landscapes with ease!\n\n![Minecraft Preview](assets/git/preview.jpg)\n<i>This Github page and [arnismc.com](https://arnismc.com) are the only official project websites. Do not download Arnis from any other website.</i>\n\n## :keyboard: Usage\n<img width=\"60%\" src=\"assets/git/gui.png\"><br>\nDownload the [latest release](https://github.com/louis-e/arnis/releases/) or [compile](#trophy-open-source) the project on your own.\n\nChoose your area on the map using the rectangle tool and select your Minecraft world - then simply click on <i>Start Generation</i>!\nAdditionally, you can customize various generation settings, such as world scale, spawn point, or building interior generation.\n\n## ğŸ“š Documentation\n\n<img src=\"assets/git/documentation.png\" width=\"100%\" alt=\"Banner\">\n\nFull documentation is available in the [GitHub Wiki](https://github.com/louis-e/arnis/wiki/), covering topics such as technical explanations, FAQs, contribution guidelines and roadmaps.\n\n## :trophy: Open Source\n#### Key objectives of this project\n- **Modularity**: Ensure that all components (e.g., data fetching, processing, and world generation) are cleanly separated into distinct modules for better maintainability and scalability.\n- **Performance Optimization**: We aim to keep a good performance and speed of the world generation process.\n- **Comprehensive Documentation**: Detailed in-code documentation for a clear structure and logic.\n- **User-Friendly Experience**: Focus on making the project easy to use for end users.\n- **Cross-Platform Support**: We want this project to run smoothly on Windows, macOS, and Linux.\n\n#### How to contribute\nThis project is open source and welcomes contributions from everyone! Whether you're interested in fixing bugs, improving performance, adding new features, or enhancing documentation, your input is valuable. Simply fork the repository, make your changes, and submit a pull request. Please respect the above mentioned key objectives. Contributions of all levels are appreciated, and your efforts help improve this tool for everyone.\n\nCommand line Build: ```cargo run --no-default-features -- --terrain --path=\"C:/YOUR_PATH/.minecraft/saves/worldname\" --bbox=\"min_lat,min_lng,max_lat,max_lng\"```<br>\nGUI Build: ```cargo run```<br>\n\nAfter your pull request was merged, I will take care of regularly creating update releases which will include your changes.\n\n## :star: Star History\n\n<a href=\"https://star-history.com/#louis-e/arnis&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=louis-e/arnis&Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=louis-e/arnis&Date&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=louis-e/arnis&Date&type=Date\" />\n </picture>\n</a>\n\n## :newspaper: Academic & Press Recognition\n\n<img src=\"assets/git/recognition.png\" width=\"100%\" alt=\"Banner\">\n\nArnis has been recognized in various academic and press publications after gaining a lot of attention in December 2024.\n\n[Floodcraft: Game-based Interactive Learning Environment using Minecraft for Flood Mitigation and Preparedness for K-12 Education](https://www.researchgate.net/publication/384644535_Floodcraft_Game-based_Interactive_Learning_Environment_using_Minecraft_for_Flood_Mitigation_and_Preparedness_for_K-12_Education)\n\n[Hackaday: Bringing OpenStreetMap Data into Minecraft](https://hackaday.com/2024/12/30/bringing-openstreetmap-data-into-minecraft/)\n\n[TomsHardware: Minecraft Tool Lets You Create Scale Replicas of Real-World Locations](https://www.tomshardware.com/video-games/pc-gaming/minecraft-tool-lets-you-create-scale-replicas-of-real-world-locations-arnis-uses-geospatial-data-from-openstreetmap-to-generate-minecraft-maps)\n\n[XDA Developers: Hometown Minecraft Map: Arnis](https://www.xda-developers.com/hometown-minecraft-map-arnis/)\n\nFree to use assets, including screenshots and logos, can be found [here](https://drive.google.com/file/d/1T1IsZSyT8oa6qAO_40hVF5KR8eEVCJjo/view?usp=sharing).\n\n## :copyright: License Information\nCopyright (c) 2022-2025 Louis Erbkamm (louis-e)\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.[^3]\n\nDownload Arnis only from the official source https://arnismc.com or https://github.com/louis-e/arnis/. Every other website providing a download and claiming to be affiliated with the project is unofficial and may be malicious.\n\nThe logo was made by @nxfx21.\n\n\n[^1]: https://en.wikipedia.org/wiki/OpenStreetMap\n\n[^2]: https://en.wikipedia.org/wiki/Arnis,_Germany\n\n[^3]: https://github.com/louis-e/arnis/blob/main/LICENSE\n",
      "stars_today": 8
    },
    {
      "id": 196353673,
      "name": "TDengine",
      "full_name": "taosdata/TDengine",
      "description": "High-performance, scalable time-series database designed for Industrial IoT (IIoT) scenarios",
      "html_url": "https://github.com/taosdata/TDengine",
      "stars": 24675,
      "forks": 4990,
      "language": "C",
      "topics": [
        "bigdata",
        "cloud-native",
        "cluster",
        "connected-vehicles",
        "database",
        "distributed",
        "financial-analysis",
        "industrial-iot",
        "iot",
        "metrics",
        "monitoring",
        "scalability",
        "sql",
        "tdengine",
        "time-series",
        "time-series-database",
        "tsdb"
      ],
      "created_at": "2019-07-11T08:33:48Z",
      "updated_at": "2026-01-15T15:20:53Z",
      "pushed_at": "2026-01-16T00:38:49Z",
      "open_issues": 474,
      "owner": {
        "login": "taosdata",
        "avatar_url": "https://avatars.githubusercontent.com/u/48876650?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://tdengine.com\" target=\"_blank\">\n  <img\n    src=\"docs/assets/tdengine.svg\"\n    alt=\"TDengine\"\n    width=\"500\"\n  />\n  </a>\n</p>\n\n[![TDengine Release Build](https://github.com/taosdata/TDengine/actions/workflows/tdengine-release-build.yml/badge.svg)](https://github.com/taosdata/TDengine/actions/workflows/tdengine-release-build.yml)\n[![Coverage Status](https://coveralls.io/repos/github/taosdata/TDengine/badge.svg?branch=3.0)](https://coveralls.io/github/taosdata/TDengine?branch=3.0)\n[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/taosdata/tdengine)](https://github.com/feici02/TDengine/commits/main/)\n<br />\n[![GitHub Release](https://img.shields.io/github/v/release/taosdata/tdengine)](https://github.com/taosdata/TDengine/releases)\n[![GitHub License](https://img.shields.io/github/license/taosdata/tdengine)](https://github.com/taosdata/TDengine/blob/main/LICENSE)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/4201/badge)](https://bestpractices.coreinfrastructure.org/projects/4201)\n<br />\n[![Twitter Follow](https://img.shields.io/twitter/follow/tdenginedb?label=TDengine&style=social)](https://twitter.com/tdenginedb)\n[![YouTube Channel](https://img.shields.io/badge/Subscribe_@tdengine--white?logo=youtube&style=social)](https://www.youtube.com/@tdengine)\n[![Discord Community](https://img.shields.io/badge/Join_Discord--white?logo=discord&style=social)](https://discord.com/invite/VZdSuUg4pS)\n[![LinkedIn](https://img.shields.io/badge/Follow_LinkedIn--white?logo=linkedin&style=social)](https://www.linkedin.com/company/tdengine)\n[![StackOverflow](https://img.shields.io/badge/Ask_StackOverflow--white?logo=stackoverflow&style=social&logoColor=orange)](https://stackoverflow.com/questions/tagged/tdengine)\n[![DeepWiki](https://img.shields.io/badge/Ask%20DeepWiki-white.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/taosdata/TDengine)\n\nEnglish | [ç®€ä½“ä¸­æ–‡](README-CN.md) | [TDengine Cloud](https://cloud.tdengine.com) | [Learn more about TSDB](https://tdengine.com/time-series-database/)\n\n# Table of Contents\n\n- [1. Introduction](#1-introduction)\n- [2. Documentation](#2-documentation)\n- [3. Prerequisites](#3-prerequisites)\n  - [3.1 Prerequisites on Linux](#31-prerequisites-on-linux)\n    - [3.1.1 For Ubuntu](#311-for-ubuntu)\n    - [3.1.2 For CentOS](#312-for-centos)\n  - [3.2 Prerequisites on macOS](#32-prerequisites-on-macos)\n  - [3.3 Prerequisites on Windows](#33-prerequisites-on-windows)\n  - [3.4 Clone the repo](#34-clone-the-repo)\n- [4. Building](#4-building)\n  - [4.1 Build on Linux](#41-build-on-linux)\n  - [4.2 Build on macOS](#42-build-on-macos)\n  - [4.3 Build on Windows](#43-build-on-windows)\n- [5. Packaging](#5-packaging)\n- [6. Installation](#6-installation)\n  - [6.1 Install on Linux](#61-install-on-linux)\n  - [6.2 Install on macOS](#62-install-on-macos)\n  - [6.3 Install on Windows](#63-install-on-windows)\n- [7. Running](#7-running)\n  - [7.1 Run TDengine on Linux](#71-run-tdengine-on-linux)\n  - [7.2 Run TDengine on macOS](#72-run-tdengine-on-macos)\n  - [7.3 Run TDengine on Windows](#73-run-tdengine-on-windows)\n- [8. Testing](#8-testing)\n- [9. Releasing](#9-releasing)\n- [10. Workflow](#10-workflow)\n- [11. Coverage](#11-coverage)\n- [12. Contributing](#12-contributing)\n\n# 1. Introduction\n\nTDengine is an open source, high-performance, cloud native and AI powered [time-series database](https://tdengine.com/tsdb/) designed for Internet of Things (IoT), Connected Cars, and Industrial IoT. It enables efficient, real-time data ingestion, processing, and analysis of TB and even PB scale data per day, generated by billions of sensors and data collectors. TDengine differentiates itself from other time-series databases with the following advantages:\n\n- **[High Performance](https://tdengine.com/tdengine/high-performance-time-series-database/)**: TDengine is the only time-series database to solve the high cardinality issue to support billions of data collection points while out performing other time-series databases for data ingestion, querying and data compression.\n\n- **[Simplified Solution](https://tdengine.com/tdengine/simplified-time-series-data-solution/)**: Through built-in caching, stream processing, data subscription and AI agent features, TDengine provides a simplified solution for time-series data processing. It reduces system design complexity and operation costs significantly.\n\n- **[Cloud Native](https://tdengine.com/tdengine/cloud-native-time-series-database/)**: Through native distributed design, sharding and partitioning, separation of compute and storage, RAFT, support for kubernetes deployment and full observability, TDengine is a cloud native Time-Series Database and can be deployed on public, private or hybrid clouds.\n\n- **[AI Powered](https://tdengine.com/tdengine/tdgpt/)**: Through the built in AI agent TDgpt, TDengine can connect to a variety of time series foundation model, large language model, machine learning and traditional algorithms to provide time series data forecasting, anomly detection, imputation and classification.\n\n- **[Ease of Use](https://tdengine.com/tdengine/easy-time-series-data-platform/)**: For administrators, TDengine significantly reduces the effort to deploy and maintain. For developers, it provides a simple interface, simplified solution and seamless integrations for third party tools. For data users, it gives easy data access.\n\n- **[Easy Data Analytics](https://tdengine.com/tdengine/time-series-data-analytics-made-easy/)**: Through super tables, storage and compute separation, data partitioning by time interval, pre-computation and AI agent, TDengine makes it easy to explore, format, and get access to data in a highly efficient way.\n\n- **[Open Source](https://tdengine.com/tdengine/open-source-time-series-database/)**: TDengineâ€™s core modules, including cluster feature and AI agent, are all available under open source licenses. It has gathered 23.7k stars on GitHub. There is an active developer community, and over 730k running instances worldwide.\n\nFor a full list of TDengine competitive advantages, please [check here](https://tdengine.com/tdengine/). The easiest way to experience TDengine is through [TDengine Cloud](https://cloud.tdengine.com). For the latest TDengine component TDgpt, please refer to [TDgpt README](./tools/tdgpt/README.md) for details.\n\n# 2. Documentation\n\nFor user manual, system design and architecture, please refer to [TDengine Documentation](https://docs.tdengine.com) ([TDengine æ–‡æ¡£](https://docs.taosdata.com))\n\nYou can choose to install TDengine via [container](https://docs.tdengine.com/get-started/deploy-in-docker/), [installation package](https://docs.tdengine.com/get-started/deploy-from-package/), [Kubernetes](https://docs.tdengine.com/operations-and-maintenance/deploy-your-cluster/#kubernetes-deployment) or try [fully managed service](https://cloud.tdengine.com/) without installation. This quick guide is for developers who want to contribute, build, release and test TDengine by themselves.\n\nFor contributing/building/testing TDengine Connectors, please check the following repositories: [JDBC Connector](https://github.com/taosdata/taos-connector-jdbc), [Go Connector](https://github.com/taosdata/driver-go), [Python Connector](https://github.com/taosdata/taos-connector-python), [Node.js Connector](https://github.com/taosdata/taos-connector-node), [C# Connector](https://github.com/taosdata/taos-connector-dotnet), [Rust Connector](https://github.com/taosdata/taos-connector-rust).\n\n# 3. Prerequisites\n\nAt the moment, TDengine server supports running on Linux/MacOS systems. Any application can also choose the RESTful interface provided by taosAdapter to connect the taosd service. TDengine supports X64/ARM64 CPU, and it will support MIPS64, Alpha64, ARM32, RISC-V and other CPU architectures in the future. Right now we don't support build with cross-compiling environment.\n\nStarting from version 3.1.0.0, TDengine supports the Windows system exclusively in its TSDB-Enterprise edition.\n\nIf you want to compile taosAdapter or taosKeeper, you need to install Go 1.23 or above.\n\n## 3.1 Prerequisites on Linux\n\n<details>\n\n<summary>Install required tools on Linux</summary>\n\n### 3.1.1 For Ubuntu\n\nVerified on Ubuntu 18.04, 20.04, 22.04.\n\n```bash\nsudo apt-get update\nsudo apt-get install -y gcc cmake build-essential git libjansson-dev \\\n  libsnappy-dev liblzma-dev zlib1g-dev pkg-config libtool autoconf automake groff\n```\n\n### 3.1.2 For CentOS\n\nVerified on CentOS 8.\n\n```bash\nsudo yum update\nyum install -y epel-release gcc gcc-c++ make cmake git perl dnf-plugins-core autoconf automake libtool groff\nyum config-manager --set-enabled powertools\nyum install -y zlib-static xz-devel snappy-devel jansson-devel pkgconfig libatomic-static libstdc++-static \n```\n\n</details>\n\n## 3.2 Prerequisites on macOS\n\n<details>\n\n<summary>Install required tools on macOS</summary>\n\nPlease install the dependencies with [brew](https://brew.sh/).\n\n```bash\nbrew install argp-standalone gflags pkgconfig\n```\n\n</details>\n\n## 3.3 Prerequisites on Windows\n\nNot available for TDengine TSDB-OSS.\n\n## 3.4 Clone the repo\n\nClone the repository to the target machine:\n\n```bash\ngit clone https://github.com/taosdata/TDengine.git\ncd TDengine\n```\n\n</details>\n\n# 4. Building\n\nTDengine provide a few useful tools such as taosBenchmark (was named taosdemo) and taosdump. They were part of TDengine. By default, TDengine compiling does not include taosTools. You can use `cmake .. -DBUILD_TOOLS=true` to make them be compiled with TDengine.\n\nTDengine requires [GCC](https://gcc.gnu.org/) 9.3.1 or higher and [CMake](https://cmake.org/) 3.18.0 or higher for building.\n\n## 4.1 Build on Linux\n\n<details>\n\n<summary>Detailed steps to build on Linux</summary>\n\nYou can run the bash script `build.sh` to build both TDengine and taosTools including taosBenchmark and taosdump as below:\n\n```bash\n./build.sh\n```\n\nIt equals to execute following commands:\n\n```bash\nmkdir debug && cd debug\ncmake .. -DBUILD_TOOLS=true -DBUILD_CONTRIB=true\nmake\n```\n\nIf you want to compile taosAdapter, you need to add the `-DBUILD_HTTP=false` option.\n\nIf you want to compile taosKeeper, you need to add the `-DBUILD_KEEPER=true` option.\n\nYou can use Jemalloc as memory allocator instead of glibc:\n\n```bash\ncmake .. -DJEMALLOC_ENABLED=ON\n```\n\nTDengine build script can auto-detect the host machine's architecture on x86, x86-64, arm64 platform.\nYou can also specify architecture manually by CPUTYPE option:\n\n```bash\ncmake .. -DCPUTYPE=aarch64 && cmake --build .\n```\n\n</details>\n\n## 4.2 Build on macOS\n\n<details>\n\n<summary>Detailed steps to build on macOS</summary>\n\nPlease install XCode command line tools and cmake. Verified with XCode 11.4+ on Catalina and Big Sur.\n\n```shell\nmkdir debug && cd debug\ncmake .. && cmake --build .\n```\n\nIf you want to compile taosAdapter, you need to add the `-DBUILD_HTTP=false` option.\n\nIf you want to compile taosKeeper, you need to add the `-DBUILD_KEEPER=true` option.\n\n</details>\n\n## 4.3 Build on Windows\n\nNot available for TDengine TSDB-OSS.\n\n# 5. Packaging\n\nThe TDengine TSDB-OSS installer can NOT be created by this repository only, due to some component dependencies. We are still working on this improvement.\n\n# 6. Installation\n\n## 6.1 Install on Linux\n\n<details>\n\n<summary>Detailed steps to install on Linux</summary>\n\nAfter building successfully, TDengine can be installed by:\n\n```bash\nsudo make install\n```\n\nInstalling from source code will also configure service management for TDengine. Users can also choose to [install from packages](https://docs.tdengine.com/get-started/deploy-from-package/) for it.\n\n</details>\n\n## 6.2 Install on macOS\n\n<details>\n\n<summary>Detailed steps to install on macOS</summary>\n\nAfter building successfully, TDengine can be installed by:\n\n```bash\nsudo make install\n```\n\n</details>\n\n## 6.3 Install on Windows\n\nNot available for TDengine TSDB-OSS.\n\n# 7. Running\n\n## 7.1 Run TDengine on Linux\n\n<details>\n\n<summary>Detailed steps to run on Linux</summary>\n\nTo start the service after installation on linux, in a terminal, use:\n\n```bash\nsudo systemctl start taosd\n```\n\nThen users can use the TDengine CLI to connect the TDengine server. In a terminal, use:\n\n```bash\ntaos\n```\n\nIf TDengine CLI connects the server successfully, welcome messages and version info are printed. Otherwise, an error message is shown.\n\nIf you don't want to run TDengine as a service, you can run it in current shell. For example, to quickly start a TDengine server after building, run the command below in terminal: (We take Linux as an example, command on Windows will be `taosd.exe`)\n\n```bash\n./build/bin/taosd -c test/cfg\n```\n\nIn another terminal, use the TDengine CLI to connect the server:\n\n```bash\n./build/bin/taos -c test/cfg\n```\n\nOption `-c test/cfg` specifies the system configuration file directory.\n\n</details>\n\n## 7.2 Run TDengine on macOS\n\n<details>\n\n<summary>Detailed steps to run on macOS</summary>\n\nTo start the service after installation on macOS, double-click the /applications/TDengine to start the program, or in a terminal, use:\n\n```bash\nsudo launchctl start com.tdengine.taosd\n```\n\nThen users can use the TDengine CLI to connect the TDengine server. In a terminal, use:\n\n```bash\ntaos\n```\n\nIf TDengine CLI connects the server successfully, welcome messages and version info are printed. Otherwise, an error message is shown.\n\n</details>\n\n## 7.3 Run TDengine on Windows\n\nNot available for TDengine TSDB-OSS.\n\n# 8. Testing\n\nFor how to run different types of tests on TDengine, please see [Testing TDengine](./tests/README.md).\n\n# 9. Releasing\n\nFor the complete list of TDengine Releases, please see [Releases](https://github.com/taosdata/TDengine/releases).\n\n# 10. Workflow\n\nTDengine build check workflow can be found in this [Github Action](https://github.com/taosdata/TDengine/actions/workflows/taosd-ci-build.yml). More workflows will be available soon.\n\n# 11. Coverage\n\nLatest TDengine test coverage report can be found on [coveralls.io](https://coveralls.io/github/taosdata/TDengine)\n\n<details>\n\n<summary>How to run the coverage report locally?</summary>\nTo create the test coverage report (in HTML format) locally, please run following commands:\n\n```bash\ncd tests\nbash setup-lcov.sh -v 1.16 && ./run_local_coverage.sh -b main -c task \n# on main branch and run cases in longtimeruning_cases.task \n# for more information about options please refer to ./run_local_coverage.sh -h\n```\n\n> **NOTE**:\n> Please note that the -b and -i options will recompile TDengine with the -DCOVER=true option, which may take a amount of time.\n\n</details>\n\n# 12. Contributing\n\nPlease follow the [contribution guidelines](CONTRIBUTING.md) to contribute to TDengine.\n",
      "stars_today": 7
    },
    {
      "id": 437245741,
      "name": "dragonfly",
      "full_name": "dragonflydb/dragonfly",
      "description": "A modern replacement for Redis and Memcached",
      "html_url": "https://github.com/dragonflydb/dragonfly",
      "stars": 29734,
      "forks": 1130,
      "language": "C++",
      "topics": [
        "cache",
        "cpp",
        "database",
        "fibers",
        "in-memory",
        "in-memory-database",
        "key-value",
        "keydb",
        "memcached",
        "message-broker",
        "multi-threading",
        "nosql",
        "redis",
        "valkey",
        "vector-search"
      ],
      "created_at": "2021-12-11T10:00:42Z",
      "updated_at": "2026-01-16T01:02:25Z",
      "pushed_at": "2026-01-15T20:30:00Z",
      "open_issues": 306,
      "owner": {
        "login": "dragonflydb",
        "avatar_url": "https://avatars.githubusercontent.com/u/104819355?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://dragonflydb.io\">\n    <img  src=\"/.github/images/logo-full.svg\"\n      width=\"284\" border=\"0\" alt=\"Dragonfly\">\n  </a>\n</p>\n\n[![ci-tests](https://github.com/dragonflydb/dragonfly/actions/workflows/ci.yml/badge.svg)](https://github.com/dragonflydb/dragonfly/actions/workflows/ci.yml) [![Twitter URL](https://img.shields.io/twitter/follow/dragonflydbio?style=social)](https://twitter.com/dragonflydbio)\n\n> Before moving on, please consider giving us a GitHub star â­ï¸. Thank you!\n\nOther languages:  [ç®€ä½“ä¸­æ–‡](README.zh-CN.md) [æ—¥æœ¬èª](README.ja-JP.md) [í•œêµ­ì–´](README.ko-KR.md) [PortuguÃªs](README.pt-BR.md)\n\n[Website](https://www.dragonflydb.io/) â€¢ [Docs](https://dragonflydb.io/docs) â€¢ [Quick Start](https://www.dragonflydb.io/docs/getting-started) â€¢ [Community Discord](https://discord.gg/HsPjXGVH85) â€¢ [Dragonfly Forum](https://dragonfly.discourse.group/) â€¢ [Join the Dragonfly Community](https://www.dragonflydb.io/community)\n\n[GitHub Discussions](https://github.com/dragonflydb/dragonfly/discussions) â€¢ [GitHub Issues](https://github.com/dragonflydb/dragonfly/issues) â€¢ [Contributing](https://github.com/dragonflydb/dragonfly/blob/main/CONTRIBUTING.md) â€¢ [AI Agents Guide](AGENTS.md) â€¢ [Dragonfly Cloud](https://www.dragonflydb.io/cloud)\n\n## The world's most efficient in-memory data store\n\nDragonfly is an in-memory data store built for modern application workloads.\n\nFully compatible with Redis and Memcached APIs, Dragonfly requires no code changes to adopt. Compared to legacy in-memory datastores, Dragonfly delivers 25X more throughput, higher cache hit rates with lower tail latency, and can run on up to 80% less resources for the same sized workload.\n\n## Contents\n\n- [Benchmarks](#benchmarks)\n- [Quick start](https://github.com/dragonflydb/dragonfly/tree/main/docs/quick-start)\n- [Configuration](#configuration)\n- [Roadmap and status](#roadmap-status)\n- [Design decisions](#design-decisions)\n- [Background](#background)\n- [Build from source](./docs/build-from-source.md)\n\n## <a name=\"benchmarks\"><a/>Benchmarks\n\nWe first compare Dragonfly with Redis on `m5.large` instance which is commonly used to run Redis\ndue to its single-threaded architecture. The benchmark program runs from another\nload-test instance (c5n) in the same AZ using `memtier_benchmark  -c 20 --test-time 100 -t 4 -d 256 --distinct-client-seed`\n\nDragonfly shows a comparable performance:\n\n1. SETs (`--ratio 1:0`):\n\n|  Redis                                   |      DF                                |\n| -----------------------------------------|----------------------------------------|\n| QPS: 159K, P99.9: 1.16ms, P99: 0.82ms    | QPS:173K, P99.9: 1.26ms, P99: 0.9ms    |\n|                                          |                                        |\n\n2. GETs (`--ratio 0:1`):\n\n|  Redis                                  |      DF                                |\n| ----------------------------------------|----------------------------------------|\n| QPS: 194K, P99.9: 0.8ms, P99: 0.65ms    | QPS: 191K, P99.9: 0.95ms, P99: 0.8ms   |\n\nThe benchmark above shows that the algorithmic layer inside DF that allows it to scale vertically\ndoes not take a large toll when running single-threaded.\n\nHowever, if we take a bit stronger instance (m5.xlarge), the gap between DF and Redis starts growing.\n(`memtier_benchmark  -c 20 --test-time 100 -t 6 -d 256 --distinct-client-seed`):\n1. SETs (`--ratio 1:0`):\n\n|  Redis                                  |      DF                                |\n| ----------------------------------------|----------------------------------------|\n| QPS: 190K, P99.9: 2.45ms, P99: 0.97ms   |  QPS: 279K , P99.9: 1.95ms, P99: 1.48ms|\n\n2. GETs (`--ratio 0:1`):\n\n|  Redis                                  |      DF                                |\n| ----------------------------------------|----------------------------------------|\n| QPS: 220K, P99.9: 0.98ms , P99: 0.8ms   |  QPS: 305K, P99.9: 1.03ms, P99: 0.87ms |\n\n\nDragonfly throughput capacity continues to grow with instance size,\nwhile single-threaded Redis is bottlenecked on CPU and reaches local maxima in terms of performance.\n\n<img src=\"http://static.dragonflydb.io/repo-assets/aws-throughput.svg\" width=\"80%\" border=\"0\"/>\n\nIf we compare Dragonfly and Redis on the most network-capable instance c6gn.16xlarge,\nDragonfly showed a 25X increase in throughput compared to Redis single process, crossing 3.8M QPS.\n\nDragonfly's 99th percentile latency metrics at its peak throughput:\n\n| op    | r6g   | c6gn  | c7g   |\n|-------|-------|-------|-------|\n| set   | 0.8ms | 1ms   | 1ms   |\n| get   | 0.9ms | 0.9ms | 0.8ms |\n| setex | 0.9ms | 1.1ms | 1.3ms |\n\n*All benchmarks were performed using `memtier_benchmark` (see below) with number of threads tuned per server and instance type. `memtier` was run on a separate c6gn.16xlarge machine. We set the expiry time to 500 for the SETEX benchmark to ensure it would survive the end of the test.*\n\n```bash\n  memtier_benchmark --ratio ... -t <threads> -c 30 -n 200000 --distinct-client-seed -d 256 \\\n     --expiry-range=...\n```\n\nIn pipeline mode `--pipeline=30`, Dragonfly reaches **10M QPS** for SET and **15M QPS** for GET operations.\n\n### Dragonfly vs. Memcached\n\nWe compared Dragonfly with Memcached on a c6gn.16xlarge instance on AWS.\n\nWith a comparable latency, Dragonfly throughput outperformed Memcached throughput in both write and read workloads. Dragonfly demonstrated better latency in write workloads due to contention on the [write path in Memcached](docs/memcached_benchmark.md).\n\n#### SET benchmark\n\n| Server    | QPS(thousands qps) | latency 99% | 99.9%   |\n|:---------:|:------------------:|:-----------:|:-------:|\n| Dragonfly |  ğŸŸ© 3844           |ğŸŸ© 0.9ms     | ğŸŸ© 2.4ms |\n| Memcached |   806              |   1.6ms     | 3.2ms    |\n\n#### GET benchmark\n\n| Server    | QPS(thousands qps) | latency 99% | 99.9%   |\n|-----------|:------------------:|:-----------:|:-------:|\n| Dragonfly | ğŸŸ© 3717            |   1ms       | 2.4ms   |\n| Memcached |   2100             |  ğŸŸ© 0.34ms  | ğŸŸ© 0.6ms |\n\n\nMemcached exhibited lower latency for the read benchmark, but also lower throughput.\n\n### Memory efficiency\n\nTo test memory efficiency, we filled Dragonfly and Redis with ~5GB of data using the `debug populate 5000000 key 1024` command, sent update traffic with `memtier`, and kicked off the snapshotting with the `bgsave` command.\n\nThis figure demonstrates how each server behaved in terms of memory efficiency.\n\n<img src=\"http://static.dragonflydb.io/repo-assets/bgsave-memusage.svg\" width=\"70%\" border=\"0\"/>\n\nDragonfly was 30% more memory efficient than Redis in the idle state and did not show any visible increase in memory use during the snapshot phase. At peak, Redis memory use increased to almost 3X that of Dragonfly.\n\nDragonfly finished the snapshot faster, within a few seconds.\n\nFor more info about memory efficiency in Dragonfly, see our [Dashtable doc](/docs/dashtable.md).\n\n\n\n## <a name=\"configuration\"><a/>Configuration\n\nDragonfly supports common Redis arguments where applicable. For example, you can run: `dragonfly --requirepass=foo --bind localhost`.\n\nDragonfly currently supports the following Redis-specific arguments:\n * `port`: Redis connection port (`default: 6379`).\n * `bind`: Use `localhost` to only allow localhost connections or a public IP address to allow connections **to that IP** address (i.e. from outside too). Use `0.0.0.0` to allow all IPv4.\n * `requirepass`: The password for AUTH authentication (`default: \"\"`).\n * `maxmemory`: Limit on maximum memory (in human-readable bytes) used by the database (`default: 0`). A `maxmemory` value of `0` means the program will automatically determine its maximum memory usage.\n * `dir`: Dragonfly Docker uses the `/data` folder for snapshotting by default, the CLI uses `\"\"`. You can use the `-v` Docker option to map it to your host folder.\n * `dbfilename`: The filename to save and load the database (`default: dump`).\n\nThere are also some Dragonfly-specific arguments:\n * `memcached_port`: The port to enable Memcached-compatible API on (`default: disabled`).\n * `keys_output_limit`: Maximum number of returned keys in `keys` command (`default: 8192`). Note that `keys` is a dangerous command. We truncate its result to avoid a blowup in memory use when fetching too many keys.\n * `dbnum`: Maximum number of supported databases for `select`.\n * `cache_mode`: See the [novel cache design](#novel-cache-design) section below.\n * `hz`: Key expiry evaluation frequency (`default: 100`). Lower frequency uses less CPU when idle at the expense of a slower eviction rate.\n * `snapshot_cron`: Cron schedule expression for automatic backup snapshots using standard cron syntax with the granularity of minutes (`default: \"\"`).\n   Here are some cron schedule expression examples below, and feel free to read more about this argument in our [documentation](https://www.dragonflydb.io/docs/managing-dragonfly/backups#the-snapshot_cron-flag).\n\n   | Cron Schedule Expression | Description                                |\n   |--------------------------|--------------------------------------------|\n   | `* * * * *`              | At every minute                            |\n   | `*/5 * * * *`            | At every 5th minute                        |\n   | `5 */2 * * *`            | At minute 5 past every 2nd hour            |\n   | `0 0 * * *`              | At 00:00 (midnight) every day              |\n   | `0 6 * * 1-5`            | At 06:00 (dawn) from Monday through Friday |\n\n * `primary_port_http_enabled`: Allows accessing HTTP console on main TCP port if `true` (`default: true`).\n * `admin_port`: To enable admin access to the console on the assigned port (`default: disabled`). Supports both HTTP and RESP protocols.\n * `admin_bind`: To bind the admin console TCP connection to a given address (`default: any`). Supports both HTTP and RESP protocols.\n * `admin_nopass`: To enable open admin access to console on the assigned port, without auth token needed (`default: false`). Supports both HTTP and RESP protocols.\n * `cluster_mode`: Cluster mode supported (`default: \"\"`). Currently supports only `emulated`.\n * `cluster_announce_ip`: The IP that cluster commands announce to the client.\n * `announce_port`: The port that cluster commands announce to the client, and to replication master.\n\n### Example start script with popular options:\n\n```bash\n./dragonfly-x86_64 --logtostderr --requirepass=youshallnotpass --cache_mode=true -dbnum 1 --bind localhost --port 6379 --maxmemory=12gb --keys_output_limit=12288 --dbfilename dump.rdb\n```\n\nArguments can be also provided via:\n * `--flagfile <filename>`: The file should list one flag per line, with equal signs instead of spaces for key-value flags. No quotes are needed for flag values.\n * Setting environment variables. Set `DFLY_x`, where `x` is the exact name of the flag, case sensitive.\n\nFor more options like logs management or TLS support, run `dragonfly --help`.\n\n## <a name=\"roadmap-status\"><a/>Roadmap and status\n\nDragonfly currently supports ~185 Redis commands and all Memcached commands besides `cas`. Almost on par with the Redis 5 API, Dragonfly's next milestone will be to stabilize basic functionality and implement the replication API. If there is a command you need that is not implemented yet, please open an issue.\n\nFor Dragonfly-native replication, we are designing a distributed log format that will support order-of-magnitude higher speeds.\n\nFollowing the replication feature, we will continue adding missing commands for Redis versions 3-6 APIs.\n\nPlease see our [Command Reference](https://dragonflydb.io/docs/category/command-reference) for the current commands supported by Dragonfly.\n\n## <a name=\"design-decisions\"><a/> Design decisions\n\n### Novel cache design\n\nDragonfly has a single, unified, adaptive caching algorithm that is simple and memory efficient.\n\nYou can enable caching mode by passing the `--cache_mode=true` flag. Once this mode is on, Dragonfly will evict items least likely to be stumbled upon in the future but only when it is near the `maxmemory` limit.\n\n### Expiration deadlines with relative accuracy\n\nExpiration ranges are limited to ~8 years.\n\nExpiration deadlines with millisecond precision (PEXPIRE, PSETEX, etc.) are rounded to the closest second **for deadlines greater than 2^28ms**, which has less than 0.001% error and should be acceptable for large ranges. If this is not suitable for your use case, get in touch or open an issue explaining your case.\n\nFor more detailed differences between Dragonfly expiration deadlines and Redis implementations, [see here](docs/differences.md).\n\n### Native HTTP console and Prometheus-compatible metrics\n\nBy default, Dragonfly allows HTTP access via its main TCP port (6379). That's right, you can connect to Dragonfly via Redis protocol and via HTTP protocol â€” the server recognizes the protocol automatically during the connection initiation. Go ahead and try it with your browser. HTTP access currently does not have much info but will include useful debugging and management info in the future.\n\nGo to the URL `:6379/metrics` to view Prometheus-compatible metrics.\n\nThe Prometheus exported metrics are compatible with the Grafana dashboard, [see here](tools/local/monitoring/grafana/provisioning/dashboards/dashboard.json).\n\n\nImportant! The HTTP console is meant to be accessed within a safe network. If you expose Dragonfly's TCP port externally, we advise you to disable the console with `--http_admin_console=false` or `--nohttp_admin_console`.\n\n\n## <a name=\"background\"><a/>Background\n\nDragonfly started as an experiment to see how an in-memory datastore could look if it was designed in 2022. Based on lessons learned from our experience as users of memory stores and engineers who worked for cloud companies, we knew that we need to preserve two key properties for Dragonfly: Atomicity guarantees for all operations and low, sub-millisecond latency over very high throughput.\n\nOur first challenge was how to fully utilize CPU, memory, and I/O resources using servers that are available today in public clouds. To solve this, we use [shared-nothing architecture](https://en.wikipedia.org/wiki/Shared-nothing_architecture), which allows us to partition the keyspace of the memory store between threads so that each thread can manage its own slice of dictionary data. We call these slices \"shards\". The library that powers thread and I/O management for shared-nothing architecture is open-sourced [here](https://github.com/romange/helio).\n\nTo provide atomicity guarantees for multi-key operations, we use the advancements from recent academic research. We chose the paper [\"VLL: a lock manager redesign for main memory database systemsâ€](https://www.cs.umd.edu/~abadi/papers/vldbj-vll.pdf) to develop the transactional framework for Dragonfly. The choice of shared-nothing architecture and VLL allowed us to compose atomic multi-key operations without using mutexes or spinlocks. This was a major milestone for our PoC and its performance stood out from other commercial and open-source solutions.\n\nOur second challenge was to engineer more efficient data structures for the new store. To achieve this goal, we based our core hashtable structure on the paper [\"Dash: Scalable Hashing on Persistent Memory\"](https://arxiv.org/pdf/2003.07302.pdf). The paper itself is centered around the persistent memory domain and is not directly related to main-memory stores, but it's still most applicable to our problem. The hashtable design suggested in the paper allowed us to maintain two special properties that are present in the Redis dictionary: The incremental hashing ability during datastore growth the ability to traverse the dictionary under changes using a stateless scan operation. In addition to these two properties, Dash is more efficient in CPU and memory use. By leveraging Dash's design, we were able to innovate further with the following features:\n * Efficient record expiry for TTL records.\n * A novel cache eviction algorithm that achieves higher hit rates than other caching strategies like LRU and LFU with **zero memory overhead**.\n * A novel **fork-less** snapshotting algorithm.\n\nOnce we had built the foundation for Dragonfly and [we were happy with its performance](#benchmarks), we went on to implement the Redis and Memcached functionality. We have to date implemented ~185 Redis commands (roughly equivalent to Redis 5.0 API) and 13 Memcached commands.\n\nAnd finally, <br>\n<em>Our mission is to build a well-designed, ultra-fast, cost-efficient in-memory datastore for cloud workloads that takes advantage of the latest hardware advancements. We intend to address the pain points of current solutions while preserving their product APIs and propositions.</em>\n",
      "stars_today": 7
    },
    {
      "id": 166515022,
      "name": "trino",
      "full_name": "trinodb/trino",
      "description": "Official repository of Trino, the distributed SQL query engine for big data, formerly known as PrestoSQL (https://trino.io)",
      "html_url": "https://github.com/trinodb/trino",
      "stars": 12420,
      "forks": 3449,
      "language": "Java",
      "topics": [
        "analytics",
        "big-data",
        "data-science",
        "database",
        "databases",
        "datalake",
        "delta-lake",
        "distributed-database",
        "distributed-systems",
        "hadoop",
        "hive",
        "iceberg",
        "java",
        "jdbc",
        "presto",
        "prestodb",
        "query-engine",
        "sql",
        "trino"
      ],
      "created_at": "2019-01-19T06:38:14Z",
      "updated_at": "2026-01-15T22:34:21Z",
      "pushed_at": "2026-01-15T22:34:14Z",
      "open_issues": 2505,
      "owner": {
        "login": "trinodb",
        "avatar_url": "https://avatars.githubusercontent.com/u/34147222?v=4"
      },
      "readme": "<p align=\"center\">\n    <a href=\"https://trino.io/\"><img alt=\"Trino Logo\" src=\".github/homepage.png\" /></a>\n</p>\n<p align=\"center\">\n    <b>Trino is a fast distributed SQL query engine for big data analytics.</b>\n</p>\n<p align=\"center\">\n    See the <a href=\"https://trino.io/docs/current/\">User Manual</a> for deployment instructions and end user documentation.\n</p>\n<p align=\"center\">\n  <a href=\"https://trino.io/download.html\" style=\"text-decoration: none\"><img\n    src=\"https://img.shields.io/github/v/release/trinodb/trino\"\n    alt=\"Trino download\"\n  /></a>\n  <a href=\"https://github.com/jvm-repo-rebuild/reproducible-central/blob/master/content/io/trino/README.md\" style=\"text-decoration: none\"><img\n    src=\"https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/jvm-repo-rebuild/reproducible-central/master/content/io/trino/badge.json\"\n    alt=\"Reproducible builds supported\"\n  /></a>\n  <a href=\"https://trino.io/slack.html\" style=\"text-decoration: none\"><img\n    src=\"https://img.shields.io/static/v1?logo=slack&logoColor=959DA5&label=Slack&labelColor=333a41&message=join%20conversation&color=3AC358\"\n    alt=\"Trino Slack\"\n  /></a>\n  <a href=\"https://trino.io/trino-the-definitive-guide.html\" style=\"text-decoration: none\"><img\n    src=\"https://img.shields.io/badge/Trino%3A%20The%20Definitive%20Guide-download-brightgreen\"\n    alt=\"Trino: The Definitive Guide book download\"\n  /></a>\n</p>\n\n## Development\n\nSee [DEVELOPMENT](.github/DEVELOPMENT.md) for information about development and release process,\ncode style and guidelines for implementors of Trino plugins.\n\nSee [CONTRIBUTING](.github/CONTRIBUTING.md) for contribution requirements.\n\n## Security\n\nSee the project [security policy](.github/SECURITY.md) for\ninformation about reporting vulnerabilities.\n\nTrino supports [reproducible builds](https://reproducible-builds.org) as of version 449.\n\n## Build requirements\n\n* Mac OS X or Linux\n  * Note that some npm packages used to build the web UI are only available\n    for x86 architectures, so if you're building on Apple Silicon, you need \n    to have Rosetta 2 installed\n* Java 25.0.1+, 64-bit\n* Docker\n  * Turn SELinux or other systems disabling write access to the local checkout\n    off, to allow containers to mount parts of the Trino source tree\n\n## Building Trino\n\nTrino is a standard Maven project. Simply run the following command from the\nproject root directory:\n\n    ./mvnw clean install -DskipTests\n\nOn the first build, Maven downloads all the dependencies from the internet\nand caches them in the local repository (`~/.m2/repository`), which can take a\nwhile, depending on your connection speed. Subsequent builds are faster.\n\nTrino has a comprehensive set of tests that take a considerable amount of time\nto run, and are thus disabled by the above command. These tests are run by the\nCI system when you submit a pull request. We recommend only running tests\nlocally for the areas of code that you change.\n\n## Running Trino in your IDE\n\n### Overview\n\nAfter building Trino for the first time, you can load the project into your IDE\nand run the server.  We recommend using\n[IntelliJ IDEA](http://www.jetbrains.com/idea/). Because Trino is a standard\nMaven project, you easily can import it into your IDE.  In IntelliJ, choose\n*Open Project* from the *Quick Start* box or choose *Open*\nfrom the *File* menu and select the root `pom.xml` file.\n\nAfter opening the project in IntelliJ, double check that the Java SDK is\nproperly configured for the project:\n\n* Open the File menu and select Project Structure\n* In the SDKs section, ensure that JDK 25 is selected (create one if none exist)\n* In the Project section, ensure the Project language level is set to 25\n\n### Running a testing server\n\nThe simplest way to run Trino for development is to run the `TpchQueryRunner`\nclass. It will start a development version of the server that is configured with\nthe TPCH connector. You can then use the CLI to execute queries against this\nserver. Many other connectors have their own `*QueryRunner` class that you can\nuse when working on a specific connector.\n\n### Running the full server\n\nTrino comes with sample configuration that should work out-of-the-box for\ndevelopment. Use the following options to create a run configuration:\n\n* Main Class: `io.trino.server.DevelopmentServer`\n* VM Options: `-ea -Dconfig=etc/config.properties -Dlog.levels-file=etc/log.properties -Djdk.attach.allowAttachSelf=true --sun-misc-unsafe-memory-access=allow --add-modules jdk.incubator.vector`\n* Working directory: `$MODULE_DIR$`\n* Use classpath of module: `trino-server-dev`\n\nThe working directory should be the `trino-server-dev` subdirectory. In\nIntelliJ, using `$MODULE_DIR$` accomplishes this automatically.\n\nIf `VM options` doesn't exist in the dialog, you need to select `Modify options`\nand enable `Add VM options`.\n\nTo adjust which plugins are enabled for the development server, adjust the value of\n`plugin.bundles` in `config.properties`. Each entry in this list must represent a plugin\nspecified by one of the following options:\n* A path to a `pom.xml` or `*.pom` file describing a Maven project that produces a plugin.\n* Maven coordinates, in the form `<groupId>:<artifactId>[:<extension>[:<classifier>]]:<version>`. The plugin will be loaded via Maven and therefore must be available in your local repository or a remote repository.\n* A path to a plugin directory containing JAR files. See [Deploying a custom plugin](https://trino.io/docs/current/develop/spi-overview.html#deploying-a-custom-plugin) for more details.\n\nIf you want to use a plugin in a catalog, you must add a corresponding\n`<catalog_name>.properties` file to `testing/trino-server-dev/etc/catalog`.\n\n### Running the CLI\n\nStart the CLI to connect to the server and run SQL queries:\n\n    client/trino-cli/target/trino-cli-*-executable.jar\n\nRun a query to see the nodes in the cluster:\n\n    SELECT * FROM system.runtime.nodes;\n\nRun a query against the TPCH connector:\n\n    SELECT * FROM tpch.tiny.region;\n",
      "stars_today": 7
    },
    {
      "id": 84240850,
      "name": "timescaledb",
      "full_name": "timescale/timescaledb",
      "description": "A time-series database for high-performance real-time analytics packaged as a Postgres extension",
      "html_url": "https://github.com/timescale/timescaledb",
      "stars": 21418,
      "forks": 1031,
      "language": "C",
      "topics": [
        "analytics",
        "database",
        "financial-analysis",
        "hacktoberfest",
        "iot",
        "postgres",
        "postgresql",
        "sql",
        "tigerdata",
        "time-series",
        "time-series-database",
        "timescaledb",
        "tsdb"
      ],
      "created_at": "2017-03-07T20:03:41Z",
      "updated_at": "2026-01-15T22:34:50Z",
      "pushed_at": "2026-01-16T01:04:58Z",
      "open_issues": 464,
      "owner": {
        "login": "timescale",
        "avatar_url": "https://avatars.githubusercontent.com/u/8986001?v=4"
      },
      "readme": "<div align=center>\n<picture align=center>\n    <source  srcset=\"https://assets.timescale.com/timescale-web/brand/show/horizontal-black.svg\">\n    <img alt=\"Tiger Data logo\" >\n</picture>\n</div>\n\n<div align=center>\n\n<h3>TimescaleDB is a PostgreSQL extension for high-performance real-time analytics on time-series and event data</h3>\n\n[![Docs](https://img.shields.io/badge/Read_the_docs-black?style=for-the-badge&logo=readthedocs&logoColor=white)](https://docs.tigerdata.com/)\n[![SLACK](https://img.shields.io/badge/Ask_the_community-black?style=for-the-badge&logo=slack&logoColor=white)](https://timescaledb.slack.com/archives/C4GT3N90X)\n[![Try TimescaleDB for free](https://img.shields.io/badge/Try_Tiger_Cloud_for_free-black?style=for-the-badge&logo=timescale&logoColor=white)](https://console.cloud.timescale.com/signup)\n\n</div>\n\n## Install TimescaleDB\n\nInstall from a Docker container:\n\n1. Run the TimescaleDB container:\n\n    ```bash\n    docker run -d --name timescaledb -p 5432:5432 -e POSTGRES_PASSWORD=password timescale/timescaledb-ha:pg17\n    ```\n\n1. Connect to a database:\n\n    ```bash\n    docker exec -it timescaledb psql -d \"postgres://postgres:password@localhost/postgres\"\n    ```\n\nSee [other installation options](https://docs.tigerdata.com/self-hosted/latest/install/) or try [Tiger Cloud](https://docs.tigerdata.com/getting-started/latest/) for free.\n\n## Create a hypertable\n\nTimescaleDB's hypercore is a hybrid row-columnar store that boosts analytical query performance on your time-series and event data, while reducing data size by more than 90%. This keeps your analytics operating at lightning speed and ensures low storage costs as you scale. Data is inserted in row format in the rowstore and converted to columnar format in the columnstore based on your configuration.\n\n```sql\n-- Create a hypertable, with the columnstore from the hypercore engine\n-- \"time\" as partitioning column and a segment by on location\nCREATE TABLE conditions (\n  time        TIMESTAMPTZ       NOT NULL,\n  location    TEXT              NOT NULL,\n  temperature DOUBLE PRECISION  NULL,\n  humidity    DOUBLE PRECISION  NULL\n)\nWITH (\n  timescaledb.hypertable,\n  timescaledb.partition_column='time',\n  timescaledb.segmentby='location'\n);\n```\n\nSee more:\n\n- [About hypertables](https://docs.tigerdata.com/use-timescale/latest/hypertables/)\n- [API reference](https://docs.tigerdata.com/api/latest/hypertable/)\n- [About columnstore](https://docs.tigerdata.com/use-timescale/latest/compression/about-compression/)\n- [Enable columnstore manually](https://docs.tigerdata.com/use-timescale/latest/compression/manual-compression/)\n- [API reference](https://docs.tigerdata.com/api/latest/compression/)\n\n## Insert and query data\n\nInsert and query data in a hypertable via regular SQL commands. For example:\n\n- Insert data into a hypertable named `conditions`:\n\n    ```sql\n    INSERT INTO conditions\n      VALUES\n        (NOW(), 'office',   70.0, 50.0),\n        (NOW(), 'basement', 66.5, 60.0),\n        (NOW(), 'garage',   77.0, 65.2);\n    ```\n\n- Return the number of entries written to the table conditions in the last 12 hours:\n\n    ```sql\n    SELECT\n      COUNT(*)\n    FROM\n      conditions\n    WHERE\n      time > NOW() - INTERVAL '12 hours';\n    ```\n\nSee more:\n\n- [Query data](https://docs.tigerdata.com/use-timescale/latest/query-data/)\n- [Write data](https://docs.tigerdata.com/use-timescale/latest/write-data/)\n\n## Create time buckets\n\nTime buckets enable you to aggregate data in hypertables by time interval and calculate summary values.\n\nFor example, calculate the average daily temperature in a table named `conditions`. The table has a `time` and `temperature` columns:\n\n```sql\nSELECT\n  time_bucket('1 day', time) AS bucket,\n  AVG(temperature) AS avg_temp\nFROM\n  conditions\nGROUP BY\n  bucket\nORDER BY\n  bucket ASC;\n```\n\nSee more:\n\n- [About time buckets](https://docs.tigerdata.com/use-timescale/latest/time-buckets/about-time-buckets/)\n- [API reference](https://docs.tigerdata.com/api/latest/hyperfunctions/time_bucket/)\n- [All TimescaleDB features](https://docs.tigerdata.com/use-timescale/latest/)\n- [Tutorials](https://docs.tigerdata.com/tutorials/latest/)\n\n## Create continuous aggregates\n\nContinuous aggregates make real-time analytics run faster on very large datasets. They continuously and incrementally refresh a query in the background, so that when you run such query, only the data that has changed needs to be computed, not the entire dataset. This is what makes them different from regular PostgreSQL [materialized views](https://www.postgresql.org/docs/current/rules-materializedviews.html), which cannot be incrementally materialized and have to be rebuilt from scratch every time you want to refresh it.\n\nFor example, create a continuous aggregate view for daily weather data in two simple steps:\n\n1. Create a materialized view:\n\n   ```sql\n   CREATE MATERIALIZED VIEW conditions_summary_daily\n   WITH (timescaledb.continuous) AS\n   SELECT\n     location,\n     time_bucket(INTERVAL '1 day', time) AS bucket,\n     AVG(temperature),\n     MAX(temperature),\n     MIN(temperature)\n   FROM\n     conditions\n   GROUP BY\n     location,\n     bucket;\n   ```\n\n1. Create a policy to refresh the view every hour:\n\n   ```sql\n   SELECT\n     add_continuous_aggregate_policy(\n       'conditions_summary_daily',\n       start_offset => INTERVAL '1 month',\n       end_offset => INTERVAL '1 day',\n       schedule_interval => INTERVAL '1 hour'\n   );\n   ```\nSee more:\n\n- [About continuous aggregates](https://docs.tigerdata.com/use-timescale/latest/continuous-aggregates/)\n- [API reference](https://docs.tigerdata.com/api/latest/continuous-aggregates/create_materialized_view/)\n\n## Want TimescaleDB hosted and managed for you? Try Tiger Cloud\n\n[Tiger Cloud](https://docs.tigerdata.com/getting-started/latest/) is the modern PostgreSQL data platform for all your applications. It enhances PostgreSQL to handle time series, events, real-time analytics, and vector searchâ€”all in a single database alongside transactional workloads. You get one system that handles live data ingestion, late and out-of-order updates, and low latency queries, with the performance, reliability, and scalability your app needs. Ideal for IoT, crypto, finance, SaaS, and a myriad other domains, Tiger Cloud allows you to build data-heavy, mission-critical apps while retaining the familiarity and reliability of PostgreSQL. See [our whitepaper](https://docs.tigerdata.com/about/latest/whitepaper/) for a deep dive into Tiger Cloud's architecture and how it meets the needs of even the most demanding applications.\n\nA Tiger Cloud service is a single optimized 100% PostgreSQL database instance that you use as is, or extend with capabilities specific to your business needs. The available capabilities are:\n\n- **Time-series and analytics**: PostgreSQL with TimescaleDB. The PostgreSQL you know and love, supercharged with functionality for storing and querying time-series data at scale for real-time analytics and other use cases. Get faster time-based queries with hypertables, continuous aggregates, and columnar storage. Save on storage with native compression, data retention policies, and bottomless data tiering to Amazon S3.\n- **AI and vector**: PostgreSQL with vector extensions. Use PostgreSQL as a vector database with purpose built extensions for building AI applications from start to scale. Get fast and accurate similarity search with the pgvector and pgvectorscale extensions. Create vector embeddings and perform LLM reasoning on your data with the pgai extension.\n- **PostgreSQL**: the trusted industry-standard RDBMS. Ideal for applications requiring strong data consistency, complex relationships, and advanced querying capabilities. Get ACID compliance, extensive SQL support, JSON handling, and extensibility through custom functions, data types, and extensions.\nAll services include all the cloud tooling you'd expect for production use: [automatic backups](https://docs.tigerdata.com/use-timescale/latest/backup-restore/backup-restore-cloud/), [high availability](https://docs.tigerdata.com/use-timescale/latest/ha-replicas/), [read replicas](https://docs.tigerdata.com/use-timescale/latest/ha-replicas/read-scaling/), [data forking](https://docs.tigerdata.com/use-timescale/latest/services/service-management/#fork-a-service), [connection pooling](https://docs.tigerdata.com/use-timescale/latest/services/connection-pooling/), [tiered storage](https://docs.tigerdata.com/use-timescale/latest/data-tiering/), [usage-based storage](https://docs.tigerdata.com/about/latest/pricing-and-account-management/), and much more.\n\n## Check build status\n\n|Linux/macOS|Linux i386|Windows|Coverity|Code Coverage|OpenSSF|\n|:---:|:---:|:---:|:---:|:---:|:---:|\n|[![Build Status Linux/macOS](https://github.com/timescale/timescaledb/actions/workflows/linux-build-and-test.yaml/badge.svg?branch=main&event=schedule)](https://github.com/timescale/timescaledb/actions/workflows/linux-build-and-test.yaml?query=workflow%3ARegression+branch%3Amain+event%3Aschedule)|[![Build Status Linux i386](https://github.com/timescale/timescaledb/actions/workflows/linux-32bit-build-and-test.yaml/badge.svg?branch=main&event=schedule)](https://github.com/timescale/timescaledb/actions/workflows/linux-32bit-build-and-test.yaml?query=workflow%3ARegression+branch%3Amain+event%3Aschedule)|[![Windows build status](https://github.com/timescale/timescaledb/actions/workflows/windows-build-and-test.yaml/badge.svg?branch=main&event=schedule)](https://github.com/timescale/timescaledb/actions/workflows/windows-build-and-test.yaml?query=workflow%3ARegression+branch%3Amain+event%3Aschedule)|[![Coverity Scan Build Status](https://scan.coverity.com/projects/timescale-timescaledb/badge.svg)](https://scan.coverity.com/projects/timescale-timescaledb)|[![Code Coverage](https://codecov.io/gh/timescale/timescaledb/branch/main/graphs/badge.svg?branch=main)](https://codecov.io/gh/timescale/timescaledb)|[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/8012/badge)](https://www.bestpractices.dev/projects/8012)|\n\n## Get involved\n\nWe welcome contributions to TimescaleDB! See [Contributing](https://github.com/timescale/timescaledb/blob/main/CONTRIBUTING.md) and [Code style guide](https://github.com/timescale/timescaledb/blob/main/docs/StyleGuide.md) for details.\n\n## Learn about Tiger Data\n\nTiger Data is the fastest PostgreSQL for transactional, analytical and agentic workloads. To learn more about the company and its products, visit [tigerdata.com](https://www.tigerdata.com).\n\n",
      "stars_today": 7
    },
    {
      "id": 19429698,
      "name": "Signal-iOS",
      "full_name": "signalapp/Signal-iOS",
      "description": "A private messenger for iOS.",
      "html_url": "https://github.com/signalapp/Signal-iOS",
      "stars": 11789,
      "forks": 3336,
      "language": "Swift",
      "topics": [],
      "created_at": "2014-05-04T15:42:40Z",
      "updated_at": "2026-01-15T14:26:15Z",
      "pushed_at": "2026-01-14T21:32:59Z",
      "open_issues": 124,
      "owner": {
        "login": "signalapp",
        "avatar_url": "https://avatars.githubusercontent.com/u/702459?v=4"
      },
      "readme": "# Signal iOS\n\nSignal is a free and open source messaging app for simple private communication with friends.\n\n[![Available on the App Store](https://signal.org/external/images/app-store-download-badge.svg)](https://apps.apple.com/app/id874139669)\n\nAlso available on [Android](https://github.com/signalapp/signal-android) and [Desktop](https://github.com/signalapp/signal-desktop).\n\n## Questions?\n\nFor troubleshooting and questions, please visit our [support center](https://support.signal.org/) or [unofficial community forum](https://community.signalusers.org/).\n\n## Contributing Bug Reports\n\nThe best way to submit a bug report or support request is [via the Support Center](https://support.signal.org/hc/requests/new). Signal iOS doesn't collect any analytics or telemetry, and we rely on your feedback to help us troubleshoot and fix problems when something isn't working correctly.\n\n## Contributing Code\n\nInstructions for how to configure your development environment and build Signal iOS can be found in [BUILDING.md](https://github.com/signalapp/Signal-iOS/blob/main/BUILDING.md). We also recommend reading the [contribution guidelines](https://github.com/signalapp/Signal-iOS/blob/main/CONTRIBUTING.md).\n\n## Contributing Ideas\n\nHave something you want to say about Signal Foundation projects or want to be part of the conversation? Get involved in the [community forum](https://community.signalusers.org).\n\n## Cryptography Notice\n\nThis distribution includes cryptographic software. The country in which you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of encryption software.\nBEFORE using any encryption software, please check your country's laws, regulations and policies concerning the import, possession, or use, and re-export of encryption software, to see if this is permitted.\nSee <http://www.wassenaar.org/> for more information.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and Security (BIS), has classified this software as Export Commodity Control Number (ECCN) 5D002.C.1, which includes information security software using or performing cryptographic functions with asymmetric algorithms.\nThe form and manner of this distribution makes it eligible for export under the License Exception ENC Technology Software Unrestricted (TSU) exception (see the BIS Export Administration Regulations, Section 740.13) for both object code and source code.\n\n## License\n\nCopyright 2013-2025 Signal Messenger, LLC\n\nLicensed under the GNU AGPLv3: https://www.gnu.org/licenses/agpl-3.0.html\n\n_Apple and the Apple logo are trademarks of Apple Inc., registered in the U.S. and other countries. App Store is a service mark of Apple Inc., registered in the U.S. and other countries._\n",
      "stars_today": 7
    },
    {
      "id": 97716052,
      "name": "XcodeGen",
      "full_name": "yonaskolb/XcodeGen",
      "description": "A Swift command line tool for generating your Xcode project",
      "html_url": "https://github.com/yonaskolb/XcodeGen",
      "stars": 7985,
      "forks": 869,
      "language": "Swift",
      "topics": [
        "ci",
        "cli",
        "generator",
        "specification",
        "swift",
        "xcode",
        "xcodeproj",
        "xcodeproject",
        "yaml"
      ],
      "created_at": "2017-07-19T12:56:04Z",
      "updated_at": "2026-01-16T00:22:53Z",
      "pushed_at": "2025-07-25T03:27:54Z",
      "open_issues": 388,
      "owner": {
        "login": "yonaskolb",
        "avatar_url": "https://avatars.githubusercontent.com/u/2393781?v=4"
      },
      "readme": "<p align=\"center\">\n<a href=\"https://github.com/yonaskolb/XcodeGen\">\n<img src=\"Assets/Logo_animated.gif\" alt=\"XcodeGen\" />\n</a>\n</p>\n<p align=\"center\">\n  <a href=\"https://github.com/yonaskolb/XcodeGen/releases\">\n    <img src=\"https://img.shields.io/github/release/yonaskolb/xcodegen.svg\"/>\n  </a>\n  <a href=\"https://swiftpackageindex.com/yonaskolb/XcodeGen\">\n    <img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fyonaskolb%2FXcodeGen%2Fbadge%3Ftype%3Dplatforms\" alt=\"Swift Package Manager Platforms\" />\n  </a>\n  <a href=\"https://swiftpackageindex.com/yonaskolb/XcodeGen\">\n    <img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fyonaskolb%2FXcodeGen%2Fbadge%3Ftype%3Dswift-versions\" alt=\"Swift Versions\" />\n  </a>\n  <a href=\"https://github.com/yonaskolb/XcodeGen/blob/master/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/yonaskolb/XcodeGen.svg\"/>\n  </a>\n</p>\n\n# XcodeGen\n\nXcodeGen is a command line tool written in Swift that generates your Xcode project using your folder structure and a project spec.\n\nThe project spec is a YAML or JSON file that defines your targets, configurations, schemes, custom build settings and many other options. All your source directories are automatically parsed and referenced appropriately while preserving your folder structure. Sensible defaults are used in many places, so you only need to customize what is needed. Very complex projects can also be defined using more advanced features.\n\n- âœ… Generate projects on demand and remove your `.xcodeproj` from git, which means **no more merge conflicts**!\n- âœ… Groups and files in Xcode are always **synced** to your directories on disk\n- âœ… Easy **configuration** of projects which is human readable and git friendly\n- âœ… Easily copy and paste **files and directories** without having to edit anything in Xcode\n- âœ… Share build settings across multiple targets with **build setting groups**\n- âœ… Automatically generate Schemes for **different environments** like test and production\n- âœ… Easily **create new projects** with complicated setups on demand without messing around with Xcode\n- âœ… Generate from anywhere including on **CI**\n- âœ… Distribute your spec amongst multiple files for easy **sharing** and overriding\n- âœ… Easily create **multi-platform** frameworks\n- âœ… Integrate **Carthage** frameworks without any work\n\nGiven an example project spec:\n\n```yaml\nname: MyProject\ninclude:\n  - base_spec.yml\noptions:\n  bundleIdPrefix: com.myapp\npackages:\n  Yams:\n    url: https://github.com/jpsim/Yams\n    from: 2.0.0\ntargets:\n  MyApp:\n    type: application\n    platform: iOS\n    deploymentTarget: \"10.0\"\n    sources: [MyApp]\n    settings:\n      configs:\n        debug:\n          CUSTOM_BUILD_SETTING: my_debug_value\n        release:\n          CUSTOM_BUILD_SETTING: my_release_value\n    dependencies:\n      - target: MyFramework\n      - carthage: Alamofire\n      - framework: Vendor/MyFramework.framework\n      - sdk: Contacts.framework\n      - sdk: libc++.tbd\n      - package: Yams\n  MyFramework:\n    type: framework\n    platform: iOS\n    sources: [MyFramework]\n```\nA project would be created with 2 connected targets, with all the required configurations and build settings. See the [Project Spec](Docs/ProjectSpec.md) documentation for all the options you can specify, and [Usage](Docs/Usage.md) for more general documentation.\n\n## Installing\n\nMake sure the latest stable (non-beta) version of Xcode is installed first.\n\n### [Mint](https://github.com/yonaskolb/mint)\n```sh\nmint install yonaskolb/xcodegen\n```\n\n### Make\n\n```shell\ngit clone https://github.com/yonaskolb/XcodeGen.git\ncd XcodeGen\nmake install\n```\n\n### Homebrew\n\n```shell\nbrew install xcodegen\n```\n\n### Swift Package Manager\n\n**Use as CLI**\n\n```shell\ngit clone https://github.com/yonaskolb/XcodeGen.git\ncd XcodeGen\nswift run xcodegen\n```\n\n**Use as dependency**\n\nAdd the following to your Package.swift file's dependencies:\n\n```swift\n.package(url: \"https://github.com/yonaskolb/XcodeGen.git\", from: \"2.44.1\"),\n```\n\nAnd then import wherever needed: `import XcodeGenKit`\n\n## Usage\n\nSimply run:\n\n```shell\nxcodegen generate\n```\n\nThis will look for a project spec in the current directory called `project.yml` and generate an Xcode project with the name defined in the spec.\n\nOptions:\n\n- **--spec**: An optional path to a `.yml` or `.json` project spec. Defaults to `project.yml`. (It is also possible to link to multiple spec files by comma separating them. Note that all other flags will be the same.)\n- **--project**: An optional path to a directory where the project will be generated. By default this is the directory the spec lives in.\n- **--quiet**: Suppress informational and success messages.\n- **--use-cache**: Used to prevent unnecessarily generating the project. If this is set, then a cache file will be written to when a project is generated. If `xcodegen` is later run but the spec and all the files it contains are the same, the project won't be generated.\n- **--cache-path**: A custom path to use for your cache file. This defaults to `~/.xcodegen/cache/{PROJECT_SPEC_PATH_HASH}`\n\nThere are other commands as well such as `xcodegen dump` which lets one output the resolved spec in many different formats, or write it to a file. Use `xcodegen help` to see more detailed usage information.\n\n## Editing\n```shell\ngit clone https://github.com/yonaskolb/XcodeGen.git\ncd XcodeGen\nswift package generate-xcodeproj\n```\nThis uses Swift Package Manager to create an `xcodeproj` file that you can open, edit and run in Xcode, which makes editing any code easier.\n\nIf you want to pass any required arguments when running in Xcode, you can edit the scheme to include launch arguments.\n\n## Documentation\n- See [Project Spec](Docs/ProjectSpec.md) documentation for all the various properties and options that can be set\n- See [Usage](Docs/Usage.md) for more specific usage and use case documentation\n- See [FAQ](Docs/FAQ.md) for a list of some frequently asked questions\n- See [Examples](Docs/Examples.md) for some real world XcodeGen project specs out in the wild\n\n## Alternatives\nIf XcodeGen doesn't meet your needs try these great alternatives:\n- [Tuist](https://github.com/tuist/tuist)\n- [Xcake](https://github.com/igor-makarov/xcake)\n- [struct](https://github.com/workshop/struct)\n\n## Attributions\nThis tool is powered by:\n\n- [XcodeProj](https://github.com/tuist/XcodeProj)\n- [JSONUtilities](https://github.com/yonaskolb/JSONUtilities)\n- [Spectre](https://github.com/kylef/Spectre)\n- [PathKit](https://github.com/kylef/PathKit)\n- [Yams](https://github.com/jpsim/Yams)\n- [SwiftCLI](https://github.com/jakeheis/SwiftCLI)\n\nInspiration for this tool came from:\n\n- [struct](https://github.com/workshop/struct)\n- [Xcake](https://github.com/igor-makarov/xcake)\n- [CocoaPods Xcodeproj](https://github.com/CocoaPods/Xcodeproj)\n\n## Contributions\nPull requests and issues are always welcome. Please open any issues and PRs for bugs, features, or documentation.\n\n[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/0)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/0)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/1)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/1)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/2)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/2)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/3)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/3)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/4)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/4)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/5)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/5)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/6)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/6)[![](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/images/7)](https://sourcerer.io/fame/yonaskolb/yonaskolb/XcodeGen/links/7)\n\n## License\n\nXcodeGen is licensed under the MIT license. See [LICENSE](LICENSE) for more info.\n",
      "stars_today": 7
    },
    {
      "id": 184341774,
      "name": "cloud-hypervisor",
      "full_name": "cloud-hypervisor/cloud-hypervisor",
      "description": "A Virtual Machine Monitor for modern Cloud workloads. Features include CPU, memory and device hotplug, support for running Windows and Linux guests, device offload with vhost-user and a minimal compact footprint. Written in Rust with a strong focus on security.",
      "html_url": "https://github.com/cloud-hypervisor/cloud-hypervisor",
      "stars": 5167,
      "forks": 567,
      "language": "Rust",
      "topics": [
        "cloud-workloads",
        "kvm",
        "rust-vmm",
        "virtualization"
      ],
      "created_at": "2019-04-30T22:49:03Z",
      "updated_at": "2026-01-15T19:51:57Z",
      "pushed_at": "2026-01-15T19:51:52Z",
      "open_issues": 151,
      "owner": {
        "login": "cloud-hypervisor",
        "avatar_url": "https://avatars.githubusercontent.com/u/50487650?v=4"
      },
      "readme": "- [1. What is Cloud Hypervisor?](#1-what-is-cloud-hypervisor)\n  - [Objectives](#objectives)\n    - [High Level](#high-level)\n    - [Architectures](#architectures)\n    - [Guest OS](#guest-os)\n- [2. Getting Started](#2-getting-started)\n  - [Host OS](#host-os)\n  - [Use Pre-built Binaries](#use-pre-built-binaries)\n  - [Packages](#packages)\n  - [Building from Source](#building-from-source)\n  - [Booting Linux](#booting-linux)\n    - [Firmware Booting](#firmware-booting)\n    - [Custom Kernel and Disk Image](#custom-kernel-and-disk-image)\n      - [Building your Kernel](#building-your-kernel)\n      - [Disk image](#disk-image)\n      - [Booting the guest VM](#booting-the-guest-vm)\n- [3. Status](#3-status)\n  - [Hot Plug](#hot-plug)\n  - [Device Model](#device-model)\n  - [Roadmap](#roadmap)\n- [4. Relationship with _Rust VMM_ Project](#4-relationship-with-rust-vmm-project)\n  - [Differences with Firecracker and crosvm](#differences-with-firecracker-and-crosvm)\n- [5. Community](#5-community)\n  - [Contribute](#contribute)\n  - [Slack](#slack)\n  - [Mailing list](#mailing-list)\n  - [Security issues](#security-issues)\n\n# 1. What is Cloud Hypervisor?\n\nCloud Hypervisor is an open source Virtual Machine Monitor (VMM) that runs on\ntop of the [KVM](https://www.kernel.org/doc/Documentation/virtual/kvm/api.txt)\nhypervisor and the Microsoft Hypervisor (MSHV).\n\nThe project focuses on running modern, _Cloud Workloads_, on specific, common,\nhardware architectures. In this case _Cloud Workloads_ refers to those that are\nrun by customers inside a Cloud Service Provider. This means modern operating\nsystems with most I/O handled by\nparavirtualised devices (e.g. _virtio_), no requirement for legacy devices, and\n64-bit CPUs.\n\nCloud Hypervisor is implemented in [Rust](https://www.rust-lang.org/) and is\nbased on the [Rust VMM](https://github.com/rust-vmm) crates.\n\n## Objectives\n\n### High Level\n\n- Runs on KVM or MSHV\n- Minimal emulation\n- Low latency\n- Low memory footprint\n- Low complexity\n- High performance\n- Small attack surface\n- 64-bit support only\n- CPU, memory, PCI hotplug\n- Machine to machine migration\n\n### Architectures\n\nCloud Hypervisor supports the `x86-64`, `AArch64` and `riscv64`\narchitectures, with functionality varying across these platforms. The\nfunctionality differences between `x86-64` and `AArch64` are documented\nin [#1125](https://github.com/cloud-hypervisor/cloud-hypervisor/issues/1125).\nThe `riscv64` architecture support is experimental and offers limited\nfunctionality. For more details and instructions, please refer to [riscv\ndocumentation](docs/riscv.md).\n\n### Guest OS\n\nCloud Hypervisor supports `64-bit Linux` and Windows 10/Windows Server 2019.\n\n# 2. Getting Started\n\nThe following sections describe how to build and run Cloud Hypervisor.\n\n## Prerequisites for AArch64\n\n- AArch64 servers (recommended) or development boards equipped with the GICv3\n  interrupt controller.\n\n## Host OS\n\nFor required KVM functionality and adequate performance the recommended host\nkernel version is 5.13. The majority of the CI currently tests with kernel\nversion 5.15.\n\n## Use Pre-built Binaries\n\nThe recommended approach to getting started with Cloud Hypervisor is by using a\npre-built binary. Binaries are available for the [latest\nrelease](https://github.com/cloud-hypervisor/cloud-hypervisor/releases/latest).\nUse `cloud-hypervisor-static` for `x86-64` or `cloud-hypervisor-static-aarch64`\nfor `AArch64` platform.\n\n## Packages\n\nFor convenience, packages are also available targeting some popular Linux\ndistributions. This is thanks to the [Open Build\nService](https://build.opensuse.org). The [OBS\nREADME](https://github.com/cloud-hypervisor/obs-packaging) explains how to\nenable the repository in a supported Linux distribution and install Cloud Hypervisor\nand accompanying packages. Please report any packaging issues in the\n[obs-packaging](https://github.com/cloud-hypervisor/obs-packaging) repository.\n\n## Building from Source\n\nPlease see the [instructions for building from source](docs/building.md) if you\ndo not wish to use the pre-built binaries.\n\n## Booting Linux\n\nCloud Hypervisor supports direct kernel boot (the x86-64 kernel requires the kernel\nbuilt with PVH support or a bzImage) or booting via a firmware (either [Rust Hypervisor\nFirmware](https://github.com/cloud-hypervisor/rust-hypervisor-firmware) or an\nedk2 UEFI firmware called `CLOUDHV` / `CLOUDHV_EFI`.)\n\nBinary builds of the firmware files are available for the latest release of\n[Rust Hypervisor\nFirmware](https://github.com/cloud-hypervisor/rust-hypervisor-firmware/releases/latest)\nand [our edk2\nrepository](https://github.com/cloud-hypervisor/edk2/releases/latest)\n\nThe choice of firmware depends on your guest OS choice; some experimentation\nmay be required.\n\n### Firmware Booting\n\nCloud Hypervisor supports booting disk images containing all needed components\nto run cloud workloads, a.k.a. cloud images.\n\nThe following sample commands will download an Ubuntu Cloud image, converting\nit into a format that Cloud Hypervisor can use and a firmware to boot the image\nwith.\n\n```shell\n$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img\n$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-amd64.img focal-server-cloudimg-amd64.raw\n$ wget https://github.com/cloud-hypervisor/rust-hypervisor-firmware/releases/download/0.4.2/hypervisor-fw\n```\n\nThe Ubuntu cloud images do not ship with a default password so it necessary to\nuse a `cloud-init` disk image to customise the image on the first boot. A basic\n`cloud-init` image is generated by this [script](scripts/create-cloud-init.sh).\nThis seeds the image with a default username/password of `cloud/cloud123`. It\nis only necessary to add this disk image on the first boot. Script also assigns\ndefault IP address using `test_data/cloud-init/ubuntu/local/network-config` details\nwith `--net \"mac=12:34:56:78:90:ab,tap=\"` option. Then the matching mac address\ninterface will be enabled as per `network-config` details.\n\n```shell\n$ sudo setcap cap_net_admin+ep ./cloud-hypervisor\n$ ./create-cloud-init.sh\n$ ./cloud-hypervisor \\\n\t--firmware ./hypervisor-fw \\\n\t--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\nIf access to the firmware messages or interaction with the boot loader (e.g.\nGRUB) is required then it necessary to switch to the serial console instead of\n`virtio-console`.\n\n```shell\n$ ./cloud-hypervisor \\\n\t--kernel ./hypervisor-fw \\\n\t--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\" \\\n\t--serial tty \\\n\t--console off\n```\n\n## Booting: `--firmware` vs `--kernel`\n\nThe following scenarios are supported by Cloud Hypervisor to bootstrap a VM, i.e.,\nto load a payload/bootitem(s):\n\n- Provide firmware\n- Provide kernel \\[+ cmdline\\]\\ [+ initrd\\]\n\nPlease note that our Cloud Hypervisor firmware (`hypervisor-fw`) has a Xen PVH\nboot entry, therefore it can also be booted via the `--kernel` parameter, as \nseen in some examples.\n\n### Custom Kernel and Disk Image\n\n#### Building your Kernel\n\nCloud Hypervisor also supports direct kernel boot. For x86-64, a `vmlinux` ELF kernel (compiled with PVH support) or a regular bzImage are supported. In order to support development there is a custom branch; however provided the required options are enabled any recent kernel will suffice.\n\nTo build the kernel:\n\n```shell\n# Clone the Cloud Hypervisor Linux branch\n$ git clone --depth 1 https://github.com/cloud-hypervisor/linux.git -b ch-6.12.8 linux-cloud-hypervisor\n$ pushd linux-cloud-hypervisor\n$ make ch_defconfig\n# Do native build of the x86-64 kernel\n$ KCFLAGS=\"-Wa,-mx86-used-note=no\" make bzImage -j `nproc`\n# Do native build of the AArch64 kernel\n$ make -j `nproc`\n$ popd\n```\n\nFor x86-64, the `vmlinux` kernel image will then be located at\n`linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin`.\nFor AArch64, the `Image` kernel image will then be located at\n`linux-cloud-hypervisor/arch/arm64/boot/Image`.\n\n#### Disk image\n\nFor the disk image the same Ubuntu image as before can be used. This contains\nan `ext4` root filesystem.\n\n```shell\n$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img # x86-64\n$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-arm64.img # AArch64\n$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-amd64.img focal-server-cloudimg-amd64.raw # x86-64\n$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-arm64.img focal-server-cloudimg-arm64.raw # AArch64\n```\n\n#### Booting the guest VM\n\nThese sample commands boot the disk image using the custom kernel whilst also\nsupplying the desired kernel command line.\n\n- x86-64\n\n```shell\n$ sudo setcap cap_net_admin+ep ./cloud-hypervisor\n$ ./create-cloud-init.sh\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin \\\n\t--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cmdline \"console=hvc0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\n- AArch64\n\n```shell\n$ sudo setcap cap_net_admin+ep ./cloud-hypervisor\n$ ./create-cloud-init.sh\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/arm64/boot/Image \\\n\t--disk path=focal-server-cloudimg-arm64.raw path=/tmp/ubuntu-cloudinit.img \\\n\t--cmdline \"console=hvc0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\nIf earlier kernel messages are required the serial console should be used instead of `virtio-console`.\n\n- x86-64\n\n```shell\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin \\\n\t--console off \\\n\t--serial tty \\\n\t--disk path=focal-server-cloudimg-amd64.raw \\\n\t--cmdline \"console=ttyS0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\n- AArch64\n\n```shell\n$ ./cloud-hypervisor \\\n\t--kernel ./linux-cloud-hypervisor/arch/arm64/boot/Image \\\n\t--console off \\\n\t--serial tty \\\n\t--disk path=focal-server-cloudimg-arm64.raw \\\n\t--cmdline \"console=ttyAMA0 root=/dev/vda1 rw\" \\\n\t--cpus boot=4 \\\n\t--memory size=1024M \\\n\t--net \"tap=,mac=,ip=,mask=\"\n```\n\n# 3. Status\n\nCloud Hypervisor is under active development. The following stability\nguarantees are currently made:\n\n* The API (including command line options) will not be removed or changed in a\n  breaking way without a minimum of 2 major releases notice. Where possible\n  warnings will be given about the use of deprecated functionality and the\n  deprecations will be documented in the release notes.\n\n* Point releases will be made between individual releases where there are\n  substantial bug fixes or security issues that need to be fixed. These point\n  releases will only include bug fixes.\n\nCurrently the following items are **not** guaranteed across updates:\n\n* Snapshot/restore is not supported across different versions\n* Live migration is not supported across different versions\n* The following features are considered experimental and may change\n  substantially between releases: TDX, vfio-user, vDPA.\n\nFurther details can be found in the [release documentation](docs/releases.md).\n\nAs of 2023-01-03, the following cloud images are supported:\n\n- [Ubuntu Focal](https://cloud-images.ubuntu.com/focal/current/) (focal-server-cloudimg-{amd64,arm64}.img)\n- [Ubuntu Jammy](https://cloud-images.ubuntu.com/jammy/current/) (jammy-server-cloudimg-{amd64,arm64}.img)\n- [Ubuntu Noble](https://cloud-images.ubuntu.com/noble/current/) (noble-server-cloudimg-{amd64,arm64}.img)\n- [Fedora 36](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/) ([Fedora-Cloud-Base-36-1.5.x86_64.raw.xz](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/x86_64/images/) / [Fedora-Cloud-Base-36-1.5.aarch64.raw.xz](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/aarch64/images/))\n\nDirect kernel boot to userspace should work with a rootfs from most\ndistributions although you may need to enable exotic filesystem types in the\nreference kernel configuration (e.g. XFS or btrfs.)\n\n## Hot Plug\n\nCloud Hypervisor supports hotplug of CPUs, passthrough devices (VFIO),\n`virtio-{net,block,pmem,fs,vsock}` and memory resizing. This\n[document](docs/hotplug.md) details how to add devices to a running VM.\n\n## Device Model\n\nDetails of the device model can be found in this\n[documentation](docs/device_model.md).\n\n## Roadmap\n\nThe project roadmap is tracked through a [GitHub\nproject](https://github.com/orgs/cloud-hypervisor/projects/6).\n\n# 4. Relationship with _Rust VMM_ Project\n\nIn order to satisfy the design goal of having a high-performance,\nsecurity-focused hypervisor the decision was made to use the\n[Rust](https://www.rust-lang.org/) programming language. The language's strong\nfocus on memory and thread safety makes it an ideal candidate for implementing\nVMMs.\n\nInstead of implementing the VMM components from scratch, Cloud Hypervisor is\nimporting the [Rust VMM](https://github.com/rust-vmm) crates, and sharing code\nand architecture together with other VMMs like e.g. Amazon's\n[Firecracker](https://firecracker-microvm.github.io/) and Google's\n[crosvm](https://chromium.googlesource.com/chromiumos/platform/crosvm/).\n\nCloud Hypervisor embraces the _Rust VMM_ project's goals, which is to be able\nto share and re-use as many virtualization crates as possible.\n\n## Differences with Firecracker and crosvm\n\nA large part of the Cloud Hypervisor code is based on either the Firecracker or\nthe crosvm project's implementations. Both of these are VMMs written in Rust\nwith a focus on safety and security, like Cloud Hypervisor.\n\nThe goal of the Cloud Hypervisor project differs from the aforementioned\nprojects in that it aims to be a general purpose VMM for _Cloud Workloads_ and\nnot limited to container/serverless or client workloads.\n\nThe Cloud Hypervisor community thanks the communities of both the Firecracker\nand crosvm projects for their excellent work.\n\n# 5. Community\n\nThe Cloud Hypervisor project follows the governance, and community guidelines\ndescribed in the [Community](https://github.com/cloud-hypervisor/community)\nrepository.\n\n## Contribute\n\nThe project strongly believes in building a global, diverse and collaborative\ncommunity around the Cloud Hypervisor project. Anyone who is interested in\n[contributing](CONTRIBUTING.md) to the project is welcome to participate.\n\nContributing to a open source project like Cloud Hypervisor covers a lot more\nthan just sending code. Testing, documentation, pull request\nreviews, bug reports, feature requests, project improvement suggestions, etc,\nare all equal and welcome means of contribution. See the\n[CONTRIBUTING](CONTRIBUTING.md) document for more details.\n\n## Slack\n\nGet an [invite to our Slack channel](https://join.slack.com/t/cloud-hypervisor/shared_invite/enQtNjY3MTE3MDkwNDQ4LWQ1MTA1ZDVmODkwMWQ1MTRhYzk4ZGNlN2UwNTI3ZmFlODU0OTcwOWZjMTkwZDExYWE3YjFmNzgzY2FmNDAyMjI),\n [join us on Slack](https://cloud-hypervisor.slack.com/), and [participate in our community activities](https://cloud-hypervisor.slack.com/archives/C04R5DUQVBN).\n\n## Mailing list\n\nPlease report bugs using the [GitHub issue\ntracker](https://github.com/cloud-hypervisor/cloud-hypervisor/issues) but for\nbroader community discussions you may use our [mailing\nlist](https://lists.cloudhypervisor.org/g/dev/).\n\n## Security issues\n\nPlease contact the maintainers listed in the MAINTAINERS.md file with security issues.\n",
      "stars_today": 7
    },
    {
      "id": 75104123,
      "name": "prettier",
      "full_name": "prettier/prettier",
      "description": "Prettier is an opinionated code formatter.",
      "html_url": "https://github.com/prettier/prettier",
      "stars": 51392,
      "forks": 4634,
      "language": "JavaScript",
      "topics": [
        "angular",
        "ast",
        "css",
        "flow",
        "formatter",
        "graphql",
        "html",
        "javascript",
        "json",
        "jsx",
        "less",
        "markdown",
        "prettier",
        "printer",
        "scss",
        "typescript",
        "vue",
        "yaml"
      ],
      "created_at": "2016-11-29T17:13:37Z",
      "updated_at": "2026-01-16T00:31:39Z",
      "pushed_at": "2026-01-16T00:31:36Z",
      "open_issues": 1443,
      "owner": {
        "login": "prettier",
        "avatar_url": "https://avatars.githubusercontent.com/u/25822731?v=4"
      },
      "readme": "[![Prettier Banner](https://unpkg.com/prettier-logo@1.0.3/images/prettier-banner-light.svg)](https://prettier.io)\n\n<h2 align=\"center\">Opinionated Code Formatter</h2>\n\n<p align=\"center\">\n  <em>\n    JavaScript\n    Â· TypeScript\n    Â· Flow\n    Â· JSX\n    Â· JSON\n  </em>\n  <br />\n  <em>\n    CSS\n    Â· SCSS\n    Â· Less\n  </em>\n  <br />\n  <em>\n    HTML\n    Â· Vue\n    Â· Angular\n  </em>\n  <br />\n  <em>\n    GraphQL\n    Â· Markdown\n    Â· YAML\n  </em>\n  <br />\n  <em>\n    <a href=\"https://prettier.io/docs/plugins\">\n      Your favorite language?\n    </a>\n  </em>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/prettier/prettier/actions?query=branch%3Amain\">\n    <img alt=\"CI Status\" src=\"https://img.shields.io/github/check-runs/prettier/prettier/main?style=flat-square&label=CI\"></a>\n  <a href=\"https://codecov.io/gh/prettier/prettier\">\n    <img alt=\"Coverage Status\" src=\"https://img.shields.io/codecov/c/github/prettier/prettier.svg?style=flat-square\"></a>\n  <a href=\"https://x.com/acdlite/status/974390255393505280\">\n    <img alt=\"Blazing Fast\" src=\"https://img.shields.io/badge/speed-blazing%20%F0%9F%94%A5-brightgreen.svg?style=flat-square\"></a>\n  <br/>\n  <a href=\"https://www.npmjs.com/package/prettier\">\n    <img alt=\"npm version\" src=\"https://img.shields.io/npm/v/prettier.svg?style=flat-square\"></a>\n  <a href=\"https://www.npmjs.com/package/prettier\">\n    <img alt=\"weekly downloads from npm\" src=\"https://img.shields.io/npm/dw/prettier.svg?style=flat-square\"></a>\n  <a href=\"https://github.com/prettier/prettier#badge\">\n    <img alt=\"code style: prettier\" src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\"></a>\n  <a href=\"https://x.com/intent/follow?screen_name=PrettierCode\">\n    <img alt=\"Follow Prettier on X\" src=\"https://img.shields.io/badge/%40PrettierCode-9f9f9f?style=flat-square&logo=x&labelColor=555\"></a>\n</p>\n\n## Intro\n\nPrettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary.\n\n### Input\n\n<!-- prettier-ignore -->\n```js\nfoo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne());\n```\n\n### Output\n\n```js\nfoo(\n  reallyLongArg(),\n  omgSoManyParameters(),\n  IShouldRefactorThis(),\n  isThereSeriouslyAnotherOne(),\n);\n```\n\nPrettier can be run [in your editor](https://prettier.io/docs/editors) on-save, in a [pre-commit hook](https://prettier.io/docs/precommit), or in [CI environments](https://prettier.io/docs/cli#list-different) to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again!\n\n---\n\n**[Documentation](https://prettier.io/docs/)**\n\n[Install](https://prettier.io/docs/install) Â·\n[Options](https://prettier.io/docs/options) Â·\n[CLI](https://prettier.io/docs/cli) Â·\n[API](https://prettier.io/docs/api)\n\n**[Playground](https://prettier.io/playground/)**\n\n---\n\n## Badge\n\nShow the world you're using _Prettier_ â†’ [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\n\n```md\n[![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\n```\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md).\n",
      "stars_today": 6
    },
    {
      "id": 49876476,
      "name": "shardingsphere",
      "full_name": "apache/shardingsphere",
      "description": "Empowering Data Intelligence with Distributed SQL for Sharding, Scalability, and Security Across All Databases.",
      "html_url": "https://github.com/apache/shardingsphere",
      "stars": 20631,
      "forks": 6913,
      "language": "Java",
      "topics": [
        "bigdata",
        "data-encryption",
        "data-pipeline",
        "database",
        "database-cluster",
        "database-gateway",
        "database-middleware",
        "distributed-database",
        "distributed-sql-database",
        "distributed-transaction",
        "encrypt",
        "mysql",
        "postgresql",
        "read-write-splitting",
        "shard",
        "sql"
      ],
      "created_at": "2016-01-18T12:49:26Z",
      "updated_at": "2026-01-15T15:03:03Z",
      "pushed_at": "2026-01-15T15:02:53Z",
      "open_issues": 375,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "## [Apache ShardingSphere - Enterprise Distributed Database Ecosystem](https://shardingsphere.apache.org/)\n\nBuilding the standards and ecosystem on top of heterogeneous databases, empowering enterprise data architecture transformation\n\n**Official Website:** [https://shardingsphere.apache.org/](https://shardingsphere.apache.org/)\n\n[![GitHub Release](https://img.shields.io/github/release/apache/shardingsphere.svg)](https://github.com/apache/shardingsphere/releases)\n[![Lines of Code](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=ncloc)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n\n[![CI](https://github.com/apache/shardingsphere/actions/workflows/ci.yml/badge.svg)](https://github.com/apache/shardingsphere/actions/workflows/ci.yml)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![Technical Debt](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=sqale_index)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=sqale_rating)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![Security Rating](https://sonarcloud.io/api/project_badges/measure?project=apache_shardingsphere&metric=security_rating)](https://sonarcloud.io/summary/new_code?id=apache_shardingsphere)\n[![codecov](https://codecov.io/gh/apache/shardingsphere/branch/master/graph/badge.svg)](https://codecov.io/gh/apache/shardingsphere)\n\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/5394/badge)](https://bestpractices.coreinfrastructure.org/projects/5394)\n\n[![Slack](https://img.shields.io/badge/%20Slack-ShardingSphere%20Channel-blueviolet)](https://join.slack.com/t/apacheshardingsphere/shared_invite/zt-sbdde7ie-SjDqo9~I4rYcR18bq0SYTg)\n[![Gitter](https://badges.gitter.im/shardingsphere/shardingsphere.svg)](https://gitter.im/shardingsphere/Lobby)\n\n[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/ShardingSphere.svg?style=social&label=Follow%20%40ShardingSphere)](https://twitter.com/ShardingSphere)\n\n<table style=\"width:100%\">\n    <tr>\n        <th>\n            <a href=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map?activity=stars&repo_id=49876476\" target=\"_blank\" style=\"display: block\" align=\"center\">\n                <picture>\n                    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=stars&repo_id=49876476&image_size=auto&color_scheme=dark\" width=\"721\" height=\"auto\">\n                    <img alt=\"Star Geographical Distribution of apache/shardingsphere\" src=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=stars&repo_id=49876476&image_size=auto&color_scheme=light\" width=\"721\" height=\"auto\">\n                </picture>\n            </a>\n        </th>\n        <th>\n            <a href=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map?activity=pull-request-creators&repo_id=49876476\" target=\"_blank\" style=\"display: block\" align=\"center\">\n                <picture>\n                    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=pull-request-creators&repo_id=49876476&image_size=auto&color_scheme=dark\" width=\"721\" height=\"auto\">\n                    <img alt=\"Pull Request Creator Geographical Distribution of apache/shardingsphere\" src=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=pull-request-creators&repo_id=49876476&image_size=auto&color_scheme=light\" width=\"721\" height=\"auto\">\n                </picture>\n            </a>\n        </th>\n        <th>\n            <a href=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map?activity=issue-creators&repo_id=49876476\" target=\"_blank\" style=\"display: block\" align=\"center\">\n                <picture>\n                    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=issue-creators&repo_id=49876476&image_size=auto&color_scheme=dark\" width=\"721\" height=\"auto\">\n                    <img alt=\"Issue Creator Geographical Distribution of apache/shardingsphere\" src=\"https://next.ossinsight.io/widgets/official/analyze-repo-stars-map/thumbnail.png?activity=issue-creators&repo_id=49876476&image_size=auto&color_scheme=light\" width=\"721\" height=\"auto\">\n                </picture>\n            </a>\n        </th>\n    </tr>\n</table>\n\n### OVERVIEW\n\n<hr>\n\nApache ShardingSphere is positioned as **Database Plus**, a standard and ecosystem built on top of heterogeneous databases. As an operating system layer above databases, ShardingSphere does not create new databases but focuses on maximizing the computing capabilities of existing databases, providing unified data access and enhanced computing capabilities.\n\n**Database Plus Core Concept**: By building a standardized and scalable enhancement layer above databases, it makes heterogeneous databases as simple to use as a single database, providing unified governance capabilities and distributed computing capabilities for enterprise data architectures.\n\n**Connect, Enhance, and Pluggable** are the three core pillars of Apache ShardingSphere:\n\n- **Connect:** Building database upper-layer standards, quickly connecting applications with multi-modal heterogeneous databases through flexible adaptation of database protocols, SQL dialects, and storage formats, providing unified data access experience;\n\n- **Enhance:** As a database computing enhancement engine, transparently providing enterprise-grade capabilities including distributed computing (data sharding, readwrite-splitting, SQL federation), data security (encryption, masking, audit), traffic control (circuit breaker, rate limiting), and observability (monitoring, tracing, analysis);\n\n- **Pluggable:** Adopting a micro-kernel + 3-layer pluggable architecture to achieve complete decoupling of kernel, functional components, and ecosystem integration. Developers can flexibly customize unique data architecture solutions that meet enterprise needs, just like building with LEGO blocks.\n\n**Differentiation Advantages**:\n- **vs Distributed Databases**: More lightweight, protecting existing investments, avoiding vendor lock-in\n- **vs Traditional Middleware**: Richer features, more complete ecosystem, more flexible architecture\n- **vs Cloud Vendor Solutions**: Support multi-cloud deployment, avoid technology binding, autonomous and controllable\n\nShardingSphere became an [Apache](https://apache.org/index.html#projects-list) Top-Level Project on April 16, 2020, and has been adopted by [19,000+ projects](https://github.com/search?l=Maven+POM&q=shardingsphere+language%3A%22Maven+POM%22&type=Code) worldwide.\n\n### DUAL-ACCESS ARCHITECTURE DESIGN\n\n<hr>\n\nShardingSphere adopts a unique dual-access architecture design, providing two access ends - JDBC and Proxy - that can be deployed independently or in hybrid deployment, meeting diverse requirements for different scenarios.\n\n#### ShardingSphere-JDBC: Lightweight Access End\n\n**Positioning**: Lightweight Java framework, enhanced JDBC driver\n\n**Core Features**:\n- **Client-side direct connection**: Shares resources with applications, decentralized architecture\n- **High performance, low overhead**: Direct database connection with minimal performance loss\n- **Complete compatibility**: Compatible with all ORM frameworks (MyBatis, JPA, Hibernate, etc.)\n- **Zero additional deployment**: Provided as JAR package, no independent deployment and dependencies required\n\n**Use Cases**: High-performance Java applications, integrated deployment with business applications, pursuing ultimate performance\n\n#### ShardingSphere-Proxy: Enterprise Access End\n\n**Positioning**: Transparent database proxy, independently deployed server-side\n\n**Core Features**:\n- **Static entry point**: Independent deployment from applications, providing stable database access entry\n- **Heterogeneous language support**: Supports any MySQL/PostgreSQL protocol compatible client\n- **DBA friendly**: Database operation and maintenance management interface, convenient for O&M personnel\n- **Enterprise-grade features**: Supports cluster deployment, load balancing, failover\n\n**Use Cases**: Heterogeneous language environments, database operation and maintenance management, enterprise applications requiring unified access entry\n\n#### Hybrid Architecture Advantages\n\nBy hybridizing ShardingSphere-JDBC and ShardingSphere-Proxy with unified configuration through the same registry center, you can flexibly build application systems suitable for various scenarios:\n\n- **Architectural flexibility**: Architects can freely adjust the optimal system architecture\n- **Scenario adaptability**: Select the most suitable access method according to different business scenarios\n- **Unified management**: Single configuration, multi-end collaboration, simplifying O&M complexity\n- **Progressive evolution**: Support smooth evolution path from JDBC to Proxy\n\n### AI ABSTRACTION\n\n[![DeepWiki](https://img.shields.io/badge/DeepWiki-apache%2Fshardingsphere-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/apache/shardingsphere)\n[![zread](https://img.shields.io/badge/Ask_Zread-_.svg?style=flat&color=00b0aa&labelColor=000000&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&logoColor=ffffff)](https://zread.ai/apache/shardingsphere)\n\n### DOCUMENTATIONğŸ“œ\n\n<hr>\n\n[![EN doc](https://img.shields.io/badge/document-English-blue.svg)](https://shardingsphere.apache.org/document/current/en/overview/)\n[![CN doc](https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡ç‰ˆ-blue.svg)](https://shardingsphere.apache.org/document/current/cn/overview/)\n\nFor full documentation & more details, visit: [Docs](https://shardingsphere.apache.org/document/current/en/overview/)\n\n### CONTRIBUTIONğŸš€ğŸ§‘ğŸ’»\n\n<hr>\n\nFor guides on how to get started and setup your environment, contributor & committer guides, visit: [Contribution Guidelines](https://shardingsphere.apache.org/community/en/involved/)\n\n### Team\n\n<hr>\n\nWe deeply appreciate [community contributors](https://shardingsphere.apache.org/community/en/team) for their dedication to Apache ShardingSphere.\n\n##\n\n### COMMUNITY & SUPPORTğŸ’ğŸ–¤\n\n<hr>\n\n:link: [Mailing List](https://shardingsphere.apache.org/community/en/involved/subscribe/). Best for: Apache community updates, releases, changes.\n\n:link: [GitHub Issues](https://github.com/apache/shardingsphere/issues). Best for: larger systemic questions/bug reports or anything development related.\n\n:link: [GitHub Discussions](https://github.com/apache/shardingsphere/discussions). Best for: technical questions & support, requesting new features, proposing new features.\n\n:link: [Slack channel](https://join.slack.com/t/apacheshardingsphere/shared_invite/zt-sbdde7ie-SjDqo9~I4rYcR18bq0SYTg). Best for: instant communications and online meetings, sharing your applications.\n\n:link: [Twitter](https://twitter.com/ShardingSphere). Best for: keeping up to date on everything ShardingSphere.\n\n:link: [LinkedIn](https://www.linkedin.com/showcase/apache-shardingsphere/e). Best for: professional networking and career development with other ShardingSphere contributors.\n\n##\n\n### PROJECT STATUS\n\n<hr>\n\n:white_check_mark: **Version 5.5.3-SNAPSHOT**: Actively under development :tada:\n\nğŸ”— For the release notes, follow this link to the relevant [GitHub page](https://github.com/apache/shardingsphere/blob/master/RELEASE-NOTES.md).\n\n:soon: **Version 5.5.3**\n\nWe are currently developing version 5.5.3, which includes multiple security enhancements and performance optimizations.\nKeep an eye on the [milestones page](https://github.com/apache/shardingsphere/milestones) of this repo for the latest development progress.\n\n[comment]: <> (##)\n\n[comment]: <> (### NIGHTLY BUILDS:)\n\n[comment]: <> (<hr>)\n\n[comment]: <> (A nightly build of ShardingSphere from the latest master branch is available. )\n\n[comment]: <> (The package is updated daily and is available [here]&#40;http://117.48.121.24:8080&#41;.)\n\n[comment]: <> (##)\n\n[comment]: <> (**â€¼ï¸ Notice:**)\n\n[comment]: <> (<hr>)\n\n[comment]: <> (Use this nightly build at your own risk! )\n\n[comment]: <> (The branch is not always fully tested. )\n\n[comment]: <> (The nightly build may contain bugs, and there may be new features added which may cause problems with your environment. )\n\n##\n\n### TECHNICAL ARCHITECTURE EVOLUTION\n\n<hr>\n\nApache ShardingSphere adopts a micro-kernel + 3-layer pluggable architecture, achieving complete decoupling of the kernel, functional components, and ecosystem integration, providing developers with ultimate flexibility and extensibility.\n\n#### Micro-Kernel + 3-Layer Pluggable Model\n\n**Core Layer**:\n- Query optimizer: Intelligent SQL routing and execution plan optimization\n- Distributed transaction: ACID transaction guarantees and consistency coordination\n- Execution engine: Efficient distributed execution and result aggregation\n\n**Feature Layer**:\n- Data sharding, readwrite-splitting, federation query\n- Data encryption, data masking, SQL audit\n- Shadow database, observability, traffic control\n\n**Ecosystem Layer**:\n- Database protocol adaptation (MySQL, PostgreSQL, Oracle, etc.)\n- Registry center integration (ZooKeeper, ETCD, etc.)\n- Configuration management, service discovery, monitoring integration\n\n#### Technical Innovation Highlights\n\n**Complete Decoupling Architecture**:\n- Database types completely decoupled, supporting rapid integration of new databases\n- Functional modules completely decoupled, supporting on-demand feature combination\n\nApache ShardingSphere consists of two access ends - JDBC and Proxy - that can be deployed independently or in hybrid deployment, providing unified distributed database solutions for diverse application scenarios including Java isomorphism, heterogeneous languages, and cloud-native environments.\n\n### ShardingSphere-JDBC\n\n<hr>\n\n[![Maven Status](https://img.shields.io/maven-central/v/org.apache.shardingsphere/shardingsphere-jdbc.svg?color=green)](https://mvnrepository.com/artifact/org.apache.shardingsphere/shardingsphere-jdbc)\n\nA lightweight Java framework providing extra services at the Java JDBC layer. \nWith the client end connecting directly to the database, it provides services in the form of a jar and requires no extra deployment and dependence.\n\n:link: For more details, follow this [link to the official website](https://shardingsphere.apache.org/document/current/en/overview/#shardingsphere-jdbc).\n\n> **Note**: When using ShardingSphere-JDBC adapter, pay attention to your application's memory configuration. Antlr uses an internal cache to improve performance during SQL parsing. If your application has too many SQL templates, the cache will continue to grow, occupying a large amount of heap memory.\nAccording to feedback from the ANTLR official [issue#4232](https://github.com/antlr/antlr4/issues/4232), this issue has not yet been optimized. When connecting your application to ShardingSphere-JDBC, it is recommended to set a reasonable heap memory size using the `-Xmx` parameter to avoid OOM errors caused by insufficient memory.\n\n### ShardingSphere-Proxy\n\n<hr>\n\n[![Nightly-Download](https://img.shields.io/static/v1?label=nightly-builds&message=download&color=orange)](https://nightlies.apache.org/shardingsphere/)\n[![Download](https://img.shields.io/badge/release-download-orange.svg)](https://www.apache.org/dyn/closer.lua/shardingsphere/5.3.2/apache-shardingsphere-5.3.2-shardingsphere-proxy-bin.tar.gz)\n[![Docker Pulls](https://img.shields.io/docker/pulls/apache/shardingsphere-proxy.svg)](https://store.docker.com/community/images/apache/shardingsphere-proxy)\n\nA transparent database proxy, providing a database server that encapsulates the database binary protocol to support heterogeneous languages. \nFriendlier to DBAs, the MariaDB, MySQL and PostgreSQL version now provided can use any kind of terminal.\n\n:link: For more details, follow this [link to the official website](https://shardingsphere.apache.org/document/current/en/overview/#shardingsphere-proxy).\n\n### Hybrid Architecture\n\n<hr>\n\nShardingSphere-JDBC adopts a decentralized architecture, applicable to high-performance light-weight OLTP applications developed with Java. \nShardingSphere-Proxy provides static entry and all languages support, suitable for an OLAP application and sharding databases management and operation.\n\nThrough the combination of ShardingSphere-JDBC & ShardingSphere-Proxy together with a unified sharding strategy by the same registry center, the ShardingSphere ecosystem can build an application system suitable to all kinds of scenarios.\n\n:link: More details can be found following this [link to the official website](https://shardingsphere.apache.org/document/current/en/overview/#hybrid-architecture).\n\n##\n\n### CORE FEATURE MATRIX\n\n<hr>\n\n#### Distributed Database Core Capabilities\n- **Data Sharding**: Horizontal sharding, vertical sharding, custom sharding strategies, automatic sharding routing\n- **Read/Write Splitting**: Master-slave replication, load balancing, failover, read weight configuration\n- **Distributed Transaction**: XA transactions, BASE transactions, transaction propagation\n\n#### Data Security & Governance\n- **Data Encryption**: Field-level encryption, transparent encryption, key management, encryption algorithm support\n- **Data Masking**: Sensitive data protection, masking strategy customization, dynamic masking rules\n- **Access Control**: Fine-grained permissions, access control, SQL firewall, security policies\n\n#### Database Gateway Capabilities\n- **Heterogeneous Databases**: MySQL, PostgreSQL, Oracle, SQL Server, Firebird, etc.\n- **SQL Dialect Translation**: Cross-database SQL compatibility, dialect adaptation, syntax conversion\n- **Protocol Adaptation**: Database protocol conversion, multi-protocol support, communication optimization\n\n#### Full-link Stress Testing & Observability\n- **Shadow Database**: Stress testing data isolation, environment separation, real data simulation\n- **Observability**: Performance monitoring, distributed tracing, QoS analysis, metrics collection\n- **Traffic Analysis**: SQL performance analysis, traffic statistics, bottleneck identification\n\n#### Enterprise-grade Features\n- **High Availability**: Cluster deployment, fault recovery, service discovery, health checks\n- **Cloud Native**: Containerized deployment, Kubernetes integration, native image support\n- **Monitoring & Alerting**: Real-time monitoring, alert notifications, performance metrics, O&M dashboard\n\n##\n\n### Roadmap\n\n<hr>\n\n![Roadmap](https://shardingsphere.apache.org/document/current/img/roadmap_en.png)\n\n##\n\n### How to Build Apache ShardingSphere\n\n<hr>\n\nCheck out [Wiki](https://github.com/apache/shardingsphere/wiki) section for details on how to build Apache ShardingSphere and a full guide on how to get started and setup your local dev environment.\n\n##\n\n### Landscapes\n\n<hr>\n\n<p align=\"center\">\n<br/><br/>\n<img src=\"https://landscape.cncf.io/images/cncf-landscape-horizontal-color.svg\" width=\"165\"/>&nbsp;&nbsp;<img src=\"https://www.cncf.io/wp-content/uploads/2023/04/cncf-main-site-logo.svg\" width=\"200\"/>\n<br/><br/>\nApache ShardingSphere enriches the <a href=\"https://landscape.cncf.io/?category=app-definition-and-development&grouping=category\">CNCF CLOUD NATIVE Landscape</a>.\n</p>\n\n##\n",
      "stars_today": 6
    },
    {
      "id": 126412363,
      "name": "simdjson",
      "full_name": "simdjson/simdjson",
      "description": "Parsing gigabytes of JSON per second : used by Facebook/Meta Velox, the Node.js runtime, ClickHouse, WatermelonDB, Apache Doris, Milvus, StarRocks",
      "html_url": "https://github.com/simdjson/simdjson",
      "stars": 23117,
      "forks": 1206,
      "language": "C++",
      "topics": [
        "aarch64",
        "arm",
        "arm64",
        "avx2",
        "avx512",
        "c-plus-plus",
        "clang",
        "clang-cl",
        "cpp11",
        "gcc-compiler",
        "json",
        "json-parser",
        "json-pointer",
        "loongarch",
        "neon",
        "simd",
        "sse42",
        "vs2019",
        "x64"
      ],
      "created_at": "2018-03-23T00:49:18Z",
      "updated_at": "2026-01-15T20:50:14Z",
      "pushed_at": "2026-01-09T18:28:14Z",
      "open_issues": 149,
      "owner": {
        "login": "simdjson",
        "avatar_url": "https://avatars.githubusercontent.com/u/62337925?v=4"
      },
      "readme": "[![][license img]][license] [![][licensemit img]][licensemit]\n\n\n[![Doxygen Documentation](https://img.shields.io/badge/docs-doxygen-green.svg)](https://simdjson.github.io/simdjson/)\n\nsimdjson : Parsing gigabytes of JSON per second\n===============================================\n\n<img src=\"images/official_logo/logo_noir/SVG/logo_simdjson_noir.svg\" width=\"40%\" style=\"float: right\">\n\nJSON is everywhere on the Internet. Servers spend a *lot* of time parsing it. We need a fresh\napproach. The simdjson library uses commonly available SIMD instructions and microparallel algorithms\nto parse JSON 4x  faster than RapidJSON and 25x faster than JSON for Modern C++.\n\n* **Fast:** Over 4x faster than commonly used production-grade JSON parsers.\n* **Record Breaking Features:** Minify JSON  at 6 GB/s, validate UTF-8  at 13 GB/s,  NDJSON at 3.5 GB/s.\n* **Easy:** First-class, easy to use and carefully documented APIs.\n* **Strict:** Full JSON and UTF-8 validation, lossless parsing. Performance with no compromises.\n* **Automatic:** Selects a CPU-tailored parser at runtime. No configuration needed.\n* **Reliable:** From memory allocation to error handling, simdjson's design avoids surprises.\n* **Peer Reviewed:** Our research appears in venues like VLDB Journal, Software: Practice and Experience.\n\nThis library is part of the [Awesome Modern C++](https://awesomecpp.com) list.\n\nTable of Contents\n-----------------\n\n* [Real-world usage](#real-world-usage)\n* [Quick Start](#quick-start)\n* [Documentation](#documentation)\n* [Godbolt](#godbolt)\n* [Performance results](#performance-results)\n* [Packages](#packages)\n* [Bindings and Ports of simdjson](#bindings-and-ports-of-simdjson)\n* [About simdjson](#about-simdjson)\n* [Funding](#funding)\n* [Contributing to simdjson](#contributing-to-simdjson)\n* [License](#license)\n\n\nReal-world usage\n----------------\n\n- [Node.js](https://nodejs.org/)\n- [ClickHouse](https://github.com/ClickHouse/ClickHouse)\n- [Meta Velox](https://velox-lib.io)\n- [Google Pax](https://github.com/google/paxml)\n- [milvus](https://github.com/milvus-io/milvus)\n- [QuestDB](https://questdb.io/blog/questdb-release-8-0-3/)\n- [Clang Build Analyzer](https://github.com/aras-p/ClangBuildAnalyzer)\n- [Shopify HeapProfiler](https://github.com/Shopify/heap-profiler)\n- [StarRocks](https://github.com/StarRocks/starrocks)\n- [Microsoft FishStore](https://github.com/microsoft/FishStore)\n- [Intel PCM](https://github.com/intel/pcm)\n- [WatermelonDB](https://github.com/Nozbe/WatermelonDB)\n- [Apache Doris](https://github.com/apache/doris)\n- [Dgraph](https://github.com/dgraph-io/dgraph)\n- [UJRPC](https://github.com/unum-cloud/ujrpc)\n- [fastgltf](https://github.com/spnda/fastgltf)\n- [vast](https://github.com/tenzir/vast)\n- [ada-url](https://github.com/ada-url/ada)\n- [fastgron](https://github.com/adamritter/fastgron)\n- [WasmEdge](https://wasmedge.org)\n- [RonDB](https://github.com/logicalclocks/rondb)\n- [GreptimeDB](https://github.com/GreptimeTeam/greptimedb)\n- [mamba](https://github.com/mamba-org/mamba)\n\n\nIf you are planning to use simdjson in a product, please work from one of our releases.\n\n\n\n\nQuick Start\n-----------\n\nThe simdjson library is easily consumable with a single .h and .cpp file.\n\n0. Prerequisites: `g++` (version 7 or better) or `clang++` (version 6 or better), and a 64-bit\n   system with a command-line shell (e.g., Linux, macOS, freeBSD). We also support programming\n   environments like Visual Studio and Xcode, but different steps are needed. Users of clang++ may need to specify the C++ version (e.g., `c++ -std=c++17`) since clang++ tends to default on C++98.\n1. Pull [simdjson.h](singleheader/simdjson.h) and [simdjson.cpp](singleheader/simdjson.cpp) into a\n   directory, along with the sample file [twitter.json](jsonexamples/twitter.json). You can download them with the `wget` utility:\n\n   ```\n   wget https://raw.githubusercontent.com/simdjson/simdjson/master/singleheader/simdjson.h https://raw.githubusercontent.com/simdjson/simdjson/master/singleheader/simdjson.cpp https://raw.githubusercontent.com/simdjson/simdjson/master/jsonexamples/twitter.json\n   ```\n2. Create `quickstart.cpp`:\n\n```cpp\n#include <iostream>\n#include \"simdjson.h\"\nusing namespace simdjson;\nint main(void) {\n    ondemand::parser parser;\n    padded_string json = padded_string::load(\"twitter.json\");\n    ondemand::document tweets = parser.iterate(json);\n    std::cout << uint64_t(tweets[\"search_metadata\"][\"count\"]) << \" results.\" << std::endl;\n}\n```\n3. `c++ -o quickstart quickstart.cpp simdjson.cpp`\n4. `./quickstart`\n\n  ```\n   100 results.\n  ```\n\n\nDocumentation\n-------------\n\nUsage documentation is available:\n\n* [Basics](doc/basics.md) is an overview of how to use simdjson and its APIs.\n* [Builder](doc/builder.md) is an overview of how to efficiently write JSON strings using simdjson.\n* [Performance](doc/performance.md) shows some more advanced scenarios and how to tune for them.\n* [Implementation Selection](doc/implementation-selection.md) describes runtime CPU detection and\n  how you can work with it.\n* [API](https://simdjson.github.io/simdjson/) contains the automatically generated API documentation.\n* [Compile-Time Parsing](doc/compile_time.md) presents our compile-time parsing function (C++26 only).\n\n\nGodbolt\n-------------\n\nSome users may want to browse code along with the compiled assembly. You want to check out the following lists of examples:\n* [C++26 reflection example](https://godbolt.org/z/K3Px64TqK)\n* [simdjson examples with errors handled through exceptions](https://godbolt.org/z/7G5qE4sr9)\n* [simdjson examples with errors without exceptions](https://godbolt.org/z/e9dWb9E4v)\n\nPerformance results\n-------------------\n\nThe simdjson library uses three-quarters less instructions than state-of-the-art parser [RapidJSON](https://rapidjson.org). To our knowledge, simdjson is the first fully-validating JSON parser\nto run at [gigabytes per second](https://en.wikipedia.org/wiki/Gigabyte) (GB/s) on commodity processors. It can parse millions of JSON documents per second on a single core.\n\nThe following figure represents parsing speed in GB/s for parsing various files\non an Intel Skylake processor (3.4 GHz) using the GNU GCC 10 compiler (with the -O3 flag).\nWe compare against the best and fastest C++ libraries on benchmarks that load and process the data.\nThe simdjson library offers full unicode ([UTF-8](https://en.wikipedia.org/wiki/UTF-8)) validation and exact\nnumber parsing.\n\n<img src=\"doc/rome.png\" width=\"60%\">\n\nThe simdjson library offers high speed whether it processes tiny files (e.g., 300 bytes)\nor larger files (e.g., 3MB). The following plot presents parsing\nspeed for [synthetic files over various sizes generated with a script](https://github.com/simdjson/simdjson_experiments_vldb2019/blob/master/experiments/growing/gen.py) on a 3.4 GHz Skylake processor (GNU GCC 9, -O3).\n\n<img src=\"doc/growing.png\" width=\"60%\">\n\n[All our experiments are reproducible](https://github.com/simdjson/simdjson_experiments_vldb2019).\n\n\nFor NDJSON files, we can exceed 3 GB/s with [our  multithreaded parsing functions](https://github.com/simdjson/simdjson/blob/master/doc/parse_many.md).\n\n\nPackages\n------------------------------\n[![Packaging status](https://repology.org/badge/vertical-allrepos/simdjson.svg)](https://repology.org/project/simdjson/versions)\n\n\nBindings and Ports of simdjson\n------------------------------\n\nWe distinguish between \"bindings\" (which just wrap the C++ code) and a port to another programming language (which reimplements everything).\n\n- [ZippyJSON](https://github.com/michaeleisel/zippyjson): Swift bindings for the simdjson project.\n- [libpy_simdjson](https://github.com/gerrymanoim/libpy_simdjson/): high-speed Python bindings for simdjson using [libpy](https://github.com/quantopian/libpy).\n- [pysimdjson](https://github.com/TkTech/pysimdjson): Python bindings for the simdjson project.\n- [cysimdjson](https://github.com/TeskaLabs/cysimdjson): high-speed Python bindings for the simdjson project.\n- [simdjson-rs](https://github.com/simd-lite): Rust port.\n- [simdjson-rust](https://github.com/SunDoge/simdjson-rust): Rust wrapper (bindings).\n- [SimdJsonSharp](https://github.com/EgorBo/SimdJsonSharp): C# version for .NET Core (bindings and full port).\n- [simdjson_nodejs](https://github.com/luizperes/simdjson_nodejs): Node.js bindings for the simdjson project.\n- [simdjson_php](https://github.com/crazyxman/simdjson_php): PHP bindings for the simdjson project.\n- [simdjson_ruby](https://github.com/saka1/simdjson_ruby): Ruby bindings for the simdjson project.\n- [fast_jsonparser](https://github.com/anilmaurya/fast_jsonparser): Ruby bindings for the simdjson project.\n- [simdjson-go](https://github.com/minio/simdjson-go): Go port using Golang assembly.\n- [rcppsimdjson](https://github.com/eddelbuettel/rcppsimdjson): R bindings.\n- [simdjson_erlang](https://github.com/ChomperT/simdjson_erlang): erlang bindings.\n- [simdjsone](https://github.com/saleyn/simdjsone): erlang bindings.\n- [lua-simdjson](https://github.com/FourierTransformer/lua-simdjson): lua bindings.\n- [hermes-json](https://hackage.haskell.org/package/hermes-json): haskell bindings.\n- [zimdjson](https://github.com/EzequielRamis/zimdjson): Zig port.\n- [simdjzon](https://github.com/travisstaloch/simdjzon): Zig port.\n- [JSON-Simd](https://github.com/rawleyfowler/JSON-simd): Raku bindings.\n- [JSON::SIMD](https://metacpan.org/pod/JSON::SIMD): Perl bindings; fully-featured JSON module that uses simdjson for decoding.\n- [gemmaJSON](https://github.com/sainttttt/gemmaJSON): Nim JSON parser based on simdjson bindings.\n- [simdjson-java](https://github.com/simdjson/simdjson-java): Java port.\n\nAbout simdjson\n--------------\n\nThe simdjson library takes advantage of modern microarchitectures, parallelizing with SIMD vector\ninstructions, reducing branch misprediction, and reducing data dependency to take advantage of each\nCPU's multiple execution cores.\n\nOur default front-end is called On-Demand, and we wrote a paper about it:\n\n- John Keiser, Daniel Lemire, [On-Demand JSON: A Better Way to Parse Documents?](http://arxiv.org/abs/2312.17149), Software: Practice and Experience 54 (6), 2024.\n\nSome people [enjoy reading the first (2019) simdjson paper](https://arxiv.org/abs/1902.08318): A description of the design\nand implementation of simdjson is in our research article:\n- Geoff Langdale, Daniel Lemire, [Parsing Gigabytes of JSON per Second](https://arxiv.org/abs/1902.08318), VLDB Journal 28 (6), 2019.\n\nWe have an in-depth paper focused on the UTF-8 validation:\n\n- John Keiser, Daniel Lemire, [Validating UTF-8 In Less Than One Instruction Per Byte](https://arxiv.org/abs/2010.03090), Software: Practice & Experience 51 (5), 2021.\n\nWe also have an informal [blog post providing some background and context](https://branchfree.org/2019/02/25/paper-parsing-gigabytes-of-json-per-second/).\n\nFor the video inclined, <br />\n[![simdjson at QCon San Francisco 2019](http://img.youtube.com/vi/wlvKAT7SZIQ/0.jpg)](http://www.youtube.com/watch?v=wlvKAT7SZIQ)<br />\n(It was the best voted talk, we're kinda proud of it.)\n\nCiting this work\n-----------------\n\nIf you use simdjson in published research, please cite the software library. A suitable BibTeX entry is:\n\n```bibtex\n@misc{simdjson,\n  title={{The simdjson library: Parsing Gigabytes of JSON per Second}},\n  author={Daniel Lemire and Geoff Langdale and John Keiser and Paul Dreik and Francisco Thiesen and others},\n  year={2019},\n  howpublished={Software library},\n  note={https://github.com/simdjson/simdjson}\n}\n```\n\nFunding\n-------\n\nThe work is supported by the Natural Sciences and Engineering Research Council of Canada under grants\nRGPIN-2017-03910 and RGPIN-2024-03787.\n\n[license]: LICENSE\n[license img]: https://img.shields.io/badge/License-Apache%202-blue.svg\n\n\n[licensemit]: LICENSE-MIT\n[licensemit img]: https://img.shields.io/badge/License-MIT-blue.svg\n\n\nContributing to simdjson\n------------------------\n\nHead over to [CONTRIBUTING.md](CONTRIBUTING.md) for information on contributing to simdjson, and\n[HACKING.md](HACKING.md) for information on source, building, and architecture/design.\n\n\nStars\n------\n\n[![Star History Chart](https://api.star-history.com/svg?repos=simdjson/simdjson&type=Date)](https://www.star-history.com/#simdjson/simdjson&Date)\n\n\nLicense\n-------\n\nThis code is made available under the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0.html) as well as under the MIT License. As a user, you can pick the license you prefer.\n\nUnder Windows, we build some tools using the windows/dirent_portable.h file (which is outside our library code): it is under the liberal (business-friendly) MIT license.\n\nFor compilers that do not support [C++17](https://en.wikipedia.org/wiki/C%2B%2B17), we bundle the string-view library which is published under the [Boost license](http://www.boost.org/LICENSE_1_0.txt). Like the Apache license, the Boost license is a permissive license allowing commercial redistribution.\n\nFor efficient number serialization, we bundle Florian Loitsch's implementation of the Grisu2 algorithm for binary to decimal floating-point numbers. The implementation was slightly modified by JSON for Modern C++ library. Both Florian Loitsch's implementation and JSON for Modern C++ are provided under the MIT license.\n\nFor runtime dispatching, we use some code from the PyTorch project licensed under 3-clause BSD.\n",
      "stars_today": 6
    },
    {
      "id": 253044228,
      "name": "nuclei-templates",
      "full_name": "projectdiscovery/nuclei-templates",
      "description": "Community curated list of templates for the nuclei engine to find security vulnerabilities.",
      "html_url": "https://github.com/projectdiscovery/nuclei-templates",
      "stars": 11797,
      "forks": 3304,
      "language": "JavaScript",
      "topics": [
        "bugbounty",
        "exploit-development",
        "exploits",
        "fingerprint",
        "hacktoberfest",
        "nuclei",
        "nuclei-checks",
        "nuclei-templates",
        "security",
        "vulnerability-detection"
      ],
      "created_at": "2020-04-04T16:21:34Z",
      "updated_at": "2026-01-15T23:13:39Z",
      "pushed_at": "2026-01-16T00:19:31Z",
      "open_issues": 157,
      "owner": {
        "login": "projectdiscovery",
        "avatar_url": "https://avatars.githubusercontent.com/u/50994705?v=4"
      },
      "readme": "\n\n<h1 align=\"center\">\nNuclei Templates\n</h1>\n<h4 align=\"center\">Community curated list of templates for the nuclei engine to find security vulnerabilities in applications.</h4>\n\n\n<p align=\"center\">\n<a href=\"https://github.com/projectdiscovery/nuclei-templates/issues\"><img src=\"https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat\"></a>\n<a href=\"https://github.com/projectdiscovery/nuclei-templates/releases\"><img src=\"https://img.shields.io/github/release/projectdiscovery/nuclei-templates\"></a>\n<a href=\"https://twitter.com/pdnuclei\"><img src=\"https://img.shields.io/twitter/follow/pdnuclei.svg?logo=twitter\"></a>\n<a href=\"https://discord.gg/projectdiscovery\"><img src=\"https://img.shields.io/discord/695645237418131507.svg?logo=discord\"></a>\n</p>\n      \n<p align=\"center\">\n  <a href=\"https://docs.projectdiscovery.io/templates/introduction\">Documentation</a> â€¢\n  <a href=\"#-contributions\">Contributions</a> â€¢\n  <a href=\"#-discussion\">Discussion</a> â€¢\n  <a href=\"#-community\">Community</a> â€¢\n  <a href=\"https://docs.projectdiscovery.io/templates/faq\">FAQs</a> â€¢\n  <a href=\"https://discord.gg/projectdiscovery\">Join Discord</a>\n</p>\n\n----\n\nTemplates are the core of the [nuclei scanner](https://github.com/projectdiscovery/nuclei) which powers the actual scanning engine.\nThis repository stores and houses various templates for the scanner provided by our team, as well as contributed by the community.\nWe hope that you also contribute by sending templates via **pull requests** or [Github issues](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=submit-template.md&title=%5Bnuclei-template%5D+) to grow the list.\n\n\n## Nuclei Templates overview\n\n\nAn overview of the nuclei template project, including statistics on unique tags, author, directory, severity, and type of templates. The table below contains the top ten statistics for each matrix; an expanded version of this is [available here](TEMPLATES-STATS.md), and also available in [JSON](TEMPLATES-STATS.json) format for integration.\n\n<table>\n<tr>\n<td>\n\n### ğŸš¨ Known Exploited Vulnerabilities (KEV) Coverage\n\nNuclei templates provide coverage for vulnerabilities actively exploited in the wild:\n\n| **KEV Source** | **Templates** | **Description** |\n|----------------|---------------|-----------------|\n| ğŸ”´ **CISA KEV** | **454** | [CISA Known Exploited Vulnerabilities Catalog](https://www.cisa.gov/known-exploited-vulnerabilities-catalog) |\n| ğŸŸ  **VulnCheck KEV** | **1449** | [VulnCheck KEV](https://vulncheck.com/kev) - Enhanced vulnerability intelligence |\n| ğŸŸ¢ **Both Sources** | **407** | Templates covering vulnerabilities in both catalogs |\n\n> ğŸ’¡ **Total unique KEV templates: 1496** - Use `nuclei -tags kev,vkev` to scan for actively exploited vulnerabilities\n\n---\n\n## Nuclei Templates Top 10 statistics\n\n|    TAG    | COUNT |    AUTHOR     | COUNT | DIRECTORY  | COUNT | SEVERITY | COUNT | TYPE | COUNT |\n|-----------|-------|---------------|-------|------------|-------|----------|-------|------|-------|\n| vuln      |  6468 | dhiyaneshdk   |  1894 | http       |  9281 | info     |  4353 | file |   436 |\n| cve       |  3587 | daffainfo     |   905 | cloud      |   659 | high     |  2552 | dns  |    26 |\n| discovery |  3265 | princechaddha |   854 | file       |   436 | medium   |  2457 |      |       |\n| vkev      |  1394 | dwisiswant0   |   805 | network    |   259 | critical |  1555 |      |       |\n| panel     |  1365 | ritikchaddha  |   678 | code       |   251 | low      |   330 |      |       |\n| xss       |  1269 | pussycat0x    |   675 | dast       |   240 | unknown  |    54 |      |       |\n| wordpress |  1261 | pikpikcu      |   353 | workflows  |   205 |          |       |      |       |\n| exposure  |  1141 | pdteam        |   314 | javascript |    92 |          |       |      |       |\n| wp-plugin |  1103 | pdresearch    |   275 | ssl        |    38 |          |       |      |       |\n| osint     |   848 | iamnoooob     |   263 | dns        |    23 |          |       |      |       |\n\n**873 directories, 11997 files**.\n\n</td>\n</tr>\n</table>\n\nğŸ“– Documentation\n-----\n\nPlease navigate to https://nuclei.projectdiscovery.io for detailed documentation to **build** new or your own **custom** templates.\nWe have also added a set of templates to help you understand how things work.\n\nğŸ’ª Contributions\n-----\n\nNuclei-templates is powered by major contributions from the community.\n[Template contributions ](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=submit-template.md&title=%5Bnuclei-template%5D+), [Feature Requests](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=feature_request.md&title=%5BFeature%5D+) and [Bug Reports](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=bug_report.md&title=%5BBug%5D+) are more than welcome.\n\n![Alt](https://repobeats.axiom.co/api/embed/55ee65543bb9a0f9c797626c4e66d472a517d17c.svg \"Repobeats analytics image\")\n\nğŸ’¬ Discussion\n-----\n\nHave questions / doubts / ideas to discuss?\nFeel free to open a discussion on [Github discussions](https://github.com/projectdiscovery/nuclei-templates/discussions) board.\n\nğŸ‘¨â€ğŸ’» Community\n-----\n\nYou are welcome to join the active [Discord Community](https://discord.gg/projectdiscovery) to discuss directly with project maintainers and share things with others around security and automation.\nAdditionally, you may follow us on [Twitter](https://twitter.com/pdnuclei) to be updated on all the things about Nuclei.\n\n\n<p align=\"center\">\n<a href=\"https://github.com/projectdiscovery/nuclei-templates/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=projectdiscovery/nuclei-templates&max=300\">\n</a>\n</p>\n\n\nThanks again for your contribution and keeping this community vibrant. :heart:\n",
      "stars_today": 6
    },
    {
      "id": 23500865,
      "name": "hyper",
      "full_name": "hyperium/hyper",
      "description": "An HTTP library for Rust",
      "html_url": "https://github.com/hyperium/hyper",
      "stars": 15858,
      "forks": 1704,
      "language": "Rust",
      "topics": [
        "http",
        "hyper",
        "rust"
      ],
      "created_at": "2014-08-30T21:14:33Z",
      "updated_at": "2026-01-16T00:08:56Z",
      "pushed_at": "2026-01-12T20:32:08Z",
      "open_issues": 243,
      "owner": {
        "login": "hyperium",
        "avatar_url": "https://avatars.githubusercontent.com/u/8730506?v=4"
      },
      "readme": "# [hyper](https://hyper.rs)\n\n[![crates.io](https://img.shields.io/crates/v/hyper.svg)](https://crates.io/crates/hyper)\n[![Released API docs](https://docs.rs/hyper/badge.svg)](https://docs.rs/hyper)\n[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)\n[![CI](https://github.com/hyperium/hyper/workflows/CI/badge.svg)](https://github.com/hyperium/hyper/actions?query=workflow%3ACI)\n[![Discord chat][discord-badge]][discord-url]\n\nA protective and efficient HTTP library for all.\n\n- HTTP/1 and HTTP/2\n- Asynchronous design\n- Leading in performance\n- Tested and **correct**\n- Extensive production use\n- Client and Server APIs\n\n**Get started** by looking over the [guides](https://hyper.rs/guides/1/).\n\n## \"Low-level\"\n\nhyper is a relatively low-level library, meant to be a building block for\nlibraries and applications.\n\nIf you are looking for a convenient HTTP client, then you may wish to consider\n[reqwest](https://github.com/seanmonstar/reqwest).\n\nIf you are not sure what HTTP server to choose, then you may want to consider\n[axum](https://github.com/tokio-rs/axum) or\n[warp](https://github.com/seanmonstar/warp), the latter taking a more functional\napproach. Both are built on top of this library.\n\n## Contributing\n\nTo get involved, take a look at [CONTRIBUTING](CONTRIBUTING.md).\n\nIf you prefer chatting, there is an active community in the [Discord server][discord-url].\n\n## License\n\nhyper is provided under the MIT license. See [LICENSE](LICENSE).\n\n[discord-badge]: https://img.shields.io/discord/500028886025895936.svg?logo=discord\n[discord-url]: https://discord.gg/kkwpueZ\n",
      "stars_today": 6
    },
    {
      "id": 999686447,
      "name": "vscode-copilot-chat",
      "full_name": "microsoft/vscode-copilot-chat",
      "description": "Copilot Chat extension for VS Code",
      "html_url": "https://github.com/microsoft/vscode-copilot-chat",
      "stars": 9279,
      "forks": 1571,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-06-10T16:21:19Z",
      "updated_at": "2026-01-16T00:28:35Z",
      "pushed_at": "2026-01-16T00:41:02Z",
      "open_issues": 124,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# GitHub Copilot - Your AI peer programmer\n\n**[GitHub Copilot](https://code.visualstudio.com/docs/copilot/overview)** is an AI peer programming tool that helps you write code faster and smarter.\n\nGitHub Copilot adapts to your unique needs allowing you to select the best model for your project, customize chat responses with custom instructions, and utilize agent mode for AI-powered, seamlessly integrated peer programming sessions.\n\n**Sign up for [GitHub Copilot Free](https://github.com/settings/copilot?utm_source=vscode-chat-readme&utm_medium=first&utm_campaign=2025mar-em-MSFT-signup)!**\n\n![Working with GitHub Copilot agent mode to make edits to code in your workspace](https://github.com/microsoft/vscode-copilot-release/blob/main/images/hero-dark.png?raw=true)\n\nWhen you install Copilot in Visual Studio Code, you get two extensions:\n* **[GitHub Copilot](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot)** - Provides inline coding suggestions as you type.\n* **[GitHub Copilot Chat](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat)** (this extension) - A companion extension that provides conversational AI assistance.\n\n## Getting access to GitHub Copilot\n\nSign up for [GitHub Copilot Free](https://github.com/settings/copilot?utm_source=vscode-chat-readme&utm_medium=second&utm_campaign=2025mar-em-MSFT-signup), or request access from your enterprise admin.\n\nTo access GitHub Copilot, an active GitHub Copilot subscription is required. You can read more about our business and individual offerings at [github.com/features/copilot](https://github.com/features/copilot?utm_source=vscode-chat&utm_medium=readme&utm_campaign=2025mar-em-MSFT-signup).\n\n## AI-powered coding sessions\n\n**Start an AI-powered coding session tailored to your workflow**. Copilot Edits allows you to quickly iterate on code changes directly in the editor, across multiple files using natural language. For a more autonomous peer programmer experience,\n[agent mode](https://aka.ms/vscode-copilot-agent) performs multi-step coding tasks at your command. It automatically handles compile and lint errors, monitors terminal and test output, and iterates until the task is complete. [Edit mode](https://aka.ms/vscode-copilot-edit) offers a conversational, step-by-step coding experience. Engage in multi-turn chat conversations while Copilot applies edits directly to your codebase, allowing you to review changes in context and maintain full control.\n\n![Agent mode in Copilot Chat creating a new Vue application](https://github.com/microsoft/vscode-copilot-release/blob/main/images/agent-mode-readme.gif?raw=true)\n\n## Inline suggestions in the editor\n\n**Automatically receive inline suggestions in the editor** from [ghost text suggestions](https://aka.ms/vscode-completions) and [next edit suggestions](https://aka.ms/vscode-nes) to help you write code faster. Ghost text suggestions provide suggestions at the current location, tailored to your coding style and your existing code. Copilot next edit suggestions (Copilot NES) takes it a step further and predicts what and where your next logical code change will be. Use the Tab key to navigate and accept changes in quick succession.\n\n![Copilot next edit suggestions](https://code.visualstudio.com/assets/docs/copilot/inline-suggestions/nes-point.gif)\n\n## Ask and learn about your code with chat\n\n**Ask Copilot for help with any task or question** in the [Chat view](https://aka.ms/vscode-chat), bringing in code from your current files. Rather than giving you a generic answer, it can give answers that are relevant for your codebase using information provided by [participants](https://aka.ms/vscode-chat-participants), [variables](https://aka.ms/vscode-chat-variables), and [slash commands](https://aka.ms/vscode-chat-commands).\n\n![Using the workspace chat participant](https://github.com/microsoft/vscode-copilot-release/blob/main/images/participants-workspace.gif?raw=true)\n\n**Apply Copilot's AI suggestions directly to your code** using [Inline chat](https://aka.ms/vscode-inline-chat), staying in the flow. Need help with refactoring a method, adding error handling, or explaining a complex algorithm - just launch Copilot in the editor!\n\n![Inline chat in VS Code](https://code.visualstudio.com/assets/docs/copilot/copilot-chat/inline-chat-question-example.png)\n\n### Supported languages and frameworks\n\nGitHub Copilot works on any language, including Java, PHP, Python, JavaScript, Ruby, Go, C#, or C++. Because itâ€™s been trained on languages in public repositories, it works for most popular languages, libraries and frameworks.\n\n### Version compatibility\n\nAs Copilot Chat releases in lockstep with VS Code due to its deep UI integration, every new version of Copilot Chat is only compatible with the latest and newest release of VS Code. This means that if you are using an older version of VS Code, you will not be able to use the latest Copilot Chat.\n\nOnly the latest Copilot Chat versions will use the latest models provided by the Copilot service, as even minor model upgrades require prompt changes and fixes in the extension.\n\n### Privacy and preview terms\n\nBy using Copilot Chat you agree to [GitHub Copilot chat preview terms](https://docs.github.com/en/early-access/copilot/github-copilot-chat-technical-preview-license-terms). Review the [transparency note](https://aka.ms/CopilotChatTransparencyNote) to understand about usage, limitations and ways to improve Copilot Chat during the technical preview.\n\nYour code is yours. We follow responsible practices in accordance with our [Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement) to ensure that your code snippets will not be used as suggested code for other users of GitHub Copilot.\n\nTo get the latest security fixes, please use the latest version of the Copilot extension and VS Code.\n\n### Resources & next steps\n* **Sign up for [GitHub Copilot Free](https://github.com/settings/copilot?utm_source=vscode-chat-readme&utm_medium=third&utm_campaign=2025mar-em-MSFT-signup)**\n    * If you're using Copilot for your business, check out [Copilot Business](https://docs.github.com/en/copilot/copilot-business/about-github-copilot-business) and [Copilot Enterprise](https://docs.github.com/en/copilot/github-copilot-enterprise/overview/about-github-copilot-enterprise)\n* **[Get started with Copilot in VS Code tutorial](https://code.visualstudio.com/docs/copilot/getting-started)**\n* **[Copilot Chat quickstart video](https://www.youtube.com/watch?v=3surPGP7_4o)** to learn Copilot Chat in less than 4 minutes\n* **[VS Code Copilot Series on YouTube](https://www.youtube.com/playlist?list=PLj6YeMhvp2S5_hvBl2SE-7YCHYlLQ0bPt)**\n* **[FAQ](https://code.visualstudio.com/docs/copilot/faq)**\n* **[Feedback](https://github.com/microsoft/vscode-copilot-release/issues)**: We'd love to get your help in making GitHub Copilot better!\n\n## Data and telemetry\n\nThe GitHub Copilot Extension for Visual Studio Code collects usage data and sends it to Microsoft to help improve our products and services. Read our [privacy statement](https://privacy.microsoft.com/privacystatement) to learn more. This extension respects the `telemetry.telemetryLevel` setting which you can learn more about at https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.\n\n## License\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the [MIT](LICENSE.txt) license.\n",
      "stars_today": 6
    },
    {
      "id": 17183871,
      "name": "iperf",
      "full_name": "esnet/iperf",
      "description": "iperf3:  A TCP, UDP, and SCTP network bandwidth measurement tool",
      "html_url": "https://github.com/esnet/iperf",
      "stars": 8193,
      "forks": 1393,
      "language": "C",
      "topics": [
        "iperf3"
      ],
      "created_at": "2014-02-25T18:42:52Z",
      "updated_at": "2026-01-15T20:57:41Z",
      "pushed_at": "2026-01-09T18:27:53Z",
      "open_issues": 258,
      "owner": {
        "login": "esnet",
        "avatar_url": "https://avatars.githubusercontent.com/u/1566018?v=4"
      },
      "readme": "iperf3:  A TCP, UDP, and SCTP network bandwidth measurement tool\n================================================================\n\nSummary\n-------\n\niperf is a tool for active measurements of the maximum achievable\nbandwidth on IP networks.  It supports tuning of various parameters\nrelated to timing, protocols, and buffers.  For each test it reports\nthe measured throughput / bitrate, loss, and other parameters.\n\nThis version, sometimes referred to as iperf3, is a redesign of an\noriginal version developed at NLANR/DAST.  iperf3 is a new\nimplementation from scratch, with the goal of a smaller, simpler code\nbase, and a library version of the functionality that can be used in\nother programs. iperf3 also has a number of features found in other tools\nsuch as nuttcp and netperf, but were missing from the original iperf.\nThese include, for example, a zero-copy mode and optional JSON output.\nNote that iperf3 is *not* backwards compatible with the original iperf.\n\nPrimary development for iperf3 takes place on Ubuntu Linux, FreeBSD,\nand macOS.  At this time, these are the only officially supported\nplatforms, however there have been some reports of success with\nOpenBSD, NetBSD, Android, Solaris, and other Linux distributions.\n\niperf3 is principally developed by ESnet / Lawrence Berkeley National\nLaboratory.  It is released under a three-clause BSD license.\n\nFor more information see: https://software.es.net/iperf\n\nSource code and issue tracker: https://github.com/esnet/iperf\n\nDiscussion forums: https://github.com/esnet/iperf/discussions\n\nReporting security vulnerabilities: iperf@es.net\n\nObtaining iperf3\n----------------\n\nDownloads of iperf3 are available at:\n\n    https://downloads.es.net/pub/iperf/\n\nTo check out the most recent code, clone the git repository at:\n\n    https://github.com/esnet/iperf.git\n\nBuilding iperf3\n---------------\n\n### Prerequisites: ###\n\nNone.\n\n### Building ###\n\n    ./configure; make; make install\n\n(Note: If configure fails, try running `./bootstrap.sh` first)\n\nInvoking iperf3\n---------------\n\niperf3 includes a manual page listing all of the command-line options.\nThe manual page is the most up-to-date reference to the various flags and parameters.\n\nFor sample command line usage, see:\n\nhttps://fasterdata.es.net/performance-testing/network-troubleshooting-tools/iperf/\n\nUsing the default options, iperf is meant to show typical well\ndesigned application performance.  \"Typical well designed application\"\nmeans avoiding artificial enhancements that work only for testing\n(such as splice()'ing the data to /dev/null).  iperf does also have\nflags for \"extreme best case\" optimizations, but they must be\nexplicitly activated.\n\nThese flags include:\n\n    -Z, --zerocopy            use a 'zero copy' sendfile() method of sending data\n    -A, --affinity n/n,m      set CPU affinity\n\nBug and Security Reports\n------------------------\n\nBefore submitting a bug report, please make sure you're running the\nlatest version of the code, and confirm that your issue has not\nalready been fixed.  Then submit to the iperf3 issue tracker on\nGitHub:\n\nhttps://github.com/esnet/iperf/issues\n\nIn your issue submission, please indicate the version of iperf3 and\nwhat platform you're trying to run on (provide the platform\ninformation even if you're not using a supported platform, we\n*might* be able to help anyway).  Exact command-line arguments will\nhelp us recreate your problem.  If you're getting error messages,\nplease include them verbatim if possible, but remember to sanitize any\nsensitive information.\n\nIf you have a question about usage or about the code, please do *not*\nsubmit an issue.  Please use one of the mailing lists for that.\n\nIf you suspect there is a potential security issue, please contact the\ndevelopers at:\n\niperf@es.net\n\nRelation to iperf 2.x\n---------------------\n\nAlthough iperf2 and iperf3 both measure network performance,\nthey are not compatible with each other.\nThe projects (as of mid-2021) are in active, but separate, development.\nThe continuing iperf2 development\nproject can be found at https://sourceforge.net/projects/iperf2/.\n\nKnown Issues\n------------\n\nA set of known issues is maintained on the iperf3 Web pages:\n\nhttps://software.es.net/iperf/dev.html#known-issues\n\nLinks\n-----\n\nThis section lists links to user-contributed Web pages regarding\niperf3.  ESnet and Lawrence Berkeley National Laboratory bear no\nresponsibility for the content of these pages.\n\n* Installation instructions for Debian Linux (by Cameron Camp\n  <cameron@ivdatacenter.com>):\n\n  http://cheatsheet.logicalwebhost.com/iperf-network-testing/\n\nCopyright\n---------\n\niperf, Copyright (c) 2014-2025, The Regents of the University of\nCalifornia, through Lawrence Berkeley National Laboratory (subject\nto receipt of any required approvals from the U.S. Dept. of\nEnergy).  All rights reserved.\n\nIf you have questions about your rights to use or distribute this\nsoftware, please contact Berkeley Lab's Technology Transfer\nDepartment at TTD@lbl.gov.\n\nNOTICE.  This software is owned by the U.S. Department of Energy.\nAs such, the U.S. Government has been granted for itself and others\nacting on its behalf a paid-up, nonexclusive, irrevocable,\nworldwide license in the Software to reproduce, prepare derivative\nworks, and perform publicly and display publicly.  Beginning five\n(5) years after the date permission to assert copyright is obtained\nfrom the U.S. Department of Energy, and subject to any subsequent\nfive (5) year renewals, the U.S. Government is granted for itself\nand others acting on its behalf a paid-up, nonexclusive,\nirrevocable, worldwide license in the Software to reproduce,\nprepare derivative works, distribute copies to the public, perform\npublicly and display publicly, and to permit others to do so.\n\nThis code is distributed under a BSD style license, see the LICENSE\nfile for complete information.\n",
      "stars_today": 6
    },
    {
      "id": 776121034,
      "name": "omi",
      "full_name": "BasedHardware/omi",
      "description": "AI wearables. Put it on, speak, transcribe, automatically",
      "html_url": "https://github.com/BasedHardware/omi",
      "stars": 7500,
      "forks": 1320,
      "language": "C",
      "topics": [
        "ai",
        "app",
        "bci",
        "c",
        "flutter",
        "friend",
        "mobile",
        "necklace",
        "nextjs",
        "omi",
        "personas",
        "python",
        "smartglasses",
        "summary",
        "transcription",
        "wearable"
      ],
      "created_at": "2024-03-22T18:12:25Z",
      "updated_at": "2026-01-16T00:36:16Z",
      "pushed_at": "2026-01-15T16:05:05Z",
      "open_issues": 322,
      "owner": {
        "login": "BasedHardware",
        "avatar_url": "https://avatars.githubusercontent.com/u/162546372?v=4"
      },
      "readme": "<div align=\"center\">\n\n# **omi**\n\nMeet Omi, the worldâ€™s leading open-source AI wearable that captures conversations, gives summaries, action items and does actions for you. Simply connect Omi to your mobile device and enjoy automatic, high-quality\ntranscriptions of meetings, chats, and voice memos wherever you are.\n\n<p align=\"center\">\n  <img src=\"https://github.com/user-attachments/assets/834d3fdb-31b5-4f22-ae35-da3d2b9a8f59\" alt=\"Omi\" width=\"49%\" />\n  <img src=\"https://github.com/user-attachments/assets/fdad4226-e5ce-4c55-b547-9101edfa3203\" alt=\"Image\" width=\"49%\" />\n\n</p>\n\n![CleanShot 2025-02-08 at 18 22 23](https://github.com/user-attachments/assets/7a658366-9e02-4057-bde5-a510e1f0217a)\n\n[![Discord Follow](https://img.shields.io/discord/1192313062041067520?label=Discord)](http://discord.omi.me) &ensp;&ensp;&ensp;\n[![Twitter Follow](https://img.shields.io/twitter/follow/kodjima33)](https://x.com/kodjima33) &ensp;&ensp;&ensp;\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)&ensp;&ensp;&ensp;\n[![GitHub Repo stars](https://img.shields.io/github/stars/BasedHardware/Omi)](https://github.com/BasedHardware/Omi)&ensp;&ensp;&ensp;\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/BasedHardware/omi)\n\n<h3>\n\n[Site](https://omi.me/) |   [Download](https://omi.me/download)   | [Docs](https://docs.omi.me/) | [Buy omi Dev Kit](https://www.omi.me/products/omi-dev-kit-2) | [Buy Omi Glass Dev Kit](https://www.omi.me/glass)\n\n</h3>\n\n</div>\n\n[//]: # \"## Features\"\n[//]: #\n[//]: # \"- **Real-Time AI Audio Processing**: Leverage powerful on-device AI capabilities for real-time audio analysis.\"\n[//]: # \"- **Low-powered Bluetooth**: Capture audio for 24h+ on a small button battery\"\n[//]: # \"- **Open-Source Software**: Access and contribute to the pin's software stack, designed with openness and community collaboration in mind.\"\n[//]: # \"- **Wearable Design**: Experience unparalleled convenience with ergonomic and lightweight design, perfect for everyday wear.\"\n\n## ğŸš€ Quick Start for Developers (2 min)\n\nGet the omi app running locally:\n\n```bash\ngit clone https://github.com/BasedHardware/omi.git\ncd omi/app\n\nbash setup.sh ios     # android, macos\n```\n\n## Create your own App (1 min)\n\nDownload omi App\n\n[<img src='https://upload.wikimedia.org/wikipedia/commons/7/78/Google_Play_Store_badge_EN.svg' alt='Get it on Google Play' height=\"50px\" width=\"180px\">](https://play.google.com/store/apps/details?id=com.friend.ios)\n[<img src='https://upload.wikimedia.org/wikipedia/commons/3/3c/Download_on_the_App_Store_Badge.svg' alt=\"Download on the App Store\" height=\"50px\" width=\"180px\">](https://apps.apple.com/us/app/friend-ai-wearable/id6502156163)\n[<img src='https://github.com/user-attachments/assets/59c47ec7-3da0-47d7-be2f-7467e4189499' alt=\"Download MacOS app\" height=\"50px\" width=\"180px\">](https://apps.apple.com/us/app/omi-ai-smart-meeting-notes/id6502156163)\n\nCreate webhook using [webhook.site](https://webhook.site) and copy this url\n\n<img src=\"https://github.com/user-attachments/assets/083a6ec4-4694-4c7a-843a-4a1a0c254453\" width=\"500\">\n\nIn omi App:\n\n| Explore => Create an App                                                                                | Select Capability                                                                                       | Paste Webhook URL                                                                                         | Install App                                                                                             |\n| ------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |\n| <img src=\"https://github.com/user-attachments/assets/31809b81-7de2-4381-b5fc-5c9714972211\" width=\"200\"> | <img src=\"https://github.com/user-attachments/assets/59cfbe8e-7e3b-437f-81f7-25eb50ccdd7d\" width=\"200\"> | <img src=\"https://github.com/user-attachments/assets/3d864ee8-555f-4ded-b4db-87ff78128323\" width = \"200\"> | <img src=\"https://github.com/user-attachments/assets/58cf6da6-e245-415e-92e7-dc1f46583cfc\" width=\"200\"> |\n\nStart speaking, you'll see Real-time transcript on [webhook.site ](https://webhook.site).\n\n## In this repo:\n\n- [omi device](omi) - nRF chips, zephyr, c/c++\n- [omi glass](omiGlass) esp32-s3, c/c++\n- [omi app](app) - flutter\n- [omi backend](backend) - python, fastapi, firebase, pinecone, redis, deepgram, speechmatic, soniox, openai-compatible apis, langchain, silero vad\n- [SDKs](sdks) - react native, swift, python\n- [ai personas (web)](web/personas-open-source) - nextjs\n\n## Documentation:\n\n- [Introduction](https://docs.omi.me/)\n- [omi App setup](https://docs.omi.me/doc/developer/AppSetup)\n- [Buying Guide](https://docs.omi.me/doc/assembly/Buying_Guide/)\n- [Build the device](https://docs.omi.me/doc/assembly/Build_the_device/)\n- [Install firmware](https://docs.omi.me/doc/get_started/Flash_device/)\n- [Create your own app in 1 minute](https://docs.omi.me/doc/developer/apps/Introduction).\n- [Integrate your own wearable with omi](https://docs.omi.me/doc/integrations)\n\n## Contributions\n\n- Check out our [contributions guide](https://docs.omi.me/doc/developer/Contribution/).\n- Earn from contributing! Check the [paid bounties ğŸ¤‘](https://omi.me/bounties).\n- Check out the [current issues](https://github.com/BasedHardware/Omi/issues).\n- Join the [Discord](http://discord.omi.me).\n- Build your own [Plugins/Integrations](https://docs.omi.me/doc/developer/apps/Introduction).\n\n[//]: # \"## More links:\"\n[//]: #\n[//]: # \"- [Contributing](https://docs.omi.me/doc/developer/Contribution/)\"\n[//]: # \"- [Support](https://docs.omi.me/doc/info/Support/)\"\n[//]: # \"- [BLE Protocol](https://docs.omi.me/doc/developer/Protocol/)\"\n[//]: # \"- [Plugins](https://docs.omi.me/doc/developer/Plugins/)\"\n\n## Licensing\n\nOmi is available under <a href=\"https://github.com/BasedHardware/omi/blob/main/LICENSE\">MIT License</a>\n",
      "stars_today": 6
    },
    {
      "id": 38304949,
      "name": "GRDB.swift",
      "full_name": "groue/GRDB.swift",
      "description": "A toolkit for SQLite databases, with a focus on application development",
      "html_url": "https://github.com/groue/GRDB.swift",
      "stars": 8104,
      "forks": 830,
      "language": "Swift",
      "topics": [
        "database",
        "database-observation",
        "grdb",
        "spm",
        "sql",
        "sql-builder",
        "sqlite",
        "sqlite-databases"
      ],
      "created_at": "2015-06-30T11:17:06Z",
      "updated_at": "2026-01-15T06:06:20Z",
      "pushed_at": "2026-01-09T15:30:58Z",
      "open_issues": 12,
      "owner": {
        "login": "groue",
        "avatar_url": "https://avatars.githubusercontent.com/u/54219?v=4"
      },
      "readme": "<picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB~dark.png\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB.png\">\n    <img alt=\"GRDB: A toolkit for SQLite databases, with a focus on application development.\" src=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB.png\">\n</picture>\n\n<p align=\"center\">\n    <strong>A toolkit for SQLite databases, with a focus on application development</strong><br>\n    Proudly serving the community since 2015\n</p>\n\n<p align=\"center\">\n    <a href=\"https://developer.apple.com/swift/\"><img alt=\"Swift 6.1\" src=\"https://img.shields.io/badge/swift-6.1-orange.svg?style=flat\"></a>\n    <a href=\"https://github.com/groue/GRDB.swift/blob/master/LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/github/license/groue/GRDB.swift.svg?maxAge=2592000\"></a>\n    <a href=\"https://github.com/groue/GRDB.swift/actions/workflows/CI.yml\"><img alt=\"CI Status\" src=\"https://github.com/groue/GRDB.swift/actions/workflows/CI.yml/badge.svg?branch=master\"></a>\n</p>\n\n**Latest release**: December 13, 2025 â€¢ [version 7.9.0](https://github.com/groue/GRDB.swift/tree/v7.9.0) â€¢ [CHANGELOG](CHANGELOG.md) â€¢ [Migrating From GRDB 6 to GRDB 7](Documentation/GRDB7MigrationGuide.md)\n\n**Requirements**: iOS 13.0+ / macOS 10.15+ / tvOS 13.0+ / watchOS 7.0+ &bull; SQLite 3.20.0+ &bull; Swift 6.1+ / Xcode 16.3+\n\n**Contact**:\n\n- Release announcements and usage tips: follow [@groue@hachyderm.io](https://hachyderm.io/@groue) on Mastodon.\n- Report bugs in a [Github issue](https://github.com/groue/GRDB.swift/issues/new). Make sure you check the [existing issues](https://github.com/groue/GRDB.swift/issues?q=is%3Aopen) first.\n- A question? Looking for advice? Do you wonder how to contribute? Fancy a chat? Go to the [GitHub discussions](https://github.com/groue/GRDB.swift/discussions), or the [GRDB forums](https://forums.swift.org/c/related-projects/grdb).\n\n\n## What is GRDB?\n\nUse this library to save your applicationâ€™s permanent data into SQLite databases. It comes with built-in tools that address common needs:\n\n- **SQL Generation**\n    \n    Enhance your application models with persistence and fetching methods, so that you don't have to deal with SQL and raw database rows when you don't want to.\n\n- **Database Observation**\n    \n    Get notifications when database values are modified. \n\n- **Robust Concurrency**\n    \n    Multi-threaded applications can efficiently use their databases, including WAL databases that support concurrent reads and writes. \n\n- **Migrations**\n    \n    Evolve the schema of your database as you ship new versions of your application.\n    \n- **Leverage your SQLite skills**\n\n    Not all developers need advanced SQLite features. But when you do, GRDB is as sharp as you want it to be. Come with your SQL and SQLite skills, or learn new ones as you go!\n\n---\n\n<p align=\"center\">\n    <a href=\"#usage\">Usage</a> &bull;\n    <a href=\"#documentation\">Documentation</a> &bull;\n    <a href=\"#installation\">Installation</a> &bull;\n    <a href=\"#faq\">FAQ</a>\n</p>\n\n---\n\n## Usage\n\n<details open>\n  <summary>Start using the database in four steps</summary>\n\n```swift\nimport GRDB\n\n// 1. Open a database connection\nlet dbQueue = try DatabaseQueue(path: \"/path/to/database.sqlite\")\n\n// 2. Define the database schema\ntry dbQueue.write { db in\n    try db.create(table: \"player\") { t in\n        t.primaryKey(\"id\", .text)\n        t.column(\"name\", .text).notNull()\n        t.column(\"score\", .integer).notNull()\n    }\n}\n\n// 3. Define a record type\nstruct Player: Codable, Identifiable, FetchableRecord, PersistableRecord {\n    var id: String\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// 4. Write and read in the database\ntry dbQueue.write { db in\n    try Player(id: \"1\", name: \"Arthur\", score: 100).insert(db)\n    try Player(id: \"2\", name: \"Barbara\", score: 1000).insert(db)\n}\n\ntry dbQueue.read { db in\n    let player = try Player.find(db, id: \"1\"))\n    \n    let bestPlayers = try Player\n        .order(\\.score.desc)\n        .limit(10)\n        .fetchAll(db)\n}\n```\n\n</details>\n\n<details>\n    <summary>Access to raw SQL</summary>\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player (\n          id TEXT PRIMARY KEY,\n          name TEXT NOT NULL,\n          score INT NOT NULL)\n        \"\"\")\n    \n    try db.execute(sql: \"\"\"\n        INSERT INTO player (id, name, score)\n        VALUES (?, ?, ?)\n        \"\"\", arguments: [\"1\", \"Arthur\", 100])\n    \n    // Avoid SQL injection with SQL interpolation\n    let id = \"2\"\n    let name = \"O'Brien\"\n    let score = 1000\n    try db.execute(literal: \"\"\"\n        INSERT INTO player (id, name, score)\n        VALUES (\\(id), \\(name), \\(score))\n        \"\"\")\n}\n```\n\nSee [Executing Updates](#executing-updates)\n\n</details>\n\n<details>\n    <summary>Access to raw database rows and values</summary>\n\n```swift\ntry dbQueue.read { db in\n    // Fetch database rows\n    let rows = try Row.fetchCursor(db, sql: \"SELECT * FROM player\")\n    while let row = try rows.next() {\n        let id: String = row[\"id\"]\n        let name: String = row[\"name\"]\n        let score: Int = row[\"score\"]\n    }\n    \n    // Fetch values\n    let playerCount = try Int.fetchOne(db, sql: \"SELECT COUNT(*) FROM player\")! // Int\n    let playerNames = try String.fetchAll(db, sql: \"SELECT name FROM player\") // [String]\n}\n\nlet playerCount = try dbQueue.read { db in\n    try Int.fetchOne(db, sql: \"SELECT COUNT(*) FROM player\")!\n}\n```\n\nSee [Fetch Queries](#fetch-queries)\n\n</details>\n\n<details>\n    <summary>Database model types aka \"records\"</summary>\n\n```swift\nstruct Player: Codable, Identifiable, FetchableRecord, PersistableRecord {\n    var id: String\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\ntry dbQueue.write { db in\n    // Create database table\n    try db.create(table: \"player\") { t in\n        t.primaryKey(\"id\", .text)\n        t.column(\"name\", .text).notNull()\n        t.column(\"score\", .integer).notNull()\n    }\n    \n    // Insert a record\n    var player = Player(id: \"1\", name: \"Arthur\", score: 100)\n    try player.insert(db)\n    \n    // Update a record\n    player.score += 10\n    try score.update(db)\n    \n    try player.updateChanges { $0.score += 10 }\n    \n    // Delete a record\n    try player.delete(db)\n}\n```\n\nSee [Records](#records)\n\n</details>\n\n<details>\n    <summary>Query the database with the Swift query interface</summary>\n\n```swift\ntry dbQueue.read { db in\n    // Player\n    let player = try Player.find(db, id: \"1\")\n    \n    // Player?\n    let arthur = try Player.filter { $0.name == \"Arthur\" }.fetchOne(db)\n    \n    // [Player]\n    let bestPlayers = try Player.order(\\.score.desc).limit(10).fetchAll(db)\n    \n    // Int\n    let playerCount = try Player.fetchCount(db)\n    \n    // SQL is always welcome\n    let players = try Player.fetchAll(db, sql: \"SELECT * FROM player\")\n}\n```\n\nSee the [Query Interface](#the-query-interface)\n\n</details>\n\n<details>\n    <summary>Database changes notifications</summary>\n\n```swift\n// Define the observed value\nlet observation = ValueObservation.tracking { db in\n    try Player.fetchAll(db)\n}\n\n// Start observation\nlet cancellable = observation.start(\n    in: dbQueue,\n    onError: { error in ... },\n    onChange: { (players: [Player]) in print(\"Fresh players: \\(players)\") })\n```\n\nReady-made support for Combine and RxSwift:\n\n```swift\n// Swift concurrency\nfor try await players in observation.values(in: dbQueue) {\n    print(\"Fresh players: \\(players)\")\n}\n\n// Combine\nlet cancellable = observation.publisher(in: dbQueue).sink(\n    receiveCompletion: { completion in ... },\n    receiveValue: { (players: [Player]) in print(\"Fresh players: \\(players)\") })\n\n// RxSwift\nlet disposable = observation.rx.observe(in: dbQueue).subscribe(\n    onNext: { (players: [Player]) in print(\"Fresh players: \\(players)\") },\n    onError: { error in ... })\n```\n\nSee [Database Observation], [Combine Support], [RxGRDB].\n\n</details>\n\nDocumentation\n=============\n\n**GRDB runs on top of SQLite**: you should get familiar with the [SQLite FAQ](http://www.sqlite.org/faq.html). For general and detailed information, jump to the [SQLite Documentation](http://www.sqlite.org/docs.html).\n\n\n#### Demo Applications & Frequently Asked Questions\n\n- [Demo Applications]\n- [FAQ]\n\n#### Reference\n\n- ğŸ“– [GRDB Reference](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/)\n\n#### Getting Started\n\n- [Installation](#installation)\n- [Database Connections]: Connect to SQLite databases\n\n#### SQLite and SQL\n\n- [SQLite API](#sqlite-api): The low-level SQLite API &bull; [executing updates](#executing-updates) &bull; [fetch queries](#fetch-queries) &bull; [SQL Interpolation]\n\n#### Records and the Query Interface\n\n- [Records](#records): Fetching and persistence methods for your custom structs and class hierarchies\n- [Query Interface](#the-query-interface): A swift way to generate SQL &bull; [create tables, indexes, etc](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema) &bull; [requests](#requests) â€¢ [associations between record types](Documentation/AssociationsBasics.md)\n\n#### Application Tools\n\n- [Migrations]: Transform your database as your application evolves.\n- [Full-Text Search]: Perform efficient and customizable full-text searches.\n- [Database Observation]: Observe database changes and transactions.\n- [Encryption](#encryption): Encrypt your database with SQLCipher.\n- [Backup](#backup): Dump the content of a database to another.\n- [Interrupt a Database](#interrupt-a-database): Abort any pending database operation.\n- [Sharing a Database]: How to share an SQLite database between multiple processes - recommendations for App Group containers, App Extensions, App Sandbox, and file coordination.\n\n#### Good to Know\n\n- [Concurrency]: How to access databases in a multi-threaded application.\n- [Combine](Documentation/Combine.md): Access and observe the database with Combine publishers.\n- [Avoiding SQL Injection](#avoiding-sql-injection)\n- [Error Handling](#error-handling)\n- [Unicode](#unicode)\n- [Memory Management](#memory-management)\n- [Data Protection](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections)\n- :bulb: [Migrating From GRDB 6 to GRDB 7](Documentation/GRDB7MigrationGuide.md)\n- :bulb: [Why Adopt GRDB?](Documentation/WhyAdoptGRDB.md)\n- :bulb: [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices)\n\n#### Companion Libraries\n\n- [GRDBQuery](https://github.com/groue/GRDBQuery): Access and observe the database from your SwiftUI views.\n- [GRDBSnapshotTesting](https://github.com/groue/GRDBSnapshotTesting): Test your database. \n\n**[FAQ]**\n\n**[Sample Code](#sample-code)**\n\n\nInstallation\n============\n\n**The installation procedures below have GRDB use the version of SQLite that ships with the target operating system.**\n\nSee [Encryption](#encryption) for the installation procedure of GRDB with SQLCipher.\n\nSee [Custom SQLite builds](Documentation/CustomSQLiteBuilds.md) for the installation procedure of GRDB with a customized build of SQLite.\n\n\n## Swift Package Manager\n\nThe [Swift Package Manager](https://swift.org/package-manager/) automates the distribution of Swift code. To use GRDB with SPM, add a dependency to `https://github.com/groue/GRDB.swift.git`\n\nGRDB offers two libraries, `GRDB` and `GRDB-dynamic`. Pick only one. When in doubt, prefer `GRDB`. The `GRDB-dynamic` library can reveal useful if you are going to link it with multiple targets within your app and only wish to link to a shared, dynamic framework once. See [How to link a Swift Package as dynamic](https://forums.swift.org/t/how-to-link-a-swift-package-as-dynamic/32062) for more information.\n\n> **Note**: Linux support is provided by contributors. It is not automatically tested, and not officially maintained. If you notice a build or runtime failure on Linux, please open a pull request with the necessary fix, thank you!\n\n\n## CocoaPods\n\n[CocoaPods](http://cocoapods.org/) is a dependency manager for Xcode projects. To use GRDB with CocoaPods (version 1.2 or higher), specify in your `Podfile`:\n\n```ruby\npod 'GRDB.swift'\n```\n\nGRDB can be installed as a framework, or a static library.\n\n**Important Note for CocoaPods installation**\n\nDue to an [issue](https://github.com/CocoaPods/CocoaPods/issues/11839) in CocoaPods, it is currently not possible to deploy new versions of GRDB to CocoaPods. The last version available on CocoaPods is 6.24.1. To install later versions of GRDB using CocoaPods, use one of the following workarounds:\n\n- Depend on the `GRDB7` branch. This is more or less equivalent to what `pod 'GRDB.swift', '~> 7.0'` would normally do, if CocoaPods would accept new GRDB versions to be published:\n\n    ```ruby\n    # Can't use semantic versioning due to https://github.com/CocoaPods/CocoaPods/issues/11839\n    pod 'GRDB.swift', git: 'https://github.com/groue/GRDB.swift.git', branch: 'GRDB7'\n    ```\n\n- Depend on a specific version explicitly (Replace the tag with the version you want to use):\n\n    ```ruby\n    # Can't use semantic versioning due to https://github.com/CocoaPods/CocoaPods/issues/11839\n    # Replace the tag with the tag that you want to use.\n    pod 'GRDB.swift', git: 'https://github.com/groue/GRDB.swift.git', tag: 'v6.29.0' \n    ```\n\n## Carthage\n\n[Carthage](https://github.com/Carthage/Carthage) is **unsupported**. For some context about this decision, see [#433](https://github.com/groue/GRDB.swift/issues/433).\n\n\n## Manually\n\n1. [Download](https://github.com/groue/GRDB.swift/releases) a copy of GRDB, or clone its repository and make sure you checkout the latest tagged version.\n\n2. Embed the `GRDB.xcodeproj` project in your own project.\n\n3. Add the `GRDB` target in the **Target Dependencies** section of the **Build Phases** tab of your application target (extension target for WatchOS).\n\n4. Add the `GRDB.framework` to the **Embedded Binaries** section of the **General**  tab of your application target (extension target for WatchOS).\n\n\nDatabase Connections\n====================\n\nGRDB provides two classes for accessing SQLite databases: [`DatabaseQueue`] and [`DatabasePool`]:\n\n```swift\nimport GRDB\n\n// Pick one:\nlet dbQueue = try DatabaseQueue(path: \"/path/to/database.sqlite\")\nlet dbPool = try DatabasePool(path: \"/path/to/database.sqlite\")\n```\n\nThe differences are:\n\n- Database pools allow concurrent database accesses (this can improve the performance of multithreaded applications).\n- Database pools open your SQLite database in the [WAL mode](https://www.sqlite.org/wal.html) (unless read-only).\n- Database queues support [in-memory databases](https://www.sqlite.org/inmemorydb.html).\n\n**If you are not sure, choose [`DatabaseQueue`].** You will always be able to switch to [`DatabasePool`] later.\n\nFor more information and tips when opening connections, see [Database Connections](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections).\n\n\nSQLite API\n==========\n\n**In this section of the documentation, we will talk SQL.** Jump to the [query interface](#the-query-interface) if SQL is not your cup of tea.\n\n- [Executing Updates](#executing-updates)\n- [Fetch Queries](#fetch-queries)\n    - [Fetching Methods](#fetching-methods)\n    - [Row Queries](#row-queries)\n    - [Value Queries](#value-queries)\n- [Values](#values)\n    - [Data](#data-and-memory-savings)\n    - [Date and DateComponents](#date-and-datecomponents)\n    - [NSNumber, NSDecimalNumber, and Decimal](#nsnumber-nsdecimalnumber-and-decimal)\n    - [Swift enums](#swift-enums)\n    - [`DatabaseValueConvertible`]: the protocol for custom value types\n- [Transactions and Savepoints]\n- [SQL Interpolation]\n\nAdvanced topics:\n\n- [Prepared Statements]\n- [Custom SQL Functions and Aggregates](#custom-sql-functions-and-aggregates)\n- [Database Schema Introspection](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschemaintrospection)\n- [Row Adapters](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter)\n- [Raw SQLite Pointers](#raw-sqlite-pointers)\n\n\n## Executing Updates\n\nOnce granted with a [database connection], the [`execute(sql:arguments:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/execute(sql:arguments:)) method executes the SQL statements that do not return any database row, such as `CREATE TABLE`, `INSERT`, `DELETE`, `ALTER`, etc.\n\nFor example:\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            name TEXT NOT NULL,\n            score INT)\n        \"\"\")\n    \n    try db.execute(\n        sql: \"INSERT INTO player (name, score) VALUES (?, ?)\",\n        arguments: [\"Barbara\", 1000])\n    \n    try db.execute(\n        sql: \"UPDATE player SET score = :score WHERE id = :id\",\n        arguments: [\"score\": 1000, \"id\": 1])\n    }\n}\n```\n\nThe `?` and colon-prefixed keys like `:score` in the SQL query are the **statements arguments**. You pass arguments with arrays or dictionaries, as in the example above. See [Values](#values) for more information on supported arguments types (Bool, Int, String, Date, Swift enums, etc.), and [`StatementArguments`] for a detailed documentation of SQLite arguments.\n\nYou can also embed query arguments right into your SQL queries, with [`execute(literal:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/execute(literal:)), as in the example below. See [SQL Interpolation] for more details.\n\n```swift\ntry dbQueue.write { db in\n    let name = \"O'Brien\"\n    let score = 550\n    try db.execute(literal: \"\"\"\n        INSERT INTO player (name, score) VALUES (\\(name), \\(score))\n        \"\"\")\n}\n```\n\n**Never ever embed values directly in your raw SQL strings**. See [Avoiding SQL Injection](#avoiding-sql-injection) for more information:\n\n```swift\n// WRONG: don't embed values in raw SQL strings\nlet id = 123\nlet name = textField.text\ntry db.execute(\n    sql: \"UPDATE player SET name = '\\(name)' WHERE id = \\(id)\")\n\n// CORRECT: use arguments dictionary\ntry db.execute(\n    sql: \"UPDATE player SET name = :name WHERE id = :id\",\n    arguments: [\"name\": name, \"id\": id])\n\n// CORRECT: use arguments array\ntry db.execute(\n    sql: \"UPDATE player SET name = ? WHERE id = ?\",\n    arguments: [name, id])\n\n// CORRECT: use SQL Interpolation\ntry db.execute(\n    literal: \"UPDATE player SET name = \\(name) WHERE id = \\(id)\")\n```\n\n**Join multiple statements with a semicolon**:\n\n```swift\ntry db.execute(sql: \"\"\"\n    INSERT INTO player (name, score) VALUES (?, ?);\n    INSERT INTO player (name, score) VALUES (?, ?);\n    \"\"\", arguments: [\"Arthur\", 750, \"Barbara\", 1000])\n\ntry db.execute(literal: \"\"\"\n    INSERT INTO player (name, score) VALUES (\\(\"Arthur\"), \\(750));\n    INSERT INTO player (name, score) VALUES (\\(\"Barbara\"), \\(1000));\n    \"\"\")\n```\n\nWhen you want to make sure that a single statement is executed, use a prepared [`Statement`].\n\n**After an INSERT statement**, you can get the row ID of the inserted row with [`lastInsertedRowID`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/lastinsertedrowid):\n\n```swift\ntry db.execute(\n    sql: \"INSERT INTO player (name, score) VALUES (?, ?)\",\n    arguments: [\"Arthur\", 1000])\nlet playerId = db.lastInsertedRowID\n```\n\nDon't miss [Records](#records), that provide classic **persistence methods**:\n\n```swift\nvar player = Player(name: \"Arthur\", score: 1000)\ntry player.insert(db)\nlet playerId = player.id\n```\n\n\n## Fetch Queries\n\n[Database connections] let you fetch database rows, plain values, and custom models aka \"records\".\n\n**Rows** are the raw results of SQL queries:\n\n```swift\ntry dbQueue.read { db in\n    if let row = try Row.fetchOne(db, sql: \"SELECT * FROM wine WHERE id = ?\", arguments: [1]) {\n        let name: String = row[\"name\"]\n        let color: Color = row[\"color\"]\n        print(name, color)\n    }\n}\n```\n\n\n**Values** are the Bool, Int, String, Date, Swift enums, etc. stored in row columns:\n\n```swift\ntry dbQueue.read { db in\n    let urls = try URL.fetchCursor(db, sql: \"SELECT url FROM wine\")\n    while let url = try urls.next() {\n        print(url)\n    }\n}\n```\n\n\n**Records** are your application objects that can initialize themselves from rows:\n\n```swift\nlet wines = try dbQueue.read { db in\n    try Wine.fetchAll(db, sql: \"SELECT * FROM wine\")\n}\n```\n\n- [Fetching Methods](#fetching-methods) and [Cursors](#cursors)\n- [Row Queries](#row-queries)\n- [Value Queries](#value-queries)\n- [Records](#records)\n\n\n### Fetching Methods\n\n**Throughout GRDB**, you can always fetch *cursors*, *arrays*, *sets*, or *single values* of any fetchable type (database [row](#row-queries), simple [value](#value-queries), or custom [record](#records)):\n\n```swift\ntry Row.fetchCursor(...) // A Cursor of Row\ntry Row.fetchAll(...)    // [Row]\ntry Row.fetchSet(...)    // Set<Row>\ntry Row.fetchOne(...)    // Row?\n```\n\n- `fetchCursor` returns a **[cursor](#cursors)** over fetched values:\n    \n    ```swift\n    let rows = try Row.fetchCursor(db, sql: \"SELECT ...\") // A Cursor of Row\n    ```\n    \n- `fetchAll` returns an **array**:\n    \n    ```swift\n    let players = try Player.fetchAll(db, sql: \"SELECT ...\") // [Player]\n    ```\n\n- `fetchSet` returns a **set**:\n    \n    ```swift\n    let names = try String.fetchSet(db, sql: \"SELECT ...\") // Set<String>\n    ```\n\n- `fetchOne` returns a **single optional value**, and consumes a single database row (if any).\n    \n    ```swift\n    let count = try Int.fetchOne(db, sql: \"SELECT COUNT(*) ...\") // Int?\n    ```\n\n**All those fetching methods require an SQL string that contains a single SQL statement.** When you want to fetch from multiple statements joined with a semicolon, iterate the multiple [prepared statements] found in the SQL string.\n\n### Cursors\n\nğŸ“– [`Cursor`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/cursor)\n\n**Whenever you consume several rows from the database, you can fetch an Array, a Set, or a Cursor**.\n\nThe `fetchAll()` and `fetchSet()` methods return regular Swift array and sets, that you iterate like all other arrays and sets:\n\n```swift\ntry dbQueue.read { db in\n    // [Player]\n    let players = try Player.fetchAll(db, sql: \"SELECT ...\")\n    for player in players {\n        // use player\n    }\n}\n```\n\nUnlike arrays and sets, cursors returned by `fetchCursor()` load their results step after step:\n\n```swift\ntry dbQueue.read { db in\n    // Cursor of Player\n    let players = try Player.fetchCursor(db, sql: \"SELECT ...\")\n    while let player = try players.next() {\n        // use player\n    }\n}\n```\n\n- **Cursors can not be used on any thread**: you must consume a cursor on the dispatch queue it was created in. Particularly, don't extract a cursor out of a database access method:\n    \n    ```swift\n    // Wrong\n    let cursor = try dbQueue.read { db in\n        try Player.fetchCursor(db, ...)\n    }\n    while let player = try cursor.next() { ... }\n    ```\n    \n    Conversely, arrays and sets may be consumed on any thread:\n    \n    ```swift\n    // OK\n    let array = try dbQueue.read { db in\n        try Player.fetchAll(db, ...)\n    }\n    for player in array { ... }\n    ```\n    \n- **Cursors can be iterated only one time.** Arrays and sets can be iterated many times.\n\n- **Cursors iterate database results in a lazy fashion**, and don't consume much memory. Arrays and sets contain copies of database values, and may take a lot of memory when there are many fetched results.\n\n- **Cursors are granted with direct access to SQLite,** unlike arrays and sets that have to take the time to copy database values. If you look after extra performance, you may prefer cursors.\n\n- **Cursors can feed Swift collections.**\n    \n    You will most of the time use `fetchAll` or `fetchSet` when you want an array or a set. For more specific needs, you may prefer one of the initializers below. All of them accept an extra optional `minimumCapacity` argument which helps optimizing your app when you have an idea of the number of elements in a cursor (the built-in `fetchAll` and `fetchSet` do not perform such an optimization).\n    \n    **Arrays** and all types conforming to `RangeReplaceableCollection`:\n    \n    ```swift\n    // [String]\n    let cursor = try String.fetchCursor(db, ...)\n    let array = try Array(cursor)\n    ```\n    \n    **Sets**:\n    \n    ```swift\n    // Set<Int>\n    let cursor = try Int.fetchCursor(db, ...)\n    let set = try Set(cursor)\n    ```\n    \n    **Dictionaries**:\n    \n    ```swift\n    // [Int64: [Player]]\n    let cursor = try Player.fetchCursor(db)\n    let dictionary = try Dictionary(grouping: cursor, by: { $0.teamID })\n    \n    // [Int64: Player]\n    let cursor = try Player.fetchCursor(db).map { ($0.id, $0) }\n    let dictionary = try Dictionary(uniqueKeysWithValues: cursor)\n    ```\n\n- **Cursors adopt the [Cursor](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/cursor) protocol, which looks a lot like standard [lazy sequences](https://developer.apple.com/reference/swift/lazysequenceprotocol) of Swift.** As such, cursors come with many convenience methods: `compactMap`, `contains`, `dropFirst`, `dropLast`, `drop(while:)`, `enumerated`, `filter`, `first`, `flatMap`, `forEach`, `joined`, `joined(separator:)`, `max`, `max(by:)`, `min`, `min(by:)`, `map`, `prefix`, `prefix(while:)`, `reduce`, `reduce(into:)`, `suffix`:\n    \n    ```swift\n    // Prints all Github links\n    try URL\n        .fetchCursor(db, sql: \"SELECT url FROM link\")\n        .filter { url in url.host == \"github.com\" }\n        .forEach { url in print(url) }\n    \n    // An efficient cursor of coordinates:\n    let locations = try Row.\n        .fetchCursor(db, sql: \"SELECT latitude, longitude FROM place\")\n        .map { row in\n            CLLocationCoordinate2D(latitude: row[0], longitude: row[1])\n        }\n    ```\n\n- **Cursors are not Swift sequences.** That's because Swift sequences can't handle iteration errors, when reading SQLite results may fail at any time.\n\n- **Cursors require a little care**:\n    \n    - Don't modify the results during a cursor iteration:\n        \n        ```swift\n        // Undefined behavior\n        while let player = try players.next() {\n            try db.execute(sql: \"DELETE ...\")\n        }\n        ```\n    \n    - Don't turn a cursor of `Row` into an array or a set. You would not get the distinct rows you expect. To get a array of rows, use `Row.fetchAll(...)`. To get a set of rows, use `Row.fetchSet(...)`. Generally speaking, make sure you copy a row whenever you extract it from a cursor for later use: `row.copy()`.\n\nIf you don't see, or don't care about the difference, use arrays. If you care about memory and performance, use cursors when appropriate.\n\n\n### Row Queries\n\n- [Fetching Rows](#fetching-rows)\n- [Column Values](#column-values)\n- [DatabaseValue](#databasevalue)\n- [Rows as Dictionaries](#rows-as-dictionaries)\n- ğŸ“– [`Row`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/row)\n\n\n#### Fetching Rows\n\nFetch **cursors** of rows, **arrays**, **sets**, or **single** rows (see [fetching methods](#fetching-methods)):\n\n```swift\ntry dbQueue.read { db in\n    try Row.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Row\n    try Row.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Row]\n    try Row.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Row>\n    try Row.fetchOne(db, sql: \"SELECT ...\", arguments: ...)    // Row?\n    \n    let rows = try Row.fetchCursor(db, sql: \"SELECT * FROM wine\")\n    while let row = try rows.next() {\n        let name: String = row[\"name\"]\n        let color: Color = row[\"color\"]\n        print(name, color)\n    }\n}\n\nlet rows = try dbQueue.read { db in\n    try Row.fetchAll(db, sql: \"SELECT * FROM player\")\n}\n```\n\nArguments are optional arrays or dictionaries that fill the positional `?` and colon-prefixed keys like `:name` in the query:\n\n```swift\nlet rows = try Row.fetchAll(db,\n    sql: \"SELECT * FROM player WHERE name = ?\",\n    arguments: [\"Arthur\"])\n\nlet rows = try Row.fetchAll(db,\n    sql: \"SELECT * FROM player WHERE name = :name\",\n    arguments: [\"name\": \"Arthur\"])\n```\n\nSee [Values](#values) for more information on supported arguments types (Bool, Int, String, Date, Swift enums, etc.), and [`StatementArguments`] for a detailed documentation of SQLite arguments.\n\nUnlike row arrays that contain copies of the database rows, row cursors are close to the SQLite metal, and require a little care:\n\n> **Note**: **Don't turn a cursor of `Row` into an array or a set**. You would not get the distinct rows you expect. To get a array of rows, use `Row.fetchAll(...)`. To get a set of rows, use `Row.fetchSet(...)`. Generally speaking, make sure you copy a row whenever you extract it from a cursor for later use: `row.copy()`.\n\n\n#### Column Values\n\n**Read column values** by index or column name:\n\n```swift\nlet name: String = row[0]      // 0 is the leftmost column\nlet name: String = row[\"name\"] // Leftmost matching column - lookup is case-insensitive\nlet name: String = row[Column(\"name\")] // Using query interface's Column\n```\n\nMake sure to ask for an optional when the value may be NULL:\n\n```swift\nlet name: String? = row[\"name\"]\n```\n\nThe `row[]` subscript returns the type you ask for. See [Values](#values) for more information on supported value types:\n\n```swift\nlet bookCount: Int     = row[\"bookCount\"]\nlet bookCount64: Int64 = row[\"bookCount\"]\nlet hasBooks: Bool     = row[\"bookCount\"] // false when 0\n\nlet string: String     = row[\"date\"]      // \"2015-09-11 18:14:15.123\"\nlet date: Date         = row[\"date\"]      // Date\nself.date = row[\"date\"] // Depends on the type of the property.\n```\n\nYou can also use the `as` type casting operator:\n\n```swift\nrow[...] as Int\nrow[...] as Int?\n```\n\nThrowing accessors exist as well. Their use is not encouraged, because a database decoding error is a programming error. If an application stores invalid data in the database file, that is a bug that needs to be fixed:\n\n```swift\nlet name = try row.decode(String.self, atIndex: 0)\nlet bookCount = try row.decode(Int.self, forColumn: \"bookCount\")\n```\n\n> **Warning**: avoid the `as!` and `as?` operators:\n> \n> ```swift\n> if let int = row[...] as? Int { ... } // BAD - doesn't work\n> if let int = row[...] as Int? { ... } // GOOD\n> ```\n\n> **Warning**: avoid nil-coalescing row values, and prefer the `coalesce` method instead:\n>\n> ```swift\n> let name: String? = row[\"nickname\"] ?? row[\"name\"]     // BAD - doesn't work\n> let name: String? = row.coalesce([\"nickname\", \"name\"]) // GOOD\n> ```\n\nGenerally speaking, you can extract the type you need, provided it can be converted from the underlying SQLite value:\n\n- **Successful conversions include:**\n    \n    - All numeric SQLite values to all numeric Swift types, and Bool (zero is the only false boolean).\n    - Text SQLite values to Swift String.\n    - Blob SQLite values to Foundation Data.\n    \n    See [Values](#values) for more information on supported types (Bool, Int, String, Date, Swift enums, etc.)\n    \n- **NULL returns nil.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT NULL\")!\n    row[0] as Int? // nil\n    row[0] as Int  // fatal error: could not convert NULL to Int.\n    ```\n    \n    There is one exception, though: the [DatabaseValue](#databasevalue) type:\n    \n    ```swift\n    row[0] as DatabaseValue // DatabaseValue.null\n    ```\n    \n- **Missing columns return nil.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'foo' AS foo\")!\n    row[\"missing\"] as String? // nil\n    row[\"missing\"] as String  // fatal error: no such column: missing\n    ```\n    \n    You can explicitly check for a column presence with the `hasColumn` method.\n\n- **Invalid conversions throw a fatal error.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'Momâ€™s birthday'\")!\n    row[0] as String // \"Momâ€™s birthday\"\n    row[0] as Date?  // fatal error: could not convert \"Momâ€™s birthday\" to Date.\n    row[0] as Date   // fatal error: could not convert \"Momâ€™s birthday\" to Date.\n    \n    let row = try Row.fetchOne(db, sql: \"SELECT 256\")!\n    row[0] as Int    // 256\n    row[0] as UInt8? // fatal error: could not convert 256 to UInt8.\n    row[0] as UInt8  // fatal error: could not convert 256 to UInt8.\n    ```\n    \n    Those conversion fatal errors can be avoided with the [DatabaseValue](#databasevalue) type:\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'Momâ€™s birthday'\")!\n    let dbValue: DatabaseValue = row[0]\n    if dbValue.isNull {\n        // Handle NULL\n    } else if let date = Date.fromDatabaseValue(dbValue) {\n        // Handle valid date\n    } else {\n        // Handle invalid date\n    }\n    ```\n    \n    This extra verbosity is the consequence of having to deal with an untrusted database: you may consider fixing the content of your database instead. See [Fatal Errors](#fatal-errors) for more information.\n    \n- **SQLite has a weak type system, and provides [convenience conversions](https://www.sqlite.org/c3ref/column_blob.html) that can turn String to Int, Double to Blob, etc.**\n    \n    GRDB will sometimes let those conversions go through:\n    \n    ```swift\n    let rows = try Row.fetchCursor(db, sql: \"SELECT '20 small cigars'\")\n    while let row = try rows.next() {\n        row[0] as Int   // 20\n    }\n    ```\n    \n    Don't freak out: those conversions did not prevent SQLite from becoming the immensely successful database engine you want to use. And GRDB adds safety checks described just above. You can also prevent those convenience conversions altogether by using the [DatabaseValue](#databasevalue) type.\n\n\n#### DatabaseValue\n\nğŸ“– [`DatabaseValue`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalue)\n\n**`DatabaseValue` is an intermediate type between SQLite and your values, which gives information about the raw value stored in the database.**\n\nYou get `DatabaseValue` just like other value types:\n\n```swift\nlet dbValue: DatabaseValue = row[0]\nlet dbValue: DatabaseValue? = row[\"name\"] // nil if and only if column does not exist\n\n// Check for NULL:\ndbValue.isNull // Bool\n\n// The stored value:\ndbValue.storage.value // Int64, Double, String, Data, or nil\n\n// All the five storage classes supported by SQLite:\nswitch dbValue.storage {\ncase .null:                 print(\"NULL\")\ncase .int64(let int64):     print(\"Int64: \\(int64)\")\ncase .double(let double):   print(\"Double: \\(double)\")\ncase .string(let string):   print(\"String: \\(string)\")\ncase .blob(let data):       print(\"Data: \\(data)\")\n}\n```\n\nYou can extract regular [values](#values) (Bool, Int, String, Date, Swift enums, etc.) from `DatabaseValue` with the [fromDatabaseValue()](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible/fromdatabasevalue(_:)-21zzv) method:\n\n```swift\nlet dbValue: DatabaseValue = row[\"bookCount\"]\nlet bookCount   = Int.fromDatabaseValue(dbValue)   // Int?\nlet bookCount64 = Int64.fromDatabaseValue(dbValue) // Int64?\nlet hasBooks    = Bool.fromDatabaseValue(dbValue)  // Bool?, false when 0\n\nlet dbValue: DatabaseValue = row[\"date\"]\nlet string = String.fromDatabaseValue(dbValue)     // \"2015-09-11 18:14:15.123\"\nlet date   = Date.fromDatabaseValue(dbValue)       // Date?\n```\n\n`fromDatabaseValue` returns nil for invalid conversions:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 'Momâ€™s birthday'\")!\nlet dbValue: DatabaseValue = row[0]\nlet string = String.fromDatabaseValue(dbValue) // \"Momâ€™s birthday\"\nlet int    = Int.fromDatabaseValue(dbValue)    // nil\nlet date   = Date.fromDatabaseValue(dbValue)   // nil\n```\n\n\n#### Rows as Dictionaries\n\nRow adopts the standard [RandomAccessCollection](https://developer.apple.com/documentation/swift/randomaccesscollection) protocol, and can be seen as a dictionary of [DatabaseValue](#databasevalue):\n\n```swift\n// All the (columnName, dbValue) tuples, from left to right:\nfor (columnName, dbValue) in row {\n    ...\n}\n```\n\n**You can build rows from dictionaries** (standard Swift dictionaries and NSDictionary). See [Values](#values) for more information on supported types:\n\n```swift\nlet row: Row = [\"name\": \"foo\", \"date\": nil]\nlet row = Row([\"name\": \"foo\", \"date\": nil])\nlet row = Row(/* [AnyHashable: Any] */) // nil if invalid dictionary\n```\n\nYet rows are not real dictionaries: they may contain duplicate columns:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 1 AS foo, 2 AS foo\")!\nrow.columnNames    // [\"foo\", \"foo\"]\nrow.databaseValues // [1, 2]\nrow[\"foo\"]         // 1 (leftmost matching column)\nfor (columnName, dbValue) in row { ... } // (\"foo\", 1), (\"foo\", 2)\n```\n\n**When you build a dictionary from a row**, you have to disambiguate identical columns, and choose how to present database values. For example:\n\n- A `[String: DatabaseValue]` dictionary that keeps leftmost value in case of duplicated column name:\n\n    ```swift\n    let dict = Dictionary(row, uniquingKeysWith: { (left, _) in left })\n    ```\n\n- A `[String: AnyObject]` dictionary which keeps rightmost value in case of duplicated column name. This dictionary is identical to FMResultSet's resultDictionary from FMDB. It contains NSNull values for null columns, and can be shared with Objective-C:\n\n    ```swift\n    let dict = Dictionary(\n        row.map { (column, dbValue) in\n            (column, dbValue.storage.value as AnyObject)\n        },\n        uniquingKeysWith: { (_, right) in right })\n    ```\n\n- A `[String: Any]` dictionary that can feed, for example, JSONSerialization:\n    \n    ```swift\n    let dict = Dictionary(\n        row.map { (column, dbValue) in\n            (column, dbValue.storage.value)\n        },\n        uniquingKeysWith: { (left, _) in left })\n    ```\n\nSee the documentation of [`Dictionary.init(_:uniquingKeysWith:)`](https://developer.apple.com/documentation/swift/dictionary/2892961-init) for more information.\n\n\n### Value Queries\n\nğŸ“– [`DatabaseValueConvertible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible)\n\n**Instead of rows, you can directly fetch values.** There are many supported [value types](#values) (Bool, Int, String, Date, Swift enums, etc.).\n\nLike rows, fetch values as **cursors**, **arrays**, **sets**, or **single** values (see [fetching methods](#fetching-methods)). Values are extracted from the leftmost column of the SQL queries:\n\n```swift\ntry dbQueue.read { db in\n    try Int.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Int\n    try Int.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Int]\n    try Int.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Int>\n    try Int.fetchOne(db, sql: \"SELECT ...\", arguments: ...)    // Int?\n    \n    let maxScore = try Int.fetchOne(db, sql: \"SELECT MAX(score) FROM player\") // Int?\n    let names = try String.fetchAll(db, sql: \"SELECT name FROM player\")       // [String]\n}\n```\n\n`Int.fetchOne` returns nil in two cases: either the SELECT statement yielded no row, or one row with a NULL value:\n\n```swift\n// No row:\ntry Int.fetchOne(db, sql: \"SELECT 42 WHERE FALSE\") // nil\n\n// One row with a NULL value:\ntry Int.fetchOne(db, sql: \"SELECT NULL\")           // nil\n\n// One row with a non-NULL value:\ntry Int.fetchOne(db, sql: \"SELECT 42\")             // 42\n```\n\nFor requests which may contain NULL, fetch optionals:\n\n```swift\ntry dbQueue.read { db in\n    try Optional<Int>.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Int?\n    try Optional<Int>.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Int?]\n    try Optional<Int>.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Int?>\n}\n```\n\n> :bulb: **Tip**: One advanced use case, when you fetch one value, is to distinguish the cases of a statement that yields no row, or one row with a NULL value. To do so, use `Optional<Int>.fetchOne`, which returns a double optional `Int??`:\n> \n> ```swift\n> // No row:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT 42 WHERE FALSE\") // .none\n> // One row with a NULL value:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT NULL\")           // .some(.none)\n> // One row with a non-NULL value:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT 42\")             // .some(.some(42))\n> ```\n\nThere are many supported value types (Bool, Int, String, Date, Swift enums, etc.). See [Values](#values) for more information.\n\n\n## Values\n\nGRDB ships with built-in support for the following value types:\n\n- **Swift Standard Library**: Bool, Double, Float, all signed and unsigned integer types, String, [Swift enums](#swift-enums).\n    \n- **Foundation**: [Data](#data-and-memory-savings), [Date](#date-and-datecomponents), [DateComponents](#date-and-datecomponents), [Decimal](#nsnumber-nsdecimalnumber-and-decimal), NSNull, [NSNumber](#nsnumber-nsdecimalnumber-and-decimal), NSString, URL, [UUID](#uuid).\n    \n- **CoreGraphics**: CGFloat.\n\n- **[DatabaseValue](#databasevalue)**, the type which gives information about the raw value stored in the database.\n\n- **Full-Text Patterns**: [FTS3Pattern](Documentation/FullTextSearch.md#fts3pattern) and [FTS5Pattern](Documentation/FullTextSearch.md#fts5pattern).\n\n- Generally speaking, all types that adopt the [`DatabaseValueConvertible`] protocol.\n\nValues can be used as [statement arguments](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments):\n\n```swift\nlet url: URL = ...\nlet verified: Bool = ...\ntry db.execute(\n    sql: \"INSERT INTO link (url, verified) VALUES (?, ?)\",\n    arguments: [url, verified])\n```\n\nValues can be [extracted from rows](#column-values):\n\n```swift\nlet rows = try Row.fetchCursor(db, sql: \"SELECT * FROM link\")\nwhile let row = try rows.next() {\n    let url: URL = row[\"url\"]\n    let verified: Bool = row[\"verified\"]\n}\n```\n\nValues can be [directly fetched](#value-queries):\n\n```swift\nlet urls = try URL.fetchAll(db, sql: \"SELECT url FROM link\")  // [URL]\n```\n\nUse values in [Records](#records):\n\n```swift\nstruct Link: FetchableRecord {\n    var url: URL\n    var isVerified: Bool\n    \n    init(row: Row) {\n        url = row[\"url\"]\n        isVerified = row[\"verified\"]\n    }\n}\n```\n\nUse values in the [query interface](#the-query-interface):\n\n```swift\nlet url: URL = ...\nlet link = try Link.filter { $0.url == url }.fetchOne(db)\n```\n\n\n### Data (and Memory Savings)\n\n**Data** suits the BLOB SQLite columns. It can be stored and fetched from the database just like other [values](#values):\n\n```swift\nlet rows = try Row.fetchCursor(db, sql: \"SELECT data, ...\")\nwhile let row = try rows.next() {\n    let data: Data = row[\"data\"]\n}\n```\n\nAt each step of the request iteration, the `row[]` subscript creates *two copies* of the database bytes: one fetched by SQLite, and another, stored in the Swift Data value.\n\n**You have the opportunity to save memory** by not copying the data fetched by SQLite:\n\n```swift\nwhile let row = try rows.next() {\n    try row.withUnsafeData(name: \"data\") { (data: Data?) in\n        ...\n    }\n}\n```\n\nThe non-copied data does not live longer than the iteration step: make sure that you do not use it past this point.\n\n\n### Date and DateComponents\n\n[**Date**](#date) and [**DateComponents**](#datecomponents) can be stored and fetched from the database.\n\nHere is how GRDB supports the various [date formats](https://www.sqlite.org/lang_datefunc.html) supported by SQLite:\n\n| SQLite format                | Date               | DateComponents |\n|:---------------------------- |:------------------:|:--------------:|\n| YYYY-MM-DD                   |       Read Â¹       | Read / Write   |\n| YYYY-MM-DD HH:MM             |       Read Â¹ Â²     | Read Â² / Write |\n| YYYY-MM-DD HH:MM:SS          |       Read Â¹ Â²     | Read Â² / Write |\n| YYYY-MM-DD HH:MM:SS.SSS      | Read Â¹ Â² / Write Â¹ | Read Â² / Write |\n| YYYY-MM-DD**T**HH:MM         |       Read Â¹ Â²     |      Read Â²    |\n| YYYY-MM-DD**T**HH:MM:SS      |       Read Â¹ Â²     |      Read Â²    |\n| YYYY-MM-DD**T**HH:MM:SS.SSS  |       Read Â¹ Â²     |      Read Â²    |\n| HH:MM                        |                    | Read Â² / Write |\n| HH:MM:SS                     |                    | Read Â² / Write |\n| HH:MM:SS.SSS                 |                    | Read Â² / Write |\n| Timestamps since unix epoch  |       Read Â³       |                |\n| `now`                        |                    |                |\n\nÂ¹ Missing components are assumed to be zero. Dates are stored and read in the UTC time zone, unless the format is followed by a timezone indicator â½Â²â¾.\n\nÂ² This format may be optionally followed by a timezone indicator of the form `[+-]HH:MM` or just `Z`.\n\nÂ³ GRDB 2+ interprets numerical values as timestamps that fuel `Date(timeIntervalSince1970:)`. Previous GRDB versions used to interpret numbers as [julian days](https://en.wikipedia.org/wiki/Julian_day). Julian days are still supported, with the `Date(julianDay:)` initializer.\n\n> **Warning**: the range of valid years in the SQLite date formats is 0000-9999. You will need to pick another date format when your application needs to process years outside of this range. See the following chapters.\n\n\n#### Date\n\n**Date** can be stored and fetched from the database just like other [values](#values):\n\n```swift\ntry db.execute(\n    sql: \"INSERT INTO player (creationDate, ...) VALUES (?, ...)\",\n    arguments: [Date(), ...])\n\nlet row = try Row.fetchOne(db, ...)!\nlet creationDate: Date = row[\"creationDate\"]\n```\n\nDates are stored using the format \"YYYY-MM-DD HH:MM:SS.SSS\" in the UTC time zone. It is precise to the millisecond.\n\n> **Note**: this format was chosen because it is the only format that is:\n> \n> - Comparable (`ORDER BY date` works)\n> - Comparable with the SQLite keyword CURRENT_TIMESTAMP (`WHERE date > CURRENT_TIMESTAMP` works)\n> - Able to feed [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html)\n> - Precise enough\n>\n> **Warning**: the range of valid years in the SQLite date format is 0000-9999. You will experience problems with years outside of this range, such as decoding errors, or invalid date computations with [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html).\n\nSome applications may prefer another date format:\n\n- Some may prefer ISO-8601, with a `T` separator.\n- Some may prefer ISO-8601, with a time zone.\n- Some may need to store years beyond the 0000-9999 range.\n- Some may need sub-millisecond precision.\n- Some may need exact `Date` roundtrip.\n- Etc.\n\n**You should think twice before choosing a different date format:**\n\n- ISO-8601 is about *exchange and communication*, when SQLite is about *storage and data manipulation*. Sharing the same representation in your database and in JSON files only provides a superficial convenience, and should be the least of your priorities. Don't store dates as ISO-8601 without understanding what you lose. For example, ISO-8601 time zones forbid database-level date comparison. \n- Sub-millisecond precision and exact `Date` roundtrip are not as obvious needs as it seems at first sight. Dates generally don't precisely roundtrip as soon as they leave your application anyway, because the other systems your app communicates with use their own date representation (the Android version of your app, the server your application is talking to, etc.) On top of that, `Date` comparison is at least as hard and nasty as [floating point comparison](https://www.google.com/search?q=floating+point+comparison+is+hard).\n\nThe customization of date format is explicit. For example:\n\n```swift\nlet date = Date()\nlet timeInterval = date.timeIntervalSinceReferenceDate\ntry db.execute(\n    sql: \"INSERT INTO player (creationDate, ...) VALUES (?, ...)\",\n    arguments: [timeInterval, ...])\n\nif let row = try Row.fetchOne(db, ...) {\n    let timeInterval: TimeInterval = row[\"creationDate\"]\n    let creationDate = Date(timeIntervalSinceReferenceDate: timeInterval)\n}\n```\n\nSee also [Codable Records] for more date customization options, and [`DatabaseValueConvertible`] if you want to define a Date-wrapping type with customized database representation.\n\n\n#### DateComponents\n\nDateComponents is indirectly supported, through the **DatabaseDateComponents** helper type.\n\nDatabaseDateComponents reads date components from all [date formats supported by SQLite](https://www.sqlite.org/lang_datefunc.html), and stores them in the format of your choice, from HH:MM to YYYY-MM-DD HH:MM:SS.SSS.\n\n> **Warning**: the range of valid years is 0000-9999. You will experience problems with years outside of this range, such as decoding errors, or invalid date computations with [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html). See [Date](#date) for more information.\n\nDatabaseDateComponents can be stored and fetched from the database just like other [values](#values):\n\n```swift\nlet components = DateComponents()\ncomponents.year = 1973\ncomponents.month = 9\ncomponents.day = 18\n\n// Store \"1973-09-18\"\nlet dbComponents = DatabaseDateComponents(components, format: .YMD)\ntry db.execute(\n    sql: \"INSERT INTO player (birthDate, ...) VALUES (?, ...)\",\n    arguments: [dbComponents, ...])\n\n// Read \"1973-09-18\"\nlet row = try Row.fetchOne(db, sql: \"SELECT birthDate ...\")!\nlet dbComponents: DatabaseDateComponents = row[\"birthDate\"]\ndbComponents.format         // .YMD (the actual format found in the database)\ndbComponents.dateComponents // DateComponents\n```\n\n\n### NSNumber, NSDecimalNumber, and Decimal\n\n**NSNumber** and **Decimal** can be stored and fetched from the database just like other [values](#values).\n\nHere is how GRDB supports the various data types supported by SQLite:\n\n|                 |    Integer   |     Double   |    String    |\n|:--------------- |:------------:|:------------:|:------------:|\n| NSNumber        | Read / Write | Read / Write |     Read     |\n| NSDecimalNumber | Read / Write | Read / Write |     Read     |\n| Decimal         |     Read     |     Read     | Read / Write |\n\n- All three types can decode database integers and doubles:\n\n    ```swift\n    let number = try NSNumber.fetchOne(db, sql: \"SELECT 10\")            // NSNumber\n    let number = try NSDecimalNumber.fetchOne(db, sql: \"SELECT 1.23\")   // NSDecimalNumber\n    let number = try Decimal.fetchOne(db, sql: \"SELECT -100\")           // Decimal\n    ```\n    \n- All three types decode database strings as decimal numbers:\n\n    ```swift\n    let number = try NSNumber.fetchOne(db, sql: \"SELECT '10'\")          // NSDecimalNumber (sic)\n    let number = try NSDecimalNumber.fetchOne(db, sql: \"SELECT '1.23'\") // NSDecimalNumber\n    let number = try Decimal.fetchOne(db, sql: \"SELECT '-100'\")         // Decimal\n    ```\n\n- `NSNumber` and `NSDecimalNumber` send 64-bit signed integers and doubles in the database:\n\n    ```swift\n    // INSERT INTO transfer VALUES (10)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSNumber(value: 10)])\n    \n    // INSERT INTO transfer VALUES (10.0)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSNumber(value: 10.0)])\n    \n    // INSERT INTO transfer VALUES (10)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSDecimalNumber(string: \"10.0\")])\n    \n    // INSERT INTO transfer VALUES (10.5)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSDecimalNumber(string: \"10.5\")])\n    ```\n    \n    > **Warning**: since SQLite does not support decimal numbers, sending a non-integer `NSDecimalNumber` can result in a loss of precision during the conversion to double.\n    >\n    > Instead of sending non-integer `NSDecimalNumber` to the database, you may prefer:\n    >\n    > - Send `Decimal` instead (those store decimal strings in the database).\n    > - Send integers instead (for example, store amounts of cents instead of amounts of Euros).\n\n- `Decimal` sends decimal strings in the database:\n\n    ```swift\n    // INSERT INTO transfer VALUES ('10')\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [Decimal(10)])\n    \n    // INSERT INTO transfer VALUES ('10.5')\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [Decimal(string: \"10.5\")!])\n    ```\n\n\n### UUID\n\n**UUID** can be stored and fetched from the database just like other [values](#values).\n\nGRDB stores uuids as 16-bytes data blobs, and decodes them from both 16-bytes data blobs and strings such as \"E621E1F8-C36C-495A-93FC-0C247A3E6E5F\".\n\n\n### Swift Enums\n\n**Swift enums** and generally all types that adopt the [RawRepresentable](https://developer.apple.com/library/tvos/documentation/Swift/Reference/Swift_RawRepresentable_Protocol/index.html) protocol can be stored and fetched from the database just like their raw [values](#values):\n\n```swift\nenum Color : Int {\n    case red, white, rose\n}\n\nenum Grape : String {\n    case chardonnay, merlot, riesling\n}\n\n// Declare empty DatabaseValueConvertible adoption\nextension Color : DatabaseValueConvertible { }\nextension Grape : DatabaseValueConvertible { }\n\n// Store\ntry db.execute(\n    sql: \"INSERT INTO wine (grape, color) VALUES (?, ?)\",\n    arguments: [Grape.merlot, Color.red])\n\n// Read\nlet rows = try Row.fetchCursor(db, sql: \"SELECT * FROM wine\")\nwhile let row = try rows.next() {\n    let grape: Grape = row[\"grape\"]\n    let color: Color = row[\"color\"]\n}\n```\n\n**When a database value does not match any enum case**, you get a fatal error. This fatal error can be avoided with the [DatabaseValue](#databasevalue) type:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 'syrah'\")!\n\nrow[0] as String  // \"syrah\"\nrow[0] as Grape?  // fatal error: could not convert \"syrah\" to Grape.\nrow[0] as Grape   // fatal error: could not convert \"syrah\" to Grape.\n\nlet dbValue: DatabaseValue = row[0]\nif dbValue.isNull {\n    // Handle NULL\n} else if let grape = Grape.fromDatabaseValue(dbValue) {\n    // Handle valid grape\n} else {\n    // Handle unknown grape\n}\n```\n\n\n## Custom SQL Functions and Aggregates\n\n**SQLite lets you define SQL functions and aggregates.**\n\nA custom SQL function or aggregate extends SQLite:\n\n```sql\nSELECT reverse(name) FROM player;   -- custom function\nSELECT maxLength(name) FROM player; -- custom aggregate\n```\n\n- [Custom SQL Functions](#custom-sql-functions)\n- [Custom Aggregates](#custom-aggregates)\n\n\n### Custom SQL Functions\n\nğŸ“– [`DatabaseFunction`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasefunction)\n\nA *function* argument takes an array of [DatabaseValue](#databasevalue), and returns any valid [value](#values) (Bool, Int, String, Date, Swift enums, etc.) The number of database values is guaranteed to be *argumentCount*.\n\nSQLite has the opportunity to perform additional optimizations when functions are \"pure\", which means that their result only depends on their arguments. So make sure to set the *pure* argument to true when possible.\n\n```swift\nlet reverse = DatabaseFunction(\"reverse\", argumentCount: 1, pure: true) { (values: [DatabaseValue]) in\n    // Extract string value, if any...\n    guard let string = String.fromDatabaseValue(values[0]) else {\n        return nil\n    }\n    // ... and return reversed string:\n    return String(string.reversed())\n}\n```\n\nYou make a function available to a database connection through its configuration:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(function: reverse)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // \"oof\"\n    try String.fetchOne(db, sql: \"SELECT reverse('foo')\")!\n}\n```\n\n\n**Functions can take a variable number of arguments:**\n\nWhen you don't provide any explicit *argumentCount*, the function can take any number of arguments:\n\n```swift\nlet averageOf = DatabaseFunction(\"averageOf\", pure: true) { (values: [DatabaseValue]) in\n    let doubles = values.compactMap { Double.fromDatabaseValue($0) }\n    return doubles.reduce(0, +) / Double(doubles.count)\n}\ndb.add(function: averageOf)\n\n// 2.0\ntry Double.fetchOne(db, sql: \"SELECT averageOf(1, 2, 3)\")!\n```\n\n\n**Functions can throw:**\n\n```swift\nlet sqrt = DatabaseFunction(\"sqrt\", argumentCount: 1, pure: true) { (values: [DatabaseValue]) in\n    guard let double = Double.fromDatabaseValue(values[0]) else {\n        return nil\n    }\n    guard double >= 0 else {\n        throw DatabaseError(message: \"invalid negative number\")\n    }\n    return sqrt(double)\n}\ndb.add(function: sqrt)\n\n// SQLite error 1 with statement `SELECT sqrt(-1)`: invalid negative number\ntry Double.fetchOne(db, sql: \"SELECT sqrt(-1)\")!\n```\n\n\n**Use custom functions in the [query interface](#the-query-interface):**\n\n```swift\n// SELECT reverseString(\"name\") FROM player\nPlayer.select { reverseString($0.name) }\n```\n\n\n**GRDB ships with built-in SQL functions that perform unicode-aware string transformations.** See [Unicode](#unicode).\n\n\n### Custom Aggregates\n\nğŸ“– [`DatabaseFunction`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasefunction), [`DatabaseAggregate`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseaggregate)\n\nBefore registering a custom aggregate, you need to define a type that adopts the `DatabaseAggregate` protocol:\n\n```swift\nprotocol DatabaseAggregate {\n    // Initializes an aggregate\n    init()\n    \n    // Called at each step of the aggregation\n    mutating func step(_ dbValues: [DatabaseValue]) throws\n    \n    // Returns the final result\n    func finalize() throws -> DatabaseValueConvertible?\n}\n```\n\nFor example:\n\n```swift\nstruct MaxLength : DatabaseAggregate {\n    var maxLength: Int = 0\n    \n    mutating func step(_ dbValues: [DatabaseValue]) {\n        // At each step, extract string value, if any...\n        guard let string = String.fromDatabaseValue(dbValues[0]) else {\n            return\n        }\n        // ... and update the result\n        let length = string.count\n        if length > maxLength {\n            maxLength = length\n        }\n    }\n    \n    func finalize() -> DatabaseValueConvertible? {\n        maxLength\n    }\n}\n\nlet maxLength = DatabaseFunction(\n    \"maxLength\",\n    argumentCount: 1,\n    pure: true,\n    aggregate: MaxLength.self)\n```\n\nLike [custom SQL Functions](#custom-sql-functions), you make an aggregate function available to a database connection through its configuration:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(function: maxLength)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // Some Int\n    try Int.fetchOne(db, sql: \"SELECT maxLength(name) FROM player\")!\n}\n```\n\nThe `step` method of the aggregate takes an array of [DatabaseValue](#databasevalue). This array contains as many values as the *argumentCount* parameter (or any number of values, when *argumentCount* is omitted).\n\nThe `finalize` method of the aggregate returns the final aggregated [value](#values) (Bool, Int, String, Date, Swift enums, etc.).\n\nSQLite has the opportunity to perform additional optimizations when aggregates are \"pure\", which means that their result only depends on their inputs. So make sure to set the *pure* argument to true when possible.\n\n\n**Use custom aggregates in the [query interface](#the-query-interface):**\n\n```swift\n// SELECT maxLength(\"name\") FROM player\nlet request = Player.select { maxLength($0.name) }\ntry Int.fetchOne(db, request) // Int?\n```\n\n\n## Raw SQLite Pointers\n\n**If not all SQLite APIs are exposed in GRDB, you can still use the [SQLite C Interface](https://www.sqlite.org/c3ref/intro.html) and call [SQLite C functions](https://www.sqlite.org/c3ref/funclist.html).**\n\nTo access the C SQLite functions from SQLCipher or the system SQLite, you need to perform an extra import:\n\n```swift\nimport SQLite3   // System SQLite\nimport SQLCipher // SQLCipher\n\nlet sqliteVersion = String(cString: sqlite3_libversion())\n```\n\nRaw pointers to database connections and statements are available through the `Database.sqliteConnection` and `Statement.sqliteStatement` properties:\n\n```swift\ntry dbQueue.read { db in\n    // The raw pointer to a database connection:\n    let sqliteConnection = db.sqliteConnection\n\n    // The raw pointer to a statement:\n    let statement = try db.makeStatement(sql: \"SELECT ...\")\n    let sqliteStatement = statement.sqliteStatement\n}\n```\n\n> **Note**\n>\n> - Those pointers are owned by GRDB: don't close connections or finalize statements created by GRDB.\n> - GRDB opens SQLite connections in the \"[multi-thread mode](https://www.sqlite.org/threadsafe.html)\", which (oddly) means that **they are not thread-safe**. Make sure you touch raw databases and statements inside their dedicated dispatch queues.\n> - Use the raw SQLite C Interface at your own risk. GRDB won't prevent you from shooting yourself in the foot.\n\n\nRecords\n=======\n\n**On top of the [SQLite API](#sqlite-api), GRDB provides protocols** that help manipulating database rows as regular objects named \"records\":\n\n```swift\ntry dbQueue.write { db in\n    if var place = try Player.fetchOne(db, id: 1) {\n        player.score += 10\n        try player.update(db)\n    }\n}\n```\n\nOf course, you need to open a [database connection], and [create database tables](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema) first.\n\nTo define a record type, define a type and extend it with database protocols:\n\n- `FetchableRecord` makes it possible to fetch instances from the database.\n- `PersistableRecord` makes it possible to save instances into the database.\n- `Codable` (not mandatory) provides ready-made serialization to and from database rows.\n- `Identifiable` (not mandatory) provides extra convenience database methods.\n\nTo make it easier to customize database requests, also nest a `Columns` enum: \n\n```swift\nstruct Player: Codable, Identifiable {\n    var id: Int64\n    var name: String\n    var score: Int\n    var team: String?\n}\n\n// Add database support\nextension Player: FetchableRecord, PersistableRecord {\n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n        static let team = Column(CodingKeys.team)\n    }\n}\n```\n\nSee more [examples of record definitions](#examples-of-record-definitions) below.\n\n> Note: if you are familiar with Core Data's NSManagedObject or Realm's Object, you may experience a cultural shock: GRDB records are not uniqued, do not auto-update, and do not lazy-load. This is both a purpose, and a consequence of protocol-oriented programming.\n>\n> Tip: The [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices) guide provides general guidance..\n>\n> Tip: See the [Demo Applications] for sample apps that uses records.\n\n**Overview**\n\n- [Inserting Records](#inserting-records)\n- [Fetching Records](#fetching-records)\n- [Updating Records](#updating-records)\n- [Deleting Records](#deleting-records)\n- [Counting Records](#counting-records)\n\n**Protocols and the Record Class**\n\n- [Record Protocols Overview](#record-protocols-overview)\n- [FetchableRecord Protocol](#fetchablerecord-protocol)\n- [TableRecord Protocol](#tablerecord-protocol)\n- [PersistableRecord Protocol](#persistablerecord-protocol)\n    - [Persistence Methods]\n    - [Persistence Methods and the `RETURNING` clause]\n    - [Persistence Callbacks]\n- [Identifiable Records]\n- [Codable Records]\n- [Record Comparison]\n- [Record Customization Options]\n- [Record Timestamps and Transaction Date]\n\n\n### Inserting Records\n\nTo insert a record in the database, call the `insert` method:\n\n```swift\nlet player = Player(id: 1, name: \"Arthur\", score: 1000)\ntry player.insert(db)\n```\n\n:point_right: `insert` is available for types that adopt the [PersistableRecord] protocol.\n\n\n### Fetching Records\n\nTo fetch records from the database, call a [fetching method](#fetching-methods):\n\n```swift\nlet arthur = try Player.fetchOne(db,            // Player?\n    sql: \"SELECT * FROM players WHERE name = ?\",\n    arguments: [\"Arthur\"])\n\nlet bestPlayers = try Player                    // [Player]\n    .order(\\.score.desc)\n    .limit(10)\n    .fetchAll(db)\n    \nlet spain = try Country.fetchOne(db, id: \"ES\")  // Country?\nlet italy = try Country.find(db, id: \"IT\")      // Country\n```\n\n:point_right: Fetching from raw SQL is available for types that adopt the [FetchableRecord] protocol.\n\n:point_right: Fetching without SQL, using the [query interface](#the-query-interface), is available for types that adopt both [FetchableRecord] and [TableRecord] protocol.\n\n\n### Updating Records\n\nTo update a record in the database, call the `update` method:\n\n```swift\nvar player: Player = ...\nplayer.score = 1000\ntry player.update(db)\n```\n\nIt is possible to [avoid useless updates](#record-comparison):\n\n```swift\n// does not hit the database if score has not changed\ntry player.updateChanges(db) {\n    $0.score = 1000\n}\n```\n\nSee the [query interface](#the-query-interface) for batch updates:\n\n```swift\ntry Player\n    .filter { $0.team == \"red\" }\n    .updateAll(db) { $0.score += 1 }\n```\n\n:point_right: update methods are available for types that adopt the [PersistableRecord] protocol. Batch updates are available on the [TableRecord] protocol.\n\n\n### Deleting Records\n\nTo delete a record in the database, call the `delete` method:\n\n```swift\nlet player: Player = ...\ntry player.delete(db)\n```\n\nYou can also delete by primary key, unique key, or perform batch deletes (see [Delete Requests](#delete-requests)):\n\n```swift\ntry Player.deleteOne(db, id: 1)\ntry Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\ntry Country.deleteAll(db, ids: [\"FR\", \"US\"])\ntry Player\n    .filter { $0.email == nil }\n    .deleteAll(db)\n```\n\n:point_right: delete methods are available for types that adopt the [PersistableRecord] protocol. Batch deletes are available on the [TableRecord] protocol.\n\n\n### Counting Records\n\nTo count records, call the `fetchCount` method:\n\n```swift\nlet playerCount: Int = try Player.fetchCount(db)\n\nlet playerWithEmailCount: Int = try Player\n    .filter { $0.email == nil }\n    .fetchCount(db)\n```\n\n:point_right: `fetchCount` is available for types that adopt the [TableRecord] protocol.\n\n\nDetails follow:\n\n- [Record Protocols Overview](#record-protocols-overview)\n- [FetchableRecord Protocol](#fetchablerecord-protocol)\n- [TableRecord Protocol](#tablerecord-protocol)\n- [PersistableRecord Protocol](#persistablerecord-protocol)\n- [Identifiable Records]\n- [Codable Records]\n- [Record Comparison]\n- [Record Customization Options]\n- [Examples of Record Definitions](#examples-of-record-definitions)\n\n\n## Record Protocols Overview\n\n**GRDB ships with three record protocols**. Your own types will adopt one or several of them, according to the abilities you want to extend your types with.\n\n- [FetchableRecord] is able to **decode database rows**.\n    \n    ```swift\n    struct Place: FetchableRecord { ... }\n    \n    let places = try dbQueue.read { db in\n        try Place.fetchAll(db, sql: \"SELECT * FROM place\")\n    }\n    ```\n    \n    > :bulb: **Tip**: `FetchableRecord` can derive its implementation from the standard `Decodable` protocol. See [Codable Records] for more information.\n    \n    `FetchableRecord` can decode database rows, but it is not able to build SQL requests for you. For that, you also need `TableRecord`:\n    \n- [TableRecord] is able to **generate SQL queries**:\n    \n    ```swift\n    struct Place: TableRecord { ... }\n    \n    let placeCount = try dbQueue.read { db in\n        // Generates and runs `SELECT COUNT(*) FROM place`\n        try Place.fetchCount(db)\n    }\n    ```\n    \n    When a type adopts both `TableRecord` and `FetchableRecord`, it can load from those requests:\n    \n    ```swift\n    struct Place: TableRecord, FetchableRecord { ... }\n    \n    try dbQueue.read { db in\n        let places = try Place.order(\\.title).fetchAll(db)\n        let paris = try Place.fetchOne(id: 1)\n    }\n    ```\n\n- [PersistableRecord] is able to **write**: it can create, update, and delete rows in the database:\n    \n    ```swift\n    struct Place : PersistableRecord { ... }\n    \n    try dbQueue.write { db in\n        try Place.delete(db, id: 1)\n        try Place(...).insert(db)\n    }\n    ```\n    \n    A persistable record can also [compare](#record-comparison) itself against other records, and avoid useless database updates.\n    \n    > :bulb: **Tip**: `PersistableRecord` can derive its implementation from the standard `Encodable` protocol. See [Codable Records] for more information.\n\n\n## FetchableRecord Protocol\n\nğŸ“– [`FetchableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/fetchablerecord)\n\n**The FetchableRecord protocol grants fetching methods to any type** that can be built from a database row:\n\n```swift\nprotocol FetchableRecord {\n    /// Row initializer\n    init(row: Row) throws\n}\n```\n\nFor example:\n\n```swift\nstruct Place {\n    var id: Int64?\n    var title: String\n    var coordinate: CLLocationCoordinate2D\n}\n\nextension Place: FetchableRecord {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n    \n    init(row: Row) {\n        id = row[Columns.id]\n        title = row[Columns.title]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[Columns.latitude],\n            longitude: row[Columns.longitude])\n    }\n}\n```\n\nSee [column values](#column-values) for more information about the `row[]` subscript.\n\nWhen your record type adopts the standard Decodable protocol, you don't have to provide the implementation for `init(row:)`. See [Codable Records] for more information:\n\n```swift\n// That's all\nstruct Player: Decodable, FetchableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n```\n\nFetchableRecord allows adopting types to be fetched from SQL queries:\n\n```swift\ntry Place.fetchCursor(db, sql: \"SELECT ...\", arguments:...) // A Cursor of Place\ntry Place.fetchAll(db, sql: \"SELECT ...\", arguments:...)    // [Place]\ntry Place.fetchSet(db, sql: \"SELECT ...\", arguments:...)    // Set<Place>\ntry Place.fetchOne(db, sql: \"SELECT ...\", arguments:...)    // Place?\n```\n\nSee [fetching methods](#fetching-methods) for information about the `fetchCursor`, `fetchAll`, `fetchSet` and `fetchOne` methods. See [`StatementArguments`] for more information about the query arguments.\n\n> **Note**: for performance reasons, the same row argument to `init(row:)` is reused during the iteration of a fetch query. If you want to keep the row for later use, make sure to store a copy: `self.row = row.copy()`.\n\n> **Note**: The `FetchableRecord.init(row:)` initializer fits the needs of most applications. But some application are more demanding than others. When FetchableRecord does not exactly provide the support you need, have a look at the [Beyond FetchableRecord] chapter.\n\n\n## TableRecord Protocol\n\nğŸ“– [`TableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord)\n\n**The TableRecord protocol** generates SQL for you:\n\n```swift\nprotocol TableRecord {\n    static var databaseTableName: String { get }\n    static var databaseSelection: [any SQLSelectable] { get }\n}\n```\n\nThe `databaseSelection` type property is optional, and documented in the [Columns Selected by a Request] chapter.\n\nThe `databaseTableName` type property is the name of a database table. By default, it is derived from the type name:\n\n```swift\nstruct Place: TableRecord { }\n\nprint(Place.databaseTableName) // prints \"place\"\n```\n\nFor example:\n\n- Place: `place`\n- Country: `country`\n- PostalAddress: `postalAddress`\n- HTTPRequest: `httpRequest`\n- TOEFL: `toefl`\n\nYou can still provide a custom table name:\n\n```swift\nstruct Place: TableRecord {\n    static let databaseTableName = \"location\"\n}\n\nprint(Place.databaseTableName) // prints \"location\"\n```\n\nWhen a type adopts both TableRecord and [FetchableRecord](#fetchablerecord-protocol), it can be fetched using the [query interface](#the-query-interface):\n\n```swift\n// SELECT * FROM place WHERE name = 'Paris'\nlet paris = try Place.filter { $0.name == \"Paris\" }.fetchOne(db)\n```\n\nTableRecord can also fetch deal with primary and unique keys: see [Fetching by Key](#fetching-by-key) and [Testing for Record Existence](#testing-for-record-existence).\n\n\n## PersistableRecord Protocol\n\nğŸ“– [`EncodableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/encodablerecord), [`MutablePersistableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/mutablepersistablerecord), [`PersistableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/persistablerecord)\n\n**GRDB record types can create, update, and delete rows in the database.**\n\nThose abilities are granted by three protocols:\n\n```swift\n// Defines how a record encodes itself into the database\nprotocol EncodableRecord {\n    /// Defines the values persisted in the database\n    func encode(to container: inout PersistenceContainer) throws\n}\n\n// Adds persistence methods\nprotocol MutablePersistableRecord: TableRecord, EncodableRecord {\n    /// Optional method that lets your adopting type store its rowID upon\n    /// successful insertion. Don't call it directly: it is called for you.\n    mutating func didInsert(_ inserted: InsertionSuccess)\n}\n\n// Adds immutability\nprotocol PersistableRecord: MutablePersistableRecord {\n    /// Non-mutating version of the optional didInsert(_:)\n    func didInsert(_ inserted: InsertionSuccess)\n}\n```\n\nYes, three protocols instead of one. Here is how you pick one or the other:\n\n- **If your type is a class**, choose `PersistableRecord`. On top of that, implement `didInsert(_:)` if the database table has an auto-incremented primary key.\n\n- **If your type is a struct, and the database table has an auto-incremented primary key**, choose `MutablePersistableRecord`, and implement `didInsert(_:)`.\n\n- **Otherwise**, choose `PersistableRecord`, and ignore `didInsert(_:)`.\n\nThe `encode(to:)` method defines which [values](#values) (Bool, Int, String, Date, Swift enums, etc.) are assigned to database columns.\n\nThe optional `didInsert` method lets the adopting type store its rowID after successful insertion, and is only useful for tables that have an auto-incremented primary key. It is called from a protected dispatch queue, and serialized with all database updates.\n\nFor example:\n\n```swift\nextension Place: MutablePersistableRecord {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n    \n    /// The values persisted in the database\n    func encode(to container: inout PersistenceContainer) {\n        container[Columns.id] = id\n        container[Columns.title] = title\n        container[Columns.latitude] = coordinate.latitude\n        container[Columns.longitude] = coordinate.longitude\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n\nvar paris = Place(\n    id: nil,\n    title: \"Paris\",\n    coordinate: CLLocationCoordinate2D(latitude: 48.8534100, longitude: 2.3488000))\n\ntry paris.insert(db)\nparis.id   // some value\n```\n\nWhen your record type adopts the standard Encodable protocol, you don't have to provide the implementation for `encode(to:)`. See [Codable Records] for more information:\n\n```swift\n// That's all\nstruct Player: Encodable, MutablePersistableRecord {\n    var id: Int64?\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n\n### Persistence Methods\n\nTypes that adopt the [PersistableRecord] protocol are given methods that insert, update, and delete:\n\n```swift\n// INSERT\ntry place.insert(db)\nlet insertedPlace = try place.inserted(db) // non-mutating\n\n// UPDATE\ntry place.update(db)\ntry place.update(db, columns: [\"title\"])\n\n// Maybe UPDATE\ntry place.updateChanges(db, from: otherPlace)\ntry place.updateChanges(db) { $0.isFavorite = true }\n\n// INSERT or UPDATE\ntry place.save(db)\nlet savedPlace = place.saved(db) // non-mutating\n\n// UPSERT\ntry place.upsert(db)\nlet insertedPlace = place.upsertAndFetch(db)\n\n// DELETE\ntry place.delete(db)\n\n// EXISTENCE CHECK\nlet exists = try place.exists(db)\n```\n\nSee [Upsert](#upsert) below for more information about upserts.\n\n**The [TableRecord] protocol comes with batch operations**:\n\n```swift\n// UPDATE\ntry Place.updateAll(db, ...)\n\n// DELETE\ntry Place.deleteAll(db)\ntry Place.deleteAll(db, ids:...)\ntry Place.deleteAll(db, keys:...)\ntry Place.deleteOne(db, id:...)\ntry Place.deleteOne(db, key:...)\n```\n\nFor more information about batch updates, see [Update Requests](#update-requests).\n\n- All persistence methods can throw a [DatabaseError](#error-handling).\n\n- `update` and `updateChanges` throw [RecordError] if the database does not contain any row for the primary key of the record.\n\n- `save` makes sure your values are stored in the database. It performs an UPDATE if the record has a non-null primary key, and then, if no row was modified, an INSERT. It directly performs an INSERT if the record has no primary key, or a null primary key.\n\n- `delete` and `deleteOne` returns whether a database row was deleted or not. `deleteAll` returns the number of deleted rows. `updateAll` returns the number of updated rows. `updateChanges` returns whether a database row was updated or not.\n\n**All primary keys are supported**, including composite primary keys that span several columns, and the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html).\n\n**To customize persistence methods**, you provide [Persistence Callbacks], described below. Do not attempt at overriding the ready-made persistence methods.\n\n### Upsert\n\n[UPSERT](https://www.sqlite.org/lang_UPSERT.html) is an SQLite feature that causes an INSERT to behave as an UPDATE or a no-op if the INSERT would violate a uniqueness constraint (primary key or unique index).\n\n> **Note**: Upsert apis are available from SQLite 3.35.0+: iOS 15.0+, macOS 12.0+, tvOS 15.0+, watchOS 8.0+, or with a [custom SQLite build] or [SQLCipher](#encryption).\n>\n> **Note**: With regard to [persistence callbacks](#available-callbacks), an upsert behaves exactly like an insert. In particular: the `aroundInsert(_:)` and `didInsert(_:)` callbacks reports the rowid of the inserted or updated row; `willUpdate`, `aroundUpdate`, `didUpdate` are not called.\n\n[PersistableRecord] provides three upsert methods:\n\n- `upsert(_:)`\n    \n    Inserts or updates a record.\n    \n    The upsert behavior is triggered by a violation of any uniqueness constraint on the table (primary key or unique index). In case of conflict, all columns but the primary key are overwritten with the inserted values:\n    \n    ```swift\n    struct Player: Encodable, PersistableRecord {\n        var id: Int64\n        var name: String\n        var score: Int\n    }\n    \n    // INSERT INTO player (id, name, score)\n    // VALUES (1, 'Arthur', 1000)\n    // ON CONFLICT DO UPDATE SET\n    //   name = excluded.name,\n    //   score = excluded.score\n    let player = Player(id: 1, name: \"Arthur\", score: 1000)\n    try player.upsert(db)\n    ```\n\n- `upsertAndFetch(_:onConflict:doUpdate:)` (requires [FetchableRecord] conformance)\n\n    Inserts or updates a record, and returns the upserted record.\n    \n    The `onConflict` and `doUpdate` arguments let you further control the upsert behavior. Make sure you check the [SQLite UPSERT documentation](https://www.sqlite.org/lang_UPSERT.html) for detailed information.\n    \n    - `onConflict`: the \"conflict target\" is the array of columns in the uniqueness constraint (primary key or unique index) that triggers the upsert.\n        \n        If empty (the default), all uniqueness constraint are considered.\n    \n    - `doUpdate`: a closure that returns columns assignments to perform in case of conflict. Other columns are overwritten with the inserted values.\n        \n        By default, all inserted columns but the primary key and the conflict target are overwritten.\n    \n    In the example below, we upsert the new vocabulary word \"jovial\". It is inserted if that word is not already in the dictionary. Otherwise, `count` is incremented, `isTainted` is not overwritten, and `kind` is overwritten:\n    \n    ```swift\n    // CREATE TABLE vocabulary(\n    //   word TEXT NOT NULL PRIMARY KEY,\n    //   kind TEXT NOT NULL,\n    //   isTainted BOOLEAN DEFAULT 0,\n    //   count INT DEFAULT 1))\n    struct Vocabulary: Encodable, PersistableRecord {\n        var word: String\n        var kind: String\n        var isTainted: Bool\n    }\n    \n    // INSERT INTO vocabulary(word, kind, isTainted)\n    // VALUES('jovial', 'adjective', 0)\n    // ON CONFLICT(word) DO UPDATE SET \\\n    //   count = count + 1,   -- on conflict, count is incremented\n    //   kind = excluded.kind -- on conflict, kind is overwritten\n    // RETURNING *\n    let vocabulary = Vocabulary(word: \"jovial\", kind: \"adjective\", isTainted: false)\n    let upserted = try vocabulary.upsertAndFetch(\n        db, onConflict: [\"word\"],\n        doUpdate: { _ in\n            [Column(\"count\") += 1,            // on conflict, count is incremented\n             Column(\"isTainted\").noOverwrite] // on conflict, isTainted is NOT overwritten\n        })\n    ```\n    \n    The `doUpdate` closure accepts an `excluded` TableAlias argument that refers to the inserted values that trigger the conflict. You can use it to specify an explicit overwrite, or to perform a computation. In the next example, the upsert keeps the maximum date in case of conflict:\n    \n    ```swift\n    // INSERT INTO message(id, text, date)\n    // VALUES(...)\n    // ON CONFLICT DO UPDATE SET \\\n    //   text = excluded.text,\n    //   date = MAX(date, excluded.date)\n    // RETURNING *\n    let upserted = try message.upsertAndFetch(doUpdate: { excluded in\n        // keep the maximum date in case of conflict\n        [Column(\"date\").set(to: max(Column(\"date\"), excluded[\"date\"]))]\n    })\n    ```\n\n- `upsertAndFetch(_:as:onConflict:doUpdate:)` (does not require [FetchableRecord] conformance)\n\n    This method is identical to `upsertAndFetch(_:onConflict:doUpdate:)` described above, but you can provide a distinct [FetchableRecord] record type as a result, in order to specify the returned columns.\n\n### Persistence Methods and the `RETURNING` clause\n\nSQLite is able to return values from a inserted, updated, or deleted row, with the [`RETURNING` clause](https://www.sqlite.org/lang_returning.html).\n\n> **Note**: Support for the `RETURNING` clause is available from SQLite 3.35.0+: iOS 15.0+, macOS 12.0+, tvOS 15.0+, watchOS 8.0+, or with a [custom SQLite build] or [SQLCipher](#encryption).\n\nThe `RETURNING` clause helps dealing with database features such as auto-incremented ids, default values, and [generated columns](https://sqlite.org/gencol.html). You can, for example, insert a few columns and fetch the default or generated ones in one step.\n\nGRDB uses the `RETURNING` clause in all persistence methods that contain `AndFetch` in their name.\n\nFor example, given a database table with an auto-incremented primary key and a default score:\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player(\n          id INTEGER PRIMARY KEY AUTOINCREMENT,\n          name TEXT NOT NULL,\n          score INTEGER NOT NULL DEFAULT 1000)\n        \"\"\")\n}\n```\n\nYou can define a record type with full database information, and another partial record type that deals with a subset of columns:\n\n```swift\n// A player with full database information\nstruct Player: Codable, PersistableRecord, FetchableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// A partial player\nstruct PartialPlayer: Encodable, PersistableRecord {\n    static let databaseTableName = \"player\"\n    var name: String\n    \n    typealias Columns = Player.Columns\n}\n```\n\nAnd now you can get a full player by inserting a partial one:\n\n```swift\ntry dbQueue.write { db in\n    let partialPlayer = PartialPlayer(name: \"Alice\")\n    \n    // INSERT INTO player (name) VALUES ('Alice') RETURNING *\n    let player = try partialPlayer.insertAndFetch(db, as: Player.self)\n    print(player.id)    // The inserted id\n    print(player.name)  // The inserted name\n    print(player.score) // The default score\n}\n```\n\nFor extra precision, you can select only the columns you need, and fetch the desired value from the provided prepared [`Statement`]:\n\n```swift\ntry dbQueue.write { db in\n    let partialPlayer = PartialPlayer(name: \"Alice\")\n    \n    // INSERT INTO player (name) VALUES ('Alice') RETURNING score\n    let score = try partialPlayer.insertAndFetch(db) { statement in\n        try Int.fetchOne(statement)\n    } select: {\n        [$0.score]\n    }\n    print(score) // Prints 1000, the default score\n}\n```\n\nThere are other similar persistence methods, such as `upsertAndFetch`, `saveAndFetch`, `updateAndFetch`, `updateChangesAndFetch`, etc. They all behave like `upsert`, `save`, `update`, `updateChanges`, except that they return saved values. For example:\n\n```swift\n// Save and return the saved player\nlet savedPlayer = try player.saveAndFetch(db)\n```\n\nSee [Persistence Methods], [Upsert](#upsert), and [`updateChanges` methods](#the-updatechanges-methods) for more information.\n\n**Batch operations** can return updated or deleted values:\n\n> **Warning**: Make sure you check the [documentation of the `RETURNING` clause](https://www.sqlite.org/lang_returning.html#limitations_and_caveats), which describes important limitations and caveats for batch operations.\n\n```swift\nlet request = Player.filter(...)...\n\n// Fetch all deleted players\n// DELETE FROM player RETURNING *\nlet deletedPlayers = try request.deleteAndFetchAll(db) // [Player]\n\n// Fetch a selection of columns from the deleted rows\n// DELETE FROM player RETURNING name\nlet statement = try request.deleteAndFetchStatement(db) { [$0.name] }\nlet deletedNames = try String.fetchSet(statement)\n\n// Fetch all updated players\n// UPDATE player SET score = score + 10 RETURNING *\nlet updatedPlayers = try request.updateAndFetchAll(db) { [$0.score += 10] } // [Player]\n\n// Fetch a selection of columns from the updated rows\n// UPDATE player SET score = score + 10 RETURNING score\nlet statement = try request.updateAndFetchStatement(db) {\n    [$0.score += 10]\n} select: {\n    [$0.score]\n}\nlet updatedScores = try Int.fetchAll(statement)\n```\n\n\n### Persistence Callbacks\n\nYour custom type may want to perform extra work when the persistence methods are invoked.\n\nTo this end, your record type can implement **persistence callbacks**. Callbacks are methods that get called at certain moments of a record's life cycle. With callbacks it is possible to write code that will run whenever an record is inserted, updated, or deleted.\n\nIn order to use a callback method, you need to provide its implementation. For example, a frequently used callback is `didInsert`, in the case of auto-incremented database ids:\n\n```swift\nstruct Player: MutablePersistableRecord {\n    var id: Int64?\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n\ntry dbQueue.write { db in\n    var player = Player(id: nil, ...)\n    try player.insert(db)\n    print(player.id) // didInsert was called: prints some non-nil id\n}\n```\n\nCallbacks can also help implementing record validation:\n\n```swift\nstruct Link: PersistableRecord {\n    var url: URL\n    \n    func willSave(_ db: Database) throws {\n        if url.host == nil {\n            throw ValidationError(\"url must be absolute.\")\n        }\n    }\n}\n\ntry link.insert(db) // Calls the willSave callback\ntry link.update(db) // Calls the willSave callback\ntry link.save(db)   // Calls the willSave callback\ntry link.upsert(db) // Calls the willSave callback\n```\n\n#### Available Callbacks\n\nHere is a list with all the available [persistence callbacks], listed in the same order in which they will get called during the respective operations:\n\n- Inserting a record (all `record.insert` and `record.upsert` methods)\n    - `willSave`\n    - `aroundSave`\n    - `willInsert`\n    - `aroundInsert`\n    - `didInsert`\n    - `didSave`\n    \n- Updating a record (all `record.update` methods)\n    - `willSave`\n    - `aroundSave`\n    - `willUpdate`\n    - `aroundUpdate`\n    - `didUpdate`\n    - `didSave`\n    \n- Deleting a record (only the `record.delete(_:)` method)\n    - `willDelete`\n    - `aroundDelete`\n    - `didDelete`\n\nFor detailed information about each callback, check the [reference](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/mutablepersistablerecord/).\n\nIn the `MutablePersistableRecord` protocol, `willInsert` and `didInsert` are mutating methods. In `PersistableRecord`, they are not mutating.\n\n> **Note**: The `record.save(_:)` method performs an UPDATE if the record has a non-null primary key, and then, if no row was modified, an INSERT. It directly performs an INSERT if the record has no primary key, or a null primary key. It triggers update and/or insert callbacks accordingly.\n>\n> **Warning**: Callbacks are only invoked from persistence methods called on record instances. Callbacks are not invoked when you call a type method, perform a batch operations, or execute raw SQL.\n>\n> **Warning**: When a `did***` callback is invoked, do not assume that the change is actually persisted on disk, because the database may still be inside an uncommitted transaction. When you need to handle transaction completions, use the [afterNextTransaction(onCommit:onRollback:)](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)). For example:\n>\n> ```swift\n> struct PictureFile: PersistableRecord {\n>     var path: String\n>     \n>     func willDelete(_ db: Database) {\n>         db.afterNextTransaction { _ in\n>             try? deleteFileOnDisk()\n>         }\n>     }\n> }\n> ```\n\n\n## Identifiable Records\n\n**When a record type maps a table with a single-column primary key, it is recommended to have it adopt the standard [Identifiable] protocol.**\n\n```swift\nstruct Player: Identifiable, FetchableRecord, PersistableRecord {\n    var id: Int64 // fulfills the Identifiable requirement\n    var name: String\n    var score: Int\n}\n```\n\nWhen `id` has a [database-compatible type](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible) (Int64, Int, String, UUID, ...), the `Identifiable` conformance unlocks type-safe record and request methods:\n\n```swift\nlet player = try Player.find(db, id: 1)               // Player\nlet player = try Player.fetchOne(db, id: 1)           // Player?\nlet players = try Player.fetchAll(db, ids: [1, 2, 3]) // [Player]\nlet players = try Player.fetchSet(db, ids: [1, 2, 3]) // Set<Player>\n\nlet request = Player.filter(id: 1)\nlet request = Player.filter(ids: [1, 2, 3])\n\ntry Player.deleteOne(db, id: 1)\ntry Player.deleteAll(db, ids: [1, 2, 3])\n```\n\n> **Note**: Not all record types can be made `Identifiable`, and not all tables have a single-column primary key. GRDB provides other methods that deal with primary and unique keys, but they won't check the type of their arguments:\n> \n> ```swift\n> // Available on non-Identifiable types\n> try Player.fetchOne(db, key: 1)\n> try Player.fetchOne(db, key: [\"email\": \"arthur@example.com\"])\n> try Country.fetchAll(db, keys: [\"FR\", \"US\"])\n> try Citizenship.fetchOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n> \n> let request = Player.filter(key: 1)\n> let request = Player.filter(keys: [1, 2, 3])\n> \n> try Player.deleteOne(db, key: 1)\n> try Player.deleteAll(db, keys: [1, 2, 3])\n> ```\n\n> **Note**: It is not recommended to use `Identifiable` on record types that use an auto-incremented primary key:\n>\n> ```swift\n> // AVOID declaring Identifiable conformance when key is auto-incremented\n> struct Player {\n>     var id: Int64? // Not an id suitable for Identifiable\n>     var name: String\n>     var score: Int\n> }\n> \n> extension Player: FetchableRecord, MutablePersistableRecord {\n>     // Update auto-incremented id upon successful insertion\n>     mutating func didInsert(_ inserted: InsertionSuccess) {\n>         id = inserted.rowID\n>     }\n> }\n> ```\n>\n> For a detailed rationale, please see [issue #1435](https://github.com/groue/GRDB.swift/issues/1435#issuecomment-1740857712).\n\nSome database tables have a single-column primary key which is not called \"id\":\n\n```swift\ntry db.create(table: \"country\") { t in\n    t.primaryKey(\"isoCode\", .text)\n    t.column(\"name\", .text).notNull()\n    t.column(\"population\", .integer).notNull()\n}\n```\n\nIn this case, `Identifiable` conformance can be achieved, for example, by returning the primary key column from the `id` property:\n\n```swift\nstruct Country: Identifiable, FetchableRecord, PersistableRecord {\n    var isoCode: String\n    var name: String\n    var population: Int\n    \n    // Fulfill the Identifiable requirement\n    var id: String { isoCode }\n}\n\nlet france = try dbQueue.read { db in\n    try Country.fetchOne(db, id: \"FR\")\n}\n```\n\n\n## Codable Records\n\nRecord types that adopt an archival protocol ([Codable, Encodable or Decodable](https://developer.apple.com/documentation/foundation/archives_and_serialization/encoding_and_decoding_custom_types)) get free database support just by declaring conformance to the desired [record protocols](#record-protocols-overview):\n\n```swift\n// Declare a record...\nstruct Player: Codable, FetchableRecord, PersistableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// ...and there you go:\ntry dbQueue.write { db in\n    try Player(id: 1, name: \"Arthur\", score: 100).insert(db)\n    let players = try Player.order(\\.score.desc).fetchAll(db)\n}\n```\n\nCodable records encode and decode their properties according to their own implementation of the Encodable and Decodable protocols. Yet databases have specific requirements:\n\n- Properties are always coded according to their preferred database representation, when they have one (all [values](#values) that adopt the [`DatabaseValueConvertible`] protocol).\n- You can customize the encoding and decoding of dates and uuids.\n- Complex properties (arrays, dictionaries, nested structs, etc.) are stored as JSON.\n\nFor more information about Codable records, see:\n\n- [JSON Columns]\n- [Column Names Coding Strategies]\n- [Data, Date, and UUID Coding Strategies]\n- [The userInfo Dictionary]\n- [Tip: Derive Columns from Coding Keys](#tip-derive-columns-from-coding-keys)\n\n> :bulb: **Tip**: see the [Demo Applications] for sample code that uses Codable records.\n\n\n### JSON Columns\n\nWhen a [Codable record](#codable-records) contains a property that is not a simple [value](#values) (Bool, Int, String, Date, Swift enums, etc.), that value is encoded and decoded as a **JSON string**. For example:\n\n```swift\nenum AchievementColor: String, Codable {\n    case bronze, silver, gold\n}\n\nstruct Achievement: Codable {\n    var name: String\n    var color: AchievementColor\n}\n\nstruct Player: Codable, FetchableRecord, PersistableRecord {\n    var name: String\n    var score: Int\n    var achievements: [Achievement] // stored in a JSON column\n}\n\ntry dbQueue.write { db in\n    // INSERT INTO player (name, score, achievements)\n    // VALUES (\n    //   'Arthur',\n    //   100,\n    //   '[{\"color\":\"gold\",\"name\":\"Use Codable Records\"}]')\n    let achievement = Achievement(name: \"Use Codable Records\", color: .gold)\n    let player = Player(name: \"Arthur\", score: 100, achievements: [achievement])\n    try player.insert(db)\n}\n```\n\nGRDB uses the standard [JSONDecoder](https://developer.apple.com/documentation/foundation/jsondecoder) and [JSONEncoder](https://developer.apple.com/documentation/foundation/jsonencoder) from Foundation. By default, Data values are handled with the `.base64` strategy, Date with the `.millisecondsSince1970` strategy, and non conforming floats with the `.throw` strategy.\n\nYou can customize the JSON format by implementing those methods:\n\n```swift\nprotocol FetchableRecord {\n    static func databaseJSONDecoder(for column: String) -> JSONDecoder\n}\n\nprotocol EncodableRecord {\n    static func databaseJSONEncoder(for column: String) -> JSONEncoder\n}\n```\n\n> :bulb: **Tip**: Make sure you set the JSONEncoder `sortedKeys` option. This option makes sure that the JSON output is stable. This stability is required for [Record Comparison] to work as expected, and database observation tools such as [ValueObservation] to accurately recognize changed records.\n\n\n### Column Names Coding Strategies\n\nBy default, [Codable Records] store their values into database columns that match their coding keys: the `teamID` property is stored into the `teamID` column.\n\nThis behavior can be overridden, so that you can, for example, store the `teamID` property into the `team_id` column:\n\n```swift\nprotocol FetchableRecord {\n    static var databaseColumnDecodingStrategy: DatabaseColumnDecodingStrategy { get }\n}\n\nprotocol EncodableRecord {\n    static var databaseColumnEncodingStrategy: DatabaseColumnEncodingStrategy { get }\n}\n```\n\nSee [DatabaseColumnDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasecolumndecodingstrategy) and [DatabaseColumnEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasecolumnencodingstrategy/) to learn about all available strategies.\n\n\n### Data, Date, and UUID Coding Strategies\n\nBy default, [Codable Records] encode and decode their Data properties as blobs, and Date and UUID properties as described in the general [Date and DateComponents](#date-and-datecomponents) and [UUID](#uuid) chapters.\n\nTo sum up: dates encode themselves in the \"YYYY-MM-DD HH:MM:SS.SSS\" format, in the UTC time zone, and decode a variety of date formats and timestamps. UUIDs encode themselves as 16-bytes data blobs, and decode both 16-bytes data blobs and strings such as \"E621E1F8-C36C-495A-93FC-0C247A3E6E5F\".\n\nThose behaviors can be overridden:\n\n```swift\nprotocol FetchableRecord {\n    static func databaseDataDecodingStrategy(for column: String) -> DatabaseDataDecodingStrategy\n    static func databaseDateDecodingStrategy(for column: String) -> DatabaseDateDecodingStrategy\n}\n\nprotocol EncodableRecord {\n    static func databaseDataEncodingStrategy(for column: String) -> DatabaseDataEncodingStrategy\n    static func databaseDateEncodingStrategy(for column: String) -> DatabaseDateEncodingStrategy\n    static func databaseUUIDEncodingStrategy(for column: String) -> DatabaseUUIDEncodingStrategy\n}\n```\n\nSee [DatabaseDataDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedatadecodingstrategy/), [DatabaseDateDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedatedecodingstrategy/), [DatabaseDataEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedataencodingstrategy/), [DatabaseDateEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedateencodingstrategy/), and [DatabaseUUIDEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseuuidencodingstrategy/) to learn about all available strategies.\n\nThere is no customization of uuid decoding, because UUID can already decode all its encoded variants (16-bytes blobs and uuid strings, both uppercase and lowercase).\n\nCustomized coding strategies apply:\n\n- When encoding and decoding database rows to and from records (fetching and persistence methods).\n- In requests by single-column primary key: `fetchOne(_:id:)`, `filter(id:)`, `deleteAll(_:keys:)`, etc.\n\n*They do not apply* in other requests based on data, date, or uuid values.\n\nSo make sure that those are properly encoded in your requests. For example:\n\n```swift\nstruct Player: Codable, FetchableRecord, PersistableRecord, Identifiable {\n    // UUIDs are stored as strings\n    static func databaseUUIDEncodingStrategy(for column: String) -> DatabaseUUIDEncodingStrategy {\n        .uppercaseString\n    }\n    \n    var id: UUID\n    ...\n}\n\ntry dbQueue.write { db in\n    let uuid = UUID()\n    let player = Player(id: uuid, ...)\n    \n    // OK: inserts a player in the database, with a string uuid\n    try player.insert(db)\n    \n    // OK: performs a string-based query, finds the inserted player\n    _ = try Player.filter(id: uuid).fetchOne(db)\n\n    // NOT OK: performs a blob-based query, fails to find the inserted player\n    _ = try Player.filter { $0.id == uuid }.fetchOne(db)\n    \n    // OK: performs a string-based query, finds the inserted player\n    _ = try Player.filter { $0.id == uuid.uuidString }.fetchOne(db)\n}\n```\n\n\n### The userInfo Dictionary\n\nYour [Codable Records] can be stored in the database, but they may also have other purposes. In this case, you may need to customize their implementations of `Decodable.init(from:)` and `Encodable.encode(to:)`, depending on the context.\n\nThe standard way to provide such context is the `userInfo` dictionary. Implement those properties:\n\n```swift\nprotocol FetchableRecord {\n    static var databaseDecodingUserInfo: [CodingUserInfoKey: Any] { get }\n}\n\nprotocol EncodableRecord {\n    static var databaseEncodingUserInfo: [CodingUserInfoKey: Any] { get }\n}\n```\n\nFor example, here is a Player type that customizes its decoding:\n\n```swift\n// A key that holds a decoder's name\nlet decoderName = CodingUserInfoKey(rawValue: \"decoderName\")!\n\nstruct Player: FetchableRecord, Decodable {\n    init(from decoder: Decoder) throws {\n        // Print the decoder name\n        let decoderName = decoder.userInfo[decoderName] as? String\n        print(\"Decoded from \\(decoderName ?? \"unknown decoder\")\")\n        ...\n    }\n}\n```\n\nYou can have a specific decoding from JSON...\n\n```swift\n// prints \"Decoded from JSON\"\nlet decoder = JSONDecoder()\ndecoder.userInfo = [decoderName: \"JSON\"]\nlet player = try decoder.decode(Player.self, from: jsonData)\n```\n\n... and another one from database rows:\n\n```swift\nextension Player: FetchableRecord {\n    static var databaseDecodingUserInfo: [CodingUserInfoKey: Any] {\n        [decoderName: \"database row\"]\n    }\n}\n\n// prints \"Decoded from database row\"\nlet player = try Player.fetchOne(db, ...)\n```\n\n> **Note**: make sure the `databaseDecodingUserInfo` and `databaseEncodingUserInfo` properties are explicitly declared as `[CodingUserInfoKey: Any]`. If they are not, the Swift compiler may silently miss the protocol requirement, resulting in sticky empty userInfo.\n\n\n### Tip: Derive Columns from Coding Keys\n\nCodable types are granted with a [CodingKeys](https://developer.apple.com/documentation/foundation/archives_and_serialization/encoding_and_decoding_custom_types) enum. You can use them to safely define database columns:\n\n```swift\nstruct Player: Codable {\n    var id: Int64\n    var name: String\n    var score: Int\n}\n\nextension Player: FetchableRecord, PersistableRecord {\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n```\n\nSee the [query interface](#the-query-interface) and [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices) for further information.\n\n\n## Record Comparison\n\n**Records that adopt the [EncodableRecord] protocol can compare against other records, or against previous versions of themselves.**\n\nThis helps avoiding costly UPDATE statements when a record has not been edited.\n\n- [The `updateChanges` Methods](#the-updatechanges-methods)\n- [The `databaseEquals` Method](#the-databaseequals-method)\n- [The `databaseChanges` and `hasDatabaseChanges` Methods](#the-databasechanges-and-hasdatabasechanges-methods)\n\n\n### The `updateChanges` Methods\n\nThe `updateChanges` methods perform a database update of the changed columns only (and does nothing if record has no change).\n\n- `updateChanges(_:from:)`\n\n    This method lets you compare two records:\n\n    ```swift\n    if let oldPlayer = try Player.fetchOne(db, id: 42) {\n        var newPlayer = oldPlayer\n        newPlayer.score = 100\n        if try newPlayer.updateChanges(db, from: oldPlayer) {\n            print(\"player was modified, and updated in the database\")\n        } else {\n            print(\"player was not modified, and database was not hit\")\n        }\n    }\n    ```\n\n- `updateChanges(_:modify:)`\n    \n    This method lets you update a record in place:\n    \n    ```swift\n    if var player = try Player.fetchOne(db, id: 42) {\n        let modified = try player.updateChanges(db) {\n            $0.score = 100\n        }\n        if modified {\n            print(\"player was modified, and updated in the database\")\n        } else {\n            print(\"player was not modified, and database was not hit\")\n        }\n    }\n    ```\n\n### The `databaseEquals` Method\n\nThis method returns whether two records have the same database representation:\n\n```swift\nlet oldPlayer: Player = ...\nvar newPlayer: Player = ...\nif newPlayer.databaseEquals(oldPlayer) == false {\n    try newPlayer.save(db)\n}\n```\n\n> **Note**: The comparison is performed on the database representation of records. As long as your record type adopts the EncodableRecord protocol, you don't need to care about Equatable.\n\n\n### The `databaseChanges` and `hasDatabaseChanges` Methods\n\n`databaseChanges(from:)` returns a dictionary of differences between two records:\n\n```swift\nlet oldPlayer = Player(id: 1, name: \"Arthur\", score: 100)\nlet newPlayer = Player(id: 1, name: \"Arthur\", score: 1000)\nfor (column, oldValue) in try newPlayer.databaseChanges(from: oldPlayer) {\n    print(\"\\(column) was \\(oldValue)\")\n}\n// prints \"score was 100\"\n```\n\nFor an efficient algorithm which synchronizes the content of a database table with a JSON payload, check [groue/SortedDifference](https://github.com/groue/SortedDifference).\n\n\n## Record Customization Options\n\nGRDB records come with many default behaviors, that are designed to fit most situations. Many of those defaults can be customized for your specific needs:\n\n- [Persistence Callbacks]: define what happens when you call a persistence method such as `player.insert(db)`\n- [Conflict Resolution]: Run `INSERT OR REPLACE` queries, and generally define what happens when a persistence method violates a unique index.\n- [Columns Selected by a Request]: define which columns are selected by requests such as `Player.fetchAll(db)`.\n- [Beyond FetchableRecord]: the FetchableRecord protocol is not the end of the story.\n\n[Codable Records] have a few extra options:\n\n- [JSON Columns]: control the format of JSON columns.\n- [Column Names Coding Strategies]: control how coding keys are turned into column names\n- [Date and UUID Coding Strategies]: control the format of Date and UUID properties in your Codable records.\n- [The userInfo Dictionary]: adapt your Codable implementation for the database.\n\n\n### Conflict Resolution\n\n**Insertions and updates can create conflicts**: for example, a query may attempt to insert a duplicate row that violates a unique index.\n\nThose conflicts normally end with an error. Yet SQLite let you alter the default behavior, and handle conflicts with specific policies. For example, the `INSERT OR REPLACE` statement handles conflicts with the \"replace\" policy which replaces the conflicting row instead of throwing an error.\n\nThe [five different policies](https://www.sqlite.org/lang_conflict.html) are: abort (the default), replace, rollback, fail, and ignore.\n\n**SQLite let you specify conflict policies at two different places:**\n\n- In the definition of the database table:\n    \n    ```swift\n    // CREATE TABLE player (\n    //     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    //     email TEXT UNIQUE ON CONFLICT REPLACE\n    // )\n    try db.create(table: \"player\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"email\", .text).unique(onConflict: .replace) // <--\n    }\n    \n    // Despite the unique index on email, both inserts succeed.\n    // The second insert replaces the first row:\n    try db.execute(sql: \"INSERT INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    try db.execute(sql: \"INSERT INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    ```\n    \n- In each modification query:\n    \n    ```swift\n    // CREATE TABLE player (\n    //     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    //     email TEXT UNIQUE\n    // )\n    try db.create(table: \"player\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"email\", .text).unique()\n    }\n    \n    // Again, despite the unique index on email, both inserts succeed.\n    try db.execute(sql: \"INSERT OR REPLACE INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    try db.execute(sql: \"INSERT OR REPLACE INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    ```\n\nWhen you want to handle conflicts at the query level, specify a custom `persistenceConflictPolicy` in your type that adopts the PersistableRecord protocol. It will alter the INSERT and UPDATE queries run by the `insert`, `update` and `save` [persistence methods]:\n\n```swift\nprotocol MutablePersistableRecord {\n    /// The policy that handles SQLite conflicts when records are\n    /// inserted or updated.\n    ///\n    /// This property is optional: its default value uses the ABORT\n    /// policy for both insertions and updates, so that GRDB generate\n    /// regular INSERT and UPDATE queries.\n    static var persistenceConflictPolicy: PersistenceConflictPolicy { get }\n}\n\nstruct Player : MutablePersistableRecord {\n    static let persistenceConflictPolicy = PersistenceConflictPolicy(\n        insert: .replace,\n        update: .replace)\n}\n\n// INSERT OR REPLACE INTO player (...) VALUES (...)\ntry player.insert(db)\n```\n\n> **Note**: If you specify the `ignore` policy for inserts, the [`didInsert` callback](#persistence-callbacks) will be called with some random id in case of failed insert. You can detect failed insertions with `insertAndFetch`:\n>     \n> ```swift\n> // How to detect failed `INSERT OR IGNORE`:\n> // INSERT OR IGNORE INTO player ... RETURNING *\n> do {\n>     let insertedPlayer = try player.insertAndFetch(db) {\n>     // Successful insertion\n> catch RecordError.recordNotFound {\n>     // Failed insertion due to IGNORE policy\n> }\n> ```\n>\n> **Note**: The `replace` policy may have to delete rows so that inserts and updates can succeed. Those deletions are not reported to [transaction observers](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactionobserver) (this might change in a future release of SQLite).\n\n### Beyond FetchableRecord\n\n**Some GRDB users eventually discover that the [FetchableRecord] protocol does not fit all situations.** Use cases that are not well handled by FetchableRecord include:\n\n- Your application needs polymorphic row decoding: it decodes some type or another, depending on the values contained in a database row.\n\n- Your application needs to decode rows with a context: each decoded value should be initialized with some extra value that does not come from the database.\n\nSince those use cases are not well handled by FetchableRecord, don't try to implement them on top of this protocol: you'll just fight the framework.\n\n\n## Examples of Record Definitions\n\nWe will show below how to declare a record type for the following database table:\n\n```swift\ntry dbQueue.write { db in\n    try db.create(table: \"place\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"title\", .text).notNull()\n        t.column(\"isFavorite\", .boolean).notNull().defaults(to: false)\n        t.column(\"longitude\", .double).notNull()\n        t.column(\"latitude\", .double).notNull()\n    }\n}\n```\n\nEach one of the three examples below is correct. You will pick one or the other depending on your personal preferences and the requirements of your application:\n\n<details>\n  <summary>Define a Codable struct, and adopt the record protocols you need</summary>\n\nThis is the shortest way to define a record type.\n\nSee the [Record Protocols Overview](#record-protocols-overview), and [Codable Records] for more information.\n\n```swift\nstruct Place: Codable {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    private var latitude: CLLocationDegrees\n    private var longitude: CLLocationDegrees\n    \n    var coordinate: CLLocationCoordinate2D {\n        get {\n            CLLocationCoordinate2D(\n                latitude: latitude,\n                longitude: longitude)\n        }\n        set {\n            latitude = newValue.latitude\n            longitude = newValue.longitude\n        }\n    }\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let title = Column(CodingKeys.title)\n        static let isFavorite = Column(CodingKeys.isFavorite)\n        static let latitude = Column(CodingKeys.latitude)\n        static let longitude = Column(CodingKeys.longitude)\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord { }\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n<details>\n  <summary>Define a plain struct, and adopt the record protocols you need</summary>\n\nSee the [Record Protocols Overview](#record-protocols-overview) for more information.\n    \n```swift\nstruct Place {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    var coordinate: CLLocationCoordinate2D\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let isFavorite = Column(\"isFavorite\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord {\n    /// Creates a record from a database row\n    init(row: Row) {\n        id = row[Columns.id]\n        title = row[Columns.title]\n        isFavorite = row[Columns.isFavorite]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[Columns.latitude],\n            longitude: row[Columns.longitude])\n    }\n}\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    /// The values persisted in the database\n    func encode(to container: inout PersistenceContainer) {\n        container[Columns.id] = id\n        container[Columns.title] = title\n        container[Columns.isFavorite] = isFavorite\n        container[Columns.latitude] = coordinate.latitude\n        container[Columns.longitude] = coordinate.longitude\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n<details>\n  <summary>Define a plain struct optimized for fetching performance</summary>\n\nThis struct derives its persistence methods from the standard Encodable protocol (see [Codable Records]), but performs optimized row decoding by accessing database columns with numeric indexes.\n\nSee the [Record Protocols Overview](#record-protocols-overview) for more information.\n    \n```swift\nstruct Place: Encodable {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    private var latitude: CLLocationDegrees\n    private var longitude: CLLocationDegrees\n    \n    var coordinate: CLLocationCoordinate2D {\n        get {\n            CLLocationCoordinate2D(\n                latitude: latitude,\n                longitude: longitude)\n        }\n        set {\n            latitude = newValue.latitude\n            longitude = newValue.longitude\n        }\n    }\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let title = Column(CodingKeys.title)\n        static let isFavorite = Column(CodingKeys.isFavorite)\n        static let latitude = Column(CodingKeys.latitude)\n        static let longitude = Column(CodingKeys.longitude)\n    }\n    \n    /// Arrange the selected columns and lock their order\n    static var databaseSelection: [any SQLSelectable] {\n        [\n            Columns.id,\n            Columns.title,\n            Columns.favorite,\n            Columns.latitude,\n            Columns.longitude,\n        ]\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord {\n    /// Creates a record from a database row\n    init(row: Row) {\n        // For high performance, use numeric indexes that match the\n        // order of Place.databaseSelection\n        id = row[0]\n        title = row[1]\n        isFavorite = row[2]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[3],\n            longitude: row[4])\n    }\n}\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n\nThe Query Interface\n===================\n\n**The query interface lets you write pure Swift instead of SQL:**\n\n```swift\ntry dbQueue.write { db in\n    // Update database schema\n    try db.create(table: \"player\") { t in ... }\n    \n    // Fetch records\n    let bestPlayers = try Player\n        .order(\\.score.desc)\n        .limit(10)\n        .fetchAll(db)\n    \n    // Count\n    let count = try Player\n        .filter { $0.score >= 1000 }\n        .fetchCount(db)\n    \n    // Batch update\n    try Player\n        .filter { $0.team == \"Reds\" }\n        .updateAll(db) { $0.score += 100 }\n    \n    // Batch delete\n    try Player\n        .filter { $0.score == 0 }\n        .deleteAll(db)\n}\n```\n\nYou need to open a [database connection] before you can query the database.\n\nPlease bear in mind that the query interface can not generate all possible SQL queries. You may also *prefer* writing SQL, and this is just OK. From little snippets to full queries, your SQL skills are welcome:\n\n```swift\ntry dbQueue.write { db in\n    // Update database schema (with SQL)\n    try db.execute(sql: \"CREATE TABLE player (...)\")\n    \n    // Fetch records (with SQL)\n    let bestPlayers = try Player.fetchAll(db, sql: \"\"\"\n        SELECT * FROM player ORDER BY score DESC LIMIT 10\n        \"\"\")\n    \n    // Count (with an SQL snippet)\n    let minScore = 1000\n    let count = try Player\n        .filter(sql: \"score >= ?\", arguments: [minScore])\n        .fetchCount(db)\n    \n    // Update (with SQL)\n    try db.execute(sql: \"UPDATE player SET score = score + 100 WHERE team = 'Reds'\")\n    \n    // Delete (with SQL)\n    try db.execute(sql: \"DELETE FROM player WHERE score = 0\")\n}\n```\n\nSo don't miss the [SQL API](#sqlite-api).\n\n> **Note**: the generated SQL may change between GRDB releases, without notice: don't have your application rely on any specific SQL output.\n\n- [The Database Schema](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema)\n- [Requests](#requests)\n- [Expressions](#expressions)\n    - [SQL Operators](#sql-operators)\n    - [SQL Functions](#sql-functions)\n- [Embedding SQL in Query Interface Requests]\n- [Fetching from Requests]\n- [Fetching by Key](#fetching-by-key)\n- [Testing for Record Existence](#testing-for-record-existence)\n- [Fetching Aggregated Values](#fetching-aggregated-values)\n- [Delete Requests](#delete-requests)\n- [Update Requests](#update-requests)\n- [Custom Requests](#custom-requests)\n- :blue_book: [Associations and Joins](Documentation/AssociationsBasics.md)\n- :blue_book: [Common Table Expressions]\n- :blue_book: [Query Interface Organization]\n\n## Requests\n\nğŸ“– [`QueryInterfaceRequest`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest), [`Table`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/table)\n\n**The query interface requests** let you fetch values from the database:\n\n```swift\nlet request = Player.filter { $0.email != nil }.order(\\.name)\nlet players = try request.fetchAll(db)  // [Player]\nlet count = try request.fetchCount(db)  // Int\n```\n\nQuery interface requests usually start from **a type** that adopts the `TableRecord` protocol:\n\n```swift\nstruct Player: TableRecord { ... }\n\n// The request for all players:\nlet request = Player.all()\nlet players = try request.fetchAll(db) // [Player]\n```\n\nWhen you can not use a record type, use `Table`:\n\n```swift\n// The request for all rows from the player table:\nlet table = Table(\"player\")\nlet request = table.all()\nlet rows = try request.fetchAll(db)    // [Row]\n\n// The request for all players from the player table:\nlet table = Table<Player>(\"player\")\nlet request = table.all()\nlet players = try request.fetchAll(db) // [Player]\n```\n\n> **Note**: all examples in the documentation below use a record type, but you can always substitute a `Table` instead.\n\nNext, declare the table **columns** that you want to use for filtering, or sorting, in a nested type named `Columns`:\n\n```swift\nextension Player {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let name = Column(\"name\")\n    }\n}\n```\n\nWhen `Player` is `Codable`, you'll prefer defining columns from coding keys:\n\n```swift\nextension Player {\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n    }\n}\n```\n\nYou can now build requests with the following methods: `all`, `none`, `select`, `distinct`, `filter`, `matching`, `group`, `having`, `order`, `reversed`, `limit`, `joining`, `including`, `with`. All those methods return another request, which you can further refine by applying another method: `Player.select(...).filter(...).order(...)`.\n\n- [`all()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord/all()), [`none()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord/none()): the requests for all rows, or no row.\n\n    ```swift\n    // SELECT * FROM player\n    Player.all()\n    ```\n    \n    By default, all columns are selected. See [Columns Selected by a Request].\n\n- [`select(...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/selectionrequest/select(_:)-ruzy) and [`select(..., as:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/select(_:as:)-58954) define the selected columns. See [Columns Selected by a Request].\n    \n    ```swift\n    // SELECT name FROM player\n    Player.select(\\.name, as: String.self)\n    ```\n\n- [`selectID()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/selectID()) is available on [Identifiable Records]. It supports all tables that have a single-column primary key:\n\n    ```swift\n    // SELECT id FROM player\n    Player.selectID()\n    \n    // SELECT id FROM player WHERE name IS NOT NULL\n    Player.filter { $0.name != nil }.selectID()\n    ```\n\n- [`annotated(with: expression...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/selectionrequest/annotated(with:)-1satx) extends the selection.\n\n    ```swift\n    // SELECT *, (score + bonus) AS total FROM player\n    Player.annotated { ($0.score + $0.bonus).forKey(\"total\") }\n    ```\n\n- [`annotated(with: aggregate)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/annotated(with:)-74xfs) extends the selection with [association aggregates](Documentation/AssociationsBasics.md#association-aggregates).\n    \n    ```swift\n    // SELECT team.*, COUNT(DISTINCT player.id) AS playerCount\n    // FROM team\n    // LEFT JOIN player ON player.teamId = team.id\n    // GROUP BY team.id\n    Team.annotated(with: Team.players.count)\n    ```\n\n- [`annotated(withRequired: association)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/annotated(withrequired:)) and [`annotated(withOptional: association)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/annotated(withoptional:)) extends the selection with [Associations].\n    \n    ```swift\n    // SELECT player.*, team.color\n    // FROM player\n    // JOIN team ON team.id = player.teamId\n    Player.annotated(withRequired: Player.team.select(\\.color))\n    ```\n\n- [`distinct()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/distinct()) performs uniquing.\n    \n    ```swift\n    // SELECT DISTINCT name FROM player\n    Player.select(\\.name, as: String.self).distinct()\n    ```\n\n- [`filter(expression)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/filteredrequest/filter(_:)-6xr3d) applies conditions.\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (1, 2, 3)\n    Player.filter { [1,2,3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE (name IS NOT NULL) AND (height > 1.75)\n    Player.filter { $0.name != nil && $0.height > 1.75 }\n    ```\n\n- [`filter(id:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(id:)) and [`filter(ids:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(ids:)) are type-safe methods available on [Identifiable Records]:\n    \n    ```swift\n    // SELECT * FROM player WHERE id = 1\n    Player.filter(id: 1)\n    \n    // SELECT * FROM country WHERE isoCode IN ('FR', 'US')\n    Country.filter(ids: [\"FR\", \"US\"])\n    ```\n    \n- [`filter(key:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(key:)-1p9sq) and [`filter(keys:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(keys:)-6ggt1) apply conditions on primary and unique keys:\n    \n    ```swift\n    // SELECT * FROM player WHERE id = 1\n    Player.filter(key: 1)\n    \n    // SELECT * FROM country WHERE isoCode IN ('FR', 'US')\n    Country.filter(keys: [\"FR\", \"US\"])\n    \n    // SELECT * FROM citizenship WHERE citizenId = 1 AND countryCode = 'FR'\n    Citizenship.filter(key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n    \n    // SELECT * FROM player WHERE email = 'arthur@example.com'\n    Player.filter(key: [\"email\": \"arthur@example.com\"])\n    ```\n\n- `matching(pattern)` ([FTS3](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/matching(_:)-3s3zr), [FTS5](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/matching(_:)-7c1e8)) performs [full-text search](Documentation/FullTextSearch.md).\n    \n    ```swift\n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    let pattern = FTS3Pattern(matchingAllTokensIn: \"SQLite database\")\n    Document.matching(pattern)\n    ```\n    \n    When the pattern is nil, no row will match.\n\n- [`group(expression, ...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/aggregatingrequest/group(_:)-2g7br) groups rows.\n    \n    ```swift\n    // SELECT name, MAX(score) FROM player GROUP BY name\n    Player\n        .select { [$0.name, max($0.score)] }\n        .group(\\.name)\n    ```\n\n- [`having(expression)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/aggregatingrequest/having(_:)-2oggh) applies conditions on grouped rows.\n    \n    ```swift\n    // SELECT team, MAX(score) FROM player GROUP BY team HAVING MIN(score) >= 1000\n    Player\n        .select { [$0.team, max($0.score)] }\n        .group(\\.team)\n        .having { min($0.score) >= 1000 }\n    ```\n\n- [`having(aggregate)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/having(_:)) applies conditions on grouped rows, according to an [association aggregate](Documentation/AssociationsBasics.md#association-aggregates).\n    \n    ```swift\n    // SELECT team.*\n    // FROM team\n    // LEFT JOIN player ON player.teamId = team.id\n    // GROUP BY team.id\n    // HAVING COUNT(DISTINCT player.id) >= 5\n    Team.having(Team.players.count >= 5)\n    ```\n\n- [`order(ordering, ...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/orderedrequest/order(_:)-9d0hr) sorts.\n    \n    ```swift\n    // SELECT * FROM player ORDER BY name\n    Player.order(\\.name)\n    \n    // SELECT * FROM player ORDER BY score DESC\n    Player.order(\\.score.desc)\n    \n    // SELECT * FROM player ORDER BY score DESC, name\n    Player.order { [$0.score.desc, $0.name] }\n    ```\n    \n    SQLite considers NULL values to be smaller than any other values for sorting purposes. Hence, NULLs naturally appear at the beginning of an ascending ordering and at the end of a descending ordering. With a [custom SQLite build], this can be changed using `.ascNullsLast` and `.descNullsFirst`:\n    \n    ```swift\n    // SELECT * FROM player ORDER BY score ASC NULLS LAST\n    Player.order(\\.name.ascNullsLast)\n    ```\n    \n    Each `order` call clears any previous ordering:\n    \n    ```swift\n    // SELECT * FROM player ORDER BY name\n    Player.order(\\.score).order(\\.name)\n    ```\n\n- [`reversed()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/orderedrequest/reversed()) reverses the eventual orderings.\n    \n    ```swift\n    // SELECT * FROM player ORDER BY score ASC, name DESC\n    Player.order { [$0.score.desc, $0.name] }.reversed()\n    ```\n    \n    If no ordering was already specified, this method has no effect:\n    \n    ```swift\n    // SELECT * FROM player\n    Player.all().reversed()\n    ```\n\n- [`limit(limit, offset: offset)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/limit(_:offset:)) limits and pages results.\n    \n    ```swift\n    // SELECT * FROM player LIMIT 5\n    Player.limit(5)\n    \n    // SELECT * FROM player LIMIT 5 OFFSET 10\n    Player.limit(5, offset: 10)\n    ```\n\n- [`joining(required:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/joining(required:)), [`joining(optional:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/joining(optional:)), [`including(required:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(required:)), [`including(optional:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(optional:)), and [`including(all:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(all:)) fetch and join records through [Associations].\n    \n    ```swift\n    // SELECT player.*, team.*\n    // FROM player\n    // JOIN team ON team.id = player.teamId\n    Player.including(required: Player.team)\n    ```\n\n- [`with(cte)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/with(_:)) embeds a [common table expression]:\n    \n    ```swift\n    // WITH ... SELECT * FROM player\n    let cte = CommonTableExpression(...)\n    Player.with(cte)\n    ```\n\n- Other requests that involve the primary key:\n    \n    - [`selectPrimaryKey(as:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/selectprimarykey(as:)) selects the primary key.\n    \n        ```swift\n        // SELECT id FROM player\n        Player.selectPrimaryKey(as: Int64.self)    // QueryInterfaceRequest<Int64>\n        \n        // SELECT code FROM country\n        Country.selectPrimaryKey(as: String.self)  // QueryInterfaceRequest<String>\n        \n        // SELECT citizenId, countryCode FROM citizenship\n        Citizenship.selectPrimaryKey(as: Row.self) // QueryInterfaceRequest<Row>\n        ```\n        \n    - [`orderByPrimaryKey()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/orderbyprimarykey()) sorts by primary key.\n        \n        ```swift\n        // SELECT * FROM player ORDER BY id\n        Player.orderByPrimaryKey()\n        \n        // SELECT * FROM country ORDER BY code\n        Country.orderByPrimaryKey()\n        \n        // SELECT * FROM citizenship ORDER BY citizenId, countryCode\n        Citizenship.orderByPrimaryKey()\n        ```\n    \n    - [`groupByPrimaryKey()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/groupbyprimarykey()) groups rows by primary key.\n\n\nYou can refine requests by chaining those methods:\n\n```swift\n// SELECT * FROM player WHERE (email IS NOT NULL) ORDER BY name\nPlayer.order(\\.name).filter { $0.email != nil }\n```\n\nThe `select`, `order`, `group`, and `limit` methods ignore and replace previously applied selection, orderings, grouping, and limits. On the opposite, `filter`, `matching`, and `having` methods extend the query:\n\n```swift\nPlayer                          // SELECT * FROM player\n    .filter { $0.name != nil }  // WHERE (name IS NOT NULL)\n    .filter { $0.email != nil } //        AND (email IS NOT NULL)\n    .order(\\.name)              // - ignored -\n    .reversed()                 // - ignored -\n    .order(\\.score)             // ORDER BY score\n    .limit(20, offset: 40)      // - ignored -\n    .limit(10)                  // LIMIT 10\n```\n\n\nRaw SQL snippets are also accepted, with eventual [arguments](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments):\n\n```swift\n// SELECT DATE(creationDate), COUNT(*) FROM player WHERE name = 'Arthur' GROUP BY date(creationDate)\nPlayer\n    .select(sql: \"DATE(creationDate), COUNT(*)\")\n    .filter(sql: \"name = ?\", arguments: [\"Arthur\"])\n    .group(sql: \"DATE(creationDate)\")\n```\n\n\n### Columns Selected by a Request\n\nBy default, query interface requests select all columns:\n\n```swift\n// SELECT * FROM player\nstruct Player: TableRecord { ... }\nlet request = Player.all()\n\n// SELECT * FROM player\nlet table = Table(\"player\")\nlet request = table.all()\n```\n\n**The selection can be changed for each individual requests, or in the case of record-based requests, for all requests built from this record type.**\n\nThe `select(...)` and `select(..., as:)` methods change the selection of a single request (see [Fetching from Requests] for detailed information):\n\n```swift\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\nlet request = Player.select({ max($0.score) }, as: Int.self)\nlet maxScore = try request.fetchOne(db)      // Int?\n```\n\nThe default selection for a record type is controlled by the `databaseSelection` property. For example:\n\n```swift\n// Select a limited set of columns\nstruct RestrictedPlayer: TableRecord {\n    static let databaseTableName = \"player\"\n    \n    enum Columns {\n        static let id = Column(\"id\")\n        static let name = Column(\"name\")\n    }\n    \n    static var databaseSelection: [any SQLSelectable] {\n        [Columns.id, Columns.name]\n    }\n}\n\n// SELECT id, name FROM player\nlet request = RestrictedPlayer.all()\n```\n\n```swift\n// Select all but a few columns\nstruct Player : TableRecord {\n    static var databaseSelection: [any SQLSelectable] { \n        [.allColumns(excluding: [\"generatedColumn\"])]\n    }\n}\n\n// SELECT id, name FROM player\nlet request = RestrictedPlayer.all()\n```\n\n```swift\n// Select all columns and more\nstruct ExtendedPlayer : TableRecord {\n    static let databaseTableName = \"player\"\n    static var databaseSelection: [any SQLSelectable] {\n        [.allColumns, .rowID]\n    }\n}\n\n// SELECT *, rowid FROM player\nlet request = ExtendedPlayer.all()\n```\n\n> **Note**: make sure the `databaseSelection` property is explicitly declared as `[any SQLSelectable]`. If it is not, the Swift compiler may silently miss the protocol requirement, resulting in sticky `SELECT *` requests. To verify your setup, see the [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql) FAQ.\n\n\n## Expressions\n\nFeed [requests](#requests) with SQL expressions built from your Swift code:\n\n\n### SQL Operators\n\nğŸ“– [`SQLSpecificExpressible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlspecificexpressible)\n\nGRDB comes with a Swift version of many SQLite [built-in operators](https://sqlite.org/lang_expr.html#operators), listed below. But not all: see [Embedding SQL in Query Interface Requests] for a way to add support for missing SQL operators.\n\n- `=`, `<>`, `<`, `<=`, `>`, `>=`, `IS`, `IS NOT`\n    \n    Comparison operators are based on the Swift operators `==`, `!=`, `===`, `!==`, `<`, `<=`, `>`, `>=`:\n    \n    ```swift\n    // SELECT * FROM player WHERE (name = 'Arthur')\n    Player.filter { $0.name == \"Arthur\" }\n    \n    // SELECT * FROM player WHERE (name IS NULL)\n    Player.filter { $0.name == nil }\n    \n    // SELECT * FROM player WHERE (score IS 1000)\n    Player.filter { $0.score === 1000 }\n    \n    // SELECT * FROM rectangle WHERE width < height\n    Rectangle.filter { $0.width < $0.height }\n    ```\n    \n    Subqueries are supported:\n    \n    ```swift\n    // SELECT * FROM player WHERE score = (SELECT max(score) FROM player)\n    let maximumScore = Player.select { max($0.score) }\n    Player.filter { $0.score == maximumScore }\n    \n    // SELECT * FROM player WHERE score = (SELECT max(score) FROM player)\n    let maximumScore = SQLRequest(\"SELECT max(score) FROM player\")\n    Player.filter { $0.score == maximumScore }\n    ```\n    \n    > **Note**: SQLite string comparison, by default, is case-sensitive and not Unicode-aware. See [string comparison](#string-comparison) if you need more control.\n\n- `*`, `/`, `+`, `-`\n    \n    SQLite arithmetic operators are derived from their Swift equivalent:\n    \n    ```swift\n    // SELECT ((temperature * 1.8) + 32) AS fahrenheit FROM planet\n    Planet.select { ($0.temperature * 1.8 + 32).forKey(\"fahrenheit\") }\n    ```\n    \n    > **Note**: an expression like `nameColumn + \"rrr\"` will be interpreted by SQLite as a numerical addition (with funny results), not as a string concatenation. See the `concat` operator below.\n    \n    When you want to join a sequence of expressions with the `+` or `*` operator, use `joined(operator:)`:\n    \n    ```swift\n    // SELECT score + bonus + 1000 FROM player\n    Player.select {\n        [$0.score, $0.bonus, 1000.databaseValue].joined(operator: .add)\n    }\n    ```\n    \n    Note in the example above how you concatenate raw values: `1000.databaseValue`. A plain `1000` would not compile.\n    \n    When the sequence is empty, `joined(operator: .add)` returns 0, and `joined(operator: .multiply)` returns 1.\n\n- `&`, `|`, `~`, `<<`, `>>`\n    \n    Bitwise operations (bitwise and, or, not, left shift, right shift) are derived from their Swift equivalent:\n    \n    ```swift\n    // SELECT mask & 2 AS isRocky FROM planet\n    Planet.select { ($0.mask & 2).forKey(\"isRocky\") }\n    ```\n\n- `||`\n    \n    Concatenate several strings:\n    \n    ```swift\n    // SELECT firstName || ' ' || lastName FROM player\n    Player.select {\n        [$0.firstName, \" \".databaseValue, $0.lastName].joined(operator: .concat)\n    }\n    ```\n    \n    Note in the example above how you concatenate raw strings: `\" \".databaseValue`. A plain `\" \"` would not compile.\n    \n    When the sequence is empty, `joined(operator: .concat)` returns the empty string.\n\n- `AND`, `OR`, `NOT`\n    \n    The SQL logical operators are derived from the Swift `&&`, `||` and `!`:\n    \n    ```swift\n    // SELECT * FROM player WHERE ((NOT isVerified) OR (score < 1000))\n    Player.filter { !$0.isVerified || $0.score < 1000 }\n    ```\n    \n    When you want to join a sequence of expressions with the `AND` or `OR` operator, use `joined(operator:)`:\n    \n    ```swift\n    // SELECT * FROM player WHERE (isVerified AND (score >= 1000) AND (name IS NOT NULL))\n    Player.filter {\n        [$0.isVerified, $0.score >= 1000, $0.name != nil].joined(operator: .and)\n    }\n    ```\n    \n    When the sequence is empty, `joined(operator: .and)` returns true, and `joined(operator: .or)` returns false:\n\n- `BETWEEN`, `IN`, `NOT IN`\n    \n    To check inclusion in a Swift sequence (array, set, rangeâ€¦), call the `contains` method:\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (1, 2, 3)\n    Player.filter { [1, 2, 3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE id NOT IN (1, 2, 3)\n    Player.filter { ![1, 2, 3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE score BETWEEN 0 AND 1000\n    Player.filter { (0...1000).contains($0.score) }\n    \n    // SELECT * FROM player WHERE (score >= 0) AND (score < 1000)\n    Player.filter { (0..<1000).contains($0.score) }\n    \n    // SELECT * FROM player WHERE initial BETWEEN 'A' AND 'N'\n    Player.filter { (\"A\"...\"N\").contains($0.initial) }\n    \n    // SELECT * FROM player WHERE (initial >= 'A') AND (initial < 'N')\n    Player.filter { (\"A\"..<\"N\").contains($0.initial) }\n    ```\n    \n    To check inclusion inside a subquery, call the `contains` method as well:\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (SELECT playerId FROM playerSelection)\n    let selectedPlayerIds = PlayerSelection.select(\\.playerId)\n    Player.filter { selectedPlayerIds.contains($0.id) }\n    \n    // SELECT * FROM player WHERE id IN (SELECT playerId FROM playerSelection)\n    let selectedPlayerIds = SQLRequest(\"SELECT playerId FROM playerSelection\")\n    Player.filter { selectedPlayerIds.contains($0.id) }\n    ```\n    \n    To check inclusion inside a [common table expression], call the `contains` method as well:\n    \n    ```swift\n    // WITH selectedName AS (...)\n    // SELECT * FROM player WHERE name IN selectedName\n    let cte = CommonTableExpression(named: \"selectedName\", ...)\n    Player\n        .with(cte)\n        .filter { cte.contains($0.name) }\n    ```\n    \n    > **Note**: SQLite string comparison, by default, is case-sensitive and not Unicode-aware. See [string comparison](#string-comparison) if you need more control.\n\n- `EXISTS`, `NOT EXISTS`\n    \n    To check if a subquery would return rows, call the `exists` method:\n    \n    ```swift\n    // Teams that have at least one other player\n    //\n    //  SELECT * FROM team\n    //  WHERE EXISTS (SELECT * FROM player WHERE teamId = team.id)\n    let teamAlias = TableAlias<Team>()\n    let player = Player.filter { $0.teamId == teamAlias.id }\n    let teams = Team.aliased(teamAlias).filter(player.exists())\n    \n    // Teams that have no player\n    //\n    //  SELECT * FROM team\n    //  WHERE NOT EXISTS (SELECT * FROM player WHERE teamId = team.id)\n    let teams = Team.aliased(teamAlias).filter(!player.exists())\n    ```\n    \n    In the above example, you use a `TableAlias` in order to let a subquery refer to a column from another table.\n    \n    In the next example, which involves the same table twice, the table alias requires an explicit disambiguation with `TableAlias(name:)`:\n    \n    ```swift    \n    // Players who coach at least one other player\n    //\n    //  SELECT coach.* FROM player coach\n    //  WHERE EXISTS (SELECT * FROM player WHERE coachId = coach.id)\n    let coachAlias = TableAlias<Player>(name: \"coach\")\n    let coachedPlayer = Player.filter { $0.coachId == coachAlias.id }\n    let coaches = Player.aliased(coachAlias).filter(coachedPlayer.exists())\n    ```\n    \n    Finally, subqueries can also be expressed as SQL, with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT coach.* FROM player coach\n    // WHERE EXISTS (SELECT * FROM player WHERE coachId = coach.id)\n    let coachedPlayer = SQLRequest(\"SELECT * FROM player WHERE coachId = \\(coachAlias.id)\")\n    let coaches = Player.aliased(coachAlias).filter(coachedPlayer.exists())\n    ```\n    \n- `LIKE`\n    \n    The SQLite LIKE operator is available as the `like` method:\n    \n    ```swift\n    // SELECT * FROM player WHERE (email LIKE '%@example.com')\n    Player.filter { $0.email.like(\"%@example.com\") }\n    \n    // SELECT * FROM book WHERE (title LIKE '%10\\%%' ESCAPE '\\')\n    Player.filter { $0.email.like(\"%10\\\\%%\", escape: \"\\\\\") }\n    ```\n    \n    > **Note**: the SQLite LIKE operator is case-insensitive but not Unicode-aware. For example, the expression `'a' LIKE 'A'` is true but `'Ã¦' LIKE 'Ã†'` is false.\n\n- `MATCH`\n    \n    The full-text MATCH operator is available through [FTS3Pattern](Documentation/FullTextSearch.md#fts3pattern) (for FTS3 and FTS4 tables) and [FTS5Pattern](Documentation/FullTextSearch.md#fts5pattern) (for FTS5):\n    \n    FTS3 and FTS4:\n    \n    ```swift\n    let pattern = FTS3Pattern(matchingAllTokensIn: \"SQLite database\")\n    \n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    Document.matching(pattern)\n    \n    // SELECT * FROM document WHERE content MATCH 'sqlite database'\n    Document.filter { $0.content.match(pattern) }\n    ```\n    \n    FTS5:\n    \n    ```swift\n    let pattern = FTS5Pattern(matchingAllTokensIn: \"SQLite database\")\n    \n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    Document.matching(pattern)\n    ```\n- `AS`\n    \n    To give an alias to an expression, use the `forKey` method:\n    \n    ```swift\n    // SELECT (score + bonus) AS total\n    // FROM player\n    Player.select { ($0.score + $0.bonus).forKey(\"total\") }\n    ```\n    \n    If you need to refer to this aliased column in another place of the request, use a detached column:\n    \n    ```swift\n    // SELECT (score + bonus) AS total\n    // FROM player \n    // ORDER BY total\n    Player\n        .select { ($0.score + $0.bonus).forKey(\"total\") }\n        .order(Column(\"total\").detached)\n    ```\n    \n    The detached column `Column(\"total\").detached` is not considered as a part of the \"player\" table, so it is always rendered as `total` in the generated SQL, even when the request involves other tables via an [association](Documentation/AssociationsBasics.md) or a [common table expression].\n\n\n### SQL Functions\n\nğŸ“– [`SQLSpecificExpressible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlspecificexpressible)\n\nGRDB comes with a Swift version of many SQLite [built-in functions](https://sqlite.org/lang_corefunc.html), listed below. But not all: see [Embedding SQL in Query Interface Requests] for a way to add support for missing SQL functions.\n\n- `ABS`, `AVG`, `COALESCE`, `COUNT`, `DATETIME`, `JULIANDAY`, `LENGTH`, `MAX`, `MIN`, `SUM`, `TOTAL`:\n    \n    Those are based on the `abs`, `average`, `coalesce`, `count`, `dateTime`, `julianDay`, `length`, `max`, `min`, `sum`, and `total` Swift functions:\n    \n    ```swift\n    // SELECT MIN(score), MAX(score) FROM player\n    Player.select { [min($0.score), max($0.score)] }\n    \n    // SELECT COUNT(name) FROM player\n    Player.select { count($0.name) }\n    \n    // SELECT COUNT(DISTINCT name) FROM player\n    Player.select { count(distinct: $0.name) }\n    \n    // SELECT JULIANDAY(date, 'start of year') FROM game\n    Game.select { julianDay($0.date, .startOfYear) }\n    ```\n    \n    For more information about the functions `dateTime` and `julianDay`, see [Date And Time Functions](https://www.sqlite.org/lang_datefunc.html).\n\n- `CAST`\n\n    Use the `cast` Swift function:\n    \n    ```swift\n    // SELECT (CAST(wins AS REAL) / games) AS successRate FROM player\n    Player.select { (cast($0.wins, as: .real) / $0.games).forKey(\"successRate\") }\n    ```\n    \n    See [CAST expressions](https://www.sqlite.org/lang_expr.html#castexpr) for more information about SQLite conversions.\n\n- `IFNULL`\n    \n    Use the Swift `??` operator:\n    \n    ```swift\n    // SELECT IFNULL(name, 'Anonymous') FROM player\n    Player.select { $0.name ?? \"Anonymous\" }\n    \n    // SELECT IFNULL(name, email) FROM player\n    Player.select { $0.name ?? $0.email }\n    ```\n\n- `LOWER`, `UPPER`\n    \n    The query interface does not give access to those SQLite functions. Nothing against them, but they are not unicode aware.\n    \n    Instead, GRDB extends SQLite with SQL functions that call the Swift built-in string functions `capitalized`, `lowercased`, `uppercased`, `localizedCapitalized`, `localizedLowercased` and `localizedUppercased`:\n    \n    ```swift\n    Player.select { $0.name.uppercased() }\n    ```\n    \n    > **Note**: When *comparing* strings, you'd rather use a [collation](#string-comparison):\n    >\n    > ```swift\n    > let name: String = ...\n    >\n    > // Not recommended\n    > Player.filter { $0.name.uppercased() == name.uppercased() }\n    >\n    > // Better\n    > Player.filter { $0.name.collating(.caseInsensitiveCompare) == name }\n    > ```\n\n- Custom SQL functions and aggregates\n    \n    You can apply your own [custom SQL functions and aggregates](#custom-functions-):\n    \n    ```swift\n    let myFunction = DatabaseFunction(\"myFunction\", ...)\n    \n    // SELECT myFunction(name) FROM player\n    Player.select { myFunction($0.name) }\n    ```\n\n## Embedding SQL in Query Interface Requests\n\nYou will sometimes want to extend your query interface requests with SQL snippets. This can happen because GRDB does not provide a Swift interface for some SQL function or operator, or because you want to use an SQLite construct that GRDB does not support.\n\nSupport for extensibility is large, but not unlimited. All the SQL queries built by the query interface request have the shape below. _If you need something else, you'll have to use [raw SQL requests](#sqlite-api)._\n\n```sql\nWITH ...     -- 1\nSELECT ...   -- 2\nFROM ...     -- 3\nJOIN ...     -- 4\nWHERE ...    -- 5\nGROUP BY ... -- 6\nHAVING ...   -- 7\nORDER BY ... -- 8\nLIMIT ...    -- 9\n```\n\n1. `WITH ...`: see [Common Table Expressions].\n\n2. `SELECT ...`\n\n    The selection can be provided as raw SQL:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let request = Player.select(sql: \"IFNULL(name, 'O''Brien'), score\")\n    \n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select(sql: \"IFNULL(name, ?), score\", arguments: [suffix])\n    ```\n\n    The selection can be provided with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select(literal: \"IFNULL(name, \\(defaultName)), score\")\n    ```\n    \n    The selection can be provided with a mix of Swift and [SQL Interpolation]:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien') AS displayName, score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select {\n        let displayName: SQL = \"IFNULL(\\($0.name), \\(defaultName)) AS displayName\"\n        return [displayName, $0.score]\n    }\n    ```\n    \n    When the custom SQL snippet should behave as a full-fledged expression, with support for the `+` Swift operator, the `forKey` aliasing method, and all other [SQL Operators](#sql-operators), build an _expression literal_ with the `SQL.sqlExpression` method:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien') AS displayName, score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select {\n        let displayName = SQL(\"IFNULL(\\($0.name), \\(defaultName))\").sqlExpression\n        return [displayName.forKey(\"displayName\"), $0.score]\n    }\n    ```\n    \n    Such expression literals allow you to build a reusable support library of SQL functions or operators that are missing from the query interface. For example, you can define a Swift `date` function:\n    \n    ```swift\n    func date(_ value: some SQLSpecificExpressible) -> SQLExpression {\n        SQL(\"DATE(\\(value))\").sqlExpression\n    }\n    \n    // SELECT * FROM \"player\" WHERE DATE(\"createdAt\") = '2020-01-23'\n    let request = Player.filter { date($0.createdAt) == \"2020-01-23\" }\n    ```\n    \n    See the [Query Interface Organization] for more information about `SQLSpecificExpressible` and `SQLExpression`.\n    \n3. `FROM ...`: only one table is supported here. You can not customize this SQL part.\n\n4. `JOIN ...`: joins are fully controlled by [Associations]. You can not customize this SQL part.\n\n5. `WHERE ...`\n    \n    The WHERE clause can be provided as raw SQL:\n    \n    ```swift\n    // SELECT * FROM player WHERE score >= 1000\n    let request = Player.filter(sql: \"score >= 1000\")\n    \n    // SELECT * FROM player WHERE score >= 1000\n    let minScore = 1000\n    let request = Player.filter(sql: \"score >= ?\", arguments: [minScore])\n    ```\n\n    The WHERE clause can be provided with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT * FROM player WHERE score >= 1000\n    let minScore = 1000\n    let request = Player.filter(literal: \"score >= \\(minScore)\")\n    ```\n    \n    The WHERE clause can be provided with a mix of Swift and [SQL Interpolation]:\n    \n    ```swift\n    // SELECT * FROM player WHERE (score >= 1000) AND (team = 'red')\n    let minScore = 1000\n    let request = Player.filter { \n        let scoreCondition: SQL = \"\\($0.score) >= \\(minScore)\"\n        return scoreCondition && $0.team == \"red\"\n    }\n    ```\n    \n    See `SELECT ...` above for more SQL Interpolation examples.\n    \n6. `GROUP BY ...`\n\n    The GROUP BY clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n7. `HAVING ...`\n\n    The HAVING clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n8. `ORDER BY ...`\n\n    The ORDER BY clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n    In order to support the `desc` and `asc` query interface operators, and the `reversed()` query interface method, you must provide your orderings as _expression literals_ with the `SQL.sqlExpression` method:\n    \n    ```swift\n    // SELECT * FROM \"player\" \n    // ORDER BY (score + bonus) ASC, name DESC\n    let request = Player\n        .order {\n            let total = SQL(\"(\\($0.score) + \\($0.bonus))\").sqlExpression\n            return [total.desc, $0.name]\n        }\n        .reversed()\n    ```\n    \n9. `LIMIT ...`: use the `limit(_:offset:)` method. You can not customize this SQL part.\n\n\n## Fetching from Requests\n\nOnce you have a request, you can fetch the records at the origin of the request:\n\n```swift\n// Some request based on `Player`\nlet request = Player.filter { ... }... // QueryInterfaceRequest<Player>\n\n// Fetch players:\ntry request.fetchCursor(db) // A Cursor of Player\ntry request.fetchAll(db)    // [Player]\ntry request.fetchSet(db)    // Set<Player>\ntry request.fetchOne(db)    // Player?\n```\n\nFor example:\n\n```swift\nlet allPlayers = try Player.fetchAll(db)                            // [Player]\nlet arthur = try Player.filter { $0.name == \"Arthur\" }.fetchOne(db) // Player?\n```\n\nSee [fetching methods](#fetching-methods) for information about the `fetchCursor`, `fetchAll`, `fetchSet` and `fetchOne` methods.\n\n**You sometimes want to fetch other values**.\n\nThe simplest way is to use the request as an argument to a fetching method of the desired type:\n\n```swift\n// Fetch an Int\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\n// Fetch a Row\nlet request = Player.select { [min($0.score), max($0.score)] }\nlet row = try Row.fetchOne(db, request)!     // Row\nlet minScore = row[0] as Int?\nlet maxScore = row[1] as Int?\n```\n\nYou can also change the request so that it knows the type it has to fetch:\n\n- With `asRequest(of:)`, useful when you use [Associations]:\n    \n    ```swift\n    struct BookInfo: FetchableRecord, Decodable {\n        var book: Book\n        var author: Author\n    }\n    \n    // A request of BookInfo\n    let request = Book\n        .including(required: Book.author)\n        .asRequest(of: BookInfo.self)\n    \n    let bookInfos = try dbQueue.read { db in\n        try request.fetchAll(db) // [BookInfo]\n    }\n    ```\n    \n- With `select(..., as:)`, which is handy when you change the selection:\n    \n    ```swift\n    // A request of Int\n    let request = Player.select({ max($0.score) }, as: Int.self)\n    \n    let maxScore = try dbQueue.read { db in\n        try request.fetchOne(db) // Int?\n    }\n    ```\n\n\n## Fetching by Key\n\n**Fetching records according to their primary key** is a common task.\n\n[Identifiable Records] can use the type-safe methods `find(_:id:)`, `fetchOne(_:id:)`, `fetchAll(_:ids:)` and `fetchSet(_:ids:)`:\n\n```swift\ntry Player.find(db, id: 1)                   // Player\ntry Player.fetchOne(db, id: 1)               // Player?\ntry Country.fetchAll(db, ids: [\"FR\", \"US\"])  // [Countries]\n```\n\nAll record types can use `find(_:key:)`, `fetchOne(_:key:)`, `fetchAll(_:keys:)` and `fetchSet(_:keys:)` that apply conditions on primary and unique keys:\n\n```swift\ntry Player.find(db, key: 1)                  // Player\ntry Player.fetchOne(db, key: 1)              // Player?\ntry Country.fetchAll(db, keys: [\"FR\", \"US\"]) // [Country]\ntry Player.fetchOne(db, key: [\"email\": \"arthur@example.com\"])            // Player?\ntry Citizenship.fetchOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"]) // Citizenship?\n```\n\nWhen the table has no explicit primary key, GRDB uses the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html):\n\n```swift\n// SELECT * FROM document WHERE rowid = 1\ntry Document.fetchOne(db, key: 1)            // Document?\n```\n\n**When you want to build a request and plan to fetch from it later**, use a `filter` method:\n\n```swift\nlet request = Player.filter(id: 1)\nlet request = Country.filter(ids: [\"FR\", \"US\"])\nlet request = Player.filter(key: [\"email\": \"arthur@example.com\"])\nlet request = Citizenship.filter(key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\n\n## Testing for Record Existence\n\n**You can check if a request has matching rows in the database.**\n\n```swift\n// Some request based on `Player`\nlet request = Player.filter { ... }...\n\n// Check for player existence:\nlet noSuchPlayer = try request.isEmpty(db) // Bool\n```\n\nYou should check for emptiness instead of counting:\n\n```swift\n// Correct\nlet noSuchPlayer = try request.fetchCount(db) == 0\n// Even better\nlet noSuchPlayer = try request.isEmpty(db)\n```\n\n**You can also check if a given primary or unique key exists in the database.**\n\n[Identifiable Records] can use the type-safe method `exists(_:id:)`:\n\n```swift\ntry Player.exists(db, id: 1)\ntry Country.exists(db, id: \"FR\")\n```\n\nAll record types can use `exists(_:key:)` that can check primary and unique keys:\n\n```swift\ntry Player.exists(db, key: 1)\ntry Country.exists(db, key: \"FR\")\ntry Player.exists(db, key: [\"email\": \"arthur@example.com\"])\ntry Citizenship.exists(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\nYou should check for key existence instead of fetching a record and checking for nil:\n\n```swift\n// Correct\nlet playerExists = try Player.fetchOne(db, id: 1) != nil\n// Even better\nlet playerExists = try Player.exists(db, id: 1)\n```\n\n\n## Fetching Aggregated Values\n\n**Requests can count.** The `fetchCount()` method returns the number of rows that would be returned by a fetch request:\n\n```swift\n// SELECT COUNT(*) FROM player\nlet count = try Player.fetchCount(db) // Int\n\n// SELECT COUNT(*) FROM player WHERE email IS NOT NULL\nlet count = try Player.filter { $0.email != nil }.fetchCount(db)\n\n// SELECT COUNT(DISTINCT name) FROM player\nlet count = try Player.select(\\.name).distinct().fetchCount(db)\n\n// SELECT COUNT(*) FROM (SELECT DISTINCT name, score FROM player)\nlet count = try Player.select { [$0.name, $0.score] }.distinct().fetchCount(db)\n```\n\n\n**Other aggregated values** can also be selected and fetched (see [SQL Functions](#sql-functions)):\n\n```swift\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\nlet request = Player.select { [min($0.score), max($0.score)] }\nlet row = try Row.fetchOne(db, request)!     // Row\nlet minScore = row[0] as Int?\nlet maxScore = row[1] as Int?\n```\n\n\n## Delete Requests\n\n**Requests can delete records**, with the `deleteAll()` method:\n\n```swift\n// DELETE FROM player\ntry Player.deleteAll(db)\n\n// DELETE FROM player WHERE team = 'Reds'\ntry Player\n    .filter { $0.team == \"Reds\" }\n    .deleteAll(db)\n\n// DELETE FROM player ORDER BY score LIMIT 10\ntry Player\n    .order(\\.score)\n    .limit(10)\n    .deleteAll(db)\n```\n\n> **Note** Deletion methods are available on types that adopt the [TableRecord] protocol, and `Table`:\n>\n> ```swift\n> struct Player: TableRecord { ... }\n> try Player.deleteAll(db)          // Fine\n> try Table(\"player\").deleteAll(db) // Just as fine\n> ```\n\n**Deleting records according to their primary key** is a common task.\n\n[Identifiable Records] can use the type-safe methods `deleteOne(_:id:)` and `deleteAll(_:ids:)`:\n\n```swift\ntry Player.deleteOne(db, id: 1)\ntry Country.deleteAll(db, ids: [\"FR\", \"US\"])\n```\n\nAll record types can use `deleteOne(_:key:)` and `deleteAll(_:keys:)` that apply conditions on primary and unique keys:\n\n```swift\ntry Player.deleteOne(db, key: 1)\ntry Country.deleteAll(db, keys: [\"FR\", \"US\"])\ntry Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\ntry Citizenship.deleteOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\nWhen the table has no explicit primary key, GRDB uses the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html):\n\n```swift\n// DELETE FROM document WHERE rowid = 1\ntry Document.deleteOne(db, id: 1)             // Document?\n```\n\n\n## Update Requests\n\n**Requests can batch update records**. The `updateAll()` method accepts *column assignments* defined with the `set(to:)` method:\n\n```swift\n// UPDATE player SET score = 0, isHealthy = 1, bonus = NULL\ntry Player.updateAll(db) { [\n    $0.score.set(to: 0), \n    $0.isHealthy.set(to: true), \n    $0.bonus.set(to: nil),\n] }\n\n// UPDATE player SET score = 0 WHERE team = 'Reds'\ntry Player\n    .filter { $0.team == \"Reds\" }\n    .updateAll(db) { $0.score.set(to: 0) }\n\n// UPDATE player SET isGreat = 1 ORDER BY score DESC LIMIT 10\ntry Player\n    .order(\\.score.desc)\n    .limit(10)\n    .updateAll(db) { $0.isGreat.set(to: true) }\n\n// UPDATE country SET population = 67848156 WHERE id = 'FR'\ntry Country\n    .filter(id: \"FR\")\n    .updateAll(db) { $0.population.set(to: 67_848_156) }\n```\n\nColumn assignments accept any expression:\n\n```swift\n// UPDATE player SET score = score + (bonus * 2)\ntry Player.updateAll(db) {\n    $0.score.set(to: $0.score + $0.bonus * 2)\n}\n```\n\nAs a convenience, you can also use the `+=`, `-=`, `*=`, or `/=` operators:\n\n```swift\n// UPDATE player SET score = score + (bonus * 2)\ntry Player.updateAll(db) { $0.score += $0.bonus * 2 }\n```\n\nDefault [Conflict Resolution] rules apply, and you may also provide a specific one:\n\n```swift\n// UPDATE OR IGNORE player SET ...\ntry Player.updateAll(db, onConflict: .ignore) { /* assignments... */ }\n```\n\n> **Note** The `updateAll` method is available on types that adopt the [TableRecord] protocol, and `Table`:\n>\n> ```swift\n> struct Player: TableRecord { ... }\n> try Player.updateAll(db, ...)          // Fine\n> try Table(\"player\").updateAll(db, ...) // Just as fine\n> ```\n\n\n## Custom Requests\n\nUntil now, we have seen [requests](#requests) created from any type that adopts the [TableRecord] protocol:\n\n```swift\nlet request = Player.all()  // QueryInterfaceRequest<Player>\n```\n\nThose requests of type `QueryInterfaceRequest` can fetch and count:\n\n```swift\ntry request.fetchCursor(db) // A Cursor of Player\ntry request.fetchAll(db)    // [Player]\ntry request.fetchSet(db)    // Set<Player>\ntry request.fetchOne(db)    // Player?\ntry request.fetchCount(db)  // Int\n```\n\n**When the query interface can not generate the SQL you need**, you can still fallback to [raw SQL](#fetch-queries):\n\n```swift\n// Custom SQL is always welcome\ntry Player.fetchAll(db, sql: \"SELECT ...\")   // [Player]\n```\n\nBut you may prefer to bring some elegance back in, and build custom requests:\n\n```swift\n// No custom SQL in sight\ntry Player.customRequest().fetchAll(db) // [Player]\n```\n\n**To build custom requests**, you can use one of the built-in requests or derive requests from other requests.\n\n- [SQLRequest] is a fetch request built from raw SQL. For example:\n    \n    ```swift\n    extension Player {\n        static func filter(color: Color) -> SQLRequest<Player> {\n            SQLRequest<Player>(\n                sql: \"SELECT * FROM player WHERE color = ?\"\n                arguments: [color])\n        }\n    }\n    \n    // [Player]\n    try Player.filter(color: .red).fetchAll(db)\n    ```\n    \n    SQLRequest supports [SQL Interpolation]:\n    \n    ```swift\n    extension Player {\n        static func filter(color: Color) -> SQLRequest<Player> {\n            \"SELECT * FROM player WHERE color = \\(color)\"\n        }\n    }\n    ```\n    \n- The [`asRequest(of:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/asrequest(of:)) method changes the type fetched by the request. It is useful, for example, when you use [Associations]:\n\n    ```swift\n    struct BookInfo: FetchableRecord, Decodable {\n        var book: Book\n        var author: Author\n    }\n    \n    let request = Book\n        .including(required: Book.author)\n        .asRequest(of: BookInfo.self)\n    \n    // [BookInfo]\n    try request.fetchAll(db)\n    ```\n\n- The [`adapted(_:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/fetchrequest/adapted(_:)) method eases the consumption of complex rows with row adapters. See [`RowAdapter`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter) and [`splittingRowAdapters(columnCounts:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/splittingrowadapters(columncounts:)) for a sample code that uses `adapted(_:)`.\n\n\nEncryption\n==========\n\n**GRDB can encrypt your database with [SQLCipher](http://sqlcipher.net) v3.4+.**\n\nUse [CocoaPods](http://cocoapods.org/), and specify in your `Podfile`:\n\n```ruby\n# GRDB with SQLCipher 4\npod 'GRDB.swift/SQLCipher'\npod 'SQLCipher', '~> 4.0'\n\n# GRDB with SQLCipher 3\npod 'GRDB.swift/SQLCipher'\npod 'SQLCipher', '~> 3.4'\n```\n\nMake sure you remove any existing `pod 'GRDB.swift'` from your Podfile. `GRDB.swift/SQLCipher` must be the only active GRDB pod in your whole project, or you will face linker or runtime errors, due to the conflicts between SQLCipher and the system SQLite.\n\n- [Creating or Opening an Encrypted Database](#creating-or-opening-an-encrypted-database)\n- [Changing the Passphrase of an Encrypted Database](#changing-the-passphrase-of-an-encrypted-database)\n- [Exporting a Database to an Encrypted Database](#exporting-a-database-to-an-encrypted-database)\n- [Security Considerations](#security-considerations)\n\n\n### Creating or Opening an Encrypted Database\n\n**You create and open an encrypted database** by providing a passphrase to your [database connection]:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nIt is also in `prepareDatabase` that you perform other [SQLCipher configuration steps](https://www.zetetic.net/sqlcipher/sqlcipher-api/) that must happen early in the lifetime of a SQLCipher connection. For example:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n    try db.execute(sql: \"PRAGMA cipher_page_size = ...\")\n    try db.execute(sql: \"PRAGMA kdf_iter = ...\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nWhen you want to open an existing SQLCipher 3 database with SQLCipher 4, you may want to run the `cipher_compatibility` pragma:\n\n```swift\n// Open an SQLCipher 3 database with SQLCipher 4\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n    try db.execute(sql: \"PRAGMA cipher_compatibility = 3\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nSee [SQLCipher 4.0.0 Release](https://www.zetetic.net/blog/2018/11/30/sqlcipher-400-release/) and [Upgrading to SQLCipher 4](https://discuss.zetetic.net/t/upgrading-to-sqlcipher-4/3283) for more information.\n\n\n### Changing the Passphrase of an Encrypted Database\n\n**You can change the passphrase** of an already encrypted database.\n\nWhen you use a [database queue](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue), open the database with the old passphrase, and then apply the new passphrase:\n\n```swift\ntry dbQueue.write { db in\n    try db.changePassphrase(\"newSecret\")\n}\n```\n\nWhen you use a [database pool](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool), make sure that no concurrent read can happen by changing the passphrase within the `barrierWriteWithoutTransaction` block. You must also ensure all future reads open a new database connection by calling the `invalidateReadOnlyConnections` method:\n\n```swift\ntry dbPool.barrierWriteWithoutTransaction { db in\n    try db.changePassphrase(\"newSecret\")\n    dbPool.invalidateReadOnlyConnections()\n}\n```\n\n> **Note**: When an application wants to keep on using a database queue or pool after the passphrase has changed, it is responsible for providing the correct passphrase to the `usePassphrase` method called in the database preparation function. Consider:\n>\n> ```swift\n> // WRONG: this won't work across a passphrase change\n> let passphrase = try getPassphrase()\n> var config = Configuration()\n> config.prepareDatabase { db in\n>     try db.usePassphrase(passphrase)\n> }\n>\n> // CORRECT: get the latest passphrase when it is needed\n> var config = Configuration()\n> config.prepareDatabase { db in\n>     let passphrase = try getPassphrase()\n>     try db.usePassphrase(passphrase)\n> }\n> ```\n\n> **Note**: The `DatabasePool.barrierWriteWithoutTransaction` method does not prevent [database snapshots](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasesnapshot) from accessing the database during the passphrase change, or after the new passphrase has been applied to the database. Those database accesses may throw errors. Applications should provide their own mechanism for invalidating open snapshots before the passphrase is changed.\n\n> **Note**: Instead of changing the passphrase \"in place\" as described here, you can also export the database in a new encrypted database that uses the new passphrase. See [Exporting a Database to an Encrypted Database](#exporting-a-database-to-an-encrypted-database).\n\n\n### Exporting a Database to an Encrypted Database\n\nProviding a passphrase won't encrypt a clear-text database that already exists, though. SQLCipher can't do that, and you will get an error instead: `SQLite error 26: file is encrypted or is not a database`.\n\nInstead, create a new encrypted database, at a distinct location, and export the content of the existing database. This can both encrypt a clear-text database, or change the passphrase of an encrypted database.\n\nThe technique to do that is [documented](https://discuss.zetetic.net/t/how-to-encrypt-a-plaintext-sqlite-database-to-use-sqlcipher-and-avoid-file-is-encrypted-or-is-not-a-database-errors/868/1) by SQLCipher.\n\nWith GRDB, it gives:\n\n```swift\n// The existing database\nlet existingDBQueue = try DatabaseQueue(path: \"/path/to/existing.db\")\n\n// The new encrypted database, at some distinct location:\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n}\nlet newDBQueue = try DatabaseQueue(path: \"/path/to/new.db\", configuration: config)\n\ntry existingDBQueue.inDatabase { db in\n    try db.execute(\n        sql: \"\"\"\n            ATTACH DATABASE ? AS encrypted KEY ?;\n            SELECT sqlcipher_export('encrypted');\n            DETACH DATABASE encrypted;\n            \"\"\",\n        arguments: [newDBQueue.path, \"secret\"])\n}\n\n// Now the export is completed, and the existing database can be deleted.\n```\n\n\n### Security Considerations\n\n#### Managing the lifetime of the passphrase string\n\nIt is recommended to avoid keeping the passphrase in memory longer than necessary. To do this, make sure you load the passphrase from the `prepareDatabase` method:\n\n```swift\n// NOT RECOMMENDED: this keeps the passphrase in memory longer than necessary\nlet passphrase = try getPassphrase()\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(passphrase)\n}\n\n// RECOMMENDED: only load the passphrase when it is needed\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    let passphrase = try getPassphrase()\n    try db.usePassphrase(passphrase)\n}\n```\n\nThis technique helps manages the lifetime of the passphrase, although keep in mind that the content of a String may remain intact in memory long after the object has been released.\n\nFor even better control over the lifetime of the passphrase in memory, use a Data object which natively provides the `resetBytes` function.\n\n```swift\n// RECOMMENDED: only load the passphrase when it is needed and reset its content immediately after use\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    var passphraseData = try getPassphraseData() // Data\n    defer {\n        passphraseData.resetBytes(in: 0..<passphraseData.count)\n    }\n    try db.usePassphrase(passphraseData)\n}\n```\n\nSome demanding users will want to go further, and manage the lifetime of the raw passphrase bytes. See below.\n\n\n#### Managing the lifetime of the passphrase bytes\n\nGRDB offers convenience methods for providing the database passphrases as Swift strings: `usePassphrase(_:)` and `changePassphrase(_:)`. Those methods don't keep the passphrase String in memory longer than necessary. But they are as secure as the standard String type: the lifetime of actual passphrase bytes in memory is not under control.\n\nWhen you want to precisely manage the passphrase bytes, talk directly to SQLCipher, using its raw C functions.\n\nFor example:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    ... // Carefully load passphrase bytes\n    let code = sqlite3_key(db.sqliteConnection, /* passphrase bytes */)\n    ... // Carefully dispose passphrase bytes\n    guard code == SQLITE_OK else {\n        throw DatabaseError(\n            resultCode: ResultCode(rawValue: code), \n            message: db.lastErrorMessage)\n    }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\n#### Passphrase availability vs. Database availability\n\nWhen the passphrase is securely stored in the system keychain, your application can protect it using the [`kSecAttrAccessible`](https://developer.apple.com/documentation/security/ksecattraccessible) attribute.\n\nSuch protection prevents GRDB from creating SQLite connections when the passphrase is not available:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    let passphrase = try loadPassphraseFromSystemKeychain()\n    try db.usePassphrase(passphrase)\n}\n\n// Success if and only if the passphrase is available\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nFor the same reason, [database pools], which open SQLite connections on demand, may fail at any time as soon as the passphrase becomes unavailable:\n\n```swift\n// Success if and only if the passphrase is available\nlet dbPool = try DatabasePool(path: dbPath, configuration: config)\n\n// May fail if passphrase has turned unavailable\ntry dbPool.read { ... }\n\n// May trigger value observation failure if passphrase has turned unavailable\ntry dbPool.write { ... }\n```\n\nBecause DatabasePool maintains a pool of long-lived SQLite connections, some database accesses will use an existing connection, and succeed. And some other database accesses will fail, as soon as the pool wants to open a new connection. It is impossible to predict which accesses will succeed or fail.\n\nFor the same reason, a database queue, which also maintains a long-lived SQLite connection, will remain available even after the passphrase has turned unavailable.\n\nApplications are thus responsible for protecting database accesses when the passphrase is unavailable. To this end, they can use [Data Protection](https://developer.apple.com/documentation/uikit/protecting_the_user_s_privacy/encrypting_your_app_s_files). They can also destroy their instances of database queue or pool when the passphrase becomes unavailable.\n\n\n## Backup\n\n**You can backup (copy) a database into another.**\n\nBackups can for example help you copying an in-memory database to and from a database file when you implement NSDocument subclasses.\n\n```swift\nlet source: DatabaseQueue = ...      // or DatabasePool\nlet destination: DatabaseQueue = ... // or DatabasePool\ntry source.backup(to: destination)\n```\n\nThe `backup` method blocks the current thread until the destination database contains the same contents as the source database.\n\nWhen the source is a [database pool](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool), concurrent writes can happen during the backup. Those writes may, or may not, be reflected in the backup, but they won't trigger any error.\n\n`Database` has an analogous `backup` method.\n\n```swift\nlet source: DatabaseQueue = ...      // or DatabasePool\nlet destination: DatabaseQueue = ... // or DatabasePool\ntry source.write { sourceDb in\n    try destination.barrierWriteWithoutTransaction { destDb in\n        try sourceDb.backup(to: destDb)\n    }\n}\n```\n\nThis method allows for the choice of source and destination `Database` handles with which to backup the database.\n\n### Backup Progress Reporting\n\nThe `backup` methods take optional `pagesPerStep` and `progress` parameters. Together these parameters can be used to track a database backup in progress and abort an incomplete backup.\n\nWhen `pagesPerStep` is provided, the database backup is performed in _steps_. At each step, no more than `pagesPerStep` database pages are copied from the source to the destination. The backup proceeds one step at a time until all pages have been copied.\n\nWhen a `progress` callback is provided, `progress` is called after every backup step, including the last. Even if a non-default `pagesPerStep` is specified or the backup is otherwise completed in a single step, the `progress` callback will be called.\n\n```swift\ntry source.backup(\n    to: destination,\n    pagesPerStep: ...)\n    { backupProgress in\n       print(\"Database backup progress:\", backupProgress)\n    }\n```\n\n### Aborting an Incomplete Backup\n\nIf a call to `progress` throws when `backupProgress.isComplete == false`, the backup will be aborted and the error rethrown. However, if a call to `progress` throws when `backupProgress.isComplete == true`, the backup is unaffected and the error is silently ignored.\n\n> **Warning**: Passing non-default values of `pagesPerStep` or `progress` to the backup methods is an advanced API intended to provide additional capabilities to expert users. GRDB's backup API provides a faithful, low-level wrapper to the underlying SQLite online backup API. GRDB's documentation is not a comprehensive substitute for the official SQLite [documentation of their backup API](https://www.sqlite.org/c3ref/backup_finish.html).\n\n## Interrupt a Database\n\n**The `interrupt()` method** causes any pending database operation to abort and return at its earliest opportunity.\n\nIt can be called from any thread.\n\n```swift\ndbQueue.interrupt()\ndbPool.interrupt()\n```\n\nA call to `interrupt()` that occurs when there are no running SQL statements is a no-op and has no effect on SQL statements that are started after `interrupt()` returns.\n\nA database operation that is interrupted will throw a DatabaseError with code `SQLITE_INTERRUPT`. If the interrupted SQL operation is an INSERT, UPDATE, or DELETE that is inside an explicit transaction, then the entire transaction will be rolled back automatically. If the rolled back transaction was started by a transaction-wrapping method such as `DatabaseWriter.write` or `Database.inTransaction`, then all database accesses will throw a DatabaseError with code `SQLITE_ABORT` until the wrapping method returns.\n\nFor example:\n\n```swift\ntry dbQueue.write { db in\n    try Player(...).insert(db)     // throws SQLITE_INTERRUPT\n    try Player(...).insert(db)     // not executed\n}                                  // throws SQLITE_INTERRUPT\n\ntry dbQueue.write { db in\n    do {\n        try Player(...).insert(db) // throws SQLITE_INTERRUPT\n    } catch { }\n}                                  // throws SQLITE_ABORT\n\ntry dbQueue.write { db in\n    do {\n        try Player(...).insert(db) // throws SQLITE_INTERRUPT\n    } catch { }\n    try Player(...).insert(db)     // throws SQLITE_ABORT\n}                                  // throws SQLITE_ABORT\n```\n\nYou can catch both `SQLITE_INTERRUPT` and `SQLITE_ABORT` errors:\n\n```swift\ndo {\n    try dbPool.write { db in ... }\n} catch DatabaseError.SQLITE_INTERRUPT, DatabaseError.SQLITE_ABORT {\n    // Oops, the database was interrupted.\n}\n```\n\nFor more information, see [Interrupt A Long-Running Query](https://www.sqlite.org/c3ref/interrupt.html).\n\n\n## Avoiding SQL Injection\n\nSQL injection is a technique that lets an attacker nuke your database.\n\n> ![XKCD: Exploits of a Mom](https://imgs.xkcd.com/comics/exploits_of_a_mom.png)\n>\n> https://xkcd.com/327/\n\nHere is an example of code that is vulnerable to SQL injection:\n\n```swift\n// BAD BAD BAD\nlet id = 1\nlet name = textField.text\ntry dbQueue.write { db in\n    try db.execute(sql: \"UPDATE students SET name = '\\(name)' WHERE id = \\(id)\")\n}\n```\n\nIf the user enters a funny string like `Robert'; DROP TABLE students; --`, SQLite will see the following SQL, and drop your database table instead of updating a name as intended:\n\n```sql\nUPDATE students SET name = 'Robert';\nDROP TABLE students;\n--' WHERE id = 1\n```\n\nTo avoid those problems, **never embed raw values in your SQL queries**. The only correct technique is to provide [arguments](#executing-updates) to your raw SQL queries:\n\n```swift\nlet name = textField.text\ntry dbQueue.write { db in\n    // Good\n    try db.execute(\n        sql: \"UPDATE students SET name = ? WHERE id = ?\",\n        arguments: [name, id])\n    \n    // Just as good\n    try db.execute(\n        sql: \"UPDATE students SET name = :name WHERE id = :id\",\n        arguments: [\"name\": name, \"id\": id])\n}\n```\n\nWhen you use [records](#records) and the [query interface](#the-query-interface), GRDB always prevents SQL injection for you:\n\n```swift\nlet id = 1\nlet name = textField.text\ntry dbQueue.write { db in\n    if var student = try Student.fetchOne(db, id: id) {\n        student.name = name\n        try student.update(db)\n    }\n}\n```\n\n\n## Error Handling\n\nGRDB can throw [DatabaseError](#databaseerror), [RecordError], [RowDecodingError], or crash your program with a [fatal error](#fatal-errors).\n\nConsidering that a local database is not some JSON loaded from a remote server, GRDB focuses on **trusted databases**. Dealing with [untrusted databases](#how-to-deal-with-untrusted-inputs) requires extra care.\n\n- [DatabaseError](#databaseerror)\n- [RecordError]\n- [RowDecodingError]\n- [Fatal Errors](#fatal-errors)\n- [How to Deal with Untrusted Inputs](#how-to-deal-with-untrusted-inputs)\n- [Error Log](#error-log)\n\n\n### DatabaseError\n\nğŸ“– [`DatabaseError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseerror)\n\n**DatabaseError** are thrown on SQLite errors:\n\n```swift\ndo {\n    try Pet(masterId: 1, name: \"Bobby\").insert(db)\n} catch let error as DatabaseError {\n    // The SQLite error code: 19 (SQLITE_CONSTRAINT)\n    error.resultCode\n    \n    // The extended error code: 787 (SQLITE_CONSTRAINT_FOREIGNKEY)\n    error.extendedResultCode\n    \n    // The eventual SQLite message: FOREIGN KEY constraint failed\n    error.message\n    \n    // The eventual erroneous SQL query\n    // \"INSERT INTO pet (masterId, name) VALUES (?, ?)\"\n    error.sql\n    \n    // The eventual SQL arguments\n    // [1, \"Bobby\"]\n    error.arguments\n    \n    // Full error description\n    // > SQLite error 19: FOREIGN KEY constraint failed -\n    // > while executing `INSERT INTO pet (masterId, name) VALUES (?, ?)`\n    error.description\n}\n```\n\nIf you want to see statement arguments in the error description, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n**SQLite uses [results codes](https://www.sqlite.org/rescode.html) to distinguish between various errors**.\n\nYou can catch a DatabaseError and match on result codes:\n\n```swift\ndo {\n    try ...\n} catch let error as DatabaseError {\n    switch error {\n    case DatabaseError.SQLITE_CONSTRAINT_FOREIGNKEY:\n        // foreign key constraint error\n    case DatabaseError.SQLITE_CONSTRAINT:\n        // any other constraint error\n    default:\n        // any other database error\n    }\n}\n```\n\nYou can also directly match errors on result codes:\n\n```swift\ndo {\n    try ...\n} catch DatabaseError.SQLITE_CONSTRAINT_FOREIGNKEY {\n    // foreign key constraint error\n} catch DatabaseError.SQLITE_CONSTRAINT {\n    // any other constraint error\n} catch {\n    // any other database error\n}\n```\n\nEach DatabaseError has two codes: an `extendedResultCode` (see [extended result code](https://www.sqlite.org/rescode.html#extended_result_code_list)), and a less precise `resultCode` (see [primary result code](https://www.sqlite.org/rescode.html#primary_result_code_list)). Extended result codes are refinements of primary result codes, as `SQLITE_CONSTRAINT_FOREIGNKEY` is to `SQLITE_CONSTRAINT`, for example.\n\n> **Warning**: SQLite has progressively introduced extended result codes across its versions. The [SQLite release notes](http://www.sqlite.org/changes.html) are unfortunately not quite clear about that: write your handling of extended result codes with care.\n\n\n### RecordError\n\nğŸ“– [`RecordError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recorderror)\n\n**RecordError** is thrown by the [PersistableRecord] protocol when the `update` method could not find any row to update:\n\n```swift\ndo {\n    try player.update(db)\n} catch let RecordError.recordNotFound(databaseTableName: table, key: key) {\n    print(\"Key \\(key) was not found in table \\(table).\")\n}\n```\n\n**RecordError** is also thrown by the [FetchableRecord] protocol when the `find` method does not find any record:\n\n```swift\ndo {\n    let player = try Player.find(db, id: 42)\n} catch let RecordError.recordNotFound(databaseTableName: table, key: key) {\n    print(\"Key \\(key) was not found in table \\(table).\")\n}\n```\n\n\n### RowDecodingError\n\nğŸ“– [`RowDecodingError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowdecodingerror)\n\n**RowDecodingError** is thrown when the application can not decode a value from a database row. For example:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT NULL AS name\")!\n// RowDecodingError: could not decode String from database value NULL.\nlet name = try row.decode(String.self, forColumn: \"name\")\n```\n\n### Fatal Errors\n\n**Fatal errors notify that the program, or the database, has to be changed.**\n\nThey uncover programmer errors, false assumptions, and prevent misuses. Here are a few examples:\n\n- **The code asks for a non-optional value, when the database contains NULL:**\n    \n    ```swift\n    // fatal error: could not convert NULL to String.\n    let name: String = row[\"name\"]\n    ```\n    \n    Solution: fix the contents of the database, use [NOT NULL constraints](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/columndefinition/notnull(onconflict:)), or load an optional:\n    \n    ```swift\n    let name: String? = row[\"name\"]\n    ```\n\n- **Conversion from database value to Swift type fails:**\n    \n    ```swift\n    // fatal error: could not convert \"Momâ€™s birthday\" to Date.\n    let date: Date = row[\"date\"]\n    \n    // fatal error: could not convert \"\" to URL.\n    let url: URL = row[\"url\"]\n    ```\n    \n    Solution: fix the contents of the database, or use [DatabaseValue](#databasevalue) to handle all possible cases:\n    \n    ```swift\n    let dbValue: DatabaseValue = row[\"date\"]\n    if dbValue.isNull {\n        // Handle NULL\n    } else if let date = Date.fromDatabaseValue(dbValue) {\n        // Handle valid date\n    } else {\n        // Handle invalid date\n    }\n    ```\n\n- **The database can't guarantee that the code does what it says:**\n\n    ```swift\n    // fatal error: table player has no unique index on column email\n    try Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\n    ```\n    \n    Solution: add a unique index to the player.email column, or use the `deleteAll` method to make it clear that you may delete more than one row:\n    \n    ```swift\n    try Player.filter { $0.email == \"arthur@example.com\" }.deleteAll(db)\n    ```\n\n- **Database connections are not reentrant:**\n    \n    ```swift\n    // fatal error: Database methods are not reentrant.\n    dbQueue.write { db in\n        dbQueue.write { db in\n            ...\n        }\n    }\n    ```\n    \n    Solution: avoid reentrancy, and instead pass a database connection along.\n\n\n### How to Deal with Untrusted Inputs\n\nLet's consider the code below:\n\n```swift\nlet sql = \"SELECT ...\"\n\n// Some untrusted arguments for the query\nlet arguments: [String: Any] = ...\nlet rows = try Row.fetchCursor(db, sql: sql, arguments: StatementArguments(arguments))\n\nwhile let row = try rows.next() {\n    // Some untrusted database value:\n    let date: Date? = row[0]\n}\n```\n\nIt has two opportunities to throw fatal errors:\n\n- **Untrusted arguments**: The dictionary may contain values that do not conform to the [DatabaseValueConvertible protocol](#values), or may miss keys required by the statement.\n- **Untrusted database content**: The row may contain a non-null value that can't be turned into a date.\n\nIn such a situation, you can still avoid fatal errors by exposing and handling each failure point, one level down in the GRDB API:\n\n```swift\n// Untrusted arguments\nif let arguments = StatementArguments(arguments) {\n    let statement = try db.makeStatement(sql: sql)\n    try statement.setArguments(arguments)\n    \n    var cursor = try Row.fetchCursor(statement)\n    while let row = try iterator.next() {\n        // Untrusted database content\n        let dbValue: DatabaseValue = row[0]\n        if dbValue.isNull {\n            // Handle NULL\n        if let date = Date.fromDatabaseValue(dbValue) {\n            // Handle valid date\n        } else {\n            // Handle invalid date\n        }\n    }\n}\n```\n\nSee [`Statement`] and [DatabaseValue](#databasevalue) for more information.\n\n\n### Error Log\n\n**SQLite can be configured to invoke a callback function containing an error code and a terse error message whenever anomalies occur.**\n\nThis global error callback must be configured early in the lifetime of your application:\n\n```swift\nDatabase.logError = { (resultCode, message) in\n    NSLog(\"%@\", \"SQLite error \\(resultCode): \\(message)\")\n}\n```\n\n> **Warning**: Database.logError must be set before any database connection is opened. This includes the connections that your application opens with GRDB, but also connections opened by other tools, such as third-party libraries. Setting it after a connection has been opened is an SQLite misuse, and has no effect.\n\nSee [The Error And Warning Log](https://sqlite.org/errlog.html) for more information.\n\n\n## Unicode\n\nSQLite lets you store unicode strings in the database.\n\nHowever, SQLite does not provide any unicode-aware string transformations or comparisons.\n\n\n### Unicode functions\n\nThe `UPPER` and `LOWER` built-in SQLite functions are not unicode-aware:\n\n```swift\n// \"JÃ©RÃ´ME\"\ntry String.fetchOne(db, sql: \"SELECT UPPER('JÃ©rÃ´me')\")\n```\n\nGRDB extends SQLite with [SQL functions](#custom-sql-functions-and-aggregates) that call the Swift built-in string functions `capitalized`, `lowercased`, `uppercased`, `localizedCapitalized`, `localizedLowercased` and `localizedUppercased`:\n\n```swift\n// \"JÃ‰RÃ”ME\"\nlet uppercased = DatabaseFunction.uppercase\ntry String.fetchOne(db, sql: \"SELECT \\(uppercased.name)('JÃ©rÃ´me')\")\n```\n\nThose unicode-aware string functions are also readily available in the [query interface](#sql-functions):\n\n```swift\nPlayer.select { $0.name.uppercased }\n```\n\n\n### String Comparison\n\nSQLite compares strings in many occasions: when you sort rows according to a string column, or when you use a comparison operator such as `=` and `<=`.\n\nThe comparison result comes from a *collating function*, or *collation*. SQLite comes with three built-in collations that do not support Unicode: [binary, nocase, and rtrim](https://www.sqlite.org/datatype3.html#collation).\n\nGRDB comes with five extra collations that leverage unicode-aware comparisons based on the standard Swift String comparison functions and operators:\n\n- `unicodeCompare` (uses the built-in `<=` and `==` Swift operators)\n- `caseInsensitiveCompare`\n- `localizedCaseInsensitiveCompare`\n- `localizedCompare`\n- `localizedStandardCompare`\n\nA collation can be applied to a table column. All comparisons involving this column will then automatically trigger the comparison function:\n    \n```swift\ntry db.create(table: \"player\") { t in\n    // Guarantees case-insensitive email unicity\n    t.column(\"email\", .text).unique().collate(.nocase)\n    \n    // Sort names in a localized case insensitive way\n    t.column(\"name\", .text).collate(.localizedCaseInsensitiveCompare)\n}\n\n// Players are sorted in a localized case insensitive way:\nlet players = try Player.order(\\.name).fetchAll(db)\n```\n\n> **Warning**: SQLite *requires* host applications to provide the definition of any collation other than binary, nocase and rtrim. When a database file has to be shared or migrated to another SQLite library of platform (such as the Android version of your application), make sure you provide a compatible collation.\n\nIf you can't or don't want to define the comparison behavior of a column (see warning above), you can still use an explicit collation in SQL requests and in the [query interface](#the-query-interface):\n\n```swift\nlet collation = DatabaseCollation.localizedCaseInsensitiveCompare\nlet players = try Player.fetchAll(db,\n    sql: \"SELECT * FROM player ORDER BY name COLLATE \\(collation.name))\")\nlet players = try Player.order { $0.name.collating(collation) }.fetchAll(db)\n```\n\n\n**You can also define your own collations**:\n\n```swift\nlet collation = DatabaseCollation(\"customCollation\") { (lhs, rhs) -> NSComparisonResult in\n    // return the comparison of lhs and rhs strings.\n}\n\n// Make the collation available to a database connection\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(collation: collation)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\n\n\n## Memory Management\n\nBoth SQLite and GRDB use non-essential memory that help them perform better.\n\nYou can reclaim this memory with the `releaseMemory` method:\n\n```swift\n// Release as much memory as possible.\ndbQueue.releaseMemory()\ndbPool.releaseMemory()\n```\n\nThis method blocks the current thread until all current database accesses are completed, and the memory collected.\n\n> **Warning**: If `DatabasePool.releaseMemory()` is called while a long read is performed concurrently, then no other read access will be possible until this long read has completed, and the memory has been released. If this does not suit your application needs, look for the asynchronous options below:\n\nYou can release memory in an asynchronous way as well:\n\n```swift\n// On a DatabaseQueue\ndbQueue.asyncWriteWithoutTransaction { db in\n    db.releaseMemory()\n}\n\n// On a DatabasePool\ndbPool.releaseMemoryEventually()\n```\n\n`DatabasePool.releaseMemoryEventually()` does not block the current thread, and does not prevent concurrent database accesses. In exchange for this convenience, you don't know when memory has been freed.\n\n\n### Memory Management on iOS\n\n**The iOS operating system likes applications that do not consume much memory.**\n\n[Database queues] and [pools](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool) automatically free non-essential memory when the application receives a memory warning, and when the application enters background.\n\nYou can opt out of this automatic memory management:\n\n```swift\nvar config = Configuration()\nconfig.automaticMemoryManagement = false\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config) // or DatabasePool\n```\n\nFAQ\n===\n\n**[FAQ: Opening Connections](#faq-opening-connections)**\n\n- [How do I create a database in my application?](#how-do-i-create-a-database-in-my-application)\n- [How do I open a database stored as a resource of my application?](#how-do-i-open-a-database-stored-as-a-resource-of-my-application)\n- [How do I close a database connection?](#how-do-i-close-a-database-connection)\n\n**[FAQ: SQL](#faq-sql)**\n\n- [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql)\n\n**[FAQ: General](#faq-general)**\n\n- [How do I monitor the duration of database statements execution?](#how-do-i-monitor-the-duration-of-database-statements-execution)\n- [What Are Experimental Features?](#what-are-experimental-features)\n- [Does GRDB support library evolution and ABI stability?](#does-grdb-support-library-evolution-and-abi-stability)\n\n**[FAQ: Associations](#faq-associations)**\n\n- [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record)\n- [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record)\n- [How do I select only one column of an associated record?](#how-do-i-select-only-one-column-of-an-associated-record)\n\n**[FAQ: ValueObservation](#faq-valueobservation)**\n\n- [Why is ValueObservation not publishing value changes?](#why-is-valueobservation-not-publishing-value-changes)\n\n**[FAQ: Errors](#faq-errors)**\n\n- [Generic parameter 'T' could not be inferred](#generic-parameter-t-could-not-be-inferred)\n- [Mutation of captured var in concurrently-executing code](#mutation-of-captured-var-in-concurrently-executing-code)\n- [SQLite error 1 \"no such column\"](#sqlite-error-1-no-such-column)\n- [SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"](#sqlite-error-10-disk-io-error-sqlite-error-23-not-authorized)\n- [SQLite error 21 \"wrong number of statement arguments\" with LIKE queries](#sqlite-error-21-wrong-number-of-statement-arguments-with-like-queries)\n\n\n## FAQ: Opening Connections\n\n- :arrow_up: [FAQ]\n- [How do I create a database in my application?](#how-do-i-create-a-database-in-my-application)\n- [How do I open a database stored as a resource of my application?](#how-do-i-open-a-database-stored-as-a-resource-of-my-application)\n- [How do I close a database connection?](#how-do-i-close-a-database-connection)\n\n### How do I create a database in my application?\n\nFirst choose a proper location for the database file. Document-based applications will let the user pick a location. Apps that use the database as a global storage will prefer the Application Support directory.\n\nThe sample code below creates or opens a database file inside its dedicated directory (a [recommended practice](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections)). On the first run, a new empty database file is created. On subsequent runs, the database file already exists, so it just opens a connection:\n\n```swift\n// HOW TO create an empty database, or open an existing database file\n\n// Create the \"Application Support/MyDatabase\" directory\nlet fileManager = FileManager.default\nlet appSupportURL = try fileManager.url(\n    for: .applicationSupportDirectory, in: .userDomainMask,\n    appropriateFor: nil, create: true) \nlet directoryURL = appSupportURL.appendingPathComponent(\"MyDatabase\", isDirectory: true)\ntry fileManager.createDirectory(at: directoryURL, withIntermediateDirectories: true)\n\n// Open or create the database\nlet databaseURL = directoryURL.appendingPathComponent(\"db.sqlite\")\nlet dbQueue = try DatabaseQueue(path: databaseURL.path)\n```\n\n### How do I open a database stored as a resource of my application?\n\nOpen a read-only connection to your resource:\n\n```swift\n// HOW TO open a read-only connection to a database resource\n\n// Get the path to the database resource.\nif let dbPath = Bundle.main.path(forResource: \"db\", ofType: \"sqlite\") {\n    // If the resource exists, open a read-only connection.\n    // Writes are disallowed because resources can not be modified. \n    var config = Configuration()\n    config.readonly = true\n    let dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n} else {\n    // The database resource can not be found.\n    // Fix your setup, or report the problem to the user. \n}\n```\n\n### How do I close a database connection?\n\nDatabase connections are automatically closed when `DatabaseQueue` or `DatabasePool` instances are deinitialized.\n\nIf the correct execution of your program depends on precise database closing, perform an explicit call to [`close()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasereader/close()). This method may fail and create zombie connections, so please check its detailed documentation.\n\n## FAQ: SQL\n\n- :arrow_up: [FAQ]\n- [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql)\n\n### How do I print a request as SQL?\n\nWhen you want to debug a request that does not deliver the expected results, you may want to print the SQL that is actually executed.\n\nYou can compile the request into a prepared [`Statement`]:\n\n```swift\ntry dbQueue.read { db in\n    let request = Player.filter { $0.email == \"arthur@example.com\" }\n    let statement = try request.makePreparedRequest(db).statement\n    print(statement) // SELECT * FROM player WHERE email = ?\n    print(statement.arguments) // [\"arthur@example.com\"]\n}\n```\n\nAnother option is to setup a tracing function that prints out the executed SQL requests. For example, provide a tracing function when you connect to the database:\n\n```swift\n// Prints all SQL statements\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace { print($0) }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // Prints \"SELECT * FROM player WHERE email = ?\"\n    let players = try Player.filter { $0.email == \"arthur@example.com\" }.fetchAll(db)\n}\n```\n\nIf you want to see statement arguments such as `'arthur@example.com'` in the logged statements, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n> **Note**: the generated SQL may change between GRDB releases, without notice: don't have your application rely on any specific SQL output.\n\n\n## FAQ: General\n\n- :arrow_up: [FAQ]\n- [How do I monitor the duration of database statements execution?](#how-do-i-monitor-the-duration-of-database-statements-execution)\n- [What Are Experimental Features?](#what-are-experimental-features)\n- [Does GRDB support library evolution and ABI stability?](#does-grdb-support-library-evolution-and-abi-stability)\n\n### How do I monitor the duration of database statements execution?\n\nUse the `trace(options:_:)` method, with the `.profile` option:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace(options: .profile) { event in\n        // Prints all SQL statements with their duration\n        print(event)\n        \n        // Access to detailed profiling information\n        if case let .profile(statement, duration) = event, duration > 0.5 {\n            print(\"Slow query: \\(statement.sql)\")\n        }\n    }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    let players = try Player.filter { $0.email == \"arthur@example.com\" }.fetchAll(db)\n    // Prints \"0.003s SELECT * FROM player WHERE email = ?\"\n}\n```\n\nIf you want to see statement arguments such as `'arthur@example.com'` in the logged statements, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n### What Are Experimental Features?\n\nSince GRDB 1.0, all backwards compatibility guarantees of [semantic versioning](http://semver.org) apply: no breaking change will happen until the next major version of the library.\n\nThere is an exception, though: *experimental features*, marked with the \"**:fire: EXPERIMENTAL**\" badge. Those are advanced features that are too young, or lack user feedback. They are not stabilized yet.\n\nThose experimental features are not protected by semantic versioning, and may break between two minor releases of the library. To help them becoming stable, [your feedback](https://github.com/groue/GRDB.swift/issues) is greatly appreciated.\n\n### Does GRDB support library evolution and ABI stability?\n\nNo, GRDB does not support library evolution and ABI stability. The only promise is API stability according to [semantic versioning](http://semver.org), with an exception for [experimental features](#what-are-experimental-features).\n\nYet, GRDB can be built with the \"Build Libraries for Distribution\" Xcode option (`BUILD_LIBRARY_FOR_DISTRIBUTION`), so that you can build binary frameworks at your convenience.\n\n## FAQ: Associations\n\n- :arrow_up: [FAQ]\n- [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record)\n- [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record)\n- [How do I select only one column of an associated record?](#how-do-i-select-only-one-column-of-an-associated-record)\n\n### How do I filter records and only keep those that are associated to another record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to only fetch books that have an author, and discard anonymous books.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: TableRecord {\n    ...\n}\n```\n\nAnd then we can write our request and only fetch books that have an author, discarding anonymous ones:\n\n```swift\nlet books: [Book] = try dbQueue.read { db in\n    // SELECT book.* FROM book \n    // JOIN author ON author.id = book.authorID\n    let request = Book.joining(required: Book.author)\n    return try request.fetchAll(db)\n}\n```\n\nNote how this request does not use the `filter` method. Indeed, we don't have any condition to express on any column. Instead, we just need to \"require that a book can be joined to its author\".\n\nSee [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record) below for the opposite question.\n\n\n### How do I filter records and only keep those that are NOT associated to another record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to only fetch anonymous books that do not have any author.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: TableRecord {\n    ...\n}\n```\n\nAnd then we can write our request and only fetch anonymous books that don't have any author:\n\n```swift\nlet books: [Book] = try dbQueue.read { db in\n    // SELECT book.* FROM book\n    // LEFT JOIN author ON author.id = book.authorID\n    // WHERE author.id IS NULL\n    let authorAlias = TableAlias<Author>()\n    let request = Book\n        .joining(optional: Book.author.aliased(authorAlias))\n        .filter(!authorAlias.exists)\n    return try request.fetchAll(db)\n}\n```\n\nThis request uses a TableAlias in order to be able to filter on the eventual associated author. We make sure that the `Author.primaryKey` is nil, which is another way to say it does not exist: the book has no author.\n\nSee [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record) above for the opposite question.\n\n\n### How do I select only one column of an associated record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to fetch all books with their author name, but not the full associated author records.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: Decodable, TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: Decodable, TableRecord {\n    ...\n    enum Columns {\n        static let name = Column(CodingKeys.name)\n    }\n}\n```\n\nAnd then we can write our request and the ad-hoc record that decodes it:\n\n```swift\nstruct BookInfo: Decodable, FetchableRecord {\n    var book: Book\n    var authorName: String? // nil when the book is anonymous\n    \n    static func all() -> QueryInterfaceRequest<BookInfo> {\n        // SELECT book.*, author.name AS authorName\n        // FROM book\n        // LEFT JOIN author ON author.id = book.authorID\n        return Book\n            .annotated(withOptional: Book.author.select { \n                $0.name.forKey(CodingKeys.authorName)\n            })\n            .asRequest(of: BookInfo.self)\n    }\n}\n\nlet bookInfos: [BookInfo] = try dbQueue.read { db in\n    BookInfo.all().fetchAll(db)\n}\n```\n\nBy defining the request as a static method of BookInfo, you have access to the private `CodingKeys.authorName`, and a compiler-checked SQL column name.\n\nBy using the `annotated(withOptional:)` method, you append the author name to the top-level selection that can be decoded by the ad-hoc record.\n\nBy using `asRequest(of:)`, you enhance the type-safety of your request.\n\n\n## FAQ: ValueObservation\n\n- :arrow_up: [FAQ]\n- [Why is ValueObservation not publishing value changes?](#why-is-valueobservation-not-publishing-value-changes)\n\n### Why is ValueObservation not publishing value changes?\n\nSometimes it looks that a [ValueObservation] does not notify the changes you expect.\n\nThere may be four possible reasons for this:\n\n1. The expected changes were not committed into the database.\n2. The expected changes were committed into the database, but were quickly overwritten.\n3. The observation was stopped.\n4. The observation does not track the expected database region.\n\nTo answer the first two questions, look at SQL statements executed by the database. This is done when you open the database connection:\n\n```swift\n// Prints all SQL statements\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace { print(\"SQL: \\($0)\") }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nIf, after that, you are convinced that the expected changes were committed into the database, and not overwritten soon after, trace observation events:\n\n```swift\nlet observation = ValueObservation\n    .tracking { db in ... }\n    .print() // <- trace observation events\nlet cancellable = observation.start(...)\n```\n\nLook at the observation logs which start with `cancel` or `failure`: maybe the observation was cancelled by your app, or did fail with an error.\n\nLook at the observation logs which start with `value`: make sure, again, that the expected value was not actually notified, then overwritten.\n\nFinally, look at the observation logs which start with `tracked region`. Does the printed database region cover the expected changes?\n\nFor example:\n\n- `empty`: The empty region, which tracks nothing and never triggers the observation.\n- `player(*)`: The full `player` table\n- `player(id,name)`: The `id` and `name` columns of the `player` table\n- `player(id,name)[1]`: The `id` and `name` columns of the row with id 1 in the `player` table\n- `player(*),team(*)`: Both the full `player` and `team` tables\n\nIf you happen to use the `ValueObservation.trackingConstantRegion(_:)` method and see a mismatch between the tracked region and your expectation, then change the definition of your observation by using `tracking(_:)`. You should witness that the logs which start with `tracked region` now evolve in order to include the expected changes, and that you get the expected notifications.\n\nIf after all those steps (thanks you!), your observation is still failing you, please [open an issue](https://github.com/groue/GRDB.swift/issues/new) and provide a [minimal reproducible example](https://stackoverflow.com/help/minimal-reproducible-example)!\n\n\n## FAQ: Errors\n\n- :arrow_up: [FAQ]\n- [Generic parameter 'T' could not be inferred](#generic-parameter-t-could-not-be-inferred)\n- [Mutation of captured var in concurrently-executing code](#mutation-of-captured-var-in-concurrently-executing-code)\n- [SQLite error 1 \"no such column\"](#sqlite-error-1-no-such-column)\n- [SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"](#sqlite-error-10-disk-io-error-sqlite-error-23-not-authorized)\n- [SQLite error 21 \"wrong number of statement arguments\" with LIKE queries](#sqlite-error-21-wrong-number-of-statement-arguments-with-like-queries)\n\n### Generic parameter 'T' could not be inferred\n    \nYou may get this error when using the `read` and `write` methods of database queues and pools:\n\n```swift\n// Generic parameter 'T' could not be inferred\nlet string = try dbQueue.read { db in\n    let result = try String.fetchOne(db, ...)\n    return result\n}\n```\n\nThis is a limitation of the Swift compiler.\n\nThe general workaround is to explicitly declare the type of the closure result:\n\n```swift\n// General Workaround\nlet string = try dbQueue.read { db -> String? in\n    let result = try String.fetchOne(db, ...)\n    return result\n}\n```\n\nYou can also, when possible, write a single-line closure:\n\n```swift\n// Single-line closure workaround:\nlet string = try dbQueue.read { db in\n    try String.fetchOne(db, ...)\n}\n```\n\n\n### Mutation of captured var in concurrently-executing code\n\nThe `insert` and `save` [persistence methods](#persistablerecord-protocol) can trigger a compiler error in async contexts:\n\n```swift\nvar player = Player(id: nil, name: \"Arthur\")\ntry await dbWriter.write { db in\n    // Error: Mutation of captured var 'player' in concurrently-executing code\n    try player.insert(db)\n}\nprint(player.id) // A non-nil id\n```\n\nWhen this happens, prefer the `inserted` and `saved` methods instead:\n\n```swift\n// OK\nvar player = Player(id: nil, name: \"Arthur\")\nplayer = try await dbWriter.write { [player] db in\n    return try player.inserted(db)\n}\nprint(player.id) // A non-nil id\n```\n\n\n### SQLite error 1 \"no such column\"\n\nThis error message is self-explanatory: do check for misspelled or non-existing column names.\n\nHowever, sometimes this error only happens when an app runs on a recent operating system (iOS 14+, Big Sur+, etc.) The error does not happen with previous ones.\n\nWhen this is the case, there are two possible explanations:\n\n1. Maybe a column name is *really* misspelled or missing from the database schema.\n    \n    To find it, check the SQL statement that comes with the [DatabaseError](#databaseerror).\n\n2. Maybe the application is using the character `\"` instead of the single quote `'` as the delimiter for string literals in raw SQL queries. Recent versions of SQLite have learned to tell about this deviation from the SQL standard, and this is why you are seeing this error. \n    \n    For example: this is not standard SQL: `UPDATE player SET name = \"Arthur\"`.\n    \n    The standard version is: `UPDATE player SET name = 'Arthur'`.\n    \n    It just happens that old versions of SQLite used to accept the former, non-standard version. Newer versions are able to reject it with an error.\n    \n    The fix is to change the SQL statements run by the application: replace `\"` with `'` in your string literals.\n    \n    It may also be time to learn about statement arguments and [SQL injection](#avoiding-sql-injection):\n    \n    ```swift\n    let name: String = ...\n    \n    // NOT STANDARD (double quote)\n    try db.execute(sql: \"\"\"\n        UPDATE player SET name = \"\\(name)\"\n        \"\"\")\n    \n    // STANDARD, BUT STILL NOT RECOMMENDED (single quote)\n    try db.execute(sql: \"UPDATE player SET name = '\\(name)'\")\n    \n    // STANDARD, AND RECOMMENDED (statement arguments)\n    try db.execute(sql: \"UPDATE player SET name = ?\", arguments: [name])\n    \n    // STANDARD, AND RECOMMENDED (SQL interpolation)\n    try db.execute(literal: \"UPDATE player SET name = \\(name)\")\n    ```\n    \nFor more information, see [Double-quoted String Literals Are Accepted](https://sqlite.org/quirks.html#double_quoted_string_literals_are_accepted), and [Configuration.acceptsDoubleQuotedStringLiterals](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration/acceptsdoublequotedstringliterals).\n    \n\n\n### SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"\n\nThose errors may be the sign that SQLite can't access the database due to [data protection](https://developer.apple.com/documentation/uikit/protecting_the_user_s_privacy/encrypting_your_app_s_files).\n\nWhen your application should be able to run in the background on a locked device, it has to catch this error, and, for example, wait for [UIApplicationDelegate.applicationProtectedDataDidBecomeAvailable(_:)](https://developer.apple.com/reference/uikit/uiapplicationdelegate/1623044-applicationprotecteddatadidbecom) or [UIApplicationProtectedDataDidBecomeAvailable](https://developer.apple.com/reference/uikit/uiapplicationprotecteddatadidbecomeavailable) notification and retry the failed database operation.\n\n```swift\ndo {\n    try ...\n} catch DatabaseError.SQLITE_IOERR, DatabaseError.SQLITE_AUTH {\n    // Handle possible data protection error\n}\n```\n\nThis error can also be prevented altogether by using a more relaxed [file protection](https://developer.apple.com/reference/foundation/filemanager/1653059-file_protection_values).\n\n\n### SQLite error 21 \"wrong number of statement arguments\" with LIKE queries\n\nYou may get the error \"wrong number of statement arguments\" when executing a LIKE query similar to:\n\n```swift\nlet name = textField.text\nlet players = try dbQueue.read { db in\n    try Player.fetchAll(db, sql: \"SELECT * FROM player WHERE name LIKE '%?%'\", arguments: [name])\n}\n```\n\nThe problem lies in the `'%?%'` pattern.\n\nSQLite only interprets `?` as a parameter when it is a placeholder for a whole value (int, double, string, blob, null). In this incorrect query, `?` is just a character in the `'%?%'` string: it is not a query parameter, and is not processed in any way. See [https://www.sqlite.org/lang_expr.html#varparam](https://www.sqlite.org/lang_expr.html#varparam) for more information about SQLite parameters.\n\nTo fix the error, you can feed the request with the pattern itself, instead of the name:\n\n```swift\nlet name = textField.text\nlet players: [Player] = try dbQueue.read { db in\n    let pattern = \"%\\(name)%\"\n    return try Player.fetchAll(db, sql: \"SELECT * FROM player WHERE name LIKE ?\", arguments: [pattern])\n}\n```\n\n\nSample Code\n===========\n\n- The [Documentation](#documentation) is full of GRDB snippets.\n- [Demo Applications]\n- Open `GRDB.xcworkspace`: it contains GRDB-enabled playgrounds to play with.\n- [groue/SortedDifference](https://github.com/groue/SortedDifference): How to synchronize a database table with a JSON payload\n\n\n---\n\n**Thanks**\n\n- [Pierlis](http://pierlis.com), where we write great software.\n- [@alextrob](https://github.com/alextrob), [@alexwlchan](https://github.com/alexwlchan), [@bellebethcooper](https://github.com/bellebethcooper), [@bfad](https://github.com/bfad), [@cfilipov](https://github.com/cfilipov), [@charlesmchen-signal](https://github.com/charlesmchen-signal), [@Chiliec](https://github.com/Chiliec), [@chrisballinger](https://github.com/chrisballinger), [@darrenclark](https://github.com/darrenclark), [@davidkraus](https://github.com/davidkraus), [@eburns-vmware](https://github.com/eburns-vmware), [@felixscheinost](https://github.com/felixscheinost), [@fpillet](https://github.com/fpillet), [@gcox](https://github.com/gcox), [@GetToSet](https://github.com/GetToSet), [@gjeck](https://github.com/gjeck), [@guidedways](https://github.com/guidedways), [@gusrota](https://github.com/gusrota), [@haikusw](https://github.com/haikusw), [@hartbit](https://github.com/hartbit), [@holsety](https://github.com/holsety), [@jroselightricks](https://github.com/jroselightricks), [@kdubb](https://github.com/kdubb), [@kluufger](https://github.com/kluufger), [@KyleLeneau](https://github.com/KyleLeneau), [@layoutSubviews](https://github.com/layoutSubviews), [@mallman](https://github.com/mallman), [@MartinP7r](https://github.com/MartinP7r), [@Marus](https://github.com/Marus), [@mattgallagher](https://github.com/mattgallagher), [@MaxDesiatov](https://github.com/MaxDesiatov), [@michaelkirk-signal](https://github.com/michaelkirk-signal), [@mtancock](https://github.com/mtancock), [@pakko972](https://github.com/pakko972), [@peter-ss](https://github.com/peter-ss), [@pierlo](https://github.com/pierlo), [@pocketpixels](https://github.com/pocketpixels), [@pp5x](https://github.com/pp5x), [@professordeng](https://github.com/professordeng), [@robcas3](https://github.com/robcas3), [@runhum](https://github.com/runhum), [@sberrevoets](https://github.com/sberrevoets), [@schveiguy](https://github.com/schveiguy), [@SD10](https://github.com/SD10), [@sobri909](https://github.com/sobri909), [@sroddy](https://github.com/sroddy), [@steipete](https://github.com/steipete), [@swiftlyfalling](https://github.com/swiftlyfalling), [@Timac](https://github.com/Timac), [@tternes](https://github.com/tternes), [@valexa](https://github.com/valexa), [@wuyuehyang](https://github.com/wuyuehyang), [@ZevEisenberg](https://github.com/ZevEisenberg), and [@zmeyc](https://github.com/zmeyc) for their contributions, help, and feedback on GRDB.\n- [@aymerick](https://github.com/aymerick) and [@kali](https://github.com/kali) because SQL.\n- [ccgus/fmdb](https://github.com/ccgus/fmdb) for its excellency.\n\n---\n\n[URIs don't change: people change them.](https://www.w3.org/Provider/Style/URI)\n\n#### Adding support for missing SQL functions or operators\n\nThis chapter was renamed to [Embedding SQL in Query Interface Requests].\n\n#### Advanced DatabasePool\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### After Commit Hook\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)).\n\n#### Asynchronous APIs\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Changes Tracking\n\nThis chapter has been renamed [Record Comparison].\n\n#### Concurrency\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Custom Value Types\n\nCustom Value Types conform to the [`DatabaseValueConvertible`] protocol.\n\n#### Customized Decoding of Database Rows\n\nThis chapter has been renamed [Beyond FetchableRecord].\n\n#### Customizing the Persistence Methods\n\nThis chapter was replaced with [Persistence Callbacks].\n\n#### Database Changes Observation\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseobservation).\n\n#### Database Configuration\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration).\n\n#### Database Queues\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue).\n\n#### Database Pools\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool).\n\n#### Database Snapshots\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### DatabaseWriter and DatabaseReader Protocols\n\nThis chapter was removed. See the references of [DatabaseReader](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasereader) and [DatabaseWriter](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasewriter).\n\n#### Date and UUID Coding Strategies\n\nThis chapter has been renamed [Data, Date, and UUID Coding Strategies].\n\n#### Dealing with External Connections\n\nThis chapter has been superseded by the [Sharing a Database] guide.\n\n#### Differences between Database Queues and Pools\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Enabling FTS5 Support\n\nFTS5 is enabled by default since GRDB 6.7.0.\n\n#### FetchedRecordsController\n\nFetchedRecordsController has been removed in GRDB 5.\n\nThe [Database Observation] chapter describes the other ways to observe the database.\n\n#### Full-Text Search\n\nThis chapter has [moved](Documentation/FullTextSearch.md).\n\n#### Guarantees and Rules\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Joined Queries Support\n\nThis chapter was replaced with the documentation of [splittingRowAdapters(columnCounts:)](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/splittingrowadapters(columncounts:)).\n\n#### List of Record Methods\n\nSee [Records and the Query Interface](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterface).\n\n#### Migrations\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/migrations).\n\n#### NSNumber and NSDecimalNumber\n\nThis chapter has [moved](#nsnumber-nsdecimalnumber-and-decimal).\n\n#### Persistable Protocol\n\nThis protocol has been renamed [PersistableRecord] in GRDB 3.0.\n\n#### PersistenceError\n\nThis error was renamed to [RecordError].\n\n#### Prepared Statements\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement).\n\n#### Record Class\n\nThe [`Record`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/record) class is a legacy GRDB type. Since GRDB 7, it is not recommended to define record types by subclassing the `Record` class.\n\n#### Row Adapters\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter).\n\n#### RowConvertible Protocol\n\nThis protocol has been renamed [FetchableRecord] in GRDB 3.0.\n\n#### TableMapping Protocol\n\nThis protocol has been renamed [TableRecord] in GRDB 3.0.\n\n#### Transactions and Savepoints\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactions).\n\n#### Transaction Hook\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)).\n\n#### TransactionObserver Protocol\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactionobserver).\n\n#### Unsafe Concurrency APIs\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### ValueObservation\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/valueobservation).\n\n#### ValueObservation and DatabaseRegionObservation\n\nThis chapter has been superseded by [ValueObservation] and [DatabaseRegionObservation].\n\n[Associations]: Documentation/AssociationsBasics.md\n[Beyond FetchableRecord]: #beyond-fetchablerecord\n[Identifiable Records]: #identifiable-records\n[Codable Records]: #codable-records\n[Columns Selected by a Request]: #columns-selected-by-a-request\n[common table expression]: Documentation/CommonTableExpressions.md\n[Common Table Expressions]: Documentation/CommonTableExpressions.md\n[Conflict Resolution]: #conflict-resolution\n[Column Names Coding Strategies]: #column-names-coding-strategies\n[Data, Date, and UUID Coding Strategies]: #data-date-and-uuid-coding-strategies\n[Fetching from Requests]: #fetching-from-requests\n[Embedding SQL in Query Interface Requests]: #embedding-sql-in-query-interface-requests\n[Full-Text Search]: Documentation/FullTextSearch.md\n[Migrations]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/migrations\n[The userInfo Dictionary]: #the-userinfo-dictionary\n[JSON Columns]: #json-columns\n[FetchableRecord]: #fetchablerecord-protocol\n[EncodableRecord]: #persistablerecord-protocol\n[PersistableRecord]: #persistablerecord-protocol\n[Record Comparison]: #record-comparison\n[Record Customization Options]: #record-customization-options\n[Persistence Callbacks]: #persistence-callbacks\n[persistence callbacks]: #persistence-callbacks\n[Record Timestamps and Transaction Date]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordtimestamps\n[TableRecord]: #tablerecord-protocol\n[ValueObservation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/valueobservation\n[DatabaseRegionObservation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseregionobservation\n[RxGRDB]: https://github.com/RxSwiftCommunity/RxGRDB\n[DatabaseRegion]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseregion\n[SQL Interpolation]: Documentation/SQLInterpolation.md\n[custom SQLite build]: Documentation/CustomSQLiteBuilds.md\n[Combine]: https://developer.apple.com/documentation/combine\n[Combine Support]: Documentation/Combine.md\n[Concurrency]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency\n[Demo Applications]: Documentation/DemoApps\n[Sharing a Database]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasesharing\n[FAQ]: #faq\n[Database Observation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseobservation\n[SQLRequest]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlrequest\n[SQL literal]: Documentation/SQLInterpolation.md#sql-literal\n[Identifiable]: https://developer.apple.com/documentation/swift/identifiable\n[Query Interface Organization]: Documentation/QueryInterfaceOrganization.md\n[Database Configuration]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration\n[Persistence Methods]: #persistence-methods\n[persistence methods]: #persistence-methods\n[Persistence Methods and the `RETURNING` clause]: #persistence-methods-and-the-returning-clause\n[RecordError]: #recorderror\n[RowDecodingError]: #rowdecodingerror\n[Transactions and Savepoints]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactions\n[`DatabaseQueue`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue\n[Database queues]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue\n[`DatabasePool`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool\n[database pools]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool\n[`DatabaseValueConvertible`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible\n[`StatementArguments`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments\n[Prepared Statements]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[prepared statements]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[`Statement`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[Database Connections]: #database-connections\n[Database connections]: #database-connections\n[database connection]: #database-connections\n",
      "stars_today": 6
    },
    {
      "id": 207354223,
      "name": "FreeRTOS-Kernel",
      "full_name": "FreeRTOS/FreeRTOS-Kernel",
      "description": "FreeRTOS kernel files only, submoduled into https://github.com/FreeRTOS/FreeRTOS and various other repos.",
      "html_url": "https://github.com/FreeRTOS/FreeRTOS-Kernel",
      "stars": 3791,
      "forks": 1422,
      "language": "C",
      "topics": [],
      "created_at": "2019-09-09T16:28:01Z",
      "updated_at": "2026-01-15T13:04:44Z",
      "pushed_at": "2026-01-13T21:35:02Z",
      "open_issues": 36,
      "owner": {
        "login": "FreeRTOS",
        "avatar_url": "https://avatars.githubusercontent.com/u/54647343?v=4"
      },
      "readme": "[![CMock Unit Tests](https://github.com/FreeRTOS/FreeRTOS-Kernel/actions/workflows/unit-tests.yml/badge.svg?branch=main&event=push)](https://github.com/FreeRTOS/FreeRTOS-Kernel/actions/workflows/unit-tests.yml?query=branch%3Amain+event%3Apush+workflow%3A%22CMock+Unit+Tests%22++)\n[![codecov](https://app.codecov.io/gh/FreeRTOS/FreeRTOS-Kernel/badge.svg?branch=main)](https://codecov.io/gh/FreeRTOS/FreeRTOS-Kernel)\n\n## Getting started\n\nThis repository contains FreeRTOS kernel source/header files and kernel\nports only. This repository is referenced as a submodule in\n[FreeRTOS/FreeRTOS](https://github.com/FreeRTOS/FreeRTOS)\nrepository, which contains pre-configured demo application projects under\n```FreeRTOS/Demo``` directory.\n\nThe easiest way to use FreeRTOS is to start with one of the pre-configured demo\napplication projects.  That way you will have the correct FreeRTOS source files\nincluded, and the correct include paths configured. Once a demo application is\nbuilding and executing you can remove the demo application files, and start to\nadd in your own application source files.  See the\n[FreeRTOS Kernel Quick Start Guide](https://www.freertos.org/Documentation/01-FreeRTOS-quick-start/01-Beginners-guide/02-Quick-start-guide)\nfor detailed instructions and other useful links.\n\nAdditionally, for FreeRTOS kernel feature information refer to the\n[Developer Documentation](https://www.freertos.org/Documentation/02-Kernel/02-Kernel-features/00-Developer-docs),\nand [API Reference](https://www.freertos.org/Documentation/02-Kernel/04-API-references/01-Task-creation/00-TaskHandle).\n\nAlso for contributing and creating a Pull Request please refer to\n[the instructions here](.github/CONTRIBUTING.md#contributing-via-pull-request).\n\n**FreeRTOS-Kernel V11.1.0\n[source code](https://github.com/FreeRTOS/FreeRTOS-Kernel/tree/V11.1.0) is part\nof the\n[FreeRTOS 202406.00 LTS](https://github.com/FreeRTOS/FreeRTOS-LTS/tree/202406-LTS)\nrelease.**\n\n### Getting help\n\nIf you have any questions or need assistance troubleshooting your FreeRTOS project,\nwe have an active community that can help on the\n[FreeRTOS Community Support Forum](https://forums.freertos.org).\n\n## To consume FreeRTOS-Kernel\n\n### Consume with CMake\n\nIf using CMake, it is recommended to use this repository using FetchContent.\nAdd the following into your project's main or a subdirectory's `CMakeLists.txt`:\n\n- Define the source and version/tag you want to use:\n\n```cmake\nFetchContent_Declare( freertos_kernel\n  GIT_REPOSITORY https://github.com/FreeRTOS/FreeRTOS-Kernel.git\n  GIT_TAG        main #Note: Best practice to use specific git-hash or tagged version\n)\n```\n\nIn case you prefer to add it as a git submodule, do:\n\n```bash\ngit submodule add https://github.com/FreeRTOS/FreeRTOS-Kernel.git <path of the submodule>\ngit submodule update --init\n```\n\n- Add a freertos_config library (typically an INTERFACE library) The following assumes the directory structure:\n  - `include/FreeRTOSConfig.h`\n\n```cmake\nadd_library(freertos_config INTERFACE)\n\ntarget_include_directories(freertos_config SYSTEM\nINTERFACE\n    include\n)\n\ntarget_compile_definitions(freertos_config\n  INTERFACE\n    projCOVERAGE_TEST=0\n)\n```\n\nIn case you installed FreeRTOS-Kernel as a submodule, you will have to add it as a subdirectory:\n\n```cmake\nadd_subdirectory(${FREERTOS_PATH})\n```\n\n- Configure the FreeRTOS-Kernel and make it available\n  - this particular example supports a native and cross-compiled build option.\n\n```cmake\nset( FREERTOS_HEAP \"4\" CACHE STRING \"\" FORCE)\n# Select the native compile PORT\nset( FREERTOS_PORT \"GCC_POSIX\" CACHE STRING \"\" FORCE)\n# Select the cross-compile PORT\nif (CMAKE_CROSSCOMPILING)\n  set(FREERTOS_PORT \"GCC_ARM_CA9\" CACHE STRING \"\" FORCE)\nendif()\n\nFetchContent_MakeAvailable(freertos_kernel)\n```\n\n- In case of cross compilation, you should also add the following to `freertos_config`:\n\n```cmake\ntarget_compile_definitions(freertos_config INTERFACE ${definitions})\ntarget_compile_options(freertos_config INTERFACE ${options})\n```\n\n### Consuming stand-alone - Cloning this repository\n\nTo clone using HTTPS:\n\n```\ngit clone https://github.com/FreeRTOS/FreeRTOS-Kernel.git\n```\n\nUsing SSH:\n\n```\ngit clone git@github.com:FreeRTOS/FreeRTOS-Kernel.git\n```\n\n## Repository structure\n\n- The root of this repository contains the three files that are common to\nevery port - list.c, queue.c and tasks.c.  The kernel is contained within these\nthree files.  croutine.c implements the optional co-routine functionality - which\nis normally only used on very memory limited systems.\n\n- The ```./portable``` directory contains the files that are specific to a particular microcontroller and/or compiler.\nSee the readme file in the ```./portable``` directory for more information.\n\n- The ```./include``` directory contains the real time kernel header files.\n\n- The ```./template_configuration``` directory contains a sample `FreeRTOSConfig.h` to help jumpstart a new project.\nSee the [FreeRTOSConfig.h](examples/template_configuration/FreeRTOSConfig.h) file for instructions.\n\n### Code Formatting\n\nFreeRTOS files are formatted using the\n\"[uncrustify](https://github.com/uncrustify/uncrustify)\" tool.\nThe configuration file used by uncrustify can be found in the\n[FreeRTOS/CI-CD-GitHub-Actions's](https://github.com/FreeRTOS/CI-CD-Github-Actions)\n[uncrustify.cfg](https://github.com/FreeRTOS/CI-CD-Github-Actions/tree/main/formatting)\nfile.\n\n### Line Endings\n\nFile checked into the FreeRTOS-Kernel repository use unix-style LF line endings\nfor the best compatibility with git.\n\nFor optimal compatibility with Microsoft Windows tools, it is best to enable\nthe git autocrlf feature. You can enable this setting for the current\nrepository using the following command:\n\n```\ngit config core.autocrlf true\n```\n\n### Git History Optimizations\n\nSome commits in this repository perform large refactors which touch many lines\nand lead to unwanted behavior when using the `git blame` command. You can\nconfigure git to ignore the list of large refactor commits in this repository\nwith the following command:\n\n```\ngit config blame.ignoreRevsFile .git-blame-ignore-revs\n```\n\n### Spelling and Formatting\n\nWe recommend using [Visual Studio Code](https://code.visualstudio.com),\ncommonly referred to as VSCode, when working on the FreeRTOS-Kernel.\nThe FreeRTOS-Kernel also uses [cSpell](https://cspell.org/) as part of its\nspelling check. The config file for which can be found at [cspell.config.yaml](cspell.config.yaml)\nThere is additionally a\n[cSpell plugin for VSCode](https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker)\nthat can be used as well.\n*[.cSpellWords.txt](.github/.cSpellWords.txt)* contains words that are not\ntraditionally found in an English dictionary. It is used by the spellchecker\nto verify the various jargon, variable names, and other odd words used in the\nFreeRTOS code base are correct. If your pull request fails to pass the spelling\nand you believe this is a mistake, then add the word to\n*[.cSpellWords.txt](.github/.cSpellWords.txt)*. When adding a word please\nthen sort the list, which can be done by running the bash command:\n`sort -u .cSpellWords.txt -o .cSpellWords.txt`\nNote that only the FreeRTOS-Kernel Source Files, [include](include),\n[portable/MemMang](portable/MemMang), and [portable/Common](portable/Common)\nfiles are checked for proper spelling, and formatting at this time.\n\n## Third Party Tools\nVisit [this link](.github/third_party_tools.md) for detailed information about\nthird-party tools with FreeRTOS support.\n",
      "stars_today": 6
    },
    {
      "id": 108035205,
      "name": "purchases-ios",
      "full_name": "RevenueCat/purchases-ios",
      "description": "In-app purchases and subscriptions made easy. Support for iOS, watchOS, tvOS, macOS, and visionOS.",
      "html_url": "https://github.com/RevenueCat/purchases-ios",
      "stars": 2902,
      "forks": 411,
      "language": "Swift",
      "topics": [
        "apple",
        "hacktoberfest",
        "iap",
        "ios",
        "objective-c",
        "storekit",
        "storekit-wrapper",
        "storekit2",
        "swift",
        "swiftui",
        "visionos"
      ],
      "created_at": "2017-10-23T20:23:47Z",
      "updated_at": "2026-01-15T22:13:14Z",
      "pushed_at": "2026-01-15T19:41:09Z",
      "open_issues": 138,
      "owner": {
        "login": "RevenueCat",
        "avatar_url": "https://avatars.githubusercontent.com/u/33013347?v=4"
      },
      "readme": "<h3 align=\"center\">ğŸ˜» In-App Subscriptions Made Easy ğŸ˜»</h3>\n\n[![License](https://img.shields.io/cocoapods/l/RevenueCat.svg?style=flat)](http://cocoapods.org/pods/RevenueCat)\n[![Version](https://img.shields.io/cocoapods/v/RevenueCat.svg?style=flat)](https://cocoapods.org/pods/RevenueCat)\n[![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://docs.revenuecat.com/docs/ios#section-install-via-carthage)\n[![SwiftPM compatible](https://img.shields.io/badge/SwiftPM-compatible-orange.svg)](https://docs.revenuecat.com/docs/ios#section-install-via-swift-package-manager)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2FRevenueCat%2Fpurchases-ios%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/RevenueCat/purchases-ios)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2FRevenueCat%2Fpurchases-ios%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/RevenueCat/purchases-ios)\n\nRevenueCat is a powerful, reliable, and free to use in-app purchase server with cross-platform support. Our open-source framework provides a backend and a wrapper around StoreKit and Google Play Billing to make implementing in-app purchases and subscriptions easy. \n\nWhether you are building a new app or already have millions of customers, you can use RevenueCat to:\n\n  * Fetch products, make purchases, and check subscription status with our [native SDKs](https://docs.revenuecat.com/docs/installation). \n  * Host and [configure products](https://docs.revenuecat.com/docs/entitlements) remotely from our dashboard. \n  * Analyze the most important metrics for your app business [in one place](https://docs.revenuecat.com/docs/charts).\n  * See customer transaction histories, chart lifetime value, and [grant promotional subscriptions](https://www.revenuecat.com/docs/dashboard-and-metrics/customer-history/promotionals).\n  * Get notified of real-time events through [webhooks](https://docs.revenuecat.com/docs/webhooks).\n  * Send enriched purchase events to analytics and attribution tools with our easy integrations.\n\nSign up to [get started for free](https://app.revenuecat.com/signup).\n\n## RevenueCat.framework\n\n*RevenueCat* is the client for the [RevenueCat](https://www.revenuecat.com/) subscription and purchase tracking system. It's 100% `Swift` and compatible with `Objective-C`.\n\n## Migrating from Purchases v4 to v5\n- See our [Migration guide](https://revenuecat.github.io/purchases-ios-docs/v5_api_migration_guide.html)\n\n## Migrating from Purchases v3 to v4\n- See our [Migration guide](https://revenuecat.github.io/purchases-ios-docs/v4_api_migration_guide.html)\n\n## RevenueCat SDK Features\n|   | RevenueCat |\n| --- | --- |\nâœ… | Server-side receipt validation\nâ¡ï¸ | [Webhooks](https://docs.revenuecat.com/docs/webhooks) - enhanced server-to-server communication with events for purchases, renewals, cancellations, and more\nğŸ–¥ | iOS, tvOS, macOS, watchOS, Mac Catalyst, and visionOS support\nğŸ¯ | Subscription status tracking - know whether a user is subscribed whether they're on iOS, Android or web\nğŸ“Š | Analytics - automatic calculation of metrics like conversion, mrr, and churn\nğŸ“ | [Online documentation](https://docs.revenuecat.com/docs) and [SDK Reference](http://revenuecat.github.io/purchases-ios-docs/) up to date\nğŸ”€ | [Integrations](https://www.revenuecat.com/integrations) - over a dozen integrations to easily send purchase data where you need it\nğŸ’¯ | Well maintained - [frequent releases](https://github.com/RevenueCat/purchases-ios/releases)\nğŸ“® | Great support - [Contact us](https://revenuecat.com/support)\n\n## Getting Started\nFor more detailed information, you can view our complete documentation at [docs.revenuecat.com](https://docs.revenuecat.com/docs).\n\nPlease follow the [Quickstart Guide](https://docs.revenuecat.com/docs/) for more information on how to install the SDK.\n\n> [!TIP]\n> When integrating with SPM, it is recommended to add the SPM mirror repository for faster download/integration times: https://github.com/RevenueCat/purchases-ios-spm\n\nOr view our iOS sample apps:\n- [MagicWeather](Examples/MagicWeather)\n- [MagicWeather SwiftUI](Examples/MagicWeatherSwiftUI)\n\n## Requirements\n- Xcode 15.0+\n\n| Platform | Minimum target |\n|----------|----------------|\n| iOS      | 13.0+          |\n| tvOS     | 13.0+          |\n| macOS    | 10.15+         |\n| watchOS  | 6.2+           |\n| visionOS | 1.0+           |\n\n## SDK Reference\nOur full SDK reference [can be found here](https://revenuecat.github.io/purchases-ios-docs).\n\n## Contributing\nContributions are always welcome! To learn how you can contribute, please see the [Contributing Guide](./Contributing/CONTRIBUTING.md).\n",
      "stars_today": 6
    },
    {
      "id": 16587283,
      "name": "xgboost",
      "full_name": "dmlc/xgboost",
      "description": "Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library,  for Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Dask, Flink and DataFlow",
      "html_url": "https://github.com/dmlc/xgboost",
      "stars": 27858,
      "forks": 8832,
      "language": "C++",
      "topics": [
        "distributed-systems",
        "gbdt",
        "gbm",
        "gbrt",
        "machine-learning",
        "xgboost"
      ],
      "created_at": "2014-02-06T17:28:03Z",
      "updated_at": "2026-01-15T21:02:18Z",
      "pushed_at": "2026-01-15T19:01:33Z",
      "open_issues": 494,
      "owner": {
        "login": "dmlc",
        "avatar_url": "https://avatars.githubusercontent.com/u/11508361?v=4"
      },
      "readme": "<img src=\"https://xgboost.ai/images/logo/xgboost-logo-trimmed.png\" width=200/> eXtreme Gradient Boosting\n===========\n\n[![XGBoost-CI](https://github.com/dmlc/xgboost/workflows/XGBoost%20CI/badge.svg?branch=master)](https://github.com/dmlc/xgboost/actions)\n[![Documentation Status](https://readthedocs.org/projects/xgboost/badge/?version=latest)](https://xgboost.readthedocs.org)\n[![GitHub license](https://dmlc.github.io/img/apache2.svg)](./LICENSE)\n[![CRAN Status Badge](https://www.r-pkg.org/badges/version/xgboost)](https://cran.r-project.org/web/packages/xgboost)\n[![PyPI version](https://badge.fury.io/py/xgboost.svg)](https://pypi.python.org/pypi/xgboost/)\n[![Conda version](https://img.shields.io/conda/vn/conda-forge/py-xgboost.svg)](https://anaconda.org/conda-forge/py-xgboost)\n[![Optuna](https://img.shields.io/badge/Optuna-integrated-blue)](https://optuna.org)\n[![Twitter](https://img.shields.io/badge/@XGBoostProject--_.svg?style=social&logo=twitter)](https://twitter.com/XGBoostProject)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/dmlc/xgboost/badge)](https://api.securityscorecards.dev/projects/github.com/dmlc/xgboost)\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/comet-examples/blob/master/integrations/model-training/xgboost/notebooks/how_to_use_comet_with_xgboost_tutorial.ipynb)\n\n[Community](https://xgboost.ai/community) |\n[Documentation](https://xgboost.readthedocs.org) |\n[Resources](demo/README.md) |\n[Contributors](CONTRIBUTORS.md) |\n[Release Notes](https://xgboost.readthedocs.io/en/latest/changes/index.html)\n\nXGBoost is an optimized distributed gradient boosting library designed to be highly ***efficient***, ***flexible*** and ***portable***.\nIt implements machine learning algorithms under the [Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting) framework.\nXGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way.\nThe same code runs on major distributed environment (Kubernetes, Hadoop, SGE, Dask, Spark, PySpark) and can solve problems beyond billions of examples.\n\nLicense\n-------\nÂ© Contributors, 2021. Licensed under an [Apache-2](https://github.com/dmlc/xgboost/blob/master/LICENSE) license.\n\nContribute to XGBoost\n---------------------\nXGBoost has been developed and used by a group of active community members. Your help is very valuable to make the package better for everyone.\nCheckout the [Community Page](https://xgboost.ai/community).\n\nReference\n---------\n- Tianqi Chen and Carlos Guestrin. [XGBoost: A Scalable Tree Boosting System](https://arxiv.org/abs/1603.02754). In 22nd SIGKDD Conference on Knowledge Discovery and Data Mining, 2016\n- XGBoost originates from research project at University of Washington.\n\nSponsors\n--------\nBecome a sponsor and get a logo here. See details at [Sponsoring the XGBoost Project](https://xgboost.ai/sponsors). The funds are used to defray the cost of continuous integration and testing infrastructure (https://xgboost-ci.net).\n\n## Open Source Collective sponsors\n[![Backers on Open Collective](https://opencollective.com/xgboost/backers/badge.svg)](#backers) [![Sponsors on Open Collective](https://opencollective.com/xgboost/sponsors/badge.svg)](#sponsors)\n\n### Sponsors\n[[Become a sponsor](https://opencollective.com/xgboost#sponsor)]\n\n<a href=\"https://www.nvidia.com/en-us/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/xgboost-ai/xgboost-ai.github.io/master/images/sponsors/nvidia.jpg\" alt=\"NVIDIA\" width=\"72\" height=\"72\"></a>\n<a href=\"https://www.comet.com/site/?utm_source=xgboost&utm_medium=github&utm_content=readme\" target=\"_blank\"><img src=\"https://cdn.comet.ml/img/notebook_logo.png\" height=\"72\"></a>\n<a href=\"https://opencollective.com/tomislav1\" target=\"_blank\"><img src=\"https://images.opencollective.com/tomislav1/avatar/256.png\" height=\"72\"></a>\n<a href=\"https://databento.com/?utm_source=xgboost&utm_medium=sponsor&utm_content=display\"><img src=\"https://raw.githubusercontent.com/xgboost-ai/xgboost-ai.github.io/refs/heads/master/images/sponsors/databento.png\" height=\"72\"></a>\n<a href=\"https://www.intel.com/\" target=\"_blank\"><img src=\"https://images.opencollective.com/intel-corporation/2fa85c1/logo/256.png\" width=\"72\" height=\"72\"></a>\n\n### Backers\n[[Become a backer](https://opencollective.com/xgboost#backer)]\n\n<a href=\"https://opencollective.com/xgboost#backers\" target=\"_blank\"><img src=\"https://opencollective.com/xgboost/backers.svg?width=890\"></a>\n",
      "stars_today": 5
    },
    {
      "id": 32538871,
      "name": "gson",
      "full_name": "google/gson",
      "description": "A Java serialization/deserialization library to convert Java Objects into JSON and back",
      "html_url": "https://github.com/google/gson",
      "stars": 24308,
      "forks": 4377,
      "language": "Java",
      "topics": [],
      "created_at": "2015-03-19T18:21:20Z",
      "updated_at": "2026-01-15T17:45:27Z",
      "pushed_at": "2026-01-12T14:45:55Z",
      "open_issues": 333,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# Gson\n\nGson is a Java library that can be used to convert Java Objects into their JSON representation. It can also be used to convert a JSON string to an equivalent Java object.\nGson can work with arbitrary Java objects including pre-existing objects that you do not have source-code of.\n\nThere are a few open-source projects that can convert Java objects to JSON. However, most of them require that you place Java annotations in your classes; something that you can not do if you do not have access to the source-code. Most also do not fully support the use of Java Generics. Gson considers both of these as very important design goals.\n\n> [!NOTE]\\\n> Gson is currently in maintenance mode; existing bugs will be fixed, but large new features will likely not be added. If you want to add a new feature, please first search for existing GitHub issues, or create a new one to discuss the feature and get feedback.\n\n> [!IMPORTANT]\\\n> Gson's main focus is on Java. Using it with other JVM languages such as Kotlin or Scala might work fine in many cases, but language-specific features such as Kotlin's non-`null` types or constructors with default arguments are not supported. This can lead to confusing and incorrect behavior.\\\n> When using languages other than Java, prefer a JSON library with explicit support for that language.\n\n> [!IMPORTANT]\\\n> Gson is not a recommended library for interacting with JSON on Android. The open-ended reflection in the Gson runtime doesn't play nicely with shrinking/optimization/obfuscation passes that Android release apps should perform.\\\n> If your app or library may be running on Android, consider using [Kotlin Serialization](https://github.com/Kotlin/kotlinx.serialization/blob/master/docs/basic-serialization.md#basics) or [Moshi's Codegen](https://github.com/square/moshi?tab=readme-ov-file#codegen),\n> which use code generation instead of reflection. This avoids Gson's runtime crashes when optimizations are applied (usually due to the fields missing or being obfuscated), and results in faster performance on Android devices.\n> The Moshi APIs may be more familiar to users who already know Gson.\n> If you still want to use Gson and attempt to avoid these crashes, you can see how to do so [here](Troubleshooting.md#proguard-r8).\n\n### Goals\n  * Provide simple `toJson()` and `fromJson()` methods to convert Java objects to JSON and vice-versa\n  * Allow pre-existing unmodifiable objects to be converted to and from JSON\n  * Extensive support of Java Generics\n  * Allow custom representations for objects\n  * Support arbitrarily complex objects (with deep inheritance hierarchies and extensive use of generic types)\n\n### Download\n\nGradle:\n```gradle\ndependencies {\n  implementation 'com.google.code.gson:gson:2.13.2'\n}\n```\n\nMaven:\n```xml\n<dependency>\n  <groupId>com.google.code.gson</groupId>\n  <artifactId>gson</artifactId>\n  <version>2.13.2</version>\n</dependency>\n```\n\n[Gson jar downloads](https://maven-badges.herokuapp.com/maven-central/com.google.code.gson/gson) are available from Maven Central.\n\n![Build Status](https://github.com/google/gson/actions/workflows/build.yml/badge.svg)\n\n### Requirements\n#### Minimum Java version\n- Gson 2.12.0 and newer: Java 8\n- Gson 2.9.0 to 2.11.0: Java 7\n- Gson 2.8.9 and older: Java 6\n\nDespite supporting older Java versions, Gson also provides a JPMS module descriptor (module name `com.google.gson`) for users of Java 9 or newer.\n\n#### JPMS dependencies (Java 9+)\nThese are the optional Java Platform Module System (JPMS) JDK modules which Gson depends on.\nThis only applies when running Java 9 or newer.\n\n- `java.sql` (optional since Gson 2.8.9)\\\nWhen this module is present, Gson provides default adapters for some SQL date and time classes.\n\n- `jdk.unsupported`, respectively class `sun.misc.Unsafe` (optional)\\\nWhen this module is present, Gson can use the `Unsafe` class to create instances of classes without no-args constructor.\nHowever, care should be taken when relying on this. `Unsafe` is not available in all environments and its usage has some pitfalls,\nsee [`GsonBuilder.disableJdkUnsafe()`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()).\n\n#### Minimum Android API level\n\n- Gson 2.11.0 and newer: API level 21\n- Gson 2.10.1 and older: API level 19\n\nOlder Gson versions may also support lower API levels, however this has not been verified.\n\n### Documentation\n  * [API Javadoc](https://www.javadoc.io/doc/com.google.code.gson/gson): Documentation for the current release\n  * [User guide](UserGuide.md): This guide contains examples on how to use Gson in your code\n  * [Troubleshooting guide](Troubleshooting.md): Describes how to solve common issues when using Gson\n  * [Releases and change log](https://github.com/google/gson/releases): Latest releases and changes in these versions; for older releases see [`CHANGELOG.md`](CHANGELOG.md)\n  * [Design document](GsonDesignDocument.md): This document discusses issues we faced while designing Gson. It also includes a comparison of Gson with other Java libraries that can be used for Json conversion\n\nPlease use the ['gson' tag on StackOverflow](https://stackoverflow.com/questions/tagged/gson), [GitHub Discussions](https://github.com/google/gson/discussions) or the [google-gson Google group](https://groups.google.com/group/google-gson) to discuss Gson or to post questions.\n\n### ProGuard / R8\n\nSee the details in the related section in the [Troubleshooting guide](Troubleshooting.md#proguard-r8).\n\n### Related Content Created by Third Parties\n  * [Gson Tutorial](https://www.studytrails.com/java/json/java-google-json-introduction/) by `StudyTrails`\n  * [Gson Tutorial Series](https://futurestud.io/tutorials/gson-getting-started-with-java-json-serialization-deserialization) by `Future Studio`\n  * [Gson API Report](https://abi-laboratory.pro/java/tracker/timeline/gson/)\n\n### Building\n\nGson uses Maven to build the project:\n```\nmvn clean verify\n```\n\nJDK 17 or newer is required for building, JDK 21 is recommended. Newer JDKs are currently not supported for building (but are supported when _using_ Gson).\n\n### Contributing\n\nSee the [contributing guide](https://github.com/google/.github/blob/master/CONTRIBUTING.md).\\\nPlease perform a quick search to check if there are already existing issues or pull requests related to your contribution.\n\nKeep in mind that Gson is in maintenance mode. If you want to add a new feature, please first search for existing GitHub issues, or create a new one to discuss the feature and get feedback.\n\n### License\n\nGson is released under the [Apache 2.0 license](LICENSE).\n\n```\nCopyright 2008 Google Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n### Disclaimer\n\nThis is not an officially supported Google product.\n",
      "stars_today": 5
    },
    {
      "id": 293498508,
      "name": "compose-multiplatform",
      "full_name": "JetBrains/compose-multiplatform",
      "description": "Compose Multiplatform, a modern UI framework for Kotlin that makes building performant and beautiful user interfaces easy and enjoyable.",
      "html_url": "https://github.com/JetBrains/compose-multiplatform",
      "stars": 18713,
      "forks": 1372,
      "language": "Kotlin",
      "topics": [
        "android",
        "awt",
        "compose",
        "declarative-ui",
        "desktop",
        "gui",
        "ios",
        "javascript",
        "kotlin",
        "multiplatform",
        "reactive",
        "swing",
        "ui",
        "wasm",
        "web",
        "webassembly"
      ],
      "created_at": "2020-09-07T10:40:49Z",
      "updated_at": "2026-01-15T18:35:34Z",
      "pushed_at": "2026-01-15T09:53:28Z",
      "open_issues": 68,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "[![official project](http://jb.gg/badges/official.svg)](https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub)\n[![stable](https://img.shields.io/github/v/release/JetBrains/compose-multiplatform?sort=semver&display_name=release&label=stable&color=brightgreen)](https://github.com/JetBrains/compose-multiplatform/releases/latest)\n[![prerelease](https://img.shields.io/github/v/release/JetBrains/compose-multiplatform?include_prereleases&sort=semver&filter=*-*&display_name=release&label=prerelease&color=blue)](https://github.com/JetBrains/compose-multiplatform/releases)\n[![dev](https://img.shields.io/github/v/tag/JetBrains/compose-multiplatform?include_prereleases&sort=semver&filter=v*%2Bdev*&label=dev&color=orange)](https://github.com/JetBrains/compose-multiplatform/tags)\n\n<a href=\"https://jb.gg/cmp\">\n    <picture>\n        <source srcset=\"artwork/compose-logo-name-white.svg\"  width=\"400\" media=\"(prefers-color-scheme: dark)\">\n        <img src=\"artwork/compose-logo-name-black.svg\" alt=\"Compose Multiplatform logo and name\" width=\"400\">\n    </picture>\n</a>\n\n[Compose Multiplatform](https://jb.gg/cmp) is a declarative framework for sharing UI code across multiple platforms with Kotlin. \nIt is based on [Jetpack Compose](https://developer.android.com/jetpack/compose) and developed by [JetBrains](https://www.jetbrains.com/) and open-source contributors.\n\nYou can choose the platforms across which to share your UI code using Compose Multiplatform:\n\n* [iOS](https://jb.gg/start-cmp)\n* [Android](https://jb.gg/start-cmp) \n* [Desktop](https://jb.gg/start-cmp) (Windows, MacOS, and Linux)\n* [Web](https://jb.gg/start-cmp) (Beta)\n\nFor example, you can share UIs between iOS and Android or Windows and MacOS.\n\n![Shared UIs of the iOS, Android, desktop, and web apps](artwork/readme/apps.png)\n\n## iOS\n\nCompose Multiplatform shares most of its API with Jetpack Compose, the Android UI framework developed by Google. \nYou can use the same APIs to build user interfaces for both Android and iOS.\n\nSince Compose is built on top of [Kotlin Multiplatform](https://jb.gg/kmp), \nyou can easily access native APIs, such as the [Camera API](https://developer.apple.com/documentation/avfoundation/capture_setup/avcam_building_a_camera_app), \nand embed complex native UI views, such as [MKMapView](https://developer.apple.com/documentation/mapkit/mkmapview).\n\n**[Get started with Compose Multiplatform](https://jb.gg/start-cmp)**\n\n## Android\n\nWhen Android is one of your targets, you get the same experience for Android as if you were developing an Android app \nusing [Jetpack Compose](https://developer.android.com/jetpack/compose).\n\n**[Get started with Compose Multiplatform](https://jb.gg/start-cmp)**\n\n## Desktop\n\nCompose Multiplatform targets the JVM and supports high-performance hardware-accelerated UI rendering on all major desktop\nplatforms â€“ macOS, Windows, and Linux.\n\nIt has desktop extensions for menus, keyboard shortcuts, window manipulation, and notification management.\n\n**[Get started with Compose Multiplatform](https://jb.gg/start-cmp)**\n\n## Web\n\n> Web support is in Beta, making it a great time to give it a try. Check out our [blog post](https://blog.jetbrains.com/kotlin/2025/09/compose-multiplatform-1-9-0-compose-for-web-beta/) to learn more about the progress made to reach this milestone.\n> We would appreciate your feedback on it in the public Slack channel [#compose-web](https://kotlinlang.slack.com/archives/C01F2HV7868/p1678887590205449). \n> If you face any issues, please report them on [YouTrack](https://youtrack.jetbrains.com/newIssue?project=CMP).\n\nYou can experiment with sharing your mobile or desktop UIs with the web. Compose Multiplatform for web is based on [Kotlin/Wasm](https://kotl.in/wasm), \nthe newest target for Kotlin Multiplatform projects. It allows Kotlin developers to run their code in the browser with \nall the benefits that WebAssembly has to offer, such as good and predictable performance for your applications.\n\n**[Get started with Compose Multiplatform for web](https://jb.gg/start-cmp)**\n\n## Libraries\n\n### Compose HTML\n\nCompose HTML is a library targeting [Kotlin/JS](https://kotlinlang.org/docs/js-overview.html) that provides Composable building blocks \nfor creating web user interfaces with HTML and CSS.    \n\n> Note that Compose HTML is not a multiplatform library. It can be used only with Kotlin/JS.\n\n## Learn more\n\n* [FAQ](https://jb.gg/cmp-faq)\n* [Samples](https://jb.gg/cmp-samples)\n* [Tutorials](tutorials/README.md)\n* [Compatibility and versioning](https://jb.gg/cmp-versioning)\n* [Changelog](CHANGELOG.md)\n* [Contibution guide](CONTRIBUTING.md)\n\n## Get help\n\nThere are dedicated public Slack channels for [#compose-ios](https://kotlinlang.slack.com/archives/C0346LWVBJ4/p1678888063176359), [#compose-desktop](https://kotlinlang.slack.com/archives/C01D6HTPATV) and [#compose-web](https://kotlinlang.slack.com/archives/C01F2HV7868/p1678887590205449), as well as the general [#compose](https://kotlinlang.slack.com/archives/CJLTWPH7S) channel.\n\nIf you encounter any issues, please report them on [YouTrack](https://youtrack.jetbrains.com/newIssue?project=CMP).\n\n",
      "stars_today": 5
    },
    {
      "id": 75413130,
      "name": "Open3D",
      "full_name": "isl-org/Open3D",
      "description": "Open3D: A Modern Library for 3D Data Processing",
      "html_url": "https://github.com/isl-org/Open3D",
      "stars": 13220,
      "forks": 2517,
      "language": "C++",
      "topics": [
        "3d",
        "3d-perception",
        "arm",
        "computer-graphics",
        "cpp",
        "cuda",
        "gpu",
        "gui",
        "machine-learning",
        "mesh-processing",
        "odometry",
        "opengl",
        "pointcloud",
        "python",
        "pytorch",
        "reconstruction",
        "registration",
        "rendering",
        "tensorflow",
        "visualization"
      ],
      "created_at": "2016-12-02T16:40:38Z",
      "updated_at": "2026-01-15T15:16:00Z",
      "pushed_at": "2026-01-15T23:44:18Z",
      "open_issues": 1327,
      "owner": {
        "login": "isl-org",
        "avatar_url": "https://avatars.githubusercontent.com/u/23507030?v=4"
      },
      "readme": "<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/isl-org/Open3D/main/docs/_static/open3d_logo_horizontal.png\" width=\"320\" />\n</p>\n\n# Open3D: A Modern Library for 3D Data Processing\n\n<h4>\n    <a href=\"https://www.open3d.org\">Homepage</a> |\n    <a href=\"https://www.open3d.org/docs\">Docs</a> |\n    <a href=\"https://www.open3d.org/docs/release/getting_started.html\">Quick Start</a> |\n    <a href=\"https://www.open3d.org/docs/release/compilation.html\">Compile</a> |\n    <a href=\"https://www.open3d.org/docs/release/index.html#python-api-index\">Python</a> |\n    <a href=\"https://www.open3d.org/docs/release/cpp_api.html\">C++</a> |\n    <a href=\"https://github.com/isl-org/Open3D-ML\">Open3D-ML</a> |\n    <a href=\"https://github.com/isl-org/Open3D/releases\">Viewer</a> |\n    <a href=\"https://www.open3d.org/docs/release/contribute/contribute.html\">Contribute</a> |\n    <a href=\"https://www.youtube.com/channel/UCRJBlASPfPBtPXJSPffJV-w\">Demo</a> |\n    <a href=\"https://github.com/isl-org/Open3D/discussions\">Forum</a>\n</h4>\n\nOpen3D is an open-source library that supports rapid development of software\nthat deals with 3D data. The Open3D frontend exposes a set of carefully selected\ndata structures and algorithms in both C++ and Python. The backend is highly\noptimized and is set up for parallelization. We welcome contributions from\nthe open-source community.\n\n[![Ubuntu CI](https://github.com/isl-org/Open3D/actions/workflows/ubuntu.yml/badge.svg)](https://github.com/isl-org/Open3D/actions?query=workflow%3A%22Ubuntu+CI%22)\n[![macOS CI](https://github.com/isl-org/Open3D/actions/workflows/macos.yml/badge.svg)](https://github.com/isl-org/Open3D/actions?query=workflow%3A%22macOS+CI%22)\n[![Windows CI](https://github.com/isl-org/Open3D/actions/workflows/windows.yml/badge.svg)](https://github.com/isl-org/Open3D/actions?query=workflow%3A%22Windows+CI%22)\n\n**Core features of Open3D include:**\n\n-   3D data structures\n-   3D data processing algorithms\n-   Scene reconstruction\n-   Surface alignment\n-   3D visualization\n-   Physically based rendering (PBR)\n-   3D machine learning support with PyTorch and TensorFlow\n-   GPU acceleration for core 3D operations\n-   Available in C++ and Python\n\nHere's a brief overview of the different components of Open3D and how they fit\ntogether to enable full end to end pipelines:\n\n![Open3D_layers](https://github.com/isl-org/Open3D/assets/41028320/e9b8645a-a823-4d78-8310-e85207bbc3e4)\n\nFor more, please visit the [Open3D documentation](https://www.open3d.org/docs).\n\nAlso checkout this great introduction to modern 3D data processing that features\nOpen3D:\n\n<img src=\"https://learning.oreilly.com/covers/urn:orm:book:9781098161323/400w/\" width=\"240\" alt=\"3D Data Science with Python\" />\n\n[3D Data Science with Python](https://learning.oreilly.com/library/view/3d-data-science/9781098161323/)\nby [Dr. Florent Poux](https://www.graphics.rwth-aachen.de/person/306/)\n\nFrom the author:\n\n> Throughout the book, I showcase how Open3D enables efficient point cloud\n> processing, mesh manipulation, and 3D visualization through practical examples\n> and code samples. Readers learn to leverage Open3D's powerful capabilities for\n> registration, segmentation, and feature extraction in real-world 3D data\n> science workflows.\n\n## Python quick start\n\nPre-built pip packages support Ubuntu 20.04+, macOS 10.15+ and Windows 10+\n(64-bit) with Python 3.8-3.11.\n\n```bash\n# Install\npip install open3d       # or\npip install open3d-cpu   # Smaller CPU only wheel on x86_64 Linux (v0.17+)\n\n# Verify installation\npython -c \"import open3d as o3d; print(o3d.__version__)\"\n\n# Python API\npython -c \"import open3d as o3d; \\\n           mesh = o3d.geometry.TriangleMesh.create_sphere(); \\\n           mesh.compute_vertex_normals(); \\\n           o3d.visualization.draw(mesh, raw_mode=True)\"\n\n# Open3D CLI\nopen3d example visualization/draw\n```\n\nTo get the latest features in Open3D, install the\n[development pip package](https://www.open3d.org/docs/latest/getting_started.html#development-version-pip).\nTo compile Open3D from source, refer to\n[compiling from source](https://www.open3d.org/docs/release/compilation.html).\n\n## C++ quick start\n\nCheckout the following links to get started with Open3D C++ API\n\n-   Download Open3D binary package: [Release](https://github.com/isl-org/Open3D/releases) or [latest development version](https://www.open3d.org/docs/latest/getting_started.html#c)\n-   [Compiling Open3D from source](https://www.open3d.org/docs/release/compilation.html)\n-   [Open3D C++ API](https://www.open3d.org/docs/release/cpp_api.html)\n\nTo use Open3D in your C++ project, checkout the following examples\n\n-   [Find Pre-Installed Open3D Package in CMake](https://github.com/isl-org/open3d-cmake-find-package)\n-   [Use Open3D as a CMake External Project](https://github.com/isl-org/open3d-cmake-external-project)\n\n## Open3D-Viewer app\n\n<img width=\"480\" src=\"https://raw.githubusercontent.com/isl-org/Open3D/main/docs/_static/open3d_viewer.png\">\n\nOpen3D-Viewer is a standalone 3D viewer app available on Debian (Ubuntu), macOS\nand Windows. Download Open3D Viewer from the\n[release page](https://github.com/isl-org/Open3D/releases).\n\n## Open3D-ML\n\n<img width=\"480\" src=\"https://raw.githubusercontent.com/isl-org/Open3D-ML/main/docs/images/getting_started_ml_visualizer.gif\">\n\nOpen3D-ML is an extension of Open3D for 3D machine learning tasks. It builds on\ntop of the Open3D core library and extends it with machine learning tools for\n3D data processing. To try it out, install Open3D with PyTorch or TensorFlow and check out\n[Open3D-ML](https://github.com/isl-org/Open3D-ML).\n\n## Communication channels\n\n-   [GitHub Issue](https://github.com/isl-org/Open3D/issues): bug reports,\n    feature requests, etc.\n-   [Forum](https://github.com/isl-org/Open3D/discussions): discussion on the usage of Open3D.\n-   [Discord Chat](https://discord.gg/D35BGvn): online chats, discussions,\n    and collaboration with other users and developers.\n\n## Citation\n\nPlease cite [our work](https://arxiv.org/abs/1801.09847) if you use Open3D.\n\n```bib\n@article{Zhou2018,\n    author    = {Qian-Yi Zhou and Jaesik Park and Vladlen Koltun},\n    title     = {{Open3D}: {A} Modern Library for {3D} Data Processing},\n    journal   = {arXiv:1801.09847},\n    year      = {2018},\n}\n```\n",
      "stars_today": 5
    },
    {
      "id": 19257422,
      "name": "questdb",
      "full_name": "questdb/questdb",
      "description": "QuestDB is a high performance, open-source, time-series database",
      "html_url": "https://github.com/questdb/questdb",
      "stars": 16570,
      "forks": 1529,
      "language": "Java",
      "topics": [
        "capital-markets",
        "cpp",
        "database",
        "financial-analysis",
        "grafana",
        "java",
        "kdb",
        "low-latency",
        "market-data",
        "olap",
        "parquet",
        "postgresql",
        "questdb",
        "real-time-analytics",
        "simd",
        "sql",
        "tick-data",
        "time-series",
        "time-series-database",
        "tsdb"
      ],
      "created_at": "2014-04-28T23:29:15Z",
      "updated_at": "2026-01-16T00:17:01Z",
      "pushed_at": "2026-01-16T00:18:49Z",
      "open_issues": 801,
      "owner": {
        "login": "questdb",
        "avatar_url": "https://avatars.githubusercontent.com/u/52297642?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://questdb.com/\" target=\"blank\"><img alt=\"QuestDB Logo\" src=\"https://questdb.com/img/questdb-logo-themed.svg\" width=\"305px\"/></a>\n</div>\n<p>&nbsp;</p>\n\n<p align=\"center\">\n  <a href=\"#contribute\">\n    <img src=\"https://img.shields.io/github/contributors/questdb/questdb\" alt=\"QuestDB open source contributors\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  English |\n  <a href=\"./i18n/README.zh-cn.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"./i18n/README.zh-hk.md\">ç¹é«”ä¸­æ–‡</a> |\n  <a href=\"./i18n/README.ar-dz.md\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a> |\n  <a href=\"./i18n/README.it-it.md\">Italiano</a> |\n  <a href=\"./i18n/README.ua-ua.md\">Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°</a> |\n  <a href=\"./i18n/README.es-es.md\">EspaÃ±ol</a> |\n  <a href=\"./i18n/README.pt.md\">PortuguÃªs</a> |\n  <a href=\"./i18n/README.fr-fr.md\">FranÃ§ais</a> |\n  <a href=\"./i18n/README.de-de.md\">Deutsch</a> |\n  <a href=\"./i18n/README.ja-ja.md\">æ—¥æœ¬èª</a> |\n  <a href=\"./i18n/README.ko-kr.md\">í•œêµ­ì–´</a> |\n  <a href=\"./i18n/README.he-il.md\">×¢×‘×¨×™×ª</a> |\n  <a href=\"./i18n/README.nl-nl.md\">Nederlands</a> |\n  <a href=\"./i18n/README.tr-tr.md\">TÃ¼rkÃ§e</a> |\n  <a href=\"./i18n/README.hn-in.md\">à¤¹à¤¿à¤‚à¤¦à¥€</a> |\n  <a href=\"./i18n/README.vi-vn.md\">Tiáº¿ng Viá»‡t</a> |\n  <a href=\"./i18n/README.ms-my.md\">Bahasa Melayu</a>\n</p>\n\n---\n\nQuestDB is an open-source time-series database offering blazingly fast ingestion\nand dynamic, low-latency SQL queries.\n\nQuestDB delivers a multi-tier storage engine (WAL â†’ native â†’ Parquet on object storage), \nand the core engine is implemented in zero-GC Java and C++; QuestDB Enterprise includes additional components in Rust.\n\nWe achieve high performance via a column-oriented storage model, parallelized\nvector execution, SIMD instructions, and low-latency techniques. In addition,\nQuestDB is hardware efficient, with quick setup and operational efficiency.\n\n> Ready to go? Jump to the\n> [Get started](#get-started) section.\n\n<p>&nbsp;</p>\n\n<div align=\"center\">\n  <a href=\"https://demo.questdb.com/\">\n    <img alt=\"QuestDB Web Console showing a SQL statement and query result\" src=\"https://raw.githubusercontent.com/questdb/questdb/master/.github/console.png\" width=\"900\" />\n  </a>\n  <p><em>QuestDB Web Console - click to launch demo</em></p>\n</div>\n\n<p>&nbsp;</p>\n\n## Benefits of QuestDB\n\nFeature highlights include:\n\n- Low-latency, high-throughput ingestion â€” from single events to millions/sec\n- Low-latency SQL with time-series extensions (ASOF JOIN, SAMPLE BY, LATEST ON)\n- SIMD-accelerated, parallel execution\n- Multi-tier storage: WAL â†’ native columnar â†’ Parquet (time-partitioned and time-ordered)\n- Postgres protocol (PGwire) and REST API\n- Materialized views and n-dimensional arrays (incl. 2D arrays for order books)\n- Web console for queries and data management\n- Apache 2.0 open source and open formats â€” no vendor lock-in\n- [Finance functions](https://questdb.com/docs/reference/function/finance/) and [orderbook analytics](https://questdb.com/docs/guides/order-book/)\n\nQuestDB excels with:\n\n- financial market data (tick data, trades, order books, OHLC)\n- Sensor/telemetry data with high data cardinality\n- real-time dashboards and monitoring\n\nAnd why use a time-series database?\n\nBeyond performance and efficiency, with a specialized time-series database, you\ndon't need to worry about:\n\n- out-of-order data\n- deduplication and exactly one semantics\n- Continuous streaming ingest with many concurrent queries\n- streaming data (low latency)\n- volatile and \"bursty\" data\n- adding new columns - change schema \"on the fly\" while streaming data\n\n## Try QuestDB, demo and dashboards\n\nThe [live, public demo](https://demo.questdb.com/) is provisioned with the latest\nQuestDB release and sample datasets:\n\n- Trades: live crypto trades with 30M+ rows per month (OKX exchange)\n- FX order book: live charts with orderbook FX pairs.\n- Trips: 10 years of NYC taxi trips with 1.6 billion rows\n\nWe also have some public, real-time demo dashboards using\nour [Grafana-native](https://questdb.com/docs/third-party-tools/grafana/) plugin:\n\n- [Real-time crypto trades:](https://questdb.com/dashboards/crypto/) executed\n  trades on OKX from more than 20 assets in real time\n- [FX order book:](https://questdb.com/dashboards/FX-orderbook/) live depth/imbalance charts for major FX pairs\n\n### QuestDB performance vs. other databases\n\nQuestDB performs very well in performance benchmarks compared to alternatives.\n\nFor deep dives into internals and performance, see the following blog posts:\n\n- [QuestDB vs InfluxDB](https://questdb.com/blog/2024/02/26/questdb-versus-influxdb/)\n- [QuestDB vs Kdb+](https://questdb.com/compare/questdb-vs-kdb/)\n- [QuestDB vs TimescaleDB](https://questdb.com/blog/timescaledb-vs-questdb-comparison/)\n- [QuestDB vs MongoDB](https://questdb.com/blog/mongodb-time-series-benchmark-review/)\n\nAs always, we encourage you to run your own benchmarks.\n\n<div align=\"center\">\n  <img alt=\"A chart comparing the ingestion rate of QuestDB, InfluxDB and TimescaleDB.\" src=\".github/readme-benchmark.png\" width=\"600\"/>\n</div>\n\n## Get started\n\nUse [Docker](https://www.docker.com/) to start quickly:\n\n```bash\ndocker run -p 9000:9000 -p 9009:9009 -p 8812:8812 questdb/questdb\n```\n\nOr macOS users can use Homebrew:\n\n```bash\nbrew install questdb\nbrew services start questdb\n```\n\n```bash\nquestdb start\nquestdb stop\n```\n\nAlternatively, to kickoff the full onboarding journey, start with our concise\n[quick start guide](https://questdb.com/docs/quick-start/).\n\n### First-party ingestion clients\n\nQuestDB clients for ingesting data via the InfluxDB Line Protocol:\n\n- [Python](https://questdb.com/docs/clients/ingest-python/)\n- [.NET](https://questdb.com/docs/clients/ingest-dotnet/)\n- [C/C++](https://questdb.com/docs/clients/ingest-c-and-cpp/)\n- [Go](https://questdb.com/docs/clients/ingest-go/)\n- [Java](https://questdb.com/docs/clients/java-ilp/)\n- [NodeJS](https://questdb.com/docs/clients/ingest-node/)\n- [Rust](https://questdb.com/docs/clients/ingest-rust/)\n\n### Connect to QuestDB\n\nInteract with QuestDB and your data via the following interfaces:\n\n- [Web Console](https://questdb.com/docs/web-console/) for an interactive SQL\n  editor and CSV import on port `9000`\n- [InfluxDB Line Protocol](https://questdb.com/docs/reference/api/ilp/overview/)\n  for streaming ingestion on port `9000`\n- [PostgreSQL Wire Protocol](https://questdb.com/docs/reference/api/postgres/)\n  for programmatic queries on port `8812`\n- [REST API](https://questdb.com/docs/reference/api/rest/) for CSV import and\n  cURL on port `9000`\n\n### Popular third-party tools\n\nPopular tools that integrate with QuestDB include:\n\n- [Kafka](https://questdb.com/docs/third-party-tools/kafka/)\n- [Redpanda](https://questdb.com/docs/third-party-tools/redpanda/)\n- [Grafana](https://questdb.com/docs/third-party-tools/grafana/)\n- [Polars](https://questdb.com/docs/third-party-tools/polars/)\n- [Pandas](https://questdb.com/docs/third-party-tools/pandas/)\n- [PowerBI](https://questdb.com/docs/third-party-tools/powerbi/)\n- [Superset](https://questdb.com/docs/third-party-tools/superset/)\n- [Apache Flink](https://questdb.com/docs/third-party-tools/flink/)\n- [Telegraf](https://questdb.com/docs/third-party-tools/telegraf/)\n- [MindsDB](https://questdb.com/docs/third-party-tools/mindsdb/)\n\n### End-to-end code scaffolds\n\nFrom streaming ingestion to visualization with Grafana, start with code\nscaffolds in from our\n[quickstart repository](https://github.com/questdb/questdb-quickstart).\n\n### Configure QuestDB for production workloads\n\nFind our\n[capacity planning](https://questdb.com/docs/deployment/capacity-planning/) to\nfine-tune QuestDB for production workloads.\n\n### QuestDB Enterprise\n\nFor secure operation at greater scale or within larger organizations.\n\nAdditional features include:\n\n- high Availablity and read replica(s)\n- multi-primary ingestion\n- cold storage integration\n- role-based access control\n- TLS encryption\n- native querying of Parquet files via object storage\n- support SLAs, enhanced monitoring and more\n\nVisit the [Enterprise page](https://questdb.com/enterprise/) for further details\nand contact information.\n\n## Additional resources\n\n### ğŸ“š Read the docs\n\n- [QuestDB documentation:](https://questdb.com/docs/) begin the journey\n- [Product roadmap:](https://github.com/orgs/questdb/projects/1/views/5) check\n  out our plan for upcoming releases\n- [Tutorials:](https://questdb.com/tutorial/) learn what's possible with QuestDB,\n  step by step\n\n### â“ Get support\n\n- [Community Discourse forum:](https://community.questdb.com/) join technical\n  discussions, ask questions, and meet other users!\n- [Public Slack:](https://slack.questdb.com/) chat with the QuestDB team and\n  community members\n- [GitHub issues:](https://github.com/questdb/questdb/issues) report bugs or\n  issues with QuestDB\n- [Stack Overflow:](https://stackoverflow.com/questions/tagged/questdb) look for\n  common troubleshooting solutions\n\n### ğŸš¢ Deploy QuestDB\n\n- [AWS AMI](https://questdb.com/docs/guides/aws-official-ami)\n- [Google Cloud Platform](https://questdb.com/docs/guides/google-cloud-platform)\n- [Official Docker image](https://questdb.com/docs/get-started/docker)\n- [DigitalOcean droplets](https://questdb.com/docs/guides/digitalocean)\n- [Kubernetes Helm charts](https://questdb.com/docs/guides/kubernetes)\n\n## Contribute\n\nContributions welcome!\n\nWe appreciate:\n\n- source code\n- documentation (see our\n  [documentation repository](https://github.com/questdb/documentation))\n- bug reports\n- feature requests or feedback.\n\nTo get started with contributing:\n\n- Have a look through GitHub issues labelled\n  \"[Good first issue](https://github.com/questdb/questdb/issues?q=is%3Aissue+is%3Aopen+label%3A%22Good+first+issue%22)\"\n- For Hacktoberfest, see the relevant\n  [labelled issues](https://github.com/questdb/questdb/issues?q=is%3Aissue+is%3Aopen+label%3Ahacktoberfest)\n- Read the\n  [contribution guide](https://github.com/questdb/questdb/blob/master/CONTRIBUTING.md)\n- For details on building QuestDB, see the\n  [build instructions](https://github.com/questdb/questdb/blob/master/core/README.md)\n- [Create a fork](https://docs.github.com/en/github/getting-started-with-github/fork-a-repo)\n  of QuestDB and submit a pull request with your proposed changes\n- Stuck? Join our [public Slack](https://slack.questdb.com/) for assistance\n\nâœ¨ As a sign of our gratitude, we send QuestDB swagto our contributors!\n\nA big thanks goes to the following wonderful people who have contributed to\nQuestDB [emoji key](https://allcontributors.org/docs/en/emoji-key):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/clickingbuttons\"><img src=\"https://avatars1.githubusercontent.com/u/43246297?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>clickingbuttons</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=clickingbuttons\" title=\"Code\">ğŸ’»</a> <a href=\"#ideas-clickingbuttons\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#userTesting-clickingbuttons\" title=\"User Testing\">ğŸ““</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ideoma\"><img src=\"https://avatars0.githubusercontent.com/u/2159629?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ideoma</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=ideoma\" title=\"Code\">ğŸ’»</a> <a href=\"#userTesting-ideoma\" title=\"User Testing\">ğŸ““</a> <a href=\"https://github.com/questdb/questdb/commits?author=ideoma\" title=\"Tests\">âš ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tonytamwk\"><img src=\"https://avatars2.githubusercontent.com/u/20872271?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tonytamwk</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=tonytamwk\" title=\"Code\">ğŸ’»</a> <a href=\"#userTesting-tonytamwk\" title=\"User Testing\">ğŸ““</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://sirinath.com/\"><img src=\"https://avatars2.githubusercontent.com/u/637415?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>sirinath</b></sub></a><br /><a href=\"#ideas-sirinath\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/suhorukov\"><img src=\"https://avatars1.githubusercontent.com/u/10332206?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>igor-suhorukov</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=igor-suhorukov\" title=\"Code\">ğŸ’»</a> <a href=\"#ideas-igor-suhorukov\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mick2004\"><img src=\"https://avatars1.githubusercontent.com/u/2042132?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mick2004</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mick2004\" title=\"Code\">ğŸ’»</a> <a href=\"#platform-mick2004\" title=\"Packaging/porting to new platform\">ğŸ“¦</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://rawkode.com\"><img src=\"https://avatars3.githubusercontent.com/u/145816?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rawkode</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=rawkode\" title=\"Code\">ğŸ’»</a> <a href=\"#infra-rawkode\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://solidnerd.dev\"><img src=\"https://avatars0.githubusercontent.com/u/886383?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>solidnerd</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=solidnerd\" title=\"Code\">ğŸ’»</a> <a href=\"#infra-solidnerd\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://solanav.github.io\"><img src=\"https://avatars1.githubusercontent.com/u/32469597?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>solanav</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=solanav\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/questdb/questdb/commits?author=solanav\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://shantanoo-desai.github.io\"><img src=\"https://avatars1.githubusercontent.com/u/12070966?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>shantanoo-desai</b></sub></a><br /><a href=\"#blog-shantanoo-desai\" title=\"Blogposts\">ğŸ“</a> <a href=\"#example-shantanoo-desai\" title=\"Examples\">ğŸ’¡</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://alexprut.com\"><img src=\"https://avatars2.githubusercontent.com/u/1648497?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>alexprut</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=alexprut\" title=\"Code\">ğŸ’»</a> <a href=\"#maintenance-alexprut\" title=\"Maintenance\">ğŸš§</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lbowman\"><img src=\"https://avatars1.githubusercontent.com/u/1477427?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>lbowman</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=lbowman\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/questdb/questdb/commits?author=lbowman\" title=\"Tests\">âš ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tutswiki.com/\"><img src=\"https://avatars1.githubusercontent.com/u/424822?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>chankeypathak</b></sub></a><br /><a href=\"#blog-chankeypathak\" title=\"Blogposts\">ğŸ“</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/upsidedownsmile\"><img src=\"https://avatars0.githubusercontent.com/u/26444088?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>upsidedownsmile</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=upsidedownsmile\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Nagriar\"><img src=\"https://avatars0.githubusercontent.com/u/2361099?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nagriar</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=Nagriar\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/piotrrzysko\"><img src=\"https://avatars.githubusercontent.com/u/6481553?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>piotrrzysko</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=piotrrzysko\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/questdb/questdb/commits?author=piotrrzysko\" title=\"Tests\">âš ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mpsq/dotfiles\"><img src=\"https://avatars.githubusercontent.com/u/5734722?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mpsq</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mpsq\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/siddheshlatkar\"><img src=\"https://avatars.githubusercontent.com/u/39632173?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>siddheshlatkar</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=siddheshlatkar\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://yitaekhwang.com\"><img src=\"https://avatars.githubusercontent.com/u/6628444?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yitaek</b></sub></a><br /><a href=\"#tutorial-Yitaek\" title=\"Tutorials\">âœ…</a> <a href=\"#example-Yitaek\" title=\"Examples\">ğŸ’¡</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.gaboros.hu\"><img src=\"https://avatars.githubusercontent.com/u/19173947?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>gabor-boros</b></sub></a><br /><a href=\"#tutorial-gabor-boros\" title=\"Tutorials\">âœ…</a> <a href=\"#example-gabor-boros\" title=\"Examples\">ğŸ’¡</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kovid-r\"><img src=\"https://avatars.githubusercontent.com/u/62409489?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kovid-r</b></sub></a><br /><a href=\"#tutorial-kovid-r\" title=\"Tutorials\">âœ…</a> <a href=\"#example-kovid-r\" title=\"Examples\">ğŸ’¡</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://borowski-software.de/\"><img src=\"https://avatars.githubusercontent.com/u/8701341?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TimBo93</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ATimBo93\" title=\"Bug reports\">ğŸ›</a> <a href=\"#userTesting-TimBo93\" title=\"User Testing\">ğŸ““</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://zikani.me\"><img src=\"https://avatars.githubusercontent.com/u/1501387?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>zikani03</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=zikani03\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jaugsburger\"><img src=\"https://avatars.githubusercontent.com/u/10787042?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>jaugsburger</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=jaugsburger\" title=\"Code\">ğŸ’»</a> <a href=\"#maintenance-jaugsburger\" title=\"Maintenance\">ğŸš§</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.questdb.com\"><img src=\"https://avatars.githubusercontent.com/u/52114895?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TheTanc</b></sub></a><br /><a href=\"#projectManagement-TheTanc\" title=\"Project Management\">ğŸ“†</a> <a href=\"#content-TheTanc\" title=\"Content\">ğŸ–‹</a> <a href=\"#ideas-TheTanc\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://davidgs.com\"><img src=\"https://avatars.githubusercontent.com/u/2071898?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>davidgs</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Adavidgs\" title=\"Bug reports\">ğŸ›</a> <a href=\"#content-davidgs\" title=\"Content\">ğŸ–‹</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://redalemeden.com\"><img src=\"https://avatars.githubusercontent.com/u/519433?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kaishin</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=kaishin\" title=\"Code\">ğŸ’»</a> <a href=\"#example-kaishin\" title=\"Examples\">ğŸ’¡</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://questdb.com\"><img src=\"https://avatars.githubusercontent.com/u/7276403?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bluestreak01</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bluestreak01\" title=\"Code\">ğŸ’»</a> <a href=\"#maintenance-bluestreak01\" title=\"Maintenance\">ğŸš§</a> <a href=\"https://github.com/questdb/questdb/commits?author=bluestreak01\" title=\"Tests\">âš ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://patrick.spacesurfer.com/\"><img src=\"https://avatars.githubusercontent.com/u/29952889?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>patrickSpaceSurfer</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=patrickSpaceSurfer\" title=\"Code\">ğŸ’»</a> <a href=\"#maintenance-patrickSpaceSurfer\" title=\"Maintenance\">ğŸš§</a> <a href=\"https://github.com/questdb/questdb/commits?author=patrickSpaceSurfer\" title=\"Tests\">âš ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://chenrui.dev\"><img src=\"https://avatars.githubusercontent.com/u/1580956?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>chenrui333</b></sub></a><br /><a href=\"#infra-chenrui333\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://bsmth.de\"><img src=\"https://avatars.githubusercontent.com/u/43580235?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bsmth</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bsmth\" title=\"Documentation\">ğŸ“–</a> <a href=\"#content-bsmth\" title=\"Content\">ğŸ–‹</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ugbot\"><img src=\"https://avatars.githubusercontent.com/u/2143631?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ugbot</b></sub></a><br /><a href=\"#question-Ugbot\" title=\"Answering Questions\">ğŸ’¬</a> <a href=\"#userTesting-Ugbot\" title=\"User Testing\">ğŸ““</a> <a href=\"#talk-Ugbot\" title=\"Talks\">ğŸ“¢</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lepolac\"><img src=\"https://avatars.githubusercontent.com/u/6312424?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>lepolac</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=lepolac\" title=\"Code\">ğŸ’»</a> <a href=\"#tool-lepolac\" title=\"Tools\">ğŸ”§</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tiagostutz\"><img src=\"https://avatars.githubusercontent.com/u/3986989?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tiagostutz</b></sub></a><br /><a href=\"#userTesting-tiagostutz\" title=\"User Testing\">ğŸ““</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Atiagostutz\" title=\"Bug reports\">ğŸ›</a> <a href=\"#projectManagement-tiagostutz\" title=\"Project Management\">ğŸ“†</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Lyncee59\"><img src=\"https://avatars.githubusercontent.com/u/13176504?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lyncee59</b></sub></a><br /><a href=\"#ideas-Lyncee59\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"https://github.com/questdb/questdb/commits?author=Lyncee59\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rrjanbiah\"><img src=\"https://avatars.githubusercontent.com/u/4907427?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rrjanbiah</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Arrjanbiah\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sarunas-stasaitis\"><img src=\"https://avatars.githubusercontent.com/u/57004257?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>sarunas-stasaitis</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Asarunas-stasaitis\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/RiccardoGiro\"><img src=\"https://avatars.githubusercontent.com/u/60734967?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>RiccardoGiro</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ARiccardoGiro\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/duggar\"><img src=\"https://avatars.githubusercontent.com/u/37486846?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>duggar</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aduggar\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/postol\"><img src=\"https://avatars.githubusercontent.com/u/7983951?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>postol</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Apostol\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/petrjahoda\"><img src=\"https://avatars.githubusercontent.com/u/45359845?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>petrjahoda</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Apetrjahoda\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.turecki.net\"><img src=\"https://avatars.githubusercontent.com/u/1933165?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>t00</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3At00\" title=\"Bug reports\">ğŸ›</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/snenkov\"><img src=\"https://avatars.githubusercontent.com/u/13110986?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>snenkov</b></sub></a><br /><a href=\"#userTesting-snenkov\" title=\"User Testing\">ğŸ““</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Asnenkov\" title=\"Bug reports\">ğŸ›</a> <a href=\"#ideas-snenkov\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/marregui\"><img src=\"https://avatars.githubusercontent.com/u/255796?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>marregui</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=marregui\" title=\"Code\">ğŸ’»</a> <a href=\"#ideas-marregui\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#design-marregui\" title=\"Design\">ğŸ¨</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bratseth\"><img src=\"https://avatars.githubusercontent.com/u/16574012?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bratseth</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bratseth\" title=\"Code\">ğŸ’»</a> <a href=\"#ideas-bratseth\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#userTesting-bratseth\" title=\"User Testing\">ğŸ““</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@wellytambunan/\"><img src=\"https://avatars.githubusercontent.com/u/242694?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>welly87</b></sub></a><br /><a href=\"#ideas-welly87\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://johnleung.com\"><img src=\"https://avatars.githubusercontent.com/u/20699?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>fuzzthink</b></sub></a><br /><a href=\"#ideas-fuzzthink\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#userTesting-fuzzthink\" title=\"User Testing\">ğŸ““</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nexthack\"><img src=\"https://avatars.githubusercontent.com/u/6803956?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>nexthack</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=nexthack\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/g-metan\"><img src=\"https://avatars.githubusercontent.com/u/88013490?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>g-metan</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ag-metan\" title=\"Bug reports\">ğŸ›</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tim2skew\"><img src=\"https://avatars.githubusercontent.com/u/54268285?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tim2skew</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Atim2skew\" title=\"Bug reports\">ğŸ›</a> <a href=\"#userTesting-tim2skew\" title=\"User Testing\">ğŸ““</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ospqsp\"><img src=\"https://avatars.githubusercontent.com/u/84992434?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ospqsp</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aospqsp\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/SuperFluffy\"><img src=\"https://avatars.githubusercontent.com/u/701177?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>SuperFluffy</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ASuperFluffy\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nu11ptr\"><img src=\"https://avatars.githubusercontent.com/u/3615587?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>nu11ptr</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Anu11ptr\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/comunidadio\"><img src=\"https://avatars.githubusercontent.com/u/10286013?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>comunidadio</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Acomunidadio\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mugendi\"><img src=\"https://avatars.githubusercontent.com/u/5348246?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mugendi</b></sub></a><br /><a href=\"#ideas-mugendi\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Amugendi\" title=\"Bug reports\">ğŸ›</a> <a href=\"https://github.com/questdb/questdb/commits?author=mugendi\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/paulwoods222\"><img src=\"https://avatars.githubusercontent.com/u/86227717?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>paulwoods222</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Apaulwoods222\" title=\"Bug reports\">ğŸ›</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mingodad\"><img src=\"https://avatars.githubusercontent.com/u/462618?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mingodad</b></sub></a><br /><a href=\"#ideas-mingodad\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Amingodad\" title=\"Bug reports\">ğŸ›</a> <a href=\"https://github.com/questdb/questdb/commits?author=mingodad\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/houarizegai\"><img src=\"https://avatars.githubusercontent.com/houarizegai?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>houarizegai</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=houarizegai\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://scrapfly.io\"><img src=\"https://avatars.githubusercontent.com/u/1763341?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>jjsaunier</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ajjsaunier\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zanek\"><img src=\"https://avatars.githubusercontent.com/u/333102?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>zanek</b></sub></a><br /><a href=\"#ideas-zanek\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#projectManagement-zanek\" title=\"Project Management\">ğŸ“†</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Geekaylee\"><img src=\"https://avatars.githubusercontent.com/u/12583377?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Geekaylee</b></sub></a><br /><a href=\"#userTesting-Geekaylee\" title=\"User Testing\">ğŸ““</a> <a href=\"#ideas-Geekaylee\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lg31415\"><img src=\"https://avatars.githubusercontent.com/u/3609384?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>lg31415</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Alg31415\" title=\"Bug reports\">ğŸ›</a> <a href=\"#projectManagement-lg31415\" title=\"Project Management\">ğŸ“†</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://nulldev.xyz/\"><img src=\"https://avatars.githubusercontent.com/u/9571936?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>null-dev</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Anull-dev\" title=\"Bug reports\">ğŸ›</a> <a href=\"#projectManagement-null-dev\" title=\"Project Management\">ğŸ“†</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ultd.io\"><img src=\"https://avatars.githubusercontent.com/u/12675427?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ultd</b></sub></a><br /><a href=\"#ideas-ultd\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#projectManagement-ultd\" title=\"Project Management\">ğŸ“†</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ericsun2\"><img src=\"https://avatars.githubusercontent.com/u/8866410?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ericsun2</b></sub></a><br /><a href=\"#ideas-ericsun2\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Aericsun2\" title=\"Bug reports\">ğŸ›</a> <a href=\"#projectManagement-ericsun2\" title=\"Project Management\">ğŸ“†</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/giovanni-k-bonetti-2809345/\"><img src=\"https://avatars.githubusercontent.com/u/3451581?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>giovannibonetti</b></sub></a><br /><a href=\"#userTesting-giovannibonetti\" title=\"User Testing\">ğŸ““</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Agiovannibonetti\" title=\"Bug reports\">ğŸ›</a> <a href=\"#projectManagement-giovannibonetti\" title=\"Project Management\">ğŸ“†</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://wavded.com\"><img src=\"https://avatars.githubusercontent.com/u/26638?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>wavded</b></sub></a><br /><a href=\"#userTesting-wavded\" title=\"User Testing\">ğŸ““</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Awavded\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://medium.com/@apechkurov\"><img src=\"https://avatars.githubusercontent.com/u/37772591?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>puzpuzpuz</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=puzpuzpuz\" title=\"Documentation\">ğŸ“–</a> <a href=\"https://github.com/questdb/questdb/commits?author=puzpuzpuz\" title=\"Code\">ğŸ’»</a> <a href=\"#userTesting-puzpuzpuz\" title=\"User Testing\">ğŸ““</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rstreics\"><img src=\"https://avatars.githubusercontent.com/u/50323347?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rstreics</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=rstreics\" title=\"Code\">ğŸ’»</a> <a href=\"#infra-rstreics\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a> <a href=\"https://github.com/questdb/questdb/commits?author=rstreics\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mariusgheorghies\"><img src=\"https://avatars.githubusercontent.com/u/84250061?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mariusgheorghies</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mariusgheorghies\" title=\"Code\">ğŸ’»</a> <a href=\"#infra-mariusgheorghies\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a> <a href=\"https://github.com/questdb/questdb/commits?author=mariusgheorghies\" title=\"Documentation\">ğŸ“–</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pswu11\"><img src=\"https://avatars.githubusercontent.com/u/48913707?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>pswu11</b></sub></a><br /><a href=\"#content-pswu11\" title=\"Content\">ğŸ–‹</a> <a href=\"#ideas-pswu11\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#design-pswu11\" title=\"Design\">ğŸ¨</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/insmac\"><img src=\"https://avatars.githubusercontent.com/u/1871646?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>insmac</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=insmac\" title=\"Code\">ğŸ’»</a> <a href=\"#ideas-insmac\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#design-insmac\" title=\"Design\">ğŸ¨</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/eugenels\"><img src=\"https://avatars.githubusercontent.com/u/79919431?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>eugenels</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=eugenels\" title=\"Code\">ğŸ’»</a> <a href=\"#ideas-eugenels\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#maintenance-eugenels\" title=\"Maintenance\">ğŸš§</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bziobrowski\"><img src=\"https://avatars.githubusercontent.com/u/26925920?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bziobrowski</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bziobrowski\" title=\"Code\">ğŸ’»</a> <a href=\"#projectManagement-bziobrowski\" title=\"Project Management\">ğŸ“†</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Zapfmeister\"><img src=\"https://avatars.githubusercontent.com/u/20150586?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Zapfmeister</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=Zapfmeister\" title=\"Code\">ğŸ’»</a> <a href=\"#userTesting-Zapfmeister\" title=\"User Testing\">ğŸ““</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mkaruza\"><img src=\"https://avatars.githubusercontent.com/u/3676457?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mkaruza</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mkaruza\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DylanDKnight\"><img src=\"https://avatars.githubusercontent.com/u/17187287?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>DylanDKnight</b></sub></a><br /><a href=\"#userTesting-DylanDKnight\" title=\"User Testing\">ğŸ““</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3ADylanDKnight\" title=\"Bug reports\">ğŸ›</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/enolal826\"><img src=\"https://avatars.githubusercontent.com/u/51820585?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>enolal826</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=enolal826\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/glasstiger\"><img src=\"https://avatars.githubusercontent.com/u/94906625?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>glasstiger</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=glasstiger\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://arijus.net\"><img src=\"https://avatars.githubusercontent.com/u/4284659?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>argshook</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=argshook\" title=\"Code\">ğŸ’»</a> <a href=\"#ideas-argshook\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"#design-argshook\" title=\"Design\">ğŸ¨</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Aargshook\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/amunra\"><img src=\"https://avatars.githubusercontent.com/u/1499096?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>amunra</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=amunra\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/questdb/questdb/commits?author=amunra\" title=\"Documentation\">ğŸ“–</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Aamunra\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://lamottsjourney.wordpress.com/\"><img src=\"https://avatars.githubusercontent.com/u/66742430?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>GothamsJoker</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=GothamsJoker\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kocko\"><img src=\"https://avatars.githubusercontent.com/u/862000?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kocko</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=kocko\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jerrinot\"><img src=\"https://avatars.githubusercontent.com/u/158619?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>jerrinot</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=jerrinot\" title=\"Code\">ğŸ’»</a> <a href=\"#ideas-jerrinot\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Ajerrinot\" title=\"Bug reports\">ğŸ›</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://ramiroberrelleza.com\"><img src=\"https://avatars.githubusercontent.com/u/475313?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rberrelleza</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=rberrelleza\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Cobalt-27\"><img src=\"https://avatars.githubusercontent.com/u/34511059?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Cobalt-27</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=Cobalt-27\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/eschultz\"><img src=\"https://avatars.githubusercontent.com/u/390064?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>eschultz</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=eschultz\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/xinyi-qiao/\"><img src=\"https://avatars.githubusercontent.com/u/47307374?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>XinyiQiao</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=XinyiQiao\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://chenquan.me\"><img src=\"https://avatars.githubusercontent.com/u/20042193?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>terasum</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=terasum\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/hristovdeveloper\"><img src=\"https://avatars.githubusercontent.com/u/3893599?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>PlamenHristov</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=PlamenHristov\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tris0laris\"><img src=\"https://avatars.githubusercontent.com/u/57298792?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tris0laris</b></sub></a><br /><a href=\"#blog-tris0laris\" title=\"Blogposts\">ğŸ“</a> <a href=\"#ideas-tris0laris\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/HeZean\"><img src=\"https://avatars.githubusercontent.com/u/49837965?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>HeZean</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=HeZean\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3AHeZean\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/iridess\"><img src=\"https://avatars.githubusercontent.com/u/104518201?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>iridess</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=iridess\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/questdb/questdb/commits?author=iridess\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/selmanfaruky%C4%B1lmaz/\"><img src=\"https://avatars.githubusercontent.com/u/96119894?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>selmanfarukyilmaz</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aselmanfarukyilmaz\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.donet5.com\"><img src=\"https://avatars.githubusercontent.com/u/12455385?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>donet5</b></sub></a><br /><a href=\"#ideas-donet5\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Adonet5\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Zahlii\"><img src=\"https://avatars.githubusercontent.com/u/218582?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Zahlii</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3AZahlii\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/salsasepp\"><img src=\"https://avatars.githubusercontent.com/u/4884807?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>salsasepp</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Asalsasepp\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/EmmettM\"><img src=\"https://avatars.githubusercontent.com/u/4196372?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>EmmettM</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3AEmmettM\" title=\"Bug reports\">ğŸ›</a> <a href=\"https://github.com/questdb/questdb/commits?author=EmmettM\" title=\"Tests\">âš ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://allfactors.com\"><img src=\"https://avatars.githubusercontent.com/u/571328?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>robd003</b></sub></a><br /><a href=\"#ideas-robd003\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AllenEdison\"><img src=\"https://avatars.githubusercontent.com/u/46532217?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>AllenEdison</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3AAllenEdison\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/CSharpDummy\"><img src=\"https://avatars.githubusercontent.com/u/7610502?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>CSharpDummy</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ACSharpDummy\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shimondoodkin\"><img src=\"https://avatars.githubusercontent.com/u/314464?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>shimondoodkin</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ashimondoodkin\" title=\"Bug reports\">ğŸ›</a> <a href=\"#ideas-shimondoodkin\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.zsmart.tech/\"><img src=\"https://avatars.githubusercontent.com/u/40519768?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>huuhait</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ahuuhait\" title=\"Bug reports\">ğŸ›</a> <a href=\"#ideas-huuhait\" title=\"Ideas, Planning, & Feedback\">ğŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://clickhouse.com/\"><img src=\"https://avatars.githubusercontent.com/u/18581488?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>alexey-milovidov</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aalexey-milovidov\" title=\"Bug reports\">ğŸ›</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://blog.suconghou.cn\"><img src=\"https://avatars.githubusercontent.com/u/4580719?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>suconghou</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Asuconghou\" title=\"Bug reports\">ğŸ›</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/allegraharris\"><img src=\"https://avatars.githubusercontent.com/u/89586969?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>allegraharris</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=allegraharris\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/oliver-daniel\"><img src=\"https://avatars.githubusercontent.com/u/17235417?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>oliver-daniel</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=oliver-daniel\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kerimsenturk5734\"><img src=\"https://avatars.githubusercontent.com/u/72925170?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kerimsenturk5734</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=kerimsenturk5734\" title=\"Documentation\">ğŸ“–</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project adheres to the\n[all-contributors](https://github.com/all-contributors/all-contributors)\nspecification. Contributions of any kind are welcome!\n",
      "stars_today": 5
    },
    {
      "id": 595662105,
      "name": "gitbutler",
      "full_name": "gitbutlerapp/gitbutler",
      "description": "The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte",
      "html_url": "https://github.com/gitbutlerapp/gitbutler",
      "stars": 17494,
      "forks": 758,
      "language": "Rust",
      "topics": [
        "git",
        "github",
        "tauri"
      ],
      "created_at": "2023-01-31T14:56:22Z",
      "updated_at": "2026-01-16T00:33:28Z",
      "pushed_at": "2026-01-16T00:59:50Z",
      "open_issues": 651,
      "owner": {
        "login": "gitbutlerapp",
        "avatar_url": "https://avatars.githubusercontent.com/u/123460877?v=4"
      },
      "readme": "<div align=\"center\">\n  <img align=\"center\" width=\"100%\" src=\"./readme-preview.webp\" />\n\n  <br />\n  <br />\n\n  <p align=\"center\" >\n    Version Control tool built from the ground up for modern, AI-powered workflows.\n    <br />\n    <br />\n    <a href=\"https://gitbutler.com\">Website</a>\n    <span>&nbsp;&nbsp;â€¢&nbsp;&nbsp;</span>\n    <a href=\"https://blog.gitbutler.com/\">Blog</a>\n    <span>&nbsp;&nbsp;â€¢&nbsp;&nbsp;</span>\n    <a href=\"https://docs.gitbutler.com/\">Docs</a>\n    <span>&nbsp;&nbsp;â€¢&nbsp;&nbsp;</span>\n    <a href=\"https://gitbutler.com/downloads\">Downloads</a>\n  </p>\n\n[![TWEET][s1]][l1] [\n![BLUESKY][s8]][l8 ] [![DISCORD][s2]][l2]\n\n[![CI][s0]][l0] [![INSTA][s3]][l3] [![YOUTUBE][s5]][l5] [![DEEPWIKI][s7]][l7]\n\n[s0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml/badge.svg\n[l0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml\n[s1]: https://img.shields.io/badge/Twitter-black?logo=x&logoColor=white\n[l1]: https://twitter.com/intent/follow?screen_name=gitbutler\n[s2]: https://img.shields.io/discord/1060193121130000425?label=Discord&color=5865F2\n[l2]: https://discord.gg/MmFkmaJ42D\n[s3]: https://img.shields.io/badge/Instagram-E4405F?logo=instagram&logoColor=white\n[l3]: https://www.instagram.com/gitbutler/\n[s5]: https://img.shields.io/youtube/channel/subscribers/UCEwkZIHGqsTGYvX8wgD0LoQ\n[l5]: https://www.youtube.com/@gitbutlerapp\n[s7]: https://deepwiki.com/badge.svg\n[l7]: https://deepwiki.com/gitbutlerapp/gitbutler\n[s8]: https://img.shields.io/badge/Bluesky-0285FF?logo=bluesky&logoColor=fff\n[l8]: https://bsky.app/profile/gitbutler.com\n\n</div>\n\n<br/>\n\n![Alt](https://repobeats.axiom.co/api/embed/fb23382bcf57c609832661874d3019a43555d6ae.svg 'Repobeats analytics for GitButler')\n\nGitButler is a git client that lets you work on multiple branches at the same time.\nIt allows you to quickly organize file changes into separate branches while still having them applied to your working directory.\nYou can then push branches individually to your remote, or directly create pull requests.\n\nIn a nutshell, it's a more flexible version of `git add -p` and `git rebase -i`, allowing you to efficiently multitask across branches.\n\n## How Does It Work?\n\nGitButler keeps track of uncommitted changes in a layer on top of Git. Changes to files or parts of files can be grouped into what we call virtual branches. Whenever you are happy with the contents of a virtual branch, you can push it to a remote. GitButler makes sure that the state of other virtual branches is kept separate.\n\n## How Do GB's Virtual Branches Differ From Git Branches?\n\nThe branches that we know and love in Git are separate universes, and switching between them is a full context switch. GitButler allows you to work with multiple branches in parallel in the same working directory. This effectively means having the content of multiple branches available at the same time.\n\nGitButler is aware of changes before they are committed. This allows it to keep a record of which virtual branch each individual diff belongs to. Effectively, this means that you can separate out individual branches with their content at any time to push them to a remote or to unapply them from your working directory.\n\nAnd finally, while in Git it is preferable that you create your desired branch ahead of time, using GitButler you can move changes between virtual branches at any point during development.\n\n## Why GitButler?\n\nWe love Git. Our own [@schacon](https://github.com/schacon) has even published the [Pro Git](https://git-scm.com/book/en/v2) book. At the same time, Git's user interface hasn't been fundamentally changed for 15 years. While it was written for Linux kernel devs sending patches to each other over mailing lists, most developers today have different workflows and needs.\n\nInstead of trying to fit the semantics of the Git CLI into a graphical interface, we are starting with the developer workflow and mapping it back to Git.\n\n## Tech\n\nGitButler is a [Tauri](https://tauri.app/)-based application. Its UI is written in [Svelte](https://svelte.dev/) using [TypeScript](https://www.typescriptlang.org) and its backend is written in [Rust](https://www.rust-lang.org/).\n\n## Main Features\n\n- **Virtual Branches**\n  - Organize work on multiple branches simultaneously, rather than constantly switching branches\n  - Automatically create new branches when needed\n- **Easy Commit Management**\n  - Undo, Amend and Squash commits by dragging and dropping\n- **Undo Timeline**\n  - Logs all operations and changes and allows you to easily undo or revert any operation\n- **GitHub Integration**\n  - Authenticate to GitHub to open Pull Requests, list branches and statuses and more\n- **Easy SSH Key Management**\n  - GitButler can generate an SSH key to upload to GitHub automatically\n- **AI Tooling**\n  - Automatically write commit messages based on your work in progress\n  - Automatically create descriptive branch names\n- **Commit Signing**\n  - Easy commit signing with GPG or SSH\n\n## Example Uses\n\n### Fixing a Bug While Working on a Feature\n\n> Say that while developing a feature, you encounter a bug that you wish to fix. It's often desirable that you ship the fix as a separate contribution (Pull request).\n\nUsing Git you can stash your changes and switch to another branch, where you can commit, and push your fix.\n\n_With GitButler_ you simply assign your fix to a separate virtual branch, which you can individually push (or directly create a PR). An additional benefit is that you can retain the fix in your working directory while waiting for CI and/or code review.\n\n### Trying Someone Else's Branch Together With My Work in Progress\n\n> Say you want to test a branch from someone else for the purpose of code review.\n\nUsing Git trying out someone else's branch is a full context switch away from your own work.\n_With GitButler_ you can apply and unapply (add / remove) any remote branch directly into your working directory.\n\n## Documentation\n\nYou can find our end user documentation at: <https://docs.gitbutler.com>\n\n## Bugs and Feature Requests\n\nIf you have a bug or feature request, feel free to open an [issue](https://github.com/gitbutlerapp/gitbutler/issues/new),\nor [join our Discord server](https://discord.gg/MmFkmaJ42D).\n\n## AI Commit Message Generation\n\nCommit message generation is an opt-in feature. You can enable it while adding your repository for the first time or later in the project settings.\n\nCurrently, GitButler uses OpenAI's API for diff summarization, which means that if enabled, code diffs would be sent to OpenAI's servers.\n\nOur goal is to make this feature more modular such that in the future you can modify the prompt as well as plug a different LLM endpoints (including local ones).\n\n## Contributing\n\nSo you want to help out? Please check out the [CONTRIBUTING.md](CONTRIBUTING.md)\ndocument.\n\nIf you want to skip right to getting the code to actually compile, take a look\nat the [DEVELOPMENT.md](DEVELOPMENT.md) file.\n\n### Contributors\n\n<a href=\"https://github.com/gitbutlerapp/gitbutler/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=gitbutlerapp/gitbutler\" />\n</a>\n",
      "stars_today": 5
    },
    {
      "id": 66302557,
      "name": "SwiftFormat",
      "full_name": "nicklockwood/SwiftFormat",
      "description": "A command-line tool and Xcode Extension for formatting Swift code",
      "html_url": "https://github.com/nicklockwood/SwiftFormat",
      "stars": 8656,
      "forks": 667,
      "language": "Swift",
      "topics": [],
      "created_at": "2016-08-22T19:39:05Z",
      "updated_at": "2026-01-15T20:51:02Z",
      "pushed_at": "2026-01-15T20:31:18Z",
      "open_issues": 327,
      "owner": {
        "login": "nicklockwood",
        "avatar_url": "https://avatars.githubusercontent.com/u/546885?v=4"
      },
      "readme": "![](EditorExtension/Application/Assets.xcassets/AppIcon.appiconset/icon_256x256.png)\n\n[![PayPal](https://img.shields.io/badge/paypal-donate-blue.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=9ZGWNK5FEZFF6&source=url)\n[![Build](https://github.com/nicklockwood/SwiftFormat/actions/workflows/build.yml/badge.svg)](https://github.com/nicklockwood/SwiftFormat/actions/workflows/build.yml)\n[![Codecov](https://codecov.io/gh/nicklockwood/SwiftFormat/graphs/badge.svg)](https://codecov.io/gh/nicklockwood/SwiftFormat)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fnicklockwood%2FSwiftFormat%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/nicklockwood/swiftformat)\n[![License](https://img.shields.io/badge/license-MIT-lightgrey.svg)](https://opensource.org/licenses/MIT)\n[![Mastodon](https://img.shields.io/badge/mastodon-@nicklockwood@mastodon.social-636dff.svg)](https://mastodon.social/@nicklockwood)\n\nTable of Contents\n-----------------\n\n- [What?](#what-is-this)\n- [Why?](#why-would-i-want-to-do-that)\n- [How?](#how-do-i-install-it)\n    - [Command-line tool](#command-line-tool)\n    - [Xcode source editor extension](#xcode-source-editor-extension)\n    - [Xcode build phase](#xcode-build-phase)\n    - [Swift Package Manager plugin](#swift-package-manager-plugin)\n    - [Via Applescript](#via-applescript)\n    - [VSCode plugin](#vscode-plugin)\n    - [Sublime Text plugin](#sublime-text-plugin)\n    - [Nova plugin](nova-plugin)\n    - [Git pre-commit hook](#git-pre-commit-hook)\n    - [GitHub Actions](#github-actions)\n    - [On CI using Danger](#on-ci-using-danger)\n    - [Bazel build](#bazel-build)\n    - [Docker](#docker)\n    - [Prerelease Builds](#prerelease-builds)\n- [Configuration](#configuration)\n    - [Options](#options)\n    - [Rules](#rules)\n    - [Swift version](#swift-version)\n    - [Config file](#config-file)\n    - [Globs](#globs)\n    - [Linting](#linting)\n    - [Error codes](#error-codes)\n    - [Cache](#cache)\n    - [File headers](#file-headers)\n    - [Markdown formatting](#markdown-formatting)\n- [FAQ](#faq)\n- [Known issues](#known-issues)\n- [Tip Jar](#tip-jar)\n- [Credits](#credits)\n\n\nWhat is this?\n----------------\n\nSwiftFormat is a code library and command-line tool for reformatting Swift code on macOS, Linux or Windows.\n\nSwiftFormat goes above and beyond what you might expect from a code formatter. In addition to adjusting white space it can insert or remove implicit `self`, remove redundant parentheses, and correct many other deviations from the standard Swift idioms.\n\n\nWhy would I want to do that?\n-----------------------------\n\nMany programmers have a preferred style for formatting their code, and others seem entirely blind to the existing formatting conventions of a project (to the enragement of their colleagues).\n\nWhen collaborating on a project, it can be helpful to agree on a common coding style, but enforcing that manually is tedious and error-prone, and can lead to arguments if some participants take it more seriously than others.\n\nHaving a tool to automatically enforce a common style eliminates those issues, and lets you focus on the behavior of the code, not its presentation.\n\n\nHow do I install it?\n---------------------\n\nThat depends - There are several ways you can use SwiftFormat:\n\n1. As a command-line tool that you run manually, or as part of some other toolchain\n2. As a Source Editor Extension that you can invoke via the Editor > SwiftFormat menu within Xcode\n3. As a build phase in your Xcode project, so that it runs every time you press Cmd-R or Cmd-B, or\n4. As a Git pre-commit hook, so that it runs on any files you've changed before you check them in\n\n\nCommand-line tool\n-------------------\n\n**Installation:**\n\nYou can install the `swiftformat` command-line tool on macOS or Linux using [Homebrew](http://brew.sh/). Assuming you already have Homebrew installed, just type:\n\n```bash\n$ brew install swiftformat\n```\n\nTo update to the latest version once installed:\n\n```bash\n$ brew upgrade swiftformat\n```\n\nAlternatively, you can install the tool on macOS or Linux by using [Mint](https://github.com/yonaskolb/Mint) as follows:\n\n```bash\n$ mint install nicklockwood/SwiftFormat\n```\n\nOr if you prefer, you can check out and build SwiftFormat manually on macOS, Linux or Windows as follows:\n\n```bash\n$ git clone https://github.com/nicklockwood/SwiftFormat\n$ cd SwiftFormat\n$ swift build -c release\n```\n\nIf you are installing SwiftFormat into your project directory, you can use [CocoaPods](https://cocoapods.org/) on macOS to automatically install the swiftformat binary along with your other pods - see the Xcode build phase instructions below for details.\n\nAnother option is to include the binary artifactbundle in your `Package.swift`:\n\n```swift\n.binaryTarget(\n    name: \"swiftformat\",\n    url: \"https://github.com/nicklockwood/SwiftFormat/releases/download/0.55.0/swiftformat-macos.artifactbundle.zip\",\n    checksum: \"CHECKSUM\"\n),\n``` \n\nIf you would prefer not to use a package manager, you can build the command-line app manually:\n\n1. open `SwiftFormat.xcodeproj` and build the `SwiftFormat (Application)` scheme.\n\n2. Drag the `swiftformat` binary into `/usr/local/bin/` (this is a hidden folder, but you can use the Finder's `Go > Go to Folder...` menu to open it).\n\n3. Open `~/.bash_profile` in your favorite text editor (this is a hidden file, but you can type `open ~/.bash_profile` in the terminal to open it).\n\n4. Add the following line to the file: `alias swiftformat=\"/usr/local/bin/swiftformat --indent 4\"` (you can omit the `--indent 4`, or replace it with something else. Run `swiftformat --help` to see the available options).\n\n5. Save the `.bash_profile` file and run the command `source ~/.bash_profile` for the changes to take effect.\n\n**Usage:**\n\nIf you followed the installation instructions above, you can now just type\n\n```bash\n$ swiftformat .\n```\n\n(that's a space and then a period after the command) in the terminal to format any Swift files in the current directory. In place of the `.`, you can instead type an absolute or relative path to the file or directory that you want to format.\n\n**WARNING:** `swiftformat .` will overwrite any Swift files it finds in the current directory, and any subfolders therein. If you run it in your home directory, it will probably reformat every Swift file on your hard drive.\n\nTo use it safely, do the following:\n\n1. Choose a file or directory that you want to apply the changes to.\n\n2. Make sure that you have committed all your changes to that code safely in git (or whatever source control system you use).\n\n3. (Optional) In Terminal, type `swiftformat --infer-options \"/path/to/your/code/\"`. This will suggest a set of formatting options to use that match your existing project style (but you are free to ignore these and use the defaults, or your own settings if you prefer).\n\n    The path can point to either a single Swift file or a directory of files. It can be either be absolute, or relative to the current directory. The `\"\"` quotes around the path are optional, but if the path contains spaces then you either need to use quotes, or escape each space with `\\`. You may include multiple paths separated by spaces.\n\n4. In Terminal, type `swiftformat \"/path/to/your/code/\"`. The same rules apply as above with respect to paths, and multiple space-delimited paths are allowed.\n\n    If you used `--infer-options` to generate a suggested set of options in step 3, you should copy and paste them into the command, either before or after the path(s) to your source files.\n\n    If you have created a [config file](#config-file), you can specify its path using `--config \"/path/to/your/config-file/\"`. Alternatively, if you name the file `.swiftformat` and place it inside the project you are formatting, it will be picked up automatically.\n\n5. Press enter to begin formatting. Once the formatting is complete, use your source control system to check the changes, and verify that no undesirable changes have been introduced. If they have, revert the changes, tweak the options and try again.\n\n6. (Optional) commit the changes.\n\nFollowing these instructions *should* ensure that you avoid catastrophic data loss, but in the unlikely event that it wipes your hard drive, **please note that I accept no responsibility**.\n\n**Using Standard Input/Output:**\n\nIf you prefer, you can use unix pipes to include SwiftFormat as part of a command chain. For example, this is an alternative way to format a file:\n\n```bash\n$ cat /path/to/file.swift | swiftformat --output /path/to/file.swift\n```\n\nOmitting the `--output /path/to/file.swift` will print the formatted file to Standard Output (stdout). You can also pass \"stdout\" explicitly as the output path:\n\n```bash\n$ cat /path/to/file.swift | swiftformat --output stdout\n```\n\nOr you can use `>` to specify the output path as follows:\n\n```bash\n$ cat /path/to/file.swift | swiftformat > /path/to/file.swift\n```\n\nIf you do not supply an input file, SwiftFormat will automatically take its input from Standard Input (stdin), but will time-out if no input is received immediately and display the help screen. To make it explicit, pass \"stdin\" as the input path:\n\n```bash\n$ cat /path/to/file.swift | swiftformat stdin\n```\n\nWhen using stdin, SwiftFormat does not have access to the file path of the input, so features that rely on the file location (such as inserting the creation date into header comments, or detecting `.swiftformat` configuration files in the file path) will not work. To solve this, you can provide the file path using the `--stdin-path` argument:\n\n```bash\n$ cat /path/to/file.swift | swiftformat stdin --stdinpath /path/to/file.swift\n```\n\n\nXcode source editor extension\n-----------------------------\n\n**Installation:**\n\nLike the command-line tool, you can install the SwiftFormat for Xcode extension application via [Homebrew](http://brew.sh/). Assuming you already have Homebrew installed, type:\n\n```bash\n$ brew install --cask swiftformat-for-xcode\n```\n\nThis will install SwiftFormat for Xcode in your Applications folder. Double-click the app to launch it, and then follow the on-screen instructions.\n\n**NOTE:** The app should be correctly signed, but if you get a Gatekeeper warning when trying to open it you can bypass this by right-clicking (or control-clicking) the app and selecting `Open`.\n\nTo update to the latest version once installed use:\n\n```bash\n$ brew upgrade --cask swiftformat-for-xcode\n```\n\nAlternatively, if you prefer not to use Homebrew, you'll find the latest version of the SwiftFormat for Xcode application on the [GitHub Releases](https://github.com/nicklockwood/SwiftFormat/releases) page. Download and unpack the zip archive, then drag `SwiftFormat for Xcode.app` into your `Applications` folder.\n\n**Usage:**\n\nOnce you have launched the app and restarted Xcode, you'll find a SwiftFormat option under Xcode's Editor menu. If the SwiftFormat menu does not appear [this thread](https://github.com/nicklockwood/SwiftFormat/issues/494) may help. \n\nYou can configure the formatting [rules](#rules) and [options](#options) using the SwiftFormat for Xcode host application. There is currently no way to override these per-project, however, you can import and export different configurations using the File menu. You will need to do this again each time you switch projects.\n\nThe format of the configuration file is described in the [Config section](#config-file) below.\n\n**Note:** SwiftFormat for Xcode cannot automatically detect changes to an imported configuration file. If you update the `.swiftformat` file for your project, you will need to manually re-import that file into SwiftFormat for Xcode in order for the Xcode source editor extension to use the new configuration.\n\n\nXcode build phase\n-------------------\n\n**NOTE:** Adding this script will overwrite your source files as you work on them, which has the annoying side-effect of clearing the undo history. You may wish to add the script to your test target rather than your main target, so that it is invoked only when you run the unit tests, and not every time you build the app.\n\nAlternatively, you might want to consider running SwiftFormat in [lint](#linting) mode as part of your normal build, and then running a formatting pass manually, or as part of a less-frequent build target (such as the tests).\n\n### Using Swift Package Manager\n\nTo set up SwiftFormat as an Xcode build phase, do the following:\n\n#### 1) Create a BuildTools folder and Package.swift\n\n1. Create a folder called `BuildTools` in the same folder as your xcodeproj file\n2. In this folder, create a file called `Package.swift`, with the following contents:\n```swift\n// swift-tools-version:5.1\nimport PackageDescription\n\nlet package = Package(\n    name: \"BuildTools\",\n    platforms: [.macOS(.v10_11)],\n    dependencies: [\n        .package(url: \"https://github.com/nicklockwood/SwiftFormat\", from: \"0.58.7\"),\n    ],\n    targets: [.target(name: \"BuildTools\", path: \"\")]\n)\n```\n3. If you are running Xcode 11.4 or later, in the `BuildTools` folder create a file called `Empty.swift` with nothing in it. This is to satisfy a change in Swift Package Manager.\n\n#### 2) Add a Build phase to your app target\n\n1. Click on your project in the file list, choose your target under `TARGETS`, click the `Build Phases` tab\n2. Add a `New Run Script Phase` by clicking the little plus icon in the top left\n3. Uncheck the `Based on dependency analysis` checkbox\n4. Drag the new `Run Script` phase **above** the `Compile Sources` phase, expand it and paste the following script:\n\n    ```bash\n    cd BuildTools\n    SDKROOT=(xcrun --sdk macosx --show-sdk-path)\n    #swift package update #Uncomment this line temporarily to update the version used to the latest matching your BuildTools/Package.swift file\n    swift run -c release swiftformat \"$SRCROOT\"\n    ```\n\nYou can also use `swift run -c release --package-path BuildTools swiftformat \"$SRCROOT\"` if you need a more complex script and `cd BuildTools` breaks stuff.\n\n**NOTE:** You may wish to check BuildTools/Package.swift into your source control so that the version used by your run-script phase is kept in version control. It is recommended to add the following to your .gitignore file: `BuildTools/.build` and `BuildTools/.swiftpm`.\n\n**NOTE (2):** If you are using Xcode 15 or later, make sure that the `ENABLE_USER_SCRIPT_SANDBOXING` (aka \"User Script Sandboxing\") option is set to NO, otherwise SwiftFormat won't be able to run correctly.\n\n### Using CocoaPods\n\n#### 1) Add the SwiftFormat CLI to your Podfile\n\n1. Add the `swiftformat` binary to your project directory via [CocoaPods](https://cocoapods.org/), by adding the following line to your Podfile then running `pod install`:\n\n    ```ruby\n    pod 'SwiftFormat/CLI', '~> 0.58.7'\n    ```\n\n**NOTE:** This will only install the pre-built command-line app, not the source code for the SwiftFormat framework.\n\n**NOTE (2):** When installing this way, GateKeeper may block swiftformat from running until you open it manually the first time by right-clicking in the Finder and selecting \"Open\".\n\n#### 2) Add a Build phase to your app target\n\n1. Click on your project in the file list, choose your target under `TARGETS`, click the `Build Phases` tab\n2. Add a `New Run Script Phase` by clicking the little plus icon in the top left\n3. Uncheck the `Based on dependency analysis` checkbox\n4. Drag the new `Run Script` phase **above** the `Compile Sources` phase, expand it and paste the following script:\n\n    ```bash\n    \"${PODS_ROOT}/SwiftFormat/CommandLineTool/swiftformat\" \"$SRCROOT\"\n    ```\n\n### Alternative: Locally installed SwiftFormat\n\nAlternatively, you could use a locally installed swiftformat command-line tool instead by putting the following in your Run Script build phase:\n\n```bash\nif which swiftformat >/dev/null; then\n  swiftformat .\nelse\n  echo \"warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\"\nfi\n```\n\nThis is not recommended for shared projects however, as different team members using different versions of SwiftFormat may result in noise in the commit history as code gets reformatted inconsistently.\n\nIf you installed SwiftFormat via Homebrew on Apple Silicon, you might experience this warning:\n\n> warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\n\nThat is because Homebrew on Apple Silicon installs the binaries into the `/opt/homebrew/bin`\nfolder by default. To instruct Xcode where to find SwiftFormat, you can either add\n`/opt/homebrew/bin` to the `PATH` environment variable in your build phase\n\n```bash\nif [[ \"$(uname -m)\" == arm64 ]]; then\n    export PATH=\"/opt/homebrew/bin:$PATH\"\nfi\n\nif which swiftformat > /dev/null; then\n  swiftformat .\nelse\n  echo \"warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\"\nfi\n```\n\nor you can create a symbolic link in `/usr/local/bin` pointing to the actual binary:\n\n```bash\nln -s /opt/homebrew/bin/swiftformat /usr/local/bin/swiftformat\n```\n\nSwift Package Manager plugin\n-----------------------------\n\nYou can use `SwiftFormat` as a SwiftPM command plugin.\n\n**NOTE:** Swift 5.6 or higher is required. Add the package to your dependencies in your `Package.swift` file.\n\n```swift\ndependencies: [\n    // ...\n    .package(url: \"https://github.com/nicklockwood/SwiftFormat\", from: \"0.58.7\"),\n]\n```\n\nThe plugin will find an existing `.swiftformat` in your package root folder and honor it automatically.\n\n### Trigger Plugin From Command-Line\n\n```bash\nswift package plugin --allow-writing-to-package-directory swiftformat\n```\n\nYou can limit the formatting to a particular target with `--target` option.\n\nYou can also specify `SwiftFormat` arguments, e.g. `--swift-version`.\n\nExample\n\n```bash\nswift package plugin --allow-writing-to-package-directory swiftformat --target MyLibrary --swift-version 5.6 --verbose\n```\n\n### Trigger Plugin From Xcode\n\nIn Xcode 14 you can trigger the command plugin execution for a Swift package or an Xcode project.\n\nFor an Xcode project the project's main directory will be processed and the `--target` option will be ignored.\n\nYou can also specify `SwiftFormat` arguments, e.g. `--swift-version`.\n\n![Run plugin in Xcode 14](https://user-images.githubusercontent.com/4176826/179352584-db7f7f42-452c-4a42-a329-01b115a237a7.gif)\n\nVia AppleScript\n----------------\n\nTo run SwiftFormat on the frontmost Xcode document (project or workspace) you can use the following AppleScript:\n\n```applescript\ntell application \"Xcode\"\n    set frontWindow to the first window\n    set myPath to path of document of frontWindow\n    do shell script \"cd \" & myPath & \";cd ..; /usr/local/bin/swiftformat .\"\nend tell\n```\n\nSome Apps you can trigger this from are [BetterTouchTool](https://folivora.ai), [Alfred](https://www.alfredapp.com) or [Keyboard Maestro](https://www.keyboardmaestro.com/main/). Another option is to define a QuickAction for Xcode via Automator and then assign a keyboard shortcut for it in the System Preferences.\n\n\nVSCode plugin\n--------------\n\nIf you prefer to use Microsoft's [VSCode](https://code.visualstudio.com) editor for writing Swift, [Valentin Knabel](https://github.com/vknabel) has created a [VSCode plugin](https://marketplace.visualstudio.com/items?itemName=vknabel.vscode-swiftformat) for SwiftFormat.\n\n\nSublime Text plugin\n--------------------\n\nIf you prefer to use the [Sublime Text](https://www.sublimetext.com) editor, try the [Sublime-Swift-Format plugin](https://github.com/aerobounce/Sublime-Swift-Format) by [Aerobounce](https://github.com/aerobounce).\n\n\nNova plugin\n-----------\n\nIf you prefer to use the [Nova](https://panic.com/nova) editor, try the [SwiftFormat extension](https://extensions.panic.com/extensions/org.padraig/org.padraig.SwiftFormat/) by [PÃ¡draig Ã“ CinnÃ©ide](https://mastodon.social/@PadraigOCinneide).\n\n\nGit pre-commit hook\n---------------------\n\n1. Follow the instructions for installing the SwiftFormat command-line tool.\n\n2. Install [git-format-staged](https://github.com/hallettj/git-format-staged).\n\n3. Edit or create a `.git/hooks/pre-commit` file in your project folder. The .git folder is hidden but should already exist if you are using Git with your project, so open it with the terminal, or the Finder's `Go > Go to Folder...` menu.\n\n4. Add the following line in the pre-commit file. The `{}` will be replaced automatically by the path to the Swift file being formatted:\n\n    ```bash\n    #!/bin/bash\n    git-format-staged --formatter \"swiftformat stdin --stdin-path '{}'\" \"*.swift\"\n    ```\n    \n    (Note that this example uses your locally installed version of SwiftFormat, not a separate copy in your project repository. You can replace `swiftformat` with the path to a copy inside your project if you prefer.)\n    \n5. enable the hook by typing `chmod +x .git/hooks/pre-commit` in the terminal.\n \nThe pre-commit hook will now run whenever you run `git commit`. Running `git commit --no-verify` will skip the pre-commit hook.\n\n**NOTE:** If you are using Git via a GUI client such as [Tower](https://www.git-tower.com), [additional steps](https://www.git-tower.com/help/mac/faq-and-tips/faq/hook-scripts) may be needed.\n\n**NOTE (2):** Unlike the Xcode build phase approach, git pre-commit hook won't be checked in to source control, and there's no way to guarantee that all users of the project are using the same version of SwiftFormat. For a collaborative project, you might want to consider a *post*-commit hook instead, which would run on your continuous integration server.\n\nGitHub Actions\n---------------------\n\n1. SwiftFormat comes preinstalled on all macOS GitHub-hosted runners. If you are self hosting you will need to ensure SwiftFormat is installed on your runner.\n2. Create a GitHub Actions workflow using SwiftFormat, passing the `--reporter github-actions-log` command line option. The following example action lints pull requests using SwiftFormat, reporting warnings using the GitHub Actions log.\n```yaml\n# Lint.yml\nname: Lint\non: pull_request\n\njobs:\n  Lint:\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: SwiftFormat\n        run: swiftformat --lint . --reporter github-actions-log\n```\n\nOn CI using Danger\n-------------------\n\nTo setup SwiftFormat to be used by your continuous integration system using [Danger](http://danger.systems/ruby/), do the following:\n\n1. Follow the [`instructions`](http://danger.systems/guides/getting_started.html) to setup Danger.\n2. Add the [`danger-swiftformat`](https://github.com/garriguv/danger-ruby-swiftformat) plugin to your `Gemfile`.\n3. Add the following to your `Dangerfile`:\n\n    ```ruby\n    swiftformat.binary_path = \"/path/to/swiftformat\" # optional\n    swiftformat.additional_args = \"--indent tab --self insert\" # optional\n    swiftformat.check_format(fail_on_error: true)\n    ```\n\n    **NOTE:** It is recommended to add the `swiftformat` binary to your project directory to ensure the same version is used each time (see the [Xcode build phase](#xcode-build-phase) instructions above).\n\n\nBazel Build\n-----------\n\nIf you use [Bazel](https://bazel.build/) to build your Swift projects and want to ensure that only properly formatted code is merged to your main branch, try [rules_swiftformat](https://github.com/cgrindel/rules_swiftformat). The repository contains Bazel rules and macros that format Swift source files using SwiftFormat, test that the formatted files exist in the workspace directory, and copy the formatted files to the workspace directory.\n\n\nDocker\n-----------\n\nSwiftFormat publishes releases into [GitHub Packages](https://github.com/features/packages) Docker registry. To pull the image call:\n\n```bash\n$ docker pull ghcr.io/nicklockwood/swiftformat:latest\n```\n\nBy default, the container runs `swiftformat .` Therefore, you need to provide a path either via an argument:\n\n```bash\ndocker run --rm -v /local/source/path:/work ghcr.io/nicklockwood/swiftformat:latest /work\n```\n\nor by changing the working dir:\n\n```bash\ndocker run --rm -v /local/source/path:/work -w /work ghcr.io/nicklockwood/swiftformat:latest\n```\n\nTo check the installed SwiftFormat version:\n\n```bash\ndocker run --rm ghcr.io/nicklockwood/swiftformat:latest --version\n```\n\nLinting example:\n\n```bash\ndocker run --rm -v /local/source/path:/work ghcr.io/nicklockwood/swiftformat:latest /work --lint\n```\n\nPrerelease Builds\n-----------------\n\n***Prerelease builds are subject to breaking changes.***\n\nNew rules, options, and fixes are merged to the [`develop`](https://github.com/nicklockwood/SwiftFormat/commits/develop/) branch before being incorporated into an official release. You may want to use a prerelease version of SwiftFormat that includes the latest unreleased changes.\n\n**Homebrew:**\n\nThe [Homebrew](http://brew.sh/) `--HEAD` option downloads, builds, and installs the latest changes from the `develop` branch. \n\nYou can install a prerelease build via Homebrew by running:\n\n```bash\n$ brew install swiftformat --HEAD\n```\n\n**Nightly Builds:**\n\nNightly builds of the `develop` branch are available in the [calda/SwiftFormat-nightly](https://github.com/calda/SwiftFormat-nightly) repo. A new release is published every day, unless there have been no changes to `develop` since the last release. You can download executables for the latest nightly release [here](https://github.com/calda/SwiftFormat-nightly/releases/latest).\n\nCommit SHAs on `develop` are unstable since that branch is occasionally rebased, but artifact URLs and tags in [calda/SwiftFormat-nightly](https://github.com/calda/SwiftFormat-nightly) are stable references that can be used from other repos or tools.\n\nConfiguration\n-------------\n\nSwiftFormat's configuration is split between **rules** and **options**. Rules are functions in the SwiftFormat library that apply changes to the code. Options are settings that control the behavior of the rules. \n\n\nOptions\n-------\n\nThe options available in SwiftFormat can be displayed using the `--options` command-line argument. The default value for each option is indicated in the help text.\n\nRules are configured by adding `--[option_name] [value]` to your command-line arguments, or by creating a `.swiftformat` [config file](#config-file) and placing it in your project directory.\n\nA given option may affect multiple rules. Use `--rule-info [rule_name]` command for details about which options affect a given rule, or see the [Rules.md](https://github.com/nicklockwood/SwiftFormat/blob/main/Rules.md) file.\n\nYou can configure options for specific files or code ranges by using `swiftformat:options` directive in comments inside your Swift file. To temporarily set one or more options inside a source file, use:\n\n```swift\n// swiftformat:options --indent 2 --allman true\n```\n\nTo apply an options override only to a particular line, use the `:this`, `:next` or `:previous` modifiers:\n\n```swift\nlet indexUrl: URL // swiftformat:options:this --preserve-acronyms url \n\n// swiftformat:options:next --semicolons inline\ndoTheThing(); print(\"Did the thing\")\n```\n\n\nRules\n-----\n\nSwiftFormat includes over 50 rules, and new ones are added all the time. An up-to-date list can be found in [Rules.md](https://github.com/nicklockwood/SwiftFormat/blob/main/Rules.md) along with documentation for how they are used.\n\nThe list of available rules can be displayed within the command-line app using the `--rules` argument. Rules can be either enabled or disabled. Most are enabled by default. Disabled rules are marked with \"(disabled)\" when displayed using `--rules`.\n\nYou can use the `--rule-info [rule_name]` command to get information about a specific rule. Pass a comma-delimited list of rule names to get information for multiple rules at once, or use `--rule-info` with no argument for info on all rules.\n\nYou can disable rules individually using `--disable` followed by a list of one or more comma-delimited rule names, or enable opt-in rules using `--enable` followed by the rule names:\n\n```bash\n--disable redundantSelf,trailingClosures\n--enable isEmpty\n```\n\nIf you prefer, you can use multiple `--enable`/`--disable` arguments instead of using commas:\n\n```bash\n--disable indent\n--disable linebreaks\n--disable redundantSelf\n```\n\nAlternatively, you can use the line continuation character `\\` to wrap a single argument over multiple line:\n\n```bash         \n--disable          \\\n    indent,        \\\n    linebreaks,    \\\n    redundantSelf\n```\n\nTo avoid automatically opting-in to new rules when SwiftFormat is updated, you can disable all rules using:\n\n```bash\n--disable all\n```\n\nAnd then individually enable just the rules you want. Alternatively, use the`--rules` argument to *only* enable the rules you specify:\n\n```bash\n--rules indent,linebreaks\n```\n\nAs above, you may include multiple `--rules` arguments, or use the line continuation character `\\` to wrap the rules onto separate lines:\n\n```bash\n--rules redundantSelf\n--rules         \\\n    indent,     \\\n    linebreaks\n```\n\nTo see exactly which rules were applied to a given file, you can use the `--verbose` command-line option to force SwiftFormat to print a more detailed log as it applies the formatting. **NOTE:** running in verbose mode is slower than the default mode.\n\nYou can disable rules for specific files or code ranges by using `swiftformat:` directives in comments inside your Swift file. To temporarily disable one or more rules inside a source file, use:\n\n```swift\n// swiftformat:disable <rule1> [<rule2> [rule<3> ...]]\n```\n\nTo enable the rule(s) again, use:\n\n```swift\n// swiftformat:enable <rule1> [<rule2> [rule<3> ...]]\n```\n\nTo disable all rules use:\n\n```swift\n// swiftformat:disable all\n```\n\nAnd to enable them all again, use:\n\n```swift\n// swiftformat:enable all\n```\n\nTo temporarily prevent one or more rules being applied to just the next line, use:\n\n```swift\n// swiftformat:disable:next <rule1> [<rule2> [rule<3> ...]]\nlet foo = bar // rule(s) will be disabled for this line\nlet bar = baz // rule(s) will be re-enabled for this line\n```\n\nYou can also use `this` or `previous` to enable or disable rules for the current or previous line. There is no need to manually re-enable a rule after using the `next`, `this` or `previous` directives.\n\n**NOTE:** The `swiftformat:enable` directive only serves to counter a previous `swiftformat:disable` directive in the same file. It is not possible to use `swiftformat:enable` to enable a rule that was not already enabled when formatting started.\n\n\nSwift version\n-------------\n\nMost SwiftFormat rules are version-agnostic, but some are applicable only to newer Swift versions. These rules will be disabled automatically if the Swift version is not specified, so to make sure that the full functionality is available you should specify the version of Swift that is used by your project.\n\nYou can specify the Swift compiler version in one of two ways:\n\nYou can specify your project's Swift compiler version using the `--swift-version` command line argument. You can also add the `--swift-version` option to your `.swiftformat` file.\n\nAnother option is to add a `.swift-version` file to your project directory. This is a text file that should contain the minimum Swift version supported by your project, and is also supported by some other tools. Any `.swift-version` files always take precedence over the `--swift-version` argument.\n\nBoth the `.swift-version` file and the `--swift-version` option in a `.swiftformat` file are applied hierarchically; If you have submodules in your project that use a different Swift version, you can add separate swift version configurations for those directories.\n\nSwift language mode\n-------------------\n\nSwiftFormat also allows you to specify the Swift _language mode_ used by your project. This is distinct from the Swift compiler version. For example, you can use the Swift 6.0 compiler with either the Swift 5 language mode or the Swift 6 language mode. Some SwiftFormat rules will behave differently under different Swift language modes.\n\nYou can specify your project's Swift language mode using the `--language-mode` command line argument. You can also add the `--language-mode` option to your `.swiftformat` file.\n\nIf not specified, SwiftFormat uses the default language mode of the specified Swift compiler version. The default language mode in Swift 5.x and Swift 6.x is the Swift 5 language mode. If your project uses the Swift 6 language mode, you should specify `--language-mode 6`.\n\n\nConfig file\n-----------\n\nAlthough it is possible to configure SwiftFormat directly by using the command-line [options](#options) and [rules](#rules) detailed above, it is sometimes more convenient to create a configuration file, which can be added to your project and shared with other developers.\n\nA SwiftFormat configuration file consists of one or more command-line options, split onto separate lines, e.g:\n\n```\n--allman true\n--indent tab\n--disable elseOnSameLine,semicolons\n```\n\nWhile formatting, SwiftFormat will automatically check inside each subdirectory for the presence of a `.swiftformat` file and will apply any options that it finds there to the files in that directory.\n\nThis allows you to override certain rules or formatting options just for a particular directory of files. You can also specify excluded files relative to that directory using `--exclude`, which may be more convenient than specifying them at the top-level:\n\n```\n--exclude Pods,Generated\n```\n\nThe `--exclude` option takes a comma-delimited list of file or directory paths to exclude from formatting. Excluded paths are relative to the config file containing the `--exclude` command. The excluded paths can include wildcards, specified using Unix \"Glob\" syntax, as [documented below](#globs).\n\nConfig files named \".swiftformat\" will be processed automatically, however, you can select an additional configuration file to use for formatting using the `--config \"path/to/config/file\"` command-line argument. A configuration file selected using `--config` does not need to be named \".swiftformat\", and can be located outside of the project directory.\n\nThe config file format is designed to be edited by hand. You may include blank lines for readability, and can also add comments using a hash prefix (#), e.g.\n\n```\n# format options\n--allman true\n--indent tab # tabs FTW!\n\n# file options\n--exclude Pods\n\n# rules\n--disable elseOnSameLine,semicolons\n```\n\nYou can create multiple configuration sections within a single `.swiftformat` file to apply different formatting options to different parts of your project. Each section should specify a `--filter` glob pattern to determine which files the configuration applies to. Options in that section are used when formatting files that match `--filter` glob, in addition to the base options in the file.\n\n```\n--enable indent\n--indent 4\n\n[Tests]\n--filter **/Tests/**\n--enable noForceUnwrapInTests\n--enable noForceTryInTests\n--indent 2\n```\n\nIf you would prefer not to edit the configuration file by hand, you can use the [SwiftFormat for Xcode](#xcode-source-editor-extension) app to edit the configuration and export a configuration file. You can also use the swiftformat command-line-tool's `--inferoptions` command to generate a config file from your existing project, like this:\n\n```bash\n$ cd /path/to/project\n$ swiftformat --infer-options . --output .swiftformat\n```\n\nGlobs\n-----\n\nWhen excluding files from formatting using the `--exclude` option, you may wish to make use of wildcard paths (aka \"Globs\") to match all files that match a particular naming convention without having to manually list them all.\n\nSwiftFormat's glob syntax is based on Ruby's implementation, which varies slightly from the Unix standard. The following patterns are supported:\n\n* `*` - A single star matches zero or more characters in a filename, but *not* a `/`.\n\n* `**` - A double star will match anything, including one or more `/`.\n\n* `?` - A question mark will match any single character except `/`.\n\n* `[abc]` - Matches any single character inside the brackets.\n\n* `[a-z]` - Matches a single character in the specified range in the brackets.\n\n* `{foo,bar}` - Matches any one of the comma-delimited strings inside the braces.\n\nExamples:\n\n* `foo.swift` - Matches the file \"foo.swift\" in the same directory as the config file.\n\n* `*.swift` - Matches any Swift file in the same directory as the config file.\n\n* `foo/bar.swift` - Matches the file \"bar.swift\" in the directory \"foo\".\n\n* `**/foo.swift` - Matches any file named \"foo.swift\" in the project.\n\n* `**/*.swift` - Matches any Swift file in the project.\n\n* `**/Generated` - Matches any folder called `Generated` in the project.\n\n* `**/*_generated.swift` - Matches any Swift file with the suffix \"_generated\" in the project.\n\n\nLinting\n-------\n\nSwiftFormat is primarily designed as a formatter rather than a linter, i.e. it is designed to fix your code rather than tell you what's wrong with it. However, sometimes it can be useful to verify that code has been formatted in a context where it is not desirable to actually change it.\n\nA typical example would be as part of a CI (Continuous Integration) process, where you may wish to have an automated script that checks committed code for style violations. While you can use a separate tool such as [SwiftLint](https://github.com/realm/SwiftLint) for this, it makes sense to be able to validate the formatting against the exact same rules as you are using to apply it.\n\nIn order to run SwiftFormat as a linter, you can use the `--lint` command-line option:\n\n```bash\n$ swiftformat --lint path/to/project\n```\n\nThis runs the same rules as format mode, and all the same configuration options apply, however, no files will be modified. Instead, SwiftFormat will format each file in memory and then compare the result against the input and report the lines that required changes.\n\nThe `--lint` option is similar to `--dry-run`, but `--lint` returns warnings for every line that required changes, and will return a nonzero error code (see [Error codes](#error-codes) below) if any changes are detected, which is useful if you want it to fail a build step on your CI server.\n\nIf you would prefer `--lint` not to fail your build, you can use the `--lenient` option to force SwiftFormat to return success in `--lint` mode even when formatting issues were detected.\n\n```bash\n$ swiftformat --lint --lenient path/to/project\n```\n\nBy default, `--lint` will only report lines that require formatting, but you can use the additional `--verbose` flag to display additional info about which files were checked, even if there were no changes needed.\n\nIf you would prefer not to see a warning for each and every formatting change, you can use the `--quiet` flag to suppress all output except errors.\n\nSometimes you may wish to autoformat some rules, but only lint others. To do that, use the `--lintonly` option in your config file to specify rules that should only be applied in `--lint` mode:\n\n```\n--rules braces,indent\n--lint-only trailingClosures,unusedArguments\n```\n\n\nError codes\n-----------\n\nThe swiftformat command-line tool will always exit with one of the following codes:\n\n* 0 - Success. This code will be returned in the event of a successful formatting run or if `--lint` detects no violations.\n* 1 - Lint failure. This code will be returned when running in `--lint` mode, or when autocorrecting in `--strict` mode, if the input requires formatting.\n* 70 - Program error. This code will be returned if there is a problem with the input or configuration arguments.\n\n\nCache\n------\n\nSwiftFormat uses a cache file to avoid reformatting files that haven't changed. For a large project, this can significantly reduce processing time.\n\nBy default, the cache is stored in `~/Library/Caches/com.charcoaldesign.swiftformat` on macOS, or `/tmp/com.charcoaldesign.swiftformat` on Linux. Use the command-line option `--cache ignore` to ignore the cached version and re-apply formatting to all files. Alternatively, you can use `--cache clear` to delete the cache (or you can just manually delete the cache file).\n\nThe cache is shared between all projects. The file is fairly small, as it only stores the path and size for each file, not the contents. If you do start experiencing slowdown due to the cache growing too large, you might want to consider using a separate cache file for each project.\n\nYou can specify a custom cache file location by passing a path as the `--cache` option value. For example, you might want to store the cache file inside your project directory. It is fine to check in the cache file if you want to share it between different users of your project, as the paths stored in the cache are relative to the location of the formatted files.\n\n\nFile headers\n-------------\n\nSwiftFormat can be configured to strip or replace the header comments in every file with a template. The \"header comment\" is defined as a comment block that begins on the first nonblank line in the file, and is followed by at least one blank line. This may consist of a single comment body, or multiple comments on consecutive lines:\n\n```swift\n// This is a header comment\n```\n\n```swift\n// This is a regular comment\nfunc foo(bar: Int) -> Void { ... }\n```\n\nThe header template is a string that you provide using the `--header` command-line option. Passing a value of `ignore` (the default) will leave the header comments unmodified. Passing `strip` or an empty string `\"\"` will remove them. If you wish to provide a custom header template, the format is as follows:\n\nFor a single-line template: `--header \"Copyright (c) 2017 Foobar Industries\"`\n\nFor a multiline comment, mark linebreaks with `\\n`: `--header \"First line\\nSecond line\"`\n\nYou can optionally include Swift comment markup in the template if you wish: `--header \"/*--- Header comment ---*/\"`\n\nIf you do not include comment markup, each line in the template will be prepended with `//` and a single space.\n\nIt is common practice to include the file name, creation date and/or the current year in a comment header copyright notice. To do that, you can use the following placeholders:\n\n* `{file}` - the name of the file\n* `{year}` - the current year\n* `{created}` - the date on which the file was created\n* `{created.year}` - the year in which the file was created\n* `{author.name}` - the name of the user who first committed the file\n* `{author.email}` - the email of the user who first committed the file \n\nFor example, a header template of:\n\n```bash\n--header \"{file}\\nCopyright (c) {year} Foobar Industries\\nCreated by John Smith on {created}.\"\n```\n\nWill be formatted as:\n\n```swift\n// SomeFile.swift\n// Copyright (c) 2019 Foobar Industries\n// Created by John Smith on 01/02/2016.\n```\n\n**NOTE:** the `{year}` value and `{created}` date format are determined from the current locale and timezone of the machine running the script. `{author.name}` and `{author.email}` requires the project to be version controlled by git.\n\n\nMarkdown formatting\n-------------------\n\nSwiftFormat can format Swift code blocks inside Markdown files (`.md`). This is useful for keeping code examples in documentation, README files, and other markdown content properly formatted.\n\n````diff\n  ### Sample README\n  \n  This is a nice project with lots of cool APIs to know about, including:\n  \n  ```swift\n  func foo(\n- bar: Bar,\n- baaz: Baaz\n+     bar: Bar,\n+     baaz: Baaz\n  ) -> Foo { ... }\n  ```\n````\n\nTo format Swift code blocks in markdown files, use the `--markdown-files` option with either `strict` or `lenient`:\n\n```bash\n$ swiftformat . --markdown-files strict\n$ swiftformat . --markdown-files lenient\n```\n\nOr add it to your `.swiftformat` config file:\n\n```\n--markdown-files strict\n```\n\n**Formatting modes:**\n\nSwiftFormat supports two modes for handling markdown files:\n\n- `lenient` (default): Ignores parsing errors in code blocks and continues formatting\n- `strict`: Fails if any code blocks contain parsing errors\n\nSwiftFormat's tokenizer is more permissive than the Swift compiler and typically only emits errors when encountering unbalanced scope tokens like `(` or `{`.\n\n**Code block options:**\n\nYou can specify options for options for individual code blocks by adding them after the opening delimiter. For example, you can use `no-format` to prevent a code block from being parsed or formatted:\n\n````md\n```swift no-format\nfunc example()\n{\n    doSomething()\n}\n```\n````\n\nYou can also specify SwiftFormat command line options to configure the behavior of individual rules:\n\n````md\n```swift --indent 2\nfunc example() {\n  doSomething()\n}\n```\n\n```swift --disable redundantSelf\nfunc example() {\n    self.doSomething()\n}\n```\n````\n\nFAQ\n-----\n\n*Q. How is this different from SwiftLint?*\n\n> A. SwiftLint is primarily designed to find and report code smells and style violations in your code. SwiftFormat is designed to fix them. While SwiftLint can autocorrect some issues, and SwiftFormat has some support for [linting](#linting), their primary functions are different.\n\n\n*Q. Can SwiftFormat and SwiftLint be used together?*\n\n> A. Absolutely! The style rules encouraged by both tools are quite similar, and SwiftFormat even fixes some style violations that SwiftLint warns about but can't currently autocorrect.\n\n\n*Q. What platforms does SwiftFormat support?*\n\n> A. SwiftFormat works on macOS 10.13 (High Sierra) and above, and also runs on Ubuntu Linux and Windows.\n\n\n*Q. What versions of Swift are supported?*\n\n> A. The SwiftFormat framework and command-line tool can be compiled using Swift 5.3 and above, and can format programs written in Swift 4.x or 5. Swift 3.x is no longer actively supported. If you are still using Swift 3.x or earlier and find that SwiftFormat breaks your code, the best solution is probably to revert to an earlier SwiftFormat release, or enable only a small subset of rules. Use the `--swift-version` argument to enable additional rules specific to later Swift versions.\n\n\n*Q. SwiftFormat made changes I didn't want it to. How can I find out which rules to disable?*\n\n> A. If you run SwiftFormat using the `--verbose` option, it will tell you which rules were applied to each file. You can then selectively disable certain rules using the `--disable` argument (see below).\n\n\n*Q. People on my team have different SwiftFormat versions installed. How can we ensure consistent formatting?\n\n> A. You can specify a `--min-version` argument in your project's .swiftformat` file to fail the build if developers attempt to use an older SwiftFormat version.\n\n\n*Q. How can I modify the formatting rules?*\n\n> A. Many configuration options are exposed in the command-line interface or `.swiftformat` configuration file. You can either set these manually, or use the `--infer-options` argument to automatically generate the configuration from your existing project.\n\n> If there is a rule that you don't like, and which cannot be configured to your liking via the command-line options, you can disable one or more rules by using the `--disable` argument, followed by the name of the rules, separated by commas. You can display a list of all supported rules using the `--rules` argument, and their behaviors are documented above this section in the README.\n\n> If you are using the Xcode source editor extension, rules and options can be configured using the [SwiftFormat for Xcode](#xcode-source-editor-extension) host application. Unfortunately, due to limitation of the Extensions API, there is no way to configure these on a per-project basis.\n\n> If the options you want aren't exposed, and disabling the rule doesn't solve the problem, the rules are implemented in the file `Rules.swift`, so you can modify them and build a new version of the command-line tool. If you think your changes might be generally useful, make a pull request.\n\n\nQ. I don't want to be surprised by new rules added when I upgrade SwiftFormat. How can I prevent this?\n\n> A. You can use the `--rules` argument to specify an exclusive list of rules to run. If new rules are added, they won't be enabled if you have specified a `--rules` list in your SwiftFormat configuration.\n\n\n*Q. Why can't I set the indent width or choose between tabs/spaces in the [SwiftFormat for Xcode](#xcode-source-editor-extension) options?*\n\n> Indent width and tabs/spaces can be configured in Xcode on a per project-basis. You'll find the option under \"Text Settings\" in the Files inspector of the right-hand sidebar.\n\n\n*Q. After applying SwiftFormat, my code won't compile. Is that a bug?*\n\n> A. SwiftFormat should ideally never break your code. Check the [known issues](#known-issues), and if it's not already listed there, or the suggested workaround doesn't solve your problem, please [open an issue on GitHub](https://github.com/nicklockwood/SwiftFormat/issues).\n\n\n*Q. Can I use SwiftFormat to lint my code without changing it?*\n\n> A. Yes, see the [linting](#linting) section above for details.\n\n\n*Q. Can I use the `SwiftFormat.framework` inside another app?*\n\n> A. Yes, the SwiftFormat framework can be included in an app or test target, and used for many kinds of parsing and processing of Swift source code besides formatting. The SwiftFormat framework is available as a [CocoaPod](https://cocoapods.org/pods/SwiftFormat) for easy integration.\n\n*Q. How to create own rule?*\n\n> A. 1) Open `SwiftFormat.xcodeproj`; 2) Add a rule in `Sources/Rules/..`; 3) Add a test in `Tests/Rules/..`; 4) Add an example in `Sources/Examples.swift`; 5) Run all tests.\n\n*Q. How do I run and debug the command line tool in Xcode while developing a new rule?*\n\n> A. You can run the `swiftformat` command line tool via the `Swift Format (Command Line Tool)` scheme, and you can pass in arguments like `/path/to/my/code --config /path/to/my/config` as the `Arguments Passed On Launch` in Xcode's scheme editor. More instructions are available [here](https://github.com/nicklockwood/SwiftFormat/pull/1804#issuecomment-2263079432).\n\nKnown issues\n---------------\n\n* When using the Xcode Source Editor Extension, the SwiftFormat menu sometimes disappears from Xcode. If this happens, try moving or renaming Xcode temporarily and then changing it back. Failing that, the suggestions in [this thread](https://github.com/nicklockwood/SwiftFormat/issues/494) may help.\n\n* The `enumNamespaces` rule replaces classes that have only static members with an `enum`. If the class is subclassed, or if there is code that depends on the class exposing certain runtime behaviors, this may break the program. To solve this you can either fix it on a per-case basis by adding a `// swiftformat:disable:next enumNamespaces` comment directive above the class declaration, or you can add `--enum-namespaces structs-only` to prevent the rule being applied to classes, or you can just disable the `enumNamespaces` rule completely.\n\n* The `redundantVoidReturnType` rule can inadvertently alter the type signature for closures, for example in cases where the closure calls a `@discardableResult` function. To solve this you can either fix it on a per-case basis by adding a `// swiftformat:disable:next redundantVoidReturnType` comment directive to disable the rule for a specific call site, or you can add `--closure-void preserve` to your [configuration](#configuration) to disable the rule completely for closures (regular functions or methods aren't affected).\n\n* The `redundantType` rule can introduce ambiguous code in certain cases when using the default mode of `--redundant-type inferred`. This can be worked around by by using `--redundant-type explicit`, or by manually removing the redundant type reference on the affected line, or by using the `// swiftformat:disable:next redundantType` comment directive to disable the rule at the call site (or just disable the `redundantType` rule completely).\n\n* If a type initializer or factory method returns an implicitly unwrapped optional value then the `redundantType` rule may remove the explicit type in a situation where it's actually required. To work around this you can either use `--redundant-type explicit`, or use the `// swiftformat:disable:next redundantType` comment directive to disable the rule at the call site (or just disable the `redundantType` rule completely).\n\n* When using the `initCoderUnavailable` rule, if an `init` that is marked as unavailable is overridden elsewhere in the program then it will cause a compilation error. The recommended workaround is to remove the override (which shouldn't affect the program behavior if the init was really unused) or use the `// swiftformat:disable:next initCoderUnavailable` comment directive to disable the rule for the overridden init (or just disable the `initCoderUnavailable` rule completely).\n\n* When using the `extensionAccessControl` rule with the `--extension-acl on-extension` option, if you have public methods defined on an internal type defined in another file, the resultant public extension will no longer compile. The recommended solution is to manually remove the `public` modifier (this won't change the program behavior) or disable the `extensionAccessControl` rule.\n\n* When using the `preferKeyPath` rule, conversion of `compactMap { $0.foo }` to `compactMap(\\.foo)` or `flatMap { $0.foo }` to `flatMap(\\.foo)` will result in code that fails to compile if `foo` is not an `Optional` property. This is due to a difference in the way that Swift handles type inference for closures vs keyPaths, as discussed [here](https://bugs.swift.org/browse/SR-13347). The recommended workaround is to replace `compactMap()` or `flatMap()` with `map()` in these cases, which will not change the behavior of the code.\n\n* When using the `--self remove` option, the `redundantSelf` rule will remove references to `self` in autoclosure arguments, which may change the meaning of the code, or cause it not to compile. To work around this issue, use the `--self-required` option to provide a comma-delimited list of methods to be excluded from the rule. The `expect()` function from the popular [Nimble](https://github.com/Quick/Nimble) unit testing framework is already excluded by default. If you are using the `--self insert` option then this is not an issue.\n\n* If you assign `SomeClass.self` to a variable and then instantiate an instance of the class using that variable, Swift requires that you use an explicit `.init()`, however, the `redundantInit` rule is not currently capable of detecting this situation in all cases, and may remove the `.init`. To work around this issue, use the `// swiftformat:disable:next redundantInit` comment directive to disable the rule for any affected lines of code (or just disable the `redundantInit` rule completely).\n\n* The `--self insert` option can only recognize locally declared member variables, not ones inherited from superclasses or extensions in other files, so it cannot insert missing `self` references for those. Note that the reverse is not true: `--self remove` should remove *all* redundant `self` references.\n\n* The `trailingClosures` rule can generate ambiguous code if a function has multiple optional closure arguments, or if multiple functions have signatures differing only by the name of the closure argument. For this reason, the rule is limited to anonymous closure arguments by default. You can use the `--trailing-closures` and `--never-trailing` arguments to explicitly opt in or out of trailing closure support for specific functions.\n\n* The `isEmpty` rule will convert `count == 0` to `isEmpty` even for types that do not have an `isEmpty` method, such as `NSArray`/`NSDictionary`/etc. Use of Foundation collections in Swift code is pretty rare, but just in case, the rule is disabled by default.\n\n* The `preferForLoop` rule will convert `foo.forEach` to `for item in foo` even for types that do not conform to the `Sequence` protocol and cannot be used with a `for ... in` loop. There are no such types built in, but custom types may have this issue.\n\n* If a file begins with a comment, the `stripHeaders` rule will remove it if it is followed by a blank line. To avoid this, make sure that the first comment is directly followed by a line of code.\n\n* When running a version of SwiftFormat built using Xcode 10.2 on macOS 10.14.3 or earlier, you may experience a crash with the error \"dyld: Library not loaded: @rpath/libswiftCore.dylib\". To fix this, you need to install the [Swift 5 Runtime Support for Command Line Tools](https://support.apple.com/kb/DL1998). These tools are included by default in macOS 10.14.4 and later.\n\n* If you have a generic typealias that defines a closure (e.g. `typealias ResultCompletion<T> = (Result<T, Error>) -> Void`) and use this closure as an argument in a generic function (e.g. `func handle<T: Decodable>(_ completion: ResultCompletion<T>)`), the `opaqueGenericParameters` rule may update the function definition to use `some` syntax (e.g. `func handle(_ completion: ResultCompletion<some Decodable>)`). `some` syntax is not permitted in closure parameters, so this will no longer compile. Workarounds include spelling out the closure explicitly in the generic function (instead of using a `typealias`) or disabling the `opaqueGenericParameters` rule (e.g. with `// swiftformat:disable:next opaqueGenericParameters`).\n\n* If compiling for macOS with Xcode 14.0 and configuring SwiftFormat with `--swift-version 5.7`, the `genericExtensions` rule may cause a build failure by updating extensions of the format `extension Collection where Element == Foo` to `extension Collection<Foo>`. This fails to compile for macOS in Xcode 14.0, because the macOS SDK in that version of Xcode [does not include](https://forums.swift.org/t/xcode-14-rc-cannot-specialize-protocol-type/60171) the Swift 5.7 standard library. Workarounds include using `--swift-version 5.6` instead, updating to Xcode 14.1+, or disabling the `genericExtensions` rule (e.g. with `// swiftformat:disable:next genericExtensions`).\n\n* The `propertyTypes` rule can cause a build failure in cases where there are multiple static overloads with the same name but different return types. As a workaround you can rename the overloads to no longer conflict, or exclude the property name with `--preserve-symbols propertyName,otherPropertyName,etc`.\n\n* The `propertyTypes` rule can cause a build failure in cases where the property's type is a protocol / existential like `let shapeStyle: ShapeStyle = .myShapeStyle`, and the value used on the right-hand side is defined in an extension like `extension ShapeStyle where Self == MyShapeStyle { static var myShapeStyle: MyShapeStyle { ... } }`. As a workaround you can use the existential `any` syntax (`let shapeStyle: any ShapeStyle = .myShapeStyle`), which the rule will preserve as-is, or exclude the type name and/or property name with `--preserve-symbols ShapeStyle,myShapeStyle,etc`.\n\n* The `propertyTypes` rule can cause a build failure in cases like `let foo = Foo.bar` where the value is a static member that doesn't return the same time. For example, `let foo: Foo = .bar` would be invalid if the `bar` property was defined as `static var bar: Bar`. As a workaround you can write the name of the type explicitly, like `let foo: Bar = Foo.bar`, or exclude the type name and/or property name with `--preserve-symbols Bar,bar,etc`.\n\n\nTip Jar\n-----------\n\nSwiftFormat is not a commercially-funded product, it's a labor of love given freely to the community. If you find it useful, please consider making a donation.\n\n[![Donate via PayPal](https://www.paypalobjects.com/en_GB/i/btn/btn_donate_LG.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=9ZGWNK5FEZFF6&source=url)\n\n\nCredits\n------------\n\n* [Cal Stephens](https://github.com/calda) - Numerous new formatting rules, options and bug fixes\n* [Tony Arnold](https://github.com/tonyarnold) - SwiftFormat for Xcode\n* [Vincent Bernier](https://github.com/vinceburn) - SwiftFormat for Xcode settings UI\n* [Vikram Kriplaney](https://github.com/markiv) - SwiftFormat for Xcode icon and search feature\n* [Hyperphonic](https://github.com/hyperphonic0) - Xcode 12 compatibility for SwiftFormat\n* [Maxime Marinel](https://github.com/bourvill) - Git pre-commit hook script\n* [Romain Pouclet](https://github.com/palleas) - Homebrew formula\n* [Aerobounce](https://github.com/aerobounce) - Homebrew cask and Sublime Text plugin\n* [Facundo Menzella](https://github.com/facumenzella) - Several new formatting rules and options\n* [Ali Akhtarzada](https://github.com/aliak00) - Several path-related CLI enhancements\n* [Yonas Kolb](https://github.com/yonaskolb) - Swift Package Manager integration\n* [Wolfgang Lutz](https://github.com/Lutzifer) - AppleScript integration instructions\n* [BalÃ¡zs KilvÃ¡dy](https://github.com/balitm) - Xcode lint warning integration\n* [Anthony Miller](https://github.com/AnthonyMDev) - Improvements to wrap/indent logic\n* [Shingo Takagi](https://github.com/zizi4n5) - Several brace-related bug fixes\n* [Benedek Kozma](https://github.com/cyberbeni) - Lint-only rules option\n* [Juri Pakaste](https://github.com/juri) - Filelist feature\n* [Jim Puls](https://github.com/puls) - Big Sur icon update\n* [Daniele Formichelli](https://github.com/danyf90) - JSON reporter\n* [Jonas Boberg](https://github.com/bobergj) - Github actions log reporter\n* [Mahdi Bchatnia](https://github.com/inket) - Linux build workflow\n* [Saleem Abdulrasool](https://github.com/compnerd) - Windows build workflow\n* [Arthur Semenyutin](https://github.com/vox-humana) - Docker image\n* [Marco Eidinger](https://github.com/MarcoEidinger) - Swift Package Manager plugin\n* [Hampus TaÌŠgerud](https://github.com/hampustagerud) - Git integration for fileHeader rule\n* [Nick Lockwood](https://github.com/nicklockwood) - Everything else\n\n([Full list of contributors](https://github.com/nicklockwood/SwiftFormat/graphs/contributors))\n",
      "stars_today": 5
    },
    {
      "id": 37778564,
      "name": "Clipy",
      "full_name": "Clipy/Clipy",
      "description": "Clipboard extension app for macOS.",
      "html_url": "https://github.com/Clipy/Clipy",
      "stars": 8348,
      "forks": 714,
      "language": "Swift",
      "topics": [
        "clipboard",
        "clipboard-extension",
        "clipmenu",
        "macos",
        "swift",
        "xcode"
      ],
      "created_at": "2015-06-20T17:21:24Z",
      "updated_at": "2026-01-16T00:34:00Z",
      "pushed_at": "2024-06-29T14:02:13Z",
      "open_issues": 256,
      "owner": {
        "login": "Clipy",
        "avatar_url": "https://avatars.githubusercontent.com/u/12979368?v=4"
      },
      "readme": "<div align=\"center\">\n  <img src=\"./Resources/clipy_logo.png\" width=\"400\">\n</div>\n\n<br>\n\n![CI](https://github.com/Clipy/Clipy/workflows/CI/badge.svg)\n[![Release version](https://img.shields.io/github/release/Clipy/Clipy.svg)](https://github.com/Clipy/Clipy/releases/latest)\n[![OpenCollective](https://opencollective.com/clipy/backers/badge.svg)](#backers)\n[![OpenCollective](https://opencollective.com/clipy/sponsors/badge.svg)](#sponsors)\n\nClipy is a Clipboard extension app for macOS.\n\n---\n\n__Requirement__: macOS 10.10 Yosemite or higher\n\n__Distribution Site__ : <https://clipy-app.com>\n\n<img src=\"http://clipy-app.com/img/screenshot1.png\" width=\"400\">\n\n### Development Environment\n* macOS 10.15 Catalina\n* Xcode 12.2\n* Swift 5.3\n\n### How to Build\n0. Move to the project root directory\n1. `bundle install --path=vendor/bundle && bundle exec pod install`\n2. Open `Clipy.xcworkspace` on Xcode.\n3. build.\n\n### Contributing\n1. Fork it ( https://github.com/Clipy/Clipy/fork )\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create a new Pull Request\n\n### Localization Contributors\nClipy is looking for localization contributors.  \nIf you can contribute, please see [CONTRIBUTING.md](https://github.com/Clipy/Clipy/blob/master/.github/CONTRIBUTING.md)\n\n### Distribution\nIf you distribute derived work, especially in the Mac App Store, I ask you to follow two rules:\n\n1. Don't use `Clipy` and `ClipMenu` as your product name.\n2. Follow the MIT license terms.\n\nThank you for your cooperation.\n\n### Backers\n\nSupport us with a monthly donation and help us continue our activities. [[Become a backer](https://opencollective.com/clipy#backer)]\n\n<a href=\"https://opencollective.com/clipy/backer/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/10/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/11/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/12/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/13/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/14/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/15/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/16/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/17/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/18/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/19/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/20/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/21/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/22/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/23/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/24/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/24/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/25/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/25/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/26/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/26/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/27/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/27/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/28/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/28/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/backer/29/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/backer/29/avatar.svg\"></a>\n\n### Sponsors\n\nBecome a sponsor and get your logo on our README on Github with a link to your site. [[Become a sponsor](https://opencollective.com/clipy#sponsor)]\n\n<a href=\"https://opencollective.com/clipy/sponsor/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/10/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/11/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/12/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/13/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/14/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/15/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/16/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/17/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/18/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/19/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/20/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/21/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/22/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/23/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/24/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/24/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/25/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/25/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/26/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/26/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/27/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/27/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/28/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/28/avatar.svg\"></a>\n<a href=\"https://opencollective.com/clipy/sponsor/29/website\" target=\"_blank\"><img src=\"https://opencollective.com/clipy/sponsor/29/avatar.svg\"></a>\n\n### Licence\nClipy is available under the MIT license. See the LICENSE file for more info.\n\nIcons are copyrighted by their respective authors.\n\n### Special Thanks\n__Thank you for [@naotaka](https://github.com/naotaka) who have published [ClipMenu](https://github.com/naotaka/ClipMenu) as OSS.__\n",
      "stars_today": 5
    },
    {
      "id": 189829392,
      "name": "ever-gauzy",
      "full_name": "ever-co/ever-gauzy",
      "description": "EverÂ® Gauzyâ„¢ - Open Business Management Platform (ERP/CRM/HRM/ATS/PM) - https://gauzy.co",
      "html_url": "https://github.com/ever-co/ever-gauzy",
      "stars": 3407,
      "forks": 717,
      "language": "TypeScript",
      "topics": [
        "accounting",
        "billing",
        "bookkeeping",
        "crm",
        "crm-platform",
        "erp",
        "expenses",
        "hr",
        "human-resources",
        "invoices",
        "invoicing",
        "issue-tracker",
        "payroll",
        "productivity",
        "project-management",
        "salary",
        "team-management",
        "time-tracker",
        "time-tracking",
        "timetracking"
      ],
      "created_at": "2019-06-02T09:47:13Z",
      "updated_at": "2026-01-16T00:08:52Z",
      "pushed_at": "2026-01-15T18:00:22Z",
      "open_issues": 405,
      "owner": {
        "login": "ever-co",
        "avatar_url": "https://avatars.githubusercontent.com/u/41295674?v=4"
      },
      "readme": "# Ever Gauzy Platform\n\n[uri_gauzy]: https://gauzy.co\n[uri_license]: https://www.gnu.org/licenses/agpl-3.0.html\n[uri_license_image]: https://img.shields.io/badge/License-AGPL%20v3-blue.svg\n\n![visitors](https://visitor-badge.laobi.icu/badge?page_id=ever-co.gauzy-platform)\n[![License: AGPL v3][uri_license_image]][uri_license]\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ever-co/ever-gauzy)\n[![Gitpod Ready-to-Code](https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod)](https://gitpod.io/#https://github.com/ever-co/ever-gauzy)\n\n## ğŸ’¡ What's New\n\nWe released [Ever Teams](https://github.com/ever-co/ever-teams) platform for Work & Project Management.\nPlease check <https://github.com/ever-co/ever-teams> and make it â­ on GitHub!\nIt's built with a React (NextJs) / ReactNative (Expo) stack and connects to headless [Ever Gauzy Platform APIs](https://api.gauzy.co/docs).\n\n## ğŸŒŸ What is it\n\n[EverÂ® Gauzyâ„¢][uri_gauzy] - **Open Business Management Platform** for Collaborative, On-Demand and Sharing Economies.\n\n-   **Enterprise Resource Planning** (ERP)\n-   **Customer Relationship Management** (CRM)\n-   **Human Resource Management** (HRM)\n-   **Applicant Tracking System** (ATS)\n-   **Work and Project Management** (PM)\n-   **Employee Time-Tracking, Activity & Productivity Tracking**\n\n![overview](https://docs.gauzy.co/overview.png)\n\nEverÂ® Gauzyâ„¢ Platform is a part of our larger Open Platform for **Collaborative, On-Demand and Sharing Economies** - [EverÂ® Platformâ„¢](https://ever.co).\n\n## âœ¨ Features\n\nMain features:\n\n-   Human Resources Management (HRM) with Time Management / Tracking and Employees Performance Monitoring\n-   Customer Relationship Management (CRM)\n-   Enterprise Resource Planning (ERP)\n-   Projects / Tasks Management\n-   Sales Management\n-   Financial and Cost Management (including _Accounting_, _Invoicing_, etc)\n-   Inventory, Supply Chain Management, and Production Management\n\nA more detailed list of the features available in the platform:\n\n-   [Headless APIs](https://api.gauzy.co/docs)\n-   Dashboard (provides an overview of different metrics, such as company income/expenses, employee bonuses, etc.)\n-   Time Management / Time Tracking / Activity Tracking / Timesheets\n-   Employees Management (register of company employees/contractors, rates of employees, etc.)\n-   Employee Onboarding\n-   Applicant Tracking System (ATS) / Candidates Interviews\n-   Contacts Management (Clients / Customers / Leads / etc.)\n-   Schedules / Appointments / Events\n-   Project Management / Tasks\n-   Goals / KPI / Objectives / Key Results\n-   Sales Pipelines\n-   Proposals\n-   Accounting / Invoicing / Estimates\n-   Billing\n-   Payments\n-   Income / Expenses Management\n-   Time Off Management / Holidays / Approvals\n-   Inventory\n-   Equipment / Sharing\n-   Multiple Organizations Management\n-   Organization Departments and Teams\n-   Organization Clients and Vendors\n-   Help Center / Knowledge Base\n-   Tags / Labels\n-   Reports / Insights / Analytics\n-   Organization and Employee Public Pages\n-   Integrations (Upwork, HubStaff, etc.)\n-   Email History / Email Templates\n-   Data Import / Export\n-   Roles / Permissions\n-   Multi-currency\n-   Multi-lingual\n-   Dark / Light / Corporate / Material and other Themes\n\nRead more [about Gauzy](https://github.com/ever-co/ever-gauzy/wiki/About-Gauzy) and [how to use it](https://github.com/ever-co/ever-gauzy/wiki/How-to-use-Gauzy) at your company, on-demand business, freelance business, agency, studio or in-house teams.\n\n## ğŸŒ¼ Screenshots\n\n<details>\n<summary>Show / Hide Screenshots</summary>\n\n### Web UI\n\n![overview](https://docs.gauzy.co/overview.png)\n\n### Desktop Timer UI (Standard)\n\n![timer](https://docs.gauzy.co/desktop/desktop-timer-small.png)\n\n### Desktop Timer UI (Expanded)\n\n![timer](https://docs.gauzy.co/desktop/desktop-timer-expanded.png)\n\n</details>\n\n## ğŸ”— Links\n\n-   **<https://gauzy.co>** - check more information about the platform at the official website.\n-   **<https://app.gauzy.co>** - SaaS (Important: it's currently in Alpha version/testing mode, please use it cautiously).\n-   **<https://demo.gauzy.co>** - Online Demo (see more info below).\n-   **<https://gauzy.co/downloads>** - Download Platform & Apps (see also more info below about available downloads).\n-   **<https://docs.gauzy.co>** - Platform Documentation (WIP). See also our [Wiki](https://github.com/ever-co/ever-gauzy/wiki).\n-   **<https://ever.co>** - get more information about our company products.\n\n## ğŸ“Š Activity\n\n<a href=\"https://trendshift.io/repositories/1775\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/1775\" alt=\"ever-co%2Fever-gauzy | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n![Alt](https://repobeats.axiom.co/api/embed/7c6f6c3bf56fd91647549cf4ae70af49ed5ee106.svg 'Repobeats analytics image')\n\n## ğŸ’» Demo, Downloads, Testing and Production\n\n### Demo\n\nEver Gauzy Platform Demo at <https://demo.gauzy.co>.\n\nNotes:\n\n-   Default super-admin user login is `admin@ever.co` and the password is `admin`\n-   Content of demo DB resets on each deployment to the demo environment (usually daily)\n-   Demo environment deployed using CI/CD from the `develop` branch\n\n### Downloads\n\nYou can download Gauzy Platform, Gauzy Server, or Desktop Apps (Windows/Mac/Linux) from the official [Downloads](https://web.gauzy.co/downloads) page.\n\nIn addition, all releases and pre-releases downloads are also available from the following pages:\n\n-   [Platform Releases](https://github.com/ever-co/ever-gauzy/releases)\n-   [Apps](https://github.com/ever-co/ever-gauzy/wiki/Gauzy-Desktop-Apps)\n\n### Production (SaaS)\n\nEverÂ® Gauzyâ„¢ Platform SaaS is available at <https://app.gauzy.co>.\n\nNote: it's currently in Alpha version/testing mode, please use it cautiously!\n\n### Staging\n\n-   Gauzy Platform Staging builds (using CI/CD, from the `stage` branch) are available at <https://stage.gauzy.co>\n-   We are using the Staging environment to test releases before they are deployed to the production environment\n-   Our pre-releases of desktop/server apps are built from this environment and can be configured manually (in settings) to connect to Stage API: <https://apistage.gauzy.co>\n\n### Server & Desktop Apps\n\nWe have Gauzy Server and two Desktop Apps (for Windows/Mac/Linux):\n\n-   EverÂ® Gauzyâ„¢ Server - includes Gauzy API, SQLite DB (or connects to external PostgreSQL) and serves Guazy frontend. It allows to quickly run Gauzy Server for multiple clients (browser-based or Desktop-based). It's a recommended option if you want to setup the Ever Gauzy Platform in small to medium organizations.\n\n-   EverÂ® Gauzyâ„¢ Desktop App - includes Gauzy frontend (UI), Gauzy API, SQLite DB, etc., all-in-one! It allows to quickly run the whole Gauzy solution locally, both UI and Timer (for time tracking, optionally of course). In addition, it allows you to connect to the external database (e.g. PostgreSQL) or external API (if you have Gauzy Server with API / DB installed on a different computer or if you want to connect to our live API). It's a recommended option if you want to try Gauzy quickly / for personal use or if you want to connect to Gauzy Server in the \"client-server\" configuration (and use Desktop App instead of web browser).\n\n-   EverÂ® Gauzyâ„¢ Desktop Timer App - allows running Time and Activity Tracking for employees/contractors with screenshots and activity monitoring. It is recommended to setup by organization employees as long as they are not interested in other Gauzy Platform features (e.g. accounting) and only need to track work time.\n\nMore information about our Server & Desktop Apps:\n\n-   Download for your OS from the official [Downloads](https://web.gauzy.co/downloads) page or see the section \"Download\" above for other links to our releases pages.\n-   Setup Gauzy Server with default choices in Setup Wizard and run it.\n-   You can also setup Gauzy Desktop App (can run independently or connect to Gauzy Server) or Gauzy Desktop Timer App (should be connected to Gauzy Server)\n-   You can login with `admin@ever.co` and password `admin` to check Admin functionality if you installed Gauzy Server or Gauzy Desktop App. Note: such an Admin user is not an employee, so you will not be able to track time.\n-   You can login with `employee@ever.co` and password `123456` to check Employee-related functionality in Gauzy UI or to run Desktop Timer from an \"Employee\" perspective (such a user is an Employee and can track time).\n-   If you install Gauzy Server, it is possible to connect to it using a browser (by default on <http://localhost:4200>) or using Gauzy Desktop Apps (make sure to configure Desktop apps to connect to Gauzy API on <http://127.0.0.1:3000/api> because it's where Gauzy Server API runs by default).\n-   You can read more information about our Desktop Apps on the [Desktop Apps Wiki Page](https://github.com/ever-co/ever-gauzy/wiki/Gauzy-Desktop-Apps) and our Server at the [Server Wiki Page](https://github.com/ever-co/ever-gauzy/wiki/Gauzy-Server).\n\n## ğŸ§± Technology Stack and Requirements\n\n-   [TypeScript](https://www.typescriptlang.org)\n-   [NodeJs](https://nodejs.org) / [NestJs](https://github.com/nestjs/nest)\n-   [Nx](https://nx.dev) / [Lerna](https://github.com/lerna/lerna)\n-   [Angular](https://angular.io) / [RxJS](http://reactivex.io/rxjs) / [Ngx-admin](https://github.com/akveo/ngx-admin)\n-   [TypeORM](https://github.com/typeorm/typeorm) / [MikroORM](https://github.com/mikro-orm/mikro-orm) / [Knex](https://github.com/knex/knex)\n\nFor Production, we recommend:\n\n-   [PostgreSQL](https://www.postgresql.org) or [MySQL](https://dev.mysql.com)\n-   [Kubernetes](https://kubernetes.io), [Docker](https://www.docker.com)\n\nNote: thanks to TypeORM / MikroORM, Gauzy will support lots of DBs: SQLite (default, for demos), PostgreSQL (development/production), MySql (development/production), MariaDb, CockroachDb, MS SQL, Oracle, MongoDb, and others (with minimal changes).\n\n#### See also README.md and CREDITS.md files in relevant folders for lists of libraries and software included in the Platform, information about licenses, and other details\n\n## ğŸ“„ Documentation\n\nPlease refer to our official [Platform Documentation](https://docs.gauzy.co) and our [Wiki](https://github.com/ever-co/ever-gauzy/wiki) (WIP).\n\n## ğŸš€ Quick Start\n\n### With Docker Compose\n\n-   Clone repo.\n-   Make sure you have the latest Docker Compose [installed locally](https://docs.docker.com/compose/install). Important: you need a minimum [v2.20](https://docs.docker.com/compose/release-notes/#2200).\n\n#### Demo\n\n-   Run `docker-compose -f docker-compose.demo.yml up`, if you want to run the platform in basic configuration (e.g. for Demo / explore functionality / quick run) using our prebuilt Docker images. Check `.env.demo.compose` file for different settings (optionally), e.g. DB type. _(Note: Docker Compose will use latest images pre-build automatically from head of `master` branch using GitHub CI/CD.)_\n-   Open <http://localhost:4200> in your browser.\n-   Login with email `admin@ever.co` and password: `admin` for Super Admin user.\n-   Login with email `employee@ever.co` and password: `123456` for Employee user.\n-   Enjoy!\n\n#### Production\n\n-   Edit `.env.compose` (if needed) to use your custom settings, e.g. DB type.\n-   Run `docker-compose up -d`, if you want to run the platform in minimal production configuration using our prebuilt Docker images. _(Note: Docker Compose will use latest images pre-build automatically from head of `master` branch using GitHub CI/CD.)_\n\nNote: we recommend using Kubernetes for production workloads instead of Docker Compose!\n\n#### Build\n\n-   Edit `.env.compose` (if needed) to use your custom settings, e.g. DB type.\n-   Run `docker-compose -f docker-compose.build.yml up -d`, if you want to build everything (code and Docker images) locally. _(Note: this is extremely long process because it builds whole platform locally. Other options above are much faster!)_\n-   :coffee: time... It might take some time for our API to seed fake data in the DB during the first Docker Compose run, even if you used prebuilt Docker images.\n\nNotes:\n\n-   while demo `docker-compose.demo.yml` runs a minimum amount of containers (API, Web UI, and DB), other Docker Compose files run multiple infrastructure dependencies (see full list below).\n-   you can also run ONLY infra dependencies (without our API / Web containers) with `docker-compose -f docker-compose.infra.yml up -d` command. We already doing it using `include` in our main docker compose files.\n-   you can add something like `--env-file .env.something` to the docker-compose `up` command to instruct Docker Compose to use a specific `.env.something` file with your custom settings\n\nTogether with Gauzy, the Docker Compose commands described above for Production (`docker-compose.yml`) and Build (`docker-compose.build.yml`) will run the following infrastructure components:\n\n-   [PostgreSQL](https://www.postgresql.org) - Primary Database.\n-   [Pgweb](https://github.com/sosedoff/pgweb) - Cross-platform client for PostgreSQL DBs, available on <http://localhost:8081>.\n-   [OpenSearch](https://github.com/opensearch-project) - Search Engine.\n-   [OpenSearch Dashboards](https://github.com/opensearch-project) - Search Engine Dashboards, available on <http://localhost:5601>. Default username: `admin` and password: `Gauzy_password_123`\n-   [Dejavu](https://github.com/appbaseio/dejavu) - Web UI for OpenSearch, available on <http://localhost:1358>.\n-   [MinIO](https://github.com/minio/minio) - Multi-Cloud â˜ï¸ Object Storage (AWS S3 compatible).\n-   [Jitsu](https://github.com/jitsucom/jitsu) - Jitsu is an open-source Segment alternative (data ingestion engine).\n-   [Redis](https://github.com/redis/redis) - In-memory data store/caching (also used by Jitsu)\n-   [Cube](https://github.com/cube-js/cube) - \"Semantic Layer\" used for Reports, Dashboards, Analytics, and other BI-related features, with UI available on <http://localhost:4000>.\n-   [Zipkin](https://github.com/openzipkin/zipkin) - distributed tracing system.\n\n### Manually\n\n#### Required\n\n-   Install [NodeJs](https://nodejs.org/en/download) LTS version or later (e.g. version 22.x or 24.x).\n-   Install [Yarn](https://github.com/yarnpkg/yarn) v1.22.x (if you don't have it) with `npm i -g yarn`.\n-   Install NPM packages and Bootstrap solution using the command `yarn bootstrap`.\n-   If you will need to make code changes (and push to Git repo), please run `yarn prepare:husky`.\n-   Adjust settings in the [`.env.local`](https://github.com/ever-co/ever-gauzy/blob/develop/.env.local) which is used in local runs.\n-   Alternatively, you can copy [`.env.sample`](https://github.com/ever-co/ever-gauzy/blob/develop/.env.sample) to `.env` and change default settings there, e.g. database type, name, user, password, etc.\n-   Run both API and UI with a single command: `yarn start`.\n-   Open Gauzy UI on <http://localhost:4200> in your browser (API runs on <http://localhost:3000/api>).\n-   Login with email `admin@ever.co` and password: `admin` for Super Admin user.\n-   Login with email `employee@ever.co` and password: `123456` for Employee user.\n-   Enjoy!\n\nNotes:\n\n-   during the first API start, DB will be automatically seeded with a minimum set of initial data if no users are found.\n-   you can run seed any moment manually (e.g. if you changed entities schemas) with the `yarn seed` command to re-initialize DB (warning: unsafe for production!).\n-   it is possible to run generation of extremely large amounts of fake data for demo purposes/testing with `yarn seed:all` (warning: takes ~10 min to complete)\n\n#### Optional / Recommended for Production\n\n-   Optionally (recommended for production) install and run [PostgreSQL](https://www.postgresql.org) version 14 or later (16.x recommended for production). Note: other DB can be configured manually in TypeORM / MikroORM / Knex. The default DB is set to SQLite (recommended for testing/demo purposes only).\n-   Optionally (recommended for production) install and run [Redis](https://github.com/redis/redis). Notes: the platform will work without Redis using an in-memory caching strategy instead of a distributed one (recommended for testing/demo purposes only). Please note however that Redis is required for Jitsu.\n-   Optionally (recommended for production) install and run [OpenSearch](https://github.com/opensearch-project). Note: the platform will work without OpenSearch using DB build-in search capabilities (recommended for testing/demo purposes only).\n-   Optionally install and run [MinIO](https://github.com/minio/minio) or [LocalStack](https://github.com/localstack/localstack). Note: the platform will work without MinIO / LocalStack or other S3-compatible storage using local filesystem-based storage (recommended for testing/demo purposes only). For production, we recommend using Wasabi or AWS S3 storage or another S3-compatible cloud storage.\n-   Optionally (recommended for production) install and run [Jitsu](https://github.com/jitsucom/jitsu). Note: the platform will work without Jitsu, however, data ingestion will be disabled for additional analyses / real-time pipelines.\n-   Optionally (recommended for production) install and run [Cube](https://github.com/cube-js/cube). Note: the platform will work without Cube, however some advanced (dynamic) reporting and data processing capabilities will be disabled.\n\n### Production\n\n#### General information\n\n-   See [Setup Gauzy for Client Server](https://github.com/ever-co/ever-gauzy/wiki/Setup-Gauzy-for-Client-Server) for more information about production setup on your servers.\n\n#### Kubernetes\n\n-   We recommend deploying to Kubernetes (k8s), either manually (see below) or with our [Terraform Modules](https://github.com/ever-co/ever-gauzy-terraform) or [Ever Helm Charts](https://github.com/ever-co/ever-charts).\n-   For more simple deployment scenarios with k8s, please see [Kubernetes configurations](https://github.com/ever-co/ever-gauzy/tree/develop/.deploy/k8s), which we are using to deploy Gauzy into [DigitalOcean k8s cluster](https://www.digitalocean.com/products/kubernetes).\n\n#### DigitalOcean App Platform\n\n-   For the most simple deployment scenarios (e.g. for yourself or your small organization), check our [DigitalOcean App Platform configurations](https://github.com/ever-co/ever-gauzy/tree/develop/.do) and corresponding [GitHub Action](https://github.com/ever-co/ever-gauzy/blob/develop/.github/workflows/deploy-do-app-platform-stage.yml).\n\n#### Virtual Instances / Droplets (via SSH)\n\n-   Another variant to deploy Gauzy is to use DigitalOcean Droplets or any other virtual instance (with Ubuntu OS) and deploy using SCP/SSH, for example, following [GitHub Action](https://github.com/ever-co/ever-gauzy/blob/develop/.github/workflows/deploy-do-droplet-demo.yml)\n\n#### Pulumi\n\n-   In addition, check [Gauzy Pulumi](https://github.com/ever-co/ever-gauzy-pulumi) project (WIP), it makes complex Clouds deployments possible with a single command (`pulumi up`). Note: it currently supports AWS EKS (Kubernetes) for development and production with Application Load Balancers and AWS RDS Serverless PostgreSQL DB deployments. We also implemented deployments to ECS EC2 and Fargate Clusters in the same Pulumi project.\n\n## ğŸ’Œ Contact Us\n\n-   [Ever.co Website Contact Us page](https://ever.co/contacts)\n-   [Slack Community](https://join.slack.com/t/gauzy/shared_invite/enQtNzc5MTA5MDUwODg2LTI0MGEwYTlmNWFlNzQzMzBlOWExNTk0NzAyY2IwYWYwMzZjMTliYjMwNDI3NTJmYmM4MDQ4NDliMDNiNDY1NWU)\n-   [Discord Chat](https://discord.gg/hKQfn4j)\n-   [![Gitter](https://badges.gitter.im/JoinChat.svg)](https://gitter.im/ever-co/ever-gauzy?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n-   [![Get help on Codementor](https://cdn.codementor.io/badges/get_help_github.svg)](https://www.codementor.io/evereq?utm_source=github&utm_medium=button&utm_term=evereq&utm_campaign=github)\n-   For business inquiries: <mailto:gauzy@ever.co>\n-   Please report security vulnerabilities to <mailto:security@ever.co>\n-   [Gauzy Platform @ Twitter](https://twitter.com/gauzyplatform)\n-   [Gauzy Platform @ Facebook](https://www.facebook.com/gauzyplatform)\n\n## ğŸ” Security\n\nEverÂ® Gauzyâ„¢ follows good security practices, but 100% security cannot be guaranteed in any software!\nEverÂ® Gauzyâ„¢ is provided AS IS without any warranty. Use at your own risk!\nSee more details in the [LICENSE](LICENSE.md).\n\nIn a production setup, all client-side to server-side (backend, APIs) communications should be encrypted using HTTPS/WSS/SSL (REST APIs, GraphQL endpoint, Socket.io WebSockets, etc.).\n\nIf you discover any issue regarding security, please disclose the information responsibly by sending an email to <mailto:security@ever.co> or on [![huntr](https://cdn.huntr.dev/huntr_security_badge_mono.svg)](https://huntr.dev) and not by creating a GitHub issue.\n\n## ğŸ›¡ï¸ License\n\nWe support the open-source community. If you're building awesome non-profit/open-source projects, we're happy to help and will provide (subject to [acceptance criteria](https://github.com/ever-co/ever-gauzy/wiki/Free-license-and-hosting-for-Non-profit-and-Open-Source-projects)) Ever Gauzy Enterprise edition license and free hosting option! Feel free to contact us at <mailto:ever@ever.co> to make a request. More details are explained in our [Wiki](https://github.com/ever-co/ever-gauzy/wiki/Free-license-and-hosting-for-Non-profit-and-Open-Source-projects).\n\nThis software is available under the following licenses:\n\n-   [EverÂ® Gauzyâ„¢ Platform Community Edition](https://github.com/ever-co/ever-gauzy/blob/master/LICENSE.md#gauzy-platform-community-edition-license)\n-   [EverÂ® Gauzyâ„¢ Platform Small Business](https://github.com/ever-co/ever-gauzy/blob/master/LICENSE.md#gauzy-platform-small-business-license)\n-   [EverÂ® Gauzyâ„¢ Platform Enterprise](https://github.com/ever-co/ever-gauzy/blob/master/LICENSE.md#gauzy-platform-enterprise-license)\n\n#### The default EverÂ® Gauzyâ„¢ Platform license, without a valid EverÂ® Gauzyâ„¢ Platform Enterprise or EverÂ® Gauzyâ„¢ Platform Small Business License agreement, is the EverÂ® Gauzyâ„¢ Platform Community Edition License\n\n#### Please see [LICENSE](LICENSE.md) for more information on licenses. You can also [compare our offering](https://ever.co/compare-gauzy/#compare)\n\n[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fever-co%2Fgauzy.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Fever-co%2Fgauzy?ref=badge_large)\n\n## â„¢ï¸ Trademarks\n\n**Ever**Â® is a registered trademark of [Ever Co. LTD](https://ever.co).\n**EverÂ® Demandâ„¢**, **EverÂ® Gauzyâ„¢**, **EverÂ® Teamsâ„¢**, **EverÂ® Recâ„¢**, **EverÂ® Recuâ„¢**, **EverÂ® Clocâ„¢**, **EverÂ® Worksâ„¢** and **EverÂ® OpenSaaSâ„¢** are all trademarks of [Ever Co. LTD](https://ever.co).\n\nThe trademarks may only be used with the written permission of Ever Co. LTD. and may not be used to promote or otherwise market competitive products or services.\n\nAll other brand and product names are trademarks, registered trademarks, or service marks of their respective holders.\n\n## ğŸº Contribute\n\n-   Please give us :star: on Github, it **helps**!\n-   You are more than welcome to submit feature requests in the [separate repo](https://github.com/ever-co/feature-requests/issues)\n-   Pull requests are always welcome! Please base pull requests against the _develop_ branch and follow the [contributing guide](.github/CONTRIBUTING.md).\n\n## ğŸ’ª Thanks to our Contributors\n\nSee our contributors list in [CONTRIBUTORS.md](https://github.com/ever-co/ever-gauzy/blob/develop/.github/CONTRIBUTORS.md).\nYou can also view a full list of our [contributors tracked by Github](https://github.com/ever-co/ever-gauzy/graphs/contributors).\n\n<img src=\"https://contributors-img.web.app/image?repo=ever-co/ever-gauzy\" />\n\n## â­ Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=ever-co/ever-gauzy&type=Date)](https://star-history.com/#ever-co/ever-gauzy&Date)\n\n## â¤ï¸ Powered By\n\n<p>\n  <a href=\"https://www.digitalocean.com/?utm_medium=opensource&utm_source=ever-co\">\n    <img src=\"https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/PoweredByDO/DO_Powered_by_Badge_blue.svg\" width=\"201px\">\n  </a>\n</p>\n\n## Â©ï¸ Copyright\n\n#### Copyright Â© 2019-present, Ever Co. LTD. All rights reserved\n\n[![Circle CI](https://circleci.com/gh/ever-co/ever-gauzy.svg?style=svg)](https://circleci.com/gh/ever-co/ever-gauzy)\n[![codecov](https://codecov.io/gh/ever-co/ever-gauzy/branch/master/graph/badge.svg)](https://codecov.io/gh/ever-co/ever-gauzy)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/8c46f9eb9df64aa9859dea4d572059ac)](https://www.codacy.com/gh/ever-co/ever-gauzy/dashboard?utm_source=github.com&utm_medium=referral&utm_content=ever-co/ever-gauzy&utm_campaign=Badge_Grade)\n[![DeepScan grade](https://deepscan.io/api/teams/3293/projects/16703/branches/363423/badge/grade.svg)](https://deepscan.io/dashboard#view=project&tid=3293&pid=16703&bid=363423)\n[![Known Vulnerabilities](https://snyk.io/test/github/ever-co/ever-gauzy/badge.svg)](https://snyk.io/test/github/ever-co/ever-gauzy)\n[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fever-co%2Fever-gauzy.svg?type=shield)](https://app.fossa.io/projects/git%2Bgithub.com%2Fever-co%2Fgauzy?ref=badge_shield)\n[![Crowdin](https://badges.crowdin.net/e/1d2b3405d65a56ec116d0984fd579cc9/localized.svg)](https://ever.crowdin.com/gauzy)\n![CodeRabbit Pull Request Reviews](https://img.shields.io/coderabbit/prs/github/ever-co/ever-gauzy?utm_source=oss&utm_medium=github&utm_campaign=ever-co%2Fever-gauzy&labelColor=171717&color=FF570A&link=https%3A%2F%2Fcoderabbit.ai&label=CodeRabbit+Reviews)\n\n## ğŸ”¥ P.S\n\n-   If you are interested in running an on-demand (delivery) or digital marketplace business, check open-source [Ever Demand Platform](https://github.com/ever-co/ever-demand)\n-   [We are Hiring: remote TypeScript / NestJS / Angular developers](https://github.com/ever-co/jobs#available-positions)\n",
      "stars_today": 5
    },
    {
      "id": 976095156,
      "name": "koog",
      "full_name": "JetBrains/koog",
      "description": "Koog is the official Kotlin framework for building predictable, fault-tolerant and enterprise-ready AI agents across all platforms â€“ from backend services to Android and iOS, JVM, and even in-browser environments. Koog is based on our AI products expertise and provides proven solutions for complex LLM and AI problems",
      "html_url": "https://github.com/JetBrains/koog",
      "stars": 3623,
      "forks": 293,
      "language": "Kotlin",
      "topics": [
        "agentframework",
        "agentic-ai",
        "agents",
        "ai",
        "ai-agents-framework",
        "aiagentframework",
        "android-ai",
        "anthropic",
        "genai",
        "generative-ai",
        "java",
        "jvm",
        "kotlin",
        "ktor",
        "llm",
        "mcp",
        "multi-agent-systems",
        "ollama",
        "openai",
        "spring"
      ],
      "created_at": "2025-05-01T13:38:01Z",
      "updated_at": "2026-01-15T18:45:05Z",
      "pushed_at": "2026-01-15T17:29:01Z",
      "open_issues": 191,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "# Koog\n\n[![Kotlin Alpha](https://kotl.in/badges/alpha.svg)](https://kotlinlang.org/docs/components-stability.html)\n[![Maven Central](https://img.shields.io/maven-central/v/ai.koog/koog-agents)](https://search.maven.org/artifact/ai.koog/koog-agents)\n[![JetBrains incubator project](https://jb.gg/badges/incubator.svg)](https://github.com/JetBrains#jetbrains-on-github)\n[![Kotlin](https://img.shields.io/badge/kotlin-2.2-blue.svg?logo=kotlin)](http://kotlinlang.org)\n[![CI status](https://img.shields.io/github/checks-status/JetBrains/koog/main)](https://github.com/JetBrains/koog/actions?query=branch%3Amain)\n[![GitHub license](https://img.shields.io/github/license/JetBrains/koog)](LICENSE.txt)\n\nBuild status:\n\n[![Checks](https://github.com/JetBrains/koog/actions/workflows/checks.yml/badge.svg?branch=develop)](https://github.com/JetBrains/koog/actions/workflows/checks.yml?query=branch%3Adevelop)\n[![Heavy Tests](https://github.com/JetBrains/koog/actions/workflows/heavy-tests.yml/badge.svg?branch=develop)](https://github.com/JetBrains/koog/actions/workflows/heavy-tests.yml?query=branch%3Adevelop)\n[![Ollama Tests](https://github.com/JetBrains/koog/actions/workflows/ollama-tests.yml/badge.svg?branch=develop)](https://github.com/JetBrains/koog/actions/workflows/ollama-tests.yml?query=branch%3Adevelop)\n\nUseful links:\n\n* [Documentation](https://docs.koog.ai/)\n* [API reference](https://api.koog.ai/)\n* [Slack channel](https://docs.koog.ai/koog-slack-channel/)\n* [Issue tracker](https://youtrack.jetbrains.com/issues/KG)\n\n## Overview\n\nKoog is a Kotlin-based framework designed to build and run AI agents entirely in idiomatic Kotlin. It lets you create agents that can interact with tools, handle complex workflows, and communicate with users.\n\n### Key features\n\nKey features of Koog include:\n\n- **Multiplatform development**: Deploy agents across JVM, JS, WasmJS, Android, and iOS targets using Kotlin Multiplatform.\n- **Reliability and fault-tolerance**: Handle failures with built-in retries and restore the agent state at specific points during execution with the agent persistence feature.\n- **Intelligent history compression**: Optimize token usage while maintaining context in long-running conversations using advanced built-in history compression techniques.\n- **Enterprise-ready integrations**: Utilize integration with popular JVM frameworks such as Spring Boot and Ktor to embed Koog into your applications.\n- **Observability with OpenTelemetry exporters**: Monitor and debug applications with built-in support for popular observability providers (W&B Weave, Langfuse).\n- **LLM switching and seamless history adaptation**: Switch to a different LLM at any point without losing the existing conversation history, or reroute between multiple LLM providers.\n- **Integration with JVM and Kotlin applications**: Build AI agents with an idiomatic, type-safe Kotlin DSL designed specifically for JVM and Kotlin developers.\n- **Model Context Protocol integration**: Use Model Context Protocol (MCP) tools in AI agents.\n- **Agent Client Protocol integration**: Build ACP-compliant agents that can communicate with standardized client applications using the Agent Client Protocol (ACP).\n- **Knowledge retrieval and memory**: Retain and retrieve knowledge across conversations using vector embeddings, ranked document storage, and shared agent memory.\n- **Powerful Streaming API**: Process responses in real-time with streaming support and parallel tool calls.\n- **Modular feature system**: Customize agent capabilities through a composable architecture.\n- **Flexible graph workflows**: Design complex agent behaviors using intuitive graph-based workflows.\n- **Custom tool creation**: Enhance your agents with tools that access external systems and APIs.\n- **Comprehensive tracing**: Debug and monitor agent execution with detailed, configurable tracing.\n\n### Available LLM providers and platforms\n\nThe LLM providers and platforms whose LLMs you can use to power your agent capabilities:\n\n- Google\n- OpenAI\n- Anthropic\n- DeepSeek\n- OpenRouter\n- Ollama\n- Bedrock\n\n### Quickstart example\n\nTo help you get started with AI agents, here is a quick example:\n\n```kotlin\nfun main() = runBlocking {\n    // Before you run the example, assign a corresponding API key as an environment variable.\n   val apiKey = System.getenv(\"OPENAI_API_KEY\") // or Anthropic, Google, OpenRouter, etc.\n\n   val agent = AIAgent(\n      promptExecutor = simpleOpenAIExecutor(apiKey), // or Anthropic, Google, OpenRouter, etc.\n      systemPrompt = \"You are a helpful assistant. Answer user questions concisely.\",\n      llmModel = OpenAIModels.Chat.GPT4o\n   )\n\n   val result = agent.run(\"Hello! How can you help me?\")\n   println(result)\n}\n```\n\n## Using in your projects\n\n### Supported targets\n\nCurrently, the framework supports the JVM, JS, WasmJS and iOS targets.\n\n### Requirements\n\n- JDK 17 or higher is required to use the framework on JVM.\n- kotlinx-coroutines 1.10.2 and kotlinx-serialization 1.8.1 versions should be set explicitly in existing projects. Please check the [libs.versions.toml](gradle/libs.versions.toml) to know more about the Koog dependencies.\n\n### Gradle (Kotlin DSL)\n\n1. Add dependencies to the `build.gradle.kts` file:\n\n    ```\n    dependencies {\n        implementation(\"ai.koog:koog-agents:0.6.0\")\n    }\n    ```\n2. Make sure that you have `mavenCentral()` in the list of repositories.\n### Gradle (Groovy)\n\n1. Add dependencies to the `build.gradle` file:\n\n    ```\n    dependencies {\n        implementation 'ai.koog:koog-agents:0.6.0'\n    }\n    ```\n2. Make sure that you have `mavenCentral()` in the list of repositories.\n### Maven\n\n1. Add dependencies to the `pom.xml` file:\n\n    ```\n    <dependency>\n        <groupId>ai.koog</groupId>\n        <artifactId>koog-agents-jvm</artifactId>\n        <version>0.6.0</version>\n    </dependency>\n    ```\n2. Make sure that you have `mavenCentral` in the list of repositories.\n## Contributing\nRead the [Contributing Guidelines](CONTRIBUTING.md).\n\n## Code of Conduct\nThis project and the corresponding community are governed by the [JetBrains Open Source and Community Code of Conduct](https://github.com/jetbrains#code-of-conduct). Please make sure you read it.\n\n## License\nKoog is licensed under the [Apache 2.0 License](LICENSE.txt).\n\n## Support\n\nPlease feel free to ask any questions in our [official Slack\nchannel](https://docs.koog.ai/koog-slack-channel/) and to\nuse [Koog official YouTrack project](https://youtrack.jetbrains.com/issues/KG)\nfor filing feature requests and bug reports.\n\n\n",
      "stars_today": 5
    },
    {
      "id": 943421085,
      "name": "nixl",
      "full_name": "ai-dynamo/nixl",
      "description": "NVIDIA Inference Xfer Library (NIXL)",
      "html_url": "https://github.com/ai-dynamo/nixl",
      "stars": 810,
      "forks": 223,
      "language": "C++",
      "topics": [],
      "created_at": "2025-03-05T17:20:28Z",
      "updated_at": "2026-01-15T17:52:42Z",
      "pushed_at": "2026-01-15T17:58:06Z",
      "open_issues": 117,
      "owner": {
        "login": "ai-dynamo",
        "avatar_url": "https://avatars.githubusercontent.com/u/201626793?v=4"
      },
      "readme": "<!--\nSPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\nSPDX-License-Identifier: Apache-2.0\n-->\n\n# NVIDIA Inference Xfer Library (NIXL)\n\nNVIDIA Inference Xfer Library (NIXL) is targeted for accelerating point to point communications in AI inference frameworks such as NVIDIA Dynamo, while providing an abstraction over various types of memory (e.g., CPU and GPU) and storage (e.g., file, block and object store) through a modular plug-in architecture.\n\n[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/nixl)](https://github.com/ai-dynamo/nixl/releases/latest)\n\n## Pre-build Distributions\n### PyPI Wheel\n\nThe nixl python API and libraries, including UCX, are available directly through PyPI.\n\nIt can be installed for CUDA 12 with:\n\n```\npip install nixl[cu12]\n```\n\nFor CUDA 13 with:\n\n```\npip install nixl[cu13]\n```\n\nFor backwards compatibility, `pip install nixl` installs automatically `nixl[cu12]`, continuing to work seamlessly for CUDA 12 users without requiring changes to downstream project dependencies.\n\nIf both `nixl-cu12` and `nixl-cu13` are installed at the same time in an environment, `nixl-cu13` takes precedence.\n\n## Prerequisites for source build\n### Ubuntu:\n\n`$ sudo apt install build-essential cmake pkg-config`\n\n### Fedora:\n\n`$ sudo dnf install gcc-c++ cmake pkg-config`\n\n### Python\n\n`$ pip3 install meson ninja pybind11 tomlkit`\n\n### UCX\n\nNIXL was tested with UCX version 1.20.x.\n\n[GDRCopy](https://github.com/NVIDIA/gdrcopy) is available on Github and is necessary for maximum performance, but UCX and NIXL will work without it.\n\n```\n$ git clone https://github.com/openucx/ucx.git\n$ cd ucx\n$ git checkout v1.20.x\n$ ./autogen.sh\n$ ./contrib/configure-release-mt       \\\n    --enable-shared                    \\\n    --disable-static                   \\\n    --disable-doxygen-doc              \\\n    --enable-optimizations             \\\n    --enable-cma                       \\\n    --enable-devel-headers             \\\n    --with-cuda=<cuda install>         \\\n    --with-verbs                       \\\n    --with-dm                          \\\n    --with-gdrcopy=<gdrcopy install>\n$ make -j\n$ make -j install-strip\n$ ldconfig\n```\n\n### ETCD (Optional)\nNIXL can use ETCD for metadata distribution and coordination between nodes in distributed environments. To use ETCD with NIXL:\n#### ETCD Server and Client\n ```\n$ sudo apt install etcd etcd-server etcd-client\n\n# Or use Docker\n$ docker run -d -p 2379:2379 quay.io/coreos/etcd:v3.5.1\n```\n\n#### ETCD CPP API\nInstalled from https://github.com/etcd-cpp-apiv3/etcd-cpp-apiv3\n\n```\n$ sudo apt install libgrpc-dev libgrpc++-dev libprotobuf-dev protobuf-compiler-grpc\n$ sudo apt install libcpprest-dev\n$ git clone https://github.com/etcd-cpp-apiv3/etcd-cpp-apiv3.git\n$ cd etcd-cpp-apiv3\n$ mkdir build && cd build\n$ cmake ..\n$ make -j$(nproc) && make install\n```\n\n### Additional plugins\n\nSome plugins may have additional build requirements, see them here:\n\n- [Mooncake](src/plugins/mooncake/README.md)\n- [POSIX](src/plugins/posix/README.md)\n- [GDS](src/plugins/cuda_gds/README.md)\n\n## Getting started\n### Build & install\n\n```\n$ meson setup <name_of_build_dir>\n$ cd <name_of_build_dir>\n$ ninja\n$ ninja install\n```\n\n### Build Options\n\n#### Release build (default)\n\n```bash\n$ meson setup <name_of_build_dir>\n```\n\n#### Debug build\n\n```bash\n$ meson setup <name_of_build_dir> --buildtype=debug\n```\n\n#### NIXL-specific build options\n\n```bash\n# Example with custom options\n$ meson setup <name_of_build_dir> \\\n    -Dbuild_docs=true \\           # Build Doxygen documentation\n    -Ducx_path=/path/to/ucx \\     # Custom UCX installation path\n    -Dinstall_headers=true \\      # Install development headers\n    -Ddisable_gds_backend=false   # Enable GDS backend\n```\n\nCommon build options:\n- `build_docs`: Build Doxygen documentation (default: false)\n- `ucx_path`: Path to UCX installation (default: system path)\n- `install_headers`: Install development headers (default: true)\n- `disable_gds_backend`: Disable GDS backend (default: false)\n- `cudapath_inc`, `cudapath_lib`: Custom CUDA paths\n- `static_plugins`: Comma-separated list of plugins to build statically\n- `enable_plugins`: Comma-separated list of plugins to build (e.g. `-Denable_plugins=UCX,POSIX`). Cannot be used with `disable_plugins`.\n- `disable_plugins`: Comma-separated list of plugins to exclude (e.g. `-Ddisable_plugins=GDS`). Cannot be used with `enable_plugins`.\n\n#### Environment Variables\n\nThere are a few environment variables that can be set to configure the build:\n- `NIXL_NO_STUBS_FALLBACK`: If not set or 0, build NIXL stub library if the library build fails\n\n### Building Documentation\n\nIf you have Doxygen installed, you can build the documentation:\n\n```bash\n# Configure with documentation enabled\n$ meson setup <name_of_build_dir> -Dbuild_docs=true\n$ cd <name_of_build_dir>\n$ ninja\n\n# Documentation will be generated in <name_of_build_dir>/html\n# After installation (ninja install), documentation will be available in <prefix>/share/doc/nixl/\n```\n\n### Python Interface\n\nNIXL provides Python bindings through pybind11. For detailed Python API documentation, see [docs/python_api.md](docs/python_api.md).\n\nThe preferred way to install the Python bindings is through pip from PyPI:\n\n```bash\npip install nixl[cu12]\n```\n\nOr for CUDA 13 with:\n\n```bash\npip install nixl[cu13]\n```\n\nTo build and install the Python bindings from source, you have to build and install separately the platform-specific package and the `nixl` meta-package:\n\nOn CUDA 12:\n\n```\npip install .\nmeson setup build\nninja -C build\npip install build/src/bindings/python/nixl-meta/nixl-*-py3-none-any.whl\n```\n\nOn CUDA 13:\n\n```\npip install .\n./contrib/tomlutil.py --wheel-name nixl-cu13 pyproject.toml\nmeson setup build\nninja -C build\npip install build/src/bindings/python/nixl-meta/nixl-*-py3-none-any.whl\n```\n\nFor Python examples, see [examples/python/](examples/python/).\n\n### Rust Bindings\n#### Build\n- Use `-Drust=true` meson option to build rust bindings.\n- Use `--buildtype=debug` for a debug build (default is release).\n- Or build manually:\n    ```bash\n    $ cargo build --release\n    ```\n#### Install\nThe bindings will be installed under `nixl-sys` in the configured installation prefix.\nCan be done using ninja, from project build directory:\n```bash\n$ ninja install\n```\n\n#### Test\n```\n# Rust bindings tests\n$ cargo test\n```\n\nUse in your project by adding to `Cargo.toml`:\n```toml\n[dependencies]\nnixl-sys = { path = \"path/to/nixl/bindings/rust\" }\n```\n\n### Other build options\nSee [contrib/README.md](contrib/README.md) for more build options.\n\n### Building Docker container\nTo build the docker container, first clone the current repository. Also make sure you are able to pull docker images to your machine before attempting to build the container.\n\nRun the following from the root folder of the cloned NIXL repository:\n```\n$ ./contrib/build-container.sh\n```\n\nBy default, the container is built with Ubuntu 24.04. To build a container for Ubuntu 22.04 use the --os option as follows:\n```\n$ ./contrib/build-container.sh --os ubuntu22\n```\n\nTo see all the options supported by the container use:\n```\n$ ./contrib/build-container.sh -h\n```\n\nThe container also includes a prebuilt python wheel in /workspace/dist if required for installing/distributing. Also, the wheel can be built with a separate script (see below).\n\n### Building the python wheel\nThe contrib folder also includes a script to build the python wheel with the UCX dependencies. Note, that UCX and other NIXL dependencies are required to be installed.\n```\n$ ./contrib/build-wheel.sh\n```\n\n## Running with ETCD\nNIXL can use ETCD for metadata exchange between distributed nodes. This is especially useful in containerized or cloud-native environments.\n\n### Environment Setup\nTo use ETCD with NIXL, set the following environment variables:\n\n```bash\n# Set ETCD endpoints (required) - replace localhost with the hostname of the etcd server\nexport NIXL_ETCD_ENDPOINTS=\"http://localhost:2379\"\n\n# Set ETCD namespace (optional, defaults to /nixl/agents)\nexport NIXL_ETCD_NAMESPACE=\"/nixl/agents\"\n```\n\n### Running the ETCD Example\nNIXL includes an example demonstrating metadata exchange and data transfer using ETCD:\n\n```bash\n# Start an ETCD server if not already running\n# For example:\n# docker run -d -p 2379:2379 quay.io/coreos/etcd:v3.5.1\n\n# Set the ETCD env variables as above\n\n# Run the example. The two agents in the example will exchange metadata through ETCD\n# and perform data transfers\n./<nixl_build_path>/examples/nixl_etcd_example\n```\n\n### nixlbench Benchmark\nFor more comprehensive testing, the nixlbench benchmarking tool supports ETCD for worker coordination:\n\n```bash\n# Build nixlbench (see benchmark/nixlbench/README.md for details)\ncd benchmark/nixlbench\nmeson setup build && cd build && ninja\n\n# Run benchmark with ETCD\n./nixlbench --etcd-endpoints http://localhost:2379 --backend UCX --initiator_seg_type VRAM\n```\n\n## Examples\n\n* [C++ examples](https://github.com/ai-dynamo/nixl/tree/main/examples/cpp)\n\n* [Python examples](https://github.com/ai-dynamo/nixl/tree/main/examples/python)\n\n## Third-Party Components\n\nThis project will download and install additional third-party open source software projects. Review the license terms of these open source projects before use.\n",
      "stars_today": 5
    },
    {
      "id": 93444615,
      "name": "terraform-provider-aws",
      "full_name": "hashicorp/terraform-provider-aws",
      "description": "The AWS Provider enables Terraform to manage AWS resources.",
      "html_url": "https://github.com/hashicorp/terraform-provider-aws",
      "stars": 10687,
      "forks": 9901,
      "language": "Go",
      "topics": [
        "aws",
        "terraform",
        "terraform-provider"
      ],
      "created_at": "2017-06-05T20:37:52Z",
      "updated_at": "2026-01-15T22:23:45Z",
      "pushed_at": "2026-01-15T22:44:26Z",
      "open_issues": 3449,
      "owner": {
        "login": "hashicorp",
        "avatar_url": "https://avatars.githubusercontent.com/u/761456?v=4"
      },
      "readme": "<!-- Copyright IBM Corp. 2014, 2026 -->\n<!-- SPDX-License-Identifier: MPL-2.0 -->\n\n<!-- markdownlint-disable first-line-h1 no-inline-html -->\n<a href=\"https://terraform.io\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\".github/terraform_logo_dark.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\".github/terraform_logo_light.svg\">\n    <img src=\".github/terraform_logo_light.svg\" alt=\"Terraform logo\" title=\"Terraform\" align=\"right\" height=\"50\">\n  </picture>\n</a>\n\n# Terraform AWS Provider\n\n[![Forums][discuss-badge]][discuss]\n\n[discuss-badge]: https://img.shields.io/badge/discuss-terraform--aws-623CE4.svg?style=flat\n[discuss]: https://discuss.hashicorp.com/c/terraform-providers/tf-aws/\n\nThe [AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs) enables [Terraform](https://terraform.io) to manage [AWS](https://aws.amazon.com) resources.\n\n- [Contributing guide](https://hashicorp.github.io/terraform-provider-aws/)\n- [Quarterly development roadmap](ROADMAP.md)\n- [FAQ](https://hashicorp.github.io/terraform-provider-aws/faq/)\n- [Tutorials](https://learn.hashicorp.com/collections/terraform/aws-get-started)\n- [discuss.hashicorp.com](https://discuss.hashicorp.com/c/terraform-providers/tf-aws/)\n\n_**Please note:** We take Terraform's security and our users' trust very seriously. If you believe you have found a security issue in the Terraform AWS Provider, please responsibly disclose it by contacting us at security@hashicorp.com._\n",
      "stars_today": 4
    },
    {
      "id": 49910095,
      "name": "vapor",
      "full_name": "vapor/vapor",
      "description": "ğŸ’§ A server-side Swift HTTP web framework.",
      "html_url": "https://github.com/vapor/vapor",
      "stars": 25898,
      "forks": 1518,
      "language": "Swift",
      "topics": [
        "framework",
        "http",
        "http2",
        "server",
        "server-side-swift",
        "swift",
        "vapor",
        "web-framework"
      ],
      "created_at": "2016-01-18T22:37:52Z",
      "updated_at": "2026-01-15T16:48:25Z",
      "pushed_at": "2026-01-15T22:09:45Z",
      "open_issues": 112,
      "owner": {
        "login": "vapor",
        "avatar_url": "https://avatars.githubusercontent.com/u/17364220?v=4"
      },
      "readme": "<a href=\"https://discord.gg/vapor\">\n\n![Vapor](https://user-images.githubusercontent.com/1342803/75634175-4876d680-5bd9-11ea-90d6-12c7b6a9ee3f.png)\n\n</a>\n\n<p align=\"center\">\n    <a href=\"https://docs.vapor.codes/4.0/\">\n        <img src=\"https://design.vapor.codes/images/readthedocs.svg\" alt=\"Documentation\">\n    </a>\n    <a href=\"https://discord.gg/vapor\">\n        <img src=\"https://design.vapor.codes/images/discordchat.svg\" alt=\"Team Chat\">\n    </a>\n    <a href=\"LICENSE\">\n        <img src=\"https://design.vapor.codes/images/mitlicense.svg\" alt=\"MIT License\">\n    </a>\n    <a href=\"https://github.com/vapor/vapor/actions/workflows/test.yml\">\n        <img src=\"https://img.shields.io/github/actions/workflow/status/vapor/vapor/test.yml?event=push&style=plastic&logo=github&label=tests&logoColor=%23ccc\" alt=\"Continuous Integration\">\n    </a>\n    <a href=\"https://codecov.io/gh/vapor/vapor\">\n        <img src=\"https://img.shields.io/codecov/c/github/vapor/vapor?style=plastic&logo=codecov&label=codecov\" alt=\"Code Coverage\">\n    </a>\n    <a href=\"https://swift.org\">\n        <img src=\"https://design.vapor.codes/images/swift60up.svg\" alt=\"Swift 6.0+\">\n    </a>\n    <a href=\"https://hachyderm.io/@codevapor\">\n        <img src=\"https://img.shields.io/badge/%20-@codevapor-6364f6.svg?style=plastic&logo=mastodon&labelColor=gray&logoColor=%239394ff\" alt=\"Mastodon\">\n    </a>\n</p>\n\n<br>\n\nVapor is an HTTP web framework for Swift. It provides a beautifully expressive and easy-to-use foundation for your next website, API, or cloud project.\n\nTake a look at some of the [awesome stuff](https://github.com/vapor-community/awesome-vapor) created with Vapor.\n\n### ğŸ’§ Community\n\nJoin the welcoming community of fellow Vapor developers on [Discord](https://vapor.team).\n\n### ğŸš€ Contributing\n\nTo contribute a **feature or idea** to Vapor, [create an issue](https://github.com/vapor/vapor/issues/new) explaining your idea or bring it up on [Discord](https://vapor.team).\n\nIf you find a **bug**, please [create an issue](https://github.com/vapor/vapor/issues/new). \n\nIf you find a **security vulnerability**, please contact [security@vapor.codes](mailto:security@vapor.codes) as soon as possible.\n\n### ğŸ’› Sponsors\n\nSupport Vapor's development by [becoming a sponsor](https://github.com/sponsors/vapor).\n\n<a href=\"https://www.brokenhands.io\">\n    <img src=\"https://user-images.githubusercontent.com/9938337/137103192-21f99099-6aaa-4cc1-a1a7-21ee767a72d1.png\" height=\"100px\" alt=\"Broken Hands\">\n</a>\n<a href=\"https://www.emergetools.com\">\n    <img src=\"https://user-images.githubusercontent.com/9938337/265658253-cb37d2fa-3251-497f-8eeb-ba7c95af373b.svg\" height=\"100px\" alt=\"Emerge Tools\">\n</a>\n<a href=\"https://github.com/MrLotU\">\n    <img src=\"https://user-images.githubusercontent.com/1342803/79599312-426a8580-80b3-11ea-89b3-8b2722485e37.png\" height=\"100px\" alt=\"Jari\">\n</a>\n<a href=\"https://github.com/DonutDane\">\n    <img src=\"https://user-images.githubusercontent.com/9938337/265657642-6b6b1705-9611-4547-8e2f-a3773fda87c6.png\" height=\"100px\" alt=\"Donut Dane\">\n</a>\n<a href=\"https://macstadium.com\">\n    <img src=\"https://uploads-ssl.webflow.com/5ac3c046c82724970fc60918/5c019d917bba312af7553b49_MacStadium-developerlogo.png\" height=\"100px\" alt=\"MacStadium\">\n</a>\n\n\n\n### ğŸ’š Backers\nSupport Vapor's development by [becoming a backer](https://github.com/sponsors/vapor).\n\n<!-- backers --><a href=\"https://github.com/slashmo\"><img src=\"https://github.com/slashmo.png\" width=\"60px\" alt=\"Moritz Lang\" /></a><a href=\"https://github.com/maartene\"><img src=\"https://github.com/maartene.png\" width=\"60px\" alt=\"Maarten Engels\" /></a><a href=\"https://github.com/tkrajacic\"><img src=\"https://github.com/tkrajacic.png\" width=\"60px\" alt=\"Thomas Krajacic\" /></a><a href=\"https://github.com/jessetipton\"><img src=\"https://github.com/jessetipton.png\" width=\"60px\" alt=\"Jesse Tipton\" /></a><a href=\"https://github.com/steve-h\"><img src=\"https://github.com/steve-h.png\" width=\"60px\" alt=\"Steve Hume\" /></a><a href=\"https://github.com/mikkelu\"><img src=\"https://github.com/mikkelu.png\" width=\"60px\" alt=\"Mikkel Ulstrup\" /></a><a href=\"https://github.com/g-Off\"><img src=\"https://github.com/g-Off.png\" width=\"60px\" alt=\"Geoffrey Foster\" /></a><a href=\"https://github.com/PSchmiedmayer\"><img src=\"https://github.com/PSchmiedmayer.png\" width=\"60px\" alt=\"Paul Schmiedmayer\" /></a><a href=\"https://github.com/ScottRobbins\"><img src=\"https://github.com/ScottRobbins.png\" width=\"60px\" alt=\"Scott Robbins\" /></a><a href=\"https://github.com/finestructure\"><img src=\"https://github.com/finestructure.png\" width=\"60px\" alt=\"Sven A. Schmidt\" /></a><a href=\"https://github.com/SpencerCurtis\"><img src=\"https://github.com/SpencerCurtis.png\" width=\"60px\" alt=\"Spencer Curtis\" /></a><a href=\"https://github.com/rausnitz\"><img src=\"https://github.com/rausnitz.png\" width=\"60px\" alt=\"Zach Rausnitz\" /></a><a href=\"https://github.com/masterofinsanity\"><img src=\"https://github.com/masterofinsanity.png\" width=\"60px\" alt=\"Tim â€Timinatorâ€œ Kretzschmar\" /></a><a href=\"https://github.com/klaas\"><img src=\"https://github.com/klaas.png\" width=\"60px\" alt=\"Klaas\" /></a><a href=\"https://github.com/Andrewangeta\"><img src=\"https://github.com/Andrewangeta.png\" width=\"60px\" alt=\"Andrew Edwards\" /></a><a href=\"https://github.com/addli\"><img src=\"https://github.com/addli.png\" width=\"60px\" alt=\"+Li, Inc.\" /></a><a href=\"https://github.com/doozMen\"><img src=\"https://github.com/doozMen.png\" width=\"60px\" alt=\"Stijn Willems\" /></a><a href=\"https://github.com/bitwit\"><img src=\"https://github.com/bitwit.png\" width=\"60px\" alt=\"Kyle Newsome\" /></a><a href=\"https://github.com/viaaurelia\"><img src=\"https://github.com/viaaurelia.png\" width=\"60px\" alt=\"Via Aurelia Solutions\" /></a><a href=\"https://github.com/kkiermasz\"><img src=\"https://github.com/kkiermasz.png\" width=\"60px\" alt=\"Jakub Kiermasz\" /></a><a href=\"https://github.com/bdrelling\"><img src=\"https://github.com/bdrelling.png\" width=\"60px\" alt=\"Brian Drelling\" /></a><a href=\"https://github.com/mayondigital\"><img src=\"https://github.com/mayondigital.png\" width=\"60px\" alt=\"\" /></a><a href=\"https://github.com/mattesmohr\"><img src=\"https://github.com/mattesmohr.png\" width=\"60px\" alt=\"Mattes Mohr\" /></a><a href=\"https://github.com/scibidoo\"><img src=\"https://github.com/scibidoo.png\" width=\"60px\" alt=\"Jamie\" /></a><a href=\"https://github.com/GalenRhodes\"><img src=\"https://github.com/GalenRhodes.png\" width=\"60px\" alt=\"Galen Rhodes\" /></a><a href=\"https://github.com/litmaps\"><img src=\"https://github.com/litmaps.png\" width=\"60px\" alt=\"Litmaps\" /></a><a href=\"https://github.com/davdroman\"><img src=\"https://github.com/davdroman.png\" width=\"60px\" alt=\"David Roman\" /></a><a href=\"https://github.com/Strobocop\"><img src=\"https://github.com/Strobocop.png\" width=\"60px\" alt=\"Brian Strobach\" /></a><a href=\"https://github.com/kishikawakatsumi\"><img src=\"https://github.com/kishikawakatsumi.png\" width=\"60px\" alt=\"Kishikawa Katsumi\" /></a><a href=\"https://github.com/mkll\"><img src=\"https://github.com/mkll.png\" width=\"60px\" alt=\"Alex Sherbakov\" /></a><a href=\"https://github.com/getsidetrack\"><img src=\"https://github.com/getsidetrack.png\" width=\"60px\" alt=\"Sidetrack\" /></a><a href=\"https://github.com/GregKarpati\"><img src=\"https://github.com/GregKarpati.png\" width=\"60px\" alt=\"Greg Karpati\" /></a><a href=\"https://github.com/fananek\"><img src=\"https://github.com/fananek.png\" width=\"60px\" alt=\"FrantiÅ¡ek MikÅ¡\" /></a><a href=\"https://github.com/jagreenwood\"><img src=\"https://github.com/jagreenwood.png\" width=\"60px\" alt=\"Jeremy Greenwood\" /></a><a href=\"https://github.com/rayfix\"><img src=\"https://github.com/rayfix.png\" width=\"60px\" alt=\"Ray Fix\" /></a><a href=\"https://github.com/micomiloloza\"><img src=\"https://github.com/micomiloloza.png\" width=\"60px\" alt=\"MiÄ‡o MiloloÅ¾a\" /></a><a href=\"https://github.com/awamser\"><img src=\"https://github.com/awamser.png\" width=\"60px\" alt=\"Alan\" /></a><a href=\"https://github.com/Suboptimierer\"><img src=\"https://github.com/Suboptimierer.png\" width=\"60px\" alt=\"Jonas Sannewald\" /></a><a href=\"https://github.com/TapEnvy-us-LLC\"><img src=\"https://github.com/TapEnvy-us-LLC.png\" width=\"60px\" alt=\"TapEnvy.us, LLC\" /></a><a href=\"https://github.com/JawadHF\"><img src=\"https://github.com/JawadHF.png\" width=\"60px\" alt=\"Jawad\" /></a><a href=\"https://github.com/PARAIPAN9\"><img src=\"https://github.com/PARAIPAN9.png\" width=\"60px\" alt=\"PARAIPAN SORIN\" /></a><a href=\"https://github.com/KalynDavis\"><img src=\"https://github.com/KalynDavis.png\" width=\"60px\" alt=\"Kalyn Davis\" /></a><a href=\"https://github.com/stevapple\"><img src=\"https://github.com/stevapple.png\" width=\"60px\" alt=\"YR Chen\" /></a><a href=\"https://github.com/roncuevas\"><img src=\"https://github.com/roncuevas.png\" width=\"60px\" alt=\"AarÃ³n MartÃ­nez Cuevas\" /></a><!-- backers -->\n\n<a href=\"https://opencollective.com/vapor/backer/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/10/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/11/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/12/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/13/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/14/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/15/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/16/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/17/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/18/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/19/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/20/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/21/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/22/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/23/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/24/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/24/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/25/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/25/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/26/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/26/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/27/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/27/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/28/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/28/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/29/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/29/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/30/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/30/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/31/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/31/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/32/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/32/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/33/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/33/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/34/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/34/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/35/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/35/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/36/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/36/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/37/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/37/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/38/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/38/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/39/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/39/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/40/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/40/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/41/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/41/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/42/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/42/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/43/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/43/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/44/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/44/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/45/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/45/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/46/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/46/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/47/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/47/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/48/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/48/avatar.svg\"></a>\n",
      "stars_today": 4
    },
    {
      "id": 53614190,
      "name": "mosquitto",
      "full_name": "eclipse-mosquitto/mosquitto",
      "description": "Eclipse Mosquitto - An open source MQTT broker",
      "html_url": "https://github.com/eclipse-mosquitto/mosquitto",
      "stars": 10513,
      "forks": 2572,
      "language": "C",
      "topics": [
        "broker",
        "eclipse-iot",
        "mosquitto",
        "mqtt"
      ],
      "created_at": "2016-03-10T20:19:09Z",
      "updated_at": "2026-01-15T18:21:38Z",
      "pushed_at": "2026-01-15T08:22:00Z",
      "open_issues": 809,
      "owner": {
        "login": "eclipse-mosquitto",
        "avatar_url": "https://avatars.githubusercontent.com/u/185921483?v=4"
      },
      "readme": "Eclipse Mosquitto\n=================\n\nMosquitto is an open source implementation of a server for version 5.0, 3.1.1,\nand 3.1 of the MQTT protocol. It also includes a C and C++ client library, and\nthe `mosquitto_pub` and `mosquitto_sub` utilities for publishing and\nsubscribing.\n\n## Links\n\nSee the following links for more information on MQTT:\n\n- Community page: <http://mqtt.org/>\n- MQTT v3.1.1 standard: <https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/mqtt-v3.1.1.html>\n- MQTT v5.0 standard: <https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html>\n\nMosquitto project information is available at the following locations:\n\n- Main homepage: <https://mosquitto.org/>\n- Find existing bugs or submit a new bug: <https://github.com/eclipse/mosquitto/issues>\n- Source code repository: <https://github.com/eclipse/mosquitto>\n\nThere is also a public test server available at <https://test.mosquitto.org/>\n\n## Installing\n\nSee <https://mosquitto.org/download/> for details on installing binaries for\nvarious platforms.\n\n## Quick start\n\nIf you have installed a binary package the broker should have been started\nautomatically. If not, it can be started with a very basic configuration:\n\n    mosquitto\n\nThen use `mosquitto_sub` to subscribe to a topic:\n\n    mosquitto_sub -t 'test/topic' -v\n\nAnd to publish a message:\n\n    mosquitto_pub -t 'test/topic' -m 'hello world'\n\nNote that starting the broker like this allows anonymous/unauthenticated access\nbut only from the local computer, so it's only really useful for initial testing.\n\nIf you want to have clients from another computer connect, you will need to\nprovide a configuration file. If you have installed from a binary package, you\nwill probably already have a configuration file at somewhere like\n`/etc/mosquitto/mosquitto.conf`. If you've compiled from source, you can write\nyour config file then run as `mosquitto -c /path/to/mosquitto.conf`.\n\nTo start your config file you define a listener and you will need to think\nabout what authentication you require. It is not advised to run your broker\nwith anonymous access when it is publically available.\n\nFor details on how to do this, look at the\n[authentication methods](https://mosquitto.org/documentation/authentication-methods/)\navailable and the [dynamic security plugin](https://mosquitto.org/documentation/dynamic-security/).\n\n## Documentation\n\nDocumentation for the broker, clients and client library API can be found in\nthe man pages, which are available online at <https://mosquitto.org/man/>. There\nare also pages with an introduction to the features of MQTT, the\n`mosquitto_passwd` utility for dealing with username/passwords, and a\ndescription of the configuration file options available for the broker.\n\nDetailed client library API documentation can be found at <https://mosquitto.org/api/>\n\n## Building from source\n\nTo build from source the recommended route for end users is to download the\narchive from <https://mosquitto.org/download/>.\n\nOn Windows and Mac, use `cmake` to build. On other platforms, just run `make`\nto build. For Windows, see also `README-windows.md`.\n\nIf you are building from the git repository then the documentation will not\nalready be built. Use `make binary` to skip building the man pages, or install\n`docbook-xsl` on Debian/Ubuntu systems.\n\n### Build Dependencies\n\n* c-ares (libc-ares-dev on Debian based systems) - only when compiled with `make WITH_SRV=yes`\n* cJSON - for client JSON output support. Disable with `make WITH_CJSON=no` Auto detected with CMake.\n* libwebsockets (libwebsockets-dev) - enable with `make WITH_WEBSOCKETS=yes`\n* openssl (libssl-dev on Debian based systems) - disable with `make WITH_TLS=no`\n* pthreads - for client library thread support. This is required to support the\n  `mosquitto_loop_start()` and `mosquitto_loop_stop()` functions. If compiled\n  without pthread support, the library isn't guaranteed to be thread safe.\n* uthash / utlist - bundled versions of these headers are provided, disable their use with `make WITH_BUNDLED_DEPS=no`\n* xsltproc (xsltproc and docbook-xsl on Debian based systems) - only needed when building from git sources - disable with `make WITH_DOCS=no`\n\nEquivalent options for enabling/disabling features are available when using the CMake build.\n\n\n## Credits\n\nMosquitto was written by Roger Light <roger@atchoo.org>\n",
      "stars_today": 4
    },
    {
      "id": 440752086,
      "name": "coder",
      "full_name": "coder/coder",
      "description": "Secure environments for developers and their agents",
      "html_url": "https://github.com/coder/coder",
      "stars": 11985,
      "forks": 1139,
      "language": "Go",
      "topics": [
        "agents",
        "dev-tools",
        "development-environment",
        "go",
        "golang",
        "ide",
        "jetbrains",
        "remote-development",
        "terraform",
        "vscode"
      ],
      "created_at": "2021-12-22T06:08:52Z",
      "updated_at": "2026-01-16T00:32:02Z",
      "pushed_at": "2026-01-16T00:52:32Z",
      "open_issues": 784,
      "owner": {
        "login": "coder",
        "avatar_url": "https://avatars.githubusercontent.com/u/95932066?v=4"
      },
      "readme": "<!-- markdownlint-disable MD041 -->\n<div align=\"center\">\n  <a href=\"https://coder.com#gh-light-mode-only\">\n    <img src=\"./docs/images/logo-black.png\" alt=\"Coder Logo Light\" style=\"width: 128px\">\n  </a>\n  <a href=\"https://coder.com#gh-dark-mode-only\">\n    <img src=\"./docs/images/logo-white.png\" alt=\"Coder Logo Dark\" style=\"width: 128px\">\n  </a>\n\n  <h1>\n  Self-Hosted Cloud Development Environments\n  </h1>\n\n  <a href=\"https://coder.com#gh-light-mode-only\">\n    <img src=\"./docs/images/banner-black.png\" alt=\"Coder Banner Light\" style=\"width: 650px\">\n  </a>\n  <a href=\"https://coder.com#gh-dark-mode-only\">\n    <img src=\"./docs/images/banner-white.png\" alt=\"Coder Banner Dark\" style=\"width: 650px\">\n  </a>\n\n  <br>\n  <br>\n\n[Quickstart](#quickstart) | [Docs](https://coder.com/docs) | [Why Coder](https://coder.com/why) | [Premium](https://coder.com/pricing#compare-plans)\n\n[![discord](https://img.shields.io/discord/747933592273027093?label=discord)](https://discord.gg/coder)\n[![release](https://img.shields.io/github/v/release/coder/coder)](https://github.com/coder/coder/releases/latest)\n[![godoc](https://pkg.go.dev/badge/github.com/coder/coder.svg)](https://pkg.go.dev/github.com/coder/coder)\n[![Go Report Card](https://goreportcard.com/badge/github.com/coder/coder/v2)](https://goreportcard.com/report/github.com/coder/coder/v2)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9511/badge)](https://www.bestpractices.dev/projects/9511)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/coder/coder/badge)](https://scorecard.dev/viewer/?uri=github.com%2Fcoder%2Fcoder)\n[![license](https://img.shields.io/github/license/coder/coder)](./LICENSE)\n\n</div>\n\n[Coder](https://coder.com) enables organizations to set up development environments in their public or private cloud infrastructure. Cloud development environments are defined with Terraform, connected through a secure high-speed WireguardÂ® tunnel, and automatically shut down when not used to save on costs. Coder gives engineering teams the flexibility to use the cloud for workloads most beneficial to them.\n\n- Define cloud development environments in Terraform\n  - EC2 VMs, Kubernetes Pods, Docker Containers, etc.\n- Automatically shutdown idle resources to save on costs\n- Onboard developers in seconds instead of days\n\n<p align=\"center\">\n  <img src=\"./docs/images/hero-image.png\" alt=\"Coder Hero Image\">\n</p>\n\n## Quickstart\n\nThe most convenient way to try Coder is to install it on your local machine and experiment with provisioning cloud development environments using Docker (works on Linux, macOS, and Windows).\n\n```shell\n# First, install Coder\ncurl -L https://coder.com/install.sh | sh\n\n# Start the Coder server (caches data in ~/.cache/coder)\ncoder server\n\n# Navigate to http://localhost:3000 to create your initial user,\n# create a Docker template and provision a workspace\n```\n\n## Install\n\nThe easiest way to install Coder is to use our\n[install script](https://github.com/coder/coder/blob/main/install.sh) for Linux\nand macOS. For Windows, use the latest `..._installer.exe` file from GitHub\nReleases.\n\n```shell\ncurl -L https://coder.com/install.sh | sh\n```\n\nYou can run the install script with `--dry-run` to see the commands that will be used to install without executing them. Run the install script with `--help` for additional flags.\n\n> See [install](https://coder.com/docs/install) for additional methods.\n\nOnce installed, you can start a production deployment with a single command:\n\n```shell\n# Automatically sets up an external access URL on *.try.coder.app\ncoder server\n\n# Requires a PostgreSQL instance (version 13 or higher) and external access URL\ncoder server --postgres-url <url> --access-url <url>\n```\n\nUse `coder --help` to get a list of flags and environment variables. Use our [install guides](https://coder.com/docs/install) for a complete walkthrough.\n\n## Documentation\n\nBrowse our docs [here](https://coder.com/docs) or visit a specific section below:\n\n- [**Templates**](https://coder.com/docs/templates): Templates are written in Terraform and describe the infrastructure for workspaces\n- [**Workspaces**](https://coder.com/docs/workspaces): Workspaces contain the IDEs, dependencies, and configuration information needed for software development\n- [**IDEs**](https://coder.com/docs/ides): Connect your existing editor to a workspace\n- [**Administration**](https://coder.com/docs/admin): Learn how to operate Coder\n- [**Premium**](https://coder.com/pricing#compare-plans): Learn about our paid features built for large teams\n\n## Support\n\nFeel free to [open an issue](https://github.com/coder/coder/issues/new) if you have questions, run into bugs, or have a feature request.\n\n[Join our Discord](https://discord.gg/coder) to provide feedback on in-progress features and chat with the community using Coder!\n\n## Integrations\n\nWe are always working on new integrations. Please feel free to open an issue and ask for an integration. Contributions are welcome in any official or community repositories.\n\n### Official\n\n- [**VS Code Extension**](https://marketplace.visualstudio.com/items?itemName=coder.coder-remote): Open any Coder workspace in VS Code with a single click\n- [**JetBrains Toolbox Plugin**](https://plugins.jetbrains.com/plugin/26968-coder): Open any Coder workspace from JetBrains Toolbox with a single click\n- [**JetBrains Gateway Plugin**](https://plugins.jetbrains.com/plugin/19620-coder): Open any Coder workspace in JetBrains Gateway with a single click\n- [**Dev Container Builder**](https://github.com/coder/envbuilder): Build development environments using `devcontainer.json` on Docker, Kubernetes, and OpenShift\n- [**Coder Registry**](https://registry.coder.com): Build and extend development environments with common use-cases\n- [**Kubernetes Log Stream**](https://github.com/coder/coder-logstream-kube): Stream Kubernetes Pod events to the Coder startup logs\n- [**Self-Hosted VS Code Extension Marketplace**](https://github.com/coder/code-marketplace): A private extension marketplace that works in restricted or airgapped networks integrating with [code-server](https://github.com/coder/code-server).\n- [**Setup Coder**](https://github.com/marketplace/actions/setup-coder): An action to setup coder CLI in GitHub workflows.\n\n### Community\n\n- [**Provision Coder with Terraform**](https://github.com/ElliotG/coder-oss-tf): Provision Coder on Google GKE, Azure AKS, AWS EKS, DigitalOcean DOKS, IBMCloud K8s, OVHCloud K8s, and Scaleway K8s Kapsule with Terraform\n- [**Coder Template GitHub Action**](https://github.com/marketplace/actions/update-coder-template): A GitHub Action that updates Coder templates\n\n## Contributing\n\nWe are always happy to see new contributors to Coder. If you are new to the Coder codebase, we have\n[a guide on how to get started](https://coder.com/docs/CONTRIBUTING). We'd love to see your\ncontributions!\n\n## Hiring\n\nApply [here](https://jobs.ashbyhq.com/coder?utm_source=github&utm_medium=readme&utm_campaign=unknown) if you're interested in joining our team.\n",
      "stars_today": 4
    },
    {
      "id": 829640443,
      "name": "tensorzero",
      "full_name": "tensorzero/tensorzero",
      "description": "TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.",
      "html_url": "https://github.com/tensorzero/tensorzero",
      "stars": 10814,
      "forks": 754,
      "language": "Rust",
      "topics": [
        "ai",
        "ai-engineering",
        "anthropic",
        "artificial-intelligence",
        "deep-learning",
        "genai",
        "generative-ai",
        "gpt",
        "large-language-models",
        "llama",
        "llm",
        "llmops",
        "llms",
        "machine-learning",
        "ml",
        "ml-engineering",
        "mlops",
        "openai",
        "python",
        "rust"
      ],
      "created_at": "2024-07-16T21:00:53Z",
      "updated_at": "2026-01-16T00:10:26Z",
      "pushed_at": "2026-01-16T00:36:51Z",
      "open_issues": 339,
      "owner": {
        "login": "tensorzero",
        "avatar_url": "https://avatars.githubusercontent.com/u/148420822?v=4"
      },
      "readme": "<p><picture><img src=\"https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9\" alt=\"TensorZero Logo\" width=\"128\" height=\"128\"></picture></p>\n\n# TensorZero\n\n<p><picture><img src=\"https://www.tensorzero.com/github-trending-badge.svg\" alt=\"#1 Repository Of The Day\"></picture></p>\n\n**TensorZero is an open-source stack for _industrial-grade LLM applications_:**\n\n- **Gateway:** access every LLM provider through a unified API, built for performance (<1ms p99 latency)\n- **Observability:** store inferences and feedback in your database, available programmatically or in the UI\n- **Optimization:** collect metrics and human feedback to optimize prompts, models, and inference strategies\n- **Evaluation:** benchmark individual inferences or end-to-end workflows using heuristics, LLM judges, etc.\n- **Experimentation:** ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.\n\nTake what you need, adopt incrementally, and complement with other tools.\n\n<video src=\"https://github.com/user-attachments/assets/04a8466e-27d8-4189-b305-e7cecb6881ee\"></video>\n\n---\n\n<p align=\"center\">\n  <b><a href=\"https://www.tensorzero.com/\" target=\"_blank\">Website</a></b>\n  Â·\n  <b><a href=\"https://www.tensorzero.com/docs\" target=\"_blank\">Docs</a></b>\n  Â·\n  <b><a href=\"https://www.x.com/tensorzero\" target=\"_blank\">Twitter</a></b>\n  Â·\n  <b><a href=\"https://www.tensorzero.com/slack\" target=\"_blank\">Slack</a></b>\n  Â·\n  <b><a href=\"https://www.tensorzero.com/discord\" target=\"_blank\">Discord</a></b>\n  <br>\n  <br>\n  <b><a href=\"https://www.tensorzero.com/docs/quickstart\" target=\"_blank\">Quick Start (5min)</a></b>\n  Â·\n  <b><a href=\"https://www.tensorzero.com/docs/gateway/deployment\" target=\"_blank\">Deployment Guide</a></b>\n  Â·\n  <b><a href=\"https://www.tensorzero.com/docs/gateway/api-reference\" target=\"_blank\">API Reference</a></b>\n  Â·\n  <b><a href=\"https://www.tensorzero.com/docs/gateway/deployment\" target=\"_blank\">Configuration Reference</a></b>\n</p>\n\n---\n\n> [!NOTE]\n>\n> ### **Coming Soon: TensorZero Autopilot**\n>\n> TensorZero Autopilot is an **automated AI engineer** (powered by the TensorZero Stack) that analyzes LLM observability data, optimizes prompts and models, sets up evals, and runs A/B tests.\n> **[Learn more](https://www.tensorzero.com/)** **[Join the waitlist](https://tensorzerodotcom.notion.site/2d87520bbad380c9ad0dd19566b3bc91)**\n\n## Features\n\n### ğŸŒ LLM Gateway\n\n> **Integrate with TensorZero once and access every major LLM provider.**\n\n- [x] **[Call any LLM](https://www.tensorzero.com/docs/gateway/call-any-llm)** (API or self-hosted) through a single unified API\n- [x] Infer with **[streaming](https://www.tensorzero.com/docs/gateway/guides/streaming-inference)**, **[tool use](https://www.tensorzero.com/docs/gateway/guides/tool-use)**, **[structured outputs (JSON)](https://www.tensorzero.com/docs/gateway/generate-structured-outputs)**, **[batch](https://www.tensorzero.com/docs/gateway/guides/batch-inference)**, **[embeddings](https://www.tensorzero.com/docs/gateway/generate-embeddings)**, **[multimodal (images, files)](https://www.tensorzero.com/docs/gateway/guides/multimodal-inference)**, **[caching](https://www.tensorzero.com/docs/gateway/guides/inference-caching)**, etc.\n- [x] **[Create prompt templates and schemas](https://www.tensorzero.com/docs/gateway/create-a-prompt-template)** to enforce a consistent, typed interface between your application and the LLMs\n- [x] Satisfy extreme throughput and latency needs, thanks to ğŸ¦€ Rust: **[<1ms p99 latency overhead at 10k+ QPS](https://www.tensorzero.com/docs/gateway/benchmarks)**\n- [x] Use any programming language: **[integrate via our Python SDK, any OpenAI SDK, or our HTTP API](https://www.tensorzero.com/docs/gateway/clients)**\n- [x] **[Ensure high availability](https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks)** with routing, retries, fallbacks, load balancing, granular timeouts, etc.\n- [x] **[Enforce custom rate limits](https://www.tensorzero.com/docs/operations/enforce-custom-rate-limits)** with granular scopes (e.g. user-defined tags) to keep usage under control\n- [x] **[Set up auth for TensorZero](https://www.tensorzero.com/docs/operations/set-up-auth-for-tensorzero)** to allow clients to access models without sharing provider API keys\n- [ ] Soon: spend tracking and budgeting\n\n<br>\n\n**Supported Model Providers:**\n**[Anthropic](https://www.tensorzero.com/docs/gateway/guides/providers/anthropic)**,\n**[AWS Bedrock](https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock)**,\n**[AWS SageMaker](https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker)**,\n**[Azure](https://www.tensorzero.com/docs/gateway/guides/providers/azure)**,\n**[DeepSeek](https://www.tensorzero.com/docs/gateway/guides/providers/deepseek)**,\n**[Fireworks](https://www.tensorzero.com/docs/gateway/guides/providers/fireworks)**,\n**[GCP Vertex AI Anthropic](https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic)**,\n**[GCP Vertex AI Gemini](https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini)**,\n**[Google AI Studio (Gemini API)](https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini)**,\n**[Groq](https://www.tensorzero.com/docs/gateway/guides/providers/groq)**,\n**[Hyperbolic](https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic)**,\n**[Mistral](https://www.tensorzero.com/docs/gateway/guides/providers/mistral)**,\n**[OpenAI](https://www.tensorzero.com/docs/gateway/guides/providers/openai)**,\n**[OpenRouter](https://www.tensorzero.com/docs/gateway/guides/providers/openrouter)**,\n**[SGLang](https://www.tensorzero.com/docs/gateway/guides/providers/sglang)**,\n**[TGI](https://www.tensorzero.com/docs/gateway/guides/providers/tgi)**,\n**[Together AI](https://www.tensorzero.com/docs/gateway/guides/providers/together)**,\n**[vLLM](https://www.tensorzero.com/docs/gateway/guides/providers/vllm)**, and\n**[xAI (Grok)](https://www.tensorzero.com/docs/gateway/guides/providers/xai)**.\nNeed something else? TensorZero also supports **[any OpenAI-compatible API (e.g. Ollama)](https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible)**.\n\n<br>\n\n<details open>\n<summary><b>Usage: Python &mdash; TensorZero SDK</b></summary>\n\nYou can access any provider using the TensorZero Python SDK.\n\n1. `pip install tensorzero`\n2. Optional: Set up the TensorZero configuration.\n3. Run inference:\n\n```python\nfrom tensorzero import TensorZeroGateway  # or AsyncTensorZeroGateway\n\n\nwith TensorZeroGateway.build_embedded(...) as t0:\n    response = t0.inference(\n        model_name=\"openai::gpt-4o-mini\",\n        # Try other providers easily: \"anthropic::claude-sonnet-4-5-20250929\"\n        input={\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": \"Write a haiku about TensorZero.\",\n                }\n            ]\n        },\n    )\n```\n\nSee **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.\n\n</details>\n\n<details>\n<summary><b>Usage: Python &mdash; OpenAI SDK</b></summary>\n\nYou can access any provider using the OpenAI Python SDK with TensorZero.\n\n1. `pip install tensorzero`\n2. Optional: Set up the TensorZero configuration.\n3. Run inference:\n\n```python\nfrom openai import OpenAI  # or AsyncOpenAI\nfrom tensorzero import patch_openai_client\n\nclient = OpenAI()\n\npatch_openai_client(client, ...)\n\nresponse = client.chat.completions.create(\n    model=\"tensorzero::model_name::openai::gpt-4o-mini\",\n    # Try other providers easily: \"tensorzero::model_name::anthropic::claude-sonnet-4-5-20250929\"\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Write a haiku about TensorZero.\",\n        }\n    ],\n)\n```\n\nSee **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.\n\n</details>\n\n<details>\n<summary><b>Usage: JavaScript / TypeScript (Node) &mdash; OpenAI SDK</b></summary>\n\nYou can access any provider using the OpenAI Node SDK with TensorZero.\n\n1. Deploy `tensorzero/gateway` using Docker.\n   **[Detailed instructions â†’](https://www.tensorzero.com/docs/gateway/deployment)**\n2. Set up the TensorZero configuration.\n3. Run inference:\n\n```ts\nimport OpenAI from \"openai\";\n\nconst client = new OpenAI({\n  baseURL: \"http://localhost:3000/openai/v1\",\n});\n\nconst response = await client.chat.completions.create({\n  model: \"tensorzero::model_name::openai::gpt-4o-mini\",\n  // Try other providers easily: \"tensorzero::model_name::anthropic::claude-sonnet-4-5-20250929\"\n  messages: [\n    {\n      role: \"user\",\n      content: \"Write a haiku about TensorZero.\",\n    },\n  ],\n});\n```\n\nSee **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.\n\n</details>\n\n<details>\n<summary><b>Usage: Other Languages & Platforms &mdash; HTTP API</b></summary>\n\nTensorZero supports virtually any programming language or platform via its HTTP API.\n\n1. Deploy `tensorzero/gateway` using Docker.\n   **[Detailed instructions â†’](https://www.tensorzero.com/docs/gateway/deployment)**\n2. Optional: Set up the TensorZero configuration.\n3. Run inference:\n\n```bash\ncurl -X POST \"http://localhost:3000/inference\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model_name\": \"openai::gpt-4o-mini\",\n    \"input\": {\n      \"messages\": [\n        {\n          \"role\": \"user\",\n          \"content\": \"Write a haiku about TensorZero.\"\n        }\n      ]\n    }\n  }'\n```\n\nSee **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.\n\n</details>\n\n### ğŸ” LLM Observability\n\n> **Zoom in to debug individual API calls, or zoom out to monitor metrics across models and prompts over time &mdash; all using the open-source TensorZero UI.**\n\n- [x] Store inferences and **[feedback (metrics, human edits, etc.)](https://www.tensorzero.com/docs/gateway/guides/metrics-feedback)** in your own database\n- [x] Dive into individual inferences or high-level aggregate patterns using the TensorZero UI or programmatically\n- [x] **[Build datasets](https://www.tensorzero.com/docs/gateway/api-reference/datasets-datapoints)** for optimization, evaluation, and other workflows\n- [x] Replay historical inferences with new prompts, models, inference strategies, etc.\n- [x] **[Export OpenTelemetry traces (OTLP)](https://www.tensorzero.com/docs/operations/export-opentelemetry-traces)** and **[export Prometheus metrics](https://www.tensorzero.com/docs/observability/export-prometheus-metrics)** to your favorite application observability tools\n- [ ] Soon: AI-assisted debugging and root cause analysis; AI-assisted data labeling\n\n<table>\n<tr></tr> <!-- flip highlight order -->\n<tr>\n<td width=\"50%\" align=\"center\" valign=\"middle\"><b>Observability Â» UI</b></td>\n<td width=\"50%\" align=\"center\" valign=\"middle\"><b>Observability Â» Programmatic</b></td>\n</tr>\n<tr>\n<td width=\"50%\" align=\"center\" valign=\"middle\"><video src=\"https://github.com/user-attachments/assets/a23e4c95-18fa-482c-8423-6078fb4cf285\"></video></td>\n<td width=\"50%\" align=\"left\" valign=\"middle\">\n\n```python\nt0.experimental_list_inferences(\n  function_name=\"sales_agent\",\n  filters=BooleanMetricFilter(\n      metric_name=\"converted_sale\",\n      value=True,\n  ),\n  # + compound filters\n  # + search\n  # + pagination\n  # ... and more ...\n)\n```\n\n</td>\n</tr>\n</table>\n\n### ğŸ“ˆ LLM Optimization\n\n> **Send production metrics and human feedback to easily optimize your prompts, models, and inference strategies &mdash; using the UI or programmatically.**\n\n- [x] Optimize your models with supervised fine-tuning, RLHF, and other techniques\n- [x] Optimize your prompts with automated prompt engineering algorithms like **[GEPA](https://www.tensorzero.com/docs/optimization/gepa)** and MIPROv2\n- [x] Optimize your **[inference strategy](https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations)** with dynamic in-context learning, best/mixture-of-N sampling, etc.\n- [x] Enable a feedback loop for your LLMs: a data & learning flywheel turning production data into smarter, faster, and cheaper models\n- [ ] Soon: synthetic data generation\n\n### ğŸ“Š LLM Evaluation\n\n> **Compare prompts, models, and inference strategies using evaluations powered by heuristics and LLM judges.**\n\n- [x] **[Evaluate individual inferences](https://www.tensorzero.com/docs/evaluations/inference-evaluations/tutorial)** with _inference evaluations_ powered by heuristics or LLM judges (&approx; unit tests for LLMs)\n- [x] **[Evaluate end-to-end workflows](https://www.tensorzero.com/docs/evaluations/workflow-evaluations/tutorial)** with _workflow evaluations_ with complete flexibility (&approx; integration tests for LLMs)\n- [x] Optimize LLM judges just like any other TensorZero function to align them to human preferences\n- [ ] Soon: more built-in evaluators; headless evaluations\n\n<table>\n  <tr></tr> <!-- flip highlight order -->\n  <tr>\n    <td width=\"50%\" align=\"center\" valign=\"middle\"><b>Evaluation Â» UI</b></td>\n    <td width=\"50%\" align=\"center\" valign=\"middle\"><b>Evaluation Â» CLI</b></td>\n  </tr>\n  <tr>\n    <td width=\"50%\" align=\"center\" valign=\"middle\"><img src=\"https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699\"></td>\n    <td width=\"50%\" align=\"left\" valign=\"middle\">\n<pre><code class=\"language-bash\">docker compose run --rm evaluations \\\n  --evaluation-name extract_data \\\n  --dataset-name hard_test_cases \\\n  --variant-name gpt_4o \\\n  --concurrency 5</code></pre>\n<pre><code class=\"language-bash\">Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4\nNumber of datapoints: 100\nâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100/100\nexact_match: 0.83 Â± 0.03 (n=100)\nsemantic_match: 0.98 Â± 0.01 (n=100)\nitem_count: 7.15 Â± 0.39 (n=100)</code></pre>\n    </td>\n  </tr>\n</table>\n\n### ğŸ§ª LLM Experimentation\n\n> **Ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.**\n\n- [x] **[Run adaptive A/B tests](https://www.tensorzero.com/docs/experimentation/run-adaptive-ab-tests)** to ship with confidence and identify the best prompts and models for your use cases.\n- [x] Enforce principled experiments in complex workflows, including support for multi-turn LLM systems, sequential testing, and more.\n\n### & more!\n\n> **Build with an open-source stack well-suited for prototypes but designed from the ground up to support the most complex LLM applications and deployments.**\n\n- [x] Build simple applications or massive deployments with GitOps-friendly orchestration\n- [x] **[Extend TensorZero](https://www.tensorzero.com/docs/operations/extend-tensorzero)** with built-in escape hatches, programmatic-first usage, direct database access, and more\n- [x] Integrate with third-party tools: specialized observability and evaluations, model providers, agent orchestration frameworks, etc.\n- [x] Iterate quickly by experimenting with prompts interactively using the Playground UI\n\n## Frequently Asked Questions\n\n**How is TensorZero different from other LLM frameworks?**\n\n1. TensorZero enables you to optimize complex LLM applications based on production metrics and human feedback.\n2. TensorZero supports the needs of industrial-grade LLM applications: low latency, high throughput, type safety, self-hosted, GitOps, customizability, etc.\n3. TensorZero unifies the entire LLMOps stack, creating compounding benefits. For example, LLM evaluations can be used for fine-tuning models alongside AI judges.\n\n**Can I use TensorZero with \\_\\_\\_?**\n\nYes.\nEvery major programming language is supported.\nIt plays nicely with the **[OpenAI SDK](https://www.tensorzero.com/docs/gateway/clients/)**, **[OpenTelemetry](https://www.tensorzero.com/docs/operations/export-opentelemetry-traces/)**, and **[every major LLM](https://www.tensorzero.com/docs/integrations/model-providers/)**.\n\n**Is TensorZero production-ready?**\n\nYes.\nTensorZero is used by companies ranging from frontier AI startups to the Fortune 50.\n\nHere's a case study: **[Automating Code Changelogs at a Large Bank with LLMs](https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms)**\n\n**How much does TensorZero cost?**\n\nTensorZero Stack (LLMOps platform) is 100% self-hosted and open-source.\n\nTensorZero Autopilot (automated AI engineer) is a complementary paid product powered by the TensorZero Stack.\n\n**Who is building TensorZero?**\n\nOur technical team includes a former Rust compiler maintainer, machine learning researchers (Stanford, CMU, Oxford, Columbia) with thousands of citations, and the chief product officer of a decacorn startup. We're backed by the same investors as leading open-source projects (e.g. ClickHouse, CockroachDB) and AI labs (e.g. OpenAI, Anthropic). See our **[$7.3M seed round announcement](https://www.tensorzero.com/blog/tensorzero-raises-7-3m-seed-round-to-build-an-open-source-stack-for-industrial-grade-llm-applications/)** and **[coverage from VentureBeat](https://venturebeat.com/ai/tensorzero-nabs-7-3m-seed-to-solve-the-messy-world-of-enterprise-llm-development/)**. We're **[hiring in NYC](https://www.tensorzero.com/jobs)**.\n\n**How do I get started?**\n\nYou can adopt TensorZero incrementally. Our **[Quick Start](https://www.tensorzero.com/docs/quickstart)** goes from a vanilla OpenAI wrapper to a production-ready LLM application with observability and fine-tuning in just 5 minutes.\n\n## Demo\n\n> **Watch LLMs get better at data extraction in real-time with TensorZero!**\n>\n> **[Dynamic in-context learning (DICL)](https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl)** is a powerful inference-time optimization available out of the box with TensorZero.\n> It enhances LLM performance by automatically incorporating relevant historical examples into the prompt, without the need for model fine-tuning.\n\nhttps://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb\n\n## Get Started\n\n**Start building today.**\nThe **[Quick Start](https://www.tensorzero.com/docs/quickstart)** shows it's easy to set up an LLM application with TensorZero.\n\n**Questions?**\nAsk us on **[Slack](https://www.tensorzero.com/slack)** or **[Discord](https://www.tensorzero.com/discord)**.\n\n**Using TensorZero at work?**\nEmail us at **[hello@tensorzero.com](mailto:hello@tensorzero.com)** to set up a Slack or Teams channel with your team (free).\n\n## Examples\n\nWe are working on a series of **complete runnable examples** illustrating TensorZero's data & learning flywheel.\n\n> **[Optimizing Data Extraction (NER) with TensorZero](https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner)**\n>\n> This example shows how to use TensorZero to optimize a data extraction pipeline.\n> We demonstrate techniques like fine-tuning and dynamic in-context learning (DICL).\n> In the end, an optimized GPT-4o Mini model outperforms GPT-4o on this task &mdash; at a fraction of the cost and latency &mdash; using a small amount of training data.\n\n> **[Agentic RAG â€” Multi-Hop Question Answering with LLMs](https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/)**\n>\n> This example shows how to build a multi-hop retrieval agent using TensorZero.\n> The agent iteratively searches Wikipedia to gather information, and decides when it has enough context to answer a complex question.\n\n> **[Writing Haikus to Satisfy a Judge with Hidden Preferences](https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences)**\n>\n> This example fine-tunes GPT-4o Mini to generate haikus tailored to a specific taste.\n> You'll see TensorZero's \"data flywheel in a box\" in action: better variants leads to better data, and better data leads to better variants.\n> You'll see progress by fine-tuning the LLM multiple times.\n\n> **[Image Data Extraction â€” Multimodal (Vision) Fine-tuning](https://github.com/tensorzero/tensorzero/tree/main/examples/multimodal-vision-finetuning)**\n>\n> This example shows how to fine-tune multimodal models (VLMs) like GPT-4o to improve their performance on vision-language tasks.\n> Specifically, we'll build a system that categorizes document images (screenshots of computer science research papers).\n\n> **[Improving LLM Chess Ability with Best-of-N Sampling](https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/)**\n>\n> This example showcases how best-of-N sampling can significantly enhance an LLM's chess-playing abilities by selecting the most promising moves from multiple generated options.\n\n## Blog Posts\n\nWe write about LLM engineering on the **[TensorZero Blog](https://www.tensorzero.com/blog)**.\nHere are some of our favorite posts:\n\n- **[Bandits in your LLM Gateway: Improve LLM Applications Faster with Adaptive Experimentation (A/B Testing)](https://www.tensorzero.com/blog/bandits-in-your-llm-gateway/)**\n- **[Is OpenAI's Reinforcement Fine-Tuning (RFT) Worth It?](https://www.tensorzero.com/blog/is-openai-reinforcement-fine-tuning-rft-worth-it/)**\n- **[Distillation with Programmatic Data Curation: Smarter LLMs, 5-30x Cheaper Inference](https://www.tensorzero.com/blog/distillation-programmatic-data-curation-smarter-llms-5-30x-cheaper-inference/)**\n- **[From NER to Agents: Does Automated Prompt Engineering Scale to Complex Tasks?](https://www.tensorzero.com/blog/from-ner-to-agents-does-automated-prompt-engineering-scale-to-complex-tasks/)**\n",
      "stars_today": 4
    },
    {
      "id": 178075572,
      "name": "kserve",
      "full_name": "kserve/kserve",
      "description": "Standardized Distributed Generative and Predictive AI Inference Platform for Scalable, Multi-Framework Deployment on Kubernetes",
      "html_url": "https://github.com/kserve/kserve",
      "stars": 5000,
      "forks": 1344,
      "language": "Go",
      "topics": [
        "artificial-intelligence",
        "cncf",
        "genai",
        "hacktoberfest",
        "istio",
        "k8s",
        "knative",
        "kserve",
        "kubeflow",
        "kubernetes",
        "llm-inference",
        "machine-learning",
        "mlops",
        "model-interpretability",
        "model-serving",
        "pytorch",
        "service-mesh",
        "tensorflow",
        "vllm",
        "xgboost"
      ],
      "created_at": "2019-03-27T21:14:14Z",
      "updated_at": "2026-01-15T20:28:19Z",
      "pushed_at": "2026-01-15T03:42:53Z",
      "open_issues": 595,
      "owner": {
        "login": "kserve",
        "avatar_url": "https://avatars.githubusercontent.com/u/83512434?v=4"
      },
      "readme": "# KServe\n[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white)](https://pkg.go.dev/github.com/kserve/kserve)\n[![Coverage Status](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/andyi2it/5174bd748ac63a6e4803afea902e9810/raw/coverage.json)](https://github.com/kserve/kserve/actions/workflows/go.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/kserve/kserve)](https://goreportcard.com/report/github.com/kserve/kserve)\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/6643/badge)](https://bestpractices.coreinfrastructure.org/projects/6643)\n[![Releases](https://img.shields.io/github/release-pre/kserve/kserve.svg?sort=semver)](https://github.com/kserve/kserve/releases)\n[![LICENSE](https://img.shields.io/github/license/kserve/kserve.svg)](https://github.com/kserve/kserve/blob/master/LICENSE)\n[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](https://github.com/kserve/community/blob/main/README.md#questions-and-issues)\n[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20KServe%20Guru-006BFF)](https://gurubase.io/g/kserve)\n\nKServe is a standardized distributed generative and predictive AI inference platform for scalable, multi-framework deployment on Kubernetes.\n\nKServe is being [used by many organizations](https://kserve.github.io/website/docs/community/adopters) and is a [Cloud Native Computing Foundation (CNCF)](https://www.cncf.io/) incubating project.\n\nFor more details, visit the [KServe website](https://kserve.github.io/website/).\n\n![KServe](/docs/diagrams/kserve_new.png)\n\n### Why KServe?\n\nSingle platform that unifies Generative and Predictive AI inference on Kubernetes. Simple enough for quick deployments, yet powerful enough to handle enterprise-scale AI workloads with advanced features.\n\n### Features\n\n**Generative AI**\n  * ğŸ§  **LLM-Optimized**: OpenAI-compatible inference protocol for seamless integration with large language models\n  * ğŸš… **GPU Acceleration**: High-performance serving with GPU support and optimized memory management for large models\n  * ğŸ’¾ **Model Caching**: Intelligent model caching to reduce loading times and improve response latency for frequently used models\n  * ğŸ—‚ï¸ **KV Cache Offloading**: Advanced memory management with KV cache offloading to CPU/disk for handling longer sequences efficiently\n  * ğŸ“ˆ **Autoscaling**: Request-based autoscaling capabilities optimized for generative workload patterns\n  * ğŸ”§ **Hugging Face Ready**: Native support for Hugging Face models with streamlined deployment workflows\n\n**Predictive AI**\n  * ğŸ§® **Multi-Framework**: Support for TensorFlow, PyTorch, scikit-learn, XGBoost, ONNX, and more\n  * ğŸ”€ **Intelligent Routing**: Seamless request routing between predictor, transformer, and explainer components with automatic traffic management\n  * ğŸ”„ **Advanced Deployments**: Canary rollouts, inference pipelines, and ensembles with InferenceGraph\n  * âš¡ **Autoscaling**: Request-based autoscaling with scale-to-zero for predictive workloads\n  * ğŸ” **Model Explainability**: Built-in support for model explanations and feature attribution to understand prediction reasoning\n  * ğŸ“Š **Advanced Monitoring**: Enables payload logging, outlier detection, adversarial detection, and drift detection\n  * ğŸ’° **Cost Efficient**: Scale-to-zero on expensive resources when not in use, reducing infrastructure costs\n\n### Learn More\nTo learn more about KServe, how to use various supported features, and how to participate in the KServe community, \nplease follow the [KServe website documentation](https://kserve.github.io/website). \nAdditionally, we have compiled a list of [presentations and demos](https://kserve.github.io/website/docs/community/presentations) to dive through various details.\n\n### :hammer_and_wrench: Installation\n\n#### Standalone Installation\n- **[Standard Kubernetes Installation](https://kserve.github.io/website/docs/admin-guide/overview#raw-kubernetes-deployment)**: Compared to Serverless Installation, this is a more **lightweight** installation. However, this option does not support canary deployment and request based autoscaling with scale-to-zero.\n- **[Knative Installation](https://kserve.github.io/website/docs/admin-guide/overview#serverless-deployment)**: KServe by default installs Knative for **serverless deployment** for InferenceService.\n- **[ModelMesh Installation](https://kserve.github.io/website/docs/admin-guide/overview#modelmesh-deployment)**: You can optionally install ModelMesh to enable **high-scale**, **high-density** and **frequently-changing model serving** use cases. \n- **[Quick Installation](https://kserve.github.io/website/docs/getting-started/quickstart-guide)**: Install KServe on your local machine.\n\n#### Kubeflow Installation\nKServe is an important addon component of Kubeflow, please learn more from the [Kubeflow KServe documentation](https://www.kubeflow.org/docs/external-add-ons/kserve/kserve). Check out the following guides for running [on AWS](https://awslabs.github.io/kubeflow-manifests/main/docs/component-guides/kserve) or [on OpenShift Container Platform](https://github.com/kserve/kserve/blob/master/docs/OPENSHIFT_GUIDE.md).\n\n### :flight_departure: [Create your first InferenceService](https://kserve.github.io/website/docs/getting-started/genai-first-isvc)\n\n### :bulb: [Roadmap](./ROADMAP.md)\n\n### :blue_book: [InferenceService API Reference](https://kserve.github.io/website/docs/reference/crd-api)\n\n### :toolbox: [Developer Guide](https://kserve.github.io/website/docs/developer-guide)\n\n### :writing_hand: [Contributor Guide](https://kserve.github.io/website/docs/developer-guide/contribution)\n\n### :handshake: [Adopters](https://kserve.github.io/website/docs/community/adopters)\n\n### Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=kserve/kserve&type=Date)](https://www.star-history.com/#kserve/kserve&Date)\n",
      "stars_today": 4
    },
    {
      "id": 78869127,
      "name": "Android",
      "full_name": "duckduckgo/Android",
      "description": "DuckDuckGo Android App",
      "html_url": "https://github.com/duckduckgo/Android",
      "stars": 4489,
      "forks": 1212,
      "language": "Kotlin",
      "topics": [
        "android",
        "duckduckgo",
        "duckduckgo-android",
        "hacktoberfest",
        "translations"
      ],
      "created_at": "2017-01-13T17:11:25Z",
      "updated_at": "2026-01-15T19:55:05Z",
      "pushed_at": "2026-01-15T22:09:05Z",
      "open_issues": 129,
      "owner": {
        "login": "duckduckgo",
        "avatar_url": "https://avatars.githubusercontent.com/u/342708?v=4"
      },
      "readme": "# DuckDuckGo Android\n\nWelcome to our android application. We are excited to engage the community in development, see [CONTRIBUTING.md](CONTRIBUTING.md).\n\n## We are hiring!\nDuckDuckGo is growing fast and we continue to expand our fully distributed team. We embrace diverse perspectives, and seek out passionate, self-motivated people, committed to our shared vision of raising the standard of trust online. If you are a senior software engineer capable in either iOS or Android, visit our [careers](https://duckduckgo.com/hiring/#open) page to find out more about our openings!\n\n## Building the Project\nWe use git submodules and so when you are checking out the app, you'll need to ensure the submodules are initialized properly. You can use the `--recursive` flag when cloning the project to do this.\n\n    git clone --recursive https://github.com/duckduckgo/android.git\n\nAlternatively, if you already have the project checked out, you can initialize the submodules manually.\n\n    git submodule update --init\n    \n## Terminology\n\nWe have taken steps to update our terminology and remove words with problematic racial connotations, most notably the change to `main` branches, `allow lists`, and `blocklists`. Closed issues or PRs may contain deprecated terminology that should not be used going forward.\n\n## Contribute\n\nPlease refer to [contributing](CONTRIBUTING.md).\n\n## Discuss\n\nContact us at https://duckduckgo.com/feedback if you have feedback, questions or want to chat. You can also use the feedback form embedded within our Mobile App - to do so please navigate to Settings and select \"Leave Feedback\".\n\n## License\nDuckDuckGo android is distributed under the Apache 2.0 [license](LICENSE).\n",
      "stars_today": 4
    },
    {
      "id": 381857226,
      "name": "typespec",
      "full_name": "microsoft/typespec",
      "description": null,
      "html_url": "https://github.com/microsoft/typespec",
      "stars": 5536,
      "forks": 331,
      "language": "Java",
      "topics": [
        "json-schema",
        "openapi3",
        "protobuf",
        "typespec"
      ],
      "created_at": "2021-06-30T23:29:49Z",
      "updated_at": "2026-01-15T20:41:04Z",
      "pushed_at": "2026-01-15T18:53:17Z",
      "open_issues": 1042,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# TypeSpec\n\n[Official Docs](https://typespec.io/) | [Try TypeSpec Online](https://aka.ms/trytypespec) | [Getting Started](https://typespec.io/docs) | [Language Overview](https://typespec.io/docs/language-basics/overview)\n\nTypeSpec is a language for defining cloud service APIs and shapes. TypeSpec is a highly extensible language with primitives that can describe API shapes common among REST, OpenAPI, gRPC, and other protocols.\n\nTypeSpec is excellent for generating many different API description formats, client and service code, documentation, and other assets while keeping your TypeSpec definition as a single source of truth.\n\nUsing TypeSpec, you can create reusable patterns for all aspects of an API and package those reusable patterns into libraries. These patterns establish \"guardrails\" for API designers and make it easier to follow best practices than to deviate from them. TypeSpec also has a rich linter framework with the ability to flag anti-patterns as well as an emitter framework that lets you control the output to ensure it follows the patterns you want.\n\nTypeSpec is a Microsoft-built, community-supported project. Your ideas, feedbacks, and code make all the difference and we deeply appreciate the support from the community.\n\n## [Installation](https://typespec.io/docs)\n\n```\nnpm install -g @typespec/compiler\n```\n\n#### Tools\n\nThe [TypeSpec VS Code extension](https://marketplace.visualstudio.com/items?itemName=typespec.typespec-vscode) can be installed from the VS Code [marketplace](https://marketplace.visualstudio.com/items?itemName=typespec.typespec-vscode) or directly on the command line:\n\n```\ntsp code install\n```\n\nThe [TypeSpec VS Extension](https://marketplace.visualstudio.com/items?itemName=typespec.typespecvs) can be installed from the [VS Marketplace](https://marketplace.visualstudio.com/items?itemName=typespec.typespecvs) or directly on the command line:\n\n```\ntsp vs install\n```\n\n## [Usage](https://typespec.io/docs#create-first-typespec-project)\n\n### TypeSpec to OpenAPI 3.0 Example\n\nThis example uses the `@typespec/http`, `@typespec/rest`, and `@typespec/openapi3` libraries to define a basic REST service and generate an OpenAPI 3.0 document from it.\n\nRun the following command and select \"Generic REST API\":\n\n```\ntsp init\n```\n\nHit enter a few times to confirm the defaults.\n\nCopy the contents below into your **main.tsp**:\n\n```typespec\nimport \"@typespec/http\";\nimport \"@typespec/rest\";\nimport \"@typespec/openapi3\";\n\nusing Http;\nusing Rest;\n\n/** This is a pet store service. */\n@service(#{ title: \"Pet Store Service\" })\n@server(\"https://example.com\", \"The service endpoint\")\nnamespace PetStore;\n\n@route(\"/pets\")\ninterface Pets {\n  list(): Pet[];\n}\n\nmodel Pet {\n  @minLength(100)\n  name: string;\n\n  @minValue(0)\n  @maxValue(100)\n  age: int32;\n\n  kind: \"dog\" | \"cat\" | \"fish\";\n}\n```\n\nInstall the dependencies of main.tsp:\n\n```\ntsp install\n```\n\nCompile it to OpenAPI 3.0:\n\n```\ntsp compile main.tsp --emit @typespec/openapi3\n```\n\nYou can find the emitted OpenAPI output in `./tsp-output/openapi.json`.\n\n## Advanced Scenarios\n\n### Installing nightly version\n\nOn every commit to the main branch, packages with changes are automatically published to npm with the `@next` tag.\nThe [packages](#packages) section shows which version corresponds to the `next` tag for each package.\n\nTo use a `nightly` version of the packages, go over each one of the packages in the `package.json` file and update it to either the latest published `@next` version or `@latest`, whichever is the newest. You can also use the tag `latest` or `next` instead of an explicit version.\n\nAfter updating the package.json file you can run `npm update --force`. Force is required as there might be some incompatible version requirement.\n\nExample\n\n```json5\n// Stable setup\n\"dependencies\": {\n  \"@typespec/compiler\": \"~0.30.0\",\n  \"@typespec/http\": \"~0.14.0\",\n  \"@typespec/rest\": \"~0.14.0\",\n  \"@typespec/openapi\": \"~0.9.0\",\n}\n\n// Consume next version\n// In this example: compiler and openapi have changes but rest library has none\n\"dependencies\": {\n  \"@typespec/compiler\": \"~0.31.0-dev.5\",\n  \"@typespec/http\": \"~0.14.0\",\n  \"@typespec/rest\": \"~0.14.0\", // No changes to @typespec/rest library so need to stay the latest.\n  \"@typespec/openapi\": \"~0.10.0-dev.2\",\n}\n```\n\n## Packages\n\n| Name                                               | Changelog                        | Latest                                                                                                                                   | Next                                                                      |\n| -------------------------------------------------- | -------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |\n| Core functionality                                 |                                  |                                                                                                                                          |                                                                           |\n| [@typespec/compiler][compiler_src]                 | [Changelog][compiler_chg]        | [![](https://img.shields.io/npm/v/@typespec/compiler)](https://www.npmjs.com/package/@typespec/compiler)                                 | ![](https://img.shields.io/npm/v/@typespec/compiler/next)                 |\n| TypeSpec Libraries                                 |                                  |                                                                                                                                          |                                                                           |\n| [@typespec/http][http_src]                         | [Changelog][http_chg]            | [![](https://img.shields.io/npm/v/@typespec/http)](https://www.npmjs.com/package/@typespec/http)                                         | ![](https://img.shields.io/npm/v/@typespec/http/next)                     |\n| [@typespec/rest][rest_src]                         | [Changelog][rest_chg]            | [![](https://img.shields.io/npm/v/@typespec/rest)](https://www.npmjs.com/package/@typespec/rest)                                         | ![](https://img.shields.io/npm/v/@typespec/rest/next)                     |\n| [@typespec/openapi][openapi_src]                   | [Changelog][openapi_chg]         | [![](https://img.shields.io/npm/v/@typespec/openapi)](https://www.npmjs.com/package/@typespec/openapi)                                   | ![](https://img.shields.io/npm/v/@typespec/openapi/next)                  |\n| [@typespec/openapi3][openapi3_src]                 | [Changelog][openapi3_chg]        | [![](https://img.shields.io/npm/v/@typespec/openapi3)](https://www.npmjs.com/package/@typespec/openapi3)                                 | ![](https://img.shields.io/npm/v/@typespec/openapi3/next)                 |\n| [@typespec/versioning][versioning_src]             | [Changelog][versioning_chg]      | [![](https://img.shields.io/npm/v/@typespec/versioning)](https://www.npmjs.com/package/@typespec/versioning)                             | ![](https://img.shields.io/npm/v/@typespec/versioning/next)               |\n| TypeSpec Tools                                     |                                  |                                                                                                                                          |                                                                           |\n| [@typespec/prettier-plugin-typespec][prettier_src] | [Changelog][prettier_chg]        | [![](https://img.shields.io/npm/v/@typespec/prettier-plugin-typespec)](https://www.npmjs.com/package/@typespec/prettier-plugin-typespec) | ![](https://img.shields.io/npm/v/@typespec/prettier-plugin-typespec/next) |\n| [typespec-vs][typespec-vs_src]                     | [Changelog][typespec-vs_chg]     | [![](https://img.shields.io/npm/v/typespec-vs)](https://www.npmjs.com/package/typespec-vs)                                               | ![](https://img.shields.io/npm/v/typespec-vs/next)                        |\n| [typespec-vscode][typespec-vscode_src]             | [Changelog][typespec-vscode_chg] | [![](https://img.shields.io/npm/v/typespec-vscode)](https://www.npmjs.com/package/typespec-vscode)                                       | ![](https://img.shields.io/npm/v/typespec-vscode/next)                    |\n| [tmlanguage-generator][tmlanguage_src]             | [Changelog][tmlanguage_chg]      | [![](https://img.shields.io/npm/v/tmlanguage-generator)](https://www.npmjs.com/package/tmlanguage-generator)                             | ![](https://img.shields.io/npm/v/tmlanguage-generator/next)               |\n\n[compiler_src]: packages/compiler\n[compiler_chg]: packages/compiler/CHANGELOG.md\n[http_src]: packages/http\n[http_chg]: packages/http/CHANGELOG.md\n[rest_src]: packages/rest\n[rest_chg]: packages/rest/CHANGELOG.md\n[openapi_src]: packages/openapi\n[openapi_chg]: packages/openapi/CHANGELOG.md\n[openapi3_src]: packages/openapi3\n[openapi3_chg]: packages/openapi3/CHANGELOG.md\n[versioning_src]: packages/versioning\n[versioning_chg]: packages/versioning/CHANGELOG.md\n[prettier_src]: packages/prettier-plugin-typespec\n[prettier_chg]: packages/prettier-plugin-typespec/CHANGELOG.md\n[typespec-vs_src]: packages/typespec-vs\n[typespec-vs_chg]: packages/typespec-vs/CHANGELOG.md\n[typespec-vscode_src]: packages/typespec-vscode\n[typespec-vscode_chg]: packages/typespec-vscode/CHANGELOG.md\n[tmlanguage_src]: packages/tmlanguage-generator\n[tmlanguage_chg]: packages/tmlanguage-generator/CHANGELOG.md\n\n`@next` version of the package are the latest versions available on the `main` branch.\n",
      "stars_today": 4
    },
    {
      "id": 13862999,
      "name": "apps-android-wikipedia",
      "full_name": "wikimedia/apps-android-wikipedia",
      "description": " ğŸ“±The official Wikipedia app for Android!",
      "html_url": "https://github.com/wikimedia/apps-android-wikipedia",
      "stars": 2812,
      "forks": 752,
      "language": "Kotlin",
      "topics": [
        "android",
        "android-app",
        "coroutines",
        "java",
        "kotlin",
        "mediawiki",
        "mediawiki-api",
        "rest-api",
        "viewmodel",
        "wiki",
        "wikipedia",
        "wikipedia-android"
      ],
      "created_at": "2013-10-25T14:31:39Z",
      "updated_at": "2026-01-15T22:47:38Z",
      "pushed_at": "2026-01-15T21:56:15Z",
      "open_issues": 32,
      "owner": {
        "login": "wikimedia",
        "avatar_url": "https://avatars.githubusercontent.com/u/56668?v=4"
      },
      "readme": "### Wikipedia Android app\n\nThis repository contains the source code for the official [Wikipedia Android app](https://play.google.com/store/apps/details?id=org.wikipedia).\n\n### Documentation\n\nAll documentation is kept on [our wiki](https://www.mediawiki.org/wiki/Wikimedia_Apps/Team/Android/App_hacking). Check it out!\n\n### Issues\n\nKindly file issues in [our bug tracker][1]\n\n\n[1]: https://phabricator.wikimedia.org/maniphest/task/edit/form/10/?title=&projects=wikipedia-android-app-backlog&points=1&description=%3D%3D%3D+Steps+to+reproduce%0A%23+%0A%23+%0A%23+%0A%0A%3D%3D%3D+Expected+results%0A%0A%3D%3D%3D+Actual+results%0A%0A%3D%3D%3D+Stack%20trace%0A%60%60%60lines%3D10%0A(Optional%20logcat%20output)%0A%60%60%60%0A%0A%3D%3D%3D+Environments+observed%0A**App+version%3A+**+%0A**Android+OS+versions%3A**+%0A**Device+model%3A**+%0A**Device+language%3A**\n",
      "stars_today": 4
    },
    {
      "id": 5152285,
      "name": "okhttp",
      "full_name": "square/okhttp",
      "description": "Squareâ€™s meticulous HTTP client for the JVM, Android, and GraalVM.",
      "html_url": "https://github.com/square/okhttp",
      "stars": 46849,
      "forks": 9258,
      "language": "Kotlin",
      "topics": [
        "android",
        "graalvm",
        "java",
        "kotlin"
      ],
      "created_at": "2012-07-23T13:42:55Z",
      "updated_at": "2026-01-15T17:55:31Z",
      "pushed_at": "2026-01-14T08:37:02Z",
      "open_issues": 88,
      "owner": {
        "login": "square",
        "avatar_url": "https://avatars.githubusercontent.com/u/82592?v=4"
      },
      "readme": "OkHttp\n======\n\nSee the [project website][okhttp] for documentation and APIs.\n\nHTTP is the way modern applications network. Itâ€™s how we exchange data & media. Doing HTTP\nefficiently makes your stuff load faster and saves bandwidth.\n\nOkHttp is an HTTP client thatâ€™s efficient by default:\n\n * HTTP/2 support allows all requests to the same host to share a socket.\n * Connection pooling reduces request latency (if HTTP/2 isnâ€™t available).\n * Transparent GZIP shrinks download sizes.\n * Response caching avoids the network completely for repeat requests.\n\nOkHttp perseveres when the network is troublesome: it will silently recover from common connection\nproblems. If your service has multiple IP addresses, OkHttp will attempt alternate addresses if the\nfirst connect fails. This is necessary for IPv4+IPv6 and services hosted in redundant data\ncenters. OkHttp supports modern TLS features (TLS 1.3, ALPN, certificate pinning). It can be\nconfigured to fall back for broad connectivity.\n\nUsing OkHttp is easy. Its request/response API is designed with fluent builders and immutability. It\nsupports both synchronous blocking calls and async calls with callbacks.\n\nA well behaved user agent\n-------------------------\n\nOkHttp follows modern HTTP specifications such as\n\n* HTTP Semantics - [RFC 9110](https://datatracker.ietf.org/doc/html/rfc9110)\n* HTTP Caching- [RFC 9111](https://datatracker.ietf.org/doc/html/rfc9111)\n* HTTP/1.1 - [RFC 9112](https://datatracker.ietf.org/doc/html/rfc9112)\n* HTTP/2 - [RFC 9113](https://datatracker.ietf.org/doc/html/rfc9113)\n* Websockets - [RFC 6455](https://datatracker.ietf.org/doc/html/rfc6455)\n* SSE - [Server-sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events)\n\nWhere the spec is ambiguous, OkHttp follows modern user agents such as popular Browsers or common HTTP Libraries.\n\nOkHttp is principled and avoids being overly configurable, especially when such configuration is\nto workaround a buggy server, test invalid scenarios or that contradict the relevant RFC.\nOther HTTP libraries exist that fill that gap allowing extensive customisation including potentially\ninvalid requests.\n\nExample Limitations\n\n* Does not allow GET with a body.\n* Cache is not an interface with alternative implementations.\n\nGet a URL\n---------\n\nThis program downloads a URL and prints its contents as a string. [Full source][get_example].\n\n```java\nOkHttpClient client = new OkHttpClient();\n\nString run(String url) throws IOException {\n  Request request = new Request.Builder()\n      .url(url)\n      .build();\n\n  try (Response response = client.newCall(request).execute()) {\n    return response.body().string();\n  }\n}\n```\n\n\nPost to a Server\n----------------\n\nThis program posts data to a service. [Full source][post_example].\n\n```java\npublic static final MediaType JSON = MediaType.get(\"application/json\");\n\nOkHttpClient client = new OkHttpClient();\n\nString post(String url, String json) throws IOException {\n  RequestBody body = RequestBody.create(json, JSON);\n  Request request = new Request.Builder()\n      .url(url)\n      .post(body)\n      .build();\n  try (Response response = client.newCall(request).execute()) {\n    return response.body().string();\n  }\n}\n```\n\nFurther examples are on the [OkHttp Recipes page][recipes].\n\n\nRequirements\n------------\n\nOkHttp works on Android 5.0+ (API level 21+) and Java 8+.\n\nOn Android, OkHttp uses [AndroidX Startup][androidx_startup]. If you disable the initializer in the manifest,\nthen apps are responsible for calling `OkHttp.initialize(applicationContext)` in `Application.onCreate`.\n\nOkHttp depends on [Okio][okio] for high-performance I/O and the [Kotlin standard library][kotlin]. Both are small libraries with strong backward-compatibility.\n\nWe highly recommend you keep OkHttp up-to-date. As with auto-updating web browsers, staying current\nwith HTTPS clients is an important defense against potential security problems. [We\ntrack][tls_history] the dynamic TLS ecosystem and adjust OkHttp to improve connectivity and\nsecurity.\n\nOkHttp uses your platform's built-in TLS implementation. On Java platforms OkHttp also supports\n[Conscrypt][conscrypt], which integrates [BoringSSL](https://github.com/google/boringssl) with Java. OkHttp will use Conscrypt if it is\nthe first security provider:\n\n```java\nSecurity.insertProviderAt(Conscrypt.newProvider(), 1);\n```\n\nThe OkHttp `3.12.x` branch supports Android 2.3+ (API level 9+) and Java 7+. These platforms lack\nsupport for TLS 1.2 and should not be used.\n\n\nReleases\n--------\n\nOur [change log][changelog] has release history.\n\nThe latest release is available on [Maven Central](https://search.maven.org/artifact/com.squareup.okhttp3/okhttp/5.3.0/jar).\n\n```kotlin\nimplementation(\"com.squareup.okhttp3:okhttp:5.3.0\")\n```\n\nSnapshot builds are [available][snap]. [R8 and ProGuard][r8_proguard] rules are available.\n\nAlso, we have a [bill of materials (BOM)][bom] available to help you keep OkHttp artifacts up to date and be sure about version compatibility.\n\n```kotlin\n    dependencies {\n       // define a BOM and its version\n       implementation(platform(\"com.squareup.okhttp3:okhttp-bom:5.3.0\"))\n\n       // define any required OkHttp artifacts without version\n       implementation(\"com.squareup.okhttp3:okhttp\")\n       implementation(\"com.squareup.okhttp3:logging-interceptor\")\n    }\n```\n\nMaven and JVM Projects\n----------------------\n\nOkHttp is published as a Kotlin Multiplatform project. While Gradle handles this automatically,\nMaven projects must select between `okhttp-jvm` and `okhttp-android`. The `okhttp` artifact will be empty in\nMaven projects.\n\n```xml\n<dependencyManagement>\n  <dependencies>\n    <dependency>\n      <groupId>com.squareup.okhttp3</groupId>\n      <artifactId>okhttp-bom</artifactId>\n      <version>5.2.0</version>\n      <type>pom</type>\n      <scope>import</scope>\n    </dependency>\n  </dependencies>\n</dependencyManagement>\n```\n\n\n\n```xml\n<dependency>\n  <groupId>com.squareup.okhttp3</groupId>\n  <artifactId>okhttp-jvm</artifactId>\n  <!-- Remove after OkHttp 5.2.0 with updated BOM. -->\n  <version>5.1.0</version>\n</dependency>\n\n<dependency>\n  <groupId>com.squareup.okhttp3</groupId>\n  <artifactId>mockwebserver3</artifactId>\n</dependency>\n\n<dependency>\n  <groupId>com.squareup.okhttp3</groupId>\n  <artifactId>logging-interceptor</artifactId>\n</dependency>\n```\n\nMockWebServer\n-------------\n\nOkHttp includes a library for testing HTTP, HTTPS, and HTTP/2 clients.\n\nThe latest release is available on [Maven Central](https://search.maven.org/artifact/com.squareup.okhttp3/mockwebserver/5.3.0/jar).\n\n```kotlin\ntestImplementation(\"com.squareup.okhttp3:mockwebserver3:5.3.0\")\n```\n\nMockWebServer is used for firstly for internal testing, and for basic testing of apps using OkHttp client.\nIt is not a full featured HTTP testing library that is developed standalone. It is not being actively developed\nfor new features. As such you might find your needs outgrow MockWebServer and you may which to use a\nmore full featured testing library such as [MockServer](https://www.mock-server.com/).\n\nGraalVM Native Image\n--------------------\n\nBuilding your native images with [GraalVM] should work automatically.\n\nSee the okcurl module for an example build.\n\n```shell\n$ ./gradlew okcurl:nativeImage\n$ ./okcurl/build/graal/okcurl https://httpbin.org/get\n```\n\nJava Modules\n------------\n\nOkHttp (5.2+) implements Java 9 Modules.\n\nWith this in place Java builds should fail if apps attempt to use internal packages.\n\n```\nerror: package okhttp3.internal.platform is not visible\n    okhttp3.internal.platform.Platform.get();\n                    ^\n  (package okhttp3.internal.platform is declared in module okhttp3,\n    which does not export it to module com.bigco.sdk)\n```\n\nThe stable public API is based on the list of defined modules:\n\n- okhttp3\n- okhttp3.brotli\n- okhttp3.coroutines\n- okhttp3.dnsoverhttps\n- okhttp3.java.net.cookiejar\n- okhttp3.logging\n- okhttp3.sse\n- okhttp3.tls\n- okhttp3.urlconnection\n- mockwebserver3\n- mockwebserver3.junit4\n- mockwebserver3.junit5\n\nLicense\n-------\n\n```\nCopyright 2019 Square, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n [GraalVM]: https://www.graalvm.org/\n [androidx_startup]: https://developer.android.com/jetpack/androidx/releases/startup\n [bom]: https://docs.gradle.org/6.2/userguide/platforms.html#sub:bom_import\n [changelog]: https://square.github.io/okhttp/changelog/\n [conscrypt]: https://github.com/google/conscrypt/\n [get_example]: https://raw.github.com/square/okhttp/master/samples/guide/src/main/java/okhttp3/guide/GetExample.java\n [kotlin]: https://kotlinlang.org/\n [okhttp3_pro]: https://raw.githubusercontent.com/square/okhttp/master/okhttp/src/main/resources/META-INF/proguard/okhttp3.pro\n [okhttp]: https://square.github.io/okhttp/\n [okhttp_312x]: https://github.com/square/okhttp/tree/okhttp_3.12.x\n [okio]: https://github.com/square/okio\n [post_example]: https://raw.github.com/square/okhttp/master/samples/guide/src/main/java/okhttp3/guide/PostExample.java\n [r8_proguard]: https://square.github.io/okhttp/features/r8_proguard/\n [recipes]: https://square.github.io/okhttp/recipes/\n [snap]: https://s01.oss.sonatype.org/content/repositories/snapshots/\n [tls_history]: https://square.github.io/okhttp/tls_configuration_history/\n",
      "stars_today": 3
    },
    {
      "id": 112785414,
      "name": "spring-cloud-alibaba",
      "full_name": "alibaba/spring-cloud-alibaba",
      "description": "Spring Cloud Alibaba provides a one-stop solution for application development for the distributed solutions of Alibaba middleware.",
      "html_url": "https://github.com/alibaba/spring-cloud-alibaba",
      "stars": 29010,
      "forks": 8520,
      "language": "Java",
      "topics": [
        "alibaba",
        "alibaba-middleware",
        "alibaba-oss",
        "aliyun",
        "circuit-breaker",
        "cloud-native",
        "distributed-configuration",
        "distributed-messaging",
        "distributed-transaction",
        "dubbo",
        "java",
        "microservices",
        "nacos",
        "rocketmq",
        "service-discovery",
        "service-registry",
        "spring",
        "spring-cloud",
        "spring-cloud-alibaba",
        "spring-cloud-core"
      ],
      "created_at": "2017-12-01T20:49:15Z",
      "updated_at": "2026-01-15T09:45:14Z",
      "pushed_at": "2026-01-13T10:56:33Z",
      "open_issues": 177,
      "owner": {
        "login": "alibaba",
        "avatar_url": "https://avatars.githubusercontent.com/u/1961952?v=4"
      },
      "readme": "# Spring Cloud Alibaba\n\n[![CircleCI](https://circleci.com/gh/alibaba/spring-cloud-alibaba/tree/2025.1.x.svg?style=svg)](https://circleci.com/gh/alibaba/spring-cloud-alibaba/tree/2025.1.x)\n[![Maven Central](https://img.shields.io/maven-central/v/com.alibaba.cloud/spring-cloud-alibaba-dependencies.svg?label=Maven%20Central)](https://search.maven.org/search?q=g:com.alibaba.cloud%20AND%20a:spring-cloud-alibaba-dependencies)\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![actions](https://github.com/alibaba/spring-cloud-alibaba/workflows/Integration%20Testing/badge.svg)](https://github.com/alibaba/spring-cloud-alibaba/actions)\n[![Leaderboard](https://img.shields.io/badge/SCA-Check%20Your%20Contribution-orange)](https://opensource.alibaba.com/contribution_leaderboard/details?projectValue=sca)\n\nA project maintained by Alibaba.\n\nSee the [ä¸­æ–‡æ–‡æ¡£](https://github.com/alibaba/spring-cloud-alibaba/blob/2025.1.x/README-zh.md) for Chinese readme.\n\nSpring Cloud Alibaba provides a one-stop solution for distributed application development. It contains all the components required to develop distributed applications, making it easy for you to develop your applications using Spring Cloud.\n\nWith Spring Cloud Alibaba, you only need to add some annotations and a small amount of configurations to connect Spring Cloud applications to the distributed solutions of Alibaba, and build a distributed application system with Alibaba middleware.\n\n\n## Features\n\n* **Flow control and service degradation**: Flow control for HTTP services is supported by default. You can also customize flow control and service degradation rules using annotations. The rules can be changed dynamically.\n* **Service registration and discovery**: Service can be registered and clients can discover the instances using Spring-managed beans. Load balancing is consistent with that supported by the corresponding Spring Cloud.\n* **Distributed configuration**: Support for externalized configuration in a distributed system, auto refresh when configuration changes.\n* **Event-driven**: Support for building highly scalable event-driven microservices connected with shared messaging systems.\n* **Distributed Transaction**: Support for distributed transaction solution with high performance and ease of use.\n* **Alibaba Cloud Object Storage**: Massive, secure, low-cost, and highly reliable cloud storage services. Support for storing and accessing any type of data in any application, anytime, anywhere.\n* **Alibaba Cloud SchedulerX**: Accurate, highly reliable, and highly available scheduled job scheduling services with response time within seconds.\n* **Alibaba Cloud SMS**: A messaging service that covers the globe, Alibaba SMS provides convenient, efficient, and intelligent communication capabilities that help businesses quickly contact their customers.\n\nFor more features, please refer to [Roadmap](https://github.com/alibaba/spring-cloud-alibaba/blob/2025.1.x/Roadmap.md).\n\nIn addition to the above-mentioned features, for the needs of enterprise users' scenarios, [Microservices Engine (MSE)](https://www.aliyun.com/product/aliware/mse?spm=github.spring.com.topbar) of Spring Cloud Alibaba's enterprise version provides an enterprise-level microservices governance center, which includes more powerful governance capabilities such as Grayscale Release, Service Warm-up, Lossless Online and Offline and Outlier Ejection. At the same time, it also provides a variety of products and solutions such as enterprise-level Nacos registration / configuration center, enterprise-level cloud native gateway.\n\n\n## Components\n\n**[Sentinel](https://github.com/alibaba/Sentinel)**: Sentinel takes \"traffic flow\" as the breakthrough point, and provides solutions in areas such as flow control, concurrency, circuit breaking, and load protection to protect service stability.\n\n**[Nacos](https://github.com/alibaba/Nacos)**: An easy-to-use dynamic service discovery, configuration and service management platform for building cloud native applications.\n\n**[RocketMQ](https://rocketmq.apache.org/)**: A distributed messaging and streaming platform with low latency, high performance and reliability, trillion-level capacity and flexible scalability.\n\n**[Seata](https://github.com/seata/seata)**: A distributed transaction solution with high performance and ease of use for microservices architecture.\n\n**[Alibaba Cloud OSS](https://www.aliyun.com/product/oss)**: An encrypted and secure cloud storage service which stores, processes and accesses massive amounts of data from anywhere in the world.\n\n**[Alibaba Cloud SMS](https://www.aliyun.com/product/sms)**: A messaging service that covers the globe, Alibaba SMS provides convenient, efficient, and intelligent communication capabilities that help businesses quickly contact their customers.\n\n**[Alibaba Cloud SchedulerX](https://www.aliyun.com/aliware/schedulerx?spm=5176.10695662.784137.1.4b07363dej23L3)**: Accurate, highly reliable, and highly available scheduled job scheduling services with response time within seconds.\n\nFor more features please refer to [Roadmap](https://github.com/alibaba/spring-cloud-alibaba/blob/2025.1.x/Roadmap.md).\n\n## How to build\n* **2025.1.x branch**: Corresponds to Spring Cloud 2025.1.x & Spring Boot 4.0.x, JDK 17 or later versions are supported.\n* **2025.0.x branch**: Corresponds to Spring Cloud 2025.0.x & Spring Boot 3.5.x, JDK 17 or later versions are supported.\n* **2023.x branch**: Corresponds to Spring Cloud 2023 & Spring Boot 3.2.x, JDK 17 or later versions are supported.\n* **2022.x branch**: Corresponds to Spring Cloud 2022 & Spring Boot 3.0.x, JDK 17 or later versions are supported.\n* **2021.x branch**: Corresponds to Spring Cloud 2021 & Spring Boot 2.6.x. JDK 1.8 or later versions are supported.\n* **2020.0 branch**: Corresponds to Spring Cloud 2020 & Spring Boot 2.4.x. JDK 1.8 or later versions are supported.\n* **2.2.x branch**: Corresponds to Spring Cloud Hoxton & Spring Boot 2.2.x. JDK 1.8 or later versions are supported.\n* **greenwich branch**: Corresponds to Spring Cloud Greenwich & Spring Boot 2.1.x. JDK 1.8 or later versions are supported.\n* **finchley branch**: Corresponds to Spring Cloud Finchley & Spring Boot 2.0.x. JDK 1.8 or later versions are supported.\n* **1.x branch**: Corresponds to Spring Cloud Edgware & Spring Boot 1.x, JDK 1.7 or later versions are supported.\n\nSpring Cloud uses Maven for most build-related activities, and you should be able to get off the ground quite quickly by cloning the project you are interested in and typing:\n```bash\n./mvnw install\n```\n\n## How to Use\n\n### Add maven dependency \n\n#### Release Version\n\nThese artifacts are available from Maven Central and Spring Release repository via BOM:\n```xml\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n            <version>2025.0.0.0</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\nadd the module in  `dependencies`. If you want to choose an older version, you can refer to the [Release Notes](https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E).\n\n#### Snapshot\n\nIf you need to use the already published `Snapshot Version`, add the following configuration in the `dependencyManagement`.\n```xml\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n            <version>2025.1.0.0-SNAPSHOT</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\n\nAdd the following configuration in `repositories`.\n```xml\n<repositories>\n    <repository>\n        <id>github</id>\n        <url>https://maven.pkg.github.com/alibaba/spring-cloud-alibaba</url>\n        <releases>\n            <enabled>false</enabled>\n        </releases>\n        <snapshots>\n            <enabled>true</enabled>\n        </snapshots>\n    </repository>\n</repositories>\n```\n\nAdd the following configuration in `settings.xml`.\n```xml\n<servers>\n    <server>\n        <id>github</id>\n        <username>Your GitHub Username</username>\n        <password>Your GitHub Token (requires read:packages permission)</password>\n    </server>\n</servers>\n```\n\n## Examples\n\nA `spring-cloud-alibaba-examples` module is included in our project for you to get started with Spring Cloud Alibaba quickly. It contains an example, and you can refer to the readme file in the example project for a quick walkthrough.\n\nExamplesï¼š\n\n[Sentinel Example](https://github.com/alibaba/spring-cloud-alibaba/tree/2025.1.x/spring-cloud-alibaba-examples/sentinel-example/sentinel-core-example/readme.md)\n\n[Nacos Example](https://github.com/alibaba/spring-cloud-alibaba/blob/2025.1.x/spring-cloud-alibaba-examples/nacos-example/readme.md)\n\n[RocketMQ Example](https://github.com/alibaba/spring-cloud-alibaba/blob/2025.1.x/spring-cloud-alibaba-examples/rocketmq-example/readme.md)\n\n[Alibaba Cloud OSS Example](https://github.com/alibaba/aliyun-spring-boot/tree/master/aliyun-spring-boot-samples/aliyun-oss-spring-boot-sample)\n\n## Version control guidelines\nThe version number of the project is in the form of x.x.x, where x is a number, starting from 0, and is not limited to the range 0~9. When the project is in the incubator phase, the version number is 0.x.x.\n\nAs the interfaces and annotations of Spring Boot 1 and Spring Boot 2 have been changed significantly in the Actuator module, and spring-cloud-commons is also changed quite a lot from 1.x.x to 2.0.0, we take the same version rule as SpringBoot version number.\n\n* 1.5.x for Spring Boot 1.5.x\n* 2.0.x for Spring Boot 2.0.x\n* 2.1.x for Spring Boot 2.1.x\n* 2.2.x for Spring Boot 2.2.x\n* 2020.x for Spring Boot 2.4.x\n* 2021.x for Spring Boot 2.6.x\n* 2022.x for Spring Boot 3.0.x\n* 2023.x for Spring Boot 3.2.x\n* 2025.0.x for Spring Boot 3.5.x\n* 2025.1.x for Spring Boot 4.0.x\n\n## Code of Conduct\nThis project is a sub-project of Spring Cloud, it adheres to the Contributor Covenant [code of conduct](https://sca.aliyun.com/en-us/community/developer/contributor-guide/new-contributor-guide_dev/). By participating, you are expected to uphold this code. Please report unacceptable behavior to spring-code-of-conduct@pivotal.io.\n\n## Code Conventions and Housekeeping\nNone of these is essential for a pull request, but they will all help. They can also be added after the original pull request but before a merge.\n\nUse the Spring Framework code format conventions. If you use Eclipse you can import formatter settings using the eclipse-code-formatter.xml file from the Spring Cloud Build project. If using IntelliJ, you can use the Eclipse Code Formatter Plugin to import the same file.\n\nMake sure all new .java files to have a simple Javadoc class comment with at least an @author tag identifying you, and preferably at least a paragraph on what the class is for.\n\nAdd the ASF license header comment to all new .java files (copy from existing files in the project)\n\nAdd yourself as an @author to the .java files that you modify substantially (more than cosmetic changes).\n\nAdd some Javadocs and, if you change the namespace, some XSD doc elements.\n\nA few unit tests would help a lot as wellâ€‰â€”â€”â€‰someone has to do it.\n\nIf no-one else is using your branch, please rebase it against the current 2023.x (or other target branch in the main project).\n\nWhen writing a commit message please follow these conventions, if you are fixing an existing issue please add Fixes gh-XXXX at the end of the commit message (where XXXX is the issue number).\n\n## Contact Us\nMailing list is recommended for discussing almost anything related to spring-cloud-alibaba. \n\nspring-cloud-alibaba@googlegroups.com: You can ask questions here if you encounter any problem when using or developing spring-cloud-alibaba.\n",
      "stars_today": 3
    },
    {
      "id": 439772085,
      "name": "linera-protocol",
      "full_name": "linera-io/linera-protocol",
      "description": "Main repository for the Linera protocol",
      "html_url": "https://github.com/linera-io/linera-protocol",
      "stars": 31959,
      "forks": 2260,
      "language": "Rust",
      "topics": [
        "blockchain",
        "rust",
        "wasm"
      ],
      "created_at": "2021-12-19T04:09:21Z",
      "updated_at": "2026-01-15T19:16:46Z",
      "pushed_at": "2026-01-15T18:46:56Z",
      "open_issues": 579,
      "owner": {
        "login": "linera-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/107513858?v=4"
      },
      "readme": "# <img src=\"https://github.com/linera-io/linera-protocol/assets/1105398/fe08c941-93af-4114-bb83-bcc0eaec95f9\" width=\"250\" height=\"85\" />\n\n[![License](https://img.shields.io/github/license/linera-io/linera-protocol)](LICENSE)\n[![Build Status for Docker](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml)\n[![Build Status for Rust](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml)\n[![Build Status for Documentation](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml)\n[![Twitter](https://img.shields.io/twitter/follow/linera_io)](https://x.com/linera_io)\n[![Discord](https://img.shields.io/discord/984941796272521226)](https://discord.com/invite/linera)\n\n<!-- [![Build Status for Kubernetes](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml) -->\n\n[Linera](https://linera.io) is a decentralized blockchain infrastructure designed for highly scalable,\nsecure, low-latency Web3 applications.\n\n## Documentation\n\nVisit our [developer page](https://linera.dev) and read our\n[whitepaper](https://linera.io/whitepaper) to learn more about the Linera protocol.\n\n## Repository Structure\n\nThe main crates and directories of this repository can be summarized as follows: (listed\nfrom low to high levels in the dependency graph)\n\n* [`linera-base`](https://linera-io.github.io/linera-protocol/linera_base/index.html) Base\n  definitions, including cryptography.\n\n* [`linera-version`](https://linera-io.github.io/linera-protocol/linera_version/index.html)\n  A library to manage version info in binaries and services.\n\n* [`linera-views`](https://linera-io.github.io/linera-protocol/linera_views/index.html) A\n  library mapping complex data structures onto a key-value store. The corresponding\n  procedural macros are implemented in `linera-views-derive`.\n\n* [`linera-execution`](https://linera-io.github.io/linera-protocol/linera_execution/index.html)\n  Persistent data and the corresponding logic for runtime and execution of Linera\n  applications.\n\n* [`linera-chain`](https://linera-io.github.io/linera-protocol/linera_chain/index.html)\n  Persistent data and the corresponding logic for chains of blocks, certificates, and\n  cross-chain messaging.\n\n* [`linera-storage`](https://linera-io.github.io/linera-protocol/linera_storage/index.html)\n  Defines the storage abstractions for the protocol on top of `linera-chain`.\n\n* [`linera-core`](https://linera-io.github.io/linera-protocol/linera_core/index.html) The\n  core Linera protocol, including client and server logic, node synchronization, etc.\n\n* [`linera-rpc`](https://linera-io.github.io/linera-protocol/linera_rpc/index.html)\n  Defines the data-type for RPC messages (currently all client &#x2194; proxy &#x2194;\n  chain &#x2194; chain interactions), and track the corresponding data schemas.\n\n* [`linera-client`](https://linera-io.github.io/linera-protocol/linera_client/index.html)\n  Library for writing Linera clients.  Used for the command-line\n  client and the node service in `linera-service`, as well as the Web\n  client in [`linera-web`](https://github.com/linera-io/linera-web/).\n\n* [`linera-service`](https://linera-io.github.io/linera-protocol/linera_service/index.html)\n  Executable for clients (aka CLI wallets), proxy (aka validator frontend) and servers.\n\n* [`linera-sdk`](https://linera-io.github.io/linera-protocol/linera_sdk/index.html) The\n  library to develop Linera applications written in Rust for the Wasm virtual machine. The\n  corresponding procedural macros are implemented in `linera-sdk-derive`.\n\n* [`examples`](./examples) Examples of Linera applications written in Rust.\n\n## Prerequisites\n\nSee [`INSTALL.md`](./INSTALL.md) for software requirements to develop in this repo.\n\n## Quickstart with the Linera CLI tool\n\nThe following commands set up a local test network and run some transfers between the\nmicrochains owned by a single wallet.\n\n```bash\n# Make sure to compile the Linera binaries and add them in the $PATH.\n# cargo build -p linera-storage-service -p linera-service --bins\nexport PATH=\"$PWD/target/debug:$PATH\"\n\n# Import the optional helper function `linera_spawn`.\nsource /dev/stdin <<<\"$(linera net helper 2>/dev/null)\"\n\n# Run a local test network with the default parameters and a number of microchains\n# owned by the default wallet. This also defines `LINERA_TMP_DIR`.\nlinera_spawn \\\nlinera net up --with-faucet --faucet-port 8080\n\n# Remember the URL of the faucet.\nFAUCET_URL=http://localhost:8080\n\n# If you're using a testnet, start here and run this instead:\n#   LINERA_TMP_DIR=$(mktemp -d)\n#   FAUCET_URL=https://faucet.testnet-XXX.linera.net  # for some value XXX\n```\n\nEnable logs for user applications:\n\n```bash\nexport LINERA_APPLICATION_LOGS=true\n```\n\nSet the path of the future wallet:\n\n```bash\nexport LINERA_WALLET=\"$LINERA_TMP_DIR/wallet.json\"\nexport LINERA_KEYSTORE=\"$LINERA_TMP_DIR/keystore.json\"\nexport LINERA_STORAGE=\"rocksdb:$LINERA_TMP_DIR/client.db\"\n\n# Initialize a new user wallet.\nlinera wallet init --faucet $FAUCET_URL\n\n# Request chains.\nINFO1=($(linera wallet request-chain --faucet $FAUCET_URL))\nINFO2=($(linera wallet request-chain --faucet $FAUCET_URL))\nCHAIN1=\"${INFO1[0]}\"\nACCOUNT1=\"${INFO1[1]}\"\nCHAIN2=\"${INFO2[0]}\"\nACCOUNT2=\"${INFO2[1]}\"\n\n# Show the different chains tracked by the wallet.\nlinera wallet show\n\n# Query the chain balance of some of the chains.\nlinera query-balance \"$CHAIN1\"\nlinera query-balance \"$CHAIN2\"\n\n# Transfer 10 units then 5 back.\nlinera transfer 10 --from \"$CHAIN1\" --to \"$CHAIN2\"\nlinera transfer 5 --from \"$CHAIN2\" --to \"$CHAIN1\"\n\n# Query balances again.\nlinera query-balance \"$CHAIN1\"\nlinera query-balance \"$CHAIN2\"\n\n# Now let's fund the user balances.\nlinera transfer 5 --from \"$CHAIN1\" --to \"$CHAIN1:$ACCOUNT1\"\nlinera transfer 2 --from \"$CHAIN1:$ACCOUNT1\" --to \"$CHAIN2:$ACCOUNT2\"\n\n# Query user balances again.\nlinera query-balance \"$CHAIN1:$ACCOUNT1\"\nlinera query-balance \"$CHAIN2:$ACCOUNT2\"\n```\n\nMore complex examples may be found in our [developer manual](https://linera.dev) as well\nas the [example applications](./examples) in this repository.\n\n## Contributing\n\nWe welcome contributions from the community! If you'd like to contribute to the Linera protocol:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\nFor detailed guidelines, see our [contribution guide](./CONTRIBUTING.md).\n",
      "stars_today": 3
    },
    {
      "id": 304344049,
      "name": "kit",
      "full_name": "sveltejs/kit",
      "description": "web development, streamlined",
      "html_url": "https://github.com/sveltejs/kit",
      "stars": 20165,
      "forks": 2188,
      "language": "JavaScript",
      "topics": [
        "hacktoberfest",
        "svelte"
      ],
      "created_at": "2020-10-15T14:00:23Z",
      "updated_at": "2026-01-15T16:46:36Z",
      "pushed_at": "2026-01-15T19:15:46Z",
      "open_issues": 1078,
      "owner": {
        "login": "sveltejs",
        "avatar_url": "https://avatars.githubusercontent.com/u/23617963?v=4"
      },
      "readme": "[![Chat](https://img.shields.io/discord/457912077277855764?label=chat&logo=discord)](https://svelte.dev/chat)\n\n# SvelteKit\n\nWeb development, streamlined. Read the [documentation](https://svelte.dev/docs/kit) to get started.\n\n### Packages\n\n| Package                                                                     | Changelog                                                     |\n| --------------------------------------------------------------------------- | ------------------------------------------------------------- |\n| [@sveltejs/kit](packages/kit)                                               | [Changelog](packages/kit/CHANGELOG.md)                        |\n| [@sveltejs/adapter-auto](packages/adapter-auto)                             | [Changelog](packages/adapter-auto/CHANGELOG.md)               |\n| [@sveltejs/adapter-cloudflare](packages/adapter-cloudflare)                 | [Changelog](packages/adapter-cloudflare/CHANGELOG.md)         |\n| [@sveltejs/adapter-netlify](packages/adapter-netlify)                       | [Changelog](packages/adapter-netlify/CHANGELOG.md)            |\n| [@sveltejs/adapter-node](packages/adapter-node)                             | [Changelog](packages/adapter-node/CHANGELOG.md)               |\n| [@sveltejs/adapter-static](packages/adapter-static)                         | [Changelog](packages/adapter-static/CHANGELOG.md)             |\n| [@sveltejs/adapter-vercel](packages/adapter-vercel)                         | [Changelog](packages/adapter-vercel/CHANGELOG.md)             |\n| [@sveltejs/amp](packages/amp)                                               | [Changelog](packages/amp/CHANGELOG.md)                        |\n| [@sveltejs/enhanced-img](packages/enhanced-img)                             | [Changelog](packages/enhanced-img/CHANGELOG.md)               |\n| [@sveltejs/package](packages/package)                                       | [Changelog](packages/package/CHANGELOG.md)                    |\n\n[Additional adapters](https://sveltesociety.dev/packages?category=sveltekit-adapters) are maintained by the community.\n\n## Bug reporting\n\nPlease make sure the issue you're reporting involves SvelteKit. Many issues related to how a project builds originate from [Vite](https://vitejs.dev/), which is used to build a SvelteKit project. You can create a new Vite project with `npm create vite@latest` for client-side only repros and `npm create vite-extra@latest` for SSR or library repros.\n\nIf an issue originates from Vite, please report it in the [Vite issue tracker](https://github.com/vitejs/vite/issues).\n\n## Contributing\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for information on how to develop SvelteKit locally.\n\n## Supporting Svelte\n\nSvelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you'd like to support their efforts, please consider:\n\n- [Becoming a backer on Open Collective](https://opencollective.com/svelte).\n\nFunds donated via Open Collective will be used for compensating expenses related to Svelte's development such as hosting costs. If sufficient donations are received, funds may also be used to support Svelte's development more directly.\n\n## License\n\n[MIT](https://github.com/sveltejs/kit/blob/main/LICENSE)\n",
      "stars_today": 3
    },
    {
      "id": 11847500,
      "name": "coreutils",
      "full_name": "uutils/coreutils",
      "description": "Cross-platform Rust rewrite of the GNU coreutils",
      "html_url": "https://github.com/uutils/coreutils",
      "stars": 22546,
      "forks": 1726,
      "language": "Rust",
      "topics": [
        "busybox",
        "command-line-tool",
        "coreutils",
        "cross-platform",
        "gnu-coreutils",
        "rust"
      ],
      "created_at": "2013-08-02T16:22:56Z",
      "updated_at": "2026-01-16T00:09:14Z",
      "pushed_at": "2026-01-15T15:45:19Z",
      "open_issues": 737,
      "owner": {
        "login": "uutils",
        "avatar_url": "https://avatars.githubusercontent.com/u/5148717?v=4"
      },
      "readme": "<!-- markdownlint-disable MD033 MD041 MD002 -->\n<!-- markdownlint-disable commands-show-output no-duplicate-heading -->\n<!-- spell-checker:ignore markdownlint ; (options) DESTDIR UTILNAME manpages reimplementation oranda libclang -->\n<div class=\"oranda-hide\">\n<div align=\"center\">\n\n![uutils logo](docs/src/logo.svg)\n\n# uutils coreutils\n\n[![Crates.io](https://img.shields.io/crates/v/coreutils.svg)](https://crates.io/crates/coreutils)\n[![Discord](https://img.shields.io/badge/discord-join-7289DA.svg?logo=discord&longCache=true&style=flat)](https://discord.gg/wQVJbvJ)\n[![License](http://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/uutils/coreutils/blob/main/LICENSE)\n[![dependency status](https://deps.rs/repo/github/uutils/coreutils/status.svg)](https://deps.rs/repo/github/uutils/coreutils)\n\n[![CodeCov](https://codecov.io/gh/uutils/coreutils/branch/main/graph/badge.svg)](https://codecov.io/gh/uutils/coreutils)\n![MSRV](https://img.shields.io/badge/MSRV-1.85.0-brightgreen)\n[![Weblate](https://hosted.weblate.org/widget/rust-coreutils/svg-badge.svg)](https://hosted.weblate.org/projects/rust-coreutils/)\n\n</div>\n\n---\n\n</div>\n\nuutils coreutils is a cross-platform reimplementation of the GNU coreutils in\n[Rust](http://www.rust-lang.org). While all programs have been implemented, some\noptions might be missing or different behavior might be experienced.\n\n<div class=\"oranda-hide\">\n\nWe provide prebuilt binaries at https://github.com/uutils/coreutils/releases/latest .\nIt is recommended to install from main branch if you install from source.\n\n</div>\n\n<!-- markdownlint-disable-next-line MD026 -->\n\n## Goals\n\nuutils coreutils aims to be a drop-in replacement for the GNU utils. Differences with GNU\nare treated as bugs.\n\nOur key objectives include:\n- Matching GNU's output (stdout and error code) exactly\n- Better error messages\n- Providing comprehensive internationalization support (UTF-8)\n- Improved performances\n- [Extensions](docs/src/extensions.md) when relevant (example: --progress)\n\nuutils aims to work on as many platforms as possible, to be able to use the same\nutils on Linux, macOS, Windows and other platforms. This ensures, for example,\nthat scripts can be easily transferred between platforms.\n\n<div class=\"oranda-hide\">\n\n## Documentation\nuutils has both user and developer documentation available:\n\n- [User Manual](https://uutils.github.io/coreutils/docs/)\n- [Developer Documentation](https://docs.rs/crate/coreutils/)\n\nBoth can also be generated locally, the instructions for that can be found in\nthe [coreutils docs](https://github.com/uutils/uutils.github.io) repository.\n\nUse [weblate/rust-coreutils](https://hosted.weblate.org/projects/rust-coreutils/) to translate the Rust coreutils into your language.\n\n<!-- ANCHOR: build (this mark is needed for mdbook) -->\n\n## Requirements\n\n- Rust (`cargo`, `rustc`)\n- GNU Make (optional)\n\n### Rust Version\n\nuutils follows Rust's release channels and is tested against stable, beta and\nnightly. The current Minimum Supported Rust Version (MSRV) is `1.85.0`.\n\n## Building\n\nThere are currently two methods to build the uutils binaries: either Cargo or\nGNU Make.\n\n> Building the full package, including all documentation, requires both Cargo\n> and GNU Make on a Unix platform.\n\nFor either method, we first need to fetch the repository:\n\n```shell\ngit clone https://github.com/uutils/coreutils\ncd coreutils\n```\n\n### Cargo\n\nBuilding uutils using Cargo is easy because the process is the same as for every\nother Rust program:\n\n```shell\ncargo build --release\n```\n\nReplace `--release` with `--profile=release-fast` or `--profile=release-small` to use all optimizations or save binary size.\n\nThis command builds the most portable common core set of uutils into a multicall\n(BusyBox-type) binary, named 'coreutils', on most Rust-supported platforms.\n\nAdditional platform-specific uutils are often available. Building these expanded\nsets of uutils for a platform (on that platform) is as simple as specifying it\nas a feature:\n\n```shell\ncargo build --release --features macos\n# or ...\ncargo build --release --features windows\n# or ...\ncargo build --release --features unix\n```\n\nTo build SELinux-specific features, including `chcon` and `runcon`, ensure that `libselinux` \nand `libclang` are installed on your system. Then, run the following command:\n```\ncargo build --release --features unix,feat_selinux\n```\n\nIf you don't want to build every utility available on your platform into the\nfinal binary, you can also specify which ones you want to build manually. For\nexample:\n\n```shell\ncargo build --features \"base32 cat echo rm\" --no-default-features\n```\n\nIf you want to build the utilities as individual binaries, that is also possible:\n\n```shell\ncargo build --release --bins --workspace --exclude coreutils --exclude uu_runcon --exclude uu_chcon\n```\nEach utility is contained in its own package within the main repository, named \"uu_UTILNAME\". To\nbuild selected individual utilities, use the `--package` [aka `-p`] option. For example:\n\n```shell\ncargo build -p uu_base32 -p uu_cat -p uu_echo -p uu_rm\n```\n\n### GNU Make\n\nBuilding using `make` is a simple process as well.\n\nTo simply build all available utilities (with debug profile):\n\n```shell\nmake\n```\n\nIn release-fast mode:\n\n```shell\nmake PROFILE=release-fast\n```\n\nTo build all but a few of the available utilities:\n\n```shell\nmake SKIP_UTILS='UTILITY_1 UTILITY_2'\n```\n\nTo build only a few of the available utilities:\n\n```shell\nmake UTILS='UTILITY_1 UTILITY_2'\n```\n\n## Installation\n\n### Install with Cargo\n\nLikewise, installing can simply be done using:\n\n```shell\ncargo install --path . --locked\n```\n\nThis command will install uutils into Cargo's _bin_ folder (_e.g._\n`$HOME/.cargo/bin`).\n\nThis does not install files necessary for shell completion or manpages. For\nmanpages or shell completion to work, use `GNU Make` or see\n`Manually install shell completions`/`Manually install manpages`.\n\n### Install with GNU Make\n\nTo install all available utilities:\n\n```shell\nmake install\n```\n\nTo install all utilities with all possible optimizations:\n\n```shell\nmake PROFILE=release-fast install\n```\n\nTo install using `sudo` switch `-E` must be used:\n\n```shell\nsudo -E make install\n```\n\nTo install all but a few of the available utilities:\n\n```shell\nmake SKIP_UTILS='UTILITY_1 UTILITY_2' install\n```\n\nTo install only a few of the available utilities:\n\n```shell\nmake UTILS='UTILITY_1 UTILITY_2' install\n```\n\nTo install every program with a prefix (e.g. uu-echo uu-cat):\n\n```shell\nmake PROG_PREFIX=uu- install\n```\n\n`PROG_PREFIX` requires separator `-`, `_`, or `=`.\n\nTo install the multicall binary:\n\n```shell\nmake MULTICALL=y install\n```\n\nSet install parent directory (default value is /usr/local):\n\n```shell\n# DESTDIR is also supported\nmake PREFIX=/my/path install\n```\n\nInstalling with `make` installs shell completions for all installed utilities\nfor `bash`, `fish` and `zsh`. Completions for `elvish` and `powershell` can also\nbe generated; See `Manually install shell completions`.\n\nTo skip installation of completions and manpages:\n\n```shell\nmake COMPLETIONS=n MANPAGES=n install\n```\n\n### Manually install shell completions\n\nThe `uudoc` binary generates completions for the `bash`, `elvish`,\n`fish`, `powershell` and `zsh` shells to stdout.\n\nInstall `uudoc` by\n```shell\ncargo install --bin uudoc --features uudoc --path .\n```\n\nThen use the installed binary:\n```shell\nuudoc completion <utility> <shell>\n```\n\nSo, to install completions for `ls` on `bash` to\n`/usr/local/share/bash-completion/completions/ls`, run:\n\n```shell\nuudoc completion ls bash > /usr/local/share/bash-completion/completions/ls.bash\n```\n\nCompletion for prefixed `cp` with `uu-` on `zsh` is generated by\n```shell\nenv PROG_PREFIX=uu- uudoc completion cp zsh\n```\n\n### Manually install manpages\n\nTo generate manpages, the syntax is:\n\n```bash\nuudoc manpage <utility>\n```\n\nSo, to install the manpage for `ls` to `/usr/local/share/man/man1/ls.1` run:\n\n```bash\nuudoc manpage ls > /usr/local/share/man/man1/ls.1\n```\n\n## Un-installation\n\nUn-installation differs depending on how you have installed uutils. If you used\nCargo to install, use Cargo to uninstall. If you used GNU Make to install, use\nMake to uninstall.\n\n### Uninstall with Cargo\n\nTo uninstall uutils:\n\n```shell\ncargo uninstall coreutils\n```\n\n### Uninstall with GNU Make\n\nTo uninstall all utilities:\n\n```shell\nmake uninstall\n```\n\nTo uninstall every program with a set prefix:\n\n```shell\nmake PROG_PREFIX=uu- uninstall\n```\n\nTo uninstall the multicall binary:\n\n```shell\nmake MULTICALL=y uninstall\n```\n\nTo uninstall from a custom parent directory:\n\n```shell\n# DESTDIR is also supported\nmake PREFIX=/my/path uninstall\n```\n\n<!-- ANCHOR_END: build (this mark is needed for mdbook) -->\n\n## GNU test suite compatibility\n\nBelow is the evolution of how many GNU tests uutils passes. A more detailed\nbreakdown of the GNU test results of the main branch can be found\n[in the user manual](https://uutils.github.io/coreutils/docs/test_coverage.html).\n\nSee <https://github.com/orgs/uutils/projects/1> for the main meta bugs\n(many are missing).\n\n![Evolution over time](https://github.com/uutils/coreutils-tracking/blob/main/gnu-results.svg?raw=true)\n\n</div> <!-- close oranda-hide div -->\n\n## Contributing\n\nTo contribute to uutils, please see [CONTRIBUTING](CONTRIBUTING.md).\n\n## License\n\nuutils is licensed under the MIT License - see the `LICENSE` file for details\n\nGNU Coreutils is licensed under the GPL 3.0 or later.\n",
      "stars_today": 3
    },
    {
      "id": 35732214,
      "name": "SwiftLint",
      "full_name": "realm/SwiftLint",
      "description": "A tool to enforce Swift style and conventions.",
      "html_url": "https://github.com/realm/SwiftLint",
      "stars": 19392,
      "forks": 2279,
      "language": "Swift",
      "topics": [
        "code-quality",
        "hacktoberfest",
        "linter",
        "linting",
        "static-analysis",
        "swift"
      ],
      "created_at": "2015-05-16T16:59:31Z",
      "updated_at": "2026-01-16T00:22:30Z",
      "pushed_at": "2026-01-15T22:07:52Z",
      "open_issues": 474,
      "owner": {
        "login": "realm",
        "avatar_url": "https://avatars.githubusercontent.com/u/7575099?v=4"
      },
      "readme": "# SwiftLint\n\nA tool to enforce Swift style and conventions, loosely based on the now\narchived [GitHub Swift Style Guide](https://github.com/github/swift-style-guide).\nSwiftLint enforces the style guide rules that are generally accepted by the\nSwift community. These rules are well described in popular style guides like\n[Kodeco's Swift Style Guide](https://github.com/kodecocodes/swift-style-guide).\n\nSwiftLint rules are predominantly based on [SwiftSyntax](https://github.com/swiftlang/swift-syntax).\nSome rules still hook into [Clang](http://clang.llvm.org) and\n[SourceKit](http://www.jpsim.com/uncovering-sourcekit) to access type information.\n\n[![Supported Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Frealm%2FSwiftLint%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/realm/SwiftLint)\n[![Supported Platforms](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Frealm%2FSwiftLint%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/realm/SwiftLint)\n[![Buildkite Build Status](https://badge.buildkite.com/e2a5bc32c347e76e2793e4c5764a5f42bcd42bbe32f79c3a53.svg?branch=main)](https://buildkite.com/swiftlint/swiftlint)\n\n![SwiftLint violations highlighted in the Xcode editor](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/screenshot.png)\n\nThis project adheres to the\n[Contributor Covenant Code of Conduct](https://realm.io/conduct).\nBy participating, you are expected to uphold this code.\n\n> Switch Language:\n> [ä¸­æ–‡](https://github.com/realm/SwiftLint/blob/main/README_CN.md),\n> [í•œêµ­ì–´](https://github.com/realm/SwiftLint/blob/main/README_KR.md)\n\n## Video Introduction\n\nTo get a high-level overview of SwiftLint, we encourage you to watch this\npresentation recorded January 9th, 2017 by JP Simard (transcript provided):\n\n[![Presentation](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/presentation.svg)](https://youtu.be/9Z1nTMTejqU)\n\n## Installation\n\n### [Swift Package Manager](https://github.com/apple/swift-package-manager)\n\nSwiftLint can be used as a [command plugin](#swift-package-command-plugin)\nor a [build tool plugin](#build-tool-plugins).\n\nAdd\n\n```swift\n.package(url: \"https://github.com/SimplyDanny/SwiftLintPlugins\", from: \"<version>\")\n```\n\nto your `Package.swift` file to consume the latest release of SwiftLint\nautomatically or pin the dependency to a specific version:\n\n```swift\n.package(url: \"https://github.com/SimplyDanny/SwiftLintPlugins\", exact: \"<version>\")\n```\n\nTherein, replace `<version>` with the desired minimum or exact version.\n\n> [!NOTE]\n> Consuming the plugins directly from the SwiftLint repository comes\n> with several drawbacks. To avoid them and reduce the overhead imposed, it's\n> highly recommended to consume the plugins from the dedicated\n> [SwiftLintPlugins repository](https://github.com/SimplyDanny/SwiftLintPlugins),\n> even though plugins from the SwiftLint repository are also absolutely\n> functional. If the plugins from SwiftLint are preferred, just use the URL\n> `https://github.com/realm/SwiftLint` in the package declarations above.\n>\n> However, [SwiftLintPlugins](https://github.com/SimplyDanny/SwiftLintPlugins)\n> facilitates plugin adoption massively. It lists some of the reasons that\n> drive the plugins as provided by SwiftLint itself very troublesome. Since\n> the plugin code and the releases are kept in sync, there is no difference\n> in functionality between the two, but you spare yourself a lot of time and\n> trouble using the dedicated plugins repository.\n>\n> This document assumes you're relying on SwiftLintPlugins.\n\n### [Xcode Package Dependency](https://developer.apple.com/documentation/xcode/adding-package-dependencies-to-your-app)\n\nUse the following link to add SwiftLint as a Package Dependency to an Xcode\nproject:\n\n```bash\nhttps://github.com/SimplyDanny/SwiftLintPlugins\n```\n\n### [Homebrew](http://brew.sh)\n\n```bash\nbrew install swiftlint\n```\n\n### [CocoaPods](https://cocoapods.org)\n\nAdd the following to your `Podfile`:\n\n```ruby\npod 'SwiftLint'\n```\n\nThis will download the SwiftLint binaries and dependencies in `Pods/` during\nyour next `pod install` execution and will allow you to invoke it via\n`${PODS_ROOT}/SwiftLint/swiftlint` in your Script Build Phases.\n\nInstalling via Cocoapods also enables pinning to a specific version of\nSwiftLint rather than simply the latest (which is the case with\n[Homebrew](#homebrew)).\n\nNote that this will add the SwiftLint binaries, its dependencies' binaries, and\nthe Swift binary library distribution to the `Pods/` directory, so checking in\nthis directory to SCM such as Git is discouraged.\n\n### [Mint](https://github.com/yonaskolb/mint)\n\n```bash\nmint install realm/SwiftLint\n```\n\n### [Bazel](https://bazel.build)\n\nPut this in your `MODULE.bazel`:\n\n```bzl\nbazel_dep(name = \"swiftlint\", version = \"0.52.4\", repo_name = \"SwiftLint\")\n```\n\nOr put this in your `WORKSPACE`:\n\n<details>\n\n<summary>WORKSPACE</summary>\n\n```bzl\nload(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\")\n\nhttp_archive(\n    name = \"build_bazel_rules_apple\",\n    sha256 = \"390841dd5f8a85fc25776684f4793d56e21b098dfd7243cd145b9831e6ef8be6\",\n    url = \"https://github.com/bazelbuild/rules_apple/releases/download/2.4.1/rules_apple.2.4.1.tar.gz\",\n)\n\nload(\n    \"@build_bazel_rules_apple//apple:repositories.bzl\",\n    \"apple_rules_dependencies\",\n)\n\napple_rules_dependencies()\n\nload(\n    \"@build_bazel_rules_swift//swift:repositories.bzl\",\n    \"swift_rules_dependencies\",\n)\n\nswift_rules_dependencies()\n\nload(\n    \"@build_bazel_rules_swift//swift:extras.bzl\",\n    \"swift_rules_extra_dependencies\",\n)\n\nswift_rules_extra_dependencies()\n\nhttp_archive(\n    name = \"SwiftLint\",\n    sha256 = \"c6ea58b9c72082cdc1ada4a2d48273ecc355896ed72204cedcc586b6ccb8aca6\",\n    url = \"https://github.com/realm/SwiftLint/releases/download/0.52.4/bazel.tar.gz\",\n)\n\nload(\"@SwiftLint//bazel:repos.bzl\", \"swiftlint_repos\")\n\nswiftlint_repos()\n\nload(\"@SwiftLint//bazel:deps.bzl\", \"swiftlint_deps\")\n\nswiftlint_deps()\n```\n\n</details>\n\nThen you can run SwiftLint in the current directory with this command:\n\n```console\nbazel run -c opt @SwiftLint//:swiftlint\n```\n\n### Pre-Built Package\n\nDownload `SwiftLint.pkg` from the\n[latest GitHub release](https://github.com/realm/SwiftLint/releases/latest) and\nrun it.\n\n### From Source\n\nMake sure the build tool [Bazel](https://bazel.build) and a\nrecent [Swift toolchain](https://www.swift.org/download/) are\ninstalled and all tools are discoverable in your `PATH`.\n\nTo build SwiftLint, clone this repository and run `make install`.\n\n## Setup\n\n> [!IMPORTANT]\n> While it may seem intuitive to run SwiftLint before compiling Swift source\n> files to exit a build early when there are lint violations, it is important\n> to understand that SwiftLint is designed to analyze valid source code that\n> is compilable. Non-compiling code can very easily lead to unexpected and\n> confusing results, especially when executing with `--fix`/`--autocorrect`\n> command line arguments.\n\n### Build Tool Plugins\n\nSwiftLint can be used as a build tool plugin for both\n[Swift Package projects](#swift-package-projects)\nand [Xcode projects](#xcode-projects).\n\nThe build tool plugin determines the SwiftLint working directory by locating\nthe topmost config file within the package/project directory. If a config file\nis not found therein, the package/project directory is used as the working\ndirectory.\n\nThe plugin throws an error when it is unable to resolve the SwiftLint working\ndirectory. For example, this will occur in Xcode projects where the target's\nSwift files are not located within the project directory.\n\nTo maximize compatibility with the plugin, avoid project structures that require\nthe use of the `--config` option.\n\n### Swift Package Projects\n\n> [!NOTE]\n> Requires installing via [Swift Package Manager](#swift-package-manager).\n\nBuild tool plugins run when building each target. When a project has multiple\ntargets, the plugin must be added to the desired targets individually.\n\nTo do this, add the plugin to the target(s) to be linted as follows:\n\n```swift\n.target(\n    ...\n    plugins: [.plugin(name: \"SwiftLintBuildToolPlugin\", package: \"SwiftLintPlugins\")]\n),\n```\n\n### Swift Package Command Plugin\n\n> [!NOTE]\n> Requires installing via [Swift Package Manager](#swift-package-manager).\n\nThe command plugin enables running SwiftLint from the command line as follows:\n\n```shell\nswift package plugin swiftlint\n```\n\n### Xcode Projects\n\n> [!NOTE]\n> Requires installing via [Xcode Package Dependency](#xcode-package-dependency).\n\nBuild tool plugins run as a build phase of each target. When a project has\nmultiple targets, the plugin must be added to the desired targets individually.\n\nTo do this, add the `SwiftLintBuildToolPlugin` to the `Run Build Tool Plug-ins`\nphase of the `Build Phases` for the target(s) to be linted.\n\n> [!TIP]\n> When using the plugin for the first time, be sure to trust and enable\n> it when prompted. If a macros build warning exists, select it to trust\n> and enable the macros as well.\n\nFor unattended use (e.g. on CI), package plugin and macro\nvalidations can be disabled with either of the following:\n\n* Using `xcodebuild` options:\n\n  ```bash\n  -skipPackagePluginValidation\n  -skipMacroValidation\n  ```\n\n* Setting Xcode defaults:\n\n  ```bash\n  defaults write com.apple.dt.Xcode IDESkipPackagePluginFingerprintValidatation -bool YES\n  defaults write com.apple.dt.Xcode IDESkipMacroFingerprintValidation -bool YES\n  ```\n\n> [!IMPORTANT]\n> The unattended use options bypass Xcode's validation dialogs\n> and implicitly trust all plugins and macros, which has security implications.\n\n#### Unexpected Xcode Project Structures\n\nProject structures where SwiftLint's configuration file is located\noutside of the package/project directory are not directly supported\nby the build tool plugin. This is because it isn't possible to pass\narguments to build tool plugins (e.g., passing the config file path).\n\nIf your project structure doesn't work directly with the build tool\nplugin, please consider one of the following options:\n\n* To use a config file located outside the package/project directory, a config\n  file may be added to that directory specifying a parent config path to the\n  other config file, e.g., `parent_config: path/to/.swiftlint.yml`.\n* You can also consider the use of a\n  [Run Script Build Phase](#xcode-run-script-build-phase) in place of the build\n  tool plugin.\n\n### Xcode Run Script Build Phase\n\n> [!NOTE]\n> Based upon the installation method used, the shell command syntax in the\n> Run Script Build Phase may be different or additional configuration could\n> be required. Refer to the [installation](#installation) instructions for\n> more information.\n\nIf the build tool plugin does not work for your project setup or when\nadditional custom setup is required, SwiftLint can be added as a Run Script\nBuild Phase. This is useful when a project setup relies on the `--config`\nSwiftLint option; or to lint all targets together in a single `swiftlint`\ninvocation. File inclusions and exclusions can be configured in the\n[`.swiftlint.yml` configuration](#configuration).\n\nTo do this, add a custom script to a `Run Script` phase of the `Build Phases`\nof the primary app target, after the `Compile Sources` phase. Use the\nfollowing script implementation:\n\n```bash\nif command -v swiftlint >/dev/null 2>&1\nthen\n    swiftlint\nelse\n    echo \"warning: `swiftlint` command not found - See https://github.com/realm/SwiftLint#installation for installation instructions.\"\nfi\n```\n\nIf you're using the SwiftLintPlugin in a Swift package,\nyou may refer to the `swiftlint` executable in the\nfollowing way:\n\n```bash\nSWIFT_PACKAGE_DIR=\"${BUILD_DIR%Build/*}SourcePackages/artifacts\"\nSWIFTLINT_CMD=\"$SWIFT_PACKAGE_DIR/swiftlintplugins/SwiftLintBinary/SwiftLintBinary.artifactbundle/macos/swiftlint\"\n\nif test -f \"$SWIFTLINT_CMD\" 2>&1\nthen\n    \"$SWIFTLINT_CMD\"\nelse\n    echo \"warning: `swiftlint` command not found - See https://github.com/realm/SwiftLint#xcode-run-script-build-phase for installation instructions.\"\nfi\n```\n\n> [!NOTE]\n> The `SWIFTLINT_CMD` path uses the default Xcode configuration and has been\n> tested on Xcode 15/16. In case of another configuration (e.g. a custom\n> Swift package path), please adapt the values accordingly.\n<!-- markdownlint-disable MD028 -->\n> [!TIP]\n> Uncheck `Based on dependency analysis` to run `swiftlint` on all incremental\n> builds, suppressing the unspecified outputs warning.\n\n#### Consideration for Xcode 15.0\n\nXcode 15 made a significant change by setting the default value of the\n`ENABLE_USER_SCRIPT_SANDBOXING` build setting from `NO` to `YES`.\nAs a result, SwiftLint encounters an error related to missing file permissions,\nwhich typically manifests as\n`error: Sandbox: swiftlint(19427) deny(1) file-read-data.`\n\nTo resolve this issue, it is necessary to manually set the\n`ENABLE_USER_SCRIPT_SANDBOXING` setting to `NO` for the specific target that\nSwiftLint is being configured for.\n\n#### Consideration for Apple Silicon\n\nIf you installed SwiftLint via Homebrew on Apple Silicon, you might experience\nthis warning:\n\n```bash\nwarning: SwiftLint not installed, download from https://github.com/realm/SwiftLint\n```\n\nThat is because Homebrew on Apple Silicon installs the binaries into the\n`/opt/homebrew/bin` folder by default. To instruct Xcode where to find\nSwiftLint, you can either add `/opt/homebrew/bin` to the `PATH` environment\nvariable in your build phase:\n\n```bash\nif [[ \"$(uname -m)\" == arm64 ]]\nthen\n    export PATH=\"/opt/homebrew/bin:$PATH\"\nfi\n\nif command -v swiftlint >/dev/null 2>&1\nthen\n    swiftlint\nelse\n    echo \"warning: `swiftlint` command not found - See https://github.com/realm/SwiftLint#installation for installation instructions.\"\nfi\n```\n\nor you can create a symbolic link in `/usr/local/bin` pointing to the actual\nbinary:\n\n```bash\nln -s /opt/homebrew/bin/swiftlint /usr/local/bin/swiftlint\n```\n\n#### Additional Considerations\n\nIf you wish to fix violations as well, your script could run\n`swiftlint --fix && swiftlint` instead of just `swiftlint`. This will mean\nthat all correctable violations are fixed while ensuring warnings show up in\nyour project for remaining violations.\n\nIf you've installed SwiftLint via CocoaPods the script should look like this:\n\n```bash\n\"${PODS_ROOT}/SwiftLint/swiftlint\"\n```\n\n### Visual Studio Code\n\nTo integrate SwiftLint with [Visual Studio Code](https://code.visualstudio.com), install the\n[`vscode-swiftlint`](https://marketplace.visualstudio.com/items?itemName=vknabel.vscode-swiftlint)\nextension from the marketplace.\n\n### Fastlane\n\nYou can use the official\n[`swiftlint` fastlane action](https://docs.fastlane.tools/actions/swiftlint)\nto run SwiftLint as part of your fastlane process.\n\n```ruby\nswiftlint(\n    mode: :lint,                            # SwiftLint mode: :lint (default) or :autocorrect\n    executable: \"Pods/SwiftLint/swiftlint\", # The SwiftLint binary path (optional). Important if you've installed it via CocoaPods\n    path: \"/path/to/lint\",                  # Specify path to lint (optional)\n    output_file: \"swiftlint.result.json\",   # The path of the output file (optional)\n    reporter: \"json\",                       # The custom reporter to use (optional)\n    config_file: \".swiftlint-ci.yml\",       # The path of the configuration file (optional)\n    files: [                                # List of files to process (optional)\n        \"AppDelegate.swift\",\n        \"path/to/project/Model.swift\"\n    ],\n    ignore_exit_status: true,               # Allow fastlane to continue even if SwiftLint returns a non-zero exit status (Default: false)\n    quiet: true,                            # Don't print status logs like 'Linting ' & 'Done linting' (Default: false)\n    strict: true                            # Fail on warnings? (Default: false)\n)\n```\n\n### Docker\n\nSwiftLint is also available as a [Docker](https://www.docker.com/) image using\n`Ubuntu`. So just the first time you need to pull the docker image using the\nnext command:\n\n```bash\ndocker pull ghcr.io/realm/swiftlint:latest\n```\n\nThen following times, you just run `swiftlint` inside of the docker like:\n\n```bash\ndocker run -it -v `pwd`:`pwd` -w `pwd` ghcr.io/realm/swiftlint:latest\n```\n\nThis will execute `swiftlint` in the folder where you are right now (`pwd`),\nshowing an output like:\n\n```bash\n$ docker run -it -v `pwd`:`pwd` -w `pwd` ghcr.io/realm/swiftlint:latest\nLinting Swift files in current working directory\nLinting 'RuleDocumentation.swift' (1/490)\n...\nLinting 'YamlSwiftLintTests.swift' (490/490)\nDone linting! Found 0 violations, 0 serious in 490 files.\n```\n\nHere you have more documentation about the usage of\n[Docker Images](https://docs.docker.com/).\n\n## Command Line Usage\n\n```txt\n$ swiftlint help\nOVERVIEW: A tool to enforce Swift style and conventions.\n\nUSAGE: swiftlint <subcommand>\n\nOPTIONS:\n  --version               Show the version.\n  -h, --help              Show help information.\n\nSUBCOMMANDS:\n  analyze                 Run analysis rules\n  docs                    Open SwiftLint documentation website in the default web browser\n  generate-docs           Generates markdown documentation for selected group of rules\n  lint (default)          Print lint warnings and errors\n  baseline                Operations on existing baselines\n  reporters               Display the list of reporters and their identifiers\n  rules                   Display the list of rules and their identifiers\n  version                 Display the current version of SwiftLint\n\n  See 'swiftlint help <subcommand>' for detailed help.\n```\n\nRun `swiftlint` in the directory containing the Swift files to lint. Directories\nwill be searched recursively.\n\nTo specify a list of files when using `lint` or `analyze`\n(like the list of files modified by Xcode specified by the\n[`ExtraBuildPhase`](https://github.com/norio-nomura/ExtraBuildPhase) Xcode\nplugin, or modified files in the working tree based on `git ls-files -m`), you\ncan do so by passing the option `--use-script-input-files` and setting the\nfollowing instance variables: `SCRIPT_INPUT_FILE_COUNT`\nand `SCRIPT_INPUT_FILE_0`, `SCRIPT_INPUT_FILE_1`, ...,\n`SCRIPT_INPUT_FILE_{SCRIPT_INPUT_FILE_COUNT - 1}`.\nSimilarly, files can be read from file lists by passing\nthe option `--use-script-input-file-lists` and setting the\nfollowing instance variables: `SCRIPT_INPUT_FILE_LIST_COUNT`\nand `SCRIPT_INPUT_FILE_LIST_0`, `SCRIPT_INPUT_FILE_LIST_1`, ...,\n`SCRIPT_INPUT_FILE_LIST_{SCRIPT_INPUT_FILE_LIST_COUNT - 1}`.\n\nThese are same environment variables set for input files to\n[custom Xcode script phases](http://indiestack.com/2014/12/speeding-up-custom-script-phases/).\n\n## Working With Multiple Swift Versions\n\nSwiftLint hooks into SourceKit so it continues working even as Swift evolves!\n\nThis also keeps SwiftLint lean, as it doesn't need to ship with a full Swift\ncompiler, it just communicates with the official one you already have installed\non your machine.\n\nYou should always run SwiftLint with the same toolchain you use to compile your\ncode.\n\nYou may want to override SwiftLint's default Swift toolchain if you have\nmultiple toolchains or Xcodes installed.\n\nHere's the order in which SwiftLint determines which Swift toolchain to use:\n\n* `$XCODE_DEFAULT_TOOLCHAIN_OVERRIDE`\n* `$TOOLCHAIN_DIR` or `$TOOLCHAINS`\n* `xcrun -find swift`\n* `/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n* `/Applications/Xcode-beta.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n* `~/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n* `~/Applications/Xcode-beta.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain`\n\n`sourcekitd.framework` is expected to be found in the `usr/lib/` subdirectory of\nthe value passed in the paths above.\n\nYou may also set the `TOOLCHAINS` environment variable to the reverse-DNS\nnotation that identifies a Swift toolchain version:\n\n```shell\nTOOLCHAINS=com.apple.dt.toolchain.Swift_2_3 swiftlint --fix\n```\n\nOn Linux, SourceKit is expected to be located in\n`/usr/lib/libsourcekitdInProc.so` or specified by the `LINUX_SOURCEKIT_LIB_PATH`\nenvironment variable.\n\n## Git `pre-commit` Hook\n\nSwiftLint can be run as a [pre-commit](https://pre-commit.com/) hook.\nOnce [installed](https://pre-commit.com/#install), add this to the\n`.pre-commit-config.yaml` in the root of your repository:\n\n```yaml\nrepos:\n  - repo: https://github.com/realm/SwiftLint\n    rev: 0.57.1\n    hooks:\n      - id: swiftlint\n```\n\nAdjust `rev` to the SwiftLint version of your choice.  `pre-commit autoupdate`\ncan be used to update to the current version.\n\nSwiftLint can be configured using `entry` to apply fixes and fail on errors:\n\n```yaml\n-   repo: https://github.com/realm/SwiftLint\n    rev: 0.57.1\n    hooks:\n    -   id: swiftlint\n        entry: swiftlint --fix --strict\n```\n\n## Rules\n\nOver 200 rules are included in SwiftLint and the Swift community (that's you!)\ncontinues to contribute more over time.\n[Pull requests](https://github.com/realm/SwiftLint/blob/main/CONTRIBUTING.md)\nare encouraged.\n\nYou can find an updated list of rules and more information about them in the\n[Rule Directory](https://realm.github.io/SwiftLint/rule-directory.html).\n\nYou can also check the\n[Source/SwiftLintBuiltInRules/Rules](https://github.com/realm/SwiftLint/tree/main/Source/SwiftLintBuiltInRules/Rules)\ndirectory to see their implementation.\n\n### Opt-In Rules\n\n`opt_in_rules` are disabled by default (i.e., you have to explicitly enable them\nin your configuration file).\n\nGuidelines on when to mark a rule as opt-in:\n\n* A rule that can have many false positives (e.g. `empty_count`)\n* A rule that is too slow\n* A rule that is not general consensus or is only useful in some cases\n  (e.g. `force_unwrapping`)\n\n### Disable rules in code\n\nRules can be disabled with a comment inside a source file with the following\nformat:\n\n`// swiftlint:disable <rule1> [<rule2> <rule3>...]`\n\nThe rules will be disabled until the end of the file or until the linter sees a\nmatching enable comment:\n\n`// swiftlint:enable <rule1> [<rule2> <rule3>...]`\n\nFor example:\n\n```swift\n// swiftlint:disable colon\nlet noWarning :String = \"\" // No warning about colons immediately after variable names!\n// swiftlint:enable colon\nlet hasWarning :String = \"\" // Warning generated about colons immediately after variable names\n```\n\nIncluding the `all` keyword will disable all rules until the linter sees a\nmatching enable comment:\n\n`// swiftlint:disable all`\n`// swiftlint:enable all`\n\nFor example:\n\n```swift\n// swiftlint:disable all\nlet noWarning :String = \"\" // No warning about colons immediately after variable names!\nlet i = \"\" // Also no warning about short identifier names\n// swiftlint:enable all\nlet hasWarning :String = \"\" // Warning generated about colons immediately after variable names\nlet y = \"\" // Warning generated about short identifier names\n```\n\nIt's also possible to modify a `disable` or `enable` command by appending\n`:previous`, `:this` or `:next` for only applying the command to the previous,\nthis (current) or next line respectively.\n\nFor example:\n\n```swift\n// swiftlint:disable:next force_cast\nlet noWarning = NSNumber() as! Int\nlet hasWarning = NSNumber() as! Int\nlet noWarning2 = NSNumber() as! Int // swiftlint:disable:this force_cast\nlet noWarning3 = NSNumber() as! Int\n// swiftlint:disable:previous force_cast\n```\n\nRun `swiftlint rules` to print a list of all available rules and their\nidentifiers.\n\n### Configuration\n\nConfigure SwiftLint by adding a `.swiftlint.yml` file from the directory you'll\nrun SwiftLint from. The following parameters can be configured:\n\nRule inclusion:\n\n* `disabled_rules`: Disable rules from the default enabled set.\n* `opt_in_rules`: Enable rules that are not part of the default set. The\n   special `all` identifier will enable all opt in linter rules, except the ones\n   listed in `disabled_rules`.\n* `only_rules`: Only the rules specified in this list will be enabled.\n   Cannot be specified alongside `disabled_rules` or `opt_in_rules`.\n* `analyzer_rules`: This is an entirely separate list of rules that are only\n  run by the `analyze` command. All analyzer rules are opt-in, so this is the\n  only configurable rule list, there are no equivalents for `disabled_rules`\n  and `only_rules`. The special `all` identifier can also be used here to enable\n  all analyzer rules, except the ones listed in `disabled_rules`.\n\n```yaml\n# By default, SwiftLint uses a set of sensible default rules you can adjust:\ndisabled_rules: # rule identifiers turned on by default to exclude from running\n  - colon\n  - comma\n  - control_statement\nopt_in_rules: # some rules are turned off by default, so you need to opt-in\n  - empty_count # find all the available rules by running: `swiftlint rules`\n\n# Alternatively, specify all rules explicitly by uncommenting this option:\n# only_rules: # delete `disabled_rules` & `opt_in_rules` if using this\n#   - empty_parameters\n#   - vertical_whitespace\n\nanalyzer_rules: # rules run by `swiftlint analyze`\n  - explicit_self\n\n# Case-sensitive paths to include during linting. Directory paths supplied on the\n# command line will be ignored.\nincluded: \n  - Sources\nexcluded: # case-sensitive paths to ignore during linting. Takes precedence over `included`\n  - Carthage\n  - Pods\n  - Sources/ExcludedFolder\n  - Sources/ExcludedFile.swift\n  - Sources/*/ExcludedFile.swift # exclude files with a wildcard\n\n# If true, SwiftLint will not fail if no lintable files are found.\nallow_zero_lintable_files: false\n\n# If true, SwiftLint will treat all warnings as errors.\nstrict: false\n\n# If true, SwiftLint will treat all errors as warnings.\nlenient: false\n\n# The path to a baseline file, which will be used to filter out detected violations.\nbaseline: Baseline.json\n\n# The path to save detected violations to as a new baseline.\nwrite_baseline: Baseline.json\n\n# If true, SwiftLint will check for updates after linting or analyzing.\ncheck_for_updates: true\n\n# configurable rules can be customized from this configuration file\n# binary rules can set their severity level\nforce_cast: warning # implicitly\nforce_try:\n  severity: warning # explicitly\n# rules that have both warning and error levels, can set just the warning level\n# implicitly\nline_length: 110\n# they can set both implicitly with an array\ntype_body_length:\n  - 300 # warning\n  - 400 # error\n# or they can set both explicitly\nfile_length:\n  warning: 500\n  error: 1200\n# naming rules can set warnings/errors for min_length and max_length\n# additionally they can set excluded names\ntype_name:\n  min_length: 4 # only warning\n  max_length: # warning and error\n    warning: 40\n    error: 50\n  excluded: iPhone # excluded via string\n  allowed_symbols: [\"_\"] # these are allowed in type names\nidentifier_name:\n  min_length: # only min_length\n    error: 4 # only error\n  excluded: # excluded via string array\n    - id\n    - URL\n    - GlobalAPIKey\nreporter: \"xcode\" # reporter type (xcode, json, csv, checkstyle, codeclimate, junit, html, emoji, sonarqube, markdown, github-actions-logging, summary)\n```\n\nYou can also use environment variables in your configuration file,\nby using `${SOME_VARIABLE}` in a string.\n\n### Defining Custom Rules\n\nIn addition to the rules that the main SwiftLint project ships with, SwiftLint\ncan also run two types of custom rules that you can define yourself in your own\nprojects:\n\n#### 1. Swift Custom Rules\n\nThese rules are written the same way as the Swift-based rules that ship with\nSwiftLint so they're fast, accurate, can leverage SwiftSyntax, can be unit\ntested, and more.\n\nUsing these requires building SwiftLint with Bazel as described in\n[this video](https://vimeo.com/820572803) or its associated code in\n[github.com/jpsim/swiftlint-bazel-example](https://github.com/jpsim/swiftlint-bazel-example).\n\n#### 2. Regex Custom Rules\n\nYou can define custom regex-based rules in your configuration file using the\nfollowing syntax:\n\n```yaml\ncustom_rules:\n  pirates_beat_ninjas: # rule identifier\n    included:\n      - \".*\\\\.swift\" # regex that defines paths to include during linting. optional.\n    excluded:\n      - \".*Test\\\\.swift\" # regex that defines paths to exclude during linting. optional\n    name: \"Pirates Beat Ninjas\" # rule name. optional.\n    regex: \"([nN]inja)\" # matching pattern\n    capture_group: 0 # number of regex capture group to highlight the rule violation at. optional.\n    match_kinds: # SyntaxKinds to match. optional.\n      - comment\n      - identifier\n    message: \"Pirates are better than ninjas.\" # violation message. optional.\n    severity: error # violation severity. optional.\n  no_hiding_in_strings:\n    regex: \"([nN]inja)\"\n    match_kinds: string\n```\n\nThis is what the output would look like:\n\n![Custom violations highlighted in the Xcode editor](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/custom-rule.png)\n\nIt is important to note that the regular expression pattern is used with the\nflags `s` and `m` enabled, that is `.`\n[matches newlines](https://developer.apple.com/documentation/foundation/nsregularexpression/options/1412529-dotmatcheslineseparators)\nand `^`/`$`\n[match the start and end of lines](https://developer.apple.com/documentation/foundation/nsregularexpression/options/1408263-anchorsmatchlines),\nrespectively. If you do not want to have `.` match newlines, for example, the\nregex can be prepended by `(?-s)`.\n\nYou can filter the matches by providing one or more `match_kinds`, which will\nreject matches that include syntax kinds that are not present in this list. Here\nare all the possible syntax kinds:\n\n* `argument`\n* `attribute.builtin`\n* `attribute.id`\n* `buildconfig.id`\n* `buildconfig.keyword`\n* `comment`\n* `comment.mark`\n* `comment.url`\n* `doccomment`\n* `doccomment.field`\n* `identifier`\n* `keyword`\n* `number`\n* `objectliteral`\n* `parameter`\n* `placeholder`\n* `string`\n* `string_interpolation_anchor`\n* `typeidentifier`\n\nAll syntax kinds used in a snippet of Swift code can be extracted asking\n[SourceKitten](https://github.com/jpsim/SourceKitten). For example,\n`sourcekitten syntax --text \"struct S {}\"` delivers\n\n* `source.lang.swift.syntaxtype.keyword` for the `struct` keyword and\n* `source.lang.swift.syntaxtype.identifier` for its name `S`\n\nwhich match to `keyword` and `identifier` in the above list.\n\nIf using custom rules in combination with `only_rules`, you must include the\nliteral string `custom_rules` in the `only_rules` list:\n\n```yaml\nonly_rules:\n  - custom_rules\n\ncustom_rules:\n  no_hiding_in_strings:\n    regex: \"([nN]inja)\"\n    match_kinds: string\n```\n\nUnlike Swift custom rules, you can use official SwiftLint builds\n(e.g. from Homebrew) to run regex custom rules.\n\n### Auto-correct\n\nSwiftLint can automatically correct certain violations. Files on disk are\noverwritten with a corrected version.\n\nPlease make sure to have backups of these files before running\n`swiftlint --fix`, otherwise important data may be lost.\n\nStandard linting is disabled while correcting because of the high likelihood of\nviolations (or their offsets) being incorrect after modifying a file while\napplying corrections.\n\n### Analyze\n\nThe `swiftlint analyze` command can lint Swift files using the\nfull type-checked AST. The compiler log path containing the clean `swiftc` build\ncommand invocation (incremental builds will fail) must be passed to `analyze`\nvia the `--compiler-log-path` flag.\ne.g. `--compiler-log-path /path/to/xcodebuild.log`\n\nThis can be obtained by\n\n1. Cleaning DerivedData (incremental builds won't work with analyze)\n2. Running `xcodebuild -workspace {WORKSPACE}.xcworkspace -scheme {SCHEME} > xcodebuild.log`\n3. Running `swiftlint analyze --compiler-log-path xcodebuild.log`\n\nAnalyzer rules tend to be considerably slower than lint rules.\n\n## Using Multiple Configuration Files\n\nSwiftLint offers a variety of ways to include multiple configuration files.\nMultiple configuration files get merged into one single configuration that is\nthen applied just as a single configuration file would get applied.\n\nThere are quite a lot of use cases where using multiple configuration files\ncould be helpful:\n\nFor instance, one could use a team-wide shared SwiftLint configuration while\nallowing overrides in each project via a child configuration file.\n\nTeam-Wide Configuration:\n\n```yaml\ndisabled_rules:\n- force_cast\n```\n\nProject-Specific Configuration:\n\n```yaml\nopt_in_rules:\n- force_cast\n```\n\n### Child/Parent Configs (Locally)\n\nYou can specify a `child_config` and/or a `parent_config` reference within a\nconfiguration file. These references should be local paths relative to the\nfolder of the configuration file they are specified in. This even works\nrecursively, as long as there are no cycles and no ambiguities.\n\n**A child config is treated as a refinement and thus has a higher priority**,\nwhile a parent config is considered a base with lower priority in case of\nconflicts.\n\nHere's an example, assuming you have the following file structure:\n\n```txt\nProjectRoot\n    |_ .swiftlint.yml\n    |_ .swiftlint_refinement.yml\n    |_ Base\n        |_ .swiftlint_base.yml\n```\n\nTo include both the refinement and the base file, your `.swiftlint.yml` should\nlook like this:\n\n```yaml\nchild_config: .swiftlint_refinement.yml\nparent_config: Base/.swiftlint_base.yml\n```\n\nWhen merging parent and child configs, `included` and `excluded` configurations\nare processed carefully to account for differences in the directory location\nof the containing configuration files.\n\n### Child/Parent Configs (Remote)\n\nJust as you can provide local `child_config`/`parent_config` references,\ninstead of referencing local paths, you can just put urls that lead to\nconfiguration files. In order for SwiftLint to detect these remote references,\nthey must start with `http://` or `https://`.\n\nThe referenced remote configuration files may even recursively reference other\nremote configuration files, but aren't allowed to include local references.\n\nUsing a remote reference, your `.swiftlint.yml` could look like this:\n\n```yaml\nparent_config: https://myteamserver.com/our-base-swiftlint-config.yml\n```\n\nEvery time you run SwiftLint and have an Internet connection, SwiftLint tries\nto get a new version of every remote configuration that is referenced. If this\nrequest times out, a cached version is used if available. If there is no cached\nversion available, SwiftLint fails â€“ but no worries, a cached version should be\nthere once SwiftLint has run successfully at least once.\n\nIf needed, the timeouts for the remote configuration fetching can be specified\nmanually via the configuration file(s) using the\n`remote_timeout`/`remote_timeout_if_cached` specifiers. These values default\nto 2 seconds or 1 second, respectively.\n\n### Command Line\n\nInstead of just providing one configuration file when running SwiftLint via the\ncommand line, you can also pass a hierarchy, where the first configuration is\ntreated as a parent, while the last one is treated as the highest-priority\nchild.\n\nA simple example including just two configuration files looks like this:\n\n`swiftlint --config .swiftlint.yml --config .swiftlint_child.yml`\n\n### Nested Configurations\n\nIn addition to a main configuration (the `.swiftlint.yml` file in the root\nfolder), you can put other configuration files named `.swiftlint.yml` into the\ndirectory structure that then get merged as a child config, but only with an\neffect for those files that are within the same directory as the config or in a\ndeeper directory where there isn't another configuration file. In other words:\nNested configurations don't work recursively â€“ there's a maximum number of one\nnested configuration per file that may be applied in addition to the main\nconfiguration.\n\n`.swiftlint.yml` files are only considered as a nested configuration if they\nhave not been used to build the main configuration already (e. g. by having\nbeen referenced via something like `child_config: Folder/.swiftlint.yml`).\nAlso, `parent_config`/`child_config` specifications of nested configurations\nare getting ignored because there's no sense to that.\n\nIf one (or more) SwiftLint file(s) are explicitly specified via the `--config`\nparameter, that configuration will be treated as an override, no matter whether\nthere exist other `.swiftlint.yml` files somewhere within the directory.\n**So if you want to use nested configurations, you can't use the `--config`\nparameter.**\n\n## License\n\n[MIT licensed.](https://github.com/realm/SwiftLint/blob/main/LICENSE)\n\n## About\n\nSwiftLint is utterly maintained by volunteers contributing to its success\nentirely in their free time. As such, SwiftLint isn't a commercial product\nin any way.\n\nBe kind to the people maintaining SwiftLint as a hobby and accept that their\ntime is limited. Support them by contributing to the project, reporting issues,\nand helping others in the community.\n\nSpecial thanks go to [MacStadium](https://www.macstadium.com) for providing\nphysical Mac mini machines to run our performance tests.\n\n![MacStadium](https://raw.githubusercontent.com/realm/SwiftLint/main/assets/macstadium.png)\n\nWe also thank Realm (now MongoDB) for their initial contributions and setup of\nthe project.\n",
      "stars_today": 3
    },
    {
      "id": 38581626,
      "name": "pybind11",
      "full_name": "pybind/pybind11",
      "description": "Seamless operability between C++11 and Python",
      "html_url": "https://github.com/pybind/pybind11",
      "stars": 17633,
      "forks": 2260,
      "language": "C++",
      "topics": [
        "bindings",
        "python"
      ],
      "created_at": "2015-07-05T19:46:48Z",
      "updated_at": "2026-01-15T17:38:56Z",
      "pushed_at": "2026-01-15T17:38:46Z",
      "open_issues": 717,
      "owner": {
        "login": "pybind",
        "avatar_url": "https://avatars.githubusercontent.com/u/17565521?v=4"
      },
      "readme": ".. figure:: https://github.com/pybind/pybind11/raw/master/docs/pybind11-logo.png\n   :alt: pybind11 logo\n\n**pybind11 (v3)  â€” Seamless interoperability between C++ and Python**\n\n|Latest Documentation Status| |Stable Documentation Status| |Gitter chat| |GitHub Discussions|\n\n|CI| |Build status| |SPEC 4 â€” Using and Creating Nightly Wheels|\n\n|Repology| |PyPI package| |Conda-forge| |Python Versions|\n\n`Setuptools example <https://github.com/pybind/python_example>`_\nâ€¢ `Scikit-build example <https://github.com/pybind/scikit_build_example>`_\nâ€¢ `CMake example <https://github.com/pybind/cmake_example>`_\n\n.. start\n\n\n**pybind11** is a lightweight header-only library that exposes C++ types\nin Python and vice versa, mainly to create Python bindings of existing\nC++ code. Its goals and syntax are similar to the excellent\n`Boost.Python <http://www.boost.org/doc/libs/1_58_0/libs/python/doc/>`_\nlibrary by David Abrahams: to minimize boilerplate code in traditional\nextension modules by inferring type information using compile-time\nintrospection.\n\nThe main issue with Boost.Pythonâ€”and the reason for creating such a\nsimilar projectâ€”is Boost. Boost is an enormously large and complex suite\nof utility libraries that works with almost every C++ compiler in\nexistence. This compatibility has its cost: arcane template tricks and\nworkarounds are necessary to support the oldest and buggiest of compiler\nspecimens. Now that C++11-compatible compilers are widely available,\nthis heavy machinery has become an excessively large and unnecessary\ndependency.\n\nThink of this library as a tiny self-contained version of Boost.Python\nwith everything stripped away that isn't relevant for binding\ngeneration. Without comments, the core header files only require ~4K\nlines of code and depend on Python (CPython 3.8+, PyPy, or GraalPy) and the C++\nstandard library. This compact implementation was possible thanks to some C++11\nlanguage features (specifically: tuples, lambda functions and variadic\ntemplates). Since its creation, this library has grown beyond Boost.Python in\nmany ways, leading to dramatically simpler binding code in many common\nsituations.\n\nTutorial and reference documentation is provided at\n`pybind11.readthedocs.io <https://pybind11.readthedocs.io/en/latest>`_.\nA PDF version of the manual is available\n`here <https://pybind11.readthedocs.io/_/downloads/en/latest/pdf/>`_.\nAnd the source code is always available at\n`github.com/pybind/pybind11 <https://github.com/pybind/pybind11>`_.\n\n\nCore features\n-------------\n\n\npybind11 can map the following core C++ features to Python:\n\n- Functions accepting and returning custom data structures per value,\n  reference, or pointer\n- Instance methods and static methods\n- Overloaded functions\n- Instance attributes and static attributes\n- Arbitrary exception types\n- Enumerations\n- Callbacks\n- Iterators and ranges\n- Custom operators\n- Single and multiple inheritance\n- STL data structures\n- Smart pointers with reference counting like ``std::shared_ptr``\n- Internal references with correct reference counting\n- C++ classes with virtual (and pure virtual) methods can be extended\n  in Python\n- Integrated NumPy support (NumPy 2 requires pybind11 2.12+)\n\nGoodies\n-------\n\nIn addition to the core functionality, pybind11 provides some extra\ngoodies:\n\n- CPython 3.8+, PyPy3 7.3.17+, and GraalPy 24.1+ are supported with an\n  implementation-agnostic interface (see older versions for older CPython\n  and PyPy versions).\n\n- It is possible to bind C++11 lambda functions with captured\n  variables. The lambda capture data is stored inside the resulting\n  Python function object.\n\n- pybind11 uses C++11 move constructors and move assignment operators\n  whenever possible to efficiently transfer custom data types.\n\n- It's easy to expose the internal storage of custom data types through\n  Pythons' buffer protocols. This is handy e.g.Â for fast conversion\n  between C++ matrix classes like Eigen and NumPy without expensive\n  copy operations.\n\n- pybind11 can automatically vectorize functions so that they are\n  transparently applied to all entries of one or more NumPy array\n  arguments.\n\n- Python's slice-based access and assignment operations can be\n  supported with just a few lines of code.\n\n- Everything is contained in just a few header files; there is no need\n  to link against any additional libraries.\n\n- Binaries are generally smaller by a factor of at least 2 compared to\n  equivalent bindings generated by Boost.Python. A recent pybind11\n  conversion of PyRosetta, an enormous Boost.Python binding project,\n  `reported <https://graylab.jhu.edu/Sergey/2016.RosettaCon/PyRosetta-4.pdf>`_\n  a binary size reduction of **5.4x** and compile time reduction by\n  **5.8x**.\n\n- Function signatures are precomputed at compile time (using\n  ``constexpr``), leading to smaller binaries.\n\n- With little extra effort, C++ types can be pickled and unpickled\n  similar to regular Python objects.\n\nSupported platforms & compilers\n-------------------------------\n\npybind11 is exercised in continuous integration across a range of operating\nsystems, Python versions, C++ standards, and toolchains. For an up-to-date\nview of the combinations we currently test, please see the\n`pybind11 GitHub Actions <https://github.com/pybind/pybind11/actions?query=branch%3Amaster>`_\nlogs.\n\nThe test matrix naturally evolves over time as older platforms and compilers\nfall out of use and new ones are added by the community. Closely related\nversions of a tested compiler or platform will often work as well in practice,\nbut we cannot promise to validate every possible combination. If a\nconfiguration you rely on is missing from the matrix or regresses, issues and\npull requests to extend coverage are very welcome. At the same time, we need\nto balance the size of the test matrix with the available CI resources,\nsuch as GitHub's limits on concurrent jobs under the free tier.\n\nAbout\n-----\n\nThis project was created by `Wenzel\nJakob <http://rgl.epfl.ch/people/wjakob>`_. Significant features and/or\nimprovements to the code were contributed by\nJonas Adler,\nLori A. Burns,\nSylvain Corlay,\nEric Cousineau,\nAaron Gokaslan,\nRalf Grosse-Kunstleve,\nTrent Houliston,\nAxel Huebl,\n@hulucc,\nYannick Jadoul,\nSergey Lyskov,\nJohan Mabille,\nTomasz MiÄ…sko,\nDean Moldovan,\nBen Pritchard,\nJason Rhinelander,\nBoris SchÃ¤ling,\nPim Schellart,\nHenry Schreiner,\nIvan Smirnov,\nDustin Spicuzza,\nBoris Staletic,\nEthan Steinberg,\nPatrick Stewart,\nIvor Wanders,\nand\nXiaofei Wang.\n\nWe thank Google for a generous financial contribution to the continuous\nintegration infrastructure used by this project.\n\n\nContributing\n~~~~~~~~~~~~\n\nSee the `contributing\nguide <https://github.com/pybind/pybind11/blob/master/.github/CONTRIBUTING.md>`_\nfor information on building and contributing to pybind11.\n\nLicense\n~~~~~~~\n\npybind11 is provided under a BSD-style license that can be found in the\n`LICENSE <https://github.com/pybind/pybind11/blob/master/LICENSE>`_\nfile. By using, distributing, or contributing to this project, you agree\nto the terms and conditions of this license.\n\n.. |Latest Documentation Status| image:: https://readthedocs.org/projects/pybind11/badge?version=latest\n   :target: http://pybind11.readthedocs.org/en/latest\n.. |Stable Documentation Status| image:: https://img.shields.io/badge/docs-stable-blue.svg\n   :target: http://pybind11.readthedocs.org/en/stable\n.. |Gitter chat| image:: https://img.shields.io/gitter/room/gitterHQ/gitter.svg\n   :target: https://gitter.im/pybind/Lobby\n.. |CI| image:: https://github.com/pybind/pybind11/workflows/CI/badge.svg\n   :target: https://github.com/pybind/pybind11/actions\n.. |Build status| image:: https://ci.appveyor.com/api/projects/status/riaj54pn4h08xy40?svg=true\n   :target: https://ci.appveyor.com/project/wjakob/pybind11\n.. |PyPI package| image:: https://img.shields.io/pypi/v/pybind11.svg\n   :target: https://pypi.org/project/pybind11/\n.. |Conda-forge| image:: https://img.shields.io/conda/vn/conda-forge/pybind11.svg\n   :target: https://github.com/conda-forge/pybind11-feedstock\n.. |Repology| image:: https://repology.org/badge/latest-versions/python:pybind11.svg\n   :target: https://repology.org/project/python:pybind11/versions\n.. |Python Versions| image:: https://img.shields.io/pypi/pyversions/pybind11.svg\n   :target: https://pypi.org/project/pybind11/\n.. |GitHub Discussions| image:: https://img.shields.io/static/v1?label=Discussions&message=Ask&color=blue&logo=github\n   :target: https://github.com/pybind/pybind11/discussions\n.. |SPEC 4 â€” Using and Creating Nightly Wheels| image:: https://img.shields.io/badge/SPEC-4-green?labelColor=%23004811&color=%235CA038\n   :target: https://scientific-python.org/specs/spec-0004/\n",
      "stars_today": 3
    },
    {
      "id": 476642602,
      "name": "rspack",
      "full_name": "web-infra-dev/rspack",
      "description": "The fast Rust-based JavaScript bundler with webpack-compatible API ğŸ¦€ï¸",
      "html_url": "https://github.com/web-infra-dev/rspack",
      "stars": 12386,
      "forks": 754,
      "language": "Rust",
      "topics": [
        "build-tool",
        "bundler",
        "compiler",
        "esm",
        "javascript",
        "jsx",
        "loaders",
        "module-bundler",
        "rspack",
        "rstack",
        "rust",
        "typescript",
        "web",
        "web-performance",
        "webpack"
      ],
      "created_at": "2022-04-01T08:45:30Z",
      "updated_at": "2026-01-15T14:51:52Z",
      "pushed_at": "2026-01-15T16:11:30Z",
      "open_issues": 227,
      "owner": {
        "login": "web-infra-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/87694465?v=4"
      },
      "readme": "<picture>\n  <img alt=\"Rspack Banner\" src=\"https://assets.rspack.rs/rspack/rspack-banner.png\">\n</picture>\n\n# Rspack\n\n<p>\n  <a href=\"https://discord.gg/79ZZ66GH9E\"><img src=\"https://img.shields.io/badge/chat-discord-blue?style=flat-square&logo=discord&colorA=564341&colorB=EDED91\" alt=\"discord channel\" /></a>\n  <a href=\"https://www.npmjs.com/package/@rspack/core?activeTab=readme\"><img src=\"https://img.shields.io/npm/v/@rspack/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>\n  <a href=\"https://crates.io/crates/rspack_core\"><img src=\"https://img.shields.io/crates/v/rspack_core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"crates version\" /></a>\n  <a href=\"https://npmcharts.com/compare/@rspack/core?minimal=true\"><img src=\"https://img.shields.io/npm/dm/@rspack/core.svg?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"downloads\" /></a>\n  <a href=\"https://nodejs.org/en/about/previous-releases\"><img src=\"https://img.shields.io/node/v/@rspack/core.svg?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"node version\"></a>\n  <a href=\"https://github.com/web-infra-dev/rspack/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"license\" /></a>\n  <a href=\"https://codspeed.io/web-infra-dev/rspack\"><img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fcodspeed.io%2Fbadge.json&style=flat-square&colorA=564341&colorB=EDED91\" alt=\"codspeed\" /></a>\n</p>\n\nEnglish | [ç®€ä½“ä¸­æ–‡](./README.zh-CN.md)\n\nRspack is a high performance JavaScript bundler written in Rust. It offers strong compatibility with the webpack ecosystem, allowing for seamless replacement of webpack, and provides lightning fast build speeds.\n\n## âœ¨ Features\n\n- ğŸš€ **Fast Startup**: Based on Rust, the build speed is extremely fast, bringing you the ultimate development experience.\n- âš¡ **Lightning HMR**: With a built-in incremental compilation mechanism, HMR is extremely fast and fully capable of developing large-scale projects.\n- ğŸ“¦ **Webpack Compatible**: Compatible with plugins and loaders in the webpack ecosystem, seamlessly integrating excellent libraries built by the community.\n- ğŸ¨ **Module Federation**: Provide first-class support for Module Federation to facilitate the development of large-scale web applications.\n- ğŸ› ï¸ **Production Optimization**: Various optimization strategies are built in by default, such as tree shaking, minification, etc.\n- ğŸ¯ **Framework Agnostic**: Not bound to any frontend framework, ensuring enough flexibility.\n\nRead [Introduction](https://rspack.rs/guide/start/introduction) for details.\n\n## ğŸ¦€ Rstack\n\nRstack is a unified JavaScript toolchain centered on Rspack, with high performance and consistent architecture.\n\n| Name                                                  | Description              | Version                                                                                                                                                                          |\n| ----------------------------------------------------- | ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [Rspack](https://github.com/web-infra-dev/rspack)     | Bundler                  | <a href=\"https://npmjs.com/package/@rspack/core\"><img src=\"https://img.shields.io/npm/v/@rspack/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>     |\n| [Rsbuild](https://github.com/web-infra-dev/rsbuild)   | Build tool               | <a href=\"https://npmjs.com/package/@rsbuild/core\"><img src=\"https://img.shields.io/npm/v/@rsbuild/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>   |\n| [Rslib](https://github.com/web-infra-dev/rslib)       | Library development tool | <a href=\"https://npmjs.com/package/@rslib/core\"><img src=\"https://img.shields.io/npm/v/@rslib/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>       |\n| [Rspress](https://github.com/web-infra-dev/rspress)   | Static site generator    | <a href=\"https://npmjs.com/package/@rspress/core\"><img src=\"https://img.shields.io/npm/v/@rspress/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>   |\n| [Rsdoctor](https://github.com/web-infra-dev/rsdoctor) | Build analyzer           | <a href=\"https://npmjs.com/package/@rsdoctor/core\"><img src=\"https://img.shields.io/npm/v/@rsdoctor/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a> |\n| [Rstest](https://github.com/web-infra-dev/rstest)     | Testing framework        | <a href=\"https://npmjs.com/package/@rstest/core\"><img src=\"https://img.shields.io/npm/v/@rstest/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>     |\n| [Rslint](https://github.com/web-infra-dev/rslint)     | Linter                   | <a href=\"https://npmjs.com/package/@rslint/core\"><img src=\"https://img.shields.io/npm/v/@rslint/core?style=flat-square&colorA=564341&colorB=EDED91\" alt=\"npm version\" /></a>     |\n\n## Getting started\n\n<p>\n  <a target=\"_blank\" href=\"https://stackblitz.com/fork/github/rstackjs/rspack-stackblitz-example\">\n    <img\n      alt=\"Open in StackBlitz\"\n      src=\"https://developer.stackblitz.com/img/open_in_stackblitz.svg\"\n    />\n  </a>\n</p>\n\nSee [Quick start](https://rspack.rs/guide/start/quick-start).\n\n## Contribution\n\nPlease read the [contributing guide](./CONTRIBUTING.md) and let's build Rspack together.\n\n### Code of conduct\n\nThis repo has adopted the ByteDance Open Source Code of Conduct. Please check [Code of conduct](./CODE_OF_CONDUCT.md) for more details.\n\n## Community\n\nCome chat with us on [Discord](https://discord.gg/79ZZ66GH9E)! Rspack team and Rspack users are active there, and we're always looking for contributions.\n\n## Links\n\n| Name                                                                           | Description                                                                   |\n| ------------------------------------------------------------------------------ | ----------------------------------------------------------------------------- |\n| [awesome-rstack](https://github.com/rstackjs/awesome-rstack)                   | A curated list of awesome things related to Rstack                            |\n| [Rspack 1.x documentation](https://rspack.rs/)                                 | Documentation for Rspack 1.x (latest)                                         |\n| [Rspack 0.x documentation](https://v0.rspack.rs/)                              | Documentation for Rspack 0.x version                                          |\n| [rspack-dev-server](https://github.com/web-infra-dev/rspack-dev-server)        | Dev server for Rspack                                                         |\n| [rstack-examples](https://github.com/rstackjs/rstack-examples)                 | Examples showcasing Rstack                                                    |\n| [rspack-sources](https://github.com/rstackjs/rspack-sources)                   | Rust port of [webpack-sources](https://www.npmjs.com/package/webpack-sources) |\n| [rstack-design-resources](https://github.com/rstackjs/rstack-design-resources) | Design resources for Rstack                                                   |\n\n## Contributors\n\n<a href=\"https://github.com/web-infra-dev/rspack/graphs/contributors\"><img src=\"https://opencollective.com/rspack/contributors.svg?width=890&button=false\" /></a>\n\n## Benchmark\n\nSee [Benchmark](https://ecosystem-benchmark.rspack.rs/).\n\n## Credits\n\nThanks to:\n\n- [The webpack team and community](https://webpack.js.org/) for creating a great bundler and ecosystem from which we draw a lot of inspiration.\n- [@sokra](https://github.com/sokra) for the great work on the [webpack](https://github.com/webpack/webpack) project.\n- [@ScriptedAlchemy](https://github.com/ScriptedAlchemy) for creating Module Federation and helping Rspack connect with the community.\n- The [SWC](https://github.com/swc-project/swc) project created by [@kdy1](https://github.com/kdy1), which powers Rspack's code parsing, transformation and minification.\n- The [esbuild](https://github.com/evanw/esbuild) project created by [@evanw](https://github.com/evanw), which inspired the concurrent architecture of Rspack.\n- The [NAPI-RS](https://github.com/napi-rs/napi-rs) project created by [@Brooooooklyn](https://github.com/Brooooooklyn), which powers Rspack's node-binding implementation.\n- The [Parcel](https://github.com/parcel-bundler/parcel) project created by [@devongovett](https://github.com/devongovett) which is the pioneer of rust bundler and inspired Rspack's incremental rebuild design.\n- The [Vite](https://github.com/vitejs/vite) project created by [Evan You](https://github.com/yyx990803) which inspired Rspack's compatibility design of webpack's ecosystem.\n- The `rolldown-legacy` project created by old Rolldown team, It's the predecessor of the [rolldown](https://github.com/rolldown) project, which explores the possibility of making a performant bundler in Rust with Rollup-compatible API. It inspires the design principles of Rspack.\n- The [html-webpack-plugin](https://github.com/jantimon/html-webpack-plugin) project created by [@jantimon](https://github.com/jantimon), `@rspack/html-plugin` is a fork of [html-webpack-plugin](https://github.com/jantimon/html-webpack-plugin) to avoid some webpack API usage not supported in Rspack.\n- The [Turbopack](https://github.com/vercel/turbo) project which inspired the AST path logic of Rspack.\n- The [react-refresh-webpack-plugin](https://github.com/pmmmwh/react-refresh-webpack-plugin) created by [@pmmmwh](https://github.com/pmmmwh), which inspires implement [react refresh rspack plugin](https://github.com/rstackjs/rspack-plugin-react-refresh).\n- The [prefresh](https://github.com/preactjs/prefresh) created by [@Jovi De Croock](https://github.com/JoviDeCroock), which inspires implement [preact refresh rspack plugin](https://github.com/rstackjs/rspack-plugin-preact-refresh).\n- The [mini-css-extract-plugin](https://github.com/webpack/mini-css-extract-plugin) project created by [@sokra](https://github.com/sokra) which inspired implement css extract plugin.\n- The [copy-webpack-plugin](https://github.com/webpack/copy-webpack-plugin) project created by [@kevlened](https://github.com/kevlened) which inspired implement copy rspack plugin.\n- The [webpack-subresource-integrity](https://github.com/waysact/webpack-subresource-integrity) project created by [@jscheid](https://github.com/jscheid), which inspires implement subresource integrity rspack plugin.\n- The [circular-dependency-plugin](https://github.com/aackerman/circular-dependency-plugin) project created by [@aackerman](https://github.com/aackerman), which inspres implement circular dependency rspack plugin.\n- The [tracing-chrome](https://github.com/thoren-d/tracing-chrome) project created by [thoren-d](https://github.com/thoren-d), which inspires the implementation of Rspack tracing.\n\n## License\n\nRspack is [MIT licensed](https://github.com/web-infra-dev/rspack/blob/main/LICENSE).\n",
      "stars_today": 3
    },
    {
      "id": 47648456,
      "name": "espeak-ng",
      "full_name": "espeak-ng/espeak-ng",
      "description": "eSpeak NG is an open source speech synthesizer that supports more than hundred languages and accents.",
      "html_url": "https://github.com/espeak-ng/espeak-ng",
      "stars": 6025,
      "forks": 1171,
      "language": "C",
      "topics": [
        "android",
        "espeak",
        "espeak-ng",
        "speech-synthesis",
        "text-to-speech"
      ],
      "created_at": "2015-12-08T20:42:42Z",
      "updated_at": "2026-01-16T00:13:47Z",
      "pushed_at": "2025-12-15T12:36:48Z",
      "open_issues": 594,
      "owner": {
        "login": "espeak-ng",
        "avatar_url": "https://avatars.githubusercontent.com/u/16214005?v=4"
      },
      "readme": "# eSpeak NG Text-to-Speech\n\n- [Features](#features)\n- [Supported languages](docs/languages.md)\n- [Documentation](#documentation)\n- [eSpeak Compatibility](#espeak-compatibility)\n- [History](#history)\n- [License Information](#license-information)\n----------\n\nThe eSpeak NG is a compact open source software text-to-speech synthesizer for \nLinux, Windows, Android and other operating systems. It supports \n[more than 100 languages and accents](docs/languages.md). It is based on the eSpeak engine\ncreated by Jonathan Duddington.\n\neSpeak NG uses a \"formant synthesis\" method. This allows many languages to be\nprovided in a small size. The speech is clear, and can be used at high speeds,\nbut is not as natural or smooth as larger synthesizers which are based on human\nspeech recordings. It also supports Klatt formant synthesis, and the ability\nto use MBROLA as backend speech synthesizer.\n\neSpeak NG is available as:\n\n*  A [command line](src/espeak-ng.1.ronn) program (Linux and Windows) to speak text from a file or\n   from stdin.\n*  A [shared library](docs/integration.md) version for use by other programs. (On Windows this is\n   a DLL).\n*  A SAPI5 version for Windows, so it can be used with screen-readers and\n   other programs that support the Windows SAPI5 interface.\n*  eSpeak NG has been ported to other platforms, including Solaris and Mac\n   OSX.\n\n## Features\n\n*  Includes different Voices, whose characteristics can be altered.\n*  Can produce speech output as a WAV file.\n*  SSML (Speech Synthesis Markup Language) is supported (not complete),\n   and also HTML.\n*  Compact size.  The program and its data, including many languages,\n   totals about few Mbytes.\n*  Can be used as a front-end to [MBROLA diphone voices](docs/mbrola.md).\n   eSpeak NG converts text to phonemes with pitch and length information.\n*  Can translate text into phoneme codes, so it could be adapted as a\n   front end for another speech synthesis engine.\n*  Potential for other languages. Several are included in varying stages\n   of progress. Help from native speakers for these or other languages is\n   welcome.\n*  Written in C.\n\nSee the [ChangeLog](ChangeLog.md) for a description of the changes in the\nvarious releases and with the eSpeak NG project.\n\nThe following platforms are supported:\n\n| Platform    | Minimum Version | Status |\n|-------------|-----------------|--------|\n| Linux       |                 | ![CI](https://github.com/espeak-ng/espeak-ng/actions/workflows/ci.yml/badge.svg) |\n| BSD         |                 |        |\n| Android     | 4.0             |        |\n| Windows     | Windows 8       |        |\n| Mac         |                 |        |\n\n## Documentation\n\n1. [User guide](docs/guide.md) explains how to set up and use eSpeak NG from command line or as a library.\n2. [Building guide](docs/building.md) provides info how to compile and build eSpeak NG from the source.\n4. [Index](docs/index.md) provides full list of more detailed information for contributors and developers.\n5. Look at [contribution guide](docs/contributing.md) to start your contribution.\n6. Look at [eSpeak NG roadmap](https://github.com/espeak-ng/espeak-ng/wiki/eSpeak-NG-roadmap) to participate in development of eSpeak NG.\n\n## eSpeak Compatibility\n\nThe *espeak-ng* binaries use the same command-line options as *espeak*, with\nseveral additions to provide new functionality from *espeak-ng* such as specifying\nthe output audio device name to use. The build creates symlinks of `espeak` to\n`espeak-ng`, and `speak` to `speak-ng`.\n\nThe espeak `speak_lib.h` include file is located in `espeak-ng/speak_lib.h` with\nan optional symlink in `espeak/speak_lib.h`. This file contains the espeak 1.48.15\nAPI, with a change to the `ESPEAK_API` macro to fix building on Windows\nand some minor changes to the documentation comments. This C API is API and ABI\ncompatible with espeak.\n\nThe `espeak-data` data has been moved to `espeak-ng-data` to avoid conflicts with\nespeak. There have been various changes to the voice, dictionary and phoneme files\nthat make them incompatible with espeak.\n\nThe *espeak-ng* project does not include the *espeakedit* program. It has moved\nthe logic to build the dictionary, phoneme and intonation binary files into the\n`libespeak-ng.so` file that is accessible from the `espeak-ng` command line and\nC API.\n\n## History\n\nThe program was originally known as __speak__ and originally written\nfor Acorn/RISC\\_OS computers starting in 1995 by Jonathan Duddington. This was\nenhanced and re-written in 2007 as __eSpeak__, including a relaxation of the\noriginal memory and processing power constraints, and with support for additional\nlanguages.\n\nIn 2010, Reece H. Dunn started maintaining a version of eSpeak on GitHub that\nwas designed to make it easier to build eSpeak on POSIX systems, porting the\nbuild system to autotools in 2012. In late 2015, this project was officially\nforked to a new __eSpeak NG__ project. The new eSpeak NG project is a significant\ndeparture from the eSpeak project, with the intention of cleaning up the\nexisting codebase, adding new features, and adding to and improving the\nsupported languages.\n\nThe *historical* branch contains the available older releases of the original\neSpeak that are not contained in the subversion repository.\n\n1.24.02 is the first version of eSpeak to appear in the subversion\nrepository, but releases from 1.05 to 1.24 are available at\n[http://sourceforge.net/projects/espeak/files/espeak/](http://sourceforge.net/projects/espeak/files/espeak/).\n\nThese early releases have been checked into the historical branch,\nwith the 1.24.02 release as the last entry. This makes it possible\nto use the replace functionality of git to see the earlier history:\n\n\tgit replace 8d59235f 63c1c019\n\n__NOTE:__ The source releases contain the `big_endian`, `espeak-edit`,\n`praat-mod`, `riskos`, `windows_dll` and `windows_sapi` folders. These\ndo not appear in the source repository until later releases, so have\nbeen excluded from the historical commits to align them better with\nthe 1.24.02 source commit.\n\n## License Information\n\neSpeak NG Text-to-Speech is released under the [GPL version 3](COPYING) or\nlater license.\n\nThe `getopt.c` compatibility implementation for getopt support on Windows is\ntaken from the NetBSD `getopt_long` implementation, which is licensed under a\n[2-clause BSD](COPYING.BSD2) license.\n\nAndroid is a trademark of Google LLC.\n\n## Acknowledgements\n\nThe catalan extension was funded by [Departament de la VicepresidÃ¨ncia i de PolÃ­tiques Digitals i Territori de la Generalitat de Catalunya](https://politiquesdigitals.gencat.cat/ca/inici/index.html#googtrans(ca|en) \nwithin the framework of \n[Projecte AINA](https://politiquesdigitals.gencat.cat/ca/economia/catalonia-ai/aina).\n",
      "stars_today": 3
    },
    {
      "id": 447060287,
      "name": "paimon",
      "full_name": "apache/paimon",
      "description": "Apache Paimon is a lake format that enables building a Realtime Lakehouse Architecture with Flink and Spark for both streaming and batch operations.",
      "html_url": "https://github.com/apache/paimon",
      "stars": 3159,
      "forks": 1253,
      "language": "Java",
      "topics": [
        "big-data",
        "data-ingestion",
        "flink",
        "paimon",
        "real-time-analytics",
        "spark",
        "streaming-datalake",
        "table-store"
      ],
      "created_at": "2022-01-12T03:13:15Z",
      "updated_at": "2026-01-15T15:56:25Z",
      "pushed_at": "2026-01-15T13:10:59Z",
      "open_issues": 686,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "![Paimon](https://github.com/apache/paimon/blob/master/docs/static/paimon-simple.png)\n\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![Get on Slack](https://img.shields.io/badge/slack-join-orange.svg)](https://the-asf.slack.com/archives/C053Q2NCW8G)\n\nApache Paimon is a lake format that enables building a Realtime Lakehouse Architecture with Flink and Spark \nfor both streaming and batch operations. Paimon innovatively combines lake format and LSM structure, bringing realtime \nstreaming updates into the lake architecture.\n\nBackground and documentation are available at https://paimon.apache.org\n\n`Paimon`'s former name was `Flink Table Store`, developed from the Flink community. The architecture refers to some \ndesign concepts of Iceberg. Thanks to Apache Flink and Apache Iceberg.\n\n## Collaboration\n\nPaimon tracks issues in GitHub and prefers to receive contributions as pull requests.\n\n## Mailing Lists\n\n<table class=\"table table-striped\">\n  <thead>\n    <th class=\"text-center\">Name</th>\n    <th class=\"text-center\">Subscribe</th>\n    <th class=\"text-center\">Digest</th>\n    <th class=\"text-center\">Unsubscribe</th>\n    <th class=\"text-center\">Post</th>\n    <th class=\"text-center\">Archive</th>\n  </thead>\n  <tr>\n    <td>\n      <strong>user</strong>@paimon.apache.org<br>\n      <small>User support and questions mailing list</small>\n    </td>\n    <td class=\"text-center\"><i class=\"fa fa-pencil-square-o\"></i> <a href=\"mailto:user-subscribe@paimon.apache.org\">Subscribe</a></td>\n    <td class=\"text-center\"><i class=\"fa fa-pencil-square-o\"></i> <a href=\"mailto:user-digest-subscribe@paimon.apache.org\">Subscribe</a></td>\n    <td class=\"text-center\"><i class=\"fa fa-pencil-square-o\"></i> <a href=\"mailto:user-unsubscribe@paimon.apache.org\">Unsubscribe</a></td>\n    <td class=\"text-center\"><i class=\"fa fa-pencil-square-o\"></i> <a href=\"mailto:user@paimon.apache.org\">Post</a></td>\n    <td class=\"text-center\">\n      <a href=\"https://lists.apache.org/list.html?user@paimon.apache.org\">Archives</a>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      <strong>dev</strong>@paimon.apache.org<br>\n      <small>Development related discussions</small>\n    </td>\n    <td class=\"text-center\"><i class=\"fa fa-pencil-square-o\"></i> <a href=\"mailto:dev-subscribe@paimon.apache.org\">Subscribe</a></td>\n    <td class=\"text-center\"><i class=\"fa fa-pencil-square-o\"></i> <a href=\"mailto:dev-digest-subscribe@paimon.apache.org\">Subscribe</a></td>\n    <td class=\"text-center\"><i class=\"fa fa-pencil-square-o\"></i> <a href=\"mailto:dev-unsubscribe@paimon.apache.org\">Unsubscribe</a></td>\n    <td class=\"text-center\"><i class=\"fa fa-pencil-square-o\"></i> <a href=\"mailto:dev@paimon.apache.org\">Post</a></td>\n    <td class=\"text-center\">\n      <a href=\"https://lists.apache.org/list.html?dev@paimon.apache.org\">Archives</a>\n    </td>\n  </tr>\n</table>\n\n<b style=\"color:red\">Please make sure you are subscribed to the mailing list you are posting to!</b> If you are not subscribed to the mailing list, your message will either be rejected (dev@ list) or you won't receive the response (user@ list).\n\n## Slack\n\nYou can join the Paimon community on Slack. Paimon channel is in ASF Slack workspace.\n\n- Anyone with an @apache.org email address can become a full member of the ASF Slack workspace.\n  Search [Paimon channel](https://the-asf.slack.com/archives/C053Q2NCW8G) and join it.\n- If you don't have an @apache.org email address, you can email to `user@paimon.apache.org` to apply for an\n  [ASF Slack invitation](https://infra.apache.org/slack.html). Then join [Paimon channel](https://the-asf.slack.com/archives/C053Q2NCW8G).\n\n## Building\n\nJDK 8/11 is required for building the project. Maven version >=3.6.3.\n\n- Run the `mvn clean install -DskipTests` command to build the project.\n- Run the `mvn spotless:apply` to format the project (both Java and Scala).\n- IDE: Mark `paimon-common/target/generated-sources/antlr4` as Sources Root.\n\n## How to Contribute\n\n[Contribution Guide](https://paimon.apache.org/docs/master/project/contributing/).\n\n## License\n\nThe code in this repository is licensed under the [Apache Software License 2](LICENSE).\n",
      "stars_today": 3
    },
    {
      "id": 695166275,
      "name": "unitree_sdk2",
      "full_name": "unitreerobotics/unitree_sdk2",
      "description": "Unitree robot sdk version 2. https://support.unitree.com/home/zh/developer",
      "html_url": "https://github.com/unitreerobotics/unitree_sdk2",
      "stars": 839,
      "forks": 268,
      "language": "C++",
      "topics": [],
      "created_at": "2023-09-22T13:54:21Z",
      "updated_at": "2026-01-16T00:55:22Z",
      "pushed_at": "2026-01-05T02:26:35Z",
      "open_issues": 11,
      "owner": {
        "login": "unitreerobotics",
        "avatar_url": "https://avatars.githubusercontent.com/u/44998897?v=4"
      },
      "readme": "# unitree_sdk2\nUnitree robot sdk version 2.\n\n### Prebuild environment\n* OS  (Ubuntu 20.04 LTS)  \n* CPU  (aarch64 and x86_64)   \n* Compiler  (gcc version 9.4.0) \n\n### Environment Setup\n\nBefore building or running the SDK, ensure the following dependencies are installed:\n\n- CMake (version 3.10 or higher)\n- GCC (version 9.4.0)\n- Make\n\nYou can install the required packages on Ubuntu 20.04 with:\n\n```bash\napt-get update\napt-get install -y cmake g++ build-essential libyaml-cpp-dev libeigen3-dev libboost-all-dev libspdlog-dev libfmt-dev\n```\n\n### Build examples\n\nTo build the examples inside this repository:\n\n```bash\nmkdir build\ncd build\ncmake ..\nmake\n```\n\n### Installation\n\nTo build your own application with the SDK, you can install the unitree_sdk2 to your system directory:\n\n```bash\nmkdir build\ncd build\ncmake ..\nsudo make install\n```\n\nOr install unitree_sdk2 to a specified directory:\n\n```bash\nmkdir build\ncd build\ncmake .. -DCMAKE_INSTALL_PREFIX=/opt/unitree_robotics\nsudo make install\n```\n\nYou can refer to `example/cmake_sample` on how to import the unitree_sdk2 into your CMake project. \n\nNote that if you install the library to other places other than `/opt/unitree_robotics`, you need to make sure the path is added to \"${CMAKE_PREFIX_PATH}\" so that cmake can find it with \"find_package()\".\n\n### Notice\nFor more reference information, please go to [Unitree Document Center](https://support.unitree.com/home/zh/developer).\n",
      "stars_today": 3
    },
    {
      "id": 390032985,
      "name": "composable_kernel",
      "full_name": "ROCm/composable_kernel",
      "description": "Composable Kernel: Performance Portable Programming Model for Machine Learning Tensor Operators",
      "html_url": "https://github.com/ROCm/composable_kernel",
      "stars": 511,
      "forks": 265,
      "language": "C++",
      "topics": [],
      "created_at": "2021-07-27T15:22:44Z",
      "updated_at": "2026-01-15T16:30:31Z",
      "pushed_at": "2026-01-16T00:48:36Z",
      "open_issues": 105,
      "owner": {
        "login": "ROCm",
        "avatar_url": "https://avatars.githubusercontent.com/u/21157610?v=4"
      },
      "readme": "# Composable Kernel\n\n> [!NOTE]\n> The published documentation is available at [Composable Kernel](https://rocm.docs.amd.com/projects/composable_kernel/en/latest/) in an organized, easy-to-read format, with search and a table of contents. The documentation source files reside in the `docs` folder of this repository. As with all ROCm projects, the documentation is open source. For more information on contributing to the documentation, see [Contribute to ROCm documentation](https://rocm.docs.amd.com/en/latest/contribute/contributing.html).\n\nThe Composable Kernel (CK) library provides a programming model for writing performance-critical\nkernels for machine learning workloads across multiple architectures (GPUs, CPUs, etc.). The CK library\nuses general purpose kernel languages, such as HIP C++.\n\nCK uses two concepts to achieve performance portability and code maintainability:\n\n* A tile-based programming model\n* Algorithm complexity reduction for complex machine learning (ML) operators. This uses an innovative\n   technique called *Tensor Coordinate Transformation*.\n\n![ALT](/docs/data/ck_component.png \"CK Components\")\n\nThe current CK library is structured into four layers:\n\n* Templated Tile Operators\n* Templated Kernel and Invoker\n* Instantiated Kernel and Invoker\n* Client API\n\n![ALT](/docs/data/ck_layer.png \"CK Layers\")\n\n## General information\n\n* [CK supported operations](include/ck/README.md)\n* [CK Tile supported operations](include/ck_tile/README.md)\n* [CK wrapper](client_example/25_wrapper/README.md)\n* [CK codegen](codegen/README.md)\n* [CK profiler](profiler/README.md)\n* [Examples (Custom use of CK supported operations)](example/README.md)\n* [Client examples (Use of CK supported operations with instance factory)](client_example/README.md)\n* [Terminology](/TERMINOLOGY.md)\n* [Contributors](/CONTRIBUTORS.md)\n\nCK is released under the **[MIT license](/LICENSE)**.\n\n## Building CK\n\nWe recommend building CK inside Docker containers, which include all necessary packages. Pre-built\nDocker images are available on [DockerHub](https://hub.docker.com/r/rocm/composable_kernel/tags).\n\n1. To build a new Docker image, use the Dockerfile provided with the source code:\n\n    ```bash\n    DOCKER_BUILDKIT=1 docker build -t ck:latest -f Dockerfile .\n    ```\n\n2. Launch the Docker container:\n\n    ```bash\n    docker run                                     \\\n    -it                                            \\\n    --privileged                                   \\\n    --group-add sudo                               \\\n    -w /root/workspace                             \\\n    -v ${PATH_TO_LOCAL_WORKSPACE}:/root/workspace  \\\n    ck:latest                                      \\\n    /bin/bash\n    ```\n\n3. Clone CK source code from the GitHub repository and start the build:\n\n    ```bash\n    git clone https://github.com/ROCm/composable_kernel.git && \\\n    cd composable_kernel && \\\n    mkdir build && \\\n    cd build\n    ```\n\n    You must set the `GPU_TARGETS` macro to specify the GPU target architecture(s) you want\n    to run CK on. You can specify single or multiple architectures. If you specify multiple architectures,\n    use a semicolon between each; for example, `gfx908;gfx90a;gfx942`.\n\n    ```bash\n    cmake                                                                                             \\\n    -D CMAKE_PREFIX_PATH=/opt/rocm                                                                    \\\n    -D CMAKE_CXX_COMPILER=/opt/rocm/bin/hipcc                                                         \\\n    -D CMAKE_BUILD_TYPE=Release                                                                       \\\n    -D GPU_TARGETS=\"gfx908;gfx90a\"                                                                    \\\n    ..\n    ```\n\n    If you don't set `GPU_TARGETS` on the cmake command line, CK is built for all GPU targets\n    supported by the current compiler (this may take a long time). \n    Tests and examples will only get built if the GPU_TARGETS is set by the user on the cmake command line.\n\n    NOTE: If you try setting `GPU_TARGETS` to a list of architectures, the build will only work if the \n    architectures are similar, e.g., `gfx908;gfx90a`, or `gfx1100;gfx1101;gfx11012`. Otherwise, if you \n    want to build the library for a list of different architectures,\n    you should use the `GPU_ARCHS` build argument, for example `GPU_ARCHS=gfx908;gfx1030;gfx1100;gfx942`.\n\n    **Convenience script for development builds:**\n\n    Alternatively, you can use the provided convenience script `script/cmake-ck-dev.sh` which automatically \n    configures CK for development with sensible defaults. In the build directory:\n\n    ```bash\n    ../script/cmake-ck-dev.sh\n    ```\n\n    This script:\n    * Cleans CMake cache files before configuring\n    * Sets `BUILD_DEV=ON` for development mode\n    * Defaults to GPU targets: `gfx908;gfx90a;gfx942`\n    * Enables verbose makefile output\n    * Sets additional compiler flags for better error messages\n\n    By default, it considers the parent directory to be the project source directory.\n\n    You can specify the source directory as the first argument.\n    You can specify custom GPU targets (semicolon-separated) as the second argument:\n\n    ```bash\n    ../script/cmake-ck-dev.sh .. gfx1100\n    ```\n\n    Or pass additional cmake arguments:\n\n    ```bash\n    ../script/cmake-ck-dev.sh .. gfx90a -DCMAKE_BUILD_TYPE=Release\n    ```\n\n5. Build the entire CK library:\n\n    ```bash\n    make -j\"$(nproc)\"\n    ```\n\n6. Install CK:\n\n    ```bash\n    make -j install\n    ```\n    **[See Note on -j](#notes)**\n\n### Building for Windows\n\nInstall TheRock and run CMake configure as\n\n```bash\n    cmake                                                                                      \\\n    -D CMAKE_PREFIX_PATH=\"C:/dist/TheRock\"                                                     \\\n    -D CMAKE_CXX_COMPILER=\"C:/dist/TheRock/bin/hipcc.exe\"                                      \\\n    -D CMAKE_BUILD_TYPE=Release                                                                \\\n    -D GPU_TARGETS=\"gfx1151\"                                                                   \\\n    -G Ninja                                                                                   \\\n    ..\n```\n\nUse Ninja to build either the whole library or individual targets.\n\n## Optional post-install steps\n\n* Build examples and tests:\n\n    ```bash\n    make -j examples tests\n    ```\n\n* Build and run all examples and tests:\n\n    ```bash\n    make -j check\n    ```\n\n    You can find instructions for running each individual example in [example](/example).\n\n* Build and run smoke/regression examples and tests:\n\n    ```bash\n    make -j smoke # tests and examples that run for < 30 seconds each\n    ```\n     ```bash\n    make -j regression # tests and examples that run for >= 30 seconds each\n    ```\n\n* Build ckProfiler:\n\n    ```bash\n    make -j ckProfiler\n    ```\n\n    You can find instructions for running ckProfiler in [profiler](/profiler).\n\n* Build our documentation locally:\n\n    ``` bash\n    cd docs\n    pip3 install -r sphinx/requirements.txt\n    python3 -m sphinx -T -E -b html -d _build/doctrees -D language=en . _build/html\n    ```\n\n### Notes\nThe `-j` option for building with multiple threads in parallel, which speeds up the build significantly.\nHowever, `-j` launches unlimited number of threads, which can cause the build to run out of memory and\ncrash. On average, you should expect each thread to use ~2Gb of RAM.\nDepending on the number of CPU cores and the amount of RAM on your system, you may want to\nlimit the number of threads. For example, if you have a 128-core CPU and 128 Gb of RAM it's advisable to use `-j32`.\n\nAdditional cmake flags can be used to significantly speed-up the build:\n\n* `DTYPES` (default is not set) can be set to any subset of \"fp64;fp32;tf32;fp16;fp8;bf16;int8\" to build\n  instances of select data types only. The main default data types are fp32 and fp16; you can safely skip\n  other data types.\n\n* `DISABLE_DL_KERNELS` (default is OFF) must be set to ON in order not to build instances, such as `gemm_dl` or\n  `batched_gemm_multi_d_dl`. These instances are useful on architectures like the NAVI2x, as most\n  other platforms have faster instances, such as `xdl` or `wmma`, available.\n\n* `DISABLE_DPP_KERNELS` (default is OFF) must be set to ON in order not to build instances, such as `gemm_dpp`. \n  These instances offer a slightly better performance of fp16 gemms on NAVI2x. But on other architectures faster alternatives are available.\n\n* `CK_USE_FP8_ON_UNSUPPORTED_ARCH` (default is OFF) must be set to ON in order to build instances,\n  such as `gemm_universal`, `gemm_universal_streamk` and `gemm_multiply_multiply` for fp8 data type for GPU targets which do not  have native support for fp8 data type, such as gfx908 or gfx90a. These instances are useful on\n  architectures like the MI100/MI200 for the functional support only.\n\n## Using sccache for building\n\nThe default CK Docker images come with a pre-installed version of sccache, which supports clang\nbeing used as hip-compiler (\" -x hip\"). Using sccache can help reduce the time to re-build code from\nhours to 1-2 minutes. In order to invoke sccache, you need to run:\n\n```bash\n sccache --start-server\n```\n\nthen add the following flags to the cmake command line:\n\n```bash\n -DCMAKE_HIP_COMPILER_LAUNCHER=sccache -DCMAKE_CXX_COMPILER_LAUNCHER=sccache -DCMAKE_C_COMPILER_LAUNCHER=sccache\n```\n\nYou may need to clean up the build folder and repeat the cmake and make steps in order to take\nadvantage of the sccache during subsequent builds.\n\n## Using CK as pre-built kernel library\n\nYou can find instructions for using CK as a pre-built kernel library in [client_example](/client_example).\n\n## Contributing to CK\n\nWhen you contribute to CK, make sure you run `clang-format` on all changed files. We highly\nrecommend using git hooks that are managed by the `pre-commit` framework. To install hooks, run:\n\n```bash\nsudo script/install_precommit.sh\n```\n\nWith this approach, `pre-commit` adds the appropriate hooks to your local repository and\nautomatically runs `clang-format` (and possibly additional checks) before any commit is created.\n\nIf you need to uninstall hooks from the repository, you can do so by running the following command:\n\n```bash\nscript/uninstall_precommit.sh\n```\n\nIf you need to temporarily disable pre-commit hooks, you can add the `--no-verify` option to the\n`git commit` command.\n",
      "stars_today": 3
    },
    {
      "id": 22458259,
      "name": "Alamofire",
      "full_name": "Alamofire/Alamofire",
      "description": "Elegant HTTP Networking in Swift",
      "html_url": "https://github.com/Alamofire/Alamofire",
      "stars": 42299,
      "forks": 7669,
      "language": "Swift",
      "topics": [
        "alamofire",
        "carthage",
        "certificate-pinning",
        "cocoapods",
        "httpurlresponse",
        "networking",
        "parameter-encoding",
        "public-key-pinning",
        "request",
        "response",
        "swift",
        "swift-package-manager",
        "urlrequest",
        "urlsession",
        "xcode"
      ],
      "created_at": "2014-07-31T05:56:19Z",
      "updated_at": "2026-01-15T14:02:31Z",
      "pushed_at": "2025-12-20T07:34:46Z",
      "open_issues": 39,
      "owner": {
        "login": "Alamofire",
        "avatar_url": "https://avatars.githubusercontent.com/u/7774181?v=4"
      },
      "readme": "![Alamofire: Elegant Networking in Swift](https://raw.githubusercontent.com/Alamofire/Alamofire/master/Resources/AlamofireLogo.png)\n\n[![Swift](https://img.shields.io/badge/Swift-6.0_6.1_6.2-orange?style=flat-square)](https://img.shields.io/badge/Swift-6.0_6.1_6.2-Orange?style=flat-square)\n[![Platforms](https://img.shields.io/badge/Platforms-macOS_iOS_tvOS_watchOS_visionOS_Linux_Windows_Android-yellowgreen?style=flat-square)](https://img.shields.io/badge/Platforms-macOS_iOS_tvOS_watchOS_vision_OS_Linux_Windows_Android-Green?style=flat-square)\n[![CocoaPods Compatible](https://img.shields.io/cocoapods/v/Alamofire.svg?style=flat-square)](https://img.shields.io/cocoapods/v/Alamofire.svg)\n[![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat-square)](https://github.com/Carthage/Carthage)\n[![Swift Package Manager](https://img.shields.io/badge/Swift_Package_Manager-compatible-orange?style=flat-square)](https://img.shields.io/badge/Swift_Package_Manager-compatible-orange?style=flat-square)\n[![Swift Forums](https://img.shields.io/badge/Swift_Forums-Alamofire-orange?style=flat-square)](https://forums.swift.org/c/related-projects/alamofire/37)\n\nAlamofire is an HTTP networking library written in Swift.\n\n- [Features](#features)\n- [Component Libraries](#component-libraries)\n- [Requirements](#requirements)\n- [Migration Guides](#migration-guides)\n- [Communication](#communication)\n- [Installation](#installation)\n- [Contributing](#contributing)\n- [Usage](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#using-alamofire)\n  - [**Introduction -**](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#introduction) [Making Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#making-requests), [Response Handling](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-handling), [Response Validation](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-validation), [Response Caching](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#response-caching)\n  - **HTTP -** [HTTP Methods](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#http-methods), [Parameters and Parameter Encoder](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md##request-parameters-and-parameter-encoders), [HTTP Headers](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#http-headers), [Authentication](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#authentication)\n  - **Large Data -** [Downloading Data to a File](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#downloading-data-to-a-file), [Uploading Data to a Server](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#uploading-data-to-a-server)\n  - **Tools -** [Statistical Metrics](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#statistical-metrics), [cURL Command Output](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Usage.md#curl-command-output)\n- [Advanced Usage](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md)\n  - **URL Session -** [Session Manager](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#session), [Session Delegate](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#sessiondelegate), [Request](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#request)\n  - **Routing -** [Routing Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#routing-requests), [Adapting and Retrying Requests](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#adapting-and-retrying-requests-with-requestinterceptor)\n  - **Model Objects -** [Custom Response Handlers](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#customizing-response-handlers)\n  - **Advanced Concurrency -** [Swift Concurrency](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#using-alamofire-with-swift-concurrency) and [Combine](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#using-alamofire-with-combine)\n  - **Connection -** [Security](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#security), [Network Reachability](https://github.com/Alamofire/Alamofire/blob/master/Documentation/AdvancedUsage.md#network-reachability)\n- [Open Radars](#open-radars)\n- [FAQ](#faq)\n- [Credits](#credits)\n- [Donations](#donations)\n- [License](#license)\n\n## Features\n\n- [x] Chainable Request / Response Methods\n- [x] Swift Concurrency Support Back to iOS 13, macOS 10.15, tvOS 13, and watchOS 6.\n- [x] Combine Support\n- [x] URL / JSON Parameter Encoding\n- [x] Upload File / Data / Stream / MultipartFormData\n- [x] Download File using Request or Resume Data\n- [x] Authentication with `URLCredential`\n- [x] HTTP Response Validation\n- [x] Upload and Download Progress Closures with Progress\n- [x] cURL Command Output\n- [x] Dynamically Adapt and Retry Requests\n- [x] TLS Certificate and Public Key Pinning\n- [x] Network Reachability\n- [x] Comprehensive Unit and Integration Test Coverage\n- [x] [Complete Documentation](https://alamofire.github.io/Alamofire)\n\n## Write Requests Fast!\n\nAlamofire's compact syntax and extensive feature set allow requests with powerful features like automatic retry to be written in just a few lines of code.\n\n```swift\n// Automatic String to URL conversion, Swift concurrency support, and automatic retry.\nlet response = await AF.request(\"https://httpbin.org/get\", interceptor: .retryPolicy)\n                       // Automatic HTTP Basic Auth.\n                       .authenticate(username: \"user\", password: \"pass\")\n                       // Caching customization.\n                       .cacheResponse(using: .cache)\n                       // Redirect customization.\n                       .redirect(using: .follow)\n                       // Validate response code and Content-Type.\n                       .validate()\n                       // Produce a cURL command for the request.\n                       .cURLDescription { description in\n                         print(description)\n                       }\n                       // Automatic Decodable support with background parsing.\n                       .serializingDecodable(DecodableType.self)\n                       // Await the full response with metrics and a parsed body.\n                       .response\n// Detailed response description for easy debugging.\ndebugPrint(response)\n```\n\n## Component Libraries\n\nIn order to keep Alamofire focused specifically on core networking implementations, additional component libraries have been created by the [Alamofire Software Foundation](https://github.com/Alamofire/Foundation) to bring additional functionality to the Alamofire ecosystem.\n\n- [AlamofireImage](https://github.com/Alamofire/AlamofireImage) - An image library including image response serializers, `UIImage` and `UIImageView` extensions, custom image filters, an auto-purging in-memory cache, and a priority-based image downloading system.\n- [AlamofireNetworkActivityIndicator](https://github.com/Alamofire/AlamofireNetworkActivityIndicator) - Controls the visibility of the network activity indicator on iOS using Alamofire. It contains configurable delay timers to help mitigate flicker and can support `URLSession` instances not managed by Alamofire.\n\n## Requirements\n\n| Platform                                             | Minimum Swift Version | Installation                                                                                                         | Status                   |\n| ---------------------------------------------------- | --------------------- | -------------------------------------------------------------------------------------------------------------------- | ------------------------ |\n| iOS 10.0+ / macOS 10.12+ / tvOS 10.0+ / watchOS 3.0+ | 6.0 / Xcode 16.0      | [CocoaPods](#cocoapods), [Carthage](#carthage), [Swift Package Manager](#swift-package-manager), [Manual](#manually) | Fully Tested             |\n| Linux                                                | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n| Windows                                              | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n| Android                                              | Latest Only           | [Swift Package Manager](#swift-package-manager)                                                                      | Building But Unsupported |\n\n#### Known Issues on Linux and Windows\n\nAlamofire builds on Linux, Windows, and Android but there are missing features and many issues in the underlying `swift-corelibs-foundation` that prevent full functionality and may cause crashes. These include:\n\n- `ServerTrustManager` and associated certificate functionality is unavailable, so there is no certificate pinning and no client certificate support.\n- Various methods of HTTP authentication may crash, including HTTP Basic and HTTP Digest. Crashes may occur if responses contain server challenges.\n- Cache control through `CachedResponseHandler` and associated APIs is unavailable, as the underlying delegate methods aren't called.\n- `URLSessionTaskMetrics` are never gathered.\n- `WebSocketRequest` is not available.\n\nDue to these issues, Alamofire is unsupported on Linux, Windows, and Android. Please report any crashes to the [Swift bug reporter](https://bugs.swift.org).\n\n## Migration Guides\n\n- [Alamofire 5.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%205.0%20Migration%20Guide.md)\n- [Alamofire 4.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%204.0%20Migration%20Guide.md)\n- [Alamofire 3.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%203.0%20Migration%20Guide.md)\n- [Alamofire 2.0 Migration Guide](https://github.com/Alamofire/Alamofire/blob/master/Documentation/Alamofire%202.0%20Migration%20Guide.md)\n\n## Communication\n\n- If you **need help with making network requests** using Alamofire, use [Stack Overflow](https://stackoverflow.com/questions/tagged/alamofire) and tag `alamofire`.\n- If you need to **find or understand an API**, check [our documentation](http://alamofire.github.io/Alamofire/) or [Apple's documentation for `URLSession`](https://developer.apple.com/documentation/foundation/url_loading_system), on top of which Alamofire is built.\n- If you need **help with an Alamofire feature**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you'd like to **discuss Alamofire best practices**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you'd like to **discuss a feature request**, use [our forum on swift.org](https://forums.swift.org/c/related-projects/alamofire).\n- If you **found a bug**, open an issue here on GitHub and follow the guide. The more detail the better!\n\n## Installation\n\n### Swift Package Manager\n\nThe [Swift Package Manager](https://swift.org/package-manager/) is a tool for automating the distribution of Swift code and is integrated into the `swift` compiler.\n\nOnce you have your Swift package set up, adding Alamofire as a dependency is as easy as adding it to the `dependencies` value of your `Package.swift` or the Package list in Xcode.\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/Alamofire/Alamofire.git\", .upToNextMajor(from: \"5.11.0\"))\n]\n```\n\nNormally you'll want to depend on the `Alamofire` target:\n\n```swift\n.product(name: \"Alamofire\", package: \"Alamofire\")\n```\n\nBut if you want to force Alamofire to be dynamically linked (do not do this unless you're sure you need it), you can depend on the `AlamofireDynamic` target:\n\n```swift\n.product(name: \"AlamofireDynamic\", package: \"Alamofire\")\n```\n\n### CocoaPods\n\n[CocoaPods](https://cocoapods.org) is a dependency manager for Cocoa projects. For usage and installation instructions, visit their website. To integrate Alamofire into your Xcode project using CocoaPods, specify it in your `Podfile`:\n\n```ruby\npod 'Alamofire'\n```\n\n### Carthage\n\n[Carthage](https://github.com/Carthage/Carthage) is a decentralized dependency manager that builds your dependencies and provides you with binary frameworks. To integrate Alamofire into your Xcode project using Carthage, specify it in your `Cartfile`:\n\n```ogdl\ngithub \"Alamofire/Alamofire\"\n```\n\n### Manually\n\nIf you prefer not to use any of the aforementioned dependency managers, you can integrate Alamofire into your project manually.\n\n#### Embedded Framework\n\n- Open up Terminal, `cd` into your top-level project directory, and run the following command \"if\" your project is not initialized as a git repository:\n\n  ```bash\n  $ git init\n  ```\n\n- Add Alamofire as a git [submodule](https://git-scm.com/docs/git-submodule) by running the following command:\n\n  ```bash\n  $ git submodule add https://github.com/Alamofire/Alamofire.git\n  ```\n\n- Open the new `Alamofire` folder, and drag the `Alamofire.xcodeproj` into the Project Navigator of your application's Xcode project.\n\n  > It should appear nested underneath your application's blue project icon. Whether it is above or below all the other Xcode groups does not matter.\n\n- Select the `Alamofire.xcodeproj` in the Project Navigator and verify the deployment target matches that of your application target.\n- Next, select your application project in the Project Navigator (blue project icon) to navigate to the target configuration window and select the application target under the \"Targets\" heading in the sidebar.\n- In the tab bar at the top of that window, open the \"General\" panel.\n- Click on the `+` button under the \"Embedded Binaries\" section.\n- You will see two different `Alamofire.xcodeproj` folders each with two different versions of the `Alamofire.framework` nested inside a `Products` folder.\n\n  > It does not matter which `Products` folder you choose from, but it does matter whether you choose the top or bottom `Alamofire.framework`.\n\n- Select the top `Alamofire.framework` for iOS and the bottom one for macOS.\n\n  > You can verify which one you selected by inspecting the build log for your project. The build target for `Alamofire` will be listed as `Alamofire iOS`, `Alamofire macOS`, `Alamofire tvOS`, or `Alamofire watchOS`.\n\n- And that's it!\n\n  > The `Alamofire.framework` is automagically added as a target dependency, linked framework and embedded framework in a copy files build phase which is all you need to build on the simulator and a device.\n\n## Contributing\n\nBefore contributing to Alamofire, please read the instructions detailed in our [contribution guide](https://github.com/Alamofire/Alamofire/blob/master/CONTRIBUTING.md).\n\n## Open Radars\n\nThe following radars have some effect on the current implementation of Alamofire.\n\n- [`rdar://21349340`](http://www.openradar.me/radar?id=5517037090635776) - Compiler throwing warning due to toll-free bridging issue in the test case\n- `rdar://26870455` - Background URL Session Configurations do not work in the simulator\n- `rdar://26849668` - Some URLProtocol APIs do not properly handle `URLRequest`\n\n## Resolved Radars\n\nThe following radars have been resolved over time after being filed against the Alamofire project.\n\n- [`rdar://26761490`](http://www.openradar.me/radar?id=5010235949318144) - Swift string interpolation causing memory leak with common usage.\n  - (Resolved): 9/1/17 in Xcode 9 beta 6.\n- [`rdar://36082113`](http://openradar.appspot.com/radar?id=4942308441063424) - `URLSessionTaskMetrics` failing to link on watchOS 3.0+\n  - (Resolved): Just add `CFNetwork` to your linked frameworks.\n- `FB7624529` - `urlSession(_:task:didFinishCollecting:)` never called on watchOS\n  - (Resolved): Metrics now collected on watchOS 7+.\n\n## FAQ\n\n### What's the origin of the name Alamofire?\n\nAlamofire is named after the [Alamo Fire flower](https://aggie-horticulture.tamu.edu/wildseed/alamofire.html), a hybrid variant of the Bluebonnet, the official state flower of Texas.\n\n## Credits\n\nAlamofire is owned and maintained by the [Alamofire Software Foundation](http://alamofire.org). You can follow them on Twitter at [@AlamofireSF](https://twitter.com/AlamofireSF) for project updates and releases.\n\n### Security Disclosure\n\nIf you believe you have identified a security vulnerability with Alamofire, you should report it as soon as possible via email to security@alamofire.org. Please do not post it to a public issue tracker.\n\n## Sponsorship\n\nThe [ASF](https://github.com/Alamofire/Foundation#members) is looking to raise money to officially stay registered as a federal non-profit organization.\nRegistering will allow Foundation members to gain some legal protections and also allow us to put donations to use, tax-free.\nSponsoring the ASF will enable us to:\n\n- Pay our yearly legal fees to keep the non-profit in good status\n- Pay for our mail servers to help us stay on top of all questions and security issues\n- Potentially fund test servers to make it easier for us to test the edge cases\n- Potentially fund developers to work on one of our projects full-time\n\nThe community adoption of the ASF libraries has been amazing.\nWe are greatly humbled by your enthusiasm around the projects and want to continue to do everything we can to move the needle forward.\nWith your continued support, the ASF will be able to improve its reach and also provide better legal safety for the core members.\nIf you use any of our libraries for work, see if your employers would be interested in donating.\nAny amount you can donate, whether once or monthly, to help us reach our goal would be greatly appreciated.\n\n[Sponsor Alamofire](https://github.com/sponsors/Alamofire)\n\n## Supporters\n\n[MacStadium](https://macstadium.com) provides Alamofire with a free, hosted Mac mini.\n\n![Powered by MacStadium](https://raw.githubusercontent.com/Alamofire/Alamofire/master/Resources/MacStadiumLogo.png)\n\n## License\n\nAlamofire is released under the MIT license. [See LICENSE](https://github.com/Alamofire/Alamofire/blob/master/LICENSE) for details.\n",
      "stars_today": 2
    },
    {
      "id": 15823460,
      "name": "redisson",
      "full_name": "redisson/redisson",
      "description": "Redisson - Valkey & Redis Java client. Real-Time Data Platform. Sync/Async/RxJava/Reactive API. Over 50 Valkey and Redis based Java objects and services: Set, Multimap, SortedSet, Map, List, Queue, Deque, Semaphore, Lock, AtomicLong, Map Reduce, Bloom filter, Spring, Tomcat, Scheduler, JCache API, Hibernate, RPC, local cache..",
      "html_url": "https://github.com/redisson/redisson",
      "stars": 24209,
      "forks": 5508,
      "language": "Java",
      "topics": [
        "cache",
        "distributed",
        "distributed-locks",
        "executor",
        "hibernate",
        "java",
        "json",
        "lock",
        "map",
        "micronaut",
        "quarkus",
        "queue",
        "redis",
        "redis-client",
        "scheduler",
        "session",
        "spring",
        "tomcat",
        "valkey",
        "valkey-client"
      ],
      "created_at": "2014-01-11T14:06:25Z",
      "updated_at": "2026-01-15T15:47:22Z",
      "pushed_at": "2026-01-15T14:51:58Z",
      "open_issues": 306,
      "owner": {
        "login": "redisson",
        "avatar_url": "https://avatars.githubusercontent.com/u/16851431?v=4"
      },
      "readme": "# Redisson - Valkey & Redis Java client.<br/>Real-Time Data Platform.\n\n[Quick start](https://redisson.org/docs/getting-started/) | [Documentation](https://redisson.org/docs/) | [Changelog](https://github.com/redisson/redisson/blob/master/CHANGELOG.md) | [Code examples](https://github.com/redisson/redisson-examples) | [JavaDocs](https://www.javadoc.io/doc/org.redisson/redisson/latest/index.html)\n\nRedisson is the Java Client and Real-Time Data Platform for Valkey and Redis. Providing the most convenient and easiest way to work with Valkey or Redis. Redisson objects provide an abstraction layer between Valkey or Redis and your Java code, which allowing maintain focus on data modeling and application logic. \n\nRedisson greatly extends the capabilities of Valkey and Redis by providing additional services and data structures not natively available in either platform. This enhancement includes distributed Java collections, objects, and service implementations.\n\n## Features\n\n* Thread-safe implementation\n* JDK 1.8+ up to the latest version compatible\n* Android compatible\n* [Redis](https://redis.io) compatible - from 3.0 up to the latest version\n* [Valkey](https://valkey.io) compatible - from 7.2.5 up to the latest version\n* Supported Valkey and Redis deployment types\n    * [Proxy](https://redisson.org/docs/configuration/#proxy-mode)\n    * [Multi-Cluster](https://redisson.org/docs/configuration/#multi-cluster-mode)\n    * [Multi-Sentinel](https://redisson.org/docs/configuration/#multi-sentinel-mode)\n    * [Single](https://redisson.org/docs/configuration/#single-mode)\n    * [Cluster](https://redisson.org/docs/configuration/#cluster-mode)\n    * [Sentinel](https://redisson.org/docs/configuration/#sentinel-mode)\n    * [Replicated](https://redisson.org/docs/configuration/#replicated-mode)\n    * [Master and Slaves](https://redisson.org/docs/configuration/#master-slave-mode)\n* Supports auto-reconnection  \n* Supports failed to send command auto-retry  \n* Supports OSGi  \n* Supports SSL  \n* Asynchronous connection pool  \n* Lua scripting  \n* [RediSearch](https://redisson.org/docs/data-and-services/services/#redisearch-service)\n* [JSON datatype](https://redisson.org/docs/data-and-services/objects/#json-object-holder)\n* [JSON Store](https://redisson.org/docs/data-and-services/collections/#json-store) \n* [Reactive Streams](https://redisson.org/docs/api-models/#reactive-api) API  \n* [RxJava3](https://redisson.org/docs/api-models/#rxjava-api) API  \n* [Asynchronous](https://redisson.org/docs/api-models/#synchronous-and-asynchronous-api) API  \n* Local cache support including [Caffeine](https://github.com/ben-manes/caffeine)-based implementation\n* [Cache API implementations](https://redisson.org/docs/cache-api-implementations)  \n    Spring Cache, JCache API (JSR-107), Hibernate Cache, MyBatis Cache, Quarkus Cache, Micronaut Cache\n* [Distributed Objects](https://redisson.org/docs/data-and-services/objects)  \n    Object holder, JSON holder, Binary stream holder, Geospatial holder, BitSet, Bloom filter, HyperLogLog, Rate Limiter\n* [Distributed Counters](https://redisson.org/docs/data-and-services/counters)  \n    Id generator, AtomicLong, AtomicDouble, LongAdder, DoubleAdder\n* [Distributed Collections](https://redisson.org/docs/data-and-services/collections)  \n    JSON Store, Map, Multimap, Set, List, SortedSet, ScoredSortedSet, LexSortedSet, TimeSeries, VectorSet\n* [Distributed Queues](https://redisson.org/docs/data-and-services/queues)  \n    ReliableQueue, Queue, Deque, Blocking Queue, Blocking Deque, Priority Queue, Priority Deque, Stream, Ring Buffer, Transfer Queue\n* [Distributed Locks and synchronizers](https://redisson.org/docs/data-and-services/locks-and-synchronizers)  \n    Lock, FairLock, MultiLock, RedLock, ReadWriteLock, Semaphore, PermitExpirableSemaphore, CountDownLatch\n* [Distributed Publish/subscribe](https://redisson.org/docs/data-and-services/publish-subscribe)  \n    Reliable PubSub, Topic, Sharded Topic\n* [Distributed Services](https://redisson.org/docs/data-and-services/services)  \n    Remote service, Live Object service, Executor service, Scheduler service, MapReduce service\n* [Microservices integration](https://redisson.org/docs/microservices-integration)  \n    Helidon, Micronaut, Quarkus\n* [Integration with Spring framework](https://redisson.org/docs/integration-with-spring)  \n    Spring Boot Starter, Spring Cache, Spring Session, Spring Transaction Manager, Spring Cloud Stream, Spring Data Redis\n* [Web Session Management](https://redisson.org/docs/web-session-management)  \n    Apache Tomcat Session, Spring Session, Micronaut Session\n* [Transactions API](https://redisson.org/docs/transactions)\n* [Redis pipelining](https://redisson.org/docs/pipelining) (command batches)\n* Supports many popular codecs ([Kryo](https://github.com/EsotericSoftware/kryo), [Jackson JSON](https://github.com/FasterXML/jackson), [Avro](http://avro.apache.org/), [Smile](http://wiki.fasterxml.com/SmileFormatSpec), [CBOR](http://cbor.io/), [MsgPack](http://msgpack.org/), [Amazon Ion](https://amzn.github.io/ion-docs/), [LZ4](https://github.com/jpountz/lz4-java), [Snappy](https://github.com/xerial/snappy-java), [Protobuf](https://github.com/protocolbuffers/protobuf) and JDK Serialization)\n* 2000+ unit tests  \n\n## [Redisson PRO vs. Community Edition âœ](https://redisson.pro/feature-comparison.html)\n\n<!--\n\n## Comparing solutions\n- [Redisson vs Spring Data Redis](https://redisson.org/articles/feature-comparison-redisson-vs-spring-data-redis.html)\n- [Redisson vs Jedis](https://redisson.org/feature-comparison-redisson-vs-jedis.html)\n- [Redisson vs Lettuce](https://redisson.org/feature-comparison-redisson-vs-lettuce.html)\n- [Redis vs Apache Ignite](https://redisson.org/feature-comparison-redis-vs-ignite.html)\n- [Redis vs Hazelcast](https://redisson.org/feature-comparison-redis-vs-hazelcast.html)\n- [Redis vs Ehcache](https://redisson.org/feature-comparison-redis-vs-ehcache.html)\n\n## Success stories\n\n- [Moving from Hazelcast to Redis  /  Datorama](https://engineering.datorama.com/moving-from-hazelcast-to-redis-b90a0769d1cb)  \n- [Migrating from Hazelcast to Redis  /  Halodoc](https://blogs.halodoc.io/why-and-how-we-move-from-hazelcast-to-redis-2/)\n- [Distributed Locking with Redis (Migration from Hazelcast)  /  ContaAzul](https://carlosbecker.com/posts/distributed-locks-redis/)  \n- [Migrating from Coherence to Redis](https://www.youtube.com/watch?v=JF5R2ucKTEg)  \n-->\n",
      "stars_today": 2
    },
    {
      "id": 1062572,
      "name": "Catch2",
      "full_name": "catchorg/Catch2",
      "description": "A modern, C++-native, test framework for unit-tests, TDD and BDD - using C++14, C++17 and later (C++11 support is in v2.x branch, and C++03 on the Catch1.x branch)",
      "html_url": "https://github.com/catchorg/Catch2",
      "stars": 20118,
      "forks": 3184,
      "language": "C++",
      "topics": [
        "bdd",
        "cpp",
        "cpp14",
        "framework",
        "no-dependencies",
        "tdd",
        "test-framework",
        "testing"
      ],
      "created_at": "2010-11-08T18:22:56Z",
      "updated_at": "2026-01-16T00:06:40Z",
      "pushed_at": "2026-01-13T08:10:07Z",
      "open_issues": 414,
      "owner": {
        "login": "catchorg",
        "avatar_url": "https://avatars.githubusercontent.com/u/33321405?v=4"
      },
      "readme": "<a id=\"top\"></a>\n\n<table width=\"100%\">\n  <tr>\n    <td align=\"center\" width=\"50%\"><img src=\"/data/artwork/catch2-logo-full-with-background.svg\" width=\"100%\"></td>\n    <td align=\"center\" width=\"50%\">\n      <figure>\n        <figcaption>Special thanks to:</figcaption>\n        <a href=\"https://tuple.app/catch2\"><img src=\"/data/sponsors/github_repo_sponsorship.png\" width=\"100%\"></a>\n      </figure>\n    </td>\n  </tr>\n</table>\n\n[![Github Releases](https://img.shields.io/github/release/catchorg/catch2.svg)](https://github.com/catchorg/catch2/releases)\n[![Linux build status](https://github.com/catchorg/Catch2/actions/workflows/linux-simple-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/linux-simple-builds.yml)\n[![Linux build status](https://github.com/catchorg/Catch2/actions/workflows/linux-other-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/linux-other-builds.yml)\n[![MacOS build status](https://github.com/catchorg/Catch2/actions/workflows/mac-builds.yml/badge.svg)](https://github.com/catchorg/Catch2/actions/workflows/mac-builds.yml)\n[![Build Status](https://ci.appveyor.com/api/projects/status/github/catchorg/Catch2?svg=true&branch=devel)](https://ci.appveyor.com/project/catchorg/catch2)\n[![Code Coverage](https://codecov.io/gh/catchorg/Catch2/branch/devel/graph/badge.svg)](https://codecov.io/gh/catchorg/Catch2)\n[![Try online](https://img.shields.io/badge/try-online-blue.svg)](https://godbolt.org/z/EdoY15q9G)\n[![Join the chat in Discord: https://discord.gg/4CWS9zD](https://img.shields.io/badge/Discord-Chat!-brightgreen.svg)](https://discord.gg/4CWS9zD)\n\n\n## What is Catch2?\n\nCatch2 is mainly a unit testing framework for C++, but it also\nprovides basic micro-benchmarking features, and simple BDD macros.\n\nCatch2's main advantage is that using it is both simple and natural.\nTest names do not have to be valid identifiers, assertions look like\nnormal C++ boolean expressions, and sections provide a nice and local way\nto share set-up and tear-down code in tests.\n\n**Example unit test**\n```cpp\n#include <catch2/catch_test_macros.hpp>\n\n#include <cstdint>\n\nuint32_t factorial( uint32_t number ) {\n    return number <= 1 ? number : factorial(number-1) * number;\n}\n\nTEST_CASE( \"Factorials are computed\", \"[factorial]\" ) {\n    REQUIRE( factorial( 1) == 1 );\n    REQUIRE( factorial( 2) == 2 );\n    REQUIRE( factorial( 3) == 6 );\n    REQUIRE( factorial(10) == 3'628'800 );\n}\n```\n\n**Example microbenchmark**\n```cpp\n#include <catch2/catch_test_macros.hpp>\n#include <catch2/benchmark/catch_benchmark.hpp>\n\n#include <cstdint>\n\nuint64_t fibonacci(uint64_t number) {\n    return number < 2 ? number : fibonacci(number - 1) + fibonacci(number - 2);\n}\n\nTEST_CASE(\"Benchmark Fibonacci\", \"[!benchmark]\") {\n    REQUIRE(fibonacci(5) == 5);\n\n    REQUIRE(fibonacci(20) == 6'765);\n    BENCHMARK(\"fibonacci 20\") {\n        return fibonacci(20);\n    };\n\n    REQUIRE(fibonacci(25) == 75'025);\n    BENCHMARK(\"fibonacci 25\") {\n        return fibonacci(25);\n    };\n}\n```\n\n_Note that benchmarks are not run by default, so you need to run it explicitly\nwith the `[!benchmark]` tag._\n\n\n## Catch2 v3 has been released!\n\nYou are on the `devel` branch, where the v3 version is being developed.\nv3 brings a bunch of significant changes, the big one being that Catch2\nis no longer a single-header library. Catch2 now behaves as a normal\nlibrary, with multiple headers and separately compiled implementation.\n\nThe documentation is slowly being updated to take these changes into\naccount, but this work is currently still ongoing.\n\nFor migrating from the v2 releases to v3, you should look at [our\ndocumentation](docs/migrate-v2-to-v3.md#top). It provides a simple\nguidelines on getting started, and collects most common migration\nproblems.\n\nFor the previous major version of Catch2 [look into the `v2.x` branch\nhere on GitHub](https://github.com/catchorg/Catch2/tree/v2.x).\n\n\n## How to use it\nThis documentation comprises these three parts:\n\n* [Why do we need yet another C++ Test Framework?](docs/why-catch.md#top)\n* [Tutorial](docs/tutorial.md#top) - getting started\n* [Reference section](docs/Readme.md#top) - all the details\n\n\n## More\n* Issues and bugs can be raised on the [Issue tracker on GitHub](https://github.com/catchorg/Catch2/issues)\n* For discussion or questions please use [our Discord](https://discord.gg/4CWS9zD)\n* See who else is using Catch2 in [Open Source Software](docs/opensource-users.md#top)\nor [commercially](docs/commercial-users.md#top).\n",
      "stars_today": 2
    },
    {
      "id": 5414488,
      "name": "mongoose",
      "full_name": "cesanta/mongoose",
      "description": "Embedded web server, with TCP/IP network stack, MQTT and Websocket",
      "html_url": "https://github.com/cesanta/mongoose",
      "stars": 12468,
      "forks": 2880,
      "language": "C",
      "topics": [
        "embedded",
        "http",
        "iot",
        "mqtt",
        "tcp",
        "tcpip",
        "tls13",
        "udp",
        "web-server",
        "webserver",
        "websocket"
      ],
      "created_at": "2012-08-14T15:09:51Z",
      "updated_at": "2026-01-15T13:42:19Z",
      "pushed_at": "2026-01-15T13:42:19Z",
      "open_issues": 6,
      "owner": {
        "login": "cesanta",
        "avatar_url": "https://avatars.githubusercontent.com/u/5111322?v=4"
      },
      "readme": "# Mongoose - Embedded Web Server / Embedded Network Library\n\n[![License: GPLv2/Commercial](https://img.shields.io/badge/License-GPLv2%20or%20Commercial-green.svg)](https://opensource.org/licenses/gpl-2.0.php)\n[![Build Status]( https://github.com/cesanta/mongoose/actions/workflows/quicktest.yml/badge.svg)](https://github.com/cesanta/mongoose/actions)\n[![Code Coverage](https://codecov.io/gh/cesanta/mongoose/branch/master/graph/badge.svg)](https://codecov.io/gh/cesanta/mongoose)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/mongoose.svg)](https://issues.oss-fuzz.com/issues?sort=-opened&can=1&q=proj:mongoose)\n\nMongoose is a network library for C/C++.  It provides event-driven non-blocking\nAPIs for TCP, UDP, HTTP, WebSocket, MQTT, and other protocols.  It is designed\nfor connecting devices and bringing them online. On the market since 2004, used\nby vast number of open source and commercial products - it even runs on the\nInternational Space Station!  Mongoose makes embedded network programming fast,\nrobust, and easy. Features include:\n\n- Cross-platform:\n  - works on Linux/UNIX, MacOS, Windows, Android\n  - works on ST, NXP, ESP32, Nordic, TI, Microchip, Infineon, Renesas and other chips\n  - write code once - and it'll work everywhere\n  - ideal for the unification of the network infrastructure code across company\n- Built-in protocols: plain TCP/UDP, SNTP, HTTP, MQTT, Websocket, and other\n- Asynchronous DNS resolver\n- Tiny static and run-time footprint\n- Source code is both ISO C and ISO C++ compliant\n- Easy to integrate: just copy [mongoose.c](https://raw.githubusercontent.com/cesanta/mongoose/master/mongoose.c)\n  and [mongoose.h](https://raw.githubusercontent.com/cesanta/mongoose/master/mongoose.h) files to your source tree\n- Built-in TCP/IP stack with drivers for bare metal or RTOS systems\n   - Available drivers: STM32F, STM32H; NXP RT1xxx; TI TM4C; Microchip SAME54; Wiznet W5500\n   - A complete Web device dashboard on bare metal ST Nucleo boards is only 6 files\n   - For comparison, a CubeIDE generated HTTP example is 400+ files\n- Can run on top of an existing TCP/IP stack with BSD API, e.g. lwIP, Zephyr, Azure, etc\n- Built-in TLS 1.3 ECC stack. Also can use external TLS libraries - mbedTLS, OpenSSL, or other\n- Does not depend on any other software to implement networking\n- Built-in firmware updates for STM32 H5, STM32 H7\n\nSee https://mongoose.ws/ for complete documentation, videos, case studies, etc.\n\n## Supported platforms\n\nMongoose can work on top of any TCP/IP stack that supports BSD sockets API.\nPlatforms supported by the 3rd party TCP/IP stacks:\n\n| TCP/IP stack    | Notes |\n| :-------------- | :------- |\n| **lwIP**        | All devices running lwIP, for example ESP32, ESP32S3, ESP32C3, ESP32C6, etc |\n| **Zephyr**      | All devices supported by Zephyr |\n| **Other**       | Any other TCP/IP stack that supports BSD socket API, for example Amazon FreeRTOS-TCP |\n| **Linux, Mac, Windows**   | Workstations, server, single board computers, embedded Linux devices running on MPUs or FPGAs |\n\nOptionally, Mongoose provides its own built-in TCP/IP stack, eliminating the\nneed for additional software to implement networking functionality. The\nbuilt-in stack supports operation in both bare-metal and RTOS environments.\nPlatforms supported by the Mongoose built-in TCP/IP stack:\n\n| Hardware       | Notes |\n| :------------- | :------- |\n| **STM32**      | All STM32 MCUs with built-in Ethernet: STM32Fxx, STM32H5xx, STM32H7xx |\n| **NXP**        |  All NXP MCUs with built-in Ethernet: IMXRT102x, IMXRT104x, IMXRT105x, IMXRT106x, IMXRT117x, RW612, MCXN94x   |\n| **Microchip**  | ATSAME54 MCUs with built-int Ethernet  |\n| **Renesas**    | RA5M, RA6M, RA8M MCUs with built-in Ethernet    |\n| **Infineon**   | XMC4, XMC7 MCUs with built-in Ethernet    |\n| **Texas Instruments**  |  TM4C, TMS570 MCUs with built-in Ethernet   |\n| **Cypress WiFi**  | Any MCU with CY43xx WiFi chips, like RP2040 Pico-W, RP2350 Pico2-W, Arduino Portenta    |\n| **Wiznet Ethernet**  | Any MCU that use Wiznet W5500 or Wiznet 5100 MAC+PHY chips    |\n| **Cellular**   | NRF9160, SIM800    |\n\n## Usage Examples\n\nBelow are quick snippets that should give an idea how simple the API is and\nhow easy it is to create applications with it.\n\nCreate a simple web server that serves a directory. The behavior of the\nHTTP server is specified by its event handler function:\n\n```c\n#include \"mongoose.h\"   // To build, run: cc main.c mongoose.c\n\n// HTTP server event handler function\nvoid ev_handler(struct mg_connection *c, int ev, void *ev_data) {\n  if (ev == MG_EV_HTTP_MSG) {\n    struct mg_http_message *hm = (struct mg_http_message *) ev_data;\n    struct mg_http_serve_opts opts = { .root_dir = \"./web_root/\" };\n    mg_http_serve_dir(c, hm, &opts);\n  }\n}\n\nint main(void) {\n  struct mg_mgr mgr;  // Declare event manager\n  mg_mgr_init(&mgr);  // Initialise event manager\n  mg_http_listen(&mgr, \"http://0.0.0.0:8000\", ev_handler, NULL);  // Setup listener\n  for (;;) {          // Run an infinite event loop\n    mg_mgr_poll(&mgr, 1000);\n  }\n  return 0;\n}\n```\n\nHTTP server implements a REST API that returns current time. JSON formatting:\n```c\nstatic void ev_handler(struct mg_connection *c, int ev, void *ev_data) {\n  if (ev == MG_EV_HTTP_MSG) {\n    struct mg_http_message *hm = (struct mg_http_message *) ev_data;\n    if (mg_match(hm->uri, mg_str(\"/api/time/get\"), NULL)) {\n      mg_http_reply(c, 200, \"\", \"{%m:%lu}\\n\", MG_ESC(\"time\"), time(NULL));\n    } else {\n      mg_http_reply(c, 500, \"\", \"{%m:%m}\\n\", MG_ESC(\"error\"), MG_ESC(\"Unsupported URI\")); \n    }\n  }\n}\n```\n\nMQTT client that subscribes to a topic `device1/rx` and\nechoes incoming messages to `device1/tx`:\n\n```c\n#include \"mongoose.h\"\n\nstatic const char *s_mqtt_url = \"mqtt://broker.hivemq.com:1883\";\nstatic struct mg_connection *s_mqtt_conn = NULL;\n\n// MQTT connection event handler function\nstatic void ev_handler(struct mg_connection *c, int ev, void *ev_data) {\n  if (ev == MG_EV_OPEN) {\n    MG_INFO((\"%lu created, connecting to %s ...\", c->id, s_mqtt_url));\n  } else if (ev == MG_EV_MQTT_OPEN) {\n    struct mg_mqtt_opts opts = {.qos = 1, .topic = mg_str(\"device1/rx\")};\n    mg_mqtt_sub(c, &opts);\n    MG_INFO((\"%lu connected, subscribing to %s\", c->id, opts.topic.buf));\n  } else if (ev == MG_EV_MQTT_MSG) {\n    char response[100];\n    struct mg_mqtt_message *mm = (struct mg_mqtt_message *) ev_data;\n    struct mg_mqtt_opts opts = {.qos = 1, .topic = mg_str(\"device1/tx\")};\n    mg_snprintf(response, sizeof(response), \"Received [%.*s] / [%.*s]\",\n                mm->topic.len, mm->topic.buf, mm->data.len, mm->data.buf);\n    opts.message = mg_str(response);\n    mg_mqtt_pub(c, &opts);\n  } else if (ev == MG_EV_CLOSE) {\n    MG_INFO((\"%u closing\", c->id));\n    s_mqtt_conn = NULL;\n  }\n}\n\n// Reconnection timer function. If we get disconnected, reconnect again\nstatic void timer_fn(void *arg) {\n  struct mg_mgr *mgr = (struct mg_mgr *) arg;\n  if (s_mqtt_conn == NULL) {\n    struct mg_mqtt_opts opts = {.clean = true};\n    s_mqtt_conn = mg_mqtt_connect(mgr, s_mqtt_url, &opts, ev_handler, NULL);\n  }\n}\n\nint main() {\n  struct mg_mgr mgr;  // Mongoose event manager. Holds all connections\n  mg_mgr_init(&mgr);  // Initialise event manager\n  mg_timer_add(&mgr, 3000, MG_TIMER_REPEAT | MG_TIMER_RUN_NOW, timer_fn, &mgr);\n  for (;;) {\n    mg_mgr_poll(&mgr, 1000);  // Infinite event loop\n  }\n  return 0;\n}\n```\n\n## Commercial use\n- Mongoose is used by hundreds of businesses, from Fortune500 giants like\n  Siemens, Schneider Electric, Broadcom, Bosch, Google, Samsung, Qualcomm, Caterpillar to the small businesses\n- Used to solve a wide range of business needs, like implementing Web UI\n  interface on devices, RESTful API services, telemetry data exchange, remote\n  control for a product, remote software updates, remote monitoring, and others\n- Deployed to hundreds of millions devices in production environment worldwide\n- See [Case Studies](https://mongoose.ws/case-studies/) from our respected\n  customers like [Schneider Electric](https://mongoose.ws/case-studies/schneider-electric/) (industrial automation), [Broadcom](https://mongoose.ws/case-studies/broadcom/) (semiconductors), [Pilz](https://mongoose.ws/case-studies/pilz/) (industrial automation), and others\n- See [Testimonials](https://mongoose.ws/testimonials/) from engineers that integrated Mongoose in their commercial products\n- We provide [Evaluation and Commercial licensing](https://mongoose.ws/licensing/), [support](https://mongoose.ws/support/), consultancy and [integration\n  services](https://mongoose.ws/integration/) - don't hesitate to [contact us](https://mongoose.ws/contact/)\n\n\n## Security\n\nWe take security seriously:\n1. Mongoose repository runs a\n  [continuous integration test powered by GitHub](https://github.com/cesanta/mongoose/actions),\n  which runs through hundreds of unit tests on every commit to the repository.\n  Our [unit tests](https://github.com/cesanta/mongoose/tree/master/test)\n  are built with modern address sanitizer technologies, which help to find\n  security vulnerabilities early\n2. Mongoose repository is integrated into Google's\n  [oss-fuzz continuous fuzzer](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:mongoose)\n  which scans for potential vulnerabilities continuously\n3.  We receive periodic vulnerability reports from the independent security\n  groups like\n  [Cisco Talos](https://www.cisco.com/c/en/us/products/security/talos.html),\n  [Microsoft Security Response Center](https://www.microsoft.com/en-us/msrc),\n  [MITRE Corporation](https://www.mitre.org/),\n  [Compass Security](https://www.compass-security.com/en/) and others.\n  In case of the vulnerability found, we act according to the industry best\n  practice: hold on to the publication, fix the software and notify all our\n  customers that have an appropriate subscription\n4. Some of our customers (for example NASA)\n  have specific security requirements and run independent security audits,\n  of which we get notified and in case of any issue, act similar to (3).\n\n\n## Articles\n\nTechnical guides and deep dives into embedded web servers, WebUI integration and embedded networking technologies:\n- [Embedded Web Server: A Comprehensive Guide for Modern Connected Devices](https://mongoose.ws/articles/embedded-web-server-a-comprehensive-guide-for-modern-connected-devices/)\n- [Building Embedded Web Device Dashboards](https://mongoose.ws/articles/building-embedded-web-device-dashboard/)\n- [ESP32 Device Dashboard: A Step-by-Step Guide for Developers](https://mongoose.ws/articles/esp32-device-dashboard/)\n- [How to build an STM32 Web Dashboard](https://mongoose.ws/articles/stm32-device-dashboard/)\n- [STM32 WebSocket Guide](https://mongoose.ws/articles/stm32-websocket-guide/)\n- [Web File Manager on STM32, ESP32 and Embedded Linux](https://mongoose.ws/articles/building-a-web-file-manager-on-stm32-esp32-embedded-linux/)\n- [Web dashboard on Zephyr RTOS](https://mongoose.ws/articles/web-dashboard-on-zephyr-rtos/)\n- [Limiting TCP/IP RAM usage on STM32](https://mongoose.ws/articles/limiting-tcpip-ram-usage-on-stm32/)\n- [STM32 Ethernet explained](https://mongoose.ws/articles/stm32-ethernet-explained/)\n- [MQTT on a Microcontroller](https://mongoose.ws/articles/mqtt-on-a-microcontroller/)\n- [STM32 OTA Firmware Update](https://mongoose.ws/articles/stm32-ota-firmware-update/)\n- [RP2350 OTA Firmware Update](https://mongoose.ws/articles/rp2350-ota-firmware-update/)\n- [STM32 Ethernet and caches](https://mongoose.ws/articles/stm32-ethernet-and-cache/)\n\n\n## Contributions\n\nContributions are welcome! Please follow the guidelines below:\n\n- Sign [Cesanta CLA](https://cesanta.com/cla.html) and send GitHub pull request\n- Make sure that PRs have only one commit, and deal with one issue only\n",
      "stars_today": 2
    },
    {
      "id": 99412308,
      "name": "seatunnel",
      "full_name": "apache/seatunnel",
      "description": "SeaTunnel is a multimodal, high-performance, distributed, massive data integration tool.",
      "html_url": "https://github.com/apache/seatunnel",
      "stars": 9049,
      "forks": 2160,
      "language": "Java",
      "topics": [
        "apache",
        "batch",
        "cdc",
        "change-data-capture",
        "data-ingestion",
        "data-integration",
        "elt",
        "embeddings",
        "high-performance",
        "llm",
        "multimodal",
        "offline",
        "real-time",
        "streaming"
      ],
      "created_at": "2017-08-05T09:14:47Z",
      "updated_at": "2026-01-15T18:02:37Z",
      "pushed_at": "2026-01-15T13:04:16Z",
      "open_issues": 369,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "# Apache SeaTunnel\n\n<img src=\"https://seatunnel.apache.org/image/logo.png\" alt=\"SeaTunnel Logo\" height=\"200px\" align=\"right\" />\n\n[![Build Workflow](https://github.com/apache/seatunnel/actions/workflows/build_main.yml/badge.svg?branch=dev)](https://github.com/apache/seatunnel/actions/workflows/build_main.yml)\n[![Join Slack](https://img.shields.io/badge/slack-%23seatunnel-4f8eba?logo=slack)](https://s.apache.org/seatunnel-slack)\n[![Twitter Follow](https://img.shields.io/twitter/follow/ASFSeaTunnel.svg?label=Follow&logo=twitter)](https://twitter.com/ASFSeaTunnel)\n[![Ask DeepWiki](https://camo.githubusercontent.com/e7d4bb1a32530e373bb53fbe8eea825440ad27c7531d8f144d561acdd20c093a/68747470733a2f2f6465657077696b692e636f6d2f62616467652e737667)](https://deepwiki.com/apache/seatunnel)\n\n## Table of Contents\n- [Overview](#overview)\n- [Why Choose SeaTunnel](#why-choose-seatunnel)\n- [Key Features](#key-features)\n- [SeaTunnel Workflow](#seatunnel-workflow)\n- [Supported Connectors](#supported-connectors)\n- [Getting Started](#getting-started)\n- [Multimodal Data Integration](#multimodal-data-integration)\n- [Apache SeaTunnel Tools](#apache-seatunnel-tools)\n- [Use Cases](#use-cases)\n- [Code of Conduct](#code-of-conduct)\n- [Contributors](#contributors)\n- [How to Compile](#how-to-compile)\n- [Contact Us](#contact-us)\n- [Landscapes](#landscapes)\n- [Apache SeaTunnel Web Project](#apache-seaTunnel-web-project)\n- [Our Users](#our-users)\n- [License](#license)\n- [Frequently Asked Questions](#frequently-asked-questions)\n\n## Overview\n\nSeaTunnel is a multimodal, high-performance, distributed data integration tool, capable of synchronizing vast amounts of data daily. It's trusted by numerous companies for its efficiency and stability.\n\n\n## Why Choose SeaTunnel\n\nSeaTunnel addresses common data integration challenges:\n\n- **Diverse Data Sources**: Seamlessly integrates with hundreds of evolving data sources.\n\n- **Multimodal Data Integration**: Supports the integration of video, images, binary files, structured and unstructured text data.\n\n- **Complex Synchronization Scenarios**: Supports various synchronization methods, including real-time, CDC, and full database synchronization.\n  \n- **Resource Efficiency**: Minimizes computing resources and JDBC connections for real-time synchronization.\n  \n- **Quality and Monitoring**: Provides data quality and monitoring to prevent data loss or duplication.\n\n## Key Features\n\n- **Diverse Connectors**: Offers support for over 100 connectors, with ongoing expansion.\n  \n- **Batch-Stream Integration**: Easily adaptable connectors simplify data integration management.\n  \n- **Distributed Snapshot Algorithm**: Ensures data consistency across synchronized data.\n  \n- **Multi-Engine Support**: Works with SeaTunnel Zeta Engine, Flink, and Spark.\n  \n- **JDBC Multiplexing and Log Parsing**: Efficiently synchronizes multi-tables and databases.\n  \n- **High Throughput and Low Latency**: Provides high-throughput data synchronization with low latency.\n  \n- **Real-Time Monitoring**: Offers detailed insights during synchronization.\n  \n- **Two Job Development Methods**: Supports coding and visual job management with the [SeaTunnel Web Project](https://github.com/apache/seatunnel-web).\n\n## SeaTunnel Workflow\n\n![SeaTunnel Workflow](docs/images/architecture_diagram.png)\n\nConfigure jobs, select execution engines, and parallelize data using Source Connectors. Easily develop and extend connectors to meet your needs.\n\n## Supported Connectors\n\n- [Source Connectors](https://seatunnel.apache.org/docs/connector-v2/source)\n- [Sink Connectors](https://seatunnel.apache.org/docs/connector-v2/sink)\n- [Transform Connectors](docs/en/transform-v2)\n\n## Getting Started\n\nDownload SeaTunnel from the [Official Website](https://seatunnel.apache.org/download).\n\nChoose your runtime execution engine:\n- [SeaTunnel Zeta Engine](https://seatunnel.apache.org/docs/start-v2/locally/quick-start-seatunnel-engine/)\n- [Spark](https://seatunnel.apache.org/docs/start-v2/locally/quick-start-spark)\n- [Flink](https://seatunnel.apache.org/docs/start-v2/locally/quick-start-flink)\n\n## Multimodal Data Integration\n\n- Most data integration tools support structured and unstructured text data, and SeaTunnel does as well. Simply refer to the desired Source/Sink to use.\n\n- For integrating video, images, and binary files with SeaTunnel, please refer to the documentation for detailed instructions.\n\n## Apache SeaTunnel Tools\n\nSeaTunnel Tools provides a range of peripheral tools, including Apache SeaTunnel Mcp Server, etc,please refer to [SeaTunnel Tools](https://github.com/apache/seatunnel-tools).\n\n## Use Cases\n\nExplore real-world use cases of SeaTunnel, such as Weibo, Tencent Cloud, Sina, Sogou, and Yonghui Superstores. More use cases can be found on the [SeaTunnel Blog](https://seatunnel.apache.org/blog).\n\n## Code of Conduct\n\nParticipate in this project in accordance with the Contributor Covenant [Code of Conduct](https://www.apache.org/foundation/policies/conduct).\n\n## Contributors\n\nWe appreciate all developers for their contributions. See the [List Of Contributors](https://github.com/apache/seatunnel/graphs/contributors).\n\n## How to Compile\n\nRefer to this [Setup](docs/en/contribution/setup.md) for compilation instructions.\n\n## Contact Us\n\n- Mail list: **dev@seatunnel.apache.org**. Subscribe by sending an email to `dev-subscribe@seatunnel.apache.org`.\n\n- Slack: [Join SeaTunnel Slack](https://s.apache.org/seatunnel-slack)\n\n- Twitter: [ASFSeaTunnel on Twitter](https://twitter.com/ASFSeaTunnel)\n\n## Landscapes\n\nSeaTunnel enriches the [CNCF CLOUD NATIVE Landscape](https://landscape.cncf.io/?landscape=observability-and-analysis&license=apache-license-2-0).\n\n## Apache SeaTunnel Web Project\n\nSeaTunnel Web is a web project that provides visual management of jobs, scheduling, running and monitoring capabilities. It is developed based on the SeaTunnel Connector API and the SeaTunnel Zeta Engine. It is a web project that can be deployed independently. It is also a sub-project of SeaTunnel.\nFor more information, please refer to [SeaTunnel Web](https://github.com/apache/seatunnel-web)\n\n## Our Users\n\nCompanies and organizations worldwide use SeaTunnel for research, production, and commercial products. Visit our [Users](https://seatunnel.apache.org/user) for more information.\n\n## License\n\n[Apache 2.0 License](LICENSE)\n\n## Frequently Asked Questions\n\n### 1. How do I install SeaTunnel?\n\nFollow the [Installation Guide](https://seatunnel.apache.org/docs/start-v2/locally/deployment/) on our website to get\nstarted.\n\n### 2. How can I contribute to SeaTunnel?\n\nWe welcome contributions! Please refer to our [Contribution Guidelines](https://github.com/apache/seatunnel/blob/dev/docs/en/contribution/coding-guide.md) for details.\n\n### 3. How do I report issues or request features?\n\nYou can report issues or request features on our [GitHub Repository](https://github.com/apache/seatunnel/issues).\n\n### 4. Can I use SeaTunnel for commercial purposes?\n\nYes, SeaTunnel is available under the Apache 2.0 License, allowing commercial use.\n\n### 5. Where can I find documentation and tutorials?\n\nOur [Official Documentation](https://seatunnel.apache.org/docs) includes detailed guides and tutorials to help you get started.\n\n### 6. Is there a community or support channel?\n\nJoin our Slack community for support and discussions: [SeaTunnel Slack](https://s.apache.org/seatunnel-slack).\nMore information, please refer to [FAQ](https://seatunnel.apache.org/docs/faq). \n",
      "stars_today": 2
    },
    {
      "id": 17101828,
      "name": "swirl_courses",
      "full_name": "swirldev/swirl_courses",
      "description": ":mortar_board: A collection of interactive courses for the swirl R package.",
      "html_url": "https://github.com/swirldev/swirl_courses",
      "stars": 4521,
      "forks": 7243,
      "language": "R",
      "topics": [],
      "created_at": "2014-02-23T04:48:04Z",
      "updated_at": "2026-01-15T13:35:31Z",
      "pushed_at": "2024-01-10T17:38:19Z",
      "open_issues": 206,
      "owner": {
        "login": "swirldev",
        "avatar_url": "https://avatars.githubusercontent.com/u/5671732?v=4"
      },
      "readme": "# swirl courses\n\nThis is a collection of interactive courses for use with the [swirl R package](http://swirlstats.com). You'll find instructions for installing courses further down on this page. Some courses are still in development and we'd love to hear any [suggestions](https://github.com/swirldev/swirl_courses/issues/new) you have as you work through them.\n\nFor more information regarding swirl, visit [swirlstats.com](http://swirlstats.com) or the [swirl GitHub repository](https://github.com/swirldev/swirl). If you'd like to write your own interactive content, please visit the [Instructors page](http://swirlstats.com/instructors.html) of our website.\n\nHere are our current offerings, organized by level of difficulty:\n\n#### Beginner\n\n- **R Programming**: The basics of programming in R\n- [**R Programming E**](https://github.com/swirldev/R_Programming_E): Same as the original, but modified slightly for in-class use (see below ***)\n- [**The R Programming Environment**](https://swirlstats.com/scn/rpe.html)\n<!-- - **Data Analysis**: Basic ideas in statistics and data visualization -->\n<!-- - **Mathematical Biostatistics Boot Camp**: One- and two-sample t-tests, power, and sample size -->\n<!-- - **Open Intro**: A very basic introduction to statistics, data analysis, and data visualization -->\n\n\\*\\*\\* *R Programming E is identical to R Programming, except we've eliminated the prompts for Coursera credentials at the end of each lesson and instead give students the option to send an email to their instructor notifying them of completion. Admittedly, it's sort of a hack until we come up with a more robust solution for in-class use (i.e. an instructor \"dashboard\").*\n\n#### Intermediate\n\n- **Regression Models**: The basics of regression modeling in R\n- **Getting and Cleaning Data**: dplyr, tidyr, lubridate, oh my!\n\n#### Advanced\n\n- **Statistical Inference**: This intermediate to advanced level course closely follows the\n[Statistical Inference course](https://www.coursera.org/course/statinference) of the Johns Hopkins \n[Data Science Specialization](https://www.coursera.org/specialization/jhudatascience/1) on Coursera. It\nintroduces the student to basic concepts of statistical inference\nincluding probability, hypothesis testing, confidence intervals and\np-values. It concludes with an initiation to topics of particular\nrelevance to big data, issues of multiple testing and resampling.\n- [**Advanced R Programming**](https://swirlstats.com/scn/arp.html)\n\nSince our users come from a variety backgrounds, it's very hard to label material as **Beginner**, **Intermediate**, or **Advanced**. If you find something that is labelled **Beginner** to be challenging, please don't be discouraged. The first step of learning anything is to acknowledge that you are capable of understanding it. True understanding will come with time and practice.\n\n#### Course Authors\n\n- **Writing swirl Courses**: An interactive guides and example \n  for swirl course authors. The first group of lessons cover basics. The rest cover \n  special topics useful primarily as samples--points of departure for one's own material.\n  For more comprehensive documentation about writing your own swirl courses see http://swirlstats.com/swirlify/.\n\n## Install and run a course automatically from swirl\n\n**This is the preferred method of installing courses.** It automates the process by allowing you to do everything right from the R console.\n\n1) Make sure you have a recent version version of swirl:\n\n```\ninstall.packages(\"swirl\")\n```\n\n2) Enter the following from the R console, **substituting the name of the course** that you wish to install:\n\n```\nlibrary(swirl)\ninstall_course(\"Course Name Here\")\nswirl()\n```\n\nFor example, `install_course(\"R Programming\")` will install the R Programming course. **Please note that course names are case sensitive!**\n\nIf that doesn't work for you...\n\n## Install and run a course manually\n\nIf the automatic course installation method outlined above does not work for you, then there's a simple alternative.\n\n1. Find the course you want to install on the [Swirl Course network website](https://swirlstats.com/scn/title.html).\n2. Follow the manual installation instructions on the course page.\n\nIf that does not work for you, consider taking a look at the \n[legacy manual install instructions](https://github.com/swirldev/swirl_courses/wiki/Legacy-Manual-Install-Instructions-for-Swirl-Courses).\n\n## Uninstall a course\n\nIf you'd like to remove a course at any time, you can use `uninstall_course(\"Course Name Here\")`.\n\n## Using swirl in the classroom\n\nInstructors around the world are using swirl in their classrooms. We think this is awesome. If you're an instructor, please feel free to do the same -- free of charge. While your students may be paying to take your course or attend your institution, we simply ask that you don't charge people *directly* for the use of our software or instructional content.\n\nIf you are not sure about a particular use case, don't hesitate to post a\nquestion to our [Google Group](https://groups.google.com/forum/#!forum/swirl-discuss).\n",
      "stars_today": 2
    },
    {
      "id": 19438,
      "name": "ggplot2",
      "full_name": "tidyverse/ggplot2",
      "description": "An implementation of the Grammar of Graphics in R",
      "html_url": "https://github.com/tidyverse/ggplot2",
      "stars": 6857,
      "forks": 2117,
      "language": "R",
      "topics": [
        "data-visualisation",
        "r",
        "visualisation"
      ],
      "created_at": "2008-05-25T01:21:32Z",
      "updated_at": "2026-01-15T20:38:22Z",
      "pushed_at": "2025-12-18T13:22:01Z",
      "open_issues": 91,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# ggplot2 <a href=\"https://ggplot2.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" alt=\"ggplot2 website\" /></a>\n\n<!-- badges: start -->\n\n[![R-CMD-check](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml)\n[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/ggplot2)](https://cran.r-project.org/package=ggplot2)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/ggplot2/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/ggplot2)\n<!-- badges: end -->\n\n## Overview\n\nggplot2 is a system for declaratively creating graphics, based on [The\nGrammar of\nGraphics](https://link.springer.com/book/10.1007/0-387-28695-0). You\nprovide the data, tell ggplot2 how to map variables to aesthetics, what\ngraphical primitives to use, and it takes care of the details.\n\n## Installation\n\n``` r\n# The easiest way to get ggplot2 is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just ggplot2:\ninstall.packages(\"ggplot2\")\n\n# Or the development version from GitHub:\n# install.packages(\"pak\")\npak::pak(\"tidyverse/ggplot2\")\n```\n\n## Cheatsheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-visualization-cheatsheet-thumbs.png\" width=\"630\" height=\"252\" alt=\"ggplot2 cheatsheet\" /></a>\n\n## Usage\n\nItâ€™s hard to succinctly describe how ggplot2 works because it embodies a\ndeep philosophy of visualisation. However, in most cases you start with\n`ggplot()`, supply a dataset and aesthetic mapping (with `aes()`). You\nthen add on layers (like `geom_point()` or `geom_histogram()`), scales\n(like `scale_colour_brewer()`), faceting specifications (like\n`facet_wrap()`) and coordinate systems (like `coord_flip()`).\n\n``` r\nlibrary(ggplot2)\n\nggplot(mpg, aes(displ, hwy, colour = class)) +\n  geom_point()\n```\n\n<img src=\"man/figures/README-example-1.png\" alt=\"Scatterplot of engine displacement versus highway miles per gallon, for 234 cars coloured by 7 'types' of car. The displacement and miles per gallon are inversely correlated.\"  />\n\n## Lifecycle\n\n[![lifecycle](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n\nggplot2 is now 18 years old and is used by hundreds of thousands of\npeople to make millions of plots. That means, by-and-large, ggplot2\nitself changes relatively little. When we do make changes, they will be\ngenerally to add new functions or arguments rather than changing the\nbehaviour of existing functions, and if we do make changes to existing\nbehaviour we will do them for compelling reasons.\n\nIf you are looking for innovation, look to ggplot2â€™s rich ecosystem of\nextensions. See a community maintained list at\n<https://exts.ggplot2.tidyverse.org/gallery/>.\n\n## Learning ggplot2\n\nIf you are new to ggplot2 you are better off starting with a systematic\nintroduction, rather than trying to learn from reading individual\ndocumentation pages. Currently, there are several good places to start:\n\n1.  The [Data Visualization](https://r4ds.hadley.nz/data-visualize) and\n    [Communication](https://r4ds.hadley.nz/communication) chapters in [R\n    for Data Science](https://r4ds.hadley.nz). R for Data Science is\n    designed to give you a comprehensive introduction to the\n    [tidyverse](https://tidyverse.org/), and these two chapters will get\n    you up to speed with the essentials of ggplot2 as quickly as\n    possible.\n\n2.  If youâ€™d like to take an online course, try [Data Visualization in R\n    With\n    ggplot2](https://learning.oreilly.com/videos/data-visualization-in/9781491963661/)\n    by Kara Woo.\n\n3.  If youâ€™d like to follow a webinar, try [Plotting Anything with\n    ggplot2](https://youtu.be/h29g21z0a68) by Thomas Lin Pedersen.\n\n4.  If you want to dive into making common graphics as quickly as\n    possible, I recommend [The R Graphics\n    Cookbook](https://r-graphics.org) by Winston Chang. It provides a\n    set of recipes to solve common graphics problems.\n\n5.  If youâ€™ve mastered the basics and want to learn more, read [ggplot2:\n    Elegant Graphics for Data Analysis](https://ggplot2-book.org). It\n    describes the theoretical underpinnings of ggplot2 and shows you how\n    all the pieces fit together. This book helps you understand the\n    theory that underpins ggplot2, and will help you create new types of\n    graphics specifically tailored to your needs.\n\n6.  For articles about announcements and deep-dives you can visit the\n    [tidyverse blog](https://tidyverse.org/tags/ggplot2/).\n\n## Getting help\n\nThere are two main places to get help with ggplot2:\n\n1.  The [Posit Community](https://forum.posit.co/) (formerly RStudio\n    Community) is a friendly place to ask any questions about ggplot2.\n\n2.  [Stack\n    Overflow](https://stackoverflow.com/questions/tagged/ggplot2?sort=frequent&pageSize=50)\n    is a great source of answers to common ggplot2 questions. It is also\n    a great place to get help, once you have created a reproducible\n    example that illustrates your problem.\n",
      "stars_today": 2
    },
    {
      "id": 67177488,
      "name": "swift-protobuf",
      "full_name": "apple/swift-protobuf",
      "description": "Plugin and runtime library for using protobuf with Swift",
      "html_url": "https://github.com/apple/swift-protobuf",
      "stars": 4860,
      "forks": 502,
      "language": "Swift",
      "topics": [],
      "created_at": "2016-09-02T00:51:55Z",
      "updated_at": "2026-01-15T05:25:27Z",
      "pushed_at": "2026-01-15T17:49:59Z",
      "open_issues": 71,
      "owner": {
        "login": "apple",
        "avatar_url": "https://avatars.githubusercontent.com/u/10639145?v=4"
      },
      "readme": "<img src=\"https://swift.org/assets/images/swift.svg\" alt=\"Swift logo\" height=\"70\" >\n\n# Swift Protobuf\n\n**Welcome to Swift Protobuf!**\n\n[Apple's Swift programming language](https://swift.org/) is a perfect\ncomplement to [Google's Protocol Buffer](https://protobuf.dev/)\n(\"protobuf\") serialization technology.\nThey both emphasize high performance and programmer safety.\n\nThis project provides both the command-line program that adds Swift\ncode generation to Google's `protoc` and the runtime library that is\nnecessary for using the generated code.\nAfter using the protoc plugin to generate Swift code from your .proto\nfiles, you will need to add this library to your project.\n\n[![Build and Test](https://github.com/apple/swift-protobuf/workflows/Build%20and%20Test/badge.svg)](https://github.com/apple/swift-protobuf/actions?query=workflow%3A%22Build+and+Test%22)\n[![Check Upstream Protos](https://github.com/apple/swift-protobuf/workflows/Check%20Upstream%20Proto%20Files/badge.svg)](https://github.com/apple/swift-protobuf/actions?query=workflow%3A%22Check+Upstream+Proto+Files%22)\n[![Run Conformance Tests](https://github.com/apple/swift-protobuf/workflows/Run%20Conformance%20Tests/badge.svg)](https://github.com/apple/swift-protobuf/actions?query=workflow%3A%22Run+Conformance+Tests%22)\n\n# Features of SwiftProtobuf\n\nSwiftProtobuf offers many advantages over alternative serialization\nsystems:\n\n* Safety: The protobuf code-generation system avoids the\n  errors that are common with hand-built serialization code.\n* Correctness: SwiftProtobuf passes both its own extensive\n  test suite and Google's full conformance test for protobuf\n  correctness.\n* Schema-driven: Defining your data structures in a separate\n  `.proto` schema file clearly documents your communications\n  conventions.\n* Idiomatic: SwiftProtobuf takes full advantage of the Swift language.\n  In particular, all generated types provide full Swift copy-on-write\n  value semantics.\n* Efficient binary serialization: The `.serializedBytes()`\n  method returns a bag of bytes with a compact binary form of your data.\n  You can deserialize the data using the `init(contiguousBytes:)`\n  initializer.\n* Standard JSON serialization: The `.jsonUTF8Bytes()` method returns a JSON\n  form of your data that can be parsed with the `init(jsonUTF8Bytes:)`\n  initializer.\n* Hashable, Equatable: The generated struct can be put into a\n  `Set<>` or `Dictionary<>`.\n* Performant: The binary and JSON serializers have been\n  extensively optimized.\n* Extensible: You can add your own Swift extensions to any\n  of the generated types.\n\nBest of all, you can take the same `.proto` file and generate\nJava, C++, Python, or Objective-C for use on other platforms. The\ngenerated code for those languages will use the exact same\nserialization and deserialization conventions as SwiftProtobuf, making\nit easy to exchange serialized data in binary or JSON forms, with no\nadditional effort on your part.\n\n# Documentation\n\nMore information is available in the associated documentation:\n\n * [Google's protobuf documentation](https://protobuf.dev/)\n   provides general information about protocol buffers, the protoc compiler,\n   and how to use protocol buffers with C++, Java, and other languages.\n * [PLUGIN.md](Documentation/PLUGIN.md) documents the `protoc-gen-swift`\n   plugin that adds Swift support to the `protoc` program\n * [API.md](Documentation/API.md) documents how to use the generated code.\n   This is recommended reading for anyone using SwiftProtobuf in their\n   project.\n * [INTERNALS.md](Documentation/INTERNALS.md) documents the internal structure\n   of the generated code and the library.  This\n   should only be needed by folks interested in working on SwiftProtobuf\n   itself.\n * [STYLE_GUIDELINES.md](Documentation/STYLE_GUIDELINES.md) documents the style\n   guidelines we have adopted in our codebase if you are interested in\n   contributing\n\n# Getting Started\n\nIf you've worked with Protocol Buffers before, adding Swift support is very\nsimple: you just need to build the `protoc-gen-swift` program and copy it into\nyour PATH.\nThe `protoc` program will find and use it automatically, allowing you\nto build Swift sources for your proto files.\nYou will also, of course, need to add the SwiftProtobuf runtime library to\nyour project as explained below.\n\n## System Requirements\n\nTo use Swift with Protocol buffers, you'll need:\n\n* A Swift 5.10 or later compiler (or, if building with Xcode, Xcode 15.3 or later\n  as required by the App Store). The Swift protobuf project is being developed\n  and tested against the latest release version of Swift available from\n  [Swift.org](https://swift.org)\n\n* Google's protoc compiler.  The Swift protoc plugin is being actively developed\n  and tested against the latest protobuf sources. The SwiftProtobuf tests need a\n  version of protoc which supports the `swift_prefix` option (introduced in\n  protoc 3.2.0). It may work with earlier versions of protoc. You can get recent\n  versions from\n  [Google's github repository](https://github.com/protocolbuffers/protobuf).\n\n## Building and Installing the Code Generator Plugin\n\nTo translate `.proto` files into Swift, you will need both Google's\nprotoc compiler and the SwiftProtobuf code generator plugin.\n\nBuilding the plugin should be simple on any supported Swift platform:\n\n```bash\ngit clone https://github.com/apple/swift-protobuf.git\ncd swift-protobuf\n```\n\nPick what released version of SwiftProtobuf you are going to use.  You can get\na list of tags with:\n\n```bash\ngit tag -l\n```\n\nOnce you pick the version you will use, set your local state to match, and\nbuild the protoc plugin:\n\n```bash\ngit checkout tags/[tag_name]\nswift build -c release\n```\n\nThis will create a binary called `protoc-gen-swift` in the `.build/release`\ndirectory.\n\nTo install, just copy this one executable into a directory that is\npart of your `PATH` environment variable.\n\nNOTE: The Swift runtime support is now included with macOS. If you are\nusing old Xcode versions or are on older system versions, you might need\nto use also use `--static-swift-stdlib` with `swift build`.\n\n### Alternatively install via Homebrew\n\nIf you prefer using [Homebrew](https://brew.sh):\n\n```bash\nbrew install swift-protobuf\n```\n\nThis will install `protoc` compiler and Swift code generator plugin.\n\n## Converting .proto files into Swift\n\nTo generate Swift output for your .proto files, you run the `protoc` command as\nusual, using the `--swift_out=<directory>` option:\n\n```bash\nprotoc --swift_out=. my.proto\n```\n\nThe `protoc` program will automatically look for `protoc-gen-swift` in your\n`PATH` and use it.\n\nEach `.proto` input file will get translated to a corresponding `.pb.swift`\nfile in the output directory.\n\nMore information about building and using `protoc-gen-swift` can be found\nin the [detailed Plugin documentation](Documentation/PLUGIN.md).\n\n## Adding the SwiftProtobuf library to your project...\n\nTo use the generated code, you need to include the `SwiftProtobuf` library\nmodule in your project.  How you do this will vary depending on how\nyou're building your project.  Note that in all cases, we strongly recommend\nthat you use the version of the SwiftProtobuf library that corresponds to\nthe version of `protoc-gen-swift` you used to generate the code.\n\n### ...using `swift build`\n\nAfter copying the `.pb.swift` files into your project, you will need to add the\n[SwiftProtobuf library](https://github.com/apple/swift-protobuf) to your\nproject to support the generated code.\nIf you are using the Swift Package Manager, add a dependency to your\n`Package.swift` file and import the `SwiftProtobuf` library into the desired\ntargets.  Adjust the `\"1.27.0\"` here to match the `[tag_name]` you used to build\nthe plugin above:\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/apple/swift-protobuf.git\", from: \"1.27.0\"),\n],\ntargets: [\n    .target(\n      name: \"MyTarget\",\n      dependencies: [.product(name: \"SwiftProtobuf\", package: \"swift-protobuf\")]\n    ),\n]\n```\n\n### ...using Xcode\n\nIf you are using Xcode, then you should:\n\n* Add the `.pb.swift` source files generated from your protos directly to your\n  project\n* Add this SwiftPM package as dependency of your xcode project:\n  [Apple Docs](https://developer.apple.com/documentation/swift_packages/adding_package_dependencies_to_your_app)\n\n### ...using CocoaPods\n\nIf you're using CocoaPods, add this to your `Podfile` adjusting the `:tag` to\nmatch the `[tag_name]` you used to build the plugin above:\n\n```ruby\npod 'SwiftProtobuf', '~> 1.0'\n```\n\nAnd run `pod install`.\n\nNOTE: CocoaPods 1.7 or newer is required.\n\n# Quick Start\n\nOnce you have installed the code generator, used it to\ngenerate Swift code from your `.proto` file, and\nadded the SwiftProtobuf library to your project, you can\njust use the generated types as you would any other Swift\nstruct.\n\nFor example, you might start with the following very simple\nproto file:\n```protobuf\nsyntax = \"proto3\";\n\nmessage BookInfo {\n   int64 id = 1;\n   string title = 2;\n   string author = 3;\n}\n```\n\nThen generate Swift code using:\n```bash\nprotoc --swift_out=. DataModel.proto\n```\n\nThe generated code will expose a Swift property for\neach of the proto fields as well as a selection\nof serialization and deserialization capabilities:\n```swift\n// Create a BookInfo object and populate it:\nvar info = BookInfo()\ninfo.id = 1734\ninfo.title = \"Really Interesting Book\"\ninfo.author = \"Jane Smith\"\n\n// As above, but generating a read-only value:\nlet info2 = BookInfo.with {\n    $0.id = 1735\n    $0.title = \"Even More Interesting\"\n    $0.author = \"Jane Q. Smith\"\n  }\n\n// Serialize to binary protobuf format: you can choose to serialize into\n// any type conforming to `SwiftProtobufContiguousBytes`. For example:\n// Resolve the `SwiftProtobufContiguousBytes` return value to `Data`\nlet binaryData: Data = try info.serializedBytes()\n// Resolve the `SwiftProtobufContiguousBytes` return value to `[UInt8]`\nlet binaryDataAsBytes: [UInt8] = try info.serializedBytes()\n\n// Note that while the `serializedBytes()` spelling is generally preferred,\n// you may also use `serializedData()` to get the bytes as an instance of \n// `Data` where required.\n// This means that the following two statements are equivalent:\n// let binaryData: Data = try info.serializedBytes()\n// let binaryData: Data = try info.serializedData()\n\n// Deserialize a received Data object from `binaryData`\nlet decodedInfo = try BookInfo(serializedData: binaryData)\n\n// Deserialize a received [UInt8] object from `binaryDataAsBytes`\nlet decodedInfo = try BookInfo(serializedBytes: binaryDataAsBytes)\n\n// Serialize to JSON format as a Data object, or as any other type conforming to\n// SwiftProtobufContiguousBytes. For example:\nlet jsonData: Data = try info.jsonUTF8Data()\nlet jsonBytes: [UInt8] = try info.jsonUTF8Bytes()\n\n// Deserialize from JSON format from `jsonBytes`\nlet receivedFromJSON = try BookInfo(jsonUTF8Bytes: jsonBytes)\n```\n\nYou can find more information in the detailed\n[API Documentation](Documentation/API.md).\n\n## Report any issues\n\nIf you run into problems, please send us a detailed report.\nAt a minimum, please include:\n\n* The specific operating system and version (for example, \"macOS 10.12.1\" or\n  \"Ubuntu 16.10\")\n* The version of Swift you have installed (from `swift --version`)\n* The version of the protoc compiler you are working with from\n  `protoc --version`\n* The specific version of this source code (you can use `git log -1` to get the\n  latest commit ID)\n* Any local changes you may have\n",
      "stars_today": 2
    },
    {
      "id": 212382406,
      "name": "ozone",
      "full_name": "apache/ozone",
      "description": "Scalable, reliable, distributed storage system optimized for data analytics and object store workloads.",
      "html_url": "https://github.com/apache/ozone",
      "stars": 1140,
      "forks": 592,
      "language": "Java",
      "topics": [
        "big-data",
        "hadoop",
        "kubernetes",
        "object-store",
        "s3",
        "storage"
      ],
      "created_at": "2019-10-02T15:56:19Z",
      "updated_at": "2026-01-15T17:33:11Z",
      "pushed_at": "2026-01-15T16:36:17Z",
      "open_issues": 74,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://ozone.apache.org\">\n    <img src=\"https://www.apache.org/logos/res/ozone/default.png\" alt=\"Apache Ozone Logo\" />\n  </a>\n</div>\n\n[![License](https://img.shields.io/:license-Apache%202-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0.txt)\n[![Docker Pulls](https://img.shields.io/docker/pulls/apache/ozone.svg)](https://hub.docker.com/r/apache/ozone)\n[![Docker Stars](https://img.shields.io/docker/stars/apache/ozone.svg)](https://hub.docker.com/r/apache/ozone)\n[![Contributors](https://img.shields.io/github/contributors/apache/ozone)](https://github.com/apache/ozone/graphs/contributors)\n[![Commit Activity](https://img.shields.io/github/commit-activity/m/apache/ozone)](https://github.com/apache/ozone/commits/master)\n[![OSSRank](https://shields.io/endpoint?url=https://ossrank.com/shield/3018)](https://ossrank.com/p/3018-apache-ozone)\n\nApache Ozone\n===\n\nOzone is a scalable, redundant, and distributed object store for Hadoop and Cloud-native environments. Apart from scaling to billions of objects of varying sizes, Ozone can function effectively in containerized environments such as Kubernetes and YARN.\n\n\n * MULTI-PROTOCOL SUPPORT: Ozone supports different protocols like S3 and Hadoop File System APIs.\n * SCALABLE: Ozone is designed to scale to tens of billions of files and blocks and, in the future, even more.\n * CONSISTENT: Ozone is a strongly consistent object store. This consistency is achieved by using protocols like RAFT.\n * CLOUD-NATIVE: Ozone is designed to work well in containerized environments like YARN and Kubernetes.\n * SECURE: Ozone integrates with Kerberos infrastructure for authentication, supports native ACLs and integrates with Ranger for access control and supports TDE and on-wire encryption.\n * HIGHLY AVAILABLE: Ozone is a fully replicated system that is designed to survive multiple failures.\n\n## Documentation\n\nThe latest documentation is generated together with the releases and hosted on the apache site.\n\nPlease check [the documentation page](https://ozone.apache.org/docs/) for more information.\n\n## Contact\n\nOzone is a top level project under the [Apache Software Foundation](https://apache.org)\n\n * Ozone [web page](https://ozone.apache.org)\n * Mailing lists\n     * For any questions use: [dev@ozone.apache.org](https://lists.apache.org/list.html?dev@ozone.apache.org)\n * Chat: There are a few ways to interact with the community\n     * You can find the #ozone channel on the official ASF Slack. Invite link is [here](http://s.apache.org/slack-invite).\n     * You can use [GitHub Discussions](https://github.com/apache/ozone/discussions) to post questions or follow community syncs. \n * There are Open [Weekly calls](https://cwiki.apache.org/confluence/display/OZONE/Ozone+Community+Calls) where you can ask anything about Ozone.\n    * Past meeting notes are also available from the wiki.\n * Reporting security issues: Please consult with [SECURITY.md](./SECURITY.md) about reporting security vulnerabilities and issues.\n\n## Download\n\nLatest release artifacts (source release and binary packages) are [available](https://ozone.apache.org/downloads/) from the Ozone web page.\n\n## Quick start\n\n### Run Ozone with Docker Compose\n\nThe easiest way to start a cluster with docker is by using Docker Compose:\n\n- Obtain Ozoneâ€™s sample Docker Compose configuration:\n```bash\ncurl -O https://raw.githubusercontent.com/apache/ozone-docker/refs/heads/latest/docker-compose.yaml\n```\n\n- Start the cluster\n```bash\ndocker compose up -d --scale datanode=3\n```\n\n- Note: By default, the cluster will be started with replication factor set to 1. It can be changed by setting the environment variable `OZONE_REPLICATION_FACTOR` to the desired value.\n\nAnd you can use AWS S3 cli:\n\n- First, letâ€™s configure AWS access key and secret key. Because the cluster is not secured, you can use any arbitrary access key and secret key. For example:\n```bash\nexport AWS_ACCESS_KEY_ID=testuser/scm@EXAMPLE.COM\nexport AWS_SECRET_ACCESS_KEY=c261b6ecabf7d37d5f9ded654b1c724adac9bd9f13e247a235e567e8296d2999\n```\n\n- Then we can create a bucket and upload a file to it:\n```\naws s3api --endpoint http://localhost:9878/ create-bucket --bucket=wordcount\n# create a temporary file to upload to Ozone via S3 support \nls -1 > /tmp/testfile\naws s3 --endpoint http://localhost:9878 cp --storage-class REDUCED_REDUNDANCY  /tmp/testfile  s3://wordcount/testfile\n```\n\n### Run Ozone from released artifact\n\nIf you need a more realistic cluster, you can [download](https://ozone.apache.org/downloads/) the latest (binary) release package, and start a cluster with the help of docker-compose:\n\nAfter you untar the binary:\n\n```\ncd compose/ozone\ndocker-compose up -d --scale datanode=3\n```\n\nThe `compose` folder contains different sets of configured clusters (secure, HA, mapreduce example), you can check the various subfolders for more examples.\n\n### Run on Kubernetes\n\nOzone is a first class citizen of the Cloud-Native environments. The binary package contains multiple sets of K8s resource files to show how it can be deployed.\n\n## Build from source\n\nOzone can be built with [Apache Maven](https://maven.apache.org):\n\n```\nmvn clean install -DskipTests\n```\n\nAnd can be started with the help of Docker:\n\n```\ncd hadoop-ozone/dist/target/ozone-*/compose/ozone\ndocker-compose up -d --scale datanode=3\n```\nFor more information, you can check the [Contribution guideline](./CONTRIBUTING.md)\n\n## Contribute\n\nAll contributions are welcome.\n\n 1. Please open a [Jira](https://issues.apache.org/jira/projects/HDDS/issues) issue\n 2. And create a pull request\n\nFor more information, you can check the [Contribution guideline](./CONTRIBUTING.md)\n\n## License\n\nThe Apache Ozone project is licensed under the Apache 2.0 License. See the [LICENSE](./LICENSE.txt) file for details.\n",
      "stars_today": 2
    },
    {
      "id": 982577878,
      "name": "nav3-recipes",
      "full_name": "android/nav3-recipes",
      "description": "Implement common use cases with Jetpack Navigation 3",
      "html_url": "https://github.com/android/nav3-recipes",
      "stars": 1106,
      "forks": 117,
      "language": "Kotlin",
      "topics": [
        "android",
        "compose",
        "navigation"
      ],
      "created_at": "2025-05-13T05:23:51Z",
      "updated_at": "2026-01-15T06:27:01Z",
      "pushed_at": "2026-01-15T18:13:03Z",
      "open_issues": 54,
      "owner": {
        "login": "android",
        "avatar_url": "https://avatars.githubusercontent.com/u/32689599?v=4"
      },
      "readme": "# Navigation 3 - Code recipes\n[Jetpack Navigation 3](https://goo.gle/nav3) is a library for app navigation. This repository contains recipes for how to \nuse its APIs to implement common navigation use cases. Each recipe introduces a single concept. Instead\nof making existing recipes more complex, there should be a new recipe for that particular concept.\n\nEvery Navigation 3 release will be an opportunity for patterns you see in recipes to \"graduate\" and become\n(optional) helpers in the library itself. Then we'll update the recipe to use that prebuilt helper, thus\nensuring that the recipes continue to be a good way to approach these kinds of problems.\n\nRecipes on the `main` branch use the **latest** (which may be an alpha or snapshot) version of Nav3. For recipes that use **stable** versions, check the [releases page](https://github.com/android/nav3-recipes/releases).\n\n## Recipes\nThese are the recipes and what they demonstrate. \n\n### Basic API examples\n- **[Basic](app/src/main/java/com/example/nav3recipes/basic)**: Shows most basic API usage.\n- **[Saveable back stack](app/src/main/java/com/example/nav3recipes/basicsaveable)**: As above, with a persistent back stack.\n- **[Entry provider DSL](app/src/main/java/com/example/nav3recipes/basicdsl)**: As above, using the entryProvider DSL.\n\n### Deep links\nRead the [guide to deeplinking](docs/deeplink-guide.md). Upvote [this issue](https://issuetracker.google.com/470282247) if you would like an API for deeplinks.\n- **[Basic](app/src/main/java/com/example/nav3recipes/deeplink/basic)**: Shows how to parse a deep link URL from an Android Intent into a navigation key.\n- **[Advanced](app/src/main/java/com/example/nav3recipes/deeplink/advanced)**: Shows how to handle deep links with a synthetic back stack and correct \"Up\" navigation behavior.\n\n### Layouts using Scenes\n- **[List-Detail Scene](app/src/main/java/com/example/nav3recipes/scenes/listdetail)**: Shows how to create a custom, list-detail layout using a `Scene` and `SceneStrategy` (see video of UI behavior below).\n- **[Two pane Scene](app/src/main/java/com/example/nav3recipes/scenes/twopane)**: Shows how to create a custom, 2-pane layout.\n- **[BottomSheet](app/src/main/java/com/example/nav3recipes/bottomsheet)**: Shows how to create a BottomSheet destination.\n- **[Dialog](app/src/main/java/com/example/nav3recipes/dialog)**: Shows how to create a Dialog.\n\n### Material adaptive layouts\nExamples showing how to use the layouts provided by the [Compose Material3 Adaptive Navigation3 library](https://developer.android.com/jetpack/androidx/releases/compose-material3-adaptive#compose_material3_adaptive_navigation3_version_10_2)\n- **[List-Detail](app/src/main/java/com/example/nav3recipes/material/listdetail)**: Shows how to use a Material adaptive list-detail layout.\n- **[Supporting Pane](app/src/main/java/com/example/nav3recipes/material/supportingpane)**: Shows how to use a Material adaptive supporting pane layout.\n\nNote: If you find a bug or have a feature request for Material3 Adaptive Scenes [please file it here](https://issuetracker.google.com/issues/new?component=1467081). Don't file an issue on this repository.\n\n### Animations\n- **[Animations](app/src/main/java/com/example/nav3recipes/animations)**: Shows how to override the default animations for all destinations and a single destination.\n\n### Common use cases\n- **[Common navigation UI](app/src/main/java/com/example/nav3recipes/commonui)**: A common navigation toolbar where each item in the toolbar navigates to a top level destination.  \n- **[Multiple back stacks](app/src/main/java/com/example/nav3recipes/multiplestacks)**: Shows how to create multiple top level routes, each with its own back stack. Top level routes are displayed in a navigation bar allowing users to switch between them. State is retained for each top level route, and the navigation state persists config changes and process death.  \n- **[Conditional navigation](app/src/main/java/com/example/nav3recipes/conditional)**: Switch to a different navigation flow when a condition is met. For example, for authentication or first-time user onboarding.\n\n### Architecture\n- **[Hilt - Modularized navigation code](app/src/main/java/com/example/nav3recipes/modular/hilt)**: Demonstrates how to decouple navigation code into separate modules (uses Dagger/Hilt for DI). \n- **[Koin - Modularized navigation code](app/src/main/java/com/example/nav3recipes/modular/koin)**: Demonstrates how to decouple navigation code into separate modules (uses Koin for DI).\n\n### Passing navigation arguments to ViewModels\n- **[Basic ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/basic)**: Navigation arguments are passed to a ViewModel constructed using `viewModel()`\n- **[Hilt injected ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/hilt)**: Navigation arguments are passed to a ViewModel constructed using `hiltViewModel()`\n- **[Koin injected ViewModel](app/src/main/java/com/example/nav3recipes/passingarguments/viewmodels/koin)**: Navigation arguments are passed to a ViewModel constructed using `koinViewModel()`\n\n### Returning Results\n- **[Returning Results as Events](app/src/main/java/com/example/nav3recipes/results/event)**: Returning results as events to content in another NavEntry.\n- **[Returning Results as State](app/src/main/java/com/example/nav3recipes/results/state)**: Returning results as state stored in a CompositionLocal.\n\n### Future recipes\nThe most upvoted [recipe requests]([url](https://github.com/android/nav3-recipes/issues?q=is%3Aissue%20state%3Aopen%20label%3Arecipe-request)) will be considered for implementation. Don't see your recipe? [File a request for one here](https://github.com/android/nav3-recipes/issues/new?template=1-recipe-request.md)\n\n## Custom layout example\nThe following is a screen recording showing the navigation behavior of a [custom, list-detail Scene](app/src/main/java/com/example/nav3recipes/scenes/listdetail).\n\n![Custom layout example](/docs/images/ListDetailScene.gif)\n\n## Instructions\nClone this repository and open the root folder in [Android Studio](https://developer.android.com/studio). Each recipe is contained in its own package with its own `Activity`.\n\n## Found an issue?\nIf the issue is _directly related to this project_, as in, it's reproducible without modifying this project's source code, then please [file an issue on github](https://github.com/android/nav3-recipes/issues/new?template=2-bug-report.md). If you've found an issue with the Jetpack Navigation 3 library, please [file an issue on the issue tracker](https://issuetracker.google.com/issues/new?component=1750212&template=2102223).\n\n## Contributing\nWe'd love to accept your contributions. Please follow [these instructions](CONTRIBUTING.md).\n\n## Compose Multiplatform Recipes\nCMP recipes can be found [here](https://github.com/terrakok/nav3-recipes).\n\n## License\n```\nCopyright 2025 The Android Open Source Project\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    https://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n",
      "stars_today": 2
    },
    {
      "id": 32578467,
      "name": "Charts",
      "full_name": "ChartsOrg/Charts",
      "description": "Beautiful charts for iOS/tvOS/OSX! The Apple side of the crossplatform MPAndroidChart.",
      "html_url": "https://github.com/ChartsOrg/Charts",
      "stars": 28004,
      "forks": 6042,
      "language": "Swift",
      "topics": [],
      "created_at": "2015-03-20T10:49:12Z",
      "updated_at": "2026-01-15T11:43:59Z",
      "pushed_at": "2025-05-13T04:45:38Z",
      "open_issues": 991,
      "owner": {
        "login": "ChartsOrg",
        "avatar_url": "https://avatars.githubusercontent.com/u/79675592?v=4"
      },
      "readme": "**Version 4.0.0**, synced to [MPAndroidChart #f6a398b](https://github.com/PhilJay/MPAndroidChart/commit/f6a398b)\n\n![alt tag](https://raw.github.com/danielgindi/Charts/master/Assets/feature_graphic.png)\n![Supported Platforms](https://img.shields.io/cocoapods/p/Charts.svg) [![Releases](https://img.shields.io/github/release/danielgindi/Charts.svg)](https://github.com/danielgindi/Charts/releases) [![Latest pod release](https://img.shields.io/cocoapods/v/Charts.svg)](http://cocoapods.org/pods/charts) [![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage) [![Build Status](https://travis-ci.org/danielgindi/Charts.svg?branch=master)](https://travis-ci.org/danielgindi/Charts) [![codecov](https://codecov.io/gh/danielgindi/Charts/branch/master/graph/badge.svg)](https://codecov.io/gh/danielgindi/Charts)\n[![Join the chat at https://gitter.im/danielgindi/Charts](https://badges.gitter.im/danielgindi/Charts.svg)](https://gitter.im/danielgindi/Charts?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n### Just a heads up: Charts 5.0 has some breaking changes. Charts has now been renamed DGCharts to prevent conflicts with Apple's new Swift Charts. Please read [the release/migration notes](https://github.com/danielgindi/Charts/releases/tag/5.0.0).\n\n### One more heads up: As Swift evolves, if you are not using the latest Swift compiler, you shouldn't check out the master branch. Instead, you should go to the release page and pick up whatever suits you.\n\n- Xcode 14 / Swift 5.7 (master branch)\n- iOS >= 12.0 (Use as an **Embedded** Framework)\n- tvOS >= 12.0\n- macOS >= 10.13\n\nOkay so there's this beautiful library called [MPAndroidChart](https://github.com/PhilJay/MPAndroidChart) by [Philipp Jahoda](https://www.linkedin.com/in/philippjahoda) which has become very popular amongst Android developers, but there was no decent solution to create charts for iOS.\n\nI've chosen to write it in `Swift` as it can be highly optimized by the compiler, and can be used in both `Swift` and `ObjC` project. The demo project is written in `ObjC` to demonstrate how it works.\n\n**An amazing feature** of this library now, for Android, iOS, tvOS and macOS, is the time it saves you when developing for both platforms, as the learning curve is singleton- it happens only once, and the code stays very similar so developers don't have to go around and re-invent the app to produce the same output with a different library. (And that's not even considering the fact that there's not really another good choice out there currently...)\n\n## Having trouble running the demo?\n\n- `ChartsDemo/ChartsDemo.xcodeproj` is the demo project for iOS/tvOS\n- `ChartsDemo-OSX/ChartsDemo-OSX.xcodeproj` is the demo project for macOS\n- Make sure you are running a supported version of Xcode.\n  - Usually it is specified here a few lines above.\n  - In most cases it will be the latest Xcode version.\n- Make sure that your project supports Swift 5.0\n- Optional: Run `carthage checkout` in the project folder, to fetch dependencies (i.e testing dependencies).\n  - If you don't have Carthage - you can get it [here](https://github.com/Carthage/Carthage/releases).\n\n## Usage\n\nIn order to correctly compile:\n\n1. Drag the `DGCharts.xcodeproj` to your project\n2. Go to your target's settings, hit the \"+\" under the \"Frameworks, Libraries, and Embedded Content\" section, and select the DGCharts.framework\n3. `@import DGCharts`\n4. When using Swift in an ObjC project:\n\n- You need to import your Bridging Header. Usually it is \"_YourProject-Swift.h_\", so in ChartsDemo it's \"_ChartsDemo-Swift.h_\". Do not try to actually include \"_ChartsDemo-Swift.h_\" in your project :-)\n- (Xcode 8.1 and earlier) Under \"Build Options\", mark \"Embedded Content Contains Swift Code\"\n- (Xcode 8.2+) Under \"Build Options\", mark \"Always Embed Swift Standard Libraries\"\n\n5. When using [Realm.io](https://realm.io/):\n   - Note that the Realm framework is not linked with Charts - it is only there for _optional_ bindings. Which means that you need to have the framework in your project, and in a compatible version to whatever is compiled with DGCharts. We will do our best to always compile against the latest version.\n   - You'll need to add `ChartsRealm` as a dependency too.\n\n## 3rd party tutorials\n\n#### Video tutorials\n\n- [Chart in Swift - Setting Up a Basic Line Chart Using iOS Charts(Alex Nagy)](https://www.youtube.com/watch?v=mWhwe_tLNE8&list=PL_csAAO9PQ8bjzg-wxEff1Fr0Y5W1hrum&index=5)\n- [Charts Framework in SwiftUI - Bar Chart (Stewart Lynch)](https://youtu.be/csd7pyfEXgw)\n\n#### Blog posts\n\n- [Using Realm and Charts with Swift 3 in iOS 10 (Sami Korpela)](https://medium.com/@skoli/using-realm-and-charts-with-swift-3-in-ios-10-40c42e3838c0#.2gyymwfh8)\n- [Creating a Line Chart in Swift 3 and iOS 10 (Osian Smith)](https://medium.com/@OsianSmith/creating-a-line-chart-in-swift-3-and-ios-10-2f647c95392e)\n- [Beginning Set-up and Example Using Charts with Swift 3](https://github.com/annalizhaz/ChartsForSwiftBasic)\n- [Creating a Radar Chart in Swift (David Piper)](https://medium.com/@HeyDaveTheDev/creating-a-radar-chart-in-swift-5791afcf92f0)\n- [Plotting in IOS using Charts framework with SwiftUI (Evgeny Basisty)](https://medium.com/@zzzzbh/plotting-in-ios-using-charts-framework-with-swiftui-222034a2bea6)\n- [Set Up a Basic Bar Chart Using iOS-Charts (Penny Huang)](https://medium.com/@penny-huang/swift-setting-up-a-basic-bar-chart-using-ios-charts-afd6aad96ac)\n- [iOS-Charts Tutorial: Highlight Selected Value With a Custom Marker (Penny Huang)](https://medium.com/@penny-huang/swift-ios-charts-tutorial-highlight-selected-value-with-a-custom-marker-30ccbf92aa1b)\n- [Drawing Charts in iOS Before SwiftUI (Gennady Stepanov)](https://medium.com/better-programming/drawing-charts-in-ios-before-swiftui-9f95b8612607)\n\nWant your tutorial to show here? Create a PR!\n\n## Troubleshooting\n\n#### Can't compile?\n\n- Please note the difference between installing a compiled framework from CocoaPods or Carthage, and copying the source code.\n- Please read the **Usage** section again.\n- Search in the issues\n- Try to politely ask in the issues section\n\n#### Other problems / feature requests\n\n- Search in the issues\n- Try to politely ask in the issues section\n\n## CocoaPods Install\n\nAdd `pod 'DGCharts'` to your Podfile. \"DGCharts\" is the name of the library.  \nFor [Realm](https://realm.io/) support, please add `pod 'ChartsRealm'` too.\n\n**Note:** ~~`pod 'ios-charts'`~~ is not the correct library, and refers to a different project by someone else.\n\n## Carthage Install\n\nDGCharts now include Carthage prebuilt binaries.\n\n```carthage\ngithub \"danielgindi/Charts\" == 5.1.0\ngithub \"danielgindi/Charts\" ~> 5.1.0\n```\n\nIn order to build the binaries for a new release, use `carthage build --no-skip-current && carthage archive Charts`.\n\n## Swift Package Manager Install\n\nSwift Package Manager\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/danielgindi/Charts.git\", .upToNextMajor(from: \"5.1.0\"))\n]\n```\n\n## 3rd party bindings\n\nXamarin (by @Flash3001): _iOS_ - [GitHub](https://github.com/Flash3001/iOSCharts.Xamarin)/[NuGet](https://www.nuget.org/packages/iOSCharts/). _Android_ - [GitHub](https://github.com/Flash3001/MPAndroidChart.Xamarin)/[NuGet](https://www.nuget.org/packages/MPAndroidChart/).\n\n## Help\n\nIf you like what you see here, and want to support the work being done in this repository, you could:\n\n- Contribute code, issues and pull requests\n- Let people know this library exists (:fire: spread the word :fire:)\n- [![Donate](https://www.paypalobjects.com/en_US/i/btn/btn_donate_LG.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=68UL6Y8KUPS96) (You can buy me a beer, or you can buy me dinner :-)\n\n**Note:** The author of [MPAndroidChart](https://github.com/PhilJay/MPAndroidChart) is the reason that this library exists, and is accepting [donations](https://github.com/PhilJay/MPAndroidChart#donations) on his page. He deserves them!\n\n## Questions & Issues\n\nIf you are having questions or problems, you should:\n\n- Make sure you are using the latest version of the library. Check the [**release-section**](https://github.com/danielgindi/Charts/releases).\n- Study the Android version's [**Documentation-Wiki**](https://github.com/PhilJay/MPAndroidChart/wiki)\n- Search or open questions on [**stackoverflow**](http://stackoverflow.com/questions/tagged/ios-charts) with the `ios-charts` tag\n- Search [**known issues**](https://github.com/danielgindi/Charts/issues) for your problem (open and closed)\n- Create new issues (please :fire: **search known issues before** :fire:, do not create duplicate issues)\n\n# Features\n\n**Core features:**\n\n- 8 different chart types\n- Scaling on both axes (with touch-gesture, axes separately or pinch-zoom)\n- Dragging / Panning (with touch-gesture)\n- Combined-Charts (line-, bar-, scatter-, candle-stick-, bubble-)\n- Dual (separate) Axes\n- Customizable Axes (both x- and y-axis)\n- Highlighting values (with customizable popup-views)\n- Save chart to camera-roll / export to PNG/JPEG\n- Predefined color templates\n- Legends (generated automatically, customizable)\n- Animations (build up animations, on both x- and y-axis)\n- Limit lines (providing additional information, maximums, ...)\n- Fully customizable (paints, typefaces, legends, colors, background, gestures, dashed lines, ...)\n- Plotting data directly from [**Realm.io**](https://realm.io) mobile database ([here](https://github.com/danielgindi/ChartsRealm))\n\n**Chart types:**\n\n_Screenshots are currently taken from the original repository, as they render exactly the same :-)_\n\n- **LineChart (with legend, simple design)**\n  ![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/simpledesign_linechart4.png)\n- **LineChart (with legend, simple design)**\n  ![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/simpledesign_linechart3.png)\n\n- **LineChart (cubic lines)**\n  ![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/cubiclinechart.png)\n\n- **LineChart (gradient fill)**\n  ![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/line_chart_gradient.png)\n\n- **Combined-Chart (bar- and linechart in this case)**\n  ![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/combined_chart.png)\n\n- **BarChart (with legend, simple design)**\n\n![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/simpledesign_barchart3.png)\n\n- **BarChart (grouped DataSets)**\n\n![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/groupedbarchart.png)\n\n- **Horizontal-BarChart**\n\n![alt tag](https://raw.github.com/PhilJay/MPChart/master/screenshots/horizontal_barchart.png)\n\n- **PieChart (with selection, ...)**\n\n![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/simpledesign_piechart1.png)\n\n- **ScatterChart** (with squares, triangles, circles, ... and more)\n\n![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/scatterchart.png)\n\n- **CandleStickChart** (for financial data)\n\n![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/candlestickchart.png)\n\n- **BubbleChart** (area covered by bubbles indicates the value)\n\n![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/bubblechart.png)\n\n- **RadarChart** (spider web chart)\n\n![alt tag](https://raw.github.com/PhilJay/MPAndroidChart/master/screenshots/radarchart.png)\n\n# Documentation\n\nCurrently there's no need for documentation for the iOS/tvOS/macOS version, as the API is **95% the same** as on Android.  \nYou can read the official [MPAndroidChart](https://github.com/PhilJay/MPAndroidChart) documentation here: [**Wiki**](https://github.com/PhilJay/MPAndroidChart/wiki)\n\nOr you can see the Charts Demo project in both Objective-C and Swift ([**ChartsDemo-iOS**](https://github.com/danielgindi/Charts/tree/master/ChartsDemo-iOS), as well as macOS [**ChartsDemo-macOS**](https://github.com/danielgindi/Charts/tree/master/ChartsDemo-macOS)) and learn the how-tos from it.\n\n# Special Thanks\n\nGoes to [@liuxuan30](https://github.com/liuxuan30), [@petester42](https://github.com/petester42) and [@AlBirdie](https://github.com/AlBirdie) for new features, bugfixes, and lots and lots of involvement in our open-sourced community! You guys are a huge help to all of those coming here with questions and issues, and I couldn't respond to all of those without you.\n\n### Our amazing sponsors\n\n[Debricked](https://debricked.com/): Use open source securely\n\n[![debricked](https://user-images.githubusercontent.com/4375169/73585544-25bfa800-44dd-11ea-9661-82519a125302.jpg)](https://debricked.com/)\n\n# License\n\nCopyright 2016 Daniel Cohen Gindi & Philipp Jahoda\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n",
      "stars_today": 1
    },
    {
      "id": 33486016,
      "name": "Kingfisher",
      "full_name": "onevcat/Kingfisher",
      "description": "A lightweight, pure-Swift library for downloading and caching images from the web.",
      "html_url": "https://github.com/onevcat/Kingfisher",
      "stars": 24237,
      "forks": 2746,
      "language": "Swift",
      "topics": [
        "cache",
        "filters",
        "image",
        "image-processor",
        "ios",
        "kingfisher",
        "macos",
        "swift",
        "xcode"
      ],
      "created_at": "2015-04-06T14:26:21Z",
      "updated_at": "2026-01-14T19:43:30Z",
      "pushed_at": "2026-01-05T14:19:51Z",
      "open_issues": 173,
      "owner": {
        "login": "onevcat",
        "avatar_url": "https://avatars.githubusercontent.com/u/1019875?v=4"
      },
      "readme": "<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/onevcat/Kingfisher/master/images/logo.png\" alt=\"Kingfisher\" title=\"Kingfisher\" width=\"557\"/>\n</p>\n\n<p align=\"center\">\n<a href=\"https://github.com/onevcat/Kingfisher/actions?query=workflow%3Abuild\"><img src=\"https://github.com/onevcat/kingfisher/workflows/build/badge.svg?branch=master\"></a>\n<a href=\"https://swiftpackageindex.com/onevcat/Kingfisher/master/documentation/kingfisher\"><img src=\"https://img.shields.io/badge/Swift-Doc-DE5C43.svg?style=flat\"></a>\n<a href=\"https://cocoapods.org/pods/Kingfisher\"><img src=\"https://img.shields.io/github/v/tag/onevcat/Kingfisher.svg?color=blue&include_prereleases=&sort=semver\"></a>\n<a href=\"https://swift.org/package-manager/\"><img src=\"https://img.shields.io/badge/SPM-supported-DE5C43.svg?style=flat\"></a>\n<a href=\"https://raw.githubusercontent.com/onevcat/Kingfisher/master/LICENSE\"><img src=\"https://img.shields.io/badge/license-MIT-black\"></a>\n</p>\n\nKingfisher is a powerful, pure-Swift library for downloading and caching images from the web. It provides you a chance to use a pure-Swift way to work with remote images in your next app.\n\n## Features\n\n- [x] Asynchronous image downloading and caching.\n- [x] Loading image from either `URLSession`-based networking or local provided data.\n- [x] Useful image processors and filters provided.\n- [x] Multiple-layer hybrid cache for both memory and disk.\n- [x] Fine control on cache behavior. Customizable expiration date and size limit.\n- [x] Cancelable downloading and auto-reusing previous downloaded content to improve performance.\n- [x] Independent components. Use the downloader, caching system, and image processors separately as you need.\n- [x] Prefetching images and showing them from the cache to boost your app.\n- [x] Extensions for `UIImageView`, `NSImageView`, `NSButton`, `UIButton`, `NSTextAttachment`, `WKInterfaceImage`, `TVMonogramView` and `CPListItem` to directly set an image from a URL.\n- [x] Built-in transition animation when setting images.\n- [x] Customizable placeholder and indicator while loading images.\n- [x] Extensible image processing and image format easily.\n- [x] Low Data Mode support.\n- [x] SwiftUI support.\n- [x] Swift 6 & Swift Concurrency (strict mode) prepared.\n- [x] Load & cache for Live Photo.\n\n### Kingfisher 101\n\nThe simplest use-case is setting an image to an image view with the `UIImageView` extension:\n\n```swift\nimport Kingfisher\n\nlet url = URL(string: \"https://example.com/image.png\")\nimageView.kf.setImage(with: url)\n```\n\nKingfisher will download the image from `url`, send it to both memory cache and disk cache, and display it in `imageView`. \nWhen you set it with the same URL later, the image will be retrieved from the cache and shown immediately.\n\nIt also works if you use SwiftUI:\n\n```swift\nvar body: some View {\n    KFImage(URL(string: \"https://example.com/image.png\")!)\n}\n```\n\n### A More Advanced Example\n\nWith the powerful options, you can do hard tasks with Kingfisher in a simple way. For example, the code below: \n\n1. Downloads a high-resolution image.\n2. Downsamples it to match the image view size.\n3. Makes it round cornered with a given radius.\n4. Shows a system indicator and a placeholder image while downloading.\n5. When prepared, it animates the small thumbnail image with a \"fade in\" effect. \n6. The original large image is also cached to disk for later use, to get rid of downloading it again in a detail view.\n7. A console log is printed when the task finishes, either for success or failure.\n\n```swift\nlet url = URL(string: \"https://example.com/high_resolution_image.png\")\nlet processor = DownsamplingImageProcessor(size: imageView.bounds.size)\n             |> RoundCornerImageProcessor(cornerRadius: 20)\nimageView.kf.indicatorType = .activity\nimageView.kf.setImage(\n    with: url,\n    placeholder: UIImage(named: \"placeholderImage\"),\n    options: [\n        .processor(processor),\n        .scaleFactor(UIScreen.main.scale),\n        .transition(.fade(1)),\n        .cacheOriginalImage\n    ])\n{\n    result in\n    switch result {\n    case .success(let value):\n        print(\"Task done for: \\(value.source.url?.absoluteString ?? \"\")\")\n    case .failure(let error):\n        print(\"Job failed: \\(error.localizedDescription)\")\n    }\n}\n```\n\nIt is a common situation I can meet in my daily work. Think about how many lines you need to write without\nKingfisher!\n\n### Method Chaining\n\nIf you are not a fan of the `kf` extension, you can also prefer to use the `KF` builder and chained the method \ninvocations. The code below is doing the same thing:\n\n```swift\n// Use `kf` extension\nimageView.kf.setImage(\n    with: url,\n    placeholder: placeholderImage,\n    options: [\n        .processor(processor),\n        .loadDiskFileSynchronously,\n        .cacheOriginalImage,\n        .transition(.fade(0.25)),\n        .lowDataMode(.network(lowResolutionURL))\n    ],\n    progressBlock: { receivedSize, totalSize in\n        // Progress updated\n    },\n    completionHandler: { result in\n        // Done\n    }\n)\n\n// Use `KF` builder\nKF.url(url)\n  .placeholder(placeholderImage)\n  .setProcessor(processor)\n  .loadDiskFileSynchronously()\n  .cacheMemoryOnly()\n  .fade(duration: 0.25)\n  .lowDataModeSource(.network(lowResolutionURL))\n  .onProgress { receivedSize, totalSize in  }\n  .onSuccess { result in  }\n  .onFailure { error in }\n  .set(to: imageView)\n```\n\nAnd even better, if later you want to switch to SwiftUI, just change the `KF` above to `KFImage`, and you've done:\n\n```swift\nstruct ContentView: View {\n    var body: some View {\n        KFImage.url(url)\n          .placeholder(placeholderImage)\n          .setProcessor(processor)\n          .loadDiskFileSynchronously()\n          .cacheMemoryOnly()\n          .fade(duration: 0.25)\n          .lowDataModeSource(.network(lowResolutionURL))\n          .onProgress { receivedSize, totalSize in  }\n          .onSuccess { result in  }\n          .onFailure { error in }\n    }\n}\n```\n\n## Requirements\n\n### Kingfisher 8.0\n\n- (UIKit/AppKit) iOS 13.0+ / macOS 10.15+ / tvOS 13.0+ / watchOS 6.0+ / visionOS 1.0+\n- (SwiftUI) iOS 14.0+ / macOS 11.0+ / tvOS 14.0+ / watchOS 7.0+ / visionOS 1.0+\n- Swift 5.9+\n\n### Kingfisher 7.0\n\n- (UIKit/AppKit) iOS 12.0+ / macOS 10.14+ / tvOS 12.0+ / watchOS 5.0+ / visionOS 1.0+\n- (SwiftUI) iOS 14.0+ / macOS 11.0+ / tvOS 14.0+ / watchOS 7.0+ / visionOS 1.0+\n- Swift 5.0+\n\n### Installation\n\nRefer to one of the following tutorials to install and use the framework:\n\n- [UIKit Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstarteduikit)\n- [SwiftUI Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstartedswiftui)\n\nAlternatively, you can follow either of the methods below.\n\n#### Swift Package Manager\n\n- File > Swift Packages > Add Package Dependency\n- Add `https://github.com/onevcat/Kingfisher.git`\n- Select \"Up to Next Major\" with \"8.0.0\"\n\n#### CocoaPods\n\n```ruby\nsource 'https://github.com/CocoaPods/Specs.git'\nplatform :ios, '13.0'\nuse_frameworks!\n\ntarget 'MyApp' do\n  pod 'Kingfisher', '~> 8.0'\nend\n```\n\n#### Pre-built Framework\n\n1. Open the release page, download the latest version of Kingfisher from the assets section. \n2. Drag the `Kingfisher.xcframework` into your project and add it to the target (usually the app target).\n3. Select your target, in the \"General\" Tab, find the \"Frameworks, Libraries, and Embedded Content\" section, set the `Embed Without Signing` to Kingfisher.\n\n## Documentation\n\nCheck the documentation and tutorials:\n\n- [Documentation Home](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher)\n- [Getting Started](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/gettingstarted)\n    - [UIKit Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstarteduikit)\n    - [SwiftUI Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstartedswiftui)\n- [Common Tasks - General](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks)\n    - [Common Tasks - Cache](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_cache)\n    - [Common Tasks - Downloader](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_downloader)\n    - [Common tasks - Processor](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_processor)\n\n### Migrating\n\n- [Kingfisher 8.0 Migration](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/migration-to-8)\n- [Kingfisher 7.0 Migration](https://github.com/onevcat/Kingfisher/wiki/Kingfisher-7.0-Migration-Guide)\n\nIf you are using an even earlier version, see the guides below to know the steps for migrating.\n\n## Other\n\n### Future of Kingfisher\n\nI want to keep Kingfisher lightweight. This framework focuses on providing a simple solution for downloading and caching images. This doesnâ€™t mean the framework canâ€™t be improved. Kingfisher is far from perfect, so necessary and useful updates will be made to make it better.\n\n### Developments and Tests\n\nAny contributing and pull requests are warmly welcome. However, before you plan to implement some features or try to fix an uncertain issue, it is recommended to open a discussion first. It would be appreciated if your pull requests could build with all tests green. :)\n\n### About the logo\n\nThe logo of Kingfisher is inspired by [Tangram (ä¸ƒå·§æ¿)](http://en.wikipedia.org/wiki/Tangram), a dissection puzzle consisting of seven flat shapes from China. I believe she's a kingfisher bird instead of a swift, but someone insists that she is a pigeon. I guess I should give her a name. Hi, guys, do you have any suggestions?\n\n### Contact\n\nFollow and contact me on [Twitter](http://twitter.com/onevcat) or [Sina Weibo](http://weibo.com/onevcat). If you find an issue, [open a ticket](https://github.com/onevcat/Kingfisher/issues/new). Pull requests are warmly welcome as well.\n\n## Backers & Sponsors\n\nOpen-source projects cannot live long without your help. If you find Kingfisher to be useful, please consider supporting this \nproject by becoming a sponsor. Your user icon or company logo shows up [on my blog](https://onevcat.com/tabs/about/) with a link to your home page. \n\nBecome a sponsor through [GitHub Sponsors](https://github.com/sponsors/onevcat). :heart:\n\nSpecial thanks to:\n\n[![imgly](https://user-images.githubusercontent.com/1812216/106253726-271ed000-6218-11eb-98e0-c9c681925770.png)](https://img.ly/)\n\n[![emergetools](https://github-production-user-asset-6210df.s3.amazonaws.com/1019875/254794187-d44f6f50-993f-42e3-b79c-960f69c4adc1.png)](https://www.emergetools.com)\n\n\n\n### License\n\nKingfisher is released under the MIT license. See LICENSE for details.\n",
      "stars_today": 1
    },
    {
      "id": 50904245,
      "name": "beam",
      "full_name": "apache/beam",
      "description": "Apache Beam is a unified programming model for Batch and Streaming data processing.",
      "html_url": "https://github.com/apache/beam",
      "stars": 8446,
      "forks": 4481,
      "language": "Java",
      "topics": [
        "batch",
        "beam",
        "big-data",
        "golang",
        "java",
        "python",
        "sql",
        "streaming"
      ],
      "created_at": "2016-02-02T08:00:06Z",
      "updated_at": "2026-01-15T19:45:40Z",
      "pushed_at": "2026-01-15T23:41:20Z",
      "open_issues": 4183,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\n    Licensed to the Apache Software Foundation (ASF) under one\n    or more contributor license agreements.  See the NOTICE file\n    distributed with this work for additional information\n    regarding copyright ownership.  The ASF licenses this file\n    to you under the Apache License, Version 2.0 (the\n    \"License\"); you may not use this file except in compliance\n    with the License.  You may obtain a copy of the License at\n\n      http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing,\n    software distributed under the License is distributed on an\n    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n    KIND, either express or implied.  See the License for the\n    specific language governing permissions and limitations\n    under the License.\n-->\n\n# Apache Beam\n\n[Apache Beam](http://beam.apache.org/) is a unified model for defining both batch and streaming data-parallel processing pipelines, as well as a set of language-specific SDKs for constructing pipelines and Runners for executing them on distributed processing backends, including [Apache Flink](http://flink.apache.org/), [Apache Spark](http://spark.apache.org/), [Google Cloud Dataflow](http://cloud.google.com/dataflow/), and [Hazelcast Jet](https://hazelcast.com/).\n\n## Status\n\n[![Maven Version](https://maven-badges.herokuapp.com/maven-central/org.apache.beam/beam-sdks-java-core/badge.svg)](http://search.maven.org/#search|gav|1|g:\"org.apache.beam\")\n[![PyPI version](https://badge.fury.io/py/apache-beam.svg)](https://badge.fury.io/py/apache-beam)\n[![Go version](https://pkg.go.dev/badge/github.com/apache/beam/sdks/v2/go.svg)](https://pkg.go.dev/github.com/apache/beam/sdks/v2/go)\n[![Python coverage](https://codecov.io/gh/apache/beam/branch/master/graph/badge.svg)](https://codecov.io/gh/apache/beam)\n[![Build python source distribution and wheels](https://github.com/apache/beam/actions/workflows/build_wheels.yml/badge.svg?event=schedule&&?branch=master)](https://github.com/apache/beam/actions?query=workflow%3A%22Build+python+source+distribution+and+wheels%22+branch%3Amaster+event%3Aschedule)\n[![Python tests](https://github.com/apache/beam/actions/workflows/python_tests.yml/badge.svg?event=schedule&&?branch=master)](https://github.com/apache/beam/actions?query=workflow%3A%22Python+Tests%22+branch%3Amaster+event%3Aschedule)\n[![Java tests](https://github.com/apache/beam/actions/workflows/java_tests.yml/badge.svg?event=schedule&&?branch=master)](https://github.com/apache/beam/actions?query=workflow%3A%22Java+Tests%22+branch%3Amaster+event%3Aschedule)\n[![Go tests](https://github.com/apache/beam/actions/workflows/go_tests.yml/badge.svg?event=schedule&&?branch=master)](https://github.com/apache/beam/actions?query=workflow%3A%22Go+Tests%22+branch%3Amaster+event%3Aschedule)\n\n## Overview\n\nBeam provides a general approach to expressing [embarrassingly parallel](https://en.wikipedia.org/wiki/Embarrassingly_parallel) data processing pipelines and supports three categories of users, each of which have relatively disparate backgrounds and needs.\n\n1. _End Users_: Writing pipelines with an existing SDK, running it on an existing runner. These users want to focus on writing their application logic and have everything else just work.\n2. _SDK Writers_: Developing a Beam SDK targeted at a specific user community (Java, Python, Scala, Go, R, graphical, etc). These users are language geeks and would prefer to be shielded from all the details of various runners and their implementations.\n3. _Runner Writers_: Have an execution environment for distributed processing and would like to support programs written against the Beam Model. Would prefer to be shielded from details of multiple SDKs.\n\n### The Beam Model\n\nThe model behind Beam evolved from several internal Google data processing projects, including [MapReduce](http://research.google.com/archive/mapreduce.html), [FlumeJava](http://research.google.com/pubs/pub35650.html), and [Millwheel](http://research.google.com/pubs/pub41378.html). This model was originally known as the â€œ[Dataflow Model](http://www.vldb.org/pvldb/vol8/p1792-Akidau.pdf)â€.\n\nTo learn more about the Beam Model (though still under the original name of Dataflow), see the World Beyond Batch: [Streaming 101](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101) and [Streaming 102](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-102) posts on Oâ€™Reillyâ€™s Radar site, and the [VLDB 2015 paper](http://www.vldb.org/pvldb/vol8/p1792-Akidau.pdf).\n\nThe key concepts in the Beam programming model are:\n\n* `PCollection`: represents a collection of data, which could be bounded or unbounded in size.\n* `PTransform`: represents a computation that transforms input PCollections into output PCollections.\n* `Pipeline`: manages a directed acyclic graph of PTransforms and PCollections that is ready for execution.\n* `PipelineRunner`: specifies where and how the pipeline should execute.\n\n### SDKs\n\nBeam supports multiple language-specific SDKs for writing pipelines against the Beam Model.\n\nCurrently, this repository contains SDKs for Java, Python and Go.\n\nHave ideas for new SDKs or DSLs? See the [sdk-ideas label](https://github.com/apache/beam/issues?q=is%3Aopen+is%3Aissue+label%3Asdk-ideas).\n\n#### Specific SDK Readmes\n\n* [Python SDK readme](./sdks/python/README.md)\n\n### Runners\n\nBeam supports executing programs on multiple distributed processing backends through PipelineRunners. Currently, the following PipelineRunners are available:\n\n- The `DirectRunner` runs the pipeline on your local machine.\n- The `PrismRunner` runs the pipeline on your local machine using Beam Portability.\n- The `DataflowRunner` submits the pipeline to the [Google Cloud Dataflow](http://cloud.google.com/dataflow/).\n- The `FlinkRunner` runs the pipeline on an Apache Flink cluster. The code has been donated from [dataArtisans/flink-dataflow](https://github.com/dataArtisans/flink-dataflow) and is now part of Beam.\n- The `SparkRunner` runs the pipeline on an Apache Spark cluster.\n- The `JetRunner` runs the pipeline on a Hazelcast Jet cluster. The code has been donated from [hazelcast/hazelcast-jet](https://github.com/hazelcast/hazelcast-jet) and is now part of Beam.\n- The `Twister2Runner` runs the pipeline on a Twister2 cluster. The code has been donated from [DSC-SPIDAL/twister2](https://github.com/DSC-SPIDAL/twister2) and is now part of Beam.\n\nHave ideas for new Runners? See the [runner-ideas label](https://github.com/apache/beam/issues?q=is%3Aopen+is%3Aissue+label%3Arunner-ideas).\n\n\nInstructions for building and testing Beam itself\nare in the [contribution guide](./CONTRIBUTING.md).\n\n## ğŸ“š Learn More\n\nHere are some resources actively maintained by the Beam community to help you get started:\n<table>\n<thead>\n  <tr>\n      <th><b>Resource</b></th>\n      <th><b>Details</b></th>\n  </tr>\n</thead>\n<tbody>\n  <tr>\n    <td><a href=\"https://beam.apache.org\" target=\"_blank\" rel=\"noopener noreferrer\">Apache Beam Website</a></td>\n    <td>Our website discussing the project, and it's specifics.</td>\n  </tr>\n  <tr>\n    <td><a href=\"https://beam.apache.org/get-started/quickstart-java\" target=\"_blank\" rel=\"noopener noreferrer\">Java Quickstart</a></td>\n    <td>A guide to getting started with the Java SDK.</td>\n  </tr>\n  <tr>\n    <td><a href=\"https://beam.apache.org/get-started/quickstart-py\" target=\"_blank\" rel=\"noopener noreferrer\">Python Quickstart</a></td>\n    <td>A guide to getting started with the Python SDK.</td>\n  </tr>\n  <tr>\n    <td><a href=\"https://beam.apache.org/get-started/quickstart-go\" target=\"_blank\" rel=\"noopener noreferrer\">Go Quickstart </a></td>\n    <td>A guide to getting started with the Go SDK.</td>\n  </tr>\n  <tr>\n    <td><a href=\"https://tour.beam.apache.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Tour of Beam </a></td>\n    <td>A comprehensive, interactive learning experience covering Beam concepts in depth.</td>\n  </tr>\n  <tr>\n    <td><a href=\"https://www.cloudskillsboost.google/course_templates/724\" target=\"_blank\" rel=\"noopener noreferrer\">Beam Quest </a></td>\n    <td>A certification granted by Google Cloud, certifying proficiency in Beam.</td>\n  </tr>\n  <tr>\n    <td><a href=\"https://metrics.beam.apache.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Community Metrics </a></td>\n    <td>Beam's Git Community Metrics.</td>\n  </tr>\n</tbody>\n</table>\n\n## Contact Us\n\nTo get involved with Apache Beam:\n\n* [Subscribe to](https://beam.apache.org/community/contact-us/#:~:text=Subscribe%20and%20Unsubscribe) or e-mail the [user@beam.apache.org](http://mail-archives.apache.org/mod_mbox/beam-user/) list.\n* [Subscribe to](https://beam.apache.org/community/contact-us/#:~:text=Subscribe%20and%20Unsubscribe) or e-mail the [dev@beam.apache.org](http://mail-archives.apache.org/mod_mbox/beam-dev/) list.\n* [Join ASF Slack](https://s.apache.org/slack-invite) on [#beam channel](https://s.apache.org/beam-slack-channel)\n* [Report an issue](https://github.com/apache/beam/issues/new/choose).\n",
      "stars_today": 1
    },
    {
      "id": 206444,
      "name": "hive",
      "full_name": "apache/hive",
      "description": "Apache Hive",
      "html_url": "https://github.com/apache/hive",
      "stars": 5983,
      "forks": 4789,
      "language": "Java",
      "topics": [
        "apache",
        "big-data",
        "database",
        "hadoop",
        "hive",
        "java",
        "sql"
      ],
      "created_at": "2009-05-21T02:31:01Z",
      "updated_at": "2026-01-15T16:25:54Z",
      "pushed_at": "2026-01-15T09:11:02Z",
      "open_issues": 48,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\n{% comment %}\nLicensed to the Apache Software Foundation (ASF) under one or more\ncontributor license agreements.  See the NOTICE file distributed with\nthis work for additional information regarding copyright ownership.\nThe ASF licenses this file to you under the Apache License, Version 2.0\n(the \"License\"); you may not use this file except in compliance with\nthe License.  You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n{% endcomment %}\n-->\nApache Hive (TM)\n================\n[![Master Build Status](https://travis-ci.org/apache/hive.svg?branch=master)](https://travis-ci.org/apache/hive/branches)\n[![Maven Central](https://maven-badges.herokuapp.com/maven-central/org.apache.hive/hive/badge.svg)](http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.apache.hive%22)\n\nThe Apache Hive (TM) data warehouse software facilitates reading,\nwriting, and managing large datasets residing in distributed storage\nusing SQL. Built on top of Apache Hadoop (TM), it provides:\n\n* Tools to enable easy access to data via SQL, thus enabling data\n  warehousing tasks such as extract/transform/load (ETL), reporting,\n  and data analysis\n\n* A mechanism to impose structure on a variety of data formats\n\n* Access to files stored either directly in Apache HDFS (TM) or in other\n  data storage systems such as Apache HBase (TM)\n\n* Query execution using Apache Tez framework, designed for interactive query, \n  and has substantially reduced overheads versus MapReduce.\n\nHive provides standard SQL functionality, including many of the later\n2003 and 2011 features for analytics.  These include OLAP functions,\nsubqueries, common table expressions, and more.  Hive's SQL can also be\nextended with user code via user defined functions (UDFs), user defined\naggregates (UDAFs), and user defined table functions (UDTFs).\n\nHive is not designed for online transaction processing. It is best used\nfor traditional data warehousing tasks where the amount of data processed \nis large enough to require a distributed system. Hive is designed to maximize\nscalability (scale out with more machines added dynamically to the Hadoop\ncluster), performance, extensibility, fault-tolerance, and\nloose-coupling with its input formats.\n\n\nGeneral Info\n============\n\nFor the latest information about Hive, please visit out website at:\n\n  http://hive.apache.org/\n\n\nGetting Started\n===============\n\n- Installation Instructions and a quick tutorial:\n  https://hive.apache.org/development/gettingstarted-latest\n  https://hive.apache.org/development/quickstart\n\n- Instructions to build Hive from source:\n  https://hive.apache.org/development/gettingstarted-latest/#building-hive-from-source\n\n- A longer tutorial that covers more features of HiveQL:\n  https://hive.apache.org/docs/latest/user/tutorial\n\n- The HiveQL Language Manual:\n  https://hive.apache.org/docs/latest/language/languagemanual\n\n\nRequirements\n============\n\nJava\n------\n\n| Hive Version  | Java Version  |\n| ------------- |:-------------:|\n| Hive 4.0.1      | Java 8        |\n| Hive 4.1.x      | Java 17        |\n| Hive 4.2.x      | Java 21        |\n\n\nHadoop\n------\n\n- Hadoop 3.x\n\n\nUpgrading from older versions of Hive\n=====================================\n\n- Hive includes changes to the MetaStore schema. If\n  you are upgrading from an earlier version of Hive it is imperative\n  that you upgrade the MetaStore schema by running the appropriate\n  schema upgrade scripts located in the scripts/metastore/upgrade\n  directory.\n\n- We have provided upgrade scripts for MySQL, PostgreSQL, Oracle,\n  Microsoft SQL Server, and Derby databases. If you are using a\n  different database for your MetaStore you will need to provide\n  your own upgrade script.\n\nUseful mailing lists\n====================\n\n1. user@hive.apache.org - To discuss and ask usage questions. Send an\n   empty email to user-subscribe@hive.apache.org in order to subscribe\n   to this mailing list.\n\n2. dev@hive.apache.org - For discussions about code, design and features.\n   Send an empty email to dev-subscribe@hive.apache.org in order to\n   subscribe to this mailing list.\n\n3. commits@hive.apache.org - In order to monitor commits to the source\n   repository. Send an empty email to commits-subscribe@hive.apache.org\n   in order to subscribe to this mailing list.\n",
      "stars_today": 1
    },
    {
      "id": 29933948,
      "name": "fluent-bit",
      "full_name": "fluent/fluent-bit",
      "description": "Fast and Lightweight Logs, Metrics and Traces processor for Linux, BSD, OSX and Windows",
      "html_url": "https://github.com/fluent/fluent-bit",
      "stars": 7568,
      "forks": 1856,
      "language": "C",
      "topics": [
        "c",
        "cloudnative",
        "data-collector",
        "fluent-bit",
        "fluentd",
        "forwarder",
        "logging",
        "logs",
        "metrics",
        "opentelemetry",
        "prometheus",
        "sql-queries",
        "stream-processing",
        "traces"
      ],
      "created_at": "2015-01-27T20:41:52Z",
      "updated_at": "2026-01-15T18:07:13Z",
      "pushed_at": "2026-01-14T08:06:41Z",
      "open_issues": 710,
      "owner": {
        "login": "fluent",
        "avatar_url": "https://avatars.githubusercontent.com/u/859518?v=4"
      },
      "readme": "# ![logo](fluentbit_logo.png)\n\n### CI Status\n\n| CI Workflow             | Status                                                                                                                                                     |\n|-------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Unit Tests (`master`)   | [![CI/Unit Tests](https://github.com/fluent/fluent-bit/actions/workflows/unit-tests.yaml/badge.svg?branch=master)](https://github.com/fluent/fluent-bit/actions/workflows/unit-tests.yaml) |\n| Integration Tests       | [![CI/Integration Tests](https://github.com/fluent/fluent-bit/actions/workflows/master-integration-test.yaml/badge.svg)](https://github.com/fluent/fluent-bit/actions/workflows/master-integration-test.yaml) |\n| Arm builds              | <a href=\"https://actuated.dev/\"><img alt=\"Arm CI sponsored by Actuated\" src=\"https://docs.actuated.dev/images/actuated-badge.png\" width=\"120px\"></img></a> |\n| Latest Release Pipeline | [![CI/Build](https://github.com/fluent/fluent-bit/actions/workflows/staging-release.yaml/badge.svg)](https://github.com/fluent/fluent-bit/actions/workflows/staging-release.yaml) |\n\n---\n\n## About\n\n[Fluent Bit](https://fluentbit.io) is a lightweight and high-performance Telemetry Agent designed to collect, process, and forward **Logs**, **Metrics**, and **Traces** from any source to any destination.\n\nIt's part of the Graduated [Fluentd](https://fluentd.org) Ecosystem and a CNCF [Cloud Native Computing Foundation](https://cncf.io) project.\n\nFluent Bit supports a wide array of platforms, including Linux, Windows, MacOS, BSD, and Embedded environments, and is built for maximum efficiency with minimal CPU and memory footprint.\n\n![](documentation/fluentbit_ecosystem.png)\n\n---\n\n## ğŸ“Œ Roadmap & Maintenance\n\nWe follow a fast-paced development cycle, with major releases every 3â€“4 months.\nThe active development branch (`master`) is currently focused on **v5.0** (development).\n\nFor version-specific maintenance timelines and policies, see our [MAINTENANCE.md](https://github.com/fluent/fluent-bit/blob/master/MAINTENANCE.md).\n\nTo track upcoming milestones, visit the [project roadmap](https://github.com/fluent/fluent-bit/wiki/Fluent-Bit-Roadmap).\n\n---\n\n## Key Features\n\n- âš¡ **High Performance** with low memory footprint\n- ğŸ“¦ **Pluggable Architecture**: 70+ built-in plugins for Inputs, Filters, and Outputs\n- ğŸ§  **SQL Stream Processing**: Perform analytics and transformations with SQL queries\n- ğŸ”’ **Secure Networking**: Built-in TLS/SSL support and async I/O\n- ğŸ“Š **Monitoring**: Expose internal metrics over HTTP/Prometheus\n- ğŸ§© **Extensibility**:\n  - Write plugins in **C**, filters in **Lua**, and outputs in **Go**\n- ğŸ”Œ **Supports Logs, Metrics, and Traces** with unified processing and delivery\n\n---\n\n## Documentation\n\nOur official documentation includes installation guides, plugin usage, developer resources, and more:\n\nğŸ“š [https://docs.fluentbit.io](https://docs.fluentbit.io)\n\n---\n\n## Quick Start\n\nBuild from source:\n\n```bash\ncd build\ncmake ..\nmake\nbin/fluent-bit -i cpu -o stdout -f 1\n```\n\nMore details: [Build & Install](https://docs.fluentbit.io/manual/installation/downloads/source/build-and-install)\n\n#### Requirements\n\n- CMake >= 3.0\n- Flex & Bison\n- YAML and OpenSSL headers\n\n---\n\n## Install Fluent Bit\n\n- [Linux packages (Debian, Ubuntu, RHEL, etc.)](https://docs.fluentbit.io/manual/installation/downloads/linux)\n- [Docker images](https://docs.fluentbit.io/manual/installation/downloads/docker)\n- [Windows binaries](https://docs.fluentbit.io/manual/installation/downloads/windows)\n\n---\n\n## Plugins: Inputs, Filters, Outputs\n\nFluent Bit is fully modular. It supports:\n\n- [Input Plugins](https://docs.fluentbit.io/manual/pipeline/inputs): collect logs/metrics/traces\n- [Filter Plugins](https://docs.fluentbit.io/manual/pipeline/filters): enrich and transform data\n- [Output Plugins](https://docs.fluentbit.io/manual/pipeline/outputs): deliver data to external services\n\nSee the full plugin list in our [documentation](https://docs.fluentbit.io/manual/pipeline/inputs).\n\n---\n\n## ğŸš€ Production Usage\n\nFluent Bit is deployed **over 10 million times daily** and has surpassed **15 billion downloads**.\n\nUsed by companies like:\n\n![users](documentation/fluentbit_users.png)\n\n> Want to add your logo? [Open an issue](https://github.com/fluent/fluent-bit/issues).\n\n---\n\n## Contributing\n\nFluent Bit is open to community contributions!\n\n- ğŸ¤ [Join our community](https://fluentbit.io/community/)\n- ğŸ›  [CONTRIBUTING.md](CONTRIBUTING.md)\n- ğŸš€ [Developer Guide](DEVELOPER_GUIDE.md)\n\n---\n\n## Community & Contact\n\n- ğŸ’¬ [Slack](http://slack.fluentd.org) (`#fluent-bit` channel)\n- ğŸ¦ [Twitter](https://twitter.com/fluentbit)\n\n---\n\n## License\n\n[Apache License v2.0](http://www.apache.org/licenses/LICENSE-2.0)\n\n---\n\n## Authors\n\nFluent Bit is a CNCF graduated project, sponsored and maintained by major cloud providers and a growing community of contributors and maintainers from across the Cloud Native ecosystem.\n\nğŸ‘‰ [See Contributors](https://github.com/fluent/fluent-bit/graphs/contributors)\n",
      "stars_today": 1
    },
    {
      "id": 6427813,
      "name": "dplyr",
      "full_name": "tidyverse/dplyr",
      "description": "dplyr: A grammar of data manipulation",
      "html_url": "https://github.com/tidyverse/dplyr",
      "stars": 4982,
      "forks": 2133,
      "language": "R",
      "topics": [
        "data-manipulation",
        "grammar",
        "r"
      ],
      "created_at": "2012-10-28T13:39:17Z",
      "updated_at": "2026-01-15T12:35:39Z",
      "pushed_at": "2025-12-19T19:01:08Z",
      "open_issues": 76,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# dplyr <a href=\"https://dplyr.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" /></a>\n\n<!-- badges: start -->\n\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/dplyr)](https://cran.r-project.org/package=dplyr)\n[![R-CMD-check](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/dplyr/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/dplyr)\n<!-- badges: end -->\n\n## Overview\n\ndplyr is a grammar of data manipulation, providing a consistent set of\nverbs that help you solve the most common data manipulation challenges:\n\n- `mutate()` adds new variables that are functions of existing variables\n- `select()` picks variables based on their names.\n- `filter()` picks cases based on their values.\n- `summarise()` reduces multiple values down to a single summary.\n- `arrange()` changes the ordering of the rows.\n\nThese all combine naturally with `group_by()` which allows you to\nperform any operation â€œby groupâ€. You can learn more about them in\n`vignette(\"dplyr\")`. As well as these single-table verbs, dplyr also\nprovides a variety of two-table verbs, which you can learn about in\n`vignette(\"two-table\")`.\n\nIf you are new to dplyr, the best place to start is the [data\ntransformation chapter](https://r4ds.hadley.nz/data-transform) in R for\nData Science.\n\n## Backends\n\nIn addition to data frames/tibbles, dplyr makes working with other\ncomputational backends accessible and efficient. Below is a list of\nalternative backends:\n\n- [arrow](https://arrow.apache.org/docs/r/) for larger-than-memory\n  datasets, including on remote cloud storage like AWS S3, using the\n  Apache Arrow C++ engine,\n  [Acero](https://arrow.apache.org/docs/cpp/acero/overview.html).\n\n- [dbplyr](https://dbplyr.tidyverse.org/) for data stored in a\n  relational database. Translates your dplyr code to SQL.\n\n- [dtplyr](https://dtplyr.tidyverse.org/) for large, in-memory datasets.\n  Translates your dplyr code to high performance\n  [data.table](https://rdatatable.gitlab.io/data.table/) code.\n\n- [duckplyr](https://duckplyr.tidyverse.org/) for large, in-memory\n  datasets. Translates your dplyr code to high performance\n  [duckdb](https://duckdb.org) queries with zero extra copies and an\n  automatic R fallback when translation isnâ€™t possible.\n\n- [sparklyr](https://spark.posit.co/) for very large datasets stored in\n  [Apache Spark](https://spark.apache.org).\n\n## Installation\n\n``` r\n# The easiest way to get dplyr is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just dplyr:\ninstall.packages(\"dplyr\")\n```\n\n### Development version\n\nTo get a bug fix or to use a feature from the development version, you\ncan install the development version of dplyr from GitHub.\n\n``` r\n# install.packages(\"pak\")\npak::pak(\"tidyverse/dplyr\")\n```\n\n## Cheat Sheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-transformation-cheatsheet-thumbs.png\" width=\"630\" height=\"252\"/></a>\n\n## Usage\n\n``` r\nlibrary(dplyr)\n\nstarwars |>\n  filter(species == \"Droid\")\n#> # A tibble: 6 Ã— 14\n#>   name   height  mass hair_color skin_color  eye_color birth_year sex   gender  \n#>   <chr>   <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr> <chr>   \n#> 1 C-3PO     167    75 <NA>       gold        yellow           112 none  masculiâ€¦\n#> 2 R2-D2      96    32 <NA>       white, blue red               33 none  masculiâ€¦\n#> 3 R5-D4      97    32 <NA>       white, red  red               NA none  masculiâ€¦\n#> 4 IG-88     200   140 none       metal       red               15 none  masculiâ€¦\n#> 5 R4-P17     96    NA none       silver, red red, blue         NA none  feminine\n#> # â„¹ 1 more row\n#> # â„¹ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  select(name, ends_with(\"color\"))\n#> # A tibble: 87 Ã— 4\n#>   name           hair_color skin_color  eye_color\n#>   <chr>          <chr>      <chr>       <chr>    \n#> 1 Luke Skywalker blond      fair        blue     \n#> 2 C-3PO          <NA>       gold        yellow   \n#> 3 R2-D2          <NA>       white, blue red      \n#> 4 Darth Vader    none       white       yellow   \n#> 5 Leia Organa    brown      light       brown    \n#> # â„¹ 82 more rows\n\nstarwars |>\n  mutate(name, bmi = mass / ((height / 100)^2)) |>\n  select(name:mass, bmi)\n#> # A tibble: 87 Ã— 4\n#>   name           height  mass   bmi\n#>   <chr>           <int> <dbl> <dbl>\n#> 1 Luke Skywalker    172    77  26.0\n#> 2 C-3PO             167    75  26.9\n#> 3 R2-D2              96    32  34.7\n#> 4 Darth Vader       202   136  33.3\n#> 5 Leia Organa       150    49  21.8\n#> # â„¹ 82 more rows\n\nstarwars |>\n  arrange(desc(mass))\n#> # A tibble: 87 Ã— 14\n#>   name      height  mass hair_color skin_color eye_color birth_year sex   gender\n#>   <chr>      <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> \n#> 1 Jabba Deâ€¦    175  1358 <NA>       green-tanâ€¦ orange         600   hermâ€¦ mascuâ€¦\n#> 2 Grievous     216   159 none       brown, whâ€¦ green, yâ€¦       NA   male  mascuâ€¦\n#> 3 IG-88        200   140 none       metal      red             15   none  mascuâ€¦\n#> 4 Darth Vaâ€¦    202   136 none       white      yellow          41.9 male  mascuâ€¦\n#> 5 Tarfful      234   136 brown      brown      blue            NA   male  mascuâ€¦\n#> # â„¹ 82 more rows\n#> # â„¹ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  group_by(species) |>\n  summarise(\n    n = n(),\n    mass = mean(mass, na.rm = TRUE)\n  ) |>\n  filter(\n    n > 1,\n    mass > 50\n  )\n#> # A tibble: 9 Ã— 3\n#>   species      n  mass\n#>   <chr>    <int> <dbl>\n#> 1 Droid        6  69.8\n#> 2 Gungan       3  74  \n#> 3 Human       35  81.3\n#> 4 Kaminoan     2  88  \n#> 5 Mirialan     2  53.1\n#> # â„¹ 4 more rows\n```\n\n## Getting help\n\nIf you encounter a clear bug, please file an issue with a minimal\nreproducible example on\n[GitHub](https://github.com/tidyverse/dplyr/issues). For questions and\nother discussion, please use [forum.posit.co](https://forum.posit.co/).\n\n## Code of conduct\n\nPlease note that this project is released with a [Contributor Code of\nConduct](https://dplyr.tidyverse.org/CODE_OF_CONDUCT). By participating\nin this project you agree to abide by its terms.\n",
      "stars_today": 1
    },
    {
      "id": 187086161,
      "name": "opentelemetry-go",
      "full_name": "open-telemetry/opentelemetry-go",
      "description": "OpenTelemetry Go API and SDK",
      "html_url": "https://github.com/open-telemetry/opentelemetry-go",
      "stars": 6238,
      "forks": 1238,
      "language": "Go",
      "topics": [
        "logging",
        "metrics",
        "opentelemetry",
        "tracing"
      ],
      "created_at": "2019-05-16T19:05:26Z",
      "updated_at": "2026-01-15T20:47:54Z",
      "pushed_at": "2026-01-15T20:28:51Z",
      "open_issues": 184,
      "owner": {
        "login": "open-telemetry",
        "avatar_url": "https://avatars.githubusercontent.com/u/49998002?v=4"
      },
      "readme": "# OpenTelemetry-Go\n\n[![ci](https://github.com/open-telemetry/opentelemetry-go/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/open-telemetry/opentelemetry-go/actions/workflows/ci.yml)\n[![codecov.io](https://codecov.io/gh/open-telemetry/opentelemetry-go/coverage.svg?branch=main)](https://app.codecov.io/gh/open-telemetry/opentelemetry-go?branch=main)\n[![PkgGoDev](https://pkg.go.dev/badge/go.opentelemetry.io/otel)](https://pkg.go.dev/go.opentelemetry.io/otel)\n[![Go Report Card](https://goreportcard.com/badge/go.opentelemetry.io/otel)](https://goreportcard.com/report/go.opentelemetry.io/otel)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/open-telemetry/opentelemetry-go/badge)](https://scorecard.dev/viewer/?uri=github.com/open-telemetry/opentelemetry-go)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9996/badge)](https://www.bestpractices.dev/projects/9996)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry-go.svg)](https://issues.oss-fuzz.com/issues?q=project:opentelemetry-go)\n[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-go.svg?type=shield&issueType=license)](https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-go?ref=badge_shield&issueType=license)\n[![Slack](https://img.shields.io/badge/slack-@cncf/otel--go-brightgreen.svg?logo=slack)](https://cloud-native.slack.com/archives/C01NPAXACKT)\n\nOpenTelemetry-Go is the [Go](https://golang.org/) implementation of [OpenTelemetry](https://opentelemetry.io/).\nIt provides a set of APIs to directly measure performance and behavior of your software and send this data to observability platforms.\n\n## Project Status\n\n| Signal  | Status             |\n|---------|--------------------|\n| Traces  | Stable             |\n| Metrics | Stable             |\n| Logs    | Beta[^1]           |\n\nProgress and status specific to this repository is tracked in our\n[project boards](https://github.com/open-telemetry/opentelemetry-go/projects)\nand\n[milestones](https://github.com/open-telemetry/opentelemetry-go/milestones).\n\nProject versioning information and stability guarantees can be found in the\n[versioning documentation](VERSIONING.md).\n\n[^1]: https://github.com/orgs/open-telemetry/projects/43\n\n### Compatibility\n\nOpenTelemetry-Go ensures compatibility with the current supported versions of\nthe [Go language](https://golang.org/doc/devel/release#policy):\n\n> Each major Go release is supported until there are two newer major releases.\n> For example, Go 1.5 was supported until the Go 1.7 release, and Go 1.6 was supported until the Go 1.8 release.\n\nFor versions of Go that are no longer supported upstream, opentelemetry-go will\nstop ensuring compatibility with these versions in the following manner:\n\n- A minor release of opentelemetry-go will be made to add support for the new\n  supported release of Go.\n- The following minor release of opentelemetry-go will remove compatibility\n  testing for the oldest (now archived upstream) version of Go. This, and\n  future, releases of opentelemetry-go may include features only supported by\n  the currently supported versions of Go.\n\nCurrently, this project supports the following environments.\n\n| OS       | Go Version | Architecture |\n|----------|------------|--------------|\n| Ubuntu   | 1.25       | amd64        |\n| Ubuntu   | 1.24       | amd64        |\n| Ubuntu   | 1.25       | 386          |\n| Ubuntu   | 1.24       | 386          |\n| Ubuntu   | 1.25       | arm64        |\n| Ubuntu   | 1.24       | arm64        |\n| macOS    | 1.25       | amd64        |\n| macOS    | 1.24       | amd64        |\n| macOS    | 1.25       | arm64        |\n| macOS    | 1.24       | arm64        |\n| Windows  | 1.25       | amd64        |\n| Windows  | 1.24       | amd64        |\n| Windows  | 1.25       | 386          |\n| Windows  | 1.24       | 386          |\n\nWhile this project should work for other systems, no compatibility guarantees\nare made for those systems currently.\n\n## Getting Started\n\nYou can find a getting started guide on [opentelemetry.io](https://opentelemetry.io/docs/languages/go/getting-started/).\n\nOpenTelemetry's goal is to provide a single set of APIs to capture distributed\ntraces and metrics from your application and send them to an observability\nplatform. This project allows you to do just that for applications written in\nGo. There are two steps to this process: instrument your application, and\nconfigure an exporter.\n\n### Instrumentation\n\nTo start capturing distributed traces and metric events from your application\nit first needs to be instrumented. The easiest way to do this is by using an\ninstrumentation library for your code. Be sure to check out [the officially\nsupported instrumentation\nlibraries](https://github.com/open-telemetry/opentelemetry-go-contrib/tree/main/instrumentation).\n\nIf you need to extend the telemetry an instrumentation library provides or want\nto build your own instrumentation for your application directly you will need\nto use the\n[Go otel](https://pkg.go.dev/go.opentelemetry.io/otel)\npackage. The [examples](https://github.com/open-telemetry/opentelemetry-go-contrib/tree/main/examples)\nare a good way to see some practical uses of this process.\n\n### Export\n\nNow that your application is instrumented to collect telemetry, it needs an\nexport pipeline to send that telemetry to an observability platform.\n\nAll officially supported exporters for the OpenTelemetry project are contained in the [exporters directory](./exporters).\n\n| Exporter                              | Logs | Metrics | Traces |\n|---------------------------------------|:----:|:-------:|:------:|\n| [OTLP](./exporters/otlp/)             |  âœ“   |    âœ“    |   âœ“    |\n| [Prometheus](./exporters/prometheus/) |      |    âœ“    |        |\n| [stdout](./exporters/stdout/)         |  âœ“   |    âœ“    |   âœ“    |\n| [Zipkin](./exporters/zipkin/)         |      |         |   âœ“    |\n\n## Contributing\n\nSee the [contributing documentation](CONTRIBUTING.md).\n",
      "stars_today": 1
    },
    {
      "id": 7454197,
      "name": "yosys",
      "full_name": "YosysHQ/yosys",
      "description": "Yosys Open SYnthesis Suite",
      "html_url": "https://github.com/YosysHQ/yosys",
      "stars": 4237,
      "forks": 1027,
      "language": "C++",
      "topics": [],
      "created_at": "2013-01-05T10:10:48Z",
      "updated_at": "2026-01-15T00:25:00Z",
      "pushed_at": "2026-01-15T04:49:13Z",
      "open_issues": 590,
      "owner": {
        "login": "YosysHQ",
        "avatar_url": "https://avatars.githubusercontent.com/u/35169771?v=4"
      },
      "readme": "yosys â€“ Yosys Open SYnthesis Suite\n===================================\n\nThis is a framework for RTL synthesis tools. It currently has\nextensive Verilog-2005 support and provides a basic set of\nsynthesis algorithms for various application domains.\n\nYosys can be adapted to perform any synthesis job by combining\nthe existing passes (algorithms) using synthesis scripts and\nadding additional passes as needed by extending the yosys C++\ncode base.\n\nYosys is free software licensed under the ISC license (a GPL\ncompatible license that is similar in terms to the MIT license\nor the 2-clause BSD license).\n\nThird-party software distributed alongside this software\nis licensed under compatible licenses.\nPlease refer to `abc` and `libs` subdirectories for their license terms.\n\n\nWeb Site and Other Resources\n============================\n\nMore information and documentation can be found on the Yosys web site:\n- https://yosyshq.net/yosys/\n\nIf you have any Yosys-related questions, please post them on the Discourse group:\n- https://yosyshq.discourse.group\n\nDocumentation from this repository is automatically built and available on Read\nthe Docs:\n- https://yosyshq.readthedocs.io/projects/yosys\n\nUsers interested in formal verification might want to use the formal\nverification front-end for Yosys, SBY:\n- https://yosyshq.readthedocs.io/projects/sby/\n- https://github.com/YosysHQ/sby\n\nThe Yosys blog has news and articles from users:\n- https://blog.yosyshq.com\n\n\nInstallation\n============\n\nYosys is part of the [Tabby CAD Suite](https://www.yosyshq.com/tabby-cad-datasheet) and the [OSS CAD Suite](https://github.com/YosysHQ/oss-cad-suite-build)! The easiest way to use yosys is to install the binary software suite, which contains all required dependencies and related tools.\n\n* [Contact YosysHQ](https://www.yosyshq.com/contact) for a [Tabby CAD Suite](https://www.yosyshq.com/tabby-cad-datasheet) Evaluation License and download link\n* OR go to https://github.com/YosysHQ/oss-cad-suite-build/releases to download the free OSS CAD Suite\n* Follow the [Install Instructions on GitHub](https://github.com/YosysHQ/oss-cad-suite-build#installation)\n\nMake sure to get a Tabby CAD Suite Evaluation License if you need features such as industry-grade SystemVerilog and VHDL parsers!\n\nFor more information about the difference between Tabby CAD Suite and the OSS CAD Suite, please visit https://www.yosyshq.com/tabby-cad-datasheet\n\nMany Linux distributions also provide Yosys binaries, some more up to date than others. Check with your package manager!\n\n\nBuilding from Source\n====================\n\nFor more details, and instructions for other platforms, check [building from\nsource](https://yosyshq.readthedocs.io/projects/yosys/en/latest/getting_started/installation.html#building-from-source)\non Read the Docs.\n\nWhen cloning Yosys, some required libraries are included as git submodules. Make\nsure to call e.g.\n\n\t$ git clone --recurse-submodules https://github.com/YosysHQ/yosys.git\n\nor\n\n\t$ git clone https://github.com/YosysHQ/yosys.git\n\t$ cd yosys\n\t$ git submodule update --init --recursive\n\nYou need a C++ compiler with C++17 support (up-to-date CLANG or GCC is\nrecommended) and some standard tools such as GNU Flex, GNU Bison, and GNU Make.\nTCL, readline and libffi are optional (see ``ENABLE_*`` settings in Makefile).\nXdot (graphviz) is used by the ``show`` command in yosys to display schematics.\n\nFor example on Ubuntu Linux 22.04 LTS the following commands will install all\nprerequisites for building yosys:\n\n\t$ sudo apt-get install gawk git make python3 lld bison clang flex \\\n\t\tlibffi-dev libfl-dev libreadline-dev pkg-config tcl-dev zlib1g-dev \\\n\t\tgraphviz xdot\n\t$ curl -LsSf https://astral.sh/uv/install.sh | sh\n\nThe environment variable `CXX` can be used to control the C++ compiler used, or\nrun one of the following to override it:\n\n\t$ make config-clang\n\t$ make config-gcc\n\nThe Makefile has many variables influencing the build process. These can be\nadjusted by modifying the Makefile.conf file which is created at the `make\nconfig-...` step (see above), or they can be set by passing an option to the\nmake command directly:\n\n  $ make CXX=$CXX\n\nFor other compilers and build configurations it might be necessary to make some\nchanges to the config section of the Makefile. It's also an alternative way to\nset the make variables mentioned above.\n\n\t$ vi Makefile            # ..or..\n\t$ vi Makefile.conf\n\nTo build Yosys simply type 'make' in this directory.\n\n\t$ make\n\t$ sudo make install\n\nTests are located in the tests subdirectory and can be executed using the test\ntarget. Note that you need gawk as well as a recent version of iverilog (i.e.\nbuild from git). Then, execute tests via:\n\n\t$ make test\n\nTo use a separate (out-of-tree) build directory, provide a path to the Makefile.\n\n\t$ mkdir build; cd build\n\t$ make -f ../Makefile\n\nOut-of-tree builds require a clean source tree.\n\n\nGetting Started\n===============\n\nYosys can be used with the interactive command shell, with\nsynthesis scripts or with command line arguments. Let's perform\na simple synthesis job using the interactive command shell:\n\n\t$ ./yosys\n\tyosys>\n\nthe command ``help`` can be used to print a list of all available\ncommands and ``help <command>`` to print details on the specified command:\n\n\tyosys> help help\n\nreading and elaborating the design using the Verilog frontend:\n\n\tyosys> read -sv tests/simple/fiedler-cooley.v\n\tyosys> hierarchy -top up3down5\n\nwriting the design to the console in the RTLIL format used by Yosys\ninternally:\n\n\tyosys> write_rtlil\n\nconvert processes (``always`` blocks) to netlist elements and perform\nsome simple optimizations:\n\n\tyosys> proc; opt\n\ndisplay design netlist using ``xdot``:\n\n\tyosys> show\n\nthe same thing using ``gv`` as postscript viewer:\n\n\tyosys> show -format ps -viewer gv\n\ntranslating netlist to gate logic and perform some simple optimizations:\n\n\tyosys> techmap; opt\n\nwrite design netlist to a new Verilog file:\n\n\tyosys> write_verilog synth.v\n\nor using a simple synthesis script:\n\n\t$ cat synth.ys\n\tread -sv tests/simple/fiedler-cooley.v\n\thierarchy -top up3down5\n\tproc; opt; techmap; opt\n\twrite_verilog synth.v\n\n\t$ ./yosys synth.ys\n\nIf ABC is enabled in the Yosys build configuration and a cell library is given\nin the liberty file ``mycells.lib``, the following synthesis script will\nsynthesize for the given cell library:\n\n\t# read design\n\tread -sv tests/simple/fiedler-cooley.v\n\thierarchy -top up3down5\n\n\t# the high-level stuff\n\tproc; fsm; opt; memory; opt\n\n\t# mapping to internal cell library\n\ttechmap; opt\n\n\t# mapping flip-flops to mycells.lib\n\tdfflibmap -liberty mycells.lib\n\n\t# mapping logic to mycells.lib\n\tabc -liberty mycells.lib\n\n\t# cleanup\n\tclean\n\nIf you do not have a liberty file but want to test this synthesis script,\nyou can use the file ``examples/cmos/cmos_cells.lib`` from the yosys sources\nas simple example.\n\nLiberty file downloads for and information about free and open ASIC standard\ncell libraries can be found here:\n\n- http://www.vlsitechnology.org/html/libraries.html\n- http://www.vlsitechnology.org/synopsys/vsclib013.lib\n\nThe command ``synth`` provides a good default synthesis script (see\n``help synth``):\n\n\tread -sv tests/simple/fiedler-cooley.v\n\tsynth -top up3down5\n\n\t# mapping to target cells\n\tdfflibmap -liberty mycells.lib\n\tabc -liberty mycells.lib\n\tclean\n\nThe command ``prep`` provides a good default word-level synthesis script, as\nused in SMT-based formal verification.\n\n\nAdditional information\n======================\n\nThe ``read_verilog`` command, used by default when calling ``read`` with Verilog\nsource input, does not perform syntax checking.  You should instead lint your\nsource with another tool such as\n[Verilator](https://www.veripool.org/verilator/) first, e.g. by calling\n``verilator --lint-only``.\n\n\nBuilding the documentation\n==========================\n\nNote that there is no need to build the manual if you just want to read it.\nSimply visit https://yosys.readthedocs.io/en/latest/ instead.\n\nIn addition to those packages listed above for building Yosys from source, the\nfollowing are used for building the website:\n\n\t$ sudo apt install pdf2svg faketime\n\nOr for MacOS, using homebrew:\n\n  $ brew install pdf2svg libfaketime\n\nPDFLaTeX, included with most LaTeX distributions, is also needed during the\nbuild process for the website.  Or, run the following:\n\n\t$ sudo apt install texlive-latex-base texlive-latex-extra latexmk\n\nOr for MacOS, using homebrew:\n\n  $ brew install basictex\n  $ sudo tlmgr update --self\n  $ sudo tlmgr install collection-latexextra latexmk tex-gyre\n\nThe Python package, Sphinx, is needed along with those listed in\n`docs/source/requirements.txt`:\n\n\t$ pip install -U sphinx -r docs/source/requirements.txt\n\nFrom the root of the repository, run `make docs`.  This will build/rebuild yosys\nas necessary before generating the website documentation from the yosys help\ncommands.  To build for pdf instead of html, call\n`make docs DOC_TARGET=latexpdf`.\n\nIt is recommended to use the `ENABLE_HELP_SOURCE` make option for Yosys builds\nthat will be used to build the documentation.  This option enables source\nlocation tracking for passes and improves the command reference through grouping\nrelated commands and allowing for the documentation to link to the corresponding\nsource files.  Without this, a warning will be raised during the Sphinx build\nabout `Found commands assigned to group unknown` and `make docs` is configured\nto fail on warnings by default.\n",
      "stars_today": 1
    },
    {
      "id": 9306568,
      "name": "WordPress-Android",
      "full_name": "wordpress-mobile/WordPress-Android",
      "description": "WordPress for Android",
      "html_url": "https://github.com/wordpress-mobile/WordPress-Android",
      "stars": 3108,
      "forks": 1349,
      "language": "Kotlin",
      "topics": [
        "android",
        "app",
        "java",
        "mobile",
        "oauth2-authentication",
        "read",
        "secret",
        "website",
        "wordpress",
        "write"
      ],
      "created_at": "2013-04-08T20:52:40Z",
      "updated_at": "2026-01-15T13:18:46Z",
      "pushed_at": "2026-01-15T20:24:12Z",
      "open_issues": 892,
      "owner": {
        "login": "wordpress-mobile",
        "avatar_url": "https://avatars.githubusercontent.com/u/1306301?v=4"
      },
      "readme": "# WordPress for Android #\n\nIf you're just looking to install WordPress for Android, you can find it on [Google Play](https://play.google.com/store/apps/details?id=org.wordpress.android&referrer=utm_source%3Dgithub%26utm_medium%3Dwebsite).\nIf you're a developer wanting to contribute, read on.\n\n## Build Instructions ##\n\n1. Make sure you've installed [Android Studio](https://developer.android.com/studio).\n2. Install npm using [Node Version Manager](https://github.com/nvm-sh/nvm)(nvm), as described in step one from the [Block Editor Quickstart guide](https://developer.wordpress.org/block-editor/getting-started/devenv/#quickstart)\n3. `cd WordPress-Android` to enter the working directory.\n4. In Android Studio, open the project from the local repository. This will auto-generate `local.properties` with the SDK location.\n5. Recommended: The CI uses JDK11 to build the app and run the tests. Some tests won't pass on the JDK embedded in Android Studio (JDK8). You might want to set JAVA_HOME and JDK location in Android Studio to JDK11.\n6. Go to Tools â†’ AVD Manager and create an emulated device.\n7. Run.\n\nNotes:\n\n* While loading/building the app in Android Studio, ignore the prompt to update the Gradle plugin version, as that will probably introduce build errors. On the other hand, feel free to update if you are planning to work on ensuring the compatibility of the newer version.\n\n## Build and Test ##\n\nTo build, install, and test the project from the command line:\n\n    $ ./gradlew assembleWordPressVanillaDebug                        # assemble the debug .apk\n    $ ./gradlew installWordPressVanillaDebug                         # install the debug .apk if you have an\n                                                                     # emulator or an Android device connected\n    $ ./gradlew :WordPress:testWordPressVanillaDebugUnitTest         # assemble, install and run unit tests\n    $ ./gradlew :WordPress:connectedWordPressVanillaDebugAndroidTest # assemble, install and run Android tests\n\n## Running the app ##\n\nYou can use your own WordPress site for developing and testing the app. If you don't have one, you can create a temporary test site for free at https://jurassic.ninja/.\nOn the app start up screen, choose \"Enter your existing site address\" and enter the URL of your site and your credentials.\n\nNote: Access to WordPress.com features is temporarily disabled in the development environment.\n\n## Directory structure ##\n    .\n    â”œâ”€â”€ libs                    # dependencies used to build debug variants\n    â”œâ”€â”€ tools                   # script collection\n    â”œâ”€â”€ gradle.properties       # properties imported by the build script\n    â”œâ”€â”€ WordPress\n    â”‚   |-- build.gradle        # main build script\n    â”‚Â Â  â””â”€â”€ src\n    â”‚Â Â      â”œâ”€â”€ androidTest     # Android test assets, resources and code\n    â”‚Â Â      â”œâ”€â”€ test            # Unit tests\n    â”‚Â Â      â”œâ”€â”€ main\n    â”‚Â Â      â”‚Â Â  â”œâ”€â”€ assets      # main project assets\n    â”‚Â Â      â”‚Â Â  â”œâ”€â”€ java        # main project java code\n    â”‚Â Â      â”‚Â Â  â””â”€â”€ res         # main project resources\n    â”‚Â Â      â”œâ”€â”€ debug           # debug variant\n    â”‚Â Â      â””â”€â”€ wasabi          # wasabi variant specific resources and manifest\n\n## Google Configuration ##\n\nGoogle Sign-In is only available for WordPress.com accounts through the [official app][1].\nContributors can build and run the app without issue, but Google Sign-In will always fail.\nGoogle Sign-In requires configuration files which contain client and server information\nthat can't be shared publicly. More documentation and guides can be found on the\n[Google Identity Platform website][8].\n\n## Contributing\n\nRead our [Contributing Guide](CONTRIBUTING.md) to learn about reporting issues, contributing code, and more ways to contribute.\n\n## Security\n\nIf you happen to find a security vulnerability, we would appreciate you letting us know at https://hackerone.com/automattic and allowing us to respond before disclosing the issue publicly.\n\n## Getting in Touch\n\nIf you have questions or just want to say hi, join the [WordPress Slack](https://chat.wordpress.org) and drop a message on the `#mobile` channel.\n\n## Documentation\n\n- [Coding Style](docs/coding-style.md) - guidelines and validation and auto-formatting tools\n- [Pull Request Guidelines](docs/pull-request-guidelines.md) - branch naming and how to write good pull requests\n\nPlease read the [docs](docs/) for more.\n\n## Resources\n\n- [WordPress Mobile Blog](http://make.wordpress.org/mobile)\n- [WordPress Mobile Handbook](http://make.wordpress.org/mobile/handbook/)\n\n## License ##\n\nWordPress for Android is an Open Source project covered by the\n[GNU General Public License version 2](LICENSE.md). Note: code\nin the `libs/` directory comes from external libraries, which might\nbe covered by a different license compatible with the GPLv2.\n\n[1]: https://play.google.com/store/apps/details?id=org.wordpress.android\n[3]: https://developer.android.com/studio\n[4]: https://make.wordpress.org/chat/\n[5]: https://developer.wordpress.com/apps/\n[6]: https://developer.wordpress.com/docs/oauth2/\n[7]: https://developer.wordpress.com/docs/api/\n[8]: https://developers.google.com/identity/\n",
      "stars_today": 1
    },
    {
      "id": 16146440,
      "name": "rmarkdown",
      "full_name": "rstudio/rmarkdown",
      "description": "Dynamic Documents for R",
      "html_url": "https://github.com/rstudio/rmarkdown",
      "stars": 3007,
      "forks": 996,
      "language": "R",
      "topics": [
        "literate-programming",
        "markdown",
        "pandoc",
        "r",
        "r-package",
        "rmarkdown"
      ],
      "created_at": "2014-01-22T17:25:19Z",
      "updated_at": "2026-01-15T20:02:11Z",
      "pushed_at": "2025-11-26T19:36:51Z",
      "open_issues": 264,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "# rmarkdown <a href=\"https://pkgs.rstudio.com/rmarkdown/\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" /></a>\n\n\n<!-- badges: start -->\n[![R-CMD-check](https://github.com/rstudio/rmarkdown/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/rmarkdown/actions/workflows/R-CMD-check.yaml)\n[![CRAN release](https://www.r-pkg.org/badges/version/rmarkdown)](https://cran.r-project.org/package=rmarkdown)\n[![Codecov test coverage](https://codecov.io/gh/rstudio/rmarkdown/branch/main/graph/badge.svg)](https://app.codecov.io/gh/rstudio/rmarkdown?branch=main)\n<!-- badges: end -->\n\n\nThe **rmarkdown** package helps you create dynamic analysis documents that combine code, rendered output (such as figures), and prose. You bring your data, code, and ideas, and R Markdown renders your content into a polished document that can be used to:\n\n- Do data science interactively within the RStudio IDE,\n\n- Reproduce your analyses,\n\n- Collaborate and share code with others, and\n\n- Communicate your results with others.\n\nR Markdown documents can be rendered to many output formats including HTML documents, PDFs, Word files, slideshows, and more, allowing you to focus on the content while R Markdown takes care of your presentation. \n\n## Books\n\n<a href=\"https://bookdown.org/yihui/rmarkdown/\"><img class=\"book\" src=\"https://bookdown.org/yihui/rmarkdown/images/cover.png\" alt=\"R Markdown: The Definitive Guide\" height=\"400\"></a>\n<a href=\"https://bookdown.org/yihui/rmarkdown-cookbook/\"><img class=\"book\" src=\"https://bookdown.org/yihui/rmarkdown-cookbook/images/cover.png\" alt=\"R Markdown Cookbook\" height=\"400\"></a>\n\nSee more about them in [Get Started](https://pkgs.rstudio.com/rmarkdown/articles/rmarkdown.html).\n\n## Installation\n\nThe easiest way to install the **rmarkdown** package is from within the [RStudio IDE](https://posit.co/download/rstudio-desktop/), but you don't need to explicitly install it or load it, as RStudio automatically does both when needed. A recent version of Pandoc (>= 1.12.3) is also required; RStudio also automatically includes this too so you do not need to download Pandoc if you plan to use rmarkdown from the RStudio IDE.\n\nIf you want to use the rmarkdown package outside of RStudio, you can install the package from CRAN as follows:\n\n```r\ninstall.packages(\"rmarkdown\")\n```\n\nIf you want to use the development version of the rmarkdown package (either with or without RStudio), you can install the package from GitHub via the [**pak** package](https://pak.r-lib.org):\n\n```r\n# install.packages(\"pak\")\npak::pak('rstudio/rmarkdown')\n```\n\nIf not using the RStudio IDE, you'll need to install a recent version of Pandoc (>= 1.12.3); see the [Pandoc installation instructions](https://pandoc.org/installing.html) for help.\n\n## Usage\n\nThe easiest way to make a new R Markdown document is from within RStudio. Go to _File > New File > R Markdown_. From the new file wizard, you may:\n\n+ Provide a document title (_optional but recommended_),\n+ Provide an author name (_optional but recommended_),\n+ Select a default output format- HTML is the recommended format for authoring, and you can switch the output format anytime (_required_), \n+ Click **OK** (_required_).\n\nOnce inside your new `.Rmd` file, you should see some boilerplate text that includes code chunks. Use the \"Knit\" button in the RStudio IDE to render the file and preview the output with a single click or use the keyboard shortcut Cmd/Ctrl + Shift + K. \n\nYou can also delete all the text below the YAML frontmatter and fill in your own `.Rmd` by:\n\n+ Adding code chunks (keyboard shortcut: `Ctrl + Alt + I`; OS X: `Cmd + Option + I`),\n+ Writing prose with [Markdown formatting](https://www.markdowntutorial.com/), and\n+ Running each code chunk interactively by clicking the ![The run button](https://rmarkdown.rstudio.com/images/notebook-run-chunk.png) icon within RStudio. \n\nYou can also click \"Knit to HTML\" again to render the full document with all code chunks. For more help getting started in R Markdown, please see the [R Markdown website](https://rmarkdown.rstudio.com/lesson-1.html) or use the **\"Get Started\"** links at the top of this page.\n\n## Getting help\n\nThere are two main places to get help:\n\n1. The [Posit community](https://forum.posit.co/c/quarto-r-markdown/10) is a friendly place to ask any questions about rmarkdown and the R Markdown family of packages.\n\n1. [Stack Overflow](https://stackoverflow.com/questions/tagged/r-markdown) is a great source of answers to common rmarkdown questions. It is also a great place to get help, once you have created a reproducible example that illustrates your problem.\n\n## Code of Conduct\n\nPlease note that the **rmarkdown** project is released with a [Contributor Code of Conduct](https://pkgs.rstudio.com/rmarkdown/CODE_OF_CONDUCT.html). By contributing to this project, you agree to abide by its terms.\n",
      "stars_today": 1
    },
    {
      "id": 920805662,
      "name": "documentdb",
      "full_name": "documentdb/documentdb",
      "description": "MongoDB-compatible database engine for cloud-native and open-source workloads. Built for scalability, performance, and developer productivity.",
      "html_url": "https://github.com/documentdb/documentdb",
      "stars": 3135,
      "forks": 205,
      "language": "C",
      "topics": [],
      "created_at": "2025-01-22T19:59:22Z",
      "updated_at": "2026-01-16T00:17:55Z",
      "pushed_at": "2026-01-12T19:42:55Z",
      "open_issues": 69,
      "owner": {
        "login": "documentdb",
        "avatar_url": "https://avatars.githubusercontent.com/u/204920982?v=4"
      },
      "readme": "# Introduction\n\n`DocumentDB` is a MongoDB compatible open source document database built on PostgreSQL. It offers a native implementation of a document-oriented NoSQL database, enabling seamless CRUD (Create, Read, Update, Delete) operations on BSON(Binary JSON) data types within a PostgreSQL framework. Beyond basic operations, DocumentDB empowers users to execute complex workloads, including full-text searches, geospatial queries, and vector search, delivering robust functionality and flexibility for diverse data management needs.\n\n[PostgreSQL](https://www.postgresql.org/about/) is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely store and scale the most complicated data workloads.\n\n## Components\n\nThe project comprises of three components, which work together to support document operations.\n\n- **pg_documentdb_core :** PostgreSQL extension introducing BSON datatype support and operations for native Postgres.\n- **pg_documentdb :** The public API surface for DocumentDB providing CRUD functionality on documents in the store.\n- **pg_documentdb_gw :** The gateway protocol translation layer that converts the user's MongoDB APIs into PostgreSQL queries.\n\n## Why DocumentDB ?\n\nAt DocumentDB, we believe in the power of open-source to drive innovation and collaboration. Our commitment to being a fully open-source MongoDB compatible document database means that we are dedicated to transparency, community involvement, and continuous improvement. We are open-sourced under the most permissive [MIT](https://opensource.org/license/mit) license, where developers and organizations alike have no restrictions incorporating the project into new and existing solutions of their own. DocumentDB introduces the BSON data type to PostgreSQL and provides APIs for seamless operation within native PostgreSQL, enhancing efficiency and aligning with operational advantages.\n\nDocumentDB also provides a powerful on-premise solution, allowing organizations to maintain full control over their data and infrastructure. This flexibility ensures that you can deploy it in your own environment, meeting your specific security, compliance, and performance requirements. With DocumentDB, you get the best of both worlds: the innovation of open-source and the control of on-premise deployment.\n\n### Based on Postgres\n\nWe chose PostgreSQL as our platform for several reasons:\n\n1. **Proven Stability and Performance**: PostgreSQL has a long history of stability and performance, making it a trusted choice for mission-critical applications.\n2. **Extensibility**: The extensible architecture of PostgreSQL allows us to integrate a DocumentDB API on BSON data type seamlessly, providing the flexibility to handle both relational and document data.\n3. **Active Community**: PostgreSQL has a vibrant and active community that continuously contributes to its development, ensuring that it remains at the forefront of database technology.\n4. **Advanced Features**: PostgreSQL offers a rich feature set, including advanced indexing, full-text search, and powerful querying capabilities, which enhance the functionality of DocumentDB.\n5. **Compliance and Security**: PostgreSQL's robust security features and compliance with various standards makes it an ideal choice for organizations with stringent security and regulatory requirements.\n\n## Get Started\n\n[Building From Source](/docs/v1/building.md)\n\n### Prerequisites\n- Python 3.7+\n- pip package manager\n- Docker\n- Git (for cloning the repository)\n\nStep 1: Install Python\n\n```bash\n\npip install pymongo\n\n```\n\nStep 2. Install optional dependencies\n\n```bash\n\npip install dnspython\n\n```\n\nStep 3. Setup DocumentDB using Docker\n\n```bash\n\n   # Pull the latest DocumentDB Docker image\n   docker pull ghcr.io/documentdb/documentdb/documentdb-local:latest\n\n   # Tag the image for convenience\n   docker tag ghcr.io/documentdb/documentdb/documentdb-local:latest documentdb\n\n   # Run the container with your chosen username and password\n   docker run -dt -p 10260:10260 --name documentdb-container documentdb --username <YOUR_USERNAME> --password <YOUR_PASSWORD>\n   docker image rm -f ghcr.io/documentdb/documentdb/documentdb-local:latest || echo \"No existing documentdb image to remove\"\n\n```\n\n   > **Note:** Replace `<YOUR_USERNAME>` and `<YOUR_PASSWORD>` with your desired credentials. You must set these when creating the container for authentication to work.\n   > \n   > **Port Note:** Port `10260` is used by default in these instructions to avoid conflicts with other local database services. You can use port `27017` (the standard MongoDB port) or any other available port if you prefer. If you do, be sure to update the port number in both your `docker run` command and your connection string accordingly.\n\nStep 4: Initialize the pymongo client with the credentials from the previous step\n\n```python\n\nimport pymongo\n\nfrom pymongo import MongoClient\n\n# Create a MongoDB client and open a connection to DocumentDB\nclient = pymongo.MongoClient(\n    'mongodb://<YOUR_USERNAME>:<YOUR_PASSWORD>@localhost:10260/?tls=true&tlsAllowInvalidCertificates=true'\n)\n\n```\n\nStep 5: Create a database and collection\n\n```python\n\nquickStartDatabase = client[\"quickStartDatabase\"]\nquickStartCollection = quickStartDatabase.create_collection(\"quickStartCollection\")\n\n```\n\nStep 6: Insert documents\n\n```python\n\n# Insert a single document\nquickStartCollection.insert_one({\n       'name': 'John Doe',\n       'email': 'john@email.com',\n       'address': '123 Main St, Anytown, USA',\n       'phone': '555-1234'\n   })\n\n# Insert multiple documents\nquickStartCollection.insert_many([\n    {\n        'name': 'Jane Smith',\n        'email': 'jane@email.com',\n        'address': '456 Elm St, Othertown, USA',\n        'phone': '555-5678'\n    },\n    {\n        'name': 'Alice Johnson',\n        'email': 'alice@email.com',\n        'address': '789 Oak St, Sometown, USA',\n        'phone': '555-8765'\n    }\n])\n\n```\n\nStep 7: Read documents\n\n```python\n\n# Read all documents\nfor document in quickStartCollection.find():\n    print(document)\n\n# Read a specific document\nsingleDocumentReadResult = quickStartCollection.find_one({'name': 'John Doe'})\nprint(singleDocumentReadResult)\n\n```\n\nStep 8: Run aggregation pipeline operation\n\n```python\n\npipeline = [\n    {'$match': {'name': 'Alice Johnson'}},\n    {'$project': {\n        '_id': 0,\n        'name': 1,\n        'email': 1\n    }}\n]\n\nresults = quickStartCollection.aggregate(pipeline)\nprint(\"Aggregation results:\")\nfor eachDocument in results:\n    print(eachDocument)\n\n```\n\n### Helpful Links\n\n- Check out our [website](https://documentdb.io) to stay up to date with the latest on the project.\n- Check out our [docs](https://documentdb.io/docs) for MongoDB API compatibility, quickstarts and more.\n- Contributors and users can join the [DocumentDB Discord channel](https://discord.gg/vH7bYu524D) for quick collaboration.\n- Check out [FerretDB](https://github.com/FerretDB/FerretDB) and their integration of DocumentDB as a backend engine.\n",
      "stars_today": 1
    },
    {
      "id": 55336932,
      "name": "iOS",
      "full_name": "home-assistant/iOS",
      "description": ":iphone: Home Assistant for Apple platforms",
      "html_url": "https://github.com/home-assistant/iOS",
      "stars": 2071,
      "forks": 407,
      "language": "Swift",
      "topics": [
        "hacktoberfest",
        "home-assistant",
        "home-automation",
        "ios",
        "macos",
        "open-source-app",
        "swift"
      ],
      "created_at": "2016-04-03T08:28:34Z",
      "updated_at": "2026-01-15T19:01:52Z",
      "pushed_at": "2026-01-15T19:43:50Z",
      "open_issues": 174,
      "owner": {
        "login": "home-assistant",
        "avatar_url": "https://avatars.githubusercontent.com/u/13844975?v=4"
      },
      "readme": "Home Assistant for Apple Platforms\n=================\n\n[![TestFlight Beta invite](https://img.shields.io/badge/TestFlight-Beta-blue.svg)](https://www.home-assistant.io/ios/beta/)\n[![Download on the App Store](https://img.shields.io/itunes/v/1099568401.svg)](https://itunes.apple.com/app/home-assistant-open-source-home-automation/id1099568401)\n[![GitHub issues](https://img.shields.io/github/issues/home-assistant/iOS.svg?style=flat)](https://github.com/home-assistant/iOS/issues)\n[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-green.svg?style=flat)](https://github.com/home-assistant/iOS/blob/master/LICENSE)\n\n## Getting Started\n\nHome Assistant uses Bundler, Homebrew and Cocoapods to manage build dependencies. You'll need Xcode 26.2 (or later) which you can download from the [App Store](https://developer.apple.com/download/). You can get the app running using the following commands:\n\n```bash\ngit clone https://github.com/home-assistant/iOS.git\ncd iOS\n\n# you must do one of the following, but you do not need to do all of them:\n\n## install cocoapods via homebrew, use that\nbrew install cocoapods\n$(brew --prefix)/opt/ruby/bin/gem install cocoapods-acknowledgements\npod install --repo-update\n\n## install ruby via homebrew, use that\nbrew install ruby@3.1\n$(brew --prefix)/opt/ruby@3.1/bin/bundle install\n$(brew --prefix)/opt/ruby@3.1/bin/bundle exec pod install --repo-update\n\n## install ruby via rbenv, use that\nbrew install rbenv ruby-build\nrbenv install\nbundle install\nbundle exec pod install --repo-update\n```\n\nOnce this completes, you can launch  `HomeAssistant.xcworkspace` and run the `App-Debug` scheme onto your simulator or iOS device.\n\n## Testing just the frontend\n\nTo just test the [frontend](https://github.com/home-assistant/frontend), you can use a simulator version built by our GitHub actions.\n\n1. Install Xcode from the [App Store](https://developer.apple.com/download/) making sure it's at least the version noted above. You do not need to install or run anything else.\n2. Launch the simulator at `/Applications/Xcode.app/Contents/Developer/Applications/Simulator.app` or in Xcode under the Xcode menu > Open Developer Tool.\n3. Open a simulator under File > Open Simulator. You can install older versions of iOS in Xcode's Components preferences.\n4. Download a simulator build from the [the GitHub action](https://github.com/home-assistant/iOS/actions/workflows/ci.yml?query=branch%3Amaster) under \"Artifacts.\"\n5. Drag the result `.app` on drop it on top of the simulator.\n6. Locate the app on the home screen and click it to launch.\n\nThe simulator behaves different than you might expect:\n\n| Action | Effect |\n| -- | -- |\n| Click | Tap |\n| Click & drag | Scroll |\n| Hold âŒ¥ | Add a second touch point |\n| Hold â‡§âŒ¥ | Move both touch points |\n| âŒ˜â†, âŒ˜â†’ | Rotate |\n| âŒ˜S | Take screenshot |\n| âŒ˜R | Record video |\n| âŒ˜K | Toggle software keyboard |\n\nYou can now debug the WebView in this simulator build using Safari's Web Inspector:\n\n1. Make sure \"Show Develop menu in menu bar\" is enabled in Safari's Advanced preferences.\n2. Under the Develop menu, expand the \"Simulator\" menu for the simulator you've opened.\n3. Choose the WebView you want to inspect. A new window will open.\n\n## Code Signing\n\nAlthough the app is set up to use Automatic provisioning for Debug builds, you'll need to customize a few of the options. This is because the app makes heavy use of entitlements that require code signing, even for simulator builds.\n\nEdit the file `Configuration/HomeAssistant.overrides.xcconfig` (which will not exist by default and is ignored by git) and add the following:\n\n```bash\nDEVELOPMENT_TEAM = YourTeamID\nBUNDLE_ID_PREFIX = some.bundle.prefix\n```\n\nXcode should generate provisioning profiles in your Team ID and our configuration will disable features your team doesn't have like Critical Alerts. You can find your Team ID on Apple's [developer portal](https://developer.apple.com/account); it looks something like `ABCDEFG123`.\n\n## Code style\n\nLinters run as part of Pull Request checks. Additionally, some linting requirements can be autocorrected.\n\n```bash\n# checks for linting problems, doesn't fix\nbundle exec fastlane lint\n# checks for linting problems and fixes them\nbundle exec fastlane autocorrect\n```\n\nIn the Xcode project, the autocorrectable linters will not modify your source code but will provide warnings. This project uses several linters:\n\n- [SwiftFormat](https://github.com/nicklockwood/SwiftFormat)\n- [SwiftLint](https://github.com/realm/swiftlint) (for things SwiftFormat doesn't automate)\n- [Rubocop](https://rubocop.org) (largely for Fastlane)\n- [YamlLint](https://yamllint.readthedocs.io/en/stable/index.html) (largely for GitHub Actions)\n\n## Continuous Integration\n\nWe use [Github Actions](https://github.com/home-assistant/iOS/actions) alongside [Fastlane](https://fastlane.tools/) to perform continuous integration both by unit testing and deploying to [App Store Connect](https://appstoreconnect.apple.com). Mac Developer ID builds are available as an artifact on every build of master.\n\n### Environment variables\n\nFastlane scripts read from the environment or `.env` file for configuration like team IDs. See [`.env.sample`](https://github.com/home-assistant/iOS/blob/master/.env.sample) for available values.\n\n### Deployment\n\nAlthough all the deployment is done through Github Actions, you can do it manually through [Fastlane](https://github.com/home-assistant/iOS/blob/master/fastlane/README.md):\n\n### Deployment to App Store Connect\n\n```bash\n# creates the builds and uploads to the app store\n# each save their artifacts to build/\nbundle exec fastlane mac build\nbundle exec fastlane ios build\n```\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md)\n\n## LICENSE\n\nApache-2.0\n\n## Credits\n\nThe format and some content of this README.md comes from the [SwipeIt](https://github.com/ivanbruel/SwipeIt) project.\n\n[![Home Assistant - A project from the Open Home Foundation](https://www.openhomefoundation.org/badges/home-assistant.png)](https://www.openhomefoundation.org/)\n",
      "stars_today": 1
    },
    {
      "id": 159560389,
      "name": "renv",
      "full_name": "rstudio/renv",
      "description": "renv: Project environments for R.",
      "html_url": "https://github.com/rstudio/renv",
      "stars": 1123,
      "forks": 162,
      "language": "R",
      "topics": [],
      "created_at": "2018-11-28T20:25:39Z",
      "updated_at": "2026-01-15T18:13:54Z",
      "pushed_at": "2026-01-15T18:17:10Z",
      "open_issues": 212,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# renv <img src=\"man/figures/logo.svg\" align=\"right\" height=\"115\"/>\n\n<!-- badges: start -->\n\n[![Lifecycle:\nstable](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/renv)](https://CRAN.R-project.org/package=renv)\n[![R-CMD-check](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml)\n\n<!-- badges: end -->\n\n## Overview\n\nThe renv package[^1] helps you create **r**eproducible **env**ironments\nfor your R projects. Use renv to make your R projects more isolated,\nportable and reproducible.\n\n- **Isolated**: Installing a new or updated package for one project\n  wonâ€™t break your other projects, and vice versa. Thatâ€™s because renv\n  gives each project its own private library.\n- **Portable**: Easily transport your projects from one computer to\n  another, even across different platforms. renv makes it easy to\n  install the packages your project depends on.\n- **Reproducible**: renv records the exact package versions you depend\n  on, and ensures those exact versions are the ones that get installed\n  wherever you go.\n\n## Installation\n\nInstall the latest version of renv from CRAN with:\n\n``` r\ninstall.packages(\"renv\")\n```\n\nAlternatively, install the development version from\n[r-universe](https://rstudio.r-universe.dev/renv) with:\n\n``` r\ninstall.packages(\"renv\", repos = \"https://rstudio.r-universe.dev\")\n```\n\n## Workflow\n\n<img src=\"vignettes/renv.png\" alt=\"A diagram showing the most important verbs and nouns of renv. Projects start with init(), which creates a project library using packages from the system library. snapshot() updates the lockfile using the packages installed in the project library, where restore() installs packages into the project library using the metadata from the lockfile, and status() compares the lockfile to the project library. You install and update packages from CRAN and GitHub using install() and update(), but because you'll need to do this for multiple projects, renv uses cache to make this fast.\" width=\"408\" style=\"display: block; margin: auto;\" />\n\nUse `renv::init()` to initialize renv in a new or existing project. This\nwill set up a **project library**, containing all the packages youâ€™re\ncurrently using. The packages (and all the metadata needed to reinstall\nthem) are recorded into a **lockfile**, `renv.lock`, and a `.Rprofile`\nensures that the library is used every time you open that project.\n\nAs you continue to work on your project, you will install and upgrade\npackages, either using `install.packages()` and `update.packages()` or\n`renv::install()` and `renv::update()`. After youâ€™ve confirmed your code\nworks as expected, use `renv::snapshot()` to record the packages and\ntheir sources in the lockfile.\n\nLater, if you need to share your code with someone else or run your code\non new machine, your collaborator (or you) can call `renv::restore()` to\nreinstall the specific package versions recorded in the lockfile.\n\n## Learning more\n\nIf this is your first time using renv, we strongly recommend starting\nwith the [Introduction to\nrenv](https://rstudio.github.io/renv/articles/renv.html) vignette: this\nwill help you understand the most important verbs and nouns of renv.\n\nIf you have a question about renv, please first check the\n[FAQ](https://rstudio.github.io/renv/articles/faq.html) to see whether\nyour question has already been addressed. If it hasnâ€™t, please feel free\nto ask on the [Posit Forum](https://forum.posit.co).\n\nIf you believe youâ€™ve found a bug in renv, please file a bug (and, if\npossible, a [reproducible example](https://reprex.tidyverse.org)) at\n<https://github.com/rstudio/renv/issues>.\n\n[^1]: Pronounced â€œRâ€ â€œenvâ€\n",
      "stars_today": 1
    },
    {
      "id": 705678696,
      "name": "openvino.genai",
      "full_name": "openvinotoolkit/openvino.genai",
      "description": "Run Generative AI models with simple C++/Python API and using OpenVINO Runtime",
      "html_url": "https://github.com/openvinotoolkit/openvino.genai",
      "stars": 415,
      "forks": 320,
      "language": "C++",
      "topics": [],
      "created_at": "2023-10-16T13:38:16Z",
      "updated_at": "2026-01-15T15:42:54Z",
      "pushed_at": "2026-01-15T17:09:52Z",
      "open_issues": 124,
      "owner": {
        "login": "openvinotoolkit",
        "avatar_url": "https://avatars.githubusercontent.com/u/55443902?v=4"
      },
      "readme": "<div align=\"center\">\n \n![OpenVINO GenAI](/site/static/img/openvino-genai-logo-gradient.svg)\n\n[<b>Getting Started</b>](#getting-started) â€¢\n[<b>AI Scenarios</b>](#ai-scenarios) â€¢\n[<b>Optimization Methods</b>](#optimization-methods) â€¢\n[<b>Documentation</b>](https://openvinotoolkit.github.io/openvino.genai/)\n\n[![GitHub Release](https://img.shields.io/github/v/release/openvinotoolkit/openvino.genai?color=green)](https://github.com/openvinotoolkit/openvino.genai/releases)\n[![PyPI Downloads](https://static.pepy.tech/badge/openvino.genai)](https://pypi.org/project/openvino.genai/)\n![Python](https://img.shields.io/badge/python-3.10+-green)\n![OS](https://img.shields.io/badge/OS-Linux_|_Windows_|_MacOS-blue)\n\n![](/site/static/img/openvino-genai-workflow.svg)\n\n</div>\n\nOpenVINOâ„¢ GenAI is a library of the most popular Generative AI model pipelines, optimized execution methods, and samples that run on top of highly performant [OpenVINO Runtime](https://github.com/openvinotoolkit/openvino).\n\nThis library is friendly to PC and laptop execution, and optimized for resource consumption. It requires no external dependencies to run generative models as it already includes all the core functionality (e.g. tokenization via [`openvino-tokenizers`](https://github.com/openvinotoolkit/openvino_tokenizers)).\n\n![Text generation using LLaMa 3.2 model running on Intel ARC770 dGPU](./samples/generation.gif)\n\n<a id=\"getting-started\"></a>\n\n## Getting Started\n\n* [Introduction to OpenVINOâ„¢ GenAI](https://openvinotoolkit.github.io/openvino.genai/docs/getting-started/introduction)\n* [Install OpenVINOâ„¢ GenAI](https://openvinotoolkit.github.io/openvino.genai/docs/getting-started/installation)\n* [Build OpenVINOâ„¢ GenAI](/src/docs/BUILD.md)\n* [Supported Models](https://openvinotoolkit.github.io/openvino.genai/docs/supported-models/)\n* [Model Preparation Guide](https://openvinotoolkit.github.io/openvino.genai/docs/category/model-preparation)\n\nExplore blogs to setup your first hands-on experience with OpenVINO GenAI:\n\n* [How to Build OpenVINOâ„¢ GenAI APP in C++](https://medium.com/openvino-toolkit/how-to-build-openvino-genai-app-in-c-32dcbe42fa67)\n* [How to run Llama 3.2 locally with OpenVINOâ„¢](https://medium.com/openvino-toolkit/how-to-run-llama-3-2-locally-with-openvino-60a0f3674549)\n\n<a id=\"ai-scenarios\"></a>\n\n## Quick Start\n\n1. Install OpenVINO GenAI from PyPI:\n    ```sh\n    pip install openvino-genai\n    ```\n2. Obtain model, e.g. export model to OpenVINO IR format from Hugging Face (see [Model Preparation Guide](https://openvinotoolkit.github.io/openvino.genai/docs/category/model-preparation) for more details):\n    ```sh\n    optimum-cli export openvino --model TinyLlama/TinyLlama-1.1B-Chat-v1.0 --weight-format int4 --trust-remote-code TinyLlama_1_1b_v1_ov\n    ```\n3. Run inference:\n    ```python\n    import openvino_genai as ov_genai\n\n    pipe = ov_genai.LLMPipeline(\"TinyLlama_1_1b_v1_ov\", \"CPU\")  # Use CPU or GPU as devices without any other code change\n    print(pipe.generate(\"What is OpenVINO?\", max_new_tokens=100))\n    ```\n\n## Supported Generative AI Scenarios\n\nOpenVINOâ„¢ GenAI library provides very lightweight C++ and Python APIs to run the following Generative AI Scenarios:\n - [Text generation using Large Language Models (LLMs)](https://openvinotoolkit.github.io/openvino.genai/docs/use-cases/text-generation/) - Chat with local Llama, Phi, Qwen and other models\n - [Image processing using Visual Language Model (VLMs)](https://openvinotoolkit.github.io/openvino.genai/docs/use-cases/image-processing/) - Analyze images/videos with LLaVa, MiniCPM-V and other models\n - [Image generation using Diffusers](https://openvinotoolkit.github.io/openvino.genai/docs/use-cases/image-generation/) - Generate images with Stable Diffusion & Flux models\n - [Speech recognition using Whisper](https://openvinotoolkit.github.io/openvino.genai/docs/use-cases/speech-recognition/) - Convert speech to text using Whisper models\n - [Speech generation using SpeechT5](https://openvinotoolkit.github.io/openvino.genai/docs/use-cases/speech-generation/) - Convert text to speech using SpeechT5 TTS models\n - [Semantic search using Text Embedding](https://openvinotoolkit.github.io/openvino.genai/docs/use-cases/text-embedding) - Compute embeddings for documents and queries to enable efficient retrieval in RAG workflows\n - [Text Rerank for Retrieval-Augmented Generation (RAG)](https://openvinotoolkit.github.io/openvino.genai/docs/use-cases/text-rerank) - Analyze the relevance and accuracy of documents and queries for your RAG workflows\n\nLibrary efficiently supports LoRA adapters for Text and Image generation scenarios:\n- Load multiple adapters per model\n- Select active adapters for every generation\n- Mix multiple adapters with coefficients via alpha blending\n\nAll scenarios are run on top of OpenVINO Runtime that supports inference on CPU, GPU and NPU. See [here](https://docs.openvino.ai/2025/about-openvino/release-notes-openvino/system-requirements.html) for platform support matrix.\n\n<a id=\"optimization-methods\"></a>\n\n## Supported Generative AI Optimization Methods\n\nOpenVINOâ„¢ GenAI library provides a transparent way to use state-of-the-art generation optimizations:\n- Speculative decoding that employs two models of different sizes and uses the large model to periodically correct the results of the small model. See [here](https://pytorch.org/blog/hitchhikers-guide-speculative-decoding/) for more detailed overview\n- KVCache token eviction algorithm that reduces the size of the KVCache by pruning less impacting tokens.\n- Sparse attention, which accelerates prefill by attending only to the most important regions of the attention matrix. OpenVINO GenAI currently supports two modes: Tri-shape and XAttention. See [here](https://openvinotoolkit.github.io/openvino.genai/docs/concepts/optimization-techniques/sparse-attention-prefill) for more details.\n\nAdditionally, OpenVINOâ„¢ GenAI library implements a continuous batching approach to use OpenVINO within LLM serving. The continuous batching library could be used in LLM serving frameworks and supports the following features:\n- Prefix caching that caches fragments of previous generation requests and corresponding KVCache entries internally and uses them in case of repeated query.\n\nContinuous batching functionality is used within OpenVINO Model Server (OVMS) to serve LLMs, see [here](https://docs.openvino.ai/2025/openvino-workflow/model-server/ovms_what_is_openvino_model_server.html) for more details.\n\n\n## Additional Resources\n\n- [OpenVINO Generative AI workflow](https://docs.openvino.ai/2025/openvino-workflow-generative.html)\n- [Optimum Intel and OpenVINO](https://huggingface.co/docs/optimum/intel/openvino/export)\n- [OpenVINO Notebooks with GenAI](https://openvinotoolkit.github.io/openvino_notebooks/?libraries=OpenVINO+GenAI)\n\n## License\n\nThe OpenVINOâ„¢ GenAI repository is licensed under [Apache License Version 2.0](LICENSE).\nBy contributing to the project, you agree to the license and copyright terms therein and release\nyour contribution under these terms.\n",
      "stars_today": 1
    },
    {
      "id": 248836530,
      "name": "scTenifoldKnk",
      "full_name": "cailab-tamu/scTenifoldKnk",
      "description": " R/MATLAB package to perform virtual knockout experiments on single-cell gene regulatory networks.",
      "html_url": "https://github.com/cailab-tamu/scTenifoldKnk",
      "stars": 126,
      "forks": 13,
      "language": "R",
      "topics": [
        "functional-genomics",
        "gene-function",
        "gene-knockout",
        "gene-regulatory-network",
        "virtual-knockout-experiments"
      ],
      "created_at": "2020-03-20T19:31:03Z",
      "updated_at": "2026-01-15T07:00:41Z",
      "pushed_at": "2025-09-16T19:17:04Z",
      "open_issues": 23,
      "owner": {
        "login": "cailab-tamu",
        "avatar_url": "https://avatars.githubusercontent.com/u/31963060?v=4"
      },
      "readme": "scTenifoldKnk\n=============\n\nA R/MATLAB/Python package to perform virtual knockout experiments on single-cell gene regulatory networks. **scTenifoldKnk** is a machine learning workflow that performs virtual knockout experiments using single-cell RNA sequencing (scRNAseq) data from wild-type (WT) control samples as input. Constructs a single-cell gene regulatory network (scGRN) and knocks out a target gene from the adjacency matrix of the WT scGRN by setting the geneâ€™s outdegree edges to zero. **scTenifoldKnk** then compares the knocked out scGRN with the WT scGRN to identify differentially regulated genes, called virtual-knockout perturbed genes, which are used to assess the impact of the gene knockout and reveal the geneâ€™s function in the analyzed cells.\n\nPython version of scTenifoldKnk is available at: https://github.com/qwerty239qwe/scTenifoldpy\n\nMATLAB version is available at: https://github.com/jamesjcai/scGEAToolbox\n\nInstall:\n-------\nYou can install **scTenifoldKnk/R** using the following command:\n\n```{R}\nlibrary(remotes)\ninstall_github('cailab-tamu/scTenifoldKnk')\nlibrary(scTenifoldKnk)\n```\n\nAvailable functions:\n--------------------\n\n|Code| Function |\n|:-|:-|\n|scTenifoldKnk|Perform virtual knockout experiments on single-cell gene regulatory networks|\n\nInput:\n--------\nThe required input for **scTenifoldKnk** is an expression matrix with genes in the rows and cells (barcodes) in the columns. Data is expected to be previously normalized or _not normalized_ if `QC = TRUE`.\n\nRunning time:\n--------\nThe running time of scTenifoldKnk is largely dependent on how long it takes to construct scGRNs from subsampled expression matrices. Time increases proportional to the number of cells and genes in the dataset used as input. Below is a table of running times under different scenarios:\n\n| Number of Cells | Number of Genes | Running Time |\n|-----------------|-----------------|--------------|\n| 300             | 1000            | 3.45 min     |\n| 1000            | 1000            | 4.25 min     |\n| 1000            | 5000            | 171.88 min (2 h 51.6 min) |\n| 2500            | 5000            | 175.29 min (2 h 55.3 min) |\n| 5000            | 5000            | 188.88 min (3 h 8.9 min) |\n| 5000            | 7500            | 189.51 min (3 h 9.5 min)  |\n| 7500            | 5000            | 615.45 min (10 h 15.5 min) |\n| 7500            | 7500            | 616.12 min (10 h 16.1 min)  |\n\n\nOutput:\n--------\nThe output of **scTenifoldKnk** is a list with 3 slots as follows: \n  * **tensorNetworks**: The computed weight-averaged denoised gene regulatory networks after CANDECOMP/PARAFAC (CP) tensor decomposition. It includes two slots with:\n    * **X**: The constructed network for the _X_ sample.\n    * **Y**: The constructed network for the _Y_ sample.\n  * **manifoldAlignment**: The generated low-dimensional features result of the non-linear manifold alignment. It is a data frame with _2 times the number of genes_ in the rows and _d_ (default= 2) dimensions in the columns\n  * **diffRegulation**: The results of the differential regulation analysis. It is a data frame with 6 columns as follows:\n    * **gene**: A character vector with the gene id identified from the manifoldAlignment output.\n    * **distance**: A numeric vector of the Euclidean distance computed between the coordinates of the same gene in both conditions.\n    * **Z**: A numeric vector of the Z-scores computed after Box-Cox power transformation.\n    * **FC**: A numeric vector of the FC computed with respect to the expectation.\n    * **p.value**: A numeric vector of the p-values associated to the fold-changes, probabilities are asigned as P[X > x] using the Chi-square distribution with one degree of freedom.\n    * **p.adj**: A numeric vector of adjusted p-values using Benjamini & Hochberg (1995) FDR correction.\n\n---\nThe function to plot the egocentric KO, the code is available at [https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R](https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R), it requires: The object out of Knk (as X), the gene to knockout (gKO).\n\n\nÂ©ï¸ The Texas A & M University System. All rights reserved.\n",
      "stars_today": 1
    },
    {
      "id": 20541795,
      "name": "SnapKit",
      "full_name": "SnapKit/SnapKit",
      "description": "A Swift Autolayout DSL for iOS & OS X",
      "html_url": "https://github.com/SnapKit/SnapKit",
      "stars": 20314,
      "forks": 2039,
      "language": "Swift",
      "topics": [
        "auto",
        "autolayout",
        "cocoapods",
        "constraints",
        "dsl",
        "layout",
        "snapkit",
        "swift",
        "ui",
        "xcode"
      ],
      "created_at": "2014-06-05T21:13:40Z",
      "updated_at": "2026-01-13T09:51:32Z",
      "pushed_at": "2025-05-08T09:55:53Z",
      "open_issues": 57,
      "owner": {
        "login": "SnapKit",
        "avatar_url": "https://avatars.githubusercontent.com/u/7809696?v=4"
      },
      "readme": "<img src=\"https://snapkit.github.io/SnapKit/images/banner.jpg\" alt=\"\" />\n\nSnapKit is a DSL to make Auto Layout easy on both iOS and OS X.\n\n[![Build Status](https://travis-ci.org/SnapKit/SnapKit.svg)](https://travis-ci.org/SnapKit/SnapKit)\n[![Platform](https://img.shields.io/cocoapods/p/SnapKit.svg?style=flat)](https://github.com/SnapKit/SnapKit)\n[![Cocoapods Compatible](https://img.shields.io/cocoapods/v/SnapKit.svg)](https://cocoapods.org/pods/SnapKit)\n[![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage)\n\n#### âš ï¸ **To use with Swift 4.x please ensure you are using >= 4.0.0** âš ï¸\n#### âš ï¸ **To use with Swift 5.x please ensure you are using >= 5.0.0** âš ï¸\n\n## Contents\n\n- [Requirements](#requirements)\n- [Migration Guides](#migration-guides)\n- [Communication](#communication)\n- [Installation](#installation)\n- [Usage](#usage)\n- [Credits](#credits)\n- [License](#license)\n\n## Requirements\n\n- iOS 12.0+ / Mac OS X 10.13+ / tvOS 10.0+\n- Xcode 10.0+\n- Swift 4.0+\n\n## Migration Guides\n\n- [SnapKit 3.0 Migration Guide](Documentation/SnapKit%203.0%20Migration%20Guide.md)\n\n## Communication\n\n- If you **need help**, use [Stack Overflow](http://stackoverflow.com/questions/tagged/snapkit). (Tag 'snapkit')\n- If you'd like to **ask a general question**, use [Stack Overflow](http://stackoverflow.com/questions/tagged/snapkit).\n- If you **found a bug**, open an issue.\n- If you **have a feature request**, open an issue.\n- If you **want to contribute**, submit a pull request.\n\n\n## Installation\n\n### CocoaPods\n\n[CocoaPods](http://cocoapods.org) is a dependency manager for Cocoa projects. You can install it with the following command:\n\n```bash\n$ gem install cocoapods\n```\n\n> CocoaPods 1.1.0+ is required to build SnapKit 4.0.0+.\n\nTo integrate SnapKit into your Xcode project using CocoaPods, specify it in your `Podfile`:\n\n```ruby\nsource 'https://github.com/CocoaPods/Specs.git'\nplatform :ios, '12.0'\nuse_frameworks!\n\ntarget '<Your Target Name>' do\n    pod 'SnapKit', '~> 5.7.0'\nend\n```\n\nThen, run the following command:\n\n```bash\n$ pod install\n```\n\n### Carthage\n\n[Carthage](https://github.com/Carthage/Carthage) is a decentralized dependency manager that builds your dependencies and provides you with binary frameworks.\n\nYou can install Carthage with [Homebrew](http://brew.sh/) using the following command:\n\n```bash\n$ brew update\n$ brew install carthage\n```\n\nTo integrate SnapKit into your Xcode project using Carthage, specify it in your `Cartfile`:\n\n```ogdl\ngithub \"SnapKit/SnapKit\" ~> 5.0.0\n```\n\nRun `carthage update` to build the framework and drag the built `SnapKit.framework` into your Xcode project.\n\n### Swift Package Manager\n\n[Swift Package Manager](https://swift.org/package-manager/) is a tool for managing the distribution of Swift code. Itâ€™s integrated with the Swift build system to automate the process of downloading, compiling, and linking dependencies.\n\n> Xcode 11+ is required to build SnapKit using Swift Package Manager.\n\nTo integrate SnapKit into your Xcode project using Swift Package Manager, add it to the dependencies value of your `Package.swift`:\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/SnapKit/SnapKit.git\", .upToNextMajor(from: \"5.0.1\"))\n]\n```\n\n### Manually\n\nIf you prefer not to use either of the aforementioned dependency managers, you can integrate SnapKit into your project manually.\n\n---\n\n## Usage\n\n### Quick Start\n\n```swift\nimport SnapKit\n\nclass MyViewController: UIViewController {\n\n    lazy var box = UIView()\n\n    override func viewDidLoad() {\n        super.viewDidLoad()\n\n        self.view.addSubview(box)\n        box.backgroundColor = .green\n        box.snp.makeConstraints { (make) -> Void in\n           make.width.height.equalTo(50)\n           make.center.equalTo(self.view)\n        }\n    }\n\n}\n```\n\n### Playground\nYou can try SnapKit in Playground.\n\n**Note:**\n\n> To try SnapKit in playground, open `SnapKit.xcworkspace` and build SnapKit.framework for any simulator first.\n\n### Resources\n\n- [Documentation](https://snapkit.github.io/SnapKit/docs/)\n- [F.A.Q.](https://snapkit.github.io/SnapKit/faq/)\n\n## Credits\n\n- Robert Payne ([@robertjpayne](https://twitter.com/robertjpayne))\n- Many other contributors\n\n## License\n\nSnapKit is released under the MIT license. See LICENSE for details.\n",
      "stars_today": 0
    },
    {
      "id": 462597790,
      "name": "aptos-core",
      "full_name": "aptos-labs/aptos-core",
      "description": "Aptos is a layer 1 blockchain built to support the widespread use of blockchain through better technology and user experience.",
      "html_url": "https://github.com/aptos-labs/aptos-core",
      "stars": 6424,
      "forks": 3881,
      "language": "Rust",
      "topics": [
        "aptos",
        "blockchain",
        "blockchain-network",
        "move",
        "smart-contracts"
      ],
      "created_at": "2022-02-23T05:43:17Z",
      "updated_at": "2026-01-15T23:26:36Z",
      "pushed_at": "2026-01-16T00:54:13Z",
      "open_issues": 571,
      "owner": {
        "login": "aptos-labs",
        "avatar_url": "https://avatars.githubusercontent.com/u/99841612?v=4"
      },
      "readme": "<a href=\"https://aptos.dev\">\n\t<img width=\"100%\" src=\"./.assets/aptos_banner.png\" alt=\"Aptos Banner\" />\n</a>\n\n---\n\n[![License](https://img.shields.io/badge/license-Apache-green.svg)](LICENSE)\n[![Lint+Test](https://github.com/aptos-labs/aptos-core/actions/workflows/lint-test.yaml/badge.svg)](https://github.com/aptos-labs/aptos-core/actions/workflows/lint-test.yaml)\n[![codecov](https://codecov.io/gh/aptos-labs/aptos-core/branch/main/graph/badge.svg?token=X01RKXSGDE)](https://codecov.io/gh/aptos-labs/aptos-core)\n[![Discord chat](https://img.shields.io/discord/945856774056083548?style=flat-square)](https://discord.gg/aptosnetwork)\n\nAptos is a layer 1 blockchain bringing a paradigm shift to Web3 through better technology and user experience. Built with Move to create a home for developers building next-gen applications.\n\n## Getting Started\n\n* [Aptos Foundation](https://aptosfoundation.org/)\n* [Aptos Developer Network](https://aptos.dev)\n* [Guide - Integrate with the Aptos Blockchain](https://aptos.dev/guides/system-integrators-guide)\n* [Tutorials](https://aptos.dev/tutorials)\n* Follow us on [Twitter](https://twitter.com/Aptos).\n* Join us on the [Aptos Discord](https://discord.gg/aptosnetwork).\n\n## Contributing\n\nYou can learn more about contributing to the Aptos project by reading our [Contribution Guide](https://github.com/aptos-labs/aptos-core/blob/main/CONTRIBUTING.md) and by viewing our [Code of Conduct](https://github.com/aptos-labs/aptos-core/blob/main/CODE_OF_CONDUCT.md).\n\nAptos Core is licensed under [Innovation-Enabling Source Code License](https://github.com/aptos-labs/aptos-core/blob/main/LICENSE).\n",
      "stars_today": 0
    },
    {
      "id": 39799721,
      "name": "r4ds",
      "full_name": "hadley/r4ds",
      "description": "R for data science: a book",
      "html_url": "https://github.com/hadley/r4ds",
      "stars": 4968,
      "forks": 4394,
      "language": "R",
      "topics": [
        "book",
        "bookdown",
        "data-science",
        "r"
      ],
      "created_at": "2015-07-27T21:52:44Z",
      "updated_at": "2026-01-15T00:09:17Z",
      "pushed_at": "2026-01-15T00:09:13Z",
      "open_issues": 35,
      "owner": {
        "login": "hadley",
        "avatar_url": "https://avatars.githubusercontent.com/u/4196?v=4"
      },
      "readme": "# R for Data Science\n\n<!-- badges: start -->\n\n[![Render and deploy Book to Netlify](https://github.com/hadley/r4ds/actions/workflows/build_book.yaml/badge.svg)](https://github.com/hadley/r4ds/actions/workflows/build_book.yaml)\n\n<!-- badges: end -->\n\nThis repository contains the source of [R for Data Science](http://r4ds.hadley.nz) book.\nThe book is built using [Quarto](https://quarto.org/).\n\n## Images\n\n### Omnigraffle drawings\n\n-   Font: 12pt Guardian Sans Condensed / Ubuntu mono\n\n-   Export as 300 dpi png.\n\n-   Website font is 18 px = 13.5 pt, so scale dpi to match font sizes: 270 = 300 \\* 12 / 13.5.\n    (I also verified this empirically by screenshotting.)\n\n    ``` r\n    #| echo: FALSE\n    #| out.width: NULL\n    knitr::include_graphics(\"diagrams/transform.png\", dpi = 270)\n    ```\n\n### Screenshots\n\n-   Make sure you're using a light theme.\n    For small interface elements (eg. toolbars), zoom in twice.\n\n-   Screenshot with Cmd + Shift + 4.\n\n-   Don't need to set dpi:\n\n    ``` r\n    #| echo: FALSE\n    #| out.width: NULL\n    knitr::include_graphics(\"screenshots/rstudio-wg.png\")\n    ```\n\n### O'Reilly\n\nTo generate book for O'Reilly, build the book then:\n\n```{r}\n# pak::pak(\"hadley/htmlbook\")\nhtmlbook::convert_book()\n\nhtml <- list.files(\"oreilly\", pattern = \"[.]html$\", full.names = TRUE)\nfile.copy(html, \"../r-for-data-science-2e/\", overwrite = TRUE)\n\npngs <- list.files(\"oreilly\", pattern = \"[.]png$\", full.names = TRUE, recursive = TRUE)\ndest <- gsub(\"oreilly\", \"../r-for-data-science-2e/\", pngs)\nfs::dir_create(unique(dirname(dest)))\nfile.copy(pngs, dest, overwrite = TRUE)\n```\n\nThen commit and push to atlas.\n\n## Code of Conduct\n\nPlease note that r4ds uses a [Contributor Code of Conduct](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html).\nBy contributing to this book, you agree to abide by its terms.\n",
      "stars_today": 0
    },
    {
      "id": 76599439,
      "name": "frr",
      "full_name": "FRRouting/frr",
      "description": "The FRRouting Protocol Suite",
      "html_url": "https://github.com/FRRouting/frr",
      "stars": 3969,
      "forks": 1434,
      "language": "C",
      "topics": [
        "babel",
        "bgp",
        "eigrp",
        "evpn",
        "is-is",
        "ldp",
        "mpls",
        "msdp",
        "networking",
        "nhrp",
        "ospf",
        "pbr",
        "pim",
        "rip",
        "ripng",
        "routing",
        "vrrp"
      ],
      "created_at": "2016-12-15T21:56:38Z",
      "updated_at": "2026-01-15T21:35:21Z",
      "pushed_at": "2026-01-15T21:35:15Z",
      "open_issues": 694,
      "owner": {
        "login": "FRRouting",
        "avatar_url": "https://avatars.githubusercontent.com/u/24592672?v=4"
      },
      "readme": "<p align=\"center\">\n<img src=\"http://docs.frrouting.org/en/latest/_static/frr-icon.svg\" alt=\"Icon\" width=\"20%\"/>\n</p>\n\nFRRouting\n=========\n\nFRR is free software that implements and manages various IPv4 and IPv6 routing\nprotocols. It runs on nearly all distributions of Linux and BSD and\nsupports all modern CPU architectures.\n\nFRR currently supports the following protocols:\n\n* BGP\n* OSPFv2\n* OSPFv3\n* RIPv1\n* RIPv2\n* RIPng\n* IS-IS\n* PIM-SM/MSDP\n* LDP\n* BFD\n* Babel\n* PBR\n* OpenFabric\n* VRRP\n* EIGRP (alpha)\n* NHRP (alpha)\n\nInstallation & Use\n------------------\n\nFor source tarballs, see the\n[releases page](https://github.com/FRRouting/frr/releases).\n\nFor Debian and its derivatives, use the APT repository at\n[https://deb.frrouting.org/](https://deb.frrouting.org/).\n\nInstructions on building and installing from source for supported platforms may\nbe found in the\n[developer docs](http://docs.frrouting.org/projects/dev-guide/en/latest/building.html).\n\nOnce installed, please refer to the [user guide](http://docs.frrouting.org/)\nfor instructions on use.\n\nCommunity\n---------\n\nThe FRRouting email list server is located\n[here](https://lists.frrouting.org/listinfo) and offers the following public\nlists:\n\n| Topic             | List                         |\n|-------------------|------------------------------|\n| Development       | dev@lists.frrouting.org      |\n| Users & Operators | frog@lists.frrouting.org     |\n| Announcements     | announce@lists.frrouting.org |\n\nFor chat, we currently use [Slack](https://frrouting.slack.com). You can join\nby clicking the \"Slack\" link under the\n[Participate](https://frrouting.org/community) section of our website.\n\n\nContributing\n------------\n\nFRR maintains [developer's documentation](http://docs.frrouting.org/projects/dev-guide/en/latest/index.html)\nwhich contains the [project workflow](http://docs.frrouting.org/projects/dev-guide/en/latest/workflow.html)\nand expectations for contributors. Some technical documentation on project\ninternals is also available.\n\nWe welcome and appreciate all contributions, no matter how small!\n\n\nSecurity\n--------\n\nTo report security issues, please use our security mailing list:\n\n```\nsecurity [at] lists.frrouting.org\n```\n",
      "stars_today": 0
    },
    {
      "id": 96496250,
      "name": "swift-snapshot-testing",
      "full_name": "pointfreeco/swift-snapshot-testing",
      "description": "ğŸ“¸ Delightful Swift snapshot testing.",
      "html_url": "https://github.com/pointfreeco/swift-snapshot-testing",
      "stars": 4111,
      "forks": 641,
      "language": "Swift",
      "topics": [
        "screenshot-testing",
        "snapshot-testing",
        "swift",
        "testing"
      ],
      "created_at": "2017-07-07T03:38:51Z",
      "updated_at": "2026-01-13T15:28:50Z",
      "pushed_at": "2025-11-17T17:51:33Z",
      "open_issues": 194,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# ğŸ“¸ SnapshotTesting\n\n[![CI](https://github.com/pointfreeco/swift-snapshot-testing/workflows/CI/badge.svg)](https://actions-badge.atrox.dev/pointfreeco/swift-snapshot-testing/goto)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](http://pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-snapshot-testing%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-snapshot-testing%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing)\n\nDelightful Swift snapshot testing.\n\n## Usage\n\nOnce [installed](#installation), _no additional configuration is required_. You can import the\n`SnapshotTesting` module and call the `assertSnapshot` function.\n\n``` swift\nimport SnapshotTesting\nimport Testing\n\n@MainActor\nstruct MyViewControllerTests {\n  @Test func myViewController() {\n    let vc = MyViewController()\n\n    assertSnapshot(of: vc, as: .image)\n  }\n}\n```\n\nWhen an assertion first runs, a snapshot is automatically recorded to disk and the test will fail,\nprinting out the file path of any newly-recorded reference.\n\n> âŒ failed - No reference was found on disk. Automatically recorded snapshot: â€¦\n>\n> open \"â€¦/MyAppTests/\\_\\_Snapshots\\_\\_/MyViewControllerTests/testMyViewController.png\"\n>\n> Re-run \"testMyViewController\" to test against the newly-recorded snapshot.\n\nRepeat test runs will load this reference and compare it with the runtime value. If they don't\nmatch, the test will fail and describe the difference. Failures can be inspected from Xcode's Report\nNavigator or by inspecting the file URLs of the failure.\n\nYou can record a new reference by customizing snapshots inline with the assertion, or using the\n`withSnapshotTesting` tool:\n\n```swift\n// Record just this one snapshot\nassertSnapshot(of: vc, as: .image, record: .all)\n\n// Record all snapshots in a scope:\nwithSnapshotTesting(record: .all) {\n  assertSnapshot(of: vc1, as: .image)\n  assertSnapshot(of: vc2, as: .image)\n  assertSnapshot(of: vc3, as: .image)\n}\n\n// Record all snapshot failures in a Swift Testing suite:\n@Suite(.snapshots(record: .failed))\nstruct FeatureTests {}\n\n// Record all snapshot failures in an 'XCTestCase' subclass:\nclass FeatureTests: XCTestCase {\n  override func invokeTest() {\n    withSnapshotTesting(record: .failed) {\n      super.invokeTest()\n    }\n  }\n}\n```\n\n## Snapshot Anything\n\nWhile most snapshot testing libraries in the Swift community are limited to `UIImage`s of `UIView`s,\nSnapshotTesting can work with _any_ format of _any_ value on _any_ Swift platform!\n\nThe `assertSnapshot` function accepts a value and any snapshot strategy that value supports. This\nmeans that a view or view controller can be tested against an image representation _and_ against a\ntextual representation of its properties and subview hierarchy.\n\n``` swift\nassertSnapshot(of: vc, as: .image)\nassertSnapshot(of: vc, as: .recursiveDescription)\n```\n\nView testing is highly configurable. You can override trait collections (for specific size classes\nand content size categories) and generate device-agnostic snapshots, all from a single simulator.\n\n``` swift\nassertSnapshot(of: vc, as: .image(on: .iPhoneSe))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneSe))\n\nassertSnapshot(of: vc, as: .image(on: .iPhoneSe(.landscape)))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneSe(.landscape)))\n\nassertSnapshot(of: vc, as: .image(on: .iPhoneX))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPhoneX))\n\nassertSnapshot(of: vc, as: .image(on: .iPadMini(.portrait)))\nassertSnapshot(of: vc, as: .recursiveDescription(on: .iPadMini(.portrait)))\n```\n\n> **Warning**\n> Snapshots must be compared using the exact same simulator that originally took the reference to\n> avoid discrepancies between images.\n\nBetter yet, SnapshotTesting isn't limited to views and view controllers! There are a number of\navailable snapshot strategies to choose from.\n\nFor example, you can snapshot test URL requests (_e.g._, those that your API client prepares).\n\n``` swift\nassertSnapshot(of: urlRequest, as: .raw)\n// POST http://localhost:8080/account\n// Cookie: pf_session={\"userId\":\"1\"}\n//\n// email=blob%40pointfree.co&name=Blob\n```\n\nAnd you can snapshot test `Encodable` values against their JSON _and_ property list representations.\n\n``` swift\nassertSnapshot(of: user, as: .json)\n// {\n//   \"bio\" : \"Blobbed around the world.\",\n//   \"id\" : 1,\n//   \"name\" : \"Blobby\"\n// }\n\nassertSnapshot(of: user, as: .plist)\n// <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n// <!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\"\n//  \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n// <plist version=\"1.0\">\n// <dict>\n//   <key>bio</key>\n//   <string>Blobbed around the world.</string>\n//   <key>id</key>\n//   <integer>1</integer>\n//   <key>name</key>\n//   <string>Blobby</string>\n// </dict>\n// </plist>\n```\n\nIn fact, _any_ value can be snapshot-tested by default using its\n[mirror](https://developer.apple.com/documentation/swift/mirror)!\n\n``` swift\nassertSnapshot(of: user, as: .dump)\n// â–¿ User\n//   - bio: \"Blobbed around the world.\"\n//   - id: 1\n//   - name: \"Blobby\"\n```\n\nIf your data can be represented as an image, text, or data, you can write a snapshot test for it!\n\n## Documentation\n\nThe latest documentation is available\n[here](https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting).\n\n## Installation\n\n### Xcode\n\n> **Warning**\n> By default, Xcode will try to add the SnapshotTesting package to your project's main\n> application/framework target. Please ensure that SnapshotTesting is added to a _test_ target\n> instead, as documented in the last step, below.\n\n 1. From the **File** menu, navigate through **Swift Packages** and select\n    **Add Package Dependencyâ€¦**.\n 2. Enter package repository URL: `https://github.com/pointfreeco/swift-snapshot-testing`.\n 3. Confirm the version and let Xcode resolve the package.\n 4. On the final dialog, update SnapshotTesting's **Add to Target** column to a test target that\n    will contain snapshot tests (if you have more than one test target, you can later add\n    SnapshotTesting to them by manually linking the library in its build phase).\n\n### Swift Package Manager\n\nIf you want to use SnapshotTesting in any other project that uses\n[SwiftPM](https://swift.org/package-manager/), add the package as a dependency in `Package.swift`:\n\n```swift\ndependencies: [\n  .package(\n    url: \"https://github.com/pointfreeco/swift-snapshot-testing\",\n    from: \"1.12.0\"\n  ),\n]\n```\n\nNext, add `SnapshotTesting` as a dependency of your test target:\n\n```swift\ntargets: [\n  .target(name: \"MyApp\"),\n  .testTarget(\n    name: \"MyAppTests\",\n    dependencies: [\n      \"MyApp\",\n      .product(name: \"SnapshotTesting\", package: \"swift-snapshot-testing\"),\n    ]\n  )\n]\n```\n\n## Features\n\n  - [**Dozens of snapshot strategies**][available-strategies]. Snapshot\n    testing isn't just for `UIView`s and `CALayer`s. Write snapshots against _any_ value.\n  - [**Write your own snapshot strategies**][defining-strategies].\n    If you can convert it to an image, string, data, or your own diffable format, you can snapshot\n    test it! Build your own snapshot strategies from scratch or transform existing ones.\n  - **No configuration required.** Don't fuss with scheme settings and environment variables.\n    Snapshots are automatically saved alongside your tests.\n  - **More hands-off.** New snapshots are recorded whether `isRecording` mode is `true` or not.\n  - **Subclass-free.** Assert from any XCTest case or Quick spec.\n  - **Device-agnostic snapshots.** Render views and view controllers for specific devices and trait\n    collections from a single simulator.\n  - **First-class Xcode support.** Image differences are captured as XCTest attachments. Text\n    differences are rendered in inline error messages.\n  - **Supports any platform that supports Swift.** Write snapshot tests for iOS, Linux, macOS, and\n    tvOS.\n  - **SceneKit, SpriteKit, and WebKit support.** Most snapshot testing libraries don't support these\n    view subclasses.\n  - **`Codable` support**. Snapshot encodable data structures into their JSON and property list\n    representations.\n  - **Custom diff tool integration**. Configure failure messages to print diff commands for\n    [Kaleidoscope](https://kaleidoscope.app) or your diff tool of choice.\n    ``` swift\n    SnapshotTesting.diffToolCommand = { \"ksdiff \\($0) \\($1)\" }\n    ```\n\n[available-strategies]: https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting/snapshotting\n[defining-strategies]: https://swiftpackageindex.com/pointfreeco/swift-snapshot-testing/main/documentation/snapshottesting/customstrategies\n\n## Plug-ins\n\n  - [AccessibilitySnapshot](https://github.com/cashapp/AccessibilitySnapshot) adds easy regression\n    testing for iOS accessibility.\n    \n  - [AccessibilitySnapshotColorBlindness](https://github.com/Sherlouk/AccessibilitySnapshotColorBlindness)\n    adds snapshot strategies for color blindness simulation on iOS views, view controllers and images.\n\n  - [GRDBSnapshotTesting](https://github.com/SebastianOsinski/GRDBSnapshotTesting) adds snapshot\n    strategy for testing SQLite database migrations made with [GRDB](https://github.com/groue/GRDB.swift).\n\n  - [Nimble-SnapshotTesting](https://github.com/tahirmt/Nimble-SnapshotTesting) adds \n    [Nimble](https://github.com/Quick/Nimble) matchers for SnapshotTesting to be used by Swift\n    Package Manager.\n\n  - [Prefire](https://github.com/BarredEwe/Prefire) generating Snapshot Tests via\n    [Swift Package Plugins](https://github.com/apple/swift-package-manager/blob/main/Documentation/Plugins.md)\n    using SwiftUI `Preview`\n  \n  - [PreviewSnapshots](https://github.com/doordash-oss/swiftui-preview-snapshots) share `View`\n    configurations between SwiftUI Previews and snapshot tests and generate several snapshots with a\n    single test assertion.\n\n  - [swift-html](https://github.com/pointfreeco/swift-html) is a Swift DSL for type-safe,\n    extensible, and transformable HTML documents and includes an `HtmlSnapshotTesting` module to\n    snapshot test its HTML documents.\n\n  - [swift-snapshot-testing-nimble](https://github.com/Killectro/swift-snapshot-testing-nimble) adds\n    [Nimble](https://github.com/Quick/Nimble) matchers for SnapshotTesting.\n\n  - [swift-snapshot-testing-stitch](https://github.com/Sherlouk/swift-snapshot-testing-stitch/) adds\n    the ability to stitch multiple UIView's or UIViewController's together in a single test.\n\n  - [SnapshotTestingDump](https://github.com/tahirmt/swift-snapshot-testing-dump) Adds support to\n    use [swift-custom-dump](https://github.com/pointfreeco/swift-custom-dump/) by using `customDump`\n    strategy for `Any`\n\n  - [SnapshotTestingHEIC](https://github.com/alexey1312/SnapshotTestingHEIC) adds image support\n  using the HEIC storage format which reduces file sizes in comparison to PNG.\n\n  - [SnapshotVision](https://github.com/gregersson/swift-snapshot-testing-vision) adds snapshot\n    strategy for text recognition on views and images. Uses Apples Vision framework.\n\nHave you written your own SnapshotTesting plug-in?\n[Add it here](https://github.com/pointfreeco/swift-snapshot-testing/edit/master/README.md) and\nsubmit a pull request!\n\n## Related Tools\n\n  - [`iOSSnapshotTestCase`](https://github.com/uber/ios-snapshot-test-case/) helped introduce screen\n    shot testing to a broad audience in the iOS community. Experience with it inspired the creation\n    of this library.\n\n  - [Jest](https://jestjs.io) brought generalized snapshot testing to the JavaScript community with\n    a polished user experience. Several features of this library (diffing, automatically capturing\n    new snapshots) were directly influenced.\n\n## Learn More\n\nSnapshotTesting was designed with [witness-oriented programming](https://www.pointfree.co/episodes/ep39-witness-oriented-library-design).\n\nThis concept (and more) are explored thoroughly in a series of episodes on\n[Point-Free](https://www.pointfree.co), a video series exploring functional programming and Swift\nhosted by [Brandon Williams](https://twitter.com/mbrandonw) and\n[Stephen Celis](https://twitter.com/stephencelis).\n\nWitness-oriented programming and the design of this library was explored in the following\n[Point-Free](https://www.pointfree.co) episodes:\n\n  - [Episode 33](https://www.pointfree.co/episodes/ep33-protocol-witnesses-part-1): Protocol Witnesses: Part 1\n  - [Episode 34](https://www.pointfree.co/episodes/ep34-protocol-witnesses-part-1): Protocol Witnesses: Part 2\n  - [Episode 35](https://www.pointfree.co/episodes/ep35-advanced-protocol-witnesses-part-1): Advanced Protocol Witnesses: Part 1\n  - [Episode 36](https://www.pointfree.co/episodes/ep36-advanced-protocol-witnesses-part-2): Advanced Protocol Witnesses: Part 2\n  - [Episode 37](https://www.pointfree.co/episodes/ep37-protocol-oriented-library-design-part-1): Protocol-Oriented Library Design: Part 1\n  - [Episode 38](https://www.pointfree.co/episodes/ep38-protocol-oriented-library-design-part-2): Protocol-Oriented Library Design: Part 2\n  - [Episode 39](https://www.pointfree.co/episodes/ep39-witness-oriented-library-design): Witness-Oriented Library Design\n  - [Episode 40](https://www.pointfree.co/episodes/ep40-async-functional-refactoring): Async Functional Refactoring\n  - [Episode 41](https://www.pointfree.co/episodes/ep41-a-tour-of-snapshot-testing): A Tour of Snapshot Testing ğŸ†“\n\n<a href=\"https://www.pointfree.co/episodes/ep41-a-tour-of-snapshot-testing\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0041.jpeg\" width=\"480\">\n</a>\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n",
      "stars_today": 0
    },
    {
      "id": 69469299,
      "name": "apollo-kotlin",
      "full_name": "apollographql/apollo-kotlin",
      "description": ":rocket: Â A strongly-typed, caching GraphQL client for the JVM, Android, and Kotlin multiplatform.",
      "html_url": "https://github.com/apollographql/apollo-kotlin",
      "stars": 3942,
      "forks": 690,
      "language": "Kotlin",
      "topics": [
        "android",
        "apollographql",
        "graphql",
        "graphql-client",
        "kotlin",
        "kotlin-multiplatform",
        "multiplatform"
      ],
      "created_at": "2016-09-28T14:03:30Z",
      "updated_at": "2026-01-14T19:26:19Z",
      "pushed_at": "2026-01-15T18:50:56Z",
      "open_issues": 112,
      "owner": {
        "login": "apollographql",
        "avatar_url": "https://avatars.githubusercontent.com/u/17189275?v=4"
      },
      "readme": "<header>\n  <div align=\"center\">\n    <a href=\"https://www.apollographql.com?utm_medium=github&utm_source=apollographql_apollo-kotlin&utm_campaign=readme\"><img src=\"https://raw.githubusercontent.com/apollographql/apollo-client-devtools/main/assets/apollo-wordmark.svg\" height=\"100\" alt=\"Apollo Logo\"></a>\n  </div>\n    <div align=\"center\">\n\n[![Discourse](https://img.shields.io/discourse/topics?label=Discourse&server=https%3A%2F%2Fcommunity.apollographql.com&logo=discourse&color=467B95&style=flat-square)](http://community.apollographql.com/new-topic?category=Help&tags=mobile,client)\n[![Slack](https://img.shields.io/static/v1?label=kotlinlang&message=apollo-kotlin&color=A97BFF&logo=slack&style=flat-square)](https://app.slack.com/client/T09229ZC6/C01A6KM1SBZ)\n\n[![Snapshots](https://img.shields.io/maven-metadata/v?metadataUrl=https%3A%2F%2Fcentral.sonatype.com%2Frepository%2Fmaven-snapshots%2Fcom%2Fapollographql%2Fapollo%2Fapollo-api-jvm%2Fmaven-metadata.xml&style=flat-square&label=snapshots&color=%2315252D&strategy=latestProperty)](https://central.sonatype.com/repository/maven-snapshots/com/apollographql/apollo/apollo-api-jvm/maven-metadata.xml)\n[![Apollo Preview](https://img.shields.io/maven-metadata/v?metadataUrl=https%3A%2F%2Fstorage.googleapis.com%2Fapollo-previews%2Fm2%2Fcom%2Fapollographql%2Fapollo%2Fapollo-api-jvm%2Fmaven-metadata.xml&style=flat-square&label=apollo-previews&color=%23365E72&strategy=latestProperty)](http://storage.googleapis.com/apollo-previews/m2/com/apollographql/apollo/apollo-api-jvm/maven-metadata.xml)\n[![Maven Central](https://img.shields.io/maven-metadata/v?metadataUrl=https%3A%2F%2Frepo1.maven.org%2Fmaven2%2Fcom%2Fapollographql%2Fapollo%2Fapollo-api-jvm%2Fmaven-metadata.xml&style=flat-square&label=maven-central&color=%235C96B2&strategy=latestProperty\n)](https://central.sonatype.com/namespace/com.apollographql.apollo)\n\n[![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A&style=flat-square)](https://ge.apollographql.com/scans)\n\n  </div>\n  <h1 align=\"center\">Apollo Kotlin</h1>\n \n**The industry-leading GraphQL client for Kotlin**. Run on Android and all the Kotlin multiplatform targets. Apollo Kotlin delivers powerful caching, code generation, intuitive APIs, and comprehensive developer tools to accelerate your app development.\n</header>\n\n\n## â“ Why Choose Apollo Kotlin?\n\n âœ… 100% type safety, from your server to your app, using code generation<br>\n âœ… Intuitive, powerful caching - intelligent in-memory or SQLite caching out of the box<br>\n âœ… Excellent support for modern Android and Kotlin Multiplatform apps<br>\n âœ… Always up-to-date - we prioritize support for the latest versions of GraphQL, Kotlin, Gradle, and more<br>\n âœ… GraphOS ready - turnkey support for Persisted Queries, and `@defer`<br>\n âœ… Production-tested - Powers countless apps worldwide that serve millions of end users<br>\n\n ## ğŸš€ Quick Start\n \nIf you are new to GraphQL, check out [the tutorial](https://www.apollographql.com/tutorials/apollo-kotlin-android-part1) that will guide you through building an Android app using Apollo.\n\nFor more in-depth documentation, head to the [official documentation site](https://www.apollographql.com/docs/kotlin?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme).\n\nFor a detailed \"Get Started\" guide, check out our [docs](https://www.apollographql.com/docs/kotlin?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme).\n\n## ğŸ’¡ Resources\n\n| Resource | Description | Link |\n| ----- | ----- | ----- |\n| **Full Documentation** | Comprehensive guides and examples | [Read Docs â†’](https://www.apollographql.com/docs/kotlin?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme) |\n| **API Reference** | Complete API documentation | [Browse Kdoc â†’](https://apollographql.github.io/apollo-kotlin/kdoc/older/4.2.0/index.html?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme) |\n| **IntelliJ Plugin** | Enhanced development experience | [Install Plugin â†’](https://plugins.jetbrains.com/plugin/20645-apollo-graphql) |\n| **Free Course** | Learn GraphQL and Apollo Client | [Take Course â†’](https://www.apollographql.com/tutorials/apollo-kotlin-android-part1?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme) |\n\n## ğŸ§‘â€ğŸš€ About Apollo \n\nDeliver tomorrow's roadmap today with our comprehensive suite of API orchestration tools:\n\n* [**Apollo Client**](https://www.apollographql.com/docs/react?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme) \\- Type-safe apps with GraphQL-powered on-device caching ([React](https://www.apollographql.com/docs/react?utm_medium=github&utm_source=apollographql_apollo-kotlin&utm_campaign=readme), [iOS](https://www.apollographql.com/docs/ios?utm_medium=github&utm_source=apollographql_apollo-kotlin&utm_campaign=readme), [Kotlin](https://www.apollographql.com/docs/kotlin?utm_medium=github&utm_source=apollographql_apollo-kotlin&utm_campaign=readme))  \n* [**Apollo Connectors**](https://www.apollographql.com/graphos/apollo-connectors?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme) \\- Compose all your GraphQL and REST APIs into one GraphQL endpoint  \n* [**Apollo MCP Server**](https://www.apollographql.com/apollo-mcp-server?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme) \\- AI needs APIs. The fastest way to ship reliable AI experiences  \n* [**Apollo Router**](https://www.apollographql.com/docs/router?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme) \\- Scale your APIs seamlessly with GraphQL Federation, Security, Auth, and more  \n* [**GraphOS**](https://www.apollographql.com/graphos?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme) \\- Deploy, manage, govern, and explore your APIs ([start for free, no credit card needed](https://www.apollographql.com/pricing?utm_medium=github&utm_source=apollographql_apollo-kotlin&utm_campaign=readme))\n\n[**Explore the Complete Apollo Platform â†’**](https://www.apollographql.com/?utm_source=github&utm_medium=apollographql-_apollo-kotlin&utm_campaign=readme)\n\n## ğŸ› ï¸ Maintained by\n\n|Name|Username|\n|---|---|\n|Benoit Lubek|[@bod](https://github.com/bod)|\n|Jeff Auriemma|[@bignimbus](https://github.com/bignimbus)|\n|Martin Bonnin|[@martinbonnin](https://github.com/martinbonnin)|\n\n## ğŸ—ºï¸ Roadmap\n\nWe regularly update our [public roadmap](https://github.com/apollographql/apollo-kotlin/blob/main/ROADMAP.md) with the status of our work-in-progress and upcoming features.\n\n## ğŸ“£ Tell us what you think\n\n| â˜‘ï¸  Apollo Kotlin User Survey |\n| :----- |\n| What do you like best about Apollo Kotlin? What needs to be improved? Please tell us by taking a [one-minute survey](https://docs.google.com/forms/d/e/1FAIpQLSczNDXfJne3ZUOXjk9Ursm9JYvhTh1_nFTDfdq3XBAFWCzplQ/viewform?usp=pp_url&entry.1170701325=Apollo+Kotlin&entry.204965213=Readme). Your responses will help us understand Apollo Kotlin usage and allow us to serve you better. |\n\n## ğŸ—“ï¸ Events\n\nJoin these live events to meet other GraphQL users and learn more: \n\nğŸª [**GraphQL Summit 2025**](https://summit.graphql.com?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme)  \n Oct 6-8, 2025 â€¢ San Francisco  \n *1000+ engineers, talks, workshops, and office hours*\n\nğŸŒŸ [**GraphQLConf 2025**](https://graphql.org/conf/2025)\n Sep 8-10, 2025 â€¢ Amsterdam  \n *Celebrating 10 Years of GraphQL*\n\n[**View All Events â†’**](https://www.apollographql.com/events?utm_source=github&utm_medium=apollographql_apollo-kotlin&utm_campaign=readme)\n\n## ğŸ† Contributing\n\nThank you for your interest in submitting a Pull Request to Apollo Kotlin!  Read our [guidelines](https://github.com/apollographql/apollo-kotlin/blob/main/CONTRIBUTING.md) first, and don't hesitate to get in touch.\n\n**New to open source?** Check out our [**Good First Issues**](https://github.com/apollographql/apollo-kotlin/issues?q=is%3Aopen%20label%3A%22%3Abooks%3A%20good-first-issue%22) to get started.\n\n## ğŸ¤ Code of Conduct\n\nPlease read our [Code of Conduct](https://community.apollographql.com/faq). This applies to any space run by Apollo, including our GitHub repositories, the Apollo GraphOS Discord, the Apollo GraphQL Forum. The Code of Conduct reflects our commitment to making the Apollo Community a welcoming and safe space in which individuals can interact.\n\n## ğŸªª License\n\nSource code in this repository is available under the terms of the MIT License.  Read the full text [here](https://github.com/apollographql/apollo-kotlin/blob/main/LICENSE).\n",
      "stars_today": 0
    },
    {
      "id": 6656911,
      "name": "stripe-ios",
      "full_name": "stripe/stripe-ios",
      "description": "Stripe iOS SDK    ",
      "html_url": "https://github.com/stripe/stripe-ios",
      "stars": 2487,
      "forks": 1038,
      "language": "Swift",
      "topics": [
        "stripe",
        "stripe-sdk"
      ],
      "created_at": "2012-11-12T16:55:08Z",
      "updated_at": "2026-01-15T22:30:27Z",
      "pushed_at": "2026-01-16T00:50:38Z",
      "open_issues": 181,
      "owner": {
        "login": "stripe",
        "avatar_url": "https://avatars.githubusercontent.com/u/856813?v=4"
      },
      "readme": "# Stripe iOS SDK\n\n[![CocoaPods](https://img.shields.io/cocoapods/v/Stripe.svg?style=flat)](http://cocoapods.org/?q=author%3Astripe%20name%3Astripe)\n[![License](https://img.shields.io/cocoapods/l/Stripe.svg?style=flat)](https://github.com/stripe/stripe-ios/blob/master/LICENSE)\n[![Platform](https://img.shields.io/cocoapods/p/Stripe.svg?style=flat)](https://github.com/stripe/stripe-ios#)\n\n> [!TIP]\n> Want to chat live with Stripe engineers? Join us on our [Discord server](https://stripe.com/go/developer-chat).\n\nThe Stripe iOS SDK makes it quick and easy to build an excellent payment experience in your iOS app. We provide powerful and customizable UI screens and elements that can be used out-of-the-box to collect your users' payment details. We also expose the low-level APIs that power those UIs so that you can build fully custom experiences.\n\nGet started with our [ğŸ“š integration guides](https://stripe.com/docs/payments/accept-a-payment?platform=ios) and [example projects](#Examples), or [ğŸ“˜ browse the SDK reference](https://stripe.dev/stripe-ios/docs/index.html).\n\n> Updating to a newer version of the SDK? See our [migration guide](https://github.com/stripe/stripe-ios/blob/master/MIGRATING.md) and [changelog](https://github.com/stripe/stripe-ios/blob/master/CHANGELOG.md).\n\nTable of contents\n=================\n<!-- NOTE: Use case-sensitive anchor links for docc compatibility -->\n<!--ts-->\n   * [Features](#Features)\n   * [Releases](#Releases)\n   * [Requirements](#Requirements)\n   * [Getting started](#Getting-started)\n      * [Integration](#Integration)\n      * [Examples](#Examples)\n      * [Building from source](#Building-from-source)\n   * [Card scanning](#Card-scanning)\n   * [Contributing](#Contributing)\n   * [Migrating](#Migrating-from-older-versions)\n   * [Code Style](#Code-style)\n   * [Licenses](#Licenses)\n\n<!--te-->\n\n## Features\n\n**Simplified security**: We make it simple for you to collect sensitive data such as credit card numbers and remain [PCI compliant](https://stripe.com/docs/security#pci-dss-guidelines). This means the sensitive data is sent directly to Stripe instead of passing through your server. For more information, see our [integration security guide](https://stripe.com/docs/security).\n\n**Apple Pay**: [StripeApplePay](StripeApplePay/README.md) provides a [seamless integration with Apple Pay](https://stripe.com/docs/apple-pay).\n\n**SCA-ready**: The SDK automatically performs native [3D Secure authentication](https://stripe.com/docs/payments/3d-secure) if needed to comply with [Strong Customer Authentication](https://stripe.com/docs/strong-customer-authentication) regulation in Europe.\n\n**Native UI**: We provide native screens and elements to collect payment details. For example, [PaymentSheet](https://stripe.com/docs/payments/accept-a-payment?platform=ios) is a prebuilt UI that combines all the steps required to pay - collecting payment details, billing details, and confirming the payment - into a single sheet that displays on top of your app.\n\n<img src=\"https://user-images.githubusercontent.com/89988962/153276097-9b3369a0-e732-45c4-96ec-ff9d48ad0fb6.png\" alt=\"PaymentSheet\" align=\"center\"/>\n\n**Stripe API**: [StripePayments](StripePayments/README.md) provides [low-level APIs](https://stripe.dev/stripe-ios/docs/Classes/STPAPIClient.html) that correspond to objects and methods in the Stripe API. You can build your own entirely custom UI on top of this layer, while still taking advantage of utilities like [STPCardValidator](https://stripe.dev/stripe-ios/docs/Classes/STPCardValidator.html) to validate your userâ€™s input.\n\n**Card scanning**: We support card scanning on iOS 13 and higher. See our [Card scanning](#Card-scanning) section.\n\n**App Clips**: The `StripeApplePay` module provides a [lightweight SDK for offering Apple Pay in an App Clip](https://stripe.com/docs/apple-pay#app-clips).\n\n**Localized**: We support the following localizations: Bulgarian, Catalan, Chinese (Hong Kong), Chinese (Simplified), Chinese (Traditional), Croatian, Czech, Danish, Dutch, English (US), English (United Kingdom), Estonian, Filipino, Finnish, French, French (Canada), German, Greek, Hungarian, Indonesian, Italian, Japanese, Korean, Latvian, Lithuanian, Malay, Maltese, Norwegian BokmÃ¥l, Norwegian Nynorsk (Norway), Polish, Portuguese, Portuguese (Brazil), Romanian, Russian, Slovak, Slovenian, Spanish, Spanish (Latin America), Swedish, Turkish, Thai and Vietnamese.\n\n**Identity**: Learn about our [Stripe Identity iOS SDK](StripeIdentity/README.md) to verify the identity of your users.\n\n#### Recommended usage\n\nIf you're selling digital products or services that will be consumed within your app, (e.g. subscriptions, in-game currencies, game levels, access to premium content, or unlocking a full version), you must use Apple's in-app purchase APIs. See the [App Store review guidelines](https://developer.apple.com/app-store/review/guidelines/#payments) for more information. For all other scenarios you can use this SDK to process payments via Stripe.\n\n#### Privacy\n\nThe Stripe iOS SDK collects data to help us improve our products and prevent fraud. This data is never used for advertising and is not rented, sold, or given to advertisers. Our full privacy policy is available at [https://stripe.com/privacy](https://stripe.com/privacy).\n\nFor help with Apple's App Privacy Details form in App Store Connect, visit [Stripe iOS SDK Privacy Details](https://support.stripe.com/questions/stripe-ios-sdk-privacy-details).\n\n## Modules\n<!-- \n  EmergeTools project must be made public before adding to this table:\n  https://www.emergetools.com/settings?tab=app-display-options&cards=public_org_apps\n\n  NOTE: Pad `Size` col with &nbsp; to prevent table from shrinking badge images and maintain readability  \n -->\n| Module | Description | Size&nbsp;([Download&nbsp;â†’&nbsp;Install](https://docs.emergetools.com/docs/ios-app-size#download-vs-install-size))&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |\n|--------|-------------|------|\n| [StripePaymentSheet](StripePaymentSheet) | Stripe's [prebuilt payment UI](https://stripe.com/docs/payments/accept-a-payment?platform=ios&ui=payment-sheet). | [![StripePaymentSheet size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripePaymentSheetSize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripePaymentSheet&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripePaymentSheetSize/release?utm_campaign=badge-data) |\n| [StripeConnect](StripeConnect) | Connect embedded components to add connected account dashboard functionality to your app. | [![StripeConnect size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripeConnectSize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripeConnect&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripeConnectSize/release?utm_campaign=badge-data) |\n| [StripeIdentity](StripeIdentity) | Securely capture ID documents and selfies on iOS for use with [Stripe's Identity API](https://docs.stripe.com/identity) to confirm the identity of global users. | [![StripeIdentity size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripeIdentitySize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripeIdentity&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripeIdentitySize/release?utm_campaign=badge-data) |\n| [StripeFinancialConnections](StripeFinancialConnections) | Securely connect financial accounts to Stripe's merchant account with [Stripe Financial Connections](https://docs.stripe.com/financial-connections). | [![StripeFinancialConnections size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripeFinancialConnectionsSize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripeFinancialConnections&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripeFinancialConnectionsSize/release?utm_campaign=badge-data) |\n| Stripe | Contains all the below frameworks, plus [Issuing](https://stripe.com/docs/issuing/cards/digital-wallets?platform=iOS). | [![Stripe size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripeSize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=Stripe&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripeSize/release?utm_campaign=badge-data) |\n| [StripeApplePay](StripeApplePay) | [Apple Pay support](/docs/apple-pay), including `STPApplePayContext`. | [![StripeApplePay size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripeApplePaySize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripeApplePay&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripeApplePaySize/release?utm_campaign=badge-data) |\n| [StripePayments](StripePayments) | Bindings for the Stripe Payments API. | [![StripePayments size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripePaymentsSize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripePayments&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripePaymentsSize/release?utm_campaign=badge-data) |\n| [StripePaymentsUI](StripePaymentsUI) | Bindings for the Stripe Payments API, [STPPaymentCardTextField](https://stripe.com/docs/payments/accept-a-payment?platform=ios&ui=custom), STPCardFormView, and other UI elements. | [![StripePaymentsUI size](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fwww.emergetools.com%2Fapi%2Fv2%2Fpublic_new_build%3FexampleId%3Dcom.stripe.StripePaymentsUISize%26platform%3Dios%26badgeOption%3Ddownload_and_install_size%26buildType%3Drelease&query=$.badgeMetadata&label=StripePaymentsUI&logo=apple)](https://www.emergetools.com/app/example/ios/com.stripe.StripePaymentsUISize/release?utm_campaign=badge-data) |\n\n## Releases\n\nWe support Cocoapods and Swift Package Manager.\n\nIf you link the library manually, use a version from our [releases](https://github.com/stripe/stripe-ios/releases) page and make sure to embed <ins>all</ins> of the required frameworks.\n\nFor the `Stripe` module, link the following frameworks:\n- `Stripe.xcframework`\n- `Stripe3DS2.xcframework`\n- `StripeApplePay.xcframework`\n- `StripePayments.xcframework`\n- `StripePaymentsUI.xcframework`\n- `StripeIssuing.xcframework`\n- `StripeCore.xcframework`\n- `StripeUICore.xcframework`\n\nFor other modules, follow the instructions below:\n- [StripeApplePay](StripeApplePay/README.md#manual-linking)\n- [StripeConnect](StripeConnect/README.md#manual-linking)\n- [StripeFinancialConnections](StripeFinancialConnections/README.md#manual-linking)\n- [StripeIdentity](StripeIdentity/README.md#manual-linking)\n- [StripeIssuing](StripeIssuing/README.md#manual-linking)\n- [StripePaymentSheet](StripePaymentSheet/README.md#manual-linking)\n- [StripePayments](StripePayments/README.md#manual-linking)\n- [StripePaymentsUI](StripePaymentsUI/README.md#manual-linking)\n\nIf you're reading this on GitHub.com, please make sure you are looking at the [tagged version](https://github.com/stripe/stripe-ios/tags) that corresponds to the release you have installed. Otherwise, the instructions and example code may be mismatched with your copy.\n\n## Requirements\n\nThe Stripe iOS SDK requires Xcode 16 or later and is compatible with apps targeting iOS 13 or above. We support Catalyst on macOS 11 or later.\n\nFor iOS 12 support, please use [v22.8.4](https://github.com/stripe/stripe-ios/tree/v22.8.4). For iOS 11 support, please use [v21.13.0](https://github.com/stripe/stripe-ios/tree/v21.13.0). For iOS 10, please use [v19.4.0](https://github.com/stripe/stripe-ios/tree/v19.4.0). If you need to support iOS 9, use [v17.0.2](https://github.com/stripe/stripe-ios/tree/v17.0.2).\n\n## Getting started\n\n### Integration\n\nGet started with our [ğŸ“š integration guides](https://stripe.com/docs/payments/accept-a-payment?platform=ios) and [example projects](/Example), or [ğŸ“˜ browse the SDK reference](https://stripe.dev/stripe-ios/docs/index.html) for fine-grained documentation of all the classes and methods in the SDK.\n\n### Examples\n\n- [Prebuilt UI](Example/PaymentSheet%20Example) (Recommended)\n  - This example demonstrates how to build a payment flow using [`PaymentSheet`](https://stripe.com/docs/payments/accept-a-payment?platform=ios), an embeddable native UI component that lets you accept [10+ payment methods](https://stripe.com/docs/payments/payment-methods/integration-options#payment-method-product-support) with a single integration.\n\n- [Non-Card Payment Examples](Example/Non-Card%20Payment%20Examples)\n  - This example demonstrates how to manually accept various payment methods using the Stripe API.\n\n## Card scanning\n\n[PaymentSheet](https://stripe.com/docs/payments/accept-a-payment?platform=ios) offers built-in card scanning. To enable card scanning, you'll need to set `NSCameraUsageDescription` in your application's plist, and provide a reason for accessing the camera (e.g. \"To scan cards\"). Card scanning is supported on devices with iOS 13 or higher.\n\nYou can demo this feature in our [PaymentSheet example app](Example/PaymentSheet%20Example). When you run the example app on a device, you'll see a \"Scan Card\" button when adding a new card.\n\n## Contributing\n\nWe welcome contributions of any kind including new features, bug fixes, and documentation improvements. Please first open an issue describing what you want to build if it is a major change so that we can discuss how to move forward. Otherwise, go ahead and open a pull request for minor changes such as typo fixes and one liners.\n\n### Running tests\n\n1. From the root of the repo, run `bundle install && bundle exec fastlane stripeios_tests`. This will install the test dependencies and run the tests.\n2. Once you have run this once, you can also run the tests in Xcode from the `StripeiOS` target in `Stripe.xcworkspace`.\n\nTo re-record snapshot tests, use the `bundle exec ruby ci_scripts/snapshots.rb --record`.\n\n## Migrating from older versions\n\nSee [MIGRATING.md](https://github.com/stripe/stripe-ios/blob/master/MIGRATING.md)\n\n## Code style\nWe use [swiftlint](https://github.com/realm/SwiftLint) to enforce code style.\n\nTo install it, run `brew install swiftlint`\n\nTo lint your code before pushing you can run `ci_scripts/lint_modified_files.sh`\n\nYou can also add this script as a pre-push hook by running `ln -s \"$(pwd)/ci_scripts/lint_modified_files.sh\" .git/hooks/pre-push && chmod +x .git/hooks/pre-push`\n\nTo format modified files automatically, you can use `ci_scripts/format_modified_files.sh` and you can add it as a pre-commit hook using `ln -s \"$(pwd)/ci_scripts/format_modified_files.sh\" .git/hooks/pre-commit && chmod +x .git/hooks/pre-commit`\n\n## Licenses\n\n- [Stripe iOS SDK License](LICENSE)\n",
      "stars_today": 0
    },
    {
      "id": 643909,
      "name": "devtools",
      "full_name": "r-lib/devtools",
      "description": "Tools to make an R developer's life easier",
      "html_url": "https://github.com/r-lib/devtools",
      "stars": 2486,
      "forks": 764,
      "language": "R",
      "topics": [
        "package-creation",
        "r"
      ],
      "created_at": "2010-05-03T04:08:49Z",
      "updated_at": "2026-01-13T23:32:52Z",
      "pushed_at": "2026-01-13T23:45:16Z",
      "open_issues": 45,
      "owner": {
        "login": "r-lib",
        "avatar_url": "https://avatars.githubusercontent.com/u/22618716?v=4"
      },
      "readme": "# devtools <a href=\"https://devtools.r-lib.org/\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" alt=\"\"/></a>\n\n<!-- badges: start -->\n[![R-CMD-check](https://github.com/r-lib/devtools/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/r-lib/devtools/actions/workflows/R-CMD-check.yaml)\n[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/devtools)](https://cran.r-project.org/package=devtools)\n[![Codecov test coverage](https://codecov.io/gh/r-lib/devtools/graph/badge.svg)](https://app.codecov.io/gh/r-lib/devtools)\n<!-- badges: end -->\n\nThe aim of devtools is to make package development easier by providing R\nfunctions that simplify and expedite common tasks. [R\nPackages](https://r-pkgs.org/) is a book based around this workflow.\n\n## Installation\n\n```r\n# Install devtools from CRAN\ninstall.packages(\"devtools\")\n\n# Or the development version from GitHub:\n# install.packages(\"pak\")\npak::pak(\"r-lib/devtools\")\n```\n\n## Cheatsheet\n\n<a href=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/package-development.pdf\"><img src=\"https://github.com/rstudio/cheatsheets/raw/main/pngs/thumbnails/package-development-thumbs.png\" height=\"252\" alt=\"thumbnail of package development cheatsheet\"/></a>\n\n\n## Usage\n\nAll devtools functions accept a path as an argument, e.g.\n`load_all(\"path/to/mypkg\")`. If you don't specify a path, devtools will\nlook in the current working directory - this is a recommended practice.\n\n### Frequent development tasks:\n\n* `load_all()` simulates installing and reloading your package, loading R code\n  in `R/`, compiled shared objects in `src/` and data files in `data/`. During\n  development you would usually want to access all functions (even un-exported\n  internal ones) so `load_all()` works as if all functions were exported in the\n  package `NAMESPACE`.\n\n* `document()` updates generated documentation in `man/`, file collation and\n  `NAMESPACE`.\n\n* `test()` reloads your code with `load_all()`, then runs all `testthat` tests.\n\n* `test_coverage()` runs test coverage on your package with\n  [covr](https://github.com/r-lib/covr). This makes it easy to see what parts of your\n  package could use more tests!\n\n### Building and installing:\n\n* `install()` reinstalls the package, detaches the currently loaded version\n  then reloads the new version with `library()`. Reloading a package is not\n  guaranteed to work: see the documentation for `unload()` for caveats.\n\n* `build()` builds a package file from package sources. You can use it to build\n  a binary version of your package.\n\n* `install_*` functions install an R package:\n   * `install_github()` from GitHub\n   * `install_gitlab()` from GitLab\n   * `install_bitbucket()` from Bitbucket\n   * `install_url()` from an arbitrary url\n   * `install_git()` and `install_svn()` from an arbitrary git or SVN repository\n   * `install_local()` from a local file on disk\n   * `install_version()` from a specific version on CRAN\n\n* `update_packages()` updates a package to the latest version. This works\n  both on packages installed from CRAN as well as those installed from any of\n  the `install_*` functions.\n\n### Check and release:\n\n* `check()` updates the documentation, then builds and checks the package locally.\n* `check_win_release()`, `check_win_devel()`, and `check_mac_release()` check\n  a package using [win-builder](https://win-builder.r-project.org/) or\n  <https://mac.r-project.org/macbuilder/submit.html>.\n* `release()` and `submit_cran()` handle the mechanics of CRAN submission with\n  or without, respectively, (re)-running lots of local checks.\n\n## Learning more\n\nR package development can be intimidating, however there are now a number of\nvaluable resources to help!\n\n<a href=\"https://r-pkgs.org\"><img src=\"http://r-pkgs.org/images/cover-2e-small.png\" height=\"252\" align = \"right\" alt=\"Cover image of R Packages book\"/></a>\n\n1. R Packages is a book that gives a comprehensive treatment of all common parts\n   of package development and uses devtools throughout.\n    * The first edition is no longer available online, but it is still in print. Note that it has grown somewhat out of sync with the current version of devtools.\n    * A second edition that reflects the current state of devtools, plus new topics such as package websites and GitHub Actions, is available at <https://r-pkgs.org> and in paperback format.\n    * The [Whole Game](https://r-pkgs.org/whole-game.html) and\n      [Package structure](https://r-pkgs.org/package-structure-state.html) chapters\n      make great places to start.\n\n2. [Posit Community - package\n   development](https://forum.posit.co/c/package-development/11)\n   is a great place to ask specific questions related to package development.\n\n3. [rOpenSci packages](https://devguide.ropensci.org/) has\n   extensive documentation on best practices for R packages looking to be\n   contributed to rOpenSci, but also very useful general recommendations\n   for package authors.\n\n4. There are a number of fantastic blog posts on writing your first package, including\n   - [Writing an R package from scratch - Hilary Parker](https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/)\n   - [How to develop good R packages - MaÃ«lle Salmon](https://masalmon.eu/2017/12/11/goodrpackages/)\n   - [Making your first R package - Fong Chun Chan](https://tinyheero.github.io/jekyll/update/2015/07/26/making-your-first-R-package.html)\n   - [Writing an R package from scratch - Tomas Westlake](https://r-mageddon.netlify.app/post/writing-an-r-package-from-scratch/)\n\n5. [Writing R\n   Extensions](https://cran.r-project.org/doc/manuals/r-release/R-exts.html) is\n   the exhaustive, canonical reference for writing R packages, maintained by\n   the R core developers.\n\n## Conscious uncoupling\n\ndevtools started off as a lean-and-mean package to facilitate local package\ndevelopment, but over the years it accumulated more and more functionality.\ndevtools has undergone a [conscious\nuncoupling](https://web.archive.org/web/20140326060230/https://www.goop.com/journal/be/conscious-uncoupling)\nto split out functionality into smaller, more tightly focussed packages. This\nincludes:\n\n* [testthat](https://github.com/r-lib/testthat): Writing and running tests\n  (i.e. `test()`).\n\n* [roxygen2](https://github.com/r-lib/roxygen2): Function and package documentation\n  (i.e. `document()`).\n\n* [remotes](https://github.com/r-lib/remotes): Installing packages (i.e.\n  `install_github()`).\n\n* [pkgbuild](https://github.com/r-lib/pkgbuild): Building binary packages\n  (including checking if build tools are available) (i.e. `build()`).\n\n* [pkgload](https://github.com/r-lib/pkgload): Simulating package loading (i.e.\n  `load_all()`).\n\n* [rcmdcheck](https://github.com/r-lib/rcmdcheck): Running R CMD check and\n  reporting the results (i.e. `check()`).\n\n* [revdepcheck](https://github.com/r-lib/revdepcheck): Running R CMD check on\n  all reverse dependencies, and figuring out what's changed since the last CRAN\n  release (i.e. `revdep_check()`).\n\n* [sessioninfo](https://github.com/r-lib/sessioninfo): R session info (i.e.\n  `session_info()`).\n\n* [usethis](https://github.com/r-lib/usethis): Automating package setup (i.e.\n  `use_test()`).\n\nGenerally, you would not need to worry about these different packages, because\ndevtools installs all of them automatically. You will need to care, however, if\nyou're filing a bug because reporting it at the correct place will lead to a\nspeedier resolution.\n\nYou may also need to care if you are trying to use some devtools functionality\nin your own package or deployed application. Generally in these cases it\nis better to depend on the particular package directly rather than depend on devtools,\ne.g. use `sessioninfo::session_info()` rather than `devtools::session_info()`,\nor `remotes::install_github()` vs `devtools::install_github()`.\n\nHowever for day to day development we recommend you continue to use\n`library(devtools)` to quickly load all needed development tools, just like\n`library(tidyverse)` quickly loads all the tools necessary for data exploration\nand visualization.\n\n## Code of conduct\n\nPlease note that the devtools project is released with a [Contributor Code of Conduct](https://github.com/r-lib/devtools/blob/main/.github/CODE_OF_CONDUCT.md). By contributing to this project, you agree to abide by its terms.\n",
      "stars_today": 0
    },
    {
      "id": 429651616,
      "name": "autoware_universe",
      "full_name": "autowarefoundation/autoware_universe",
      "description": null,
      "html_url": "https://github.com/autowarefoundation/autoware_universe",
      "stars": 1451,
      "forks": 832,
      "language": "C++",
      "topics": [
        "3d-map",
        "autonomous-driving",
        "autonomous-vehicles",
        "autoware",
        "calibration",
        "planner",
        "ros",
        "ros2",
        "self-driving-car"
      ],
      "created_at": "2021-11-19T02:59:37Z",
      "updated_at": "2026-01-16T01:04:58Z",
      "pushed_at": "2026-01-16T01:04:53Z",
      "open_issues": 394,
      "owner": {
        "login": "autowarefoundation",
        "avatar_url": "https://avatars.githubusercontent.com/u/48420599?v=4"
      },
      "readme": "# Autoware Universe\n\n## Welcome to Autoware Universe\n\nAutoware Universe serves as a foundational pillar within the Autoware ecosystem, playing a critical role in enhancing the core functionalities of autonomous driving technologies.\nThis repository is a pivotal element of the Autoware Core/Universe concept, managing a wide array of packages that significantly extend the capabilities of autonomous vehicles.\n\n![autoware_universe_front](docs/assets/images/autoware_universe_front.png)\n\n## Getting Started\n\nTo dive into the vast world of Autoware and understand how Autoware Universe fits into the bigger picture, we recommend starting with the [Autoware Documentation](https://autowarefoundation.github.io/autoware-documentation/). This resource provides a thorough overview of the Autoware ecosystem, guiding you through its components, functionalities, and how to get started with development.\n\n### Explore Autoware Universe documentation\n\nFor those looking to explore the specifics of Autoware Universe components, the [Autoware Universe Documentation](https://autowarefoundation.github.io/autoware_universe/), deployed with MKDocs, offers detailed insights.\n\n## Code Coverage Metrics\n\nBelow table shows the coverage rate of entire Autoware Universe and sub-components respectively.\n\n### Entire Project Coverage\n\n[![codecov](https://codecov.io/github/autowarefoundation/autoware_universe/graph/badge.svg?token=KQP68YQ65D)](https://codecov.io/github/autowarefoundation/autoware_universe)\n\n### Component-wise Coverage\n\nYou can check more details by clicking the badge and navigating the codecov website.\n\n| Component    | Coverage                                                                                                                                                                                                                                                                                                        |\n| ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Common       | [![codecov](https://img.shields.io/badge/dynamic/json?url=https://codecov.io/api/v2/github/autowarefoundation/repos/autoware_universe/components&label=Common%20Packages&query=$.[0].coverage)](https://app.codecov.io/gh/autowarefoundation/autoware_universe?components%5B0%5D=Common%20Packages)             |\n| Control      | [![codecov](https://img.shields.io/badge/dynamic/json?url=https://codecov.io/api/v2/github/autowarefoundation/repos/autoware_universe/components&label=Control%20Packages&query=$.[1].coverage)](https://app.codecov.io/gh/autowarefoundation/autoware_universe?components%5B0%5D=Control%20Packages)           |\n| Evaluator    | [![codecov](https://img.shields.io/badge/dynamic/json?url=https://codecov.io/api/v2/github/autowarefoundation/repos/autoware_universe/components&label=Evaluator%20Packages&query=$.[2].coverage)](https://app.codecov.io/gh/autowarefoundation/autoware_universe?components%5B0%5D=Evaluator%20Packages)       |\n| Launch       | TBD                                                                                                                                                                                                                                                                                                             |\n| Localization | [![codecov](https://img.shields.io/badge/dynamic/json?url=https://codecov.io/api/v2/github/autowarefoundation/repos/autoware_universe/components&label=Localization%20Packages&query=$.[4].coverage)](https://app.codecov.io/gh/autowarefoundation/autoware_universe?components%5B0%5D=Localization%20Packages) |\n| Map          | [![codecov](https://img.shields.io/badge/dynamic/json?url=https://codecov.io/api/v2/github/autowarefoundation/repos/autoware_universe/components&label=Map%20Packages&query=$.[5].coverage)](https://app.codecov.io/gh/autowarefoundation/autoware_universe?components%5B0%5D=Map%20Packages)                   |\n| Perception   | [![codecov](https://img.shields.io/badge/dynamic/json?url=https://codecov.io/api/v2/github/autowarefoundation/repos/autoware_universe/components&label=Perception%20Packages&query=$.[6].coverage)](https://app.codecov.io/gh/autowarefoundation/autoware_universe?components%5B0%5D=Perception%20Packages)     |\n| Planning     | [![codecov](https://img.shields.io/badge/dynamic/json?url=https://codecov.io/api/v2/github/autowarefoundation/repos/autoware_universe/components&label=Planning%20Packages&query=$.[7].coverage)](https://app.codecov.io/gh/autowarefoundation/autoware_universe?components%5B0%5D=Planning%20Packages)         |\n| Sensing      | [![codecov](https://img.shields.io/badge/dynamic/json?url=https://codecov.io/api/v2/github/autowarefoundation/repos/autoware_universe/components&label=Sensing%20Packages&query=$.[8].coverage)](https://app.codecov.io/gh/autowarefoundation/autoware_universe?components%5B0%5D=Sensing%20Packages)           |\n| Simulator    | [![codecov](https://img.shields.io/badge/dynamic/json?url=https://codecov.io/api/v2/github/autowarefoundation/repos/autoware_universe/components&label=Simulator%20Packages&query=$.[9].coverage)](https://app.codecov.io/gh/autowarefoundation/autoware_universe?components%5B0%5D=Simulator%20Packages)       |\n| System       | [![codecov](https://img.shields.io/badge/dynamic/json?url=https://codecov.io/api/v2/github/autowarefoundation/repos/autoware_universe/components&label=System%20Packages&query=$.[10].coverage)](https://app.codecov.io/gh/autowarefoundation/autoware_universe?components%5B0%5D=System%20Packages)            |\n| Vehicle      | [![codecov](https://img.shields.io/badge/dynamic/json?url=https://codecov.io/api/v2/github/autowarefoundation/repos/autoware_universe/components&label=Vehicle%20Packages&query=$.[11].coverage)](https://app.codecov.io/gh/autowarefoundation/autoware_universe?components%5B0%5D=Vehicle%20Packages)          |\n\n<!-- NOTE: `query` fields to shields.io should be converted to slug form   -->\n<!--\nTODO(soblin):\n- dynamic `label` name(maybe not supported by shields.io)\n- use https://github.com/marketplace/actions/dynamic-badges\n-->\n",
      "stars_today": 0
    },
    {
      "id": 6926049,
      "name": "stripe-android",
      "full_name": "stripe/stripe-android",
      "description": "Stripe Android SDK    ",
      "html_url": "https://github.com/stripe/stripe-android",
      "stars": 1466,
      "forks": 703,
      "language": "Kotlin",
      "topics": [
        "stripe",
        "stripe-sdk"
      ],
      "created_at": "2012-11-29T18:11:30Z",
      "updated_at": "2026-01-15T22:02:56Z",
      "pushed_at": "2026-01-16T00:10:56Z",
      "open_issues": 94,
      "owner": {
        "login": "stripe",
        "avatar_url": "https://avatars.githubusercontent.com/u/856813?v=4"
      },
      "readme": "[<img width=\"250\" height=\"119\" src=\"https://raw.githubusercontent.com/stripe/stripe-android/master/assets/stripe_logo_slate_small.png\"/>](https://stripe.com/docs/mobile/android)\n\n# Stripe Android SDK\n\n[![CI](https://github.com/stripe/stripe-android/workflows/CI/badge.svg)](https://github.com/stripe/stripe-android/actions?query=workflow%3ACI)\n[![GitHub release](https://img.shields.io/github/release/stripe/stripe-android.svg?maxAge=60)](https://github.com/stripe/stripe-android/releases)\n[![License](https://img.shields.io/github/license/stripe/stripe-android)](https://github.com/stripe/stripe-android/blob/master/LICENSE)\n\n> [!TIP]\n> Want to chat live with Stripe engineers? Join us on our [Discord server](https://stripe.com/go/developer-chat).\n\nThe Stripe Android SDK makes it quick and easy to build an excellent payment experience in your Android app. We provide powerful and customizable UI elements that can be used out-of-the-box to collect your users' payment details. We also expose the low-level APIs that power those UIs so that you can build fully custom experiences. \n\nGet started with our [ğŸ“š integration guides](https://stripe.com/docs/payments/accept-a-payment?platform=android) and [example projects](#examples), or [ğŸ“˜ browse the SDK reference](https://stripe.dev/stripe-android/).\n\n> Updating to a newer version of the SDK? See our [migration guide](https://github.com/stripe/stripe-android/blob/master/MIGRATING.md) and [changelog](https://github.com/stripe/stripe-android/blob/master/CHANGELOG.md).\n\n\nTable of contents\n=================\n\n<!--ts-->\n   * [Features](#features)\n   * [Releases](#releases)\n   * [Installation](#installation)\n      * [Requirements](#requirements)\n      * [Configuration](#configuration)\n   * [Getting Started](#getting-started)\n   * [Examples](#examples)\n<!--te-->\n\n## Features\n\n**Simplified Security**: Use the SDK to collect credit card numbers and remain [PCI compliant](https://stripe.com/docs/security#pci-dss-guidelines). This means sensitive data is sent directly to Stripe instead of passing through your server. For more information, see our [Integration Security Guide](https://stripe.com/docs/security).\n\n**SCA-Ready**: The SDK automatically performs native [3D Secure authentication](https://stripe.com/docs/payments/3d-secure) to comply with [Strong Customer Authentication](https://stripe.com/docs/strong-customer-authentication) regulation in Europe.\n\n**Native UI**: We provide native screens and elements to collect payment. For example, [PaymentSheet](https://stripe.com/docs/payments/accept-a-payment?platform=android) is a prebuilt UI that combines all the steps required to pay - collecting payment details, and confirming the payment  - into a single sheet that displays on top of your app.\n\n<img src=\"https://raw.githubusercontent.com/stripe/stripe-android/master/assets/payment_sheet_complete.png\"/>\n\n**Google Pay**: Stripe is fully compatible with [Google Pay](https://stripe.com/docs/google-pay).\n\n**Stripe API**: We provide [low-level APIs](https://stripe.dev/stripe-android/payments-core/com.stripe.android/-stripe/index.html) that correspond to objects and methods in the Stripe API. You can build a custom UI on top of this layer.\n\n**Localized**: We support the following localizations: Bulgarian, Catalan, Chinese (Hong Kong), Chinese (Simplified), Chinese (Traditional), Croatian, Czech, Danish, Dutch, English (US), English (United Kingdom), Estonian, Filipino, Finnish, French, French (Canada), German, Greek, Hungarian, Indonesian, Italian, Japanese, Korean, Latvian, Lithuanian, Malay, Maltese, Norwegian BokmÃ¥l, Norwegian Nynorsk (Norway), Polish, Portuguese, Portuguese (Brazil), Romanian, Russian, Slovak, Slovenian, Spanish, Spanish (Latin America), Swedish, Turkish, Thai and Vietnamese.\n\n**Recommended usage**\nIf you're selling digital products or services that will be consumed within your app, (e.g. subscriptions, in-game currencies, game levels, access to premium content, or unlocking a full version), and you plan to distribute it through the Google Play Store, you must use Googles's in-app purchase APIs. See the [Google Play Billing](https://developer.android.com/distribute/play-billing) for more information. For all other scenarios you can use this SDK to process payments via Stripe.\n\n## Releases\n* The [changelog](CHANGELOG.md) provides a summary of changes in each release.\n* The [migration guide](MIGRATING.md) provides instructions on upgrading from older versions.\n\n## Installation\n\n### Requirements\n\n* Android 5.0 (API level 21) and above\n* [Android Gradle Plugin](https://developer.android.com/studio/releases/gradle-plugin) 8.1\n* [Gradle](https://gradle.org/releases/) 8.0\n\n### Configuration\n\nAdd `stripe-android` to your `build.gradle` dependencies.\n\n```\ndependencies {\n    implementation 'com.stripe:stripe-android:22.6.0'\n}\n```\n\n### Compatibility with Jetpack Compose\n\n`stripe-android` uses Jetpack Compose internally and expects consumers to use a compatible version:\n\n<table>\n <tr>\n  <td>20.22.0-20.31.0</td><td>Compose UI 1.4.x</td>\n </tr>\n <tr>\n  <td>20.32.0-20.53.0</td><td>Compose UI 1.5.x</td>\n </tr>\n <tr>\n  <td>21.0.0-Current</td><td>Compose UI 1.6.x or Compose UI 1.7.x</td>\n </tr>\n</table>\n\n## Getting Started\n\n### Integration\nGet started with our [ğŸ“š integration guides](https://stripe.com/docs/payments/accept-a-payment?platform=android) and [example projects](#examples), or [ğŸ“˜ browse the SDK reference](https://stripe.dev/stripe-android/).\n\n### Examples\n- The [PaymentSheet example project](https://github.com/stripe/stripe-android/tree/master/paymentsheet-example) demonstrates how to integrate and use our prebuilt ui (single-step and multi-step).\n- The [example project](https://github.com/stripe/stripe-android/tree/master/example) demonstrates other integrations, that give you more control over the user experience:\n    - how to use the Stripe class's synchronous and asynchronous methods\n    - how to use the CardFormView.\n",
      "stars_today": 0
    },
    {
      "id": 3368190,
      "name": "sentry-java",
      "full_name": "getsentry/sentry-java",
      "description": "A Sentry SDK for Java, Android and other JVM languages.",
      "html_url": "https://github.com/getsentry/sentry-java",
      "stars": 1292,
      "forks": 465,
      "language": "Kotlin",
      "topics": [
        "android",
        "apollo-client",
        "crash-reporting",
        "feign-client",
        "hacktoberfest",
        "java",
        "kotlin",
        "log4j2",
        "logback",
        "okhttp",
        "sdk",
        "sentry",
        "servlet",
        "spring",
        "spring-boot",
        "tag-production",
        "team-mobile",
        "team-web-backend",
        "timber"
      ],
      "created_at": "2012-02-06T15:46:55Z",
      "updated_at": "2026-01-15T15:24:20Z",
      "pushed_at": "2026-01-15T17:14:32Z",
      "open_issues": 235,
      "owner": {
        "login": "getsentry",
        "avatar_url": "https://avatars.githubusercontent.com/u/1396951?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://sentry.io/?utm_source=github&utm_medium=logo\" target=\"_blank\">\n    <picture>\n      <source srcset=\"https://sentry-brand.storage.googleapis.com/sentry-logo-white.png\" media=\"(prefers-color-scheme: dark)\" />\n      <source srcset=\"https://sentry-brand.storage.googleapis.com/sentry-logo-black.png\" media=\"(prefers-color-scheme: light), (prefers-color-scheme: no-preference)\" />\n      <img src=\"https://sentry-brand.storage.googleapis.com/sentry-logo-black.png\" alt=\"Sentry\" width=\"280\">\n    </picture>\n  </a>\n</p>\n\n_Bad software is everywhere, and we're tired of it. Sentry is on a mission to help developers write better software faster, so we can get back to enjoying technology. If you want to join us [<kbd>**Check out our open positions**</kbd>](https://sentry.io/careers/)_\n\nSentry SDK for Java and Android\n===========\n[![GH Workflow](https://img.shields.io/github/actions/workflow/status/getsentry/sentry-java/build.yml?branch=main)](https://github.com/getsentry/sentry-java/actions)\n[![codecov](https://codecov.io/gh/getsentry/sentry-java/branch/main/graph/badge.svg)](https://codecov.io/gh/getsentry/sentry-java)\n[![X Follow](https://img.shields.io/twitter/follow/sentry?label=sentry&style=social)](https://x.com/intent/follow?screen_name=sentry)\n[![Discord Chat](https://img.shields.io/discord/621778831602221064?logo=discord&logoColor=ffffff&color=7389D8)](https://discord.gg/PXa5Apfe7K)\n\n| Packages                                | Maven Central                                                                                                                                                  | Minimum Android API Version |\n|-----------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------| ------- |\n| sentry-android                          | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-android?style=for-the-badge&logo=sentry&color=green)                          | 21 |\n| sentry-android-core                     | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-android-core?style=for-the-badge&logo=sentry&color=green)                     | 21 |\n| sentry-android-distribution             | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-android-distribution?style=for-the-badge&logo=sentry&color=green)             | 21 |\n| sentry-android-ndk                      | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-android-ndk?style=for-the-badge&logo=sentry&color=green)                      | 21 |\n| sentry-android-timber                   | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-android-timber?style=for-the-badge&logo=sentry&color=green)                   | 21 |\n| sentry-android-fragment                 | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-android-fragment?style=for-the-badge&logo=sentry&color=green)                 | 21 |\n| sentry-android-navigation               | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-android-navigation?style=for-the-badge&logo=sentry&color=green)               | 21 |\n| sentry-android-sqlite                   | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-android-sqlite?style=for-the-badge&logo=sentry&color=green)                   | 21 |\n| sentry-android-replay                   | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-android-replay?style=for-the-badge&logo=sentry&color=green)                   | 26 |\n| sentry-compose-android                  | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-compose-android?style=for-the-badge&logo=sentry&color=green)                  | 21 |\n| sentry-compose-desktop                  | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-compose-desktop?style=for-the-badge&logo=sentry&color=green)                  | \n| sentry-compose                          | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-compose?style=for-the-badge&logo=sentry&color=green)                          | \n| sentry-apache-http-client-5             | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-apache-http-client-5?style=for-the-badge&logo=sentry&color=green)             |\n| sentry                                  | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry?style=for-the-badge&logo=sentry&color=green)                                  | 21 |\n| sentry-jul                              | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-jul?style=for-the-badge&logo=sentry&color=green)                              |\n| sentry-jdbc                             | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-jdbc?style=for-the-badge&logo=sentry&color=green)                             |\n| sentry-apollo                           | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-apollo?style=for-the-badge&logo=sentry&color=green)                           | 21 |\n| sentry-apollo-3                         | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-apollo-3?style=for-the-badge&logo=sentry&color=green)                         | 21 |\n| sentry-apollo-4                         | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-apollo-4?style=for-the-badge&logo=sentry&color=green)                         | 21 |\n| sentry-kotlin-extensions                | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-kotlin-extensions?style=for-the-badge&logo=sentry&color=green)                | 21 |\n| sentry-ktor-client                      | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-ktor-client?style=for-the-badge&logo=sentry&color=green)                      | 21 |\n| sentry-servlet                          | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-servlet?style=for-the-badge&logo=sentry&color=green)                          | |\n| sentry-servlet-jakarta                  | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-servlet-jakarta?style=for-the-badge&logo=sentry&color=green)                  | |\n| sentry-spring-boot                      | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-spring-boot?style=for-the-badge&logo=sentry&color=green)                      |\n| sentry-spring-boot-jakarta              | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-spring-boot-jakarta?style=for-the-badge&logo=sentry&color=green)              |\n| sentry-spring-boot-4                    | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-spring-boot-4?style=for-the-badge&logo=sentry&color=green)                    |\n| sentry-spring-boot-4-starter            | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-spring-boot-4-starter?style=for-the-badge&logo=sentry&color=green)            |\n| sentry-spring-boot-starter              | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-spring-boot-starter?style=for-the-badge&logo=sentry&color=green)              |\n| sentry-spring-boot-starter-jakarta      | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-spring-boot-starter-jakarta?style=for-the-badge&logo=sentry&color=green)      |\n| sentry-spring                           | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-spring?style=for-the-badge&logo=sentry&color=green)                           |\n| sentry-spring-jakarta                   | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-spring-jakarta?style=for-the-badge&logo=sentry&color=green)                   |\n| sentry-spring-7                         | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-spring-7?style=for-the-badge&logo=sentry&color=green)                         |\n| sentry-logback                          | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-logback?style=for-the-badge&logo=sentry&color=green)                          |\n| sentry-log4j2                           | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-log4j2?style=for-the-badge&logo=sentry&color=green)                           |\n| sentry-bom                              | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-bom?style=for-the-badge&logo=sentry&color=green)                              |\n| sentry-graphql                          | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-graphql?style=for-the-badge&logo=sentry&color=green)                          |\n| sentry-graphql-core                     | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-graphql-core?style=for-the-badge&logo=sentry&color=green)                     |\n| sentry-graphql-22                       | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-graphql-22?style=for-the-badge&logo=sentry&color=green)                       |\n| sentry-quartz                           | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-quartz?style=for-the-badge&logo=sentry&color=green)                           |\n| sentry-openfeign                        | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-openfeign?style=for-the-badge&logo=sentry&color=green)                        |\n| sentry-openfeature                      | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-openfeature?style=for-the-badge&logo=sentry&color=green)                      |\n| sentry-launchdarkly-android             | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-launchdarkly-android?style=for-the-badge&logo=sentry&color=green)             |\n| sentry-launchdarkly-server              | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-launchdarkly-server?style=for-the-badge&logo=sentry&color=green)              |\n| sentry-opentelemetry-agent              | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-opentelemetry-agent?style=for-the-badge&logo=sentry&color=green)              |\n| sentry-opentelemetry-agentcustomization | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-opentelemetry-agentcustomization?style=for-the-badge&logo=sentry&color=green) |\n| sentry-opentelemetry-core               | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-opentelemetry-core?style=for-the-badge&logo=sentry&color=green)               |\n| sentry-okhttp                           | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-okhttp?style=for-the-badge&logo=sentry&color=green)                           |\n| sentry-reactor                          | ![Maven Central Version](https://img.shields.io/maven-central/v/io.sentry/sentry-reactor?style=for-the-badge&logo=sentry&color=green)                          |\n\n# Releases\n\nThis repo uses the following ways to release SDK updates:\n\n- `Pre-release`: We create pre-releases (alpha, beta, RC,â€¦) for larger and potentially more impactful changes, such as new features or major versions.\n- `Latest`: We continuously release major/minor/hotfix versions from the `main` branch. These releases go through all our internal quality gates and are very safe to use and intended to be the default for most teams.\n- `Stable`: We promote releases from `Latest` when they have been used in the field for some time and in scale, considering time since release, adoption, and other quality and stability metrics. These releases will be indicated on the releases page (https://github.com/getsentry/sentry-java/releases/) with the `Stable` suffix.\n\n# Useful links and docs\n\n* A deep dive into how we built [Session Replay for Android](https://www.droidcon.com/2024/11/22/rewind-and-resolve-a-deep-dive-into-building-session-replay-for-android/) at Droidcon London 2024.\n* Current Javadocs [generated from source code](https://getsentry.github.io/sentry-java/).\n* Java SDK version 1.x [can still be found here](https://docs.sentry.io/clients/java/).\n* Migration page from [sentry-android 1.x and 2.x to sentry-android 4.x](https://docs.sentry.io/platforms/android/migration/).\n* Migration page from [sentry 1.x to sentry 4.x](https://docs.sentry.io/platforms/java/migration/).\n* Releases from sentry-android [2.x and its changelogs](https://github.com/getsentry/sentry-android/releases).\n* Sentry Android Gradle Plugin repo [sits on another repo](https://github.com/getsentry/sentry-android-gradle-plugin)\n\n# Blog posts\n\n* [Sentryâ€™s Android Gradle Plugin Updated with Room Support and More](https://blog.sentry.io/2022/04/20/sentrys-android-gradle-plugin-updated-with-room-support-and-more/)\n* [Troubleshooting Spring Boot applications with Sentry](https://blog.sentry.io/2022/04/18/troubleshooting-spring-boot-applications-with-sentry)\n* [Android Manifest Placeholders](https://blog.sentry.io/2022/03/30/android-manifest-placeholders/)\n* [UI Breadcrumbs for Android Error Events](https://blog.sentry.io/2022/02/08/ui-breadcrumbs-for-android-error-events)\n* [Bytecode transformations: The Android Gradle Plugin](https://blog.sentry.io/2021/12/14/bytecode-transformations-the-android-gradle-plugin)\n* [Sentry's response to Log4j vulnerability CVE-2021-44228](https://blog.sentry.io/2021/12/15/sentrys-response-to-log4j-vulnerability-cve-2021-44228)\n* [Mobile Vitals - Four Metrics Every Mobile Developer Should Care About](https://blog.sentry.io/2021/08/23/mobile-vitals-four-metrics-every-mobile-developer-should-care-about/).\n* [Supporting Native Android Libraries Loaded From APKs](https://blog.sentry.io/2021/05/13/supporting-native-android-libraries-loaded-from-apks).\n* [A Sanity Listicle for Mobile Developers](https://blog.sentry.io/2021/03/30/a-sanity-listicle-for-mobile-developers/).\n* [Performance Monitoring for Android Applications](https://blog.sentry.io/2021/03/18/performance-monitoring-for-android-applications).\n* [Close the Loop with User Feedback](https://blog.sentry.io/2021/02/16/close-the-loop-with-user-feedback).\n* [How to use Sentry Attachments with Mobile Applications](https://blog.sentry.io/2021/02/03/how-to-use-sentry-attachments-with-mobile-applications).\n* [Adding Native support to our Android SDK](https://blog.sentry.io/2019/11/25/adding-native-support-to-our-android-sdk).\n* [New Android SDK How-to](https://blog.sentry.io/2019/12/10/new-android-sdk-how-to).\n\n# Samples\n\n* [Sample App. with Sentry Android SDK and Sentry Gradle Plugin](https://github.com/getsentry/examples/tree/master/android).\n* [Sample App. with Sentry Java SDK](https://github.com/getsentry/examples/tree/master/java).\n* [Sample for Development](https://github.com/getsentry/sentry-java/tree/main/sentry-samples).\n\n# Sentry Self Hosted Compatibility\n\nSince version 3.0.0 of this SDK, Sentry version >= v20.6.0 is required. This only applies to self-hosted Sentry, if you are using [sentry.io](http://sentry.io/) no action is needed.\n\nSince version 6.0.0 of this SDK, Sentry version >= v21.9.0 is required or you have to manually disable sending client reports via the `sendClientReports` option. This only applies to self-hosted Sentry, if you are using [sentry.io](http://sentry.io/) no action is needed.\n\nSince version 7.0.0 of this SDK, Sentry version >= 22.12.0 is required to properly ingest transactions with unfinished spans. This only applies to self-hosted Sentry, if you are using [sentry.io](http://sentry.io/) no action is needed.\n\n# Resources\n\n* [![Java Documentation](https://img.shields.io/badge/documentation-sentry.io-green.svg?label=java%20docs)](https://docs.sentry.io/platforms/java/)\n* [![Android Documentation](https://img.shields.io/badge/documentation-sentry.io-green.svg?label=android%20docs)](https://docs.sentry.io/platforms/android/)\n* [![Discussions](https://img.shields.io/github/discussions/getsentry/sentry-java.svg)](https://github.com/getsentry/sentry-java/discussions)\n* [![Discord Chat](https://img.shields.io/discord/621778831602221064?logo=discord&logoColor=ffffff&color=7389D8)](https://discord.gg/PXa5Apfe7K)\n* [![Stack Overflow](https://img.shields.io/badge/stack%20overflow-sentry-green.svg)](http://stackoverflow.com/questions/tagged/sentry)\n* [![Code of Conduct](https://img.shields.io/badge/code%20of%20conduct-sentry-green.svg)](https://github.com/getsentry/.github/blob/master/CODE_OF_CONDUCT.md)\n* [![Twitter Follow](https://img.shields.io/twitter/follow/getsentry?label=getsentry&style=social)](https://twitter.com/intent/follow?screen_name=getsentry)\n",
      "stars_today": 0
    },
    {
      "id": 45709704,
      "name": "sf",
      "full_name": "r-spatial/sf",
      "description": "Simple Features for R",
      "html_url": "https://github.com/r-spatial/sf",
      "stars": 1415,
      "forks": 300,
      "language": "R",
      "topics": [
        "gdal",
        "geos",
        "proj",
        "r",
        "r-package",
        "rstats",
        "spatial"
      ],
      "created_at": "2015-11-06T21:49:34Z",
      "updated_at": "2026-01-15T17:20:21Z",
      "pushed_at": "2026-01-15T17:26:00Z",
      "open_issues": 74,
      "owner": {
        "login": "r-spatial",
        "avatar_url": "https://avatars.githubusercontent.com/u/25086656?v=4"
      },
      "readme": "<!-- badges: start -->\n[![R-CMD-check](https://github.com/r-spatial/sf/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/r-spatial/sf/actions/workflows/R-CMD-check.yaml)\n[![tic-db](https://github.com/r-spatial/sf/actions/workflows/tic-db.yml/badge.svg)](https://github.com/r-spatial/sf/actions/workflows/tic-db.yml)\n[![Coverage Status](https://img.shields.io/codecov/c/github/r-spatial/sf/main.svg)](https://app.codecov.io/gh/r-spatial/sf)\n[![License](http://img.shields.io/badge/license-GPL%20%28%3E=%202%29-brightgreen.svg?style=flat)](http://www.gnu.org/licenses/gpl-2.0.html)\n[![CRAN](https://www.r-pkg.org/badges/version/sf)](https://cran.r-project.org/package=sf)\n[![cran checks](https://badges.cranchecks.info/worst/sf.svg)](https://cran.r-project.org/web/checks/check_results_sf.html)\n[![Downloads](https://cranlogs.r-pkg.org/badges/sf?color=brightgreen)](https://www.r-pkg.org/pkg/sf)\n[![status](https://tinyverse.netlify.app/badge/sf)](https://CRAN.R-project.org/package=sf)\n<!-- badges: end -->\n\n# Simple Features for R\n\n<a href=\"https://gist.github.com/edzer/f461a3a95570c4ab7edf3125c2f19d20\"><img align=\"right\" src=\"https://user-images.githubusercontent.com/520851/34887433-ce1d130e-f7c6-11e7-83fc-d60ad4fae6bd.gif\" /></a>\n\nA package that provides [simple features access](https://en.wikipedia.org/wiki/Simple_Features) for R. \n\n[Blogs, links](#blogs-presentations-vignettes-sp-sf-wiki) â€¢ [Cheatsheet](#cheatsheet) â€¢ [Installing](#installing)\nâ€¢ [Contributing](#contributing) â€¢ [Acknowledgment](#acknowledgment) â€¢ [How to cite](#how-to-cite)\n\nPackage sf:\n\n* represents simple features as records in a `data.frame` or `tibble` with a geometry list-column\n* represents natively in R all 17 simple feature types for all dimensions (XY, XYZ, XYM, XYZM)\n* interfaces to [GEOS](https://libgeos.org) for geometrical operations on projected coordinates, and (through R package [s2](https://cran.r-project.org/package=s2)) to [s2geometry](http://s2geometry.io/) for geometrical operations on ellipsoidal coordinates\n* interfaces to [GDAL](https://gdal.org/), supporting all driver options, `Date` and `POSIXct` and list-columns\n* interfaces to [PRÃ˜J](http://proj.org/) for coordinate reference system conversion and transformation\n* uses [well-known-binary](https://en.wikipedia.org/wiki/Well-known_text#Well-known_binary) serialisations written in C++/Rcpp for fast I/O with GDAL and GEOS \n* reads from and writes to spatial databases such as [PostGIS](http://postgis.net/) using [DBI](https://cran.r-project.org/package=DBI)\n* is extended by \n    * [lwgeom](https://github.com/r-spatial/lwgeom/) for selected liblwgeom/PostGIS functions\n    * [stars](https://github.com/r-spatial/stars/) for raster data, and raster or vector data cubes (spatial time series)\n    * [sfnetworks](https://luukvdmeer.github.io/sfnetworks/) for geospatial network data\n\n<a href=\"https://gist.github.com/edzer/442d74a5775abcd5068cf3e73b23687b\"><img align=\"left\" src=\"https://user-images.githubusercontent.com/520851/50280460-e35c1880-044c-11e9-9ed7-cc46754e49db.jpg\" /></a>\n\n(Illustration (c) 2018 by <a href=\"https://twitter.com/allison_horst/status/1071456081308614656\">Allison Horst</a>)\n\n## Books, journal articles, blogs, presentations, vignettes, sp-sf wiki\n\n* an open access [R Journal article](https://journal.r-project.org/archive/2018/RJ-2018-009/index.html) summarizes the package\n* two books: [Spatial Data Science: with applications in R](https://r-spatial.org/book/), [Geocomputation with R](https://r.geocompx.org/)\n* package vignettes: [first](https://r-spatial.github.io/sf/articles/sf1.html), [second](https://r-spatial.github.io/sf/articles/sf2.html), [third](https://r-spatial.github.io/sf/articles/sf3.html), [fourth](https://r-spatial.github.io/sf/articles/sf4.html), [fifth](https://r-spatial.github.io/sf/articles/sf5.html), [sixth](https://r-spatial.github.io/sf/articles/sf6.html), [seventh](https://r-spatial.github.io/sf/articles/sf7.html)\n* blog posts: [first](https://r-spatial.org/r/2016/02/15/simple-features-for-r.html), [second](https://r-spatial.org/r/2016/07/18/sf2.html), [third](https://r-spatial.org/r/2016/11/02/sfcran.html), [fourth](https://r-spatial.org/r/2017/01/12/newssf.html)\n* the original R Consortium ISC [proposal](PROPOSAL.md), the R Consortium [blog post](https://www.r-consortium.org/blog/2017/01/03/simple-features-now-on-cran)\n* presentations: [rstudio::conf 2018](https://edzer.github.io/rstudio_conf/#1) ([video](https://posit.co/resources/videos/tidy-spatial-data-analysis/)), [UseR! 2016](http://pebesma.staff.ifgi.de/pebesma_sfr.pdf)\n* wiki page describing [sp-sf migration](https://github.com/r-spatial/sf/wiki/Migrating)\n\n## Cheatsheet\n[CC 4.0](https://creativecommons.org/licenses/by/4.0/) BY [Ryan Garnett](https://github.com/ryangarnett)  \n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/sf.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/sf.png\" /></a>\n\n## Installing\n\nInstall either from CRAN with:\n```r\ninstall.packages(\"sf\")\n```\nThis will install binary packages on Windows and MacOS, unless you configured R such that it tries to install source packages; in that case, see below.\n\nInstall development versions from GitHub with:\n```r\nlibrary(remotes)\ninstall_github(\"r-spatial/sf\")\n```\n\n### Windows\n\nInstalling sf from source works under Windows when [Rtools](https://cran.r-project.org/bin/windows/Rtools/) is installed.\n\n### MacOS\n\nMacOS users are strongly encouraged to install the `sf` binary packages from CRAN, unless they are familiar with compilers, linking, C++ source code, and homebrew. If you experience that R tries to install `sf` from source (or otherwise your install fails but you don't understand what is going on) try again by explicitly installing the binary, using\n\n```r\ninstall.packages(\"sf\", type = \"binary\")\n```\n\nThe remainder of this section is for those who understand what source installs mean, and imply.\n\nPerhaps the easiest way of an install from source is to first install `gdal` using Homebrew. Recent versions of Homebrew include a full-featured up-to-date [gdal formula](https://github.com/Homebrew/homebrew-core/blob/master/Formula/g/gdal.rb), which installs `proj` and `gdal` at the same time:\n\n```\nbrew install pkg-config\nbrew install gdal\n```\n\nOnce gdal is installed, you may be able to install `sf` package from source in R. With the current version of `proj` on homebrew, installation requires additional configuration:\n\n```r\ninstall.packages(\"sf\", type = \"source\", configure.args = \"--with-proj-lib=$(brew --prefix)/lib/\")\n```\n\nOr the development version:\n\n```r\nlibrary(remotes)\ninstall_github(\"r-spatial/sf\", configure.args = \"--with-proj-lib=$(brew --prefix)/lib/\")\n```\n\nAlternatively, [these instructions](https://stat.ethz.ch/pipermail/r-sig-mac/2017-June/012429.html) explain how to install gdal using kyngchaos frameworks.\n\nFor Mac OS 11 Big Sur source install instruction, see [here](https://github.com/r-spatial/sf/issues/1536#issuecomment-727342736)\n\n### Linux\n\nFor Unix-alikes, GDAL (>= 2.0.1), GEOS (>= 3.4.0) and Proj.4 (>= 4.8.0) are required.\n\n#### Ubuntu\n\nDependencies for recent versions of Ubuntu (18.04 and later) are available in the official repositories; you can install them with:\n\n```sh\nsudo apt -y update && apt install -y libudunits2-dev libgdal-dev libgeos-dev libproj-dev libsqlite3-dev\n```\n\nHowever, to get more up-to-date versions of dependencies such as GDAL, GEOS and PROJ we recommend adding the [ubuntugis-unstable](http://ppa.launchpad.net/ubuntugis/ubuntugis-unstable/ubuntu/) PPA to the package repositories and installing them as follows:\n\n```sh\nsudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt update\nsudo apt install libudunits2-dev libgdal-dev libgeos-dev libproj-dev libsqlite3-dev\n```\n\nAdding this PPA is required for installing `sf` on older versions of Ubuntu (e.g. Xenial).\n\nAnother option, for advanced users, is to install dependencies from source; see e.g. an older [Travis](https://github.com/r-spatial/sf/blob/593ee48b34001fe3b383ea73ea57063ecf690732/.travis.yml) config file for hints.\n\n#### Fedora\nThe following command installs all required dependencies:\n```sh\nsudo dnf install gdal-devel proj-devel geos-devel sqlite-devel udunits2-devel\n```\n\n#### Arch\n\nGet gdal, proj, geos and podofo from the main repos, and udunits from the AUR:\n\n```\npacman -S gdal proj geos arrow podofo\nyay/pacaur/yaourt/whatever -S udunits\n```\n\n#### `renv` or `conda`\n\nThere are several reports that `sf` fails to install as a source package when R is used with `renv`, or when R is installed in a `conda` environment. If you experience this, please do not raise an issue here, but \n\n* try to sort this out with the `renv` developers or the `conda` maintainers, or\n* try to use binary installs of the `sf` package, e.g. from [r2u](https://github.com/eddelbuettel/r2u), or the Posit package manager\n\n#### Other\n\nTo install on Debian, the [rocker geospatial](https://github.com/rocker-org/geospatial) Dockerfiles may be helpful. Ubuntu Dockerfiles are found [here](https://github.com/r-spatial/sf/tree/main/inst/docker).\n\n### Multiple GDAL, GEOS and/or PROJ versions on your system\n\nIf you use dynamic linking (installation from source) and have multiple versions of these libraries installed (e.g. one from ubuntugis-unstable, another installed from source in `/usr/local/lib`) then this will in general not work, even when setting `LD_LIBRARY_PATH` manually. See [here](https://github.com/r-spatial/sf/issues/844) for the reason why. \n\n### lwgeom\n\nFunctions and methods that require `liblwgeom`, including ellipsoidal (not spherical or Euclidean) metrics (area, distances), are provide by and used from [lwgeom](https://github.com/r-spatial/lwgeom), which is also on [CRAN](https://cran.r-project.org/package=lwgeom).\n\n## Contributing\n\n* Contributions of all sorts are most welcome, issues and pull requests are the preferred ways of sharing them.\n* When contributing pull requests, please adhere to the package style (in package code use `=` rather than `<-`; don't change indentation; tab stops of 4 spaces are preferred).\n* This project is released with a [Contributor Code of Conduct](CONDUCT.md). By participating in this project, you agree to abide by its terms.\n\n## How to cite\n\nPackage `sf` can be cited as: \n\n* Edzer Pebesma, 2018.  Simple Features for R: Standardized Support\nfor Spatial Vector Data. The R Journal [10:1, 439-446.](https://journal.r-project.org/archive/2018/RJ-2018-009/index.html)\n\n* Pebesma, E.; Bivand, R. (2023). [Spatial Data Science: With Applications in R](https://r-spatial.org/book/) \n(1st ed.). 314 pages. [Chapman and Hall/CRC](https://doi.org/10.1201/9780429459016).\n\n## Acknowledgment\n\nThis project gratefully acknowledges financial [support](https://www.r-consortium.org/projects) from the\n\n<a href=\"https://r-consortium.org/all-projects/2016-group-1.html#simple-features-for-r\">\n<img src=\"https://r-consortium.org/images/RConsortium_Horizontal_Pantone.webp\" width=\"300\">\n</a>\n<!--\n<img src=\"http://pebesma.staff.ifgi.de/RConsortium_Horizontal_Pantone.png\" width=\"300\">\n-->\n\n",
      "stars_today": 0
    },
    {
      "id": 601205363,
      "name": "tt-metal",
      "full_name": "tenstorrent/tt-metal",
      "description": ":metal: TT-NN operator library, and TT-Metalium low level kernel programming model.",
      "html_url": "https://github.com/tenstorrent/tt-metal",
      "stars": 1309,
      "forks": 331,
      "language": "C++",
      "topics": [
        "accelerator",
        "ai",
        "cuda",
        "deepseek",
        "gpu",
        "img-gen",
        "kernels",
        "llama",
        "llm",
        "metal",
        "scale-out",
        "stable-diffusion",
        "tenstorrent",
        "video-gen"
      ],
      "created_at": "2023-02-13T15:30:05Z",
      "updated_at": "2026-01-16T00:59:25Z",
      "pushed_at": "2026-01-16T00:59:32Z",
      "open_issues": 3722,
      "owner": {
        "login": "tenstorrent",
        "avatar_url": "https://avatars.githubusercontent.com/u/64161552?v=4"
      },
      "readme": "[![tt-metal CI](https://github.com/tenstorrent/tt-metal/actions/workflows/all-post-commit-workflows.yaml/badge.svg)](https://github.com/tenstorrent/tt-metal/actions/workflows/all-post-commit-workflows.yaml)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/tenstorrent/tt-metal)\n\n<div align=\"center\">\n\n<h1>\n\n[Hardware](https://tenstorrent.com/hardware/blackhole) | [Install](./INSTALLING.md) |  [Discord](https://discord.gg/tvhGzHQwaj) | [Join Us](https://boards.greenhouse.io/tenstorrent/jobs/4155609007) | [Bounty $](https://github.com/tenstorrent/tt-metal/issues?q=is%3Aissue%20state%3Aopen%20label%3Abounty)\n\n</h1>\n\n<img src=\"https://raw.githubusercontent.com/tenstorrent/tt-metal/main/docs/source/common/_static/tt_nn_w_logo.png\" alt=\"ttnn logo\" height=\"180\"/>\n\n**TT-NN** is a Python & C++ Neural Network OP library.\n\n<h3>\n\n[API Reference](https://docs.tenstorrent.com/tt-metal/latest/ttnn/index.html) | [Model Demos](./models/demos/)\n\n</h3>\n\n</div>\n\n## Quick Links\n\n- [TT-Forge](https://github.com/tenstorrent/tt-forge/tree/main)\n- [TT-Forge-FE](https://github.com/tenstorrent/tt-forge-fe)\n- [TT-Torch](https://github.com/tenstorrent/tt-torch)\n- [TT-XLA](https://github.com/tenstorrent/tt-xla)\n- [TT-MLIR](https://github.com/tenstorrent/tt-mlir)\n- [TT-TVM](https://github.com/tenstorrent/tt-tvm)\n- [Releases](https://github.com/tenstorrent/tt-metal/releases)\n\n## Featured Models\n\nThe Models team is focused on developing the following models, optimizing them for performance, accuracy, and compatibility. Follow each model link for more details.\n\n>[!IMPORTANT]\n> For a **full model list** see the **[Model Matrix](https://github.com/tenstorrent/tt-metal/tree/main/models/README.md)**, or visit the **[Developer Hub](https://tenstorrent.com/developers)**.\n\n>[!NOTE]\n> Performance Metrics:\n> - Time to First Token (TTFT) measures the time (in milliseconds) it takes to generate the first output token after input is received.\n> - T/S/U (Tokens per Second per User): Represents the throughput of first-token generation after prefill. It is calculated as 1 / inter-token latency.\n> - T/S (Tokens per Second): Represents total token throughput, calculated as T/S = T/S/U x batch size.\n> - TP (Tensor Parallel) and DP (Data Parallel): Indicate the parallelization factors across multiple devices.\n> - Reported LLM Performance: Based on an input sequence length of 128 tokens for all models.\n> - Performance Data Source: Metrics were collected using the tt-metal model demos (linked above). Results may vary when using other runtimes such as the vLLM inference server.\n\n### [Llama 3.3 70B (TP=32)](./models/demos/llama3_70b_galaxy)\n| Batch | Hardware | TTFT (MS) | T/S/U | Target<br>T/S/U | T/S | TT-Metalium Release | vLLM Tenstorrent Repo Release |\n|-------|----------|-----------|-------|-----------------|-----|---------------------|-------------------------------|\n| 32    | [Galaxy (Wormhole)](https://tenstorrent.com/hardware/galaxy) | 53      | 72.5  | 80              | 2268.8  | [v0.65.0-rc7](https://github.com/tenstorrent/tt-metal/tree/v0.65.0-rc7) | [59be953](https://github.com/tenstorrent/vllm/tree/59be953f2bbd21e227f9ef4b779f545f9c3bf599/tt_metal) |\n\n### [Qwen 2.5 7B (TP=2)](https://github.com/tenstorrent/tt-metal/tree/main/models/tt_transformers)\n| Batch | Hardware | TTFT (MS) | T/S/U | Target<br>T/S/U | T/S  | TT-Metalium Release | vLLM Tenstorrent Repo Release |\n|-------|----------|-----------|-------|-----------------|------|---------------------|-------------------------------|\n| 32 | [n300 (Wormhole)](https://tenstorrent.com/hardware/wormhole) | 109 | 22.1 | 30 | 707.2 | [v0.62.0-rc35](https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc35) | [ced0161](https://github.com/tenstorrent/vllm/tree/ced0161dc223e6d8aca5f44a6c43d13070c3fba6/tt_metal) |\n\n### [Qwen 2.5 72B (TP=8)](https://github.com/tenstorrent/tt-metal/tree/main/models/tt_transformers)\n| Batch | Hardware | TTFT (MS) | T/S/U | Target<br>T/S/U | T/S | TT-Metalium Release | vLLM Tenstorrent Repo Release |\n|-------|----------|-----------|-------|-----------------|-----|---------------------|-------------------------------|\n| 32 | [QuietBox (Wormhole)](https://tenstorrent.com/hardware/tt-quietbox) | 223 | 15.4 | 20 | 492.8 | [v0.62.0-rc25](https://github.com/tenstorrent/tt-metal/tree/v0.62.0-rc25) | [e7c329b](https://github.com/tenstorrent/vllm/tree/e7c329b1664f8591ae8b4269bed9690726e52a24/tt_metal) |\n\n### [Whisper (distil-large-v3)](https://github.com/tenstorrent/tt-metal/tree/main/models/demos/whisper)\n| Batch | Hardware | TTFT (MS) | T/S/U | Target<br>T/S/U | T/S | TT-Metalium Release |\n|-------|----------|-----------|-------|-----------------|-----|---------------------|\n| 1     | [n150 (Wormhole)](https://tenstorrent.com/hardware/wormhole)        | 163       | 105.0  | 45           | 105.0   | [v0.65.0-dev20251208](https://github.com/tenstorrent/tt-metal/tree/v0.65.0-dev20251208) |\n| 1     | [p150 (Blackhole)](https://tenstorrent.com/hardware/blackhole)        | 63       | 263.4  |            | 263.4   | [v0.65.0-dev20251208](https://github.com/tenstorrent/tt-metal/tree/v0.65.0-dev20251208) |\n\n### [Mixtral 8x7B (TP=8)](https://github.com/tenstorrent/tt-metal/tree/main/models/tt_transformers)\n| Batch | Hardware | TTFT (MS) | T/S/U | Target<br>T/S/U | T/S | TT-Metalium Release |\n|-------|----------|-----------|-------|-----------------|-----|---------------------|\n| 32 | [QuietBox (Wormhole)](https://tenstorrent.com/hardware/tt-quietbox) | 122 | 24.9 | 33 | 796.8 | [v0.62.0-dev20251015](https://github.com/tenstorrent/tt-metal/tree/v0.62.0-dev20251015) |\n\nBlackhole software optimization is under active development.  Please join us in shaping the future of open source AI! <br> [\\[Discord\\]](https://discord.gg/tenstorrent) [\\[Developer Hub\\]](https://tenstorrent.com/developers)\n\nFor more information regarding vLLM installation and environment creation visit the [Tenstorrent vLLM repository](https://github.com/tenstorrent/vllm/blob/dev/tt_metal/README.md).\n\n## Model Updates\n\nFor the latest model updates and features, please see [MODEL_UPDATES.md](models/docs/MODEL_UPDATES.md)\n\n## Model Bring-Up and Testing\n\nFor information on initial model procedures, please see [Model Bring-Up and Testing](https://github.com/tenstorrent/tt-metal/blob/main/models/docs/model_bring_up.md)\n\n## TT-NN Tech Reports\n\n- [Advanced Performance Optimizations for Models](./tech_reports/AdvancedPerformanceOptimizationsForModels/AdvancedPerformanceOptimizationsForModels.md) (updated March 4th, 2025)\n- [Programming Mesh of Devices](./tech_reports/Programming_Mesh_of_Devices/Programming_Mesh_of_Devices_with_TT-NN.md) (updated Sept 9th, 2024)\n- [ViT Implementation in TT-NN on GS](./tech_reports/ViT-TTNN/vit.md)  (updated Sept 22nd, 2024)\n- [LLMs Bring up in TT-NN](./tech_reports/LLMs/llms.md)  (updated Oct 29th, 2024)\n- [CNN Bring up & Optimization in TT-NN](./tech_reports/CNNs/cnn_optimizations.md) (updated Jan 22nd, 2025)\n\n## Benchmarks\n\n- [Matrix Multiply FLOPS on Wormhole and Blackhole](./tech_reports/GEMM_FLOPS/GEMM_FLOPS.md)  (updated June 17th, 2025)\n\n---\n\n<div align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/tenstorrent/tt-metal/main/docs/source/common/images/tt_refresh_metalium_w_icon.png\" alt=\"TT-Metalium logo\" height=\"180\"/>\n\n**TT-Metalium** is our low-level programming model, enabling kernel development for Tenstorrent hardware.\n\n<h3>\n\n[Programming Guide](./METALIUM_GUIDE.md) | [API Reference](https://docs.tenstorrent.com/tt-metal/latest/tt-metalium/tt_metal/apis/index.html)\n\n</h3>\n</div>\n\n## Getting started\n\nGet started with [simple kernels](https://docs.tenstorrent.com/tt-metal/latest/tt-metalium/tt_metal/examples/index.html).\n\n## TT-Metalium Tech Reports\n\n- [Matrix Engine](./tech_reports/matrix_engine/matrix_engine.md) (updated Sept 6th, 2024)\n- [Data Formats](./tech_reports/data_formats/data_formats.md) (updated Sept 7th, 2024)\n- [Reconfiguring Data Formats](./tech_reports/data_formats/reconfig_data_format.md) (updated Oct 17th, 2024)\n- [Handling special floating-point numbers](./tech_reports/Handling_Special_Value/special_values.md) (updated Oct 5th, 2024)\n- [Allocator](./tech_reports/memory/allocator.md) (Updated Dec 19th, 2024)\n- [Tensor Layouts](./tech_reports/tensor_layouts/tensor_layouts.md) (updated Sept 6th, 2024)\n- [Saturating DRAM Bandwidth](./tech_reports/Saturating_DRAM_bandwidth/Saturating_DRAM_bandwidth.md) (updated Sept 6th, 2024)\n- [Flash Attention on Wormhole](./tech_reports/FlashAttention/FlashAttention.md) (updated Sept 6th, 2024)\n- [CNNs on TT Architectures](./tech_reports/CNNs/ttcnn.md) (updated Sept 6th, 2024)\n- [Ethernet and Multichip Basics](./tech_reports/EthernetMultichip/BasicEthernetGuide.md) (Updated Sept 20th, 2024)\n- [Blackhole Bring-Up Programming Guide](./tech_reports/Blackhole/BlackholeBringUpProgrammingGuide.md) (Updated Dec 18th, 2024)\n- [Sub-Devices](./tech_reports/SubDevices/SubDevices.md) (Updated Jan 7th, 2025)\n\n## TT-Metalium Programming Examples\n\n### Hello World\n\n- [Hello World! Compute Kernel](https://github.com/tenstorrent/tt-metal/blob/main/tt_metal/programming_examples/hello_world_compute_kernel/hello_world_compute.md)\n- [Hello World! Data Movement Kernel](https://github.com/tenstorrent/tt-metal/blob/main/tt_metal/programming_examples/hello_world_datamovement_kernel/hello_world_data_movement.md)\n\n### Add Integers\n\n- [Add 2 Integers in Baby RiscV](https://github.com/tenstorrent/tt-metal/blob/main/tt_metal/programming_examples/add_2_integers_in_riscv/add_2_integers_in_riscv.md)\n- [Add 2 Integers in Compute Kernel](https://github.com/tenstorrent/tt-metal/blob/main/tt_metal/programming_examples/add_2_integers_in_compute/add_2_integers_in_compute.md)\n\n### Simple Tensor Manipulation\n\n- [Sharding](./tech_reports/prog_examples/shard_data_rm/shard_data_rm.md)\n- [Padding](./tech_reports/prog_examples/pad_multi_core/pad_multi_core.md)\n\n### DRAM Data Movement\n\n- [Dram Loopback Data Movement](https://github.com/tenstorrent/tt-metal/blob/main/tt_metal/programming_examples/loopback/dram_loopback.md)\n\n### Eltwise\n\n- [Eltwise Unary OP in Vector Engine (SFPU)](https://github.com/tenstorrent/tt-metal/blob/main/tt_metal/programming_examples/eltwise_sfpu/eltwise_sfpu.md)\n- [Eltwise Binary OP in Matrix Engine (FPU)](https://github.com/tenstorrent/tt-metal/blob/main/tt_metal/programming_examples/eltwise_binary/eltwise_binary.md)\n\n### Matmul\n\n- [Matmul OP on a Single_core](https://github.com/tenstorrent/tt-metal/blob/main/tt_metal/programming_examples/matmul/matmul_single_core/matmul_single_core.md)\n- [Matmul OP on Multi_core (Basic)](https://github.com/tenstorrent/tt-metal/blob/main/tt_metal/programming_examples/matmul/matmul_multi_core/matmul_multi_core.md)\n- [Matmul Multi_core Reuse (Optimized)](./tech_reports/prog_examples/matmul_multi_core_optimized/data_reuse.md)\n- [Matmul Multi_core Multi-Cast (Optimized)](./tech_reports/prog_examples/matmul_multi_core_optimized/data_mcast.md)\n\n### Tools and Instruments\n\n#### [TT-NN Visualizer](https://github.com/tenstorrent/ttnn-visualizer)\nA comprehensive tool for visualizing and analyzing model execution, offering interactive graphs, memory plots, tensor details, buffer overviews, operation flow graphs, and multi-instance support with file or SSH-based report loading.\n\n#### [TT-Exalens](https://github.com/tenstorrent/tt-exalens)\nThe TT-Exalens repository describes TT-Lensium, a low-level debugging tool for Tenstorrent hardware. It allows developers to access and communicate with Wormhole and Blackhole devices.\n\n#### [TT-SMI](https://github.com/tenstorrent/tt-smi)\nThe TT-SMI repository describes the Tenstorrent System Management Interface. This command line utility can interact with Tenstorrent devices on host. TT-SMI provides an easy to use interface displaying device, telemetry, and firmware information.\n\n#### [Model Explorer](https://github.com/tenstorrent/model-explorer)\nThe Model Explorer is an intuitive and hierarchical visualization tool using model graphs. It organizes model operations into nested layers and provides features for model exploration and debugging.\n\n#### [Tracy Profiler](https://github.com/tenstorrent/tracy)\nThe Tracy Profiler is a real-time nanosecond resolution, remote telemetry, hybrid frame, and sampling tool. Tracy supports profiling CPU, GPU, memory allocation, locks, context switches, and more.\n\n#### [Kernel Print Debug](https://docs.tenstorrent.com/tt-metal/latest/tt-metalium/tools/kernel_print.html)\nDPRINT can print variables, addresses, and circular buffer data from kernels to the host terminal or log file. This feature is useful for debugging issues with kernels.\n\n#### [Watcher](https://github.com/tenstorrent/tt-metal/blob/main/docs/source/tt-metalium/tools/watcher.rst)\nWatcher monitors firmware and kernels for common programming errors, and overall device status. If an error or hang occurs, Watcher displays log data of that occurrence.\n\n#### [Inspector](https://github.com/tenstorrent/tt-metal/blob/main/docs/source/tt-metalium/tools/inspector.rst)\nInspector provides insights into host runtime. It logs necessary data for investigation and allows queries to host runtime data.\n\n## Related Tenstorrent Projects\n- [TT-Forge](https://github.com/tenstorrent/tt-forge/tree/main)\n- [TT-Forge-FE](https://github.com/tenstorrent/tt-forge-fe)\n- [TT-Torch](https://github.com/tenstorrent/tt-torch)\n- [TT-XLA](https://github.com/tenstorrent/tt-xla)\n- [TT-MLIR](https://github.com/tenstorrent/tt-mlir)\n- [TT-TVM](https://github.com/tenstorrent/tt-tvm)\n\n## Latest Releases\n\n| Release | Release Date | FW Version |\n|:---------:|:--------------:|:------------:|\n| 0.65.0 | ETA Dec 15, 2025 | 19.2.0 |\n| [0.64.5](https://github.com/tenstorrent/tt-metal/releases/tag/v0.64.5) | Dec  1, 2025 | 18.12.0 |\n| [0.64.4](https://github.com/tenstorrent/tt-metal/releases/tag/v0.64.4) | Nov 24, 2025 | 18.12.0 |\n| [0.64.3](https://github.com/tenstorrent/tt-metal/releases/tag/v0.64.3) | Nov 14, 2025 | 18.12.0 |\n| [0.64.0](https://github.com/tenstorrent/tt-metal/releases/tag/v0.64.0) | Oct 29, 2025 | 18.12.0 |\n| [0.63.0](https://github.com/tenstorrent/tt-metal/releases/tag/v0.63.0) | Sep 22, 2025 | 18.8.0 |\n| [0.62.2](https://github.com/tenstorrent/tt-metal/releases/tag/v0.62.2) | Aug 20, 2025 | 18.6.0 |\n| 0.61.0  | Skipped | - |\n| [0.60.1](https://github.com/tenstorrent/tt-metal/releases/tag/v0.60.1) | Jul 22, 2025 | 18.6.0 |\n| [0.59.0](https://github.com/tenstorrent/tt-metal/releases/tag/v0.59.0) | Jun 18, 2025 | - |\n| [0.58.0](https://github.com/tenstorrent/tt-metal/releases/tag/v0.58.0) | May 13, 2025 | - |\n| [0.57.0](https://github.com/tenstorrent/tt-metal/releases/tag/v0.57.0) | Apr 15, 2025 | - |\n| [0.56.0](https://github.com/tenstorrent/tt-metal/releases/tag/v0.56.0) | Mar 7, 2025  | - |\n\nVisit the [releases](https://github.com/tenstorrent/tt-metal/tree/main/releases) folder for details on releases, release notes, and estimated release dates.\n\n## Tenstorrent Bounty Program Terms and Conditions\nThis repo is a part of Tenstorrentâ€™s bounty program. If you are interested in helping to improve tt-metal, please make sure to read the [Tenstorrent Bounty Program Terms and Conditions](https://docs.tenstorrent.com/bounty_terms.html) before heading to the issues tab. Look for the issues that are tagged with both â€œbountyâ€ and difficulty level!\n\n## License\nTT-Metalium and TTNN are licensed under the Apache 2.0 License, as detailed in [LICENSE](LICENSE) and [LICENSE_understanding.txt](LICENSE_understanding.txt).\n\nSome distributable forms of this projectâ€”such as manylinux-compliant wheelsâ€”may need to bundle additional libraries beyond the standard Linux system libraries. For example:\n\n- libnuma\n- libhwloc\n- openmpi (when built with multihost support)\n- libevent (when built with multihost support)\n\nThese libraries are bound by their own license terms.\n",
      "stars_today": 0
    },
    {
      "id": 55534429,
      "name": "sentry-cocoa",
      "full_name": "getsentry/sentry-cocoa",
      "description": "The official Sentry SDK for iOS, tvOS, macOS, watchOS, iPadOS and visionOS.",
      "html_url": "https://github.com/getsentry/sentry-cocoa",
      "stars": 997,
      "forks": 375,
      "language": "Swift",
      "topics": [
        "cocoa",
        "crash",
        "crash-reporting",
        "crash-reports",
        "error-handler",
        "error-monitoring",
        "ios",
        "ipados",
        "macos",
        "objective-c",
        "sdk",
        "sentry",
        "swift",
        "tag-production",
        "team-mobile",
        "tvos",
        "visionos",
        "watchos"
      ],
      "created_at": "2016-04-05T18:55:09Z",
      "updated_at": "2026-01-15T19:56:23Z",
      "pushed_at": "2026-01-16T00:22:15Z",
      "open_issues": 363,
      "owner": {
        "login": "getsentry",
        "avatar_url": "https://avatars.githubusercontent.com/u/1396951?v=4"
      },
      "readme": "<div align=\"center\">\n    <a href=\"https://sentry.io/?utm_source=github&utm_medium=logo\" target=\"_blank\">\n        <img src=\"https://sentry-brand.storage.googleapis.com/github-banners/github-sdk-cocoa.jpg\" alt=\"Sentry for Apple\">\n    </a>\n</div>\n\n_Bad software is everywhere, and we're tired of it. Sentry is on a mission to help developers write better software faster, so we can get back to enjoying technology. If you want to join us [<kbd>**Check out our open positions**</kbd>](https://sentry.io/careers/)_\n\n> [!NOTE]\n> You are currently viewing the **`main`** branch which contains the upcoming **v9** release with breaking changes.\n>\n> For the stable **v8** release, please switch to the [`v8.x` branch](https://github.com/getsentry/sentry-cocoa/tree/v8.x) and refer to the [v8 CHANGELOG](https://github.com/getsentry/sentry-cocoa/blob/v8.x/CHANGELOG.md).\n\n# Official Sentry SDK for iOS / tvOS / macOS / watchOS <sup>(1)</sup>\n\n[![Build](https://img.shields.io/github/actions/workflow/status/getsentry/sentry-cocoa/build.yml?branch=main)](https://github.com/getsentry/sentry-cocoa/actions/workflows/build.yml?query=branch%3Amain)\n[![codecov.io](https://codecov.io/gh/getsentry/sentry-cocoa/branch/master/graph/badge.svg)](https://codecov.io/gh/getsentry/sentry-cocoa)\n[![CocoaPods compatible](https://img.shields.io/cocoapods/v/Sentry.svg)](https://cocoapods.org/pods/Sentry)\n[![SwiftPM compatible](https://img.shields.io/badge/spm-compatible-brightgreen.svg?style=flat)](https://swift.org/package-manager)\n![platforms](https://img.shields.io/cocoapods/p/Sentry.svg?style=flat)\n[![Swift Package Index](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fgetsentry%2Fsentry-cocoa%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/getsentry/sentry-cocoa)\n[![X Follow](https://img.shields.io/twitter/follow/sentry?label=sentry&style=social)](https://x.com/intent/follow?screen_name=sentry)\n[![Discord Chat](https://img.shields.io/discord/621778831602221064?logo=discord&logoColor=ffffff&color=7389D8)](https://discord.com/invite/sentry)\n\n# Installation\n\nSPM is the recommended way to include Sentry into your project, but we also support [CocoaPods](https://cocoapods.org/pods/Sentry), and provide pre-built XCFrameworks on [our GitHub Releases page](https://github.com/getsentry/sentry-cocoa/releases).\n\n# Initialization\n\n_Remember to call this as early in your application life cycle as possible_\nIdeally in `applicationDidFinishLaunching` in `AppDelegate`\n\n```swift\nimport Sentry\n\n// ....\n\nSentrySDK.start { options in\n    options.dsn = \"___PUBLIC_DSN___\"\n    options.debug = true // Helpful to see what's going on\n}\n```\n\n```objc\n@import Sentry;\n\n// ....\n\n[SentrySDK startWithConfigureOptions:^(SentryOptions *options) {\n    options.dsn = @\"___PUBLIC_DSN___\";\n    options.debug = @YES; // Helpful to see what's going on\n}];\n```\n\nFor more information checkout the [docs](https://docs.sentry.io/platforms/apple).\n\n<sup>(1)</sup>limited symbolication support and no crash handling.\n\n# Blog posts\n\n[Mobile Vitals - Four Metrics Every Mobile Developer Should Care About](https://blog.sentry.io/2021/08/23/mobile-vitals-four-metrics-every-mobile-developer-should-care-about/).\n\n[How to use Sentry Attachments with Mobile Applications](https://blog.sentry.io/2021/02/03/how-to-use-sentry-attachments-with-mobile-applications/?utm_source=github&utm_medium=readme&utm_campaign=sentry-cocoa).\n\n[Close the Loop with User Feedback](https://blog.sentry.io/2021/02/16/close-the-loop-with-user-feedback/?utm_source=github&utm_medium=readme&utm_campaign=sentry-cocoa).\n\n[A Sanity Listicle for Mobile Developers](https://blog.sentry.io/2021/03/30/a-sanity-listicle-for-mobile-developers/?utm_source=github&utm_medium=readme&utm_campaign=sentry-cocoa).\n\n# Resources\n\n- [![Documentation](https://img.shields.io/badge/documentation-sentry.io-green.svg)](https://docs.sentry.io/platforms/apple/)\n- [![Discussions](https://img.shields.io/github/discussions/getsentry/sentry-cocoa.svg)](https://github.com/getsentry/sentry-cocoa/discussions)\n- [![Discord Chat](https://img.shields.io/discord/621778831602221064?logo=discord&logoColor=ffffff&color=7389D8)](https://discord.com/invite/sentry)\n- [![Stack Overflow](https://img.shields.io/badge/stack%20overflow-sentry-green.svg)](http://stackoverflow.com/questions/tagged/sentry)\n- [![Code of Conduct](https://img.shields.io/badge/code%20of%20conduct-sentry-green.svg)](https://github.com/getsentry/.github/blob/master/CODE_OF_CONDUCT.md)\n- [![Twitter Follow](https://img.shields.io/twitter/follow/getsentry?label=getsentry&style=social)](https://twitter.com/intent/follow?screen_name=getsentry)\n",
      "stars_today": 0
    },
    {
      "id": 20360040,
      "name": "clusterProfiler",
      "full_name": "YuLab-SMU/clusterProfiler",
      "description": ":bar_chart: A universal enrichment tool for interpreting omics data",
      "html_url": "https://github.com/YuLab-SMU/clusterProfiler",
      "stars": 1154,
      "forks": 263,
      "language": "R",
      "topics": [
        "enrichment-analysis",
        "go",
        "gsea",
        "kegg",
        "rstats",
        "visualization"
      ],
      "created_at": "2014-05-31T16:34:32Z",
      "updated_at": "2026-01-15T03:16:51Z",
      "pushed_at": "2026-01-15T03:16:46Z",
      "open_issues": 362,
      "owner": {
        "login": "YuLab-SMU",
        "avatar_url": "https://avatars.githubusercontent.com/u/40430016?v=4"
      },
      "readme": "# clusterProfiler\n\n<img src=\"https://raw.githubusercontent.com/Bioconductor/BiocStickers/master/clusterProfiler/clusterProfiler.png\" height=\"200\" align=\"right\" />\n\n[![Project Status: Active - The project has reached a stable, usable\nstate and is being actively\ndeveloped.](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)\n[![](https://img.shields.io/badge/release%20version-4.18.1-green.svg)](https://www.bioconductor.org/packages/clusterProfiler)\n[![](https://img.shields.io/badge/devel%20version-4.19.2-green.svg)](https://github.com/guangchuangyu/clusterProfiler)\n[![Bioc](http://www.bioconductor.org/shields/years-in-bioc/clusterProfiler.svg)](https://www.bioconductor.org/packages/devel/bioc/html/clusterProfiler.html#since)\n\n[![platform](http://www.bioconductor.org/shields/availability/devel/clusterProfiler.svg)](https://www.bioconductor.org/packages/devel/bioc/html/clusterProfiler.html#archives)\n[![Build\nStatus](http://www.bioconductor.org/shields/build/devel/bioc/clusterProfiler.svg)](https://bioconductor.org/checkResults/devel/bioc-LATEST/clusterProfiler/)\n[![codecov](https://codecov.io/gh/GuangchuangYu/clusterProfiler/branch/master/graph/badge.svg)](https://codecov.io/gh/GuangchuangYu/clusterProfiler/)\n\n<!--\n[![Last-changedate](https://img.shields.io/badge/last%20change-2025--11--20-green.svg)](https://github.com/GuangchuangYu/clusterProfiler/commits/master)\n-->\n\n- [clusterProfiler](http://bioconductor.org/packages/clusterProfiler)\n  supports exploring functional characteristics of both coding and\n  non-coding genomics data for thousands of species with up-to-date gene\n  annotation.\n- It provides a universal interface for gene functional annotation from\n  a variety of sources and thus can be applied in diverse scenarios.\n- It provides a tidy interface to access, manipulate, and visualize\n  enrichment results to help users achieve efficient data interpretation\n- Datasets obtained from multiple treatments and time points can be\n  analyzed and compared in a single run, easily revealing functional\n  consensus and differences among distinct conditions\n\nFor details, please visit:\n\n- <https://yulab-smu.top/contribution-knowledge-mining/>\n- <https://yulab-smu.top/biomedical-knowledge-mining-book/>\n\n<img src=\"graphic-abstract-The-Innovation-2021.jpg\" width=\"890\"/>\n\n## :writing_hand: Authors\n\nGuangchuang YU <https://yulab-smu.top>\n\nSchool of Basic Medical Sciences, Southern Medical University\n\n------------------------------------------------------------------------\n\nIf you use\n[clusterProfiler](http://bioconductor.org/packages/clusterProfiler) in\npublished research, please cite the most appropriate paper(s) from this\nlist:\n\n1.  S Xu<sup>\\#</sup>, E Hu<sup>\\#</sup>, Y Cai<sup>\\#</sup>, Z\n    Xie<sup>\\#</sup>, X Luo<sup>\\#</sup>, L Zhan, W Tang, Q Wang, B Liu,\n    R Wang, W Xie, T Wu, L Xie, **G Yu**<sup>\\*</sup>. Using\n    clusterProfiler to characterise Multi-Omics Data. ***Nature\n    Protocols***. 2024, accepted. doi:\n    [10.1038/s41596-024-01020-z](https://doi.org/10.1038/s41596-024-01020-z)\n2.  T Wu<sup>\\#</sup>, E Hu<sup>\\#</sup>, S Xu, M Chen, P Guo, Z Dai, T\n    Feng, L Zhou, W Tang, L Zhan, X Fu, S Liu, X Bo<sup>\\*</sup>, **G\n    Yu**<sup>\\*</sup>. clusterProfiler 4.0: A universal enrichment tool\n    for interpreting omics data. ***The Innovation***. 2021,\n    2(3):100141. doi:\n    [10.1016/j.xinn.2021.100141](https://doi.org/10.1016/j.xinn.2021.100141)\n3.  **G Yu**<sup>\\*</sup>. Gene Ontology Semantic Similarity Analysis\n    Using GOSemSim. In: Kidder B. (eds) Stem Cell Transcriptional\n    Networks. ***Methods in Molecular Biology***. 2020, 2117:207-215.\n    Humana, New York, NY. doi:\n    [10.1007/978-1-0716-0301-7_11](https://doi.org/10.1007/978-1-0716-0301-7_11)\n4.  **G Yu**<sup>\\*</sup>. Using meshes for MeSH term enrichment and\n    semantic analyses. ***Bioinformatics***. 2018, 34(21):3766â€“3767.\n    doi:\n    [10.1093/bioinformatics/bty410](https://doi.org/10.1093/bioinformatics/bty410)\n5.  **G Yu**, QY He<sup>\\*</sup>. ReactomePA: an R/Bioconductor package\n    for reactome pathway analysis and visualization. ***Molecular\n    BioSystems***. 2016, 12(2):477-479. doi:\n    [10.1039/C5MB00663E](https://doi.org/10.1039/C5MB00663E)\n6.  **G Yu**<sup>\\*</sup>, LG Wang, and QY He<sup>\\*</sup>. ChIPseeker:\n    an R/Bioconductor package for ChIP peak annotation, comparison and\n    visualization. ***Bioinformatics***. 2015, 31(14):2382-2383. doi:\n    [10.1093/bioinformatics/btv145](https://doi.org/10.1093/bioinformatics/btv145)\n7.  **G Yu**<sup>\\*</sup>, LG Wang, GR Yan, QY He<sup>\\*</sup>. DOSE: an\n    R/Bioconductor package for Disease Ontology Semantic and Enrichment\n    analysis. ***Bioinformatics***. 2015, 31(4):608-609. doi:\n    [10.1093/bioinformatics/btu684](https://doi.org/10.1093/bioinformatics/btu684)\n8.  **G Yu**, LG Wang, Y Han and QY He<sup>\\*</sup>. clusterProfiler: an\n    R package for comparing biological themes among gene clusters.\n    ***OMICS: A Journal of Integrative Biology***. 2012, 16(5):284-287.\n    doi: [10.1089/omi.2011.0118](https://doi.org/10.1089/omi.2011.0118)\n9.  **G Yu**, F Li, Y Qin, X Bo<sup>\\*</sup>, Y Wu, S Wang<sup>\\*</sup>.\n    GOSemSim: an R package for measuring semantic similarity among GO\n    terms and gene products. ***Bioinformatics***. 2010, 26(7):976-978.\n    doi:\n    [10.1093/bioinformatics/btq064](https://doi.org/10.1093/bioinformatics/btq064)\n\n<!--\n&#10;\n&#10; r badge_custom(\"1st most cited paper\", \"in OMICS\", \"green\",\n  \"http://online.liebertpub.com/action/showMostCitedArticles?journalCode=omi\")`\n r badge_custom(\"ESI\", \"Highly Cited Paper\", \"green\")`\n r badge_doi(\"10.1089/omi.2011.0118\", \"green\")`\n&#10;\n------------------------------------------------------------------------\n&#10;### Citation\n&#10;\n&#10;\n<img src=\"https://guangchuangyu.github.io/software/citation_trend/clusterProfiler.png\" width=\"890\"/>\n&#10;\n### Download stats\n&#10;r badge_download_bioc(\"clusterProfiler\")\nr badge_bioc_download(\"clusterProfiler\", \"total\", \"blue\")\nr badge_bioc_download(\"clusterProfiler\", \"month\", \"blue\")\n&#10;\n<img src=\"https://guangchuangyu.github.io/software/dlstats/clusterProfiler.png\" width=\"890\"/>\n&#10;-->\n",
      "stars_today": 0
    },
    {
      "id": 369991603,
      "name": "supabase-swift",
      "full_name": "supabase/supabase-swift",
      "description": "A Swift SDK for Supabase. Query your Supabase database, subscribe to realtime events, upload and download files, browse Swift examples, invoke postgres functions via rpc, invoke supabase edge functions, query pgvector. ",
      "html_url": "https://github.com/supabase/supabase-swift",
      "stars": 1137,
      "forks": 221,
      "language": "Swift",
      "topics": [
        "database",
        "ios",
        "supabase",
        "swift"
      ],
      "created_at": "2021-05-23T07:46:26Z",
      "updated_at": "2026-01-16T00:14:04Z",
      "pushed_at": "2026-01-13T12:46:53Z",
      "open_issues": 25,
      "owner": {
        "login": "supabase",
        "avatar_url": "https://avatars.githubusercontent.com/u/54469796?v=4"
      },
      "readme": "# supabase-swift\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fsupabase%2Fsupabase-swift%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/supabase/supabase-swift)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fsupabase%2Fsupabase-swift%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/supabase/supabase-swift)\n[![Coverage Status](https://coveralls.io/repos/github/supabase/supabase-swift/badge.svg?branch=main)](https://coveralls.io/github/supabase/supabase-swift?branch=main)\n\nSupabase SDK for Swift. Mirrors the design of [supabase-js](https://github.com/supabase/supabase-js/blob/master/README.md).\n\n* Documentation: [https://supabase.com/docs/reference/swift/introduction](https://supabase.com/docs/reference/swift/introduction)\n\n## Usage\n\n### Requirements\n- iOS 13.0+ / macOS 10.15+ / tvOS 13+ / watchOS 6+ / visionOS 1+\n- Xcode 15.3+\n- Swift 5.10+\n\n> [!IMPORTANT]\n> Check the [Support Policy](#support-policy) to learn when dropping Xcode, Swift, and platform versions will not be considered a **breaking change**.\n\n### Installation\nInstall the library using the Swift Package Manager.\n\n```swift\nlet package = Package(\n    ...\n    dependencies: [\n        ...\n        .package(\n            url: \"https://github.com/supabase/supabase-swift.git\",\n            from: \"2.0.0\"\n        ),\n    ],\n    targets: [\n        .target(\n            name: \"YourTargetName\",\n            dependencies: [\n                .product(name: \"Supabase\", package: \"supabase-swift\") // Add as a dependency\n            ]\n        )\n    ]\n)\n```\n\nIf you're using Xcode, [use this guide](https://developer.apple.com/documentation/swift_packages/adding_package_dependencies_to_your_app) to add `supabase-swift` to your project. Use `https://github.com/supabase-community/supabase-swift.git` for the url when Xcode asks.\n\nIf you don't want the full Supabase environment, you can also add individual packages, such as `Functions`, `Auth`, `Realtime`, `Storage`, or `PostgREST`.\n\nThen you're able to import the package and establish the connection with the database.\n\n```swift\n/// Create a single supabase client for interacting with your database\nlet client = SupabaseClient(\n    supabaseURL: URL(string: \"https://xyzcompany.supabase.co\")!,\n    supabaseKey: \"public-anon-key\"\n)\n```\n\n### Initialize with custom options\n\n```swift\nlet client = SupabaseClient(\n    supabaseURL: URL(string: \"https://xyzcompany.supabase.co\")!, \n    supabaseKey: \"public-anon-key\",\n    options: SupabaseClientOptions(\n        db: .init(\n            schema: \"public\"\n        ),\n        auth: .init(\n            storage: MyCustomLocalStorage(),\n            flowType: .pkce\n        ),\n        global: .init(\n            headers: [\"x-my-custom-header\": \"my-app-name\"],\n            session: URLSession.myCustomSession\n        )\n    )\n)\n```\n\nAdditional examples are available [here](https://github.com/supabase/supabase-swift/tree/main/Examples).\n\n## Support Policy\n\nThis document outlines the scope of support for Xcode, Swift, and the various platforms (iOS, macOS, tvOS, watchOS, and visionOS) in Supabase.\n\n### Xcode\nWe only support Xcode versions that are currently eligible for submitting apps to the App Store. Once a specific version of Xcode is no longer supported, its removal from Supabase **won't be treated as a breaking change** and will occur in a minor release.\n\n### Swift\nThe minimum supported Swift version corresponds to the minor version released with the oldest-supported Xcode version. When a Swift version reaches its end of support, it will be dropped from Supabase in a **minor release**, and **this won't be considered a breaking change**.\n\n### Platforms\nWe maintain support for the four latest major versions of each platform, including the current version.\n\nWhen a platform version is no longer supported, Supabase will drop it in a **minor release**, and **this won't count as a breaking change**. For instance, iOS 14 will no longer be supported after the release of iOS 18, allowing its removal in a minor update.\n\nFor macOS, the named yearly releases are treated as major versions for this policy, regardless of their version numbers.\n\n> [!IMPORTANT]\n> Android, Linux and Windows works but aren't supported, and may stop working on future versions of the library.\n\n## Contributing\n\n- Fork the repo on GitHub\n- Clone the project to your own machine\n- Commit changes to your own branch\n- Push your work back up to your fork\n- Submit a Pull request so that we can review your changes and merge\n\n## Sponsors\n\nWe are building the features of Firebase using enterprise-grade, open source products. We support existing communities wherever possible, and if the products donâ€™t exist we build them and open source them ourselves. Thanks to these sponsors who are making the OSS ecosystem better for everyone.\n\n[![New Sponsor](https://user-images.githubusercontent.com/10214025/90518111-e74bbb00-e198-11ea-8f88-c9e3c1aa4b5b.png)](https://github.com/sponsors/supabase)\n",
      "stars_today": 0
    },
    {
      "id": 259225467,
      "name": "CellChat",
      "full_name": "sqjin/CellChat",
      "description": "R toolkit for inference, visualization and analysis of cell-cell communication from single-cell data",
      "html_url": "https://github.com/sqjin/CellChat",
      "stars": 756,
      "forks": 167,
      "language": "R",
      "topics": [
        "cell-cell-communication",
        "cell-cell-interaction",
        "microenvironment",
        "single-cell-analysis"
      ],
      "created_at": "2020-04-27T06:28:33Z",
      "updated_at": "2026-01-11T17:20:28Z",
      "pushed_at": "2024-01-06T18:23:14Z",
      "open_issues": 455,
      "owner": {
        "login": "sqjin",
        "avatar_url": "https://avatars.githubusercontent.com/u/32399212?v=4"
      },
      "readme": "\n<p align=\"center\">\n  <img width=\"200\"  src=\"https://github.com/sqjin/CellChat/blob/master/CellChat_Logo.png\">\n</p>\n\n# CAUTION\nWe have updated CellChat to v2 and migrated CellChat to a new repository. This repository will be NOT updated and maintained any more. Please check the new repository [jinworks/CellChat](https://github.com/jinworks/CellChat) for the new updates, and the [CellChat v2 paper](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) for a comprehensive protocol of CellChat.  \n\n# About CellChat and CellChatDB\nCellChat is an R package designed for inference, analysis, and visualization of cell-cell communication from single-cell data. CellChat aims to enable users to identify and interpret cell-cell communication within an easily interpretable framework, with the emphasis of clear, attractive, and interpretable visualizations.  \n\nCellChatDB is a manually curated database of literature-supported ligand-receptor interactions in mutiple species, leading to a comprehensive recapitulation of known molecular interaction mechanisms including multi-subunit structure of ligand-receptor complexes and co-factors.\n\nIf you use CellChat in your research, please considering citing our papers: \n- [Suoqin Jin et al., CellChat for systematic analysis of cell-cell communication from single-cell and spatially resolved transcriptomics, bioRxiv 2023](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) [CellChat v2]\n- [Suoqin Jin et al., Inference and analysis of cell-cell communication using CellChat, Nature Communications 2021](https://www.nature.com/articles/s41467-021-21246-9) [CellChat v1]\n\n# Capabilities\nIn addition to infer the intercellular communication from any given single-cell data, CellChat provides functionality for further data exploration, analysis, and visualization. \n\n- It can quantitatively characterize and compare the inferred cell-cell communication networks using a systems approach by combining social network analysis, pattern recognition, and manifold learning approaches.\n- It provides an easy-to-use tool for extracting and visualizing high-order information of the inferred networks. For example, it allows ready prediction of major signaling inputs and outputs for all cell populations and how these populations and signals coordinate together for functions.\n- It enables comparative analysis of cell-cell communication across different conditions and identification of altered signaling and cell populations. \n- It provides several visualization outputs to facilitate intuitive user-guided data interpretation.\n\n<p align=\"center\">\n  <img width=\"700\"  src=\"https://github.com/sqjin/CellChat/blob/master/overview_CellChat.png\">\n</p>\n\n\n<p align=\"center\">\n  <a href=\"https://clustrmaps.com/site/1bpq2\">\n     <img width=\"200\"  src=\"https://clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=n&d=42WqeykSXznN_NSaBlpf6CtSXQxhqmIs6QusUsguFdY\" />\n   </a>\n</p>\n<p align=\"center\">\n  <a href=\"#\">\n     <img src=\"https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fsqjin%2FCellChat&labelColor=%233499cc&countColor=%2370c168\" />\n   </a>\n</p>\n\n\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 53894616,
      "name": "infercnv",
      "full_name": "broadinstitute/infercnv",
      "description": "Inferring CNV from Single-Cell RNA-Seq",
      "html_url": "https://github.com/broadinstitute/infercnv",
      "stars": 648,
      "forks": 177,
      "language": "R",
      "topics": [],
      "created_at": "2016-03-14T21:53:54Z",
      "updated_at": "2026-01-12T23:27:31Z",
      "pushed_at": "2025-11-14T17:35:17Z",
      "open_issues": 236,
      "owner": {
        "login": "broadinstitute",
        "avatar_url": "https://avatars.githubusercontent.com/u/393552?v=4"
      },
      "readme": "\n***********************************************\n>InferCNV is no longer supported. Please explore alternatives such as InferCNA (https://jlaffy.github.io/infercna/)[https://jlaffy.github.io/infercna/], CopyKAT (https://github.com/navinlabcode/copykat)[https://github.com/navinlabcode/copykat], and Numbat (https://github.com/kharchenkolab/numbat)[https://github.com/kharchenkolab/numbat]\n***********************************************\n\n# Subclustering\n\nSubclustering resolution is one of the primary settings that will need to be adjusted in most runs to avoid oversplitting. The tutorial below explains how it works and details about it can also be found on the [wiki](https://github.com/broadinstitute/infercnv/wiki/infercnv-tumor-subclusters#tumor-subclustering-by-leiden-clustering-preferred).\n\n# Documentation\n### Full documentation\n\nVisit project [wiki](https://github.com/broadinstitute/inferCNV/wiki) for InferCNV documentation.\n\n\n### Infercnv video tutorial\n\nA **video** tutorial giving on overview of infercnv features and how to run an analysis can be found below **(click on the image)**:\n\n[![Tutorial: Running infercnv](http://img.youtube.com/vi/-qOcHAavZT8/0.jpg)](http://www.youtube.com/watch?v=-qOcHAavZT8 \"Tutorial: Running infercnv\")\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 120286519,
      "name": "nichenetr",
      "full_name": "saeyslab/nichenetr",
      "description": "NicheNet: predict active ligand-target links between interacting cells",
      "html_url": "https://github.com/saeyslab/nichenetr",
      "stars": 602,
      "forks": 134,
      "language": "R",
      "topics": [
        "cell-cell-communication",
        "data-integration",
        "gene-expression",
        "intercellular-communication",
        "ligand-receptor",
        "ligand-target",
        "network-inference",
        "rna-seq",
        "single-cell-omics",
        "single-cell-rna-seq"
      ],
      "created_at": "2018-02-05T09:58:45Z",
      "updated_at": "2026-01-12T00:44:16Z",
      "pushed_at": "2025-11-12T09:07:45Z",
      "open_issues": 25,
      "owner": {
        "login": "saeyslab",
        "avatar_url": "https://avatars.githubusercontent.com/u/18485264?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n<!-- github markdown built using\nrmarkdown::render(\"README.Rmd\",output_format = \"md_document\")\n-->\n\n# nichenetr\n\n<!-- badges: start -->\n\n[![R build\nstatus](https://github.com/saeyslab/nichenetr/workflows/R-CMD-check-bioc/badge.svg)](https://github.com/saeyslab/nichenetr/actions)\n[![Coverage\nStatus](https://codecov.io/gh/saeyslab/nichenetr/branch/master/graph/badge.svg)](https://codecov.io/gh/saeyslab/nichenetr)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3260758.svg)](https://doi.org/10.5281/zenodo.3260758)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7074291.svg)](https://doi.org/10.5281/zenodo.7074291)\n<!-- badges: end -->\n\n**nichenetr: the R implementation of the NicheNet method.** The goal of\nNicheNet is to study intercellular communication from a computational\nperspective. NicheNet uses human or mouse gene expression data of\ninteracting cells as input and combines this with a prior model that\nintegrates existing knowledge on ligand-to-target signaling paths. This\nallows to predict ligand-receptor interactions that might drive gene\nexpression changes in cells of interest.\n\nWe describe the NicheNet algorithm in the following paper: [NicheNet:\nmodeling intercellular communication by linking ligands to target\ngenes](https://www.nature.com/articles/s41592-019-0667-5).\n\nTo help users **customize NicheNet** to their specific biological use-case, we have recently published a **best practices workflow** cultivated over four years of experience and user feedback  \n[Unraveling cell-cell communication with NicheNet by inferring active\nligands from transcriptomics\ndata](https://www.nature.com/articles/s41596-024-01121-9). In the\nstep-by-step protocol, we describe both a â€˜sender-agnosticâ€™ approach\nthat considers ligands from the entire microenvironment and a\nâ€˜sender-focusedâ€™ approach that only considers ligands from cell\npopulations of interest. We also include a new downstream procedure for\nprioritizing cell type-specific ligand-receptor pairs. The code to\nreproduce this protocol and the resulting figures can be found on\n<https://github.com/saeyslab/nichenet_protocol>.\n\n## Installation of nichenetr\n\nInstallation typically takes a few minutes, depending on the number of\ndependencies that has already been installed on your PC. You can install\nnichenetr (and required dependencies) from github with:\n\n``` r\nif(!requireNamespace(\"devtools\", quietly = TRUE)) {\n  install.packages(\"devtools\") \n}\n\ndevtools::install_github(\"saeyslab/nichenetr\")\n```\n\nnichenetr was tested on both Windows and Linux (most recently tested R\nversion: R 4.3.2)\n\n## Overview of NicheNet\n\n<details>\n<summary>\n<h3>\nBackground\n</h3>\n</summary>\n\nNicheNet strongly differs from most computational approaches to study\ncell-cell communication (CCC), as summarized conceptually by the figure\nbelow (**top panel:** current ligand-receptor inference approaches;\n**bottom panel:** NicheNet). Many approaches to study CCC from\nexpression data involve linking ligands expressed by sender cells to\ntheir corresponding receptors expressed by receiver cells. However,\nfunctional understanding of a CCC process also requires knowing how\nthese inferred ligand-receptor interactions result in changes in the\nexpression of downstream target genes within the receiver cells.\nTherefore, we developed NicheNet to consider the gene regulatory effects\nof ligands. <br><br>\n<img src=\"vignettes/images/comparison_other_approaches_2.jpg\"\nwidth=\"450\" /> <br><br>\n\nAt the core of NicheNet is a prior knowledge model, created by\nintegrating three types of databasesâ€”ligand-receptor interactions,\nsignaling pathways, and transcription factor (TF) regulationâ€”to form a\ncomplete communication network spanning from ligands to their downstream\ntarget genes (see figure below). Therefore, this model goes beyond\nligand-receptor interactions and incorporates intracellular signaling\nand transcriptional regulation as well. As a result, NicheNet is able to\npredict which ligands influence the expression in another cell, which\ntarget genes are affected by each ligand, and which signaling mediators\nmay be involved. By generating these novel types of hypotheses, NicheNet\ncan drive an improved functional understanding of a CCC process of\ninterest. Note that although we provide a pre-built prior model, it is\nalso possible to construct your own model (see vignettes below).\n\n<img src=\"vignettes/images/nichenet_prior_model.png\"\nstyle=\"width:70.0%\" />\n</details>\n<details>\n<summary>\n<h3>\nMain functionalities of nichenetr\n</h3>\n</summary>\n\n- Assessing how well ligands expressed by a sender cell can predict\n  changes in gene expression in the receiver cell\n- Prioritizing ligands based on their effect on gene expression\n- Inferring putative ligand-target links active in the system under\n  study\n- Inferring potential signaling paths between ligands and target genes\n  of interest: to generate causal hypotheses and check which data\n  sources support the predictions\n- Validation of the prior ligand-target model\n- Construction of user-defined prior ligand-target models\n\nMoreover, we provide instructions on how to make intuitive\nvisualizations of the main predictions (e.g., via circos plots as shown\nhere below).\n\n<br><br>\n<img src=\"vignettes/images/circos_plot_adapted.jpg\" width=\"600\" />\n\n</details>\n\nAs input to NicheNet, users must provide cell type-annotated expression\ndata that reflects a cell-cell communication (CCC) event. The input can\nbe single-cell or sorted bulk data from human or mouse. As output,\nNicheNet returns the ranking of ligands that best explain the CCC event\nof interest, as well as candidate target genes with high potential to be\nregulated by these ligands. As an intermediate step, we extract the\nthree features required for the analysis: a list of potential ligands, a\ngene set that captures the downstream effects of the CCC event of\ninterest, and a background set of genes. Further explanation on each\nfeature can be found in the introductory vignette.\n\n![](vignettes/images/figure1.svg) <br><br>\n\n## Learning to use nichenetr\n\nThe following vignettes contain the explanation on how to perform a\nbasic NicheNet analysis on a Seurat object. This includes prioritizing\nligands and predicting target genes of prioritized ligands. We recommend\nstarting with the step-by-step analysis, but we also demonstrate the use\nof a single wrapper function. This demo analysis takes only a few\nminutes to run.\n\n- [Perform NicheNet analysis starting from a Seurat object: step-by-step\n  analysis](vignettes/seurat_steps.md):`vignette(\"seurat_steps\", package=\"nichenetr\")`\n- [Perform NicheNet analysis starting from a Seurat\n  object](vignettes/seurat_wrapper.md):`vignette(\"seurat_wrapper\", package=\"nichenetr\")`\n\nCase study on HNSCC tumor which demonstrates the flexibility of\nNicheNet. Here, the gene set of interest was determined by the original\nauthors, and the expression data is a matrix rather than a Seurat\nobject.\n\n- [NicheNetâ€™s ligand activity analysis on a gene set of\n  interest](vignettes/ligand_activity_geneset.md):\n  `vignette(\"ligand_activity_geneset\", package=\"nichenetr\")`\n\nThe following vignettes contain explanation on how to do some follow-up\nanalyses after performing the most basic analysis:\n\n- [Prioritization of ligands based on expression\n  values](vignettes/seurat_steps_prioritization.md):\n  `vignette(\"seurat_steps_prioritization\", package=\"nichenetr\")`\n- [Inferring ligand-to-target signaling\n  paths](vignettes/ligand_target_signaling_path.md):\n  `vignette(\"ligand_target_signaling_path\", package=\"nichenetr\")`\n- [Assess how well top-ranked ligands can predict a gene set of\n  interest](vignettes/target_prediction_evaluation_geneset.md):\n  `vignette(\"target_prediction_evaluation_geneset\", package=\"nichenetr\")`\n- [Single-cell NicheNetâ€™s ligand activity\n  analysis](vignettes/ligand_activity_single_cell.md):\n  `vignette(\"ligand_activity_single_cell\", package=\"nichenetr\")`\n\nIf you want to make a circos plot visualization of the NicheNet output\nto show active ligand-target links between interacting cells, you can\ncheck following vignettes:\n\n- [Seurat Wrapper + circos\n  visualization](vignettes/seurat_wrapper_circos.md):`vignette(\"seurat_wrapper_circos\", package=\"nichenetr\")`.\n- [HNSCC case study + double circos\n  visualization](vignettes/circos.md):`vignette(\"circos\", package=\"nichenetr\")`.\n\nPeople interested in building their own models or benchmarking their own\nmodels against NicheNet can read one of the following vignettes:\n\n- [Model construction](vignettes/model_construction.md):\n  `vignette(\"model_construction\", package=\"nichenetr\")`\n- [Using LIANA ligand-receptor databases to construct the ligand-target\n  model](vignettes/model_construction_with_liana.md):\n  `vignette(\"model_construction_with_liana\", package=\"nichenetr\")`\n- [Model evaluation: target gene and ligand activity\n  prediction](vignettes/model_evaluation.md):\n  `vignette(\"model_evaluation\", package=\"nichenetr\")`\n- [Parameter optimization via\n  NSGAII-R](vignettes/parameter_optimization.md):\n  `vignette(\"parameter_optimization\", package=\"nichenetr\")`\n\n## FAQ\n\nCheck the FAQ page at [FAQ NicheNet](vignettes/faq.md):\n`vignette(\"faq\", package=\"nichenetr\")`\n\n<details>\n<summary>\n<h2>\nPrevious updates\n</h2>\n</summary>\n\n**20-06-2023:**\n\n- MultiNicheNet - a multi-sample, multi-condition extension of\n  NicheNet - is now available on\n  [biorxiv](https://www.biorxiv.org/content/10.1101/2023.06.13.544751v1)\n  and [Github](https://github.com/saeyslab/multinichenetr).\n- MultiNicheNet uses an [updated prior model\n  (v2)](https://zenodo.org/record/7074291/) consisting of additional\n  ligand-receptor interactions from the [Omnipath\n  database](https://omnipathdb.org/) and from [Verschueren et\n  al.Â (2020)](https://www.sciencedirect.com/science/article/pii/S0092867420306942?via%3Dihub).\n  We have now also updated the vignettes of NicheNet to use the new\n  model instead.\n- **New functionality:** we have included additional functions to\n  prioritize ligands not only based on the ligand activity, but also on\n  the ligand and receptor expression, cell type specificity, and\n  condition specificity. This is similar to the criteria used in\n  Differential NicheNet and MultiNicheNet. See the [Prioritizing ligands\n  based on expression values](vignettes/seurat_steps_prioritization.md)\n  vignette for more information.\n- Due to this more generalizable prioritization scheme, we will no\n  longer provide support for Differential NicheNet.\n- We included code for making a ligand-receptor-target circos plot in\n  the [Circos plot visualization](vignettes/circos.md) vignette.\n\n<h5>\nDeprecated vignettes\n</h5>\n\nDifferential NicheNet has been deprecated: we will not longer provide\nsupport or code fixes on Differential NicheNet and its vignettes. You\nmay want to consider using the [general prioritization\nscheme](vignettes/seurat_steps_prioritization.md) instead.\n\n- [Differential NicheNet analysis between niches of\n  interest](vignettes/differential_nichenet.md):`vignette(\"differential_nichenet\", package=\"nichenetr\")`\n- [Differential NicheNet analysis between conditions of\n  interest](vignettes/differential_nichenet_pEMT.md):`vignette(\"differential_nichenet_pEMT\", package=\"nichenetr\")`\n\nIn NicheNet v2, the mouse and human ligand-target models are uploaded\nseparately so symbol conversion is not necessary. If you are still using\nthe NicheNet v1 model, you can check the following vignette on how to\nconvert the model (given in human symbols) to mouse symbols:\n\n- [Converting NicheNetâ€™s model from human to mouse\n  symbols](vignettes/symbol_conversion.md):\n  `vignette(\"symbol_conversion\", package=\"nichenetr\")`\n\n**12-01-2022:** In the Liver Atlas paper from Guilliams et al.: [Spatial\nproteogenomics reveals distinct and evolutionarily conserved hepatic\nmacrophage\nniches](https://www.sciencedirect.com/science/article/pii/S0092867421014811),\nwe used Differential NicheNet, an extension to the default NicheNet\nalgorithm. **Differential NicheNet** can be used to compare cell-cell\ninteractions between different niches and better predict niche-specific\nligand-receptor (L-R) pairs. It was used in that paper to predict\nligand-receptor pairs specific for the Kupffer cell niche in mouse and\nhuman.\n\nThe main difference between the classic NicheNet pipeline and the\nDifferential NicheNet pipeline is that Differential NicheNet also uses\nthe differential expression between the conditions/niches of the\nligand-receptor pairs for prioritization in addition to the ligand\nactivities. The classic NicheNet pipeline on the contrary uses only\nligand acivity for prioritization (and shows differential expression\nonly in visualizations).\n\nSo if you have data of multiple conditions or niches, and you want to\ninclude differential expression of the ligand-receptor pairs in the\nprioritization, we recommend you check out Differential NicheNet (update\nnichenetr to the 1.1.0 version). At the bottom of this page, you can\nfind the links to two vignettes illustrating a Differential NicheNet\nanalysis. We recommend these vignettes if you want to apply Differential\nNicheNet on your own data. If you want to see the code used for the\nanalyses used in the Guilliams et al.Â paper, see\n<https://github.com/saeyslab/NicheNet_LiverCellAtlas>.\n\n**15-10-2019:** Bonnardel, Tâ€™Jonck et al.Â used NicheNet to predict\nupstream niche signals driving Kupffer cell differentiation [Stellate\nCells, Hepatocytes, and Endothelial Cells Imprint the Kupffer Cell\nIdentity on Monocytes Colonizing the Liver Macrophage\nNiche](https://www.cell.com/immunity/fulltext/S1074-7613(19)30368-1).\n\n</details>\n\n## References\n\nBrowaeys, R., Saelens, W. & Saeys, Y. NicheNet: modeling intercellular\ncommunication by linking ligands to target genes. Nat Methods (2019)\n<doi:10.1038/s41592-019-0667-5>\n\nBonnardel et al.Â Stellate Cells, Hepatocytes, and Endothelial Cells\nImprint the Kupffer Cell Identity on Monocytes Colonizing the Liver\nMacrophage Niche. Immunity (2019) <doi:10.1016/j.immuni.2019.08.017>\n\nGuilliams et al.Â Spatial proteogenomics reveals distinct and\nevolutionarily conserved hepatic macrophage niches. Cell (2022)\n<doi:10.1016/j.cell.2021.12.018>\n",
      "stars_today": 0
    },
    {
      "id": 28114218,
      "name": "dada2",
      "full_name": "benjjneb/dada2",
      "description": "Accurate sample inference from amplicon data with single nucleotide resolution",
      "html_url": "https://github.com/benjjneb/dada2",
      "stars": 532,
      "forks": 162,
      "language": "R",
      "topics": [
        "amplicon",
        "bioconductor",
        "bioinformatics",
        "metabarcoding",
        "metagenomics",
        "microbiome",
        "taxonomy"
      ],
      "created_at": "2014-12-17T00:53:58Z",
      "updated_at": "2026-01-07T21:19:32Z",
      "pushed_at": "2025-12-15T19:22:15Z",
      "open_issues": 193,
      "owner": {
        "login": "benjjneb",
        "avatar_url": "https://avatars.githubusercontent.com/u/5797204?v=4"
      },
      "readme": "\n[![Build Status](https://app.travis-ci.com/benjjneb/dada2.svg?branch=master)](https://app.travis-ci.com/benjjneb/dada2)\n\n# dada2\n\nExact sample inference from high-throughput amplicon data. Resolves real variants differing by as little as one nucleotide. Visit [the DADA2 website](https://benjjneb.github.io/dada2/index.html) for the most detailed and up-to-date documentation.\n\n### Installation\n\nThe dada2 package binaries are available through Bioconductor:\n\n```S\n## try http:// if https:// URLs are not supported\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"dada2\")\n```\n\nIn order to install dada2 from source (and get the latest and greatest new features) see our [installation from source instructions](https://benjjneb.github.io/dada2/dada-installation.html).\n\n### Documentation\n\nThe [tutorial walkthrough of the DADA2 pipeline on paired end Illumina Miseq data](https://benjjneb.github.io/dada2/tutorial.html). \n\nThe [dada2 R package manual](https://www.bioconductor.org/packages/3.6/bioc/manuals/dada2/man/dada2.pdf).\n\nFurther documentation is available on [the DADA2 front page](http://benjjneb.github.io/dada2/). \n\n### DADA2 Articles\n\n[DADA2: High resolution sample inference from Illumina amplicon data. Nature Methods, 2016.](http://dx.doi.org/10.1038/nmeth.3869) [(Open Access link.)](http://rdcu.be/ipGh)\n\n[Bioconductor workflow for microbiome data analysis: from raw reads to community analyses. F1000 Research, 2016.](https://f1000research.com/articles/5-1492)\n\n[Exact sequence variants should replace operational taxonomic units in marker-gene data analysis. ISMEJ, 2017.](http://dx.doi.org/10.1038/ismej.2017.119)\n\n[High-throughput amplicon sequencing of the full-length 16S rRNA gene with single-nucleotide resolution. Nucleic Acids Research, 2019.](http://dx.doi.org/10.1093/nar/gkz569)\n\n### Other Resources\n\nPlanned feature improvements are publicly catalogued at the main DADA2 development site on github, specifically on the \"Issues\" page for DADA2:\n\nhttps://github.com/benjjneb/dada2/issues\n\nIf the feature you are hoping for is not listed, you are welcome to add it as a feature request \"issue\" on this page. This request will be publicly available and listed on the page.\n\nBugs and difficulties in using DADA2 are also welcome on [the issue tracker](https://github.com/benjjneb/dada2/issues).\n",
      "stars_today": 0
    },
    {
      "id": 50672978,
      "name": "gcam-core",
      "full_name": "JGCRI/gcam-core",
      "description": "GCAM -- The Global Change Analysis Model",
      "html_url": "https://github.com/JGCRI/gcam-core",
      "stars": 376,
      "forks": 203,
      "language": "R",
      "topics": [
        "climate",
        "coupled-human-natural-systems",
        "economics",
        "energy",
        "gcam",
        "human-earth-system",
        "integrated-assessment",
        "land",
        "water"
      ],
      "created_at": "2016-01-29T15:57:28Z",
      "updated_at": "2026-01-14T17:19:35Z",
      "pushed_at": "2025-12-12T20:56:28Z",
      "open_issues": 253,
      "owner": {
        "login": "JGCRI",
        "avatar_url": "https://avatars.githubusercontent.com/u/8431983?v=4"
      },
      "readme": "# Global Change Analysis Model (GCAM)\n\nThe Joint Global Change Research Institute (JGCRI) of the Pacific \nNorthwest National Laboratory (PNNL) is the home and primary \ndevelopment institution for GCAM, a multisector model for exploring \nconsequences of and responses to global to local changes and stressors. \nRegional energy, water, land, and economic systems are connected to the\nrest of the globe through trade and interactions with environmental systems.\nThese systems are also connected with each other.\nMultisector models such as GCAM capture these \ninterconnected impacts in an economic framework in order to explore \nthese dynamic interactions and feedbacks between regions and sectors.\n\nGCAM has been developed at PNNL-JGCRI for over 20 years and is a freely\navailable community model and documented online (See below). The team\nat JGCRI is comprised of physical scientists, engineers, economists, energy\nexperts, forest ecologists, agricultural scientists, and environmental system\nscientists who develop the model and apply it to a range of research questions.\nThe JGCRI team works closely with the developers of other Earth system and\necosystem models to integrate the effects of human actions modeled in GCAM\ninto their research.\n\n## Model Overview\n\nGCAM is a dynamic-recursive model with technology-rich representations\nof the economy, energy sector, land use, and water linked to a reduced complexity\nEarth system model that can be used to explore many science and decision-relevant\nquestions including the effects of changes in trade patterns, critical minerals\n& materials availability, and deployment of energy technologies on human and\nEarth systems. Regional population and labor productivity growth assumptions\ndrive the energy and land-use systems, employing numerous technology options to\nproduce, transform, and provide energy services, as well as to produce\nagriculture and forest products, and to determine land use and land cover.\nUsing a run period extending from 1990 â€“ 2100 (historical years through 2021)\nwith annual results computed at 1-5 year intervals, GCAM has been used to\nexplore the potential role of emerging energy supply technologies and\nthe consequences of specific measures or energy technology adoption, including\nbioenergy; critical minerals & materials; hydrogen systems; nuclear energy;\nrenewable energy technologies; carbon capture, storage, and utilization and\nenergy use technology in buildings, industry, and the transportation\nsectors. GCAM outputs include projections of future energy and critical mineral\nsupply, trade, and demand and the resulting radiative forcing and other effects\nof 16 greenhouse gases, aerosols, and short-lived species at 0.5Ã—0.5 degree\nresolution, contingent on assumptions about future population, economy, technology,\ntrade and other polices.\n\n## Community guidelines for peer-reviewed journal articles using GCAM\n\nThis section outlines some suggested language which the GCAM user community \ncan employ to describe GCAM in papers in peer-reviewed journal articles,\nreports, or other public documents using GCAM or versions of GCAM. GCAM is\nunder continuous development. The suggested language for the opening paragraphs\nof a methodology or introduction section of a paper describing GCAM is as\nfollows:\n\n\"The Global Change Analysis Model (GCAM) is a multisector model developed and maintained at the Pacific Northwest National Laboratoryâ€™s Joint Global Change Research Institute (JGCRI, 2023) _\\<include additional citations to previous GCAM studies as relevant\\>_. GCAM is an open-source community model. In this study, we use GCAM v NN. The documentation of the model is available at the GCAM documentation page ([http://jgcri.github.io/gcam-doc](http://jgcri.github.io/gcam-doc)) and the description below is a summary. GCAM includes representations of: economy, energy, agriculture, and water supply in 32 geopolitical regions across the globe; their GHG and air pollutant emissions and global GHG concentrations, radiative forcing, and temperature change; and the associated land allocation, water use, and agriculture production across 396 land sub-regions and 235 water basins.  _\\<If using GCAM-USA, include without quotes: \"This study uses a U.S.-focused version of GCAM called GCAM-USA that includes representation of energy, economy, and water systems for the fifty states and the District of Columbia in addition to 31 regions outside of the United States.â€\\>_. The version of GCAM used in this study is available â€“ along with full source code and instructions for use â€“ in a public repository _\\<include citation including link to the GCAM repository with doi used in paper\\>_. \n\nSubsequent paragraphs of the description might expound on particular capabilities, systems, or sectors of focus in the paper. Details in the GCAM documentation page can be used as a reference to develop these paragraphs.\n\nCommunity users of GCAM might also undertake their own model developments and/or assumptions for papers. It is recommended that these departures from the publicly available version of the model be clearly described. In addition, if these developments are substantial, we suggest making this clear by including an additional phrase (e.g. region name or name of institution) in the name of the model and explicitly calling it out in place of or immediately following the italicized portion in the above paragraphs. For example: _\"This study uses a modified version of GCAM/GCAM-USA called GCAM-\\<institution name\\>/GCAM-USA-\\<institution name\\>. GCAM-\\<institution name\\>/GCAM-USA-\\<institution name\\> incorporates additional details and modified assumptions from GCAM v NN as described subsequently\"_. \n\n## Documentation\n\n* [GCAM Documentation](http://jgcri.github.io/gcam-doc/)\n* [Getting Started with GCAM](http://jgcri.github.io/gcam-doc/user-guide.html)\n* [GCAM Community](https://gcims.pnnl.gov/community)\n* [GCAM Videos and Tutorial Slides](https://gcims.pnnl.gov/community)\n* [GCAM Citation and Co-authorship Guidelines](http://jgcri.github.io/gcam-doc/community-guide.html)\n\n## Selected Publications\n\nCalvin, K., Patel, P., Clarke, L., Asrar, G., Bond-Lamberty, B., Cui, R. Y., Di Vittorio, A., Dorheim, K., Edmonds, J., Hartin, C., Hejazi, M., Horowitz, R., Iyer, G., Kyle, P., Kim, S., Link, R., McJeon, H., Smith, S. J., Snyder, A., Waldhoff, S., and Wise, M.: GCAM v5.1: representing the linkages between energy, water, land, climate, and economic systems, Geosci. Model Dev., 12, 677â€“698, https://doi.org/10.5194/gmd-12-677-2019, 2019.\n\nEdmonds, J., and J. Reilly (1985)Global Energy: Assessing the Future (Oxford University Press, New York) pp.317.\n\nEdmonds, J., M. Wise, H. Pitcher, R. Richels, T. Wigley, and C. MacCracken. (1997) â€œAn Integrated Assessment of Climate Change and the Accelerated Introduction of Advanced Energy Technologiesâ€, Mitigation and Adaptation Strategies for Global Change, 1, pp. 311-39\n\nKim, S.H., J. Edmonds, J. Lurz, S. J. Smith, and M. Wise (2006) â€œThe ObjECTS Framework for Integrated Assessment: Hybrid Modeling of Transportation â€ Energy Journal (Special Issue #2) pp 51-80.\n\n[Full list of GCAM publications](http://jgcri.github.io/gcam-doc/references.html)\n",
      "stars_today": 0
    },
    {
      "id": 167440342,
      "name": "monocle3",
      "full_name": "cole-trapnell-lab/monocle3",
      "description": null,
      "html_url": "https://github.com/cole-trapnell-lab/monocle3",
      "stars": 430,
      "forks": 114,
      "language": "R",
      "topics": [
        "single-cell-rna-seq"
      ],
      "created_at": "2019-01-24T21:26:18Z",
      "updated_at": "2026-01-12T00:26:39Z",
      "pushed_at": "2026-01-08T18:32:17Z",
      "open_issues": 259,
      "owner": {
        "login": "cole-trapnell-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8060918?v=4"
      },
      "readme": "MONOCLE 3\n=======================\n\nMonocle 3 is an analysis toolkit for single-cell RNA-Seq experiments.  To use this package, you will need the R statistical computing environment (version 3.0 or later) and several packages available through Bioconductor and CRAN.\n\nDetails on how to install and use Monocle 3 are available on our website:\n\nhttp://cole-trapnell-lab.github.io/monocle3/\n\n## Monocle3 with BPCells counts matrix support\n\nThis development branch version of Monocle3 adds the ability to store the counts matrix on-disk using the BPCells package. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as in previous versions. In order to store the matrix on-disk, you must set the matrix_control list value `matrix_class=\"BPCells\"` in the affected commands. For example, to load a MatrixMarket file as an on-disk matrix, use the command\n\n```\ncds <- load_mm_data(mat_path=<path_to_mtx_file>,\n                    feature_anno_path=<path_to_feature_anno_file>,\n                    cell_anno_path=<path_to_cell_anno_file>,\n                    matrix_control=list(matrix_class='BPCells'))\n```\n\n### Install Monocle3 with BPCells\n\nYou must install BPCells from Github before you can install this Monocle3 version, and BPCells requires an HDF5 object library for installation. After installing the HDF5 library, you install BPCells using the command\n\n```\nremotes::install_github(\"bnprks/BPCells/r\")\n```\n\nThe [BPCells Github site](https://github.com/bnprks/BPCells)  has additional information.\n\nSome Linux distributions provide the HDF5 library as an option. The\nBPCells site has information about installing the HDF5 library on various operating systems.\n\nI used Homebrew to install an HDF5 library on MacOS. I seemed to need to install the pkg-config package as well, and add a pkg-config configuration file for HDF5. Homebrew installed pkg-config in '/opt/homebrew' so I added the hdf5.pc file in\n\n> /opt/homebrew/lib/pkgconfig/hdf5.pc\n\nwith the contents\n\n```\nprefix=/opt/homebrew/Cellar/hdf5/1.12.2_2\nexec_prefix=${prefix}\nincludedir=${prefix}/include\nlibdir=/opt/homebrew/Cellar/hdf5/1.12.2_2/lib\n  \nName: hdf5\nDescription: HDF5\nURL: xx\nVersion: 1.12.2_2\nCflags: -I${includedir}\nLibs: -L${libdir} -lhdf5\n```\n\nYou may need to update the version strings in your hdf5.pc file.\n\nMonocle3 no longer uses the terra package, so it does not need to be installed.\n\n### Notes\n\n- Monocle3 can use the BPCells package to store the feature-cell counts matrix on-disk rather than in-memory, which enables analysis of considerably larger data sets than before. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as it has in the past. To store the counts matrix on-disk, use the parameter `matrix_control=list(matrix_class=\"BPCells\")` when you make the CDS or convert the counts matrix using one of the functions\n  - `load_mm_data()`\n  - `load_mtx_data()`\n  - `load_cellranger_data()`\n  - `load_a549()`\n  - `load_worm_embryo()`\n  - `load_worm_l2()`\n  - `convert_counts_matrix()`\n\n  For example, to convert a dgCMatrix counts matrix to a BPCells on-disk matrix in an existing CDS, use the command `cds <- convert_counts_matrix(cds, matrix_control=list(matrix_class=\"BPCells\"))`.\n- BPCells stores the count matrix information in directories with names similar to `monocle.bpcells.20230830.4c4b1bebe4b4.tmp`. Monocle3 tries to remove those directories when you quit R. Please do not remove them while Monocle3 is running because doing so eliminates the count matrix data. You *can* remove them after quitting R if Monocle3 fails to remove them.\n- The method `new_cell_data_set()` accepts a BPCells on-disk counts matrix.\n- The functions `save_monocle_objects()` and `load_monocle_objects()` store and load BPCells on-disk matrices when the CDS counts matrix is an on-disk BPCells matrix.\n- The Monocle3 `saveRDS()` function warns the user to use `save_monocle_objects()` when saving a CDS with a BPCells on-disk counts matrix. If you insist on using the `saveRDS()` function, the BPCells on-disk matrix directory will not be stored and you will be unable to load it with the `readRDS()` function.\n- The function `combine_cds()` combines CDSes with mixes of dgCMatrix and BPCells on-disk counts matrices into a BPCells on-disk counts matrix. When called with the `matrix_control=list(matrix_class=\"BPCells\")` parameter, `combine_cds()` combines CDSes with all dgCMatrix counts matrices into a BPCells on-disk counts matrix.\n- Note that when the counts matrix is stored as a BPCells on-disk matrix, the `new_cell_data_set()` method stores a second BPCells on-disk copy of the matrix in the CDS assays slot with the name `counts_row_order`. The `counts_row_order` matrix is used by Monocle3 when the counts matrix is accessed intensively by row. The reason is that, by default, BPCells stores the matrix as a one-dimensional vector in column-major order, as does R. As a result, column access is fast and row access is slow. We use BPCell's ability to also store and access matrices in row-major order, which gives fast row access. However, this means that the two copies of the counts matrix must have the same count values. If you replace or change the CDS's counts matrix, you must also update the `counts_row_order` matrix, which you can do using the function `set_cds_row_order_matrix()`.\n  - The CDS assays slot is a named list where the standard, column-major order, matrix is called `counts` and the BPCells row-major order matrix is called `counts_row_order`.\n  - The `counts` matrix getter and setter methods are `counts(cds)` and `counts(cds)<-`.\n  - The Monocle3 setter warns about re-setting the BPCells `counts_row_order` matrix, unless called with the parameter `bpcells_warn=FALSE`.\n  - The `counts_row_order` getter method is called `counts_row_order`.\n  - There is no corresponding `counts_row_order` setter method\n- By default, the BPCells on-disk matrix is stored in a directory that is created where R is started. You can change the directory location using the `matrix_path` value in the `matrix_control` parameter.\n- For more information about the `matrix_control` values, see the help document for the function `set_matrix_control()`.\n- I tested this version using BPCells counts matrices on the examples in the Monocle3 documentation although I did not try all of the plotting functions.\n\n",
      "stars_today": 0
    },
    {
      "id": 185880527,
      "name": "signac",
      "full_name": "stuart-lab/signac",
      "description": "R toolkit for the analysis of single-cell chromatin data",
      "html_url": "https://github.com/stuart-lab/signac",
      "stars": 400,
      "forks": 102,
      "language": "R",
      "topics": [
        "atac",
        "bioinformatics",
        "single-cell"
      ],
      "created_at": "2019-05-09T22:32:26Z",
      "updated_at": "2026-01-10T20:34:16Z",
      "pushed_at": "2025-12-11T05:17:49Z",
      "open_issues": 19,
      "owner": {
        "login": "stuart-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/102445397?v=4"
      },
      "readme": "# Signac <img align=\"right\" src=\"man/figures/logo.svg\" style=\"height:100px;\" />\n\n[![R-CMD-check](https://github.com/stuart-lab/signac/workflows/R-CMD-check/badge.svg)](https://github.com/stuart-lab/signac/actions)\n[![CRAN\nVersion](https://www.r-pkg.org/badges/version/Signac)](https://cran.r-project.org/package=Signac)\n[![CRAN\nDownloads](https://cranlogs.r-pkg.org/badges/Signac)](https://cran.r-project.org/package=Signac)\n\n## Overview\n\nSignac is a comprehensive R package for the analysis of single-cell\nchromatin data. Signac includes functions for quality control,\nnormalization, dimension reduction, clustering, differential activity,\nand more.\n\nDocumentation and tutorials can be found at\n<https://stuartlab.org/signac/>\n\n## Installation\n\nTo install the latest release of Signac from CRAN:\n\n``` r\nsetRepositories(ind=1:3) # needed to automatically install Bioconductor dependencies\ninstall.packages(\"Signac\")\n```\n\nTo release the latest develop version from GitHub:\n\n``` r\nif (!requireNamespace(\"remotes\", quietly = TRUE))\n    install.packages(\"remotes\")\nremotes::install_github(\"stuart-lab/signac\", ref = \"develop\")\n```\n\n## Release notes\n\nFor a changelog please see the [NEWS\nfile](https://github.com/stuart-lab/signac/blob/develop/NEWS.md), also\navailable on the [Signac\nwebsite](https://stuartlab.org/signac/news/index.html).\n\n## Contributing\n\nWe welcome contributions to the Signac package. Please see the\n[contribution guide](https://github.com/stuart-lab/signac/blob/develop/CONTRIBUTING.md)\nfor more information.\n\n## Getting help\n\nIf you encounter a bug or have a feature request, please open an\n[issue](https://github.com/stuart-lab/signac/issues).\n\nIf you would like to discuss questions related to single-cell analysis,\nyou can open a\n[discussion](https://github.com/stuart-lab/signac/discussions).\n\n## Citing Signac\n\nIf you use the Signac package in your work please cite [Stuart et\nal. 2021](https://doi.org/10.1038/s41592-021-01282-5)\n\n```\n@ARTICLE{signac,\n  title     = \"Single-cell chromatin state analysis with Signac\",\n  author    = \"Stuart, Tim and Srivastava, Avi and Madad, Shaista and Lareau,\n               Caleb A and Satija, Rahul\",\n  journal   = \"Nat. Methods\",\n  publisher = \"Nature Publishing Group\",\n  pages     = \"1--9\",\n  month     =  nov,\n  year      =  2021,\n  url       = \"https://www.nature.com/articles/s41592-021-01282-5\",\n  language  = \"en\"\n}\n```\n\n## Related packages\n\n-   [Seurat](https://github.com/satijalab/seurat)\n-   [SeuratObject](https://github.com/satijalab/seurat-object)\n-   [SeuratDisk](https://github.com/mojaveazure/seurat-disk)\n-   [SeuratData](https://github.com/satijalab/seurat-data)\n-   [SeuratWrappers](https://github.com/satijalab/seurat-wrappers)\n-   [Azimuth](https://github.com/satijalab/azimuth)\n",
      "stars_today": 0
    }
  ],
  "created_at": "2026-01-16T01:06:36.470680966Z"
}